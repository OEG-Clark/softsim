{"home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.BasicBlock.__init__": [[59, 68], ["torch.Module.__init__", "resnet.conv3x3", "bn_fn", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "bn_fn"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.conv3x3", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "bn_fn", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "bn_fn", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "bn_fn", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.BasicBlock.forward": [[69, 86], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.BasicBlockFilm.__init__": [[97, 106], ["torch.Module.__init__", "resnet.conv3x3", "bn_fn", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "bn_fn"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.conv3x3", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "bn_fn", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlockFilm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "bn_fn", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "bn_fn", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.BasicBlockFilm.forward": [[107, 137], ["resnet.BasicBlockFilm.conv1", "resnet.BasicBlockFilm.bn1", "resnet.BasicBlockFilm._film", "resnet.BasicBlockFilm.relu", "resnet.BasicBlockFilm.conv2", "resnet.BasicBlockFilm.bn2", "resnet.BasicBlockFilm._film", "resnet.BasicBlockFilm.relu", "resnet.BasicBlockFilm.downsample"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.BasicBlockFilm._film", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.BasicBlockFilm._film"], ["", "def", "forward", "(", "self", ",", "x", ",", "gamma1", ",", "beta1", ",", "gamma2", ",", "beta2", ")", ":", "\n", "        ", "\"\"\"\n        Implements a forward pass through the FiLM adapted ResNet block. FiLM parameters for adaptation are passed\n        through to the method, one gamma / beta set for each convolutional layer in the block (2 for the blocks we are\n        working with).\n        :param x: (torch.tensor) Batch of images to apply computation to.\n        :param gamma1: (torch.tensor) Multiplicative FiLM parameter for first conv layer (one for each channel).\n        :param beta1: (torch.tensor) Additive FiLM parameter for first conv layer (one for each channel).\n        :param gamma2: (torch.tensor) Multiplicative FiLM parameter for second conv layer (one for each channel).\n        :param beta2: (torch.tensor) Additive FiLM parameter for second conv layer (one for each channel).\n        :return: (torch.tensor) Resulting representation after passing through layer.\n        \"\"\"", "\n", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "_film", "(", "out", ",", "gamma1", ",", "beta1", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "_film", "(", "out", ",", "gamma2", ",", "beta2", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.BasicBlockFilm._film": [[138, 142], ["None"], "methods", ["None"], ["", "def", "_film", "(", "self", ",", "x", ",", "gamma", ",", "beta", ")", ":", "\n", "        ", "gamma", "=", "gamma", "[", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "beta", "=", "beta", "[", "None", ",", ":", ",", "None", ",", "None", "]", "\n", "return", "gamma", "*", "x", "+", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.ResNet.__init__": [[145, 165], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "bn_fn", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "resnet.ResNet.modules", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "bn_fn", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "initial_pool", "=", "False", "\n", "inplanes", "=", "self", ".", "inplanes", "=", "64", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "self", ".", "inplanes", ",", "kernel_size", "=", "5", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "bn_fn", "(", "self", ".", "inplanes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", ",", "layers", "[", "0", "]", ",", "bn_fn", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", "*", "2", ",", "layers", "[", "1", "]", ",", "bn_fn", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", "*", "4", ",", "layers", "[", "2", "]", ",", "bn_fn", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", "*", "8", ",", "layers", "[", "3", "]", ",", "bn_fn", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", "or", "isinstance", "(", "m", ",", "TaskNormI", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.ResNet._make_layer": [[166, 181], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "resnet.conv1x1", "bn_fn", "block"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.conv1x1"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "bn_fn", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "stride", ")", ",", "\n", "bn_fn", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "bn_fn", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "bn_fn", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.ResNet.forward": [[182, 198], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.maxpool", "resnet.ResNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "param_dict", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "if", "self", ".", "initial_pool", ":", "\n", "            ", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.ResNet.get_layer_output": [[199, 214], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "range", "resnet.ResNet.maxpool"], "methods", ["None"], ["", "def", "get_layer_output", "(", "self", ",", "x", ",", "param_dict", ",", "layer_to_return", ")", ":", "\n", "        ", "if", "layer_to_return", "==", "0", ":", "\n", "            ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "if", "self", ".", "initial_pool", ":", "\n", "                ", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "", "return", "x", "\n", "", "else", ":", "\n", "            ", "resnet_layers", "=", "[", "self", ".", "layer1", ",", "self", ".", "layer2", ",", "self", ".", "layer3", ",", "self", ".", "layer4", "]", "\n", "layer", "=", "layer_to_return", "-", "1", "\n", "for", "block", "in", "range", "(", "self", ".", "layers", "[", "layer", "]", ")", ":", "\n", "                ", "x", "=", "resnet_layers", "[", "layer", "]", "[", "block", "]", "(", "x", ",", "param_dict", "[", "layer", "]", "[", "block", "]", "[", "'gamma1'", "]", ",", "param_dict", "[", "layer", "]", "[", "block", "]", "[", "'beta1'", "]", ",", "\n", "param_dict", "[", "layer", "]", "[", "block", "]", "[", "'gamma2'", "]", ",", "param_dict", "[", "layer", "]", "[", "block", "]", "[", "'beta2'", "]", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.ResNet.output_size": [[215, 218], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "512", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.FilmResNet.__init__": [[226, 229], ["resnet.ResNet.__init__"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__"], ["def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "bn_fn", ")", ":", "\n", "        ", "ResNet", ".", "__init__", "(", "self", ",", "block", ",", "layers", ",", "bn_fn", ")", "\n", "self", ".", "layers", "=", "layers", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.FilmResNet.forward": [[230, 262], ["resnet.FilmResNet.conv1", "resnet.FilmResNet.bn1", "resnet.FilmResNet.relu", "range", "range", "range", "range", "resnet.FilmResNet.avgpool", "resnet.FilmResNet.view", "resnet.FilmResNet.maxpool", "resnet.FilmResNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "param_dict", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass through ResNet. Same logic as standard ResNet, but expects a dictionary of FiLM parameters to be\n        provided (by adaptation network objects).\n        :param x: (torch.tensor) Batch of images to pass through ResNet.\n        :param param_dict: (list::dict::torch.tensor) One dictionary for each block in each layer of the ResNet,\n                           containing the FiLM adaptation parameters for each conv layer in the model.\n        :return: (torch.tensor) Feature representation after passing through adapted network.\n        \"\"\"", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "if", "self", ".", "initial_pool", ":", "\n", "            ", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "", "for", "block", "in", "range", "(", "self", ".", "layers", "[", "0", "]", ")", ":", "\n", "            ", "x", "=", "self", ".", "layer1", "[", "block", "]", "(", "x", ",", "param_dict", "[", "0", "]", "[", "block", "]", "[", "'gamma1'", "]", ",", "param_dict", "[", "0", "]", "[", "block", "]", "[", "'beta1'", "]", ",", "\n", "param_dict", "[", "0", "]", "[", "block", "]", "[", "'gamma2'", "]", ",", "param_dict", "[", "0", "]", "[", "block", "]", "[", "'beta2'", "]", ")", "\n", "", "for", "block", "in", "range", "(", "self", ".", "layers", "[", "1", "]", ")", ":", "\n", "            ", "x", "=", "self", ".", "layer2", "[", "block", "]", "(", "x", ",", "param_dict", "[", "1", "]", "[", "block", "]", "[", "'gamma1'", "]", ",", "param_dict", "[", "1", "]", "[", "block", "]", "[", "'beta1'", "]", ",", "\n", "param_dict", "[", "1", "]", "[", "block", "]", "[", "'gamma2'", "]", ",", "param_dict", "[", "1", "]", "[", "block", "]", "[", "'beta2'", "]", ")", "\n", "", "for", "block", "in", "range", "(", "self", ".", "layers", "[", "2", "]", ")", ":", "\n", "            ", "x", "=", "self", ".", "layer3", "[", "block", "]", "(", "x", ",", "param_dict", "[", "2", "]", "[", "block", "]", "[", "'gamma1'", "]", ",", "param_dict", "[", "2", "]", "[", "block", "]", "[", "'beta1'", "]", ",", "\n", "param_dict", "[", "2", "]", "[", "block", "]", "[", "'gamma2'", "]", ",", "param_dict", "[", "2", "]", "[", "block", "]", "[", "'beta2'", "]", ")", "\n", "", "for", "block", "in", "range", "(", "self", ".", "layers", "[", "3", "]", ")", ":", "\n", "            ", "x", "=", "self", ".", "layer4", "[", "block", "]", "(", "x", ",", "param_dict", "[", "3", "]", "[", "block", "]", "[", "'gamma1'", "]", ",", "param_dict", "[", "3", "]", "[", "block", "]", "[", "'beta1'", "]", ",", "\n", "param_dict", "[", "3", "]", "[", "block", "]", "[", "'gamma2'", "]", ",", "param_dict", "[", "3", "]", "[", "block", "]", "[", "'beta2'", "]", ")", "\n", "\n", "", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.conv3x3": [[45, 49], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.conv1x1": [[51, 54], ["torch.Conv2d"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.get_normalization_layer": [[264, 271], ["None"], "function", ["None"], ["", "", "def", "get_normalization_layer", "(", "batch_normalization", ")", ":", "\n", "    ", "if", "batch_normalization", "==", "\"task_norm-i\"", ":", "\n", "        ", "nl", "=", "TaskNormI", "\n", "", "else", ":", "\n", "        ", "nl", "=", "nn", ".", "BatchNorm2d", "\n", "\n", "", "return", "nl", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.resnet18": [[273, 285], ["resnet.get_normalization_layer", "resnet.ResNet", "torch.load", "torch.load", "ResNet.load_state_dict"], "function", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.get_normalization_layer"], ["", "def", "resnet18", "(", "pretrained", "=", "False", ",", "pretrained_model_path", "=", "None", ",", "batch_normalization", "=", "'basic'", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n        Constructs a ResNet-18 model.\n    \"\"\"", "\n", "nl", "=", "get_normalization_layer", "(", "batch_normalization", ")", "\n", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "nl", ",", "**", "kwargs", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "ckpt_dict", "=", "torch", ".", "load", "(", "pretrained_model_path", ")", "\n", "model", ".", "load_state_dict", "(", "ckpt_dict", "[", "'state_dict'", "]", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.film_resnet18": [[287, 300], ["resnet.get_normalization_layer", "resnet.FilmResNet", "torch.load", "torch.load", "FilmResNet.load_state_dict"], "function", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.get_normalization_layer"], ["", "def", "film_resnet18", "(", "pretrained", "=", "False", ",", "pretrained_model_path", "=", "None", ",", "batch_normalization", "=", "\"eval\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n        Constructs a FiLM adapted ResNet-18 model.\n    \"\"\"", "\n", "nl", "=", "get_normalization_layer", "(", "batch_normalization", ")", "\n", "\n", "model", "=", "FilmResNet", "(", "BasicBlockFilm", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "nl", ",", "**", "kwargs", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "ckpt_dict", "=", "torch", ".", "load", "(", "pretrained_model_path", ")", "\n", "model", ".", "load_state_dict", "(", "ckpt_dict", "[", "'state_dict'", "]", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.prepare_extra_datasets.ExtraDatasetConverter.create_splits": [[17, 20], ["sorted", "os.listdir"], "methods", ["None"], ["    ", "def", "create_splits", "(", "self", ")", ":", "\n", "        ", "class_names", "=", "sorted", "(", "os", ".", "listdir", "(", "self", ".", "data_root", ")", ")", "\n", "return", "{", "'train'", ":", "[", "]", ",", "'valid'", ":", "[", "]", ",", "'test'", ":", "class_names", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.prepare_extra_datasets.ExtraDatasetConverter.create_dataset_specification_and_records": [[21, 33], ["prepare_extra_datasets.ExtraDatasetConverter.get_splits", "len", "len", "len", "enumerate", "print", "os.path.join", "os.path.join", "meta_dataset.dataset_conversion.dataset_to_records.write_tfrecord_from_directory", "prepare_extra_datasets.ExtraDatasetConverter.dataset_spec.file_pattern.format"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print"], ["", "def", "create_dataset_specification_and_records", "(", "self", ")", ":", "\n", "        ", "splits", "=", "self", ".", "get_splits", "(", "force_create", "=", "True", ")", "\n", "self", ".", "classes_per_split", "[", "learning_spec", ".", "Split", ".", "TRAIN", "]", "=", "len", "(", "splits", "[", "'train'", "]", ")", "\n", "self", ".", "classes_per_split", "[", "learning_spec", ".", "Split", ".", "VALID", "]", "=", "len", "(", "splits", "[", "'valid'", "]", ")", "\n", "self", ".", "classes_per_split", "[", "learning_spec", ".", "Split", ".", "TEST", "]", "=", "len", "(", "splits", "[", "'test'", "]", ")", "\n", "\n", "for", "class_id", ",", "class_name", "in", "enumerate", "(", "splits", "[", "'test'", "]", ")", ":", "\n", "            ", "print", "(", "'Creating record for class ID {} ({})'", ".", "format", "(", "class_id", ",", "class_name", ")", ")", "\n", "class_directory", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_root", ",", "class_name", ")", "\n", "class_records_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "records_path", ",", "self", ".", "dataset_spec", ".", "file_pattern", ".", "format", "(", "class_id", ")", ")", "\n", "self", ".", "class_names", "[", "class_id", "]", "=", "class_name", "\n", "self", ".", "images_per_class", "[", "class_id", "]", "=", "write_tfrecord_from_directory", "(", "class_directory", ",", "class_id", ",", "class_records_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.prepare_extra_datasets.process_cifar": [[35, 66], ["prepare_extra_datasets.process_cifar.unpickle"], "function", ["None"], ["", "", "", "def", "process_cifar", "(", "src_path", ",", "dst_path", ",", "imagesFileName", ",", "labelsFileName", ",", "labelKey1", ",", "labelKey2", ")", ":", "\n", "    ", "def", "unpickle", "(", "file", ")", ":", "\n", "        ", "with", "open", "(", "file", ",", "'rb'", ")", "as", "fo", ":", "\n", "            ", "dict", "=", "pickle", ".", "load", "(", "fo", ",", "encoding", "=", "'bytes'", ")", "\n", "", "return", "dict", "\n", "\n", "", "def", "save_images_in_data_batch", "(", "source_dir", ",", "data_batch", ",", "data_dir", ",", "labelKey1", ",", "labelKey2", ")", ":", "\n", "        ", "data_dict", "=", "unpickle", "(", "os", ".", "path", ".", "join", "(", "source_dir", ",", "data_batch", ")", ")", "\n", "num_images", "=", "len", "(", "data_dict", "[", "labelKey1", "]", ")", "\n", "for", "i", "in", "range", "(", "num_images", ")", ":", "\n", "            ", "label", "=", "data_dict", "[", "labelKey1", "]", "[", "i", "]", "\n", "label_name", "=", "(", "labels_dict", "[", "labelKey2", "]", "[", "label", "]", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "class_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "label_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "class_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "class_dir", ")", "\n", "", "file_name", "=", "(", "data_dict", "[", "b'filenames'", "]", "[", "i", "]", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "image", "=", "data_dict", "[", "b'data'", "]", "[", "i", "]", "\n", "image", "=", "np", ".", "reshape", "(", "image", ",", "(", "3", ",", "32", ",", "32", ")", ")", "\n", "image", "=", "np", ".", "transpose", "(", "image", ",", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "pil_image", "=", "Image", ".", "fromarray", "(", "image", ")", "\n", "pil_image", "=", "pil_image", ".", "resize", "(", "(", "84", ",", "84", ")", ",", "resample", "=", "Image", ".", "LANCZOS", ")", "\n", "pil_image", ".", "save", "(", "os", ".", "path", ".", "join", "(", "class_dir", ",", "file_name", ")", ")", "\n", "\n", "# load the label names", "\n", "", "", "labels_dict", "=", "unpickle", "(", "os", ".", "path", ".", "join", "(", "src_path", ",", "labelsFileName", ")", ")", "\n", "\n", "# process test batch", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dst_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dst_path", ")", "\n", "\n", "", "save_images_in_data_batch", "(", "src_path", ",", "imagesFileName", ",", "dst_path", ",", "labelKey1", ",", "labelKey2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.prepare_extra_datasets.process_mnist": [[68, 107], ["prepare_extra_datasets.process_mnist.get_images"], "function", ["None"], ["", "def", "process_mnist", "(", "datasrc_path", ")", ":", "\n", "    ", "def", "get_images", "(", "path", ")", ":", "\n", "        ", "\"\"\"Return images loaded locally.\"\"\"", "\n", "with", "gzip", ".", "open", "(", "path", ")", "as", "f", ":", "\n", "# First 16 bytes are magic_number, n_imgs, n_rows, n_cols", "\n", "            ", "pixels", "=", "np", ".", "frombuffer", "(", "f", ".", "read", "(", ")", ",", "'B'", ",", "offset", "=", "16", ")", "\n", "", "return", "pixels", ".", "reshape", "(", "-", "1", ",", "28", ",", "28", ")", "\n", "\n", "", "def", "get_labels", "(", "path", ")", ":", "\n", "        ", "\"\"\"Return labels loaded locally.\"\"\"", "\n", "with", "gzip", ".", "open", "(", "path", ")", "as", "f", ":", "\n", "# First 8 bytes are magic_number, n_labels", "\n", "            ", "integer_labels", "=", "np", ".", "frombuffer", "(", "f", ".", "read", "(", ")", ",", "'B'", ",", "offset", "=", "8", ")", "\n", "", "return", "integer_labels", "\n", "\n", "", "def", "create_image_dir", "(", "images", ",", "labels", ",", "path", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "class_counter", "=", "{", "}", "\n", "for", "cls", "in", "range", "(", "10", ")", ":", "\n", "            ", "class_counter", "[", "cls", "]", "=", "0", "\n", "", "for", "step", ",", "(", "image", ",", "label", ")", "in", "enumerate", "(", "zip", "(", "images", ",", "labels", ")", ")", ":", "\n", "            ", "im", "=", "Image", ".", "fromarray", "(", "image", ")", "\n", "im", "=", "im", ".", "convert", "(", "'RGB'", ")", "\n", "im", "=", "im", ".", "resize", "(", "(", "84", ",", "84", ")", ",", "resample", "=", "Image", ".", "LANCZOS", ")", "\n", "\n", "class_dir", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'class_%s'", "%", "label", ".", "item", "(", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "class_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "class_dir", ")", "\n", "\n", "", "im_file", "=", "class_dir", "+", "'/image_%s.png'", "%", "(", "class_counter", "[", "label", "]", ")", "\n", "im", ".", "save", "(", "im_file", ")", "\n", "class_counter", "[", "label", "]", "+=", "1", "\n", "if", "(", "step", "+", "1", ")", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "'Processed %s images.'", "%", "(", "step", "+", "1", ")", ")", "\n", "\n", "", "", "", "test_images", "=", "get_images", "(", "os", ".", "path", ".", "join", "(", "datasrc_path", ",", "'t10k-images-idx3-ubyte.gz'", ")", ")", "\n", "test_labels", "=", "get_labels", "(", "os", ".", "path", ".", "join", "(", "datasrc_path", ",", "'t10k-labels-idx1-ubyte.gz'", ")", ")", "\n", "create_image_dir", "(", "test_images", ",", "test_labels", ",", "os", ".", "path", ".", "join", "(", "datasrc_path", ",", "'mnist'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.prepare_extra_datasets.main": [[109, 165], ["os.path.abspath", "os.path.abspath", "os.path.abspath", "print", "prepare_extra_datasets.process_mnist", "prepare_extra_datasets.ExtraDatasetConverter", "ExtraDatasetConverter.convert_dataset", "print", "prepare_extra_datasets.process_cifar", "prepare_extra_datasets.ExtraDatasetConverter", "ExtraDatasetConverter.convert_dataset", "print", "prepare_extra_datasets.process_cifar", "prepare_extra_datasets.ExtraDatasetConverter", "ExtraDatasetConverter.convert_dataset", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.prepare_extra_datasets.process_mnist", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.prepare_extra_datasets.process_cifar", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.prepare_extra_datasets.process_cifar", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print"], ["", "def", "main", "(", ")", ":", "\n", "    ", "datasrc_path", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "environ", "[", "'DATASRC'", "]", ")", "\n", "records_path", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "environ", "[", "'RECORDS'", "]", ")", "\n", "splits_path", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "environ", "[", "'SPLITS'", "]", ")", "\n", "\n", "print", "(", "'Processing MNIST test set.'", ")", "\n", "process_mnist", "(", "datasrc_path", ")", "\n", "converter", "=", "ExtraDatasetConverter", "(", "\n", "name", "=", "'mnist'", ",", "\n", "data_root", "=", "os", ".", "path", ".", "join", "(", "datasrc_path", ",", "'mnist'", ")", ",", "\n", "has_superclasses", "=", "False", ",", "\n", "records_path", "=", "os", ".", "path", ".", "join", "(", "records_path", ",", "'mnist'", ")", ",", "\n", "split_file", "=", "os", ".", "path", ".", "join", "(", "splits_path", ",", "'mnist_splits.json'", ")", ",", "\n", "random_seed", "=", "22", "\n", ")", "\n", "converter", ".", "convert_dataset", "(", ")", "\n", "\n", "print", "(", "'Processing CIFAR10 test set.'", ")", "\n", "process_cifar", "(", "\n", "src_path", "=", "os", ".", "path", ".", "join", "(", "datasrc_path", ",", "'cifar-10-batches-py'", ")", ",", "\n", "dst_path", "=", "os", ".", "path", ".", "join", "(", "datasrc_path", ",", "'cifar10'", ")", ",", "\n", "imagesFileName", "=", "'test_batch'", ",", "\n", "labelsFileName", "=", "'batches.meta'", ",", "\n", "labelKey1", "=", "b'labels'", ",", "\n", "labelKey2", "=", "b'label_names'", "\n", ")", "\n", "converter", "=", "ExtraDatasetConverter", "(", "\n", "name", "=", "'cifar10'", ",", "\n", "data_root", "=", "os", ".", "path", ".", "join", "(", "datasrc_path", ",", "'cifar10'", ")", ",", "\n", "has_superclasses", "=", "False", ",", "\n", "records_path", "=", "os", ".", "path", ".", "join", "(", "records_path", ",", "'cifar10'", ")", ",", "\n", "split_file", "=", "os", ".", "path", ".", "join", "(", "splits_path", ",", "'cifar10_splits.json'", ")", ",", "\n", "random_seed", "=", "22", "\n", ")", "\n", "converter", ".", "convert_dataset", "(", ")", "\n", "\n", "print", "(", "'Processing CIFAR100 test set.'", ")", "\n", "process_cifar", "(", "\n", "src_path", "=", "os", ".", "path", ".", "join", "(", "datasrc_path", ",", "'cifar-100-python'", ")", ",", "\n", "dst_path", "=", "os", ".", "path", ".", "join", "(", "datasrc_path", ",", "'cifar100'", ")", ",", "\n", "imagesFileName", "=", "'test'", ",", "\n", "labelsFileName", "=", "'meta'", ",", "\n", "labelKey1", "=", "b'fine_labels'", ",", "\n", "labelKey2", "=", "b'fine_label_names'", "\n", ")", "\n", "converter", "=", "ExtraDatasetConverter", "(", "\n", "name", "=", "'cifar100'", ",", "\n", "data_root", "=", "os", ".", "path", ".", "join", "(", "datasrc_path", ",", "'cifar100'", ")", ",", "\n", "has_superclasses", "=", "False", ",", "\n", "records_path", "=", "os", ".", "path", ".", "join", "(", "records_path", ",", "'cifar100'", ")", ",", "\n", "split_file", "=", "os", ".", "path", ".", "join", "(", "splits_path", ",", "'cifar100_splits.json'", ")", ",", "\n", "random_seed", "=", "22", "\n", ")", "\n", "converter", ".", "convert_dataset", "(", ")", "\n", "\n", "print", "(", "'Finished.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.config_networks.ConfigureNetworks.__init__": [[11, 62], ["set_encoder.SetEncoder", "config_networks.ConfigureNetworks.feature_extractor.parameters", "adaptation_networks.LinearClassifierAdaptationNetwork", "resnet.resnet18", "adaptation_networks.NullFeatureAdaptationNetwork", "resnet.film_resnet18", "adaptation_networks.FilmAdaptationNetwork", "resnet.film_resnet18", "adaptation_networks.FilmArAdaptationNetwork"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.resnet18", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.film_resnet18", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.film_resnet18"], ["def", "__init__", "(", "self", ",", "pretrained_resnet_path", ",", "feature_adaptation", ",", "batch_normalization", ")", ":", "\n", "        ", "self", ".", "classifier", "=", "linear_classifier", "\n", "\n", "self", ".", "encoder", "=", "SetEncoder", "(", "batch_normalization", ")", "\n", "z_g_dim", "=", "self", ".", "encoder", ".", "pre_pooling_fn", ".", "output_size", "\n", "\n", "# parameters for ResNet18", "\n", "num_maps_per_layer", "=", "[", "64", ",", "128", ",", "256", ",", "512", "]", "\n", "num_blocks_per_layer", "=", "[", "2", ",", "2", ",", "2", ",", "2", "]", "\n", "num_initial_conv_maps", "=", "64", "\n", "\n", "if", "feature_adaptation", "==", "\"no_adaptation\"", ":", "\n", "            ", "self", ".", "feature_extractor", "=", "resnet18", "(", "\n", "pretrained", "=", "True", ",", "\n", "pretrained_model_path", "=", "pretrained_resnet_path", ",", "\n", "batch_normalization", "=", "batch_normalization", "\n", ")", "\n", "self", ".", "feature_adaptation_network", "=", "NullFeatureAdaptationNetwork", "(", ")", "\n", "\n", "", "elif", "feature_adaptation", "==", "\"film\"", ":", "\n", "            ", "self", ".", "feature_extractor", "=", "film_resnet18", "(", "\n", "pretrained", "=", "True", ",", "\n", "pretrained_model_path", "=", "pretrained_resnet_path", ",", "\n", "batch_normalization", "=", "batch_normalization", "\n", ")", "\n", "self", ".", "feature_adaptation_network", "=", "FilmAdaptationNetwork", "(", "\n", "layer", "=", "FilmLayerNetwork", ",", "\n", "num_maps_per_layer", "=", "num_maps_per_layer", ",", "\n", "num_blocks_per_layer", "=", "num_blocks_per_layer", ",", "\n", "z_g_dim", "=", "z_g_dim", "\n", ")", "\n", "\n", "", "elif", "feature_adaptation", "==", "'film+ar'", ":", "\n", "            ", "self", ".", "feature_extractor", "=", "film_resnet18", "(", "\n", "pretrained", "=", "True", ",", "\n", "pretrained_model_path", "=", "pretrained_resnet_path", ",", "\n", "batch_normalization", "=", "batch_normalization", "\n", ")", "\n", "self", ".", "feature_adaptation_network", "=", "FilmArAdaptationNetwork", "(", "\n", "feature_extractor", "=", "self", ".", "feature_extractor", ",", "\n", "num_maps_per_layer", "=", "num_maps_per_layer", ",", "\n", "num_blocks_per_layer", "=", "num_blocks_per_layer", ",", "\n", "num_initial_conv_maps", "=", "num_initial_conv_maps", ",", "\n", "z_g_dim", "=", "z_g_dim", "\n", ")", "\n", "\n", "# Freeze the parameters of the feature extractor", "\n", "", "for", "param", "in", "self", ".", "feature_extractor", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "classifier_adaptation_network", "=", "LinearClassifierAdaptationNetwork", "(", "self", ".", "feature_extractor", ".", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.config_networks.ConfigureNetworks.get_encoder": [[63, 65], ["None"], "methods", ["None"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.config_networks.ConfigureNetworks.get_classifier": [[66, 68], ["None"], "methods", ["None"], ["", "def", "get_classifier", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.config_networks.ConfigureNetworks.get_classifier_adaptation": [[69, 71], ["None"], "methods", ["None"], ["", "def", "get_classifier_adaptation", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "classifier_adaptation_network", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.config_networks.ConfigureNetworks.get_feature_adaptation": [[72, 74], ["None"], "methods", ["None"], ["", "def", "get_feature_adaptation", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "feature_adaptation_network", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.config_networks.ConfigureNetworks.get_feature_extractor": [[75, 77], ["None"], "methods", ["None"], ["", "def", "get_feature_extractor", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "feature_extractor", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps.__init__": [[19, 35], ["torch.Module.__init__", "config_networks.ConfigureNetworks", "config_networks.ConfigureNetworks.get_encoder", "config_networks.ConfigureNetworks.get_classifier_adaptation", "config_networks.ConfigureNetworks.get_classifier", "config_networks.ConfigureNetworks.get_feature_extractor", "config_networks.ConfigureNetworks.get_feature_adaptation", "collections.OrderedDict"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.config_networks.ConfigureNetworks.get_encoder", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.config_networks.ConfigureNetworks.get_classifier_adaptation", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.config_networks.ConfigureNetworks.get_classifier", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.config_networks.ConfigureNetworks.get_feature_extractor", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.config_networks.ConfigureNetworks.get_feature_adaptation"], ["def", "__init__", "(", "self", ",", "device", ",", "use_two_gpus", ",", "args", ")", ":", "\n", "        ", "super", "(", "Cnaps", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "use_two_gpus", "=", "use_two_gpus", "\n", "networks", "=", "ConfigureNetworks", "(", "pretrained_resnet_path", "=", "self", ".", "args", ".", "pretrained_resnet_path", ",", "\n", "feature_adaptation", "=", "self", ".", "args", ".", "feature_adaptation", ",", "\n", "batch_normalization", "=", "args", ".", "batch_normalization", ")", "\n", "self", ".", "set_encoder", "=", "networks", ".", "get_encoder", "(", ")", "\n", "self", ".", "classifier_adaptation_network", "=", "networks", ".", "get_classifier_adaptation", "(", ")", "\n", "self", ".", "classifier", "=", "networks", ".", "get_classifier", "(", ")", "\n", "self", ".", "feature_extractor", "=", "networks", ".", "get_feature_extractor", "(", ")", "\n", "self", ".", "feature_adaptation_network", "=", "networks", ".", "get_feature_adaptation", "(", ")", "\n", "self", ".", "task_representation", "=", "None", "\n", "self", ".", "class_representations", "=", "OrderedDict", "(", ")", "# Dictionary mapping class label (integer) to encoded representation", "\n", "self", ".", "total_iterations", "=", "args", ".", "training_iterations", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps.forward": [[36, 58], ["model.Cnaps.set_encoder", "model.Cnaps._get_features", "model.Cnaps._build_class_reps", "model.Cnaps._get_classifier_params", "model.Cnaps.classifier", "model.Cnaps.class_representations.clear", "utils.split_first_dim_linear"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps._get_features", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps._build_class_reps", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps._get_classifier_params", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.split_first_dim_linear"], ["", "def", "forward", "(", "self", ",", "context_images", ",", "context_labels", ",", "target_images", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass through the model for one episode.\n        :param context_images: (torch.tensor) Images in the context set (batch x C x H x W).\n        :param context_labels: (torch.tensor) Labels for the context set (batch x 1 -- integer representation).\n        :param target_images: (torch.tensor) Images in the target set (batch x C x H x W).\n        :return: (torch.tensor) Categorical distribution on label set for each image in target set (batch x num_labels).\n        \"\"\"", "\n", "# extract train and test features", "\n", "self", ".", "task_representation", "=", "self", ".", "set_encoder", "(", "context_images", ")", "\n", "context_features", ",", "target_features", "=", "self", ".", "_get_features", "(", "context_images", ",", "target_images", ")", "\n", "\n", "# get the parameters for the linear classifier.", "\n", "self", ".", "_build_class_reps", "(", "context_features", ",", "context_labels", ")", "\n", "classifier_params", "=", "self", ".", "_get_classifier_params", "(", ")", "\n", "\n", "# classify", "\n", "sample_logits", "=", "self", ".", "classifier", "(", "target_features", ",", "classifier_params", ")", "\n", "self", ".", "class_representations", ".", "clear", "(", ")", "\n", "\n", "# this adds back extra first dimension for num_samples", "\n", "return", "split_first_dim_linear", "(", "sample_logits", ",", "[", "NUM_SAMPLES", ",", "target_images", ".", "shape", "[", "0", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps._get_features": [[59, 101], ["context_images.cuda", "target_images.cuda", "model.Cnaps.set_batch_norm_mode", "model.Cnaps.feature_extractor", "model.Cnaps.cuda", "model.Cnaps.set_batch_norm_mode", "model.Cnaps.feature_extractor", "model.Cnaps.cuda", "model.Cnaps.set_batch_norm_mode", "model.Cnaps.feature_extractor", "model.Cnaps.set_batch_norm_mode", "model.Cnaps.feature_extractor", "model.Cnaps.task_representation.cuda", "model.Cnaps.set_batch_norm_mode", "model.Cnaps.feature_adaptation_network", "model.Cnaps.task_representation.cuda", "model.Cnaps.feature_adaptation_network", "model.Cnaps.set_batch_norm_mode", "model.Cnaps.feature_adaptation_network", "model.Cnaps.feature_adaptation_network"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps.set_batch_norm_mode", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps.set_batch_norm_mode", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps.set_batch_norm_mode", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps.set_batch_norm_mode", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps.set_batch_norm_mode", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps.set_batch_norm_mode"], ["", "def", "_get_features", "(", "self", ",", "context_images", ",", "target_images", ")", ":", "\n", "        ", "\"\"\"\n        Helper function to extract task-dependent feature representation for each image in both context and target sets.\n        :param context_images: (torch.tensor) Images in the context set (batch x C x H x W).\n        :param target_images: (torch.tensor) Images in the target set (batch x C x H x W).\n        :return: (tuple::torch.tensor) Feature representation for each set of images.\n        \"\"\"", "\n", "# Parallelize forward pass across multiple GPUs (model parallelism)", "\n", "if", "self", ".", "use_two_gpus", ":", "\n", "            ", "context_images_1", "=", "context_images", ".", "cuda", "(", "1", ")", "\n", "target_images_1", "=", "target_images", ".", "cuda", "(", "1", ")", "\n", "if", "self", ".", "args", ".", "feature_adaptation", "==", "'film+ar'", ":", "\n", "                ", "task_representation_1", "=", "self", ".", "task_representation", ".", "cuda", "(", "1", ")", "\n", "# Get adaptation params by passing context set through the adaptation networks", "\n", "self", ".", "set_batch_norm_mode", "(", "True", ")", "\n", "self", ".", "feature_extractor_params", "=", "self", ".", "feature_adaptation_network", "(", "context_images_1", ",", "task_representation_1", ")", "\n", "", "else", ":", "\n", "                ", "task_representation_1", "=", "self", ".", "task_representation", ".", "cuda", "(", "1", ")", "\n", "# Get adaptation params by passing context set through the adaptation networks", "\n", "self", ".", "feature_extractor_params", "=", "self", ".", "feature_adaptation_network", "(", "task_representation_1", ")", "\n", "# Given adaptation parameters for task, conditional forward pass through the adapted feature extractor", "\n", "", "self", ".", "set_batch_norm_mode", "(", "True", ")", "\n", "context_features_1", "=", "self", ".", "feature_extractor", "(", "context_images_1", ",", "self", ".", "feature_extractor_params", ")", "\n", "context_features", "=", "context_features_1", ".", "cuda", "(", "0", ")", "\n", "self", ".", "set_batch_norm_mode", "(", "False", ")", "\n", "target_features_1", "=", "self", ".", "feature_extractor", "(", "target_images_1", ",", "self", ".", "feature_extractor_params", ")", "\n", "target_features", "=", "target_features_1", ".", "cuda", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "args", ".", "feature_adaptation", "==", "'film+ar'", ":", "\n", "# Get adaptation params by passing context set through the adaptation networks", "\n", "                ", "self", ".", "set_batch_norm_mode", "(", "True", ")", "\n", "self", ".", "feature_extractor_params", "=", "self", ".", "feature_adaptation_network", "(", "context_images", ",", "self", ".", "task_representation", ")", "\n", "", "else", ":", "\n", "# Get adaptation params by passing context set through the adaptation networks", "\n", "                ", "self", ".", "feature_extractor_params", "=", "self", ".", "feature_adaptation_network", "(", "self", ".", "task_representation", ")", "\n", "# Given adaptation parameters for task, conditional forward pass through the adapted feature extractor", "\n", "", "self", ".", "set_batch_norm_mode", "(", "True", ")", "\n", "context_features", "=", "self", ".", "feature_extractor", "(", "context_images", ",", "self", ".", "feature_extractor_params", ")", "\n", "self", ".", "set_batch_norm_mode", "(", "False", ")", "\n", "target_features", "=", "self", ".", "feature_extractor", "(", "target_images", ",", "self", ".", "feature_extractor_params", ")", "\n", "\n", "", "return", "context_features", ",", "target_features", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps._build_class_reps": [[102, 114], ["torch.unique", "torch.unique", "torch.unique", "torch.unique", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "set_encoder.mean_pooling", "model.Cnaps._extract_class_indices", "c.item"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.mean_pooling", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps._extract_class_indices"], ["", "def", "_build_class_reps", "(", "self", ",", "context_features", ",", "context_labels", ")", ":", "\n", "        ", "\"\"\"\n        Construct and return class level representation for each class in task.\n        :param context_features: (torch.tensor) Adapted feature representation for each image in the context set.\n        :param context_labels: (torch.tensor) Label for each image in the context set.\n        :return: (void) Updates the internal class representation dictionary.\n        \"\"\"", "\n", "for", "c", "in", "torch", ".", "unique", "(", "context_labels", ")", ":", "\n", "# filter out feature vectors which have class c", "\n", "            ", "class_features", "=", "torch", ".", "index_select", "(", "context_features", ",", "0", ",", "self", ".", "_extract_class_indices", "(", "context_labels", ",", "c", ")", ")", "\n", "class_rep", "=", "mean_pooling", "(", "class_features", ")", "\n", "self", ".", "class_representations", "[", "c", ".", "item", "(", ")", "]", "=", "class_rep", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps._get_classifier_params": [[115, 122], ["model.Cnaps.classifier_adaptation_network"], "methods", ["None"], ["", "", "def", "_get_classifier_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Processes the class representations and generated the linear classifier weights and biases.\n        :return: Linear classifier weights and biases.\n        \"\"\"", "\n", "classifier_params", "=", "self", ".", "classifier_adaptation_network", "(", "self", ".", "class_representations", ")", "\n", "return", "classifier_params", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps._extract_class_indices": [[123, 134], ["torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_extract_class_indices", "(", "labels", ",", "which_class", ")", ":", "\n", "        ", "\"\"\"\n        Helper method to extract the indices of elements which have the specified label.\n        :param labels: (torch.tensor) Labels of the context set.\n        :param which_class: Label for which indices are extracted.\n        :return: (torch.tensor) Indices in the form of a mask that indicate the locations of the specified label.\n        \"\"\"", "\n", "class_mask", "=", "torch", ".", "eq", "(", "labels", ",", "which_class", ")", "# binary mask of labels equal to which_class", "\n", "class_mask_indices", "=", "torch", ".", "nonzero", "(", "class_mask", ",", "as_tuple", "=", "False", ")", "# indices of labels equal to which class", "\n", "return", "torch", ".", "reshape", "(", "class_mask_indices", ",", "(", "-", "1", ",", ")", ")", "# reshape to be a 1D vector", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps.distribute_model": [[135, 142], ["model.Cnaps.feature_extractor.cuda", "model.Cnaps.feature_adaptation_network.cuda"], "methods", ["None"], ["", "def", "distribute_model", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Moves the feature extractor and feature adaptation network to a second GPU.\n        :return: Nothing\n        \"\"\"", "\n", "self", ".", "feature_extractor", ".", "cuda", "(", "1", ")", "\n", "self", ".", "feature_adaptation_network", ".", "cuda", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps.set_batch_norm_mode": [[143, 157], ["model.Cnaps.feature_extractor.eval", "model.Cnaps.feature_extractor.train", "model.Cnaps.feature_extractor.eval"], "methods", ["None"], ["", "def", "set_batch_norm_mode", "(", "self", ",", "context", ")", ":", "\n", "        ", "\"\"\"\n        Controls the batch norm mode in the feature extractor.\n        :param context: Set to true ehen processing the context set and False when processing the target set.\n        :return: Nothing\n        \"\"\"", "\n", "if", "self", ".", "args", ".", "batch_normalization", "==", "\"basic\"", ":", "\n", "            ", "self", ".", "feature_extractor", ".", "eval", "(", ")", "# always in eval mode", "\n", "", "else", ":", "\n", "# \"task_norm-i\" - respect context flag, regardless of state", "\n", "            ", "if", "context", ":", "\n", "                ", "self", ".", "feature_extractor", ".", "train", "(", ")", "# use train when processing the context set", "\n", "", "else", ":", "\n", "                ", "self", ".", "feature_extractor", ".", "eval", "(", ")", "# use eval when processing the target set", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader.__init__": [[18, 44], ["tensorflow.compat.v1.disable_eager_execution", "tensorflow.compat.v1.Session", "gin.parse_config_file", "meta_dataset_reader.MetaDatasetReader._get_train_episode_description", "meta_dataset_reader.MetaDatasetReader._init_multi_source_dataset", "meta_dataset_reader.MetaDatasetReader._get_test_episode_description", "meta_dataset_reader.MetaDatasetReader._get_test_episode_description", "meta_dataset_reader.MetaDatasetReader._init_single_source_dataset", "meta_dataset_reader.MetaDatasetReader._init_single_source_dataset"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_train_episode_description", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader._init_multi_source_dataset", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_test_episode_description", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_test_episode_description", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader._init_single_source_dataset", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader._init_single_source_dataset"], ["def", "__init__", "(", "self", ",", "data_path", ",", "mode", ",", "train_set", ",", "validation_set", ",", "test_set", ",", "max_way_train", ",", "max_way_test", ",", "max_support_train", ",", "max_support_test", ")", ":", "\n", "\n", "        ", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "train_dataset_next_task", "=", "None", "\n", "self", ".", "validation_set_dict", "=", "{", "}", "\n", "self", ".", "test_set_dict", "=", "{", "}", "\n", "tf", ".", "compat", ".", "v1", ".", "disable_eager_execution", "(", ")", "\n", "self", ".", "session", "=", "tf", ".", "compat", ".", "v1", ".", "Session", "(", ")", "\n", "gin", ".", "parse_config_file", "(", "'./meta_dataset_config.gin'", ")", "\n", "\n", "if", "mode", "==", "'train'", "or", "mode", "==", "'train_test'", ":", "\n", "            ", "train_episode_description", "=", "self", ".", "_get_train_episode_description", "(", "max_way_train", ",", "max_support_train", ")", "\n", "self", ".", "train_dataset_next_task", "=", "self", ".", "_init_multi_source_dataset", "(", "train_set", ",", "learning_spec", ".", "Split", ".", "TRAIN", ",", "\n", "train_episode_description", ")", "\n", "\n", "test_episode_description", "=", "self", ".", "_get_test_episode_description", "(", "max_way_test", ",", "max_support_test", ")", "\n", "for", "item", "in", "validation_set", ":", "\n", "                ", "next_task", "=", "self", ".", "validation_dataset", "=", "self", ".", "_init_single_source_dataset", "(", "item", ",", "learning_spec", ".", "Split", ".", "VALID", ",", "\n", "test_episode_description", ")", "\n", "self", ".", "validation_set_dict", "[", "item", "]", "=", "next_task", "\n", "\n", "", "", "if", "mode", "==", "'test'", "or", "mode", "==", "'train_test'", ":", "\n", "            ", "test_episode_description", "=", "self", ".", "_get_test_episode_description", "(", "max_way_test", ",", "max_support_test", ")", "\n", "for", "item", "in", "test_set", ":", "\n", "                ", "next_task", "=", "self", ".", "_init_single_source_dataset", "(", "item", ",", "learning_spec", ".", "Split", ".", "TEST", ",", "test_episode_description", ")", "\n", "self", ".", "test_set_dict", "[", "item", "]", "=", "next_task", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader._init_multi_source_dataset": [[45, 71], ["meta_dataset.data.pipeline.make_multisource_episode_pipeline", "meta_dataset.data.pipeline.make_multisource_episode_pipeline.make_one_shot_iterator", "pipeline.make_multisource_episode_pipeline.make_one_shot_iterator.get_next", "os.path.join", "meta_dataset.data.dataset_spec.load_dataset_spec", "dataset_specs.append", "len", "len", "items.index", "items.index"], "methods", ["None"], ["", "", "", "def", "_init_multi_source_dataset", "(", "self", ",", "items", ",", "split", ",", "episode_description", ")", ":", "\n", "        ", "dataset_specs", "=", "[", "]", "\n", "for", "dataset_name", "in", "items", ":", "\n", "            ", "dataset_records_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "dataset_name", ")", "\n", "dataset_spec", "=", "dataset_spec_lib", ".", "load_dataset_spec", "(", "dataset_records_path", ")", "\n", "dataset_specs", ".", "append", "(", "dataset_spec", ")", "\n", "\n", "", "use_bilevel_ontology_list", "=", "[", "False", "]", "*", "len", "(", "items", ")", "\n", "use_dag_ontology_list", "=", "[", "False", "]", "*", "len", "(", "items", ")", "\n", "# Enable ontology aware sampling for Omniglot and ImageNet.", "\n", "if", "'omniglot'", "in", "items", ":", "\n", "            ", "use_bilevel_ontology_list", "[", "items", ".", "index", "(", "'omniglot'", ")", "]", "=", "True", "\n", "", "if", "'ilsvrc_2012'", "in", "items", ":", "\n", "            ", "use_dag_ontology_list", "[", "items", ".", "index", "(", "'ilsvrc_2012'", ")", "]", "=", "True", "\n", "\n", "", "multi_source_pipeline", "=", "pipeline", ".", "make_multisource_episode_pipeline", "(", "\n", "dataset_spec_list", "=", "dataset_specs", ",", "\n", "use_dag_ontology_list", "=", "use_dag_ontology_list", ",", "\n", "use_bilevel_ontology_list", "=", "use_bilevel_ontology_list", ",", "\n", "split", "=", "split", ",", "\n", "episode_descr_config", "=", "episode_description", ",", "\n", "image_size", "=", "84", ",", "\n", "shuffle_buffer_size", "=", "1000", ")", "\n", "\n", "iterator", "=", "multi_source_pipeline", ".", "make_one_shot_iterator", "(", ")", "\n", "return", "iterator", ".", "get_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader._init_single_source_dataset": [[72, 96], ["os.path.join", "meta_dataset.data.dataset_spec.load_dataset_spec", "meta_dataset.data.pipeline.make_one_source_episode_pipeline", "meta_dataset.data.pipeline.make_one_source_episode_pipeline.make_one_shot_iterator", "pipeline.make_one_source_episode_pipeline.make_one_shot_iterator.get_next"], "methods", ["None"], ["", "def", "_init_single_source_dataset", "(", "self", ",", "dataset_name", ",", "split", ",", "episode_description", ")", ":", "\n", "        ", "dataset_records_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "dataset_name", ")", "\n", "dataset_spec", "=", "dataset_spec_lib", ".", "load_dataset_spec", "(", "dataset_records_path", ")", "\n", "\n", "# Enable ontology aware sampling for Omniglot and ImageNet.", "\n", "use_bilevel_ontology", "=", "False", "\n", "if", "'omniglot'", "in", "dataset_name", ":", "\n", "            ", "use_bilevel_ontology", "=", "True", "\n", "\n", "", "use_dag_ontology", "=", "False", "\n", "if", "'ilsvrc_2012'", "in", "dataset_name", ":", "\n", "            ", "use_dag_ontology", "=", "True", "\n", "\n", "", "single_source_pipeline", "=", "pipeline", ".", "make_one_source_episode_pipeline", "(", "\n", "dataset_spec", "=", "dataset_spec", ",", "\n", "use_dag_ontology", "=", "use_dag_ontology", ",", "\n", "use_bilevel_ontology", "=", "use_bilevel_ontology", ",", "\n", "split", "=", "split", ",", "\n", "episode_descr_config", "=", "episode_description", ",", "\n", "image_size", "=", "84", ",", "\n", "shuffle_buffer_size", "=", "1000", ")", "\n", "\n", "iterator", "=", "single_source_pipeline", ".", "make_one_shot_iterator", "(", ")", "\n", "return", "iterator", ".", "get_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader._get_task": [[97, 106], ["meta_dataset_reader.MetaDatasetReader.session.run"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.run"], ["", "def", "_get_task", "(", "self", ",", "next_task", ")", ":", "\n", "        ", "(", "episode", ",", "source_id", ")", "=", "self", ".", "session", ".", "run", "(", "next_task", ")", "\n", "task_dict", "=", "{", "\n", "'context_images'", ":", "episode", "[", "0", "]", ",", "\n", "'context_labels'", ":", "episode", "[", "1", "]", ",", "\n", "'target_images'", ":", "episode", "[", "3", "]", ",", "\n", "'target_labels'", ":", "episode", "[", "4", "]", "\n", "}", "\n", "return", "task_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader.get_train_task": [[107, 109], ["meta_dataset_reader.MetaDatasetReader._get_task"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_task"], ["", "def", "get_train_task", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_get_task", "(", "self", ".", "train_dataset_next_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader.get_validation_task": [[110, 112], ["meta_dataset_reader.MetaDatasetReader._get_task"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_task"], ["", "def", "get_validation_task", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "self", ".", "_get_task", "(", "self", ".", "validation_set_dict", "[", "item", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader.get_test_task": [[113, 115], ["meta_dataset_reader.MetaDatasetReader._get_task"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_task"], ["", "def", "get_test_task", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "self", ".", "_get_task", "(", "self", ".", "test_set_dict", "[", "item", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader._get_train_episode_description": [[116, 132], ["meta_dataset.data.config.EpisodeDescriptionConfig"], "methods", ["None"], ["", "def", "_get_train_episode_description", "(", "self", ",", "max_way_train", ",", "max_support_train", ")", ":", "\n", "        ", "return", "config", ".", "EpisodeDescriptionConfig", "(", "\n", "num_ways", "=", "None", ",", "\n", "num_support", "=", "None", ",", "\n", "num_query", "=", "None", ",", "\n", "min_ways", "=", "5", ",", "\n", "max_ways_upper_bound", "=", "max_way_train", ",", "\n", "max_num_query", "=", "10", ",", "\n", "max_support_set_size", "=", "max_support_train", ",", "\n", "max_support_size_contrib_per_class", "=", "100", ",", "\n", "min_log_weight", "=", "-", "0.69314718055994529", ",", "# np.cnaps_layer_log.txt(0.5)", "\n", "max_log_weight", "=", "0.69314718055994529", ",", "# np.cnaps_layer_log.txt(2)", "\n", "ignore_dag_ontology", "=", "False", ",", "\n", "ignore_bilevel_ontology", "=", "False", ",", "\n", "ignore_hierarchy_probability", "=", "0.0", ",", "\n", "simclr_episode_fraction", "=", "0.0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.MetaDatasetReader._get_test_episode_description": [[134, 150], ["meta_dataset.data.config.EpisodeDescriptionConfig"], "methods", ["None"], ["", "def", "_get_test_episode_description", "(", "self", ",", "max_way_test", ",", "max_support_test", ")", ":", "\n", "        ", "return", "config", ".", "EpisodeDescriptionConfig", "(", "\n", "num_ways", "=", "None", ",", "\n", "num_support", "=", "None", ",", "\n", "num_query", "=", "None", ",", "\n", "min_ways", "=", "5", ",", "\n", "max_ways_upper_bound", "=", "max_way_test", ",", "\n", "max_num_query", "=", "10", ",", "\n", "max_support_set_size", "=", "max_support_test", ",", "\n", "max_support_size_contrib_per_class", "=", "100", ",", "\n", "min_log_weight", "=", "-", "0.69314718055994529", ",", "# np.cnaps_layer_log.txt(0.5)", "\n", "max_log_weight", "=", "0.69314718055994529", ",", "# np.cnaps_layer_log.txt(2)", "\n", "ignore_dag_ontology", "=", "False", ",", "\n", "ignore_bilevel_ontology", "=", "False", ",", "\n", "ignore_hierarchy_probability", "=", "0.0", ",", "\n", "simclr_episode_fraction", "=", "0.0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader.__init__": [[157, 176], ["tensorflow.compat.v1.disable_eager_execution", "tensorflow.compat.v1.Session", "gin.parse_config_file", "meta_dataset_reader.SingleDatasetReader._get_train_episode_description", "meta_dataset_reader.SingleDatasetReader._get_test_episode_description", "meta_dataset_reader.SingleDatasetReader._init_dataset", "meta_dataset_reader.SingleDatasetReader._init_dataset", "meta_dataset_reader.SingleDatasetReader._init_dataset"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_train_episode_description", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_test_episode_description", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._init_dataset", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._init_dataset", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._init_dataset"], ["def", "__init__", "(", "self", ",", "data_path", ",", "mode", ",", "dataset", ",", "way", ",", "shot", ",", "query_train", ",", "query_test", ")", ":", "\n", "\n", "        ", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "train_next_task", "=", "None", "\n", "self", ".", "validation_next_task", "=", "None", "\n", "self", ".", "test_next_task", "=", "None", "\n", "tf", ".", "compat", ".", "v1", ".", "disable_eager_execution", "(", ")", "\n", "self", ".", "session", "=", "tf", ".", "compat", ".", "v1", ".", "Session", "(", ")", "\n", "gin", ".", "parse_config_file", "(", "'./meta_dataset_config.gin'", ")", "\n", "\n", "fixed_way_shot_train", "=", "self", ".", "_get_train_episode_description", "(", "num_ways", "=", "way", ",", "num_support", "=", "shot", ",", "num_query", "=", "query_train", ")", "\n", "fixed_way_shot_test", "=", "self", ".", "_get_test_episode_description", "(", "num_ways", "=", "way", ",", "num_support", "=", "shot", ",", "num_query", "=", "query_test", ")", "\n", "\n", "if", "mode", "==", "'train'", "or", "mode", "==", "'train_test'", ":", "\n", "            ", "self", ".", "train_next_task", "=", "self", ".", "_init_dataset", "(", "dataset", ",", "learning_spec", ".", "Split", ".", "TRAIN", ",", "fixed_way_shot_train", ")", "\n", "self", ".", "validation_next_task", "=", "self", ".", "_init_dataset", "(", "dataset", ",", "learning_spec", ".", "Split", ".", "VALID", ",", "fixed_way_shot_test", ")", "\n", "\n", "", "if", "mode", "==", "'test'", "or", "mode", "==", "'train_test'", ":", "\n", "            ", "self", ".", "test_next_task", "=", "self", ".", "_init_dataset", "(", "dataset", ",", "learning_spec", ".", "Split", ".", "TEST", ",", "fixed_way_shot_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._init_dataset": [[177, 192], ["os.path.join", "meta_dataset.data.dataset_spec.load_dataset_spec", "meta_dataset.data.pipeline.make_one_source_episode_pipeline", "meta_dataset.data.pipeline.make_one_source_episode_pipeline.make_one_shot_iterator", "pipeline.make_one_source_episode_pipeline.make_one_shot_iterator.get_next"], "methods", ["None"], ["", "", "def", "_init_dataset", "(", "self", ",", "dataset", ",", "split", ",", "episode_description", ")", ":", "\n", "        ", "dataset_records_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "dataset", ")", "\n", "dataset_spec", "=", "dataset_spec_lib", ".", "load_dataset_spec", "(", "dataset_records_path", ")", "\n", "\n", "single_source_pipeline", "=", "pipeline", ".", "make_one_source_episode_pipeline", "(", "\n", "dataset_spec", "=", "dataset_spec", ",", "\n", "use_dag_ontology", "=", "False", ",", "\n", "use_bilevel_ontology", "=", "False", ",", "\n", "split", "=", "split", ",", "\n", "episode_descr_config", "=", "episode_description", ",", "\n", "image_size", "=", "84", ",", "\n", "shuffle_buffer_size", "=", "1000", ")", "\n", "\n", "iterator", "=", "single_source_pipeline", ".", "make_one_shot_iterator", "(", ")", "\n", "return", "iterator", ".", "get_next", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_task": [[193, 202], ["meta_dataset_reader.SingleDatasetReader.session.run"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.run"], ["", "def", "_get_task", "(", "self", ",", "next_task", ")", ":", "\n", "        ", "(", "episode", ",", "source_id", ")", "=", "self", ".", "session", ".", "run", "(", "next_task", ")", "\n", "task_dict", "=", "{", "\n", "'context_images'", ":", "episode", "[", "0", "]", ",", "\n", "'context_labels'", ":", "episode", "[", "1", "]", ",", "\n", "'target_images'", ":", "episode", "[", "3", "]", ",", "\n", "'target_labels'", ":", "episode", "[", "4", "]", "\n", "}", "\n", "return", "task_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader.get_train_task": [[203, 205], ["meta_dataset_reader.SingleDatasetReader._get_task"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_task"], ["", "def", "get_train_task", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_get_task", "(", "self", ".", "train_next_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader.get_validation_task": [[206, 208], ["meta_dataset_reader.SingleDatasetReader._get_task"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_task"], ["", "def", "get_validation_task", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "self", ".", "_get_task", "(", "self", ".", "validation_next_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader.get_test_task": [[209, 211], ["meta_dataset_reader.SingleDatasetReader._get_task"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_task"], ["", "def", "get_test_task", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "self", ".", "_get_task", "(", "self", ".", "test_next_task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_train_episode_description": [[212, 228], ["meta_dataset.data.config.EpisodeDescriptionConfig"], "methods", ["None"], ["", "def", "_get_train_episode_description", "(", "self", ",", "num_ways", ",", "num_support", ",", "num_query", ")", ":", "\n", "        ", "return", "config", ".", "EpisodeDescriptionConfig", "(", "\n", "num_ways", "=", "num_ways", ",", "\n", "num_support", "=", "num_support", ",", "\n", "num_query", "=", "num_query", ",", "\n", "min_ways", "=", "5", ",", "\n", "max_ways_upper_bound", "=", "50", ",", "\n", "max_num_query", "=", "10", ",", "\n", "max_support_set_size", "=", "500", ",", "\n", "max_support_size_contrib_per_class", "=", "100", ",", "\n", "min_log_weight", "=", "-", "0.69314718055994529", ",", "# np.cnaps_layer_log.txt(0.5)", "\n", "max_log_weight", "=", "0.69314718055994529", ",", "# np.cnaps_layer_log.txt(2)", "\n", "ignore_dag_ontology", "=", "False", ",", "\n", "ignore_bilevel_ontology", "=", "False", ",", "\n", "ignore_hierarchy_probability", "=", "0.0", ",", "\n", "simclr_episode_fraction", "=", "0.0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader._get_test_episode_description": [[230, 246], ["meta_dataset.data.config.EpisodeDescriptionConfig"], "methods", ["None"], ["", "def", "_get_test_episode_description", "(", "self", ",", "num_ways", ",", "num_support", ",", "num_query", ")", ":", "\n", "        ", "return", "config", ".", "EpisodeDescriptionConfig", "(", "\n", "num_ways", "=", "num_ways", ",", "\n", "num_support", "=", "num_support", ",", "\n", "num_query", "=", "num_query", ",", "\n", "min_ways", "=", "5", ",", "\n", "max_ways_upper_bound", "=", "50", ",", "\n", "max_num_query", "=", "10", ",", "\n", "max_support_set_size", "=", "500", ",", "\n", "max_support_size_contrib_per_class", "=", "100", ",", "\n", "min_log_weight", "=", "-", "0.69314718055994529", ",", "# np.cnaps_layer_log.txt(0.5)", "\n", "max_log_weight", "=", "0.69314718055994529", ",", "# np.cnaps_layer_log.txt(2)", "\n", "ignore_dag_ontology", "=", "False", ",", "\n", "ignore_bilevel_ontology", "=", "False", ",", "\n", "ignore_hierarchy_probability", "=", "0.0", ",", "\n", "simclr_episode_fraction", "=", "0.0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.__init__": [[64, 92], ["run_cnaps.Learner.parse_command_line", "utils.get_log_files", "utils.print_and_log", "utils.print_and_log", "torch.device", "run_cnaps.Learner.init_model", "run_cnaps.Learner.init_data", "torch.optim.Adam", "utils.ValidationAccuracies", "run_cnaps.Learner.optimizer.zero_grad", "meta_dataset_reader.MetaDatasetReader", "meta_dataset_reader.SingleDatasetReader", "run_cnaps.Learner.model.parameters", "run_cnaps.Learner.load_checkpoint", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.parse_command_line", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.get_log_files", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.init_model", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.init_data", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.load_checkpoint"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "args", "=", "self", ".", "parse_command_line", "(", ")", "\n", "\n", "self", ".", "checkpoint_dir", ",", "self", ".", "logfile", ",", "self", ".", "checkpoint_path_validation", ",", "self", ".", "checkpoint_path_final", "=", "get_log_files", "(", "self", ".", "args", ".", "checkpoint_dir", ",", "self", ".", "args", ".", "resume_from_checkpoint", ",", "self", ".", "args", ".", "mode", "==", "\"test\"", ")", "\n", "\n", "print_and_log", "(", "self", ".", "logfile", ",", "\"Options: %s\\n\"", "%", "self", ".", "args", ")", "\n", "print_and_log", "(", "self", ".", "logfile", ",", "\"Checkpoint Directory: %s\\n\"", "%", "self", ".", "checkpoint_dir", ")", "\n", "\n", "gpu_device", "=", "'cuda:0'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "gpu_device", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "self", ".", "model", "=", "self", ".", "init_model", "(", ")", "\n", "self", ".", "train_set", ",", "self", ".", "validation_set", ",", "self", ".", "test_set", "=", "self", ".", "init_data", "(", ")", "\n", "if", "self", ".", "args", ".", "dataset", "==", "\"meta-dataset\"", ":", "\n", "            ", "self", ".", "dataset", "=", "MetaDatasetReader", "(", "self", ".", "args", ".", "data_path", ",", "self", ".", "args", ".", "mode", ",", "self", ".", "train_set", ",", "self", ".", "validation_set", ",", "\n", "self", ".", "test_set", ",", "self", ".", "args", ".", "max_way_train", ",", "self", ".", "args", ".", "max_way_test", ",", "\n", "self", ".", "args", ".", "max_support_train", ",", "self", ".", "args", ".", "max_support_test", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dataset", "=", "SingleDatasetReader", "(", "self", ".", "args", ".", "data_path", ",", "self", ".", "args", ".", "mode", ",", "self", ".", "args", ".", "dataset", ",", "self", ".", "args", ".", "way", ",", "\n", "self", ".", "args", ".", "shot", ",", "self", ".", "args", ".", "query_train", ",", "self", ".", "args", ".", "query_test", ")", "\n", "", "self", ".", "loss", "=", "loss", "\n", "self", ".", "accuracy_fn", "=", "aggregate_accuracy", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "args", ".", "learning_rate", ")", "\n", "self", ".", "validation_accuracies", "=", "ValidationAccuracies", "(", "self", ".", "validation_set", ")", "\n", "self", ".", "start_iteration", "=", "0", "\n", "if", "self", ".", "args", ".", "resume_from_checkpoint", ":", "\n", "            ", "self", ".", "load_checkpoint", "(", ")", "\n", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.init_model": [[93, 105], ["run_cnaps.Learner.use_two_gpus", "Cnaps().to.Cnaps().to", "run_cnaps.Learner.register_extra_parameters", "model.Cnaps().to.train", "model.Cnaps().to.feature_extractor.eval", "model.Cnaps().to.distribute_model", "Cnaps().to.Cnaps"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.use_two_gpus", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.register_extra_parameters", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.model.Cnaps.distribute_model"], ["", "def", "init_model", "(", "self", ")", ":", "\n", "        ", "use_two_gpus", "=", "self", ".", "use_two_gpus", "(", ")", "\n", "model", "=", "Cnaps", "(", "device", "=", "self", ".", "device", ",", "use_two_gpus", "=", "use_two_gpus", ",", "args", "=", "self", ".", "args", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "register_extra_parameters", "(", "model", ")", "\n", "\n", "# set encoder is always in train mode (it only sees context data).", "\n", "model", ".", "train", "(", ")", "\n", "# Feature extractor is in eval mode by default, but gets switched in model depending on args.batch_normalization", "\n", "model", ".", "feature_extractor", ".", "eval", "(", ")", "\n", "if", "use_two_gpus", ":", "\n", "            ", "model", ".", "distribute_model", "(", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.init_data": [[106, 118], ["None"], "methods", ["None"], ["", "def", "init_data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "dataset", "==", "\"meta-dataset\"", ":", "\n", "            ", "train_set", "=", "[", "'ilsvrc_2012'", ",", "'omniglot'", ",", "'aircraft'", ",", "'cu_birds'", ",", "'dtd'", ",", "'quickdraw'", ",", "'fungi'", ",", "'vgg_flower'", "]", "\n", "validation_set", "=", "[", "'ilsvrc_2012'", ",", "'omniglot'", ",", "'aircraft'", ",", "'cu_birds'", ",", "'dtd'", ",", "'quickdraw'", ",", "'fungi'", ",", "'vgg_flower'", ",", "\n", "'mscoco'", "]", "\n", "test_set", "=", "self", ".", "args", ".", "test_datasets", "\n", "", "else", ":", "\n", "            ", "train_set", "=", "[", "self", ".", "args", ".", "dataset", "]", "\n", "validation_set", "=", "[", "self", ".", "args", ".", "dataset", "]", "\n", "test_set", "=", "[", "self", ".", "args", ".", "dataset", "]", "\n", "\n", "", "return", "train_set", ",", "validation_set", ",", "test_set", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.parse_command_line": [[122, 168], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "methods", ["None"], ["def", "parse_command_line", "(", "self", ")", ":", "\n", "        ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "choices", "=", "[", "\"meta-dataset\"", ",", "\"ilsvrc_2012\"", ",", "\"omniglot\"", ",", "\"aircraft\"", ",", "\"cu_birds\"", ",", "\n", "\"dtd\"", ",", "\"quickdraw\"", ",", "\"fungi\"", ",", "\"vgg_flower\"", ",", "\"traffic_sign\"", ",", "\"mscoco\"", ",", "\n", "\"mnist\"", ",", "\"cifar10\"", ",", "\"cifar100\"", "]", ",", "default", "=", "\"meta-dataset\"", ",", "\n", "help", "=", "\"Dataset to use.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--test_datasets'", ",", "nargs", "=", "'+'", ",", "help", "=", "'Datasets to use for testing'", ",", "\n", "default", "=", "[", "\"ilsvrc_2012\"", ",", "\"omniglot\"", ",", "\"aircraft\"", ",", "\"cu_birds\"", ",", "\"dtd\"", ",", "\"quickdraw\"", ",", "\"fungi\"", ",", "\n", "\"vgg_flower\"", ",", "\"traffic_sign\"", ",", "\"mscoco\"", ",", "\"mnist\"", ",", "\"cifar10\"", ",", "\"cifar100\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_path\"", ",", "default", "=", "\"../datasets\"", ",", "help", "=", "\"Path to dataset records.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--pretrained_resnet_path\"", ",", "default", "=", "\"../models/pretrained_resnet.pt.tar\"", ",", "\n", "help", "=", "\"Path to pretrained feature extractor model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mode\"", ",", "choices", "=", "[", "\"train\"", ",", "\"test\"", ",", "\"train_test\"", "]", ",", "default", "=", "\"train_test\"", ",", "\n", "help", "=", "\"Whether to run training only, testing only, or both training and testing.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "\"-lr\"", ",", "type", "=", "float", ",", "default", "=", "5e-4", ",", "help", "=", "\"Learning rate.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tasks_per_batch\"", ",", "type", "=", "int", ",", "default", "=", "16", ",", "\n", "help", "=", "\"Number of tasks between parameter optimizations.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint_dir\"", ",", "\"-c\"", ",", "default", "=", "'../checkpoints'", ",", "help", "=", "\"Directory to save checkpoint to.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_model_path\"", ",", "\"-m\"", ",", "default", "=", "None", ",", "help", "=", "\"Path to model to load and test.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--feature_adaptation\"", ",", "choices", "=", "[", "\"no_adaptation\"", ",", "\"film\"", ",", "\"film+ar\"", "]", ",", "default", "=", "\"film\"", ",", "\n", "help", "=", "\"Method to adapt feature extractor parameters.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_normalization\"", ",", "choices", "=", "[", "\"basic\"", ",", "\"task_norm-i\"", "]", ",", "\n", "default", "=", "\"basic\"", ",", "help", "=", "\"Normalization layer to use.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--training_iterations\"", ",", "\"-i\"", ",", "type", "=", "int", ",", "default", "=", "110000", ",", "\n", "help", "=", "\"Number of meta-training iterations.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--val_freq\"", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "help", "=", "\"Number of iterations between validations.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_way_train\"", ",", "type", "=", "int", ",", "default", "=", "40", ",", "\n", "help", "=", "\"Maximum way of meta-dataset meta-train task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_way_test\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Maximum way of meta-dataset meta-test task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_support_train\"", ",", "type", "=", "int", ",", "default", "=", "400", ",", "\n", "help", "=", "\"Maximum support set size of meta-dataset meta-train task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_support_test\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "\"Maximum support set size of meta-dataset meta-test task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--resume_from_checkpoint\"", ",", "\"-r\"", ",", "dest", "=", "\"resume_from_checkpoint\"", ",", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "help", "=", "\"Restart from latest checkpoint.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--way\"", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"Way of single dataset task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--shot\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"Shots per class for context of single dataset task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--query_train\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "\"Shots per class for target  of single dataset task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--query_test\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "\"Shots per class for target  of single dataset task.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.run": [[169, 217], ["run_cnaps.Learner.logfile.close", "range", "torch.save", "run_cnaps.Learner.test", "run_cnaps.Learner.test", "run_cnaps.Learner.test", "torch.set_grad_enabled", "run_cnaps.Learner.dataset.get_train_task", "run_cnaps.Learner.train_task", "train_accuracies.append", "losses.append", "run_cnaps.Learner.model.state_dict", "run_cnaps.Learner.optimizer.step", "run_cnaps.Learner.optimizer.zero_grad", "utils.print_and_log", "run_cnaps.Learner.validate", "run_cnaps.Learner.validation_accuracies.print", "run_cnaps.Learner.validation_accuracies.is_better", "run_cnaps.Learner.save_checkpoint", "run_cnaps.Learner.validation_accuracies.replace", "torch.save", "utils.print_and_log", "utils.print_and_log", "torch.Tensor().mean().item", "torch.Tensor().mean().item", "run_cnaps.Learner.model.state_dict", "torch.Tensor().mean", "torch.Tensor().mean", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.test", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.test", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.test", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader.get_train_task", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.train_task", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.validate", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.is_better", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.save_checkpoint", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.replace", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "mode", "==", "'train'", "or", "self", ".", "args", ".", "mode", "==", "'train_test'", ":", "\n", "            ", "train_accuracies", "=", "[", "]", "\n", "losses", "=", "[", "]", "\n", "total_iterations", "=", "self", ".", "args", ".", "training_iterations", "\n", "for", "iteration", "in", "range", "(", "self", ".", "start_iteration", ",", "total_iterations", ")", ":", "\n", "                ", "torch", ".", "set_grad_enabled", "(", "True", ")", "\n", "task_dict", "=", "self", ".", "dataset", ".", "get_train_task", "(", ")", "\n", "task_loss", ",", "task_accuracy", "=", "self", ".", "train_task", "(", "task_dict", ")", "\n", "train_accuracies", ".", "append", "(", "task_accuracy", ")", "\n", "losses", ".", "append", "(", "task_loss", ")", "\n", "\n", "# optimize", "\n", "if", "(", "(", "iteration", "+", "1", ")", "%", "self", ".", "args", ".", "tasks_per_batch", "==", "0", ")", "or", "(", "iteration", "==", "(", "total_iterations", "-", "1", ")", ")", ":", "\n", "                    ", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "(", "iteration", "+", "1", ")", "%", "PRINT_FREQUENCY", "==", "0", ":", "\n", "# print training stats", "\n", "                    ", "print_and_log", "(", "self", ".", "logfile", ",", "'Task [{}/{}], Train Loss: {:.7f}, Train Accuracy: {:.7f}'", "\n", ".", "format", "(", "iteration", "+", "1", ",", "total_iterations", ",", "torch", ".", "Tensor", "(", "losses", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "torch", ".", "Tensor", "(", "train_accuracies", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", ")", "\n", "train_accuracies", "=", "[", "]", "\n", "losses", "=", "[", "]", "\n", "\n", "", "if", "(", "(", "iteration", "+", "1", ")", "%", "self", ".", "args", ".", "val_freq", "==", "0", ")", "and", "(", "iteration", "+", "1", ")", "!=", "total_iterations", ":", "\n", "# validate", "\n", "                    ", "accuracy_dict", "=", "self", ".", "validate", "(", ")", "\n", "self", ".", "validation_accuracies", ".", "print", "(", "self", ".", "logfile", ",", "accuracy_dict", ")", "\n", "# save the model if validation is the best so far", "\n", "if", "self", ".", "validation_accuracies", ".", "is_better", "(", "accuracy_dict", ")", ":", "\n", "                        ", "self", ".", "validation_accuracies", ".", "replace", "(", "accuracy_dict", ")", "\n", "torch", ".", "save", "(", "self", ".", "model", ".", "state_dict", "(", ")", ",", "self", ".", "checkpoint_path_validation", ")", "\n", "print_and_log", "(", "self", ".", "logfile", ",", "'Best validation model was updated.'", ")", "\n", "print_and_log", "(", "self", ".", "logfile", ",", "''", ")", "\n", "", "self", ".", "save_checkpoint", "(", "iteration", "+", "1", ")", "\n", "\n", "# save the final model", "\n", "", "", "torch", ".", "save", "(", "self", ".", "model", ".", "state_dict", "(", ")", ",", "self", ".", "checkpoint_path_final", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "mode", "==", "'train_test'", ":", "\n", "            ", "self", ".", "test", "(", "self", ".", "checkpoint_path_final", ")", "\n", "self", ".", "test", "(", "self", ".", "checkpoint_path_validation", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "mode", "==", "'test'", ":", "\n", "            ", "self", ".", "test", "(", "self", ".", "args", ".", "test_model_path", ")", "\n", "\n", "", "self", ".", "logfile", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.train_task": [[218, 235], ["run_cnaps.Learner.prepare_task", "run_cnaps.Learner.model", "run_cnaps.Learner.accuracy_fn", "task_loss.backward", "run_cnaps.Learner.loss", "run_cnaps.Learner.use_two_gpus", "run_cnaps.Learner.model.feature_adaptation_network.regularization_term().cuda", "run_cnaps.Learner.model.feature_adaptation_network.regularization_term", "run_cnaps.Learner.model.feature_adaptation_network.regularization_term"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.prepare_task", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.loss", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.use_two_gpus", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork.regularization_term", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork.regularization_term"], ["", "def", "train_task", "(", "self", ",", "task_dict", ")", ":", "\n", "        ", "context_images", ",", "target_images", ",", "context_labels", ",", "target_labels", "=", "self", ".", "prepare_task", "(", "task_dict", ")", "\n", "\n", "target_logits", "=", "self", ".", "model", "(", "context_images", ",", "context_labels", ",", "target_images", ")", "\n", "task_loss", "=", "self", ".", "loss", "(", "target_logits", ",", "target_labels", ",", "self", ".", "device", ")", "/", "self", ".", "args", ".", "tasks_per_batch", "\n", "if", "self", ".", "args", ".", "feature_adaptation", "==", "'film'", "or", "self", ".", "args", ".", "feature_adaptation", "==", "'film+ar'", ":", "\n", "            ", "if", "self", ".", "use_two_gpus", "(", ")", ":", "\n", "                ", "regularization_term", "=", "(", "self", ".", "model", ".", "feature_adaptation_network", ".", "regularization_term", "(", ")", ")", ".", "cuda", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "regularization_term", "=", "(", "self", ".", "model", ".", "feature_adaptation_network", ".", "regularization_term", "(", ")", ")", "\n", "", "regularizer_scaling", "=", "0.001", "\n", "task_loss", "+=", "regularizer_scaling", "*", "regularization_term", "\n", "", "task_accuracy", "=", "self", ".", "accuracy_fn", "(", "target_logits", ",", "target_labels", ")", "\n", "\n", "task_loss", ".", "backward", "(", "retain_graph", "=", "False", ")", "\n", "\n", "return", "task_loss", ",", "task_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.validate": [[236, 255], ["torch.no_grad", "range", "run_cnaps.Learner.dataset.get_validation_task", "run_cnaps.Learner.prepare_task", "run_cnaps.Learner.model", "run_cnaps.Learner.accuracy_fn", "accuracies.append", "numpy.array().mean", "numpy.sqrt", "run_cnaps.Learner.item", "numpy.array().std", "len", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader.get_validation_task", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.prepare_task"], ["", "def", "validate", "(", "self", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "accuracy_dict", "=", "{", "}", "\n", "for", "item", "in", "self", ".", "validation_set", ":", "\n", "                ", "accuracies", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "NUM_VALIDATION_TASKS", ")", ":", "\n", "                    ", "task_dict", "=", "self", ".", "dataset", ".", "get_validation_task", "(", "item", ")", "\n", "context_images", ",", "target_images", ",", "context_labels", ",", "target_labels", "=", "self", ".", "prepare_task", "(", "task_dict", ")", "\n", "target_logits", "=", "self", ".", "model", "(", "context_images", ",", "context_labels", ",", "target_images", ")", "\n", "accuracy", "=", "self", ".", "accuracy_fn", "(", "target_logits", ",", "target_labels", ")", "\n", "accuracies", ".", "append", "(", "accuracy", ".", "item", "(", ")", ")", "\n", "del", "target_logits", "\n", "\n", "", "accuracy", "=", "np", ".", "array", "(", "accuracies", ")", ".", "mean", "(", ")", "*", "100.0", "\n", "confidence", "=", "(", "196.0", "*", "np", ".", "array", "(", "accuracies", ")", ".", "std", "(", ")", ")", "/", "np", ".", "sqrt", "(", "len", "(", "accuracies", ")", ")", "\n", "\n", "accuracy_dict", "[", "item", "]", "=", "{", "\"accuracy\"", ":", "accuracy", ",", "\"confidence\"", ":", "confidence", "}", "\n", "\n", "", "", "return", "accuracy_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.test": [[256, 277], ["utils.print_and_log", "utils.print_and_log", "run_cnaps.Learner.init_model", "run_cnaps.Learner.model.load_state_dict", "torch.load", "torch.no_grad", "range", "utils.print_and_log", "run_cnaps.Learner.dataset.get_test_task", "run_cnaps.Learner.prepare_task", "run_cnaps.Learner.model", "run_cnaps.Learner.accuracy_fn", "accuracies.append", "numpy.array().mean", "numpy.sqrt", "run_cnaps.Learner.item", "numpy.array().std", "len", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.init_model", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.meta_dataset_reader.SingleDatasetReader.get_test_task", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.prepare_task"], ["", "def", "test", "(", "self", ",", "path", ")", ":", "\n", "        ", "print_and_log", "(", "self", ".", "logfile", ",", "\"\"", ")", "# add a blank line", "\n", "print_and_log", "(", "self", ".", "logfile", ",", "'Testing model {0:}: '", ".", "format", "(", "path", ")", ")", "\n", "self", ".", "model", "=", "self", ".", "init_model", "(", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "path", ")", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "item", "in", "self", ".", "test_set", ":", "\n", "                ", "accuracies", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "NUM_TEST_TASKS", ")", ":", "\n", "                    ", "task_dict", "=", "self", ".", "dataset", ".", "get_test_task", "(", "item", ")", "\n", "context_images", ",", "target_images", ",", "context_labels", ",", "target_labels", "=", "self", ".", "prepare_task", "(", "task_dict", ")", "\n", "target_logits", "=", "self", ".", "model", "(", "context_images", ",", "context_labels", ",", "target_images", ")", "\n", "accuracy", "=", "self", ".", "accuracy_fn", "(", "target_logits", ",", "target_labels", ")", "\n", "accuracies", ".", "append", "(", "accuracy", ".", "item", "(", ")", ")", "\n", "del", "target_logits", "\n", "\n", "", "accuracy", "=", "np", ".", "array", "(", "accuracies", ")", ".", "mean", "(", ")", "*", "100.0", "\n", "accuracy_confidence", "=", "(", "196.0", "*", "np", ".", "array", "(", "accuracies", ")", ".", "std", "(", ")", ")", "/", "np", ".", "sqrt", "(", "len", "(", "accuracies", ")", ")", "\n", "\n", "print_and_log", "(", "self", ".", "logfile", ",", "'{0:}: {1:3.1f}+/-{2:2.1f}'", ".", "format", "(", "item", ",", "accuracy", ",", "accuracy_confidence", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.prepare_task": [[278, 298], ["context_images_np.transpose.transpose.transpose", "run_cnaps.Learner.shuffle", "torch.from_numpy", "torch.from_numpy", "target_images_np.transpose.transpose.transpose", "run_cnaps.Learner.shuffle", "torch.from_numpy", "torch.from_numpy", "context_images.to.to.to", "target_images.to.to.to", "context_labels.to.to.to", "target_labels.type().to.type().to.type().to", "target_labels.type().to.type().to.type"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.shuffle", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.shuffle"], ["", "", "", "def", "prepare_task", "(", "self", ",", "task_dict", ")", ":", "\n", "        ", "context_images_np", ",", "context_labels_np", "=", "task_dict", "[", "'context_images'", "]", ",", "task_dict", "[", "'context_labels'", "]", "\n", "target_images_np", ",", "target_labels_np", "=", "task_dict", "[", "'target_images'", "]", ",", "task_dict", "[", "'target_labels'", "]", "\n", "\n", "context_images_np", "=", "context_images_np", ".", "transpose", "(", "[", "0", ",", "3", ",", "1", ",", "2", "]", ")", "\n", "context_images_np", ",", "context_labels_np", "=", "self", ".", "shuffle", "(", "context_images_np", ",", "context_labels_np", ")", "\n", "context_images", "=", "torch", ".", "from_numpy", "(", "context_images_np", ")", "\n", "context_labels", "=", "torch", ".", "from_numpy", "(", "context_labels_np", ")", "\n", "\n", "target_images_np", "=", "target_images_np", ".", "transpose", "(", "[", "0", ",", "3", ",", "1", ",", "2", "]", ")", "\n", "target_images_np", ",", "target_labels_np", "=", "self", ".", "shuffle", "(", "target_images_np", ",", "target_labels_np", ")", "\n", "target_images", "=", "torch", ".", "from_numpy", "(", "target_images_np", ")", "\n", "target_labels", "=", "torch", ".", "from_numpy", "(", "target_labels_np", ")", "\n", "\n", "context_images", "=", "context_images", ".", "to", "(", "self", ".", "device", ")", "\n", "target_images", "=", "target_images", ".", "to", "(", "self", ".", "device", ")", "\n", "context_labels", "=", "context_labels", ".", "to", "(", "self", ".", "device", ")", "\n", "target_labels", "=", "target_labels", ".", "type", "(", "torch", ".", "LongTensor", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "return", "context_images", ",", "target_images", ",", "context_labels", ",", "target_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.shuffle": [[299, 305], ["numpy.random.permutation"], "methods", ["None"], ["", "def", "shuffle", "(", "self", ",", "images", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n        Return shuffled data.\n        \"\"\"", "\n", "permutation", "=", "np", ".", "random", ".", "permutation", "(", "images", ".", "shape", "[", "0", "]", ")", "\n", "return", "images", "[", "permutation", "]", ",", "labels", "[", "permutation", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.use_two_gpus": [[306, 314], ["None"], "methods", ["None"], ["", "def", "use_two_gpus", "(", "self", ")", ":", "\n", "        ", "use_two_gpus", "=", "False", "\n", "if", "self", ".", "args", ".", "dataset", "==", "\"meta-dataset\"", ":", "\n", "            ", "if", "self", ".", "args", ".", "feature_adaptation", "==", "\"film+ar\"", "or", "self", ".", "args", ".", "batch_normalization", "==", "\"task_norm-i\"", ":", "\n", "                ", "use_two_gpus", "=", "True", "# These models do not fit on one GPU, so use model parallelism.", "\n", "\n", "", "", "return", "use_two_gpus", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.save_checkpoint": [[315, 322], ["torch.save", "os.path.join", "run_cnaps.Learner.model.state_dict", "run_cnaps.Learner.optimizer.state_dict", "run_cnaps.Learner.validation_accuracies.get_current_best_accuracy_dict"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.get_current_best_accuracy_dict"], ["", "def", "save_checkpoint", "(", "self", ",", "iteration", ")", ":", "\n", "        ", "torch", ".", "save", "(", "{", "\n", "'iteration'", ":", "iteration", ",", "\n", "'model_state_dict'", ":", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_state_dict'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'best_accuracy'", ":", "self", ".", "validation_accuracies", ".", "get_current_best_accuracy_dict", "(", ")", ",", "\n", "}", ",", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "'checkpoint.pt'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.load_checkpoint": [[323, 329], ["torch.load", "run_cnaps.Learner.model.load_state_dict", "run_cnaps.Learner.optimizer.load_state_dict", "run_cnaps.Learner.validation_accuracies.replace", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.replace"], ["", "def", "load_checkpoint", "(", "self", ")", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoint_dir", ",", "'checkpoint.pt'", ")", ")", "\n", "self", ".", "start_iteration", "=", "checkpoint", "[", "'iteration'", "]", "\n", "self", ".", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model_state_dict'", "]", ")", "\n", "self", ".", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer_state_dict'", "]", ")", "\n", "self", ".", "validation_accuracies", ".", "replace", "(", "checkpoint", "[", "'best_accuracy'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.register_extra_parameters": [[330, 334], ["model.modules", "isinstance", "module.register_extra_weights"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.TaskNormBase.register_extra_weights"], ["", "def", "register_extra_parameters", "(", "self", ",", "model", ")", ":", "\n", "        ", "for", "module", "in", "model", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "TaskNormI", ")", ":", "\n", "                ", "module", ".", "register_extra_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.main": [[58, 61], ["run_cnaps.Learner", "run_cnaps.Learner.run"], "function", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.run_cnaps.Learner.run"], ["def", "main", "(", ")", ":", "\n", "    ", "learner", "=", "Learner", "(", ")", "\n", "learner", ".", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.DenseResidualLayer.__init__": [[10, 13], ["torch.Module.__init__", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__"], ["def", "__init__", "(", "self", ",", "num_features", ")", ":", "\n", "        ", "super", "(", "DenseResidualLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "num_features", ",", "num_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.DenseResidualLayer.forward": [[14, 28], ["adaptation_networks.DenseResidualLayer.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forward-pass through the layer. Implements the following computation:\n\n                f(x) = f_theta(x) + x\n                f_theta(x) = W^T x + b\n\n        :param x: (torch.tensor) Input representation to apply layer to ( dim(x) = (batch, num_features) ).\n        :return: (torch.tensor) Return f(x) ( dim(f(x) = (batch, num_features) ).\n        \"\"\"", "\n", "identity", "=", "x", "\n", "out", "=", "self", ".", "linear", "(", "x", ")", "\n", "out", "+=", "identity", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.DenseResidualBlock.__init__": [[36, 42], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ELU", "torch.ELU"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__"], ["def", "__init__", "(", "self", ",", "in_size", ",", "out_size", ")", ":", "\n", "        ", "super", "(", "DenseResidualBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "in_size", ",", "out_size", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "out_size", ",", "out_size", ")", "\n", "self", ".", "linear3", "=", "nn", ".", "Linear", "(", "out_size", ",", "out_size", ")", "\n", "self", ".", "elu", "=", "nn", ".", "ELU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.DenseResidualBlock.forward": [[43, 65], ["adaptation_networks.DenseResidualBlock.linear1", "adaptation_networks.DenseResidualBlock.elu", "adaptation_networks.DenseResidualBlock.linear2", "adaptation_networks.DenseResidualBlock.elu", "adaptation_networks.DenseResidualBlock.linear3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass through residual block. Implements following computation:\n\n                h = f3( f2( f1(x) ) ) + x\n                or\n                h = f3( f2( f1(x) ) )\n\n                where fi(x) = Elu( Wi^T x + bi )\n\n        :param x: (torch.tensor) Input representation to apply layer to ( dim(x) = (batch, in_size) ).\n        :return: (torch.tensor) Return f(x) ( dim(f(x) = (batch, out_size) ).\n        \"\"\"", "\n", "identity", "=", "x", "\n", "out", "=", "self", ".", "linear1", "(", "x", ")", "\n", "out", "=", "self", ".", "elu", "(", "out", ")", "\n", "out", "=", "self", ".", "linear2", "(", "out", ")", "\n", "out", "=", "self", ".", "elu", "(", "out", ")", "\n", "out", "=", "self", ".", "linear3", "(", "out", ")", "\n", "if", "x", ".", "shape", "[", "-", "1", "]", "==", "out", ".", "shape", "[", "-", "1", "]", ":", "\n", "            ", "out", "+=", "identity", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmAdaptationNetwork.__init__": [[76, 84], ["torch.Module.__init__", "len", "adaptation_networks.FilmAdaptationNetwork.get_layers"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmAdaptationNetwork.get_layers"], ["def", "__init__", "(", "self", ",", "layer", ",", "num_maps_per_layer", ",", "num_blocks_per_layer", ",", "z_g_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_g_dim", "=", "z_g_dim", "\n", "self", ".", "num_maps", "=", "num_maps_per_layer", "\n", "self", ".", "num_blocks", "=", "num_blocks_per_layer", "\n", "self", ".", "num_target_layers", "=", "len", "(", "self", ".", "num_maps", ")", "\n", "self", ".", "layer", "=", "layer", "\n", "self", ".", "layers", "=", "self", ".", "get_layers", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmAdaptationNetwork.get_layers": [[85, 100], ["torch.ModuleList", "torch.ModuleList", "zip", "torch.ModuleList.append", "adaptation_networks.FilmAdaptationNetwork.layer"], "methods", ["None"], ["", "def", "get_layers", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Loop over layers of base network and initialize adaptation network.\n        :return: (nn.ModuleList) ModuleList containing the adaptation network for each layer in base network.\n        \"\"\"", "\n", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "num_maps", ",", "num_blocks", "in", "zip", "(", "self", ".", "num_maps", ",", "self", ".", "num_blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "self", ".", "layer", "(", "\n", "num_maps", "=", "num_maps", ",", "\n", "num_blocks", "=", "num_blocks", ",", "\n", "z_g_dim", "=", "self", ".", "z_g_dim", "\n", ")", "\n", ")", "\n", "", "return", "layers", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmAdaptationNetwork.forward": [[101, 108], ["range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass through adaptation network to create list of adaptation parameters.\n        :param x: (torch.tensor) (z -- task level representation for generating adaptation).\n        :return: (list::adaptation_params) Returns a list of adaptation dictionaries, one for each layer in base net.\n        \"\"\"", "\n", "return", "[", "self", ".", "layers", "[", "layer", "]", "(", "x", ")", "for", "layer", "in", "range", "(", "self", ".", "num_target_layers", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmAdaptationNetwork.regularization_term": [[109, 118], ["layer.regularization_term"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork.regularization_term"], ["", "def", "regularization_term", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to aggregate the regularization terms from each of the layers in the adaptation network.\n        :return: (torch.scalar) A order-0 torch tensor with the regularization term for the adaptation net params.\n        \"\"\"", "\n", "l2_term", "=", "0", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "l2_term", "+=", "layer", ".", "regularization_term", "(", ")", "\n", "", "return", "l2_term", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmLayerNetwork.__init__": [[128, 163], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "range", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "adaptation_networks.FilmLayerNetwork.gamma1_processors.append", "adaptation_networks.FilmLayerNetwork.gamma1_regularizers.append", "adaptation_networks.FilmLayerNetwork.beta1_processors.append", "adaptation_networks.FilmLayerNetwork.beta1_regularizers.append", "adaptation_networks.FilmLayerNetwork.gamma2_processors.append", "adaptation_networks.FilmLayerNetwork.gamma2_regularizers.append", "adaptation_networks.FilmLayerNetwork.beta2_processors.append", "adaptation_networks.FilmLayerNetwork.beta2_regularizers.append", "adaptation_networks.FilmLayerNetwork._make_layer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "adaptation_networks.FilmLayerNetwork._make_layer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "adaptation_networks.FilmLayerNetwork._make_layer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "adaptation_networks.FilmLayerNetwork._make_layer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer"], ["def", "__init__", "(", "self", ",", "num_maps", ",", "num_blocks", ",", "z_g_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_g_dim", "=", "z_g_dim", "\n", "self", ".", "num_maps", "=", "num_maps", "\n", "self", ".", "num_blocks", "=", "num_blocks", "\n", "\n", "# Initialize a simple shared layer for all parameter adapters (gammas and betas)", "\n", "self", ".", "shared_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "z_g_dim", ",", "self", ".", "num_maps", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "\n", "# Initialize the processors (adaptation networks) and regularization lists for each of the output params", "\n", "self", ".", "gamma1_processors", ",", "self", ".", "gamma1_regularizers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", ",", "torch", ".", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "gamma2_processors", ",", "self", ".", "gamma2_regularizers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", ",", "torch", ".", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "beta1_processors", ",", "self", ".", "beta1_regularizers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", ",", "torch", ".", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "beta2_processors", ",", "self", ".", "beta2_regularizers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", ",", "torch", ".", "nn", ".", "ParameterList", "(", ")", "\n", "\n", "# Generate the required layers / regularization parameters, and collect them in ModuleLists and ParameterLists", "\n", "for", "_", "in", "range", "(", "self", ".", "num_blocks", ")", ":", "\n", "            ", "self", ".", "gamma1_processors", ".", "append", "(", "self", ".", "_make_layer", "(", "num_maps", ")", ")", "\n", "self", ".", "gamma1_regularizers", ".", "append", "(", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "num_maps", ")", ",", "0", ",", "0.001", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "\n", "self", ".", "beta1_processors", ".", "append", "(", "self", ".", "_make_layer", "(", "num_maps", ")", ")", "\n", "self", ".", "beta1_regularizers", ".", "append", "(", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "num_maps", ")", ",", "0", ",", "0.001", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "\n", "self", ".", "gamma2_processors", ".", "append", "(", "self", ".", "_make_layer", "(", "num_maps", ")", ")", "\n", "self", ".", "gamma2_regularizers", ".", "append", "(", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "num_maps", ")", ",", "0", ",", "0.001", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "\n", "self", ".", "beta2_processors", ".", "append", "(", "self", ".", "_make_layer", "(", "num_maps", ")", ")", "\n", "self", ".", "beta2_regularizers", ".", "append", "(", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "num_maps", ")", ",", "0", ",", "0.001", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmLayerNetwork._make_layer": [[164, 177], ["torch.Sequential", "torch.Sequential", "adaptation_networks.DenseResidualLayer", "torch.ReLU", "torch.ReLU", "adaptation_networks.DenseResidualLayer", "torch.ReLU", "torch.ReLU", "adaptation_networks.DenseResidualLayer"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_make_layer", "(", "size", ")", ":", "\n", "        ", "\"\"\"\n        Simple layer generation method for adaptation network of one of the parameter sets (all have same structure).\n        :param size: (int) Number of parameters in layer.\n        :return: (nn.Sequential) Three layer dense residual network to generate adaptation parameters.\n        \"\"\"", "\n", "return", "nn", ".", "Sequential", "(", "\n", "DenseResidualLayer", "(", "size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "DenseResidualLayer", "(", "size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "DenseResidualLayer", "(", "size", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmLayerNetwork.forward": [[179, 200], ["adaptation_networks.FilmLayerNetwork.shared_layer", "range", "block_params.append", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass through adaptation network.\n        :param x: (torch.tensor) Input representation to network (task level representation z).\n        :return: (list::dictionaries) Dictionary for every block in layer. Dictionary contains all the parameters\n                 necessary to adapt layer in base network. Base network is aware of dict structure and can pull params\n                 out during forward pass.\n        \"\"\"", "\n", "x", "=", "self", ".", "shared_layer", "(", "x", ")", "\n", "block_params", "=", "[", "]", "\n", "for", "block", "in", "range", "(", "self", ".", "num_blocks", ")", ":", "\n", "            ", "block_param_dict", "=", "{", "\n", "'gamma1'", ":", "self", ".", "gamma1_processors", "[", "block", "]", "(", "x", ")", ".", "squeeze", "(", ")", "*", "self", ".", "gamma1_regularizers", "[", "block", "]", "+", "\n", "torch", ".", "ones_like", "(", "self", ".", "gamma1_regularizers", "[", "block", "]", ")", ",", "\n", "'beta1'", ":", "self", ".", "beta1_processors", "[", "block", "]", "(", "x", ")", ".", "squeeze", "(", ")", "*", "self", ".", "beta1_regularizers", "[", "block", "]", ",", "\n", "'gamma2'", ":", "self", ".", "gamma2_processors", "[", "block", "]", "(", "x", ")", ".", "squeeze", "(", ")", "*", "self", ".", "gamma2_regularizers", "[", "block", "]", "+", "\n", "torch", ".", "ones_like", "(", "self", ".", "gamma2_regularizers", "[", "block", "]", ")", ",", "\n", "'beta2'", ":", "self", ".", "beta2_processors", "[", "block", "]", "(", "x", ")", ".", "squeeze", "(", ")", "*", "self", ".", "beta2_regularizers", "[", "block", "]", "\n", "}", "\n", "block_params", ".", "append", "(", "block_param_dict", ")", "\n", "", "return", "block_params", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmLayerNetwork.regularization_term": [[201, 215], ["zip", "zip"], "methods", ["None"], ["", "def", "regularization_term", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Compute the regularization term for the parameters. Recall, FiLM applies gamma * x + beta. As such, params\n        gamma and beta are regularized to unity, i.e. ||gamma - 1||_2 and ||beta||_2.\n        :return: (torch.tensor) Scalar for l2 norm for all parameters according to regularization scheme.\n        \"\"\"", "\n", "l2_term", "=", "0", "\n", "for", "gamma_regularizer", ",", "beta_regularizer", "in", "zip", "(", "self", ".", "gamma1_regularizers", ",", "self", ".", "beta1_regularizers", ")", ":", "\n", "            ", "l2_term", "+=", "(", "gamma_regularizer", "**", "2", ")", ".", "sum", "(", ")", "\n", "l2_term", "+=", "(", "beta_regularizer", "**", "2", ")", ".", "sum", "(", ")", "\n", "", "for", "gamma_regularizer", ",", "beta_regularizer", "in", "zip", "(", "self", ".", "gamma2_regularizers", ",", "self", ".", "beta2_regularizers", ")", ":", "\n", "            ", "l2_term", "+=", "(", "gamma_regularizer", "**", "2", ")", ".", "sum", "(", ")", "\n", "l2_term", "+=", "(", "beta_regularizer", "**", "2", ")", ".", "sum", "(", ")", "\n", "", "return", "l2_term", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.NullFeatureAdaptationNetwork.__init__": [[221, 223], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.NullFeatureAdaptationNetwork.forward": [[224, 226], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.NullFeatureAdaptationNetwork.regularization_term": [[227, 230], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "regularization_term", "(", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.LinearClassifierAdaptationNetwork.__init__": [[237, 241], ["torch.Module.__init__", "adaptation_networks.LinearClassifierAdaptationNetwork._make_mean_dense_block", "adaptation_networks.LinearClassifierAdaptationNetwork._make_mean_dense_block"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.LinearClassifierAdaptationNetwork._make_mean_dense_block", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.LinearClassifierAdaptationNetwork._make_mean_dense_block"], ["def", "__init__", "(", "self", ",", "d_theta", ")", ":", "\n", "        ", "super", "(", "LinearClassifierAdaptationNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight_means_processor", "=", "self", ".", "_make_mean_dense_block", "(", "d_theta", ",", "d_theta", ")", "\n", "self", ".", "bias_means_processor", "=", "self", ".", "_make_mean_dense_block", "(", "d_theta", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.LinearClassifierAdaptationNetwork._make_mean_dense_block": [[242, 251], ["adaptation_networks.DenseResidualBlock"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_mean_dense_block", "(", "in_size", ",", "out_size", ")", ":", "\n", "        ", "\"\"\"\n        Simple method for generating different types of blocks. Final code only uses dense residual blocks.\n        :param in_size: (int) Input representation dimensionality.\n        :param out_size: (int) Output representation dimensionality.\n        :return: (nn.Module) Adaptation network parameters for outputting classification parameters.\n        \"\"\"", "\n", "return", "DenseResidualBlock", "(", "in_size", ",", "out_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.LinearClassifierAdaptationNetwork.forward": [[252, 282], ["list", "list.sort", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "representation_dict.keys", "class_weight_means.append", "class_bias_means.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "adaptation_networks.LinearClassifierAdaptationNetwork.weight_means_processor", "adaptation_networks.LinearClassifierAdaptationNetwork.bias_means_processor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "representation_dict", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass through adaptation network. Returns classification parameters for task.\n        :param representation_dict: (dict::torch.tensors) Dictionary containing class-level representations for each\n                                    class in the task.\n        :return: (dict::torch.tensors) Dictionary containing the weights and biases for the classification of each class\n                 in the task. Model can extract parameters and build the classifier accordingly. Supports sampling if\n                 ML-PIP objective is desired.\n        \"\"\"", "\n", "classifier_param_dict", "=", "{", "}", "\n", "class_weight_means", "=", "[", "]", "\n", "class_bias_means", "=", "[", "]", "\n", "\n", "# Extract and sort the label set for the task", "\n", "label_set", "=", "list", "(", "representation_dict", ".", "keys", "(", ")", ")", "\n", "label_set", ".", "sort", "(", ")", "\n", "num_classes", "=", "len", "(", "label_set", ")", "\n", "\n", "# For each class, extract the representation and pass it through adaptation network to generate classification", "\n", "# params for that class. Store parameters in a list,", "\n", "for", "class_num", "in", "label_set", ":", "\n", "            ", "nu", "=", "representation_dict", "[", "class_num", "]", "\n", "class_weight_means", ".", "append", "(", "self", ".", "weight_means_processor", "(", "nu", ")", ")", "\n", "class_bias_means", ".", "append", "(", "self", ".", "bias_means_processor", "(", "nu", ")", ")", "\n", "\n", "# Save the parameters as torch tensors (matrix and vector) and add to dictionary", "\n", "", "classifier_param_dict", "[", "'weight_mean'", "]", "=", "torch", ".", "cat", "(", "class_weight_means", ",", "dim", "=", "0", ")", "\n", "classifier_param_dict", "[", "'bias_mean'", "]", "=", "torch", ".", "reshape", "(", "torch", ".", "cat", "(", "class_bias_means", ",", "dim", "=", "1", ")", ",", "[", "num_classes", ",", "]", ")", "\n", "\n", "return", "classifier_param_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArAdaptationNetwork.__init__": [[295, 314], ["torch.Module.__init__", "len", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.ModuleList", "torch.ModuleList", "zip", "adaptation_networks.FilmArAdaptationNetwork.layers.append", "adaptation_networks.FilmArAdaptationNetwork.affine_layer"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__"], ["def", "__init__", "(", "self", ",", "feature_extractor", ",", "num_maps_per_layer", ",", "num_blocks_per_layer", ",", "num_initial_conv_maps", ",", "z_g_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feature_extractor", "=", "feature_extractor", "\n", "self", ".", "z_g_dim", "=", "z_g_dim", "\n", "self", ".", "num_maps", "=", "num_maps_per_layer", "\n", "self", ".", "num_blocks", "=", "num_blocks_per_layer", "\n", "self", ".", "num_target_layers", "=", "len", "(", "self", ".", "num_maps", ")", "\n", "self", ".", "affine_layer", "=", "FilmArLayerNetwork", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "previous_maps", "=", "[", "num_initial_conv_maps", "]", "+", "self", ".", "num_maps", "\n", "for", "input_dim", ",", "num_maps", ",", "num_blocks", "in", "zip", "(", "previous_maps", "[", ":", "-", "1", "]", ",", "self", ".", "num_maps", ",", "self", ".", "num_blocks", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "self", ".", "affine_layer", "(", "\n", "input_dim", "=", "input_dim", ",", "\n", "z_g_dim", "=", "self", ".", "z_g_dim", ",", "\n", "num_maps", "=", "num_maps", ",", "\n", "num_blocks", "=", "num_blocks", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArAdaptationNetwork.forward": [[317, 341], ["adaptation_networks.FilmArAdaptationNetwork.feature_extractor.get_layer_output", "adaptation_networks.FilmArAdaptationNetwork.forward.flatten"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.resnet.ResNet.get_layer_output"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "task_representation", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass through the adaptation network. Implements auto-regressive computation detailed in paper (see\n        Section 2.2 in https://arxiv.org/pdf/1906.07697 for further details).\n        :param x: (torch.tensor) Example images context set of task.\n        :param task_representation: (torch.tensor) Global task representation z_G from set encoder.\n        :return: (list::dict::torch.tensor) List of dictionaries of adaptation parameters to be used by model.\n        \"\"\"", "\n", "def", "flatten", "(", "t", ")", ":", "\n", "            ", "t", "=", "self", ".", "avgpool", "(", "t", ")", "\n", "return", "t", ".", "view", "(", "t", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "", "param_dicts", "=", "[", "]", "\n", "# Start with initial convolution layer from ResNet to embedd context set and generate first local representation", "\n", "z", "=", "self", ".", "feature_extractor", ".", "get_layer_output", "(", "x", ",", "None", ",", "0", ")", "\n", "z_hn", "=", "flatten", "(", "z", ")", "\n", "# For every following layer: pass global and local representations through hypernet layer. This returns the", "\n", "# next layer adaptation parameters. Use these to make a pass through the next layer with context set, and", "\n", "# save adaptation parameters.", "\n", "for", "layer", ",", "hn_layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "param_dicts", ".", "append", "(", "hn_layer", "(", "z_hn", ",", "task_representation", ")", ")", "\n", "z", "=", "self", ".", "feature_extractor", ".", "get_layer_output", "(", "z", ",", "param_dicts", ",", "layer", "+", "1", ")", "\n", "z_hn", "=", "flatten", "(", "z", ")", "\n", "", "return", "param_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArAdaptationNetwork.regularization_term": [[342, 351], ["layer.regularization_term"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork.regularization_term"], ["", "def", "regularization_term", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to aggregate the regularization terms from each of the layers in the adaptation network.\n        :return: (torch.scalar) A order-0 torch tensor with the regularization term for the adaptation net params.\n        \"\"\"", "\n", "l2_term", "=", "0", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "l2_term", "+=", "layer", ".", "regularization_term", "(", ")", "\n", "", "return", "l2_term", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork.__init__": [[362, 393], ["torch.Module.__init__", "adaptation_networks.FilmArLayerNetwork.get_shared_layers", "range", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "adaptation_networks.FilmArLayerNetwork.gamma1_processors.append", "adaptation_networks.FilmArLayerNetwork.gamma1_regularizers.append", "adaptation_networks.FilmArLayerNetwork.beta1_processors.append", "adaptation_networks.FilmArLayerNetwork.beta1_regularizers.append", "adaptation_networks.FilmArLayerNetwork.gamma2_processors.append", "adaptation_networks.FilmArLayerNetwork.gamma2_regularizers.append", "adaptation_networks.FilmArLayerNetwork.beta2_processors.append", "adaptation_networks.FilmArLayerNetwork.beta2_regularizers.append", "adaptation_networks.FilmArLayerNetwork._make_layer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "adaptation_networks.FilmArLayerNetwork._make_layer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "adaptation_networks.FilmArLayerNetwork._make_layer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "adaptation_networks.FilmArLayerNetwork._make_layer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork.get_shared_layers", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "z_g_dim", ",", "num_maps", ",", "num_blocks", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "z_g_dim", "=", "z_g_dim", "\n", "self", ".", "num_maps", "=", "num_maps", "\n", "self", ".", "num_blocks", "=", "num_blocks", "\n", "self", ".", "shared_layer", ",", "self", ".", "shared_layer_post", "=", "self", ".", "get_shared_layers", "(", ")", "\n", "\n", "# Initialize ModuleLists and ParameterLists for layer processeors (hyper-nets) and regluarizers", "\n", "self", ".", "gamma1_processors", ",", "self", ".", "gamma1_regularizers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", ",", "torch", ".", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "gamma2_processors", ",", "self", ".", "gamma2_regularizers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", ",", "torch", ".", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "beta1_processors", ",", "self", ".", "beta1_regularizers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", ",", "torch", ".", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "beta2_processors", ",", "self", ".", "beta2_regularizers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", ",", "torch", ".", "nn", ".", "ParameterList", "(", ")", "\n", "\n", "# Loop over blocks. For each block, collect necessary parameters and regularizers", "\n", "for", "_", "in", "range", "(", "self", ".", "num_blocks", ")", ":", "\n", "            ", "self", ".", "gamma1_processors", ".", "append", "(", "self", ".", "_make_layer", "(", "self", ".", "num_maps", "+", "self", ".", "z_g_dim", ",", "num_maps", ")", ")", "\n", "self", ".", "gamma1_regularizers", ".", "append", "(", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "num_maps", ")", ",", "0", ",", "0.001", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "\n", "self", ".", "beta1_processors", ".", "append", "(", "self", ".", "_make_layer", "(", "self", ".", "num_maps", "+", "self", ".", "z_g_dim", ",", "num_maps", ")", ")", "\n", "self", ".", "beta1_regularizers", ".", "append", "(", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "num_maps", ")", ",", "0", ",", "0.001", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "\n", "self", ".", "gamma2_processors", ".", "append", "(", "self", ".", "_make_layer", "(", "self", ".", "num_maps", "+", "self", ".", "z_g_dim", ",", "num_maps", ")", ")", "\n", "self", ".", "gamma2_regularizers", ".", "append", "(", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "num_maps", ")", ",", "0", ",", "0.001", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "\n", "self", ".", "beta2_processors", ".", "append", "(", "self", ".", "_make_layer", "(", "self", ".", "num_maps", "+", "self", ".", "z_g_dim", ",", "num_maps", ")", ")", "\n", "self", ".", "beta2_regularizers", ".", "append", "(", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "num_maps", ")", ",", "0", ",", "0.001", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork.get_shared_layers": [[394, 414], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "adaptation_networks.DenseResidualLayer", "torch.ReLU", "torch.ReLU", "adaptation_networks.DenseResidualLayer", "torch.ReLU", "torch.ReLU", "adaptation_networks.DenseResidualLayer", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU"], "methods", ["None"], ["", "", "def", "get_shared_layers", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Simple layer generation method for shared layer to be used in layer adaptation network.\n        :param size: (int) Number of parameters in layer.\n        :return: (nn.Sequential) Three layer dense residual network to generate adaptation parameters.\n        \"\"\"", "\n", "shared_layer_pre", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "self", ".", "num_maps", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "DenseResidualLayer", "(", "self", ".", "num_maps", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "DenseResidualLayer", "(", "self", ".", "num_maps", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "DenseResidualLayer", "(", "self", ".", "num_maps", ")", "\n", ")", "\n", "shared_layer_post", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "num_maps", ",", "self", ".", "num_maps", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "return", "shared_layer_pre", ",", "shared_layer_post", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork._make_layer": [[415, 430], ["torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "adaptation_networks.DenseResidualLayer", "torch.ReLU", "torch.ReLU", "adaptation_networks.DenseResidualLayer", "torch.ReLU", "torch.ReLU", "adaptation_networks.DenseResidualLayer"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_layer", "(", "in_size", ",", "out_size", ")", ":", "\n", "        ", "\"\"\"\n        Simple layer generation method for processor for each of the parameters associated with the base net layer.\n        :param size: (int) Number of parameters in layer.\n        :return: (nn.Sequential) Three layer dense residual network to generate adaptation parameters.\n        \"\"\"", "\n", "return", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_size", ",", "out_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "DenseResidualLayer", "(", "out_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "DenseResidualLayer", "(", "out_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "DenseResidualLayer", "(", "out_size", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork.forward": [[432, 456], ["adaptation_networks.FilmArLayerNetwork.shared_layer", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "adaptation_networks.FilmArLayerNetwork.shared_layer_post", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "block_params.append", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "task_representation", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass through adaptation network.\n        :param x: (torch.tensor) Input representation to network (task level representation z).\n        :return: (list::dictionaries) Dictionary for every block in layer. Dictionary contains all the parameters\n                 necessary to adapt layer in base network. Base network is aware of dict structure and can pull params\n                 out during forward pass.\n        \"\"\"", "\n", "x", "=", "self", ".", "shared_layer", "(", "x", ")", "\n", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "self", ".", "shared_layer_post", "(", "x", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "task_representation", "]", ",", "dim", "=", "-", "1", ")", "\n", "block_params", "=", "[", "]", "\n", "for", "block", "in", "range", "(", "self", ".", "num_blocks", ")", ":", "\n", "            ", "block_param_dict", "=", "{", "\n", "'gamma1'", ":", "self", ".", "gamma1_processors", "[", "block", "]", "(", "x", ")", ".", "squeeze", "(", ")", "*", "self", ".", "gamma1_regularizers", "[", "block", "]", "+", "\n", "torch", ".", "ones_like", "(", "self", ".", "gamma1_regularizers", "[", "block", "]", ")", ",", "\n", "'beta1'", ":", "self", ".", "beta1_processors", "[", "block", "]", "(", "x", ")", ".", "squeeze", "(", ")", "*", "self", ".", "beta1_regularizers", "[", "block", "]", ",", "\n", "'gamma2'", ":", "self", ".", "gamma2_processors", "[", "block", "]", "(", "x", ")", ".", "squeeze", "(", ")", "*", "self", ".", "gamma2_regularizers", "[", "block", "]", "+", "\n", "torch", ".", "ones_like", "(", "self", ".", "gamma2_regularizers", "[", "block", "]", ")", ",", "\n", "'beta2'", ":", "self", ".", "beta2_processors", "[", "block", "]", "(", "x", ")", ".", "squeeze", "(", ")", "*", "self", ".", "beta2_regularizers", "[", "block", "]", "\n", "}", "\n", "block_params", ".", "append", "(", "block_param_dict", ")", "\n", "", "return", "block_params", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.adaptation_networks.FilmArLayerNetwork.regularization_term": [[457, 471], ["zip", "zip"], "methods", ["None"], ["", "def", "regularization_term", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Compute the regularization term for the parameters. Recall, FiLM applies gamma * x + beta. As such, params\n        gamma and beta are regularized to unity, i.e. ||gamma - 1||_2 and ||beta||_2.\n        :return: (torch.tensor) Scalar for l2 norm for all parameters according to regularization scheme.\n        \"\"\"", "\n", "l2_term", "=", "0", "\n", "for", "gamma_regularizer", ",", "beta_regularizer", "in", "zip", "(", "self", ".", "gamma1_regularizers", ",", "self", ".", "beta1_regularizers", ")", ":", "\n", "            ", "l2_term", "+=", "(", "gamma_regularizer", "**", "2", ")", ".", "sum", "(", ")", "\n", "l2_term", "+=", "(", "beta_regularizer", "**", "2", ")", ".", "sum", "(", ")", "\n", "", "for", "gamma_regularizer", ",", "beta_regularizer", "in", "zip", "(", "self", ".", "gamma2_regularizers", ",", "self", ".", "beta2_regularizers", ")", ":", "\n", "            ", "l2_term", "+=", "(", "gamma_regularizer", "**", "2", ")", ".", "sum", "(", ")", "\n", "l2_term", "+=", "(", "beta_regularizer", "**", "2", ")", ".", "sum", "(", ")", "\n", "", "return", "l2_term", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.NormalizationLayer.__init__": [[10, 21], ["torch.BatchNorm2d.__init__"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__"], ["def", "__init__", "(", "self", ",", "num_features", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the class.\n        :param num_features: number of channels in the 2D convolutional layer\n        \"\"\"", "\n", "super", "(", "NormalizationLayer", ",", "self", ")", ".", "__init__", "(", "\n", "num_features", ",", "\n", "eps", "=", "1e-05", ",", "\n", "momentum", "=", "0.1", ",", "\n", "affine", "=", "True", ",", "\n", "track_running_stats", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.NormalizationLayer.forward": [[22, 29], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Normalize activations.\n        :param x: input activations\n        :return: normalized activations\n        \"\"\"", "\n", "pass", "# always override this method", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.NormalizationLayer._normalize": [[30, 39], ["normalization_layers.NormalizationLayer.bias.view", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "normalization_layers.NormalizationLayer.weight.view"], "methods", ["None"], ["", "def", "_normalize", "(", "self", ",", "x", ",", "mean", ",", "var", ")", ":", "\n", "        ", "\"\"\"\n        Normalize activations.\n        :param x: input activations\n        :param mean: mean used to normalize\n        :param var: var used to normalize\n        :return: normalized activations\n        \"\"\"", "\n", "return", "(", "self", ".", "weight", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "*", "(", "x", "-", "mean", ")", "/", "torch", ".", "sqrt", "(", "var", "+", "self", ".", "eps", ")", ")", "+", "self", ".", "bias", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.NormalizationLayer._compute_batch_moments": [[40, 48], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.var", "torch.var", "torch.var", "torch.var"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_batch_moments", "(", "x", ")", ":", "\n", "        ", "\"\"\"\n        Compute conventional batch mean and variance.\n        :param x: input activations\n        :return: batch mean, batch variance\n        \"\"\"", "\n", "return", "torch", ".", "mean", "(", "x", ",", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", ",", "torch", ".", "var", "(", "x", ",", "dim", "=", "(", "0", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.NormalizationLayer._compute_instance_moments": [[49, 57], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.var", "torch.var", "torch.var", "torch.var"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_instance_moments", "(", "x", ")", ":", "\n", "        ", "\"\"\"\n        Compute instance mean and variance.\n        :param x: input activations\n        :return: instance mean, instance variance\n        \"\"\"", "\n", "return", "torch", ".", "mean", "(", "x", ",", "dim", "=", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", ",", "torch", ".", "var", "(", "x", ",", "dim", "=", "(", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.NormalizationLayer._compute_layer_moments": [[58, 66], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.var", "torch.var", "torch.var", "torch.var"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_layer_moments", "(", "x", ")", ":", "\n", "        ", "\"\"\"\n        Compute layer mean and variance.\n        :param x: input activations\n        :return: layer mean, layer variance\n        \"\"\"", "\n", "return", "torch", ".", "mean", "(", "x", ",", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", ",", "torch", ".", "var", "(", "x", ",", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.NormalizationLayer._compute_pooled_moments": [[67, 85], ["augment_moment_fn"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_pooled_moments", "(", "x", ",", "alpha", ",", "batch_mean", ",", "batch_var", ",", "augment_moment_fn", ")", ":", "\n", "        ", "\"\"\"\n        Combine batch moments with augment moments using blend factor alpha.\n        :param x: input activations\n        :param alpha: moment blend factor\n        :param batch_mean: standard batch mean\n        :param batch_var: standard batch variance\n        :param augment_moment_fn: function to compute augment moments\n        :return: pooled mean, pooled variance\n        \"\"\"", "\n", "augment_mean", ",", "augment_var", "=", "augment_moment_fn", "(", "x", ")", "\n", "pooled_mean", "=", "alpha", "*", "batch_mean", "+", "(", "1.0", "-", "alpha", ")", "*", "augment_mean", "\n", "batch_mean_diff", "=", "batch_mean", "-", "pooled_mean", "\n", "augment_mean_diff", "=", "augment_mean", "-", "pooled_mean", "\n", "pooled_var", "=", "alpha", "*", "(", "batch_var", "+", "(", "batch_mean_diff", "*", "batch_mean_diff", ")", ")", "+", "(", "1.0", "-", "alpha", ")", "*", "(", "augment_var", "+", "(", "augment_mean_diff", "*", "augment_mean_diff", ")", ")", "\n", "return", "pooled_mean", ",", "pooled_var", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.TaskNormBase.__init__": [[89, 96], ["normalization_layers.NormalizationLayer.__init__", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__"], ["def", "__init__", "(", "self", ",", "num_features", ")", ":", "\n", "        ", "\"\"\"\n        Initialize\n        :param num_features: number of channels in the 2D convolutional layer\n        \"\"\"", "\n", "super", "(", "TaskNormBase", ",", "self", ")", ".", "__init__", "(", "num_features", ")", "\n", "self", ".", "sigmoid", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.TaskNormBase.register_extra_weights": [[97, 121], ["torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "normalization_layers.TaskNormBase.register_parameter", "normalization_layers.TaskNormBase.register_parameter", "normalization_layers.TaskNormBase.register_buffer", "normalization_layers.TaskNormBase.register_buffer", "normalization_layers.TaskNormBase.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "register_extra_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The parameters here get registered after initialization because the pre-trained resnet model does not have\n        these parameters and would fail to load if these were declared at initialization.\n        :return: Nothing\n        \"\"\"", "\n", "device", "=", "self", ".", "weight", ".", "device", "\n", "\n", "# Initialize and register the learned parameters 'a' (SCALE) and 'b' (OFFSET)", "\n", "# for calculating alpha as a function of context size.", "\n", "a", "=", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", ".", "to", "(", "device", ")", "\n", "b", "=", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "register_parameter", "(", "name", "=", "'a'", ",", "param", "=", "torch", ".", "nn", ".", "Parameter", "(", "a", ",", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "register_parameter", "(", "name", "=", "'b'", ",", "param", "=", "torch", ".", "nn", ".", "Parameter", "(", "b", ",", "requires_grad", "=", "True", ")", ")", "\n", "\n", "# Variables to store the context moments to use for normalizing the target.", "\n", "self", ".", "register_buffer", "(", "name", "=", "'batch_mean'", ",", "\n", "tensor", "=", "torch", ".", "zeros", "(", "(", "1", ",", "self", ".", "num_features", ",", "1", ",", "1", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", ")", "\n", "self", ".", "register_buffer", "(", "name", "=", "'batch_var'", ",", "\n", "tensor", "=", "torch", ".", "ones", "(", "(", "1", ",", "self", ".", "num_features", ",", "1", ",", "1", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", ")", "\n", "\n", "# Variable to save the context size.", "\n", "self", ".", "register_buffer", "(", "name", "=", "'context_size'", ",", "\n", "tensor", "=", "torch", ".", "zeros", "(", "(", "1", ")", ",", "requires_grad", "=", "False", ",", "device", "=", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.TaskNormBase._get_augment_moment_fn": [[122, 128], ["None"], "methods", ["None"], ["", "def", "_get_augment_moment_fn", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Provides the function to compute augment moemnts.\n        :return: function to compute augment moments.\n        \"\"\"", "\n", "pass", "# always override this function", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.TaskNormBase.forward": [[129, 150], ["normalization_layers.TaskNormBase._normalize", "normalization_layers.TaskNormBase.sigmoid", "normalization_layers.TaskNormBase._compute_batch_moments", "normalization_layers.TaskNormBase._compute_pooled_moments", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "normalization_layers.TaskNormBase.sigmoid", "normalization_layers.TaskNormBase._compute_pooled_moments", "normalization_layers.TaskNormBase._get_augment_moment_fn", "normalization_layers.TaskNormBase._get_augment_moment_fn", "x.size", "x.size"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.NormalizationLayer._normalize", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.NormalizationLayer._compute_batch_moments", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.NormalizationLayer._compute_pooled_moments", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.NormalizationLayer._compute_pooled_moments", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.TaskNormI._get_augment_moment_fn", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.TaskNormI._get_augment_moment_fn"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Normalize activations.\n        :param x: input activations\n        :return: normalized activations\n        \"\"\"", "\n", "if", "self", ".", "training", ":", "# compute the pooled moments for the context and save off the moments and context size", "\n", "            ", "alpha", "=", "self", ".", "sigmoid", "(", "self", ".", "a", "*", "(", "x", ".", "size", "(", ")", ")", "[", "0", "]", "+", "self", ".", "b", ")", "# compute alpha with context size", "\n", "batch_mean", ",", "batch_var", "=", "self", ".", "_compute_batch_moments", "(", "x", ")", "\n", "pooled_mean", ",", "pooled_var", "=", "self", ".", "_compute_pooled_moments", "(", "x", ",", "alpha", ",", "batch_mean", ",", "batch_var", ",", "\n", "self", ".", "_get_augment_moment_fn", "(", ")", ")", "\n", "self", ".", "context_batch_mean", "=", "batch_mean", "\n", "self", ".", "context_batch_var", "=", "batch_var", "\n", "self", ".", "context_size", "=", "torch", ".", "full_like", "(", "self", ".", "context_size", ",", "x", ".", "size", "(", ")", "[", "0", "]", ")", "\n", "", "else", ":", "# compute the pooled moments for the target", "\n", "            ", "alpha", "=", "self", ".", "sigmoid", "(", "self", ".", "a", "*", "self", ".", "context_size", "+", "self", ".", "b", ")", "# compute alpha with saved context size", "\n", "pooled_mean", ",", "pooled_var", "=", "self", ".", "_compute_pooled_moments", "(", "x", ",", "alpha", ",", "self", ".", "context_batch_mean", ",", "\n", "self", ".", "context_batch_var", ",", "\n", "self", ".", "_get_augment_moment_fn", "(", ")", ")", "\n", "\n", "", "return", "self", ".", "_normalize", "(", "x", ",", "pooled_mean", ",", "pooled_var", ")", "# normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.TaskNormI.__init__": [[156, 162], ["normalization_layers.TaskNormBase.__init__"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__"], ["def", "__init__", "(", "self", ",", "num_features", ")", ":", "\n", "        ", "\"\"\"\n        Initialize\n        :param num_features: number of channels in the 2D convolutional layer\n        \"\"\"", "\n", "super", "(", "TaskNormI", ",", "self", ")", ".", "__init__", "(", "num_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.normalization_layers.TaskNormI._get_augment_moment_fn": [[163, 169], ["None"], "methods", ["None"], ["", "def", "_get_augment_moment_fn", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Override the base class to get the function to compute instance moments.\n        :return: function to compute instance moments\n        \"\"\"", "\n", "return", "self", ".", "_compute_instance_moments", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.__init__": [[17, 23], ["len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "validation_datasets", ")", ":", "\n", "        ", "self", ".", "datasets", "=", "validation_datasets", "\n", "self", ".", "dataset_count", "=", "len", "(", "self", ".", "datasets", ")", "\n", "self", ".", "current_best_accuracy_dict", "=", "{", "}", "\n", "for", "dataset", "in", "self", ".", "datasets", ":", "\n", "            ", "self", ".", "current_best_accuracy_dict", "[", "dataset", "]", "=", "{", "\"accuracy\"", ":", "0.0", ",", "\"confidence\"", ":", "0.0", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.is_better": [[24, 35], ["enumerate", "int", "math.ceil"], "methods", ["None"], ["", "", "def", "is_better", "(", "self", ",", "accuracies_dict", ")", ":", "\n", "        ", "is_better", "=", "False", "\n", "is_better_count", "=", "0", "\n", "for", "i", ",", "dataset", "in", "enumerate", "(", "self", ".", "datasets", ")", ":", "\n", "            ", "if", "accuracies_dict", "[", "dataset", "]", "[", "\"accuracy\"", "]", ">", "self", ".", "current_best_accuracy_dict", "[", "dataset", "]", "[", "\"accuracy\"", "]", ":", "\n", "                ", "is_better_count", "+=", "1", "\n", "\n", "", "", "if", "is_better_count", ">=", "int", "(", "math", ".", "ceil", "(", "self", ".", "dataset_count", "/", "2.0", ")", ")", ":", "\n", "            ", "is_better", "=", "True", "\n", "\n", "", "return", "is_better", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.replace": [[36, 38], ["None"], "methods", ["None"], ["", "def", "replace", "(", "self", ",", "accuracies_dict", ")", ":", "\n", "        ", "self", ".", "current_best_accuracy_dict", "=", "accuracies_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print": [[39, 46], ["utils.print_and_log", "utils.print_and_log", "utils.print_and_log", "utils.print_and_log"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log"], ["", "def", "print", "(", "self", ",", "logfile", ",", "accuracy_dict", ")", ":", "\n", "        ", "print_and_log", "(", "logfile", ",", "\"\"", ")", "# add a blank line", "\n", "print_and_log", "(", "logfile", ",", "\"Validation Accuracies:\"", ")", "\n", "for", "dataset", "in", "self", ".", "datasets", ":", "\n", "            ", "print_and_log", "(", "logfile", ",", "\"{0:}: {1:.1f}+/-{2:.1f}\"", ".", "format", "(", "dataset", ",", "accuracy_dict", "[", "dataset", "]", "[", "\"accuracy\"", "]", ",", "\n", "accuracy_dict", "[", "dataset", "]", "[", "\"confidence\"", "]", ")", ")", "\n", "", "print_and_log", "(", "logfile", ",", "\"\"", ")", "# add a blank line", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.get_current_best_accuracy_dict": [[47, 49], ["None"], "methods", ["None"], ["", "def", "get_current_best_accuracy_dict", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "current_best_accuracy_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.verify_checkpoint_dir": [[51, 71], ["os.path.join", "os.path.exists", "print", "sys.exit", "os.path.isfile", "print", "sys.exit", "os.path.exists", "os.path.exists", "print", "sys.exit", "print", "print", "print", "sys.exit"], "function", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print"], ["", "", "def", "verify_checkpoint_dir", "(", "checkpoint_dir", ",", "resume", ",", "test_mode", ")", ":", "\n", "    ", "if", "resume", ":", "# verify that the checkpoint directory and file exists", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "            ", "print", "(", "\"Can't resume for checkpoint. Checkpoint directory ({}) does not exist.\"", ".", "format", "(", "checkpoint_dir", ")", ",", "flush", "=", "True", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "checkpoint_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'checkpoint.pt'", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "checkpoint_file", ")", ":", "\n", "            ", "print", "(", "\"Can't resume for checkpoint. Checkpoint file ({}) does not exist.\"", ".", "format", "(", "checkpoint_file", ")", ",", "flush", "=", "True", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "elif", "test_mode", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "            ", "print", "(", "\"Can't test. Checkpoint directory ({}) does not exist.\"", ".", "format", "(", "checkpoint_dir", ")", ",", "flush", "=", "True", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "checkpoint_dir", ")", ":", "\n", "            ", "print", "(", "\"Checkpoint directory ({}) already exits.\"", ".", "format", "(", "checkpoint_dir", ")", ",", "flush", "=", "True", ")", "\n", "print", "(", "\"If starting a new training run, specify a directory that does not already exist.\"", ",", "flush", "=", "True", ")", "\n", "print", "(", "\"If you want to resume a training run, specify the -r option on the command line.\"", ",", "flush", "=", "True", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.print_and_log": [[73, 79], ["print", "log_file.write"], "function", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.ValidationAccuracies.print"], ["", "", "", "def", "print_and_log", "(", "log_file", ",", "message", ")", ":", "\n", "    ", "\"\"\"\n    Helper function to print to the screen and the cnaps_layer_log.txt file.\n    \"\"\"", "\n", "print", "(", "message", ",", "flush", "=", "True", ")", "\n", "log_file", ".", "write", "(", "message", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.get_log_files": [[81, 98], ["utils.verify_checkpoint_dir", "os.path.join", "os.path.join", "os.path.join", "os.path.isfile", "os.makedirs", "open", "open"], "function", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.verify_checkpoint_dir"], ["", "def", "get_log_files", "(", "checkpoint_dir", ",", "resume", ",", "test_mode", ")", ":", "\n", "    ", "\"\"\"\n    Function that takes a path to a checkpoint directory and returns a reference to a logfile and paths to the\n    fully trained model and the model with the best validation score.\n    \"\"\"", "\n", "verify_checkpoint_dir", "(", "checkpoint_dir", ",", "resume", ",", "test_mode", ")", "\n", "if", "not", "test_mode", "and", "not", "resume", ":", "\n", "        ", "os", ".", "makedirs", "(", "checkpoint_dir", ")", "\n", "", "checkpoint_path_validation", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'best_validation.pt'", ")", "\n", "checkpoint_path_final", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'fully_trained.pt'", ")", "\n", "logfile_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'log.txt'", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "logfile_path", ")", ":", "\n", "        ", "logfile", "=", "open", "(", "logfile_path", ",", "\"a\"", ",", "buffering", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "logfile", "=", "open", "(", "logfile_path", ",", "\"w\"", ",", "buffering", "=", "1", ")", "\n", "\n", "", "return", "checkpoint_dir", ",", "logfile", ",", "checkpoint_path_validation", ",", "checkpoint_path_final", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.stack_first_dim": [[100, 109], ["x.size", "x.view", "len"], "function", ["None"], ["", "def", "stack_first_dim", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    Method to combine the first two dimension of an array\n    \"\"\"", "\n", "x_shape", "=", "x", ".", "size", "(", ")", "\n", "new_shape", "=", "[", "x_shape", "[", "0", "]", "*", "x_shape", "[", "1", "]", "]", "\n", "if", "len", "(", "x_shape", ")", ">", "2", ":", "\n", "        ", "new_shape", "+=", "x_shape", "[", "2", ":", "]", "\n", "", "return", "x", ".", "view", "(", "new_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.split_first_dim_linear": [[111, 120], ["x.size", "x.view", "len"], "function", ["None"], ["", "def", "split_first_dim_linear", "(", "x", ",", "first_two_dims", ")", ":", "\n", "    ", "\"\"\"\n    Undo the stacking operation\n    \"\"\"", "\n", "x_shape", "=", "x", ".", "size", "(", ")", "\n", "new_shape", "=", "first_two_dims", "\n", "if", "len", "(", "x_shape", ")", ">", "1", ":", "\n", "        ", "new_shape", "+=", "[", "x_shape", "[", "-", "1", "]", "]", "\n", "", "return", "x", ".", "view", "(", "new_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.sample_normal": [[122, 133], ["torch.distributions.Normal", "torch.distributions.Normal", "torch.distributions.Normal.rsample", "mean.repeat", "var.repeat", "len", "mean.size"], "function", ["None"], ["", "def", "sample_normal", "(", "mean", ",", "var", ",", "num_samples", ")", ":", "\n", "    ", "\"\"\"\n    Generate samples from a reparameterized normal distribution\n    :param mean: tensor - mean parameter of the distribution\n    :param var: tensor - variance of the distribution\n    :param num_samples: np scalar - number of samples to generate\n    :return: tensor - samples from distribution of size numSamples x dim(mean)\n    \"\"\"", "\n", "sample_shape", "=", "[", "num_samples", "]", "+", "len", "(", "mean", ".", "size", "(", ")", ")", "*", "[", "1", "]", "\n", "normal_distribution", "=", "torch", ".", "distributions", ".", "Normal", "(", "mean", ".", "repeat", "(", "sample_shape", ")", ",", "var", ".", "repeat", "(", "sample_shape", ")", ")", "\n", "return", "normal_distribution", ".", "rsample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.loss": [[135, 148], ["test_logits_sample.size", "torch.tensor", "torch.tensor", "torch.empty", "torch.empty", "range", "torch.logsumexp", "torch.logsumexp", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.cross_entropy"], "function", ["None"], ["", "def", "loss", "(", "test_logits_sample", ",", "test_labels", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    Compute the classification loss.\n    \"\"\"", "\n", "size", "=", "test_logits_sample", ".", "size", "(", ")", "\n", "sample_count", "=", "size", "[", "0", "]", "# scalar for the loop counter", "\n", "num_samples", "=", "torch", ".", "tensor", "(", "[", "sample_count", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ",", "requires_grad", "=", "False", ")", "\n", "\n", "log_py", "=", "torch", ".", "empty", "(", "size", "=", "(", "size", "[", "0", "]", ",", "size", "[", "1", "]", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "for", "sample", "in", "range", "(", "sample_count", ")", ":", "\n", "        ", "log_py", "[", "sample", "]", "=", "-", "F", ".", "cross_entropy", "(", "test_logits_sample", "[", "sample", "]", ",", "test_labels", ",", "reduction", "=", "'none'", ")", "\n", "", "score", "=", "torch", ".", "logsumexp", "(", "log_py", ",", "dim", "=", "0", ")", "-", "torch", ".", "log", "(", "num_samples", ")", "\n", "return", "-", "torch", ".", "sum", "(", "score", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.aggregate_accuracy": [[150, 156], ["torch.logsumexp", "torch.logsumexp", "torch.mean", "torch.mean", "torch.eq().float", "torch.eq().float", "torch.eq", "torch.eq", "torch.argmax", "torch.argmax"], "function", ["None"], ["", "def", "aggregate_accuracy", "(", "test_logits_sample", ",", "test_labels", ")", ":", "\n", "    ", "\"\"\"\n    Compute classification accuracy.\n    \"\"\"", "\n", "averaged_predictions", "=", "torch", ".", "logsumexp", "(", "test_logits_sample", ",", "dim", "=", "0", ")", "\n", "return", "torch", ".", "mean", "(", "torch", ".", "eq", "(", "test_labels", ",", "torch", ".", "argmax", "(", "averaged_predictions", ",", "dim", "=", "-", "1", ")", ")", ".", "float", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.utils.linear_classifier": [[158, 163], ["torch.linear"], "function", ["None"], ["", "def", "linear_classifier", "(", "x", ",", "param_dict", ")", ":", "\n", "    ", "\"\"\"\n    Classifier.\n    \"\"\"", "\n", "return", "F", ".", "linear", "(", "x", ",", "param_dict", "[", "'weight_mean'", "]", ",", "param_dict", "[", "'bias_mean'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SetEncoder.__init__": [[20, 24], ["torch.Module.__init__", "set_encoder.SimplePrePoolNet"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__"], ["def", "__init__", "(", "self", ",", "batch_normalization", ")", ":", "\n", "        ", "super", "(", "SetEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pre_pooling_fn", "=", "SimplePrePoolNet", "(", "batch_normalization", ")", "\n", "self", ".", "pooling_fn", "=", "mean_pooling", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SetEncoder.forward": [[25, 39], ["set_encoder.SetEncoder.pre_pooling_fn", "set_encoder.SetEncoder.pooling_fn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass through DeepSet SetEncoder. Implements the following computation:\n\n                g(X) = rho ( mean ( phi(x) ) )\n                Where X = (x0, ... xN) is a set of elements x in X (in our case, images from a context set)\n                and the mean is a pooling operation over elements in the set.\n\n        :param x: (torch.tensor) Set of elements X (e.g., for images has shape batch x C x H x W ).\n        :return: (torch.tensor) Representation of the set, single vector in Rk.\n        \"\"\"", "\n", "x", "=", "self", ".", "pre_pooling_fn", "(", "x", ")", "\n", "x", "=", "self", ".", "pooling_fn", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__": [[46, 61], ["torch.Module.__init__", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "set_encoder.SimplePrePoolNet._make_conv2d_layer_task_norm", "set_encoder.SimplePrePoolNet._make_conv2d_layer_task_norm", "set_encoder.SimplePrePoolNet._make_conv2d_layer_task_norm", "set_encoder.SimplePrePoolNet._make_conv2d_layer_task_norm", "set_encoder.SimplePrePoolNet._make_conv2d_layer_task_norm", "set_encoder.SimplePrePoolNet._make_conv2d_layer", "set_encoder.SimplePrePoolNet._make_conv2d_layer", "set_encoder.SimplePrePoolNet._make_conv2d_layer", "set_encoder.SimplePrePoolNet._make_conv2d_layer", "set_encoder.SimplePrePoolNet._make_conv2d_layer"], "methods", ["home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.__init__", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer_task_norm", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer_task_norm", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer_task_norm", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer_task_norm", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer_task_norm", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer", "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer"], ["def", "__init__", "(", "self", ",", "batch_normalization", ")", ":", "\n", "        ", "super", "(", "SimplePrePoolNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "batch_normalization", "==", "\"task_norm-i\"", ":", "\n", "            ", "self", ".", "layer1", "=", "self", ".", "_make_conv2d_layer_task_norm", "(", "3", ",", "64", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_conv2d_layer_task_norm", "(", "64", ",", "64", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_conv2d_layer_task_norm", "(", "64", ",", "64", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_conv2d_layer_task_norm", "(", "64", ",", "64", ")", "\n", "self", ".", "layer5", "=", "self", ".", "_make_conv2d_layer_task_norm", "(", "64", ",", "64", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer1", "=", "self", ".", "_make_conv2d_layer", "(", "3", ",", "64", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_conv2d_layer", "(", "64", ",", "64", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_conv2d_layer", "(", "64", ",", "64", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_conv2d_layer", "(", "64", ",", "64", ")", "\n", "self", ".", "layer5", "=", "self", ".", "_make_conv2d_layer", "(", "64", ",", "64", ")", "\n", "", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer": [[62, 69], ["torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_conv2d_layer", "(", "in_maps", ",", "out_maps", ")", ":", "\n", "        ", "return", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_maps", ",", "out_maps", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_maps", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "ceil_mode", "=", "False", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet._make_conv2d_layer_task_norm": [[71, 78], ["torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "normalization_layers.TaskNormI", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_conv2d_layer_task_norm", "(", "in_maps", ",", "out_maps", ")", ":", "\n", "        ", "return", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_maps", ",", "out_maps", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ",", "\n", "TaskNormI", "(", "out_maps", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "ceil_mode", "=", "False", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.forward": [[80, 89], ["set_encoder.SimplePrePoolNet.layer1", "set_encoder.SimplePrePoolNet.layer2", "set_encoder.SimplePrePoolNet.layer3", "set_encoder.SimplePrePoolNet.layer4", "set_encoder.SimplePrePoolNet.layer5", "set_encoder.SimplePrePoolNet.avgpool", "x.view.view.view", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "x", "=", "self", ".", "layer5", "(", "x", ")", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.SimplePrePoolNet.output_size": [[90, 93], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "64", "\n", "", "", ""]], "home.repos.pwc.inspect_result.cambridge-mlg_cnaps.src.set_encoder.mean_pooling": [[11, 13], ["torch.mean", "torch.mean"], "function", ["None"], ["def", "mean_pooling", "(", "x", ")", ":", "\n", "    ", "return", "torch", ".", "mean", "(", "x", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "\n"]]}