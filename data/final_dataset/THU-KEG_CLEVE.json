{"home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.InputExample.__init__": [[28, 44], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "example_id", ",", "tokens", ",", "triggerL", ",", "triggerR", ",", "label", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            example_id: Unique id for the example.\n            contexts: list of str. The untokenized text of the first sequence (context of corresponding question).\n            question: string. The untokenized text of the second sequence (question).\n            endings: list of str. multiple choice's options. Its length must be equal to contexts' length.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "triggerL", "=", "triggerL", "\n", "self", ".", "triggerR", "=", "triggerR", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.InputContrastExample.__init__": [[46, 58], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "example_id", ",", "tokens", ",", "triggerL", ",", "triggerR", ",", "argL", ",", "argR", ",", "neg_meta_t", ",", "neg_meta_a_t", ",", "neg_meta_a_a", ")", ":", "\n", "        ", "\"\"\"Constructs a Input Contrast Example.\n        \"\"\"", "\n", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "triggerL", "=", "triggerL", "\n", "self", ".", "triggerR", "=", "triggerR", "\n", "self", ".", "argL", "=", "argL", "\n", "self", ".", "argR", "=", "argR", "\n", "self", ".", "neg_meta_t", "=", "neg_meta_t", "\n", "self", ".", "neg_meta_a_t", "=", "neg_meta_a_t", "\n", "self", ".", "neg_meta_a_a", "=", "neg_meta_a_a", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.InputContrastFeatures.__init__": [[60, 72], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "example_id", ",", "\n", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "trigger_mask", ",", "arg_mask", ",", "none_arg_mask", ",", "none_arg_length_mask", ",", "lm_masked_labels", ")", ":", "\n", "        ", "self", ".", "example_id", "=", "example_id", "\n", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "trigger_mask", "=", "trigger_mask", "\n", "self", ".", "arg_mask", "=", "arg_mask", "\n", "self", ".", "none_arg_mask", "=", "none_arg_mask", "\n", "self", ".", "none_arg_length_mask", "=", "none_arg_length_mask", "\n", "self", ".", "lm_masked_labels", "=", "lm_masked_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.InputFeatures.__init__": [[78, 86], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "example_id", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "maskL", ",", "maskR", ",", "label", ")", ":", "\n", "        ", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "maskL", "=", "maskL", "\n", "self", ".", "maskR", "=", "maskR", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.DataProcessor.get_train_examples": [[91, 94], ["NotImplementedError"], "methods", ["None"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.DataProcessor.get_dev_examples": [[95, 98], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.DataProcessor.get_test_examples": [[99, 102], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.DataProcessor.get_labels": [[103, 106], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.DataProcessor.get_MI_examples": [[107, 109], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_MI_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.DataProcessor._create_examples": [[110, 112], ["NotImplementedError"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.ACEProcessor.get_train_examples": [[117, 122], ["logger.info", "json.load", "utils_ee.ACEProcessor._create_examples", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} train\"", ".", "format", "(", "data_dir", ")", ")", "\n", "self", ".", "train", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train.json'", ")", ",", "\"r\"", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "train", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.ACEProcessor.get_dev_examples": [[123, 127], ["logger.info", "utils_ee.ACEProcessor._create_examples", "json.load", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'dev.json'", ")", ",", "\"r\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.ACEProcessor.get_test_examples": [[128, 132], ["logger.info", "utils_ee.ACEProcessor._create_examples", "json.load", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} test\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'test.json'", ")", ",", "\"r\"", ")", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.ACEProcessor.get_contrast_examples": [[133, 138], ["logger.info", "pickle.load", "utils_ee.ACEProcessor.get_contrast_meta", "utils_ee.ACEProcessor._create_contrast_examples", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.ACEProcessor.get_contrast_meta", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.ACEProcessor._create_contrast_examples"], ["", "def", "get_contrast_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"LOOKING AT {} train contrast\"", ".", "format", "(", "data_dir", ")", ")", "\n", "lines", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'contrast_examples.pkl'", ")", ",", "\"rb\"", ")", ")", "\n", "pos_meta", ",", "neg_meta", "=", "self", ".", "get_contrast_meta", "(", "lines", ")", "\n", "return", "self", ".", "_create_contrast_examples", "(", "lines", ",", "pos_meta", ",", "neg_meta", ",", "\"train-contrast\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.ACEProcessor.get_labels": [[139, 142], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "'None'", ",", "'End-Position'", ",", "'Charge-Indict'", ",", "'Convict'", ",", "'Transfer-Ownership'", ",", "'Demonstrate'", ",", "'Transport'", ",", "'Sentence'", ",", "'Appeal'", ",", "'Start-Org'", ",", "'Start-Position'", ",", "'End-Org'", ",", "'Phone-Write'", ",", "'Nominate'", ",", "'Marry'", ",", "'Pardon'", ",", "'Release-Parole'", ",", "'Meet'", ",", "'Trial-Hearing'", ",", "'Extradite'", ",", "'Execute'", ",", "'Transfer-Money'", ",", "'Elect'", ",", "'Injure'", ",", "'Acquit'", ",", "'Divorce'", ",", "'Die'", ",", "'Arrest-Jail'", ",", "'Declare-Bankruptcy'", ",", "'Be-Born'", ",", "'Merge-Org'", ",", "'Fine'", ",", "'Sue'", ",", "'Attack'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.ACEProcessor.get_contrast_meta": [[180, 215], ["enumerate", "example[].keys", "[].extend", "[].extend", "[].extend", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "[].append", "[].append"], "methods", ["None"], ["", "def", "get_contrast_meta", "(", "self", ",", "lines", ")", ":", "\n", "        ", "\"\"\"\n        Get meta data for contrastive learning\n        \n        \"\"\"", "\n", "positive_meta", "=", "{", "}", "\n", "negative_meta", "=", "{", "}", "\n", "# trigger_meta = defaultdict(list)", "\n", "# line_idx = {}", "\n", "for", "example_idx", ",", "example", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "metainfo", "=", "example_idx", "\n", "if", "metainfo", "not", "in", "positive_meta", ":", "\n", "\n", "                ", "positive_meta", "[", "metainfo", "]", "=", "[", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", "]", "\n", "negative_meta", "[", "metainfo", "]", "=", "[", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", ",", "[", "]", "]", "\n", "\n", "", "for", "node", "in", "example", "[", "'positive_edges'", "]", ".", "keys", "(", ")", ":", "\n", "                ", "trigger_idx", "=", "(", "node", "[", "0", "]", ",", "node", "[", "1", "]", "-", "1", ")", "#TODO: this part can be cleaner", "\n", "entities", "=", "example", "[", "'positive_edges'", "]", "[", "node", "]", "+", "example", "[", "'negative_edges'", "]", "[", "node", "]", "\n", "entities", "=", "[", "(", "e", "[", "0", "]", ",", "e", "[", "1", "]", "-", "1", ")", "for", "e", "in", "entities", "]", "\n", "role_idxs", "=", "[", "(", "e", "[", "0", "]", ",", "e", "[", "1", "]", "-", "1", ")", "for", "e", "in", "example", "[", "'positive_edges'", "]", "[", "node", "]", "]", "\n", "none_role_idxs", "=", "[", "(", "e", "[", "0", "]", ",", "e", "[", "1", "]", "-", "1", ")", "for", "e", "in", "example", "[", "'negative_edges'", "]", "[", "node", "]", "]", "\n", "\n", "assert", "trigger_idx", "not", "in", "positive_meta", "[", "metainfo", "]", "[", "0", "]", "\n", "assert", "trigger_idx", "not", "in", "negative_meta", "[", "metainfo", "]", "[", "0", "]", "\n", "positive_meta", "[", "metainfo", "]", "[", "0", "]", "[", "trigger_idx", "]", ".", "extend", "(", "role_idxs", ")", "\n", "negative_meta", "[", "metainfo", "]", "[", "0", "]", "[", "trigger_idx", "]", ".", "extend", "(", "none_role_idxs", ")", "\n", "for", "role_idx", "in", "role_idxs", ":", "\n", "                    ", "positive_meta", "[", "metainfo", "]", "[", "1", "]", "[", "role_idx", "]", ".", "append", "(", "trigger_idx", ")", "\n", "", "for", "none_role_idx", "in", "none_role_idxs", ":", "\n", "                    ", "negative_meta", "[", "metainfo", "]", "[", "1", "]", "[", "none_role_idx", "]", ".", "append", "(", "trigger_idx", ")", "\n", "", "negative_meta", "[", "metainfo", "]", "[", "2", "]", ".", "extend", "(", "role_idxs", "+", "none_role_idxs", ")", "\n", "\n", "", "", "return", "positive_meta", ",", "negative_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.ACEProcessor._create_contrast_examples": [[243, 269], ["enumerate", "enumerate", "list", "enumerate", "data_raw[].keys", "examples.append", "utils_ee.InputContrastExample"], "methods", ["None"], ["", "def", "_create_contrast_examples", "(", "self", ",", "lines", ",", "pos_meta", ",", "neg_meta", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"\n        Create examples for contrastive training\n        \"\"\"", "\n", "\n", "examples", "=", "[", "]", "\n", "for", "(", "idx", ",", "data_raw", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "metainfo", "=", "idx", "\n", "for", "idx_t", ",", "t", "in", "enumerate", "(", "list", "(", "data_raw", "[", "'positive_edges'", "]", ".", "keys", "(", ")", ")", ")", ":", "\n", "                ", "for", "idx2", ",", "entity", "in", "enumerate", "(", "data_raw", "[", "'positive_edges'", "]", "[", "t", "]", ")", ":", "\n", "                    ", "e_id", "=", "\"%s-%s-%s-%s\"", "%", "(", "set_type", ",", "idx", ",", "idx_t", ",", "idx2", ")", "\n", "examples", ".", "append", "(", "\n", "InputContrastExample", "(", "\n", "example_id", "=", "e_id", ",", "\n", "tokens", "=", "data_raw", "[", "'tokens'", "]", ",", "\n", "triggerL", "=", "t", "[", "0", "]", ",", "\n", "triggerR", "=", "t", "[", "1", "]", "-", "1", ",", "\n", "argL", "=", "entity", "[", "0", "]", ",", "\n", "argR", "=", "entity", "[", "1", "]", "-", "1", ",", "\n", "neg_meta_t", "=", "neg_meta", "[", "metainfo", "]", "[", "0", "]", "[", "(", "t", "[", "0", "]", ",", "t", "[", "1", "]", "-", "1", ")", "]", ",", "\n", "neg_meta_a_t", "=", "neg_meta", "[", "metainfo", "]", "[", "1", "]", "[", "(", "entity", "[", "0", "]", ",", "entity", "[", "1", "]", "-", "1", ")", "]", ",", "\n", "neg_meta_a_a", "=", "[", "e", "for", "e", "in", "neg_meta", "[", "metainfo", "]", "[", "2", "]", "]", "\n", ")", "\n", ")", "\n", "", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.ACEProcessor._create_examples": [[271, 286], ["enumerate", "examples.append", "utils_ee.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "idx", ",", "data_raw", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "e_id", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "idx", ")", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "\n", "example_id", "=", "e_id", ",", "\n", "tokens", "=", "data_raw", "[", "'tokens'", "]", ",", "\n", "triggerL", "=", "data_raw", "[", "'trigger_start'", "]", ",", "\n", "triggerR", "=", "data_raw", "[", "'trigger_end'", "]", "+", "1", ",", "\n", "label", "=", "data_raw", "[", "'event_type'", "]", ",", "\n", ")", "\n", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.MAVENProcessor.get_train_examples": [[290, 294], ["logger.info", "utils_ee.MAVENProcessor._create_examples", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor._create_examples"], ["def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} train\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train.jsonl'", ")", ",", "\"r\"", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.MAVENProcessor.get_dev_examples": [[295, 299], ["logger.info", "utils_ee.MAVENProcessor._create_examples", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'valid.jsonl'", ")", ",", "\"r\"", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.MAVENProcessor.get_test_examples": [[300, 304], ["logger.info", "utils_ee.MAVENProcessor._create_examples", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} test\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'test.jsonl'", ")", ",", "\"r\"", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.MAVENProcessor.get_labels": [[305, 308], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "'None'", ",", "'Change_tool'", ",", "'Becoming'", ",", "'Using'", ",", "'Change_of_leadership'", ",", "'Come_together'", ",", "'Justifying'", ",", "'Name_conferral'", ",", "'Collaboration'", ",", "'Filling'", ",", "'Prison'", ",", "'Giving'", ",", "'Cause_change_of_position_on_a_scale'", ",", "'Limiting'", ",", "'Bringing'", ",", "'Conquering'", ",", "'Forming_relationships'", ",", "'Self_motion'", ",", "'Commitment'", ",", "'Achieve'", ",", "'Attack'", ",", "'Create_artwork'", ",", "'Employment'", ",", "'Motion'", ",", "'Testing'", ",", "'Traveling'", ",", "'Preventing_or_letting'", ",", "'GiveUp'", ",", "'Response'", ",", "'Manufacturing'", ",", "'Commerce_sell'", ",", "'Check'", ",", "'Getting'", ",", "'Imposing_obligation'", ",", "'Earnings_and_losses'", ",", "'Assistance'", ",", "'Surrounding'", ",", "'Resolve_problem'", ",", "'Escaping'", ",", "'Ratification'", ",", "'Presence'", ",", "'Warning'", ",", "'Exchange'", ",", "'Renting'", ",", "'Suspicion'", ",", "'Agree_or_refuse_to_act'", ",", "'Expansion'", ",", "'Openness'", ",", "'Having_or_lacking_access'", ",", "'Recovering'", ",", "'Reveal_secret'", ",", "'Perception_active'", ",", "'Committing_crime'", ",", "'Aiming'", ",", "'Wearing'", ",", "'Creating'", ",", "'Writing'", ",", "'Hold'", ",", "'Education_teaching'", ",", "'Incident'", ",", "'Quarreling'", ",", "'Supply'", ",", "'Change'", ",", "'Telling'", ",", "'Hindering'", ",", "'Rewards_and_punishments'", ",", "'Protest'", ",", "'Know'", ",", "'Extradition'", ",", "'Departing'", ",", "'Sign_agreement'", ",", "'Adducing'", ",", "'Control'", ",", "'Body_movement'", ",", "'Releasing'", ",", "'Hiding_objects'", ",", "'Kidnapping'", ",", "'Carry_goods'", ",", "'Participation'", ",", "'Arrest'", ",", "'Sending'", ",", "'Reporting'", ",", "'Theft'", ",", "'Change_sentiment'", ",", "'Convincing'", ",", "'Preserving'", ",", "'Causation'", ",", "'Breathing'", ",", "'Vocalizations'", ",", "'Criminal_investigation'", ",", "'Influence'", ",", "'Bearing_arms'", ",", "'Practice'", ",", "'Violence'", ",", "'Deciding'", ",", "'Being_in_operation'", ",", "'Rescuing'", ",", "'Temporary_stay'", ",", "'Reforming_a_system'", ",", "'Catastrophe'", ",", "'Besieging'", ",", "'Arranging'", ",", "'Risk'", ",", "'Cause_to_be_included'", ",", "'Legal_rulings'", ",", "'Confronting_problem'", ",", "'Communication'", ",", "'Process_start'", ",", "'Cure'", ",", "'Dispersal'", ",", "'Cause_to_amalgamate'", ",", "'Institutionalization'", ",", "'Competition'", ",", "'Killing'", ",", "'Submitting_documents'", ",", "'Supporting'", ",", "'Death'", ",", "'Surrendering'", ",", "'Recording'", ",", "'Revenge'", ",", "'Change_event_time'", ",", "'Connect'", ",", "'Use_firearm'", ",", "'Coming_to_be'", ",", "'Cause_change_of_strength'", ",", "'Ingestion'", ",", "'Legality'", ",", "'Research'", ",", "'Action'", ",", "'Award'", ",", "'Defending'", ",", "'Scrutiny'", ",", "'Placing'", ",", "'Rite'", ",", "'Request'", ",", "'Terrorism'", ",", "'Process_end'", ",", "'Becoming_a_member'", ",", "'Expend_resource'", ",", "'Commerce_pay'", ",", "'Cost'", ",", "'Bodily_harm'", ",", "'Hostile_encounter'", ",", "'GetReady'", ",", "'Judgment_communication'", ",", "'Containing'", ",", "'Robbery'", ",", "'Receiving'", ",", "'Choosing'", ",", "'Lighting'", ",", "'Commerce_buy'", ",", "'Coming_to_believe'", ",", "'Destroying'", ",", "'Emptying'", ",", "'Building'", ",", "'Patrolling'", ",", "'Scouring'", ",", "'Statement'", ",", "'Arriving'", ",", "'Social_event'", ",", "'Cause_to_make_progress'", ",", "'Motion_directional'", ",", "'Emergency'", ",", "'Labeling'", ",", "'Publishing'", ",", "'Expressing_publicly'", ",", "'Military_operation'", ",", "'Removing'", ",", "'Damaging'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.MAVENProcessor._create_examples": [[309, 342], ["fin.readlines", "enumerate", "json.loads", "examples.append", "examples.append", "utils_ee.InputExample", "utils_ee.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "fin", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "lines", "=", "fin", ".", "readlines", "(", ")", "\n", "for", "(", "_", ",", "data_raw", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "data", "=", "json", ".", "loads", "(", "data_raw", ")", "\n", "for", "event", "in", "data", "[", "'events'", "]", ":", "\n", "                ", "if", "event", "[", "'type'", "]", "==", "'None of the above'", ":", "# This should never happen", "\n", "                    ", "continue", "\n", "", "for", "mention", "in", "event", "[", "'mention'", "]", ":", "\n", "                    ", "e_id", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "mention", "[", "'id'", "]", ")", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "\n", "example_id", "=", "e_id", ",", "\n", "tokens", "=", "data", "[", "'content'", "]", "[", "mention", "[", "'sent_id'", "]", "]", "[", "'tokens'", "]", ",", "\n", "triggerL", "=", "mention", "[", "'offset'", "]", "[", "0", "]", ",", "\n", "triggerR", "=", "mention", "[", "'offset'", "]", "[", "1", "]", ",", "\n", "label", "=", "event", "[", "'type'", "]", ",", "\n", ")", "\n", ")", "\n", "", "", "for", "nIns", "in", "data", "[", "'negative_triggers'", "]", ":", "\n", "                ", "e_id", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "nIns", "[", "'id'", "]", ")", "\n", "examples", ".", "append", "(", "\n", "InputExample", "(", "\n", "example_id", "=", "e_id", ",", "\n", "tokens", "=", "data", "[", "'content'", "]", "[", "nIns", "[", "'sent_id'", "]", "]", "[", "'tokens'", "]", ",", "\n", "triggerL", "=", "nIns", "[", "'offset'", "]", "[", "0", "]", ",", "\n", "triggerR", "=", "nIns", "[", "'offset'", "]", "[", "1", "]", ",", "\n", "label", "=", "'None'", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.convert_contrast_examples_to_features": [[344, 451], ["tqdm.tqdm", "sorted", "collections.defaultdict", "enumerate", "res.extend", "enumerate", "list", "ValueError", "list", "utils_ee.convert_contrast_examples_to_features.ins"], "function", ["None"], ["", "", "def", "convert_contrast_examples_to_features", "(", "\n", "examples", ":", "List", "[", "InputContrastExample", "]", ",", "\n", "max_contrast_ent_per_sent", ":", "int", ",", "\n", "max_length", ":", "int", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", ")", "->", "List", "[", "InputContrastFeatures", "]", ":", "\n", "\n", "    ", "\"\"\"\n    Loads a data file into a list of `InputFeatures`\n    \"\"\"", "\n", "\n", "features", "=", "[", "]", "\n", "def", "ins", "(", "tokens", ",", "add", ")", ":", "\n", "        ", "add_split", "=", "[", "(", "e", ",", "e", "[", "0", "]", ")", "for", "e", "in", "add", "]", "+", "[", "(", "e", ",", "e", "[", "1", "]", "+", "1", ")", "for", "e", "in", "add", "]", "\n", "add_split", "=", "sorted", "(", "add_split", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "res", "=", "[", "]", "\n", "add_idxs", "=", "defaultdict", "(", "list", ")", "\n", "for", "idx", ",", "p", "in", "enumerate", "(", "add_split", ")", ":", "\n", "            ", "res", ".", "extend", "(", "tokenizer", ".", "tokenize", "(", "\" \"", ".", "join", "(", "tokens", "[", "(", "add_split", "[", "idx", "-", "1", "]", "[", "1", "]", "if", "idx", ">=", "1", "else", "0", ")", ":", "p", "[", "1", "]", "]", ")", ")", ")", "# TODO:May occur error when two identical posi..", "\n", "add_idxs", "[", "p", "[", "0", "]", "]", ".", "append", "(", "len", "(", "res", ")", "+", "1", ")", "\n", "", "res", ".", "extend", "(", "tokenizer", ".", "tokenize", "(", "\" \"", ".", "join", "(", "tokens", "[", "add_split", "[", "-", "1", "]", "[", "1", "]", ":", "]", ")", ")", ")", "\n", "for", "e", "in", "add_idxs", ":", "\n", "            ", "assert", "len", "(", "add_idxs", "[", "e", "]", ")", "==", "2", "\n", "", "return", "res", ",", "add_idxs", "\n", "\n", "", "for", "(", "ex_index", ",", "example", ")", "in", "tqdm", ".", "tqdm", "(", "enumerate", "(", "examples", ")", ",", "desc", "=", "\"convert contrast examples to features\"", ")", ":", "\n", "        ", "trigger_posi", "=", "(", "example", ".", "triggerL", ",", "example", ".", "triggerR", ")", "\n", "arg_posi", "=", "(", "example", ".", "argL", ",", "example", ".", "argR", ")", "\n", "\n", "if", "trigger_posi", "==", "arg_posi", ":", "\n", "            ", "continue", "\n", "\n", "", "entities", "=", "list", "(", "set", "(", "example", ".", "neg_meta_a_a", ")", ")", "\n", "neg_meta_t", "=", "example", ".", "neg_meta_t", "\n", "\n", "assert", "arg_posi", "in", "entities", ",", "ValueError", "(", "'Contrast processing seems incorrect, please make sure you follow our guide lines and get a correct [nyt_parsed_file]'", ")", "\n", "\n", "\n", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing contrast example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "examples", ")", ")", ")", "\n", "\n", "", "to_rank", "=", "list", "(", "set", "(", "[", "trigger_posi", "]", "+", "entities", ")", ")", "\n", "text", ",", "word_idxs", "=", "ins", "(", "example", ".", "tokens", ",", "to_rank", ")", "\n", "\n", "if", "max", "(", "word_idxs", "[", "trigger_posi", "]", ")", ">", "max_length", "or", "max", "(", "word_idxs", "[", "arg_posi", "]", ")", ">", "max_length", ":", "\n", "            ", "continue", "\n", "\n", "", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "\n", "text", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_length", ",", "return_token_type_ids", "=", "True", "\n", ")", "\n", "\n", "if", "\"num_truncated_tokens\"", "in", "inputs", "and", "inputs", "[", "\"num_truncated_tokens\"", "]", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Attention! you are cropping tokens.\"", "\n", ")", "\n", "\n", "", "input_ids", ",", "token_type_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "lm_masked_labels", "=", "[", "-", "100", "]", "+", "input_ids", "[", "1", ":", "-", "1", "]", "+", "[", "-", "100", "]", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "token_type_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "token_type_ids", "\n", "lm_masked_labels", "=", "(", "[", "-", "100", "]", "*", "padding_length", ")", "+", "lm_masked_labels", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "token_type_ids", "=", "token_type_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "lm_masked_labels", "=", "lm_masked_labels", "+", "(", "[", "-", "100", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_length", ",", "ValueError", "(", "'sentence length is not correct, this should never happened.'", ")", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", ",", "ValueError", "(", "'sentence length is not correct, this should never happened.'", ")", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", ",", "ValueError", "(", "'sentence length is not correct, this should never happened.'", ")", "\n", "assert", "len", "(", "lm_masked_labels", ")", "==", "max_length", ",", "ValueError", "(", "'sentence length is not correct, this should never happened.'", ")", "\n", "\n", "trigger_mask", "=", "[", "0", "]", "*", "max_length", "\n", "trigger_mask", "[", "word_idxs", "[", "trigger_posi", "]", "[", "0", "]", ":", "word_idxs", "[", "trigger_posi", "]", "[", "1", "]", "]", "=", "[", "1", "]", "*", "(", "word_idxs", "[", "trigger_posi", "]", "[", "1", "]", "-", "word_idxs", "[", "trigger_posi", "]", "[", "0", "]", ")", "\n", "\n", "assert", "sum", "(", "trigger_mask", ")", "!=", "0", ",", "ValueError", "(", "'This example should have triggers but we found none trigger after processing. This should never happened.'", ")", "\n", "\n", "\n", "arg_mask", "=", "[", "0", "]", "*", "max_length", "\n", "arg_mask", "[", "word_idxs", "[", "arg_posi", "]", "[", "0", "]", ":", "word_idxs", "[", "arg_posi", "]", "[", "1", "]", "]", "=", "[", "1", "]", "*", "(", "word_idxs", "[", "arg_posi", "]", "[", "1", "]", "-", "word_idxs", "[", "arg_posi", "]", "[", "0", "]", ")", "\n", "\n", "assert", "sum", "(", "arg_mask", ")", "!=", "0", ",", "ValueError", "(", "'This example should have args but we found none args after processing. This should never happened.'", ")", "\n", "\n", "none_arg", "=", "[", "word_idxs", "[", "e", "]", "for", "e", "in", "neg_meta_t", "if", "word_idxs", "[", "e", "]", "[", "1", "]", "<=", "max_length", "]", "[", ":", "max_contrast_ent_per_sent", "]", "\n", "none_arg_mask", "=", "[", "[", "0", "]", "*", "max_length", "]", "*", "max_contrast_ent_per_sent", "\n", "for", "idx", ",", "e", "in", "enumerate", "(", "none_arg", ")", ":", "\n", "            ", "none_arg_mask", "[", "idx", "]", "[", "e", "[", "0", "]", ":", "e", "[", "1", "]", "]", "=", "[", "1", "]", "*", "(", "e", "[", "1", "]", "-", "e", "[", "0", "]", ")", "\n", "assert", "sum", "(", "none_arg_mask", "[", "idx", "]", ")", "!=", "0", ",", "ValueError", "(", "'This example should have entities that are not args but we found less entities that are not args after processing. This should never happened.'", ")", "\n", "\n", "", "none_arg_length_mask", "=", "[", "1", "]", "*", "len", "(", "none_arg", ")", "+", "[", "0", "]", "*", "(", "max_contrast_ent_per_sent", "-", "len", "(", "none_arg", ")", ")", "\n", "\n", "features", ".", "append", "(", "InputContrastFeatures", "(", "example_id", "=", "example", ".", "example_id", ",", "input_ids", "=", "input_ids", ",", "input_mask", "=", "attention_mask", ",", "segment_ids", "=", "token_type_ids", ",", "trigger_mask", "=", "trigger_mask", ",", "arg_mask", "=", "arg_mask", ",", "none_arg_mask", "=", "none_arg_mask", ",", "none_arg_length_mask", "=", "none_arg_length_mask", ",", "lm_masked_labels", "=", "lm_masked_labels", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.convert_examples_to_features": [[454, 530], ["tqdm.tqdm", "enumerate", "tokenizer.tokenize", "tokenizer.tokenize", "tokenizer.encode_plus", "features.append", "enumerate", "logger.info", "len", "len", "logger.info", "len", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils_ee.InputFeatures", "range", "range", "range", "range", "len", "map", "map", "map", "map", "map", "len", "len", "len", "len"], "function", ["None"], ["", "def", "convert_examples_to_features", "(", "\n", "examples", ":", "List", "[", "InputExample", "]", ",", "\n", "label_list", ":", "List", "[", "str", "]", ",", "\n", "max_length", ":", "int", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", ")", "->", "List", "[", "InputFeatures", "]", ":", "\n", "    ", "\"\"\"\n    Loads a data file into a list of `InputFeatures`\n    \"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "tqdm", ".", "tqdm", "(", "enumerate", "(", "examples", ")", ",", "desc", "=", "\"convert examples to features\"", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", "%", "(", "ex_index", ",", "len", "(", "examples", ")", ")", ")", "\n", "", "textL", "=", "tokenizer", ".", "tokenize", "(", "\" \"", ".", "join", "(", "example", ".", "tokens", "[", ":", "example", ".", "triggerL", "]", ")", ")", "\n", "textR", "=", "tokenizer", ".", "tokenize", "(", "\" \"", ".", "join", "(", "example", ".", "tokens", "[", "example", ".", "triggerL", ":", "]", ")", ")", "\n", "maskL", "=", "[", "1.0", "for", "i", "in", "range", "(", "0", ",", "len", "(", "textL", ")", "+", "1", ")", "]", "+", "[", "0.0", "for", "i", "in", "range", "(", "0", ",", "len", "(", "textR", ")", "+", "2", ")", "]", "\n", "maskR", "=", "[", "0.0", "for", "i", "in", "range", "(", "0", ",", "len", "(", "textL", ")", "+", "1", ")", "]", "+", "[", "1.0", "for", "i", "in", "range", "(", "0", ",", "len", "(", "textR", ")", "+", "2", ")", "]", "\n", "if", "len", "(", "maskL", ")", ">", "max_length", ":", "\n", "            ", "maskL", "=", "maskL", "[", ":", "max_length", "]", "\n", "", "if", "len", "(", "maskR", ")", ">", "max_length", ":", "\n", "            ", "maskR", "=", "maskR", "[", ":", "max_length", "]", "\n", "", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "\n", "textL", "+", "[", "'[unused0]'", "]", "+", "textR", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_length", ",", "return_token_type_ids", "=", "True", "\n", ")", "\n", "if", "\"num_truncated_tokens\"", "in", "inputs", "and", "inputs", "[", "\"num_truncated_tokens\"", "]", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Attention! you are cropping tokens.\"", "\n", ")", "\n", "\n", "", "input_ids", ",", "token_type_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "\"token_type_ids\"", "]", "\n", "assert", "len", "(", "input_ids", ")", "==", "len", "(", "maskL", ")", "\n", "assert", "len", "(", "input_ids", ")", "==", "len", "(", "maskR", ")", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "token_type_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "token_type_ids", "\n", "maskL", "=", "(", "[", "0.0", "]", "*", "padding_length", ")", "+", "maskL", "\n", "maskR", "=", "(", "[", "0.0", "]", "*", "padding_length", ")", "+", "maskR", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "token_type_ids", "=", "token_type_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "maskL", "=", "maskL", "+", "(", "[", "0.0", "]", "*", "padding_length", ")", "\n", "maskR", "=", "maskR", "+", "(", "[", "0.0", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_length", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", "\n", "\n", "label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "\n", "if", "ex_index", "<", "2", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"example_id: {}\"", ".", "format", "(", "example", ".", "example_id", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: {}\"", ".", "format", "(", "\" \"", ".", "join", "(", "map", "(", "str", ",", "input_ids", ")", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"attention_mask: {}\"", ".", "format", "(", "\" \"", ".", "join", "(", "map", "(", "str", ",", "attention_mask", ")", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"token_type_ids: {}\"", ".", "format", "(", "\" \"", ".", "join", "(", "map", "(", "str", ",", "token_type_ids", ")", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"maskL: {}\"", ".", "format", "(", "\" \"", ".", "join", "(", "map", "(", "str", ",", "maskL", ")", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"maskR: {}\"", ".", "format", "(", "\" \"", ".", "join", "(", "map", "(", "str", ",", "maskR", ")", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"label: {}\"", ".", "format", "(", "label", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "InputFeatures", "(", "example_id", "=", "example", ".", "example_id", ",", "input_ids", "=", "input_ids", ",", "input_mask", "=", "attention_mask", ",", "segment_ids", "=", "token_type_ids", ",", "maskL", "=", "maskL", ",", "maskR", "=", "maskR", ",", "label", "=", "label", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.model.BERTContrastive.__init__": [[14, 19], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.model.DMRoBERTa.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "W", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "trigger_mask", "=", "None", ",", "arg_mask", "=", "None", ",", "none_arg_mask", "=", "None", ",", "none_arg_length_mask", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.model.BERTContrastive.forward": [[19, 75], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model.BERTContrastive.linear", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model.BERTContrastive.linear", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.BERTContrastive.bert", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "trigger_mask", "=", "None", ",", "arg_mask", "=", "None", ",", "none_arg_mask", "=", "None", ",", "none_arg_length_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "# [bs, length, emd] ", "\n", "input_ids", ",", "# [batch,length]", "\n", "attention_mask", "=", "attention_mask", ",", "# padding", "\n", "token_type_ids", "=", "token_type_ids", ",", "# sentence segmentation", "\n", "position_ids", "=", "position_ids", ",", "# position emebedding", "\n", "head_mask", "=", "head_mask", ",", "# \uff1f", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "# lookup mat", "\n", ")", "[", "0", "]", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "outputs", ")", ")", "==", "0", "\n", "trigger_mask", "=", "torch", ".", "unsqueeze", "(", "trigger_mask", ",", "dim", "=", "2", ")", "#[bs,length, 1]", "\n", "trigger_reps", "=", "outputs", "*", "trigger_mask", "#[bs,length, emd]", "\n", "trigger_reps", "=", "torch", ".", "sum", "(", "trigger_reps", ",", "dim", "=", "1", ")", "#[bs, emd]", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "trigger_reps", "=", "trigger_reps", "/", "torch", ".", "sum", "(", "trigger_mask", ",", "dim", "=", "1", ")", "#[bs, emd]", "\n", "trigger_reps", "=", "self", ".", "linear", "(", "trigger_reps", ")", "\n", "trigger_reps", "=", "trigger_reps", "/", "(", "torch", ".", "norm", "(", "trigger_reps", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "\n", "arg_mask", "=", "torch", ".", "unsqueeze", "(", "arg_mask", ",", "dim", "=", "2", ")", "\n", "arg_reps", "=", "outputs", "*", "arg_mask", "\n", "arg_reps", "=", "torch", ".", "sum", "(", "arg_reps", ",", "dim", "=", "1", ")", "\n", "arg_reps", "=", "arg_reps", "/", "torch", ".", "sum", "(", "arg_mask", ",", "dim", "=", "1", ")", "\n", "arg_reps", "=", "self", ".", "linear", "(", "arg_reps", ")", "\n", "arg_reps", "=", "arg_reps", "/", "(", "torch", ".", "norm", "(", "arg_reps", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "\n", "none_arg_mask", "=", "torch", ".", "unsqueeze", "(", "none_arg_mask", ",", "dim", "=", "3", ")", "#[bs, max_contras_ent, length, 1]", "\n", "outputs_un", "=", "torch", ".", "unsqueeze", "(", "outputs", ",", "dim", "=", "1", ")", "#[bs, 1, length, emd]", "\n", "none_arg_reps", "=", "outputs_un", "*", "none_arg_mask", "#[bs, max_contras_ent, length, emd]", "\n", "none_arg_reps", "=", "torch", ".", "sum", "(", "none_arg_reps", ",", "dim", "=", "2", ")", "#[bs, max_contras_ent, emd]", "\n", "none_arg_reps", "=", "none_arg_reps", "/", "(", "torch", ".", "sum", "(", "none_arg_mask", ",", "dim", "=", "2", ")", "+", "1e-8", ")", "#[bs, max_contras_ent, emd]", "\n", "none_arg_reps", "=", "none_arg_reps", "/", "(", "torch", ".", "norm", "(", "none_arg_reps", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "\n", "# pos_loss = torch.sum(self.W(trigger_reps) * arg_reps,dim=1)          #[bs]", "\n", "pos_loss", "=", "torch", ".", "sum", "(", "trigger_reps", "*", "arg_reps", ",", "dim", "=", "1", ")", "\n", "\n", "# neg_loss_1 = torch.mm(self.W(trigger_reps), torch.transpose(arg_reps,0,1))  #[bs,bs]", "\n", "neg_loss_1", "=", "torch", ".", "mm", "(", "trigger_reps", ",", "torch", ".", "transpose", "(", "arg_reps", ",", "0", ",", "1", ")", ")", "\n", "neg_loss_1", "=", "torch", ".", "exp", "(", "neg_loss_1", ")", "\n", "neg_loss_1", "=", "torch", ".", "sum", "(", "neg_loss_1", ",", "dim", "=", "1", ")", "#[bs]", "\n", "\n", "trigger_reps", "=", "torch", ".", "unsqueeze", "(", "trigger_reps", ",", "dim", "=", "1", ")", "\n", "# neg_loss_2 = torch.sum(self.W(trigger_reps) * none_arg_reps, dim=2) #[bs, max_contras_ent]", "\n", "neg_loss_2", "=", "torch", ".", "sum", "(", "trigger_reps", "*", "none_arg_reps", ",", "dim", "=", "2", ")", "\n", "neg_loss_2", "=", "torch", ".", "exp", "(", "neg_loss_2", ")", "*", "none_arg_length_mask", "\n", "neg_loss_2", "=", "torch", ".", "sum", "(", "neg_loss_2", ",", "dim", "=", "1", ")", "#[bs]", "\n", "\n", "loss", "=", "-", "pos_loss", "+", "torch", ".", "log", "(", "neg_loss_2", "+", "neg_loss_1", "+", "1e-8", ")", "\n", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "return", "(", "loss", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.model.DMBERT.__init__": [[78, 85], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.model.DMRoBERTa.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "maxpooling", "=", "nn", ".", "MaxPool1d", "(", "128", ")", "#???????", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "num_labels", ")", "\n", "self", ".", "W", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.model.DMBERT.forward": [[86, 118], ["input_ids.size", "model.DMBERT.bert", "conved.transpose.transpose.transpose", "conved.transpose.transpose.transpose", "model.DMBERT.maxpooling().contiguous().view", "model.DMBERT.maxpooling().contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.DMBERT.dropout", "model.DMBERT.classifier", "model.DMBERT.view", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "model.DMBERT.maxpooling().contiguous", "model.DMBERT.maxpooling().contiguous", "model.DMBERT.maxpooling", "model.DMBERT.maxpooling"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "maskL", "=", "None", ",", "maskR", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "batchSize", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "# [batch,length]", "\n", "attention_mask", "=", "attention_mask", ",", "# padding", "\n", "token_type_ids", "=", "token_type_ids", ",", "# sentence segmentation", "\n", "position_ids", "=", "position_ids", ",", "# position emebedding", "\n", "head_mask", "=", "head_mask", ",", "# \uff1f", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "# lookup mat", "\n", ")", "\n", "conved", "=", "outputs", "[", "0", "]", "\n", "conved", "=", "conved", ".", "transpose", "(", "1", ",", "2", ")", "\n", "conved", "=", "conved", ".", "transpose", "(", "0", ",", "1", ")", "\n", "L", "=", "(", "conved", "*", "maskL", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "R", "=", "(", "conved", "*", "maskR", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "L", "=", "L", "+", "torch", ".", "ones_like", "(", "L", ")", "\n", "R", "=", "R", "+", "torch", ".", "ones_like", "(", "R", ")", "\n", "pooledL", "=", "self", ".", "maxpooling", "(", "L", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batchSize", ",", "self", ".", "config", ".", "hidden_size", ")", "\n", "pooledR", "=", "self", ".", "maxpooling", "(", "R", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batchSize", ",", "self", ".", "config", ".", "hidden_size", ")", "\n", "pooled", "=", "torch", ".", "cat", "(", "(", "pooledL", ",", "pooledR", ")", ",", "1", ")", "\n", "pooled", "=", "pooled", "-", "torch", ".", "ones_like", "(", "pooled", ")", "\n", "pooled", "=", "self", ".", "dropout", "(", "pooled", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "num_labels", ")", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "#rep=torch.cat((pooled,loc_embeds),1)", "\n", "#rep=F.tanh(self.dropout(pooled))", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.model.DMRoBERTa.__init__": [[121, 128], ["transformers.BertPreTrainedModel.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.model.DMRoBERTa.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "bert", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "maxpooling", "=", "nn", ".", "MaxPool1d", "(", "128", ")", "#???????", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "num_labels", ")", "\n", "self", ".", "W", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.model.DMRoBERTa.forward": [[129, 161], ["input_ids.size", "model.DMRoBERTa.bert", "conved.transpose.transpose.transpose", "conved.transpose.transpose.transpose", "model.DMRoBERTa.maxpooling().contiguous().view", "model.DMRoBERTa.maxpooling().contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.DMRoBERTa.dropout", "model.DMRoBERTa.classifier", "model.DMRoBERTa.view", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "model.DMRoBERTa.maxpooling().contiguous", "model.DMRoBERTa.maxpooling().contiguous", "model.DMRoBERTa.maxpooling", "model.DMRoBERTa.maxpooling"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "maskL", "=", "None", ",", "maskR", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "batchSize", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "# [batch,length]", "\n", "attention_mask", "=", "attention_mask", ",", "# padding", "\n", "token_type_ids", "=", "token_type_ids", ",", "# sentence segmentation", "\n", "position_ids", "=", "position_ids", ",", "# position emebedding", "\n", "head_mask", "=", "head_mask", ",", "# \uff1f", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "# lookup mat", "\n", ")", "\n", "conved", "=", "outputs", "[", "0", "]", "\n", "conved", "=", "conved", ".", "transpose", "(", "1", ",", "2", ")", "\n", "conved", "=", "conved", ".", "transpose", "(", "0", ",", "1", ")", "\n", "L", "=", "(", "conved", "*", "maskL", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "R", "=", "(", "conved", "*", "maskR", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "L", "=", "L", "+", "torch", ".", "ones_like", "(", "L", ")", "\n", "R", "=", "R", "+", "torch", ".", "ones_like", "(", "R", ")", "\n", "pooledL", "=", "self", ".", "maxpooling", "(", "L", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batchSize", ",", "self", ".", "config", ".", "hidden_size", ")", "\n", "pooledR", "=", "self", ".", "maxpooling", "(", "R", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batchSize", ",", "self", ".", "config", ".", "hidden_size", ")", "\n", "pooled", "=", "torch", ".", "cat", "(", "(", "pooledL", ",", "pooledR", ")", ",", "1", ")", "\n", "pooled", "=", "pooled", "-", "torch", ".", "ones_like", "(", "pooled", ")", "\n", "pooled", "=", "self", ".", "dropout", "(", "pooled", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "num_labels", ")", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "#rep=torch.cat((pooled,loc_embeds),1)", "\n", "#rep=F.tanh(self.dropout(pooled))", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.model.RoBERTaContrastive.__init__": [[163, 168], ["transformers.RobertaForMaskedLM.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.model.DMRoBERTa.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "roberta", "=", "bert", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "W", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "trigger_mask", "=", "None", ",", "arg_mask", "=", "None", ",", "none_arg_mask", "=", "None", ",", "none_arg_length_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.model.RoBERTaContrastive.forward": [[168, 238], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model.RoBERTaContrastive.W", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model.RoBERTaContrastive.linear", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model.RoBERTaContrastive.linear", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.RoBERTaContrastive.roberta", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "super().forward", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.model.DMRoBERTa.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "trigger_mask", "=", "None", ",", "arg_mask", "=", "None", ",", "none_arg_mask", "=", "None", ",", "none_arg_length_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "# [bs, length, emd] ", "\n", "input_ids", ",", "# [batch,length]", "\n", "attention_mask", "=", "attention_mask", ",", "# padding", "\n", "token_type_ids", "=", "token_type_ids", ",", "# sentence segmentation", "\n", "position_ids", "=", "position_ids", ",", "# position emebedding", "\n", "head_mask", "=", "head_mask", ",", "# \uff1f", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "# lookup mat", "\n", ")", "[", "0", "]", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "outputs", ")", ")", "==", "0", "\n", "trigger_mask", "=", "torch", ".", "unsqueeze", "(", "trigger_mask", ",", "dim", "=", "2", ")", "#[bs,length, 1]", "\n", "trigger_reps", "=", "outputs", "*", "trigger_mask", "#[bs,length, emd]", "\n", "trigger_reps", "=", "torch", ".", "sum", "(", "trigger_reps", ",", "dim", "=", "1", ")", "#[bs, emd]", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "trigger_reps", "=", "trigger_reps", "/", "torch", ".", "sum", "(", "trigger_mask", ",", "dim", "=", "1", ")", "#[bs, emd]", "\n", "# trigger_reps = self.linear(trigger_reps)", "\n", "trigger_reps", "=", "self", ".", "W", "(", "trigger_reps", ")", "\n", "trigger_reps", "=", "trigger_reps", "/", "(", "torch", ".", "norm", "(", "trigger_reps", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "\n", "arg_mask", "=", "torch", ".", "unsqueeze", "(", "arg_mask", ",", "dim", "=", "2", ")", "\n", "arg_reps", "=", "outputs", "*", "arg_mask", "\n", "arg_reps", "=", "torch", ".", "sum", "(", "arg_reps", ",", "dim", "=", "1", ")", "\n", "arg_reps", "=", "arg_reps", "/", "torch", ".", "sum", "(", "arg_mask", ",", "dim", "=", "1", ")", "\n", "arg_reps", "=", "self", ".", "linear", "(", "arg_reps", ")", "\n", "arg_reps", "=", "arg_reps", "/", "(", "torch", ".", "norm", "(", "arg_reps", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "\n", "none_arg_mask", "=", "torch", ".", "unsqueeze", "(", "none_arg_mask", ",", "dim", "=", "3", ")", "#[bs, max_contras_ent, length, 1]", "\n", "outputs_un", "=", "torch", ".", "unsqueeze", "(", "outputs", ",", "dim", "=", "1", ")", "#[bs, 1, length, emd]", "\n", "none_arg_reps", "=", "outputs_un", "*", "none_arg_mask", "#[bs, max_contras_ent, length, emd]", "\n", "none_arg_reps", "=", "torch", ".", "sum", "(", "none_arg_reps", ",", "dim", "=", "2", ")", "#[bs, max_contras_ent, emd]", "\n", "none_arg_reps", "=", "none_arg_reps", "/", "(", "torch", ".", "sum", "(", "none_arg_mask", ",", "dim", "=", "2", ")", "+", "1e-8", ")", "#[bs, max_contras_ent, emd]", "\n", "none_arg_reps", "=", "self", ".", "linear", "(", "none_arg_reps", ")", "\n", "none_arg_reps", "=", "none_arg_reps", "/", "(", "torch", ".", "norm", "(", "none_arg_reps", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "\n", "# pos_loss = torch.sum(self.W(trigger_reps) * arg_reps,dim=1)          #[bs]", "\n", "pos_loss", "=", "torch", ".", "sum", "(", "trigger_reps", "*", "arg_reps", ",", "dim", "=", "1", ")", "\n", "\n", "# neg_loss_1 = torch.mm(self.W(trigger_reps), torch.transpose(arg_reps,0,1))  #[bs,bs]", "\n", "neg_loss_1", "=", "torch", ".", "mm", "(", "trigger_reps", ",", "torch", ".", "transpose", "(", "arg_reps", ",", "0", ",", "1", ")", ")", "\n", "neg_loss_1", "=", "torch", ".", "exp", "(", "neg_loss_1", ")", "\n", "neg_loss_1", "=", "torch", ".", "sum", "(", "neg_loss_1", ",", "dim", "=", "1", ")", "#[bs]", "\n", "\n", "trigger_reps", "=", "torch", ".", "unsqueeze", "(", "trigger_reps", ",", "dim", "=", "1", ")", "\n", "# neg_loss_2 = torch.sum(self.W(trigger_reps) * none_arg_reps, dim=2) #[bs, max_contras_ent]", "\n", "neg_loss_2", "=", "torch", ".", "sum", "(", "trigger_reps", "*", "none_arg_reps", ",", "dim", "=", "2", ")", "\n", "neg_loss_2", "=", "torch", ".", "exp", "(", "neg_loss_2", ")", "*", "none_arg_length_mask", "\n", "neg_loss_2", "=", "torch", ".", "sum", "(", "neg_loss_2", ",", "dim", "=", "1", ")", "#[bs]", "\n", "\n", "loss", "=", "-", "pos_loss", "+", "torch", ".", "log", "(", "neg_loss_2", "+", "neg_loss_1", "+", "1e-8", ")", "\n", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "\n", "\n", "lm_loss", "=", "super", "(", ")", ".", "forward", "(", "\n", "input_ids", ",", "# [batch,length]", "\n", "attention_mask", "=", "attention_mask", ",", "# padding", "\n", "token_type_ids", "=", "token_type_ids", ",", "# sentence segmentation", "\n", "position_ids", "=", "position_ids", ",", "# position emebedding", "\n", "head_mask", "=", "head_mask", ",", "# \uff1f", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "# lookup mat", "\n", "masked_lm_labels", "=", "masked_lm_labels", "\n", ")", "[", "0", "]", "\n", "\n", "return", "(", "loss", ",", "0.0", "*", "lm_loss", ",", ")", "\n", "# return (loss,)", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.calculate_scores": [[54, 60], ["list", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "range"], "function", ["None"], ["def", "calculate_scores", "(", "preds", ",", "labels", ",", "dimE", ")", ":", "\n", "    ", "positive_labels", "=", "list", "(", "range", "(", "1", ",", "dimE", ")", ")", "#assume 0 is NA", "\n", "pre", "=", "precision_score", "(", "labels", ",", "preds", ",", "labels", "=", "positive_labels", ",", "average", "=", "'micro'", ")", "\n", "recall", "=", "recall_score", "(", "labels", ",", "preds", ",", "labels", "=", "positive_labels", ",", "average", "=", "'micro'", ")", "\n", "f1", "=", "f1_score", "(", "labels", ",", "preds", ",", "labels", "=", "positive_labels", ",", "average", "=", "'micro'", ")", "\n", "return", "pre", ",", "recall", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.set_seed": [[61, 67], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.train": [[69, 242], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_ee.set_seed", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "logger.info", "any", "run_ee.evaluate", "str", "str", "run_ee.evaluate", "logger.info", "str", "str", "str", "open", "f.write", "f.write", "f.write", "f.write", "f.write", "open", "json.dump", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.set_seed", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.train", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.evaluate", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#tb_writer = SummaryWriter()", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "best_dev_f1", "=", "0.0", "\n", "best_steps", "=", "0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "best_dev_preds", "=", "[", "]", "\n", "best_test_preds", "=", "[", "]", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"maskL\"", ":", "batch", "[", "3", "]", ",", "\n", "\"maskR\"", ":", "batch", "[", "4", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "5", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", ",", "dev_pred_results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "#for key, value in results.items():", "\n", "#tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)", "\n", "if", "results", "[", "\"eval_f1\"", "]", ">", "best_dev_f1", ":", "\n", "                            ", "best_dev_f1", "=", "results", "[", "\"eval_f1\"", "]", "\n", "best_steps", "=", "global_step", "\n", "best_dev_preds", "=", "dev_pred_results", "\n", "if", "args", ".", "do_test", ":", "\n", "                                ", "results_test", ",", "test_pred_results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "test", "=", "True", ")", "\n", "best_test_preds", "=", "test_pred_results", "\n", "#for key, value in results_test.items():", "\n", "#tb_writer.add_scalar(\"test_{}\".format(key), value, global_step)", "\n", "logger", ".", "info", "(", "\n", "\"test f1: %s, loss: %s, global steps: %s\"", ",", "\n", "str", "(", "results_test", "[", "\"eval_f1\"", "]", ")", ",", "\n", "str", "(", "results_test", "[", "\"eval_loss\"", "]", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "with", "open", "(", "args", ".", "output_dir", "+", "'/best.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "                                    ", "f", ".", "write", "(", "\"best F1: {}\\n\"", ".", "format", "(", "str", "(", "results_test", "[", "\"eval_f1\"", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "\"best p: {}\\n\"", ".", "format", "(", "str", "(", "results_test", "[", "\"eval_p\"", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "\"best recall: {}\\n\"", ".", "format", "(", "str", "(", "results_test", "[", "\"eval_recall\"", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "\"best loss: {}\\n\"", ".", "format", "(", "str", "(", "results_test", "[", "\"eval_loss\"", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "\"best step: {}\\n\"", ".", "format", "(", "str", "(", "best_steps", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "output_dir", "+", "'/pred.json'", ",", "'w'", ")", "as", "f", ":", "\n", "                                    ", "json", ".", "dump", "(", "{", "'dev'", ":", "best_dev_preds", ",", "'test'", ":", "best_test_preds", "}", ",", "f", ")", "\n", "\n", "#tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)", "\n", "#tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)", "\n", "", "", "", "", "logger", ".", "info", "(", "\n", "\"Average loss: %s at global step: %s\"", ",", "\n", "str", "(", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "# if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:", "\n", "#     # Save model checkpoint", "\n", "#     output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))", "\n", "#     if not os.path.exists(output_dir):", "\n", "#         os.makedirs(output_dir)", "\n", "#     model_to_save = (", "\n", "#         model.module if hasattr(model, \"module\") else model", "\n", "#     )  # Take care of distributed/parallel training", "\n", "#     model_to_save.save_pretrained(output_dir)", "\n", "#     tokenizer.save_vocabulary(output_dir)", "\n", "#     torch.save(args, os.path.join(output_dir, \"training_args.bin\"))", "\n", "#     logger.info(\"Saving model checkpoint to %s\", output_dir)", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#tb_writer.close()", "\n", "\n", "", "", "return", "global_step", ",", "tr_loss", "/", "global_step", ",", "best_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.pretrain": [[243, 412], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_ee.set_seed", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "con_loss.mean.item", "lm_loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "loss.mean.mean", "con_loss.mean.mean", "lm_loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_ee.pretrain_evaluate", "logger.info", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "any", "str", "str", "str", "str", "str", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "os.path.exists", "os.makedirs", "open", "f.write", "f.write", "os.path.join", "str", "str"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.set_seed", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.train", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.pretrain_evaluate"], ["", "def", "pretrain", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "test_dataset", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#tb_writer = SummaryWriter()", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "con_tr_loss", ",", "con_logging_loss", "=", "0.0", ",", "0.0", "\n", "lm_tr_loss", ",", "lm_logging_loss", "=", "0.0", ",", "0.0", "\n", "best_dev_f1", "=", "0.0", "\n", "min_eval_loss", "=", "-", "1", "\n", "best_steps", "=", "0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"trigger_mask\"", ":", "batch", "[", "3", "]", ",", "\n", "\"arg_mask\"", ":", "batch", "[", "4", "]", ",", "\n", "\"none_arg_mask\"", ":", "batch", "[", "5", "]", ",", "\n", "\"none_arg_length_mask\"", ":", "batch", "[", "6", "]", ",", "\n", "'masked_lm_labels'", ":", "batch", "[", "7", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "# loss = outputs[0] + outputs[1]  # model outputs are always tuple in transformers (see doc)", "\n", "\n", "con_loss", "=", "outputs", "[", "0", "]", "\n", "lm_loss", "=", "outputs", "[", "1", "]", "\n", "loss", "=", "con_loss", "+", "lm_loss", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "con_loss", "=", "con_loss", ".", "mean", "(", ")", "\n", "lm_loss", "=", "lm_loss", ".", "mean", "(", ")", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "con_loss", "=", "con_loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "lm_loss", "=", "lm_loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "con_tr_loss", "+=", "con_loss", ".", "item", "(", ")", "\n", "lm_tr_loss", "+=", "lm_loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "\n", "                    ", "eval_loss", "=", "pretrain_evaluate", "(", "args", ",", "test_dataset", ",", "model", ",", "tokenizer", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "\"Average loss: %s, con_loss: %s, lm_loss: %s, eval_loss: %s, at global step: %s\"", ",", "\n", "str", "(", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ")", ",", "\n", "str", "(", "(", "con_tr_loss", "-", "con_logging_loss", ")", "/", "args", ".", "logging_steps", ")", ",", "\n", "str", "(", "(", "lm_tr_loss", "-", "lm_logging_loss", ")", "/", "args", ".", "logging_steps", ")", ",", "\n", "str", "(", "eval_loss", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "con_logging_loss", "=", "con_tr_loss", "\n", "lm_logging_loss", "=", "lm_tr_loss", "\n", "if", "eval_loss", "<", "min_eval_loss", "or", "min_eval_loss", "==", "-", "1", ":", "\n", "                        ", "best_steps", "=", "global_step", "+", "0", "\n", "min_eval_loss", "=", "eval_loss", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"best_steps.txt\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                            ", "f", ".", "write", "(", "'best step at:'", "+", "str", "(", "best_steps", ")", "+", "'\\n'", ")", "\n", "f", ".", "write", "(", "'eval_loss:'", "+", "str", "(", "eval_loss", ")", ")", "\n", "\n", "", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", ".", "roberta", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", ".", "roberta", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#tb_writer.close()", "\n", "\n", "", "", "return", "global_step", ",", "tr_loss", "/", "global_step", ",", "best_steps", ",", "min_eval_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.pretrain_evaluate": [[413, 443], ["torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "tqdm.tqdm", "max", "model.eval", "tuple", "torch.no_grad", "model", "t.to"], "function", ["None"], ["", "def", "pretrain_evaluate", "(", "args", ",", "eval_dataset", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ",", "test", "=", "False", ")", ":", "\n", "\n", "    ", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "eval_loss", "=", "0.0", "\n", "step", "=", "0", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"trigger_mask\"", ":", "batch", "[", "3", "]", ",", "\n", "\"arg_mask\"", ":", "batch", "[", "4", "]", ",", "\n", "\"none_arg_mask\"", ":", "batch", "[", "5", "]", ",", "\n", "\"none_arg_length_mask\"", ":", "batch", "[", "6", "]", ",", "\n", "'masked_lm_labels'", ":", "batch", "[", "7", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "eval_loss", "+=", "(", "outputs", "[", "0", "]", "+", "outputs", "[", "1", "]", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "step", "+=", "1", "\n", "\n", "", "return", "eval_loss", "/", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.evaluate": [[445, 532], ["zip", "run_ee.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "numpy.argmax", "pred_results.extend", "run_ee.calculate_scores", "results.update", "os.path.join", "dict", "os.makedirs", "max", "len", "model.eval", "tuple", "np.append.tolist", "len", "open", "logger.info", "writer.write", "writer.write", "writer.write", "writer.write", "writer.write", "sorted", "len", "len", "list", "os.path.exists", "torch.no_grad", "model", "tmp_eval_loss.mean().item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "result.keys", "logger.info", "writer.write", "zip", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "str().lower", "str", "str", "tmp_eval_loss.mean", "logits.detach().cpu", "inputs[].detach().cpu", "str", "logits.detach().cpu", "inputs[].detach().cpu", "str", "str", "torch.distributed.get_world_size", "str", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.load_and_cache_examples", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.calculate_scores"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ",", "test", "=", "False", ")", ":", "\n", "    ", "eval_task_names", "=", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "pred_results", "=", "[", "]", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "eval_dataset", ",", "eval_ids", "=", "load_and_cache_examples", "(", "args", ",", "eval_task", ",", "tokenizer", ",", "evaluate", "=", "not", "test", ",", "test", "=", "test", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "#if args.n_gpu > 1:", "\n", "#print(\"?????\",args.n_gpu)", "\n", "#model = torch.nn.DataParallel(model)", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"maskL\"", ":", "batch", "[", "3", "]", ",", "\n", "\"maskR\"", ":", "batch", "[", "4", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "5", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "#print(eval_task)", "\n", "#print(processors[eval_task])", "\n", "pred_results", ".", "extend", "(", "preds", ".", "tolist", "(", ")", ")", "\n", "precision", ",", "recall", ",", "f1", "=", "calculate_scores", "(", "preds", ",", "out_label_ids", ",", "len", "(", "processors", "[", "eval_task", "]", "(", ")", ".", "get_labels", "(", ")", ")", ")", "\n", "result", "=", "{", "\"eval_p\"", ":", "precision", ",", "\"eval_recall\"", ":", "recall", ",", "\"eval_f1\"", ":", "f1", ",", "\"eval_loss\"", ":", "eval_loss", "}", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "\"is_test_\"", "+", "str", "(", "test", ")", ".", "lower", "(", ")", "+", "\"_eval_results.txt\"", ")", "\n", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "str", "(", "prefix", ")", "+", "\" is test:\"", "+", "str", "(", "test", ")", ")", ")", "\n", "writer", ".", "write", "(", "\"model           =%s\\n\"", "%", "str", "(", "args", ".", "model_name_or_path", ")", ")", "\n", "writer", ".", "write", "(", "\n", "\"total batch size=%d\\n\"", "\n", "%", "(", "\n", "args", ".", "per_gpu_train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", "\n", ")", "\n", ")", "\n", "writer", ".", "write", "(", "\"train num epochs=%d\\n\"", "%", "args", ".", "num_train_epochs", ")", "\n", "writer", ".", "write", "(", "\"fp16            =%s\\n\"", "%", "args", ".", "fp16", ")", "\n", "writer", ".", "write", "(", "\"max seq length  =%d\\n\"", "%", "args", ".", "max_seq_length", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "", "", "assert", "len", "(", "eval_ids", ")", "==", "len", "(", "pred_results", ")", "\n", "", "return", "results", ",", "dict", "(", "list", "(", "zip", "(", "eval_ids", ",", "pred_results", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.load_and_cache_contrast_examples": [[533, 604], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "torch.load", "logger.info", "processor.get_contrast_examples", "utils_ee.convert_contrast_examples_to_features", "int", "torch.distributed.barrier", "list().pop", "str", "str", "logger.info", "torch.save", "torch.save", "bool", "list", "len", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.ACEProcessor.get_contrast_examples", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.utils_ee.convert_contrast_examples_to_features"], ["", "def", "load_and_cache_contrast_examples", "(", "args", ",", "task", ",", "tokenizer", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "# Load data features from cache or dataset file", "\n", "cached_mode", "=", "\"pretrain_contrast\"", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"contrast_cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "cached_mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading contrast features from cached file %s\"", ",", "cached_features_file", ")", "\n", "train_contrast_features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "test_contrast_features", "=", "torch", ".", "load", "(", "cached_features_file", "+", "'_test'", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating contrast features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "\n", "contrast_examples", "=", "processor", ".", "get_contrast_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "contrast_features", "=", "convert_contrast_examples_to_features", "(", "\n", "contrast_examples", ",", "\n", "args", ".", "max_seq_length", ",", "\n", "args", ".", "max_contrast_entity_per_sentence", ",", "\n", "tokenizer", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", ")", "\n", "\n", "feature_len", "=", "int", "(", "len", "(", "contrast_features", ")", "/", "10", "*", "8", ")", "\n", "\n", "train_contrast_features", "=", "contrast_features", "[", ":", "feature_len", "]", "\n", "test_contrast_features", "=", "contrast_features", "[", "feature_len", ":", "]", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "train_contrast_features", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "test_contrast_features", ",", "cached_features_file", "+", "\"_test\"", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_trigger_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "trigger_mask", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_arg_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "arg_mask", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_none_arg_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "none_arg_mask", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_none_arg_length_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "none_arg_length_mask", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_lm_masked_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "lm_masked_labels", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "train_dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_trigger_mask", ",", "all_arg_mask", ",", "all_none_arg_mask", ",", "all_none_arg_length_mask", ",", "all_lm_masked_labels", ")", "\n", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_trigger_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "trigger_mask", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_arg_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "arg_mask", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_none_arg_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "none_arg_mask", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_none_arg_length_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "none_arg_length_mask", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_lm_masked_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "lm_masked_labels", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "test_dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_trigger_mask", ",", "all_arg_mask", ",", "all_none_arg_mask", ",", "all_none_arg_length_mask", ",", "all_lm_masked_labels", ")", "\n", "\n", "return", "train_dataset", ",", "test_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.load_and_cache_examples": [[605, 669], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "processor.get_labels", "logger.info", "utils_ee.convert_examples_to_features", "torch.distributed.barrier", "list().pop", "str", "str", "processor.get_dev_examples", "str", "logger.info", "torch.save", "processor.get_test_examples", "processor.get_train_examples", "len", "bool", "list", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_labels", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.convert_examples_to_features", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_dev_examples", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_test_examples", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_train_examples"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "test", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "# Load data features from cache or dataset file", "\n", "if", "evaluate", ":", "\n", "        ", "cached_mode", "=", "\"dev\"", "\n", "", "elif", "test", ":", "\n", "        ", "cached_mode", "=", "\"test\"", "\n", "", "else", ":", "\n", "        ", "cached_mode", "=", "\"train\"", "\n", "", "assert", "not", "(", "evaluate", "and", "test", ")", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "cached_mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "if", "evaluate", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "test", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "", "logger", ".", "info", "(", "\"Training number: %s\"", ",", "str", "(", "len", "(", "examples", ")", ")", ")", "\n", "\n", "features", "=", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "label_list", ",", "\n", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_maskL", "=", "torch", ".", "tensor", "(", "[", "f", ".", "maskL", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_maskR", "=", "torch", ".", "tensor", "(", "[", "f", ".", "maskR", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_maskL", ",", "all_maskR", ",", "all_label_ids", ")", "\n", "if", "evaluate", "or", "test", ":", "\n", "        ", "return", "dataset", ",", "[", "f", ".", "example_id", "for", "f", "in", "features", "]", "\n", "", "else", ":", "\n", "        ", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.main": [[671, 1038], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.exists", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "logging.basicConfig", "logger.warning", "run_ee.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "os.path.exists", "os.listdir", "ValueError", "os.listdir", "os.listdir", "os.listdir", "os.path.exists", "ValueError", "os.listdir", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "print", "run_ee.load_and_cache_contrast_examples", "run_ee.pretrain", "logger.info", "run_ee.load_and_cache_examples", "run_ee.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "model_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "logger.info", "logger.info", "torch.cuda.device_count", "contrastive_class.from_pretrained", "model.RoBERTaContrastive", "ValueError", "model_class.from_pretrained", "model.DMRoBERTa", "ValueError", "os.makedirs", "hasattr", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_ee.evaluate", "dict", "results.update", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_ee.evaluate", "dict", "results.update", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "utils_ee.processors.keys", "torch.cuda.is_available", "bool", "bool", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.set_seed", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_labels", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.load_and_cache_contrast_examples", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.None.run_ee.pretrain", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.load_and_cache_examples", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.train", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.evaluate", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.evaluate"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "+", "\", \"", ".", "join", "(", "ALL_MODELS", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_contrast_entity_per_sentence\"", ",", "\n", "default", "=", "10", ",", "\n", "type", "=", "int", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Max contrast entity per sentence in contrastive pretraining stage.\"", ",", "\n", ")", "\n", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_pretrain\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to pretrain using MI.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run test on the test set\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_positive_batch_size\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for positive pretrain\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_negativex_batch_size\"", ",", "default", "=", "3", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for negativex pretrain\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_negativey_batch_size\"", ",", "default", "=", "3", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for negativey pretrain\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_pretrain_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of pretraining epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--positive_max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of pretraining steps to perform. Override num_pretrain_epochs.\"", ",", "\n", ")", "\n", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "\n", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "\n", "", "\"\"\"\n        Input Error Check\n    \"\"\"", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "args", ".", "data_dir", ")", ",", "ValueError", "(", "'data_dir does not exist!'", ")", "\n", "assert", "args", ".", "task_name", "==", "'ace'", ",", "ValueError", "(", "'task_name is not supported, please use ace'", ")", "\n", "check_suffix", "=", "'json'", "if", "args", ".", "task_name", "==", "'ace'", "else", "'jsonl'", "\n", "assert", "'train.{}'", ".", "format", "(", "check_suffix", ")", "in", "os", ".", "listdir", "(", "args", ".", "data_dir", ")", ",", "ValueError", "(", "'train file does not exist!'", ")", "\n", "assert", "'dev.{}'", ".", "format", "(", "check_suffix", ")", "in", "os", ".", "listdir", "(", "args", ".", "data_dir", ")", ",", "ValueError", "(", "'dev file does not exist!'", ")", "\n", "assert", "'test.{}'", ".", "format", "(", "check_suffix", ")", "in", "os", ".", "listdir", "(", "args", ".", "data_dir", ")", ",", "ValueError", "(", "'test file does not exist!'", ")", "\n", "\n", "if", "not", "args", ".", "do_pretrain", ":", "\n", "        ", "assert", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ",", "ValueError", "(", "'Model path does not exists!'", ")", "\n", "check_model_files", "=", "os", ".", "listdir", "(", "args", ".", "model_name_or_path", ")", "\n", "assert", "'config.json'", "in", "check_model_files", ",", "ValueError", "(", "'Model files are not complete! (config.json is missing)'", ")", "\n", "assert", "'merges.txt'", "in", "check_model_files", ",", "ValueError", "(", "'Model files are not complete! (merges.txt is missing)'", ")", "\n", "assert", "'pytorch_model.bin'", "in", "check_model_files", ",", "ValueError", "(", "'Model files are not complete! (pytorch_model.bin is missing)'", ")", "\n", "assert", "'special_tokens_map.json'", "in", "check_model_files", ",", "ValueError", "(", "'Model files are not complete! (special_tokens_map.json is missing)'", ")", "\n", "assert", "'tokenizer_config.json'", "in", "check_model_files", ",", "ValueError", "(", "'Model files are not complete! (tokenizer_config.json is missing)'", ")", "\n", "assert", "'training_args.bin'", "in", "check_model_files", ",", "ValueError", "(", "'Model files are not complete! (training_args.bin is missing)'", ")", "\n", "assert", "'vocab.json'", "in", "check_model_files", ",", "ValueError", "(", "'Model files are not complete! (vocab.json is missing)'", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", ",", "contrastive_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "if", "args", ".", "do_pretrain", ":", "\n", "        ", "if", "args", ".", "model_type", "==", "'roberta'", ":", "\n", "            ", "model", "=", "contrastive_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "#True,", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", "\n", ")", "\n", "model", "=", "RoBERTaContrastive", "(", "config", ",", "model", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'model_type should be roberta'", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "args", ".", "model_type", "==", "'roberta'", ":", "\n", "            ", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "#True,", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", "\n", ")", "\n", "model", "=", "DMRoBERTa", "(", "config", ",", "model", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'model_type should be roberta'", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "best_steps", "=", "0", "\n", "\n", "if", "args", ".", "do_pretrain", ":", "\n", "        ", "print", "(", "\"--do pretrain--\"", ")", "\n", "pretrain_dataset", ",", "pretrain_dataset_test", "=", "load_and_cache_contrast_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ")", "\n", "global_step", ",", "tr_loss", ",", "best_steps", ",", "min_loss", "=", "pretrain", "(", "args", ",", "pretrain_dataset", ",", "model", ",", "tokenizer", ",", "pretrain_dataset_test", ")", "\n", "logger", ".", "info", "(", "\" contrast_global_step = %s, contrast_average loss = %s, best_steps = %s, min_loss = %s\"", ",", "global_step", ",", "tr_loss", ",", "best_steps", ",", "min_loss", ")", "\n", "return", "\n", "\n", "# Trainingr", "\n", "", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "global_step", ",", "tr_loss", ",", "best_steps", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s, best_steps = %s\"", ",", "global_step", ",", "tr_loss", ",", "best_steps", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "if", "not", "args", ".", "do_train", ":", "\n", "            ", "args", ".", "output_dir", "=", "args", ".", "model_name_or_path", "\n", "", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "if", "not", "args", ".", "do_train", ":", "\n", "            ", "args", ".", "output_dir", "=", "args", ".", "model_name_or_path", "\n", "", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "# if args.eval_all_checkpoints: # can not use this to do test!!", "\n", "#     checkpoints = list(os.path.dirname(c) for c in sorted(glob.glob(args.output_dir + '/**/' + WEIGHTS_NAME, recursive=True)))", "\n", "#     logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.WARN)  # Reduce logging", "\n", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ",", "test", "=", "True", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "", "", "if", "best_steps", ":", "\n", "        ", "logger", ".", "info", "(", "\"best steps of eval f1 is the following checkpoints: %s\"", ",", "best_steps", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.sent_tokenize.sent_tokenize": [[7, 37], ["os.listdir", "tqdm.tqdm", "random.shuffle", "os.listdir", "tqdm.tqdm", "open", "os.listdir", "f.write", "f.write", "os.listdir", "open", "f.read", "nltk.sent_tokenize", "all_sents.extend", "len", "len", "nltk.word_tokenize", "nltk.word_tokenize"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.sent_tokenize.sent_tokenize"], ["def", "sent_tokenize", "(", "args", ")", ":", "\n", "    ", "all_sents", "=", "[", "]", "\n", "\n", "data_dir", "=", "args", ".", "data_dir", "\n", "years", "=", "os", ".", "listdir", "(", "data_dir", ")", "\n", "years", "=", "[", "data_dir", "+", "'/'", "+", "year", "for", "year", "in", "years", "]", "\n", "for", "year", "in", "tqdm", "(", "years", ",", "desc", "=", "'years'", ")", ":", "\n", "        ", "subfolders", "=", "os", ".", "listdir", "(", "year", ")", "\n", "if", "year", "in", "[", "'1987'", ",", "'1988'", ",", "'1989'", ",", "'1990'", "]", ":", "\n", "            ", "continue", "\n", "", "subfolders", "=", "[", "year", "+", "'/'", "+", "subfolder", "for", "subfolder", "in", "subfolders", "]", "\n", "for", "subfolder", "in", "tqdm", "(", "subfolders", ",", "desc", "=", "'subfolders'", ")", ":", "\n", "            ", "subsubfolders", "=", "os", ".", "listdir", "(", "subfolder", ")", "\n", "subsubfolders", "=", "[", "subfolder", "+", "'/'", "+", "subsubfolder", "for", "subsubfolder", "in", "subsubfolders", "]", "\n", "for", "subsubfolder", "in", "subsubfolders", ":", "\n", "                ", "files", "=", "os", ".", "listdir", "(", "subsubfolder", ")", "\n", "files", "=", "[", "subsubfolder", "+", "'/'", "+", "file", "for", "file", "in", "files", "]", "\n", "for", "file", "in", "files", ":", "\n", "                    ", "with", "open", "(", "file", ",", "'r'", ")", "as", "f", ":", "\n", "                        ", "text", "=", "f", ".", "read", "(", ")", "\n", "sents", "=", "nltk", ".", "sent_tokenize", "(", "text", ")", "\n", "sents", "=", "[", "sent", "for", "sent", "in", "sents", "if", "len", "(", "nltk", ".", "word_tokenize", "(", "sent", ")", ")", ">=", "10", "and", "len", "(", "nltk", ".", "word_tokenize", "(", "sent", ")", ")", "<", "50", "]", "\n", "all_sents", ".", "extend", "(", "sents", ")", "\n", "\n", "", "", "", "", "", "shuffle", "(", "all_sents", ")", "\n", "all_sents", "=", "all_sents", "[", "-", "args", ".", "num", ":", "]", "\n", "with", "open", "(", "\"nyt_sent_limit.txt\"", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "sent", "in", "all_sents", ":", "\n", "            ", "f", ".", "write", "(", "sent", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.Graph.__init__": [[7, 13], ["load_AMR.Graph.process_nodes", "load_AMR.Graph.process_edges", "load_AMR.Graph.process_graph", "load_AMR.Graph.process_graph", "re.compile", "re.compile"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.Graph.process_nodes", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.Graph.process_edges", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.Graph.process_graph", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.Graph.process_graph"], ["    ", "def", "__init__", "(", "self", ",", "raw_nodes", ",", "raw_edges", ",", "tokens", ")", ":", "\n", "        ", "self", ".", "node_id2idx", ",", "self", ".", "abandon_wordidx", "=", "self", ".", "process_nodes", "(", "raw_nodes", ")", "#{id:(st,ed)}", "\n", "self", ".", "edges", "=", "self", ".", "process_edges", "(", "raw_edges", ")", "#{(st,ed):[(type,(st,ed)),....]}", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "process_graph", "(", "re", ".", "compile", "(", "r'^op\\d+'", ")", ")", "\n", "self", ".", "process_graph", "(", "re", ".", "compile", "(", "r'name'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.Graph.process_nodes": [[14, 23], ["re.compile", "int", "int", "abandon_wordidx.append", "re.compile.match", "int", "int"], "methods", ["None"], ["", "def", "process_nodes", "(", "self", ",", "nodes", ")", ":", "\n", "        ", "node_id2idx", "=", "{", "}", "\n", "abandon_wordidx", "=", "[", "]", "\n", "proper_noun", "=", "re", ".", "compile", "(", "r'\"(\\S+)\"'", ")", "\n", "for", "node", "in", "nodes", ":", "\n", "            ", "node_id2idx", "[", "node", "[", "0", "]", "]", "=", "(", "int", "(", "node", "[", "2", "]", ")", ",", "int", "(", "node", "[", "3", "]", ")", ")", "\n", "if", "node", "[", "1", "]", "in", "[", "'and'", ",", "'or'", ",", "'not'", "]", "or", "(", "proper_noun", ".", "match", "(", "node", "[", "1", "]", ")", "is", "not", "None", ")", ":", "# Remove concat words and proper nouns from pretraining", "\n", "                ", "abandon_wordidx", ".", "append", "(", "(", "int", "(", "node", "[", "2", "]", ")", ",", "int", "(", "node", "[", "3", "]", ")", ")", ")", "\n", "", "", "return", "node_id2idx", ",", "abandon_wordidx", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.Graph.process_edges": [[24, 37], ["collections.defaultdict", "raw_edge[].endswith", "edges[].append", "edges[].append"], "methods", ["None"], ["", "def", "process_edges", "(", "self", ",", "raw_edges", ")", ":", "\n", "        ", "edges", "=", "defaultdict", "(", "list", ")", "\n", "for", "raw_edge", "in", "raw_edges", ":", "\n", "            ", "node1", ",", "node2", "=", "raw_edge", "[", "3", "]", ",", "raw_edge", "[", "4", "]", "\n", "node1idx", "=", "self", ".", "node_id2idx", "[", "node1", "]", "if", "node1", "in", "self", ".", "node_id2idx", "else", "node1", "\n", "node2idx", "=", "self", ".", "node_id2idx", "[", "node2", "]", "if", "node2", "in", "self", ".", "node_id2idx", "else", "node2", "\n", "if", "node1idx", "==", "node2idx", ":", "#remove self circle. This will also remove edges like:   country ---:name---> name ---:op---> U.S. if they are same word", "\n", "                ", "continue", "\n", "", "if", "raw_edge", "[", "1", "]", ".", "endswith", "(", "'-of'", ")", ":", "# reverse edge", "\n", "                ", "edges", "[", "node2idx", "]", ".", "append", "(", "(", "raw_edge", "[", "1", "]", "[", ":", "-", "3", "]", ",", "node1idx", ")", ")", "\n", "", "else", ":", "\n", "                ", "edges", "[", "node1idx", "]", ".", "append", "(", "(", "raw_edge", "[", "1", "]", ",", "node2idx", ")", ")", "\n", "", "", "return", "edges", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.Graph.process_graph": [[38, 53], ["load_AMR.Graph.edges[].append", "edges.items", "rule.match", "new_op_edges_tuple.extend"], "methods", ["None"], ["", "def", "process_graph", "(", "self", ",", "rule", ")", ":", "\n", "        ", "edges", "=", "self", ".", "edges", "\n", "edges_tuple", "=", "[", "(", "k", ",", "v", "[", "0", "]", ",", "v", "[", "1", "]", ")", "for", "k", ",", "vs", "in", "edges", ".", "items", "(", ")", "for", "v", "in", "vs", "]", "\n", "new_op_edges_tuple", "=", "[", "]", "\n", "for", "edge_tuple", "in", "edges_tuple", ":", "\n", "            ", "node1idx", "=", "edge_tuple", "[", "0", "]", "\n", "edge_rel", "=", "edge_tuple", "[", "1", "]", "\n", "node2idx", "=", "edge_tuple", "[", "2", "]", "\n", "if", "rule", ".", "match", "(", "edge_rel", ")", "is", "not", "None", ":", "# Merge all op/name nodes to its parent nodes", "\n", "                ", "new_edges_tuple", "=", "[", "(", "e_t", "[", "0", "]", ",", "e_t", "[", "1", "]", ",", "node2idx", ")", "for", "e_t", "in", "edges_tuple", "if", "e_t", "[", "2", "]", "==", "node1idx", "]", "\n", "new_op_edges_tuple", ".", "extend", "(", "new_edges_tuple", ")", "\n", "\n", "", "", "for", "new_edges_tuple", "in", "new_op_edges_tuple", ":", "\n", "            ", "n1", ",", "rel", ",", "n2", "=", "new_edges_tuple", "\n", "self", ".", "edges", "[", "n1", "]", ".", "append", "(", "(", "rel", ",", "n2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.load_amr": [[55, 73], ["f.read.split", "re.compile", "re.compile", "open", "f.read", "tokens[].split.startswith", "tokens[].split", "re.compile.findall", "re.compile.findall", "load_AMR.Graph", "gs.append", "amr.split", "len"], "function", ["None"], ["", "", "", "def", "load_amr", "(", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "amrs", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "amrs", "=", "amrs", ".", "split", "(", "'\\n\\n'", ")", "\n", "amrs", "=", "amrs", "[", ":", "-", "1", "]", "if", "amrs", "[", "-", "1", "]", "==", "\"\"", "else", "amrs", "\n", "node_format", "=", "re", ".", "compile", "(", "r'# ::node\\t(\\S+)\\t(\\S+)\\t(\\d+)-(\\d+)'", ")", "\n", "edge_format", "=", "re", ".", "compile", "(", "r'# ::edge\\t(\\S+)\\t(\\S+)\\t(\\S+)\\t(\\S+)\\t(\\S+)'", ")", "\n", "gs", "=", "[", "]", "\n", "for", "amr", "in", "amrs", ":", "\n", "        ", "tokens", "=", "amr", ".", "split", "(", "'\\n'", ")", "[", "2", "]", "\n", "assert", "tokens", ".", "startswith", "(", "'# ::tok '", ")", "\n", "tokens", "=", "tokens", "[", "len", "(", "\"# ::tok \"", ")", ":", "]", ".", "split", "(", "' '", ")", "\n", "nodes", "=", "node_format", ".", "findall", "(", "amr", ")", "\n", "edges", "=", "edge_format", ".", "findall", "(", "amr", ")", "\n", "graph", "=", "Graph", "(", "nodes", ",", "edges", ",", "tokens", ")", "\n", "gs", ".", "append", "(", "graph", ")", "\n", "", "return", "gs", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.minus_list": [[76, 82], ["rax.append"], "function", ["None"], ["", "def", "minus_list", "(", "list1", ",", "list2", ")", ":", "\n", "    ", "rax", "=", "[", "]", "\n", "for", "a", "in", "list1", ":", "\n", "        ", "if", "a", "not", "in", "list2", ":", "\n", "            ", "rax", ".", "append", "(", "a", ")", "\n", "", "", "return", "rax", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.process_to_pretrain": [[84, 114], ["list", "edges.items", "list", "set", "list.extend", "set", "len", "examples.append", "g.node_id2idx.values", "len", "load_AMR.minus_list", "type", "v[].lower().startswith", "type", "v[].lower", "v[].lower"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.AMR.load_AMR.minus_list"], ["", "def", "process_to_pretrain", "(", "gs", ")", ":", "\n", "    ", "examples", "=", "[", "]", "\n", "for", "g", "in", "gs", ":", "\n", "        ", "example", "=", "{", "}", "\n", "tokens", "=", "g", ".", "tokens", "\n", "edges", "=", "g", ".", "edges", "\n", "example", "[", "'tokens'", "]", "=", "tokens", "\n", "\n", "nodes", "=", "list", "(", "set", "(", "g", ".", "node_id2idx", ".", "values", "(", ")", ")", ")", "\n", "example", "[", "'positive_edges'", "]", "=", "{", "}", "\n", "example", "[", "'negative_edges'", "]", "=", "{", "}", "\n", "useful_nodes", "=", "[", "]", "\n", "for", "k", ",", "vs", "in", "edges", ".", "items", "(", ")", ":", "\n", "            ", "if", "type", "(", "k", ")", "!=", "tuple", "or", "k", "in", "g", ".", "abandon_wordidx", ":", "\n", "                ", "continue", "\n", "", "positive_nodes", "=", "[", "v", "[", "1", "]", "for", "v", "in", "vs", "if", "(", "(", "v", "[", "0", "]", ".", "lower", "(", ")", ".", "startswith", "(", "'arg'", ")", "or", "v", "[", "0", "]", ".", "lower", "(", ")", "in", "[", "'time'", ",", "'year'", ",", "'duration'", ",", "'decade'", ",", "'weekday'", ",", "'location'", ",", "'path'", ",", "'destination'", "]", ")", "and", "type", "(", "v", "[", "1", "]", ")", "==", "tuple", "and", "(", "v", "[", "1", "]", "not", "in", "g", ".", "abandon_wordidx", ")", ")", "]", "\n", "if", "len", "(", "positive_nodes", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "example", "[", "'positive_edges'", "]", "[", "k", "]", "=", "positive_nodes", "\n", "useful_nodes", ".", "extend", "(", "positive_nodes", ")", "\n", "", "useful_nodes", "=", "list", "(", "set", "(", "useful_nodes", ")", ")", "\n", "for", "k", "in", "edges", ":", "\n", "            ", "try", ":", "\n", "                ", "example", "[", "'negative_edges'", "]", "[", "k", "]", "=", "minus_list", "(", "useful_nodes", ",", "example", "[", "'positive_edges'", "]", "[", "k", "]", "+", "[", "k", "]", "+", "g", ".", "abandon_wordidx", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "", "", "if", "len", "(", "example", "[", "'positive_edges'", "]", ")", ">", "1", ":", "\n", "            ", "examples", ".", "append", "(", "example", ")", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.InputExample.__init__": [[38, 58], ["None"], "methods", ["None"], ["\n", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "triggerL", "=", "triggerL", "\n", "self", ".", "triggerR", "=", "triggerR", "\n", "self", ".", "label", "=", "label", "\n", "\n", "", "", "class", "InputContrastExample", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "example_id", ",", "tokens", ",", "triggerL", ",", "triggerR", ",", "argL", ",", "argR", ",", "neg_meta_t", ",", "neg_meta_a_t", ",", "neg_meta_a_a", ")", ":", "\n", "        ", "\"\"\"Constructs a Input Contrast Example.\n        \"\"\"", "\n", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "triggerL", "=", "triggerL", "\n", "self", ".", "triggerR", "=", "triggerR", "\n", "self", ".", "argL", "=", "argL", "\n", "self", ".", "argR", "=", "argR", "\n", "self", ".", "neg_meta_t", "=", "neg_meta_t", "\n", "self", ".", "neg_meta_a_t", "=", "neg_meta_a_t", "\n", "self", ".", "neg_meta_a_a", "=", "neg_meta_a_a", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.InputFeatures.__init__": [[61, 72], ["None"], "methods", ["None"], ["input_ids", ",", "input_mask", ",", "segment_ids", ",", "trigger_mask", ",", "arg_mask", ",", "none_arg_mask", ",", "none_arg_length_mask", ",", "lm_masked_labels", ")", ":", "\n", "        ", "self", ".", "example_id", "=", "example_id", "\n", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "trigger_mask", "=", "trigger_mask", "\n", "self", ".", "arg_mask", "=", "arg_mask", "\n", "self", ".", "none_arg_mask", "=", "none_arg_mask", "\n", "self", ".", "none_arg_length_mask", "=", "none_arg_length_mask", "\n", "self", ".", "lm_masked_labels", "=", "lm_masked_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.DataProcessor.get_train_examples": [[77, 80], ["NotImplementedError"], "methods", ["None"], ["", "", "class", "InputFeatures", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "example_id", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "maskL", ",", "maskR", ",", "label", ")", ":", "\n", "        ", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "input_ids", "=", "input_ids", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.DataProcessor.get_dev_examples": [[81, 84], ["NotImplementedError"], "methods", ["None"], ["self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "maskL", "=", "maskL", "\n", "self", ".", "maskR", "=", "maskR", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.DataProcessor.get_test_examples": [[85, 88], ["NotImplementedError"], "methods", ["None"], ["self", ".", "label", "=", "label", "\n", "\n", "\n", "", "", "class", "DataProcessor", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.DataProcessor.get_labels": [[89, 92], ["NotImplementedError"], "methods", ["None"], ["    ", "\"\"\"Base class for data converters for multiple choice data sets.\"\"\"", "\n", "\n", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_train_examples": [[97, 101], ["logger.info", "utils_ee.ACEProcessor._create_examples", "json.load", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor._create_examples"], ["raise", "NotImplementedError", "(", ")", "\n", "\n", "", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the test set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_dev_examples": [[102, 108], ["logger.info", "utils_ee.ACEProcessor._create_examples", "open", "json.load", "os.path.join", "json.load", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor._create_examples"], ["\n", "", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "def", "get_MI_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_test_examples": [[109, 115], ["logger.info", "utils_ee.ACEProcessor._create_examples", "open", "json.load", "os.path.join", "json.load", "open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor._create_examples"], ["\n", "", "def", "_create_examples", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "\n", "", "", "class", "ACEProcessor", "(", "DataProcessor", ")", ":", "\n", "    ", "\"\"\"Processor for the RACE data set.\"\"\"", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_labels": [[116, 119], ["None"], "methods", ["None"], ["\n", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} train\"", ".", "format", "(", "data_dir", ")", ")", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_eventTypes": [[120, 122], ["None"], "methods", ["None"], ["self", ".", "train", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train.json'", ")", ",", "\"r\"", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "train", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor._create_examples": [[123, 153], ["enumerate", "enumerate", "examples.append", "utils_ee.ACEProcessor.get_eventTypes", "utils_ee.InputExample"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_eventTypes"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} dev\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'dev.json'", ")", ",", "\"r\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n", "", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {} test\"", ".", "format", "(", "data_dir", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'test.json'", ")", ",", "\"r\"", ")", ")", ",", "\"test\"", ")", "\n", "\n", "", "def", "get_contrast_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"LOOKING AT {} train contrast\"", ".", "format", "(", "data_dir", ")", ")", "\n", "lines", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'contrast_examples.pkl'", ")", ",", "\"rb\"", ")", ")", "\n", "pos_meta", ",", "neg_meta", "=", "self", ".", "get_contrast_meta", "(", "lines", ")", "\n", "return", "self", ".", "_create_contrast_examples", "(", "lines", ",", "pos_meta", ",", "neg_meta", ",", "\"train-contrast\"", ")", "\n", "\n", "", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "'None'", ",", "'End-Position'", ",", "'Charge-Indict'", ",", "'Convict'", ",", "'Transfer-Ownership'", ",", "'Demonstrate'", ",", "'Transport'", ",", "'Sentence'", ",", "'Appeal'", ",", "'Start-Org'", ",", "'Start-Position'", ",", "'End-Org'", ",", "'Phone-Write'", ",", "'Nominate'", ",", "'Marry'", ",", "'Pardon'", ",", "'Release-Parole'", ",", "'Meet'", ",", "'Trial-Hearing'", ",", "'Extradite'", ",", "'Execute'", ",", "'Transfer-Money'", ",", "'Elect'", ",", "'Injure'", ",", "'Acquit'", ",", "'Divorce'", ",", "'Die'", ",", "'Arrest-Jail'", ",", "'Declare-Bankruptcy'", ",", "'Be-Born'", ",", "'Merge-Org'", ",", "'Fine'", ",", "'Sue'", ",", "'Attack'", "]", "\n", "\n", "# def get_contrast_meta(self,lines):", "\n", "#     \"\"\"", "\n", "#     Get meta data for contrastive learning", "\n", "\n", "#     \"\"\"", "\n", "#     positive_meta = {}", "\n", "#     negative_meta = {}", "\n", "#     # trigger_meta = defaultdict(list)", "\n", "#     # line_idx = {}", "\n", "#     for example in lines:", "\n", "#         if example['event_type']!=\"None\":", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.convert_examples_to_features": [[155, 270], ["tqdm.tqdm", "sorted", "enumerate", "res.extend", "enumerate", "utils_ee.convert_examples_to_features.ins"], "function", ["None"], ["#             if metainfo not in positive_meta:", "\n", "\n", "#                 positive_meta[metainfo] = [defaultdict(list),defaultdict(list)]", "\n", "#                 negative_meta[metainfo] = [defaultdict(list),defaultdict(list),[]]", "\n", "\n", "\n", "#             trigger_idx = example['trigger_start']", "\n", "#             entities = example['entities']", "\n", "#             role_idxs = [(e['idx_start'],e['idx_end']) for e in entities if e['role'] != 'None']", "\n", "#             none_role_idxs = [(e['idx_start'],e['idx_end']) for e in entities if e['role'] == 'None']", "\n", "\n", "#             # trigger_meta[metainfo].append(trigger_idx)", "\n", "\n", "#             assert trigger_idx not in positive_meta[metainfo][0]", "\n", "#             assert trigger_idx not in negative_meta[metainfo][0]", "\n", "#             positive_meta[metainfo][0][trigger_idx].extend(role_idxs)       ", "\n", "#             negative_meta[metainfo][0][trigger_idx].extend(none_role_idxs)", "\n", "#             for role_idx in role_idxs:", "\n", "#                 positive_meta[metainfo][1][role_idx].append(trigger_idx)", "\n", "#             for none_role_idx in none_role_idxs:", "\n", "#                 negative_meta[metainfo][1][none_role_idx].append(trigger_idx)", "\n", "#             negative_meta[metainfo][2] = role_idxs+none_role_idxs", "\n", "\n", "#     return positive_meta,negative_meta", "\n", "\n", "", "def", "get_contrast_meta", "(", "self", ",", "lines", ")", ":", "\n", "        ", "\"\"\"\n        Get meta data for contrastive learning\n        \n        \"\"\"", "\n", "positive_meta", "=", "{", "}", "\n", "negative_meta", "=", "{", "}", "\n", "# trigger_meta = defaultdict(list)", "\n", "# line_idx = {}", "\n", "for", "example_idx", ",", "example", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "metainfo", "=", "example_idx", "\n", "if", "metainfo", "not", "in", "positive_meta", ":", "\n", "\n", "                ", "positive_meta", "[", "metainfo", "]", "=", "[", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", "]", "\n", "negative_meta", "[", "metainfo", "]", "=", "[", "defaultdict", "(", "list", ")", ",", "defaultdict", "(", "list", ")", ",", "[", "]", "]", "\n", "\n", "", "for", "node", "in", "example", "[", "'positive_edges'", "]", ".", "keys", "(", ")", ":", "\n", "                ", "trigger_idx", "=", "(", "node", "[", "0", "]", ",", "node", "[", "1", "]", "-", "1", ")", "#TODO: this part can be cleaner", "\n", "entities", "=", "example", "[", "'positive_edges'", "]", "[", "node", "]", "+", "example", "[", "'negative_edges'", "]", "[", "node", "]", "\n", "entities", "=", "[", "(", "e", "[", "0", "]", ",", "e", "[", "1", "]", "-", "1", ")", "for", "e", "in", "entities", "]", "\n", "role_idxs", "=", "[", "(", "e", "[", "0", "]", ",", "e", "[", "1", "]", "-", "1", ")", "for", "e", "in", "example", "[", "'positive_edges'", "]", "[", "node", "]", "]", "\n", "none_role_idxs", "=", "[", "(", "e", "[", "0", "]", ",", "e", "[", "1", "]", "-", "1", ")", "for", "e", "in", "example", "[", "'negative_edges'", "]", "[", "node", "]", "]", "\n", "\n", "assert", "trigger_idx", "not", "in", "positive_meta", "[", "metainfo", "]", "[", "0", "]", "\n", "assert", "trigger_idx", "not", "in", "negative_meta", "[", "metainfo", "]", "[", "0", "]", "\n", "positive_meta", "[", "metainfo", "]", "[", "0", "]", "[", "trigger_idx", "]", ".", "extend", "(", "role_idxs", ")", "\n", "negative_meta", "[", "metainfo", "]", "[", "0", "]", "[", "trigger_idx", "]", ".", "extend", "(", "none_role_idxs", ")", "\n", "for", "role_idx", "in", "role_idxs", ":", "\n", "                    ", "positive_meta", "[", "metainfo", "]", "[", "1", "]", "[", "role_idx", "]", ".", "append", "(", "trigger_idx", ")", "\n", "", "for", "none_role_idx", "in", "none_role_idxs", ":", "\n", "                    ", "negative_meta", "[", "metainfo", "]", "[", "1", "]", "[", "none_role_idx", "]", ".", "append", "(", "trigger_idx", ")", "\n", "", "negative_meta", "[", "metainfo", "]", "[", "2", "]", ".", "extend", "(", "role_idxs", "+", "none_role_idxs", ")", "\n", "\n", "", "", "return", "positive_meta", ",", "negative_meta", "\n", "\n", "\n", "# def _create_contrast_examples(self,lines,pos_meta, neg_meta, set_type):", "\n", "#     \"\"\"", "\n", "#     Create examples for contrastive training", "\n", "#     \"\"\"", "\n", "\n", "#     examples = []", "\n", "#     for (idx, data_raw) in enumerate(lines):", "\n", "#         if data_raw['event_type']!=\"None\":", "\n", "#             metainfo = (data_raw['start'],data_raw['end'],data_raw['file'],data_raw['dir'])", "\n", "#             for idx2, entity in enumerate(data_raw['entities']):", "\n", "#                 if entity['role']!=\"None\":", "\n", "#                     e_id = \"%s-%s-%s\" % (set_type, idx,idx2)", "\n", "#                     examples.append(", "\n", "#                         InputContrastExample(", "\n", "#                             example_id=e_id,", "\n", "#                             tokens=data_raw['tokens'],", "\n", "#                             triggerL=data_raw['trigger_start'],", "\n", "#                             triggerR=data_raw['trigger_end'],", "\n", "#                             argL=entity['idx_start'],", "\n", "#                             argR=entity['idx_end'],", "\n", "#                             neg_meta_t = neg_meta[metainfo][0][data_raw['trigger_start']],", "\n", "#                             neg_meta_a_t= neg_meta[metainfo][1][(entity['idx_start'],entity['idx_end'])],", "\n", "#                             neg_meta_a_a = [e for e in neg_meta[metainfo][2]]", "\n", "#                         )", "\n", "#                     )", "\n", "#     return examples", "\n", "", "def", "_create_contrast_examples", "(", "self", ",", "lines", ",", "pos_meta", ",", "neg_meta", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"\n        Create examples for contrastive training\n        \"\"\"", "\n", "\n", "examples", "=", "[", "]", "\n", "for", "(", "idx", ",", "data_raw", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "\n", "            ", "metainfo", "=", "idx", "\n", "for", "idx_t", ",", "t", "in", "enumerate", "(", "list", "(", "data_raw", "[", "'positive_edges'", "]", ".", "keys", "(", ")", ")", ")", ":", "\n", "                ", "for", "idx2", ",", "entity", "in", "enumerate", "(", "data_raw", "[", "'positive_edges'", "]", "[", "t", "]", ")", ":", "\n", "                    ", "e_id", "=", "\"%s-%s-%s-%s\"", "%", "(", "set_type", ",", "idx", ",", "idx_t", ",", "idx2", ")", "\n", "examples", ".", "append", "(", "\n", "InputContrastExample", "(", "\n", "example_id", "=", "e_id", ",", "\n", "tokens", "=", "data_raw", "[", "'tokens'", "]", ",", "\n", "triggerL", "=", "t", "[", "0", "]", ",", "\n", "triggerR", "=", "t", "[", "1", "]", "-", "1", ",", "\n", "argL", "=", "entity", "[", "0", "]", ",", "\n", "argR", "=", "entity", "[", "1", "]", "-", "1", ",", "\n", "neg_meta_t", "=", "neg_meta", "[", "metainfo", "]", "[", "0", "]", "[", "(", "t", "[", "0", "]", ",", "t", "[", "1", "]", "-", "1", ")", "]", ",", "\n", "neg_meta_a_t", "=", "neg_meta", "[", "metainfo", "]", "[", "1", "]", "[", "(", "entity", "[", "0", "]", ",", "entity", "[", "1", "]", "-", "1", ")", "]", ",", "\n", "neg_meta_a_a", "=", "[", "e", "for", "e", "in", "neg_meta", "[", "metainfo", "]", "[", "2", "]", "]", "\n", ")", "\n", ")", "\n", "", "", "", "return", "examples", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.model.DMBERT.__init__": [[9, 15], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.model.DMRoBERTa.__init__"], ["import", "torch", "\n", "import", "torch", ".", "nn", "as", "nn", "\n", "import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "\n", "class", "BERTContrastive", "(", "BertPreTrainedModel", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.model.DMBERT.forward": [[15, 50], ["input_ids.size", "model.DMBERT.roberta", "conved.transpose.transpose.transpose", "conved.transpose.transpose.transpose", "model.DMBERT.maxpooling().contiguous().view", "model.DMBERT.maxpooling().contiguous().view", "model.DMBERT.maxpooling().contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.DMBERT.dropout", "model.DMBERT.classifier", "model.DMBERT.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "model.DMBERT.maxpooling().contiguous", "model.DMBERT.maxpooling().contiguous", "model.DMBERT.maxpooling().contiguous", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "model.DMBERT.maxpooling", "model.DMBERT.maxpooling", "model.DMBERT.maxpooling"], "methods", ["None"], ["        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "W", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "trigger_mask", "=", "None", ",", "arg_mask", "=", "None", ",", "none_arg_mask", "=", "None", ",", "none_arg_length_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "# [bs, length, emd] ", "\n", "input_ids", ",", "# [batch,length]", "\n", "attention_mask", "=", "attention_mask", ",", "# padding", "\n", "token_type_ids", "=", "token_type_ids", ",", "# sentence segmentation", "\n", "position_ids", "=", "position_ids", ",", "# position emebedding", "\n", "head_mask", "=", "head_mask", ",", "# \uff1f", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "# lookup mat", "\n", ")", "[", "0", "]", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "outputs", ")", ")", "==", "0", "\n", "trigger_mask", "=", "torch", ".", "unsqueeze", "(", "trigger_mask", ",", "dim", "=", "2", ")", "#[bs,length, 1]", "\n", "trigger_reps", "=", "outputs", "*", "trigger_mask", "#[bs,length, emd]", "\n", "trigger_reps", "=", "torch", ".", "sum", "(", "trigger_reps", ",", "dim", "=", "1", ")", "#[bs, emd]", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "trigger_reps", "=", "trigger_reps", "/", "torch", ".", "sum", "(", "trigger_mask", ",", "dim", "=", "1", ")", "#[bs, emd]", "\n", "trigger_reps", "=", "self", ".", "linear", "(", "trigger_reps", ")", "\n", "trigger_reps", "=", "trigger_reps", "/", "(", "torch", ".", "norm", "(", "trigger_reps", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "\n", "arg_mask", "=", "torch", ".", "unsqueeze", "(", "arg_mask", ",", "dim", "=", "2", ")", "\n", "arg_reps", "=", "outputs", "*", "arg_mask", "\n", "arg_reps", "=", "torch", ".", "sum", "(", "arg_reps", ",", "dim", "=", "1", ")", "\n", "arg_reps", "=", "arg_reps", "/", "torch", ".", "sum", "(", "arg_mask", ",", "dim", "=", "1", ")", "\n", "arg_reps", "=", "self", ".", "linear", "(", "arg_reps", ")", "\n", "arg_reps", "=", "arg_reps", "/", "(", "torch", ".", "norm", "(", "arg_reps", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "\n", "none_arg_mask", "=", "torch", ".", "unsqueeze", "(", "none_arg_mask", ",", "dim", "=", "3", ")", "#[bs, max_contras_ent, length, 1]", "\n", "outputs_un", "=", "torch", ".", "unsqueeze", "(", "outputs", ",", "dim", "=", "1", ")", "#[bs, 1, length, emd]", "\n", "none_arg_reps", "=", "outputs_un", "*", "none_arg_mask", "#[bs, max_contras_ent, length, emd]", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.model.DMRoBERTa.__init__": [[53, 59], ["transformers.BertPreTrainedModel.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.model.DMRoBERTa.__init__"], ["none_arg_reps", "=", "none_arg_reps", "/", "(", "torch", ".", "norm", "(", "none_arg_reps", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "\n", "assert", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "trigger_reps", ")", ")", "==", "0", "\n", "\n", "# pos_loss = torch.sum(self.W(trigger_reps) * arg_reps,dim=1)          #[bs]", "\n", "pos_loss", "=", "torch", ".", "sum", "(", "trigger_reps", "*", "arg_reps", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.model.DMRoBERTa.forward": [[59, 94], ["input_ids.size", "model.DMRoBERTa.bert", "conved.transpose.transpose.transpose", "conved.transpose.transpose.transpose", "model.DMRoBERTa.maxpooling().contiguous().view", "model.DMRoBERTa.maxpooling().contiguous().view", "model.DMRoBERTa.maxpooling().contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.DMRoBERTa.dropout", "model.DMRoBERTa.classifier", "model.DMRoBERTa.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "model.DMRoBERTa.maxpooling().contiguous", "model.DMRoBERTa.maxpooling().contiguous", "model.DMRoBERTa.maxpooling().contiguous", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "model.DMRoBERTa.maxpooling", "model.DMRoBERTa.maxpooling", "model.DMRoBERTa.maxpooling"], "methods", ["None"], ["\n", "# neg_loss_1 = torch.mm(self.W(trigger_reps), torch.transpose(arg_reps,0,1))  #[bs,bs]", "\n", "neg_loss_1", "=", "torch", ".", "mm", "(", "trigger_reps", ",", "torch", ".", "transpose", "(", "arg_reps", ",", "0", ",", "1", ")", ")", "\n", "neg_loss_1", "=", "torch", ".", "exp", "(", "neg_loss_1", ")", "\n", "neg_loss_1", "=", "torch", ".", "sum", "(", "neg_loss_1", ",", "dim", "=", "1", ")", "#[bs]", "\n", "\n", "trigger_reps", "=", "torch", ".", "unsqueeze", "(", "trigger_reps", ",", "dim", "=", "1", ")", "\n", "# neg_loss_2 = torch.sum(self.W(trigger_reps) * none_arg_reps, dim=2) #[bs, max_contras_ent]", "\n", "neg_loss_2", "=", "torch", ".", "sum", "(", "trigger_reps", "*", "none_arg_reps", ",", "dim", "=", "2", ")", "\n", "neg_loss_2", "=", "torch", ".", "exp", "(", "neg_loss_2", ")", "*", "none_arg_length_mask", "\n", "neg_loss_2", "=", "torch", ".", "sum", "(", "neg_loss_2", ",", "dim", "=", "1", ")", "#[bs]", "\n", "\n", "loss", "=", "-", "pos_loss", "+", "torch", ".", "log", "(", "neg_loss_2", "+", "neg_loss_1", "+", "1e-8", ")", "\n", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", ")", "\n", "return", "(", "loss", ",", ")", "\n", "\n", "\n", "", "", "class", "DMBERT", "(", "BertPreTrainedModel", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "maxpooling", "=", "nn", ".", "MaxPool1d", "(", "128", ")", "#???????", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "num_labels", ")", "\n", "self", ".", "W", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "maskL", "=", "None", ",", "maskR", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "batchSize", "=", "input_ids", ".", "size", "(", "0", ")", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "# [batch,length]", "\n", "attention_mask", "=", "attention_mask", ",", "# padding", "\n", "token_type_ids", "=", "token_type_ids", ",", "# sentence segmentation", "\n", "position_ids", "=", "position_ids", ",", "# position emebedding", "\n", "head_mask", "=", "head_mask", ",", "# \uff1f", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "# lookup mat", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.calculate_scores": [[78, 117], ["range", "len", "len", "len", "len", "isinstance", "len", "run_ee.calculate_scores.is_NA"], "function", ["None"], ["if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.set_seed": [[118, 124], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.train": [[126, 284], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_ee.set_seed", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "logger.info", "any", "run_ee.evaluate", "str", "str", "run_ee.evaluate", "logger.info", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.set_seed", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.train", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.evaluate", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.evaluate"], ["logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "best_dev_f1", "=", "0.0", "\n", "best_steps", "=", "0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "best_dev_preds", "=", "[", "]", "\n", "best_test_preds", "=", "[", "]", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"maskL\"", ":", "batch", "[", "3", "]", ",", "\n", "\"maskR\"", ":", "batch", "[", "4", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "5", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", ",", "dev_pred_results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "#for key, value in results.items():", "\n", "#tb_writer.add_scalar(\"eval_{}\".format(key), value, global_step)", "\n", "if", "results", "[", "\"eval_f1\"", "]", ">", "best_dev_f1", ":", "\n", "                            ", "best_dev_f1", "=", "results", "[", "\"eval_f1\"", "]", "\n", "best_steps", "=", "global_step", "\n", "best_dev_preds", "=", "dev_pred_results", "\n", "if", "args", ".", "do_test", ":", "\n", "                                ", "results_test", ",", "test_pred_results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "test", "=", "True", ")", "\n", "best_test_preds", "=", "test_pred_results", "\n", "#for key, value in results_test.items():", "\n", "#tb_writer.add_scalar(\"test_{}\".format(key), value, global_step)", "\n", "logger", ".", "info", "(", "\n", "\"test f1: %s, loss: %s, global steps: %s\"", ",", "\n", "str", "(", "results_test", "[", "\"eval_f1\"", "]", ")", ",", "\n", "str", "(", "results_test", "[", "\"eval_loss\"", "]", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "with", "open", "(", "args", ".", "output_dir", "+", "'/best.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "                                    ", "f", ".", "write", "(", "\"best F1: {}\\n\"", ".", "format", "(", "str", "(", "results_test", "[", "\"eval_f1\"", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "\"best p: {}\\n\"", ".", "format", "(", "str", "(", "results_test", "[", "\"eval_p\"", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "\"best recall: {}\\n\"", ".", "format", "(", "str", "(", "results_test", "[", "\"eval_recall\"", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "\"best loss: {}\\n\"", ".", "format", "(", "str", "(", "results_test", "[", "\"eval_loss\"", "]", ")", ")", ")", "\n", "f", ".", "write", "(", "\"best step: {}\\n\"", ".", "format", "(", "str", "(", "best_steps", ")", ")", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "output_dir", "+", "'/pred.json'", ",", "'w'", ")", "as", "f", ":", "\n", "                                    ", "json", ".", "dump", "(", "{", "'dev'", ":", "best_dev_preds", ",", "'test'", ":", "best_test_preds", "}", ",", "f", ")", "\n", "\n", "#tb_writer.add_scalar(\"lr\", scheduler.get_lr()[0], global_step)", "\n", "#tb_writer.add_scalar(\"loss\", (tr_loss - logging_loss) / args.logging_steps, global_step)", "\n", "", "", "", "", "logger", ".", "info", "(", "\n", "\"Average loss: %s at global step: %s\"", ",", "\n", "str", "(", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "# if args.local_rank in [-1, 0] and args.save_steps > 0 and global_step % args.save_steps == 0:", "\n", "#     # Save model checkpoint", "\n", "#     output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))", "\n", "#     if not os.path.exists(output_dir):", "\n", "#         os.makedirs(output_dir)", "\n", "#     model_to_save = (", "\n", "#         model.module if hasattr(model, \"module\") else model", "\n", "#     )  # Take care of distributed/parallel training", "\n", "#     model_to_save.save_pretrained(output_dir)", "\n", "#     tokenizer.save_vocabulary(output_dir)", "\n", "#     torch.save(args, os.path.join(output_dir, \"training_args.bin\"))", "\n", "#     logger.info(\"Saving model checkpoint to %s\", output_dir)", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#tb_writer.close()", "\n", "\n", "", "", "return", "global_step", ",", "tr_loss", "/", "global_step", ",", "best_steps", "\n", "\n", "", "def", "pretrain", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "test_dataset", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#tb_writer = SummaryWriter()", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.evaluate": [[286, 381], ["zip", "run_ee.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "numpy.argmax", "run_ee.calculate_scores", "results.update", "os.path.join", "os.makedirs", "max", "len", "model.eval", "tuple", "batch[].detach().cpu().numpy", "batch[].detach().cpu().numpy", "open", "logger.info", "writer.write", "writer.write", "writer.write", "writer.write", "writer.write", "sorted", "os.path.exists", "torch.no_grad", "model", "tmp_eval_loss.mean().item", "numpy.append", "numpy.append", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "result.keys", "logger.info", "writer.write", "t.to", "batch[].detach().cpu", "batch[].detach().cpu", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "str().lower", "str", "str", "tmp_eval_loss.mean", "logits.detach().cpu", "inputs[].detach().cpu", "str", "batch[].detach", "batch[].detach", "logits.detach().cpu", "inputs[].detach().cpu", "str", "str", "torch.distributed.get_world_size", "str", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.load_and_cache_examples", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.calculate_scores"], [")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "con_tr_loss", ",", "con_logging_loss", "=", "0.0", ",", "0.0", "\n", "lm_tr_loss", ",", "lm_logging_loss", "=", "0.0", ",", "0.0", "\n", "best_dev_f1", "=", "0.0", "\n", "min_eval_loss", "=", "-", "1", "\n", "best_steps", "=", "0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"trigger_mask\"", ":", "batch", "[", "3", "]", ",", "\n", "\"arg_mask\"", ":", "batch", "[", "4", "]", ",", "\n", "\"none_arg_mask\"", ":", "batch", "[", "5", "]", ",", "\n", "\"none_arg_length_mask\"", ":", "batch", "[", "6", "]", ",", "\n", "'masked_lm_labels'", ":", "batch", "[", "7", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "# loss = outputs[0] + outputs[1]  # model outputs are always tuple in transformers (see doc)", "\n", "\n", "con_loss", "=", "outputs", "[", "0", "]", "\n", "lm_loss", "=", "outputs", "[", "1", "]", "\n", "loss", "=", "con_loss", "+", "lm_loss", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "con_loss", "=", "con_loss", ".", "mean", "(", ")", "\n", "lm_loss", "=", "lm_loss", ".", "mean", "(", ")", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "con_loss", "=", "con_loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "lm_loss", "=", "lm_loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "con_tr_loss", "+=", "con_loss", ".", "item", "(", ")", "\n", "lm_tr_loss", "+=", "lm_loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "\n", "                    ", "eval_loss", "=", "pretrain_evaluate", "(", "args", ",", "test_dataset", ",", "model", ",", "tokenizer", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "\"Average loss: %s, con_loss: %s, lm_loss: %s, eval_loss: %s, at global step: %s\"", ",", "\n", "str", "(", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ")", ",", "\n", "str", "(", "(", "con_tr_loss", "-", "con_logging_loss", ")", "/", "args", ".", "logging_steps", ")", ",", "\n", "str", "(", "(", "lm_tr_loss", "-", "lm_logging_loss", ")", "/", "args", ".", "logging_steps", ")", ",", "\n", "str", "(", "eval_loss", ")", ",", "\n", "str", "(", "global_step", ")", ",", "\n", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "con_logging_loss", "=", "con_tr_loss", "\n", "lm_logging_loss", "=", "lm_tr_loss", "\n", "if", "eval_loss", "<", "min_eval_loss", "or", "min_eval_loss", "==", "-", "1", ":", "\n", "                        ", "best_steps", "=", "global_step", "+", "0", "\n", "min_eval_loss", "=", "eval_loss", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.load_and_cache_examples": [[383, 447], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "processor.get_labels", "processor.get_eventTypes", "logger.info", "utils_ee.convert_examples_to_features", "torch.distributed.barrier", "list().pop", "str", "str", "processor.get_dev_examples", "str", "logger.info", "torch.save", "processor.get_test_examples", "processor.get_train_examples", "len", "bool", "list", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_labels", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_eventTypes", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.convert_examples_to_features", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_dev_examples", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_test_examples", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_train_examples"], ["", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"best_steps.txt\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                            ", "f", ".", "write", "(", "'best step at:'", "+", "str", "(", "best_steps", ")", "+", "'\\n'", ")", "\n", "f", ".", "write", "(", "'eval_loss:'", "+", "str", "(", "eval_loss", ")", ")", "\n", "\n", "", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", ".", "roberta", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", ".", "roberta", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "#if args.local_rank in [-1, 0]:", "\n", "#tb_writer.close()", "\n", "\n", "", "", "return", "global_step", ",", "tr_loss", "/", "global_step", ",", "best_steps", ",", "min_eval_loss", "\n", "\n", "", "def", "pretrain_evaluate", "(", "args", ",", "eval_dataset", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ",", "test", "=", "False", ")", ":", "\n", "\n", "    ", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "eval_loss", "=", "0.0", "\n", "step", "=", "0", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"trigger_mask\"", ":", "batch", "[", "3", "]", ",", "\n", "\"arg_mask\"", ":", "batch", "[", "4", "]", ",", "\n", "\"none_arg_mask\"", ":", "batch", "[", "5", "]", ",", "\n", "\"none_arg_length_mask\"", ":", "batch", "[", "6", "]", ",", "\n", "'masked_lm_labels'", ":", "batch", "[", "7", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "eval_loss", "+=", "(", "outputs", "[", "0", "]", "+", "outputs", "[", "1", "]", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "step", "+=", "1", "\n", "\n", "", "return", "eval_loss", "/", "step", "\n", "\n", "\n", "", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ",", "test", "=", "False", ")", ":", "\n", "    ", "eval_task_names", "=", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", ")", "\n"]], "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.main": [[449, 771], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.exists", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "os.path.exists", "ValueError", "os.listdir", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "logging.basicConfig", "logger.warning", "run_ee.set_seed", "parser.parse_args.task_name.lower", "processor.get_labels", "len", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "os.path.exists", "os.listdir", "ValueError", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "model.DMRoBERTa", "ValueError", "torch.distributed.barrier", "run_ee.load_and_cache_examples", "run_ee.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "model_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "logger.info", "logger.info", "torch.cuda.device_count", "bool", "os.makedirs", "hasattr", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_ee.evaluate", "dict", "results.update", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_ee.evaluate", "dict", "results.update", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "utils_ee.processors.keys", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.set_seed", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.utils_ee.ACEProcessor.get_labels", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.load_and_cache_examples", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.train", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.evaluate", "home.repos.pwc.inspect_result.THU-KEG_CLEVE.EAE.run_ee.evaluate"], ["pred_results", "=", "[", "]", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "eval_dataset", ",", "eval_ids", "=", "load_and_cache_examples", "(", "args", ",", "eval_task", ",", "tokenizer", ",", "evaluate", "=", "not", "test", ",", "test", "=", "test", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "#if args.n_gpu > 1:", "\n", "#print(\"?????\",args.n_gpu)", "\n", "#model = torch.nn.DataParallel(model)", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "\n", "else", "None", ",", "# XLM don't use segment_ids", "\n", "\"maskL\"", ":", "batch", "[", "3", "]", ",", "\n", "\"maskR\"", ":", "batch", "[", "4", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "5", "]", ",", "\n", "}", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "#print(eval_task)", "\n", "#print(processors[eval_task])", "\n", "pred_results", ".", "extend", "(", "preds", ".", "tolist", "(", ")", ")", "\n", "precision", ",", "recall", ",", "f1", "=", "calculate_scores", "(", "preds", ",", "out_label_ids", ",", "len", "(", "processors", "[", "eval_task", "]", "(", ")", ".", "get_labels", "(", ")", ")", ")", "\n", "result", "=", "{", "\"eval_p\"", ":", "precision", ",", "\"eval_recall\"", ":", "recall", ",", "\"eval_f1\"", ":", "f1", ",", "\"eval_loss\"", ":", "eval_loss", "}", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "\"is_test_\"", "+", "str", "(", "test", ")", ".", "lower", "(", ")", "+", "\"_eval_results.txt\"", ")", "\n", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "str", "(", "prefix", ")", "+", "\" is test:\"", "+", "str", "(", "test", ")", ")", ")", "\n", "writer", ".", "write", "(", "\"model           =%s\\n\"", "%", "str", "(", "args", ".", "model_name_or_path", ")", ")", "\n", "writer", ".", "write", "(", "\n", "\"total batch size=%d\\n\"", "\n", "%", "(", "\n", "args", ".", "per_gpu_train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", "\n", ")", "\n", ")", "\n", "writer", ".", "write", "(", "\"train num epochs=%d\\n\"", "%", "args", ".", "num_train_epochs", ")", "\n", "writer", ".", "write", "(", "\"fp16            =%s\\n\"", "%", "args", ".", "fp16", ")", "\n", "writer", ".", "write", "(", "\"max seq length  =%d\\n\"", "%", "args", ".", "max_seq_length", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "", "", "assert", "len", "(", "eval_ids", ")", "==", "len", "(", "pred_results", ")", "\n", "", "return", "results", ",", "dict", "(", "list", "(", "zip", "(", "eval_ids", ",", "pred_results", ")", ")", ")", "\n", "\n", "", "def", "load_and_cache_contrast_examples", "(", "args", ",", "task", ",", "tokenizer", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "# Load data features from cache or dataset file", "\n", "cached_mode", "=", "\"pretrain_contrast\"", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"contrast_cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "cached_mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading contrast features from cached file %s\"", ",", "cached_features_file", ")", "\n", "train_contrast_features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "test_contrast_features", "=", "torch", ".", "load", "(", "cached_features_file", "+", "'_test'", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating contrast features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "\n", "contrast_examples", "=", "processor", ".", "get_contrast_examples", "(", "args", ".", "data_dir", ")", "\n", "\n", "contrast_features", "=", "convert_contrast_examples_to_features", "(", "\n", "contrast_examples", ",", "\n", "args", ".", "max_seq_length", ",", "\n", "args", ".", "max_contrast_entity_per_sentence", ",", "\n", "tokenizer", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", ")", "\n", "\n", "feature_len", "=", "int", "(", "len", "(", "contrast_features", ")", "/", "10", "*", "8", ")", "\n", "\n", "train_contrast_features", "=", "contrast_features", "[", ":", "feature_len", "]", "\n", "test_contrast_features", "=", "contrast_features", "[", "feature_len", ":", "]", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "train_contrast_features", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "test_contrast_features", ",", "cached_features_file", "+", "\"_test\"", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_trigger_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "trigger_mask", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_arg_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "arg_mask", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_none_arg_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "none_arg_mask", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_none_arg_length_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "none_arg_length_mask", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_lm_masked_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "lm_masked_labels", "for", "f", "in", "train_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "train_dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_trigger_mask", ",", "all_arg_mask", ",", "all_none_arg_mask", ",", "all_none_arg_length_mask", ",", "all_lm_masked_labels", ")", "\n", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_trigger_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "trigger_mask", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_arg_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "arg_mask", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_none_arg_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "none_arg_mask", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_none_arg_length_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "none_arg_length_mask", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_lm_masked_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "lm_masked_labels", "for", "f", "in", "test_contrast_features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "test_dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_trigger_mask", ",", "all_arg_mask", ",", "all_none_arg_mask", ",", "all_none_arg_length_mask", ",", "all_lm_masked_labels", ")", "\n", "\n", "return", "train_dataset", ",", "test_dataset", "\n", "\n", "", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "test", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "# Load data features from cache or dataset file", "\n", "if", "evaluate", ":", "\n", "        ", "cached_mode", "=", "\"dev\"", "\n", "", "elif", "test", ":", "\n", "        ", "cached_mode", "=", "\"test\"", "\n", "", "else", ":", "\n", "        ", "cached_mode", "=", "\"train\"", "\n", "", "assert", "not", "(", "evaluate", "and", "test", ")", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}_{}\"", ".", "format", "(", "\n", "cached_mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "if", "evaluate", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ")", "\n", "", "elif", "test", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "args", ".", "data_dir", ")", "\n", "", "else", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ")", "\n", "", "logger", ".", "info", "(", "\"Training number: %s\"", ",", "str", "(", "len", "(", "examples", ")", ")", ")", "\n", "\n", "features", "=", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "label_list", ",", "\n", "args", ".", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_maskL", "=", "torch", ".", "tensor", "(", "[", "f", ".", "maskL", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_maskR", "=", "torch", ".", "tensor", "(", "[", "f", ".", "maskR", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_maskL", ",", "all_maskR", ",", "all_label_ids", ")", "\n", "if", "evaluate", "or", "test", ":", "\n", "        ", "return", "dataset", ",", "[", "f", ".", "example_id", "for", "f", "in", "features", "]", "\n", "", "else", ":", "\n", "        ", "return", "dataset", "\n", "\n", "\n", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the .tsv files (or other data files) for the task.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "+", "\", \"", ".", "join", "(", "ALL_MODELS", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train selected in the list: \"", "+", "\", \"", ".", "join", "(", "processors", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_contrast_entity_per_sentence\"", ",", "\n", "default", "=", "10", ",", "\n", "type", "=", "int", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Max contrast entity per sentence in contrastive pretraining stage.\"", ",", "\n", ")", "\n", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_pretrain\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to pretrain using MI.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run test on the test set\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_positive_batch_size\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for positive pretrain\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_negativex_batch_size\"", ",", "default", "=", "3", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for negativex pretrain\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_negativey_batch_size\"", ",", "default", "=", "3", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for negativey pretrain\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_pretrain_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of pretraining epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--positive_max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of pretraining steps to perform. Override num_pretrain_epochs.\"", ",", "\n", ")", "\n", "\n"]]}