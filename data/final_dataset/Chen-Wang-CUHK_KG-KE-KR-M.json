{"home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.translate.main": [[13, 22], ["onmt.translate.translator.build_translator", "onmt.translate.translator.build_translator.translate"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.build_translator", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator.translate"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "translator", "=", "build_translator", "(", "opt", ",", "report_score", "=", "True", ")", "\n", "translator", ".", "translate", "(", "src_path", "=", "opt", ".", "src", ",", "\n", "rk_path", "=", "opt", ".", "retrieved_keys", ",", "\n", "key_indicator_path", "=", "opt", ".", "key_indicators", ",", "\n", "tgt_path", "=", "opt", ".", "tgt", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "attn_debug", "=", "opt", ".", "attn_debug", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.data_utils.get_tokens": [[10, 27], ["re.sub", "list", "filter", "re.sub.split", "filter", "re.split", "re.match", "len"], "function", ["None"], ["def", "get_tokens", "(", "text", ",", "fine_grad", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Need use the same word tokenizer between keywords and source context\n    keep [_<>,\\(\\)\\.\\'%], replace digits to <digit>, split by [^a-zA-Z0-9_<>,\\(\\)\\.\\'%]\n    \"\"\"", "\n", "text", "=", "re", ".", "sub", "(", "r'[\\r\\n\\t]'", ",", "''", ",", "text", ")", "\n", "text", "=", "''", ".", "join", "(", "list", "(", "filter", "(", "lambda", "x", ":", "x", "in", "PRINTABLE", ",", "text", ")", ")", ")", "\n", "if", "fine_grad", ":", "\n", "# tokenize by non-letters", "\n", "# Although we have will use corenlp for tokenizing later,", "\n", "# we still use the following tokenizer for fine granularity", "\n", "        ", "tokens", "=", "filter", "(", "lambda", "w", ":", "len", "(", "w", ")", ">", "0", ",", "re", ".", "split", "(", "r'[^a-zA-Z0-9_<>,\\(\\)\\.\\'%]'", ",", "text", ")", ")", "\n", "", "else", ":", "\n", "        ", "tokens", "=", "text", ".", "split", "(", ")", "\n", "# replace the digit terms with <digit>", "\n", "", "tokens", "=", "[", "w", "if", "not", "re", ".", "match", "(", "'^\\d+$'", ",", "w", ")", "else", "DIGIT", "for", "w", "in", "tokens", "]", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.data_utils.process_keyphrase": [[29, 46], ["keyword_str.replace", "re.sub.replace", "re.sub", "data_utils.get_tokens", "keyword.strip", "re.sub.split", "len", "len"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.data_utils.get_tokens"], ["", "def", "process_keyphrase", "(", "keyword_str", ",", "limit_num", "=", "True", ",", "fine_grad", "=", "True", ")", ":", "\n", "# replace some noise characters", "\n", "    ", "keyphrases", "=", "keyword_str", ".", "replace", "(", "'?'", ",", "''", ")", "\n", "# retrieved keyphrases are split by '<eos>'", "\n", "keyphrases", "=", "keyphrases", ".", "replace", "(", "'<eos>'", ",", "';'", ")", "\n", "# replace abbreviations", "\n", "keyphrases", "=", "re", ".", "sub", "(", "r'\\(.*?\\)'", ",", "''", ",", "keyphrases", ")", "\n", "# Note: keyword should be applied the same tokenizer as the source did", "\n", "keyphrases", "=", "[", "get_tokens", "(", "keyword", ".", "strip", "(", ")", ",", "fine_grad", ")", "for", "keyword", "in", "keyphrases", ".", "split", "(", "';'", ")", "]", "\n", "\n", "# ['key1a key1b', 'key2a key2b']", "\n", "if", "limit_num", ":", "\n", "        ", "keyphrases", "=", "[", "' '", ".", "join", "(", "key", ")", "for", "key", "in", "keyphrases", "if", "0", "<", "len", "(", "key", ")", "<=", "MAX_KEYWORD_LEN", "]", "\n", "", "else", ":", "\n", "        ", "keyphrases", "=", "[", "' '", ".", "join", "(", "key", ")", "for", "key", "in", "keyphrases", "if", "0", "<", "len", "(", "key", ")", "]", "\n", "\n", "", "return", "keyphrases", "\n", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.train.main": [[14, 25], ["AssertionError", "AssertionError", "len", "onmt.train_multi.main", "onmt.train_single.main"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.main", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.main"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "rnn_type", "==", "\"SRU\"", "and", "not", "opt", ".", "gpuid", ":", "\n", "        ", "raise", "AssertionError", "(", "\"Using SRU requires -gpuid set.\"", ")", "\n", "\n", "", "if", "opt", ".", "epochs", ":", "\n", "        ", "raise", "AssertionError", "(", "\"-epochs is deprecated please use -train_steps.\"", ")", "\n", "\n", "", "if", "len", "(", "opt", ".", "gpuid", ")", ">", "1", ":", "\n", "        ", "multi_main", "(", "opt", ")", "\n", "", "else", ":", "\n", "        ", "single_main", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.merge_rerank.get_extracted_keys_fr_line": [[18, 59], ["src_line.strip().split.strip().split", "float", "max", "len", "len", "len", "len", "ex_keys.append", "ex_probs.append", "round", "len", "src_line.strip().split.strip", "sel_probs_line.strip().split", "max", "sorted", "ex_key.append", "ex_prob.append", "len", "ex_keys.append", "ex_probs.append", "sum", "len", "zip", "sel_probs_line.strip"], "function", ["None"], ["def", "get_extracted_keys_fr_line", "(", "src_line", ",", "sel_probs_line", ",", "prob_th", "=", "0.7", ",", "ratio_th", "=", "0.3", ")", ":", "\n", "    ", "ex_keys", "=", "[", "]", "\n", "ex_probs", "=", "[", "]", "\n", "src_line", "=", "src_line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "sel_probs_line", "=", "[", "float", "(", "prob", ")", "for", "prob", "in", "sel_probs_line", ".", "strip", "(", ")", ".", "split", "(", "' ; '", ")", "]", "\n", "if", "max", "(", "sel_probs_line", ")", "<", "prob_th", ":", "\n", "        ", "prob_th", "=", "max", "(", "sel_probs_line", ")", "*", "0.8", "\n", "", "assert", "len", "(", "src_line", ")", "==", "len", "(", "sel_probs_line", ")", "\n", "idx", "=", "0", "\n", "previous_idx", "=", "-", "1", "\n", "ex_key", "=", "[", "]", "\n", "ex_prob", "=", "[", "]", "\n", "while", "idx", "<", "len", "(", "src_line", ")", ":", "\n", "        ", "if", "sel_probs_line", "[", "idx", "]", ">=", "prob_th", ":", "\n", "            ", "if", "idx", "==", "(", "previous_idx", "+", "1", ")", "or", "previous_idx", "==", "-", "1", ":", "\n", "                ", "ex_key", ".", "append", "(", "src_line", "[", "idx", "]", ")", "\n", "ex_prob", ".", "append", "(", "sel_probs_line", "[", "idx", "]", ")", "\n", "", "else", ":", "\n", "                ", "ex_key", "=", "[", "src_line", "[", "idx", "]", "]", "\n", "ex_prob", "=", "[", "sel_probs_line", "[", "idx", "]", "]", "\n", "", "previous_idx", "=", "idx", "\n", "", "elif", "len", "(", "ex_key", ")", "!=", "0", ":", "\n", "            ", "ex_keys", ".", "append", "(", "' '", ".", "join", "(", "ex_key", ")", ")", "\n", "ex_probs", ".", "append", "(", "ex_prob", ")", "\n", "\n", "previous_idx", "=", "-", "1", "\n", "ex_key", "=", "[", "]", "\n", "ex_prob", "=", "[", "]", "\n", "", "idx", "+=", "1", "\n", "", "if", "len", "(", "ex_key", ")", "!=", "0", ":", "\n", "        ", "ex_keys", ".", "append", "(", "' '", ".", "join", "(", "ex_key", ")", ")", "\n", "ex_probs", ".", "append", "(", "ex_prob", ")", "\n", "\n", "", "mean_ex_probs", "=", "[", "round", "(", "sum", "(", "ex_prob", ")", "/", "len", "(", "ex_prob", ")", ",", "5", ")", "for", "ex_prob", "in", "ex_probs", "]", "\n", "ranked_ex_keys_pair", "=", "[", "(", "x", ",", "prob", ")", "for", "x", ",", "prob", "in", "\n", "sorted", "(", "zip", "(", "ex_keys", ",", "mean_ex_probs", ")", ",", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "reverse", "=", "True", ")", "]", "\n", "ranked_ex_keys", "=", "[", "pair", "[", "0", "]", "for", "pair", "in", "ranked_ex_keys_pair", "]", "\n", "ranked_ex_probs", "=", "[", "pair", "[", "1", "]", "for", "pair", "in", "ranked_ex_keys_pair", "]", "\n", "assert", "len", "(", "ranked_ex_keys", ")", "!=", "0", "\n", "\n", "return", "ranked_ex_keys", ",", "ranked_ex_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.merge_rerank.get_extracted_keys": [[61, 72], ["open", "open.readlines", "open", "open.readlines", "open", "zip", "merge_rerank.get_extracted_keys_fr_line", "open.write"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.merge_rerank.get_extracted_keys_fr_line"], ["", "def", "get_extracted_keys", "(", "opt", ")", ":", "\n", "    ", "src_file", "=", "open", "(", "opt", ".", "src", ",", "encoding", "=", "'utf-8'", ")", "\n", "src_lines", "=", "src_file", ".", "readlines", "(", ")", "\n", "sel_probs", "=", "open", "(", "opt", ".", "sel_probs", ",", "encoding", "=", "'utf-8'", ")", "\n", "sel_probs_lines", "=", "sel_probs", ".", "readlines", "(", ")", "\n", "\n", "sel_keys_out", "=", "open", "(", "opt", ".", "sel_keys_output", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "for", "src_line", ",", "sel_probs_line", "in", "zip", "(", "src_lines", ",", "sel_probs_lines", ")", ":", "\n", "        ", "ex_keys", ",", "ex_probs", "=", "get_extracted_keys_fr_line", "(", "src_line", ",", "sel_probs_line", ")", "\n", "# mul_ex_probs = [round(numpy.prod(ex_prob), 5) for ex_prob in ex_probs]", "\n", "sel_keys_out", ".", "write", "(", "' ; '", ".", "join", "(", "ex_keys", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.merge_rerank.main1": [[74, 277], ["onmt.reranker.reranker_scorer.build_reranker_scorer", "open", "open.readlines", "open", "open.readlines", "logger.info", "open", "open.readlines", "open", "open.readlines", "open", "open", "open", "int", "range", "open.close", "open.close", "open.close", "logger.info", "evaluation_utils.evaluate_func", "len", "len", "len", "len", "open", "open.readlines", "open", "open.readlines", "open", "open.readlines", "len", "len", "min", "len", "zip", "len", "len", "len", "int", "range", "zip", "set", "open.write", "open.write", "len", "len", "len", "len", "logger.info", "tgt_line.strip().split", "gen_scores_line.strip().split", "key.strip.strip", "zip", "merge_rerank.get_extracted_keys_fr_line", "open.write", "math.ceil", "min", "onmt.reranker.reranker_scorer.build_reranker_scorer.scoring", "round", "len", "len", "round", "len", "len", "len", "len", "len", "len", "str", "len", "len", "len", "expand_tgt.append", "gen_scores.append", "rk_line.strip().split", "rsc_line.strip().split", "key.strip.strip", "round", "round", "len", "zip", "sorted", "sorted", "sorted", "tgt_line.strip", "gen_scores_line.strip", "float", "len", "expand_rk.append", "rk_scores.append", "sum", "sum", "sum", "sum", "len", "gt_keys_line.strip().split", "zip", "zip", "sorted", "sorted", "gen_sc.strip", "rk_line.strip", "rsc_line.strip", "float", "STEMMER.stem", "STEMMER.stem", "STEMMER.stem", "STEMMER.stem", "zip", "zip", "rk_sc.strip", "w.strip", "key.strip.split", "w.strip", "key.strip.split", "w.strip", "key.strip.split", "w.strip", "key.strip.split", "gt_keys_line.strip"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.build_reranker_scorer", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.evaluate_func", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.merge_rerank.get_extracted_keys_fr_line", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.scoring"], ["", "", "def", "main1", "(", "opt", ",", "logger", ")", ":", "\n", "    ", "reranker_scorer", "=", "build_reranker_scorer", "(", "opt", ")", "\n", "\n", "src_file", "=", "open", "(", "opt", ".", "src", ",", "encoding", "=", "'utf-8'", ")", "\n", "src_lines", "=", "src_file", ".", "readlines", "(", ")", "\n", "tgt_file", "=", "open", "(", "opt", ".", "tgt", ",", "encoding", "=", "'utf-8'", ")", "\n", "tgt_lines", "=", "tgt_file", ".", "readlines", "(", ")", "\n", "assert", "len", "(", "src_lines", ")", "==", "len", "(", "tgt_lines", ")", "\n", "logger", ".", "info", "(", "'Reranking {} ... '", ".", "format", "(", "opt", ".", "tgt", ")", ")", "\n", "\n", "# generated keyphrases", "\n", "gen_scores_file", "=", "open", "(", "opt", ".", "gen_scores", ",", "encoding", "=", "'utf-8'", ")", "\n", "gen_scores_lines", "=", "gen_scores_file", ".", "readlines", "(", ")", "\n", "assert", "len", "(", "tgt_lines", ")", "==", "len", "(", "gen_scores_lines", ")", "\n", "\n", "# retrieved keyphrases", "\n", "if", "opt", ".", "merge_rk_keys", ":", "\n", "        ", "retrieved_keys", "=", "open", "(", "opt", ".", "retrieved_keys", ",", "encoding", "=", "'utf-8'", ")", "\n", "rk_lines", "=", "retrieved_keys", ".", "readlines", "(", ")", "\n", "assert", "len", "(", "src_lines", ")", "==", "len", "(", "rk_lines", ")", "\n", "\n", "retrieved_scores", "=", "open", "(", "opt", ".", "retrieved_scores", ",", "encoding", "=", "'utf-8'", ")", "\n", "rsc_lines", "=", "retrieved_scores", ".", "readlines", "(", ")", "\n", "assert", "len", "(", "src_lines", ")", "==", "len", "(", "rsc_lines", ")", "\n", "\n", "# extracted key words", "\n", "", "if", "opt", ".", "merge_ex_keys", ":", "\n", "        ", "sel_probs", "=", "open", "(", "opt", ".", "sel_probs", ",", "encoding", "=", "'utf-8'", ")", "\n", "sel_probs_lines", "=", "sel_probs", ".", "readlines", "(", ")", "\n", "\n", "# ground_truth keywords", "\n", "", "gt_keys", "=", "open", "(", "opt", ".", "kpg_tgt", ",", "encoding", "=", "'utf-8'", ")", "\n", "gt_keys_lines", "=", "gt_keys", ".", "readlines", "(", ")", "\n", "assert", "len", "(", "src_lines", ")", "==", "len", "(", "gt_keys_lines", ")", "\n", "\n", "sel_keys_out", "=", "open", "(", "opt", ".", "sel_keys_output", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "out_file", "=", "open", "(", "opt", ".", "reranked_scores_output", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "reranked_out_file", "=", "open", "(", "opt", ".", "output", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n", "report_every", "=", "int", "(", "min", "(", "len", "(", "src_lines", ")", "/", "10", ",", "200", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "src_lines", ")", ")", ":", "\n", "        ", "if", "(", "i", "+", "1", ")", "%", "report_every", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'{} papers complete!'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "", "src_line", "=", "src_lines", "[", "i", "]", "\n", "tgt_line", "=", "tgt_lines", "[", "i", "]", "\n", "gen_scores_line", "=", "gen_scores_lines", "[", "i", "]", "\n", "gt_keys_line", "=", "gt_keys_lines", "[", "i", "]", "\n", "\n", "# get the predicted keys and scores by the generator", "\n", "gen_scores", "=", "[", "]", "\n", "expand_tgt", "=", "[", "]", "\n", "for", "key", ",", "gen_sc", "in", "zip", "(", "tgt_line", ".", "strip", "(", ")", ".", "split", "(", "' ; '", ")", ",", "gen_scores_line", ".", "strip", "(", ")", ".", "split", "(", "' ; '", ")", ")", ":", "\n", "            ", "key", "=", "key", ".", "strip", "(", ")", "\n", "if", "len", "(", "key", ")", ">", "2", ":", "\n", "                ", "expand_tgt", ".", "append", "(", "key", ")", "\n", "gen_scores", ".", "append", "(", "float", "(", "gen_sc", ".", "strip", "(", ")", ")", ")", "\n", "", "", "gen_num", "=", "len", "(", "expand_tgt", ")", "\n", "\n", "# get the predicted keys and scores by the retriever", "\n", "rk_scores", "=", "[", "]", "\n", "expand_rk", "=", "[", "]", "\n", "if", "opt", ".", "merge_rk_keys", ":", "\n", "            ", "rk_line", "=", "rk_lines", "[", "i", "]", "\n", "rsc_line", "=", "rsc_lines", "[", "i", "]", "\n", "for", "key", ",", "rk_sc", "in", "zip", "(", "rk_line", ".", "strip", "(", ")", ".", "split", "(", "' <eos> '", ")", ",", "rsc_line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", ":", "\n", "                ", "key", "=", "key", ".", "strip", "(", ")", "\n", "if", "len", "(", "key", ")", ">", "2", ":", "\n", "                    ", "expand_rk", ".", "append", "(", "key", ")", "\n", "rk_scores", ".", "append", "(", "float", "(", "rk_sc", ".", "strip", "(", ")", ")", ")", "\n", "", "", "", "rk_num", "=", "len", "(", "expand_rk", ")", "\n", "\n", "# get the extracted keys and predicted scores by the extactor", "\n", "ex_keys", "=", "[", "]", "\n", "ex_scores", "=", "[", "]", "\n", "if", "opt", ".", "merge_ex_keys", ":", "\n", "            ", "sel_probs_line", "=", "sel_probs_lines", "[", "i", "]", "\n", "ex_keys", ",", "ex_scores", "=", "get_extracted_keys_fr_line", "(", "src_line", ",", "sel_probs_line", ")", "\n", "# store the extracted keys", "\n", "sel_keys_out", ".", "write", "(", "' ; '", ".", "join", "(", "ex_keys", ")", "+", "'\\n'", ")", "\n", "", "ex_num", "=", "len", "(", "ex_keys", ")", "\n", "\n", "expand_src", "=", "[", "src_line", "]", "*", "(", "gen_num", "+", "rk_num", "+", "ex_num", ")", "\n", "merged_tgt", "=", "expand_tgt", "+", "expand_rk", "+", "ex_keys", "\n", "\n", "# dynamically give weights to rk_scores", "\n", "rescaled_rk_scores", "=", "[", "]", "\n", "if", "rk_num", "!=", "0", ":", "\n", "            ", "rk_lambda", "=", "(", "sum", "(", "gen_scores", ")", "/", "gen_num", ")", "/", "(", "sum", "(", "rk_scores", ")", "/", "rk_num", ")", "\n", "rescaled_rk_scores", "=", "[", "round", "(", "rk_sc", "*", "rk_lambda", ",", "5", ")", "for", "rk_sc", "in", "rk_scores", "]", "\n", "# dynamically give weights to ex_scores", "\n", "", "rescaled_ex_scores", "=", "[", "]", "\n", "if", "ex_num", "!=", "0", ":", "\n", "            ", "ex_lambda", "=", "(", "(", "sum", "(", "gen_scores", ")", "/", "gen_num", ")", "/", "(", "sum", "(", "ex_scores", ")", "/", "ex_num", ")", ")", "\n", "rescaled_ex_scores", "=", "[", "round", "(", "ex_sc", "*", "ex_lambda", ",", "5", ")", "for", "ex_sc", "in", "ex_scores", "]", "\n", "\n", "", "merged_scores", "=", "gen_scores", "+", "rescaled_rk_scores", "+", "rescaled_ex_scores", "\n", "\n", "scored_triplets", "=", "[", "]", "\n", "loop_num", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "merged_tgt", ")", "/", "100", ")", ")", "\n", "for", "loop_idx", "in", "range", "(", "loop_num", ")", ":", "\n", "            ", "start_idx", "=", "loop_idx", "*", "100", "\n", "end_idx", "=", "min", "(", "(", "loop_idx", "+", "1", ")", "*", "100", ",", "len", "(", "merged_tgt", ")", ")", "\n", "scored_triplets_tmp", "=", "reranker_scorer", ".", "scoring", "(", "src_data_iter", "=", "expand_src", "[", "start_idx", ":", "end_idx", "]", ",", "\n", "tgt_data_iter", "=", "merged_tgt", "[", "start_idx", ":", "end_idx", "]", ")", "\n", "scored_triplets", "=", "scored_triplets", "+", "scored_triplets_tmp", "\n", "\n", "", "reranker_scores", "=", "[", "round", "(", "triplet", "[", "'score'", "]", ",", "5", ")", "for", "triplet", "in", "scored_triplets", "]", "\n", "assert", "len", "(", "reranker_scores", ")", "==", "len", "(", "merged_scores", ")", "\n", "rescaled_scores", "=", "[", "round", "(", "re_sc", "*", "mg_sc", ",", "8", ")", "for", "re_sc", ",", "mg_sc", "in", "zip", "(", "reranker_scores", ",", "merged_scores", ")", "]", "\n", "\n", "# get the statistics of the gen_keys and rk_keys", "\n", "if", "opt", ".", "merge_with_stemmer", ":", "\n", "            ", "stemmed_expand_tgt", "=", "[", "' '", ".", "join", "(", "[", "STEMMER", ".", "stem", "(", "w", ".", "strip", "(", ")", ")", "for", "w", "in", "key", ".", "split", "(", ")", "]", ")", "for", "key", "in", "expand_tgt", "]", "\n", "stemmed_rk_keys", "=", "[", "' '", ".", "join", "(", "[", "STEMMER", ".", "stem", "(", "w", ".", "strip", "(", ")", ")", "for", "w", "in", "key", ".", "split", "(", ")", "]", ")", "for", "key", "in", "expand_rk", "]", "\n", "stemmed_ex_keys", "=", "[", "' '", ".", "join", "(", "[", "STEMMER", ".", "stem", "(", "w", ".", "strip", "(", ")", ")", "for", "w", "in", "key", ".", "split", "(", ")", "]", ")", "for", "key", "in", "ex_keys", "]", "\n", "stemmed_mg_keys", "=", "stemmed_expand_tgt", "+", "stemmed_rk_keys", "+", "stemmed_ex_keys", "\n", "", "else", ":", "\n", "            ", "stemmed_expand_tgt", "=", "expand_tgt", "\n", "stemmed_rk_keys", "=", "expand_rk", "\n", "stemmed_ex_keys", "=", "ex_keys", "\n", "stemmed_mg_keys", "=", "stemmed_expand_tgt", "+", "stemmed_rk_keys", "+", "stemmed_ex_keys", "\n", "# stemmed_gt_keys_set = gt_keys_line.strip().split(' ; ')", "\n", "\n", "", "stem_map", "=", "{", "}", "\n", "for", "stemmed_key", ",", "key", "in", "zip", "(", "stemmed_mg_keys", ",", "merged_tgt", ")", ":", "\n", "            ", "if", "stemmed_key", "not", "in", "stem_map", ":", "\n", "                ", "stem_map", "[", "stemmed_key", "]", "=", "key", "\n", "\n", "", "", "stemmed_gt_keys_set", "=", "set", "(", "\n", "[", "' '", ".", "join", "(", "[", "STEMMER", ".", "stem", "(", "w", ".", "strip", "(", ")", ")", "for", "w", "in", "key", ".", "split", "(", ")", "]", ")", "for", "key", "in", "gt_keys_line", ".", "strip", "(", ")", ".", "split", "(", "' ; '", ")", "]", ")", "\n", "\n", "# get the reranked results W/O merging the duplicates among gen_keys, rk_keys and ex_keys", "\n", "no_merge_sc_reranked_pair", "=", "[", "(", "x", ",", "sc", ")", "for", "x", ",", "sc", "in", "sorted", "(", "\n", "zip", "(", "stemmed_mg_keys", ",", "rescaled_scores", ")", ",", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "\n", "reverse", "=", "True", ")", "]", "\n", "no_merge_sc_reranked_tgt", "=", "[", "x", "for", "x", ",", "_", "in", "no_merge_sc_reranked_pair", "]", "\n", "\n", "no_merge_sc_reranked_gen_pair", "=", "[", "(", "x", ",", "sc", ")", "for", "x", ",", "sc", "in", "sorted", "(", "\n", "zip", "(", "stemmed_mg_keys", "[", ":", "gen_num", "]", ",", "rescaled_scores", "[", ":", "gen_num", "]", ")", ",", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "\n", "reverse", "=", "True", ")", "]", "\n", "assert", "len", "(", "no_merge_sc_reranked_gen_pair", ")", "==", "len", "(", "expand_tgt", ")", "\n", "\n", "no_merge_sc_reranked_rk_pair", "=", "[", "]", "\n", "if", "opt", ".", "merge_rk_keys", ":", "\n", "            ", "no_merge_sc_reranked_rk_pair", "=", "[", "(", "x", ",", "sc", ")", "for", "x", ",", "sc", "in", "sorted", "(", "\n", "zip", "(", "stemmed_mg_keys", "[", "gen_num", ":", "gen_num", "+", "rk_num", "]", ",", "rescaled_scores", "[", "gen_num", ":", "gen_num", "+", "rk_num", "]", ")", ",", "\n", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "reverse", "=", "True", ")", "]", "\n", "", "assert", "len", "(", "no_merge_sc_reranked_rk_pair", ")", "==", "len", "(", "expand_rk", ")", "\n", "\n", "no_merge_sc_reranked_ex_pair", "=", "[", "]", "\n", "if", "opt", ".", "merge_ex_keys", ":", "\n", "            ", "no_merge_sc_reranked_ex_pair", "=", "[", "(", "x", ",", "sc", ")", "for", "x", ",", "sc", "in", "sorted", "(", "\n", "zip", "(", "stemmed_mg_keys", "[", "gen_num", "+", "rk_num", ":", "]", ",", "rescaled_scores", "[", "gen_num", "+", "rk_num", ":", "]", ")", ",", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "\n", "reverse", "=", "True", ")", "]", "\n", "", "assert", "len", "(", "no_merge_sc_reranked_ex_pair", ")", "==", "len", "(", "ex_keys", ")", "\n", "\n", "# get the reranked results W/ merging the duplicates between gen_keys and rk_keys", "\n", "final_candies_set", "=", "{", "}", "\n", "sc_from_rk", "=", "{", "}", "\n", "sc_from_ex", "=", "{", "}", "\n", "for", "stemmed_mg_tgt", ",", "sc", "in", "no_merge_sc_reranked_gen_pair", ":", "\n", "            ", "if", "stemmed_mg_tgt", "not", "in", "final_candies_set", ":", "\n", "                ", "final_candies_set", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "sc_from_rk", "[", "stemmed_mg_tgt", "]", "=", "0.0", "\n", "sc_from_ex", "[", "stemmed_mg_tgt", "]", "=", "0.0", "\n", "\n", "", "", "if", "opt", ".", "merge_rk_keys", ":", "\n", "            ", "for", "stemmed_mg_tgt", ",", "sc", "in", "no_merge_sc_reranked_rk_pair", ":", "\n", "                ", "if", "stemmed_mg_tgt", "in", "final_candies_set", ":", "\n", "                    ", "if", "sc_from_rk", "[", "stemmed_mg_tgt", "]", "==", "0.0", ":", "\n", "                        ", "final_candies_set", "[", "stemmed_mg_tgt", "]", "+=", "sc", "\n", "sc_from_rk", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "", "", "else", ":", "\n", "                    ", "final_candies_set", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "sc_from_rk", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "sc_from_ex", "[", "stemmed_mg_tgt", "]", "=", "0.0", "\n", "\n", "", "", "", "if", "opt", ".", "merge_ex_keys", ":", "\n", "            ", "for", "stemmed_mg_tgt", ",", "sc", "in", "no_merge_sc_reranked_ex_pair", ":", "\n", "                ", "if", "stemmed_mg_tgt", "in", "final_candies_set", ":", "\n", "                    ", "if", "sc_from_ex", "[", "stemmed_mg_tgt", "]", "==", "0.0", ":", "\n", "                        ", "final_candies_set", "[", "stemmed_mg_tgt", "]", "+=", "sc", "\n", "sc_from_ex", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "", "", "else", ":", "\n", "                    ", "final_candies_set", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "sc_from_ex", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "\n", "", "", "", "fn_reranked_tgt", "=", "[", "x", "for", "x", "in", "sorted", "(", "final_candies_set", ",", "key", "=", "final_candies_set", ".", "get", ",", "reverse", "=", "True", ")", "]", "\n", "\n", "# store the final scores of each keyphrase candidate", "\n", "scores_str", "=", "[", "str", "(", "final_candies_set", "[", "fn_key", "]", ")", "for", "fn_key", "in", "fn_reranked_tgt", "]", "\n", "score_line", "=", "' ; '", ".", "join", "(", "scores_str", ")", "+", "'\\n'", "\n", "out_file", ".", "write", "(", "score_line", ")", "\n", "# store the final merged and reranked keyphrase candidates", "\n", "fn_reranked_tgt", "=", "[", "stem_map", "[", "fn_key", "]", "for", "fn_key", "in", "fn_reranked_tgt", "]", "\n", "fn_reranked_tgt_line", "=", "' ; '", ".", "join", "(", "fn_reranked_tgt", ")", "+", "'\\n'", "\n", "reranked_out_file", ".", "write", "(", "fn_reranked_tgt_line", ")", "\n", "", "reranked_out_file", ".", "close", "(", ")", "\n", "out_file", ".", "close", "(", ")", "\n", "sel_keys_out", ".", "close", "(", ")", "\n", "logger", ".", "info", "(", "'{} papers complete!'", ".", "format", "(", "len", "(", "src_lines", ")", ")", ")", "\n", "# evaluate the final predictions", "\n", "evaluate_func", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.preprocess.check_existing_pt_files": [[20, 31], ["glob.glob", "sys.stderr.write", "sys.exit"], "function", ["None"], ["def", "check_existing_pt_files", "(", "opt", ")", ":", "\n", "    ", "\"\"\" Checking if there are existing .pt files to avoid tampering \"\"\"", "\n", "# We will use glob.glob() to find sharded {train|valid}.[0-9]*.pt", "\n", "# when training, so check to avoid tampering with existing pt files", "\n", "# or mixing them up.", "\n", "for", "t", "in", "[", "'train'", ",", "'valid'", ",", "'vocab'", "]", ":", "\n", "        ", "pattern", "=", "opt", ".", "save_data", "+", "'.'", "+", "t", "+", "'*.pt'", "\n", "if", "glob", ".", "glob", "(", "pattern", ")", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\"Please backup existing pt file: %s, \"", "\n", "\"to avoid tampering!\\n\"", "%", "pattern", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.preprocess.parse_args": [[33, 48], ["argparse.ArgumentParser", "onmt.add_md_help_argument", "onmt.preprocess_opts", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "preprocess.check_existing_pt_files"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.add_md_help_argument", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.preprocess_opts", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.parse_args", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.check_existing_pt_files"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "\"\"\" Parsing arguments \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'preprocess.py'", ",", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "\n", "opts", ".", "add_md_help_argument", "(", "parser", ")", "\n", "opts", ".", "preprocess_opts", "(", "parser", ")", "\n", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "\n", "check_existing_pt_files", "(", "opt", ")", "\n", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.preprocess.build_save_in_shards": [[50, 133], ["os.path.getsize", "onmt.ShardedTextCorpusIterator", "onmt.ShardedTextCorpusIterator", "onmt.ShardedTextCorpusIterator", "onmt.ShardedTextCorpusIterator", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "inputters.ShardedTextCorpusIterator.hit_end", "onmt.TextDataset", "onmt.utils.logging.logger.info", "torch.save", "ret_list.append", "len"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.ShardedTextCorpusIterator.hit_end"], ["", "def", "build_save_in_shards", "(", "src_corpus", ",", "tgt_corpus", ",", "key_indicators", ",", "retrieved_keys", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Divide the big corpus into shards, and build dataset separately.\n    This is currently only for data_type=='text'.\n\n    The reason we do this is to avoid taking up too much memory due\n    to sucking in a huge corpus file.\n\n    To tackle this, we only read in part of the corpus file of size\n    `max_shard_size`(actually it is multiples of 64 bytes that equals\n    or is slightly larger than this size), and process it into dataset,\n    then write it to disk along the way. By doing this, we only focus on\n    part of the corpus at any moment, thus effectively reducing memory use.\n    According to test, this method can reduce memory footprint by ~50%.\n\n    Note! As we process along the shards, previous shards might still\n    stay in memory, but since we are done with them, and no more\n    reference to them, if there is memory tight situation, the OS could\n    easily reclaim these memory.\n\n    If `max_shard_size` is 0 or is larger than the corpus size, it is\n    effectively preprocessed into one dataset, i.e. no sharding.\n\n    NOTE! `max_shard_size` is measuring the input corpus size, not the\n    output pt file size. So a shard pt file consists of examples of size\n    2 * `max_shard_size`(source + target).\n    \"\"\"", "\n", "\n", "corpus_size", "=", "os", ".", "path", ".", "getsize", "(", "src_corpus", ")", "\n", "if", "corpus_size", ">", "10", "*", "(", "1024", "**", "2", ")", "and", "opt", ".", "max_shard_size", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\"Warning. The corpus %s is larger than 10M bytes, \"", "\n", "\"you can set '-max_shard_size' to process it by \"", "\n", "\"small shards to use less memory.\"", "%", "src_corpus", ")", "\n", "\n", "", "if", "opt", ".", "max_shard_size", "!=", "0", ":", "\n", "        ", "logger", ".", "info", "(", "' * divide corpus into shards and build dataset '", "\n", "'separately (shard_size = %d bytes).'", "\n", "%", "opt", ".", "max_shard_size", ")", "\n", "\n", "", "ret_list", "=", "[", "]", "\n", "src_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "src_corpus", ",", "opt", ".", "src_seq_length_trunc", ",", "\n", "\"src\"", ",", "opt", ".", "max_shard_size", ")", "\n", "\n", "# KE-KG-KR-M: add for KE", "\n", "key_indicators_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "key_indicators", ",", "opt", ".", "src_seq_length_trunc", ",", "\n", "\"key_indicators\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "# KE-KG-KR-M: add for RK", "\n", "retrieved_keys_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "retrieved_keys", ",", "0", ",", "\n", "\"retrieved_keys\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "\n", "tgt_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "tgt_corpus", ",", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "\"tgt\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "\n", "index", "=", "0", "\n", "while", "not", "src_iter", ".", "hit_end", "(", ")", ":", "\n", "        ", "index", "+=", "1", "\n", "dataset", "=", "inputters", ".", "TextDataset", "(", "\n", "fields", ",", "src_iter", ",", "key_indicators_iter", ",", "retrieved_keys_iter", ",", "tgt_iter", ",", "\n", "src_iter", ".", "num_feats", ",", "tgt_iter", ".", "num_feats", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ")", "\n", "\n", "# We save fields in vocab.pt separately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.{:d}.pt\"", ".", "format", "(", "\n", "opt", ".", "save_data", ",", "corpus_type", ",", "index", ")", "\n", "logger", ".", "info", "(", "\" * saving %s data shard to %s. %d examples.\"", "\n", "%", "(", "corpus_type", ",", "pt_file", ",", "len", "(", "dataset", ")", ")", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "ret_list", ".", "append", "(", "pt_file", ")", "\n", "\n", "", "return", "ret_list", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.preprocess.build_save_dataset": [[135, 187], ["onmt.build_dataset", "onmt.utils.logging.logger.info", "torch.save", "preprocess.build_save_in_shards"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.build_save_in_shards"], ["", "def", "build_save_dataset", "(", "corpus_type", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "\"\"\" Building and saving the dataset \"\"\"", "\n", "assert", "corpus_type", "in", "[", "'train'", ",", "'valid'", "]", "\n", "\n", "if", "corpus_type", "==", "'train'", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "train_src", "\n", "tgt_corpus", "=", "opt", ".", "train_tgt", "\n", "# KE-KG-KR-M: add for KE", "\n", "key_indicators", "=", "opt", ".", "train_key_indicators", "\n", "# KE-KG-KR-M: add for RK", "\n", "retrieved_keys", "=", "opt", ".", "train_retrieved_keys", "\n", "", "else", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "valid_src", "\n", "tgt_corpus", "=", "opt", ".", "valid_tgt", "\n", "# KE-KG-KR-M: add for KE", "\n", "key_indicators", "=", "opt", ".", "valid_key_indicators", "\n", "# KE-KG-KR-M: add for RK", "\n", "retrieved_keys", "=", "opt", ".", "valid_retrieved_keys", "\n", "\n", "# Currently we only do preprocess sharding for corpus: data_type=='text'.", "\n", "", "if", "opt", ".", "data_type", "==", "'text'", ":", "\n", "        ", "return", "build_save_in_shards", "(", "\n", "src_corpus", ",", "tgt_corpus", ",", "key_indicators", ",", "retrieved_keys", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", "\n", "\n", "# For data_type == 'img' or 'audio', currently we don't do", "\n", "# preprocess sharding. We only build a monolithic dataset.", "\n", "# But since the interfaces are uniform, it would be not hard", "\n", "# to do this should users need this feature.", "\n", "", "dataset", "=", "inputters", ".", "build_dataset", "(", "\n", "fields", ",", "opt", ".", "data_type", ",", "\n", "src_path", "=", "src_corpus", ",", "\n", "tgt_path", "=", "tgt_corpus", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "src_seq_length_trunc", "=", "opt", ".", "src_seq_length_trunc", ",", "\n", "tgt_seq_length_trunc", "=", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ",", "\n", "sample_rate", "=", "opt", ".", "sample_rate", ",", "\n", "window_size", "=", "opt", ".", "window_size", ",", "\n", "window_stride", "=", "opt", ".", "window_stride", ",", "\n", "window", "=", "opt", ".", "window", ")", "\n", "\n", "# We save fields in vocab.pt seperately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.pt\"", ".", "format", "(", "opt", ".", "save_data", ",", "corpus_type", ")", "\n", "logger", ".", "info", "(", "\" * saving %s dataset to %s.\"", "%", "(", "corpus_type", ",", "pt_file", ")", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "return", "[", "pt_file", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.preprocess.build_save_vocab": [[189, 203], ["onmt.build_vocab", "torch.save", "onmt.save_fields_to_vocab"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.save_fields_to_vocab"], ["", "def", "build_save_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "\"\"\" Building and saving the vocab \"\"\"", "\n", "fields", "=", "inputters", ".", "build_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ".", "data_type", ",", "\n", "opt", ".", "share_vocab", ",", "\n", "opt", ".", "src_vocab", ",", "\n", "opt", ".", "src_vocab_size", ",", "\n", "opt", ".", "src_words_min_frequency", ",", "\n", "opt", ".", "tgt_vocab", ",", "\n", "opt", ".", "tgt_vocab_size", ",", "\n", "opt", ".", "tgt_words_min_frequency", ")", "\n", "\n", "# Can't save fields, so remove/reconstruct at training time.", "\n", "vocab_file", "=", "opt", ".", "save_data", "+", "'.vocab.pt'", "\n", "torch", ".", "save", "(", "inputters", ".", "save_fields_to_vocab", "(", "fields", ")", ",", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.preprocess.main": [[205, 228], ["preprocess.parse_args", "onmt.utils.logging.init_logger", "onmt.utils.logging.logger.info", "onmt.get_num_features", "onmt.get_num_features", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.get_fields", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset", "onmt.utils.logging.logger.info", "preprocess.build_save_vocab", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.parse_args", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.logging.init_logger", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.build_save_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.build_save_dataset"], ["", "def", "main", "(", ")", ":", "\n", "    ", "opt", "=", "parse_args", "(", ")", "\n", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "logger", ".", "info", "(", "\"Extracting features...\"", ")", "\n", "\n", "src_nfeats", "=", "inputters", ".", "get_num_features", "(", "\n", "opt", ".", "data_type", ",", "opt", ".", "train_src", ",", "'src'", ")", "\n", "tgt_nfeats", "=", "inputters", ".", "get_num_features", "(", "\n", "opt", ".", "data_type", ",", "opt", ".", "train_tgt", ",", "'tgt'", ")", "\n", "logger", ".", "info", "(", "\" * number of source features: %d.\"", "%", "src_nfeats", ")", "\n", "logger", ".", "info", "(", "\" * number of target features: %d.\"", "%", "tgt_nfeats", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building `Fields` object...\"", ")", "\n", "fields", "=", "inputters", ".", "get_fields", "(", "opt", ".", "data_type", ",", "src_nfeats", ",", "tgt_nfeats", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building & saving training data...\"", ")", "\n", "train_dataset_files", "=", "build_save_dataset", "(", "'train'", ",", "fields", ",", "opt", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building & saving vocabulary...\"", ")", "\n", "build_save_vocab", "(", "train_dataset_files", ",", "fields", ",", "opt", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building & saving validation data...\"", ")", "\n", "build_save_dataset", "(", "'valid'", ",", "fields", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.evaluation_utils.evaluate_func": [[12, 186], ["open", "open.readlines", "open", "open.readlines", "open", "open.readlines", "PorterStemmer", "zip", "print", "print", "print", "print", "print", "print", "print", "print", "print", "evaluation_utils.map_score_fc", "evaluation_utils.map_score_fc", "evaluation_utils.map_score_fc", "evaluation_utils.micro_ave_fc", "evaluation_utils.micro_ave_fc", "evaluation_utils.micro_ave_fc", "len", "len", "len", "len", "data_utils.process_keyphrase", "data_utils.process_keyphrase.replace", "data_utils.process_keyphrase", "set", "set", "set", "context.strip.split", "set", "set", "present_target_lens_list.append", "absent_target_lens_list.append", "total_target_lens_list.append", "len", "len", "len", "len", "len", "macro_metrics[].append", "macro_metrics[].append", "macro_metrics[].append", "print", "data_utils.process_keyphrase.strip", "data_utils.process_keyphrase.strip", "data_utils.get_tokens", "context.strip.strip", "len", "len", "len", "len", "len", "len", "len", "total_correctly_matched_at[].append", "present_correctly_matched_at[].append", "absent_correctly_matched_at[].append", "evaluation_utils.macro_metric_fc", "evaluation_utils.macro_metric_fc", "evaluation_utils.macro_metric_fc", "opts.kpg_tgt.lower", "tgt.split", "evaluation_utils.in_context2", "set.add", "set.add", "evaluation_utils.in_context2", "time.strftime", "PorterStemmer.stem", "len", "pred.split", "total_preds.append", "present_preds.append", "set.add", "total_preds.append", "absent_preds.append", "set.add", "context.strip.strip().split", "PorterStemmer.stem", "pred.split", "int", "int", "int", "PorterStemmer.stem", "keyphrase.split", "context.strip.strip", "keyphrase.split", "keyphrase.split"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.map_score_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.map_score_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.map_score_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.micro_ave_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.micro_ave_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.micro_ave_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.data_utils.process_keyphrase", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.data_utils.process_keyphrase", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.data_utils.get_tokens", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.macro_metric_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.macro_metric_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.macro_metric_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.in_context2", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.in_context2"], ["def", "evaluate_func", "(", "opts", ",", "do_stem", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    calculate the macro-averaged precesion, recall and F1 score\n    \"\"\"", "\n", "context_file", "=", "open", "(", "opts", ".", "kpg_context", ",", "encoding", "=", "'utf-8'", ")", "\n", "context_lines", "=", "context_file", ".", "readlines", "(", ")", "\n", "\n", "target_file", "=", "open", "(", "opts", ".", "kpg_tgt", ",", "encoding", "=", "'utf-8'", ")", "\n", "target_lines", "=", "target_file", ".", "readlines", "(", ")", "\n", "\n", "preds_file", "=", "open", "(", "opts", ".", "output", ",", "encoding", "=", "'utf-8'", ")", "\n", "preds_lines", "=", "preds_file", ".", "readlines", "(", ")", "\n", "\n", "# the number of examples should be the same", "\n", "assert", "len", "(", "context_lines", ")", "==", "len", "(", "preds_lines", ")", "\n", "assert", "len", "(", "preds_lines", ")", "==", "len", "(", "target_lines", ")", "\n", "\n", "stemmer", "=", "PorterStemmer", "(", ")", "\n", "num_groundtruth", "=", "0", "\n", "num_present_groundtruth", "=", "0", "\n", "num_absent_groundtruth", "=", "0", "\n", "min_num_present_preds", "=", "1000", "\n", "min_num_absent_preds", "=", "1000", "\n", "ave_num_present_preds", "=", "0", "\n", "ave_num_absent_preds", "=", "0", "\n", "\n", "macro_metrics", "=", "{", "'total'", ":", "[", "]", ",", "'present'", ":", "[", "]", ",", "'absent'", ":", "[", "]", "}", "\n", "cnt", "=", "1", "\n", "present_correctly_matched_at", "=", "{", "'5'", ":", "[", "]", ",", "'10'", ":", "[", "]", ",", "'15'", ":", "[", "]", ",", "'50'", ":", "[", "]", "}", "\n", "absent_correctly_matched_at", "=", "{", "'5'", ":", "[", "]", ",", "'10'", ":", "[", "]", ",", "'15'", ":", "[", "]", ",", "'50'", ":", "[", "]", "}", "\n", "total_correctly_matched_at", "=", "{", "'5'", ":", "[", "]", ",", "'10'", ":", "[", "]", ",", "'15'", ":", "[", "]", ",", "'50'", ":", "[", "]", "}", "\n", "present_target_lens_list", "=", "[", "]", "\n", "absent_target_lens_list", "=", "[", "]", "\n", "total_target_lens_list", "=", "[", "]", "\n", "for", "context", ",", "targets", ",", "preds", "in", "zip", "(", "context_lines", ",", "target_lines", ",", "preds_lines", ")", ":", "\n", "        ", "if", "cnt", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "time", ".", "strftime", "(", "'%H:%M:%S'", ")", "+", "': {} papers evaluation complete!'", ".", "format", "(", "cnt", ")", ")", "\n", "# preprocess predictions and targets to a list ['key1a key1b', 'key2a key2b']", "\n", "", "targets", "=", "process_keyphrase", "(", "targets", ".", "strip", "(", ")", ",", "limit_num", "=", "False", ",", "fine_grad", "=", "True", ")", "\n", "preds", "=", "preds", ".", "replace", "(", "opts", ".", "splitter", ",", "';'", ")", "\n", "preds", "=", "process_keyphrase", "(", "preds", ".", "strip", "(", ")", ",", "limit_num", "=", "False", ",", "fine_grad", "=", "True", ")", "\n", "# preprocess context in a fine-gradularity: [word1, word2,..., wordk,...]", "\n", "context", "=", "' '", ".", "join", "(", "get_tokens", "(", "context", ",", "fine_grad", "=", "True", ")", ")", "\n", "\n", "# stem words in context, target, pred, if needed", "\n", "if", "do_stem", ":", "\n", "            ", "context", "=", "' '", ".", "join", "(", "[", "stemmer", ".", "stem", "(", "w", ")", "for", "w", "in", "context", ".", "strip", "(", ")", ".", "split", "(", ")", "]", ")", "\n", "# the gold keyphrases of SemEval testing dataset are already stemmed", "\n", "if", "'semeval'", "in", "opts", ".", "kpg_tgt", ".", "lower", "(", ")", ":", "\n", "                ", "targets", "=", "[", "' '", ".", "join", "(", "[", "w", "for", "w", "in", "keyphrase", ".", "split", "(", ")", "]", ")", "for", "keyphrase", "in", "targets", "]", "\n", "", "else", ":", "\n", "                ", "targets", "=", "[", "' '", ".", "join", "(", "[", "stemmer", ".", "stem", "(", "w", ")", "for", "w", "in", "keyphrase", ".", "split", "(", ")", "]", ")", "for", "keyphrase", "in", "targets", "]", "\n", "", "preds", "=", "[", "' '", ".", "join", "(", "[", "stemmer", ".", "stem", "(", "w", ")", "for", "w", "in", "keyphrase", ".", "split", "(", ")", "]", ")", "for", "keyphrase", "in", "preds", "]", "\n", "", "else", ":", "\n", "            ", "context", "=", "context", ".", "strip", "(", ")", "\n", "\n", "", "if", "opts", ".", "filter_dot_comma_unk", ":", "\n", "            ", "targets", "=", "[", "keyphrase", "for", "keyphrase", "in", "targets", "if", "','", "not", "in", "keyphrase", "and", "'.'", "not", "in", "keyphrase", "and", "'<unk>'", "not", "in", "keyphrase", "]", "\n", "preds", "=", "[", "keyphrase", "for", "keyphrase", "in", "preds", "if", "','", "not", "in", "keyphrase", "and", "'.'", "not", "in", "keyphrase", "and", "'<unk>'", "not", "in", "keyphrase", "]", "\n", "\n", "# get the present_tgt_keyphrase, absent_tgt_keyphrase", "\n", "", "present_tgt_set", "=", "set", "(", ")", "\n", "absent_tgt_set", "=", "set", "(", ")", "\n", "total_tgt_set", "=", "set", "(", "targets", ")", "\n", "context_list", "=", "context", ".", "split", "(", ")", "\n", "\n", "for", "tgt", "in", "targets", ":", "\n", "            ", "if", "opts", ".", "match_method", "==", "'word_match'", ":", "\n", "                ", "tgt_list", "=", "tgt", ".", "split", "(", ")", "\n", "match", "=", "in_context2", "(", "context_list", ",", "tgt_list", ")", "\n", "", "else", ":", "\n", "                ", "match", "=", "tgt", "in", "context", "\n", "", "if", "match", ":", "\n", "                ", "present_tgt_set", ".", "add", "(", "tgt", ")", "\n", "", "else", ":", "\n", "                ", "absent_tgt_set", ".", "add", "(", "tgt", ")", "\n", "\n", "", "", "present_preds", "=", "[", "]", "\n", "present_preds_set", "=", "set", "(", ")", "\n", "absent_preds", "=", "[", "]", "\n", "absent_preds_set", "=", "set", "(", ")", "\n", "\n", "total_preds", "=", "[", "]", "\n", "\n", "single_word_maxnum", "=", "opts", ".", "single_word_maxnum", "\n", "# split to present and absent predictions and also delete the repeated predictions", "\n", "for", "pred", "in", "preds", ":", "\n", "# # only keep single_word_maxnum single word keyphrase", "\n", "# single_word_maxnum = -1 means we keep all the single word phrase", "\n", "            ", "if", "single_word_maxnum", "!=", "-", "1", "and", "len", "(", "pred", ".", "split", "(", ")", ")", "==", "1", ":", "\n", "                ", "if", "single_word_maxnum", ">", "0", ":", "\n", "                    ", "single_word_maxnum", "-=", "1", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "", "", "if", "opts", ".", "match_method", "==", "'word_match'", ":", "\n", "                ", "match", "=", "in_context2", "(", "context_list", ",", "pred", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "match", "=", "pred", "in", "context", "\n", "", "if", "match", ":", "\n", "                ", "if", "pred", "not", "in", "present_preds_set", ":", "\n", "                    ", "total_preds", ".", "append", "(", "pred", ")", "\n", "present_preds", ".", "append", "(", "pred", ")", "\n", "present_preds_set", ".", "add", "(", "pred", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "pred", "not", "in", "absent_preds_set", ":", "\n", "                    ", "total_preds", ".", "append", "(", "pred", ")", "\n", "absent_preds", ".", "append", "(", "pred", ")", "\n", "absent_preds_set", ".", "add", "(", "pred", ")", "\n", "\n", "# store the nums", "\n", "", "", "", "present_target_lens_list", ".", "append", "(", "len", "(", "present_tgt_set", ")", ")", "\n", "absent_target_lens_list", ".", "append", "(", "len", "(", "absent_tgt_set", ")", ")", "\n", "total_target_lens_list", ".", "append", "(", "len", "(", "total_tgt_set", ")", ")", "\n", "num_groundtruth", "+=", "len", "(", "targets", ")", "\n", "num_present_groundtruth", "+=", "len", "(", "present_tgt_set", ")", "\n", "num_absent_groundtruth", "+=", "len", "(", "absent_tgt_set", ")", "\n", "\n", "if", "len", "(", "present_preds_set", ")", "<", "min_num_present_preds", ":", "\n", "            ", "min_num_present_preds", "=", "len", "(", "present_preds_set", ")", "\n", "", "if", "len", "(", "absent_preds_set", ")", "<", "min_num_absent_preds", ":", "\n", "            ", "min_num_absent_preds", "=", "len", "(", "absent_preds_set", ")", "\n", "\n", "", "ave_num_present_preds", "+=", "len", "(", "present_preds_set", ")", "\n", "ave_num_absent_preds", "+=", "len", "(", "absent_preds_set", ")", "\n", "\n", "# get the correctly_matched", "\n", "total_correctly_matched", "=", "[", "1", "if", "total_pred", "in", "total_tgt_set", "else", "0", "for", "total_pred", "in", "total_preds", "]", "\n", "# get the total_correctly_matched_at", "\n", "for", "at_key", "in", "total_correctly_matched_at", ":", "\n", "            ", "total_correctly_matched_at", "[", "at_key", "]", ".", "append", "(", "total_correctly_matched", "[", ":", "int", "(", "at_key", ")", "]", ")", "\n", "\n", "# get the correctly_matched", "\n", "", "present_correctly_matched", "=", "[", "1", "if", "present_pred", "in", "present_tgt_set", "else", "0", "for", "present_pred", "in", "present_preds", "]", "\n", "# get the present_correctly_matched_at", "\n", "for", "at_key", "in", "present_correctly_matched_at", ":", "\n", "            ", "present_correctly_matched_at", "[", "at_key", "]", ".", "append", "(", "present_correctly_matched", "[", ":", "int", "(", "at_key", ")", "]", ")", "\n", "\n", "", "absent_correctly_matched", "=", "[", "1", "if", "absent_pred", "in", "absent_tgt_set", "else", "0", "for", "absent_pred", "in", "absent_preds", "]", "\n", "# get the present_correctly_matched_at", "\n", "for", "at_key", "in", "absent_correctly_matched_at", ":", "\n", "            ", "absent_correctly_matched_at", "[", "at_key", "]", ".", "append", "(", "absent_correctly_matched", "[", ":", "int", "(", "at_key", ")", "]", ")", "\n", "\n", "# macro metric calculating", "\n", "", "macro_metrics", "[", "'total'", "]", ".", "append", "(", "\n", "macro_metric_fc", "(", "total_tgt_set", ",", "total_correctly_matched", ")", ")", "\n", "macro_metrics", "[", "'present'", "]", ".", "append", "(", "\n", "macro_metric_fc", "(", "present_tgt_set", ",", "present_correctly_matched", ")", ")", "\n", "\n", "macro_metrics", "[", "'absent'", "]", ".", "append", "(", "\n", "macro_metric_fc", "(", "absent_tgt_set", ",", "absent_correctly_matched", ")", ")", "\n", "\n", "cnt", "+=", "1", "\n", "\n", "# compute the corpus evaluation", "\n", "", "print", "(", "'#(Ground-truth Keyphrase)=%d'", "%", "num_groundtruth", ")", "\n", "print", "(", "'#(Present Ground-truth Keyphrase)=%d'", "%", "num_present_groundtruth", ")", "\n", "print", "(", "'#(Absent Ground-truth Keyphrase)=%d'", "%", "num_absent_groundtruth", ")", "\n", "\n", "print", "(", "'#(Total Num of Present Preds Per Example)=%d'", "%", "ave_num_present_preds", ")", "\n", "print", "(", "'#(Total Num of Absent Preds Per Example)=%d'", "%", "ave_num_absent_preds", ")", "\n", "print", "(", "'#(Ave Num of Present Preds Per Example)=%d'", "%", "(", "ave_num_present_preds", "/", "(", "cnt", "-", "1", ")", ")", ")", "\n", "print", "(", "'#(Ave Num of Absent Preds Per Example)=%d'", "%", "(", "ave_num_absent_preds", "/", "(", "cnt", "-", "1", ")", ")", ")", "\n", "print", "(", "'#(Min Num of Present Preds Per Example)=%d'", "%", "min_num_present_preds", ")", "\n", "print", "(", "'#(Min Num of Absent Preds Per Example)=%d'", "%", "min_num_absent_preds", ")", "\n", "\n", "# calculate and print the MAP metrics, some code are borrowed from the internet", "\n", "map_score_fc", "(", "total_correctly_matched_at", ",", "total_target_lens_list", ",", "keyphrase_type", "=", "'total'", ")", "\n", "map_score_fc", "(", "present_correctly_matched_at", ",", "present_target_lens_list", ",", "keyphrase_type", "=", "'present'", ")", "\n", "map_score_fc", "(", "absent_correctly_matched_at", ",", "absent_target_lens_list", ",", "keyphrase_type", "=", "'absent'", ")", "\n", "\n", "# calculate and print the Micro and Macro averaged F1, P, R metrics", "\n", "micro_ave_fc", "(", "macro_metrics", "[", "'total'", "]", ",", "keyphrase_type", "=", "'total'", ")", "\n", "micro_ave_fc", "(", "macro_metrics", "[", "'present'", "]", ",", "keyphrase_type", "=", "'present'", ")", "\n", "micro_ave_fc", "(", "macro_metrics", "[", "'absent'", "]", ",", "keyphrase_type", "=", "'absent'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.evaluation_utils.in_context2": [[188, 197], ["range", "len", "len", "len"], "function", ["None"], ["", "def", "in_context2", "(", "context_list", ",", "tgt_list", ")", ":", "\n", "    ", "match", "=", "False", "\n", "for", "c_idx", "in", "range", "(", "len", "(", "context_list", ")", "-", "len", "(", "tgt_list", ")", "+", "1", ")", ":", "\n", "        ", "context_piece", "=", "' '", ".", "join", "(", "context_list", "[", "c_idx", ":", "c_idx", "+", "len", "(", "tgt_list", ")", "]", ")", "\n", "tgt_piece", "=", "' '", ".", "join", "(", "tgt_list", ")", "\n", "if", "context_piece", "==", "tgt_piece", ":", "\n", "            ", "match", "=", "True", "\n", "break", "\n", "", "", "return", "match", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.evaluation_utils.precision_at_k": [[199, 226], ["numpy.mean", "ValueError", "numpy.asarray"], "function", ["None"], ["", "def", "precision_at_k", "(", "r", ",", "k", ")", ":", "\n", "    ", "\"\"\"Score is precision @ k\n    Relevance is binary (nonzero is relevant).\n    >>> r = [0, 0, 1]\n    >>> precision_at_k(r, 1)\n    0.0\n    >>> precision_at_k(r, 2)\n    0.0\n    >>> precision_at_k(r, 3)\n    0.33333333333333331\n    >>> precision_at_k(r, 4)\n    Traceback (most recent call last):\n        File \"<stdin>\", line 1, in ?\n    ValueError: Relevance score length < k\n    Args:\n        r: Relevance scores (list or numpy) in rank order\n            (first element is the first item)\n    Returns:\n        Precision @ k\n    Raises:\n        ValueError: len(r) must be >= k\n    \"\"\"", "\n", "assert", "k", ">=", "1", "\n", "r", "=", "np", ".", "asarray", "(", "r", ")", "[", ":", "k", "]", "!=", "0", "\n", "if", "r", ".", "size", "!=", "k", ":", "\n", "        ", "raise", "ValueError", "(", "'Relevance score length < k'", ")", "\n", "", "return", "np", ".", "mean", "(", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.evaluation_utils.average_precision": [[228, 251], ["numpy.asarray", "evaluation_utils.precision_at_k", "numpy.mean", "range", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.precision_at_k"], ["", "def", "average_precision", "(", "r", ",", "target_num", "=", "None", ")", ":", "\n", "    ", "\"\"\"Score is average precision (area under PR curve)\n    Relevance is binary (nonzero is relevant).\n    >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n    >>> delta_r = 1. / sum(r)\n    >>> sum([sum(r[:x + 1]) / (x + 1.) * delta_r for x, y in enumerate(r) if y])\n    0.7833333333333333\n    >>> average_precision(r)\n    0.78333333333333333\n    Args:\n        r: Relevance scores (list or numpy) in rank order\n            (first element is the first item)\n    Returns:\n        Average precision\n    \"\"\"", "\n", "r", "=", "np", ".", "asarray", "(", "r", ")", "!=", "0", "\n", "out", "=", "[", "precision_at_k", "(", "r", ",", "k", "+", "1", ")", "for", "k", "in", "range", "(", "r", ".", "size", ")", "if", "r", "[", "k", "]", "]", "\n", "if", "not", "out", ":", "\n", "        ", "return", "0.", "\n", "", "if", "target_num", ":", "\n", "        ", "return", "np", ".", "sum", "(", "out", ")", "*", "1.0", "/", "target_num", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "mean", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.evaluation_utils.mean_average_precision": [[253, 272], ["numpy.mean", "numpy.mean", "evaluation_utils.average_precision", "evaluation_utils.average_precision", "zip"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.average_precision", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.average_precision"], ["", "", "def", "mean_average_precision", "(", "rs", ",", "target_nums_list", ")", ":", "\n", "    ", "\"\"\"Score is mean average precision\n    Relevance is binary (nonzero is relevant).\n    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n    >>> mean_average_precision(rs)\n    0.78333333333333333\n    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0]]\n    >>> mean_average_precision(rs)\n    0.39166666666666666\n    Args:\n        rs: Iterator of relevance scores (list or numpy) in rank order\n            (first element is the first item)\n    Returns:\n        Mean average precision\n    \"\"\"", "\n", "if", "target_nums_list", ":", "\n", "        ", "return", "np", ".", "mean", "(", "[", "average_precision", "(", "r", ",", "target_num", ")", "for", "r", ",", "target_num", "in", "zip", "(", "rs", ",", "target_nums_list", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "mean", "(", "[", "average_precision", "(", "r", ")", "for", "r", "in", "rs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.evaluation_utils.map_score_fc": [[274, 285], ["print", "evaluation_utils.mean_average_precision", "evaluation_utils.mean_average_precision", "evaluation_utils.mean_average_precision", "evaluation_utils.mean_average_precision", "print", "print"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.mean_average_precision", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.mean_average_precision", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.mean_average_precision", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.mean_average_precision"], ["", "", "def", "map_score_fc", "(", "correctly_matched_at", ",", "target_lens_list", "=", "None", ",", "keyphrase_type", "=", "''", ")", ":", "\n", "    ", "assert", "keyphrase_type", "!=", "''", "\n", "print", "(", "'\\nBegin'", "+", "'='", "*", "20", "+", "keyphrase_type", "+", "'='", "*", "20", "+", "'Begin'", ")", "\n", "map_5", "=", "mean_average_precision", "(", "correctly_matched_at", "[", "'5'", "]", ",", "target_lens_list", ")", "\n", "map_10", "=", "mean_average_precision", "(", "correctly_matched_at", "[", "'10'", "]", ",", "target_lens_list", ")", "\n", "map_15", "=", "mean_average_precision", "(", "correctly_matched_at", "[", "'15'", "]", ",", "target_lens_list", ")", "\n", "map_50", "=", "mean_average_precision", "(", "correctly_matched_at", "[", "'50'", "]", ",", "target_lens_list", ")", "\n", "\n", "output_str", "=", "'MAP_%s:\\t\\t@5=%f, @10=%f, @15=%f, @50=%f'", "%", "(", "keyphrase_type", ",", "map_5", ",", "map_10", ",", "map_15", ",", "map_50", ")", "\n", "print", "(", "output_str", ")", "\n", "print", "(", "'End'", "+", "'='", "*", "20", "+", "keyphrase_type", "+", "'='", "*", "20", "+", "'End'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.evaluation_utils.macro_metric_fc": [[287, 310], ["len", "len", "sum", "float", "float", "len", "sum", "float", "float", "float", "sum", "len"], "function", ["None"], ["", "def", "macro_metric_fc", "(", "tgt_set", ",", "correctly_matched", ")", ":", "\n", "    ", "metric_dict", "=", "{", "}", "\n", "for", "number_to_predict", "in", "[", "5", ",", "10", ",", "15", ",", "50", "]", ":", "\n", "        ", "metric_dict", "[", "'target_number'", "]", "=", "len", "(", "tgt_set", ")", "\n", "metric_dict", "[", "'prediction_number'", "]", "=", "len", "(", "correctly_matched", ")", "\n", "metric_dict", "[", "'correct_number@%d'", "%", "number_to_predict", "]", "=", "sum", "(", "correctly_matched", "[", ":", "number_to_predict", "]", ")", "\n", "\n", "metric_dict", "[", "'p@%d'", "%", "number_to_predict", "]", "=", "float", "(", "sum", "(", "correctly_matched", "[", ":", "number_to_predict", "]", ")", ")", "/", "float", "(", "\n", "number_to_predict", ")", "\n", "\n", "if", "len", "(", "tgt_set", ")", "!=", "0", ":", "\n", "            ", "metric_dict", "[", "'r@%d'", "%", "number_to_predict", "]", "=", "float", "(", "sum", "(", "correctly_matched", "[", ":", "number_to_predict", "]", ")", ")", "/", "float", "(", "\n", "len", "(", "tgt_set", ")", ")", "\n", "", "else", ":", "\n", "            ", "metric_dict", "[", "'r@%d'", "%", "number_to_predict", "]", "=", "0", "\n", "\n", "", "if", "metric_dict", "[", "'p@%d'", "%", "number_to_predict", "]", "+", "metric_dict", "[", "'r@%d'", "%", "number_to_predict", "]", "!=", "0", ":", "\n", "            ", "metric_dict", "[", "'f1@%d'", "%", "number_to_predict", "]", "=", "2", "*", "metric_dict", "[", "'p@%d'", "%", "number_to_predict", "]", "*", "metric_dict", "[", "\n", "'r@%d'", "%", "number_to_predict", "]", "/", "float", "(", "\n", "metric_dict", "[", "'p@%d'", "%", "number_to_predict", "]", "+", "metric_dict", "[", "'r@%d'", "%", "number_to_predict", "]", ")", "\n", "", "else", ":", "\n", "            ", "metric_dict", "[", "'f1@%d'", "%", "number_to_predict", "]", "=", "0", "\n", "", "", "return", "metric_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.KG-KE-KR.evaluation_utils.micro_ave_fc": [[312, 359], ["print", "len", "sum", "sum", "sum", "print", "print", "print", "print", "float", "float", "float", "float", "float", "float", "min", "sum", "sum", "sum", "float", "float", "float"], "function", ["None"], ["", "def", "micro_ave_fc", "(", "macro_metrics", ",", "keyphrase_type", "=", "'total'", ")", ":", "\n", "    ", "print", "(", "'\\nBegin'", "+", "'='", "*", "20", "+", "keyphrase_type", "+", "'='", "*", "20", "+", "'Begin'", ")", "\n", "real_test_size", "=", "len", "(", "macro_metrics", ")", "\n", "overall_score", "=", "{", "}", "\n", "for", "k", "in", "[", "5", ",", "10", ",", "15", ",", "50", "]", ":", "\n", "        ", "correct_number", "=", "sum", "(", "[", "m", "[", "'correct_number@%d'", "%", "k", "]", "for", "m", "in", "macro_metrics", "]", ")", "\n", "overall_target_number", "=", "sum", "(", "[", "m", "[", "'target_number'", "]", "for", "m", "in", "macro_metrics", "]", ")", "\n", "overall_prediction_number", "=", "sum", "(", "[", "min", "(", "m", "[", "'prediction_number'", "]", ",", "k", ")", "for", "m", "in", "macro_metrics", "]", ")", "\n", "\n", "# Compute the Macro Measures, by averaging the macro-score of each prediction", "\n", "overall_score", "[", "'p@%d'", "%", "k", "]", "=", "float", "(", "sum", "(", "[", "m", "[", "'p@%d'", "%", "k", "]", "for", "m", "in", "macro_metrics", "]", ")", ")", "/", "float", "(", "real_test_size", ")", "\n", "overall_score", "[", "'r@%d'", "%", "k", "]", "=", "float", "(", "sum", "(", "[", "m", "[", "'r@%d'", "%", "k", "]", "for", "m", "in", "macro_metrics", "]", ")", ")", "/", "float", "(", "real_test_size", ")", "\n", "overall_score", "[", "'f1@%d'", "%", "k", "]", "=", "float", "(", "sum", "(", "[", "m", "[", "'f1@%d'", "%", "k", "]", "for", "m", "in", "macro_metrics", "]", ")", ")", "/", "float", "(", "real_test_size", ")", "\n", "\n", "# Print basic statistics", "\n", "output_str", "=", "'Overall - valid testing data=%d, Number of Target=%d/%d, Number of Prediction=%d, Number of Correct=%d'", "%", "(", "\n", "real_test_size", ",", "\n", "overall_target_number", ",", "overall_target_number", ",", "\n", "overall_prediction_number", ",", "correct_number", "\n", ")", "\n", "print", "(", "output_str", ")", "\n", "# Print Macro-average performance", "\n", "output_str", "=", "'Macro_%s_%d:\\t\\tP@%d=%f, R@%d=%f, F1@%d=%f'", "%", "(", "\n", "keyphrase_type", ",", "k", ",", "\n", "k", ",", "overall_score", "[", "'p@%d'", "%", "k", "]", ",", "\n", "k", ",", "overall_score", "[", "'r@%d'", "%", "k", "]", ",", "\n", "k", ",", "overall_score", "[", "'f1@%d'", "%", "k", "]", "\n", ")", "\n", "print", "(", "output_str", ")", "\n", "\n", "# Print Micro-average performance", "\n", "overall_score", "[", "'micro_p@%d'", "%", "k", "]", "=", "correct_number", "/", "float", "(", "overall_prediction_number", ")", "if", "overall_prediction_number", "!=", "0", "else", "0", "\n", "overall_score", "[", "'micro_r@%d'", "%", "k", "]", "=", "correct_number", "/", "float", "(", "overall_target_number", ")", "if", "overall_prediction_number", "!=", "0", "else", "0", "\n", "if", "overall_score", "[", "'micro_p@%d'", "%", "k", "]", "+", "overall_score", "[", "'micro_r@%d'", "%", "k", "]", ">", "0", ":", "\n", "            ", "overall_score", "[", "'micro_f1@%d'", "%", "k", "]", "=", "2", "*", "overall_score", "[", "'micro_p@%d'", "%", "k", "]", "*", "overall_score", "[", "\n", "'micro_r@%d'", "%", "k", "]", "/", "float", "(", "overall_score", "[", "'micro_p@%d'", "%", "k", "]", "+", "overall_score", "[", "'micro_r@%d'", "%", "k", "]", ")", "\n", "", "else", ":", "\n", "            ", "overall_score", "[", "'micro_f1@%d'", "%", "k", "]", "=", "0", "\n", "\n", "", "output_str", "=", "'Micro_%s_%d:\\t\\tP@%d=%f, R@%d=%f, F1@%d=%f'", "%", "(", "\n", "keyphrase_type", ",", "k", ",", "\n", "k", ",", "overall_score", "[", "'micro_p@%d'", "%", "k", "]", ",", "\n", "k", ",", "overall_score", "[", "'micro_r@%d'", "%", "k", "]", ",", "\n", "k", ",", "overall_score", "[", "'micro_f1@%d'", "%", "k", "]", "\n", ")", "\n", "print", "(", "output_str", ")", "\n", "print", "(", "'End'", "+", "'='", "*", "20", "+", "keyphrase_type", "+", "'='", "*", "20", "+", "'End'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_multi.ErrorHandler.__init__": [[58, 68], ["threading.Thread", "train_multi.ErrorHandler.error_thread.start", "signal.signal"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.start"], ["def", "__init__", "(", "self", ",", "error_queue", ")", ":", "\n", "        ", "\"\"\" init error handler \"\"\"", "\n", "import", "signal", "\n", "import", "threading", "\n", "self", ".", "error_queue", "=", "error_queue", "\n", "self", ".", "children_pids", "=", "[", "]", "\n", "self", ".", "error_thread", "=", "threading", ".", "Thread", "(", "\n", "target", "=", "self", ".", "error_listener", ",", "daemon", "=", "True", ")", "\n", "self", ".", "error_thread", ".", "start", "(", ")", "\n", "signal", ".", "signal", "(", "signal", ".", "SIGUSR1", ",", "self", ".", "signal_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_multi.ErrorHandler.add_child": [[69, 72], ["train_multi.ErrorHandler.children_pids.append"], "methods", ["None"], ["", "def", "add_child", "(", "self", ",", "pid", ")", ":", "\n", "        ", "\"\"\" error handler \"\"\"", "\n", "self", ".", "children_pids", ".", "append", "(", "pid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_multi.ErrorHandler.error_listener": [[73, 78], ["train_multi.ErrorHandler.error_queue.get", "train_multi.ErrorHandler.error_queue.put", "os.kill", "os.getpid"], "methods", ["None"], ["", "def", "error_listener", "(", "self", ")", ":", "\n", "        ", "\"\"\" error listener \"\"\"", "\n", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "self", ".", "error_queue", ".", "put", "(", "(", "rank", ",", "original_trace", ")", ")", "\n", "os", ".", "kill", "(", "os", ".", "getpid", "(", ")", ",", "signal", ".", "SIGUSR1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_multi.ErrorHandler.signal_handler": [[79, 88], ["train_multi.ErrorHandler.error_queue.get", "Exception", "os.kill"], "methods", ["None"], ["", "def", "signal_handler", "(", "self", ",", "signalnum", ",", "stackframe", ")", ":", "\n", "        ", "\"\"\" signal handler \"\"\"", "\n", "for", "pid", "in", "self", ".", "children_pids", ":", "\n", "            ", "os", ".", "kill", "(", "pid", ",", "signal", ".", "SIGINT", ")", "# kill children processes", "\n", "", "(", "rank", ",", "original_trace", ")", "=", "self", ".", "error_queue", ".", "get", "(", ")", "\n", "msg", "=", "\"\"\"\\n\\n-- Tracebacks above this line can probably\n                 be ignored --\\n\\n\"\"\"", "\n", "msg", "+=", "original_trace", "\n", "raise", "Exception", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_multi.main": [[17, 39], ["len", "torch.multiprocessing.get_context", "torch.multiprocessing.get_context.SimpleQueue", "train_multi.ErrorHandler", "range", "procs.append", "procs[].start", "onmt.utils.logging.logger.info", "train_multi.ErrorHandler.add_child", "p.join", "torch.multiprocessing.get_context.Process"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.start", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_multi.ErrorHandler.add_child"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "\"\"\" Spawns 1 process per GPU \"\"\"", "\n", "nb_gpu", "=", "len", "(", "opt", ".", "gpuid", ")", "\n", "mp", "=", "torch", ".", "multiprocessing", ".", "get_context", "(", "'spawn'", ")", "\n", "\n", "# Create a thread to listen for errors in the child processes.", "\n", "error_queue", "=", "mp", ".", "SimpleQueue", "(", ")", "\n", "error_handler", "=", "ErrorHandler", "(", "error_queue", ")", "\n", "\n", "# Train with multiprocessing.", "\n", "procs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nb_gpu", ")", ":", "\n", "        ", "opt", ".", "gpu_rank", "=", "i", "\n", "opt", ".", "device_id", "=", "i", "\n", "\n", "procs", ".", "append", "(", "mp", ".", "Process", "(", "target", "=", "run", ",", "args", "=", "(", "\n", "opt", ",", "error_queue", ",", ")", ",", "daemon", "=", "True", ")", ")", "\n", "procs", "[", "i", "]", ".", "start", "(", ")", "\n", "logger", ".", "info", "(", "\" Starting process pid: %d  \"", "%", "procs", "[", "i", "]", ".", "pid", ")", "\n", "error_handler", ".", "add_child", "(", "procs", "[", "i", "]", ".", "pid", ")", "\n", "", "for", "p", "in", "procs", ":", "\n", "        ", "p", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_multi.run": [[41, 52], ["onmt.utils.distributed.multi_init", "onmt.utils.distributed.multi_init", "onmt.train_single.main", "error_queue.put", "traceback.format_exc"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.multi_init", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.multi_init", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.main"], ["", "", "def", "run", "(", "opt", ",", "error_queue", ")", ":", "\n", "    ", "\"\"\" run process \"\"\"", "\n", "try", ":", "\n", "        ", "opt", ".", "gpu_rank", "=", "onmt", ".", "utils", ".", "distributed", ".", "multi_init", "(", "opt", ")", "\n", "single_main", "(", "opt", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "pass", "# killed by parent, do nothing", "\n", "", "except", "Exception", ":", "\n", "# propagate exception to parent process, keeping original traceback", "\n", "        ", "import", "traceback", "\n", "error_queue", ".", "put", "(", "(", "opt", ".", "gpu_rank", ",", "traceback", ".", "format_exc", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.MarkdownHelpFormatter._format_usage": [[707, 709], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.MarkdownHelpFormatter.format_help": [[710, 714], ["print", "super().format_help"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.MarkdownHelpFormatter.format_help"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.MarkdownHelpFormatter.start_section": [[715, 718], ["super().start_section"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.MarkdownHelpFormatter.start_section"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.MarkdownHelpFormatter._format_action": [[719, 731], ["lines.append", "lines.extend", "opts.MarkdownHelpFormatter._expand_help", "lines.extend", "opts.MarkdownHelpFormatter._split_lines"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.MarkdownHelpAction.__init__": [[736, 745], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.MarkdownHelpAction.__call__": [[746, 750], ["parser.print_help", "parser.exit"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.DeprecateAction.__init__": [[755, 758], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.DeprecateAction.__call__": [[759, 763], ["argparse.ArgumentTypeError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.model_opts": [[8, 154], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["def", "model_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\"\n    These options are passed to the construction of the model.\n    Be careful with these as they will be used during translation.\n    \"\"\"", "\n", "\n", "# Embedding Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embeddings'", ")", "\n", "group", ".", "add_argument", "(", "'-src_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for src.'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Word embedding size for tgt.'", ")", "\n", "group", ".", "add_argument", "(", "'-word_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Word embedding size for src and tgt.'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-share_decoder_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a shared weight matrix for the input and\n                       output word  embeddings in the decoder.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Share the word embeddings between encoder\n                       and decoder. Need to use shared dictionary for this\n                       option.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-position_encoding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use a sin to mark relative words positions.\n                       Necessary for non-RNN style models.\n                       \"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model-Embedding Features'", ")", "\n", "group", ".", "add_argument", "(", "'-feat_merge'", ",", "type", "=", "str", ",", "default", "=", "'concat'", ",", "\n", "choices", "=", "[", "'concat'", ",", "'sum'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"Merge action for incorporating features embeddings.\n                       Options [concat|sum|mlp].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_size'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"If specified, feature embedding sizes\n                       will be set to this. Otherwise, feat_vec_exponent\n                       will be used.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-feat_vec_exponent'", ",", "type", "=", "float", ",", "default", "=", "0.7", ",", "\n", "help", "=", "\"\"\"If -feat_merge_size is not set, feature\n                       embedding sizes will be set to N^feat_vec_exponent\n                       where N is the number of values the feature takes.\"\"\"", ")", "\n", "\n", "# KG-KE-KR-M: add for KE-KG-KR", "\n", "group", ".", "add_argument", "(", "'-key_model'", ",", "type", "=", "str", ",", "default", "=", "'key_generator'", ",", "\n", "choices", "=", "[", "'key_selector'", ",", "'key_generator'", ",", "'key_end2end'", "]", ",", "\n", "help", "=", "\"\"\"Type of model to use. Options are\n                               [key_selector|key_generator|key_end2end].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-not_use_sel_probs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Do not use the selection probs to rescale the attention score\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-only_rescale_copy'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Only use the selector probs to rescale copy probabilities\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-no_sftmax_bf_rescale'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use the sigmoid function + summation normalization to normalize the attn scores instead of softmax\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-use_gt_sel_probs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use the binary ground-truth of the selector probabilities as the output of the selector\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-use_retrieved_keys'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use the retrieved_keys as the extra information for keyphrase generation\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-rk_to_src_attn'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Use the final state of retrieved_keys as the extra information for src attention\"\"\"", ")", "\n", "# KG-KE-KR-M: add for selector", "\n", "group", ".", "add_argument", "(", "'-sel_classifier'", ",", "type", "=", "str", ",", "default", "=", "'complex_Nallapati'", ",", "\n", "choices", "=", "[", "'simple_fc'", ",", "'complex_Nallapati'", "]", ",", "\n", "help", "=", "\"\"\"Type of selector's classifier to use. Options are\n                                   [simple_fc|complex_Nallapati].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-selector_share_embeddings'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Share the word embeddings between encoder\n                           and selector.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-detach_sel_probs'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Detach the probs of the selector from the graph.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-e2e_type'", ",", "type", "=", "str", ",", "default", "=", "'separate_enc_sel'", ",", "\n", "choices", "=", "[", "'separate_enc_sel'", ",", "'share_enc_sel'", "]", ",", "\n", "help", "=", "\"\"\"Whether share the embedding and BiRNN encoding layers of the encoder and selector.\n                       Options are [separate_enc_sel|share_enc_sel].\"\"\"", ")", "\n", "\n", "# Encoder-Deocder Options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Encoder-Decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-model_type'", ",", "default", "=", "'text'", ",", "\n", "help", "=", "\"\"\"Type of source model to use. Allows\n                       the system to incorporate non-text inputs.\n                       Options are [text|img|audio].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-encoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'brnn'", "]", ",", "\n", "help", "=", "\"\"\"Options are [rnn|brnn].\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decoder_type'", ",", "type", "=", "str", ",", "default", "=", "'rnn'", ",", "\n", "choices", "=", "[", "'rnn'", "]", ",", "\n", "help", "=", "\"\"\"Options are [rnn].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-layers'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'Number of layers in enc/dec.'", ")", "\n", "group", ".", "add_argument", "(", "'-enc_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the encoder'", ")", "\n", "group", ".", "add_argument", "(", "'-dec_layers'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of layers in the decoder'", ")", "\n", "group", ".", "add_argument", "(", "'-rnn_size'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "'Size of rnn hidden states'", ")", "\n", "group", ".", "add_argument", "(", "'-cnn_kernel_width'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"\"\"Size of windows in the cnn, the kernel_size is\n                       (cnn_kernel_width, 1) in conv layer\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-input_feed'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Feed the context vector at each time step as\n                       additional input (via concatenation with the word\n                       embeddings) to the decoder.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-bridge'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Have an additional layer between the last encoder\n                       state and the first decoder state\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'LSTM'", ",", "\n", "choices", "=", "[", "'LSTM'", ",", "'GRU'", ",", "'SRU'", "]", ",", "\n", "action", "=", "CheckSRU", ",", "\n", "help", "=", "\"\"\"The gate type to use in the RNNs\"\"\"", ")", "\n", "# group.add_argument('-residual',   action=\"store_true\",", "\n", "#                     help=\"Add residual connections between RNN layers.\")", "\n", "\n", "group", ".", "add_argument", "(", "'-brnn'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `encoder_type`.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-context_gate'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "choices", "=", "[", "'source'", ",", "'target'", ",", "'both'", "]", ",", "\n", "help", "=", "\"\"\"Type of context gate to use.\n                       Do not select for no context gate.\"\"\"", ")", "\n", "\n", "# Attention options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model- Attention'", ")", "\n", "group", ".", "add_argument", "(", "'-global_attention'", ",", "type", "=", "str", ",", "default", "=", "'general'", ",", "\n", "choices", "=", "[", "'dot'", ",", "'general'", ",", "'mlp'", "]", ",", "\n", "help", "=", "\"\"\"The attention type to use:\n                       dotprod or general (Luong) or MLP (Bahdanau)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-self_attn_type'", ",", "type", "=", "str", ",", "default", "=", "\"scaled-dot\"", ",", "\n", "help", "=", "\"\"\"Self attention type in Transformer decoder\n                       layer -- currently \"scaled-dot\" or \"average\" \"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-heads'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'Number of heads for transformer self-attention'", ")", "\n", "group", ".", "add_argument", "(", "'-transformer_ff'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "'Size of hidden transformer feed-forward'", ")", "\n", "\n", "\n", "# Genenerator and loss options.", "\n", "group", ".", "add_argument", "(", "'-copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train copy attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-copy_attn_force'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'When available, train to copy.'", ")", "\n", "group", ".", "add_argument", "(", "'-reuse_copy_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Reuse standard attention for copy\"", ")", "\n", "group", ".", "add_argument", "(", "'-copy_loss_by_seqlength'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Divide copy loss by length of sequence\"", ")", "\n", "group", ".", "add_argument", "(", "'-coverage_attn'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Train a coverage attention layer.'", ")", "\n", "group", ".", "add_argument", "(", "'-lambda_coverage'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.preprocess_opts": [[156, 255], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["\n", "\n", "", "def", "preprocess_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Pre-procesing options \"\"\"", "\n", "# Data options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"\"\"Type of the source input.\n                       Options are [text|img].\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-train_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training target data\"", ")", "\n", "# KG-KE-KR-M: add for keyword extraction training", "\n", "group", ".", "add_argument", "(", "'-train_key_indicators'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training key_indicators data\"", ")", "\n", "# KG-KE-KR-M: add for retrieved keyphrases of training set", "\n", "group", ".", "add_argument", "(", "'-train_retrieved_keys'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the training retrieved_keyphrases data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-valid_src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation source data\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation target data\"", ")", "\n", "# KG-KE-KR-M: add for keyword extraction validation", "\n", "group", ".", "add_argument", "(", "'-valid_key_indicators'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the valid key_indicators data\"", ")", "\n", "# KG-KE-KR-M: add for retrieved keyphrases of validation set", "\n", "group", ".", "add_argument", "(", "'-valid_retrieved_keys'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to the validation retrieved_keyphrases data\"", ")", "\n", "\n", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Source directory for image or audio files.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Output file for the prepared data\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-max_shard_size'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"For text corpus of large volume, it will\n                       be divided into shards of this size to preprocess.\n                       If 0, the data will be handled as a whole. The unit\n                       is in bytes. Optimal value should be multiples of\n                       64 bytes. A commonly used sharding value is 131072000.\n                       It is recommended to ensure the corpus is shuffled\n                       before sharding.\"\"\"", ")", "\n", "\n", "# Dictionary options, for text corpus", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Vocab'", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"\"\"Path to an existing source vocabulary. Format:\n                       one word per line.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"\"\"Path to an existing target vocabulary. Format:\n                       one word per line.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-features_vocabs_prefix'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "\"Path prefix to existing features vocabularies\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the source vocabulary\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_vocab_size'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Size of the target vocabulary\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_words_min_frequency'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "# Truncation options, for text corpus", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Pruning'", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum source sequence length\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate source sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Maximum target sequence length to keep.\"", ")", "\n", "group", ".", "add_argument", "(", "'-tgt_seq_length_trunc'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Truncate target sequence length.\"", ")", "\n", "group", ".", "add_argument", "(", "'-lower'", ",", "action", "=", "'store_true'", ",", "help", "=", "'lowercase data'", ")", "\n", "\n", "# Data processing options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Random'", ")", "\n", "group", ".", "add_argument", "(", "'-shuffle'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Shuffle data\"", ")", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "3435", ",", "\n", "help", "=", "\"Random seed\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "\"Report status every this many sentences\"", ")", "\n", "group", ".", "add_argument", "(", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "\n", "# Options most relevant to speech", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.train_opts": [[257, 486], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "\"Window stride for spectrogram in seconds.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "\"Window type for spectrogram generation.\"", ")", "\n", "\n", "\n", "", "def", "train_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Training and saving options \"\"\"", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'General'", ")", "\n", "group", ".", "add_argument", "(", "'-data'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Path prefix to the \".train.pt\" and\n                       \".valid.pt\" file path from preprocess.py\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-vocab'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Path prefix to the \".vocab.pt\" and from preprocess.py\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "'model'", ",", "\n", "help", "=", "\"\"\"Model filename (the model will be saved as\n                       <save_model>_N.pt where N is the number\n                       of steps\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-save_checkpoint_steps'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "\"\"\"Save a checkpoint every X steps\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-keep_checkpoint'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"Keep X checkpoints (negative: keep all)\"\"\"", ")", "\n", "\n", "# GPU", "\n", "group", ".", "add_argument", "(", "'-gpuid'", ",", "default", "=", "[", "]", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Use CUDA on the listed devices.\"", ")", "\n", "group", ".", "add_argument", "(", "'-gpu_rank'", ",", "default", "=", "0", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Rank the current gpu device.\"", ")", "\n", "group", ".", "add_argument", "(", "'-device_id'", ",", "default", "=", "0", ",", "nargs", "=", "'+'", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Rank the current gpu device.\"", ")", "\n", "group", ".", "add_argument", "(", "'-gpu_backend'", ",", "default", "=", "'nccl'", ",", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Type of torch distributed backend\"", ")", "\n", "group", ".", "add_argument", "(", "'-gpu_verbose_level'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Gives more info on each process per GPU.\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-seed'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"Random seed used for the experiments\n                       reproducibility.\"\"\"", ")", "\n", "\n", "# Init options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Initialization'", ")", "\n", "group", ".", "add_argument", "(", "'-param_init'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "\n", "help", "=", "\"\"\"Parameters are initialized over uniform distribution\n                       with support (-param_init, param_init).\n                       Use 0 to not use initialization\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-param_init_glorot'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Init parameters with xavier_uniform.\n                       Required for transfomer.\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-train_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If training from a checkpoint then this is the\n                       path to the pretrained model's state_dict.\"\"\"", ")", "\n", "\n", "# KG-KE-KR-M: add for loading a pretrained selector", "\n", "group", ".", "add_argument", "(", "'-load_pretrained_selector_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If loading a pretrained selector from a checkpoint for the end2end model,\n                       then this is the path to the pretrained model's state_dict.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-fix_sel_all'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Fix the pretrained selector.'", ")", "\n", "group", ".", "add_argument", "(", "'-fix_sel_classifier'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Only Fix the classifier of the pretrained selector.'", ")", "\n", "# KG-KE-KR-M: add for loading a pretrained s2s model", "\n", "group", ".", "add_argument", "(", "'-load_pretrained_s2s_generator_from'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "\n", "help", "=", "\"\"\"If loading a pretrained s2s generator from a checkpoint for the end2end model,\n                           then this is the path to the pretrained model's state_dict.\"\"\"", ")", "\n", "\n", "# Pretrained word vectors", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_enc'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the encoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-pre_word_vecs_dec'", ",", "\n", "help", "=", "\"\"\"If a valid path is specified, then this will load\n                       pretrained word embeddings on the decoder side.\n                       See README for specific formatting instructions.\"\"\"", ")", "\n", "# Fixed word vectors", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_enc'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "group", ".", "add_argument", "(", "'-fix_word_vecs_dec'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Fix word embeddings on the encoder side.\"", ")", "\n", "\n", "# Optimization options", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Type'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'Maximum batch size for training'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_type'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", ",", "\"tokens\"", "]", ",", "\n", "help", "=", "\"\"\"Batch grouping for batch_size. Standard\n                               is sents. Tokens will do dynamic batching\"\"\"", ")", "\n", "\n", "# KG-KE-KR-M: changed from [\"sents\", \"tokens\"] to [\"sents\"]", "\n", "group", ".", "add_argument", "(", "'-normalization'", ",", "default", "=", "'sents'", ",", "\n", "choices", "=", "[", "\"sents\"", "]", ",", "\n", "help", "=", "'Normalization method of the gradient.'", ")", "\n", "# KG-KE-KR-M: add for loss computation", "\n", "group", ".", "add_argument", "(", "'-sel_normalize_by_length'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Whether normalize the selector loss by the sequence length before the summation.'", ")", "\n", "group", ".", "add_argument", "(", "'-gen_normalize_by_length'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Whether normalize the generator loss by the sequence length before the summation.'", ")", "\n", "group", ".", "add_argument", "(", "'-incons_normalize_by_length'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Whether normalize the inconsistency loss by the sequence length before the summation.'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-top_k'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "\n", "help", "=", "'The top k attended words for calculating inconsistency loss.'", ")", "\n", "# group.add_argument('-sel_report_topk', type=int, default=20,", "\n", "#                    help='Report the R, P, F1 scores of the predicted sel_report_topk words of the selector')", "\n", "group", ".", "add_argument", "(", "'-pos_weight'", ",", "type", "=", "float", ",", "default", "=", "9.0", ",", "\n", "help", "=", "'The pos_weight for calculating BCE loss for the selector.'", ")", "\n", "group", ".", "add_argument", "(", "'-sel_threshold'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'The probability threshold for selecting as a keyword.'", ")", "\n", "group", ".", "add_argument", "(", "'-sel_train_ratio'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'The probability for training the selector using current batch.'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-sel_lambda'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'The weight for the extraction loss.'", ")", "\n", "group", ".", "add_argument", "(", "'-gen_lambda'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'The weight for the generation loss.'", ")", "\n", "group", ".", "add_argument", "(", "'-incons_lambda'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "'The weight for the inconsistency loss.'", ")", "\n", "\n", "\n", "group", ".", "add_argument", "(", "'-accum_count'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"Accumulate gradient this many times.\n                       Approximately equivalent to updating\n                       batch_size * accum_count batches at once.\n                       Recommended for Transformer.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-valid_steps'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "'Perfom validation every X steps'", ")", "\n", "group", ".", "add_argument", "(", "'-valid_batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'Maximum batch size for validation'", ")", "\n", "group", ".", "add_argument", "(", "'-max_generator_batches'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "\"\"\"Maximum batches of words in a sequence to run\n                        the generator on in parallel. Higher is faster, but\n                        uses more memory.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-train_steps'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "\n", "help", "=", "'Number of training steps'", ")", "\n", "group", ".", "add_argument", "(", "'-epochs'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Deprecated epochs see train_steps'", ")", "\n", "group", ".", "add_argument", "(", "'-optim'", ",", "default", "=", "'sgd'", ",", "\n", "choices", "=", "[", "'sgd'", ",", "'adagrad'", ",", "'adadelta'", ",", "'adam'", ",", "\n", "'sparseadam'", "]", ",", "\n", "help", "=", "\"\"\"Optimization method.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adagrad_accumulator_init'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Initializes the accumulator values in adagrad.\n                       Mirrors the initial_accumulator_value option\n                       in the tensorflow adagrad (use 0.1 for their default).\n                       \"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-max_grad_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "\"\"\"If the norm of the gradient vector exceeds this,\n                       renormalize it to have the norm equal to\n                       max_grad_norm\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "\n", "help", "=", "\"Dropout probability; applied in LSTM stacks.\"", ")", "\n", "group", ".", "add_argument", "(", "'-truncated_decoder'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"\"\"Truncated bptt.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta1'", ",", "type", "=", "float", ",", "default", "=", "0.9", ",", "\n", "help", "=", "\"\"\"The beta1 parameter used by Adam.\n                       Almost without exception a value of 0.9 is used in\n                       the literature, seemingly giving good results,\n                       so we would discourage changing this value from\n                       the default without due consideration.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-adam_beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "\"\"\"The beta2 parameter used by Adam.\n                       Typically a value of 0.999 is recommended, as this is\n                       the value suggested by the original paper describing\n                       Adam, and is also the value adopted in other frameworks\n                       such as Tensorflow and Kerras, i.e. see:\n                       https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n                       https://keras.io/optimizers/ .\n                       Whereas recently the paper \"Attention is All You Need\"\n                       suggested a value of 0.98 for beta2, this parameter may\n                       not work well for normal models / default\n                       baselines.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-label_smoothing'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "\"\"\"Label smoothing value epsilon.\n                       Probabilities of all non-true labels\n                       will be smoothed by epsilon / (vocab_size - 1).\n                       Set to zero to turn off label smoothing.\n                       For more detailed information, see:\n                       https://arxiv.org/abs/1512.00567\"\"\"", ")", "\n", "# learning rate", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Optimization- Rate'", ")", "\n", "group", ".", "add_argument", "(", "'-learning_rate'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "\n", "help", "=", "\"\"\"Starting learning rate.\n                       Recommended settings: sgd = 1, adagrad = 0.1,\n                       adadelta = 1, adam = 0.001\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-learning_rate_decay'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "\"\"\"If update_learning_rate, decay learning rate by\n                       this much if (i) perplexity does not decrease on the\n                       validation set or (ii) steps have gone past\n                       start_decay_steps\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-start_decay_steps'", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"\"\"Start decaying every decay_steps after\n                       start_decay_steps\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-decay_steps'", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"\"\"Decay every decay_steps\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-decay_method'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "choices", "=", "[", "'noam'", "]", ",", "help", "=", "\"Use a custom decay rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "4000", ",", "\n", "help", "=", "\"\"\"Number of warmup steps for custom decay.\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-report_every'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Print stats at this interval.\"", ")", "\n", "group", ".", "add_argument", "(", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp_host'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Send logs to this crayon server.\"", ")", "\n", "group", ".", "add_argument", "(", "'-exp'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Name of the experiment for logging.\"", ")", "\n", "# Use TensorboardX for visualization during training", "\n", "group", ".", "add_argument", "(", "'-tensorboard'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Use tensorboardX for visualization during training.\n                       Must have the library tensorboardX.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "\"-tensorboard_log_dir\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"runs\"", ",", "\n", "help", "=", "\"\"\"Log directory for Tensorboard.\n                       This is also the name of the run.\n                       \"\"\"", ")", "\n", "group", ".", "add_argument", "(", "\"-tensorboard_comment\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"Uncmt\"", ",", "\n", "help", "=", "\"\"\"Comments for the tensorboard runs.\"\"\"", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.translate_opts": [[488, 629], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "# Options most relevant to speech", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "\"Window size for spectrogram in seconds.\"", ")", "\n", "\n", "\n", "", "def", "translate_opts", "(", "parser", ")", ":", "\n", "    ", "\"\"\" Translation / inference options \"\"\"", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Model'", ")", "\n", "group", ".", "add_argument", "(", "'-model'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to model .pt file'", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Data'", ")", "\n", "group", ".", "add_argument", "(", "'-data_type'", ",", "default", "=", "\"text\"", ",", "\n", "help", "=", "\"Type of the source input. Options: [text|img].\"", ")", "\n", "\n", "# KG-KE-KR-M", "\n", "group", ".", "add_argument", "(", "'-key_indicators'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"key word indicators (one line per\n                           sequence)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-retrieved_keys'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"retrieved external keyphrases (one line per\n                               sequence)\"\"\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'-src'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"Source sequence to decode (one line per\n                       sequence)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-src_dir'", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'Source directory for image or audio files'", ")", "\n", "group", ".", "add_argument", "(", "'-tgt'", ",", "\n", "help", "=", "'True target sequence (optional)'", ")", "\n", "group", ".", "add_argument", "(", "'-output'", ",", "default", "=", "'pred.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the predictions (each line will\n                       be the decoded sequence\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-scores_output'", ",", "default", "=", "'pred_scores.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the scores of the predictions\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-sel_probs_output'", ",", "default", "=", "'sel_probs.txt'", ",", "\n", "help", "=", "\"\"\"Path to output the sel_probs of the src words\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_bleu'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report bleu score after translation,\n                       call tools/multi-bleu.perl on command line\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-report_rouge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Report rouge 1/2/3/L/SU4 score after translation\n                       call tools/test_rouge.py on command line\"\"\"", ")", "\n", "\n", "# KG-KE-KR-M: add for evaluations", "\n", "group", ".", "add_argument", "(", "'-kpg_tgt'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"True target sequence\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-kpg_context'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"\"\"True context sequence\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-single_word_maxnum'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"\"\"The maxnum of single word prediction\"\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'-filter_dot_comma_unk'", ",", "type", "=", "bool", ",", "default", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'-match_method'", ",", "type", "=", "str", ",", "default", "=", "'word_match'", ",", "\n", "choices", "=", "[", "'str_match'", ",", "'word_match'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'-splitter'", ",", "type", "=", "str", ",", "default", "=", "';'", ")", "\n", "\n", "# Options most relevant to summarization.", "\n", "group", ".", "add_argument", "(", "'-dynamic_dict'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Create dynamic dictionaries\"", ")", "\n", "group", ".", "add_argument", "(", "'-share_vocab'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Share source and target vocabulary\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Beam'", ")", "\n", "group", ".", "add_argument", "(", "'-fast'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Use fast beam search (some features may not be\n                       supported!)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-beam_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'Beam size'", ")", "\n", "group", ".", "add_argument", "(", "'-min_length'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Minimum prediction length'", ")", "\n", "group", ".", "add_argument", "(", "'-max_length'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'Maximum prediction length.'", ")", "\n", "group", ".", "add_argument", "(", "'-max_sent_length'", ",", "action", "=", "DeprecateAction", ",", "\n", "help", "=", "\"Deprecated, use `-max_length` instead\"", ")", "\n", "\n", "# Alpha and Beta values for Google Length + Coverage penalty", "\n", "# Described here: https://arxiv.org/pdf/1609.08144.pdf, Section 7", "\n", "group", ".", "add_argument", "(", "'-stepwise_penalty'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"\"\"Apply penalty at every decoding step.\n                       Helpful for summary penalty.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-length_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'avg'", "]", ",", "\n", "help", "=", "\"\"\"Length Penalty to use.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-coverage_penalty'", ",", "default", "=", "'none'", ",", "\n", "choices", "=", "[", "'none'", ",", "'wu'", ",", "'summary'", "]", ",", "\n", "help", "=", "\"\"\"Coverage Penalty to use.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-alpha'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "\n", "help", "=", "\"\"\"Google NMT length penalty parameter\n                        (higher = longer generation)\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-beta'", ",", "type", "=", "float", ",", "default", "=", "-", "0.", ",", "\n", "help", "=", "\"\"\"Coverage penalty parameter\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-block_ngram_repeat'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'Block repetition of ngrams during decoding.'", ")", "\n", "group", ".", "add_argument", "(", "'-ignore_when_blocking'", ",", "nargs", "=", "'+'", ",", "type", "=", "str", ",", "\n", "default", "=", "[", "]", ",", "\n", "help", "=", "\"\"\"Ignore these strings when blocking repeats.\n                       You want to block sentence delimiters.\"\"\"", ")", "\n", "group", ".", "add_argument", "(", "'-replace_unk'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"\"\"Replace the generated UNK tokens with the\n                       source token that had highest attention weight. If\n                       phrase_table is provided, it will lookup the\n                       identified source token and give the corresponding\n                       target token. If it is not provided(or the identified\n                       source token does not exist in the table) then it\n                       will copy the source token\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Logging'", ")", "\n", "group", ".", "add_argument", "(", "'-verbose'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print scores and predictions for each sentence'", ")", "\n", "group", ".", "add_argument", "(", "'-log_file'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Output logs to a file under this path.\"", ")", "\n", "group", ".", "add_argument", "(", "'-attn_debug'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Print best attn for each word'", ")", "\n", "group", ".", "add_argument", "(", "'-dump_beam'", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "'File to dump beam information to.'", ")", "\n", "group", ".", "add_argument", "(", "'-n_best'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"\"\"If verbose is set, will output the n_best\n                       decoded sentences\"\"\"", ")", "\n", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Efficiency'", ")", "\n", "group", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'Batch size'", ")", "\n", "group", ".", "add_argument", "(", "'-gpu'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Device to run on\"", ")", "\n", "\n", "# Options most relevant to speech.", "\n", "group", "=", "parser", ".", "add_argument_group", "(", "'Speech'", ")", "\n", "group", ".", "add_argument", "(", "'-sample_rate'", ",", "type", "=", "int", ",", "default", "=", "16000", ",", "\n", "help", "=", "\"Sample rate.\"", ")", "\n", "group", ".", "add_argument", "(", "'-window_size'", ",", "type", "=", "float", ",", "default", "=", ".02", ",", "\n", "help", "=", "'Window size for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window_stride'", ",", "type", "=", "float", ",", "default", "=", ".01", ",", "\n", "help", "=", "'Window stride for spectrogram in seconds'", ")", "\n", "group", ".", "add_argument", "(", "'-window'", ",", "default", "=", "'hamming'", ",", "\n", "help", "=", "'Window type for spectrogram generation'", ")", "\n", "\n", "\n", "", "def", "add_md_help_argument", "(", "parser", ")", ":", "\n", "    ", "\"\"\" md help parser \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.add_md_help_argument": [[685, 689], ["parser.add_argument"], "function", ["None"], ["default", "=", "default", ",", "\n", "nargs", "=", "0", ",", "\n", "**", "kwargs", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer.__init__": [[102, 137], ["trainer.Trainer.model.train"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer.train"], ["def", "__init__", "(", "self", ",", "key_model", ",", "model", ",", "train_loss", ",", "valid_loss", ",", "optim", ",", "\n", "trunc_size", "=", "0", ",", "shard_size", "=", "None", ",", "data_type", "=", "'text'", ",", "\n", "norm_method", "=", "\"sents\"", ",", "grad_accum_count", "=", "1", ",", "n_gpu", "=", "1", ",", "gpu_rank", "=", "1", ",", "\n", "gpu_verbose_level", "=", "0", ",", "report_manager", "=", "None", ",", "model_saver", "=", "None", ",", "stop_nodecrease_steps", "=", "3", ")", ":", "\n", "# sharding is not convenient to mult-task learning, we avoid it.", "\n", "# assert not shard_size", "\n", "# Basic attributes.", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "train_loss", "=", "train_loss", "\n", "self", ".", "valid_loss", "=", "valid_loss", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "trunc_size", "=", "trunc_size", "\n", "self", ".", "shard_size", "=", "shard_size", "\n", "self", ".", "data_type", "=", "data_type", "\n", "self", ".", "norm_method", "=", "norm_method", "\n", "self", ".", "grad_accum_count", "=", "grad_accum_count", "\n", "self", ".", "n_gpu", "=", "n_gpu", "\n", "self", ".", "gpu_rank", "=", "gpu_rank", "\n", "self", ".", "gpu_verbose_level", "=", "gpu_verbose_level", "\n", "self", ".", "report_manager", "=", "report_manager", "\n", "self", ".", "model_saver", "=", "model_saver", "\n", "# KG-KE-KR-M", "\n", "self", ".", "key_model", "=", "key_model", "\n", "self", ".", "cur_valid_ppl", "=", "None", "\n", "self", ".", "stop_nodecrease_steps", "=", "stop_nodecrease_steps", "\n", "self", ".", "nodecrease_steps", "=", "0", "\n", "\n", "assert", "grad_accum_count", ">", "0", "\n", "if", "grad_accum_count", ">", "1", ":", "\n", "            ", "assert", "(", "self", ".", "trunc_size", "==", "0", ")", ",", "\"\"\"To enable accumulated gradients,\n                   you must disable target sequence truncating.\"\"\"", "\n", "\n", "# Set model in training mode.", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer.train": [[138, 288], ["onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "train_iter_fct", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "trainer.Trainer._start_report_manager", "enumerate", "train_iter_fct", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "train_iter_fct.get_cur_dataset", "true_batchs.append", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "trainer.Trainer._reranker_gradient_accumulation", "trainer.Trainer._maybe_report_training", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "sum", "valid_iter_fct", "trainer.Trainer.validate", "trainer.Trainer._maybe_gather_stats", "trainer.Trainer._report_step", "trainer.Trainer._maybe_save", "trainer.Trainer.ave_loss", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.distributed.all_gather_list", "onmt.utils.distributed.all_gather_list", "onmt.utils.distributed.all_gather_list", "onmt.utils.distributed.all_gather_list", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "len"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._start_report_manager", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.DatasetLazyIter.get_cur_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._reranker_gradient_accumulation", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._maybe_report_training", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer.validate", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._maybe_gather_stats", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr._report_step", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._maybe_save", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.all_gather_list", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.all_gather_list"], ["", "def", "train", "(", "self", ",", "train_iter_fct", ",", "valid_iter_fct", ",", "train_steps", ",", "valid_steps", ")", ":", "\n", "        ", "\"\"\"\n        The main training loops.\n        by iterating over training data (i.e. `train_iter_fct`)\n        and running validation (i.e. iterating over `valid_iter_fct`\n\n        Args:\n            train_iter_fct(function): a function that returns the train\n                iterator. e.g. something like\n                train_iter_fct = lambda: generator(*args, **kwargs)\n            valid_iter_fct(function): same as train_iter_fct, for valid data\n            train_steps(int):\n            valid_steps(int):\n        Return:\n            None\n        \"\"\"", "\n", "logger", ".", "info", "(", "' '", ")", "\n", "logger", ".", "info", "(", "'Start training...'", ")", "\n", "\n", "step", "=", "self", ".", "optim", ".", "_step", "+", "1", "\n", "true_batchs", "=", "[", "]", "\n", "accum", "=", "0", "\n", "normalization", "=", "0", "\n", "train_iter", "=", "train_iter_fct", "(", ")", "\n", "\n", "total_stats", "=", "onmt", ".", "utils", ".", "E2EStatistics", "(", ")", "\n", "report_stats", "=", "onmt", ".", "utils", ".", "E2EStatistics", "(", ")", "\n", "\n", "self", ".", "_start_report_manager", "(", "start_time", "=", "total_stats", ".", "start_time", ")", "\n", "\n", "while", "step", "<=", "train_steps", ":", "\n", "            ", "reduce_counter", "=", "0", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "train_iter", ")", ":", "\n", "# print('batch_idx: {}'.format(i))", "\n", "                ", "if", "self", ".", "n_gpu", "==", "0", "or", "(", "i", "%", "self", ".", "n_gpu", "==", "self", ".", "gpu_rank", ")", ":", "\n", "                    ", "if", "self", ".", "gpu_verbose_level", ">", "1", ":", "\n", "                        ", "logger", ".", "info", "(", "\"GpuRank %d: index: %d accum: %d\"", "\n", "%", "(", "self", ".", "gpu_rank", ",", "i", ",", "accum", ")", ")", "\n", "", "cur_dataset", "=", "train_iter", ".", "get_cur_dataset", "(", ")", "\n", "self", ".", "train_loss", ".", "cur_dataset", "=", "cur_dataset", "\n", "\n", "true_batchs", ".", "append", "(", "batch", ")", "\n", "\n", "if", "self", ".", "norm_method", "==", "\"tokens\"", ":", "\n", "                        ", "num_tokens", "=", "batch", ".", "tgt", "[", "1", ":", "]", ".", "data", ".", "view", "(", "-", "1", ")", ".", "ne", "(", "self", ".", "train_loss", ".", "padding_idx", ")", ".", "sum", "(", ")", "\n", "normalization", "+=", "num_tokens", "\n", "", "else", ":", "\n", "                        ", "normalization", "+=", "batch", ".", "batch_size", "\n", "\n", "", "accum", "+=", "1", "\n", "if", "accum", "==", "self", ".", "grad_accum_count", ":", "\n", "                        ", "reduce_counter", "+=", "1", "\n", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                            ", "logger", ".", "info", "(", "\"GpuRank %d: reduce_counter: %d \\\n                                        n_minibatch %d\"", "\n", "%", "(", "self", ".", "gpu_rank", ",", "reduce_counter", ",", "\n", "len", "(", "true_batchs", ")", ")", ")", "\n", "", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "                            ", "normalization", "=", "sum", "(", "onmt", ".", "utils", ".", "distributed", "\n", ".", "all_gather_list", "\n", "(", "normalization", ")", ")", "\n", "", "if", "self", ".", "key_model", "==", "\"key_selector\"", ":", "\n", "                            ", "self", ".", "_selector_gradient_accumulation", "(", "\n", "true_batchs", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ")", "\n", "", "elif", "self", ".", "key_model", "==", "\"key_end2end\"", ":", "\n", "                            ", "self", ".", "_end2end_gradient_accumulation", "(", "\n", "true_batchs", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "_generator_gradient_accumulation", "(", "\n", "true_batchs", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ")", "\n", "\n", "", "report_stats", "=", "self", ".", "_maybe_report_training", "(", "\n", "step", ",", "train_steps", ",", "\n", "self", ".", "optim", ".", "learning_rate", ",", "\n", "report_stats", ")", "\n", "\n", "true_batchs", "=", "[", "]", "\n", "accum", "=", "0", "\n", "normalization", "=", "0", "\n", "if", "(", "step", "%", "valid_steps", "==", "0", ")", ":", "\n", "                            ", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                                ", "logger", ".", "info", "(", "'GpuRank %d: validate step %d'", "\n", "%", "(", "self", ".", "gpu_rank", ",", "step", ")", ")", "\n", "", "valid_iter", "=", "valid_iter_fct", "(", ")", "\n", "valid_stats", "=", "self", ".", "validate", "(", "valid_iter", ")", "\n", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                                ", "logger", ".", "info", "(", "'GpuRank %d: gather valid stat \\\n                                            step %d'", "%", "(", "self", ".", "gpu_rank", ",", "step", ")", ")", "\n", "", "valid_stats", "=", "self", ".", "_maybe_gather_stats", "(", "valid_stats", ")", "\n", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                                ", "logger", ".", "info", "(", "'GpuRank %d: report stat step %d'", "\n", "%", "(", "self", ".", "gpu_rank", ",", "step", ")", ")", "\n", "\n", "", "self", ".", "_report_step", "(", "self", ".", "optim", ".", "learning_rate", ",", "\n", "step", ",", "train_stats", "=", "total_stats", ",", "valid_stats", "=", "valid_stats", ")", "\n", "\n", "assert", "valid_steps", "==", "self", ".", "model_saver", ".", "save_checkpoint_steps", "\n", "self", ".", "_maybe_save", "(", "step", ",", "valid_stats", ")", "\n", "\n", "if", "self", ".", "key_model", "==", "'key_selector'", ":", "\n", "                                ", "new_valid_ppl", "=", "valid_stats", ".", "sel_ave_loss", "(", ")", "\n", "total_stats", "=", "onmt", ".", "utils", ".", "E2EStatistics", "(", ")", "\n", "", "elif", "self", ".", "key_model", "==", "'key_end2end'", ":", "\n", "                                ", "new_valid_ppl", "=", "valid_stats", ".", "gen_ppl", "(", ")", "\n", "total_stats", "=", "onmt", ".", "utils", ".", "E2EStatistics", "(", ")", "\n", "", "else", ":", "\n", "                                ", "new_valid_ppl", "=", "valid_stats", ".", "gen_ppl", "(", ")", "\n", "total_stats", "=", "onmt", ".", "utils", ".", "E2EStatistics", "(", ")", "\n", "\n", "", "if", "self", ".", "cur_valid_ppl", "is", "not", "None", ":", "\n", "                                ", "if", "self", ".", "cur_valid_ppl", "<", "new_valid_ppl", ":", "\n", "                                    ", "self", ".", "nodecrease_steps", "+=", "1", "\n", "", "else", ":", "\n", "                                    ", "self", ".", "nodecrease_steps", "=", "0", "\n", "", "", "self", ".", "cur_valid_ppl", "=", "new_valid_ppl", "\n", "\n", "", "if", "self", ".", "nodecrease_steps", ">=", "self", ".", "stop_nodecrease_steps", ":", "\n", "                            ", "break", "\n", "", "step", "+=", "1", "\n", "if", "step", ">", "train_steps", ":", "\n", "                            ", "break", "\n", "\n", "", "", "", "", "if", "self", ".", "nodecrease_steps", ">=", "self", ".", "stop_nodecrease_steps", ":", "\n", "                ", "break", "\n", "\n", "", "if", "self", ".", "gpu_verbose_level", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "'GpuRank %d: we completed an epoch \\\n                            at step %d'", "%", "(", "self", ".", "gpu_rank", ",", "step", ")", ")", "\n", "", "train_iter", "=", "train_iter_fct", "(", ")", "\n", "\n", "", "return", "total_stats", "\n", "\n", "", "def", "validate", "(", "self", ",", "valid_iter", ")", ":", "\n", "        ", "\"\"\" Validate model.\n            valid_iter: validate data iterator\n        Returns:\n            :obj:`nmt.Statistics`: validation loss statistics\n        \"\"\"", "\n", "# Set model in validating mode.", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "stats", "=", "onmt", ".", "utils", ".", "E2EStatistics", "(", ")", "\n", "\n", "print_examples", "=", "3", "\n", "for", "batch", "in", "valid_iter", ":", "\n", "            ", "cur_dataset", "=", "valid_iter", ".", "get_cur_dataset", "(", ")", "\n", "self", ".", "valid_loss", ".", "cur_dataset", "=", "cur_dataset", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer.validate": [[289, 355], ["trainer.Trainer.model.eval", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "trainer.Trainer.model.train", "valid_iter.get_cur_dataset", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "trainer.Trainer.model", "trainer.Trainer.valid_loss.monolithic_compute_loss", "onmt.utils.ReRankerStatistics.update", "onmt.utils.ReRankerStatistics.update"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer.train", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.DatasetLazyIter.get_cur_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute.monolithic_compute_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update"], ["\n", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "self", ".", "data_type", ")", "\n", "retrieved_keys", "=", "inputters", ".", "make_features", "(", "batch", ",", "'retrieved_keys'", ",", "self", ".", "data_type", ")", "\n", "if", "self", ".", "data_type", "==", "'text'", ":", "\n", "                ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "_", ",", "rk_lengths", "=", "batch", ".", "retrieved_keys", "\n", "", "else", ":", "\n", "                ", "src_lengths", "=", "None", "\n", "\n", "# F-prop through the model.", "\n", "", "if", "self", ".", "key_model", "==", "\"key_selector\"", ":", "\n", "                ", "logits", ",", "probs", "=", "self", ".", "model", "(", "src", ",", "src_lengths", ")", "\n", "# Compute loss", "\n", "batch_stats", "=", "self", ".", "valid_loss", ".", "monolithic_compute_loss", "(", "batch", ",", "logits", ",", "probs", ",", "None", ",", "None", ")", "\n", "# show predicted examples if chosen", "\n", "if", "print_examples", "!=", "0", ":", "\n", "                    ", "random", ".", "seed", "(", "3435", ")", "\n", "for", "ex_idx", "in", "random", ".", "sample", "(", "range", "(", "batch", ".", "batch_size", ")", ",", "print_examples", ")", ":", "\n", "                        ", "_", ",", "pred_topk_idx", "=", "probs", "[", ":", ",", "ex_idx", "]", ".", "topk", "(", "k", "=", "self", ".", "valid_loss", ".", "sel_report_topk", ",", "dim", "=", "0", ")", "\n", "ex_src", "=", "batch", ".", "src", "[", "0", "]", "[", ":", ",", "ex_idx", "]", "\n", "ex_src", "=", "[", "cur_dataset", ".", "fields", "[", "'src'", "]", ".", "vocab", ".", "itos", "[", "word_idx", "]", "for", "word_idx", "in", "ex_src", "]", "\n", "ex_ind", "=", "batch", ".", "key_indicators", "[", "0", "]", "[", ":", ",", "ex_idx", "]", "\n", "ex_ind", "=", "[", "cur_dataset", ".", "fields", "[", "'key_indicators'", "]", ".", "vocab", ".", "itos", "[", "word_idx", "]", "for", "word_idx", "in", "ex_ind", "]", "\n", "pred_ind_positions", "=", "pred_topk_idx", "\n", "ex_pred_ind", "=", "[", "'p_1'", "if", "posi_idx", "in", "pred_ind_positions", "else", "'p_0'", "for", "posi_idx", "in", "range", "(", "len", "(", "ex_src", ")", ")", "]", "\n", "ex_pred_scores", "=", "probs", "[", ":", ",", "ex_idx", "]", "\n", "ex_pred_scores", "=", "[", "'{:.3f}'", ".", "format", "(", "prob", ".", "data", ".", "item", "(", ")", ")", "for", "prob", "in", "ex_pred_scores", "]", "\n", "out_ex", "=", "[", "'|'", ".", "join", "(", "[", "src_word", ",", "tgt_ind", ",", "pred_ind", ",", "pred_score", "]", ")", "\n", "for", "src_word", ",", "tgt_ind", ",", "pred_ind", ",", "pred_score", "in", "zip", "(", "ex_src", ",", "ex_ind", ",", "ex_pred_ind", ",", "ex_pred_scores", ")", "]", "\n", "gt_key_words", "=", "[", "word", "for", "word", "in", "out_ex", "if", "'I'", "in", "word", "]", "\n", "pred_key_words", "=", "[", "word", "for", "word", "in", "out_ex", "if", "'p_1'", "in", "word", "]", "\n", "out_ex", "=", "' '", ".", "join", "(", "out_ex", ")", "\n", "logger", ".", "info", "(", "''", ")", "\n", "logger", ".", "info", "(", "'Example {}:'", ".", "format", "(", "ex_idx", ")", "+", "out_ex", ")", "\n", "logger", ".", "info", "(", "'Example gt: '", "+", "' '", ".", "join", "(", "gt_key_words", ")", ")", "\n", "logger", ".", "info", "(", "'Example pred: '", "+", "' '", ".", "join", "(", "pred_key_words", ")", ")", "\n", "", "", "print_examples", "=", "0", "\n", "\n", "", "elif", "self", ".", "key_model", "==", "\"key_end2end\"", ":", "\n", "                ", "tgt", "=", "inputters", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "\n", "dec_outputs", ",", "attns", ",", "dec_state", ",", "sel_outputs", ",", "sel_probs", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "src_lengths", ",", "\n", "gt_probs", "=", "batch", ".", "key_indicators", "[", "0", "]", ",", "retrieved_keys", "=", "retrieved_keys", ",", "rk_lengths", "=", "rk_lengths", ")", "\n", "\n", "# Compute loss", "\n", "# (self, batch, sel_outputs, sel_probs, dec_outputs, attns, normalization)", "\n", "batch_stats", "=", "self", ".", "valid_loss", ".", "monolithic_compute_loss", "(", "\n", "batch", ",", "sel_outputs", ",", "sel_probs", ",", "dec_outputs", ",", "attns", ")", "\n", "", "else", ":", "\n", "                ", "tgt", "=", "inputters", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "\n", "outputs", ",", "attns", ",", "_", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "src_lengths", ",", "\n", "retrieved_keys", "=", "retrieved_keys", ",", "rk_lengths", "=", "rk_lengths", ")", "\n", "# Compute loss.", "\n", "# (self, batch, sel_outputs, sel_probs, dec_outputs, attns)", "\n", "batch_stats", "=", "self", ".", "valid_loss", ".", "monolithic_compute_loss", "(", "batch", "=", "batch", ",", "\n", "sel_outputs", "=", "None", ",", "\n", "sel_probs", "=", "None", ",", "\n", "dec_outputs", "=", "outputs", ",", "\n", "attns", "=", "attns", ")", "\n", "\n", "# Update statistics.", "\n", "", "stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# Set model back to training mode.", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "return", "stats", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._gradient_accumulation": [[356, 413], ["trainer.Trainer.optim.step", "trainer.Trainer.model.zero_grad", "batch.tgt.size", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "range", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "onmt.utils.distributed.all_reduce_and_rescale_tensors", "src_lengths.sum().item", "trainer.Trainer.model", "trainer.Trainer.train_loss.sharded_compute_loss", "total_stats.update", "report_stats.update", "float", "trainer.Trainer.model.zero_grad", "dec_state.detach", "trainer.Trainer.model.parameters", "src_lengths.sum"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.all_reduce_and_rescale_tensors", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute.sharded_compute_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.detach"], ["\n", "", "def", "_gradient_accumulation", "(", "self", ",", "true_batchs", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ")", ":", "\n", "        ", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "for", "batch", "in", "true_batchs", ":", "\n", "            ", "target_size", "=", "batch", ".", "tgt", ".", "size", "(", "0", ")", "\n", "# Truncated BPTT", "\n", "if", "self", ".", "trunc_size", ":", "\n", "                ", "trunc_size", "=", "self", ".", "trunc_size", "\n", "", "else", ":", "\n", "                ", "trunc_size", "=", "target_size", "\n", "\n", "", "dec_state", "=", "None", "\n", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "self", ".", "data_type", ")", "# [src_len, batch_size, num_features]", "\n", "if", "self", ".", "data_type", "==", "'text'", ":", "\n", "                ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "report_stats", ".", "n_src_words", "+=", "src_lengths", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                ", "src_lengths", "=", "None", "\n", "\n", "", "tgt_outer", "=", "inputters", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "\n", "\n", "for", "j", "in", "range", "(", "0", ",", "target_size", "-", "1", ",", "trunc_size", ")", ":", "\n", "# 1. Create truncated target.", "\n", "                ", "tgt", "=", "tgt_outer", "[", "j", ":", "j", "+", "trunc_size", "]", "\n", "\n", "# 2. F-prop all but generator.", "\n", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "                    ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "", "outputs", ",", "attns", ",", "dec_state", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "src_lengths", ",", "dec_state", ")", "\n", "\n", "# 3. Compute loss in shards for memory efficiency.", "\n", "batch_stats", "=", "self", ".", "train_loss", ".", "sharded_compute_loss", "(", "\n", "batch", ",", "outputs", ",", "attns", ",", "j", ",", "\n", "trunc_size", ",", "self", ".", "shard_size", ",", "normalization", ")", "\n", "total_stats", ".", "update", "(", "batch_stats", ")", "\n", "report_stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# If truncated, don't backprop fully.", "\n", "if", "dec_state", "is", "not", "None", ":", "\n", "                    ", "dec_state", ".", "detach", "(", ")", "\n", "\n", "# bis Multi GPU gradient gather", "\n", "", "", "", "if", "self", ".", "n_gpu", ">", "1", ":", "\n", "            ", "grads", "=", "[", "p", ".", "grad", ".", "data", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "\n", "if", "p", ".", "requires_grad", "\n", "and", "p", ".", "grad", "is", "not", "None", "]", "\n", "onmt", ".", "utils", ".", "distributed", ".", "all_reduce_and_rescale_tensors", "(", "\n", "grads", ",", "float", "(", "1", ")", ")", "\n", "\n", "# Update the parameters and statistics.", "\n", "", "self", ".", "optim", ".", "step", "(", "self", ".", "cur_valid_ppl", ")", "\n", "report_stats", ".", "lr_rate", "=", "self", ".", "optim", ".", "learning_rate", "\n", "report_stats", ".", "total_norm", "=", "self", ".", "optim", ".", "total_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._generator_gradient_accumulation": [[414, 452], ["trainer.Trainer.optim.step", "trainer.Trainer.model.zero_grad", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "trainer.Trainer.model", "trainer.Trainer.train_loss.sharded_compute_loss", "total_stats.update", "report_stats.update", "trainer.Trainer.model.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute.sharded_compute_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad"], ["", "def", "_generator_gradient_accumulation", "(", "self", ",", "true_batchs", ",", "normalization", ",", "total_stats", ",", "report_stats", ")", ":", "\n", "        ", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "for", "batch", "in", "true_batchs", ":", "\n", "\n", "            ", "dec_state", "=", "None", "\n", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "self", ".", "data_type", ")", "# [src_len, batch_size, num_features]", "\n", "# add for RK", "\n", "retrieved_keys", "=", "inputters", ".", "make_features", "(", "batch", ",", "'retrieved_keys'", ",", "self", ".", "data_type", ")", "# [rk_len, batch_size, num_features]", "\n", "if", "self", ".", "data_type", "==", "'text'", ":", "\n", "                ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "_", ",", "rk_lengths", "=", "batch", ".", "retrieved_keys", "\n", "# report_stats.n_src_words += src_lengths.sum().item()", "\n", "", "else", ":", "\n", "                ", "src_lengths", "=", "None", "\n", "\n", "", "tgt_outer", "=", "inputters", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "\n", "\n", "# 1. F-prop all but generator.", "\n", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "                ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "", "outputs", ",", "attns", ",", "dec_state", "=", "self", ".", "model", "(", "src", ",", "tgt_outer", ",", "src_lengths", ",", "dec_state", ",", "retrieved_keys", ",", "rk_lengths", ")", "\n", "\n", "# 2. Compute loss.", "\n", "# sharded_compute_loss(self, batch, sel_outputs, sel_probs, dec_outputs, attns, normalization)", "\n", "batch_stats", "=", "self", ".", "train_loss", ".", "sharded_compute_loss", "(", "batch", "=", "batch", ",", "\n", "sel_outputs", "=", "None", ",", "\n", "sel_probs", "=", "None", ",", "\n", "dec_outputs", "=", "outputs", ",", "\n", "attns", "=", "attns", ",", "\n", "normalization", "=", "normalization", ")", "\n", "total_stats", ".", "update", "(", "batch_stats", ")", "\n", "report_stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# 3. Update the parameters and statistics.", "\n", "", "self", ".", "optim", ".", "step", "(", "self", ".", "cur_valid_ppl", ")", "\n", "report_stats", ".", "lr_rate", "=", "self", ".", "optim", ".", "learning_rate", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._end2end_gradient_accumulation": [[453, 483], ["trainer.Trainer.optim.step", "trainer.Trainer.model.zero_grad", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "trainer.Trainer.model", "trainer.Trainer.train_loss.sharded_compute_loss", "total_stats.update", "report_stats.update", "trainer.Trainer.model.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute.sharded_compute_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad"], ["report_stats", ".", "total_norm", "=", "self", ".", "optim", ".", "total_norm", "\n", "\n", "", "def", "_end2end_gradient_accumulation", "(", "self", ",", "true_batchs", ",", "normalization", ",", "total_stats", ",", "report_stats", ")", ":", "\n", "        ", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "for", "batch", "in", "true_batchs", ":", "\n", "# 1. prepare the batch", "\n", "            ", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "self", ".", "data_type", ")", "# [src_len, batch_size, num_features]", "\n", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "\n", "# add for RK", "\n", "retrieved_keys", "=", "inputters", ".", "make_features", "(", "batch", ",", "'retrieved_keys'", ",", "\n", "self", ".", "data_type", ")", "# [rk_len, batch_size, num_features]", "\n", "_", ",", "rk_lengths", "=", "batch", ".", "retrieved_keys", "\n", "\n", "tgt", "=", "inputters", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "\n", "\n", "# 2. F-prop all but generator.", "\n", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "                ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "dec_outputs", ",", "attns", ",", "dec_state", ",", "sel_outputs", ",", "sel_probs", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "src_lengths", ",", "\n", "gt_probs", "=", "batch", ".", "key_indicators", "[", "0", "]", ",", "retrieved_keys", "=", "retrieved_keys", ",", "rk_lengths", "=", "rk_lengths", ")", "\n", "\n", "# 3. Compute loss", "\n", "# (self, batch, sel_outputs, sel_probs, dec_outputs, attns, normalization)", "\n", "batch_stats", "=", "self", ".", "train_loss", ".", "sharded_compute_loss", "(", "\n", "batch", ",", "sel_outputs", ",", "sel_probs", ",", "dec_outputs", ",", "attns", ",", "normalization", ")", "\n", "total_stats", ".", "update", "(", "batch_stats", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._selector_gradient_accumulation": [[484, 512], ["trainer.Trainer.optim.step", "trainer.Trainer.model.zero_grad", "onmt.make_features", "onmt.make_features", "trainer.Trainer.model", "trainer.Trainer.train_loss.sharded_compute_loss", "total_stats.update", "report_stats.update", "trainer.Trainer.model.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute.sharded_compute_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad"], ["report_stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "# assert self.n_gpu == 1", "\n", "# 4. Update the parameters and statistics.", "\n", "", "self", ".", "optim", ".", "step", "(", "self", ".", "cur_valid_ppl", ")", "\n", "report_stats", ".", "lr_rate", "=", "self", ".", "optim", ".", "learning_rate", "\n", "report_stats", ".", "total_norm", "=", "self", ".", "optim", ".", "total_norm", "\n", "\n", "", "def", "_selector_gradient_accumulation", "(", "self", ",", "true_batchs", ",", "normalization", ",", "total_stats", ",", "\n", "report_stats", ")", ":", "\n", "        ", "if", "self", ".", "grad_accum_count", ">", "1", ":", "\n", "            ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "for", "batch", "in", "true_batchs", ":", "\n", "            ", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "self", ".", "data_type", ")", "# [src_len, batch_size, num_features]", "\n", "\n", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "\n", "# 1. F-prop all.", "\n", "if", "self", ".", "grad_accum_count", "==", "1", ":", "\n", "                ", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "", "logits", ",", "probs", "=", "self", ".", "model", "(", "src", ",", "src_lengths", ")", "\n", "\n", "# 2. Compute loss in shards for memory efficiency.", "\n", "# sharded_compute_loss(self, batch, sel_outputs, sel_probs, dec_outputs, attns, normalization)", "\n", "batch_stats", "=", "self", ".", "train_loss", ".", "sharded_compute_loss", "(", "\n", "batch", ",", "logits", ",", "probs", ",", "None", ",", "None", ",", "normalization", ")", "\n", "total_stats", ".", "update", "(", "batch_stats", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._start_report_manager": [[543, 552], ["trainer.Trainer.report_manager.start"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.start"], ["            ", "if", "stat", "is", "not", "None", "and", "self", ".", "n_gpu", ">", "1", ":", "\n", "                ", "return", "onmt", ".", "utils", ".", "SelectorStatistics", ".", "all_gather_stats", "(", "stat", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "stat", "is", "not", "None", "and", "self", ".", "n_gpu", ">", "1", ":", "\n", "                ", "return", "onmt", ".", "utils", ".", "Statistics", ".", "all_gather_stats", "(", "stat", ")", "\n", "", "", "return", "stat", "\n", "\n", "", "def", "_maybe_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._maybe_gather_stats": [[553, 573], ["None"], "methods", ["None"], ["\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "report_manager", ".", "report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ",", "\n", "multigpu", "=", "self", ".", "n_gpu", ">", "1", ")", "\n", "\n", "", "", "def", "_report_step", "(", "self", ",", "learning_rate", ",", "step", ",", "train_stats", "=", "None", ",", "\n", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to report stats (if report_manager is set)\n        see `onmt.utils.ReportManagerBase.report_step` for doc\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "report_manager", ".", "report_step", "(", "\n", "learning_rate", ",", "step", ",", "train_stats", "=", "train_stats", ",", "\n", "valid_stats", "=", "valid_stats", ")", "\n", "\n", "", "", "def", "_maybe_save", "(", "self", ",", "step", ",", "stats", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._maybe_report_training": [[574, 584], ["trainer.Trainer.report_manager.report_training"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr.report_training"], ["\n", "if", "self", ".", "model_saver", "is", "not", "None", ":", "\n", "            ", "self", ".", "model_saver", ".", "maybe_save", "(", "step", ",", "stats", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._report_step": [[585, 595], ["trainer.Trainer.report_manager.report_step"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.ReportMgrBase.report_step"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._maybe_save": [[596, 602], ["trainer.Trainer.model_saver.maybe_save"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ModelSaverBase.maybe_save"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.build_trainer": [[22, 75], ["onmt.utils.loss.my_build_loss_compute", "onmt.utils.loss.my_build_loss_compute", "onmt.utils.loss.my_build_loss_compute", "onmt.utils.loss.my_build_loss_compute", "len", "onmt.utils.build_report_manager", "onmt.utils.build_report_manager", "onmt.Trainer", "onmt.Trainer"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.my_build_loss_compute", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.my_build_loss_compute", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.my_build_loss_compute", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.my_build_loss_compute", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.build_report_manager", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.build_report_manager"], ["def", "build_trainer", "(", "opt", ",", "model", ",", "fields", ",", "optim", ",", "data_type", ",", "model_saver", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Simplify `Trainer` creation based on user `opt`s*\n\n    Args:\n        opt (:obj:`Namespace`): user options (usually from argument parsing)\n        model (:obj:`onmt.models.NMTModel`): the model to train\n        fields (dict): dict of fields\n        optim (:obj:`onmt.utils.Optimizer`): optimizer used during training\n        data_type (str): string describing the type of data\n            e.g. \"text\", \"img\", \"audio\"\n        model_saver(:obj:`onmt.models.ModelSaverBase`): the utility object\n            used to save the model\n    \"\"\"", "\n", "if", "opt", ".", "key_model", "==", "\"key_selector\"", ":", "\n", "        ", "train_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "my_build_loss_compute", "(", "\n", "model", ",", "fields", "[", "\"key_indicators\"", "]", ".", "vocab", ",", "None", ",", "opt", ")", "\n", "valid_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "my_build_loss_compute", "(", "\n", "model", ",", "fields", "[", "\"key_indicators\"", "]", ".", "vocab", ",", "None", ",", "opt", ",", "train", "=", "False", ")", "\n", "", "elif", "opt", ".", "key_model", "==", "\"key_end2end\"", ":", "\n", "        ", "train_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "my_build_loss_compute", "(", "\n", "model", ",", "fields", "[", "\"key_indicators\"", "]", ".", "vocab", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ")", "\n", "valid_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "my_build_loss_compute", "(", "\n", "model", ",", "fields", "[", "\"key_indicators\"", "]", ".", "vocab", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ",", "train", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "train_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "my_build_loss_compute", "(", "\n", "model", ",", "None", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ")", "\n", "valid_loss", "=", "onmt", ".", "utils", ".", "loss", ".", "my_build_loss_compute", "(", "\n", "model", ",", "None", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "opt", ",", "train", "=", "False", ")", "\n", "\n", "", "trunc_size", "=", "opt", ".", "truncated_decoder", "# Badly named...", "\n", "# we avoid sharding except for `key_generator` model", "\n", "if", "opt", ".", "key_model", "==", "\"key_generator\"", ":", "\n", "        ", "shard_size", "=", "opt", ".", "max_generator_batches", "\n", "", "else", ":", "\n", "        ", "shard_size", "=", "None", "\n", "", "norm_method", "=", "opt", ".", "normalization", "\n", "grad_accum_count", "=", "opt", ".", "accum_count", "\n", "n_gpu", "=", "len", "(", "opt", ".", "gpuid", ")", "\n", "gpu_rank", "=", "opt", ".", "gpu_rank", "\n", "gpu_verbose_level", "=", "opt", ".", "gpu_verbose_level", "\n", "\n", "report_manager", "=", "onmt", ".", "utils", ".", "build_report_manager", "(", "opt", ")", "\n", "\n", "key_model", "=", "opt", ".", "key_model", "\n", "trainer", "=", "onmt", ".", "Trainer", "(", "key_model", ",", "model", ",", "train_loss", ",", "valid_loss", ",", "optim", ",", "trunc_size", ",", "\n", "shard_size", ",", "data_type", ",", "norm_method", ",", "\n", "grad_accum_count", ",", "n_gpu", ",", "gpu_rank", ",", "\n", "gpu_verbose_level", ",", "report_manager", ",", "\n", "model_saver", "=", "model_saver", ")", "\n", "return", "trainer", "\n", "\n", "\n", "", "class", "Trainer", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_embeddings": [[30, 63], ["len", "onmt.modules.Embeddings", "len"], "function", ["None"], ["def", "build_embeddings", "(", "opt", ",", "word_dict", ",", "feature_dicts", ",", "for_encoder", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Build an Embeddings instance.\n    Args:\n        opt: the option in current environment.\n        word_dict(Vocab): words dictionary.\n        feature_dicts([Vocab], optional): a list of feature dictionary.\n        for_encoder(bool): build Embeddings for encoder or decoder?\n    \"\"\"", "\n", "if", "for_encoder", ":", "\n", "        ", "embedding_dim", "=", "opt", ".", "src_word_vec_size", "\n", "", "else", ":", "\n", "        ", "embedding_dim", "=", "opt", ".", "tgt_word_vec_size", "\n", "\n", "", "word_padding_idx", "=", "word_dict", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "num_word_embeddings", "=", "len", "(", "word_dict", ")", "\n", "\n", "feats_padding_idx", "=", "[", "feat_dict", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "for", "feat_dict", "in", "feature_dicts", "]", "\n", "num_feat_embeddings", "=", "[", "len", "(", "feat_dict", ")", "for", "feat_dict", "in", "\n", "feature_dicts", "]", "\n", "\n", "return", "Embeddings", "(", "word_vec_size", "=", "embedding_dim", ",", "\n", "position_encoding", "=", "opt", ".", "position_encoding", ",", "\n", "feat_merge", "=", "opt", ".", "feat_merge", ",", "\n", "feat_vec_exponent", "=", "opt", ".", "feat_vec_exponent", ",", "\n", "feat_vec_size", "=", "opt", ".", "feat_vec_size", ",", "\n", "dropout", "=", "opt", ".", "dropout", ",", "\n", "word_padding_idx", "=", "word_padding_idx", ",", "\n", "feat_padding_idx", "=", "feats_padding_idx", ",", "\n", "word_vocab_size", "=", "num_word_embeddings", ",", "\n", "feat_vocab_sizes", "=", "num_feat_embeddings", ",", "\n", "sparse", "=", "opt", ".", "optim", "==", "\"sparseadam\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_selector": [[76, 85], ["RNNSelector"], "function", ["None"], ["", "def", "build_encoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Various encoder dispatcher function.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this encoder.\n    \"\"\"", "\n", "if", "opt", ".", "encoder_type", "==", "\"transformer\"", ":", "\n", "        ", "return", "TransformerEncoder", "(", "opt", ".", "enc_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "heads", ",", "opt", ".", "transformer_ff", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_encoder": [[87, 109], ["onmt.encoders.transformer.TransformerEncoder", "onmt.encoders.cnn_encoder.CNNEncoder", "onmt.encoders.mean_encoder.MeanEncoder", "onmt.encoders.rnn_encoder.RNNEncoder"], "function", ["None"], ["", "elif", "opt", ".", "encoder_type", "==", "\"cnn\"", ":", "\n", "        ", "return", "CNNEncoder", "(", "opt", ".", "enc_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "cnn_kernel_width", ",", "\n", "opt", ".", "dropout", ",", "embeddings", ")", "\n", "", "elif", "opt", ".", "encoder_type", "==", "\"mean\"", ":", "\n", "        ", "return", "MeanEncoder", "(", "opt", ".", "enc_layers", ",", "embeddings", ")", "\n", "", "else", ":", "\n", "# \"rnn\" or \"brnn\"", "\n", "        ", "return", "RNNEncoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "rnn_size", ",", "opt", ".", "dropout", ",", "embeddings", ",", "\n", "opt", ".", "bridge", ")", "\n", "\n", "\n", "", "", "def", "build_rk_encoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "return", "RKRNNEncoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "rnn_size", ",", "opt", ".", "dropout", ",", "embeddings", ",", "\n", "opt", ".", "bridge", ")", "\n", "\n", "\n", "", "def", "build_decoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_rk_encoder": [[100, 104], ["onmt.encoders.rnn_encoder.RKRNNEncoder"], "function", ["None"], ["", "", "def", "build_rk_encoder", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "return", "RKRNNEncoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "rnn_size", ",", "opt", ".", "dropout", ",", "embeddings", ",", "\n", "opt", ".", "bridge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_decoder": [[111, 164], ["onmt.decoders.transformer.TransformerDecoder", "onmt.decoders.cnn_decoder.CNNDecoder", "onmt.decoders.decoder.StdRNNDecoder", "onmt.decoders.decoder.InputFeedRNNDecoder", "onmt.decoders.decoder.MyInputFeedRNNDecoder"], "function", ["None"], ["\n", "if", "opt", ".", "decoder_type", "==", "\"transformer\"", ":", "\n", "        ", "return", "TransformerDecoder", "(", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "heads", ",", "opt", ".", "transformer_ff", ",", "\n", "opt", ".", "global_attention", ",", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "self_attn_type", ",", "\n", "opt", ".", "dropout", ",", "embeddings", ")", "\n", "", "elif", "opt", ".", "decoder_type", "==", "\"cnn\"", ":", "\n", "        ", "return", "CNNDecoder", "(", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "cnn_kernel_width", ",", "opt", ".", "dropout", ",", "\n", "embeddings", ")", "\n", "", "elif", "opt", ".", "input_feed", ":", "\n", "        ", "assert", "opt", ".", "key_model", "in", "[", "\"key_generator\"", ",", "\"key_end2end\"", "]", "\n", "if", "opt", ".", "key_model", "==", "\"key_generator\"", ":", "\n", "            ", "return", "InputFeedRNNDecoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "\n", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "coverage_attn", ",", "\n", "opt", ".", "context_gate", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "reuse_copy_attn", ",", "\n", "no_sftmax_bf_rescale", "=", "opt", ".", "no_sftmax_bf_rescale", ",", "\n", "use_retrieved_keys", "=", "opt", ".", "use_retrieved_keys", ")", "\n", "", "else", ":", "\n", "            ", "return", "MyInputFeedRNNDecoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "\n", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "coverage_attn", ",", "\n", "opt", ".", "context_gate", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "reuse_copy_attn", ",", "\n", "not_use_sel_probs", "=", "opt", ".", "not_use_sel_probs", ",", "\n", "no_sftmax_bf_rescale", "=", "opt", ".", "no_sftmax_bf_rescale", ",", "\n", "use_retrieved_keys", "=", "opt", ".", "use_retrieved_keys", ",", "\n", "only_rescale_copy", "=", "opt", ".", "only_rescale_copy", ")", "\n", "", "", "else", ":", "\n", "        ", "return", "StdRNNDecoder", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "\n", "opt", ".", "dec_layers", ",", "opt", ".", "rnn_size", ",", "\n", "opt", ".", "global_attention", ",", "\n", "opt", ".", "coverage_attn", ",", "\n", "opt", ".", "context_gate", ",", "\n", "opt", ".", "copy_attn", ",", "\n", "opt", ".", "dropout", ",", "\n", "embeddings", ",", "\n", "opt", ".", "reuse_copy_attn", ")", "\n", "\n", "\n", "", "", "def", "load_test_model", "(", "opt", ",", "dummy_opt", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.load_test_model": [[166, 182], ["torch.load", "torch.load", "onmt.load_fields_from_vocab", "model_builder.build_model", "build_model.eval"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.load_fields_from_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_model"], ["checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "fields", "=", "inputters", ".", "load_fields_from_vocab", "(", "\n", "checkpoint", "[", "'vocab'", "]", ",", "data_type", "=", "opt", ".", "data_type", ")", "\n", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "for", "arg", "in", "dummy_opt", ":", "\n", "        ", "if", "arg", "not", "in", "model_opt", ":", "\n", "            ", "model_opt", ".", "__dict__", "[", "arg", "]", "=", "dummy_opt", "[", "arg", "]", "\n", "", "", "model", "=", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", ".", "generator", ".", "eval", "(", ")", "\n", "return", "fields", ",", "model", ",", "model_opt", "\n", "\n", "\n", "", "def", "build_base_model", "(", "model_opt", ",", "fields", ",", "gpu", ",", "checkpoint", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_base_model": [[184, 280], ["onmt.collect_feature_vocabs", "model_builder.build_embeddings", "model_builder.build_decoder", "torch.device", "torch.device", "onmt.models.NMTModel", "onmt.models.NMTModel", "onmt.models.NMTModel.to", "onmt.collect_feature_vocabs", "model_builder.build_embeddings", "model_builder.build_encoder", "torch.Sequential", "onmt.modules.CopyGenerator", "onmt.models.NMTModel.load_state_dict", "onmt.modules.CopyGenerator.load_state_dict", "hasattr", "hasattr", "onmt.encoders.image_encoder.ImageEncoder", "AssertionError", "torch.Linear", "torch.LogSoftmax", "onmt.models.NMTModel.parameters", "onmt.modules.CopyGenerator.parameters", "onmt.models.NMTModel.parameters", "onmt.modules.CopyGenerator.parameters", "onmt.models.NMTModel.encoder.embeddings.load_pretrained_vectors", "onmt.models.NMTModel.decoder.embeddings.load_pretrained_vectors", "onmt.encoders.audio_encoder.AudioEncoder", "len", "p.data.uniform_", "p.data.uniform_", "p.dim", "torch.nn.init.xavier_uniform_", "p.dim", "torch.nn.init.xavier_uniform_"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_feature_vocabs", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_feature_vocabs", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.image_encoder.ImageEncoder.load_pretrained_vectors", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.image_encoder.ImageEncoder.load_pretrained_vectors"], ["\n", "assert", "model_opt", ".", "model_type", "in", "[", "\"text\"", ",", "\"img\"", ",", "\"audio\"", "]", ",", "(", "\"Unsupported model type %s\"", "%", "(", "model_opt", ".", "model_type", ")", ")", "\n", "\n", "# Build encoder.", "\n", "if", "model_opt", ".", "model_type", "==", "\"text\"", ":", "\n", "        ", "src_dict", "=", "fields", "[", "\"src\"", "]", ".", "vocab", "\n", "feature_dicts", "=", "inputters", ".", "collect_feature_vocabs", "(", "fields", ",", "'src'", ")", "\n", "src_embeddings", "=", "build_embeddings", "(", "model_opt", ",", "src_dict", ",", "feature_dicts", ")", "\n", "encoder", "=", "build_encoder", "(", "model_opt", ",", "src_embeddings", ")", "\n", "rk_encoder", "=", "None", "\n", "if", "model_opt", ".", "use_retrieved_keys", ":", "\n", "            ", "rk_encoder", "=", "build_rk_encoder", "(", "model_opt", ",", "src_embeddings", ")", "\n", "", "", "elif", "model_opt", ".", "model_type", "==", "\"img\"", ":", "\n", "        ", "encoder", "=", "ImageEncoder", "(", "model_opt", ".", "enc_layers", ",", "\n", "model_opt", ".", "brnn", ",", "\n", "model_opt", ".", "rnn_size", ",", "\n", "model_opt", ".", "dropout", ")", "\n", "", "elif", "model_opt", ".", "model_type", "==", "\"audio\"", ":", "\n", "        ", "encoder", "=", "AudioEncoder", "(", "model_opt", ".", "enc_layers", ",", "\n", "model_opt", ".", "brnn", ",", "\n", "model_opt", ".", "rnn_size", ",", "\n", "model_opt", ".", "dropout", ",", "\n", "model_opt", ".", "sample_rate", ",", "\n", "model_opt", ".", "window_size", ")", "\n", "\n", "# Build decoder.", "\n", "", "tgt_dict", "=", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "feature_dicts", "=", "inputters", ".", "collect_feature_vocabs", "(", "fields", ",", "'tgt'", ")", "\n", "tgt_embeddings", "=", "build_embeddings", "(", "model_opt", ",", "tgt_dict", ",", "\n", "feature_dicts", ",", "for_encoder", "=", "False", ")", "\n", "\n", "# Share the embedding matrix - preprocess with share_vocab required.", "\n", "if", "model_opt", ".", "share_embeddings", ":", "\n", "# src/tgt vocab should be the same if `-share_vocab` is specified.", "\n", "        ", "if", "src_dict", "!=", "tgt_dict", ":", "\n", "            ", "raise", "AssertionError", "(", "'The `-share_vocab` should be set during '", "\n", "'preprocess if you use share_embeddings!'", ")", "\n", "\n", "", "tgt_embeddings", ".", "word_lut", ".", "weight", "=", "src_embeddings", ".", "word_lut", ".", "weight", "\n", "\n", "", "decoder", "=", "build_decoder", "(", "model_opt", ",", "tgt_embeddings", ")", "\n", "\n", "# Build NMTModel(= encoder + decoder).", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "gpu", "else", "\"cpu\"", ")", "\n", "model", "=", "onmt", ".", "models", ".", "NMTModel", "(", "encoder", ",", "rk_encoder", ",", "decoder", ",", "rk_to_src_attn", "=", "model_opt", ".", "rk_to_src_attn", ")", "\n", "model", ".", "model_type", "=", "model_opt", ".", "model_type", "\n", "\n", "# Build Generator.", "\n", "if", "not", "model_opt", ".", "copy_attn", ":", "\n", "        ", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "rnn_size", ",", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", ")", ",", "\n", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", ")", "\n", "if", "model_opt", ".", "share_decoder_embeddings", ":", "\n", "            ", "generator", "[", "0", "]", ".", "weight", "=", "decoder", ".", "embeddings", ".", "word_lut", ".", "weight", "\n", "", "", "else", ":", "\n", "        ", "generator", "=", "CopyGenerator", "(", "model_opt", ".", "rnn_size", ",", "\n", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", "\n", "\n", "# Load the model states from checkpoint or initialize them.", "\n", "", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'generator'", "]", ")", "\n", "", "else", ":", "\n", "        ", "if", "model_opt", ".", "param_init", "!=", "0.0", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "", "if", "model_opt", ".", "param_init_glorot", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "\n", "", "", "", "if", "hasattr", "(", "model", ".", "encoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "encoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_enc", ",", "model_opt", ".", "fix_word_vecs_enc", ")", "\n", "", "if", "hasattr", "(", "model", ".", "decoder", ",", "'embeddings'", ")", ":", "\n", "            ", "model", ".", "decoder", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_dec", ",", "model_opt", ".", "fix_word_vecs_dec", ")", "\n", "\n", "# Add generator to model (this registers it as parameter of model).", "\n", "", "", "model", ".", "generator", "=", "generator", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_end2end_model": [[282, 391], ["onmt.collect_feature_vocabs", "model_builder.build_embeddings", "model_builder.build_selector", "onmt.collect_feature_vocabs", "model_builder.build_embeddings", "model_builder.build_decoder", "torch.device", "torch.device", "onmt.models.E2EModel", "onmt.models.E2EModel", "onmt.models.E2EModel.to", "model_builder.build_encoder", "torch.Sequential", "onmt.modules.CopyGenerator", "onmt.models.E2EModel.load_state_dict", "onmt.modules.CopyGenerator.load_state_dict", "model_builder.build_embeddings", "model_builder.build_embeddings", "AssertionError", "torch.Linear", "torch.LogSoftmax", "onmt.models.E2EModel.parameters", "onmt.modules.CopyGenerator.parameters", "onmt.models.E2EModel.parameters", "onmt.modules.CopyGenerator.parameters", "onmt.models.E2EModel.load_state_dict", "onmt.models.E2EModel.load_state_dict", "onmt.modules.CopyGenerator.load_state_dict", "len", "p.data.uniform_", "p.data.uniform_", "p.dim", "torch.nn.init.xavier_uniform_", "p.dim", "torch.nn.init.xavier_uniform_"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_feature_vocabs", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_selector", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_feature_vocabs", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_decoder", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_encoder", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict"], ["", "def", "build_end2end_model", "(", "model_opt", ",", "fields", ",", "gpu", ",", "checkpoint", "=", "None", ",", "sel_checkpoint", "=", "None", ",", "s2s_gen_checkpoint", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        model_opt: the option loaded from checkpoint.\n        fields: `Field` objects for the model.\n        gpu(bool): whether to use gpu.\n        checkpoint: the model gnerated by train phase, or a resumed snapshot\n                    model from a stopped training.\n        sel_checkpoint: a pretrained selector.\n\n    Returns:\n        the E2EModel.\n    \"\"\"", "\n", "assert", "model_opt", ".", "model_type", "in", "[", "\"text\"", "]", ",", "(", "\"Unsupported model type %s\"", "%", "(", "model_opt", ".", "model_type", ")", ")", "\n", "\n", "# Build selector", "\n", "src_dict", "=", "fields", "[", "\"src\"", "]", ".", "vocab", "\n", "feature_dicts", "=", "inputters", ".", "collect_feature_vocabs", "(", "fields", ",", "'src'", ")", "\n", "sel_src_embeddings", "=", "build_embeddings", "(", "model_opt", ",", "src_dict", ",", "feature_dicts", ")", "\n", "selector", "=", "build_selector", "(", "model_opt", ",", "sel_src_embeddings", ")", "\n", "\n", "# Build encoder", "\n", "if", "model_opt", ".", "e2e_type", "==", "\"separate_enc_sel\"", ":", "\n", "        ", "if", "model_opt", ".", "selector_share_embeddings", ":", "\n", "# the shared embeddings are in the encoder.embeddings", "\n", "# TODO: change the state name to load the embeddings in the pretrained selector embeddings", "\n", "            ", "assert", "model_opt", ".", "load_pretrained_selector_from", "==", "''", "\n", "src_embeddings", "=", "build_embeddings", "(", "model_opt", ",", "src_dict", ",", "feature_dicts", ")", "\n", "src_embeddings", ".", "word_lut", ".", "weight", "=", "sel_src_embeddings", ".", "word_lut", ".", "weight", "\n", "", "else", ":", "\n", "            ", "src_embeddings", "=", "build_embeddings", "(", "model_opt", ",", "src_dict", ",", "feature_dicts", ")", "\n", "", "encoder", "=", "build_encoder", "(", "model_opt", ",", "src_embeddings", ")", "\n", "", "else", ":", "\n", "# model_opt.e2e_type == \"share_enc_sel\"", "\n", "        ", "src_embeddings", "=", "sel_src_embeddings", "\n", "encoder", "=", "None", "\n", "\n", "# build rk_encoder", "\n", "rk_encoder", "=", "None", "\n", "if", "model_opt", ".", "use_retrieved_keys", ":", "\n", "            ", "rk_encoder", "=", "build_rk_encoder", "(", "model_opt", ",", "sel_src_embeddings", ")", "\n", "\n", "# Build decoder", "\n", "", "", "tgt_dict", "=", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "feature_dicts", "=", "inputters", ".", "collect_feature_vocabs", "(", "fields", ",", "'tgt'", ")", "\n", "tgt_embeddings", "=", "build_embeddings", "(", "model_opt", ",", "tgt_dict", ",", "\n", "feature_dicts", ",", "for_encoder", "=", "False", ")", "\n", "\n", "# Share the embedding matrix - preprocess with share_vocab required.", "\n", "if", "model_opt", ".", "share_embeddings", ":", "\n", "# src/tgt vocab should be the same if `-share_vocab` is specified.", "\n", "        ", "if", "src_dict", "!=", "tgt_dict", ":", "\n", "            ", "raise", "AssertionError", "(", "'The `-share_vocab` should be set during '", "\n", "'preprocess if you use share_embeddings!'", ")", "\n", "\n", "", "tgt_embeddings", ".", "word_lut", ".", "weight", "=", "src_embeddings", ".", "word_lut", ".", "weight", "\n", "\n", "", "decoder", "=", "build_decoder", "(", "model_opt", ",", "tgt_embeddings", ")", "\n", "\n", "# Build E2EModel(= encoders + selector + decoder).", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "gpu", "else", "\"cpu\"", ")", "\n", "model", "=", "onmt", ".", "models", ".", "E2EModel", "(", "encoder", ",", "rk_encoder", ",", "selector", ",", "decoder", ",", "\n", "e2e_type", "=", "model_opt", ".", "e2e_type", ",", "use_gt_sel_probs", "=", "model_opt", ".", "use_gt_sel_probs", ",", "\n", "rk_to_src_attn", "=", "model_opt", ".", "rk_to_src_attn", ")", "\n", "model", ".", "model_type", "=", "model_opt", ".", "model_type", "\n", "\n", "# Build Generator.", "\n", "if", "not", "model_opt", ".", "copy_attn", ":", "\n", "        ", "generator", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model_opt", ".", "rnn_size", ",", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", ")", ",", "\n", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", ")", "\n", "if", "model_opt", ".", "share_decoder_embeddings", ":", "\n", "            ", "generator", "[", "0", "]", ".", "weight", "=", "decoder", ".", "embeddings", ".", "word_lut", ".", "weight", "\n", "", "", "else", ":", "\n", "        ", "generator", "=", "CopyGenerator", "(", "model_opt", ".", "rnn_size", ",", "\n", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", "\n", "\n", "# Load the model states from checkpoint or initialize them.", "\n", "", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'end2end_model'", "]", ")", "\n", "generator", ".", "load_state_dict", "(", "checkpoint", "[", "'generator'", "]", ")", "\n", "", "else", ":", "\n", "        ", "if", "model_opt", ".", "param_init", "!=", "0.0", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "", "if", "model_opt", ".", "param_init_glorot", ":", "\n", "            ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "", "", "for", "p", "in", "generator", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "\n", "", "", "", "if", "sel_checkpoint", "is", "not", "None", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "sel_checkpoint", "[", "'selector'", "]", ",", "strict", "=", "False", ")", "\n", "\n", "", "if", "s2s_gen_checkpoint", "is", "not", "None", ":", "\n", "            ", "model", ".", "load_state_dict", "(", "s2s_gen_checkpoint", "[", "'model'", "]", ",", "strict", "=", "False", ")", "\n", "generator", ".", "load_state_dict", "(", "s2s_gen_checkpoint", "[", "'generator'", "]", ")", "\n", "\n", "# if hasattr(model.encoder, 'embeddings'):", "\n", "#     model.encoder.embeddings.load_pretrained_vectors(", "\n", "#         model_opt.pre_word_vecs_enc, model_opt.fix_word_vecs_enc)", "\n", "# if hasattr(model.decoder, 'embeddings'):", "\n", "#     model.decoder.embeddings.load_pretrained_vectors(", "\n", "#         model_opt.pre_word_vecs_dec, model_opt.fix_word_vecs_dec)", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_selector_model": [[393, 439], ["onmt.collect_feature_vocabs", "model_builder.build_embeddings", "model_builder.build_selector", "onmt.models.SelectorModel", "onmt.models.SelectorModel", "torch.device", "torch.device", "onmt.models.SelectorModel.to", "onmt.models.SelectorModel.load_state_dict", "hasattr", "onmt.models.SelectorModel.parameters", "onmt.models.SelectorModel.parameters", "onmt.models.SelectorModel.embeddings.load_pretrained_vectors", "p.data.uniform_", "p.dim", "torch.nn.init.xavier_uniform_"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_feature_vocabs", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_selector", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.image_encoder.ImageEncoder.load_pretrained_vectors"], ["", "", "model", ".", "generator", "=", "generator", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "return", "model", "\n", "\n", "\n", "", "def", "build_selector_model", "(", "model_opt", ",", "fields", ",", "gpu", ",", "checkpoint", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        model_opt: the option loaded from checkpoint.\n        fields: `Field` objects for the model.\n        gpu(bool): whether to use gpu.\n        checkpoint: the model generated by train phase, or a resumed snapshot\n                    model from a stopped training.\n    Returns:\n        the selector model.\n    \"\"\"", "\n", "assert", "model_opt", ".", "model_type", "in", "[", "\"text\"", "]", ",", "(", "\"Unsupported model type %s\"", "%", "(", "model_opt", ".", "model_type", ")", ")", "\n", "\n", "# Build encoder.", "\n", "src_dict", "=", "fields", "[", "\"src\"", "]", ".", "vocab", "\n", "feature_dicts", "=", "inputters", ".", "collect_feature_vocabs", "(", "fields", ",", "'src'", ")", "\n", "src_embeddings", "=", "build_embeddings", "(", "model_opt", ",", "src_dict", ",", "feature_dicts", ")", "\n", "selector", "=", "build_selector", "(", "model_opt", ",", "src_embeddings", ")", "\n", "selector", "=", "onmt", ".", "models", ".", "SelectorModel", "(", "selector", ")", "\n", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "gpu", "else", "\"cpu\"", ")", "\n", "selector", ".", "model_type", "=", "model_opt", ".", "model_type", "\n", "\n", "# Load the model states from checkpoint or initialize them.", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "selector", ".", "load_state_dict", "(", "checkpoint", "[", "'selector'", "]", ")", "\n", "", "else", ":", "\n", "        ", "if", "model_opt", ".", "param_init", "!=", "0.0", ":", "\n", "            ", "for", "p", "in", "selector", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "data", ".", "uniform_", "(", "-", "model_opt", ".", "param_init", ",", "model_opt", ".", "param_init", ")", "\n", "", "", "if", "model_opt", ".", "param_init_glorot", ":", "\n", "            ", "for", "p", "in", "selector", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "xavier_uniform_", "(", "p", ")", "\n", "\n", "", "", "", "if", "hasattr", "(", "selector", ",", "'embeddings'", ")", ":", "\n", "            ", "selector", ".", "embeddings", ".", "load_pretrained_vectors", "(", "\n", "model_opt", ".", "pre_word_vecs_enc", ",", "model_opt", ".", "fix_word_vecs_enc", ")", "\n", "\n", "", "", "selector", ".", "to", "(", "device", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_model": [[490, 497], ["onmt.utils.logging.logger.info", "model_builder.build_reranker_model", "onmt.utils.logging.logger.info", "onmt.utils.misc.use_gpu"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_reranker_model", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.use_gpu"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_single._check_save_model_path": [[23, 28], ["os.path.abspath", "os.path.dirname", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "_check_save_model_path", "(", "opt", ")", ":", "\n", "    ", "save_model_path", "=", "os", ".", "path", ".", "abspath", "(", "opt", ".", "save_model", ")", "\n", "model_dirname", "=", "os", ".", "path", ".", "dirname", "(", "save_model_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_single._tally_parameters": [[30, 40], ["sum", "model.named_parameters", "p.nelement", "param.nelement", "model.parameters", "param.nelement"], "function", ["None"], ["", "", "def", "_tally_parameters", "(", "model", ")", ":", "\n", "    ", "n_params", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "enc", "=", "0", "\n", "dec", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'encoder'", "in", "name", ":", "\n", "            ", "enc", "+=", "param", ".", "nelement", "(", ")", "\n", "", "elif", "'decoder'", "or", "'generator'", "in", "name", ":", "\n", "            ", "dec", "+=", "param", ".", "nelement", "(", ")", "\n", "", "", "return", "n_params", ",", "enc", ",", "dec", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_single._my_tally_parameters": [[42, 61], ["sum", "model.named_parameters", "p.nelement", "param.nelement", "model.parameters", "param.nelement", "param.nelement", "param.nelement", "AssertionError"], "function", ["None"], ["", "def", "_my_tally_parameters", "(", "model", ")", ":", "\n", "    ", "n_params", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "sel", "=", "0", "\n", "enc", "=", "0", "\n", "dec", "=", "0", "\n", "gen", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "'selector'", "in", "name", ":", "\n", "            ", "sel", "+=", "param", ".", "nelement", "(", ")", "\n", "", "elif", "'encoder'", "in", "name", ":", "\n", "            ", "enc", "+=", "param", ".", "nelement", "(", ")", "\n", "", "elif", "'decoder'", "in", "name", ":", "\n", "            ", "dec", "+=", "param", ".", "nelement", "(", ")", "\n", "", "elif", "'generator'", "in", "name", ":", "\n", "            ", "gen", "+=", "param", ".", "nelement", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"The parameters {} do not belong to any part!\"", ".", "format", "(", "name", ")", ")", "\n", "\n", "", "", "return", "n_params", ",", "sel", ",", "enc", ",", "dec", ",", "gen", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_single.training_opt_postprocessing": [[63, 91], ["AssertionError", "torch.cuda.is_available", "onmt.utils.logging.logger.info", "torch.cuda.set_device", "random.seed", "torch.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "def", "training_opt_postprocessing", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "word_vec_size", "!=", "-", "1", ":", "\n", "        ", "opt", ".", "src_word_vec_size", "=", "opt", ".", "word_vec_size", "\n", "opt", ".", "tgt_word_vec_size", "=", "opt", ".", "word_vec_size", "\n", "\n", "", "if", "opt", ".", "layers", "!=", "-", "1", ":", "\n", "        ", "opt", ".", "enc_layers", "=", "opt", ".", "layers", "\n", "opt", ".", "dec_layers", "=", "opt", ".", "layers", "\n", "\n", "", "opt", ".", "brnn", "=", "(", "opt", ".", "encoder_type", "==", "\"brnn\"", ")", "\n", "\n", "if", "opt", ".", "rnn_type", "==", "\"SRU\"", "and", "not", "opt", ".", "gpuid", ":", "\n", "        ", "raise", "AssertionError", "(", "\"Using SRU requires -gpuid set.\"", ")", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "opt", ".", "gpuid", ":", "\n", "        ", "logger", ".", "info", "(", "\"WARNING: You have a CUDA device, should run with -gpuid\"", ")", "\n", "\n", "", "if", "opt", ".", "gpuid", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "device_id", ")", "\n", "if", "opt", ".", "seed", ">", "0", ":", "\n", "# this one is needed for torchtext random call (shuffled iterator)", "\n", "# in multi gpu it ensures datasets are read in the same order", "\n", "            ", "random", ".", "seed", "(", "opt", ".", "seed", ")", "\n", "# These ensure same initialization in multi gpu mode", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "\n", "", "", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_single.main": [[93, 156], ["train_single.training_opt_postprocessing", "onmt.utils.logging.init_logger", "onmt.utils.logging.logger.info", "next", "onmt.inputters.inputter._load_fields", "onmt.inputters.inputter._collect_report_features", "enumerate", "enumerate", "onmt.model_builder.build_model", "train_single._tally_parameters", "onmt.utils.logging.logger.info", "train_single.print_trainable_parameters", "train_single._check_save_model_path", "onmt.utils.optimizers.build_optim", "onmt.models.build_model_saver", "onmt.trainer.build_trainer", "onmt.trainer.build_trainer.train", "onmt.utils.logging.logger.info", "torch.load", "onmt.inputters.inputter.lazily_load_dataset", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.inputters.inputter.build_dataset_iter", "onmt.inputters.inputter.build_dataset_iter", "onmt.trainer.build_trainer.report_manager.tensorboard_writer.close", "onmt.inputters.inputter.lazily_load_dataset", "onmt.inputters.inputter.lazily_load_dataset", "len", "len"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_single.training_opt_postprocessing", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.logging.init_logger", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._load_fields", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._collect_report_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_model", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_single._tally_parameters", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_single.print_trainable_parameters", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_single._check_save_model_path", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.build_optim", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.build_model_saver", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.build_trainer", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer.train", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.lazily_load_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset_iter", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset_iter", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.lazily_load_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.lazily_load_dataset"], ["", "def", "main", "(", "opt", ")", ":", "\n", "    ", "opt", "=", "training_opt_postprocessing", "(", "opt", ")", "\n", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "# Load checkpoint if we resume from a previous training.", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading checkpoint from %s'", "%", "opt", ".", "train_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "train_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "None", "\n", "model_opt", "=", "opt", "\n", "\n", "", "if", "opt", ".", "load_pretrained_selector_from", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading selector checkpoint from %s'", "%", "opt", ".", "load_pretrained_selector_from", ")", "\n", "sel_checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "load_pretrained_selector_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "else", ":", "\n", "        ", "sel_checkpoint", "=", "None", "\n", "\n", "", "if", "opt", ".", "load_pretrained_s2s_generator_from", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading s2s generator checkpoint from %s'", "%", "opt", ".", "load_pretrained_s2s_generator_from", ")", "\n", "s2s_gen_checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "load_pretrained_s2s_generator_from", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "else", ":", "\n", "        ", "s2s_gen_checkpoint", "=", "None", "\n", "\n", "# Peek the fisrt dataset to determine the data_type.", "\n", "# (All datasets have the same data_type).", "\n", "", "first_dataset", "=", "next", "(", "lazily_load_dataset", "(", "\"train\"", ",", "opt", ")", ")", "\n", "data_type", "=", "first_dataset", ".", "data_type", "\n", "\n", "# Load fields generated from preprocess phase.", "\n", "fields", "=", "_load_fields", "(", "first_dataset", ",", "data_type", ",", "opt", ",", "checkpoint", ")", "\n", "\n", "# Report src/tgt features.", "\n", "src_features", ",", "tgt_features", "=", "_collect_report_features", "(", "fields", ")", "\n", "for", "j", ",", "feat", "in", "enumerate", "(", "src_features", ")", ":", "\n", "        ", "logger", ".", "info", "(", "' * src feature %d size = %d'", "\n", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "", "for", "j", ",", "feat", "in", "enumerate", "(", "tgt_features", ")", ":", "\n", "        ", "logger", ".", "info", "(", "' * tgt feature %d size = %d'", "\n", "%", "(", "j", ",", "len", "(", "fields", "[", "feat", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "# Build model.", "\n", "", "model", "=", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ",", "sel_checkpoint", ",", "s2s_gen_checkpoint", ")", "\n", "\n", "# Fix the pretrained selector parameters if needed", "\n", "if", "model_opt", ".", "fix_sel_all", ":", "\n", "        ", "assert", "opt", ".", "load_pretrained_selector_from", "\n", "assert", "opt", ".", "sel_lambda", "==", "0.0", "\n", "assert", "not", "model_opt", ".", "fix_sel_classifier", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'selector'", "in", "name", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "# only fix the classifier of the selector", "\n", "", "", "", "if", "model_opt", ".", "fix_sel_classifier", ":", "\n", "        ", "assert", "opt", ".", "load_pretrained_selector_from", "\n", "assert", "not", "model_opt", ".", "fix_sel_all", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "'selector'", "in", "name", "and", "'rnn'", "not", "in", "name", "and", "'embeddings'", "not", "in", "name", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "n_params", ",", "sel", ",", "enc", ",", "dec", ",", "gen", "=", "_my_tally_parameters", "(", "model", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.train_single.print_trainable_parameters": [[158, 163], ["sum", "onmt.utils.logging.logger.info", "model.named_parameters", "onmt.utils.logging.logger.info", "p.nelement", "model.parameters"], "function", ["None"], ["logger", ".", "info", "(", "'encoder: %d'", "%", "enc", ")", "\n", "logger", ".", "info", "(", "'decoder: %d'", "%", "dec", ")", "\n", "logger", ".", "info", "(", "'generator: %d'", "%", "gen", ")", "\n", "logger", ".", "info", "(", "'* number of parameters: %d'", "%", "n_params", ")", "\n", "\n", "print_trainable_parameters", "(", "model", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.merge_opts": [[631, 683], ["parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument_group.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument_group.add_argument"], "function", ["None"], ["help", "=", "'print Markdown-formatted help text and exit.'", ")", "\n", "\n", "\n", "# MARKDOWN boilerplate", "\n", "\n", "# Copyright 2016 The Chromium Authors. All rights reserved.", "\n", "# Use of this source code is governed by a BSD-style license that can be", "\n", "# found in the LICENSE file.", "\n", "", "class", "MarkdownHelpFormatter", "(", "argparse", ".", "HelpFormatter", ")", ":", "\n", "    ", "\"\"\"A really bare-bones argparse help formatter that generates valid markdown.\n    This will generate something like:\n    usage\n    # **section heading**:\n    ## **--argument-one**\n    ```\n    argument-one help text\n    ```\n    \"\"\"", "\n", "\n", "def", "_format_usage", "(", "self", ",", "usage", ",", "actions", ",", "groups", ",", "prefix", ")", ":", "\n", "        ", "return", "\"\"", "\n", "\n", "", "def", "format_help", "(", "self", ")", ":", "\n", "        ", "print", "(", "self", ".", "_prog", ")", "\n", "self", ".", "_root_section", ".", "heading", "=", "'# Options: %s'", "%", "self", ".", "_prog", "\n", "return", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "format_help", "(", ")", "\n", "\n", "", "def", "start_section", "(", "self", ",", "heading", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpFormatter", ",", "self", ")", ".", "start_section", "(", "'### **%s**'", "%", "heading", ")", "\n", "\n", "", "def", "_format_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "action", ".", "dest", "==", "\"help\"", "or", "action", ".", "dest", "==", "\"md\"", ":", "\n", "            ", "return", "\"\"", "\n", "", "lines", "=", "[", "]", "\n", "lines", ".", "append", "(", "'* **-%s %s** '", "%", "(", "action", ".", "dest", ",", "\n", "\"[%s]\"", "%", "action", ".", "default", "\n", "if", "action", ".", "default", "else", "\"[]\"", ")", ")", "\n", "if", "action", ".", "help", ":", "\n", "            ", "help_text", "=", "self", ".", "_expand_help", "(", "action", ")", "\n", "lines", ".", "extend", "(", "self", ".", "_split_lines", "(", "help_text", ",", "80", ")", ")", "\n", "", "lines", ".", "extend", "(", "[", "''", ",", "''", "]", ")", "\n", "return", "'\\n'", ".", "join", "(", "lines", ")", "\n", "\n", "\n", "", "", "class", "MarkdownHelpAction", "(", "argparse", ".", "Action", ")", ":", "\n", "    ", "\"\"\" MD help action \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "option_strings", ",", "\n", "dest", "=", "argparse", ".", "SUPPRESS", ",", "default", "=", "argparse", ".", "SUPPRESS", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MarkdownHelpAction", ",", "self", ")", ".", "__init__", "(", "\n", "option_strings", "=", "option_strings", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.trainer.Trainer._reranker_gradient_accumulation": [[513, 542], ["onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "trainer.Trainer.model", "trainer.Trainer.train_loss.sharded_compute_loss", "total_stats.update", "report_stats.update", "trainer.Trainer.optim.step", "trainer.Trainer.model.zero_grad", "len", "trainer.Trainer.model.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute.sharded_compute_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad"], ["report_stats", ".", "update", "(", "batch_stats", ")", "\n", "\n", "", "assert", "self", ".", "n_gpu", "==", "1", "\n", "# 3. Update the parameters and statistics.", "\n", "self", ".", "optim", ".", "step", "(", "self", ".", "cur_valid_ppl", ")", "\n", "report_stats", ".", "lr_rate", "=", "self", ".", "optim", ".", "learning_rate", "\n", "report_stats", ".", "total_norm", "=", "self", ".", "optim", ".", "total_norm", "\n", "\n", "", "def", "_start_report_manager", "(", "self", ",", "start_time", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Simple function to start report manager (if any)\n        \"\"\"", "\n", "if", "self", ".", "report_manager", "is", "not", "None", ":", "\n", "            ", "if", "start_time", "is", "None", ":", "\n", "                ", "self", ".", "report_manager", ".", "start", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "report_manager", ".", "start_time", "=", "start_time", "\n", "\n", "", "", "", "def", "_maybe_gather_stats", "(", "self", ",", "stat", ")", ":", "\n", "        ", "\"\"\"\n        Gather statistics in multi-processes cases\n\n        Args:\n            stat(:obj:onmt.utils.Statistics): a Statistics object to gather\n                or None (it returns None in this case)\n\n        Returns:\n            stat: the updated (or unchanged) stat object\n        \"\"\"", "\n", "if", "self", ".", "key_model", "==", "\"key_selector\"", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_reranker": [[65, 74], ["onmt.reranker.rnn_reranker.RNNReRanker"], "function", ["None"], ["", "def", "build_selector", "(", "opt", ",", "embeddings", ")", ":", "\n", "    ", "\"\"\"\n    Build a selector network.\n    Args:\n        opt: the option in current environment.\n        embeddings (Embeddings): vocab embeddings for this selector.\n    \"\"\"", "\n", "return", "RNNSelector", "(", "opt", ".", "rnn_type", ",", "opt", ".", "brnn", ",", "opt", ".", "enc_layers", ",", "\n", "opt", ".", "rnn_size", ",", "opt", ".", "dropout", ",", "embeddings", ",", "opt", ".", "sel_classifier", ",", "opt", ".", "detach_sel_probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_reranker_model": [[441, 488], ["onmt.collect_feature_vocabs", "model_builder.build_embeddings", "model_builder.build_reranker", "onmt.models.ReRankerModel", "onmt.models.ReRankerModel", "torch.device", "torch.device", "onmt.models.ReRankerModel.to", "onmt.models.ReRankerModel.load_state_dict", "hasattr", "onmt.models.ReRankerModel.parameters", "onmt.models.ReRankerModel.parameters", "onmt.models.ReRankerModel.parameters", "onmt.models.ReRankerModel.reranker.embeddings.load_pretrained_vectors", "p.data.uniform_", "p.dim", "torch.nn.init.xavier_uniform_", "p.dim", "torch.nn.init.xavier_uniform_"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_feature_vocabs", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_embeddings", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.build_reranker", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.image_encoder.ImageEncoder.load_pretrained_vectors"], ["return", "selector", "\n", "\n", "\n", "", "def", "build_model", "(", "model_opt", ",", "opt", ",", "fields", ",", "checkpoint", ",", "sel_checkpoint", "=", "None", ",", "s2s_gen_checkpoint", "=", "None", ")", ":", "\n", "    ", "\"\"\" Build the specified Model \"\"\"", "\n", "# Refer to Figure 2. of our KG-KE-KR-M paper (https://arxiv.org/pdf/1904.03454.pdf),", "\n", "# we show the components of each model.", "\n", "# 'key_selector': Encoder1 + Extractor", "\n", "# 'key_generator': Encoder1 + Encoder2 (if model_opt.use_retrieved_keys == True) + Decoder", "\n", "# 'key_end2end': Encoder1 + Encoder2 (if model_opt.use_retrieved_keys == True) + Extractor + Decoder", "\n", "assert", "model_opt", ".", "key_model", "in", "[", "'key_generator'", ",", "'key_selector'", ",", "'key_end2end'", "]", "\n", "if", "model_opt", ".", "key_model", "==", "'key_generator'", ":", "\n", "        ", "logger", ".", "info", "(", "'Building seq2seq model...'", ")", "\n", "model", "=", "build_base_model", "(", "model_opt", ",", "fields", ",", "use_gpu", "(", "opt", ")", ",", "checkpoint", ")", "\n", "", "elif", "model_opt", ".", "key_model", "==", "'key_selector'", ":", "\n", "        ", "logger", ".", "info", "(", "'Building selector model...'", ")", "\n", "model", "=", "build_selector_model", "(", "model_opt", ",", "fields", ",", "use_gpu", "(", "opt", ")", ",", "checkpoint", ")", "\n", "", "else", ":", "\n", "# model_opt.key_model == 'key_end2end'", "\n", "        ", "logger", ".", "info", "(", "'Building end2end model...'", ")", "\n", "model", "=", "build_end2end_model", "(", "model_opt", ",", "fields", ",", "\n", "use_gpu", "(", "opt", ")", ",", "checkpoint", ",", "sel_checkpoint", ",", "s2s_gen_checkpoint", ")", "\n", "", "logger", ".", "info", "(", "model", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.selectors.rnn_selectors.RNNSelector.__init__": [[31, 71], ["onmt.encoders.encoder.EncoderBase.__init__", "onmt.utils.rnn_factory.rnn_factory", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.rnn_factory.rnn_factory"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "sel_classifier", "=", "'simple_fc'", ",", "detach_sel_probs", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNSelector", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "embeddings", "is", "not", "None", "\n", "assert", "bidirectional", "\n", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "assert", "hidden_size", "%", "num_directions", "==", "0", "\n", "hidden_size", "=", "hidden_size", "//", "num_directions", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n", "self", ".", "detach_sel_probs", "=", "detach_sel_probs", "\n", "\n", "self", ".", "rnn", ",", "self", ".", "no_pack_padded_seq", "=", "rnn_factory", "(", "rnn_type", ",", "\n", "input_size", "=", "embeddings", ".", "embedding_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", "if", "num_layers", ">", "1", "else", "0.0", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n", "# add a simplest classifier first to build the whole framework", "\n", "# activation function: sigmoid", "\n", "self", ".", "sel_classifier", "=", "sel_classifier", "\n", "if", "sel_classifier", "==", "'simple_fc'", ":", "\n", "            ", "self", ".", "word_feats_linear", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "simple_classifier", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "", "else", ":", "\n", "# for complex_Nallapati classifier, refer to https://arxiv.org/pdf/1611.04230.pdf", "\n", "            ", "self", ".", "word_feats_linear", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "art_feats_linear", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", ",", "hidden_size", ")", "\n", "\n", "self", ".", "w_content", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ")", "\n", "self", ".", "w_salience", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "w_novelty", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "\n", "", "self", ".", "dropout_m", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.selectors.rnn_selectors.RNNSelector.forward": [[72, 130], ["rnn_selectors.RNNSelector._check_args", "rnn_selectors.RNNSelector.embeddings", "rnn_selectors.RNNSelector.size", "rnn_selectors.RNNSelector.rnn", "rnn_selectors.RNNSelector.dropout_m", "lengths.view().tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "rnn_selectors.RNNSelector.tanh", "rnn_selectors.RNNSelector.simple_classifier", "torch.cat().transpose.view", "torch.cat().transpose.view", "torch.cat().transpose.view", "rnn_selectors.RNNSelector.sigmoid", "rnn_selectors.RNNSelector.tanh", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rnn_selectors.RNNSelector.art_feats_linear", "rnn_selectors.RNNSelector.tanh", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "range", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "probs.detach.detach.detach", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "rnn_selectors.RNNSelector.word_feats_linear", "rnn_selectors.RNNSelector.word_feats_linear", "rnn_selectors.RNNSelector.w_content", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat().transpose.append", "torch.cat().transpose.append", "torch.cat().transpose.append", "rnn_selectors.RNNSelector.sigmoid", "probs.detach.detach.append", "lengths.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rnn_selectors.RNNSelector.w_salience", "rnn_selectors.RNNSelector.w_novelty", "rnn_selectors.RNNSelector.tanh"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.detach"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`EncoderBase.forward()`\"", "\n", "self", ".", "_check_args", "(", "src", ",", "lengths", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "seq_len", ",", "batch_size", ",", "_", "=", "emb", ".", "size", "(", ")", "\n", "\n", "packed_emb", "=", "emb", "\n", "if", "lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "# Lengths data is wrapped inside a Tensor.", "\n", "            ", "lengths_list", "=", "lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "packed_emb", "=", "pack", "(", "emb", ",", "lengths_list", ")", "\n", "\n", "# encoder_final: [2(directions), batch_size, hidden_dim]", "\n", "# memory_bank: [seq_len, batch_size, 2 * hidden_dim]", "\n", "", "memory_bank", ",", "encoder_final", "=", "self", ".", "rnn", "(", "packed_emb", ")", "\n", "\n", "if", "lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "            ", "memory_bank", "=", "unpack", "(", "memory_bank", ")", "[", "0", "]", "\n", "\n", "", "memory_bank", "=", "self", ".", "dropout_m", "(", "memory_bank", ")", "\n", "if", "self", ".", "sel_classifier", "==", "'simple_fc'", ":", "\n", "            ", "word_feats", "=", "self", ".", "tanh", "(", "self", ".", "word_feats_linear", "(", "memory_bank", ")", ")", "\n", "logits", "=", "self", ".", "simple_classifier", "(", "word_feats", ")", "# [seq_len, batch_size, 1]", "\n", "logits", "=", "logits", ".", "view", "(", "seq_len", ",", "batch_size", ")", "# [seq_len, batch_size]", "\n", "probs", "=", "self", ".", "sigmoid", "(", "logits", ")", "# [seq_len, batch_size]", "\n", "", "else", ":", "\n", "# [corrected]", "\n", "            ", "word_feats", "=", "self", ".", "tanh", "(", "self", ".", "word_feats_linear", "(", "memory_bank", ")", ")", "# [seq_len, batch_size, hidden_size]", "\n", "\n", "# use the concatenation of the final state as the article feature", "\n", "art_feats", "=", "torch", ".", "cat", "(", "[", "encoder_final", "[", "0", "]", ",", "encoder_final", "[", "1", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "art_feats", "=", "self", ".", "art_feats_linear", "(", "art_feats", ")", "# [batch_size, hidden_size]", "\n", "art_feats", "=", "self", ".", "tanh", "(", "art_feats", ")", "\n", "s", "=", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "cuda", "(", ")", "\n", "\n", "logits", "=", "[", "]", "\n", "probs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "seq_len", ")", ":", "\n", "                ", "content_feats", "=", "self", ".", "w_content", "(", "word_feats", "[", "i", ",", ":", ",", ":", "]", ")", "# [batch_size, 1]", "\n", "salience_feats", "=", "torch", ".", "sum", "(", "self", ".", "w_salience", "(", "word_feats", "[", "i", ",", ":", ",", ":", "]", ")", "*", "art_feats", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# [batch_size, 1]", "\n", "novelty_feats", "=", "torch", ".", "sum", "(", "self", ".", "w_novelty", "(", "word_feats", "[", "i", ",", ":", ",", ":", "]", ")", "*", "self", ".", "tanh", "(", "s", ")", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "logit", "=", "content_feats", "+", "salience_feats", "-", "novelty_feats", "# [batch_size, 1]", "\n", "logits", ".", "append", "(", "logit", ")", "\n", "\n", "prob", "=", "self", ".", "sigmoid", "(", "logit", ")", "\n", "probs", ".", "append", "(", "prob", ")", "\n", "\n", "s", "=", "s", "+", "word_feats", "[", "i", ",", ":", ",", ":", "]", "*", "prob", "\n", "\n", "", "logits", "=", "torch", ".", "cat", "(", "logits", ",", "dim", "=", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", "# [seq_len, batch_size]", "\n", "probs", "=", "torch", ".", "cat", "(", "probs", ",", "dim", "=", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", "# [seq_len, batch_size]", "\n", "\n", "", "if", "self", ".", "detach_sel_probs", ":", "\n", "            ", "probs", "=", "probs", ".", "detach", "(", ")", "\n", "\n", "", "return", "logits", ",", "probs", ",", "encoder_final", ",", "memory_bank", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.__init__": [[16, 45], ["time.time"], "methods", ["None"], ["gen_loss", "=", "0.0", ",", "gen_n_words", "=", "0", ",", "gen_n_correct", "=", "0", ",", "incons_loss", "=", "0.0", ",", "merged_loss", "=", "0.0", ")", ":", "\n", "# for the selector", "\n", "        ", "self", ".", "sel_loss", "=", "sel_loss", "\n", "self", ".", "sel_loss_list", "=", "[", "]", "if", "sel_loss", "==", "0", "else", "[", "sel_loss", "]", "\n", "self", ".", "sel_true_positive", "=", "sel_true_positive", "\n", "self", ".", "sel_pred_select_num", "=", "sel_pred_select_num", "\n", "self", ".", "sel_gt_select_num", "=", "sel_gt_select_num", "\n", "\n", "# for the s2s generator", "\n", "self", ".", "gen_loss", "=", "gen_loss", "\n", "self", ".", "gen_loss_list", "=", "[", "]", "if", "gen_loss", "==", "0.0", "else", "[", "gen_loss", "]", "\n", "self", ".", "gen_n_words", "=", "gen_n_words", "\n", "self", ".", "gen_n_correct", "=", "gen_n_correct", "\n", "\n", "# for inconsistency loss", "\n", "self", ".", "incons_loss", "=", "incons_loss", "\n", "self", ".", "incons_loss_list", "=", "[", "]", "if", "incons_loss", "==", "0.0", "else", "[", "incons_loss", "]", "\n", "\n", "# for merged loss", "\n", "self", ".", "merged_loss", "=", "merged_loss", "\n", "self", ".", "merged_loss_list", "=", "[", "]", "if", "merged_loss", "==", "0.0", "else", "[", "merged_loss", "]", "\n", "\n", "# for common use", "\n", "self", ".", "batch_size_list", "=", "[", "]", "if", "batch_size", "==", "0", "else", "[", "batch_size", "]", "\n", "self", ".", "lr_rate", "=", "0.0", "\n", "self", ".", "total_norm", "=", "0.0", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# def sel_pred_select_ratio(self):", "\n", "#     \"\"\" compute prediction selection ratio \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_ave_loss": [[56, 61], ["float", "len", "zip", "sum"], "methods", ["None"], ["batch_normalized_losses", "=", "[", "l", "/", "b", "for", "l", ",", "b", "in", "zip", "(", "self", ".", "sel_loss_list", ",", "self", ".", "batch_size_list", ")", "]", "\n", "nums", "=", "float", "(", "len", "(", "batch_normalized_losses", ")", ")", "\n", "return", "sum", "(", "batch_normalized_losses", ")", "/", "nums", "if", "nums", "!=", "0.0", "else", "0.0", "\n", "\n", "", "def", "sel_precision", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute the precision \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_precision": [[62, 68], ["None"], "methods", ["None"], ["if", "self", ".", "sel_pred_select_num", "==", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "sel_true_positive", "*", "1.0", "/", "self", ".", "sel_pred_select_num", "\n", "\n", "", "", "def", "sel_recall", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute the recall \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_recall": [[69, 75], ["None"], "methods", ["None"], ["if", "self", ".", "sel_gt_select_num", "==", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "sel_true_positive", "*", "1.0", "/", "self", ".", "sel_gt_select_num", "\n", "\n", "", "", "def", "sel_f1_score", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute the F1 score \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_f1_score": [[76, 84], ["statistics.E2EStatistics.sel_recall", "statistics.E2EStatistics.sel_precision"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_recall", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_precision"], ["R", "=", "self", ".", "sel_recall", "(", ")", "\n", "P", "=", "self", ".", "sel_precision", "(", ")", "\n", "if", "P", "==", "0.0", "or", "R", "==", "0.0", ":", "\n", "            ", "return", "0.0", "\n", "", "else", ":", "\n", "            ", "return", "2", "*", "P", "*", "R", "/", "(", "P", "+", "R", ")", "\n", "\n", "# def sel_accuracy(self):", "\n", "#     \"\"\" compute the accuracy\"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_accuracy": [[90, 96], ["None"], "methods", ["None"], ["if", "self", ".", "gen_n_words", "==", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "else", ":", "\n", "            ", "return", "100", "*", "(", "self", ".", "gen_n_correct", "/", "self", ".", "gen_n_words", ")", "\n", "\n", "", "", "def", "gen_xent", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute cross entropy \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_xent": [[97, 103], ["None"], "methods", ["None"], ["if", "self", ".", "gen_n_words", "==", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "gen_loss", "/", "self", ".", "gen_n_words", "\n", "\n", "", "", "def", "gen_ppl", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute perplexity \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_ppl": [[104, 110], ["math.exp", "min"], "methods", ["None"], ["if", "self", ".", "gen_n_words", "==", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "else", ":", "\n", "            ", "return", "math", ".", "exp", "(", "min", "(", "self", ".", "gen_loss", "/", "self", ".", "gen_n_words", ",", "100", ")", ")", "\n", "\n", "", "", "def", "gen_ave_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute the averaged generation loss\"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_ave_loss": [[111, 116], ["float", "len", "zip", "sum"], "methods", ["None"], ["batch_normalized_losses", "=", "[", "l", "/", "b", "for", "l", ",", "b", "in", "zip", "(", "self", ".", "gen_loss_list", ",", "self", ".", "batch_size_list", ")", "]", "\n", "nums", "=", "float", "(", "len", "(", "batch_normalized_losses", ")", ")", "\n", "return", "sum", "(", "batch_normalized_losses", ")", "/", "nums", "if", "nums", "!=", "0.0", "else", "0.0", "\n", "\n", "", "def", "incons_ave_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute the averaged inconsistency loss\"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.incons_ave_loss": [[117, 122], ["float", "len", "zip", "sum"], "methods", ["None"], ["batch_normalized_losses", "=", "[", "l", "/", "b", "for", "l", ",", "b", "in", "zip", "(", "self", ".", "incons_loss_list", ",", "self", ".", "batch_size_list", ")", "]", "\n", "nums", "=", "float", "(", "len", "(", "batch_normalized_losses", ")", ")", "\n", "return", "sum", "(", "batch_normalized_losses", ")", "/", "nums", "if", "nums", "!=", "0.0", "else", "0.0", "\n", "\n", "", "def", "merged_ave_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute the averaged merged_loss\"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.merged_ave_loss": [[123, 128], ["float", "len", "zip", "sum"], "methods", ["None"], ["batch_normalized_losses", "=", "[", "l", "/", "b", "for", "l", ",", "b", "in", "zip", "(", "self", ".", "merged_loss_list", ",", "self", ".", "batch_size_list", ")", "]", "\n", "nums", "=", "float", "(", "len", "(", "batch_normalized_losses", ")", ")", "\n", "return", "sum", "(", "batch_normalized_losses", ")", "/", "nums", "if", "nums", "!=", "0.0", "else", "0.0", "\n", "\n", "", "def", "elapsed_time", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute elapsed time \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.elapsed_time": [[135, 138], ["time.time"], "methods", ["None"], ["self", ".", "sel_true_positive", "+=", "stat", ".", "sel_true_positive", "\n", "# self.sel_true_negative += stat.sel_true_negative", "\n", "self", ".", "sel_pred_select_num", "+=", "stat", ".", "sel_pred_select_num", "\n", "self", ".", "sel_gt_select_num", "+=", "stat", ".", "sel_gt_select_num", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.update": [[139, 168], ["None"], "methods", ["None"], ["# self.sel_total_words_num += stat.sel_total_words_num", "\n", "\n", "# for the s2s generator", "\n", "self", ".", "gen_loss", "+=", "stat", ".", "gen_loss", "\n", "self", ".", "gen_loss_list", "+=", "stat", ".", "gen_loss_list", "\n", "self", ".", "gen_n_words", "+=", "stat", ".", "gen_n_words", "\n", "self", ".", "gen_n_correct", "+=", "stat", ".", "gen_n_correct", "\n", "\n", "# for the inconsistency loss", "\n", "self", ".", "incons_loss", "+=", "stat", ".", "incons_loss", "\n", "self", ".", "incons_loss_list", "+=", "stat", ".", "incons_loss_list", "\n", "\n", "# for merged loss", "\n", "self", ".", "merged_loss", "+=", "stat", ".", "merged_loss", "\n", "self", ".", "merged_loss_list", "+=", "stat", ".", "merged_loss_list", "\n", "\n", "# for common use", "\n", "self", ".", "batch_size_list", "+=", "stat", ".", "batch_size_list", "\n", "\n", "", "def", "output", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "start", ")", ":", "\n", "        ", "\"\"\"Write out statistics to stdout.\n\n        Args:\n           step (int): current step\n           n_batch (int): total batches\n           start (int): start time of step.\n        \"\"\"", "\n", "# t = self.elapsed_time()", "\n", "logger", ".", "info", "(", "\n", "(", "\"Step %06d; sel_ave_loss: %7.5f; sel_p: %4.2f; sel_r: %4.2f; \"", "+", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.output": [[169, 194], ["onmt.utils.logging.logger.info", "sys.stdout.flush", "statistics.E2EStatistics.sel_ave_loss", "statistics.E2EStatistics.sel_precision", "statistics.E2EStatistics.sel_recall", "statistics.E2EStatistics.gen_ppl", "statistics.E2EStatistics.gen_accuracy", "statistics.E2EStatistics.incons_ave_loss", "statistics.E2EStatistics.merged_ave_loss", "statistics.E2EStatistics.ave_total_norm", "time.time"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_precision", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_recall", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_ppl", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_accuracy", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.incons_ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.merged_ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_total_norm"], ["\"gen_ppl: %5.2f; gen_acc: %6.2f;\"", "+", "\n", "\"incons_ave_loss: %7.5f; merged_ave_loss: %7.5f; \"", "+", "\n", "\"lr: %7.5f; tnorm: %4.2f; %6.0f sec\"", ")", "\n", "%", "(", "step", ",", "self", ".", "sel_ave_loss", "(", ")", ",", "\n", "self", ".", "sel_precision", "(", ")", ",", "\n", "self", ".", "sel_recall", "(", ")", ",", "\n", "self", ".", "gen_ppl", "(", ")", ",", "\n", "self", ".", "gen_accuracy", "(", ")", ",", "\n", "self", ".", "incons_ave_loss", "(", ")", ",", "\n", "self", ".", "merged_ave_loss", "(", ")", ",", "\n", "learning_rate", ",", "\n", "self", ".", "total_norm", ",", "\n", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "def", "log_tensorboard", "(", "self", ",", "prefix", ",", "writer", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "\"\"\" display statistics to tensorboard \"\"\"", "\n", "# selector", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/sel_ave_loss\"", ",", "self", ".", "sel_ave_loss", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/sel_precision\"", ",", "self", ".", "sel_precision", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/sel_recall\"", ",", "self", ".", "sel_recall", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/sel_F1\"", ",", "self", ".", "sel_f1_score", "(", ")", ",", "step", ")", "\n", "# generator", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/gen_ppl\"", ",", "self", ".", "gen_ppl", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/gen_acc\"", ",", "self", ".", "gen_accuracy", "(", ")", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/gen_ave_loss\"", ",", "self", ".", "gen_ave_loss", "(", ")", ",", "step", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.log_tensorboard": [[195, 213], ["writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "statistics.E2EStatistics.sel_ave_loss", "statistics.E2EStatistics.sel_precision", "statistics.E2EStatistics.sel_recall", "statistics.E2EStatistics.sel_f1_score", "statistics.E2EStatistics.gen_ppl", "statistics.E2EStatistics.gen_accuracy", "statistics.E2EStatistics.gen_ave_loss", "statistics.E2EStatistics.incons_ave_loss", "statistics.E2EStatistics.merged_ave_loss", "statistics.E2EStatistics.ave_total_norm"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_precision", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_recall", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_f1_score", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_ppl", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_accuracy", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.incons_ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.merged_ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_total_norm"], ["# inconsistency", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/incons_ave_loss\"", ",", "self", ".", "incons_ave_loss", "(", ")", ",", "step", ")", "\n", "# merged", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/merged_ave_loss\"", ",", "self", ".", "merged_ave_loss", "(", ")", ",", "step", ")", "\n", "# public", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/lr_rate\"", ",", "learning_rate", ",", "step", ")", "\n", "writer", ".", "add_scalar", "(", "prefix", "+", "\"/total_norm\"", ",", "self", ".", "total_norm", ",", "step", ")", "\n", "\n", "\n", "", "@", "staticmethod", "\n", "def", "all_gather_stats", "(", "stat", ",", "max_size", "=", "4096", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.all_gather_stats": [[215, 229], ["None"], "methods", ["None"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "@", "staticmethod", "\n", "def", "all_gather_stats_list", "(", "stat_list", ",", "max_size", "=", "4096", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "\n", "# class SelectorStatistics(object):", "\n", "#     \"\"\"", "\n", "#     Accumulator for loss statistics of the selector.", "\n", "#     \"\"\"", "\n", "#", "\n", "#     def __init__(self, loss=0, batch_size=0, true_positive=0, pred_select_num=0, gt_select_num=0, total_words_num=0):", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.all_gather_stats_list": [[230, 233], ["None"], "methods", ["None"], ["#         self.loss = loss", "\n", "#         self.loss_list = [] if loss == 0 else [loss]", "\n", "#         self.batch_size_list = [] if batch_size == 0 else [batch_size]", "\n", "#         self.true_positive = true_positive", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.logging.init_logger": [[9, 24], ["logging.Formatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.FileHandler", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler"], "function", ["None"], ["def", "init_logger", "(", "log_file", "=", "None", ")", ":", "\n", "    ", "log_format", "=", "logging", ".", "Formatter", "(", "\"[%(asctime)s %(levelname)s] %(message)s\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "\n", "if", "log_file", "and", "log_file", "!=", "''", ":", "\n", "        ", "file_handler", "=", "logging", ".", "FileHandler", "(", "log_file", ")", "\n", "file_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "addHandler", "(", "file_handler", ")", "\n", "\n", "", "console_handler", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console_handler", ".", "setFormatter", "(", "log_format", ")", "\n", "logger", ".", "handlers", "=", "[", "console_handler", "]", "\n", "\n", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.is_master": [[16, 18], ["None"], "function", ["None"], ["def", "is_master", "(", "opt", ")", ":", "\n", "    ", "return", "opt", ".", "gpu_rank", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.multi_init": [[20, 33], ["len", "torch.distributed.init_process_group", "torch.distributed.get_rank", "len", "ValueError", "distributed.is_master"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.is_master"], ["", "def", "multi_init", "(", "opt", ")", ":", "\n", "    ", "if", "len", "(", "opt", ".", "gpuid", ")", "==", "1", ":", "\n", "        ", "raise", "ValueError", "(", "'Cannot initialize multiprocess with one gpu only'", ")", "\n", "", "dist_init_method", "=", "'tcp://localhost:10000'", "\n", "dist_world_size", "=", "len", "(", "opt", ".", "gpuid", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "opt", ".", "gpu_backend", ",", "init_method", "=", "dist_init_method", ",", "\n", "world_size", "=", "dist_world_size", ",", "rank", "=", "opt", ".", "gpu_rank", ")", "\n", "opt", ".", "gpu_rank", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "if", "not", "is_master", "(", "opt", ")", ":", "\n", "        ", "logger", ".", "disabled", "=", "True", "\n", "\n", "", "return", "opt", ".", "gpu_rank", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.all_reduce_and_rescale_tensors": [[35, 87], ["tensors[].new().zero_", "torch.distributed.all_reduce", "tensors[].new().zero_.div_", "len", "distributed.all_reduce_and_rescale_tensors.all_reduce_buffer"], "function", ["None"], ["", "def", "all_reduce_and_rescale_tensors", "(", "tensors", ",", "rescale_denom", ",", "\n", "buffer_size", "=", "10485760", ")", ":", "\n", "    ", "\"\"\"All-reduce and rescale tensors in chunks of the specified size.\n\n    Args:\n        tensors: list of Tensors to all-reduce\n        rescale_denom: denominator for rescaling summed Tensors\n        buffer_size: all-reduce chunk size in bytes\n    \"\"\"", "\n", "# buffer size in bytes, determine equiv. # of elements based on data type", "\n", "buffer_t", "=", "tensors", "[", "0", "]", ".", "new", "(", "\n", "math", ".", "ceil", "(", "buffer_size", "/", "tensors", "[", "0", "]", ".", "element_size", "(", ")", ")", ")", ".", "zero_", "(", ")", "\n", "buffer", "=", "[", "]", "\n", "\n", "def", "all_reduce_buffer", "(", ")", ":", "\n", "# copy tensors into buffer_t", "\n", "        ", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ".", "copy_", "(", "t", ".", "view", "(", "-", "1", ")", ")", "\n", "offset", "+=", "numel", "\n", "\n", "# all-reduce and rescale", "\n", "", "torch", ".", "distributed", ".", "all_reduce", "(", "buffer_t", "[", ":", "offset", "]", ")", "\n", "buffer_t", ".", "div_", "(", "rescale_denom", ")", "\n", "\n", "# copy all-reduced buffer back into tensors", "\n", "offset", "=", "0", "\n", "for", "t", "in", "buffer", ":", "\n", "            ", "numel", "=", "t", ".", "numel", "(", ")", "\n", "t", ".", "view", "(", "-", "1", ")", ".", "copy_", "(", "buffer_t", "[", "offset", ":", "offset", "+", "numel", "]", ")", "\n", "offset", "+=", "numel", "\n", "\n", "", "", "filled", "=", "0", "\n", "for", "t", "in", "tensors", ":", "\n", "        ", "sz", "=", "t", ".", "numel", "(", ")", "*", "t", ".", "element_size", "(", ")", "\n", "if", "sz", ">", "buffer_size", ":", "\n", "# tensor is bigger than buffer, all-reduce and rescale directly", "\n", "            ", "torch", ".", "distributed", ".", "all_reduce", "(", "t", ")", "\n", "t", ".", "div_", "(", "rescale_denom", ")", "\n", "", "elif", "filled", "+", "sz", ">", "buffer_size", ":", "\n", "# buffer is full, all-reduce and replace buffer with grad", "\n", "            ", "all_reduce_buffer", "(", ")", "\n", "buffer", "=", "[", "t", "]", "\n", "filled", "=", "sz", "\n", "", "else", ":", "\n", "# add tensor to buffer", "\n", "            ", "buffer", ".", "append", "(", "t", ")", "\n", "filled", "+=", "sz", "\n", "\n", "", "", "if", "len", "(", "buffer", ")", ">", "0", ":", "\n", "        ", "all_reduce_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.distributed.all_gather_list": [[89, 123], ["torch.distributed.get_world_size", "pickle.dumps", "len", "torch.ByteTensor", "torch.distributed.all_gather", "range", "torch.cuda.ByteTensor", "ValueError", "list", "in_buffer.cuda", "bytes", "pickle.loads", "results.append", "hasattr", "all_gather_list._in_buffer.size", "torch.cuda.ByteTensor", "out_buffer[].item", "out_buffer[].tolist", "range", "out_buffer[].item"], "function", ["None"], ["", "", "def", "all_gather_list", "(", "data", ",", "max_size", "=", "4096", ")", ":", "\n", "    ", "\"\"\"Gathers arbitrary data from all nodes into a list.\"\"\"", "\n", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "if", "not", "hasattr", "(", "all_gather_list", ",", "'_in_buffer'", ")", "or", "max_size", "!=", "all_gather_list", ".", "_in_buffer", ".", "size", "(", ")", ":", "\n", "        ", "all_gather_list", ".", "_in_buffer", "=", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "all_gather_list", ".", "_out_buffers", "=", "[", "\n", "torch", ".", "cuda", ".", "ByteTensor", "(", "max_size", ")", "\n", "for", "i", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "", "in_buffer", "=", "all_gather_list", ".", "_in_buffer", "\n", "out_buffers", "=", "all_gather_list", ".", "_out_buffers", "\n", "\n", "enc", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "enc_size", "=", "len", "(", "enc", ")", "\n", "if", "enc_size", "+", "2", ">", "max_size", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'encoded data exceeds max_size: {}'", ".", "format", "(", "enc_size", "+", "2", ")", ")", "\n", "", "assert", "max_size", "<", "255", "*", "256", "\n", "in_buffer", "[", "0", "]", "=", "enc_size", "//", "255", "# this encoding works for max_size < 65k", "\n", "in_buffer", "[", "1", "]", "=", "enc_size", "%", "255", "\n", "in_buffer", "[", "2", ":", "enc_size", "+", "2", "]", "=", "torch", ".", "ByteTensor", "(", "list", "(", "enc", ")", ")", "\n", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "out_buffers", ",", "in_buffer", ".", "cuda", "(", ")", ")", "\n", "\n", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "        ", "out_buffer", "=", "out_buffers", "[", "i", "]", "\n", "size", "=", "(", "255", "*", "out_buffer", "[", "0", "]", ".", "item", "(", ")", ")", "+", "out_buffer", "[", "1", "]", ".", "item", "(", ")", "\n", "\n", "bytes_list", "=", "bytes", "(", "out_buffer", "[", "2", ":", "size", "+", "2", "]", ".", "tolist", "(", ")", ")", "\n", "result", "=", "pickle", ".", "loads", "(", "bytes_list", ")", "\n", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.ReportMgrBase.__init__": [[41, 51], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "report_every", ",", "start_time", "=", "-", "1.", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            report_every(int): Report status every this many sentences\n            start_time(float): manually set report start time. Negative values\n                means that you will need to set it later or use `start()`\n        \"\"\"", "\n", "self", ".", "report_every", "=", "report_every", "\n", "self", ".", "progress_step", "=", "0", "\n", "self", ".", "start_time", "=", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.ReportMgrBase.start": [[52, 54], ["time.time"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.ReportMgrBase.log": [[55, 57], ["onmt.utils.logging.logger.info"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "logger", ".", "info", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.ReportMgrBase.report_training": [[58, 86], ["ValueError", "onmt.utils.Statistics.all_gather_stats", "report_manager.ReportMgrBase._report_training", "onmt.utils.Statistics"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.all_gather_stats", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr._report_training"], ["", "def", "report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ",", "multigpu", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        This is the user-defined batch-level traing progress\n        report function.\n\n        Args:\n            step(int): current step count.\n            num_steps(int): total number of batches.\n            learning_rate(float): current learning rate.\n            report_stats(Statistics): old Statistics instance.\n        Returns:\n            report_stats(Statistics): updated Statistics instance.\n        \"\"\"", "\n", "if", "self", ".", "start_time", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"\"\"ReportMgr needs to be started\n                                (set 'start_time' or use 'start()'\"\"\"", ")", "\n", "\n", "", "if", "multigpu", ":", "\n", "            ", "report_stats", "=", "onmt", ".", "utils", ".", "Statistics", ".", "all_gather_stats", "(", "report_stats", ")", "\n", "\n", "", "if", "step", "%", "self", ".", "report_every", "==", "0", ":", "\n", "            ", "self", ".", "_report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ")", "\n", "self", ".", "progress_step", "+=", "1", "\n", "return", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.ReportMgrBase._report_training": [[87, 90], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "_report_training", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" To be overridden \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.ReportMgrBase.report_step": [[91, 102], ["report_manager.ReportMgrBase._report_step"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr._report_step"], ["", "def", "report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Report stats of a step\n\n        Args:\n            train_stats(Statistics): training stats\n            valid_stats(Statistics): validation stats\n            lr(float): current learning rate\n        \"\"\"", "\n", "self", ".", "_report_step", "(", "\n", "lr", ",", "step", ",", "train_stats", "=", "train_stats", ",", "valid_stats", "=", "valid_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.ReportMgrBase._report_step": [[103, 105], ["NotImplementedError"], "methods", ["None"], ["", "def", "_report_step", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr.__init__": [[108, 121], ["report_manager.ReportMgrBase.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "key_model", ",", "report_every", ",", "start_time", "=", "-", "1.", ",", "tensorboard_writer", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        A report manager that writes statistics on standard output as well as\n        (optionally) TensorBoard\n\n        Args:\n            report_every(int): Report status every this many sentences\n            tensorboard_writer(:obj:`tensorboard.SummaryWriter`):\n                The TensorBoard Summary writer to use or None\n        \"\"\"", "\n", "super", "(", "MyReportMgr", ",", "self", ")", ".", "__init__", "(", "report_every", ",", "start_time", ")", "\n", "self", ".", "key_model", "=", "key_model", "\n", "self", ".", "tensorboard_writer", "=", "tensorboard_writer", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr.maybe_log_tensorboard": [[122, 126], ["stats.log_tensorboard"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.log_tensorboard"], ["", "def", "maybe_log_tensorboard", "(", "self", ",", "stats", ",", "prefix", ",", "learning_rate", ",", "step", ")", ":", "\n", "        ", "if", "self", ".", "tensorboard_writer", "is", "not", "None", ":", "\n", "            ", "stats", ".", "log_tensorboard", "(", "\n", "prefix", ",", "self", ".", "tensorboard_writer", ",", "learning_rate", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr.report_training": [[127, 156], ["ValueError", "report_manager.MyReportMgr._report_training", "onmt.utils.ReRankerStatistics"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr._report_training"], ["", "", "def", "report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ",", "multigpu", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        This is the user-defined batch-level traing progress\n        report function.\n\n        Args:\n            step(int): current step count.\n            num_steps(int): total number of batches.\n            learning_rate(float): current learning rate.\n            report_stats(E2EStatistics): old Statistics instance.\n        Returns:\n            report_stats(E2EStatistics): updated Statistics instance.\n        \"\"\"", "\n", "if", "self", ".", "start_time", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"\"\"ReportMgr needs to be started\n                                (set 'start_time' or use 'start()'\"\"\"", ")", "\n", "\n", "", "if", "multigpu", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# report_stats = onmt.utils.SelectorStatistics.all_gather_stats(report_stats)", "\n", "\n", "", "if", "step", "%", "self", ".", "report_every", "==", "0", ":", "\n", "            ", "self", ".", "_report_training", "(", "\n", "step", ",", "num_steps", ",", "learning_rate", ",", "report_stats", ")", "\n", "self", ".", "progress_step", "+=", "1", "\n", "return", "onmt", ".", "utils", ".", "E2EStatistics", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "report_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr._report_training": [[157, 168], ["onmt.utils.ReRankerStatistics.output", "onmt.utils.ReRankerStatistics"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.output"], ["", "", "def", "_report_training", "(", "self", ",", "step", ",", "num_steps", ",", "learning_rate", ",", "\n", "report_stats", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_training`.\n        \"\"\"", "\n", "report_stats", ".", "output", "(", "step", ",", "num_steps", ",", "\n", "learning_rate", ",", "self", ".", "start_time", ")", "\n", "\n", "# Log the progress using the number of batches on the x-axis.", "\n", "# self.maybe_log_tensorboard(report_stats,", "\n", "#                            \"progress\",", "\n", "#                            learning_rate,", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr._report_step": [[169, 190], ["report_manager.MyReportMgr.log", "report_manager.MyReportMgr.log", "report_manager.MyReportMgr.log", "report_manager.MyReportMgr.log", "report_manager.MyReportMgr.log", "report_manager.MyReportMgr.maybe_log_tensorboard", "report_manager.MyReportMgr.log", "report_manager.MyReportMgr.log", "report_manager.MyReportMgr.log", "report_manager.MyReportMgr.log", "report_manager.MyReportMgr.log", "report_manager.MyReportMgr.maybe_log_tensorboard", "report_manager.MyReportMgr.log", "train_stats.ave_loss", "train_stats.posi_acc", "train_stats.neg_acc", "train_stats.total_acc", "valid_stats.ave_loss", "valid_stats.posi_acc", "valid_stats.neg_acc", "valid_stats.total_acc"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.MyReportMgr.maybe_log_tensorboard", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.posi_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.neg_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.total_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.posi_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.neg_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.total_acc"], ["#                            self.progress_step)", "\n", "report_stats", "=", "onmt", ".", "utils", ".", "E2EStatistics", "(", ")", "\n", "\n", "return", "report_stats", "\n", "\n", "", "def", "_report_step", "(", "self", ",", "lr", ",", "step", ",", "train_stats", "=", "None", ",", "valid_stats", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See base class method `ReportMgrBase.report_step`.\n        \"\"\"", "\n", "if", "train_stats", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "key_model", "==", "'key_selector'", "or", "self", ".", "key_model", "==", "'key_end2end'", ":", "\n", "                ", "self", ".", "log", "(", "' '", ")", "\n", "self", ".", "log", "(", "'Sel Train sel_ave_loss: %g'", "%", "train_stats", ".", "sel_ave_loss", "(", ")", ")", "\n", "# self.log('Sel Train sel_acc: %g' % train_stats.sel_accuracy())", "\n", "self", ".", "log", "(", "'Sel Train sel_p: %g'", "%", "train_stats", ".", "sel_precision", "(", ")", ")", "\n", "self", ".", "log", "(", "'Sel Train sel_r: %g'", "%", "train_stats", ".", "sel_recall", "(", ")", ")", "\n", "self", ".", "log", "(", "'Sel Train sel_F1: %g'", "%", "train_stats", ".", "sel_f1_score", "(", ")", ")", "\n", "# self.log('Sel Train sel_pred_sel_ratio: %g' % train_stats.sel_pred_select_ratio())", "\n", "# self.log('Sel Train sel_gt_sel_ratio: %g' % train_stats.sel_gt_select_ratio())", "\n", "\n", "", "if", "self", ".", "key_model", "==", "'key_generator'", "or", "self", ".", "key_model", "==", "'key_end2end'", ":", "\n", "                ", "self", ".", "log", "(", "' '", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.report_manager.build_report_manager": [[11, 31], ["report_manager.MyReportMgr", "SummaryWriter", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["def", "build_report_manager", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "tensorboard", ":", "\n", "        ", "from", "tensorboardX", "import", "SummaryWriter", "\n", "writer", "=", "SummaryWriter", "(", "opt", ".", "tensorboard_log_dir", "+", "'/'", "+", "opt", ".", "tensorboard_comment", "\n", "+", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"/%b-%d_%H-%M-%S\"", ")", ",", "\n", "comment", "=", "opt", ".", "tensorboard_comment", ")", "\n", "", "else", ":", "\n", "        ", "writer", "=", "None", "\n", "# if opt.key_model == 'key_selector':", "\n", "#     report_mgr = SelectorReportMgr(opt.report_every, start_time=-1,", "\n", "#                                    tensorboard_writer=writer)", "\n", "# elif opt.key_model == 'key_end2end':", "\n", "#     report_mgr = E2EReportMgr(opt.report_every, start_time=-1,", "\n", "#                               tensorboard_writer=writer)", "\n", "# else:", "\n", "#     report_mgr = ReportMgr(opt.report_every, start_time=-1,", "\n", "#                            tensorboard_writer=writer)", "\n", "", "report_mgr", "=", "MyReportMgr", "(", "opt", ".", "key_model", ",", "opt", ".", "report_every", ",", "start_time", "=", "-", "1", ",", "\n", "tensorboard_writer", "=", "writer", ")", "\n", "return", "report_mgr", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.LossComputeBase.__init__": [[74, 79], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.LossComputeBase._make_shard_state": [[80, 93], ["None"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "generator", ",", "tgt_vocab", ")", ":", "\n", "        ", "super", "(", "LossComputeBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "generator", "=", "generator", "\n", "self", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "self", ".", "padding_idx", "=", "tgt_vocab", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "\n", "", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.LossComputeBase._compute_loss": [[94, 106], ["None"], "methods", ["None"], ["\n", "return", "NotImplementedError", "\n", "\n", "", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "**", "kwargs", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.LossComputeBase.monolithic_compute_loss": [[107, 126], ["loss.LossComputeBase._make_shard_state", "loss.LossComputeBase._compute_loss", "batch.tgt.size"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._compute_loss"], ["\n", "return", "NotImplementedError", "\n", "\n", "", "def", "monolithic_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "attns", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.LossComputeBase.sharded_compute_loss": [[127, 166], ["onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "loss.LossComputeBase._make_shard_state", "loss.shards", "loss.LossComputeBase._compute_loss", "loss.div().backward", "onmt.utils.Statistics.update", "onmt.utils.Statistics.update", "loss.div", "float"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.shards", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._compute_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update"], ["\n", "range_", "=", "(", "0", ",", "batch", ".", "tgt", ".", "size", "(", "0", ")", ")", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ",", "output", ",", "range_", ",", "attns", ")", "\n", "_", ",", "batch_stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard_state", ")", "\n", "\n", "return", "batch_stats", "\n", "\n", "", "def", "sharded_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "attns", ",", "\n", "cur_trunc", ",", "trunc_size", ",", "shard_size", ",", "\n", "normalization", ")", ":", "\n", "        ", "\"\"\"Compute the forward loss and backpropagate.  Computation is done\n        with shards and optionally truncation for memory efficiency.\n\n        Also supports truncated BPTT for long sequences by taking a\n        range in the decoder output sequence to back propagate in.\n        Range is from `(cur_trunc, cur_trunc + trunc_size)`.\n\n        Note sharding is an exact efficiency trick to relieve memory\n        required for the generation buffers. Truncation is an\n        approximate efficiency trick to relieve the memory required\n        in the RNN buffers.\n\n        Args:\n          batch (batch) : batch of labeled examples\n          output (:obj:`FloatTensor`) :\n              output of decoder model `[tgt_len x batch x hidden]`\n          attns (dict) : dictionary of attention distributions\n              `[tgt_len x batch x src_len]`\n          cur_trunc (int) : starting position of truncation window\n          trunc_size (int) : length of truncation window\n          shard_size (int) : maximum number of examples in a shard\n          normalization (int) : Loss is divided by this number\n\n        Returns:\n            :obj:`onmt.utils.Statistics`: validation loss statistics\n\n        \"\"\"", "\n", "batch_stats", "=", "onmt", ".", "utils", ".", "Statistics", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.LossComputeBase._stats": [[167, 185], ["target.ne", "pred.eq().masked_select().sum().item", "target.ne.sum().item", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "onmt.utils.Statistics", "scores.max", "loss.item", "pred.eq().masked_select().sum", "target.ne.sum", "pred.eq().masked_select", "pred.eq"], "methods", ["None"], ["range_", "=", "(", "cur_trunc", ",", "cur_trunc", "+", "trunc_size", ")", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ",", "output", ",", "range_", ",", "attns", ")", "\n", "for", "shard", "in", "shards", "(", "shard_state", ",", "shard_size", ")", ":", "\n", "            ", "loss", ",", "stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard", ")", "\n", "loss", ".", "div", "(", "float", "(", "normalization", ")", ")", ".", "backward", "(", ")", "\n", "batch_stats", ".", "update", "(", "stats", ")", "\n", "\n", "", "return", "batch_stats", "\n", "\n", "", "def", "_stats", "(", "self", ",", "loss", ",", "scores", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            loss (:obj:`FloatTensor`): the loss computed by the loss criterion.\n            scores (:obj:`FloatTensor`): a score for each possible output\n            target (:obj:`FloatTensor`): true targets\n\n        Returns:\n            :obj:`onmt.utils.Statistics` : statistics for this batch.\n        \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.LossComputeBase._bottle": [[186, 188], ["_v.view", "_v.size"], "methods", ["None"], ["pred", "=", "scores", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "non_padding", "=", "target", ".", "ne", "(", "self", ".", "padding_idx", ")", "\n", "num_correct", "=", "pred", ".", "eq", "(", "target", ")"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.LossComputeBase._unbottle": [[189, 191], ["_v.view", "_v.size"], "methods", ["None"], [".", "masked_select", "(", "non_padding", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.InconsistencyLoss.__init__": [[203, 206], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "top_k", ",", "eps", "=", "1e-20", ")", ":", "\n", "        ", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.InconsistencyLoss.__call__": [[207, 240], ["sel_probs.transpose.transpose.transpose", "enumerate", "norescale_attns.split", "attn_dist.squeeze.squeeze.squeeze", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "losses.append", "sum().sum", "torch.log", "torch.log", "torch.log", "torch.log", "sum", "sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log"], ["", "def", "__call__", "(", "self", ",", "sel_probs", ",", "sel_mask", ",", "norescale_attns", ",", "dec_mask", ",", "normalize_by_length", ")", ":", "\n", "        ", "\"\"\"\n        Calculate the inconsistency loss between the selector predicted probs and the norescale_attns.\n        Refer to https://aclweb.org/anthology/P18-1013 for more details. Some code is borrowed from the\n        released code of this paper.\n        Args:\n            sel_probs (:obj:'FloatTensor') : the predicted probabilities by the selector [src_len, batch]\n            sel_mask (:obj:'FloatTensor') : the mask for sel_probs [src_len, batch]\n            norescale_attns: (:obj:'FloatTensor'): the norescaled attention scores [tgt_len, batch, src_len]\n            dec_mask (:obj:'FloatTensor') : the mask for the decoder output [tgt_len, batch]\n            normalize_by_length (:obj:`bool`) : If true, normalize the loss with the length\n        return:\n            Inconsistency loss:\n                - (1/T) * sum(t=1,...,T)(log((1/top_k) * sum(k=1,...,top_k)(norescale_attns_t_k * sel_probs_t_k)))\n        \"\"\"", "\n", "#", "\n", "sel_probs", "=", "sel_probs", "*", "sel_mask", "\n", "sel_probs", "=", "sel_probs", ".", "transpose", "(", "0", ",", "1", ")", "# [batch, src_len]", "\n", "losses", "=", "[", "]", "\n", "for", "dec_step", ",", "attn_dist", "in", "enumerate", "(", "norescale_attns", ".", "split", "(", "1", ")", ")", ":", "\n", "            ", "attn_dist", "=", "attn_dist", ".", "squeeze", "(", "dim", "=", "0", ")", "\n", "attn_topk", ",", "attn_topk_id", "=", "torch", ".", "topk", "(", "attn_dist", ",", "k", "=", "self", ".", "top_k", ",", "dim", "=", "1", ")", "# [batch, topk]", "\n", "sel_topk", "=", "torch", ".", "gather", "(", "sel_probs", ",", "dim", "=", "1", ",", "index", "=", "attn_topk_id", ")", "# [batch, topk]", "\n", "# mean first than log", "\n", "loss_one_step", "=", "torch", ".", "mean", "(", "attn_topk", "*", "sel_topk", ",", "dim", "=", "1", ")", "# [batch]", "\n", "loss_one_step", "=", "-", "torch", ".", "log", "(", "loss_one_step", "+", "self", ".", "eps", ")", "# [batch]", "\n", "loss_one_step", "=", "loss_one_step", "*", "dec_mask", "[", "dec_step", ",", ":", "]", "# [batch]", "\n", "losses", ".", "append", "(", "loss_one_step", ")", "\n", "", "if", "normalize_by_length", ":", "\n", "            ", "loss", "=", "(", "sum", "(", "losses", ")", "/", "torch", ".", "mean", "(", "dec_mask", ",", "dim", "=", "0", ")", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "(", "sum", "(", "losses", ")", ")", ".", "sum", "(", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute.__init__": [[263, 317], ["torch.Module.__init__", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "onmt.modules.CopyGeneratorCriterion", "onmt.modules.CopyGeneratorCriterion", "onmt.modules.CopyGeneratorCriterion", "onmt.modules.CopyGeneratorCriterion", "loss.InconsistencyLoss", "onmt.utils.logging.logger.warning", "onmt.utils.logging.logger.warning", "onmt.utils.logging.logger.warning", "onmt.utils.logging.logger.warning", "onmt.utils.logging.logger.warning", "onmt.utils.logging.logger.warning", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "opt", ",", "generator", ",", "indicator_vocab", ",", "tgt_vocab", ",", "eps", "=", "1e-20", ")", ":", "\n", "        ", "super", "(", "E2ELossCompute", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "key_model", "=", "opt", ".", "key_model", "\n", "self", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "self", ".", "cur_dataset", "=", "None", "\n", "self", ".", "force_copy", "=", "opt", ".", "copy_attn_force", "\n", "self", ".", "top_k", "=", "opt", ".", "top_k", "\n", "self", ".", "sel_report_topk", "=", "opt", ".", "top_k", "\n", "self", ".", "sel_normalize_by_length", "=", "opt", ".", "sel_normalize_by_length", "\n", "self", ".", "gen_normalize_by_length", "=", "opt", ".", "gen_normalize_by_length", "\n", "self", ".", "incons_normalize_by_length", "=", "opt", ".", "incons_normalize_by_length", "\n", "self", ".", "pos_weight", "=", "opt", ".", "pos_weight", "# default 9.0", "\n", "self", ".", "sel_threshold", "=", "opt", ".", "sel_threshold", "# default 0.9", "\n", "self", ".", "sel_lambda", "=", "opt", ".", "sel_lambda", "# default 0.5", "\n", "self", ".", "sel_train_ratio", "=", "opt", ".", "sel_train_ratio", "# default 1.0", "\n", "self", ".", "gen_lambda", "=", "opt", ".", "gen_lambda", "# default 0.5", "\n", "self", ".", "incons_lambda", "=", "opt", ".", "incons_lambda", "# default 0.5", "\n", "\n", "self", ".", "generator", "=", "generator", "\n", "if", "opt", ".", "key_model", "!=", "'key_selector'", ":", "\n", "            ", "self", ".", "tgt_padding_idx", "=", "tgt_vocab", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "", "if", "opt", ".", "key_model", "!=", "'key_generator'", ":", "\n", "            ", "assert", "len", "(", "indicator_vocab", ")", "==", "3", "\n", "self", ".", "src_unk_idx", "=", "inputters", ".", "UNK", "\n", "self", ".", "sel_padding_idx", "=", "indicator_vocab", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "self", ".", "pos_idx", "=", "indicator_vocab", ".", "stoi", "[", "'I'", "]", "\n", "self", ".", "neg_idx", "=", "indicator_vocab", ".", "stoi", "[", "'O'", "]", "\n", "\n", "# BCEWithLogits loss for extraction (selector)", "\n", "", "if", "self", ".", "key_model", "==", "'key_selector'", "or", "(", "self", ".", "key_model", "==", "'key_end2end'", "and", "self", ".", "sel_lambda", "!=", "0.0", ")", ":", "\n", "            ", "self", ".", "bcewithlogits_criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", "reduction", "=", "'none'", ",", "pos_weight", "=", "torch", ".", "tensor", "(", "[", "self", ".", "pos_weight", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bcewithlogits_criterion", "=", "None", "\n", "\n", "# CopyGenerator loss for generation (generator)", "\n", "# (len(tgt_vocab), force_copy, self.padding_idx)", "\n", "", "if", "self", ".", "key_model", "==", "'key_generator'", "or", "self", ".", "key_model", "==", "'key_end2end'", ":", "\n", "            ", "self", ".", "copynmtloss_criterion", "=", "onmt", ".", "modules", ".", "CopyGeneratorCriterion", "(", "len", "(", "tgt_vocab", ")", ",", "self", ".", "force_copy", ",", "self", ".", "tgt_padding_idx", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "copynmtloss_criterion", "=", "0.0", "\n", "\n", "# inconsistency loss for extraction attention and generating attention", "\n", "", "if", "self", ".", "key_model", "==", "'key_end2end'", "and", "self", ".", "incons_lambda", "!=", "0.0", ":", "\n", "            ", "self", ".", "inconsistloss_criterion", "=", "InconsistencyLoss", "(", "top_k", "=", "self", ".", "top_k", ")", "\n", "\n", "", "if", "not", "self", ".", "sel_normalize_by_length", ":", "\n", "            ", "logger", ".", "warning", "(", "\"These selector losses will not be normalized by length since opt.sel_normalize_by_length=False!\"", ")", "\n", "", "if", "not", "self", ".", "gen_normalize_by_length", ":", "\n", "            ", "logger", ".", "warning", "(", "\"These generator losses will not be normalized by length since opt.gen_normalize_by_length=False!\"", ")", "\n", "", "if", "not", "self", ".", "incons_normalize_by_length", ":", "\n", "            ", "logger", ".", "warning", "(", "\"These inconsisitency losses will not be normalized by length since opt.incons_normalize_by_length=False!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute._make_shard_state": [[318, 339], ["getattr", "AssertionError", "attns.get", "attns.get"], "methods", ["None"], ["", "", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "sel_output", ",", "sel_probs", ",", "dec_output", ",", "attns", ")", ":", "\n", "        ", "\"\"\"\n        Make shard state dictionary for shards() to return iterable\n        shards for efficient loss computation. Subclass must define\n        this method to match its own _compute_loss() interface.\n        Args:\n            batch: the current batch.\n            sel_output: the predicted logits output from the selector.\n            sel_probs: the predicted importance scores output from the selector.\n            dec_output: the predicted output from the decoder.\n            attns: the attns dictionary returned from the decoder.\n        \"\"\"", "\n", "if", "getattr", "(", "batch", ",", "\"alignment\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"using -copy_attn you need to pass in \"", "\n", "\"-dynamic_dict during preprocess stage.\"", ")", "\n", "\n", "", "return", "{", "\"sel_output\"", ":", "sel_output", ",", "\n", "\"sel_probs\"", ":", "sel_probs", ",", "\n", "\"dec_output\"", ":", "dec_output", ",", "\n", "\"copy_attn\"", ":", "None", "if", "attns", "is", "None", "else", "attns", ".", "get", "(", "\"copy\"", ")", ",", "\n", "\"norescale_attn\"", ":", "None", "if", "attns", "is", "None", "else", "attns", ".", "get", "(", "\"norescale_std\"", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute._compute_extraction_loss": [[340, 377], ["sel_target.ne().float", "batch.src[].ne().float", "sel_target.eq().float", "loss.E2ELossCompute.bcewithlogits_criterion", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "sel_target.ne", "batch.src[].ne", "sel_target.eq", "mask.sum", "sel_loss.sum.sum.view().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "sel_loss.sum.sum.sum", "sel_loss.sum.sum.view", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["None"], ["", "def", "_compute_extraction_loss", "(", "self", ",", "batch", ",", "sel_output", ")", ":", "\n", "        ", "\"\"\"\n        Compute the extraction loss.\n\n        Args:\n            batch: the current batch.\n            sel_output: the predicted logits from the selector.\n        \"\"\"", "\n", "sel_target", "=", "batch", ".", "key_indicators", "[", "0", "]", "\n", "\n", "# get the sequence mask", "\n", "pad_mask", "=", "sel_target", ".", "ne", "(", "self", ".", "sel_padding_idx", ")", ".", "float", "(", ")", "\n", "# filter out the unk keywords", "\n", "src_unk_mask", "=", "batch", ".", "src", "[", "0", "]", ".", "ne", "(", "self", ".", "src_unk_idx", ")", ".", "float", "(", ")", "\n", "# final mask", "\n", "mask", "=", "pad_mask", "*", "src_unk_mask", "\n", "\n", "gt_indicators", "=", "sel_target", ".", "eq", "(", "self", ".", "pos_idx", ")", ".", "float", "(", ")", "\n", "\n", "# get the loss tensor", "\n", "if", "self", ".", "sel_lambda", "!=", "0.0", ":", "\n", "            ", "sel_loss", "=", "self", ".", "bcewithlogits_criterion", "(", "sel_output", ",", "gt_indicators", ")", "\n", "sel_loss", "=", "sel_loss", "*", "mask", "\n", "if", "self", ".", "sel_normalize_by_length", ":", "\n", "# Compute Loss as BCE divided by seq length", "\n", "# Compute Sequence Lengths", "\n", "                ", "tgt_lens", "=", "mask", ".", "sum", "(", "0", ")", "\n", "# Compute Total Loss per sequence in batch", "\n", "sel_loss", "=", "sel_loss", ".", "view", "(", "-", "1", ",", "batch", ".", "batch_size", ")", ".", "sum", "(", "0", ")", "\n", "# Divide by length of each sequence and sum", "\n", "sel_loss", "=", "torch", ".", "div", "(", "sel_loss", ",", "tgt_lens", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "                ", "sel_loss", "=", "sel_loss", ".", "sum", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "sel_loss", "=", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", "\n", "\n", "", "return", "sel_loss", ",", "gt_indicators", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute._compute_generation_loss": [[378, 428], ["dec_target.view.view.ne().float", "dec_target.view.view.view", "align.view.view.view", "loss.sum.E2ELossCompute.generator", "loss.sum.E2ELossCompute.copynmtloss_criterion", "loss.sum.E2ELossCompute.data.clone", "onmt.TextDataset.collapse_copy_scores", "onmt.TextDataset.collapse_copy_scores", "loss.sum.E2ELossCompute._bottle", "dec_target.view.view.data.clone", "loss.sum.sum.sum().data.clone", "loss.sum.E2ELossCompute._bottle", "loss.sum.E2ELossCompute._bottle", "loss.sum.E2ELossCompute._unbottle", "dec_target.view.data.clone.eq", "align.view.view.data.ne", "correct_mask.long", "dec_target.view.ne().float.sum", "loss.sum.sum.view().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "loss.sum.sum.sum", "dec_target.view.view.ne", "len", "loss.sum.sum.sum", "loss.sum.sum.view", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.collapse_copy_scores", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.collapse_copy_scores", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._bottle", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._bottle", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._bottle", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._unbottle"], ["", "def", "_compute_generation_loss", "(", "self", ",", "batch", ",", "dec_output", ",", "copy_attn", ")", ":", "\n", "        ", "\"\"\"\n        Compute the generation loss.\n        Args:\n            batch: the current batch.\n            dec_output: the predicted output from the decoder. [tgt_len, batch, hidden_size]\n            dec_target: the validate target to compare output with.\n            copy_attn: the copy attention value. [tgt_len, batch, src_len]\n        \"\"\"", "\n", "dec_target", "=", "batch", ".", "tgt", "[", "1", ":", "]", "# [tgt_len, batch]", "\n", "dec_mask", "=", "dec_target", ".", "ne", "(", "self", ".", "tgt_padding_idx", ")", ".", "float", "(", ")", "# [tgt_len, batch]", "\n", "dec_target", "=", "dec_target", ".", "view", "(", "-", "1", ")", "# [tgt_len * batch]", "\n", "\n", "align", "=", "batch", ".", "alignment", "[", "1", ":", "]", "# [tgt_len, batch]", "\n", "align", "=", "align", ".", "view", "(", "-", "1", ")", "# [tgt_len * batch]", "\n", "\n", "scores", "=", "self", ".", "generator", "(", "self", ".", "_bottle", "(", "dec_output", ")", ",", "\n", "self", ".", "_bottle", "(", "copy_attn", ")", ",", "\n", "batch", ".", "src_map", ")", "# [tgt_len * batch, vocab_size + copy_vocab_size]", "\n", "loss", "=", "self", ".", "copynmtloss_criterion", "(", "scores", ",", "align", ",", "dec_target", ")", "# [tgt_len * batch_size]", "\n", "scores_data", "=", "scores", ".", "data", ".", "clone", "(", ")", "\n", "scores_data", "=", "inputters", ".", "TextDataset", ".", "collapse_copy_scores", "(", "\n", "self", ".", "_unbottle", "(", "scores_data", ",", "batch", ".", "batch_size", ")", ",", "\n", "batch", ",", "self", ".", "tgt_vocab", ",", "self", ".", "cur_dataset", ".", "src_vocabs", ")", "\n", "scores_data", "=", "self", ".", "_bottle", "(", "scores_data", ")", "\n", "\n", "# Correct target copy token instead of <unk>", "\n", "# tgt[i] = align[i] + len(tgt_vocab)", "\n", "# for i such that tgt[i] == 0 and align[i] != 0", "\n", "target_data", "=", "dec_target", ".", "data", ".", "clone", "(", ")", "\n", "correct_mask", "=", "target_data", ".", "eq", "(", "0", ")", "*", "align", ".", "data", ".", "ne", "(", "0", ")", "\n", "correct_copy", "=", "(", "align", ".", "data", "+", "len", "(", "self", ".", "tgt_vocab", ")", ")", "*", "correct_mask", ".", "long", "(", ")", "\n", "target_data", "=", "target_data", "+", "correct_copy", "\n", "\n", "# Compute sum of perplexities for stats", "\n", "loss_data", "=", "loss", ".", "sum", "(", ")", ".", "data", ".", "clone", "(", ")", "\n", "# stats = self._stats(loss_data, scores_data, target_data)", "\n", "\n", "if", "self", ".", "gen_normalize_by_length", ":", "\n", "# Compute Loss as NLL divided by seq length", "\n", "# Compute Sequence Lengths", "\n", "            ", "tgt_lens", "=", "dec_mask", ".", "sum", "(", "0", ")", "\n", "# Compute Total Loss per sequence in batch", "\n", "loss", "=", "loss", ".", "view", "(", "-", "1", ",", "batch", ".", "batch_size", ")", ".", "sum", "(", "0", ")", "\n", "# Divide by length of each sequence and sum", "\n", "loss", "=", "torch", ".", "div", "(", "loss", ",", "tgt_lens", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "\n", "", "return", "loss", ",", "loss_data", ",", "scores_data", ",", "target_data", ",", "dec_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute._compute_loss": [[429, 494], ["loss.E2ELossCompute._compute_extraction_loss", "loss.E2ELossCompute._compute_generation_loss", "loss.E2ELossCompute._stats", "loss.E2ELossCompute._stats", "random.random", "loss.E2ELossCompute._stats", "loss.E2ELossCompute.inconsistloss_criterion", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "sel_loss.data.clone", "sel_probs.data.clone", "gt_indicators.data.clone", "sel_mask.data.clone", "gen_loss_data.data.clone", "gen_scores_data.data.clone", "gen_target_data.data.clone", "torch.Tensor.data.clone", "torch.Tensor.data.clone", "merged_loss.data.clone", "sel_loss.data.clone", "sel_probs.data.clone", "gt_indicators.data.clone", "sel_mask.data.clone", "gen_loss_data.data.clone", "gen_scores_data.data.clone", "gen_target_data.data.clone"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute._compute_extraction_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute._compute_generation_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._stats", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._stats", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._stats"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "sel_output", ",", "sel_probs", ",", "dec_output", ",", "copy_attn", ",", "norescale_attn", ")", ":", "\n", "        ", "\"\"\"\n        Compute the loss. Subclass must define this method.\n        Args:\n            batch: the current batch.\n            sel_output: the predicted output(logits) from the selector\n            sel_probs: the predicted importance scores output from the selector\n            dec_output: the predicted output from the decoder\n            copy_attn: the rescaled copy attention\n            norescale_attn: the original attention\n        \"\"\"", "\n", "# calculate the extraction loss", "\n", "if", "self", ".", "key_model", "in", "(", "'key_selector'", ",", "'key_end2end'", ")", ":", "\n", "            ", "sel_loss", ",", "gt_indicators", ",", "sel_mask", "=", "self", ".", "_compute_extraction_loss", "(", "batch", ",", "sel_output", ")", "\n", "\n", "# calculate the generation loss", "\n", "# Note: the gen_loss maybe the length-normalized value of gen_loss_data", "\n", "", "if", "self", ".", "key_model", "in", "(", "'key_generator'", ",", "'key_end2end'", ")", ":", "\n", "            ", "gen_loss", ",", "gen_loss_data", ",", "gen_scores_data", ",", "gen_target_data", ",", "dec_mask", "=", "self", ".", "_compute_generation_loss", "(", "batch", ",", "dec_output", ",", "copy_attn", ")", "\n", "\n", "# calculate the inconsistency loss", "\n", "# (self, sel_probs, sel_mask, norescale_attns, dec_mask, normalize_by_length)", "\n", "", "if", "self", ".", "key_model", "==", "'key_end2end'", ":", "\n", "            ", "if", "self", ".", "incons_lambda", "!=", "0.0", ":", "\n", "                ", "incons_loss", "=", "self", ".", "inconsistloss_criterion", "(", "sel_probs", ",", "sel_mask", ",", "norescale_attn", ",", "dec_mask", ",", "self", ".", "incons_normalize_by_length", ")", "\n", "", "else", ":", "\n", "                ", "incons_loss", "=", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", "\n", "\n", "# merge all the loss according to the options", "\n", "", "", "if", "self", ".", "key_model", "==", "'key_selector'", ":", "\n", "            ", "assert", "self", ".", "sel_lambda", "!=", "0.0", "\n", "merged_loss", "=", "self", ".", "sel_lambda", "*", "sel_loss", "\n", "stats", "=", "self", ".", "_stats", "(", "batch_size", "=", "batch", ".", "batch_size", ",", "\n", "sel_loss_data", "=", "sel_loss", ".", "data", ".", "clone", "(", ")", ",", "\n", "sel_probs", "=", "sel_probs", ".", "data", ".", "clone", "(", ")", ",", "\n", "gt_indicators", "=", "gt_indicators", ".", "data", ".", "clone", "(", ")", ",", "\n", "sel_mask", "=", "sel_mask", ".", "data", ".", "clone", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "key_model", "==", "'key_generator'", ":", "\n", "            ", "assert", "self", ".", "gen_lambda", "!=", "0.0", "\n", "merged_loss", "=", "self", ".", "gen_lambda", "*", "gen_loss", "\n", "stats", "=", "self", ".", "_stats", "(", "batch_size", "=", "batch", ".", "batch_size", ",", "\n", "gen_loss_data", "=", "gen_loss_data", ".", "data", ".", "clone", "(", ")", ",", "\n", "gen_scores_data", "=", "gen_scores_data", ".", "data", ".", "clone", "(", ")", ",", "\n", "gen_target_data", "=", "gen_target_data", ".", "data", ".", "clone", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "key_model", "==", "'key_end2end'", ":", "\n", "# merged_loss = self.sel_lambda * sel_loss + self.gen_lambda * gen_loss + self.incons_lambda * incons_loss", "\n", "            ", "merged_loss", "=", "self", ".", "gen_lambda", "*", "gen_loss", "\n", "\n", "rnd_num", "=", "random", ".", "random", "(", ")", "\n", "if", "self", ".", "sel_lambda", "!=", "0.0", "and", "rnd_num", "<", "self", ".", "sel_train_ratio", ":", "\n", "                ", "merged_loss", "=", "self", ".", "sel_lambda", "*", "sel_loss", "+", "merged_loss", "\n", "", "if", "self", ".", "incons_lambda", "!=", "0.0", ":", "\n", "                ", "merged_loss", "=", "self", ".", "incons_lambda", "*", "incons_loss", "+", "merged_loss", "\n", "", "stats", "=", "self", ".", "_stats", "(", "batch", ".", "batch_size", ",", "\n", "sel_loss", ".", "data", ".", "clone", "(", ")", ",", "sel_probs", ".", "data", ".", "clone", "(", ")", ",", "\n", "gt_indicators", ".", "data", ".", "clone", "(", ")", ",", "sel_mask", ".", "data", ".", "clone", "(", ")", ",", "\n", "gen_loss_data", ".", "data", ".", "clone", "(", ")", ",", "gen_scores_data", ".", "data", ".", "clone", "(", ")", ",", "\n", "gen_target_data", ".", "data", ".", "clone", "(", ")", ",", "incons_loss", ".", "data", ".", "clone", "(", ")", ",", "\n", "merged_loss", ".", "data", ".", "clone", "(", ")", ")", "\n", "\n", "", "return", "merged_loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute.monolithic_compute_loss": [[495, 516], ["loss.E2ELossCompute._make_shard_state", "loss.E2ELossCompute._compute_loss"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._compute_loss"], ["", "def", "monolithic_compute_loss", "(", "self", ",", "batch", ",", "sel_outputs", ",", "sel_probs", ",", "dec_outputs", ",", "attns", ")", ":", "\n", "        ", "\"\"\"\n        Compute the forward loss for the batch.\n        Args:\n          batch (batch): batch of labeled examples\n          sel_output (:obj:`FloatTensor`):\n              logits output of the selector `[src_len x batch ]`\n          sel_probs (:obj:`FloatTensor`):\n              importance socres output of the selector `[src_len x batch ]`\n          dec_outputs (:obj:`FloatTensor`):\n              output of the decoder `[tgt_len x batch x hidden]`\n          attns (dict of :obj:`FloatTensor`) :\n              dictionary of attention distributions `[tgt_len x batch x src_len]`\n\n        Returns:\n            :obj:`onmt.utils.Statistics`: loss statistics\n        \"\"\"", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ",", "sel_outputs", ",", "sel_probs", ",", "dec_outputs", ",", "attns", ")", "\n", "_", ",", "batch_stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard_state", ")", "\n", "\n", "return", "batch_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute.sharded_compute_loss": [[517, 554], ["onmt.utils.E2EStatistics", "onmt.utils.E2EStatistics", "onmt.utils.E2EStatistics", "onmt.utils.E2EStatistics", "loss.E2ELossCompute._make_shard_state", "loss.E2ELossCompute._compute_loss", "loss.div().backward", "onmt.utils.E2EStatistics.update", "onmt.utils.E2EStatistics.update", "loss.div", "float"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._compute_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update"], ["", "def", "sharded_compute_loss", "(", "self", ",", "batch", ",", "sel_outputs", ",", "sel_probs", ",", "dec_outputs", ",", "attns", ",", "normalization", ")", ":", "\n", "        ", "\"\"\"Compute the forward loss and backpropagate.  Computation is done\n        with shards and optionally truncation for memory efficiency.\n\n        Also supports truncated BPTT for long sequences by taking a\n        range in the decoder output sequence to back propagate in.\n        Range is from `(cur_trunc, cur_trunc + trunc_size)`.\n\n        Note sharding is an exact efficiency trick to relieve memory\n        required for the generation buffers. Truncation is an\n        approximate efficiency trick to relieve the memory required\n        in the RNN buffers.\n\n        Args:\n          batch (batch): batch of labeled examples\n          sel_output (:obj:`FloatTensor`):\n              logits output of the selector `[src_len x batch ]`\n          sel_probs (:obj:`FloatTensor`):\n              importance socres output of the selector `[src_len x batch ]`\n          dec_outputs (:obj:`FloatTensor`):\n              output of the decoder `[tgt_len x batch x hidden]`\n          attns (dict of :obj:`FloatTensor`) :\n              dictionary of attention distributions `[tgt_len x batch x src_len]`\n          normalization (int) : Loss is divided by this number\n\n        Returns:\n            :obj:`onmt.utils.Statistics`: validation loss statistics\n\n        \"\"\"", "\n", "# sharding is not convenient to mult-task learning, we avoid it.", "\n", "batch_stats", "=", "onmt", ".", "utils", ".", "E2EStatistics", "(", ")", "\n", "shard_state", "=", "self", ".", "_make_shard_state", "(", "batch", ",", "sel_outputs", ",", "sel_probs", ",", "dec_outputs", ",", "attns", ")", "\n", "loss", ",", "stats", "=", "self", ".", "_compute_loss", "(", "batch", ",", "**", "shard_state", ")", "\n", "loss", ".", "div", "(", "float", "(", "normalization", ")", ")", ".", "backward", "(", ")", "\n", "batch_stats", ".", "update", "(", "stats", ")", "\n", "\n", "return", "batch_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute._stats": [[555, 631], ["onmt.utils.E2EStatistics", "onmt.utils.E2EStatistics", "onmt.utils.E2EStatistics", "onmt.utils.E2EStatistics", "sel_probs.size", "sel_probs.mul", "sel_mask.gather.sum().item", "gt_indicators.gather.sum().item", "gt_indicators.sum().item", "gen_target_data.ne", "gen_pred.eq().masked_select().sum().item", "gen_target_data.ne.sum().item", "sel_mask.float", "sel_probs.mul.topk", "gt_indicators.gather", "sel_mask.gather", "gen_scores_data.max", "sel_mask.gather.sum", "gt_indicators.gather.sum", "gt_indicators.sum", "gen_pred.eq().masked_select().sum", "gen_target_data.ne.sum", "gen_pred.eq().masked_select", "gen_pred.eq"], "methods", ["None"], ["", "def", "_stats", "(", "self", ",", "batch_size", ",", "sel_loss_data", "=", "None", ",", "sel_probs", "=", "None", ",", "gt_indicators", "=", "None", ",", "sel_mask", "=", "None", ",", "\n", "gen_loss_data", "=", "None", ",", "gen_scores_data", "=", "None", ",", "gen_target_data", "=", "None", ",", "incons_loss", "=", "None", ",", "merged_loss", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            batch_size (:obj:`int`): the batch size\n            sel_loss_data (:obj:`FloatTensor`): the computed extraction loss\n            sel_probs (:obj:`FloatTensor`): the predicted importance socres\n            gt_indicators (:obj:`LongTensor`): the ground-truth keyword indicators\n            sel_mask (:obj:`ByteTensor`): the selection mask\n            gen_loss_data (:obj:`FloatTensor`): the computed generation loss\n            gen_scores_data (:obj:`FloatTensor`): the predicted probability distribution from the generator\n            gen_target_data (:obj:`LongTensor`): the target data\n            incons_loss (:obj:`FloatTensor`): the computed inconsistency loss\n            merged_loss (:obj:`FloatTensor`): the total loss\n\n        Returns:\n            :obj:`onmt.utils.E2EStatistics` : statistics for this batch.\n        \"\"\"", "\n", "# ================ calculate selector statistics ====================", "\n", "# selector predictions", "\n", "if", "sel_loss_data", "is", "not", "None", ":", "\n", "            ", "seq_len", ",", "_", "=", "sel_probs", ".", "size", "(", ")", "\n", "# predictions", "\n", "pred", "=", "sel_probs", ".", "mul", "(", "sel_mask", ".", "float", "(", ")", ")", "\n", "# pred.gt(self.sel_threshold)", "\n", "if", "self", ".", "sel_report_topk", "<=", "seq_len", ":", "\n", "                ", "pred_topk", ",", "pred_topk_idx", "=", "pred", ".", "topk", "(", "k", "=", "self", ".", "sel_report_topk", ",", "dim", "=", "0", ")", "# [sel_report_topk, batch_size]", "\n", "tgt_at_pred_idx", "=", "gt_indicators", ".", "gather", "(", "dim", "=", "0", ",", "index", "=", "pred_topk_idx", ")", "# [sel_report_topk, batch_size]", "\n", "mask_at_pred_idx", "=", "sel_mask", ".", "gather", "(", "dim", "=", "0", ",", "index", "=", "pred_topk_idx", ")", "\n", "", "else", ":", "\n", "                ", "tgt_at_pred_idx", "=", "gt_indicators", "# [seq_len, batch_size]", "\n", "mask_at_pred_idx", "=", "sel_mask", "\n", "\n", "", "sel_pred_select_num", "=", "mask_at_pred_idx", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "# True Positive", "\n", "TP", "=", "tgt_at_pred_idx", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "# targets", "\n", "sel_gt_select_num", "=", "gt_indicators", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "sel_loss_data", "=", "0.0", "\n", "sel_pred_select_num", "=", "0", "\n", "sel_gt_select_num", "=", "0", "\n", "TP", "=", "0", "\n", "\n", "# ================ calculate s2s generator statistics ====================", "\n", "# stats = self._stats(loss_data, scores.data, target.view(-1).data)", "\n", "", "if", "gen_loss_data", "is", "not", "None", ":", "\n", "            ", "gen_pred", "=", "gen_scores_data", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "# gen_target_data = gen_target_data.view(-1)", "\n", "gen_non_padding", "=", "gen_target_data", ".", "ne", "(", "self", ".", "tgt_padding_idx", ")", "\n", "gen_num_correct", "=", "gen_pred", ".", "eq", "(", "gen_target_data", ")", ".", "masked_select", "(", "gen_non_padding", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "gen_num_non_padding", "=", "gen_non_padding", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "gen_loss_data", "=", "0.0", "\n", "gen_num_correct", "=", "0", "\n", "gen_num_non_padding", "=", "0", "\n", "\n", "# ================ calculate s2s inconsistency loss statistics ====================", "\n", "", "if", "incons_loss", "is", "None", ":", "\n", "            ", "incons_loss", "=", "0.0", "\n", "", "if", "merged_loss", "is", "None", ":", "\n", "            ", "merged_loss", "=", "0.0", "\n", "\n", "# (batch_size=0,", "\n", "#  sel_loss=0.0, sel_true_positive=0, sel_true_negative=0, sel_pred_select_num=0, sel_gt_select_num=0, sel_total_words_num=0,", "\n", "#  gen_loss=0.0, gen_n_words=0, gen_n_correct=0)", "\n", "", "return", "onmt", ".", "utils", ".", "E2EStatistics", "(", "batch_size", ",", "\n", "sel_loss", "=", "sel_loss_data", ",", "\n", "sel_true_positive", "=", "TP", ",", "\n", "sel_pred_select_num", "=", "sel_pred_select_num", ",", "\n", "sel_gt_select_num", "=", "sel_gt_select_num", ",", "\n", "gen_loss", "=", "gen_loss_data", ",", "gen_n_words", "=", "gen_num_non_padding", ",", "\n", "gen_n_correct", "=", "gen_num_correct", ",", "incons_loss", "=", "incons_loss", ",", "merged_loss", "=", "merged_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute._bottle": [[632, 634], ["_v.view", "_v.size"], "methods", ["None"], ["", "def", "_bottle", "(", "self", ",", "_v", ")", ":", "\n", "        ", "return", "_v", ".", "view", "(", "-", "1", ",", "_v", ".", "size", "(", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.E2ELossCompute._unbottle": [[635, 637], ["_v.view", "_v.size"], "methods", ["None"], ["", "def", "_unbottle", "(", "self", ",", "_v", ",", "batch_size", ")", ":", "\n", "        ", "return", "_v", ".", "view", "(", "-", "1", ",", "batch_size", ",", "_v", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.NMTLossCompute.__init__": [[358, 379], ["loss.LossComputeBase.__init__", "torch.KLDivLoss", "torch.KLDivLoss", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn.fill_", "torch.randn.fill_", "loss.NMTLossCompute.register_buffer", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.NLLLoss", "torch.NLLLoss", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["\n", "# get the loss tensor", "\n", "if", "self", ".", "sel_lambda", "!=", "0.0", ":", "\n", "            ", "sel_loss", "=", "self", ".", "bcewithlogits_criterion", "(", "sel_output", ",", "gt_indicators", ")", "\n", "sel_loss", "=", "sel_loss", "*", "mask", "\n", "if", "self", ".", "sel_normalize_by_length", ":", "\n", "# Compute Loss as BCE divided by seq length", "\n", "# Compute Sequence Lengths", "\n", "                ", "tgt_lens", "=", "mask", ".", "sum", "(", "0", ")", "\n", "# Compute Total Loss per sequence in batch", "\n", "sel_loss", "=", "sel_loss", ".", "view", "(", "-", "1", ",", "batch", ".", "batch_size", ")", ".", "sum", "(", "0", ")", "\n", "# Divide by length of each sequence and sum", "\n", "sel_loss", "=", "torch", ".", "div", "(", "sel_loss", ",", "tgt_lens", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "                ", "sel_loss", "=", "sel_loss", ".", "sum", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "sel_loss", "=", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", "\n", "\n", "", "return", "sel_loss", ",", "gt_indicators", ",", "mask", "\n", "\n", "", "def", "_compute_generation_loss", "(", "self", ",", "batch", ",", "dec_output", ",", "copy_attn", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.NMTLossCompute._make_shard_state": [[380, 384], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.NMTLossCompute._compute_loss": [[386, 410], ["loss.NMTLossCompute.NMTLossCompute.generator", "target.view", "loss.NMTLossCompute.NMTLossCompute.criterion", "loss.NMTLossCompute.NMTLossCompute._stats", "loss.NMTLossCompute.NMTLossCompute._bottle", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "loss.NMTLossCompute.NMTLossCompute.one_hot.repeat", "loss.NMTLossCompute.NMTLossCompute.scatter_", "loss.NMTLossCompute.NMTLossCompute.data.clone", "loss.NMTLossCompute.NMTLossCompute.data.clone", "target.view.size", "tdata.unsqueeze", "torch.nonzero().squeeze.size", "torch.nonzero().squeeze.size", "loss.NMTLossCompute.NMTLossCompute.index_fill_", "target.view", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "tdata.eq"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._stats", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._bottle"], ["\n", "dec_target", "=", "batch", ".", "tgt", "[", "1", ":", "]", "# [tgt_len, batch]", "\n", "dec_mask", "=", "dec_target", ".", "ne", "(", "self", ".", "tgt_padding_idx", ")", ".", "float", "(", ")", "# [tgt_len, batch]", "\n", "dec_target", "=", "dec_target", ".", "view", "(", "-", "1", ")", "# [tgt_len * batch]", "\n", "\n", "align", "=", "batch", ".", "alignment", "[", "1", ":", "]", "# [tgt_len, batch]", "\n", "align", "=", "align", ".", "view", "(", "-", "1", ")", "# [tgt_len * batch]", "\n", "\n", "scores", "=", "self", ".", "generator", "(", "self", ".", "_bottle", "(", "dec_output", ")", ",", "\n", "self", ".", "_bottle", "(", "copy_attn", ")", ",", "\n", "batch", ".", "src_map", ")", "# [tgt_len * batch, vocab_size + copy_vocab_size]", "\n", "loss", "=", "self", ".", "copynmtloss_criterion", "(", "scores", ",", "align", ",", "dec_target", ")", "# [tgt_len * batch_size]", "\n", "scores_data", "=", "scores", ".", "data", ".", "clone", "(", ")", "\n", "scores_data", "=", "inputters", ".", "TextDataset", ".", "collapse_copy_scores", "(", "\n", "self", ".", "_unbottle", "(", "scores_data", ",", "batch", ".", "batch_size", ")", ",", "\n", "batch", ",", "self", ".", "tgt_vocab", ",", "self", ".", "cur_dataset", ".", "src_vocabs", ")", "\n", "scores_data", "=", "self", ".", "_bottle", "(", "scores_data", ")", "\n", "\n", "# Correct target copy token instead of <unk>", "\n", "# tgt[i] = align[i] + len(tgt_vocab)", "\n", "# for i such that tgt[i] == 0 and align[i] != 0", "\n", "target_data", "=", "dec_target", ".", "data", ".", "clone", "(", ")", "\n", "correct_mask", "=", "target_data", ".", "eq", "(", "0", ")", "*", "align", ".", "data", ".", "ne", "(", "0", ")", "\n", "correct_copy", "=", "(", "align", ".", "data", "+", "len", "(", "self", ".", "tgt_vocab", ")", ")", "*", "correct_mask", ".", "long", "(", ")", "\n", "target_data", "=", "target_data", "+", "correct_copy", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.my_build_loss_compute": [[19, 31], ["torch.device", "torch.device", "loss.ReRankerLossCompute", "ReRankerLossCompute.to", "onmt.utils.misc.use_gpu", "onmt.utils.misc.use_gpu"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.use_gpu", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.use_gpu"], ["def", "my_build_loss_compute", "(", "model", ",", "indicator_vocab", ",", "tgt_vocab", ",", "opt", ",", "train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined LossCompute object, which is used to\n    compute loss in train/validate process. You can implement your\n    own *LossCompute class, by subclassing LossComputeBase.\n    \"\"\"", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "onmt", ".", "utils", ".", "misc", ".", "use_gpu", "(", "opt", ")", "else", "\"cpu\"", ")", "\n", "\n", "if", "opt", ".", "key_model", "!=", "'key_selector'", ":", "\n", "        ", "assert", "opt", ".", "copy_attn", "\n", "generator", "=", "model", ".", "generator", "\n", "", "else", ":", "\n", "        ", "generator", "=", "None", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.build_loss_compute": [[33, 52], ["torch.device", "torch.device", "NMTLossCompute.to", "onmt.modules.CopyGeneratorLossCompute", "onmt.modules.CopyGeneratorLossCompute", "loss.NMTLossCompute", "onmt.utils.misc.use_gpu", "onmt.utils.misc.use_gpu"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.use_gpu", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.use_gpu"], ["generator", "=", "generator", ",", "\n", "indicator_vocab", "=", "indicator_vocab", ",", "\n", "tgt_vocab", "=", "tgt_vocab", ")", "\n", "\n", "compute", ".", "to", "(", "device", ")", "\n", "\n", "return", "compute", "\n", "\n", "\n", "", "def", "build_loss_compute", "(", "model", ",", "tgt_vocab", ",", "opt", ",", "train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined LossCompute object, which is used to\n    compute loss in train/validate process. You can implement your\n    own *LossCompute class, by subclassing LossComputeBase.\n    \"\"\"", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "onmt", ".", "utils", ".", "misc", ".", "use_gpu", "(", "opt", ")", "else", "\"cpu\"", ")", "\n", "\n", "if", "opt", ".", "copy_attn", ":", "\n", "        ", "compute", "=", "onmt", ".", "modules", ".", "CopyGeneratorLossCompute", "(", "\n", "model", ".", "generator", ",", "tgt_vocab", ",", "opt", ".", "copy_attn_force", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.filter_shard_state": [[412, 426], ["state.items", "isinstance", "torch.split", "torch.split", "v_chunk.data.clone.data.clone", "v_split.append"], "function", ["None"], ["# Compute sum of perplexities for stats", "\n", "loss_data", "=", "loss", ".", "sum", "(", ")", ".", "data", ".", "clone", "(", ")", "\n", "# stats = self._stats(loss_data, scores_data, target_data)", "\n", "\n", "if", "self", ".", "gen_normalize_by_length", ":", "\n", "# Compute Loss as NLL divided by seq length", "\n", "# Compute Sequence Lengths", "\n", "            ", "tgt_lens", "=", "dec_mask", ".", "sum", "(", "0", ")", "\n", "# Compute Total Loss per sequence in batch", "\n", "loss", "=", "loss", ".", "view", "(", "-", "1", ",", "batch", ".", "batch_size", ")", ".", "sum", "(", "0", ")", "\n", "# Divide by length of each sequence and sum", "\n", "loss", "=", "torch", ".", "div", "(", "loss", ",", "tgt_lens", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.shards": [[428, 476], ["dict", "zip", "zip", "dict.items", "zip", "torch.autograd.backward", "torch.autograd.backward", "loss.filter_shard_state", "loss.filter_shard_state", "dict", "isinstance", "variables.extend", "zip", "zip", "dict.items", "torch.split", "torch.split"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.filter_shard_state", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.filter_shard_state"], ["\n", "", "def", "_compute_loss", "(", "self", ",", "batch", ",", "sel_output", ",", "sel_probs", ",", "dec_output", ",", "copy_attn", ",", "norescale_attn", ")", ":", "\n", "        ", "\"\"\"\n        Compute the loss. Subclass must define this method.\n        Args:\n            batch: the current batch.\n            sel_output: the predicted output(logits) from the selector\n            sel_probs: the predicted importance scores output from the selector\n            dec_output: the predicted output from the decoder\n            copy_attn: the rescaled copy attention\n            norescale_attn: the original attention\n        \"\"\"", "\n", "# calculate the extraction loss", "\n", "if", "self", ".", "key_model", "in", "(", "'key_selector'", ",", "'key_end2end'", ")", ":", "\n", "            ", "sel_loss", ",", "gt_indicators", ",", "sel_mask", "=", "self", ".", "_compute_extraction_loss", "(", "batch", ",", "sel_output", ")", "\n", "\n", "# calculate the generation loss", "\n", "# Note: the gen_loss maybe the length-normalized value of gen_loss_data", "\n", "", "if", "self", ".", "key_model", "in", "(", "'key_generator'", ",", "'key_end2end'", ")", ":", "\n", "            ", "gen_loss", ",", "gen_loss_data", ",", "gen_scores_data", ",", "gen_target_data", ",", "dec_mask", "=", "self", ".", "_compute_generation_loss", "(", "batch", ",", "dec_output", ",", "copy_attn", ")", "\n", "\n", "# calculate the inconsistency loss", "\n", "# (self, sel_probs, sel_mask, norescale_attns, dec_mask, normalize_by_length)", "\n", "", "if", "self", ".", "key_model", "==", "'key_end2end'", ":", "\n", "            ", "if", "self", ".", "incons_lambda", "!=", "0.0", ":", "\n", "                ", "incons_loss", "=", "self", ".", "inconsistloss_criterion", "(", "sel_probs", ",", "sel_mask", ",", "norescale_attn", ",", "dec_mask", ",", "self", ".", "incons_normalize_by_length", ")", "\n", "", "else", ":", "\n", "                ", "incons_loss", "=", "torch", ".", "Tensor", "(", "[", "0.0", "]", ")", "\n", "\n", "# merge all the loss according to the options", "\n", "", "", "if", "self", ".", "key_model", "==", "'key_selector'", ":", "\n", "            ", "assert", "self", ".", "sel_lambda", "!=", "0.0", "\n", "merged_loss", "=", "self", ".", "sel_lambda", "*", "sel_loss", "\n", "stats", "=", "self", ".", "_stats", "(", "batch_size", "=", "batch", ".", "batch_size", ",", "\n", "sel_loss_data", "=", "sel_loss", ".", "data", ".", "clone", "(", ")", ",", "\n", "sel_probs", "=", "sel_probs", ".", "data", ".", "clone", "(", ")", ",", "\n", "gt_indicators", "=", "gt_indicators", ".", "data", ".", "clone", "(", ")", ",", "\n", "sel_mask", "=", "sel_mask", ".", "data", ".", "clone", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "key_model", "==", "'key_generator'", ":", "\n", "            ", "assert", "self", ".", "gen_lambda", "!=", "0.0", "\n", "merged_loss", "=", "self", ".", "gen_lambda", "*", "gen_loss", "\n", "stats", "=", "self", ".", "_stats", "(", "batch_size", "=", "batch", ".", "batch_size", ",", "\n", "gen_loss_data", "=", "gen_loss_data", ".", "data", ".", "clone", "(", ")", ",", "\n", "gen_scores_data", "=", "gen_scores_data", ".", "data", ".", "clone", "(", ")", ",", "\n", "gen_target_data", "=", "gen_target_data", ".", "data", ".", "clone", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.cnn_factory.GatedConv.__init__": [[22, 29], ["torch.Module.__init__", "onmt.modules.WeightNormConv2d", "torch.xavier_uniform_", "torch.xavier_uniform_", "torch.xavier_uniform_", "torch.xavier_uniform_", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "width", "=", "3", ",", "dropout", "=", "0.2", ",", "nopad", "=", "False", ")", ":", "\n", "        ", "super", "(", "GatedConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "onmt", ".", "modules", ".", "WeightNormConv2d", "(", "\n", "input_size", ",", "2", "*", "input_size", ",", "kernel_size", "=", "(", "width", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "width", "//", "2", "*", "(", "1", "-", "nopad", ")", ",", "0", ")", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "conv", ".", "weight", ",", "gain", "=", "(", "4", "*", "(", "1", "-", "dropout", ")", ")", "**", "0.5", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.cnn_factory.GatedConv.forward": [[30, 36], ["cnn_factory.GatedConv.dropout", "cnn_factory.GatedConv.conv", "cnn_factory.GatedConv.split", "int", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "cnn_factory.GatedConv.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_var", ")", ":", "\n", "        ", "x_var", "=", "self", ".", "dropout", "(", "x_var", ")", "\n", "x_var", "=", "self", ".", "conv", "(", "x_var", ")", "\n", "out", ",", "gate", "=", "x_var", ".", "split", "(", "int", "(", "x_var", ".", "size", "(", "1", ")", "/", "2", ")", ",", "1", ")", "\n", "out", "=", "out", "*", "F", ".", "sigmoid", "(", "gate", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.cnn_factory.StackedCNN.__init__": [[41, 50], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "cnn_factory.StackedCNN.layers.append", "cnn_factory.GatedConv"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "cnn_kernel_width", "=", "3", ",", "\n", "dropout", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "StackedCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "GatedConv", "(", "input_size", ",", "cnn_kernel_width", ",", "dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.cnn_factory.StackedCNN.forward": [[51, 56], ["conv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "conv", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "x", "+", "conv", "(", "x", ")", "\n", "x", "*=", "SCALE_WEIGHT", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.cnn_factory.shape_transform": [[14, 17], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose"], "function", ["None"], ["def", "shape_transform", "(", "x", ")", ":", "\n", "    ", "\"\"\" Tranform the size of the tensors to fit for conv input. \"\"\"", "\n", "return", "torch", ".", "unsqueeze", "(", "torch", ".", "transpose", "(", "x", ",", "1", ",", "2", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.rnn_factory.rnn_factory": [[10, 20], ["onmt.models.sru.SRU", "getattr"], "function", ["None"], ["def", "rnn_factory", "(", "rnn_type", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" rnn factory, Use pytorch version when available. \"\"\"", "\n", "no_pack_padded_seq", "=", "False", "\n", "if", "rnn_type", "==", "\"SRU\"", ":", "\n", "# SRU doesn't support PackedSequence.", "\n", "        ", "no_pack_padded_seq", "=", "True", "\n", "rnn", "=", "onmt", ".", "models", ".", "sru", ".", "SRU", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "rnn", "=", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "**", "kwargs", ")", "\n", "", "return", "rnn", ",", "no_pack_padded_seq", "\n", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq": [[6, 14], ["next", "all", "str"], "function", ["None"], ["def", "aeq", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    Assert all arguments have the same value\n    \"\"\"", "\n", "arguments", "=", "(", "arg", "for", "arg", "in", "args", ")", "\n", "first", "=", "next", "(", "arguments", ")", "\n", "assert", "all", "(", "arg", "==", "first", "for", "arg", "in", "arguments", ")", ",", "\"Not all arguments have the same value: \"", "+", "str", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.sequence_mask": [[16, 26], ["lengths.numel", "torch.arange().type_as().repeat().lt", "lengths.max", "lengths.unsqueeze", "torch.arange().type_as().repeat", "torch.arange().type_as", "torch.arange"], "function", ["None"], ["", "def", "sequence_mask", "(", "lengths", ",", "max_len", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Creates a boolean mask from sequence lengths.\n    \"\"\"", "\n", "batch_size", "=", "lengths", ".", "numel", "(", ")", "\n", "max_len", "=", "max_len", "or", "lengths", ".", "max", "(", ")", "\n", "return", "(", "torch", ".", "arange", "(", "0", ",", "max_len", ")", "\n", ".", "type_as", "(", "lengths", ")", "\n", ".", "repeat", "(", "batch_size", ",", "1", ")", "\n", ".", "lt", "(", "lengths", ".", "unsqueeze", "(", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile": [[28, 48], ["list", "list", "x.permute().contiguous.size", "x.permute().contiguous.view().transpose().repeat().transpose().contiguous().view", "range", "x.permute().contiguous.permute().contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute().contiguous", "len", "x.permute().contiguous.view().transpose().repeat().transpose().contiguous", "x.permute().contiguous.size", "x.permute().contiguous.permute", "x.permute().contiguous.permute", "x.permute().contiguous.view().transpose().repeat().transpose", "x.permute().contiguous.view().transpose().repeat", "x.permute().contiguous.view().transpose", "x.permute().contiguous.view"], "function", ["None"], ["", "def", "tile", "(", "x", ",", "count", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Tiles x on dimension dim count times.\n    \"\"\"", "\n", "perm", "=", "list", "(", "range", "(", "len", "(", "x", ".", "size", "(", ")", ")", ")", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "        ", "perm", "[", "0", "]", ",", "perm", "[", "dim", "]", "=", "perm", "[", "dim", "]", ",", "perm", "[", "0", "]", "\n", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "out_size", "=", "list", "(", "x", ".", "size", "(", ")", ")", "\n", "out_size", "[", "0", "]", "*=", "count", "\n", "batch", "=", "x", ".", "size", "(", "0", ")", "\n", "x", "=", "x", ".", "view", "(", "batch", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "repeat", "(", "count", ",", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "out_size", ")", "\n", "if", "dim", "!=", "0", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "perm", ")", ".", "contiguous", "(", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.use_gpu": [[50, 56], ["hasattr", "hasattr", "len"], "function", ["None"], ["", "def", "use_gpu", "(", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Creates a boolean if gpu used\n    \"\"\"", "\n", "return", "(", "hasattr", "(", "opt", ",", "'gpuid'", ")", "and", "len", "(", "opt", ".", "gpuid", ")", ">", "0", ")", "or", "(", "hasattr", "(", "opt", ",", "'gpu'", ")", "and", "opt", ".", "gpu", ">", "-", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.__init__": [[74, 77], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "op", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "self", ".", "optimizers", "=", "op", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad": [[78, 82], ["op.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.step": [[83, 87], ["op.step"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer.step"], ["", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "for", "op", "in", "self", ".", "optimizers", ":", "\n", "            ", "op", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.state": [[88, 92], ["op.state.items"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "state", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "{", "k", ":", "v", "for", "op", "in", "self", ".", "optimizers", "for", "k", ",", "v", "in", "op", ".", "state", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.state_dict": [[93, 96], ["op.state_dict"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "[", "op", ".", "state_dict", "(", ")", "for", "op", "in", "self", ".", "optimizers", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict": [[97, 102], ["range", "len", "len", "len", "optimizers.MultipleOptimizer.optimizers[].load_state_dict"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dicts", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "assert", "len", "(", "state_dicts", ")", "==", "len", "(", "self", ".", "optimizers", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "state_dicts", ")", ")", ":", "\n", "            ", "self", ".", "optimizers", "[", "i", "]", ".", "load_state_dict", "(", "state_dicts", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer.__init__": [[135, 159], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "method", ",", "learning_rate", ",", "max_grad_norm", ",", "\n", "lr_decay", "=", "1", ",", "start_decay_steps", "=", "None", ",", "decay_steps", "=", "None", ",", "\n", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "\n", "adagrad_accum", "=", "0.0", ",", "\n", "decay_method", "=", "None", ",", "\n", "warmup_steps", "=", "4000", ",", "\n", "model_size", "=", "None", ")", ":", "\n", "        ", "self", ".", "last_ppl", "=", "None", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "original_lr", "=", "learning_rate", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "lr_decay", "=", "lr_decay", "\n", "self", ".", "start_decay_steps", "=", "start_decay_steps", "\n", "self", ".", "decay_steps", "=", "decay_steps", "\n", "self", ".", "start_decay", "=", "False", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "betas", "=", "[", "beta1", ",", "beta2", "]", "\n", "self", ".", "adagrad_accum", "=", "adagrad_accum", "\n", "self", ".", "decay_method", "=", "decay_method", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "model_size", "=", "model_size", "\n", "# add for KE_KG", "\n", "self", ".", "total_norm", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer.set_parameters": [[160, 191], ["torch.SGD", "torch.SGD", "torch.Adagrad", "torch.Adagrad", "optimizers.Optimizer.params.append", "optimizers.Optimizer.sparse_params.append", "torch.Adadelta", "torch.Adadelta", "[].fill_", "torch.Adam", "torch.Adam", "optimizers.MultipleOptimizer", "RuntimeError", "torch.Adam", "torch.Adam", "torch.SparseAdam", "torch.SparseAdam"], "methods", ["None"], ["", "def", "set_parameters", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "self", ".", "params", "=", "[", "]", "\n", "self", ".", "sparse_params", "=", "[", "]", "\n", "for", "k", ",", "p", "in", "params", ":", "\n", "            ", "if", "p", ".", "requires_grad", ":", "\n", "                ", "if", "self", ".", "method", "!=", "'sparseadam'", "or", "\"embed\"", "not", "in", "k", ":", "\n", "                    ", "self", ".", "params", ".", "append", "(", "p", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "sparse_params", ".", "append", "(", "p", ")", "\n", "", "", "", "if", "self", ".", "method", "==", "'sgd'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "", "elif", "self", ".", "method", "==", "'adagrad'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adagrad", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "for", "group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                    ", "self", ".", "optimizer", ".", "state", "[", "p", "]", "[", "'sum'", "]", "=", "self", ".", "optimizer", ".", "state", "[", "p", "]", "[", "'sum'", "]", ".", "fill_", "(", "self", ".", "adagrad_accum", ")", "\n", "", "", "", "elif", "self", ".", "method", "==", "'adadelta'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adadelta", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ")", "\n", "", "elif", "self", ".", "method", "==", "'adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-9", ")", "\n", "", "elif", "self", ".", "method", "==", "'sparseadam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "MultipleOptimizer", "(", "\n", "[", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "learning_rate", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-8", ")", ",", "\n", "optim", ".", "SparseAdam", "(", "self", ".", "sparse_params", ",", "lr", "=", "self", ".", "learning_rate", ",", "\n", "betas", "=", "self", ".", "betas", ",", "eps", "=", "1e-8", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Invalid optim method: \"", "+", "self", ".", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer._set_rate": [[192, 199], ["None"], "methods", ["None"], ["", "", "def", "_set_rate", "(", "self", ",", "learning_rate", ")", ":", "\n", "        ", "self", ".", "learning_rate", "=", "learning_rate", "\n", "if", "self", ".", "method", "!=", "'sparseadam'", ":", "\n", "            ", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "", "else", ":", "\n", "            ", "for", "op", "in", "self", ".", "optimizer", ".", "optimizers", ":", "\n", "                ", "op", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer.step": [[200, 242], ["optimizers.Optimizer.optimizer.step", "optimizers.Optimizer._set_rate", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "max", "min"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer.step", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer._set_rate"], ["", "", "", "def", "step", "(", "self", ",", "cur_ppl", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update the model parameters based on current gradients.\n\n        Optionally, will employ gradient modification or update learning\n        rate.\n        \"\"\"", "\n", "self", ".", "_step", "+=", "1", "\n", "\n", "# Decay method used in tensor2tensor.", "\n", "if", "self", ".", "decay_method", "==", "\"noam\"", ":", "\n", "            ", "self", ".", "_set_rate", "(", "\n", "self", ".", "original_lr", "*", "\n", "(", "self", ".", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "self", ".", "_step", "**", "(", "-", "0.5", ")", ",", "\n", "self", ".", "_step", "*", "self", ".", "warmup_steps", "**", "(", "-", "1.5", ")", ")", ")", ")", "\n", "# Decay based on start_decay_steps every decay_steps", "\n", "", "else", ":", "\n", "# if ((self.start_decay_steps is not None) and (", "\n", "#          self._step >= self.start_decay_steps)):", "\n", "#     self.start_decay = True", "\n", "\n", "# add for KE_KG", "\n", "            ", "if", "self", ".", "last_ppl", "is", "not", "None", ":", "\n", "                ", "if", "cur_ppl", ">", "self", ".", "last_ppl", ":", "\n", "                    ", "self", ".", "start_decay", "=", "True", "\n", "", "else", ":", "\n", "                    ", "self", ".", "start_decay", "=", "False", "\n", "", "", "self", ".", "last_ppl", "=", "cur_ppl", "\n", "\n", "if", "self", ".", "start_decay", ":", "\n", "# if ((self._step - self.start_decay_steps)", "\n", "#    % self.decay_steps == 0):", "\n", "#     self.learning_rate = self.learning_rate * self.lr_decay", "\n", "                ", "self", ".", "learning_rate", "=", "max", "(", "self", ".", "learning_rate", "*", "self", ".", "lr_decay", ",", "1e-5", ")", "\n", "\n", "", "", "if", "self", ".", "method", "!=", "'sparseadam'", ":", "\n", "            ", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "self", ".", "learning_rate", "\n", "\n", "", "if", "self", ".", "max_grad_norm", ":", "\n", "# changed for KE_KG", "\n", "            ", "self", ".", "total_norm", "=", "clip_grad_norm_", "(", "self", ".", "params", ",", "self", ".", "max_grad_norm", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.build_optim": [[9, 69], ["optimizers.Optimizer.set_parameters", "Optimizer.optimizer.state_dict", "optimizers.Optimizer", "model.named_parameters", "Optimizer.optimizer.load_state_dict", "onmt.utils.use_gpu", "Optimizer.optimizer.state.values", "RuntimeError", "state.items", "len", "torch.is_tensor", "torch.is_tensor", "v.cuda"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.Optimizer.set_parameters", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.load_state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.use_gpu"], ["def", "build_optim", "(", "model", ",", "opt", ",", "checkpoint", ")", ":", "\n", "    ", "\"\"\" Build optimizer \"\"\"", "\n", "saved_optimizer_state_dict", "=", "None", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "        ", "optim", "=", "checkpoint", "[", "'optim'", "]", "\n", "# We need to save a copy of optim.optimizer.state_dict() for setting", "\n", "# the, optimizer state later on in Stage 2 in this method, since", "\n", "# the method optim.set_parameters(model.parameters()) will overwrite", "\n", "# optim.optimizer, and with ith the values stored in", "\n", "# optim.optimizer.state_dict()", "\n", "saved_optimizer_state_dict", "=", "optim", ".", "optimizer", ".", "state_dict", "(", ")", "\n", "", "else", ":", "\n", "        ", "optim", "=", "Optimizer", "(", "\n", "opt", ".", "optim", ",", "opt", ".", "learning_rate", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "\n", "start_decay_steps", "=", "opt", ".", "start_decay_steps", ",", "\n", "decay_steps", "=", "opt", ".", "decay_steps", ",", "\n", "beta1", "=", "opt", ".", "adam_beta1", ",", "\n", "beta2", "=", "opt", ".", "adam_beta2", ",", "\n", "adagrad_accum", "=", "opt", ".", "adagrad_accumulator_init", ",", "\n", "decay_method", "=", "opt", ".", "decay_method", ",", "\n", "warmup_steps", "=", "opt", ".", "warmup_steps", ",", "\n", "model_size", "=", "opt", ".", "rnn_size", ")", "\n", "\n", "# Stage 1:", "\n", "# Essentially optim.set_parameters (re-)creates and optimizer using", "\n", "# model.paramters() as parameters that will be stored in the", "\n", "# optim.optimizer.param_groups field of the torch optimizer class.", "\n", "# Importantly, this method does not yet load the optimizer state, as", "\n", "# essentially it builds a new optimizer with empty optimizer state and", "\n", "# parameters from the model.", "\n", "", "optim", ".", "set_parameters", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "\n", "if", "opt", ".", "train_from", ":", "\n", "# Stage 2: In this stage, which is only performed when loading an", "\n", "# optimizer from a checkpoint, we load the saved_optimizer_state_dict", "\n", "# into the re-created optimizer, to set the optim.optimizer.state", "\n", "# field, which was previously empty. For this, we use the optimizer", "\n", "# state saved in the \"saved_optimizer_state_dict\" variable for", "\n", "# this purpose.", "\n", "# See also: https://github.com/pytorch/pytorch/issues/2830", "\n", "        ", "optim", ".", "optimizer", ".", "load_state_dict", "(", "saved_optimizer_state_dict", ")", "\n", "# Convert back the state values to cuda type if applicable", "\n", "if", "use_gpu", "(", "opt", ")", ":", "\n", "            ", "for", "state", "in", "optim", ".", "optimizer", ".", "state", ".", "values", "(", ")", ":", "\n", "                ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "                    ", "if", "torch", ".", "is_tensor", "(", "v", ")", ":", "\n", "                        ", "state", "[", "k", "]", "=", "v", ".", "cuda", "(", ")", "\n", "\n", "# We want to make sure that indeed we have a non-empty optimizer state", "\n", "# when we loaded an existing model. This should be at least the case", "\n", "# for Adam, which saves \"exp_avg\" and \"exp_avg_sq\" state", "\n", "# (Exponential moving average of gradient and squared gradient values)", "\n", "", "", "", "", "if", "(", "optim", ".", "method", "==", "'adam'", ")", "and", "(", "len", "(", "optim", ".", "optimizer", ".", "state", ")", "<", "1", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Error: loaded Adam optimizer from existing model\"", "+", "\n", "\" but optimizer state is empty\"", ")", "\n", "\n", "", "", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.ave_total_norm": [[129, 134], ["len", "len"], "methods", ["None"], ["return", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n", "\n", "", "def", "update", "(", "self", ",", "stat", ")", ":", "\n", "# for the selector", "\n", "        ", "self", ".", "sel_loss", "+=", "stat", ".", "sel_loss", "\n", "self", ".", "sel_loss_list", "+=", "stat", ".", "sel_loss_list", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.__init__": [[240, 253], ["time.time"], "methods", ["None"], ["#         self.total_norm = 0.0", "\n", "#         self.start_time = time.time()", "\n", "#", "\n", "#     # def pred_select_ratio(self):", "\n", "#     #     \"\"\" compute prediction selection ratio \"\"\"", "\n", "#     #     assert self.total_words_num != 0", "\n", "#     #     return self.pred_select_num * 1.0 / self.total_words_num", "\n", "#", "\n", "#     # def gt_select_ratio(self):", "\n", "#     #     \"\"\" compute prediction selection ratio \"\"\"", "\n", "#     #     assert self.total_words_num != 0", "\n", "#     #     return self.gt_select_num * 1.0 / self.total_words_num", "\n", "#", "\n", "#     def ave_loss(self):", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_loss": [[254, 258], ["sum", "float", "zip", "len"], "methods", ["None"], ["#         \"\"\" compute the averaged loss\"\"\"", "\n", "#         batch_normalized_losses = [l / b for l, b in zip(self.loss_list, self.batch_size_list)]", "\n", "#         return sum(batch_normalized_losses) / float(len(batch_normalized_losses))", "\n", "#", "\n", "#     def precision(self):", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.posi_acc": [[259, 262], ["None"], "methods", ["None"], ["#         \"\"\" compute the precision \"\"\"", "\n", "#         if self.pred_select_num == 0:", "\n", "#             return 0.0", "\n", "#         else:", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.neg_acc": [[263, 266], ["None"], "methods", ["None"], ["#             return self.true_positive * 1.0 / self.pred_select_num", "\n", "#", "\n", "#     def recall(self):", "\n", "#         \"\"\" compute the recall \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.total_acc": [[267, 270], ["None"], "methods", ["None"], ["#         if self.gt_select_num == 0:", "\n", "#             return 0.0", "\n", "#         else:", "\n", "#             return self.true_positive * 1.0 / self.gt_select_num", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_total_norm": [[271, 276], ["len", "len"], "methods", ["None"], ["#", "\n", "#     def f1_score(self):", "\n", "#         \"\"\" compute the F1 score \"\"\"", "\n", "#         R = self.recall()", "\n", "#         P = self.precision()", "\n", "#         if P == 0.0 or R == 0.0:", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.elapsed_time": [[277, 280], ["time.time"], "methods", ["None"], ["#             return 0.0", "\n", "#         else:", "\n", "#             return 2 * P * R / (P + R)", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update": [[281, 290], ["None"], "methods", ["None"], ["#     # def accuracy(self):", "\n", "#     #     \"\"\" compute the accuracy\"\"\"", "\n", "#     #     assert self.total_words_num != 0", "\n", "#     #     return 100 * (self.true_positive + self.true_negative) * 1.0 / self.total_words_num", "\n", "#", "\n", "#     def elapsed_time(self):", "\n", "#         \"\"\" compute elapsed time \"\"\"", "\n", "#         return time.time() - self.start_time", "\n", "#", "\n", "#     def update(self, stat):", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.output": [[291, 311], ["statistics.ReRankerStatistics.elapsed_time", "onmt.utils.logging.logger.info", "sys.stdout.flush", "statistics.ReRankerStatistics.ave_loss", "statistics.ReRankerStatistics.posi_acc", "statistics.ReRankerStatistics.neg_acc", "statistics.ReRankerStatistics.total_acc", "statistics.ReRankerStatistics.ave_total_norm", "time.time"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.elapsed_time", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.posi_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.neg_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.total_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_total_norm"], ["#         self.loss += stat.loss", "\n", "#         self.loss_list += stat.loss_list", "\n", "#         self.batch_size_list += stat.batch_size_list", "\n", "#         self.true_positive += stat.true_positive", "\n", "#         self.pred_select_num += stat.pred_select_num", "\n", "#         self.gt_select_num += stat.gt_select_num", "\n", "#         self.total_words_num += stat.total_words_num", "\n", "#", "\n", "#     def output(self, step, num_steps, learning_rate, start):", "\n", "#         \"\"\"Write out statistics to stdout.", "\n", "#", "\n", "#         Args:", "\n", "#            step (int): current step", "\n", "#            n_batch (int): total batches", "\n", "#            start (int): start time of step.", "\n", "#         \"\"\"", "\n", "#         t = self.elapsed_time()", "\n", "#         logger.info(", "\n", "#             (\"Step %06d; ave_loss: %7.5f; sel_f1: %4.2f; sel_p: %4.2f; sel_r: %4.2f; \" +", "\n", "#              \"lr: %7.5f; tnorm: %4.2f; %06.0f tok/s; %6.0f sec\")", "\n", "#             % (step, self.ave_loss(),", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.log_tensorboard": [[312, 322], ["writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "statistics.ReRankerStatistics.ave_loss", "statistics.ReRankerStatistics.posi_acc", "statistics.ReRankerStatistics.neg_acc", "statistics.ReRankerStatistics.total_acc", "statistics.ReRankerStatistics.ave_total_norm"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.posi_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.neg_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.total_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_total_norm"], ["#                self.f1_score(),", "\n", "#                self.precision(),", "\n", "#                self.recall(),", "\n", "#                self.lr_rate,", "\n", "#                self.total_norm,", "\n", "#                self.total_words_num / (t + 1e-5),", "\n", "#                time.time() - start))", "\n", "#         sys.stdout.flush()", "\n", "#", "\n", "#     def log_tensorboard(self, prefix, writer, learning_rate, step):", "\n", "#         \"\"\" display statistics to tensorboard \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.all_gather_stats": [[323, 337], ["None"], "methods", ["None"], ["#         raise NotImplementedError", "\n", "#", "\n", "#     @staticmethod", "\n", "#     def all_gather_stats(stat, max_size=4096):", "\n", "#         \"\"\"", "\n", "#         Gather a `Statistics` object accross multiple process/nodes", "\n", "#", "\n", "#         Args:", "\n", "#             stat(:obj:Statistics): the statistics object to gather", "\n", "#                 accross all processes/nodes", "\n", "#             max_size(int): max buffer size to use", "\n", "#", "\n", "#         Returns:", "\n", "#             `Statistics`, the update stats object", "\n", "#         \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.all_gather_stats_list": [[338, 341], ["None"], "methods", ["None"], ["#         raise NotImplementedError", "\n", "#", "\n", "#     @staticmethod", "\n", "#     def all_gather_stats_list(stat_list, max_size=4096):", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute.__init__": [[209, 219], ["torch.Module.__init__", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "len"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._make_shard_state": [[220, 236], ["None"], "methods", ["None"], ["\n", "#", "\n", "sel_probs", "=", "sel_probs", "*", "sel_mask", "\n", "sel_probs", "=", "sel_probs", ".", "transpose", "(", "0", ",", "1", ")", "# [batch, src_len]", "\n", "losses", "=", "[", "]", "\n", "for", "dec_step", ",", "attn_dist", "in", "enumerate", "(", "norescale_attns", ".", "split", "(", "1", ")", ")", ":", "\n", "            ", "attn_dist", "=", "attn_dist", ".", "squeeze", "(", "dim", "=", "0", ")", "\n", "attn_topk", ",", "attn_topk_id", "=", "torch", ".", "topk", "(", "attn_dist", ",", "k", "=", "self", ".", "top_k", ",", "dim", "=", "1", ")", "# [batch, topk]", "\n", "sel_topk", "=", "torch", ".", "gather", "(", "sel_probs", ",", "dim", "=", "1", ",", "index", "=", "attn_topk_id", ")", "# [batch, topk]", "\n", "# mean first than log", "\n", "loss_one_step", "=", "torch", ".", "mean", "(", "attn_topk", "*", "sel_topk", ",", "dim", "=", "1", ")", "# [batch]", "\n", "loss_one_step", "=", "-", "torch", ".", "log", "(", "loss_one_step", "+", "self", ".", "eps", ")", "# [batch]", "\n", "loss_one_step", "=", "loss_one_step", "*", "dec_mask", "[", "dec_step", ",", ":", "]", "# [batch]", "\n", "losses", ".", "append", "(", "loss_one_step", ")", "\n", "", "if", "normalize_by_length", ":", "\n", "            ", "loss", "=", "(", "sum", "(", "losses", ")", "/", "torch", ".", "mean", "(", "dec_mask", ",", "dim", "=", "0", ")", ")", ".", "sum", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._compute_loss": [[238, 263], ["target.eq().float", "output.squeeze.squeeze.squeeze", "probs.squeeze.squeeze.squeeze", "gt_indicators.squeeze.squeeze.squeeze", "loss.ReRankerLossCompute.criterion", "reranker_loss.sum.sum.sum", "reranker_loss.sum.sum.data.clone", "loss.ReRankerLossCompute._stats", "target.eq"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._stats"], ["            ", "loss", "=", "(", "sum", "(", "losses", ")", ")", ".", "sum", "(", ")", "\n", "", "return", "loss", "\n", "\n", "\n", "", "", "class", "E2ELossCompute", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Class for managing efficient loss computation. Handles\n    sharding next step predictions and accumulating mutiple\n    loss computations\n\n    Users can implement their own loss computation strategy by making\n    subclass of this one.  Users need to implement the _compute_loss()\n    and make_shard_state() methods.\n\n    Args:\n        generator (:obj:`nn.Module`) :\n             module that maps the output of the decoder to a\n             distribution over the target vocabulary.\n        indicator_vocab (:obj:`Vocab`) :\n             torchtext vocab object representing the ground-truth keyword indicators\n        tgt_vocab (:obj:`Vocab`) :\n             torchtext vocab object representing the target output\n        normalzation (str): normalize by \"sents\" or \"tokens\"\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "opt", ",", "generator", ",", "indicator_vocab", ",", "tgt_vocab", ",", "eps", "=", "1e-20", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute.monolithic_compute_loss": [[264, 282], ["loss.ReRankerLossCompute._make_shard_state", "loss.ReRankerLossCompute._compute_loss"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._compute_loss"], ["        ", "super", "(", "E2ELossCompute", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "key_model", "=", "opt", ".", "key_model", "\n", "self", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "self", ".", "cur_dataset", "=", "None", "\n", "self", ".", "force_copy", "=", "opt", ".", "copy_attn_force", "\n", "self", ".", "top_k", "=", "opt", ".", "top_k", "\n", "self", ".", "sel_report_topk", "=", "opt", ".", "top_k", "\n", "self", ".", "sel_normalize_by_length", "=", "opt", ".", "sel_normalize_by_length", "\n", "self", ".", "gen_normalize_by_length", "=", "opt", ".", "gen_normalize_by_length", "\n", "self", ".", "incons_normalize_by_length", "=", "opt", ".", "incons_normalize_by_length", "\n", "self", ".", "pos_weight", "=", "opt", ".", "pos_weight", "# default 9.0", "\n", "self", ".", "sel_threshold", "=", "opt", ".", "sel_threshold", "# default 0.9", "\n", "self", ".", "sel_lambda", "=", "opt", ".", "sel_lambda", "# default 0.5", "\n", "self", ".", "sel_train_ratio", "=", "opt", ".", "sel_train_ratio", "# default 1.0", "\n", "self", ".", "gen_lambda", "=", "opt", ".", "gen_lambda", "# default 0.5", "\n", "self", ".", "incons_lambda", "=", "opt", ".", "incons_lambda", "# default 0.5", "\n", "\n", "self", ".", "generator", "=", "generator", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute.sharded_compute_loss": [[283, 320], ["onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "loss.ReRankerLossCompute._make_shard_state", "loss.ReRankerLossCompute._compute_loss", "loss.div().backward", "onmt.utils.ReRankerStatistics.update", "onmt.utils.ReRankerStatistics.update", "loss.div", "float"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._compute_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU_Compute.backward", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update"], ["if", "opt", ".", "key_model", "!=", "'key_selector'", ":", "\n", "            ", "self", ".", "tgt_padding_idx", "=", "tgt_vocab", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "", "if", "opt", ".", "key_model", "!=", "'key_generator'", ":", "\n", "            ", "assert", "len", "(", "indicator_vocab", ")", "==", "3", "\n", "self", ".", "src_unk_idx", "=", "inputters", ".", "UNK", "\n", "self", ".", "sel_padding_idx", "=", "indicator_vocab", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "self", ".", "pos_idx", "=", "indicator_vocab", ".", "stoi", "[", "'I'", "]", "\n", "self", ".", "neg_idx", "=", "indicator_vocab", ".", "stoi", "[", "'O'", "]", "\n", "\n", "# BCEWithLogits loss for extraction (selector)", "\n", "", "if", "self", ".", "key_model", "==", "'key_selector'", "or", "(", "self", ".", "key_model", "==", "'key_end2end'", "and", "self", ".", "sel_lambda", "!=", "0.0", ")", ":", "\n", "            ", "self", ".", "bcewithlogits_criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", "reduction", "=", "'none'", ",", "pos_weight", "=", "torch", ".", "tensor", "(", "[", "self", ".", "pos_weight", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bcewithlogits_criterion", "=", "None", "\n", "\n", "# CopyGenerator loss for generation (generator)", "\n", "# (len(tgt_vocab), force_copy, self.padding_idx)", "\n", "", "if", "self", ".", "key_model", "==", "'key_generator'", "or", "self", ".", "key_model", "==", "'key_end2end'", ":", "\n", "            ", "self", ".", "copynmtloss_criterion", "=", "onmt", ".", "modules", ".", "CopyGeneratorCriterion", "(", "len", "(", "tgt_vocab", ")", ",", "self", ".", "force_copy", ",", "self", ".", "tgt_padding_idx", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "copynmtloss_criterion", "=", "0.0", "\n", "\n", "# inconsistency loss for extraction attention and generating attention", "\n", "", "if", "self", ".", "key_model", "==", "'key_end2end'", "and", "self", ".", "incons_lambda", "!=", "0.0", ":", "\n", "            ", "self", ".", "inconsistloss_criterion", "=", "InconsistencyLoss", "(", "top_k", "=", "self", ".", "top_k", ")", "\n", "\n", "", "if", "not", "self", ".", "sel_normalize_by_length", ":", "\n", "            ", "logger", ".", "warning", "(", "\"These selector losses will not be normalized by length since opt.sel_normalize_by_length=False!\"", ")", "\n", "", "if", "not", "self", ".", "gen_normalize_by_length", ":", "\n", "            ", "logger", ".", "warning", "(", "\"These generator losses will not be normalized by length since opt.gen_normalize_by_length=False!\"", ")", "\n", "", "if", "not", "self", ".", "incons_normalize_by_length", ":", "\n", "            ", "logger", ".", "warning", "(", "\"These inconsisitency losses will not be normalized by length since opt.incons_normalize_by_length=False!\"", ")", "\n", "\n", "", "", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "sel_output", ",", "sel_probs", ",", "dec_output", ",", "attns", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._stats": [[321, 345], ["scores.gt", "posi_pred_correct.sum().item.sum().item.sum().item", "neg_pred_correct.sum().item.sum().item.sum().item", "gt_indicators.sum().item", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "onmt.utils.ReRankerStatistics", "scores.gt.float", "loss.item", "posi_pred_correct.sum().item.sum().item.sum", "neg_pred_correct.sum().item.sum().item.sum", "gt_indicators.sum"], "methods", ["None"], ["\n", "if", "getattr", "(", "batch", ",", "\"alignment\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"using -copy_attn you need to pass in \"", "\n", "\"-dynamic_dict during preprocess stage.\"", ")", "\n", "\n", "", "return", "{", "\"sel_output\"", ":", "sel_output", ",", "\n", "\"sel_probs\"", ":", "sel_probs", ",", "\n", "\"dec_output\"", ":", "dec_output", ",", "\n", "\"copy_attn\"", ":", "None", "if", "attns", "is", "None", "else", "attns", ".", "get", "(", "\"copy\"", ")", ",", "\n", "\"norescale_attn\"", ":", "None", "if", "attns", "is", "None", "else", "attns", ".", "get", "(", "\"norescale_std\"", ")", "}", "\n", "\n", "", "def", "_compute_extraction_loss", "(", "self", ",", "batch", ",", "sel_output", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._bottle": [[346, 348], ["_v.view", "_v.size"], "methods", ["None"], ["\n", "sel_target", "=", "batch", ".", "key_indicators", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._unbottle": [[349, 351], ["_v.view", "_v.size"], "methods", ["None"], ["\n", "# get the sequence mask", "\n", "pad_mask", "=", "sel_target", ".", "ne", "(", "self", ".", "sel_padding_idx", ")", ".", "float", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.image_dataset.ImageDataset.__init__": [[35, 75], ["image_dataset.ImageDataset._peek", "ex.keys", "list", "onmt.inputters.dataset_base.DatasetBase.__init__", "image_dataset.ImageDataset._construct_example_fromlist", "image_dataset.ImageDataset._join_dicts", "zip", "len"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._peek", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._construct_example_fromlist", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._join_dicts"], ["def", "__init__", "(", "self", ",", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", "=", "0", ",", "num_tgt_feats", "=", "0", ",", "\n", "tgt_seq_length", "=", "0", ",", "use_filter_pred", "=", "True", ")", ":", "\n", "        ", "self", ".", "data_type", "=", "'img'", "\n", "\n", "self", ".", "n_src_feats", "=", "num_src_feats", "\n", "self", ".", "n_tgt_feats", "=", "num_tgt_feats", "\n", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "            ", "examples_iter", "=", "(", "self", ".", "_join_dicts", "(", "src", ",", "tgt", ")", "for", "src", ",", "tgt", "in", "\n", "zip", "(", "src_examples_iter", ",", "tgt_examples_iter", ")", ")", "\n", "", "else", ":", "\n", "            ", "examples_iter", "=", "src_examples_iter", "\n", "\n", "# Peek at the first to see which fields are used.", "\n", "", "ex", ",", "examples_iter", "=", "self", ".", "_peek", "(", "examples_iter", ")", "\n", "keys", "=", "ex", ".", "keys", "(", ")", "\n", "\n", "out_fields", "=", "[", "(", "k", ",", "fields", "[", "k", "]", ")", "if", "k", "in", "fields", "else", "(", "k", ",", "None", ")", "\n", "for", "k", "in", "keys", "]", "\n", "example_values", "=", "(", "[", "ex", "[", "k", "]", "for", "k", "in", "keys", "]", "for", "ex", "in", "examples_iter", ")", "\n", "out_examples", "=", "(", "self", ".", "_construct_example_fromlist", "(", "\n", "ex_values", ",", "out_fields", ")", "\n", "for", "ex_values", "in", "example_values", ")", "\n", "# If out_examples is a generator, we need to save the filter_pred", "\n", "# function in serialization too, which would cause a problem when", "\n", "# `torch.save()`. Thus we materialize it as a list.", "\n", "out_examples", "=", "list", "(", "out_examples", ")", "\n", "\n", "def", "filter_pred", "(", "example", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "                ", "return", "0", "<", "len", "(", "example", ".", "tgt", ")", "<=", "tgt_seq_length", "\n", "", "else", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "filter_pred", "=", "filter_pred", "if", "use_filter_pred", "else", "lambda", "x", ":", "True", "\n", "\n", "super", "(", "ImageDataset", ",", "self", ")", ".", "__init__", "(", "\n", "out_examples", ",", "out_fields", ",", "filter_pred", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.image_dataset.ImageDataset.sort_key": [[77, 80], ["ex.src.size", "ex.src.size"], "methods", ["None"], ["", "def", "sort_key", "(", "self", ",", "ex", ")", ":", "\n", "        ", "\"\"\" Sort using the size of the image: (width, height).\"\"\"", "\n", "return", "(", "ex", ".", "src", ".", "size", "(", "2", ")", ",", "ex", ".", "src", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.image_dataset.ImageDataset.make_image_examples_nfeats_tpl": [[81, 106], ["image_dataset.ImageDataset.make_examples", "image_dataset.ImageDataset.make_img_iterator_from_file", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.make_examples", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.image_dataset.ImageDataset.make_img_iterator_from_file"], ["", "@", "staticmethod", "\n", "def", "make_image_examples_nfeats_tpl", "(", "img_iter", ",", "img_path", ",", "img_dir", ")", ":", "\n", "        ", "\"\"\"\n        Note: one of img_iter and img_path must be not None\n        Args:\n            img_iter(iterator): an iterator that yields pairs (img, filename)\n                (or None)\n            img_path(str): location of a src file containing image paths\n                (or None)\n            src_dir (str): location of source images\n\n        Returns:\n            (example_dict iterator, num_feats) tuple\n        \"\"\"", "\n", "if", "img_iter", "is", "None", ":", "\n", "            ", "if", "img_path", "is", "not", "None", ":", "\n", "                ", "img_iter", "=", "ImageDataset", ".", "make_img_iterator_from_file", "(", "img_path", ",", "\n", "img_dir", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"\"\"One of 'img_iter' and 'img_path'\n                                    must be not None\"\"\"", ")", "\n", "", "", "examples_iter", "=", "ImageDataset", ".", "make_examples", "(", "img_iter", ",", "img_dir", ",", "'src'", ")", "\n", "num_feats", "=", "0", "# Source side(img) has no features.", "\n", "\n", "return", "(", "examples_iter", ",", "num_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.image_dataset.ImageDataset.make_examples": [[107, 132], ["enumerate", "os.path.exists", "img.size", "img.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "make_examples", "(", "img_iter", ",", "src_dir", ",", "side", ",", "truncate", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src file containing image paths\n            src_dir (str): location of source images\n            side (str): 'src' or 'tgt'\n            truncate: maximum img size ((0,0) or None for unlimited)\n\n        Yields:\n            a dictionary containing image data, path and index for each line.\n        \"\"\"", "\n", "assert", "(", "src_dir", "is", "not", "None", ")", "and", "os", ".", "path", ".", "exists", "(", "src_dir", ")", ",", "'src_dir must be a valid directory if data_type is img'", "\n", "\n", "for", "index", ",", "(", "img", ",", "filename", ")", "in", "enumerate", "(", "img_iter", ")", ":", "\n", "            ", "if", "truncate", "and", "truncate", "!=", "(", "0", ",", "0", ")", ":", "\n", "                ", "if", "not", "(", "img", ".", "size", "(", "1", ")", "<=", "truncate", "[", "0", "]", "\n", "and", "img", ".", "size", "(", "2", ")", "<=", "truncate", "[", "1", "]", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "example_dict", "=", "{", "side", ":", "img", ",", "\n", "side", "+", "'_path'", ":", "filename", ",", "\n", "'indices'", ":", "index", "}", "\n", "yield", "example_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.image_dataset.ImageDataset.make_img_iterator_from_file": [[133, 159], ["codecs.open", "line.strip", "os.path.join", "os.path.exists", "os.path.exists", "line.strip", "transforms.ToTensor", "Image.open"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "make_img_iterator_from_file", "(", "path", ",", "src_dir", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path(str):\n            src_dir(str):\n\n        Yields:\n            img: and image tensor\n            filename(str): the image filename\n        \"\"\"", "\n", "from", "PIL", "import", "Image", "\n", "from", "torchvision", "import", "transforms", "\n", "\n", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "            ", "for", "line", "in", "corpus_file", ":", "\n", "                ", "filename", "=", "line", ".", "strip", "(", ")", "\n", "img_path", "=", "os", ".", "path", ".", "join", "(", "src_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "img_path", ")", ":", "\n", "                    ", "img_path", "=", "line", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "img_path", ")", ",", "'img path %s not found'", "%", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "img", "=", "transforms", ".", "ToTensor", "(", ")", "(", "Image", ".", "open", "(", "img_path", ")", ")", "\n", "yield", "img", ",", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.image_dataset.ImageDataset.get_fields": [[160, 233], ["torchtext.data.Field", "range", "torchtext.data.Field", "range", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "data[].size", "max", "max", "torch.zeros().fill_", "enumerate", "torchtext.data.Field", "torchtext.data.Field", "max", "torch.zeros", "enumerate", "max", "torch.zeros().long", "enumerate", "max", "len", "enumerate", "t.size", "t.size", "torch.zeros", "t.size", "t.size", "torch.zeros", "len", "str", "str", "t.max", "len", "img.size", "img.size", "sent.size"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            n_src_features: the number of source features to\n                create `torchtext.data.Field` for.\n            n_tgt_features: the number of target features to\n                create `torchtext.data.Field` for.\n\n        Returns:\n            A dictionary whose keys are strings and whose values\n            are the corresponding Field objects.\n        \"\"\"", "\n", "fields", "=", "{", "}", "\n", "\n", "def", "make_img", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "c", "=", "data", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "h", "=", "max", "(", "[", "t", ".", "size", "(", "1", ")", "for", "t", "in", "data", "]", ")", "\n", "w", "=", "max", "(", "[", "t", ".", "size", "(", "2", ")", "for", "t", "in", "data", "]", ")", "\n", "imgs", "=", "torch", ".", "zeros", "(", "len", "(", "data", ")", ",", "c", ",", "h", ",", "w", ")", ".", "fill_", "(", "1", ")", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "imgs", "[", "i", ",", ":", ",", "0", ":", "img", ".", "size", "(", "1", ")", ",", "0", ":", "img", ".", "size", "(", "2", ")", "]", "=", "img", "\n", "", "return", "imgs", "\n", "\n", "", "fields", "[", "\"src\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_img", ",", "sequential", "=", "False", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_src_features", ")", ":", "\n", "            ", "fields", "[", "\"src_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "fields", "[", "\"tgt\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_tgt_features", ")", ":", "\n", "            ", "fields", "[", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "def", "make_src", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "src_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "src_vocab_size", "=", "max", "(", "[", "t", ".", "max", "(", ")", "for", "t", "in", "data", "]", ")", "+", "1", "\n", "alignment", "=", "torch", ".", "zeros", "(", "src_size", ",", "len", "(", "data", ")", ",", "src_vocab_size", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "for", "j", ",", "t", "in", "enumerate", "(", "sent", ")", ":", "\n", "                    ", "alignment", "[", "j", ",", "i", ",", "t", "]", "=", "1", "\n", "", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"src_map\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_src", ",", "sequential", "=", "False", ")", "\n", "\n", "def", "make_tgt", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", ",", "len", "(", "data", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "alignment", "[", ":", "sent", ".", "size", "(", "0", ")", ",", "i", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"alignment\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "postprocessing", "=", "make_tgt", ",", "sequential", "=", "False", ")", "\n", "\n", "fields", "[", "\"indices\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "sequential", "=", "False", ")", "\n", "\n", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.image_dataset.ImageDataset.get_num_features": [[234, 256], ["codecs.open", "cf.readline().strip().split", "ImageDataset.extract_text_features", "cf.readline().strip", "cf.readline"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.extract_text_features"], ["", "@", "staticmethod", "\n", "def", "get_num_features", "(", "corpus_file", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        For image corpus, source side is in form of image, thus\n        no feature; while target side is in form of text, thus\n        we can extract its text features.\n\n        Args:\n            corpus_file (str): file path to get the features.\n            side (str): 'src' or 'tgt'.\n\n        Returns:\n            number of features on `side`.\n        \"\"\"", "\n", "if", "side", "==", "'src'", ":", "\n", "            ", "num_feats", "=", "0", "\n", "", "else", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "corpus_file", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "cf", ":", "\n", "                ", "f_line", "=", "cf", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "_", ",", "_", ",", "num_feats", "=", "ImageDataset", ".", "extract_text_features", "(", "f_line", ")", "\n", "\n", "", "", "return", "num_feats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.__init__": [[40, 95], ["text_dataset.TextDataset._peek", "ex.keys", "onmt.inputters.dataset_base.DatasetBase.__init__", "text_dataset.TextDataset._dynamic_dict", "text_dataset.TextDataset._construct_example_fromlist", "len", "out_examples.append", "text_dataset.TextDataset._join_dicts", "text_dataset.TextDataset._join_dicts", "zip", "zip", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._peek", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset._dynamic_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._construct_example_fromlist", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._join_dicts", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._join_dicts"], ["def", "__init__", "(", "self", ",", "fields", ",", "src_examples_iter", ",", "key_indicators_iter", ",", "retrieved_keys_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", "=", "0", ",", "num_tgt_feats", "=", "0", ",", "\n", "src_seq_length", "=", "0", ",", "tgt_seq_length", "=", "0", ",", "\n", "dynamic_dict", "=", "True", ",", "use_filter_pred", "=", "True", ")", ":", "\n", "        ", "self", ".", "data_type", "=", "'text'", "\n", "\n", "# self.src_vocabs: mutated in dynamic_dict, used in", "\n", "# collapse_copy_scores and in Translator.py", "\n", "self", ".", "src_vocabs", "=", "[", "]", "\n", "\n", "self", ".", "n_src_feats", "=", "num_src_feats", "\n", "self", ".", "n_tgt_feats", "=", "num_tgt_feats", "\n", "\n", "# Each element of an example is a dictionary whose keys represents", "\n", "# at minimum the src tokens and their indices and potentially also", "\n", "# the src and tgt features and alignment information.", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "            ", "examples_iter", "=", "(", "self", ".", "_join_dicts", "(", "src", ",", "indicators", ",", "retrieved_keys", ",", "tgt", ")", "for", "src", ",", "indicators", ",", "retrieved_keys", ",", "tgt", "in", "\n", "zip", "(", "src_examples_iter", ",", "key_indicators_iter", ",", "retrieved_keys_iter", ",", "tgt_examples_iter", ")", ")", "\n", "", "else", ":", "\n", "            ", "examples_iter", "=", "(", "self", ".", "_join_dicts", "(", "src", ",", "retrieved_keys", ")", "for", "src", ",", "retrieved_keys", "in", "\n", "zip", "(", "src_examples_iter", ",", "retrieved_keys_iter", ")", ")", "\n", "\n", "", "if", "dynamic_dict", ":", "\n", "            ", "examples_iter", "=", "self", ".", "_dynamic_dict", "(", "examples_iter", ")", "\n", "\n", "# Peek at the first to see which fields are used.", "\n", "", "ex", ",", "examples_iter", "=", "self", ".", "_peek", "(", "examples_iter", ")", "\n", "keys", "=", "ex", ".", "keys", "(", ")", "\n", "\n", "out_fields", "=", "[", "(", "k", ",", "fields", "[", "k", "]", ")", "if", "k", "in", "fields", "else", "(", "k", ",", "None", ")", "\n", "for", "k", "in", "keys", "]", "\n", "example_values", "=", "(", "[", "ex", "[", "k", "]", "for", "k", "in", "keys", "]", "for", "ex", "in", "examples_iter", ")", "\n", "\n", "# If out_examples is a generator, we need to save the filter_pred", "\n", "# function in serialization too, which would cause a problem when", "\n", "# `torch.save()`. Thus we materialize it as a list.", "\n", "src_size", "=", "0", "\n", "\n", "out_examples", "=", "[", "]", "\n", "for", "ex_values", "in", "example_values", ":", "\n", "            ", "example", "=", "self", ".", "_construct_example_fromlist", "(", "\n", "ex_values", ",", "out_fields", ")", "\n", "src_size", "+=", "len", "(", "example", ".", "src", ")", "\n", "out_examples", ".", "append", "(", "example", ")", "\n", "\n", "", "def", "filter_pred", "(", "example", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "return", "0", "<", "len", "(", "example", ".", "src", ")", "<=", "src_seq_length", "and", "0", "<", "len", "(", "example", ".", "tgt", ")", "<=", "tgt_seq_length", "\n", "\n", "", "filter_pred", "=", "filter_pred", "if", "use_filter_pred", "else", "lambda", "x", ":", "True", "\n", "\n", "super", "(", "TextDataset", ",", "self", ")", ".", "__init__", "(", "\n", "out_examples", ",", "out_fields", ",", "filter_pred", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.sort_key": [[97, 104], ["hasattr", "len", "len", "len"], "methods", ["None"], ["", "def", "sort_key", "(", "self", ",", "ex", ")", ":", "\n", "        ", "\"\"\" Sort using length of source sentences. \"\"\"", "\n", "# Default to a balanced sort, prioritizing tgt len match.", "\n", "# TODO: make this configurable.", "\n", "if", "hasattr", "(", "ex", ",", "\"tgt\"", ")", ":", "\n", "            ", "return", "len", "(", "ex", ".", "src", ")", ",", "len", "(", "ex", ".", "tgt", ")", "\n", "", "return", "len", "(", "ex", ".", "src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.collapse_copy_scores": [[105, 131], ["len", "range", "range", "len", "torch.Tensor().type_as", "torch.Tensor().type_as", "scores[].index_add_", "scores[].index_fill_", "torch.Tensor().type_as.append", "torch.Tensor().type_as.append", "scores[].index_select", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collapse_copy_scores", "(", "scores", ",", "batch", ",", "tgt_vocab", ",", "src_vocabs", ")", ":", "\n", "        ", "\"\"\"\n        Given scores from an expanded dictionary\n        corresponeding to a batch, sums together copies,\n        with a dictionary word when it is ambigious.\n        \"\"\"", "\n", "offset", "=", "len", "(", "tgt_vocab", ")", "\n", "for", "b", "in", "range", "(", "batch", ".", "batch_size", ")", ":", "\n", "            ", "blank", "=", "[", "]", "\n", "fill", "=", "[", "]", "\n", "index", "=", "batch", ".", "indices", ".", "data", "[", "b", "]", "\n", "src_vocab", "=", "src_vocabs", "[", "index", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "src_vocab", ")", ")", ":", "\n", "                ", "sw", "=", "src_vocab", ".", "itos", "[", "i", "]", "\n", "ti", "=", "tgt_vocab", ".", "stoi", "[", "sw", "]", "\n", "if", "ti", "!=", "0", ":", "\n", "                    ", "blank", ".", "append", "(", "offset", "+", "i", ")", "\n", "fill", ".", "append", "(", "ti", ")", "\n", "", "", "if", "blank", ":", "\n", "                ", "blank", "=", "torch", ".", "Tensor", "(", "blank", ")", ".", "type_as", "(", "batch", ".", "indices", ".", "data", ")", "\n", "fill", "=", "torch", ".", "Tensor", "(", "fill", ")", ".", "type_as", "(", "batch", ".", "indices", ".", "data", ")", "\n", "scores", "[", ":", ",", "b", "]", ".", "index_add_", "(", "1", ",", "fill", ",", "\n", "scores", "[", ":", ",", "b", "]", ".", "index_select", "(", "1", ",", "blank", ")", ")", "\n", "scores", "[", ":", ",", "b", "]", ".", "index_fill_", "(", "1", ",", "blank", ",", "1e-10", ")", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.make_text_examples_nfeats_tpl": [[132, 168], ["text_dataset.TextDataset.make_examples", "next", "itertools.chain", "text_dataset.TextDataset.make_text_iterator_from_file"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.make_examples", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.make_text_iterator_from_file"], ["", "@", "staticmethod", "\n", "def", "make_text_examples_nfeats_tpl", "(", "text_iter", ",", "text_path", ",", "truncate", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            text_iter(iterator): an iterator (or None) that we can loop over\n                to read examples.\n                It may be an openned file, a string list etc...\n            text_path(str): path to file or None\n            path (str): location of a src or tgt file.\n            truncate (int): maximum sequence length (0 for unlimited).\n            side (str): \"src\" or \"tgt\".\n\n        Returns:\n            (example_dict iterator, num_feats) tuple.\n        \"\"\"", "\n", "assert", "side", "in", "[", "'src'", ",", "'tgt'", ",", "'key_indicator'", ",", "'retrieved_keys'", "]", "\n", "\n", "if", "text_iter", "is", "None", ":", "\n", "            ", "if", "text_path", "is", "not", "None", ":", "\n", "                ", "text_iter", "=", "TextDataset", ".", "make_text_iterator_from_file", "(", "text_path", ")", "\n", "", "else", ":", "\n", "                ", "return", "(", "None", ",", "0", ")", "\n", "\n", "# All examples have same number of features, so we peek first one", "\n", "# to get the num_feats.", "\n", "", "", "examples_nfeats_iter", "=", "TextDataset", ".", "make_examples", "(", "text_iter", ",", "truncate", ",", "side", ")", "\n", "\n", "first_ex", "=", "next", "(", "examples_nfeats_iter", ")", "\n", "num_feats", "=", "first_ex", "[", "1", "]", "\n", "\n", "# Chain back the first element - we only want to peek it.", "\n", "examples_nfeats_iter", "=", "chain", "(", "[", "first_ex", "]", ",", "examples_nfeats_iter", ")", "\n", "examples_iter", "=", "(", "ex", "for", "ex", ",", "nfeats", "in", "examples_nfeats_iter", ")", "\n", "\n", "return", "(", "examples_iter", ",", "num_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.make_examples": [[169, 194], ["enumerate", "line.strip().split.strip().split.strip().split", "TextDataset.extract_text_features", "example_dict.update", "line.strip().split.strip().split.strip", "enumerate", "str"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.extract_text_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update"], ["", "@", "staticmethod", "\n", "def", "make_examples", "(", "text_iter", ",", "truncate", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            text_iter (iterator): iterator of text sequences\n            truncate (int): maximum sequence length (0 for unlimited).\n            side (str): \"src\" or \"tgt\".\n\n        Yields:\n            (word, features, nfeat) triples for each line.\n        \"\"\"", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "text_iter", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "truncate", ":", "\n", "                ", "line", "=", "line", "[", ":", "truncate", "]", "\n", "\n", "", "words", ",", "feats", ",", "n_feats", "=", "TextDataset", ".", "extract_text_features", "(", "line", ")", "\n", "\n", "example_dict", "=", "{", "side", ":", "words", ",", "\"indices\"", ":", "i", "}", "\n", "if", "feats", ":", "\n", "                ", "prefix", "=", "side", "+", "\"_feat_\"", "\n", "example_dict", ".", "update", "(", "(", "prefix", "+", "str", "(", "j", ")", ",", "f", ")", "\n", "for", "j", ",", "f", "in", "enumerate", "(", "feats", ")", ")", "\n", "", "yield", "example_dict", ",", "n_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.make_text_iterator_from_file": [[195, 200], ["codecs.open"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "make_text_iterator_from_file", "(", "path", ")", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "            ", "for", "line", "in", "corpus_file", ":", "\n", "                ", "yield", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.get_fields": [[201, 268], ["torchtext.data.Field", "range", "torchtext.data.Field", "range", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "max", "torch.zeros", "enumerate", "max", "torch.zeros().long", "enumerate", "max", "len", "enumerate", "t.size", "t.size", "torch.zeros", "str", "str", "t.max", "len", "sent.size"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            n_src_features (int): the number of source features to\n                create `torchtext.data.Field` for.\n            n_tgt_features (int): the number of target features to\n                create `torchtext.data.Field` for.\n\n        Returns:\n            A dictionary whose keys are strings and whose values\n            are the corresponding Field objects.\n        \"\"\"", "\n", "fields", "=", "{", "}", "\n", "\n", "fields", "[", "\"src\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "pad_token", "=", "PAD_WORD", ",", "\n", "include_lengths", "=", "True", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_src_features", ")", ":", "\n", "            ", "fields", "[", "\"src_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "fields", "[", "\"tgt\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_tgt_features", ")", ":", "\n", "            ", "fields", "[", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "# KE-KG-KR-M: add for keyword extraction", "\n", "", "fields", "[", "\"key_indicators\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "pad_token", "=", "PAD_WORD", ",", "\n", "unk_token", "=", "None", ",", "\n", "include_lengths", "=", "True", ")", "\n", "\n", "# KE-KG-KR-M: add for retrieved keyphrases", "\n", "fields", "[", "\"retrieved_keys\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "pad_token", "=", "PAD_WORD", ",", "\n", "include_lengths", "=", "True", ")", "\n", "\n", "def", "make_src", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "src_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "src_vocab_size", "=", "max", "(", "[", "t", ".", "max", "(", ")", "for", "t", "in", "data", "]", ")", "+", "1", "\n", "alignment", "=", "torch", ".", "zeros", "(", "src_size", ",", "len", "(", "data", ")", ",", "src_vocab_size", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "for", "j", ",", "t", "in", "enumerate", "(", "sent", ")", ":", "\n", "                    ", "alignment", "[", "j", ",", "i", ",", "t", "]", "=", "1", "\n", "", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"src_map\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_src", ",", "sequential", "=", "False", ")", "\n", "\n", "def", "make_tgt", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", ",", "len", "(", "data", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "alignment", "[", ":", "sent", ".", "size", "(", "0", ")", ",", "i", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"alignment\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "postprocessing", "=", "make_tgt", ",", "sequential", "=", "False", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.get_num_features": [[269, 289], ["codecs.open", "cf.readline().strip().split", "TextDataset.extract_text_features", "cf.readline().strip", "cf.readline"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.extract_text_features"], ["\n", "fields", "[", "\"indices\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "sequential", "=", "False", ")", "\n", "\n", "return", "fields", "\n", "\n", "", "@", "staticmethod", "\n", "def", "get_num_features", "(", "corpus_file", ",", "side", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset._dynamic_dict": [[291, 307], ["torchtext.vocab.Vocab", "text_dataset.TextDataset.src_vocabs.append", "torch.LongTensor", "collections.Counter", "torch.LongTensor"], "methods", ["None"], ["with", "codecs", ".", "open", "(", "corpus_file", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "cf", ":", "\n", "            ", "f_line", "=", "cf", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "_", ",", "_", ",", "num_feats", "=", "TextDataset", ".", "extract_text_features", "(", "f_line", ")", "\n", "\n", "", "return", "num_feats", "\n", "\n", "# Below are helper functions for intra-class use only.", "\n", "", "def", "_dynamic_dict", "(", "self", ",", "examples_iter", ")", ":", "\n", "        ", "for", "example", "in", "examples_iter", ":", "\n", "            ", "src", "=", "example", "[", "\"src\"", "]", "\n", "src_vocab", "=", "torchtext", ".", "vocab", ".", "Vocab", "(", "Counter", "(", "src", ")", ",", "\n", "specials", "=", "[", "UNK_WORD", ",", "PAD_WORD", "]", ")", "\n", "self", ".", "src_vocabs", ".", "append", "(", "src_vocab", ")", "\n", "# Mapping source tokens to indices in the dynamic dict.", "\n", "src_map", "=", "torch", ".", "LongTensor", "(", "[", "src_vocab", ".", "stoi", "[", "w", "]", "for", "w", "in", "src", "]", ")", "\n", "example", "[", "\"src_map\"", "]", "=", "src_map", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.ShardedTextCorpusIterator.__init__": [[319, 346], ["io.open", "sys.stderr.write", "sys.exit"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "corpus_path", ",", "line_truncate", ",", "side", ",", "shard_size", ",", "\n", "assoc_iter", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            corpus_path: the corpus file path.\n            line_truncate: the maximum length of a line to read.\n                            0 for unlimited.\n            side: \"src\" or \"tgt\".\n            shard_size: the shard size, 0 means not sharding the file.\n            assoc_iter: if not None, it is the associate iterator that\n                        this iterator should align its step with.\n        \"\"\"", "\n", "try", ":", "\n", "# The codecs module seems to have bugs with seek()/tell(),", "\n", "# so we use io.open().", "\n", "            ", "self", ".", "corpus", "=", "io", ".", "open", "(", "corpus_path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "", "except", "IOError", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\"Failed to open corpus file: %s\"", "%", "corpus_path", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "", "self", ".", "line_truncate", "=", "line_truncate", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.ShardedTextCorpusIterator.__iter__": [[347, 394], ["text_dataset.ShardedTextCorpusIterator.corpus.seek", "text_dataset.ShardedTextCorpusIterator.corpus.readline", "text_dataset.ShardedTextCorpusIterator.corpus.close", "text_dataset.ShardedTextCorpusIterator.corpus.readline", "AssertionError", "text_dataset.ShardedTextCorpusIterator._example_dict_iter", "text_dataset.ShardedTextCorpusIterator.corpus.tell", "text_dataset.ShardedTextCorpusIterator.corpus.close", "text_dataset.ShardedTextCorpusIterator._example_dict_iter"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.ShardedTextCorpusIterator._example_dict_iter", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.ShardedTextCorpusIterator._example_dict_iter"], ["self", ".", "side", "=", "side", "\n", "self", ".", "shard_size", "=", "shard_size", "\n", "self", ".", "assoc_iter", "=", "assoc_iter", "\n", "self", ".", "last_pos", "=", "0", "\n", "self", ".", "line_index", "=", "-", "1", "\n", "self", ".", "eof", "=", "False", "\n", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Iterator of (example_dict, nfeats).\n        On each call, it iterates over as many (example_dict, nfeats) tuples\n        until this shard's size equals to or approximates `self.shard_size`.\n        \"\"\"", "\n", "iteration_index", "=", "-", "1", "\n", "if", "self", ".", "assoc_iter", "is", "not", "None", ":", "\n", "# We have associate iterator, just yields tuples", "\n", "# util we run parallel with it.", "\n", "            ", "while", "self", ".", "line_index", "<", "self", ".", "assoc_iter", ".", "line_index", ":", "\n", "                ", "line", "=", "self", ".", "corpus", ".", "readline", "(", ")", "\n", "if", "line", "==", "''", ":", "\n", "                    ", "raise", "AssertionError", "(", "\n", "\"Two corpuses must have same number of lines!\"", ")", "\n", "\n", "", "self", ".", "line_index", "+=", "1", "\n", "iteration_index", "+=", "1", "\n", "yield", "self", ".", "_example_dict_iter", "(", "line", ",", "iteration_index", ")", "\n", "\n", "", "if", "self", ".", "assoc_iter", ".", "eof", ":", "\n", "                ", "self", ".", "eof", "=", "True", "\n", "self", ".", "corpus", ".", "close", "(", ")", "\n", "", "", "else", ":", "\n", "# Yield tuples util this shard's size reaches the threshold.", "\n", "            ", "self", ".", "corpus", ".", "seek", "(", "self", ".", "last_pos", ")", "\n", "while", "True", ":", "\n", "                ", "if", "self", ".", "shard_size", "!=", "0", "and", "self", ".", "line_index", "%", "64", "==", "0", ":", "\n", "# This part of check is time consuming on Py2 (but", "\n", "# it is quite fast on Py3, weird!). So we don't bother", "\n", "# to check for very line. Instead we chekc every 64", "\n", "# lines. Thus we are not dividing exactly per", "\n", "# `shard_size`, but it is not too much difference.", "\n", "                    ", "cur_pos", "=", "self", ".", "corpus", ".", "tell", "(", ")", "\n", "if", "cur_pos", ">=", "self", ".", "last_pos", "+", "self", ".", "shard_size", ":", "\n", "                        ", "self", ".", "last_pos", "=", "cur_pos", "\n", "raise", "StopIteration", "\n", "\n", "", "", "line", "=", "self", ".", "corpus", ".", "readline", "(", ")", "\n", "if", "line", "==", "''", ":", "\n", "                    ", "self", ".", "eof", "=", "True", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.ShardedTextCorpusIterator.hit_end": [[395, 398], ["None"], "methods", ["None"], ["self", ".", "corpus", ".", "close", "(", ")", "\n", "raise", "StopIteration", "\n", "\n", "", "self", ".", "line_index", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.ShardedTextCorpusIterator.num_feats": [[399, 415], ["text_dataset.ShardedTextCorpusIterator.corpus.tell", "text_dataset.ShardedTextCorpusIterator.corpus.readline().split", "TextDataset.extract_text_features", "text_dataset.ShardedTextCorpusIterator.corpus.seek", "text_dataset.ShardedTextCorpusIterator.corpus.readline"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.extract_text_features"], ["iteration_index", "+=", "1", "\n", "yield", "self", ".", "_example_dict_iter", "(", "line", ",", "iteration_index", ")", "\n", "\n", "", "", "", "def", "hit_end", "(", "self", ")", ":", "\n", "        ", "\"\"\" ? \"\"\"", "\n", "return", "self", ".", "eof", "\n", "\n", "", "@", "property", "\n", "def", "num_feats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        We peek the first line and seek back to\n        the beginning of the file.\n        \"\"\"", "\n", "saved_pos", "=", "self", ".", "corpus", ".", "tell", "(", ")", "\n", "\n", "line", "=", "self", ".", "corpus", ".", "readline", "(", ")", ".", "split", "(", ")", "\n", "if", "self", ".", "line_truncate", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.ShardedTextCorpusIterator._example_dict_iter": [[416, 431], ["line.split.split.split", "TextDataset.extract_text_features", "onmt.utils.misc.aeq", "example_dict.update", "enumerate", "str"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.extract_text_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update"], ["            ", "line", "=", "line", "[", ":", "self", ".", "line_truncate", "]", "\n", "", "_", ",", "_", ",", "self", ".", "n_feats", "=", "TextDataset", ".", "extract_text_features", "(", "line", ")", "\n", "\n", "self", ".", "corpus", ".", "seek", "(", "saved_pos", ")", "\n", "\n", "return", "self", ".", "n_feats", "\n", "\n", "", "def", "_example_dict_iter", "(", "self", ",", "line", ",", "index", ")", ":", "\n", "        ", "line", "=", "line", ".", "split", "(", ")", "\n", "if", "self", ".", "line_truncate", ":", "\n", "            ", "line", "=", "line", "[", ":", "self", ".", "line_truncate", "]", "\n", "", "words", ",", "feats", ",", "n_feats", "=", "TextDataset", ".", "extract_text_features", "(", "line", ")", "\n", "example_dict", "=", "{", "self", ".", "side", ":", "words", ",", "\"indices\"", ":", "index", "}", "\n", "if", "feats", ":", "\n", "# All examples must have same number of features.", "\n", "            ", "aeq", "(", "self", ".", "n_feats", ",", "n_feats", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.OrderedIterator.create_batches": [[401, 417], ["inputter.OrderedIterator.create_batches._pool"], "methods", ["None"], ["            ", "with", "open", "(", "vocabulary_path", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "if", "len", "(", "line", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "word", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "vocabulary", ".", "add", "(", "word", ")", "\n", "", "", "", "", "return", "vocabulary", "\n", "\n", "\n", "", "class", "OrderedIterator", "(", "torchtext", ".", "data", ".", "Iterator", ")", ":", "\n", "    ", "\"\"\" Ordered Iterator Class \"\"\"", "\n", "\n", "def", "create_batches", "(", "self", ")", ":", "\n", "        ", "\"\"\" Create batches \"\"\"", "\n", "if", "self", ".", "train", ":", "\n", "            ", "def", "_pool", "(", "data", ",", "random_shuffler", ")", ":", "\n", "                ", "for", "p", "in", "torchtext", ".", "data", ".", "batch", "(", "data", ",", "self", ".", "batch_size", "*", "100", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.DatasetLazyIter.__init__": [[432, 444], ["inputter.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.DatasetLazyIter._next_dataset_iterator"], ["    ", "\"\"\" An Ordered Dataset Iterator, supporting multiple datasets,\n        and lazy loading.\n\n    Args:\n        datsets (list): a list of datasets, which are lazily loaded.\n        fields (dict): fields dict for the datasets.\n        batch_size (int): batch size.\n        batch_size_fn: custom batch process function.\n        device: the GPU device.\n        is_train (bool): train or valid?\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.DatasetLazyIter.__iter__": [[445, 451], ["inputter.DatasetLazyIter._next_dataset_iterator"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.DatasetLazyIter._next_dataset_iterator"], ["device", ",", "is_train", ")", ":", "\n", "        ", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "batch_size_fn", "=", "batch_size_fn", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_train", "=", "is_train", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.DatasetLazyIter.__len__": [[452, 458], ["len"], "methods", ["None"], ["\n", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "datasets", ")", "\n", "# We have at least one dataset.", "\n", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "dataset_iter", "=", "(", "d", "for", "d", "in", "self", ".", "datasets", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.DatasetLazyIter.get_cur_dataset": [[459, 462], ["None"], "methods", ["None"], ["while", "self", ".", "cur_iter", "is", "not", "None", ":", "\n", "            ", "for", "batch", "in", "self", ".", "cur_iter", ":", "\n", "                ", "yield", "batch", "\n", "", "self", ".", "cur_iter", "=", "self", ".", "_next_dataset_iterator", "(", "dataset_iter", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.DatasetLazyIter._next_dataset_iterator": [[463, 480], ["inputter.OrderedIterator", "next"], "methods", ["None"], ["\n", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "# We return the len of cur_dataset, otherwise we need to load", "\n", "# all datasets to determine the real len, which loses the benefit", "\n", "# of lazy loading.", "\n", "        ", "assert", "self", ".", "cur_iter", "is", "not", "None", "\n", "return", "len", "(", "self", ".", "cur_iter", ")", "\n", "\n", "", "def", "get_cur_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return the current dataset settings \"\"\"", "\n", "return", "self", ".", "cur_dataset", "\n", "\n", "", "def", "_next_dataset_iterator", "(", "self", ",", "dataset_iter", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "cur_dataset", "=", "next", "(", "dataset_iter", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._getstate": [[21, 23], ["dict", "dict"], "function", ["None"], ["def", "_getstate", "(", "self", ")", ":", "\n", "    ", "return", "dict", "(", "self", ".", "__dict__", ",", "stoi", "=", "dict", "(", "self", ".", "stoi", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._setstate": [[25, 28], ["inputter..__dict__.update", "collections.defaultdict"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update"], ["", "def", "_setstate", "(", "self", ",", "state", ")", ":", "\n", "    ", "self", ".", "__dict__", ".", "update", "(", "state", ")", "\n", "self", ".", "stoi", "=", "defaultdict", "(", "lambda", ":", "0", ",", "self", ".", "stoi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.get_fields": [[34, 55], ["onmt.inputters.text_dataset.TextDataset.get_fields", "onmt.inputters.image_dataset.ImageDataset.get_fields", "onmt.inputters.audio_dataset.AudioDataset.get_fields", "ValueError"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_fields"], ["def", "get_fields", "(", "data_type", ",", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        data_type: type of the source input. Options are [text|img|audio].\n        n_src_features: the number of source features to\n            create `torchtext.data.Field` for.\n        n_tgt_features: the number of target features to\n            create `torchtext.data.Field` for.\n\n    Returns:\n        A dictionary whose keys are strings and whose values are the\n        corresponding Field objects.\n    \"\"\"", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "return", "TextDataset", ".", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", "\n", "", "elif", "data_type", "==", "'img'", ":", "\n", "        ", "return", "ImageDataset", ".", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "        ", "return", "AudioDataset", ".", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Data type not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.load_fields_from_vocab": [[57, 70], ["dict", "len", "len", "inputter.get_fields", "dict.items", "inputter.collect_features", "inputter.collect_features", "collections.defaultdict"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_features"], ["", "", "def", "load_fields_from_vocab", "(", "vocab", ",", "data_type", "=", "\"text\"", ")", ":", "\n", "    ", "\"\"\"\n    Load Field objects from `vocab.pt` file.\n    \"\"\"", "\n", "vocab", "=", "dict", "(", "vocab", ")", "\n", "n_src_features", "=", "len", "(", "collect_features", "(", "vocab", ",", "'src'", ")", ")", "\n", "n_tgt_features", "=", "len", "(", "collect_features", "(", "vocab", ",", "'tgt'", ")", ")", "\n", "fields", "=", "get_fields", "(", "data_type", ",", "n_src_features", ",", "n_tgt_features", ")", "\n", "for", "k", ",", "v", "in", "vocab", ".", "items", "(", ")", ":", "\n", "# Hack. Can't pickle defaultdict :(", "\n", "        ", "v", ".", "stoi", "=", "defaultdict", "(", "lambda", ":", "0", ",", "v", ".", "stoi", ")", "\n", "fields", "[", "k", "]", ".", "vocab", "=", "v", "\n", "", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.save_fields_to_vocab": [[72, 82], ["fields.items", "vocab.append"], "function", ["None"], ["", "def", "save_fields_to_vocab", "(", "fields", ")", ":", "\n", "    ", "\"\"\"\n    Save Vocab objects in Field objects to `vocab.pt` file.\n    \"\"\"", "\n", "vocab", "=", "[", "]", "\n", "for", "k", ",", "f", "in", "fields", ".", "items", "(", ")", ":", "\n", "        ", "if", "f", "is", "not", "None", "and", "'vocab'", "in", "f", ".", "__dict__", ":", "\n", "            ", "f", ".", "vocab", ".", "stoi", "=", "f", ".", "vocab", ".", "stoi", "\n", "vocab", ".", "append", "(", "(", "k", ",", "f", ".", "vocab", ")", ")", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.merge_vocabs": [[84, 99], ["sum", "torchtext.vocab.Vocab", "torchtext.vocab.Vocab", "collections.Counter"], "function", ["None"], ["", "def", "merge_vocabs", "(", "vocabs", ",", "vocab_size", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Merge individual vocabularies (assumed to be generated from disjoint\n    documents) into a larger vocabulary.\n\n    Args:\n        vocabs: `torchtext.vocab.Vocab` vocabularies to be merged\n        vocab_size: `int` the final vocabulary size. `None` for no limit.\n    Return:\n        `torchtext.vocab.Vocab`\n    \"\"\"", "\n", "merged", "=", "sum", "(", "[", "vocab", ".", "freqs", "for", "vocab", "in", "vocabs", "]", ",", "Counter", "(", ")", ")", "\n", "return", "torchtext", ".", "vocab", ".", "Vocab", "(", "merged", ",", "\n", "specials", "=", "[", "UNK_WORD", ",", "PAD_WORD", ",", "\n", "BOS_WORD", ",", "EOS_WORD", "]", ",", "\n", "max_size", "=", "vocab_size", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.get_num_features": [[101, 122], ["onmt.inputters.text_dataset.TextDataset.get_num_features", "onmt.inputters.image_dataset.ImageDataset.get_num_features", "onmt.inputters.audio_dataset.AudioDataset.get_num_features", "ValueError"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_num_features"], ["\n", "", "def", "get_num_features", "(", "data_type", ",", "corpus_file", ",", "side", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        data_type (str): type of the source input.\n            Options are [text|img|audio].\n        corpus_file (str): file path to get the features.\n        side (str): for source or for target.\n\n    Returns:\n        number of features on `side`.\n    \"\"\"", "\n", "assert", "side", "in", "[", "\"src\"", ",", "\"tgt\"", "]", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "return", "TextDataset", ".", "get_num_features", "(", "corpus_file", ",", "side", ")", "\n", "", "elif", "data_type", "==", "'img'", ":", "\n", "        ", "return", "ImageDataset", ".", "get_num_features", "(", "corpus_file", ",", "side", ")", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "        ", "return", "AudioDataset", ".", "get_num_features", "(", "corpus_file", ",", "side", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Data type not implemented\"", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features": [[124, 151], ["isinstance", "sorted", "torch.cat", "level.unsqueeze"], "function", ["None"], ["\n", "", "", "def", "make_features", "(", "batch", ",", "side", ",", "data_type", "=", "'text'", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        batch (Tensor): a batch of source or target data.\n        side (str): for source or for target.\n        data_type (str): type of the source input.\n            Options are [text|img|audio].\n    Returns:\n        A sequence of src/tgt tensors with optional feature tensors\n        of size (len x batch).\n    \"\"\"", "\n", "# changed for KE_KG", "\n", "assert", "side", "in", "[", "'src'", ",", "'tgt'", ",", "'key_indicators'", ",", "'retrieved_keys'", "]", "\n", "if", "isinstance", "(", "batch", ".", "__dict__", "[", "side", "]", ",", "tuple", ")", ":", "\n", "        ", "data", "=", "batch", ".", "__dict__", "[", "side", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "data", "=", "batch", ".", "__dict__", "[", "side", "]", "\n", "\n", "", "feat_start", "=", "side", "+", "\"_feat_\"", "\n", "keys", "=", "sorted", "(", "[", "k", "for", "k", "in", "batch", ".", "__dict__", "if", "feat_start", "in", "k", "]", ")", "\n", "features", "=", "[", "batch", ".", "__dict__", "[", "k", "]", "for", "k", "in", "keys", "]", "\n", "levels", "=", "[", "data", "]", "+", "features", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "[", "level", ".", "unsqueeze", "(", "2", ")", "for", "level", "in", "levels", "]", ",", "2", ")", "\n", "", "else", ":", "\n", "        ", "return", "levels", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_features": [[153, 165], ["itertools.count", "feats.append", "str"], "function", ["None"], ["\n", "", "", "def", "collect_features", "(", "fields", ",", "side", "=", "\"src\"", ")", ":", "\n", "    ", "\"\"\"\n    Collect features from Field object.\n    \"\"\"", "\n", "assert", "side", "in", "[", "\"src\"", ",", "\"tgt\"", "]", "\n", "feats", "=", "[", "]", "\n", "for", "j", "in", "count", "(", ")", ":", "\n", "        ", "key", "=", "side", "+", "\"_feat_\"", "+", "str", "(", "j", ")", "\n", "if", "key", "not", "in", "fields", ":", "\n", "            ", "break", "\n", "", "feats", ".", "append", "(", "key", ")", "\n", "", "return", "feats", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_feature_vocabs": [[167, 179], ["itertools.count", "feature_vocabs.append", "str"], "function", ["None"], ["\n", "", "def", "collect_feature_vocabs", "(", "fields", ",", "side", ")", ":", "\n", "    ", "\"\"\"\n    Collect feature Vocab objects from Field object.\n    \"\"\"", "\n", "assert", "side", "in", "[", "'src'", ",", "'tgt'", "]", "\n", "feature_vocabs", "=", "[", "]", "\n", "for", "j", "in", "count", "(", ")", ":", "\n", "        ", "key", "=", "side", "+", "\"_feat_\"", "+", "str", "(", "j", ")", "\n", "if", "key", "not", "in", "fields", ":", "\n", "            ", "break", "\n", "", "feature_vocabs", ".", "append", "(", "fields", "[", "key", "]", ".", "vocab", ")", "\n", "", "return", "feature_vocabs", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset": [[181, 273], ["inputter.build_dataset._make_examples_nfeats_tpl"], "function", ["None"], ["\n", "", "def", "build_dataset", "(", "fields", ",", "data_type", ",", "src_data_iter", "=", "None", ",", "src_path", "=", "None", ",", "\n", "rk_path", "=", "None", ",", "rk_data_iter", "=", "None", ",", "\n", "key_indicator_iter", "=", "None", ",", "key_indicator_path", "=", "None", ",", "\n", "src_dir", "=", "None", ",", "tgt_data_iter", "=", "None", ",", "tgt_path", "=", "None", ",", "\n", "src_seq_length", "=", "0", ",", "tgt_seq_length", "=", "0", ",", "\n", "src_seq_length_trunc", "=", "0", ",", "tgt_seq_length_trunc", "=", "0", ",", "\n", "dynamic_dict", "=", "True", ",", "sample_rate", "=", "0", ",", "\n", "window_size", "=", "0", ",", "window_stride", "=", "0", ",", "window", "=", "None", ",", "\n", "normalize_audio", "=", "True", ",", "use_filter_pred", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Build src/tgt examples iterator from corpus files, also extract\n    number of features.\n    \"\"\"", "\n", "def", "_make_examples_nfeats_tpl", "(", "data_type", ",", "src_data_iter", ",", "src_path", ",", "src_dir", ",", "\n", "src_seq_length_trunc", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "\n", "window", ",", "normalize_audio", ")", ":", "\n", "        ", "\"\"\"\n        Process the corpus into (example_dict iterator, num_feats) tuple\n        on source side for different 'data_type'.\n        \"\"\"", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "src_examples_iter", ",", "num_src_feats", "=", "TextDataset", ".", "make_text_examples_nfeats_tpl", "(", "\n", "src_data_iter", ",", "src_path", ",", "src_seq_length_trunc", ",", "\"src\"", ")", "\n", "\n", "", "elif", "data_type", "==", "'img'", ":", "\n", "            ", "src_examples_iter", ",", "num_src_feats", "=", "ImageDataset", ".", "make_image_examples_nfeats_tpl", "(", "\n", "src_data_iter", ",", "src_path", ",", "src_dir", ")", "\n", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "            ", "if", "src_data_iter", ":", "\n", "                ", "raise", "ValueError", "(", "\"\"\"Data iterator for AudioDataset isn't\n                                    implemented\"\"\"", ")", "\n", "\n", "", "if", "src_path", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"AudioDataset requires a non None path\"", ")", "\n", "", "src_examples_iter", ",", "num_src_feats", "=", "AudioDataset", ".", "make_audio_examples_nfeats_tpl", "(", "\n", "src_path", ",", "src_dir", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "window", ",", "\n", "normalize_audio", ")", "\n", "\n", "", "return", "src_examples_iter", ",", "num_src_feats", "\n", "\n", "", "src_examples_iter", ",", "num_src_feats", "=", "_make_examples_nfeats_tpl", "(", "data_type", ",", "src_data_iter", ",", "src_path", ",", "src_dir", ",", "\n", "src_seq_length_trunc", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "\n", "window", ",", "normalize_audio", ")", "\n", "\n", "# add for key_indicator", "\n", "key_indicator_examples_iter", ",", "num_key_indicator_feats", "=", "TextDataset", ".", "make_text_examples_nfeats_tpl", "(", "\n", "key_indicator_iter", ",", "key_indicator_path", ",", "src_seq_length_trunc", ",", "\"key_indicator\"", ")", "\n", "\n", "# add for RK", "\n", "rk_examples_iter", ",", "num_rk_feats", "=", "TextDataset", ".", "make_text_examples_nfeats_tpl", "(", "\n", "rk_data_iter", ",", "rk_path", ",", "0", ",", "\"retrieved_keys\"", ")", "\n", "\n", "# For all data types, the tgt side corpus is in form of text.", "\n", "tgt_examples_iter", ",", "num_tgt_feats", "=", "TextDataset", ".", "make_text_examples_nfeats_tpl", "(", "\n", "tgt_data_iter", ",", "tgt_path", ",", "tgt_seq_length_trunc", ",", "\"tgt\"", ")", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "# (self, fields, src_examples_iter, key_indicators_iter, retrieved_keys_iter, tgt_examples_iter,", "\n", "#  num_src_feats=0, num_tgt_feats=0,", "\n", "#  src_seq_length=0, tgt_seq_length=0,", "\n", "#  dynamic_dict=True, use_filter_pred=True)", "\n", "        ", "dataset", "=", "TextDataset", "(", "fields", ",", "src_examples_iter", ",", "key_indicator_examples_iter", ",", "\n", "rk_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", ",", "num_tgt_feats", ",", "\n", "src_seq_length", "=", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "tgt_seq_length", ",", "\n", "dynamic_dict", "=", "dynamic_dict", ",", "\n", "use_filter_pred", "=", "use_filter_pred", ")", "\n", "\n", "", "elif", "data_type", "==", "'img'", ":", "\n", "        ", "dataset", "=", "ImageDataset", "(", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", ",", "num_tgt_feats", ",", "\n", "tgt_seq_length", "=", "tgt_seq_length", ",", "\n", "use_filter_pred", "=", "use_filter_pred", ")", "\n", "\n", "", "elif", "data_type", "==", "'audio'", ":", "\n", "        ", "dataset", "=", "AudioDataset", "(", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", ",", "num_tgt_feats", ",", "\n", "tgt_seq_length", "=", "tgt_seq_length", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._build_field_vocab": [[275, 281], ["list", "field.vocab_cls", "collections.OrderedDict.fromkeys"], "function", ["None"], ["window_stride", "=", "window_stride", ",", "\n", "window", "=", "window", ",", "\n", "normalize_audio", "=", "normalize_audio", ",", "\n", "use_filter_pred", "=", "use_filter_pred", ")", "\n", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_vocab": [[283, 370], ["inputter.load_vocabulary", "inputter.load_vocabulary", "inputter._build_field_vocab", "onmt.utils.logging.logger.info", "range", "collections.Counter", "torch.load", "onmt.utils.logging.logger.info", "inputter._build_field_vocab", "onmt.utils.logging.logger.info", "inputter._build_field_vocab", "onmt.utils.logging.logger.info", "inputter._build_field_vocab", "onmt.utils.logging.logger.info", "range", "len", "str", "inputter._build_field_vocab", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "inputter.merge_vocabs", "getattr", "counter[].update", "len", "len", "str", "len", "len"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.load_vocabulary", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.load_vocabulary", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._build_field_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._build_field_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._build_field_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._build_field_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._build_field_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.merge_vocabs", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update"], ["", "def", "_build_field_vocab", "(", "field", ",", "counter", ",", "**", "kwargs", ")", ":", "\n", "    ", "specials", "=", "list", "(", "OrderedDict", ".", "fromkeys", "(", "\n", "tok", "for", "tok", "in", "[", "field", ".", "unk_token", ",", "field", ".", "pad_token", ",", "field", ".", "init_token", ",", "\n", "field", ".", "eos_token", "]", "\n", "if", "tok", "is", "not", "None", ")", ")", "\n", "field", ".", "vocab", "=", "field", ".", "vocab_cls", "(", "counter", ",", "specials", "=", "specials", ",", "**", "kwargs", ")", "\n", "\n", "\n", "", "def", "build_vocab", "(", "train_dataset_files", ",", "fields", ",", "data_type", ",", "share_vocab", ",", "\n", "src_vocab_path", ",", "src_vocab_size", ",", "src_words_min_frequency", ",", "\n", "tgt_vocab_path", ",", "tgt_vocab_size", ",", "tgt_words_min_frequency", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        train_dataset_files: a list of train dataset pt file.\n        fields (dict): fields to build vocab for.\n        data_type: \"text\", \"img\" or \"audio\"?\n        share_vocab(bool): share source and target vocabulary?\n        src_vocab_path(string): Path to src vocabulary file.\n        src_vocab_size(int): size of the source vocabulary.\n        src_words_min_frequency(int): the minimum frequency needed to\n                include a source word in the vocabulary.\n        tgt_vocab_path(string): Path to tgt vocabulary file.\n        tgt_vocab_size(int): size of the target vocabulary.\n        tgt_words_min_frequency(int): the minimum frequency needed to\n                include a target word in the vocabulary.\n\n    Returns:\n        Dict of Fields\n    \"\"\"", "\n", "counter", "=", "{", "}", "\n", "for", "k", "in", "fields", ":", "\n", "        ", "counter", "[", "k", "]", "=", "Counter", "(", ")", "\n", "\n", "# Load vocabulary", "\n", "", "src_vocab", "=", "load_vocabulary", "(", "src_vocab_path", ",", "tag", "=", "\"source\"", ")", "\n", "tgt_vocab", "=", "load_vocabulary", "(", "tgt_vocab_path", ",", "tag", "=", "\"target\"", ")", "\n", "\n", "for", "path", "in", "train_dataset_files", ":", "\n", "        ", "dataset", "=", "torch", ".", "load", "(", "path", ")", "\n", "logger", ".", "info", "(", "\" * reloading %s.\"", "%", "path", ")", "\n", "for", "ex", "in", "dataset", ".", "examples", ":", "\n", "            ", "for", "k", "in", "fields", ":", "\n", "                ", "val", "=", "getattr", "(", "ex", ",", "k", ",", "None", ")", "\n", "if", "val", "is", "not", "None", "and", "not", "fields", "[", "k", "]", ".", "sequential", ":", "\n", "                    ", "val", "=", "[", "val", "]", "\n", "", "elif", "k", "==", "'src'", "and", "src_vocab", ":", "\n", "                    ", "val", "=", "[", "item", "for", "item", "in", "val", "if", "item", "in", "src_vocab", "]", "\n", "", "elif", "k", "==", "'tgt'", "and", "tgt_vocab", ":", "\n", "                    ", "val", "=", "[", "item", "for", "item", "in", "val", "if", "item", "in", "tgt_vocab", "]", "\n", "", "counter", "[", "k", "]", ".", "update", "(", "val", ")", "\n", "\n", "", "", "", "_build_field_vocab", "(", "fields", "[", "\"tgt\"", "]", ",", "counter", "[", "\"tgt\"", "]", ",", "\n", "max_size", "=", "tgt_vocab_size", ",", "\n", "min_freq", "=", "tgt_words_min_frequency", ")", "\n", "logger", ".", "info", "(", "\" * tgt vocab size: %d.\"", "%", "len", "(", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", ")", "\n", "\n", "# All datasets have same num of n_tgt_features,", "\n", "# getting the last one is OK.", "\n", "for", "j", "in", "range", "(", "dataset", ".", "n_tgt_feats", ")", ":", "\n", "        ", "key", "=", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "\n", "_build_field_vocab", "(", "fields", "[", "key", "]", ",", "counter", "[", "key", "]", ")", "\n", "logger", ".", "info", "(", "\" * %s vocab size: %d.\"", "%", "(", "key", ",", "\n", "len", "(", "fields", "[", "key", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "", "if", "data_type", "==", "'text'", ":", "\n", "        ", "_build_field_vocab", "(", "fields", "[", "\"src\"", "]", ",", "counter", "[", "\"src\"", "]", ",", "\n", "max_size", "=", "src_vocab_size", ",", "\n", "min_freq", "=", "src_words_min_frequency", ")", "\n", "logger", ".", "info", "(", "\" * src vocab size: %d.\"", "%", "len", "(", "fields", "[", "\"src\"", "]", ".", "vocab", ")", ")", "\n", "\n", "# KE-KG-KR-M: add for KE", "\n", "_build_field_vocab", "(", "fields", "[", "\"key_indicators\"", "]", ",", "counter", "[", "\"key_indicators\"", "]", ",", "\n", "max_size", "=", "3", ",", "\n", "min_freq", "=", "1", ")", "\n", "logger", ".", "info", "(", "\" * key_indicators vocab size: %d.\"", "%", "len", "(", "fields", "[", "\"key_indicators\"", "]", ".", "vocab", ")", ")", "\n", "\n", "# All datasets have same num of n_src_features,", "\n", "# getting the last one is OK.", "\n", "for", "j", "in", "range", "(", "dataset", ".", "n_src_feats", ")", ":", "\n", "            ", "key", "=", "\"src_feat_\"", "+", "str", "(", "j", ")", "\n", "_build_field_vocab", "(", "fields", "[", "key", "]", ",", "counter", "[", "key", "]", ")", "\n", "logger", ".", "info", "(", "\" * %s vocab size: %d.\"", "%", "\n", "(", "key", ",", "len", "(", "fields", "[", "key", "]", ".", "vocab", ")", ")", ")", "\n", "\n", "# Merge the input and output vocabularies.", "\n", "", "if", "share_vocab", ":", "\n", "# `tgt_vocab_size` is ignored when sharing vocabularies", "\n", "            ", "logger", ".", "info", "(", "\" * merging src and tgt vocab...\"", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.load_vocabulary": [[372, 396], ["set", "onmt.utils.logging.logger.info", "os.path.exists", "RuntimeError", "open", "set.add", "len", "line.strip().split", "line.strip", "line.strip"], "function", ["None"], ["[", "fields", "[", "\"src\"", "]", ".", "vocab", ",", "fields", "[", "\"tgt\"", "]", ".", "vocab", "]", ",", "\n", "vocab_size", "=", "src_vocab_size", ")", "\n", "fields", "[", "\"src\"", "]", ".", "vocab", "=", "merged_vocab", "\n", "fields", "[", "\"tgt\"", "]", ".", "vocab", "=", "merged_vocab", "\n", "\n", "# KE-KG-KR-M: add for RK", "\n", "# keep the vocabs of the retrieved keyphrases the same with the src", "\n", "", "fields", "[", "'retrieved_keys'", "]", ".", "vocab", "=", "fields", "[", "'src'", "]", ".", "vocab", "\n", "\n", "", "return", "fields", "\n", "\n", "\n", "", "def", "load_vocabulary", "(", "vocabulary_path", ",", "tag", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"\n    Loads a vocabulary from the given path.\n    :param vocabulary_path: path to load vocabulary from\n    :param tag: tag for vocabulary (only used for logging)\n    :return: vocabulary or None if path is null\n    \"\"\"", "\n", "vocabulary", "=", "None", "\n", "if", "vocabulary_path", ":", "\n", "        ", "vocabulary", "=", "set", "(", "[", "]", ")", "\n", "logger", ".", "info", "(", "\"Loading {} vocabulary from {}\"", ".", "format", "(", "tag", ",", "\n", "vocabulary_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset_iter": [[482, 520], ["inputter.DatasetLazyIter", "max", "max", "max", "len", "len"], "function", ["None"], ["", "self", ".", "cur_dataset", ".", "fields", "=", "self", ".", "fields", "\n", "\n", "# Sort batch by decreasing lengths of sentence required by pytorch.", "\n", "# sort=False means \"Use dataset's sortkey instead of iterator's\".", "\n", "return", "OrderedIterator", "(", "\n", "dataset", "=", "self", ".", "cur_dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "batch_size_fn", "=", "self", ".", "batch_size_fn", ",", "\n", "device", "=", "self", ".", "device", ",", "train", "=", "self", ".", "is_train", ",", "\n", "sort", "=", "False", ",", "sort_within_batch", "=", "True", ",", "\n", "repeat", "=", "False", ")", "\n", "\n", "\n", "", "", "def", "build_dataset_iter", "(", "datasets", ",", "fields", ",", "opt", ",", "is_train", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    This returns user-defined train/validate data iterator for the trainer\n    to iterate over. We implement simple ordered iterator strategy here,\n    but more sophisticated strategy like curriculum learning is ok too.\n    \"\"\"", "\n", "batch_size", "=", "opt", ".", "batch_size", "if", "is_train", "else", "opt", ".", "valid_batch_size", "\n", "if", "is_train", "and", "opt", ".", "batch_type", "==", "\"tokens\"", ":", "\n", "        ", "def", "batch_size_fn", "(", "new", ",", "count", ",", "sofar", ")", ":", "\n", "            ", "\"\"\"\n            In token batching scheme, the number of sequences is limited\n            such that the total number of src/tgt tokens (including padding)\n            in a batch <= batch_size\n            \"\"\"", "\n", "# Maintains the longest src and tgt length in the current batch", "\n", "global", "max_src_in_batch", ",", "max_tgt_in_batch", "\n", "# Reset current longest length at a new batch (count=1)", "\n", "if", "count", "==", "1", ":", "\n", "                ", "max_src_in_batch", "=", "0", "\n", "max_tgt_in_batch", "=", "0", "\n", "# Src: <bos> w1 ... wN <eos>", "\n", "", "max_src_in_batch", "=", "max", "(", "max_src_in_batch", ",", "len", "(", "new", ".", "src", ")", "+", "2", ")", "\n", "# Tgt: w1 ... wN <eos>", "\n", "max_tgt_in_batch", "=", "max", "(", "max_tgt_in_batch", ",", "len", "(", "new", ".", "tgt", ")", "+", "1", ")", "\n", "src_elements", "=", "count", "*", "max_src_in_batch", "\n", "tgt_elements", "=", "count", "*", "max_tgt_in_batch", "\n", "return", "max", "(", "src_elements", ",", "tgt_elements", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.lazily_load_dataset": [[522, 549], ["sorted", "torch.load", "onmt.utils.logging.logger.info", "glob.glob", "inputter.lazily_load_dataset._lazy_dataset_loader"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load"], ["        ", "batch_size_fn", "=", "None", "\n", "# device = opt.device_id if opt.gpuid else -1", "\n", "# breaking change torchtext 0.3", "\n", "", "if", "opt", ".", "gpuid", ":", "\n", "        ", "device", "=", "\"cuda\"", "\n", "", "else", ":", "\n", "        ", "device", "=", "\"cpu\"", "\n", "\n", "", "return", "DatasetLazyIter", "(", "datasets", ",", "fields", ",", "batch_size", ",", "batch_size_fn", ",", "\n", "device", ",", "is_train", ")", "\n", "\n", "\n", "", "def", "lazily_load_dataset", "(", "corpus_type", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Dataset generator. Don't do extra stuff here, like printing,\n    because they will be postponed to the first loading time.\n\n    Args:\n        corpus_type: 'train' or 'valid'\n    Returns:\n        A list of dataset, the dataset(s) are lazily loaded.\n    \"\"\"", "\n", "assert", "corpus_type", "in", "[", "\"train\"", ",", "\"valid\"", "]", "\n", "\n", "def", "_lazy_dataset_loader", "(", "pt_file", ",", "corpus_type", ")", ":", "\n", "        ", "dataset", "=", "torch", ".", "load", "(", "pt_file", ")", "\n", "logger", ".", "info", "(", "'Loading %s dataset from %s, number of examples: %d'", "%", "\n", "(", "corpus_type", ",", "pt_file", ",", "len", "(", "dataset", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._load_fields": [[551, 572], ["dict", "onmt.utils.logging.logger.info", "inputter.load_fields_from_vocab", "inputter.load_fields_from_vocab", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "torch.load", "load_fields_from_vocab.items", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.load_fields_from_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.load_fields_from_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load"], ["\n", "# Sort the glob output by file name (by increasing indexes).", "\n", "", "pts", "=", "sorted", "(", "glob", ".", "glob", "(", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.[0-9]*.pt'", ")", ")", "\n", "if", "pts", ":", "\n", "        ", "for", "pt", "in", "pts", ":", "\n", "            ", "yield", "_lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "", "", "else", ":", "\n", "# Only one inputters.*Dataset, simple!", "\n", "        ", "pt", "=", "opt", ".", "data", "+", "'.'", "+", "corpus_type", "+", "'.pt'", "\n", "yield", "_lazy_dataset_loader", "(", "pt", ",", "corpus_type", ")", "\n", "\n", "\n", "", "", "def", "_load_fields", "(", "dataset", ",", "data_type", ",", "opt", ",", "checkpoint", ")", ":", "\n", "    ", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "'Loading vocab from checkpoint at %s.'", "%", "opt", ".", "train_from", ")", "\n", "fields", "=", "load_fields_from_vocab", "(", "\n", "checkpoint", "[", "'vocab'", "]", ",", "data_type", ")", "\n", "", "else", ":", "\n", "# changed for KE_KG", "\n", "# opt.data + '.vocab.pt' -> opt.vocab + '.vocab.pt'", "\n", "        ", "fields", "=", "load_fields_from_vocab", "(", "\n", "torch", ".", "load", "(", "opt", ".", "vocab", "+", "'.vocab.pt'", ")", ",", "data_type", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter._collect_report_features": [[574, 579], ["inputter.collect_features", "inputter.collect_features"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.collect_features"], ["if", "k", "in", "dataset", ".", "examples", "[", "0", "]", ".", "__dict__", "]", ")", "\n", "\n", "if", "data_type", "==", "'text'", ":", "\n", "        ", "logger", ".", "info", "(", "' * vocabulary size. source = %d; target = %d'", "%", "\n", "(", "len", "(", "fields", "[", "'src'", "]", ".", "vocab", ")", ",", "len", "(", "fields", "[", "'tgt'", "]", ".", "vocab", ")", ")", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.__getstate__": [[31, 33], ["None"], "methods", ["None"], ["def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.__setstate__": [[34, 36], ["dataset_base.DatasetBase.__dict__.update"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.update"], ["", "def", "__setstate__", "(", "self", ",", "_d", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "_d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.__reduce_ex__": [[37, 40], ["super().__reduce_ex__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.__reduce_ex__"], ["", "def", "__reduce_ex__", "(", "self", ",", "proto", ")", ":", "\n", "        ", "\"This is a hack. Something is broken with torch pickle.\"", "\n", "return", "super", "(", "DatasetBase", ",", "self", ")", ".", "__reduce_ex__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.load_fields": [[41, 51], ["onmt.inputters.inputter.load_fields_from_vocab", "dict", "vocab_dict.items", "onmt.inputters.inputter.load_fields_from_vocab.items"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.load_fields_from_vocab"], ["", "def", "load_fields", "(", "self", ",", "vocab_dict", ")", ":", "\n", "        ", "\"\"\" Load fields from vocab.pt, and set the `fields` attribute.\n\n        Args:\n            vocab_dict (dict): a dict of loaded vocab from vocab.pt file.\n        \"\"\"", "\n", "fields", "=", "onmt", ".", "inputters", ".", "inputter", ".", "load_fields_from_vocab", "(", "\n", "vocab_dict", ".", "items", "(", ")", ",", "self", ".", "data_type", ")", "\n", "self", ".", "fields", "=", "dict", "(", "[", "(", "k", ",", "f", ")", "for", "(", "k", ",", "f", ")", "in", "fields", ".", "items", "(", ")", "\n", "if", "k", "in", "self", ".", "examples", "[", "0", "]", ".", "__dict__", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.extract_text_features": [[52, 75], ["len", "all", "list", "token.split", "zip", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "extract_text_features", "(", "tokens", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tokens: A list of tokens, where each token consists of a word,\n                optionally followed by u\"\uffe8\"-delimited features.\n        Returns:\n            A sequence of words, a sequence of features, and num of features.\n        \"\"\"", "\n", "if", "not", "tokens", ":", "\n", "            ", "return", "[", "]", ",", "[", "]", ",", "-", "1", "\n", "\n", "", "split_tokens", "=", "[", "token", ".", "split", "(", "u\"\uffe8\"", ")", "for", "token", "in", "tokens", "]", "\n", "split_tokens", "=", "[", "token", "for", "token", "in", "split_tokens", "if", "token", "[", "0", "]", "]", "\n", "token_size", "=", "len", "(", "split_tokens", "[", "0", "]", ")", "\n", "\n", "assert", "all", "(", "len", "(", "token", ")", "==", "token_size", "for", "token", "in", "split_tokens", ")", ",", "\"all words must have the same number of features\"", "\n", "words_and_features", "=", "list", "(", "zip", "(", "*", "split_tokens", ")", ")", "\n", "words", "=", "words_and_features", "[", "0", "]", "\n", "features", "=", "words_and_features", "[", "1", ":", "]", "\n", "\n", "return", "words", ",", "features", ",", "token_size", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._join_dicts": [[78, 87], ["dict", "itertools.chain", "d.items"], "methods", ["None"], ["", "def", "_join_dicts", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dictionaries with disjoint keys.\n\n        Returns:\n            a single dictionary that has the union of these keys.\n        \"\"\"", "\n", "return", "dict", "(", "chain", "(", "*", "[", "d", ".", "items", "(", ")", "for", "d", "in", "args", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._peek": [[88, 100], ["next", "itertools.chain"], "methods", ["None"], ["", "def", "_peek", "(", "self", ",", "seq", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            seq: an iterator.\n\n        Returns:\n            the first thing returned by calling next() on the iterator\n            and an iterator created by re-chaining that value to the beginning\n            of the iterator.\n        \"\"\"", "\n", "first", "=", "next", "(", "seq", ")", "\n", "return", "first", ",", "chain", "(", "[", "first", "]", ",", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._construct_example_fromlist": [[101, 120], ["torchtext.data.Example", "zip", "setattr", "setattr", "field.preprocess"], "methods", ["None"], ["", "def", "_construct_example_fromlist", "(", "self", ",", "data", ",", "fields", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            data: the data to be set as the value of the attributes of\n                the to-be-created `Example`, associating with respective\n                `Field` objects with same key.\n            fields: a dict of `torchtext.data.Field` objects. The keys\n                are attributes of the to-be-created `Example`.\n\n        Returns:\n            the created `Example` object.\n        \"\"\"", "\n", "ex", "=", "torchtext", ".", "data", ".", "Example", "(", ")", "\n", "for", "(", "name", ",", "field", ")", ",", "val", "in", "zip", "(", "fields", ",", "data", ")", ":", "\n", "            ", "if", "field", "is", "not", "None", ":", "\n", "                ", "setattr", "(", "ex", ",", "name", ",", "field", ".", "preprocess", "(", "val", ")", ")", "\n", "", "else", ":", "\n", "                ", "setattr", "(", "ex", ",", "name", ",", "val", ")", "\n", "", "", "return", "ex", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.__init__": [[40, 88], ["audio_dataset.AudioDataset._peek", "ex.keys", "list", "onmt.inputters.dataset_base.DatasetBase.__init__", "audio_dataset.AudioDataset._construct_example_fromlist", "audio_dataset.AudioDataset._join_dicts", "zip", "len"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._peek", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._construct_example_fromlist", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase._join_dicts"], ["def", "__init__", "(", "self", ",", "fields", ",", "src_examples_iter", ",", "tgt_examples_iter", ",", "\n", "num_src_feats", "=", "0", ",", "num_tgt_feats", "=", "0", ",", "\n", "tgt_seq_length", "=", "0", ",", "sample_rate", "=", "0", ",", "\n", "window_size", "=", "0.0", ",", "window_stride", "=", "0.0", ",", "window", "=", "None", ",", "\n", "normalize_audio", "=", "True", ",", "use_filter_pred", "=", "True", ")", ":", "\n", "        ", "self", ".", "data_type", "=", "'audio'", "\n", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "window_stride", "=", "window_stride", "\n", "self", ".", "window", "=", "window", "\n", "self", ".", "normalize_audio", "=", "normalize_audio", "\n", "\n", "self", ".", "n_src_feats", "=", "num_src_feats", "\n", "self", ".", "n_tgt_feats", "=", "num_tgt_feats", "\n", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "            ", "examples_iter", "=", "(", "self", ".", "_join_dicts", "(", "src", ",", "tgt", ")", "for", "src", ",", "tgt", "in", "\n", "zip", "(", "src_examples_iter", ",", "tgt_examples_iter", ")", ")", "\n", "", "else", ":", "\n", "            ", "examples_iter", "=", "src_examples_iter", "\n", "\n", "# Peek at the first to see which fields are used.", "\n", "", "ex", ",", "examples_iter", "=", "self", ".", "_peek", "(", "examples_iter", ")", "\n", "keys", "=", "ex", ".", "keys", "(", ")", "\n", "\n", "out_fields", "=", "[", "(", "k", ",", "fields", "[", "k", "]", ")", "if", "k", "in", "fields", "else", "(", "k", ",", "None", ")", "\n", "for", "k", "in", "keys", "]", "\n", "example_values", "=", "(", "[", "ex", "[", "k", "]", "for", "k", "in", "keys", "]", "for", "ex", "in", "examples_iter", ")", "\n", "out_examples", "=", "(", "self", ".", "_construct_example_fromlist", "(", "\n", "ex_values", ",", "out_fields", ")", "\n", "for", "ex_values", "in", "example_values", ")", "\n", "# If out_examples is a generator, we need to save the filter_pred", "\n", "# function in serialization too, which would cause a problem when", "\n", "# `torch.save()`. Thus we materialize it as a list.", "\n", "out_examples", "=", "list", "(", "out_examples", ")", "\n", "\n", "def", "filter_pred", "(", "example", ")", ":", "\n", "            ", "\"\"\"    ?    \"\"\"", "\n", "if", "tgt_examples_iter", "is", "not", "None", ":", "\n", "                ", "return", "0", "<", "len", "(", "example", ".", "tgt", ")", "<=", "tgt_seq_length", "\n", "", "else", ":", "\n", "                ", "return", "True", "\n", "\n", "", "", "filter_pred", "=", "filter_pred", "if", "use_filter_pred", "else", "lambda", "x", ":", "True", "\n", "\n", "super", "(", "AudioDataset", ",", "self", ")", ".", "__init__", "(", "\n", "out_examples", ",", "out_fields", ",", "filter_pred", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.sort_key": [[90, 93], ["ex.src.size"], "methods", ["None"], ["", "def", "sort_key", "(", "self", ",", "ex", ")", ":", "\n", "        ", "\"\"\" Sort using duration time of the sound spectrogram. \"\"\"", "\n", "return", "ex", ".", "src", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.make_audio_examples_nfeats_tpl": [[94, 121], ["audio_dataset.AudioDataset.read_audio_file"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.read_audio_file"], ["", "@", "staticmethod", "\n", "def", "make_audio_examples_nfeats_tpl", "(", "path", ",", "audio_dir", ",", "\n", "sample_rate", ",", "window_size", ",", "\n", "window_stride", ",", "window", ",", "\n", "normalize_audio", ",", "truncate", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src file containing audio paths.\n            audio_dir (str): location of source audio files.\n            sample_rate (int): sample_rate.\n            window_size (float) : window size for spectrogram in seconds.\n            window_stride (float): window stride for spectrogram in seconds.\n            window (str): window type for spectrogram generation.\n            normalize_audio (bool): subtract spectrogram by mean and divide\n                by std or not.\n            truncate (int): maximum audio length (0 or None for unlimited).\n\n        Returns:\n            (example_dict iterator, num_feats) tuple\n        \"\"\"", "\n", "examples_iter", "=", "AudioDataset", ".", "read_audio_file", "(", "\n", "path", ",", "audio_dir", ",", "\"src\"", ",", "sample_rate", ",", "\n", "window_size", ",", "window_stride", ",", "window", ",", "\n", "normalize_audio", ",", "truncate", ")", "\n", "num_feats", "=", "0", "# Source side(audio) has no features.", "\n", "\n", "return", "(", "examples_iter", ",", "num_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.read_audio_file": [[122, 196], ["os.path.exists", "codecs.open", "os.path.join", "os.path.exists", "torchaudio.load", "sound.mean.mean.numpy", "int", "int", "librosa.stft", "librosa.magphase", "np.log1p", "torch.FloatTensor", "line.strip", "os.path.exists", "line.strip", "len", "torch.FloatTensor.mean", "torch.FloatTensor.std", "torch.FloatTensor.add_", "torch.FloatTensor.div_", "line.strip", "sound.mean.mean.size", "sound.mean.mean.squeeze", "sound.mean.mean.mean"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load"], ["", "@", "staticmethod", "\n", "def", "read_audio_file", "(", "path", ",", "src_dir", ",", "side", ",", "sample_rate", ",", "window_size", ",", "\n", "window_stride", ",", "window", ",", "normalize_audio", ",", "\n", "truncate", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            path (str): location of a src file containing audio paths.\n            src_dir (str): location of source audio files.\n            side (str): 'src' or 'tgt'.\n            sample_rate (int): sample_rate.\n            window_size (float) : window size for spectrogram in seconds.\n            window_stride (float): window stride for spectrogram in seconds.\n            window (str): window type for spectrogram generation.\n            normalize_audio (bool): subtract spectrogram by mean and divide\n                by std or not.\n            truncate (int): maximum audio length (0 or None for unlimited).\n\n        Yields:\n            a dictionary containing audio data for each line.\n        \"\"\"", "\n", "assert", "(", "src_dir", "is", "not", "None", ")", "and", "os", ".", "path", ".", "exists", "(", "src_dir", ")", ",", "\"src_dir must be a valid directory if data_type is audio\"", "\n", "\n", "import", "torchaudio", "\n", "import", "librosa", "\n", "import", "numpy", "as", "np", "\n", "\n", "with", "codecs", ".", "open", "(", "path", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "corpus_file", ":", "\n", "            ", "index", "=", "0", "\n", "for", "line", "in", "corpus_file", ":", "\n", "                ", "audio_path", "=", "os", ".", "path", ".", "join", "(", "src_dir", ",", "line", ".", "strip", "(", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "audio_path", ")", ":", "\n", "                    ", "audio_path", "=", "line", "\n", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "audio_path", ")", ",", "'audio path %s not found'", "%", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "sound", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "audio_path", ")", "\n", "if", "truncate", "and", "truncate", ">", "0", ":", "\n", "                    ", "if", "sound", ".", "size", "(", "0", ")", ">", "truncate", ":", "\n", "                        ", "continue", "\n", "\n", "", "", "assert", "sample_rate", "==", "sample_rate", ",", "'Sample rate of %s != -sample_rate (%d vs %d)'", "%", "(", "audio_path", ",", "sample_rate", ",", "sample_rate", ")", "\n", "\n", "sound", "=", "sound", ".", "numpy", "(", ")", "\n", "if", "len", "(", "sound", ".", "shape", ")", ">", "1", ":", "\n", "                    ", "if", "sound", ".", "shape", "[", "1", "]", "==", "1", ":", "\n", "                        ", "sound", "=", "sound", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "                        ", "sound", "=", "sound", ".", "mean", "(", "axis", "=", "1", ")", "# average multiple channels", "\n", "\n", "", "", "n_fft", "=", "int", "(", "sample_rate", "*", "window_size", ")", "\n", "win_length", "=", "n_fft", "\n", "hop_length", "=", "int", "(", "sample_rate", "*", "window_stride", ")", "\n", "# STFT", "\n", "d", "=", "librosa", ".", "stft", "(", "sound", ",", "n_fft", "=", "n_fft", ",", "hop_length", "=", "hop_length", ",", "\n", "win_length", "=", "win_length", ",", "window", "=", "window", ")", "\n", "spect", ",", "_", "=", "librosa", ".", "magphase", "(", "d", ")", "\n", "spect", "=", "np", ".", "log1p", "(", "spect", ")", "\n", "spect", "=", "torch", ".", "FloatTensor", "(", "spect", ")", "\n", "if", "normalize_audio", ":", "\n", "                    ", "mean", "=", "spect", ".", "mean", "(", ")", "\n", "std", "=", "spect", ".", "std", "(", ")", "\n", "spect", ".", "add_", "(", "-", "mean", ")", "\n", "spect", ".", "div_", "(", "std", ")", "\n", "\n", "", "example_dict", "=", "{", "side", ":", "spect", ",", "\n", "side", "+", "'_path'", ":", "line", ".", "strip", "(", ")", ",", "\n", "'indices'", ":", "index", "}", "\n", "index", "+=", "1", "\n", "\n", "yield", "example_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_fields": [[197, 269], ["torchtext.data.Field", "range", "torchtext.data.Field", "range", "torchtext.data.Field", "torchtext.data.Field", "torchtext.data.Field", "data[].size", "max", "torch.zeros", "enumerate", "torchtext.data.Field", "torchtext.data.Field", "max", "torch.zeros", "enumerate", "max", "torch.zeros().long", "enumerate", "len", "max", "len", "enumerate", "max.size", "max.size", "max.size", "torch.zeros", "str", "str", "max.max", "len", "spect.size", "sent.size"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "get_fields", "(", "n_src_features", ",", "n_tgt_features", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            n_src_features: the number of source features to\n                create `torchtext.data.Field` for.\n            n_tgt_features: the number of target features to\n                create `torchtext.data.Field` for.\n\n        Returns:\n            A dictionary whose keys are strings and whose values\n            are the corresponding Field objects.\n        \"\"\"", "\n", "fields", "=", "{", "}", "\n", "\n", "def", "make_audio", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "nfft", "=", "data", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "t", "=", "max", "(", "[", "t", ".", "size", "(", "1", ")", "for", "t", "in", "data", "]", ")", "\n", "sounds", "=", "torch", ".", "zeros", "(", "len", "(", "data", ")", ",", "1", ",", "nfft", ",", "t", ")", "\n", "for", "i", ",", "spect", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "sounds", "[", "i", ",", ":", ",", ":", ",", "0", ":", "spect", ".", "size", "(", "1", ")", "]", "=", "spect", "\n", "", "return", "sounds", "\n", "\n", "", "fields", "[", "\"src\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_audio", ",", "sequential", "=", "False", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_src_features", ")", ":", "\n", "            ", "fields", "[", "\"src_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "fields", "[", "\"tgt\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "for", "j", "in", "range", "(", "n_tgt_features", ")", ":", "\n", "            ", "fields", "[", "\"tgt_feat_\"", "+", "str", "(", "j", ")", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "init_token", "=", "BOS_WORD", ",", "eos_token", "=", "EOS_WORD", ",", "\n", "pad_token", "=", "PAD_WORD", ")", "\n", "\n", "", "def", "make_src", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "src_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "src_vocab_size", "=", "max", "(", "[", "t", ".", "max", "(", ")", "for", "t", "in", "data", "]", ")", "+", "1", "\n", "alignment", "=", "torch", ".", "zeros", "(", "src_size", ",", "len", "(", "data", ")", ",", "src_vocab_size", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "for", "j", ",", "t", "in", "enumerate", "(", "sent", ")", ":", "\n", "                    ", "alignment", "[", "j", ",", "i", ",", "t", "]", "=", "1", "\n", "", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"src_map\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "float", ",", "\n", "postprocessing", "=", "make_src", ",", "sequential", "=", "False", ")", "\n", "\n", "def", "make_tgt", "(", "data", ",", "vocab", ")", ":", "\n", "            ", "\"\"\" ? \"\"\"", "\n", "tgt_size", "=", "max", "(", "[", "t", ".", "size", "(", "0", ")", "for", "t", "in", "data", "]", ")", "\n", "alignment", "=", "torch", ".", "zeros", "(", "tgt_size", ",", "len", "(", "data", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "sent", "in", "enumerate", "(", "data", ")", ":", "\n", "                ", "alignment", "[", ":", "sent", ".", "size", "(", "0", ")", ",", "i", "]", "=", "sent", "\n", "", "return", "alignment", "\n", "\n", "", "fields", "[", "\"alignment\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "postprocessing", "=", "make_tgt", ",", "sequential", "=", "False", ")", "\n", "\n", "fields", "[", "\"indices\"", "]", "=", "torchtext", ".", "data", ".", "Field", "(", "\n", "use_vocab", "=", "False", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "sequential", "=", "False", ")", "\n", "\n", "return", "fields", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_num_features": [[270, 292], ["codecs.open", "cf.readline().strip().split", "AudioDataset.extract_text_features", "cf.readline().strip", "cf.readline"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.dataset_base.DatasetBase.extract_text_features"], ["", "@", "staticmethod", "\n", "def", "get_num_features", "(", "corpus_file", ",", "side", ")", ":", "\n", "        ", "\"\"\"\n        For audio corpus, source side is in form of audio, thus\n        no feature; while target side is in form of text, thus\n        we can extract its text features.\n\n        Args:\n            corpus_file (str): file path to get the features.\n            side (str): 'src' or 'tgt'.\n\n        Returns:\n            number of features on `side`.\n        \"\"\"", "\n", "if", "side", "==", "'src'", ":", "\n", "            ", "num_feats", "=", "0", "\n", "", "else", ":", "\n", "            ", "with", "codecs", ".", "open", "(", "corpus_file", ",", "\"r\"", ",", "\"utf-8\"", ")", "as", "cf", ":", "\n", "                ", "f_line", "=", "cf", ".", "readline", "(", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "_", ",", "_", ",", "num_feats", "=", "AudioDataset", ".", "extract_text_features", "(", "f_line", ")", "\n", "\n", "", "", "return", "num_feats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.util_class.LayerNorm.__init__": [[11, 16], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "features", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "a_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "features", ")", ")", "\n", "self", ".", "b_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "features", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.util_class.LayerNorm.forward": [[17, 21], ["x.mean", "x.std"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "self", ".", "a_2", "*", "(", "x", "-", "mean", ")", "/", "(", "std", "+", "self", ".", "eps", ")", "+", "self", ".", "b_2", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.util_class.Elementwise.__init__": [[35, 39], ["torch.ModuleList.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "merge", "=", "None", ",", "*", "args", ")", ":", "\n", "        ", "assert", "merge", "in", "[", "None", ",", "'first'", ",", "'concat'", ",", "'sum'", ",", "'mlp'", "]", "\n", "self", ".", "merge", "=", "merge", "\n", "super", "(", "Elementwise", ",", "self", ")", ".", "__init__", "(", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.util_class.Elementwise.forward": [[40, 52], ["feat.squeeze", "len", "len", "f", "inputs.split", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "inputs_", "=", "[", "feat", ".", "squeeze", "(", "2", ")", "for", "feat", "in", "inputs", ".", "split", "(", "1", ",", "dim", "=", "2", ")", "]", "\n", "assert", "len", "(", "self", ")", "==", "len", "(", "inputs_", ")", "\n", "outputs", "=", "[", "f", "(", "x", ")", "for", "f", ",", "x", "in", "zip", "(", "self", ",", "inputs_", ")", "]", "\n", "if", "self", ".", "merge", "==", "'first'", ":", "\n", "            ", "return", "outputs", "[", "0", "]", "\n", "", "elif", "self", ".", "merge", "==", "'concat'", "or", "self", ".", "merge", "==", "'mlp'", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "outputs", ",", "2", ")", "\n", "", "elif", "self", ".", "merge", "==", "'sum'", ":", "\n", "            ", "return", "sum", "(", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "return", "outputs", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.conv_multi_step_attention.ConvMultiStepAttention.__init__": [[29, 33], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ")", ":", "\n", "        ", "super", "(", "ConvMultiStepAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "input_size", ",", "input_size", ")", "\n", "self", ".", "mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.conv_multi_step_attention.ConvMultiStepAttention.apply_mask": [[34, 37], ["None"], "methods", ["None"], ["", "def", "apply_mask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "\"\"\" Apply mask \"\"\"", "\n", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.conv_multi_step_attention.ConvMultiStepAttention.forward": [[38, 84], ["base_target_emb.size", "input_from_dec.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "encoder_out_top.size", "encoder_out_combine.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "conv_multi_step_attention.seq_linear", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "pre_attn.transpose.transpose.transpose", "torch.softmax", "torch.softmax", "torch.softmax", "attn.transpose().contiguous.transpose().contiguous.transpose().contiguous", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "pre_attn.transpose.transpose.data.masked_fill_", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "attn.transpose().contiguous.transpose().contiguous.transpose", "float"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.conv_multi_step_attention.seq_linear"], ["", "def", "forward", "(", "self", ",", "base_target_emb", ",", "input_from_dec", ",", "encoder_out_top", ",", "\n", "encoder_out_combine", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            base_target_emb: target emb tensor\n            input: output of decode conv\n            encoder_out_t: the key matrix for calculation of attetion weight,\n                which is the top output of encode conv\n            encoder_out_combine:\n                the value matrix for the attention-weighted sum,\n                which is the combination of base emb and top output of encode\n\n        \"\"\"", "\n", "# checks", "\n", "# batch, channel, height, width = base_target_emb.size()", "\n", "batch", ",", "_", ",", "height", ",", "_", "=", "base_target_emb", ".", "size", "(", ")", "\n", "# batch_, channel_, height_, width_ = input_from_dec.size()", "\n", "batch_", ",", "_", ",", "height_", ",", "_", "=", "input_from_dec", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "height", ",", "height_", ")", "\n", "\n", "# enc_batch, enc_channel, enc_height = encoder_out_top.size()", "\n", "enc_batch", ",", "_", ",", "enc_height", "=", "encoder_out_top", ".", "size", "(", ")", "\n", "# enc_batch_, enc_channel_, enc_height_ = encoder_out_combine.size()", "\n", "enc_batch_", ",", "_", ",", "enc_height_", "=", "encoder_out_combine", ".", "size", "(", ")", "\n", "\n", "aeq", "(", "enc_batch", ",", "enc_batch_", ")", "\n", "aeq", "(", "enc_height", ",", "enc_height_", ")", "\n", "\n", "preatt", "=", "seq_linear", "(", "self", ".", "linear_in", ",", "input_from_dec", ")", "\n", "target", "=", "(", "base_target_emb", "+", "preatt", ")", "*", "SCALE_WEIGHT", "\n", "target", "=", "torch", ".", "squeeze", "(", "target", ",", "3", ")", "\n", "target", "=", "torch", ".", "transpose", "(", "target", ",", "1", ",", "2", ")", "\n", "pre_attn", "=", "torch", ".", "bmm", "(", "target", ",", "encoder_out_top", ")", "\n", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "pre_attn", ".", "data", ".", "masked_fill_", "(", "self", ".", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "pre_attn", "=", "pre_attn", ".", "transpose", "(", "0", ",", "2", ")", "\n", "attn", "=", "F", ".", "softmax", "(", "pre_attn", ",", "dim", "=", "-", "1", ")", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "context_output", "=", "torch", ".", "bmm", "(", "\n", "attn", ",", "torch", ".", "transpose", "(", "encoder_out_combine", ",", "1", ",", "2", ")", ")", "\n", "context_output", "=", "torch", ".", "transpose", "(", "\n", "torch", ".", "unsqueeze", "(", "context_output", ",", "3", ")", ",", "1", ",", "2", ")", "\n", "return", "context_output", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.conv_multi_step_attention.seq_linear": [[11, 17], ["x.size", "linear", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "torch.transpose().contiguous().view", "linear.view", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose", "torch.transpose", "torch.transpose"], "function", ["None"], ["def", "seq_linear", "(", "linear", ",", "x", ")", ":", "\n", "    ", "\"\"\" linear transform for 3-d tensor \"\"\"", "\n", "batch", ",", "hidden_size", ",", "length", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "h", "=", "linear", "(", "torch", ".", "transpose", "(", "x", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch", "*", "length", ",", "hidden_size", ")", ")", "\n", "return", "torch", ".", "transpose", "(", "h", ".", "view", "(", "batch", ",", "length", ",", "hidden_size", ",", "1", ")", ",", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.multi_headed_attn.MultiHeadedAttention.__init__": [[51, 68], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "head_count", ",", "model_dim", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "assert", "model_dim", "%", "head_count", "==", "0", "\n", "self", ".", "dim_per_head", "=", "model_dim", "//", "head_count", "\n", "self", ".", "model_dim", "=", "model_dim", "\n", "\n", "super", "(", "MultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "head_count", "=", "head_count", "\n", "\n", "self", ".", "linear_keys", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_values", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "model_dim", ",", "\n", "head_count", "*", "self", ".", "dim_per_head", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "model_dim", ",", "model_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.multi_headed_attn.MultiHeadedAttention.forward": [[69, 202], ["shape.size", "shape.size", "multi_headed_attn.MultiHeadedAttention.size", "multi_headed_attn.MultiHeadedAttention.forward.shape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "key", ",", "value", ",", "query", ",", "mask", "=", "None", ",", "\n", "layer_cache", "=", "None", ",", "type", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Compute the context vector and the attention vectors.\n\n        Args:\n           key (`FloatTensor`): set of `key_len`\n                key vectors `[batch, key_len, dim]`\n           value (`FloatTensor`): set of `key_len`\n                value vectors `[batch, key_len, dim]`\n           query (`FloatTensor`): set of `query_len`\n                 query vectors  `[batch, query_len, dim]`\n           mask: binary mask indicating which keys have\n                 non-zero attention `[batch, query_len, key_len]`\n        Returns:\n           (`FloatTensor`, `FloatTensor`) :\n\n           * output context vectors `[batch, query_len, dim]`\n           * one of the attention vectors `[batch, query_len, key_len]`\n        \"\"\"", "\n", "\n", "# CHECKS", "\n", "# batch, k_len, d = key.size()", "\n", "# batch_, k_len_, d_ = value.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(k_len, k_len_)", "\n", "# aeq(d, d_)", "\n", "# batch_, q_len, d_ = query.size()", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "# aeq(self.model_dim % 8, 0)", "\n", "# if mask is not None:", "\n", "#    batch_, q_len_, k_len_ = mask.size()", "\n", "#    aeq(batch_, batch)", "\n", "#    aeq(k_len_, k_len)", "\n", "#    aeq(q_len_ == q_len)", "\n", "# END CHECKS", "\n", "\n", "batch_size", "=", "key", ".", "size", "(", "0", ")", "\n", "dim_per_head", "=", "self", ".", "dim_per_head", "\n", "head_count", "=", "self", ".", "head_count", "\n", "key_len", "=", "key", ".", "size", "(", "1", ")", "\n", "query_len", "=", "query", ".", "size", "(", "1", ")", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "head_count", "*", "dim_per_head", ")", "\n", "\n", "# 1) Project key, value, and query.", "\n", "", "if", "layer_cache", "is", "not", "None", ":", "\n", "            ", "if", "type", "==", "\"self\"", ":", "\n", "                ", "query", ",", "key", ",", "value", "=", "self", ".", "linear_query", "(", "query", ")", ",", "self", ".", "linear_keys", "(", "query", ")", ",", "self", ".", "linear_values", "(", "query", ")", "\n", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "                    ", "device", "=", "key", ".", "device", "\n", "if", "layer_cache", "[", "\"self_keys\"", "]", "is", "not", "None", ":", "\n", "                        ", "key", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_keys\"", "]", ".", "to", "(", "device", ")", ",", "key", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "if", "layer_cache", "[", "\"self_values\"", "]", "is", "not", "None", ":", "\n", "                        ", "value", "=", "torch", ".", "cat", "(", "\n", "(", "layer_cache", "[", "\"self_values\"", "]", ".", "to", "(", "device", ")", ",", "value", ")", ",", "\n", "dim", "=", "2", ")", "\n", "", "layer_cache", "[", "\"self_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "value", "\n", "", "", "elif", "type", "==", "\"context\"", ":", "\n", "                ", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "                    ", "if", "layer_cache", "[", "\"memory_keys\"", "]", "is", "None", ":", "\n", "                        ", "key", ",", "value", "=", "self", ".", "linear_keys", "(", "key", ")", ",", "self", ".", "linear_values", "(", "value", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "", "else", ":", "\n", "                        ", "key", ",", "value", "=", "layer_cache", "[", "\"memory_keys\"", "]", ",", "layer_cache", "[", "\"memory_values\"", "]", "\n", "", "layer_cache", "[", "\"memory_keys\"", "]", "=", "key", "\n", "layer_cache", "[", "\"memory_values\"", "]", "=", "value", "\n", "", "else", ":", "\n", "                    ", "key", ",", "value", "=", "self", ".", "linear_keys", "(", "key", ")", ",", "self", ".", "linear_values", "(", "value", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "", "", "", "else", ":", "\n", "            ", "key", "=", "self", ".", "linear_keys", "(", "key", ")", "\n", "value", "=", "self", ".", "linear_values", "(", "value", ")", "\n", "query", "=", "self", ".", "linear_query", "(", "query", ")", "\n", "key", "=", "shape", "(", "key", ")", "\n", "value", "=", "shape", "(", "value", ")", "\n", "\n", "", "query", "=", "shape", "(", "query", ")", "\n", "\n", "key_len", "=", "key", ".", "size", "(", "2", ")", "\n", "query_len", "=", "query", ".", "size", "(", "2", ")", "\n", "\n", "# 2) Calculate and scale scores.", "\n", "query", "=", "query", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "\n", "scores", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "scores", ")", "\n", "scores", "=", "scores", ".", "masked_fill", "(", "mask", ",", "-", "1e18", ")", "\n", "\n", "# 3) Apply attention dropout and compute context vectors.", "\n", "", "attn", "=", "self", ".", "softmax", "(", "scores", ")", "\n", "drop_attn", "=", "self", ".", "dropout", "(", "attn", ")", "\n", "context", "=", "unshape", "(", "torch", ".", "matmul", "(", "drop_attn", ",", "value", ")", ")", "\n", "\n", "output", "=", "self", ".", "final_linear", "(", "context", ")", "\n", "# CHECK", "\n", "# batch_, q_len_, d_ = output.size()", "\n", "# aeq(q_len, q_len_)", "\n", "# aeq(batch, batch_)", "\n", "# aeq(d, d_)", "\n", "\n", "# Return one attn", "\n", "top_attn", "=", "attn", ".", "view", "(", "batch_size", ",", "head_count", ",", "\n", "query_len", ",", "key_len", ")", "[", ":", ",", "0", ",", ":", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "\n", "return", "output", ",", "top_attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.structured_attention.MatrixTree.__init__": [[16, 19], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "eps", "=", "1e-5", ")", ":", "\n", "        ", "self", ".", "eps", "=", "eps", "\n", "super", "(", "MatrixTree", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.structured_attention.MatrixTree.forward": [[20, 42], ["input.clone", "range", "input.exp", "input.size", "laplacian[].masked_fill", "input[].diag().exp", "laplacian[].masked_fill.inverse", "laplacian[].masked_fill.inverse.diag().unsqueeze().expand_as().transpose", "input[].exp().mul().clone", "input[].exp().mul().clone", "input[].diag().exp().mul", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.eye().cuda().ne", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "laplacian[].masked_fill.sum", "input[].diag", "laplacian[].masked_fill.inverse.diag().unsqueeze().expand_as", "input[].exp().mul", "input[].exp().mul", "input[].diag().exp", "laplacian[].masked_fill.inverse.transpose", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "laplacian[].masked_fill.inverse.transpose", "laplacian[].masked_fill.inverse.diag().unsqueeze", "input[].exp", "input[].exp", "input[].diag", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "input.size", "laplacian[].masked_fill.inverse.diag"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "laplacian", "=", "input", ".", "exp", "(", ")", "+", "self", ".", "eps", "\n", "output", "=", "input", ".", "clone", "(", ")", "\n", "for", "b", "in", "range", "(", "input", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "lap", "=", "laplacian", "[", "b", "]", ".", "masked_fill", "(", "\n", "torch", ".", "eye", "(", "input", ".", "size", "(", "1", ")", ")", ".", "cuda", "(", ")", ".", "ne", "(", "0", ")", ",", "0", ")", "\n", "lap", "=", "-", "lap", "+", "torch", ".", "diag", "(", "lap", ".", "sum", "(", "0", ")", ")", "\n", "# store roots on diagonal", "\n", "lap", "[", "0", "]", "=", "input", "[", "b", "]", ".", "diag", "(", ")", ".", "exp", "(", ")", "\n", "inv_laplacian", "=", "lap", ".", "inverse", "(", ")", "\n", "\n", "factor", "=", "inv_laplacian", ".", "diag", "(", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "input", "[", "b", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "term1", "=", "input", "[", "b", "]", ".", "exp", "(", ")", ".", "mul", "(", "factor", ")", ".", "clone", "(", ")", "\n", "term2", "=", "input", "[", "b", "]", ".", "exp", "(", ")", ".", "mul", "(", "inv_laplacian", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "clone", "(", ")", "\n", "term1", "[", ":", ",", "0", "]", "=", "0", "\n", "term2", "[", "0", "]", "=", "0", "\n", "output", "[", "b", "]", "=", "term1", "-", "term2", "\n", "roots_output", "=", "input", "[", "b", "]", ".", "diag", "(", ")", ".", "exp", "(", ")", ".", "mul", "(", "\n", "inv_laplacian", ".", "transpose", "(", "0", ",", "1", ")", "[", "0", "]", ")", "\n", "output", "[", "b", "]", "=", "output", "[", "b", "]", "+", "torch", ".", "diag", "(", "roots_output", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.average_attn.AverageAttention.__init__": [[22, 30], ["torch.Module.__init__", "onmt.modules.position_ffn.PositionwiseFeedForward", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "model_dim", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "model_dim", "=", "model_dim", "\n", "\n", "super", "(", "AverageAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "average_layer", "=", "PositionwiseFeedForward", "(", "model_dim", ",", "model_dim", ",", "\n", "dropout", ")", "\n", "self", ".", "gating_layer", "=", "nn", ".", "Linear", "(", "model_dim", "*", "2", ",", "model_dim", "*", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.average_attn.AverageAttention.cumulative_average_mask": [[31, 51], ["torch.tril", "torch.tril", "torch.tril", "torch.tril", "mask.unsqueeze().expand", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "weights.transpose", "mask.unsqueeze"], "methods", ["None"], ["", "def", "cumulative_average_mask", "(", "self", ",", "batch_size", ",", "inputs_len", ")", ":", "\n", "        ", "\"\"\"\n        Builds the mask to compute the cumulative average as described in\n        https://arxiv.org/abs/1805.00631 -- Figure 3\n\n        Args:\n            batch_size (int): batch size\n            inputs_len (int): length of the inputs\n\n        Returns:\n            (`FloatTensor`):\n\n            * A Tensor of shape `[batch_size x input_len x input_len]`\n        \"\"\"", "\n", "\n", "triangle", "=", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "(", "inputs_len", ",", "inputs_len", ")", ")", ")", "\n", "weights", "=", "torch", ".", "ones", "(", "(", "1", ",", "inputs_len", ")", ")", "/", "torch", ".", "arange", "(", "1", ",", "inputs_len", "+", "1", ")", "\n", "mask", "=", "triangle", "*", "weights", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "mask", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "inputs_len", ",", "inputs_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.average_attn.AverageAttention.cumulative_average": [[52, 78], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "layer_cache[].to"], "methods", ["None"], ["", "def", "cumulative_average", "(", "self", ",", "inputs", ",", "mask_or_step", ",", "\n", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Computes the cumulative average as described in\n        https://arxiv.org/abs/1805.00631 -- Equations (1) (5) (6)\n\n        Args:\n            inputs (`FloatTensor`): sequence to average\n                `[batch_size x input_len x dimension]`\n            mask_or_step: if cache is set, this is assumed\n                to be the current step of the\n                dynamic decoding. Otherwise, it is the mask matrix\n                used to compute the cumulative average.\n            cache: a dictionary containing the cumulative average\n                of the previous step.\n        \"\"\"", "\n", "if", "layer_cache", "is", "not", "None", ":", "\n", "            ", "step", "=", "mask_or_step", "\n", "device", "=", "inputs", ".", "device", "\n", "average_attention", "=", "(", "inputs", "+", "step", "*", "\n", "layer_cache", "[", "\"prev_g\"", "]", ".", "to", "(", "device", ")", ")", "/", "(", "step", "+", "1", ")", "\n", "layer_cache", "[", "\"prev_g\"", "]", "=", "average_attention", "\n", "return", "average_attention", "\n", "", "else", ":", "\n", "            ", "mask", "=", "mask_or_step", "\n", "return", "torch", ".", "matmul", "(", "mask", ",", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.average_attn.AverageAttention.forward": [[79, 106], ["inputs.size", "inputs.size", "average_attn.AverageAttention.cumulative_average", "average_attn.AverageAttention.average_layer", "average_attn.AverageAttention.gating_layer", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "average_attn.AverageAttention.cumulative_average_mask().to().float", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "average_attn.AverageAttention.cumulative_average_mask().to", "average_attn.AverageAttention.cumulative_average_mask"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.average_attn.AverageAttention.cumulative_average", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.average_attn.AverageAttention.cumulative_average_mask"], ["", "", "def", "forward", "(", "self", ",", "inputs", ",", "mask", "=", "None", ",", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (`FloatTensor`): `[batch_size x input_len x model_dim]`\n\n        Returns:\n            (`FloatTensor`, `FloatTensor`):\n\n            * gating_outputs `[batch_size x 1 x model_dim]`\n            * average_outputs average attention `[batch_size x 1 x model_dim]`\n        \"\"\"", "\n", "batch_size", "=", "inputs", ".", "size", "(", "0", ")", "\n", "inputs_len", "=", "inputs", ".", "size", "(", "1", ")", "\n", "\n", "device", "=", "inputs", ".", "device", "\n", "average_outputs", "=", "self", ".", "cumulative_average", "(", "\n", "inputs", ",", "self", ".", "cumulative_average_mask", "(", "batch_size", ",", "\n", "inputs_len", ")", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "if", "layer_cache", "is", "None", "else", "step", ",", "layer_cache", "=", "layer_cache", ")", "\n", "average_outputs", "=", "self", ".", "average_layer", "(", "average_outputs", ")", "\n", "gating_outputs", "=", "self", ".", "gating_layer", "(", "torch", ".", "cat", "(", "(", "inputs", ",", "\n", "average_outputs", ")", ",", "-", "1", ")", ")", "\n", "input_gate", ",", "forget_gate", "=", "torch", ".", "chunk", "(", "gating_outputs", ",", "2", ",", "dim", "=", "2", ")", "\n", "gating_outputs", "=", "torch", ".", "sigmoid", "(", "input_gate", ")", "*", "inputs", "+", "torch", ".", "sigmoid", "(", "forget_gate", ")", "*", "average_outputs", "\n", "\n", "return", "gating_outputs", ",", "average_outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.position_ffn.PositionwiseFeedForward.__init__": [[20, 28], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "onmt.modules.LayerNorm", "torch.Dropout", "torch.ReLU", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_ff", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_ff", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_ff", ",", "d_model", ")", "\n", "self", ".", "layer_norm", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout_1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout_2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.position_ffn.PositionwiseFeedForward.forward": [[29, 43], ["position_ffn.PositionwiseFeedForward.dropout_1", "position_ffn.PositionwiseFeedForward.dropout_2", "position_ffn.PositionwiseFeedForward.relu", "position_ffn.PositionwiseFeedForward.w_2", "position_ffn.PositionwiseFeedForward.w_1", "position_ffn.PositionwiseFeedForward.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Layer definition.\n\n        Args:\n            input: [ batch_size, input_len, model_dim ]\n\n\n        Returns:\n            output: [ batch_size, input_len, model_dim ]\n        \"\"\"", "\n", "inter", "=", "self", ".", "dropout_1", "(", "self", ".", "relu", "(", "self", ".", "w_1", "(", "self", ".", "layer_norm", "(", "x", ")", ")", ")", ")", "\n", "output", "=", "self", ".", "dropout_2", "(", "self", ".", "w_2", "(", "inter", ")", ")", "\n", "return", "output", "+", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGenerator.__init__": [[62, 69], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "len"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "tgt_dict", ")", ":", "\n", "        ", "super", "(", "CopyGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "len", "(", "tgt_dict", ")", ")", "\n", "self", ".", "linear_copy", "=", "nn", ".", "Linear", "(", "input_size", ",", "1", ")", "\n", "self", ".", "tgt_dict", "=", "tgt_dict", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGenerator.forward": [[70, 106], ["hidden.size", "attn.size", "src_map.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "copy_generator.CopyGenerator.linear", "copy_generator.CopyGenerator.softmax", "copy_generator.CopyGenerator.sigmoid", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "torch.bmm().transpose", "copy_prob.contiguous().view.contiguous().view.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "float", "copy_generator.CopyGenerator.linear_copy", "copy_generator.CopyGenerator.expand_as", "copy_generator.CopyGenerator.expand_as", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "copy_prob.contiguous().view.contiguous().view.contiguous", "torch.mul.view().transpose", "torch.mul.view().transpose", "torch.mul.view().transpose", "src_map.transpose", "torch.mul.view", "torch.mul.view", "torch.mul.view"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "attn", ",", "src_map", ")", ":", "\n", "        ", "\"\"\"\n        Compute a distribution over the target dictionary\n        extended by the dynamic dictionary implied by compying\n        source words.\n\n        Args:\n           hidden (`FloatTensor`): hidden outputs `[batch*tlen, input_size]`\n           attn (`FloatTensor`): attn for each `[batch*tlen, input_size]`\n           src_map (`FloatTensor`):\n             A sparse indicator matrix mapping each source word to\n             its index in the \"extended\" vocab containing.\n             `[src_len, batch, extra_words]`\n        \"\"\"", "\n", "# CHECKS", "\n", "batch_by_tlen", ",", "_", "=", "hidden", ".", "size", "(", ")", "\n", "batch_by_tlen_", ",", "slen", "=", "attn", ".", "size", "(", ")", "\n", "slen_", ",", "batch", ",", "cvocab", "=", "src_map", ".", "size", "(", ")", "\n", "aeq", "(", "batch_by_tlen", ",", "batch_by_tlen_", ")", "\n", "aeq", "(", "slen", ",", "slen_", ")", "\n", "\n", "# Original probabilities.", "\n", "logits", "=", "self", ".", "linear", "(", "hidden", ")", "\n", "logits", "[", ":", ",", "self", ".", "tgt_dict", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "prob", "=", "self", ".", "softmax", "(", "logits", ")", "\n", "\n", "# Probability of copying p(z=1) batch.", "\n", "p_copy", "=", "self", ".", "sigmoid", "(", "self", ".", "linear_copy", "(", "hidden", ")", ")", "\n", "# Probibility of not copying: p_{word}(w) * (1 - p(z))", "\n", "out_prob", "=", "torch", ".", "mul", "(", "prob", ",", "1", "-", "p_copy", ".", "expand_as", "(", "prob", ")", ")", "\n", "mul_attn", "=", "torch", ".", "mul", "(", "attn", ",", "p_copy", ".", "expand_as", "(", "attn", ")", ")", "\n", "copy_prob", "=", "torch", ".", "bmm", "(", "mul_attn", ".", "view", "(", "-", "1", ",", "batch", ",", "slen", ")", "\n", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "src_map", ".", "transpose", "(", "0", ",", "1", ")", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "copy_prob", "=", "copy_prob", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "cvocab", ")", "\n", "return", "torch", ".", "cat", "(", "[", "out_prob", ",", "copy_prob", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorCriterion.__init__": [[111, 116], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "force_copy", ",", "pad", ",", "eps", "=", "1e-20", ")", ":", "\n", "        ", "self", ".", "force_copy", "=", "force_copy", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "offset", "=", "vocab_size", "\n", "self", ".", "pad", "=", "pad", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorCriterion.__call__": [[117, 144], ["align.eq().float", "align.ne().float", "target.eq().float", "target.ne().float", "scores.gather().view", "scores.gather().view", "scores.gather().view.mul", "scores.gather().view.log().mul", "align.eq", "align.ne", "target.eq", "target.ne", "scores.gather", "scores.gather", "scores.gather().view.mul", "scores.gather().view.mul().mul", "scores.gather().view.mul", "target.ne().float", "target.view", "scores.gather().view.log", "align.view", "scores.gather().view.mul", "target.ne"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log"], ["", "def", "__call__", "(", "self", ",", "scores", ",", "align", ",", "target", ")", ":", "\n", "# Compute unks in align and target for readability", "\n", "        ", "align_unk", "=", "align", ".", "eq", "(", "0", ")", ".", "float", "(", ")", "\n", "align_not_unk", "=", "align", ".", "ne", "(", "0", ")", ".", "float", "(", ")", "\n", "target_unk", "=", "target", ".", "eq", "(", "0", ")", ".", "float", "(", ")", "\n", "target_not_unk", "=", "target", ".", "ne", "(", "0", ")", ".", "float", "(", ")", "\n", "\n", "# Copy probability of tokens in source", "\n", "out", "=", "scores", ".", "gather", "(", "1", ",", "align", ".", "view", "(", "-", "1", ",", "1", ")", "+", "self", ".", "offset", ")", ".", "view", "(", "-", "1", ")", "\n", "# Set scores for unk to 0 and add eps", "\n", "out", "=", "out", ".", "mul", "(", "align_not_unk", ")", "+", "self", ".", "eps", "\n", "# Get scores for tokens in target", "\n", "tmp", "=", "scores", ".", "gather", "(", "1", ",", "target", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Regular prob (no unks and unks that can't be copied)", "\n", "if", "not", "self", ".", "force_copy", ":", "\n", "# Add score for non-unks in target", "\n", "            ", "out", "=", "out", "+", "tmp", ".", "mul", "(", "target_not_unk", ")", "\n", "# Add score for when word is unk in both align and tgt", "\n", "out", "=", "out", "+", "tmp", ".", "mul", "(", "align_unk", ")", ".", "mul", "(", "target_unk", ")", "\n", "", "else", ":", "\n", "# Forced copy. Add only probability for not-copied tokens", "\n", "            ", "out", "=", "out", "+", "tmp", ".", "mul", "(", "align_unk", ")", "\n", "\n", "# Drop padding.", "\n", "", "loss", "=", "-", "out", ".", "log", "(", ")", ".", "mul", "(", "target", ".", "ne", "(", "self", ".", "pad", ")", ".", "float", "(", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute.__init__": [[151, 164], ["onmt.utils.loss.LossComputeBase.__init__", "copy_generator.CopyGeneratorCriterion", "len"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "generator", ",", "tgt_vocab", ",", "\n", "force_copy", ",", "normalize_by_length", ",", "\n", "eps", "=", "1e-20", ")", ":", "\n", "        ", "super", "(", "CopyGeneratorLossCompute", ",", "self", ")", ".", "__init__", "(", "\n", "generator", ",", "tgt_vocab", ")", "\n", "\n", "# We lazily load datasets when there are more than one, so postpone", "\n", "# the setting of cur_dataset.", "\n", "self", ".", "cur_dataset", "=", "None", "\n", "self", ".", "force_copy", "=", "force_copy", "\n", "self", ".", "normalize_by_length", "=", "normalize_by_length", "\n", "self", ".", "criterion", "=", "CopyGeneratorCriterion", "(", "len", "(", "tgt_vocab", ")", ",", "force_copy", ",", "\n", "self", ".", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._make_shard_state": [[165, 176], ["getattr", "AssertionError", "attns.get"], "methods", ["None"], ["", "def", "_make_shard_state", "(", "self", ",", "batch", ",", "output", ",", "range_", ",", "attns", ")", ":", "\n", "        ", "\"\"\" See base class for args description. \"\"\"", "\n", "if", "getattr", "(", "batch", ",", "\"alignment\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"using -copy_attn you need to pass in \"", "\n", "\"-dynamic_dict during preprocess stage.\"", ")", "\n", "\n", "", "return", "{", "\n", "\"output\"", ":", "output", ",", "\n", "\"target\"", ":", "batch", ".", "tgt", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", "]", ",", "\n", "\"copy_attn\"", ":", "attns", ".", "get", "(", "\"copy\"", ")", ",", "\n", "\"align\"", ":", "batch", ".", "alignment", "[", "range_", "[", "0", "]", "+", "1", ":", "range_", "[", "1", "]", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.copy_generator.CopyGeneratorLossCompute._compute_loss": [[178, 226], ["target.view.view.view", "align.view.view.view", "copy_generator.CopyGeneratorLossCompute.generator", "copy_generator.CopyGeneratorLossCompute.criterion", "copy_generator.CopyGeneratorLossCompute.data.clone", "onmt.TextDataset.collapse_copy_scores", "copy_generator.CopyGeneratorLossCompute._bottle", "target.view.view.data.clone", "loss.sum.sum.sum().data.clone", "copy_generator.CopyGeneratorLossCompute._stats", "copy_generator.CopyGeneratorLossCompute._bottle", "copy_generator.CopyGeneratorLossCompute._bottle", "copy_generator.CopyGeneratorLossCompute._unbottle", "target.view.data.clone.eq", "align.view.view.data.ne", "correct_mask.long", "batch.tgt[].ne().float().sum", "loss.sum.sum.view().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "torch.div().sum", "loss.sum.sum.sum", "len", "loss.sum.sum.sum", "batch.tgt[].ne().float", "loss.sum.sum.view", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "batch.tgt[].ne"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.TextDataset.collapse_copy_scores", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._bottle", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._stats", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._bottle", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._bottle", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.loss.ReRankerLossCompute._unbottle"], ["", "def", "_compute_loss", "(", "self", ",", "batch", ",", "output", ",", "target", ",", "copy_attn", ",", "align", ")", ":", "\n", "        ", "\"\"\"\n        Compute the loss. The args must match self._make_shard_state().\n        Args:\n            batch: the current batch.\n            output: the predict output from the model.\n            target: the validate target to compare output with.\n            copy_attn: the copy attention value.\n            align: the align info.\n        \"\"\"", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "align", "=", "align", ".", "view", "(", "-", "1", ")", "\n", "scores", "=", "self", ".", "generator", "(", "self", ".", "_bottle", "(", "output", ")", ",", "\n", "self", ".", "_bottle", "(", "copy_attn", ")", ",", "\n", "batch", ".", "src_map", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "scores", ",", "align", ",", "target", ")", "# [tgt_len * batch_size]", "\n", "scores_data", "=", "scores", ".", "data", ".", "clone", "(", ")", "\n", "scores_data", "=", "inputters", ".", "TextDataset", ".", "collapse_copy_scores", "(", "\n", "self", ".", "_unbottle", "(", "scores_data", ",", "batch", ".", "batch_size", ")", ",", "\n", "batch", ",", "self", ".", "tgt_vocab", ",", "self", ".", "cur_dataset", ".", "src_vocabs", ")", "\n", "scores_data", "=", "self", ".", "_bottle", "(", "scores_data", ")", "\n", "\n", "# Correct target copy token instead of <unk>", "\n", "# tgt[i] = align[i] + len(tgt_vocab)", "\n", "# for i such that tgt[i] == 0 and align[i] != 0", "\n", "target_data", "=", "target", ".", "data", ".", "clone", "(", ")", "\n", "correct_mask", "=", "target_data", ".", "eq", "(", "0", ")", "*", "align", ".", "data", ".", "ne", "(", "0", ")", "\n", "correct_copy", "=", "(", "align", ".", "data", "+", "len", "(", "self", ".", "tgt_vocab", ")", ")", "*", "correct_mask", ".", "long", "(", ")", "\n", "target_data", "=", "target_data", "+", "correct_copy", "\n", "\n", "# Compute sum of perplexities for stats", "\n", "loss_data", "=", "loss", ".", "sum", "(", ")", ".", "data", ".", "clone", "(", ")", "\n", "stats", "=", "self", ".", "_stats", "(", "loss_data", ",", "scores_data", ",", "target_data", ")", "\n", "\n", "if", "self", ".", "normalize_by_length", ":", "\n", "# Compute Loss as NLL divided by seq length", "\n", "# Compute Sequence Lengths", "\n", "            ", "pad_ix", "=", "batch", ".", "dataset", ".", "fields", "[", "'tgt'", "]", ".", "vocab", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", "\n", "# changed for KE_KG \"tgt->tgt[1:]\"", "\n", "tgt_lens", "=", "batch", ".", "tgt", "[", "1", ":", "]", ".", "ne", "(", "pad_ix", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "# Compute Total Loss per sequence in batch", "\n", "loss", "=", "loss", ".", "view", "(", "-", "1", ",", "batch", ".", "batch_size", ")", ".", "sum", "(", "0", ")", "\n", "# Divide by length of each sequence and sum", "\n", "loss", "=", "torch", ".", "div", "(", "loss", ",", "tgt_lens", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss", ".", "sum", "(", ")", "\n", "\n", "", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.embeddings.PositionalEncoding.__init__": [[23, 35], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "torch.Module.__init__", "embeddings.PositionalEncoding.register_buffer", "torch.Dropout", "torch.Dropout", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange().unsqueeze.float", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.log"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log"], ["def", "__init__", "(", "self", ",", "dropout", ",", "dim", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "dim", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "(", "torch", ".", "arange", "(", "0", ",", "dim", ",", "2", ")", "*", "\n", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "dim", ")", ")", ".", "float", "(", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", ".", "float", "(", ")", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "1", ")", "\n", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.embeddings.PositionalEncoding.forward": [[36, 44], ["embeddings.PositionalEncoding.dropout", "math.sqrt", "embeddings.PositionalEncoding.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "emb", ",", "step", "=", "None", ")", ":", "\n", "        ", "emb", "=", "emb", "*", "math", ".", "sqrt", "(", "self", ".", "dim", ")", "\n", "if", "step", "is", "None", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", ":", "emb", ".", "size", "(", "0", ")", "]", "\n", "", "else", ":", "\n", "            ", "emb", "=", "emb", "+", "self", ".", "pe", "[", "step", "]", "\n", "", "emb", "=", "self", ".", "dropout", "(", "emb", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.embeddings.Embeddings.__init__": [[89, 156], ["vocab_sizes.extend", "emb_dims.extend", "pad_indices.extend", "zip", "onmt.modules.util_class.Elementwise", "torch.Module.__init__", "torch.Sequential", "torch.Sequential", "embeddings.Embeddings.make_embedding.add_module", "torch.Embedding", "torch.Embedding", "sum", "sum", "torch.Sequential", "torch.Sequential", "embeddings.Embeddings.make_embedding.add_module", "embeddings.PositionalEncoding", "embeddings.Embeddings.make_embedding.add_module", "len", "len", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "len", "int"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "word_vec_size", ",", "\n", "word_vocab_size", ",", "\n", "word_padding_idx", ",", "\n", "position_encoding", "=", "False", ",", "\n", "feat_merge", "=", "\"concat\"", ",", "\n", "feat_vec_exponent", "=", "0.7", ",", "feat_vec_size", "=", "-", "1", ",", "\n", "feat_padding_idx", "=", "[", "]", ",", "\n", "feat_vocab_sizes", "=", "[", "]", ",", "\n", "dropout", "=", "0", ",", "\n", "sparse", "=", "False", ")", ":", "\n", "\n", "        ", "if", "feat_padding_idx", "is", "None", ":", "\n", "            ", "feat_padding_idx", "=", "[", "]", "\n", "", "self", ".", "word_padding_idx", "=", "word_padding_idx", "\n", "\n", "# Dimensions and padding for constructing the word embedding matrix", "\n", "vocab_sizes", "=", "[", "word_vocab_size", "]", "\n", "emb_dims", "=", "[", "word_vec_size", "]", "\n", "pad_indices", "=", "[", "word_padding_idx", "]", "\n", "\n", "# Dimensions and padding for feature embedding matrices", "\n", "# (these have no effect if feat_vocab_sizes is empty)", "\n", "if", "feat_merge", "==", "'sum'", ":", "\n", "            ", "feat_dims", "=", "[", "word_vec_size", "]", "*", "len", "(", "feat_vocab_sizes", ")", "\n", "", "elif", "feat_vec_size", ">", "0", ":", "\n", "            ", "feat_dims", "=", "[", "feat_vec_size", "]", "*", "len", "(", "feat_vocab_sizes", ")", "\n", "", "else", ":", "\n", "            ", "feat_dims", "=", "[", "int", "(", "vocab", "**", "feat_vec_exponent", ")", "\n", "for", "vocab", "in", "feat_vocab_sizes", "]", "\n", "", "vocab_sizes", ".", "extend", "(", "feat_vocab_sizes", ")", "\n", "emb_dims", ".", "extend", "(", "feat_dims", ")", "\n", "pad_indices", ".", "extend", "(", "feat_padding_idx", ")", "\n", "\n", "# The embedding matrix look-up tables. The first look-up table", "\n", "# is for words. Subsequent ones are for features, if any exist.", "\n", "emb_params", "=", "zip", "(", "vocab_sizes", ",", "emb_dims", ",", "pad_indices", ")", "\n", "embeddings", "=", "[", "nn", ".", "Embedding", "(", "vocab", ",", "dim", ",", "padding_idx", "=", "pad", ",", "sparse", "=", "sparse", ")", "\n", "for", "vocab", ",", "dim", ",", "pad", "in", "emb_params", "]", "\n", "emb_luts", "=", "Elementwise", "(", "feat_merge", ",", "embeddings", ")", "\n", "\n", "# The final output size of word + feature vectors. This can vary", "\n", "# from the word vector size if and only if features are defined.", "\n", "# This is the attribute you should access if you need to know", "\n", "# how big your embeddings are going to be.", "\n", "self", ".", "embedding_size", "=", "(", "sum", "(", "emb_dims", ")", "if", "feat_merge", "==", "'concat'", "\n", "else", "word_vec_size", ")", "\n", "\n", "# The sequence of operations that converts the input sequence", "\n", "# into a sequence of embeddings. At minimum this consists of", "\n", "# looking up the embeddings for each word and feature in the", "\n", "# input. Model parameters may require the sequence to contain", "\n", "# additional operations as well.", "\n", "super", "(", "Embeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "make_embedding", "=", "nn", ".", "Sequential", "(", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'emb_luts'", ",", "emb_luts", ")", "\n", "\n", "if", "feat_merge", "==", "'mlp'", "and", "len", "(", "feat_vocab_sizes", ")", ">", "0", ":", "\n", "            ", "in_dim", "=", "sum", "(", "emb_dims", ")", "\n", "out_dim", "=", "word_vec_size", "\n", "mlp", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_dim", ",", "out_dim", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'mlp'", ",", "mlp", ")", "\n", "\n", "", "self", ".", "position_encoding", "=", "position_encoding", "\n", "\n", "if", "self", ".", "position_encoding", ":", "\n", "            ", "pe", "=", "PositionalEncoding", "(", "dropout", ",", "self", ".", "embedding_size", ")", "\n", "self", ".", "make_embedding", ".", "add_module", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.embeddings.Embeddings.word_lut": [[157, 161], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "word_lut", "(", "self", ")", ":", "\n", "        ", "\"\"\" word look-up table \"\"\"", "\n", "return", "self", ".", "make_embedding", "[", "0", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.embeddings.Embeddings.emb_luts": [[162, 166], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "emb_luts", "(", "self", ")", ":", "\n", "        ", "\"\"\" embedding look-up table \"\"\"", "\n", "return", "self", ".", "make_embedding", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.embeddings.Embeddings.load_pretrained_vectors": [[167, 179], ["torch.load", "torch.load", "torch.load", "torch.load", "embeddings.Embeddings.word_lut.weight.data.copy_"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "emb_file", ",", "fixed", ")", ":", "\n", "        ", "\"\"\"Load in pretrained embeddings.\n\n        Args:\n          emb_file (str) : path to torch serialized embeddings\n          fixed (bool) : if true, embeddings are not updated\n        \"\"\"", "\n", "if", "emb_file", ":", "\n", "            ", "pretrained", "=", "torch", ".", "load", "(", "emb_file", ")", "\n", "self", ".", "word_lut", ".", "weight", ".", "data", ".", "copy_", "(", "pretrained", ")", "\n", "if", "fixed", ":", "\n", "                ", "self", ".", "word_lut", ".", "weight", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.embeddings.Embeddings.forward": [[180, 199], ["enumerate", "embeddings.Embeddings.make_embedding", "embeddings.Embeddings.make_embedding._modules.values", "module", "module", "len", "embeddings.Embeddings.make_embedding._modules.values"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "source", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Computes the embeddings for words and features.\n\n        Args:\n            source (`LongTensor`): index tensor `[len x batch x nfeat]`\n        Return:\n            `FloatTensor`: word embeddings `[len x batch x embedding_size]`\n        \"\"\"", "\n", "if", "self", ".", "position_encoding", ":", "\n", "            ", "for", "i", ",", "module", "in", "enumerate", "(", "self", ".", "make_embedding", ".", "_modules", ".", "values", "(", ")", ")", ":", "\n", "                ", "if", "i", "==", "len", "(", "self", ".", "make_embedding", ".", "_modules", ".", "values", "(", ")", ")", "-", "1", ":", "\n", "                    ", "source", "=", "module", "(", "source", ",", "step", "=", "step", ")", "\n", "", "else", ":", "\n", "                    ", "source", "=", "module", "(", "source", ")", "\n", "", "", "", "else", ":", "\n", "            ", "source", "=", "self", ".", "make_embedding", "(", "source", ")", "\n", "\n", "", "return", "source", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormLinear.__init__": [[44, 61], ["torch.Linear.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.register_buffer", "weight_norm.WeightNormLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "\n", "init_scale", "=", "1.", ",", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormLinear", ",", "self", ")", ".", "__init__", "(", "\n", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "\n", "'V_avg'", ",", "torch", ".", "zeros", "(", "out_features", ",", "in_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_features", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormLinear.reset_parameters": [[62, 64], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormLinear.forward": [[65, 99], ["weight_norm.WeightNormLinear.V.data.copy_", "weight_norm.WeightNormLinear.g.data.copy_", "weight_norm.WeightNormLinear.b.data.copy_", "weight_norm.WeightNormLinear.V_avg.copy_", "weight_norm.WeightNormLinear.g_avg.copy_", "weight_norm.WeightNormLinear.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.linear", "torch.linear", "torch.linear", "weight_norm.WeightNormLinear.V.data.norm().expand_as", "torch.linear", "torch.linear", "torch.linear", "x_init.mean().squeeze", "x_init.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view().expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "b.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "m_init.view().expand_as", "scalar.view().expand_as", "weight_norm.WeightNormLinear.V.data.norm", "x_init.mean", "x_init.var", "scale_init.view", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "b.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "m_init.view", "scalar.view", "weight_norm.WeightNormLinear.V.data.size"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.get_vars_maybe_avg"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_features * in_features", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "# norm is out_features * 1", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "norm", "(", "2", ",", "1", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "# batch_size * out_features", "\n", "x_init", "=", "F", ".", "linear", "(", "x", ",", "v_norm", ")", ".", "data", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "x_init", ".", "mean", "(", "0", ")", ".", "squeeze", "(", "\n", "0", ")", ",", "x_init", ".", "var", "(", "0", ")", ".", "squeeze", "(", "0", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "x_init", "=", "scale_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "\n", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "# batch_size * out_features", "\n", "x", "=", "F", ".", "linear", "(", "x", ",", "v", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "v", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "x", "=", "scalar", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "*", "x", "+", "b", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormConv2d.__init__": [[102, 120], ["torch.Conv2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.register_buffer", "weight_norm.WeightNormConv2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "weight_norm.WeightNormConv2d.V.size"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConv2d", ",", "self", ")", ".", "__init__", "(", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "padding", ",", "\n", "dilation", ",", "groups", ")", "\n", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormConv2d.reset_parameters": [[121, 123], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormConv2d.forward": [[124, 170], ["weight_norm.WeightNormConv2d.V.data.copy_", "x_init.transpose().contiguous().view", "weight_norm.WeightNormConv2d.g.data.copy_", "weight_norm.WeightNormConv2d.b.data.copy_", "scale_init.view", "m_init.view", "weight_norm.WeightNormConv2d.V_avg.copy_", "weight_norm.WeightNormConv2d.g_avg.copy_", "weight_norm.WeightNormConv2d.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.conv2d", "torch.conv2d", "torch.conv2d", "weight_norm.WeightNormConv2d.V.data.view().norm().view().expand_as", "torch.conv2d", "torch.conv2d", "torch.conv2d", "x_init.transpose().contiguous().view.mean().squeeze", "x_init.transpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "v.view", "len", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.norm.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "x_init.transpose().contiguous", "m_init.view.expand_as", "torch.norm.size", "torch.norm.size", "torch.norm.size", "torch.norm.squeeze", "torch.norm.squeeze", "torch.norm.squeeze", "weight_norm.WeightNormConv2d.V.data.view().norm().view", "x_init.transpose().contiguous().view.mean", "x_init.transpose().contiguous().view.var", "torch.norm.view", "torch.norm.view", "torch.norm.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.transpose", "len", "len", "weight_norm.WeightNormConv2d.V.data.size", "weight_norm.WeightNormConv2d.V.data.view().norm", "x_init.size", "x_init.size", "weight_norm.WeightNormConv2d.V.data.view", "len", "len", "v.size"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.get_vars_maybe_avg"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# out_channels, in_channels // groups, * kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", "\n", ")", ".", "type_as", "(", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "self", ".", "out_channels", ",", "*", "(", "\n", "[", "1", "]", "*", "(", "len", "(", "self", ".", "kernel_size", ")", "+", "1", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv2d", "(", "x", ",", "v_norm", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", ".", "data", "\n", "t_x_init", "=", "x_init", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "\n", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "\n", "scalar", "=", "torch", ".", "norm", "(", "v", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", "\n", "if", "len", "(", "scalar", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "scalar", "=", "g", "/", "scalar", "\n", "\n", "", "w", "=", "scalar", ".", "view", "(", "self", ".", "out_channels", ",", "*", "\n", "(", "[", "1", "]", "*", "(", "len", "(", "v", ".", "size", "(", ")", ")", "-", "1", ")", ")", ")", ".", "expand_as", "(", "v", ")", "*", "v", "\n", "\n", "x", "=", "F", ".", "conv2d", "(", "x", ",", "w", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormConvTranspose2d.__init__": [[175, 195], ["torch.ConvTranspose2d.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.register_buffer", "weight_norm.WeightNormConvTranspose2d.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "weight_norm.WeightNormConvTranspose2d.V.size"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "output_padding", "=", "0", ",", "groups", "=", "1", ",", "init_scale", "=", "1.", ",", "\n", "polyak_decay", "=", "0.9995", ")", ":", "\n", "        ", "super", "(", "WeightNormConvTranspose2d", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "\n", "kernel_size", ",", "stride", ",", "\n", "padding", ",", "output_padding", ",", "\n", "groups", ")", "\n", "# in_channels, out_channels, *kernel_size", "\n", "self", ".", "V", "=", "self", ".", "weight", "\n", "self", ".", "g", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "b", "=", "self", ".", "bias", "\n", "\n", "self", ".", "register_buffer", "(", "'V_avg'", ",", "torch", ".", "zeros", "(", "self", ".", "V", ".", "size", "(", ")", ")", ")", "\n", "self", ".", "register_buffer", "(", "'g_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "self", ".", "register_buffer", "(", "'b_avg'", ",", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "\n", "self", ".", "init_scale", "=", "init_scale", "\n", "self", ".", "polyak_decay", "=", "polyak_decay", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormConvTranspose2d.reset_parameters": [[196, 198], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.WeightNormConvTranspose2d.forward": [[199, 247], ["weight_norm.WeightNormConvTranspose2d.V.data.copy_", "x_init.tranpose().contiguous().view", "weight_norm.WeightNormConvTranspose2d.g.data.copy_", "weight_norm.WeightNormConvTranspose2d.b.data.copy_", "scale_init.view", "m_init.view", "weight_norm.WeightNormConvTranspose2d.V_avg.copy_", "weight_norm.WeightNormConvTranspose2d.g_avg.copy_", "weight_norm.WeightNormConvTranspose2d.b_avg.copy_", "weight_norm.get_vars_maybe_avg", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view().expand_as", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "x_init.tranpose().contiguous().view.mean().squeeze", "x_init.tranpose().contiguous().view.var().squeeze", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "scale_init.view.expand_as", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "torch.norm().squeeze", "scalar.view().expand_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "torch.randn().type_as", "x_init.tranpose().contiguous", "m_init.view.expand_as", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm().view", "x_init.tranpose().contiguous().view.mean", "x_init.tranpose().contiguous().view.var", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "scalar.view", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "x_init.tranpose", "len", "len", "v.transpose().contiguous().view", "weight_norm.WeightNormConvTranspose2d.V.data.size", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view().norm", "x_init.size", "x_init.size", "len", "v.transpose().contiguous", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous().view", "len", "v.transpose", "v.size", "weight_norm.WeightNormConvTranspose2d.V.data.transpose().contiguous", "weight_norm.WeightNormConvTranspose2d.V.data.transpose"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.get_vars_maybe_avg"], ["", "def", "forward", "(", "self", ",", "x", ",", "init", "=", "False", ")", ":", "\n", "        ", "if", "init", "is", "True", ":", "\n", "# in_channels, out_channels, *kernel_size", "\n", "            ", "self", ".", "V", ".", "data", ".", "copy_", "(", "torch", ".", "randn", "(", "self", ".", "V", ".", "data", ".", "size", "(", ")", ")", ".", "type_as", "(", "\n", "self", ".", "V", ".", "data", ")", "*", "0.05", ")", "\n", "v_norm", "=", "self", ".", "V", ".", "data", "/", "self", ".", "V", ".", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", ".", "norm", "(", "2", ",", "1", ")", ".", "view", "(", "\n", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "len", "(", "self", ".", "kernel_size", ")", ")", ")", ".", "expand_as", "(", "self", ".", "V", ".", "data", ")", "\n", "x_init", "=", "F", ".", "conv_transpose2d", "(", "\n", "x", ",", "v_norm", ",", "None", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "self", ".", "groups", ")", ".", "data", "\n", "# self.out_channels, 1", "\n", "t_x_init", "=", "x_init", ".", "tranpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "# out_features", "\n", "m_init", ",", "v_init", "=", "t_x_init", ".", "mean", "(", "1", ")", ".", "squeeze", "(", "\n", "1", ")", ",", "t_x_init", ".", "var", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "# out_features", "\n", "scale_init", "=", "self", ".", "init_scale", "/", "torch", ".", "sqrt", "(", "v_init", "+", "1e-10", ")", "\n", "self", ".", "g", ".", "data", ".", "copy_", "(", "scale_init", ")", "\n", "self", ".", "b", ".", "data", ".", "copy_", "(", "-", "m_init", "*", "scale_init", ")", "\n", "scale_init_shape", "=", "scale_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "m_init_shape", "=", "m_init", ".", "view", "(", "\n", "1", ",", "self", ".", "out_channels", ",", "*", "(", "[", "1", "]", "*", "(", "len", "(", "x_init", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", "\n", "\n", "x_init", "=", "scale_init_shape", ".", "expand_as", "(", "x_init", ")", "*", "(", "x_init", "-", "m_init_shape", ".", "expand_as", "(", "x_init", ")", ")", "\n", "self", ".", "V_avg", ".", "copy_", "(", "self", ".", "V", ".", "data", ")", "\n", "self", ".", "g_avg", ".", "copy_", "(", "self", ".", "g", ".", "data", ")", "\n", "self", ".", "b_avg", ".", "copy_", "(", "self", ".", "b", ".", "data", ")", "\n", "return", "x_init", "\n", "", "else", ":", "\n", "            ", "v", ",", "g", ",", "b", "=", "get_vars_maybe_avg", "(", "\n", "self", ",", "[", "'V'", ",", "'g'", ",", "'b'", "]", ",", "self", ".", "training", ",", "\n", "polyak_decay", "=", "self", ".", "polyak_decay", ")", "\n", "scalar", "=", "g", "/", "torch", ".", "norm", "(", "v", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "out_channels", ",", "-", "1", ")", ",", "2", ",", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "w", "=", "scalar", ".", "view", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "*", "(", "[", "1", "]", "*", "(", "len", "(", "v", ".", "size", "(", ")", ")", "-", "2", ")", ")", ")", ".", "expand_as", "(", "v", ")", "*", "v", "\n", "\n", "x", "=", "F", ".", "conv_transpose2d", "(", "x", ",", "w", ",", "b", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "output_padding", ",", "\n", "self", ".", "groups", ")", "\n", "return", "x", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.get_var_maybe_avg": [[8, 20], ["getattr", "getattr"], "function", ["None"], ["def", "get_var_maybe_avg", "(", "namespace", ",", "var_name", ",", "training", ",", "polyak_decay", ")", ":", "\n", "    ", "\"\"\" utility for retrieving polyak averaged params\n        Update average\n    \"\"\"", "\n", "v", "=", "getattr", "(", "namespace", ",", "var_name", ")", "\n", "v_avg", "=", "getattr", "(", "namespace", ",", "var_name", "+", "'_avg'", ")", "\n", "v_avg", "-=", "(", "1", "-", "polyak_decay", ")", "*", "(", "v_avg", "-", "v", ".", "data", ")", "\n", "\n", "if", "training", ":", "\n", "        ", "return", "v", "\n", "", "else", ":", "\n", "        ", "return", "v_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.get_vars_maybe_avg": [[22, 29], ["vars.append", "weight_norm.get_var_maybe_avg"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.weight_norm.get_var_maybe_avg"], ["", "", "def", "get_vars_maybe_avg", "(", "namespace", ",", "var_names", ",", "training", ",", "polyak_decay", ")", ":", "\n", "    ", "\"\"\" utility for retrieving polyak averaged params \"\"\"", "\n", "vars", "=", "[", "]", "\n", "for", "vn", "in", "var_names", ":", "\n", "        ", "vars", ".", "append", "(", "get_var_maybe_avg", "(", "\n", "namespace", ",", "vn", ",", "training", ",", "polyak_decay", ")", ")", "\n", "", "return", "vars", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.global_attention.GlobalAttention.__init__": [[68, 93], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Tanh", "torch.Tanh", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "dim", ",", "coverage", "=", "False", ",", "attn_type", "=", "\"dot\"", ",", "no_sftmax_bf_rescale", "=", "False", ",", "use_retrieved_keys", "=", "False", ")", ":", "\n", "        ", "super", "(", "GlobalAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "self", ".", "no_sftmax_bf_rescale", "=", "no_sftmax_bf_rescale", "\n", "self", ".", "use_retrieved_keys", "=", "use_retrieved_keys", "\n", "\n", "# assert (self.attn_type in [\"dot\", \"general\", \"mlp\"]), (", "\n", "#     \"Please select a valid attention type.\")", "\n", "\n", "assert", "(", "self", ".", "attn_type", "==", "\"general\"", ")", ",", "\"Currently, only general attention is supported.\"", "\n", "\n", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "            ", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "if", "self", ".", "use_retrieved_keys", ":", "\n", "                ", "self", ".", "rk_linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "", "", "elif", "self", ".", "attn_type", "==", "\"mlp\"", ":", "\n", "            ", "self", ".", "linear_context", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "# mlp wants it with bias", "\n", "", "out_bias", "=", "self", ".", "attn_type", "==", "\"mlp\"", "\n", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ",", "bias", "=", "out_bias", ")", "\n", "\n", "if", "self", ".", "use_retrieved_keys", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.global_attention.GlobalAttention.score": [[94, 136], ["h_s.size", "global_attention.GlobalAttention.view.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "h_s.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "global_attention.GlobalAttention.linear_query", "wq.expand.expand.view", "wq.expand.expand.expand", "global_attention.GlobalAttention.linear_context", "uh.expand.expand.view", "uh.expand.expand.expand", "global_attention.GlobalAttention.tanh", "global_attention.GlobalAttention.v().view", "global_attention.GlobalAttention.view.view", "global_attention.GlobalAttention.linear_in", "global_attention.GlobalAttention.view", "global_attention.GlobalAttention.view.view", "h_s.contiguous().view", "global_attention.GlobalAttention.v", "h_s.contiguous", "global_attention.GlobalAttention.view"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq"], ["            ", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "3", ",", "dim", ",", "bias", "=", "out_bias", ")", "\n", "\n", "", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "if", "coverage", ":", "\n", "            ", "self", ".", "linear_cover", "=", "nn", ".", "Linear", "(", "1", ",", "dim", ",", "bias", "=", "False", ")", "\n", "\n", "", "", "def", "score", "(", "self", ",", "h_t", ",", "h_s", ",", "rk", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n          h_t (`FloatTensor`): sequence of queries `[batch x tgt_len x dim]`\n          h_s (`FloatTensor`): sequence of sources `[batch x src_len x dim]`\n\n        Returns:\n          :obj:`FloatTensor`:\n           raw attention scores (unnormalized) for each src index\n          `[batch x tgt_len x src_len]`\n\n        \"\"\"", "\n", "\n", "# Check input sizes", "\n", "src_batch", ",", "src_len", ",", "src_dim", "=", "h_s", ".", "size", "(", ")", "\n", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", "=", "h_t", ".", "size", "(", ")", "\n", "aeq", "(", "src_batch", ",", "tgt_batch", ")", "\n", "aeq", "(", "src_dim", ",", "tgt_dim", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "src_dim", ")", "\n", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "                ", "h_t_", "=", "h_t", ".", "view", "(", "tgt_batch", "*", "tgt_len", ",", "tgt_dim", ")", "\n", "if", "not", "rk", ":", "\n", "                    ", "h_t_", "=", "self", ".", "linear_in", "(", "h_t_", ")", "\n", "", "else", ":", "\n", "                    ", "h_t_", "=", "self", ".", "rk_linear_in", "(", "h_t_", ")", "\n", "", "h_t", "=", "h_t_", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", ")", "\n", "", "h_s_", "=", "h_s", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# (batch, t_len, d) x (batch, d, s_len) --> (batch, t_len, s_len)", "\n", "return", "torch", ".", "bmm", "(", "h_t", ",", "h_s_", ")", "\n", "", "else", ":", "\n", "            ", "dim", "=", "self", ".", "dim", "\n", "wq", "=", "self", ".", "linear_query", "(", "h_t", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.global_attention.GlobalAttention.forward": [[137, 235], ["memory_bank.size", "source.unsqueeze.unsqueeze.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "global_attention.GlobalAttention.score", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "global_attention.GlobalAttention.linear_out().view", "source.unsqueeze.unsqueeze.dim", "source.unsqueeze.unsqueeze.unsqueeze", "coverage.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "coverage.view().unsqueeze", "onmt.utils.misc.sequence_mask", "mask.unsqueeze.unsqueeze.unsqueeze", "global_attention.GlobalAttention.masked_fill_", "global_attention.GlobalAttention.softmax", "align_vectors.transpose().contiguous.transpose().contiguous.view", "global_attention.GlobalAttention.sigmoid", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "global_attention.GlobalAttention.tanh", "attn_h.transpose().contiguous.transpose().contiguous.squeeze", "align_vectors.transpose().contiguous.transpose().contiguous.squeeze", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "attn_h.transpose().contiguous.transpose().contiguous.transpose().contiguous", "align_vectors.transpose().contiguous.transpose().contiguous.transpose().contiguous", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "global_attention.GlobalAttention.linear_cover().view_as", "global_attention.GlobalAttention.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "global_attention.GlobalAttention.linear_out", "coverage.view", "global_attention.GlobalAttention.size", "float", "mask.unsqueeze.unsqueeze.float", "attn_h.transpose().contiguous.transpose().contiguous.transpose", "align_vectors.transpose().contiguous.transpose().contiguous.transpose", "global_attention.GlobalAttention.linear_cover"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.GNMTGlobalScorer.score", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.sequence_mask", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq"], ["wq", "=", "wq", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "1", ",", "dim", ")", "\n", "wq", "=", "wq", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "uh", "=", "self", ".", "linear_context", "(", "h_s", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "uh", "=", "uh", ".", "view", "(", "src_batch", ",", "1", ",", "src_len", ",", "dim", ")", "\n", "uh", "=", "uh", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "# (batch, t_len, s_len, d)", "\n", "wquh", "=", "self", ".", "tanh", "(", "wq", "+", "uh", ")", "\n", "\n", "return", "self", ".", "v", "(", "wquh", ".", "view", "(", "-", "1", ",", "dim", ")", ")", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "source", ",", "memory_bank", ",", "rk_memory_bank", ",", "memory_lengths", "=", "None", ",", "\n", "rk_memory_lengths", "=", "None", ",", "coverage", "=", "None", ",", "rk_final_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n          source (`FloatTensor`): query vectors `[batch x tgt_len x dim]`\n          memory_bank (`FloatTensor`): source vectors `[batch x src_len x dim]`\n          rk_memory_bank (`FloatTensor`): retrieved keys vectors `[batch x rk_len x dim]`\n          memory_lengths (`LongTensor`): the source context lengths `[batch]`\n          rk_memory_lengths (`LongTensor`): the rk lengths `[batch]`\n          coverage (`FloatTensor`): None (not supported yet)\n          rk_final_state (`FloatTensor`): final state of the retrieved keys `[batch x dim]`\n\n        Returns:\n          (`FloatTensor`, `FloatTensor`):\n\n          * Computed vector `[tgt_len x batch x dim]`\n          * Attention distribtutions for each query\n             `[tgt_len x batch x src_len]`\n        \"\"\"", "\n", "\n", "# one step input", "\n", "if", "source", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "one_step", "=", "True", "\n", "source", "=", "source", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "one_step", "=", "False", "\n", "\n", "", "batch", ",", "source_l", ",", "dim", "=", "memory_bank", ".", "size", "(", ")", "\n", "batch_", ",", "target_l", ",", "dim_", "=", "source", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "dim", ")", "\n", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "batch_", ",", "source_l_", "=", "coverage", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "source_l", ",", "source_l_", ")", "\n", "\n", "", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "cover", "=", "coverage", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "memory_bank", "=", "memory_bank", "+", "self", ".", "linear_cover", "(", "cover", ")", ".", "view_as", "(", "memory_bank", ")", "\n", "# memory_bank = self.tanh(memory_bank)", "\n", "\n", "# compute attention scores for the context, as in Luong et al.", "\n", "", "if", "rk_final_state", "is", "not", "None", ":", "\n", "            ", "align", "=", "self", ".", "score", "(", "source", "+", "rk_final_state", ".", "unsqueeze", "(", "1", ")", ",", "memory_bank", ",", "rk", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "align", "=", "self", ".", "score", "(", "source", ",", "memory_bank", ",", "rk", "=", "False", ")", "\n", "\n", "", "mask", "=", "None", "\n", "if", "memory_lengths", "is", "not", "None", ":", "\n", "            ", "mask", "=", "sequence_mask", "(", "memory_lengths", ",", "max_len", "=", "align", ".", "size", "(", "-", "1", ")", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# Make it broadcastable.", "\n", "align", ".", "masked_fill_", "(", "1", "-", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "if", "not", "self", ".", "no_sftmax_bf_rescale", ":", "\n", "# Softmax to normalize attention weights", "\n", "            ", "align_vectors", "=", "self", ".", "softmax", "(", "align", ".", "view", "(", "batch", "*", "target_l", ",", "source_l", ")", ")", "\n", "align_vectors", "=", "align_vectors", ".", "view", "(", "batch", ",", "target_l", ",", "source_l", ")", "\n", "", "else", ":", "\n", "# Summation to normalize the sigmoided attention weights", "\n", "            ", "align", "=", "self", ".", "sigmoid", "(", "align", ")", "\n", "\n", "# calculate the norescaled_align_vectors", "\n", "if", "mask", "is", "not", "None", ":", "\n", "                ", "masked_align", "=", "align", "*", "mask", ".", "float", "(", ")", "\n", "", "normalize_term", "=", "torch", ".", "sum", "(", "masked_align", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "# [batch x tgt_len x 1]", "\n", "align_vectors", "=", "masked_align", "/", "normalize_term", "\n", "\n", "# each context vector c_t is the weighted average", "\n", "# over all the source hidden states", "\n", "", "c", "=", "torch", ".", "bmm", "(", "align_vectors", ",", "memory_bank", ")", "\n", "\n", "rk_c", "=", "None", "\n", "if", "self", ".", "use_retrieved_keys", ":", "\n", "            ", "_", ",", "rk_source_l", ",", "_", "=", "rk_memory_bank", ".", "size", "(", ")", "\n", "rk_align", "=", "self", ".", "score", "(", "source", ",", "rk_memory_bank", ",", "rk", "=", "True", ")", "\n", "\n", "rk_mask", "=", "None", "\n", "if", "rk_memory_lengths", "is", "not", "None", ":", "\n", "                ", "rk_mask", "=", "sequence_mask", "(", "rk_memory_lengths", ",", "max_len", "=", "rk_align", ".", "size", "(", "-", "1", ")", ")", "\n", "rk_mask", "=", "rk_mask", ".", "unsqueeze", "(", "1", ")", "# Make it broadcastable.", "\n", "rk_align", ".", "masked_fill_", "(", "1", "-", "rk_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "# Softmax to normalize attention weights", "\n", "# add for RK", "\n", "", "rk_align_vectors", "=", "self", ".", "softmax", "(", "rk_align", ".", "view", "(", "batch", "*", "target_l", ",", "rk_source_l", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.global_attention.MyGlobalAttention.__init__": [[292, 318], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Tanh", "torch.Tanh", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["aeq", "(", "source_l", ",", "source_l_", ")", "\n", "\n", "", "return", "attn_h", ",", "align_vectors", "\n", "\n", "\n", "", "", "class", "MyGlobalAttention", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.global_attention.MyGlobalAttention.score": [[319, 361], ["h_s.size", "global_attention.MyGlobalAttention.view.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "h_s.transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "global_attention.MyGlobalAttention.linear_query", "wq.expand.expand.view", "wq.expand.expand.expand", "global_attention.MyGlobalAttention.linear_context", "uh.expand.expand.view", "uh.expand.expand.expand", "global_attention.MyGlobalAttention.tanh", "global_attention.MyGlobalAttention.v().view", "global_attention.MyGlobalAttention.view.view", "global_attention.MyGlobalAttention.linear_in", "global_attention.MyGlobalAttention.view", "global_attention.MyGlobalAttention.view.view", "h_s.contiguous().view", "global_attention.MyGlobalAttention.v", "h_s.contiguous", "global_attention.MyGlobalAttention.view"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq"], ["\n", "\n", "def", "__init__", "(", "self", ",", "dim", ",", "coverage", "=", "False", ",", "attn_type", "=", "\"dot\"", ",", "\n", "not_use_sel_probs", "=", "False", ",", "no_sftmax_bf_rescale", "=", "False", ",", "\n", "use_retrieved_keys", "=", "False", ",", "only_rescale_copy", "=", "False", ")", ":", "\n", "        ", "super", "(", "MyGlobalAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "not_use_sel_probs", "=", "not_use_sel_probs", "\n", "self", ".", "no_sftmax_bf_rescale", "=", "no_sftmax_bf_rescale", "\n", "self", ".", "use_retrieved_keys", "=", "use_retrieved_keys", "\n", "self", ".", "only_rescale_copy", "=", "only_rescale_copy", "\n", "self", ".", "dim", "=", "dim", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.global_attention.MyGlobalAttention.forward": [[362, 512], ["memory_bank.size", "source.unsqueeze.unsqueeze.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "global_attention.MyGlobalAttention.score", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "global_attention.MyGlobalAttention.linear_out().view", "source.unsqueeze.unsqueeze.dim", "source.unsqueeze.unsqueeze.unsqueeze", "coverage.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "coverage.view().unsqueeze", "onmt.utils.misc.sequence_mask", "mask.unsqueeze.unsqueeze.unsqueeze", "global_attention.MyGlobalAttention.masked_fill_", "global_attention.MyGlobalAttention.softmax", "norescale_align_vectors.transpose().contiguous.transpose().contiguous.view", "global_attention.MyGlobalAttention.sigmoid", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "global_attention.MyGlobalAttention.tanh", "attn_h.transpose().contiguous.transpose().contiguous.squeeze", "align_vectors.transpose().contiguous.transpose().contiguous.squeeze", "norescale_align_vectors.transpose().contiguous.transpose().contiguous.squeeze", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "attn_h.transpose().contiguous.transpose().contiguous.transpose().contiguous", "align_vectors.transpose().contiguous.transpose().contiguous.transpose().contiguous", "norescale_align_vectors.transpose().contiguous.transpose().contiguous.transpose().contiguous", "attn_h.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "align_vectors.transpose().contiguous.transpose().contiguous.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "global_attention.MyGlobalAttention.linear_cover().view_as", "global_attention.MyGlobalAttention.view", "probs.unsqueeze.unsqueeze.unsqueeze", "probs.unsqueeze.unsqueeze.unsqueeze", "mask.unsqueeze.unsqueeze.float", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "global_attention.MyGlobalAttention.linear_out", "coverage.view", "global_attention.MyGlobalAttention.size", "float", "mask.unsqueeze.unsqueeze.float", "attn_h.transpose().contiguous.transpose().contiguous.transpose", "align_vectors.transpose().contiguous.transpose().contiguous.transpose", "norescale_align_vectors.transpose().contiguous.transpose().contiguous.transpose", "global_attention.MyGlobalAttention.linear_cover"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.GNMTGlobalScorer.score", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.sequence_mask", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq"], ["self", ".", "attn_type", "=", "attn_type", "\n", "\n", "# assert (self.attn_type in [\"dot\", \"general\", \"mlp\"]), (", "\n", "#     \"Please select a valid attention type.\")", "\n", "assert", "(", "self", ".", "attn_type", "==", "\"general\"", ")", ",", "\"Currently, only general attention is supported.\"", "\n", "\n", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "            ", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "if", "self", ".", "use_retrieved_keys", ":", "\n", "                ", "self", ".", "rk_linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "", "", "elif", "self", ".", "attn_type", "==", "\"mlp\"", ":", "\n", "            ", "self", ".", "linear_context", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "# mlp wants it with bias", "\n", "", "out_bias", "=", "self", ".", "attn_type", "==", "\"mlp\"", "\n", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ",", "bias", "=", "out_bias", ")", "\n", "\n", "if", "self", ".", "use_retrieved_keys", ":", "\n", "            ", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "3", ",", "dim", ",", "bias", "=", "out_bias", ")", "\n", "\n", "", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n", "if", "coverage", ":", "\n", "            ", "self", ".", "linear_cover", "=", "nn", ".", "Linear", "(", "1", ",", "dim", ",", "bias", "=", "False", ")", "\n", "\n", "", "", "def", "score", "(", "self", ",", "h_t", ",", "h_s", ",", "rk", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n          h_t (`FloatTensor`): sequence of queries `[batch x tgt_len x dim]`\n          h_s (`FloatTensor`): sequence of sources `[batch x src_len x dim]`\n\n        Returns:\n          :obj:`FloatTensor`:\n           raw attention scores (unnormalized) for each src index\n          `[batch x tgt_len x src_len]`\n\n        \"\"\"", "\n", "\n", "# Check input sizes", "\n", "src_batch", ",", "src_len", ",", "src_dim", "=", "h_s", ".", "size", "(", ")", "\n", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", "=", "h_t", ".", "size", "(", ")", "\n", "aeq", "(", "src_batch", ",", "tgt_batch", ")", "\n", "aeq", "(", "src_dim", ",", "tgt_dim", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "src_dim", ")", "\n", "\n", "if", "self", ".", "attn_type", "in", "[", "\"general\"", ",", "\"dot\"", "]", ":", "\n", "            ", "if", "self", ".", "attn_type", "==", "\"general\"", ":", "\n", "                ", "h_t_", "=", "h_t", ".", "view", "(", "tgt_batch", "*", "tgt_len", ",", "tgt_dim", ")", "\n", "if", "not", "rk", ":", "\n", "                    ", "h_t_", "=", "self", ".", "linear_in", "(", "h_t_", ")", "\n", "", "else", ":", "\n", "                    ", "h_t_", "=", "self", ".", "rk_linear_in", "(", "h_t_", ")", "\n", "", "h_t", "=", "h_t_", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "tgt_dim", ")", "\n", "", "h_s_", "=", "h_s", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# (batch, t_len, d) x (batch, d, s_len) --> (batch, t_len, s_len)", "\n", "return", "torch", ".", "bmm", "(", "h_t", ",", "h_s_", ")", "\n", "", "else", ":", "\n", "            ", "dim", "=", "self", ".", "dim", "\n", "wq", "=", "self", ".", "linear_query", "(", "h_t", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "wq", "=", "wq", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "1", ",", "dim", ")", "\n", "wq", "=", "wq", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "uh", "=", "self", ".", "linear_context", "(", "h_s", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "dim", ")", ")", "\n", "uh", "=", "uh", ".", "view", "(", "src_batch", ",", "1", ",", "src_len", ",", "dim", ")", "\n", "uh", "=", "uh", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ",", "dim", ")", "\n", "\n", "# (batch, t_len, s_len, d)", "\n", "wquh", "=", "self", ".", "tanh", "(", "wq", "+", "uh", ")", "\n", "\n", "return", "self", ".", "v", "(", "wquh", ".", "view", "(", "-", "1", ",", "dim", ")", ")", ".", "view", "(", "tgt_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "source", ",", "memory_bank", ",", "rk_memory_bank", ",", "probs", ",", "memory_lengths", "=", "None", ",", "\n", "rk_memory_lengths", "=", "None", ",", "coverage", "=", "None", ",", "rk_final_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n          input (`FloatTensor`): query vectors `[batch x tgt_len x dim]`\n          memory_bank (`FloatTensor`): source vectors `[batch x src_len x dim]`\n          probs (`FloatTensor`): key probabilities `[batch x src_len]`\n          memory_lengths (`LongTensor`): the source context lengths `[batch]`\n          coverage (`FloatTensor`): None (not supported yet)\n\n        Returns:\n          (`FloatTensor`, `FloatTensor`):\n\n          * Computed vector `[tgt_len x batch x dim]`\n          * Attention distribtutions for each query\n             `[tgt_len x batch x src_len]`\n        \"\"\"", "\n", "\n", "# one step input", "\n", "if", "source", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "one_step", "=", "True", "\n", "source", "=", "source", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "one_step", "=", "False", "\n", "\n", "", "batch", ",", "source_l", ",", "dim", "=", "memory_bank", ".", "size", "(", ")", "\n", "batch_", ",", "target_l", ",", "dim_", "=", "source", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "dim", ",", "dim_", ")", "\n", "aeq", "(", "self", ".", "dim", ",", "dim", ")", "\n", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "batch_", ",", "source_l_", "=", "coverage", ".", "size", "(", ")", "\n", "aeq", "(", "batch", ",", "batch_", ")", "\n", "aeq", "(", "source_l", ",", "source_l_", ")", "\n", "\n", "", "if", "coverage", "is", "not", "None", ":", "\n", "            ", "cover", "=", "coverage", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "memory_bank", "=", "memory_bank", "+", "self", ".", "linear_cover", "(", "cover", ")", ".", "view_as", "(", "memory_bank", ")", "\n", "# memory_bank = self.tanh(memory_bank)", "\n", "\n", "# compute attention scores, as in Luong et al.", "\n", "", "if", "rk_final_state", "is", "not", "None", ":", "\n", "            ", "align", "=", "self", ".", "score", "(", "source", "+", "rk_final_state", ".", "unsqueeze", "(", "1", ")", ",", "memory_bank", ",", "rk", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "align", "=", "self", ".", "score", "(", "source", ",", "memory_bank", ",", "rk", "=", "False", ")", "# [batch x tgt_len x src_len]", "\n", "\n", "\n", "# align_tmp = align.clone()", "\n", "\n", "", "mask", "=", "None", "\n", "if", "memory_lengths", "is", "not", "None", ":", "\n", "            ", "mask", "=", "sequence_mask", "(", "memory_lengths", ",", "max_len", "=", "align", ".", "size", "(", "-", "1", ")", ")", "# [batch x src_len]", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "# Make it broadcastable.  # [batch x 1 x src_len]", "\n", "align", ".", "masked_fill_", "(", "1", "-", "mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "\n", "", "if", "not", "self", ".", "no_sftmax_bf_rescale", ":", "\n", "# Softmax to normalize attention weights", "\n", "            ", "norescale_align_vectors", "=", "self", ".", "softmax", "(", "align", ".", "view", "(", "batch", "*", "target_l", ",", "source_l", ")", ")", "\n", "norescale_align_vectors", "=", "norescale_align_vectors", ".", "view", "(", "batch", ",", "target_l", ",", "source_l", ")", "\n", "\n", "# changed for KE_KG", "\n", "if", "not", "self", ".", "not_use_sel_probs", ":", "\n", "                ", "probs", "=", "probs", ".", "unsqueeze", "(", "1", ")", "# [batch x src_len] -> [batch x 1 x src_len]", "\n", "scaled_align", "=", "norescale_align_vectors", "*", "probs", "# [batch x tgt_len x src_len]", "\n", "", "else", ":", "\n", "                ", "scaled_align", "=", "norescale_align_vectors", "*", "1.0", "\n", "", "", "else", ":", "\n", "# Summation to normalize the sigmoided attention weights", "\n", "            ", "align", "=", "self", ".", "sigmoid", "(", "align", ")", "\n", "\n", "# calculate the norescaled_align_vectors", "\n", "if", "mask", "is", "not", "None", ":", "\n", "                ", "masked_align", "=", "align", "*", "mask", ".", "float", "(", ")", "\n", "", "normalize_term", "=", "torch", ".", "sum", "(", "masked_align", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "# [batch x tgt_len x 1]", "\n", "norescale_align_vectors", "=", "masked_align", "/", "normalize_term", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.gate.ContextGate.__init__": [[29, 38], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "ContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "input_size", "=", "embeddings_size", "+", "decoder_size", "+", "attention_size", "\n", "self", ".", "gate", "=", "nn", ".", "Linear", "(", "input_size", ",", "output_size", ",", "bias", "=", "True", ")", "\n", "self", ".", "sig", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "source_proj", "=", "nn", ".", "Linear", "(", "attention_size", ",", "output_size", ")", "\n", "self", ".", "target_proj", "=", "nn", ".", "Linear", "(", "embeddings_size", "+", "decoder_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.gate.ContextGate.forward": [[39, 46], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "gate.ContextGate.sig", "gate.ContextGate.source_proj", "gate.ContextGate.target_proj", "gate.ContextGate.gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "input_tensor", "=", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ",", "dim", "=", "1", ")", "\n", "z", "=", "self", ".", "sig", "(", "self", ".", "gate", "(", "input_tensor", ")", ")", "\n", "proj_source", "=", "self", ".", "source_proj", "(", "attn_state", ")", "\n", "proj_target", "=", "self", ".", "target_proj", "(", "\n", "torch", ".", "cat", "(", "(", "prev_emb", ",", "dec_state", ")", ",", "dim", "=", "1", ")", ")", "\n", "return", "z", ",", "proj_source", ",", "proj_target", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.gate.SourceContextGate.__init__": [[51, 57], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "SourceContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.gate.SourceContextGate.forward": [[58, 62], ["gate.SourceContextGate.context_gate", "gate.SourceContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "\n", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "target", "+", "z", "*", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.gate.TargetContextGate.__init__": [[67, 73], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "TargetContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.gate.TargetContextGate.forward": [[74, 77], ["gate.TargetContextGate.context_gate", "gate.TargetContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "z", "*", "target", "+", "source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.gate.BothContextGate.__init__": [[82, 88], ["torch.Module.__init__", "gate.ContextGate", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "BothContextGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "context_gate", "=", "ContextGate", "(", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.gate.BothContextGate.forward": [[89, 92], ["gate.BothContextGate.context_gate", "gate.BothContextGate.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_emb", ",", "dec_state", ",", "attn_state", ")", ":", "\n", "        ", "z", ",", "source", ",", "target", "=", "self", ".", "context_gate", "(", "prev_emb", ",", "dec_state", ",", "attn_state", ")", "\n", "return", "self", ".", "tanh", "(", "(", "1.", "-", "z", ")", "*", "target", "+", "z", "*", "source", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.gate.context_gate_factory": [[6, 18], ["None"], "function", ["None"], ["def", "context_gate_factory", "(", "gate_type", ",", "embeddings_size", ",", "decoder_size", ",", "\n", "attention_size", ",", "output_size", ")", ":", "\n", "    ", "\"\"\"Returns the correct ContextGate class\"\"\"", "\n", "\n", "gate_types", "=", "{", "'source'", ":", "SourceContextGate", ",", "\n", "'target'", ":", "TargetContextGate", ",", "\n", "'both'", ":", "BothContextGate", "}", "\n", "\n", "assert", "gate_type", "in", "gate_types", ",", "\"Not valid ContextGate type: {0}\"", ".", "format", "(", "\n", "gate_type", ")", "\n", "return", "gate_types", "[", "gate_type", "]", "(", "embeddings_size", ",", "decoder_size", ",", "attention_size", ",", "\n", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.cnn_decoder.CNNDecoder.__init__": [[24, 57], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "range", "cnn_decoder.CNNDecoder.conv_layers.append", "cnn_decoder.CNNDecoder.attn_layers.append", "onmt.modules.GlobalAttention", "onmt.utils.cnn_factory.GatedConv", "onmt.modules.ConvMultiStepAttention"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "hidden_size", ",", "attn_type", ",", "\n", "copy_attn", ",", "cnn_kernel_width", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "CNNDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'cnn'", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "cnn_kernel_width", "=", "cnn_kernel_width", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "# Build the CNN.", "\n", "input_size", "=", "self", ".", "embeddings", ".", "embedding_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "self", ".", "hidden_size", ")", "\n", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "self", ".", "conv_layers", ".", "append", "(", "\n", "GatedConv", "(", "self", ".", "hidden_size", ",", "self", ".", "cnn_kernel_width", ",", "\n", "self", ".", "dropout", ",", "True", ")", ")", "\n", "\n", "", "self", ".", "attn_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "self", ".", "attn_layers", ".", "append", "(", "\n", "onmt", ".", "modules", ".", "ConvMultiStepAttention", "(", "self", ".", "hidden_size", ")", ")", "\n", "\n", "# CNNDecoder has its own attention mechanism.", "\n", "# Set up a separated copy attention layer, if needed.", "\n", "", "self", ".", "_copy", "=", "False", "\n", "if", "copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "attn_type", ")", "\n", "self", ".", "_copy", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.cnn_decoder.CNNDecoder.forward": [[58, 123], ["isinstance", "torch.cat.size", "torch.cat.size", "memory_bank.size", "onmt.utils.misc.aeq", "cnn_decoder.CNNDecoder.embeddings", "cnn_decoder.CNNDecoder.transpose().contiguous", "memory_bank.transpose().contiguous", "state.init_src.transpose().contiguous", "cnn_decoder.CNNDecoder.transpose().contiguous.contiguous().view", "cnn_decoder.CNNDecoder.linear", "cnn_decoder.CNNDecoder.view", "onmt.utils.cnn_factory.shape_transform", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "pad.type_as.type_as.type_as", "zip", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose.transpose().contiguous", "state.update_state", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cnn_decoder.CNNDecoder.dim", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.size", "onmt.utils.cnn_factory.shape_transform.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "conv", "attention", "attn[].squeeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "cnn_decoder.CNNDecoder.transpose", "memory_bank.transpose", "state.init_src.transpose", "cnn_decoder.CNNDecoder.transpose().contiguous.contiguous", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "cnn_decoder.CNNDecoder.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.squeeze", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose.transpose", "state.previous_input.size", "state.previous_input.size"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.cnn_factory.shape_transform", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.update_state"], ["", "", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\" See :obj:`onmt.modules.RNNDecoderBase.forward()`\"\"\"", "\n", "# NOTE: memory_lengths is only here for compatibility reasons", "\n", "#       with onmt.modules.RNNDecoderBase.forward()", "\n", "# CHECKS", "\n", "assert", "isinstance", "(", "state", ",", "CNNDecoderState", ")", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "_", ",", "contxt_batch", ",", "_", "=", "memory_bank", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "contxt_batch", ")", "\n", "# END CHECKS", "\n", "\n", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "tgt", "=", "torch", ".", "cat", "(", "[", "state", ".", "previous_input", ",", "tgt", "]", ",", "0", ")", "\n", "\n", "# Initialize return variables.", "\n", "", "outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "assert", "not", "self", ".", "_copy", ",", "\"Copy mechanism not yet tested in conv2conv\"", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "tgt_emb", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# The output of CNNEncoder.", "\n", "src_memory_bank_t", "=", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "# The combination of output of CNNEncoder and source embeddings.", "\n", "src_memory_bank_c", "=", "state", ".", "init_src", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Run the forward pass of the CNNDecoder.", "\n", "emb_reshape", "=", "tgt_emb", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "tgt_emb", ".", "size", "(", "0", ")", "*", "tgt_emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "linear_out", "=", "self", ".", "linear", "(", "emb_reshape", ")", "\n", "x", "=", "linear_out", ".", "view", "(", "tgt_emb", ".", "size", "(", "0", ")", ",", "tgt_emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "x", "=", "shape_transform", "(", "x", ")", "\n", "\n", "pad", "=", "torch", ".", "zeros", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "\n", "self", ".", "cnn_kernel_width", "-", "1", ",", "1", ")", "\n", "\n", "pad", "=", "pad", ".", "type_as", "(", "x", ")", "\n", "base_target_emb", "=", "x", "\n", "\n", "for", "conv", ",", "attention", "in", "zip", "(", "self", ".", "conv_layers", ",", "self", ".", "attn_layers", ")", ":", "\n", "            ", "new_target_input", "=", "torch", ".", "cat", "(", "[", "pad", ",", "x", "]", ",", "2", ")", "\n", "out", "=", "conv", "(", "new_target_input", ")", "\n", "c", ",", "attn", "=", "attention", "(", "base_target_emb", ",", "out", ",", "\n", "src_memory_bank_t", ",", "src_memory_bank_c", ")", "\n", "x", "=", "(", "x", "+", "(", "c", "+", "out", ")", "*", "SCALE_WEIGHT", ")", "*", "SCALE_WEIGHT", "\n", "", "output", "=", "x", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "# Process the result and update the attentions.", "\n", "outputs", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "outputs", "[", "state", ".", "previous_input", ".", "size", "(", "0", ")", ":", "]", "\n", "attn", "=", "attn", "[", ":", ",", "state", ".", "previous_input", ".", "size", "(", "0", ")", ":", "]", ".", "squeeze", "(", ")", "\n", "attn", "=", "torch", ".", "stack", "(", "[", "attn", "]", ")", "\n", "", "attns", "[", "\"std\"", "]", "=", "attn", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "attn", "\n", "\n", "# Update the state.", "\n", "", "state", ".", "update_state", "(", "tgt", ")", "\n", "\n", "return", "outputs", ",", "state", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.cnn_decoder.CNNDecoder.init_decoder_state": [[124, 129], ["cnn_decoder.CNNDecoderState"], "methods", ["None"], ["", "def", "init_decoder_state", "(", "self", ",", "_", ",", "memory_bank", ",", "enc_hidden", ",", "with_cache", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Init decoder state.\n        \"\"\"", "\n", "return", "CNNDecoderState", "(", "memory_bank", ",", "enc_hidden", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.cnn_decoder.CNNDecoderState.__init__": [[136, 139], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "memory_bank", ",", "enc_hidden", ")", ":", "\n", "        ", "self", ".", "init_src", "=", "(", "memory_bank", "+", "enc_hidden", ")", "*", "SCALE_WEIGHT", "\n", "self", ".", "previous_input", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.cnn_decoder.CNNDecoderState._all": [[140, 146], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_all", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Contains attributes that need to be updated in self.beam_update().\n        \"\"\"", "\n", "return", "(", "self", ".", "previous_input", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.cnn_decoder.CNNDecoderState.detach": [[147, 149], ["cnn_decoder.CNNDecoderState.previous_input.detach"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.detach"], ["", "def", "detach", "(", "self", ")", ":", "\n", "        ", "self", ".", "previous_input", "=", "self", ".", "previous_input", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.cnn_decoder.CNNDecoderState.update_state": [[150, 153], ["None"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "new_input", ")", ":", "\n", "        ", "\"\"\" Called for every decoder forward pass. \"\"\"", "\n", "self", ".", "previous_input", "=", "new_input", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.cnn_decoder.CNNDecoderState.repeat_beam_size_times": [[154, 157], ["cnn_decoder.CNNDecoderState.init_src.data.repeat"], "methods", ["None"], ["", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "self", ".", "init_src", "=", "self", ".", "init_src", ".", "data", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.RNNDecoderBase.__init__": [[59, 103], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "decoder.RNNDecoderBase._build_rnn", "onmt.modules.GlobalAttention", "onmt.modules.context_gate_factory", "onmt.modules.GlobalAttention"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.MyInputFeedRNNDecoder._build_rnn", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.modules.gate.context_gate_factory"], ["\n", "\n", "def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional_encoder", ",", "num_layers", ",", "\n", "hidden_size", ",", "attn_type", "=", "\"general\"", ",", "\n", "coverage_attn", "=", "False", ",", "context_gate", "=", "None", ",", "\n", "copy_attn", "=", "False", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "reuse_copy_attn", "=", "False", ",", "no_sftmax_bf_rescale", "=", "False", ",", "\n", "use_retrieved_keys", "=", "False", ",", "only_rescale_copy", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNDecoderBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# add for RK", "\n", "self", ".", "use_retrieved_keys", "=", "use_retrieved_keys", "\n", "self", ".", "only_rescale_copy", "=", "only_rescale_copy", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'rnn'", "\n", "self", ".", "bidirectional_encoder", "=", "bidirectional_encoder", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "# Build the RNN.", "\n", "self", ".", "rnn", "=", "self", ".", "_build_rnn", "(", "rnn_type", ",", "\n", "input_size", "=", "self", ".", "_input_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", "if", "num_layers", "!=", "1", "else", "0.0", ")", "\n", "\n", "# Set up the context gate.", "\n", "self", ".", "context_gate", "=", "None", "\n", "if", "context_gate", "is", "not", "None", ":", "\n", "            ", "self", ".", "context_gate", "=", "onmt", ".", "modules", ".", "context_gate_factory", "(", "\n", "context_gate", ",", "self", ".", "_input_size", ",", "\n", "hidden_size", ",", "hidden_size", ",", "hidden_size", "\n", ")", "\n", "\n", "# Set up the standard attention.", "\n", "", "self", ".", "_coverage", "=", "coverage_attn", "\n", "self", ".", "attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "coverage", "=", "coverage_attn", ",", "\n", "attn_type", "=", "attn_type", ",", "no_sftmax_bf_rescale", "=", "no_sftmax_bf_rescale", ",", "use_retrieved_keys", "=", "self", ".", "use_retrieved_keys", ")", "\n", "\n", "# Set up a separated copy attention layer, if needed.", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.RNNDecoderBase.forward": [[104, 157], ["isinstance", "tgt.size", "memory_bank.size", "onmt.utils.misc.aeq", "decoder.RNNDecoderBase._run_forward_pass", "state.update_state", "[].unsqueeze", "final_output.unsqueeze", "type", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "type", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.MyInputFeedRNNDecoder._run_forward_pass", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.update_state"], ["self", ".", "_copy", "=", "False", "\n", "if", "copy_attn", "and", "not", "reuse_copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "hidden_size", ",", "attn_type", "=", "attn_type", ",", "\n", "no_sftmax_bf_rescale", "=", "no_sftmax_bf_rescale", ",", "use_retrieved_keys", "=", "self", ".", "use_retrieved_keys", ")", "\n", "", "if", "copy_attn", ":", "\n", "            ", "self", ".", "_copy", "=", "True", "\n", "", "self", ".", "_reuse_copy_attn", "=", "reuse_copy_attn", "\n", "\n", "", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "rk_memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "\n", "rk_memory_lengths", "=", "None", ",", "probs", "=", "None", ",", "step", "=", "None", ",", "rk_final_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tgt (`LongTensor`): sequences of padded tokens\n                 `[tgt_len x batch x nfeats]`.\n            memory_bank (`FloatTensor`): vectors from the encoder\n                 `[src_len x batch x hidden]`.\n            rk_memory_bank (`FloatTensor`): vectors from the rk_encoder\n                 `[rk_len x batch x hidden]`.\n            state (:obj:`onmt.models.DecoderState`):\n                 decoder state object to initialize the decoder\n            memory_lengths (`LongTensor`): the padded source lengths\n                `[batch]`.\n            rk_memory_lengths (`LongTensor`): the padded retrieved keyphrase lengths\n                 `[batch]`.\n            probs (`FloatTensor`): the predicted importance scores from the selector\n                 `[src_len x batch]`\n            step (int): current step\n            rk_final_state (tuple): the final state of the rk_encoder\n        Returns:\n            (`FloatTensor`,:obj:`onmt.Models.DecoderState`,`FloatTensor`):\n                * decoder_outputs: output from the decoder (after attn)\n                         `[tgt_len x batch x hidden]`.\n                * decoder_state: final hidden state from the decoder\n                * attns: distribution over src at each tgt\n                        `[tgt_len x batch x src_len]`.\n        \"\"\"", "\n", "# Check", "\n", "assert", "isinstance", "(", "state", ",", "RNNDecoderState", ")", "\n", "# tgt.size() returns tgt length and batch", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "_", ",", "memory_batch", ",", "_", "=", "memory_bank", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "memory_batch", ")", "\n", "# END", "\n", "\n", "# Run the forward pass of the RNN.", "\n", "decoder_final", ",", "decoder_outputs", ",", "attns", "=", "self", ".", "_run_forward_pass", "(", "\n", "tgt", ",", "memory_bank", ",", "rk_memory_bank", ",", "state", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "rk_memory_lengths", "=", "rk_memory_lengths", ",", "probs", "=", "probs", ",", "rk_final_state", "=", "rk_final_state", ")", "\n", "\n", "# Update the state with the result.", "\n", "final_output", "=", "decoder_outputs", "[", "-", "1", "]", "\n", "coverage", "=", "None", "\n", "if", "\"coverage\"", "in", "attns", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.RNNDecoderBase.init_decoder_state": [[158, 176], ["isinstance", "decoder.RNNDecoderState", "decoder.RNNDecoderState", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tuple", "decoder.RNNDecoderBase.init_decoder_state._fix_enc_hidden"], "methods", ["None"], ["            ", "coverage", "=", "attns", "[", "\"coverage\"", "]", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "", "state", ".", "update_state", "(", "decoder_final", ",", "final_output", ".", "unsqueeze", "(", "0", ")", ",", "coverage", ")", "\n", "\n", "# Concatenates sequence of tensors along a new dimension.", "\n", "# NOTE: v0.3 to 0.4: decoder_outputs / attns[*] may not be list", "\n", "#       (in particular in case of SRU) it was not raising error in 0.3", "\n", "#       since stack(Variable) was allowed.", "\n", "#       In 0.4, SRU returns a tensor that shouldn't be stacke", "\n", "if", "type", "(", "decoder_outputs", ")", "==", "list", ":", "\n", "            ", "decoder_outputs", "=", "torch", ".", "stack", "(", "decoder_outputs", ")", "\n", "\n", "for", "k", "in", "attns", ":", "\n", "                ", "if", "type", "(", "attns", "[", "k", "]", ")", "==", "list", ":", "\n", "                    ", "attns", "[", "k", "]", "=", "torch", ".", "stack", "(", "attns", "[", "k", "]", ")", "\n", "\n", "", "", "", "return", "decoder_outputs", ",", "state", ",", "attns", "\n", "\n", "", "def", "init_decoder_state", "(", "self", ",", "src", ",", "memory_bank", ",", "encoder_final", ",", "\n", "with_cache", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.StdRNNDecoder._run_forward_pass": [[194, 254], ["decoder.StdRNNDecoder.embeddings", "isinstance", "tgt.size", "rnn_output.size", "onmt.utils.misc.aeq", "onmt.utils.misc.aeq", "decoder.StdRNNDecoder.attn", "decoder.StdRNNDecoder.dropout", "decoder.StdRNNDecoder.rnn", "decoder.StdRNNDecoder.rnn", "rnn_output.transpose().contiguous", "memory_bank.transpose", "decoder.StdRNNDecoder.context_gate", "decoder_outputs.view.view.view", "decoder.StdRNNDecoder.view", "rnn_output.view", "decoder_outputs.view.view.view", "rnn_output.transpose", "decoder.StdRNNDecoder.size", "rnn_output.size", "decoder_outputs.view.view.size"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq"], ["\n", "", "", "", "class", "StdRNNDecoder", "(", "RNNDecoderBase", ")", ":", "\n", "    ", "\"\"\"\n    Standard fully batched RNN decoder with attention.\n    Faster implementation, uses CuDNN for implementation.\n    See :obj:`RNNDecoderBase` for options.\n\n\n    Based around the approach from\n    \"Neural Machine Translation By Jointly Learning To Align and Translate\"\n    :cite:`Bahdanau2015`\n\n\n    Implemented without input_feeding and currently with no `coverage_attn`\n    or `copy_attn` support.\n    \"\"\"", "\n", "\n", "def", "_run_forward_pass", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "probs", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Private helper for running the specific RNN forward pass.\n        Must be overriden by all subclasses.\n        Args:\n            tgt (LongTensor): a sequence of input tokens tensors\n                                 [len x batch x nfeats].\n            memory_bank (FloatTensor): output(tensor sequence) from the encoder\n                        RNN of size (src_len x batch x hidden_size).\n            state (FloatTensor): hidden state from the encoder RNN for\n                                 initializing the decoder.\n            memory_lengths (LongTensor): the source memory_bank lengths.\n        Returns:\n            decoder_final (Tensor): final hidden state from the decoder.\n            decoder_outputs ([FloatTensor]): an array of output of every time\n                                     step from the decoder.\n            attns (dict of (str, [FloatTensor]): a dictionary of different\n                            type of attention Tensor array of every time\n                            step from the decoder.\n        \"\"\"", "\n", "assert", "not", "self", ".", "_copy", "# TODO, no support yet.", "\n", "assert", "not", "self", ".", "_coverage", "# TODO, no support yet.", "\n", "\n", "# Initialize local and return variables.", "\n", "attns", "=", "{", "}", "\n", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "\n", "# Run the forward pass of the RNN.", "\n", "if", "isinstance", "(", "self", ".", "rnn", ",", "nn", ".", "GRU", ")", ":", "\n", "            ", "rnn_output", ",", "decoder_final", "=", "self", ".", "rnn", "(", "emb", ",", "state", ".", "hidden", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "rnn_output", ",", "decoder_final", "=", "self", ".", "rnn", "(", "emb", ",", "state", ".", "hidden", ")", "\n", "\n", "# Check", "\n", "", "tgt_len", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "output_len", ",", "output_batch", ",", "_", "=", "rnn_output", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_len", ",", "output_len", ")", "\n", "aeq", "(", "tgt_batch", ",", "output_batch", ")", "\n", "# END", "\n", "\n", "# Calculate the attention.", "\n", "decoder_outputs", ",", "p_attn", "=", "self", ".", "attn", "(", "\n", "rnn_output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.StdRNNDecoder._build_rnn": [[255, 258], ["onmt.utils.rnn_factory.rnn_factory"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.rnn_factory.rnn_factory"], ["memory_lengths", "=", "memory_lengths", "\n", ")", "\n", "attns", "[", "\"std\"", "]", "=", "p_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.StdRNNDecoder._input_size": [[259, 265], ["None"], "methods", ["None"], ["# Calculate the context gate.", "\n", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "            ", "decoder_outputs", "=", "self", ".", "context_gate", "(", "\n", "emb", ".", "view", "(", "-", "1", ",", "emb", ".", "size", "(", "2", ")", ")", ",", "\n", "rnn_output", ".", "view", "(", "-", "1", ",", "rnn_output", ".", "size", "(", "2", ")", ")", ",", "\n", "decoder_outputs", ".", "view", "(", "-", "1", ",", "decoder_outputs", ".", "size", "(", "2", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.InputFeedRNNDecoder._run_forward_pass": [[294, 360], ["state.input_feed.squeeze", "state.input_feed.squeeze.size", "tgt.size", "onmt.utils.misc.aeq", "decoder.InputFeedRNNDecoder.embeddings", "enumerate", "decoder.InputFeedRNNDecoder.dim", "state.coverage.squeeze", "decoder.InputFeedRNNDecoder.split", "emb_t.squeeze.squeeze.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder.InputFeedRNNDecoder.rnn", "decoder.InputFeedRNNDecoder.attn", "decoder.InputFeedRNNDecoder.dropout", "memory_bank.transpose", "decoder.InputFeedRNNDecoder.context_gate", "decoder.InputFeedRNNDecoder.copy_attn", "memory_bank.transpose"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq"], ["\n", "\n", "def", "_run_forward_pass", "(", "self", ",", "tgt", ",", "memory_bank", ",", "rk_memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "\n", "rk_memory_lengths", "=", "None", ",", "probs", "=", "None", ",", "rk_final_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See StdRNNDecoder._run_forward_pass() for description\n        of arguments and return values.\n        \"\"\"", "\n", "# Additional args check.", "\n", "input_feed", "=", "state", ".", "input_feed", ".", "squeeze", "(", "0", ")", "\n", "input_feed_batch", ",", "_", "=", "input_feed", ".", "size", "(", ")", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "input_feed_batch", ")", "\n", "# END Additional args check.", "\n", "\n", "# Initialize local and return variables.", "\n", "decoder_outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "", "if", "self", ".", "_coverage", ":", "\n", "            ", "attns", "[", "\"coverage\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "hidden", "=", "state", ".", "hidden", "\n", "coverage", "=", "state", ".", "coverage", ".", "squeeze", "(", "0", ")", "if", "state", ".", "coverage", "is", "not", "None", "else", "None", "\n", "\n", "# Input feed concatenates hidden state with", "\n", "# input at every time step.", "\n", "for", "_", ",", "emb_t", "in", "enumerate", "(", "emb", ".", "split", "(", "1", ")", ")", ":", "\n", "            ", "emb_t", "=", "emb_t", ".", "squeeze", "(", "0", ")", "\n", "decoder_input", "=", "torch", ".", "cat", "(", "[", "emb_t", ",", "input_feed", "]", ",", "1", ")", "\n", "\n", "rnn_output", ",", "hidden", "=", "self", ".", "rnn", "(", "decoder_input", ",", "hidden", ")", "\n", "decoder_output", ",", "p_attn", "=", "self", ".", "attn", "(", "\n", "rnn_output", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "rk_memory_bank", ".", "transpose", "(", "0", ",", "1", ")", "if", "rk_memory_bank", "is", "not", "None", "else", "None", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "\n", "rk_memory_lengths", "=", "rk_memory_lengths", ",", "\n", "coverage", "=", "coverage", ",", "\n", "rk_final_state", "=", "rk_final_state", ")", "\n", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "# TODO: context gate should be employed", "\n", "# instead of second RNN transform.", "\n", "                ", "decoder_output", "=", "self", ".", "context_gate", "(", "\n", "decoder_input", ",", "rnn_output", ",", "decoder_output", "\n", ")", "\n", "", "decoder_output", "=", "self", ".", "dropout", "(", "decoder_output", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.InputFeedRNNDecoder._build_rnn": [[361, 371], ["stacked_cell"], "methods", ["None"], ["input_feed", "=", "decoder_output", "\n", "\n", "decoder_outputs", "+=", "[", "decoder_output", "]", "\n", "attns", "[", "\"std\"", "]", "+=", "[", "p_attn", "]", "\n", "\n", "# Update the coverage attention.", "\n", "if", "self", ".", "_coverage", ":", "\n", "                ", "coverage", "=", "coverage", "+", "p_attn", "if", "coverage", "is", "not", "None", "else", "p_attn", "\n", "attns", "[", "\"coverage\"", "]", "+=", "[", "coverage", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.InputFeedRNNDecoder._input_size": [[372, 378], ["None"], "methods", ["None"], ["# Run the forward pass of the copy attention layer.", "\n", "", "if", "self", ".", "_copy", "and", "not", "self", ".", "_reuse_copy_attn", ":", "\n", "                ", "_", ",", "copy_attn", "=", "self", ".", "copy_attn", "(", "decoder_output", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "attns", "[", "\"copy\"", "]", "+=", "[", "copy_attn", "]", "\n", "", "elif", "self", ".", "_copy", ":", "\n", "                ", "attns", "[", "\"copy\"", "]", "=", "attns", "[", "\"std\"", "]", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.MyInputFeedRNNDecoder.__init__": [[407, 425], ["decoder.RNNDecoderBase.__init__", "onmt.modules.MyGlobalAttention"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], []], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.MyInputFeedRNNDecoder._run_forward_pass": [[426, 497], ["state.input_feed.squeeze", "state.input_feed.squeeze.size", "tgt.size", "onmt.utils.misc.aeq", "decoder.MyInputFeedRNNDecoder.embeddings", "enumerate", "decoder.MyInputFeedRNNDecoder.dim", "state.coverage.squeeze", "decoder.MyInputFeedRNNDecoder.split", "emb_t.squeeze.squeeze.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder.MyInputFeedRNNDecoder.rnn", "decoder.MyInputFeedRNNDecoder.attn", "decoder.MyInputFeedRNNDecoder.dropout", "memory_bank.transpose", "probs.transpose", "decoder.MyInputFeedRNNDecoder.context_gate", "decoder.MyInputFeedRNNDecoder.copy_attn", "memory_bank.transpose"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq"], ["\n", "\n", "def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional_encoder", ",", "num_layers", ",", "\n", "hidden_size", ",", "attn_type", "=", "\"general\"", ",", "\n", "coverage_attn", "=", "False", ",", "context_gate", "=", "None", ",", "\n", "copy_attn", "=", "False", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "reuse_copy_attn", "=", "False", ",", "not_use_sel_probs", "=", "False", ",", "\n", "no_sftmax_bf_rescale", "=", "False", ",", "use_retrieved_keys", "=", "False", ",", "\n", "only_rescale_copy", "=", "False", ")", ":", "\n", "\n", "# dropout = 0.0 if num_layers == 1 else dropout", "\n", "        ", "super", "(", "MyInputFeedRNNDecoder", ",", "self", ")", ".", "__init__", "(", "rnn_type", ",", "bidirectional_encoder", ",", "num_layers", ",", "\n", "hidden_size", ",", "attn_type", ",", "\n", "coverage_attn", ",", "context_gate", ",", "\n", "copy_attn", ",", "dropout", ",", "embeddings", ",", "\n", "reuse_copy_attn", ",", "no_sftmax_bf_rescale", ",", "\n", "use_retrieved_keys", ",", "only_rescale_copy", ")", "\n", "\n", "assert", "reuse_copy_attn", "\n", "self", ".", "attn", "=", "onmt", ".", "modules", ".", "MyGlobalAttention", "(", "\n", "dim", "=", "hidden_size", ",", "\n", "coverage", "=", "coverage_attn", ",", "\n", "attn_type", "=", "attn_type", ",", "\n", "not_use_sel_probs", "=", "not_use_sel_probs", ",", "\n", "no_sftmax_bf_rescale", "=", "no_sftmax_bf_rescale", ",", "\n", "use_retrieved_keys", "=", "use_retrieved_keys", ",", "\n", "only_rescale_copy", "=", "only_rescale_copy", ")", "\n", "\n", "", "def", "_run_forward_pass", "(", "self", ",", "tgt", ",", "memory_bank", ",", "rk_memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "\n", "rk_memory_lengths", "=", "None", ",", "probs", "=", "None", ",", "rk_final_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See StdRNNDecoder._run_forward_pass() for description\n        of arguments and return values.\n        probs (FloatTensor): output(tensor sequence) from the selector\n                        RNN of size (src_len x batch).\n        \"\"\"", "\n", "# Additional args check.", "\n", "input_feed", "=", "state", ".", "input_feed", ".", "squeeze", "(", "0", ")", "\n", "input_feed_batch", ",", "_", "=", "input_feed", ".", "size", "(", ")", "\n", "_", ",", "tgt_batch", ",", "_", "=", "tgt", ".", "size", "(", ")", "\n", "aeq", "(", "tgt_batch", ",", "input_feed_batch", ")", "\n", "# END Additional args check.", "\n", "\n", "# Initialize local and return variables.", "\n", "decoder_outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", ",", "\"norescale_std\"", ":", "[", "]", "}", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "", "if", "self", ".", "_coverage", ":", "\n", "            ", "attns", "[", "\"coverage\"", "]", "=", "[", "]", "\n", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "hidden", "=", "state", ".", "hidden", "\n", "coverage", "=", "state", ".", "coverage", ".", "squeeze", "(", "0", ")", "if", "state", ".", "coverage", "is", "not", "None", "else", "None", "\n", "\n", "# Input feed concatenates hidden state with", "\n", "# input at every time step.", "\n", "for", "_", ",", "emb_t", "in", "enumerate", "(", "emb", ".", "split", "(", "1", ")", ")", ":", "\n", "            ", "emb_t", "=", "emb_t", ".", "squeeze", "(", "0", ")", "\n", "decoder_input", "=", "torch", ".", "cat", "(", "[", "emb_t", ",", "input_feed", "]", ",", "1", ")", "\n", "\n", "rnn_output", ",", "hidden", "=", "self", ".", "rnn", "(", "decoder_input", ",", "hidden", ")", "\n", "decoder_output", ",", "p_attn", ",", "norescale_p_attn", "=", "self", ".", "attn", "(", "\n", "rnn_output", ",", "\n", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "rk_memory_bank", ".", "transpose", "(", "0", ",", "1", ")", "if", "rk_memory_bank", "is", "not", "None", "else", "None", ",", "\n", "probs", ".", "transpose", "(", "0", ",", "1", ")", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "\n", "rk_memory_lengths", "=", "rk_memory_lengths", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.MyInputFeedRNNDecoder._build_rnn": [[498, 508], ["stacked_cell"], "methods", ["None"], ["coverage", "=", "coverage", ",", "\n", "rk_final_state", "=", "rk_final_state", ")", "\n", "if", "self", ".", "context_gate", "is", "not", "None", ":", "\n", "# TODO: context gate should be employed", "\n", "# instead of second RNN transform.", "\n", "                ", "decoder_output", "=", "self", ".", "context_gate", "(", "\n", "decoder_input", ",", "rnn_output", ",", "decoder_output", "\n", ")", "\n", "", "decoder_output", "=", "self", ".", "dropout", "(", "decoder_output", ")", "\n", "input_feed", "=", "decoder_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.MyInputFeedRNNDecoder._input_size": [[509, 515], ["None"], "methods", ["None"], ["decoder_outputs", "+=", "[", "decoder_output", "]", "\n", "attns", "[", "\"std\"", "]", "+=", "[", "p_attn", "]", "\n", "# add for KE_KG", "\n", "attns", "[", "\"norescale_std\"", "]", "+=", "[", "norescale_p_attn", "]", "\n", "\n", "# Update the coverage attention.", "\n", "if", "self", ".", "_coverage", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.DecoderState.detach": [[525, 529], ["tuple", "decoder.DecoderState.input_feed.detach", "_.detach"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.detach", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.detach"], ["", "elif", "self", ".", "_copy", ":", "\n", "                ", "attns", "[", "\"copy\"", "]", "=", "attns", "[", "\"std\"", "]", "\n", "# Return result.", "\n", "", "", "return", "hidden", ",", "decoder_outputs", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.DecoderState.beam_update": [[530, 546], ["e.size", "sent_states.data.copy_", "len", "sent_states.data.index_select", "e.view", "e.view"], "methods", ["None"], ["", "def", "_build_rnn", "(", "self", ",", "rnn_type", ",", "input_size", ",", "\n", "hidden_size", ",", "num_layers", ",", "dropout", ")", ":", "\n", "        ", "assert", "not", "rnn_type", "==", "\"SRU\"", ",", "\"SRU doesn't support input feed! \"", "\"Please set -input_feed 0!\"", "\n", "if", "rnn_type", "==", "\"LSTM\"", ":", "\n", "            ", "stacked_cell", "=", "onmt", ".", "models", ".", "stacked_rnn", ".", "StackedLSTM", "\n", "", "else", ":", "\n", "            ", "stacked_cell", "=", "onmt", ".", "models", ".", "stacked_rnn", ".", "StackedGRU", "\n", "", "return", "stacked_cell", "(", "num_layers", ",", "input_size", ",", "\n", "hidden_size", ",", "dropout", ")", "\n", "\n", "", "@", "property", "\n", "def", "_input_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Using input feed by concatenating input with attention vectors.\n        \"\"\"", "\n", "return", "self", ".", "embeddings", ".", "embedding_size", "+", "self", ".", "hidden_size", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.DecoderState.map_batch_fn": [[547, 549], ["NotImplementedError"], "methods", ["None"], ["\n", "\n", "", "", "class", "DecoderState", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.RNNDecoderState.__init__": [[554, 572], ["decoder.RNNDecoderState.hidden[].size", "decoder.RNNDecoderState.hidden[].data.new().zero_().unsqueeze", "isinstance", "decoder.RNNDecoderState.hidden[].data.new().zero_", "decoder.RNNDecoderState.hidden[].data.new"], "methods", ["None"], ["\n", "def", "detach", "(", "self", ")", ":", "\n", "        ", "\"\"\" Need to document this \"\"\"", "\n", "self", ".", "hidden", "=", "tuple", "(", "[", "_", ".", "detach", "(", ")", "for", "_", "in", "self", ".", "hidden", "]", ")", "\n", "self", ".", "input_feed", "=", "self", ".", "input_feed", ".", "detach", "(", ")", "\n", "\n", "", "def", "beam_update", "(", "self", ",", "idx", ",", "positions", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Need to document this \"\"\"", "\n", "for", "e", "in", "self", ".", "_all", ":", "\n", "            ", "sizes", "=", "e", ".", "size", "(", ")", "\n", "br", "=", "sizes", "[", "1", "]", "\n", "if", "len", "(", "sizes", ")", "==", "3", ":", "\n", "                ", "sent_states", "=", "e", ".", "view", "(", "sizes", "[", "0", "]", ",", "beam_size", ",", "br", "//", "beam_size", ",", "\n", "sizes", "[", "2", "]", ")", "[", ":", ",", ":", ",", "idx", "]", "\n", "", "else", ":", "\n", "                ", "sent_states", "=", "e", ".", "view", "(", "sizes", "[", "0", "]", ",", "beam_size", ",", "\n", "br", "//", "beam_size", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.RNNDecoderState._all": [[573, 576], ["None"], "methods", ["None"], ["sizes", "[", "2", "]", ",", "\n", "sizes", "[", "3", "]", ")", "[", ":", ",", ":", ",", "idx", "]", "\n", "\n", "", "sent_states", ".", "data", ".", "copy_", "(", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.RNNDecoderState.update_state": [[577, 585], ["isinstance"], "methods", ["None"], ["sent_states", ".", "data", ".", "index_select", "(", "1", ",", "positions", ")", ")", "\n", "\n", "", "", "def", "map_batch_fn", "(", "self", ",", "fn", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "\n", "", "", "class", "RNNDecoderState", "(", "DecoderState", ")", ":", "\n", "    ", "\"\"\" Base class for RNN decoder state \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.RNNDecoderState.repeat_beam_size_times": [[586, 592], ["tuple", "e.data.repeat"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "hidden_size", ",", "rnnstate", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            hidden_size (int): the size of hidden layer of the decoder.\n            rnnstate: final hidden state from the encoder.\n                transformed to shape: layers x batch x (directions*dim).\n        \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.decoder.RNNDecoderState.map_batch_fn": [[593, 596], ["tuple", "fn", "map", "fn"], "methods", ["None"], ["if", "not", "isinstance", "(", "rnnstate", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "hidden", "=", "(", "rnnstate", ",", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "hidden", "=", "rnnstate", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderLayer.__init__": [[28, 52], ["torch.Module.__init__", "onmt.modules.MultiHeadedAttention", "onmt.modules.position_ffn.PositionwiseFeedForward", "onmt.modules.LayerNorm", "onmt.modules.LayerNorm", "torch.Dropout", "torch.Dropout", "transformer.TransformerDecoderLayer._get_attn_subsequent_mask", "transformer.TransformerDecoderLayer.register_buffer", "onmt.modules.MultiHeadedAttention", "onmt.modules.AverageAttention"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderLayer._get_attn_subsequent_mask"], ["def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "\n", "self_attn_type", "=", "\"scaled-dot\"", ")", ":", "\n", "        ", "super", "(", "TransformerDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "self_attn_type", "=", "self_attn_type", "\n", "\n", "if", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "onmt", ".", "modules", ".", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "", "elif", "self_attn_type", "==", "\"average\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "onmt", ".", "modules", ".", "AverageAttention", "(", "\n", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "\n", "", "self", ".", "context_attn", "=", "onmt", ".", "modules", ".", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "dropout", ")", "\n", "self", ".", "layer_norm_1", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "layer_norm_2", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "mask", "=", "self", ".", "_get_attn_subsequent_mask", "(", "MAX_SIZE", ")", "\n", "# Register self.mask as a buffer in TransformerDecoderLayer, so", "\n", "# it gets TransformerDecoderLayer's cuda behavior automatically.", "\n", "self", ".", "register_buffer", "(", "'mask'", ",", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderLayer.forward": [[53, 98], ["torch.gt", "torch.gt", "torch.gt", "torch.gt", "transformer.TransformerDecoderLayer.layer_norm_1", "transformer.TransformerDecoderLayer.layer_norm_2", "transformer.TransformerDecoderLayer.context_attn", "transformer.TransformerDecoderLayer.feed_forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.drop", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.drop", "tgt_pad_mask.size", "tgt_pad_mask.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "memory_bank", ",", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n", "previous_input", "=", "None", ",", "layer_cache", "=", "None", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (`FloatTensor`): `[batch_size x 1 x model_dim]`\n            memory_bank (`FloatTensor`): `[batch_size x src_len x model_dim]`\n            src_pad_mask (`LongTensor`): `[batch_size x 1 x src_len]`\n            tgt_pad_mask (`LongTensor`): `[batch_size x 1 x 1]`\n\n        Returns:\n            (`FloatTensor`, `FloatTensor`, `FloatTensor`):\n\n            * output `[batch_size x 1 x model_dim]`\n            * attn `[batch_size x 1 x src_len]`\n            * all_input `[batch_size x current_step x model_dim]`\n\n        \"\"\"", "\n", "dec_mask", "=", "torch", ".", "gt", "(", "tgt_pad_mask", "+", "\n", "self", ".", "mask", "[", ":", ",", ":", "tgt_pad_mask", ".", "size", "(", "1", ")", ",", "\n", ":", "tgt_pad_mask", ".", "size", "(", "1", ")", "]", ",", "0", ")", "\n", "input_norm", "=", "self", ".", "layer_norm_1", "(", "inputs", ")", "\n", "all_input", "=", "input_norm", "\n", "if", "previous_input", "is", "not", "None", ":", "\n", "            ", "all_input", "=", "torch", ".", "cat", "(", "(", "previous_input", ",", "input_norm", ")", ",", "dim", "=", "1", ")", "\n", "dec_mask", "=", "None", "\n", "\n", "", "if", "self", ".", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "all_input", ",", "all_input", ",", "input_norm", ",", "\n", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"self\"", ")", "\n", "", "elif", "self", ".", "self_attn_type", "==", "\"average\"", ":", "\n", "            ", "query", ",", "attn", "=", "self", ".", "self_attn", "(", "input_norm", ",", "mask", "=", "dec_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "step", "=", "step", ")", "\n", "\n", "", "query", "=", "self", ".", "drop", "(", "query", ")", "+", "inputs", "\n", "\n", "query_norm", "=", "self", ".", "layer_norm_2", "(", "query", ")", "\n", "mid", ",", "attn", "=", "self", ".", "context_attn", "(", "memory_bank", ",", "memory_bank", ",", "query_norm", ",", "\n", "mask", "=", "src_pad_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"context\"", ")", "\n", "output", "=", "self", ".", "feed_forward", "(", "self", ".", "drop", "(", "mid", ")", "+", "query", ")", "\n", "\n", "return", "output", ",", "attn", ",", "all_input", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderLayer._get_attn_subsequent_mask": [[99, 115], ["numpy.triu().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.triu", "numpy.ones"], "methods", ["None"], ["", "def", "_get_attn_subsequent_mask", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"\n        Get an attention mask to avoid using the subsequent info.\n\n        Args:\n            size: int\n\n        Returns:\n            (`LongTensor`):\n\n            * subsequent_mask `[1 x size x size]`\n        \"\"\"", "\n", "attn_shape", "=", "(", "1", ",", "size", ",", "size", ")", "\n", "subsequent_mask", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "attn_shape", ")", ",", "k", "=", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "subsequent_mask", "=", "torch", ".", "from_numpy", "(", "subsequent_mask", ")", "\n", "return", "subsequent_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoder.__init__": [[147, 171], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "onmt.modules.LayerNorm", "onmt.modules.GlobalAttention", "transformer.TransformerDecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "d_model", ",", "heads", ",", "d_ff", ",", "attn_type", ",", "\n", "copy_attn", ",", "self_attn_type", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "TransformerDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# Basic attributes.", "\n", "self", ".", "decoder_type", "=", "'transformer'", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "self", ".", "self_attn_type", "=", "self_attn_type", "\n", "\n", "# Build TransformerDecoder.", "\n", "self", ".", "transformer_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "TransformerDecoderLayer", "(", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "\n", "self_attn_type", "=", "self_attn_type", ")", "\n", "for", "_", "in", "range", "(", "num_layers", ")", "]", ")", "\n", "\n", "# TransformerDecoder has its own attention mechanism.", "\n", "# Set up a separated copy attention layer, if needed.", "\n", "self", ".", "_copy", "=", "False", "\n", "if", "copy_attn", ":", "\n", "            ", "self", ".", "copy_attn", "=", "onmt", ".", "modules", ".", "GlobalAttention", "(", "\n", "d_model", ",", "attn_type", "=", "attn_type", ")", "\n", "self", ".", "_copy", "=", "True", "\n", "", "self", ".", "layer_norm", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoder.forward": [[172, 238], ["src[].transpose", "tgt[].transpose", "src[].transpose.size", "tgt[].transpose.size", "transformer.TransformerDecoder.embeddings", "transformer.TransformerDecoder.transpose().contiguous", "memory_bank.transpose().contiguous", "src[].transpose.data.eq().unsqueeze().expand", "tgt[].transpose.data.eq().unsqueeze().expand", "range", "transformer.TransformerDecoder.layer_norm", "transformer.TransformerDecoder.transpose().contiguous", "attn.transpose().contiguous.transpose().contiguous.transpose().contiguous", "transformer.TransformerDecoder.dim", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "state.update_state.update_state.update_state", "transformer.TransformerDecoder.transpose", "memory_bank.transpose", "src[].transpose.data.eq().unsqueeze", "tgt[].transpose.data.eq().unsqueeze", "torch.stack.append", "torch.stack.append", "transformer.TransformerDecoder.transpose", "attn.transpose().contiguous.transpose().contiguous.transpose", "src[].transpose.data.eq", "tgt[].transpose.data.eq"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.update_state"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory_bank", ",", "state", ",", "memory_lengths", "=", "None", ",", "\n", "step", "=", "None", ",", "cache", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        See :obj:`onmt.modules.RNNDecoderBase.forward()`\n        \"\"\"", "\n", "src", "=", "state", ".", "src", "\n", "src_words", "=", "src", "[", ":", ",", ":", ",", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "tgt_words", "=", "tgt", "[", ":", ",", ":", ",", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "src_batch", ",", "src_len", "=", "src_words", ".", "size", "(", ")", "\n", "tgt_batch", ",", "tgt_len", "=", "tgt_words", ".", "size", "(", ")", "\n", "\n", "# Initialize return variables.", "\n", "outputs", "=", "[", "]", "\n", "attns", "=", "{", "\"std\"", ":", "[", "]", "}", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "[", "]", "\n", "\n", "# Run the forward pass of the TransformerDecoder.", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ",", "step", "=", "step", ")", "\n", "assert", "emb", ".", "dim", "(", ")", "==", "3", "# len x batch x embedding_dim", "\n", "\n", "output", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "src_memory_bank", "=", "memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "padding_idx", "=", "self", ".", "embeddings", ".", "word_padding_idx", "\n", "src_pad_mask", "=", "src_words", ".", "data", ".", "eq", "(", "padding_idx", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "src_batch", ",", "tgt_len", ",", "src_len", ")", "\n", "tgt_pad_mask", "=", "tgt_words", ".", "data", ".", "eq", "(", "padding_idx", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "tgt_batch", ",", "tgt_len", ",", "tgt_len", ")", "\n", "\n", "if", "state", ".", "cache", "is", "None", ":", "\n", "            ", "saved_inputs", "=", "[", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "prev_layer_input", "=", "None", "\n", "if", "state", ".", "cache", "is", "None", ":", "\n", "                ", "if", "state", ".", "previous_input", "is", "not", "None", ":", "\n", "                    ", "prev_layer_input", "=", "state", ".", "previous_layer_inputs", "[", "i", "]", "\n", "", "", "output", ",", "attn", ",", "all_input", "=", "self", ".", "transformer_layers", "[", "i", "]", "(", "\n", "output", ",", "src_memory_bank", ",", "\n", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n", "previous_input", "=", "prev_layer_input", ",", "\n", "layer_cache", "=", "state", ".", "cache", "[", "\"layer_{}\"", ".", "format", "(", "i", ")", "]", "\n", "if", "state", ".", "cache", "is", "not", "None", "else", "None", ",", "\n", "step", "=", "step", ")", "\n", "if", "state", ".", "cache", "is", "None", ":", "\n", "                ", "saved_inputs", ".", "append", "(", "all_input", ")", "\n", "\n", "", "", "if", "state", ".", "cache", "is", "None", ":", "\n", "            ", "saved_inputs", "=", "torch", ".", "stack", "(", "saved_inputs", ")", "\n", "\n", "", "output", "=", "self", ".", "layer_norm", "(", "output", ")", "\n", "\n", "# Process the result and update the attentions.", "\n", "outputs", "=", "output", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "attns", "[", "\"std\"", "]", "=", "attn", "\n", "if", "self", ".", "_copy", ":", "\n", "            ", "attns", "[", "\"copy\"", "]", "=", "attn", "\n", "\n", "", "if", "state", ".", "cache", "is", "None", ":", "\n", "            ", "state", "=", "state", ".", "update_state", "(", "tgt", ",", "saved_inputs", ")", "\n", "\n", "", "return", "outputs", ",", "state", ",", "attns", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoder.init_decoder_state": [[239, 247], ["transformer.TransformerDecoderState", "transformer.TransformerDecoderState._init_cache"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState._init_cache"], ["", "def", "init_decoder_state", "(", "self", ",", "src", ",", "memory_bank", ",", "enc_hidden", ",", "\n", "with_cache", "=", "False", ")", ":", "\n", "        ", "\"\"\" Init decoder state \"\"\"", "\n", "state", "=", "TransformerDecoderState", "(", "src", ")", "\n", "if", "with_cache", ":", "\n", "            ", "state", ".", "_init_cache", "(", "memory_bank", ",", "self", ".", "num_layers", ",", "\n", "self", ".", "self_attn_type", ")", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.__init__": [[252, 262], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "src", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src (FloatTensor): a sequence of source words tensors\n                    with optional feature tensors, of size (len x batch).\n        \"\"\"", "\n", "self", ".", "src", "=", "src", "\n", "self", ".", "previous_input", "=", "None", "\n", "self", ".", "previous_layer_inputs", "=", "None", "\n", "self", ".", "cache", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState._all": [[263, 275], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "_all", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Contains attributes that need to be updated in self.beam_update().\n        \"\"\"", "\n", "if", "(", "self", ".", "previous_input", "is", "not", "None", "\n", "and", "self", ".", "previous_layer_inputs", "is", "not", "None", ")", ":", "\n", "            ", "return", "(", "self", ".", "previous_input", ",", "\n", "self", ".", "previous_layer_inputs", ",", "\n", "self", ".", "src", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "self", ".", "src", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.detach": [[276, 282], ["transformer.TransformerDecoderState.src.detach", "transformer.TransformerDecoderState.previous_input.detach", "transformer.TransformerDecoderState.previous_layer_inputs.detach"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.detach", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.detach", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.detach"], ["", "", "def", "detach", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "previous_input", "is", "not", "None", ":", "\n", "            ", "self", ".", "previous_input", "=", "self", ".", "previous_input", ".", "detach", "(", ")", "\n", "", "if", "self", ".", "previous_layer_inputs", "is", "not", "None", ":", "\n", "            ", "self", ".", "previous_layer_inputs", "=", "self", ".", "previous_layer_inputs", ".", "detach", "(", ")", "\n", "", "self", ".", "src", "=", "self", ".", "src", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.update_state": [[283, 288], ["transformer.TransformerDecoderState"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "new_input", ",", "previous_layer_inputs", ")", ":", "\n", "        ", "state", "=", "TransformerDecoderState", "(", "self", ".", "src", ")", "\n", "state", ".", "previous_input", "=", "new_input", "\n", "state", ".", "previous_layer_inputs", "=", "previous_layer_inputs", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState._init_cache": [[289, 308], ["memory_bank.size", "memory_bank.size", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "_init_cache", "(", "self", ",", "memory_bank", ",", "num_layers", ",", "self_attn_type", ")", ":", "\n", "        ", "self", ".", "cache", "=", "{", "}", "\n", "batch_size", "=", "memory_bank", ".", "size", "(", "1", ")", "\n", "depth", "=", "memory_bank", ".", "size", "(", "-", "1", ")", "\n", "\n", "for", "l", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "layer_cache", "=", "{", "\n", "\"memory_keys\"", ":", "None", ",", "\n", "\"memory_values\"", ":", "None", "\n", "}", "\n", "if", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n", "                ", "layer_cache", "[", "\"self_keys\"", "]", "=", "None", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "None", "\n", "", "elif", "self_attn_type", "==", "\"average\"", ":", "\n", "                ", "layer_cache", "[", "\"prev_g\"", "]", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "1", ",", "depth", ")", ")", "\n", "", "else", ":", "\n", "                ", "layer_cache", "[", "\"self_keys\"", "]", "=", "None", "\n", "layer_cache", "[", "\"self_values\"", "]", "=", "None", "\n", "", "self", ".", "cache", "[", "\"layer_{}\"", ".", "format", "(", "l", ")", "]", "=", "layer_cache", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.repeat_beam_size_times": [[309, 312], ["transformer.TransformerDecoderState.src.data.repeat"], "methods", ["None"], ["", "", "def", "repeat_beam_size_times", "(", "self", ",", "beam_size", ")", ":", "\n", "        ", "\"\"\" Repeat beam_size times along batch dimension. \"\"\"", "\n", "self", ".", "src", "=", "self", ".", "src", ".", "data", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.map_batch_fn": [[313, 325], ["fn", "struct.items", "transformer.TransformerDecoderState.map_batch_fn._recursive_map"], "methods", ["None"], ["", "def", "map_batch_fn", "(", "self", ",", "fn", ")", ":", "\n", "        ", "def", "_recursive_map", "(", "struct", ",", "batch_dim", "=", "0", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "struct", ".", "items", "(", ")", ":", "\n", "                ", "if", "v", "is", "not", "None", ":", "\n", "                    ", "if", "isinstance", "(", "v", ",", "dict", ")", ":", "\n", "                        ", "_recursive_map", "(", "v", ")", "\n", "", "else", ":", "\n", "                        ", "struct", "[", "k", "]", "=", "fn", "(", "v", ",", "batch_dim", ")", "\n", "\n", "", "", "", "", "self", ".", "src", "=", "fn", "(", "self", ".", "src", ",", "1", ")", "\n", "if", "self", ".", "cache", "is", "not", "None", ":", "\n", "            ", "_recursive_map", "(", "self", ".", "cache", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.TranslationBuilder.__init__": [[25, 32], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "fields", ",", "n_best", "=", "1", ",", "replace_unk", "=", "False", ",", "\n", "has_tgt", "=", "False", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "replace_unk", "=", "replace_unk", "\n", "self", ".", "has_tgt", "=", "has_tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.TranslationBuilder._build_target_tokens": [[33, 50], ["range", "len", "tokens.append", "tokens.append", "len", "attn[].max", "len"], "methods", ["None"], ["", "def", "_build_target_tokens", "(", "self", ",", "src", ",", "src_vocab", ",", "src_raw", ",", "pred", ",", "attn", ")", ":", "\n", "        ", "vocab", "=", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "tokens", "=", "[", "]", "\n", "for", "tok", "in", "pred", ":", "\n", "            ", "if", "tok", "<", "len", "(", "vocab", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "vocab", ".", "itos", "[", "tok", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "src_vocab", ".", "itos", "[", "tok", "-", "len", "(", "vocab", ")", "]", ")", "\n", "", "if", "tokens", "[", "-", "1", "]", "==", "inputters", ".", "EOS_WORD", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "-", "1", "]", "\n", "break", "\n", "", "", "if", "self", ".", "replace_unk", "and", "(", "attn", "is", "not", "None", ")", "and", "(", "src", "is", "not", "None", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "tokens", "[", "i", "]", "==", "vocab", ".", "itos", "[", "inputters", ".", "UNK", "]", ":", "\n", "                    ", "_", ",", "max_index", "=", "attn", "[", "i", "]", ".", "max", "(", "0", ")", "\n", "tokens", "[", "i", "]", "=", "src_raw", "[", "max_index", "[", "0", "]", "]", "\n", "", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.TranslationBuilder.from_batch": [[51, 106], ["list", "torch.sort", "range", "len", "len", "zip", "batch.src[].data.index_select", "batch.tgt.data.index_select", "Translation.Translation", "translations.append", "Translation.TranslationBuilder._build_target_tokens", "Translation.TranslationBuilder._build_target_tokens", "sorted", "range", "zip"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.TranslationBuilder._build_target_tokens", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.TranslationBuilder._build_target_tokens"], ["", "def", "from_batch", "(", "self", ",", "translation_batch", ")", ":", "\n", "        ", "batch", "=", "translation_batch", "[", "\"batch\"", "]", "\n", "selector_probs", "=", "translation_batch", "[", "\"selector_probs\"", "]", "\n", "assert", "(", "len", "(", "translation_batch", "[", "\"gold_score\"", "]", ")", "==", "\n", "len", "(", "translation_batch", "[", "\"predictions\"", "]", ")", ")", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "\n", "preds", ",", "pred_score", ",", "attn", ",", "gold_score", ",", "indices", "=", "list", "(", "zip", "(", "\n", "*", "sorted", "(", "zip", "(", "translation_batch", "[", "\"predictions\"", "]", ",", "\n", "translation_batch", "[", "\"scores\"", "]", ",", "\n", "translation_batch", "[", "\"attention\"", "]", ",", "\n", "translation_batch", "[", "\"gold_score\"", "]", ",", "\n", "batch", ".", "indices", ".", "data", ")", ",", "\n", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ")", ")", ")", "\n", "\n", "# Sorting", "\n", "inds", ",", "perm", "=", "torch", ".", "sort", "(", "batch", ".", "indices", ".", "data", ")", "\n", "data_type", "=", "self", ".", "data", ".", "data_type", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "src", "=", "batch", ".", "src", "[", "0", "]", ".", "data", ".", "index_select", "(", "1", ",", "perm", ")", "\n", "if", "selector_probs", "is", "not", "None", ":", "\n", "                ", "selector_probs", "=", "selector_probs", ".", "data", ".", "index_select", "(", "1", ",", "perm", ")", "\n", "", "", "else", ":", "\n", "            ", "src", "=", "None", "\n", "\n", "", "if", "self", ".", "has_tgt", ":", "\n", "            ", "tgt", "=", "batch", ".", "tgt", ".", "data", ".", "index_select", "(", "1", ",", "perm", ")", "\n", "", "else", ":", "\n", "            ", "tgt", "=", "None", "\n", "\n", "", "translations", "=", "[", "]", "\n", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "data_type", "==", "'text'", ":", "\n", "                ", "src_vocab", "=", "self", ".", "data", ".", "src_vocabs", "[", "inds", "[", "b", "]", "]", "if", "self", ".", "data", ".", "src_vocabs", "else", "None", "\n", "src_raw", "=", "self", ".", "data", ".", "examples", "[", "inds", "[", "b", "]", "]", ".", "src", "\n", "\n", "if", "selector_probs", "is", "not", "None", ":", "\n", "                    ", "src_len", "=", "len", "(", "src_raw", ")", "\n", "probs_len", "=", "selector_probs", "[", ":", ",", "b", "]", ".", "gt", "(", "0.0", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "assert", "src_len", "==", "probs_len", "\n", "", "", "else", ":", "\n", "                ", "src_vocab", "=", "None", "\n", "src_raw", "=", "None", "\n", "", "pred_sents", "=", "[", "self", ".", "_build_target_tokens", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_vocab", ",", "src_raw", ",", "\n", "preds", "[", "b", "]", "[", "n", "]", ",", "attn", "[", "b", "]", "[", "n", "]", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n_best", ")", "]", "\n", "gold_sent", "=", "None", "\n", "if", "tgt", "is", "not", "None", ":", "\n", "                ", "gold_sent", "=", "self", ".", "_build_target_tokens", "(", "\n", "src", "[", ":", ",", "b", "]", "if", "src", "is", "not", "None", "else", "None", ",", "\n", "src_vocab", ",", "src_raw", ",", "\n", "tgt", "[", "1", ":", ",", "b", "]", "if", "tgt", "is", "not", "None", "else", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.__init__": [[124, 133], ["None"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "src", ",", "src_raw", ",", "pred_sents", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log": [[134, 157], ["len", "zip"], "methods", ["None"], ["attn", ",", "pred_scores", ",", "tgt_sent", ",", "gold_score", ",", "selector_probs", ")", ":", "\n", "        ", "self", ".", "src", "=", "src", "\n", "self", ".", "src_raw", "=", "src_raw", "\n", "self", ".", "pred_sents", "=", "pred_sents", "\n", "self", ".", "attns", "=", "attn", "\n", "self", ".", "pred_scores", "=", "pred_scores", "\n", "self", ".", "gold_sent", "=", "tgt_sent", "\n", "self", ".", "gold_score", "=", "gold_score", "\n", "self", ".", "selector_probs", "=", "selector_probs", "\n", "\n", "", "def", "log", "(", "self", ",", "sent_number", ")", ":", "\n", "        ", "\"\"\"\n        Log translation.\n        \"\"\"", "\n", "\n", "output", "=", "'\\nSENT {}: {}\\n'", ".", "format", "(", "sent_number", ",", "self", ".", "src_raw", ")", "\n", "\n", "best_pred", "=", "self", ".", "pred_sents", "[", "0", "]", "\n", "best_score", "=", "self", ".", "pred_scores", "[", "0", "]", "\n", "pred_sent", "=", "' '", ".", "join", "(", "best_pred", ")", "\n", "output", "+=", "'PRED {}: {}\\n'", ".", "format", "(", "sent_number", ",", "pred_sent", ")", "\n", "output", "+=", "\"PRED SCORE: {:.4f}\\n\"", ".", "format", "(", "best_score", ")", "\n", "\n", "if", "self", ".", "gold_sent", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator.__init__": [[73, 144], ["set"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "\n", "opt", ",", "\n", "model_opt", ",", "\n", "model", ",", "\n", "fields", ",", "\n", "beam_size", ",", "\n", "n_best", "=", "1", ",", "\n", "max_length", "=", "100", ",", "\n", "global_scorer", "=", "None", ",", "\n", "copy_attn", "=", "False", ",", "\n", "logger", "=", "None", ",", "\n", "gpu", "=", "False", ",", "\n", "dump_beam", "=", "\"\"", ",", "\n", "min_length", "=", "0", ",", "\n", "stepwise_penalty", "=", "False", ",", "\n", "block_ngram_repeat", "=", "0", ",", "\n", "ignore_when_blocking", "=", "[", "]", ",", "\n", "sample_rate", "=", "'16000'", ",", "\n", "window_size", "=", ".02", ",", "\n", "window_stride", "=", ".01", ",", "\n", "window", "=", "'hamming'", ",", "\n", "use_filter_pred", "=", "False", ",", "\n", "data_type", "=", "\"text\"", ",", "\n", "replace_unk", "=", "False", ",", "\n", "report_score", "=", "True", ",", "\n", "report_bleu", "=", "False", ",", "\n", "report_rouge", "=", "False", ",", "\n", "verbose", "=", "False", ",", "\n", "out_file", "=", "None", ",", "\n", "scores_out_file", "=", "None", ",", "\n", "sel_probs_out_file", "=", "None", ",", "\n", "fast", "=", "False", ")", ":", "\n", "        ", "self", ".", "logger", "=", "logger", "\n", "self", ".", "gpu", "=", "gpu", "\n", "self", ".", "cuda", "=", "gpu", ">", "-", "1", "\n", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "n_best", "=", "n_best", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "copy_attn", "=", "copy_attn", "\n", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "min_length", "=", "min_length", "\n", "self", ".", "stepwise_penalty", "=", "stepwise_penalty", "\n", "self", ".", "dump_beam", "=", "dump_beam", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n", "self", ".", "ignore_when_blocking", "=", "set", "(", "ignore_when_blocking", ")", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "window_stride", "=", "window_stride", "\n", "self", ".", "window", "=", "window", "\n", "self", ".", "use_filter_pred", "=", "use_filter_pred", "\n", "self", ".", "replace_unk", "=", "replace_unk", "\n", "self", ".", "data_type", "=", "data_type", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "out_file", "=", "out_file", "\n", "self", ".", "scores_out_file", "=", "scores_out_file", "\n", "self", ".", "sel_probs_out_file", "=", "sel_probs_out_file", "\n", "self", ".", "report_score", "=", "report_score", "\n", "self", ".", "report_bleu", "=", "report_bleu", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator.translate": [[145, 303], ["onmt.build_dataset", "onmt.build_dataset", "onmt.build_dataset", "onmt.build_dataset", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "onmt.translate.TranslationBuilder", "itertools.count", "ValueError", "translator.Translator.translate_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "onmt.translate.TranslationBuilder.from_batch", "translator.Translator._report_score", "json.dump", "evaluation_utils.evaluate_func", "len", "translator.Translator.out_file.write", "translator.Translator.out_file.flush", "translator.Translator.logger.info", "print", "translator.Translator._report_score", "codecs.open", "next", "trans.log", "preds.append", "trans.attns[].tolist", "zip", "os.write", "translator.Translator.logger.info", "print", "translator.Translator._report_bleu", "translator.Translator._report_rouge", "len", "translator.Translator.logger.info", "os.write", "header_format.format", "row.index", "row_format.replace.replace.replace", "row_format.replace.replace.replace", "trans.log.encode", "translator.Translator.logger.info", "print", "translator.Translator.logger.info", "print", "trans.log.encode", "len", "len", "max", "row_format.replace.replace.format", "len"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator.translate_batch", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.TranslationBuilder.from_batch", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._report_score", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.evaluate_func", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._report_score", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._report_bleu", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._report_rouge"], ["self", ".", "report_rouge", "=", "report_rouge", "\n", "self", ".", "fast", "=", "fast", "\n", "\n", "# for debugging", "\n", "self", ".", "beam_trace", "=", "self", ".", "dump_beam", "!=", "\"\"", "\n", "self", ".", "beam_accum", "=", "None", "\n", "if", "self", ".", "beam_trace", ":", "\n", "            ", "self", ".", "beam_accum", "=", "{", "\n", "\"predicted_ids\"", ":", "[", "]", ",", "\n", "\"beam_parent_ids\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"log_probs\"", ":", "[", "]", "}", "\n", "\n", "", "", "def", "translate", "(", "self", ",", "\n", "src_path", "=", "None", ",", "\n", "src_data_iter", "=", "None", ",", "\n", "rk_path", "=", "None", ",", "\n", "rk_data_iter", "=", "None", ",", "\n", "key_indicator_path", "=", "None", ",", "\n", "key_indicator_iter", "=", "None", ",", "\n", "tgt_path", "=", "None", ",", "\n", "tgt_data_iter", "=", "None", ",", "\n", "src_dir", "=", "None", ",", "\n", "batch_size", "=", "None", ",", "\n", "attn_debug", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Translate content of `src_data_iter` (if not None) or `src_path`\n        and get gold scores if one of `tgt_data_iter` or `tgt_path` is set.\n\n        Note: batch_size must not be None\n        Note: one of ('src_path', 'src_data_iter') must not be None\n\n        Args:\n            src_path (str): filepath of source data\n            src_data_iter (iterator): an interator generating source data\n                e.g. it may be a list or an openned file\n            rk_path (str): filepath of retrieved keyphrases\n            rk_data_iter (iterator): an interator generating retrieved keyphrases\n                e.g. it may be a list or an openned file\n            key_indicator_path (str): filepath of src keyword indicators\n            key_indicator_iter (iterator): an interator generating src keyword indicators\n                e.g. it may be a list or an openned file\n            tgt_path (str): filepath of target data\n            tgt_data_iter (iterator): an interator generating target data\n            src_dir (str): source directory path\n                (used for Audio and Image datasets)\n            batch_size (int): size of examples per mini-batch\n            attn_debug (bool): enables the attention logging\n\n        Returns:\n            (`list`, `list`)\n\n            * all_scores is a list of `batch_size` lists of `n_best` scores\n            * all_predictions is a list of `batch_size` lists\n                of `n_best` predictions\n        \"\"\"", "\n", "assert", "src_data_iter", "is", "not", "None", "or", "src_path", "is", "not", "None", "\n", "\n", "if", "batch_size", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"batch_size must be set\"", ")", "\n", "", "data", "=", "inputters", ".", "build_dataset", "(", "self", ".", "fields", ",", "\n", "self", ".", "data_type", ",", "\n", "src_path", "=", "src_path", ",", "\n", "src_data_iter", "=", "src_data_iter", ",", "\n", "rk_path", "=", "rk_path", ",", "\n", "rk_data_iter", "=", "rk_data_iter", ",", "\n", "key_indicator_path", "=", "key_indicator_path", ",", "\n", "key_indicator_iter", "=", "key_indicator_iter", ",", "\n", "tgt_path", "=", "tgt_path", ",", "\n", "tgt_data_iter", "=", "tgt_data_iter", ",", "\n", "src_dir", "=", "src_dir", ",", "\n", "sample_rate", "=", "self", ".", "sample_rate", ",", "\n", "window_size", "=", "self", ".", "window_size", ",", "\n", "window_stride", "=", "self", ".", "window_stride", ",", "\n", "window", "=", "self", ".", "window", ",", "\n", "use_filter_pred", "=", "self", ".", "use_filter_pred", ")", "\n", "\n", "if", "self", ".", "cuda", ":", "\n", "            ", "cur_device", "=", "\"cuda\"", "\n", "", "else", ":", "\n", "            ", "cur_device", "=", "\"cpu\"", "\n", "\n", "", "data_iter", "=", "inputters", ".", "OrderedIterator", "(", "\n", "dataset", "=", "data", ",", "device", "=", "cur_device", ",", "\n", "batch_size", "=", "batch_size", ",", "train", "=", "False", ",", "sort", "=", "False", ",", "\n", "sort_within_batch", "=", "True", ",", "shuffle", "=", "False", ")", "\n", "\n", "builder", "=", "onmt", ".", "translate", ".", "TranslationBuilder", "(", "\n", "data", ",", "self", ".", "fields", ",", "\n", "self", ".", "n_best", ",", "self", ".", "replace_unk", ",", "tgt_path", ")", "\n", "\n", "# Statistics", "\n", "counter", "=", "count", "(", "1", ")", "\n", "pred_score_total", ",", "pred_words_total", "=", "0", ",", "0", "\n", "gold_score_total", ",", "gold_words_total", "=", "0", ",", "0", "\n", "\n", "all_scores", "=", "[", "]", "\n", "all_predictions", "=", "[", "]", "\n", "\n", "for", "batch", "in", "data_iter", ":", "\n", "            ", "batch_data", "=", "self", ".", "translate_batch", "(", "batch", ",", "data", ",", "fast", "=", "self", ".", "fast", ")", "\n", "translations", "=", "builder", ".", "from_batch", "(", "batch_data", ")", "\n", "\n", "for", "trans", "in", "translations", ":", "\n", "                ", "all_scores", "+=", "[", "trans", ".", "pred_scores", "[", ":", "self", ".", "n_best", "]", "]", "\n", "pred_score_total", "+=", "trans", ".", "pred_scores", "[", "0", "]", "\n", "pred_words_total", "+=", "len", "(", "trans", ".", "pred_sents", "[", "0", "]", ")", "\n", "if", "tgt_path", "is", "not", "None", ":", "\n", "                    ", "gold_score_total", "+=", "trans", ".", "gold_score", "\n", "gold_words_total", "+=", "len", "(", "trans", ".", "gold_sent", ")", "+", "1", "\n", "\n", "", "n_best_preds", "=", "[", "\" \"", ".", "join", "(", "pred", ")", "\n", "for", "pred", "in", "trans", ".", "pred_sents", "[", ":", "self", ".", "n_best", "]", "]", "\n", "\n", "n_best_preds_scores", "=", "[", "round", "(", "sc", ".", "exp", "(", ")", ".", "item", "(", ")", ",", "5", ")", "for", "sc", "in", "trans", ".", "pred_scores", "[", ":", "self", ".", "n_best", "]", "]", "\n", "\n", "all_predictions", "+=", "[", "n_best_preds", "]", "\n", "self", ".", "out_file", ".", "write", "(", "' ; '", ".", "join", "(", "n_best_preds", ")", "+", "'\\n'", ")", "\n", "self", ".", "out_file", ".", "flush", "(", ")", "\n", "self", ".", "scores_out_file", ".", "write", "(", "' ; '", ".", "join", "(", "[", "str", "(", "sc", ")", "for", "sc", "in", "n_best_preds_scores", "]", ")", "+", "'\\n'", ")", "\n", "\n", "if", "trans", ".", "selector_probs", "is", "not", "None", ":", "\n", "                    ", "selector_probs", "=", "trans", ".", "selector_probs", ".", "tolist", "(", ")", "\n", "selector_probs", "=", "[", "round", "(", "sp", ",", "5", ")", "for", "sp", "in", "selector_probs", "if", "sp", "!=", "0.0", "]", "\n", "self", ".", "sel_probs_out_file", ".", "write", "(", "' ; '", ".", "join", "(", "[", "str", "(", "sp", ")", "for", "sp", "in", "selector_probs", "]", ")", "+", "'\\n'", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "                    ", "sent_number", "=", "next", "(", "counter", ")", "\n", "output", "=", "trans", ".", "log", "(", "sent_number", ")", "\n", "if", "self", ".", "logger", ":", "\n", "                        ", "self", ".", "logger", ".", "info", "(", "output", ")", "\n", "", "else", ":", "\n", "                        ", "os", ".", "write", "(", "1", ",", "output", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n", "# Debug attention.", "\n", "", "", "if", "attn_debug", ":", "\n", "                    ", "srcs", "=", "trans", ".", "src_raw", "\n", "preds", "=", "trans", ".", "pred_sents", "[", "0", "]", "\n", "preds", ".", "append", "(", "'</s>'", ")", "\n", "attns", "=", "trans", ".", "attns", "[", "0", "]", ".", "tolist", "(", ")", "\n", "header_format", "=", "\"{:>10.10} \"", "+", "\"{:>10.7} \"", "*", "len", "(", "srcs", ")", "\n", "row_format", "=", "\"{:>10.10} \"", "+", "\"{:>10.7f} \"", "*", "len", "(", "srcs", ")", "\n", "output", "=", "header_format", ".", "format", "(", "\"\"", ",", "*", "trans", ".", "src_raw", ")", "+", "'\\n'", "\n", "for", "word", ",", "row", "in", "zip", "(", "preds", ",", "attns", ")", ":", "\n", "                        ", "max_index", "=", "row", ".", "index", "(", "max", "(", "row", ")", ")", "\n", "row_format", "=", "row_format", ".", "replace", "(", "\n", "\"{:>10.7f} \"", ",", "\"{:*>10.7f} \"", ",", "max_index", "+", "1", ")", "\n", "row_format", "=", "row_format", ".", "replace", "(", "\n", "\"{:*>10.7f} \"", ",", "\"{:>10.7f} \"", ",", "max_index", ")", "\n", "output", "+=", "row_format", ".", "format", "(", "word", ",", "*", "row", ")", "+", "'\\n'", "\n", "row_format", "=", "\"{:>10.10} \"", "+", "\"{:>10.7f} \"", "*", "len", "(", "srcs", ")", "\n", "", "os", ".", "write", "(", "1", ",", "output", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "\n", "", "", "", "if", "self", ".", "report_score", ":", "\n", "            ", "msg", "=", "self", ".", "_report_score", "(", "'PRED'", ",", "pred_score_total", ",", "\n", "pred_words_total", ")", "\n", "if", "self", ".", "logger", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "msg", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator.translate_batch": [[304, 329], ["torch.no_grad", "translator.Translator._fast_translate_batch", "translator.Translator._translate_batch"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._fast_translate_batch", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._translate_batch"], ["                ", "print", "(", "msg", ")", "\n", "", "if", "tgt_path", "is", "not", "None", ":", "\n", "                ", "msg", "=", "self", ".", "_report_score", "(", "'GOLD'", ",", "gold_score_total", ",", "\n", "gold_words_total", ")", "\n", "if", "self", ".", "logger", ":", "\n", "                    ", "self", ".", "logger", ".", "info", "(", "msg", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "msg", ")", "\n", "", "if", "self", ".", "report_bleu", ":", "\n", "                    ", "msg", "=", "self", ".", "_report_bleu", "(", "tgt_path", ")", "\n", "if", "self", ".", "logger", ":", "\n", "                        ", "self", ".", "logger", ".", "info", "(", "msg", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "msg", ")", "\n", "", "", "if", "self", ".", "report_rouge", ":", "\n", "                    ", "msg", "=", "self", ".", "_report_rouge", "(", "tgt_path", ")", "\n", "if", "self", ".", "logger", ":", "\n", "                        ", "self", ".", "logger", ".", "info", "(", "msg", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "msg", ")", "\n", "\n", "", "", "", "", "if", "self", ".", "dump_beam", ":", "\n", "            ", "import", "json", "\n", "json", ".", "dump", "(", "self", ".", "translator", ".", "beam_accum", ",", "\n", "codecs", ".", "open", "(", "self", ".", "dump_beam", ",", "'w'", ",", "'utf-8'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._fast_translate_batch": [[330, 491], ["onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "translator.Translator.model.encoder", "translator.Translator.model.decoder.init_decoder_state", "translator.Translator.map_batch_fn", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "torch.arange", "torch.arange", "torch.full", "torch.tensor().repeat", "range", "alive_seq[].view", "translator.Translator.model.decoder", "translator.Translator.model.generator.forward", "translator.Translator.size", "topk_log_probs.index_select.index_select.view().unsqueeze", "curr_scores.reshape.reshape.reshape", "curr_scores.reshape.reshape.topk", "topk_ids.index_select.index_select.div", "topk_ids.index_select.index_select.fmod", "topk_ids[].eq", "topk_ids[].eq.nonzero().view", "batch_index.index_select.index_select.view", "torch.cat.index_select", "memory_bank.index_select.index_select.index_select", "memory_lengths.index_select.index_select.index_select", "translator.Translator.map_batch_fn", "torch.cat", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "onmt.utils.misc.tile", "torch.tensor", "range", "range", "range", "dec_out.squeeze", "beam_offset[].unsqueeze", "topk_ids[].eq.fill_", "len", "torch.cat.view", "topk_scores.view", "topk_ids[].eq.eq().nonzero().view", "topk_log_probs.index_select.index_select.index_select", "topk_ids.index_select.index_select.index_select", "batch_index.index_select.index_select.index_select", "batch_offset.index_select.index_select.index_select", "attn[].index_select", "topk_log_probs.index_select.index_select.view", "topk_ids[].eq.nonzero", "torch.cat.size", "torch.cat.view", "range", "len", "topk_ids[].eq.eq().nonzero().view.to", "state.index_select", "topk_ids.index_select.index_select.view", "torch.cat.index_select", "torch.cat", "torch.cat.size", "torch.cat.size", "[].append", "[].append", "topk_ids[].eq.eq().nonzero", "[].append", "[].append", "float", "topk_ids.index_select.div.size", "topk_ids[].eq.eq"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoder.init_decoder_state", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.map_batch_fn", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.rnn_reranker.RNNReRanker.forward", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoderState.map_batch_fn", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.tile"], ["", "if", "self", ".", "opt", "is", "not", "None", ":", "\n", "            ", "evaluate_func", "(", "opts", "=", "self", ".", "opt", ",", "do_stem", "=", "True", ")", "\n", "", "return", "all_scores", ",", "all_predictions", "\n", "\n", "", "def", "translate_batch", "(", "self", ",", "batch", ",", "data", ",", "fast", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Translate a batch of sentences.\n\n        Mostly a wrapper around :obj:`Beam`.\n\n        Args:\n           batch (:obj:`Batch`): a batch from a dataset object\n           data (:obj:`Dataset`): the dataset object\n           fast (bool): enables fast beam search (may not support all features)\n\n        Todo:\n           Shouldn't need the original dataset.\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "fast", ":", "\n", "                ", "return", "self", ".", "_fast_translate_batch", "(", "\n", "batch", ",", "\n", "data", ",", "\n", "self", ".", "max_length", ",", "\n", "min_length", "=", "self", ".", "min_length", ",", "\n", "n_best", "=", "self", ".", "n_best", ",", "\n", "return_attention", "=", "self", ".", "replace_unk", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_translate_batch", "(", "batch", ",", "data", ")", "\n", "\n", "", "", "", "def", "_fast_translate_batch", "(", "self", ",", "\n", "batch", ",", "\n", "data", ",", "\n", "max_length", ",", "\n", "min_length", "=", "0", ",", "\n", "n_best", "=", "1", ",", "\n", "return_attention", "=", "False", ")", ":", "\n", "# TODO: faster code path for beam_size == 1.", "\n", "\n", "# TODO: support these blacklisted features.", "\n", "        ", "assert", "data", ".", "data_type", "==", "'text'", "\n", "assert", "not", "self", ".", "copy_attn", "\n", "assert", "not", "self", ".", "dump_beam", "\n", "assert", "not", "self", ".", "use_filter_pred", "\n", "assert", "self", ".", "block_ngram_repeat", "==", "0", "\n", "assert", "self", ".", "global_scorer", ".", "beta", "==", "0", "\n", "\n", "beam_size", "=", "self", ".", "beam_size", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "vocab", "=", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "start_token", "=", "vocab", ".", "stoi", "[", "inputters", ".", "BOS_WORD", "]", "\n", "end_token", "=", "vocab", ".", "stoi", "[", "inputters", ".", "EOS_WORD", "]", "\n", "\n", "# Encoder forward.", "\n", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "data", ".", "data_type", ")", "\n", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "enc_states", ",", "memory_bank", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "dec_states", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "\n", "src", ",", "memory_bank", ",", "enc_states", ",", "with_cache", "=", "True", ")", "\n", "\n", "# Tile states and memory beam_size times.", "\n", "dec_states", ".", "map_batch_fn", "(", "\n", "lambda", "state", ",", "dim", ":", "tile", "(", "state", ",", "beam_size", ",", "dim", "=", "dim", ")", ")", "\n", "memory_bank", "=", "tile", "(", "memory_bank", ",", "beam_size", ",", "dim", "=", "1", ")", "\n", "memory_lengths", "=", "tile", "(", "src_lengths", ",", "beam_size", ")", "\n", "\n", "batch_offset", "=", "torch", ".", "arange", "(", "\n", "batch_size", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "memory_bank", ".", "device", ")", "\n", "beam_offset", "=", "torch", ".", "arange", "(", "\n", "0", ",", "\n", "batch_size", "*", "beam_size", ",", "\n", "step", "=", "beam_size", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "memory_bank", ".", "device", ")", "\n", "alive_seq", "=", "torch", ".", "full", "(", "\n", "[", "batch_size", "*", "beam_size", ",", "1", "]", ",", "\n", "start_token", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "memory_bank", ".", "device", ")", "\n", "alive_attn", "=", "None", "\n", "\n", "# Give full probability to the first beam on the first step.", "\n", "topk_log_probs", "=", "(", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", "+", "[", "float", "(", "\"-inf\"", ")", "]", "*", "(", "beam_size", "-", "1", ")", ",", "\n", "device", "=", "memory_bank", ".", "device", ")", ".", "repeat", "(", "batch_size", ")", ")", "\n", "\n", "results", "=", "{", "}", "\n", "results", "[", "\"predictions\"", "]", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "# noqa: F812", "\n", "results", "[", "\"scores\"", "]", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "# noqa: F812", "\n", "results", "[", "\"attention\"", "]", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "# noqa: F812", "\n", "results", "[", "\"gold_score\"", "]", "=", "[", "0", "]", "*", "batch_size", "\n", "results", "[", "\"batch\"", "]", "=", "batch", "\n", "\n", "max_length", "+=", "1", "\n", "\n", "for", "step", "in", "range", "(", "max_length", ")", ":", "\n", "            ", "decoder_input", "=", "alive_seq", "[", ":", ",", "-", "1", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "\n", "\n", "# Decoder forward.", "\n", "dec_out", ",", "dec_states", ",", "attn", "=", "self", ".", "model", ".", "decoder", "(", "\n", "decoder_input", ",", "\n", "memory_bank", ",", "\n", "dec_states", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "\n", "step", "=", "step", ")", "\n", "\n", "# Generator forward.", "\n", "log_probs", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec_out", ".", "squeeze", "(", "0", ")", ")", "\n", "vocab_size", "=", "log_probs", ".", "size", "(", "-", "1", ")", "\n", "\n", "if", "step", "<", "min_length", ":", "\n", "                ", "log_probs", "[", ":", ",", "end_token", "]", "=", "-", "1e20", "\n", "\n", "# Multiply probs by the beam probability.", "\n", "", "log_probs", "+=", "topk_log_probs", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "alpha", "=", "self", ".", "global_scorer", ".", "alpha", "\n", "length_penalty", "=", "(", "(", "5.0", "+", "(", "step", "+", "1", ")", ")", "/", "6.0", ")", "**", "alpha", "\n", "\n", "# Flatten probs into a list of possibilities.", "\n", "curr_scores", "=", "log_probs", "/", "length_penalty", "\n", "curr_scores", "=", "curr_scores", ".", "reshape", "(", "-", "1", ",", "beam_size", "*", "vocab_size", ")", "\n", "topk_scores", ",", "topk_ids", "=", "curr_scores", ".", "topk", "(", "beam_size", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Recover log probs.", "\n", "topk_log_probs", "=", "topk_scores", "*", "length_penalty", "\n", "\n", "# Resolve beam origin and true word ids.", "\n", "topk_beam_index", "=", "topk_ids", ".", "div", "(", "vocab_size", ")", "\n", "topk_ids", "=", "topk_ids", ".", "fmod", "(", "vocab_size", ")", "\n", "\n", "# Map beam_index to batch_index in the flat representation.", "\n", "batch_index", "=", "(", "\n", "topk_beam_index", "\n", "+", "beam_offset", "[", ":", "topk_beam_index", ".", "size", "(", "0", ")", "]", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "# End condition is the top beam reached end_token.", "\n", "end_condition", "=", "topk_ids", "[", ":", ",", "0", "]", ".", "eq", "(", "end_token", ")", "\n", "if", "step", "+", "1", "==", "max_length", ":", "\n", "                ", "end_condition", ".", "fill_", "(", "1", ")", "\n", "", "finished", "=", "end_condition", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Save result of finished sentences.", "\n", "if", "len", "(", "finished", ")", ">", "0", ":", "\n", "                ", "predictions", "=", "alive_seq", ".", "view", "(", "-", "1", ",", "beam_size", ",", "alive_seq", ".", "size", "(", "-", "1", ")", ")", "\n", "scores", "=", "topk_scores", ".", "view", "(", "-", "1", ",", "beam_size", ")", "\n", "attention", "=", "None", "\n", "if", "alive_attn", "is", "not", "None", ":", "\n", "                    ", "attention", "=", "alive_attn", ".", "view", "(", "\n", "alive_attn", ".", "size", "(", "0", ")", ",", "-", "1", ",", "beam_size", ",", "alive_attn", ".", "size", "(", "-", "1", ")", ")", "\n", "", "for", "i", "in", "finished", ":", "\n", "                    ", "b", "=", "batch_offset", "[", "i", "]", "\n", "for", "n", "in", "range", "(", "n_best", ")", ":", "\n", "                        ", "results", "[", "\"predictions\"", "]", "[", "b", "]", ".", "append", "(", "predictions", "[", "i", ",", "n", ",", "1", ":", "]", ")", "\n", "results", "[", "\"scores\"", "]", "[", "b", "]", ".", "append", "(", "scores", "[", "i", ",", "n", "]", ")", "\n", "if", "attention", "is", "None", ":", "\n", "                            ", "results", "[", "\"attention\"", "]", "[", "b", "]", ".", "append", "(", "[", "]", ")", "\n", "", "else", ":", "\n", "                            ", "results", "[", "\"attention\"", "]", "[", "b", "]", ".", "append", "(", "\n", "attention", "[", ":", ",", "i", ",", "n", ",", ":", "memory_lengths", "[", "i", "]", "]", ")", "\n", "", "", "", "non_finished", "=", "end_condition", ".", "eq", "(", "0", ")", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "# If all sentences are translated, no need to go further.", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._translate_batch": [[492, 631], ["set", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "translator.Translator.model.decoder.init_decoder_state", "translator.Translator._translate_batch.rvar"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoder.init_decoder_state"], ["if", "len", "(", "non_finished", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "# Remove finished batches for the next step.", "\n", "", "topk_log_probs", "=", "topk_log_probs", ".", "index_select", "(", "\n", "0", ",", "non_finished", ".", "to", "(", "topk_log_probs", ".", "device", ")", ")", "\n", "topk_ids", "=", "topk_ids", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "batch_index", "=", "batch_index", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "batch_offset", "=", "batch_offset", ".", "index_select", "(", "0", ",", "non_finished", ")", "\n", "\n", "# Select and reorder alive batches.", "\n", "", "select_indices", "=", "batch_index", ".", "view", "(", "-", "1", ")", "\n", "alive_seq", "=", "alive_seq", ".", "index_select", "(", "0", ",", "select_indices", ")", "\n", "memory_bank", "=", "memory_bank", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "memory_lengths", "=", "memory_lengths", ".", "index_select", "(", "0", ",", "select_indices", ")", "\n", "dec_states", ".", "map_batch_fn", "(", "\n", "lambda", "state", ",", "dim", ":", "state", ".", "index_select", "(", "dim", ",", "select_indices", ")", ")", "\n", "\n", "# Append last prediction.", "\n", "alive_seq", "=", "torch", ".", "cat", "(", "[", "alive_seq", ",", "topk_ids", ".", "view", "(", "-", "1", ",", "1", ")", "]", ",", "-", "1", ")", "\n", "\n", "if", "return_attention", ":", "\n", "                ", "current_attn", "=", "attn", "[", "\"std\"", "]", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "if", "alive_attn", "is", "None", ":", "\n", "                    ", "alive_attn", "=", "current_attn", "\n", "", "else", ":", "\n", "                    ", "alive_attn", "=", "alive_attn", ".", "index_select", "(", "1", ",", "select_indices", ")", "\n", "alive_attn", "=", "torch", ".", "cat", "(", "[", "alive_attn", ",", "current_attn", "]", ",", "0", ")", "\n", "\n", "", "", "", "return", "results", "\n", "\n", "", "def", "_translate_batch", "(", "self", ",", "batch", ",", "data", ")", ":", "\n", "# (0) Prep each of the components of the search.", "\n", "# And helper method for reducing verbosity.", "\n", "        ", "beam_size", "=", "self", ".", "beam_size", "\n", "batch_size", "=", "batch", ".", "batch_size", "\n", "data_type", "=", "data", ".", "data_type", "\n", "vocab", "=", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", "\n", "\n", "# Define a list of tokens to exclude from ngram-blocking", "\n", "# exclusion_list = [\"<t>\", \"</t>\", \".\"]", "\n", "exclusion_tokens", "=", "set", "(", "[", "vocab", ".", "stoi", "[", "t", "]", "\n", "for", "t", "in", "self", ".", "ignore_when_blocking", "]", ")", "\n", "\n", "beam", "=", "[", "onmt", ".", "translate", ".", "Beam", "(", "beam_size", ",", "n_best", "=", "self", ".", "n_best", ",", "\n", "cuda", "=", "self", ".", "cuda", ",", "\n", "global_scorer", "=", "self", ".", "global_scorer", ",", "\n", "pad", "=", "vocab", ".", "stoi", "[", "inputters", ".", "PAD_WORD", "]", ",", "\n", "eos", "=", "vocab", ".", "stoi", "[", "inputters", ".", "EOS_WORD", "]", ",", "\n", "bos", "=", "vocab", ".", "stoi", "[", "inputters", ".", "BOS_WORD", "]", ",", "\n", "min_length", "=", "self", ".", "min_length", ",", "\n", "stepwise_penalty", "=", "self", ".", "stepwise_penalty", ",", "\n", "block_ngram_repeat", "=", "self", ".", "block_ngram_repeat", ",", "\n", "exclusion_tokens", "=", "exclusion_tokens", ")", "\n", "for", "__", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "# Help functions for working with beams and batches", "\n", "def", "var", "(", "a", ")", ":", "return", "torch", ".", "tensor", "(", "a", ",", "requires_grad", "=", "False", ")", "\n", "\n", "def", "rvar", "(", "a", ")", ":", "return", "var", "(", "a", ".", "repeat", "(", "1", ",", "beam_size", ",", "1", ")", ")", "\n", "\n", "def", "bottle", "(", "m", ")", ":", "\n", "            ", "return", "m", ".", "view", "(", "batch_size", "*", "beam_size", ",", "-", "1", ")", "\n", "\n", "", "def", "unbottle", "(", "m", ")", ":", "\n", "            ", "return", "m", ".", "view", "(", "beam_size", ",", "batch_size", ",", "-", "1", ")", "\n", "\n", "# (1) Run the encoder on the src.", "\n", "", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "data_type", ")", "\n", "src_lengths", "=", "None", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "\n", "", "probs", "=", "None", "\n", "if", "self", ".", "model_opt", ".", "key_model", "==", "'key_generator'", ":", "\n", "            ", "enc_states", ",", "memory_bank", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "", "elif", "self", ".", "model_opt", ".", "key_model", "==", "'key_end2end'", ":", "\n", "            ", "if", "self", ".", "model_opt", ".", "e2e_type", "==", "'separate_enc_sel'", ":", "\n", "                ", "_", ",", "probs", ",", "_", ",", "_", "=", "self", ".", "model", ".", "selector", "(", "src", ",", "src_lengths", ")", "\n", "enc_states", ",", "memory_bank", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "", "else", ":", "\n", "                ", "_", ",", "probs", ",", "enc_states", ",", "memory_bank", "=", "self", ".", "model", ".", "selector", "(", "src", ",", "src_lengths", ")", "\n", "\n", "", "", "retrieved_keys", "=", "inputters", ".", "make_features", "(", "batch", ",", "'retrieved_keys'", ",", "data_type", ")", "\n", "rk_lengths", "=", "None", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "_", ",", "rk_lengths", "=", "batch", ".", "retrieved_keys", "\n", "\n", "", "rk_memory_bank", "=", "None", "\n", "if", "self", ".", "model", ".", "rk_encoder", "is", "not", "None", ":", "\n", "            ", "_", ",", "rk_memory_bank", "=", "self", ".", "model", ".", "rk_encoder", "(", "retrieved_keys", ",", "rk_lengths", ")", "\n", "\n", "", "dec_states", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "\n", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "\n", "if", "src_lengths", "is", "None", ":", "\n", "            ", "src_lengths", "=", "torch", ".", "Tensor", "(", "batch_size", ")", ".", "type_as", "(", "memory_bank", ".", "data", ")", ".", "long", "(", ")", ".", "fill_", "(", "memory_bank", ".", "size", "(", "0", ")", ")", "\n", "\n", "# (2) Repeat src objects `beam_size` times.", "\n", "", "src_map", "=", "rvar", "(", "batch", ".", "src_map", ".", "data", ")", "if", "data_type", "==", "'text'", "and", "self", ".", "copy_attn", "else", "None", "\n", "memory_bank", "=", "rvar", "(", "memory_bank", ".", "data", ")", "\n", "\n", "if", "rk_memory_bank", "is", "not", "None", ":", "\n", "            ", "rk_memory_bank", "=", "rvar", "(", "rk_memory_bank", ".", "data", ")", "\n", "\n", "\n", "", "if", "probs", "is", "not", "None", ":", "\n", "            ", "expand_probs", "=", "probs", ".", "repeat", "(", "1", ",", "beam_size", ")", "\n", "", "else", ":", "\n", "            ", "expand_probs", "=", "None", "\n", "\n", "", "memory_lengths", "=", "src_lengths", ".", "repeat", "(", "beam_size", ")", "\n", "\n", "if", "rk_lengths", "is", "not", "None", ":", "\n", "            ", "rk_lengths", "=", "rk_lengths", ".", "repeat", "(", "beam_size", ")", "\n", "\n", "", "dec_states", ".", "repeat_beam_size_times", "(", "beam_size", ")", "\n", "\n", "# (3) run the decoder to generate sentences, using beam search.", "\n", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "            ", "if", "all", "(", "(", "b", ".", "done", "(", ")", "for", "b", "in", "beam", ")", ")", ":", "\n", "                ", "break", "\n", "\n", "# Construct batch x beam_size nxt words.", "\n", "# Get all the pending current beam words and arrange for forward.", "\n", "", "inp", "=", "var", "(", "torch", ".", "stack", "(", "[", "b", ".", "get_current_state", "(", ")", "for", "b", "in", "beam", "]", ")", "\n", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "\n", "# Turn any copied words to UNKs", "\n", "# 0 is unk", "\n", "if", "self", ".", "copy_attn", ":", "\n", "                ", "inp", "=", "inp", ".", "masked_fill", "(", "\n", "inp", ".", "gt", "(", "len", "(", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", ")", "-", "1", ")", ",", "0", ")", "\n", "\n", "# Temporary kludge solution to handle changed dim expectation", "\n", "# in the decoder", "\n", "", "inp", "=", "inp", ".", "unsqueeze", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._from_beam": [[632, 648], ["b.sort_finished", "enumerate", "ret[].append", "ret[].append", "ret[].append", "b.get_hyp", "hyps.append", "attn.append"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.Beam.sort_finished", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.Beam.get_hyp"], ["# Run one step.", "\n", "dec_out", ",", "dec_states", ",", "attn", "=", "self", ".", "model", ".", "decoder", "(", "\n", "inp", ",", "memory_bank", ",", "rk_memory_bank", ",", "\n", "dec_states", ",", "\n", "memory_lengths", "=", "memory_lengths", ",", "\n", "rk_memory_lengths", "=", "rk_lengths", ",", "\n", "step", "=", "i", ",", "probs", "=", "expand_probs", ")", "\n", "\n", "\n", "\n", "dec_out", "=", "dec_out", ".", "squeeze", "(", "0", ")", "\n", "\n", "# dec_out: beam x rnn_size", "\n", "\n", "# (b) Compute a vector of batch x beam word scores.", "\n", "if", "not", "self", ".", "copy_attn", ":", "\n", "                ", "out", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec_out", ")", ".", "data", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._run_target": [[649, 679], ["onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "translator.Translator.model.encoder", "translator.Translator.model.decoder.init_decoder_state", "tt.FloatTensor().fill_", "translator.Translator.model.decoder", "zip", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "translator.Translator.model.generator.forward", "tgt.unsqueeze.unsqueeze.unsqueeze", "translator.Translator.data.gather", "translator.Translator.data.gather.masked_fill_", "translator.Translator.data.gather.view", "tt.FloatTensor", "tgt.unsqueeze.unsqueeze.eq"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoder.init_decoder_state", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.rnn_reranker.RNNReRanker.forward"], ["out", "=", "unbottle", "(", "out", ")", "\n", "# beam x tgt_vocab", "\n", "beam_attn", "=", "unbottle", "(", "attn", "[", "\"std\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "self", ".", "model", ".", "generator", ".", "forward", "(", "dec_out", ",", "\n", "attn", "[", "\"copy\"", "]", ".", "squeeze", "(", "0", ")", ",", "\n", "src_map", ")", "\n", "# beam x (tgt_vocab + extra_vocab)", "\n", "out", "=", "data", ".", "collapse_copy_scores", "(", "\n", "unbottle", "(", "out", ".", "data", ")", ",", "\n", "batch", ",", "self", ".", "fields", "[", "\"tgt\"", "]", ".", "vocab", ",", "data", ".", "src_vocabs", ")", "\n", "# beam x tgt_vocab", "\n", "out", "=", "out", ".", "log", "(", ")", "\n", "beam_attn", "=", "unbottle", "(", "attn", "[", "\"copy\"", "]", ")", "\n", "\n", "# (c) Advance each beam.", "\n", "", "for", "j", ",", "b", "in", "enumerate", "(", "beam", ")", ":", "\n", "                ", "b", ".", "advance", "(", "out", "[", ":", ",", "j", "]", ",", "\n", "beam_attn", ".", "data", "[", ":", ",", "j", ",", ":", "memory_lengths", "[", "j", "]", "]", ")", "\n", "dec_states", ".", "beam_update", "(", "j", ",", "b", ".", "get_current_origin", "(", ")", ",", "beam_size", ")", "\n", "\n", "# (4) Extract sentences from beam.", "\n", "", "", "ret", "=", "self", ".", "_from_beam", "(", "beam", ")", "\n", "ret", "[", "\"gold_score\"", "]", "=", "[", "0", "]", "*", "batch_size", "\n", "if", "\"tgt\"", "in", "batch", ".", "__dict__", ":", "\n", "            ", "ret", "[", "\"gold_score\"", "]", "=", "self", ".", "_run_target", "(", "batch", ",", "data", ")", "\n", "", "ret", "[", "\"batch\"", "]", "=", "batch", "\n", "ret", "[", "\"selector_probs\"", "]", "=", "probs", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._report_score": [[680, 685], ["math.exp"], "methods", ["None"], ["", "def", "_from_beam", "(", "self", ",", "beam", ")", ":", "\n", "        ", "ret", "=", "{", "\"predictions\"", ":", "[", "]", ",", "\n", "\"scores\"", ":", "[", "]", ",", "\n", "\"attention\"", ":", "[", "]", "}", "\n", "for", "b", "in", "beam", ":", "\n", "            ", "n_best", "=", "self", ".", "n_best", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._report_bleu": [[686, 700], ["os.path.abspath", "translator.Translator.out_file.seek", "print", "subprocess.check_output().decode", "subprocess.check_output().decode.strip", "subprocess.check_output"], "methods", ["None"], ["scores", ",", "ks", "=", "b", ".", "sort_finished", "(", "minimum", "=", "n_best", ")", "\n", "hyps", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "(", "times", ",", "k", ")", "in", "enumerate", "(", "ks", "[", ":", "n_best", "]", ")", ":", "\n", "                ", "hyp", ",", "att", "=", "b", ".", "get_hyp", "(", "times", ",", "k", ")", "\n", "hyps", ".", "append", "(", "hyp", ")", "\n", "attn", ".", "append", "(", "att", ")", "\n", "", "ret", "[", "\"predictions\"", "]", ".", "append", "(", "hyps", ")", "\n", "ret", "[", "\"scores\"", "]", ".", "append", "(", "scores", ")", "\n", "ret", "[", "\"attention\"", "]", ".", "append", "(", "attn", ")", "\n", "", "return", "ret", "\n", "\n", "", "def", "_run_target", "(", "self", ",", "batch", ",", "data", ")", ":", "\n", "        ", "data_type", "=", "data", ".", "data_type", "\n", "if", "data_type", "==", "'text'", ":", "\n", "            ", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.Translator._report_rouge": [[701, 711], ["subprocess.check_output().decode", "subprocess.check_output().decode.strip", "os.path.split", "os.path.realpath", "subprocess.check_output"], "methods", ["None"], ["", "else", ":", "\n", "            ", "src_lengths", "=", "None", "\n", "", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "data_type", ")", "\n", "tgt_in", "=", "inputters", ".", "make_features", "(", "batch", ",", "'tgt'", ")", "[", ":", "-", "1", "]", "\n", "\n", "#  (1) run the encoder on the src", "\n", "enc_states", ",", "memory_bank", "=", "self", ".", "model", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "dec_states", "=", "self", ".", "model", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "memory_bank", ",", "enc_states", ")", "\n", "\n", "#  (2) if a target is specified, compute the 'goldScore'", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.build_translator": [[21, 51], ["argparse.ArgumentParser", "onmt.model_opts", "onmt.model_builder.load_test_model", "onmt.model_builder.load_test_model", "onmt.model_builder.load_test_model", "onmt.model_builder.load_test_model", "onmt.translate.GNMTGlobalScorer", "onmt.translate.GNMTGlobalScorer", "onmt.translate.GNMTGlobalScorer", "onmt.translate.GNMTGlobalScorer", "translator.Translator", "codecs.open", "torch.cuda.set_device", "argparse.ArgumentParser.parse_known_args", "getattr"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.model_opts", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.load_test_model", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.load_test_model", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.load_test_model", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.load_test_model"], ["def", "build_translator", "(", "opt", ",", "report_score", "=", "True", ",", "logger", "=", "None", ",", "out_file", "=", "None", ")", ":", "\n", "    ", "if", "out_file", "is", "None", ":", "\n", "        ", "out_file", "=", "codecs", ".", "open", "(", "opt", ".", "output", ",", "'w+'", ",", "'utf-8'", ")", "\n", "", "scores_out_file", "=", "codecs", ".", "open", "(", "opt", ".", "scores_output", ",", "'w+'", ",", "'utf-8'", ")", "\n", "if", "'end2end'", "in", "opt", ".", "model", ":", "\n", "        ", "sel_probs_out_file", "=", "codecs", ".", "open", "(", "opt", ".", "sel_probs_output", ",", "'w+'", ",", "'utf-8'", ")", "\n", "", "else", ":", "\n", "        ", "sel_probs_out_file", "=", "None", "\n", "\n", "", "if", "opt", ".", "gpu", ">", "-", "1", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "\n", "", "dummy_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'train.py'", ")", "\n", "opts", ".", "model_opts", "(", "dummy_parser", ")", "\n", "dummy_opt", "=", "dummy_parser", ".", "parse_known_args", "(", "[", "]", ")", "[", "0", "]", "\n", "\n", "fields", ",", "model", ",", "model_opt", "=", "onmt", ".", "model_builder", ".", "load_test_model", "(", "opt", ",", "dummy_opt", ".", "__dict__", ")", "\n", "\n", "scorer", "=", "onmt", ".", "translate", ".", "GNMTGlobalScorer", "(", "opt", ".", "alpha", ",", "\n", "opt", ".", "beta", ",", "\n", "opt", ".", "coverage_penalty", ",", "\n", "opt", ".", "length_penalty", ")", "\n", "\n", "kwargs", "=", "{", "k", ":", "getattr", "(", "opt", ",", "k", ")", "\n", "for", "k", "in", "[", "\"beam_size\"", ",", "\"n_best\"", ",", "\"max_length\"", ",", "\"min_length\"", ",", "\n", "\"stepwise_penalty\"", ",", "\"block_ngram_repeat\"", ",", "\n", "\"ignore_when_blocking\"", ",", "\"dump_beam\"", ",", "\"report_bleu\"", ",", "\n", "\"data_type\"", ",", "\"replace_unk\"", ",", "\"gpu\"", ",", "\"verbose\"", ",", "\"fast\"", "]", "}", "\n", "\n", "translator", "=", "Translator", "(", "opt", ",", "model_opt", ",", "model", ",", "fields", ",", "global_scorer", "=", "scorer", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.Timer.__init__": [[19, 25], ["translation_server.Timer.start"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.start"], ["    ", "def", "__init__", "(", "self", ",", "start", "=", "False", ")", ":", "\n", "        ", "self", ".", "stime", "=", "-", "1", "\n", "self", ".", "prev", "=", "-", "1", "\n", "self", ".", "times", "=", "{", "}", "\n", "if", "start", ":", "\n", "            ", "self", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.Timer.start": [[26, 30], ["time.time"], "methods", ["None"], ["", "", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "stime", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "prev", "=", "self", ".", "stime", "\n", "self", ".", "times", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.Timer.tick": [[31, 42], ["time.time"], "methods", ["None"], ["", "def", "tick", "(", "self", ",", "name", "=", "None", ",", "tot", "=", "False", ")", ":", "\n", "        ", "t", "=", "time", ".", "time", "(", ")", "\n", "if", "not", "tot", ":", "\n", "            ", "elapsed", "=", "t", "-", "self", ".", "prev", "\n", "", "else", ":", "\n", "            ", "elapsed", "=", "t", "-", "self", ".", "stime", "\n", "", "self", ".", "prev", "=", "t", "\n", "\n", "if", "name", "is", "not", "None", ":", "\n", "            ", "self", ".", "times", "[", "name", "]", "=", "elapsed", "\n", "", "return", "elapsed", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.__init__": [[49, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "models", "=", "{", "}", "\n", "self", ".", "next_id", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.start": [[53, 76], ["translation_server.TranslationServer.confs.get", "enumerate", "open", "json.load", "conf.get", "translation_server.TranslationServer.preload_model", "ValueError", "conf.get", "conf.get", "conf.get", "conf.get", "conf.get", "kwargs.items"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.preload_model"], ["", "def", "start", "(", "self", ",", "config_file", ")", ":", "\n", "        ", "\"\"\"Read the config file and pre-/load the models\n        \"\"\"", "\n", "self", ".", "config_file", "=", "config_file", "\n", "with", "open", "(", "self", ".", "config_file", ")", "as", "f", ":", "\n", "            ", "self", ".", "confs", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "models_root", "=", "self", ".", "confs", ".", "get", "(", "'models_root'", ",", "'./available_models'", ")", "\n", "for", "i", ",", "conf", "in", "enumerate", "(", "self", ".", "confs", "[", "\"models\"", "]", ")", ":", "\n", "            ", "if", "\"model\"", "not", "in", "conf", ":", "\n", "                ", "raise", "ValueError", "(", "\"\"\"Incorrect config file: missing 'model'\n                                    parameter for model #%d\"\"\"", "%", "i", ")", "\n", "", "kwargs", "=", "{", "'timeout'", ":", "conf", ".", "get", "(", "'timeout'", ",", "None", ")", ",", "\n", "'load'", ":", "conf", ".", "get", "(", "'load'", ",", "None", ")", ",", "\n", "'tokenizer_opt'", ":", "conf", ".", "get", "(", "'tokenizer'", ",", "None", ")", ",", "\n", "'on_timeout'", ":", "conf", ".", "get", "(", "'on_timeout'", ",", "None", ")", ",", "\n", "'model_root'", ":", "conf", ".", "get", "(", "'model_root'", ",", "self", ".", "models_root", ")", "\n", "}", "\n", "kwargs", "=", "{", "k", ":", "v", "for", "(", "k", ",", "v", ")", "in", "kwargs", ".", "items", "(", ")", "if", "v", "is", "not", "None", "}", "\n", "model_id", "=", "conf", ".", "get", "(", "\"id\"", ",", "None", ")", "\n", "opt", "=", "conf", "[", "\"opt\"", "]", "\n", "opt", "[", "\"model\"", "]", "=", "conf", "[", "\"model\"", "]", "\n", "self", ".", "preload_model", "(", "opt", ",", "model_id", "=", "model_id", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.clone_model": [[77, 89], ["translation_server.TranslationServer.load_model", "translation_server.ServerModelError", "str"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.load_model"], ["", "", "def", "clone_model", "(", "self", ",", "model_id", ",", "opt", ",", "timeout", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Clone a model `model_id`.\n           Different options may be passed. If `opt` is None, it will use the\n           same set of options\n        \"\"\"", "\n", "if", "model_id", "in", "self", ".", "models", ":", "\n", "            ", "if", "opt", "is", "None", ":", "\n", "                ", "opt", "=", "self", ".", "models", "[", "model_id", "]", ".", "user_opt", "\n", "", "opt", "[", "\"model\"", "]", "=", "self", ".", "models", "[", "model_id", "]", ".", "opt", ".", "model", "\n", "return", "self", ".", "load_model", "(", "opt", ",", "timeout", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.load_model": [[90, 97], ["translation_server.TranslationServer.preload_model"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.preload_model"], ["", "", "def", "load_model", "(", "self", ",", "opt", ",", "model_id", "=", "None", ",", "**", "model_kwargs", ")", ":", "\n", "        ", "\"\"\"Loading a model given a set of options\n        \"\"\"", "\n", "model_id", "=", "self", ".", "preload_model", "(", "opt", ",", "model_id", "=", "model_id", ",", "**", "model_kwargs", ")", "\n", "load_time", "=", "self", ".", "models", "[", "model_id", "]", ".", "load_time", "\n", "\n", "return", "model_id", ",", "load_time", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.preload_model": [[98, 115], ["print", "translation_server.ServerModel", "translation_server.TranslationServer.models.keys", "ValueError", "translation_server.TranslationServer.models.keys"], "methods", ["None"], ["", "def", "preload_model", "(", "self", ",", "opt", ",", "model_id", "=", "None", ",", "**", "model_kwargs", ")", ":", "\n", "        ", "\"\"\"Preloading the model: updating internal datastructure\n           It will effectively load the model if `load` is set\n        \"\"\"", "\n", "if", "model_id", "is", "not", "None", ":", "\n", "            ", "if", "model_id", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Model ID %d already exists\"", "%", "model_id", ")", "\n", "", "", "else", ":", "\n", "            ", "model_id", "=", "self", ".", "next_id", "\n", "while", "model_id", "in", "self", ".", "models", ".", "keys", "(", ")", ":", "\n", "                ", "model_id", "+=", "1", "\n", "", "self", ".", "next_id", "=", "model_id", "+", "1", "\n", "", "print", "(", "\"Pre-loading model %d\"", "%", "model_id", ")", "\n", "model", "=", "ServerModel", "(", "opt", ",", "model_id", ",", "**", "model_kwargs", ")", "\n", "self", ".", "models", "[", "model_id", "]", "=", "model", "\n", "\n", "return", "model_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.run": [[116, 129], ["inputs[].get", "translation_server.TranslationServer.models[].run", "print", "translation_server.ServerModelError", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.run"], ["", "def", "run", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Translate `inputs`\n           We keep the same format as the Lua version i.e.\n             [{\"id\": model_id, \"src\": \"sequence to translate\"},{ ...}]\n\n           We use inputs[0][\"id\"] as the model id\n        \"\"\"", "\n", "model_id", "=", "inputs", "[", "0", "]", ".", "get", "(", "\"id\"", ",", "0", ")", "\n", "if", "model_id", "in", "self", ".", "models", "and", "self", ".", "models", "[", "model_id", "]", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "models", "[", "model_id", "]", ".", "run", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Error No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.unload_model": [[130, 138], ["translation_server.TranslationServer.models[].unload", "translation_server.ServerModelError", "str"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.unload"], ["", "", "def", "unload_model", "(", "self", ",", "model_id", ")", ":", "\n", "        ", "\"\"\"Manually unload a model.\n           It will free the memory and cancel the timer\n        \"\"\"", "\n", "if", "model_id", "in", "self", ".", "models", "and", "self", ".", "models", "[", "model_id", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "models", "[", "model_id", "]", ".", "unload", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"No such model '%s'\"", "%", "str", "(", "model_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.list_models": [[139, 146], ["translation_server.TranslationServer.models.items", "model.to_dict"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.to_dict"], ["", "", "def", "list_models", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the list of available models\n        \"\"\"", "\n", "models", "=", "[", "]", "\n", "for", "_", ",", "model", "in", "self", ".", "models", ".", "items", "(", ")", ":", "\n", "            ", "models", "+=", "[", "model", ".", "to_dict", "(", ")", "]", "\n", "", "return", "models", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.__init__": [[149, 182], ["translation_server.ServerModel.parse_opt", "onmt.utils.logging.init_logger", "ValueError", "translation_server.ServerModel.load"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.parse_opt", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.logging.init_logger", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "model_id", ",", "tokenizer_opt", "=", "None", ",", "load", "=", "False", ",", "\n", "timeout", "=", "-", "1", ",", "on_timeout", "=", "\"to_cpu\"", ",", "model_root", "=", "\"./\"", ")", ":", "\n", "        ", "\"\"\"\n            Args:\n                opt: (dict) options for the Translator\n                model_id: (int) model id\n                tokenizer_opt: (dict) options for the tokenizer or None\n                load: (bool) whether to load the model during __init__\n                timeout: (int) seconds before running `do_timeout`\n                         Negative values means no timeout\n                on_timeout: (str) in [\"to_cpu\", \"unload\"] set what to do on\n                            timeout (see function `do_timeout`)\n                model_root: (str) path to the model directory\n                            it must contain de model and tokenizer file\n\n        \"\"\"", "\n", "self", ".", "model_root", "=", "model_root", "\n", "self", ".", "opt", "=", "self", ".", "parse_opt", "(", "opt", ")", "\n", "if", "self", ".", "opt", ".", "n_best", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Values of n_best > 1 are not supported\"", ")", "\n", "\n", "", "self", ".", "model_id", "=", "model_id", "\n", "self", ".", "tokenizer_opt", "=", "tokenizer_opt", "\n", "self", ".", "timeout", "=", "timeout", "\n", "self", ".", "on_timeout", "=", "on_timeout", "\n", "\n", "self", ".", "unload_timer", "=", "None", "\n", "self", ".", "user_opt", "=", "opt", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "logger", "=", "init_logger", "(", "self", ".", "opt", ".", "log_file", ")", "\n", "\n", "if", "load", ":", "\n", "            ", "self", ".", "load", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.parse_opt": [[183, 207], ["argparse.ArgumentParser", "onmt.opts.translate_opts", "os.path.join", "argparse.ArgumentParser.parse_args.items", "argparse.ArgumentParser.parse_args", "str"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.translate_opts", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.parse_args"], ["", "", "def", "parse_opt", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Parse the option set passed by the user using `onmt.opts`\n           Args:\n               opt: (dict) options passed by the user\n\n           Returns:\n               opt: (Namespace) full set of options for the Translator\n        \"\"\"", "\n", "prec_argv", "=", "sys", ".", "argv", "\n", "sys", ".", "argv", "=", "sys", ".", "argv", "[", ":", "1", "]", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "onmt", ".", "opts", ".", "translate_opts", "(", "parser", ")", "\n", "\n", "opt", "[", "'model'", "]", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_root", ",", "opt", "[", "'model'", "]", ")", "\n", "opt", "[", "'src'", "]", "=", "\"dummy_src\"", "\n", "\n", "for", "(", "k", ",", "v", ")", "in", "opt", ".", "items", "(", ")", ":", "\n", "            ", "sys", ".", "argv", "+=", "[", "'-%s'", "%", "k", ",", "str", "(", "v", ")", "]", "\n", "\n", "", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "opt", ".", "gpu", ">", "-", "1", "\n", "\n", "sys", ".", "argv", "=", "prec_argv", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.loaded": [[208, 211], ["hasattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "loaded", "(", "self", ")", ":", "\n", "        ", "return", "hasattr", "(", "self", ",", "'translator'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load": [[212, 244], ["translation_server.Timer", "translation_server.ServerModel.logger.info", "translation_server.Timer.start", "translation_server.Timer.tick", "translation_server.Timer.tick", "translation_server.ServerModel.reset_unload_timer", "onmt.translate.translator.build_translator", "translation_server.ServerModel.logger.info", "translation_server.ServerModelError", "spm.SentencePieceProcessor", "os.path.join", "spm.SentencePieceProcessor.Load", "ValueError", "open", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.start", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.reset_unload_timer", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translator.build_translator"], ["", "def", "load", "(", "self", ")", ":", "\n", "        ", "timer", "=", "Timer", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"Loading model %d\"", "%", "self", ".", "model_id", ")", "\n", "timer", ".", "start", "(", ")", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "translator", "=", "build_translator", "(", "self", ".", "opt", ",", "\n", "report_score", "=", "False", ",", "\n", "out_file", "=", "open", "(", "os", ".", "devnull", ",", "\"w\"", ")", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "            ", "raise", "ServerModelError", "(", "\"Runtime Error: %s\"", "%", "str", "(", "e", ")", ")", "\n", "\n", "", "timer", ".", "tick", "(", "\"model_loading\"", ")", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading tokenizer\"", ")", "\n", "mandatory", "=", "[", "\"type\"", ",", "\"model\"", "]", "\n", "for", "m", "in", "mandatory", ":", "\n", "                ", "if", "m", "not", "in", "self", ".", "tokenizer_opt", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Missing mandatory tokenizer option '%s'\"", "\n", "%", "m", ")", "\n", "", "", "if", "self", ".", "tokenizer_opt", "[", "'type'", "]", "==", "'sentencepiece'", ":", "\n", "                ", "import", "sentencepiece", "as", "spm", "\n", "sp", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "model_root", ",", "\n", "self", ".", "tokenizer_opt", "[", "'model'", "]", ")", "\n", "sp", ".", "Load", "(", "model_path", ")", "\n", "self", ".", "tokenizer", "=", "sp", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid value for tokenizer type\"", ")", "\n", "\n", "", "", "self", ".", "load_time", "=", "timer", ".", "tick", "(", ")", "\n", "self", ".", "reset_unload_timer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.run": [[245, 330], ["translation_server.Timer", "translation_server.ServerModel.logger.info", "translation_server.Timer.start", "enumerate", "translation_server.Timer.tick", "translation_server.Timer.tick", "translation_server.ServerModel.logger.info", "translation_server.ServerModel.reset_unload_timer", "translation_server.ServerModel.run.flatten_list"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.start", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.Timer.tick", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.reset_unload_timer"], ["", "def", "run", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Translate `inputs` using this model\n\n            Args:\n                inputs: [{\"src\": \"...\"},{\"src\": ...}]\n\n            Returns:\n                result: (list) translations\n                times: (dict) containing times\n        \"\"\"", "\n", "timer", "=", "Timer", "(", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"\\nRunning translation using %d\"", "%", "self", ".", "model_id", ")", "\n", "\n", "timer", ".", "start", "(", ")", "\n", "if", "not", "self", ".", "loaded", ":", "\n", "            ", "self", ".", "load", "(", ")", "\n", "timer", ".", "tick", "(", "name", "=", "\"load\"", ")", "\n", "", "elif", "self", ".", "opt", ".", "cuda", ":", "\n", "            ", "self", ".", "to_gpu", "(", ")", "\n", "timer", ".", "tick", "(", "name", "=", "\"to_gpu\"", ")", "\n", "\n", "", "texts", "=", "[", "]", "\n", "whitespace_segments", "=", "{", "}", "\n", "subsegment", "=", "{", "}", "\n", "sscount", "=", "0", "\n", "sslength", "=", "[", "]", "\n", "for", "(", "i", ",", "inp", ")", "in", "enumerate", "(", "inputs", ")", ":", "\n", "            ", "src", "=", "inp", "[", "'src'", "]", "\n", "lines", "=", "src", ".", "split", "(", "\"\\n\"", ")", "\n", "subsegment", "[", "i", "]", "=", "slice", "(", "sscount", ",", "sscount", "+", "len", "(", "lines", ")", ")", "\n", "for", "line", "in", "lines", ":", "\n", "                ", "tok", "=", "self", ".", "maybe_tokenize", "(", "line", ")", "\n", "if", "len", "(", "''", ".", "join", "(", "line", ".", "split", "(", ")", ")", ")", "==", "0", ":", "\n", "                    ", "whitespace_segments", "[", "sscount", "]", "=", "line", "\n", "", "else", ":", "\n", "                    ", "texts", "+=", "[", "tok", "]", "\n", "sslength", "+=", "[", "len", "(", "tok", ".", "split", "(", ")", ")", "]", "\n", "sscount", "+=", "1", "\n", "\n", "", "", "", "timer", ".", "tick", "(", "name", "=", "\"writing\"", ")", "\n", "\n", "scores", "=", "[", "]", "\n", "predictions", "=", "[", "]", "\n", "if", "sscount", ">", "0", ":", "\n", "            ", "try", ":", "\n", "                ", "scores", ",", "predictions", "=", "self", ".", "translator", ".", "translate", "(", "\n", "src_data_iter", "=", "texts", ",", "batch_size", "=", "self", ".", "opt", ".", "batch_size", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "                ", "raise", "ServerModelError", "(", "\"Runtime Error: %s\"", "%", "str", "(", "e", ")", ")", "\n", "\n", "", "", "timer", ".", "tick", "(", "name", "=", "\"translation\"", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"\"\"Using model #%d\\t%d inputs (%d subsegment)\n               \\ttranslation time: %f\"\"\"", "%", "(", "self", ".", "model_id", ",", "len", "(", "subsegment", ")", ",", "\n", "sscount", ",", "\n", "timer", ".", "times", "[", "'translation'", "]", ")", ")", "\n", "self", ".", "reset_unload_timer", "(", ")", "\n", "\n", "# NOTE: translator returns lists of `n_best` list", "\n", "#       we can ignore that (i.e. flatten lists) only because", "\n", "#       we restrict `n_best=1`", "\n", "def", "flatten_list", "(", "_list", ")", ":", "return", "sum", "(", "_list", ",", "[", "]", ")", "\n", "results", "=", "flatten_list", "(", "predictions", ")", "\n", "scores", "=", "[", "score_tensor", ".", "item", "(", ")", "\n", "for", "score_tensor", "in", "flatten_list", "(", "scores", ")", "]", "\n", "\n", "self", ".", "logger", ".", "info", "(", "\"Translation Results: \"", ",", "len", "(", "results", ")", ")", "\n", "if", "len", "(", "whitespace_segments", ")", ">", "0", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Whitespace segments: %d\"", "\n", "%", "len", "(", "whitespace_segments", ")", ")", "\n", "\n", "", "for", "k", "in", "sorted", "(", "whitespace_segments", ".", "keys", "(", ")", ")", ":", "\n", "            ", "results", ".", "insert", "(", "k", ",", "whitespace_segments", "[", "k", "]", ")", "\n", "scores", ".", "insert", "(", "k", ",", "0.0", ")", "\n", "\n", "", "results", "=", "[", "'\\n'", ".", "join", "(", "[", "self", ".", "maybe_detokenize", "(", "_", ")", "\n", "for", "_", "in", "results", "[", "subsegment", "[", "i", "]", "]", "]", ")", "\n", "for", "i", "in", "sorted", "(", "subsegment", ".", "keys", "(", ")", ")", "]", "\n", "\n", "avg_scores", "=", "[", "sum", "(", "[", "s", "*", "l", "for", "s", ",", "l", "in", "zip", "(", "scores", "[", "sub", "]", ",", "sslength", "[", "sub", "]", ")", "]", ")", "\n", "/", "sum", "(", "sslength", "[", "sub", "]", ")", "\n", "if", "sum", "(", "sslength", "[", "sub", "]", ")", "!=", "0", "else", "0.0", "\n", "for", "k", ",", "sub", "\n", "in", "sorted", "(", "subsegment", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "]", "\n", "\n", "return", "results", ",", "avg_scores", ",", "self", ".", "opt", ".", "n_best", ",", "timer", ".", "times", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.do_timeout": [[331, 342], ["translation_server.ServerModel.logger.info", "translation_server.ServerModel.unload", "translation_server.ServerModel.logger.info", "translation_server.ServerModel.to_cpu"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.unload", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.to_cpu"], ["", "def", "do_timeout", "(", "self", ")", ":", "\n", "        ", "\"\"\"Timeout function that free GPU memory by moving the model to CPU\n           or unloading it; depending on `self.on_timemout` value\n        \"\"\"", "\n", "if", "self", ".", "on_timeout", "==", "\"unload\"", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Timeout: unloading model %d\"", "%", "self", ".", "model_id", ")", "\n", "self", ".", "unload", "(", ")", "\n", "", "if", "self", ".", "on_timeout", "==", "\"to_cpu\"", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Timeout: sending model %d to CPU\"", "\n", "%", "self", ".", "model_id", ")", "\n", "self", ".", "to_cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.unload": [[343, 349], ["translation_server.ServerModel.logger.info", "torch.cuda.empty_cache"], "methods", ["None"], ["", "", "def", "unload", "(", "self", ")", ":", "\n", "        ", "self", ".", "logger", ".", "info", "(", "\"Unloading model %d\"", "%", "self", ".", "model_id", ")", "\n", "del", "self", ".", "translator", "\n", "if", "self", ".", "opt", ".", "cuda", ":", "\n", "            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "self", ".", "unload_timer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.reset_unload_timer": [[350, 358], ["threading.Timer", "translation_server.ServerModel.unload_timer.start", "translation_server.ServerModel.unload_timer.cancel"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.TranslationServer.start"], ["", "def", "reset_unload_timer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "timeout", "<", "0", ":", "\n", "            ", "return", "\n", "\n", "", "if", "self", ".", "unload_timer", "is", "not", "None", ":", "\n", "            ", "self", ".", "unload_timer", ".", "cancel", "(", ")", "\n", "", "self", ".", "unload_timer", "=", "threading", ".", "Timer", "(", "self", ".", "timeout", ",", "self", ".", "do_timeout", ")", "\n", "self", ".", "unload_timer", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.to_dict": [[359, 371], ["translation_server.ServerModel.user_opt.keys"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "hide_opt", "=", "[", "\"model\"", ",", "\"src\"", "]", "\n", "d", "=", "{", "\"model_id\"", ":", "self", ".", "model_id", ",", "\n", "\"opt\"", ":", "{", "k", ":", "self", ".", "user_opt", "[", "k", "]", "for", "k", "in", "self", ".", "user_opt", ".", "keys", "(", ")", "\n", "if", "k", "not", "in", "hide_opt", "}", ",", "\n", "\"model\"", ":", "self", ".", "user_opt", "[", "\"model\"", "]", ",", "\n", "\"loaded\"", ":", "self", ".", "loaded", ",", "\n", "\"timeout\"", ":", "self", ".", "timeout", ",", "\n", "}", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "d", "[", "\"tokenizer\"", "]", "=", "self", ".", "tokenizer_opt", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.to_cpu": [[372, 378], ["translation_server.ServerModel.translator.model.cpu", "torch.cuda.empty_cache"], "methods", ["None"], ["", "def", "to_cpu", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move the model to CPU and clear CUDA cache\n        \"\"\"", "\n", "self", ".", "translator", ".", "model", ".", "cpu", "(", ")", "\n", "if", "self", ".", "opt", ".", "cuda", ":", "\n", "            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.to_gpu": [[379, 384], ["torch.cuda.set_device", "translation_server.ServerModel.translator.model.cuda"], "methods", ["None"], ["", "", "def", "to_gpu", "(", "self", ")", ":", "\n", "        ", "\"\"\"Move the model to GPU\n        \"\"\"", "\n", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "opt", ".", "gpu", ")", "\n", "self", ".", "translator", ".", "model", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.maybe_tokenize": [[385, 393], ["translation_server.ServerModel.tokenize"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.tokenize"], ["", "def", "maybe_tokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Tokenize the sequence (or not)\n\n           Same args/returns as `tokenize`\n        \"\"\"", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "tokenize", "(", "sequence", ")", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.tokenize": [[394, 411], ["ValueError", "translation_server.ServerModel.tokenizer.EncodeAsPieces"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Tokenize a single sequence\n\n            Args:\n                sequence: (str) the sequence to tokenize\n\n            Returns:\n                tok: (str) the tokenized sequence\n\n        \"\"\"", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"No tokenizer loaded\"", ")", "\n", "\n", "", "if", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"sentencepiece\"", ":", "\n", "            ", "tok", "=", "self", ".", "tokenizer", ".", "EncodeAsPieces", "(", "sequence", ")", "\n", "tok", "=", "\" \"", ".", "join", "(", "tok", ")", "\n", "", "return", "tok", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.maybe_detokenize": [[412, 420], ["translation_server.ServerModel.detokenize"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.detokenize"], ["", "def", "maybe_detokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"De-tokenize the sequence (or not)\n\n           Same args/returns as `tokenize`\n        \"\"\"", "\n", "if", "self", ".", "tokenizer_opt", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "detokenize", "(", "sequence", ")", "\n", "", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.detokenize": [[421, 432], ["ValueError", "translation_server.ServerModel.tokenizer.DecodePieces", "sequence.split"], "methods", ["None"], ["", "def", "detokenize", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Detokenize a single sequence\n\n           Same args/returns as `tokenize`\n        \"\"\"", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"No tokenizer loaded\"", ")", "\n", "\n", "", "if", "self", ".", "tokenizer_opt", "[", "\"type\"", "]", "==", "\"sentencepiece\"", ":", "\n", "            ", "detok", "=", "self", ".", "tokenizer", ".", "DecodePieces", "(", "sequence", ".", "split", "(", ")", ")", "\n", "", "return", "detok", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.Beam.__init__": [[20, 65], ["set", "beam.Beam.tt.FloatTensor().zero_", "beam.Beam.tt.LongTensor().fill_", "beam.Beam.tt.FloatTensor", "beam.Beam.tt.LongTensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "pad", ",", "bos", ",", "eos", ",", "\n", "n_best", "=", "1", ",", "cuda", "=", "False", ",", "\n", "global_scorer", "=", "None", ",", "\n", "min_length", "=", "0", ",", "\n", "stepwise_penalty", "=", "False", ",", "\n", "block_ngram_repeat", "=", "0", ",", "\n", "exclusion_tokens", "=", "set", "(", ")", ")", ":", "\n", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "tt", "=", "torch", ".", "cuda", "if", "cuda", "else", "torch", "\n", "\n", "# The score for each translation on the beam.", "\n", "self", ".", "scores", "=", "self", ".", "tt", ".", "FloatTensor", "(", "size", ")", ".", "zero_", "(", ")", "\n", "self", ".", "all_scores", "=", "[", "]", "\n", "\n", "# The backpointers at each time-step.", "\n", "self", ".", "prev_ks", "=", "[", "]", "\n", "\n", "# The outputs at each time-step.", "\n", "self", ".", "next_ys", "=", "[", "self", ".", "tt", ".", "LongTensor", "(", "size", ")", "\n", ".", "fill_", "(", "pad", ")", "]", "\n", "self", ".", "next_ys", "[", "0", "]", "[", "0", "]", "=", "bos", "\n", "\n", "# Has EOS topped the beam yet.", "\n", "self", ".", "_eos", "=", "eos", "\n", "self", ".", "eos_top", "=", "False", "\n", "\n", "# The attentions (matrix) for each time.", "\n", "self", ".", "attn", "=", "[", "]", "\n", "\n", "# Time and k pair for finished.", "\n", "self", ".", "finished", "=", "[", "]", "\n", "self", ".", "n_best", "=", "n_best", "\n", "\n", "# Information for global scoring.", "\n", "self", ".", "global_scorer", "=", "global_scorer", "\n", "self", ".", "global_state", "=", "{", "}", "\n", "\n", "# Minimum prediction length", "\n", "self", ".", "min_length", "=", "min_length", "\n", "\n", "# Apply Penalty at every step", "\n", "self", ".", "stepwise_penalty", "=", "stepwise_penalty", "\n", "self", ".", "block_ngram_repeat", "=", "block_ngram_repeat", "\n", "self", ".", "exclusion_tokens", "=", "exclusion_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.Beam.get_current_state": [[66, 69], ["None"], "methods", ["None"], ["", "def", "get_current_state", "(", "self", ")", ":", "\n", "        ", "\"Get the outputs for the current timestep.\"", "\n", "return", "self", ".", "next_ys", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.Beam.get_current_origin": [[70, 73], ["None"], "methods", ["None"], ["", "def", "get_current_origin", "(", "self", ")", ":", "\n", "        ", "\"Get the backpointers for the current timestep.\"", "\n", "return", "self", ".", "prev_ks", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.Beam.advance": [[74, 151], ["word_probs.size", "len", "beam_scores.view", "beam_scores.view.topk", "beam.Beam.all_scores.append", "beam.Beam.prev_ks.append", "beam.Beam.next_ys.append", "beam.Beam.attn.append", "beam.Beam.global_scorer.update_global_state", "range", "beam.Beam.global_scorer.update_score", "range", "len", "range", "attn_out.index_select", "beam.Beam.next_ys[].size", "beam.Beam.all_scores.append", "len", "beam.Beam.scores.unsqueeze().expand_as", "beam.Beam.next_ys[].size", "len", "range", "beam.Beam.global_scorer.score", "beam.Beam.finished.append", "beam.Beam.next_ys[].size", "beam.Beam.get_hyp", "set", "range", "beam.Beam.scores.unsqueeze", "set.add", "set", "tuple", "tuple", "len", "hyp[].item"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.GNMTGlobalScorer.update_global_state", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.GNMTGlobalScorer.update_score", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.GNMTGlobalScorer.score", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.Beam.get_hyp"], ["", "def", "advance", "(", "self", ",", "word_probs", ",", "attn_out", ")", ":", "\n", "        ", "\"\"\"\n        Given prob over words for every last beam `wordLk` and attention\n        `attn_out`: Compute and update the beam search.\n\n        Parameters:\n\n        * `word_probs`- probs of advancing from the last step (K x words)\n        * `attn_out`- attention at the last step\n\n        Returns: True if beam search is complete.\n        \"\"\"", "\n", "num_words", "=", "word_probs", ".", "size", "(", "1", ")", "\n", "if", "self", ".", "stepwise_penalty", ":", "\n", "            ", "self", ".", "global_scorer", ".", "update_score", "(", "self", ",", "attn_out", ")", "\n", "# force the output to be longer than self.min_length", "\n", "", "cur_len", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "if", "cur_len", "<", "self", ".", "min_length", ":", "\n", "            ", "for", "k", "in", "range", "(", "len", "(", "word_probs", ")", ")", ":", "\n", "                ", "word_probs", "[", "k", "]", "[", "self", ".", "_eos", "]", "=", "-", "1e20", "\n", "# Sum the previous scores.", "\n", "", "", "if", "len", "(", "self", ".", "prev_ks", ")", ">", "0", ":", "\n", "            ", "beam_scores", "=", "word_probs", "+", "self", ".", "scores", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "word_probs", ")", "\n", "# Don't let EOS have children.", "\n", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                    ", "beam_scores", "[", "i", "]", "=", "-", "1e20", "\n", "\n", "# Block ngram repeats", "\n", "", "", "if", "self", ".", "block_ngram_repeat", ">", "0", ":", "\n", "                ", "ngrams", "=", "[", "]", "\n", "le", "=", "len", "(", "self", ".", "next_ys", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "hyp", ",", "_", "=", "self", ".", "get_hyp", "(", "le", "-", "1", ",", "j", ")", "\n", "ngrams", "=", "set", "(", ")", "\n", "fail", "=", "False", "\n", "gram", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "le", "-", "1", ")", ":", "\n", "# Last n tokens, n = block_ngram_repeat", "\n", "                        ", "gram", "=", "(", "gram", "+", "\n", "[", "hyp", "[", "i", "]", ".", "item", "(", ")", "]", ")", "[", "-", "self", ".", "block_ngram_repeat", ":", "]", "\n", "# Skip the blocking if it is in the exclusion list", "\n", "if", "set", "(", "gram", ")", "&", "self", ".", "exclusion_tokens", ":", "\n", "                            ", "continue", "\n", "", "if", "tuple", "(", "gram", ")", "in", "ngrams", ":", "\n", "                            ", "fail", "=", "True", "\n", "", "ngrams", ".", "add", "(", "tuple", "(", "gram", ")", ")", "\n", "", "if", "fail", ":", "\n", "                        ", "beam_scores", "[", "j", "]", "=", "-", "10e20", "\n", "", "", "", "", "else", ":", "\n", "            ", "beam_scores", "=", "word_probs", "[", "0", "]", "\n", "", "flat_beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "\n", "best_scores", ",", "best_scores_id", "=", "flat_beam_scores", ".", "topk", "(", "self", ".", "size", ",", "0", ",", "\n", "True", ",", "True", ")", "\n", "\n", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "scores", "=", "best_scores", "\n", "\n", "# best_scores_id is flattened beam x word array, so calculate which", "\n", "# word and beam each score came from", "\n", "prev_k", "=", "best_scores_id", "/", "num_words", "\n", "self", ".", "prev_ks", ".", "append", "(", "prev_k", ")", "\n", "self", ".", "next_ys", ".", "append", "(", "(", "best_scores_id", "-", "prev_k", "*", "num_words", ")", ")", "\n", "self", ".", "attn", ".", "append", "(", "attn_out", ".", "index_select", "(", "0", ",", "prev_k", ")", ")", "\n", "self", ".", "global_scorer", ".", "update_global_state", "(", "self", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "next_ys", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "i", "]", "==", "self", ".", "_eos", ":", "\n", "                ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "global_scores", "[", "i", "]", "\n", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "\n", "# End condition is when top-of-beam is EOS and no global score.", "\n", "", "", "if", "self", ".", "next_ys", "[", "-", "1", "]", "[", "0", "]", "==", "self", ".", "_eos", ":", "\n", "            ", "self", ".", "all_scores", ".", "append", "(", "self", ".", "scores", ")", "\n", "self", ".", "eos_top", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.Beam.done": [[152, 154], ["len"], "methods", ["None"], ["", "", "def", "done", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "eos_top", "and", "len", "(", "self", ".", "finished", ")", ">=", "self", ".", "n_best", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.Beam.sort_finished": [[155, 169], ["beam.Beam.finished.sort", "len", "beam.Beam.global_scorer.score", "beam.Beam.finished.append", "len"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.GNMTGlobalScorer.score"], ["", "def", "sort_finished", "(", "self", ",", "minimum", "=", "None", ")", ":", "\n", "        ", "if", "minimum", "is", "not", "None", ":", "\n", "            ", "i", "=", "0", "\n", "# Add from beam until we have minimum outputs.", "\n", "while", "len", "(", "self", ".", "finished", ")", "<", "minimum", ":", "\n", "                ", "global_scores", "=", "self", ".", "global_scorer", ".", "score", "(", "self", ",", "self", ".", "scores", ")", "\n", "s", "=", "global_scores", "[", "i", "]", "\n", "self", ".", "finished", ".", "append", "(", "(", "s", ",", "len", "(", "self", ".", "next_ys", ")", "-", "1", ",", "i", ")", ")", "\n", "i", "+=", "1", "\n", "\n", "", "", "self", ".", "finished", ".", "sort", "(", "key", "=", "lambda", "a", ":", "-", "a", "[", "0", "]", ")", "\n", "scores", "=", "[", "sc", "for", "sc", ",", "_", ",", "_", "in", "self", ".", "finished", "]", "\n", "ks", "=", "[", "(", "t", ",", "k", ")", "for", "_", ",", "t", ",", "k", "in", "self", ".", "finished", "]", "\n", "return", "scores", ",", "ks", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.Beam.get_hyp": [[170, 180], ["range", "hyp.append", "attn.append", "torch.stack", "len"], "methods", ["None"], ["", "def", "get_hyp", "(", "self", ",", "timestep", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        Walk back to construct the full hypothesis.\n        \"\"\"", "\n", "hyp", ",", "attn", "=", "[", "]", ",", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "self", ".", "prev_ks", "[", ":", "timestep", "]", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "hyp", ".", "append", "(", "self", ".", "next_ys", "[", "j", "+", "1", "]", "[", "k", "]", ")", "\n", "attn", ".", "append", "(", "self", ".", "attn", "[", "j", "]", "[", "k", "]", ")", "\n", "k", "=", "self", ".", "prev_ks", "[", "j", "]", "[", "k", "]", "\n", "", "return", "hyp", "[", ":", ":", "-", "1", "]", ",", "torch", ".", "stack", "(", "attn", "[", ":", ":", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.GNMTGlobalScorer.__init__": [[192, 201], ["onmt.translate.penalties.PenaltyBuilder", "onmt.translate.penalties.PenaltyBuilder.coverage_penalty", "onmt.translate.penalties.PenaltyBuilder.length_penalty"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.coverage_penalty", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.length_penalty"], ["def", "__init__", "(", "self", ",", "alpha", ",", "beta", ",", "cov_penalty", ",", "length_penalty", ")", ":", "\n", "        ", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "penalty_builder", "=", "penalties", ".", "PenaltyBuilder", "(", "cov_penalty", ",", "\n", "length_penalty", ")", "\n", "# Term will be subtracted from probability", "\n", "self", ".", "cov_penalty", "=", "penalty_builder", ".", "coverage_penalty", "(", ")", "\n", "# Probability will be divided by this", "\n", "self", ".", "length_penalty", "=", "penalty_builder", ".", "length_penalty", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.GNMTGlobalScorer.score": [[202, 216], ["beam.GNMTGlobalScorer.length_penalty", "beam.GNMTGlobalScorer.cov_penalty"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.length_penalty"], ["", "def", "score", "(", "self", ",", "beam", ",", "logprobs", ")", ":", "\n", "        ", "\"\"\"\n        Rescores a prediction based on penalty functions\n        \"\"\"", "\n", "normalized_probs", "=", "self", ".", "length_penalty", "(", "beam", ",", "\n", "logprobs", ",", "\n", "self", ".", "alpha", ")", "\n", "if", "not", "beam", ".", "stepwise_penalty", ":", "\n", "            ", "penalty", "=", "self", ".", "cov_penalty", "(", "beam", ",", "\n", "beam", ".", "global_state", "[", "\"coverage\"", "]", ",", "\n", "self", ".", "beta", ")", "\n", "normalized_probs", "-=", "penalty", "\n", "\n", "", "return", "normalized_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.GNMTGlobalScorer.update_score": [[217, 227], ["beam.global_state.keys", "beam.scores.add_", "beam.GNMTGlobalScorer.cov_penalty", "beam.scores.sub_"], "methods", ["None"], ["", "def", "update_score", "(", "self", ",", "beam", ",", "attn", ")", ":", "\n", "        ", "\"\"\"\n        Function to update scores of a Beam that is not finished\n        \"\"\"", "\n", "if", "\"prev_penalty\"", "in", "beam", ".", "global_state", ".", "keys", "(", ")", ":", "\n", "            ", "beam", ".", "scores", ".", "add_", "(", "beam", ".", "global_state", "[", "\"prev_penalty\"", "]", ")", "\n", "penalty", "=", "self", ".", "cov_penalty", "(", "beam", ",", "\n", "beam", ".", "global_state", "[", "\"coverage\"", "]", "+", "attn", ",", "\n", "self", ".", "beta", ")", "\n", "beam", ".", "scores", ".", "sub_", "(", "penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.beam.GNMTGlobalScorer.update_global_state": [[228, 244], ["len", "beam.scores.clone().fill_", "beam.attn[].sum", "torch.min().sum", "beam.global_state[].index_select().add", "beam.GNMTGlobalScorer.cov_penalty", "beam.scores.clone", "torch.min", "beam.global_state[].index_select"], "methods", ["None"], ["", "", "def", "update_global_state", "(", "self", ",", "beam", ")", ":", "\n", "        ", "\"Keeps the coverage vector as sum of attentions\"", "\n", "if", "len", "(", "beam", ".", "prev_ks", ")", "==", "1", ":", "\n", "            ", "beam", ".", "global_state", "[", "\"prev_penalty\"", "]", "=", "beam", ".", "scores", ".", "clone", "(", ")", ".", "fill_", "(", "0.0", ")", "\n", "beam", ".", "global_state", "[", "\"coverage\"", "]", "=", "beam", ".", "attn", "[", "-", "1", "]", "\n", "self", ".", "cov_total", "=", "beam", ".", "attn", "[", "-", "1", "]", ".", "sum", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "cov_total", "+=", "torch", ".", "min", "(", "beam", ".", "attn", "[", "-", "1", "]", ",", "\n", "beam", ".", "global_state", "[", "'coverage'", "]", ")", ".", "sum", "(", "1", ")", "\n", "beam", ".", "global_state", "[", "\"coverage\"", "]", "=", "beam", ".", "global_state", "[", "\"coverage\"", "]", ".", "index_select", "(", "0", ",", "beam", ".", "prev_ks", "[", "-", "1", "]", ")", ".", "add", "(", "beam", ".", "attn", "[", "-", "1", "]", ")", "\n", "\n", "prev_penalty", "=", "self", ".", "cov_penalty", "(", "beam", ",", "\n", "beam", ".", "global_state", "[", "\"coverage\"", "]", ",", "\n", "self", ".", "beta", ")", "\n", "beam", ".", "global_state", "[", "\"prev_penalty\"", "]", "=", "prev_penalty", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.__init__": [[14, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cov_pen", ",", "length_pen", ")", ":", "\n", "        ", "self", ".", "length_pen", "=", "length_pen", "\n", "self", ".", "cov_pen", "=", "cov_pen", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.coverage_penalty": [[18, 25], ["None"], "methods", ["None"], ["", "def", "coverage_penalty", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "cov_pen", "==", "\"wu\"", ":", "\n", "            ", "return", "self", ".", "coverage_wu", "\n", "", "elif", "self", ".", "cov_pen", "==", "\"summary\"", ":", "\n", "            ", "return", "self", ".", "coverage_summary", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "coverage_none", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.length_penalty": [[26, 33], ["None"], "methods", ["None"], ["", "", "def", "length_penalty", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "length_pen", "==", "\"wu\"", ":", "\n", "            ", "return", "self", ".", "length_wu", "\n", "", "elif", "self", ".", "length_pen", "==", "\"avg\"", ":", "\n", "            ", "return", "self", ".", "length_average", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "length_none", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.coverage_wu": [[38, 45], ["torch.min().log().sum", "torch.min().log", "torch.min", "cov.clone().fill_", "cov.clone"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation.Translation.log"], ["def", "coverage_wu", "(", "self", ",", "beam", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        NMT coverage re-ranking score from\n        \"Google's Neural Machine Translation System\" :cite:`wu2016google`.\n        \"\"\"", "\n", "penalty", "=", "-", "torch", ".", "min", "(", "cov", ",", "cov", ".", "clone", "(", ")", ".", "fill_", "(", "1.0", ")", ")", ".", "log", "(", ")", ".", "sum", "(", "1", ")", "\n", "return", "beta", "*", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.coverage_summary": [[46, 53], ["torch.max().sum", "cov.size", "torch.max", "cov.clone().fill_", "cov.clone"], "methods", ["None"], ["", "def", "coverage_summary", "(", "self", ",", "beam", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        Our summary penalty.\n        \"\"\"", "\n", "penalty", "=", "torch", ".", "max", "(", "cov", ",", "cov", ".", "clone", "(", ")", ".", "fill_", "(", "1.0", ")", ")", ".", "sum", "(", "1", ")", "\n", "penalty", "-=", "cov", ".", "size", "(", "1", ")", "\n", "return", "beta", "*", "penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.coverage_none": [[54, 59], ["beam.scores.clone().fill_", "beam.scores.clone"], "methods", ["None"], ["", "def", "coverage_none", "(", "self", ",", "beam", ",", "cov", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        returns zero as penalty\n        \"\"\"", "\n", "return", "beam", ".", "scores", ".", "clone", "(", ")", ".", "fill_", "(", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.length_wu": [[60, 69], ["len"], "methods", ["None"], ["", "def", "length_wu", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        NMT length re-ranking score from\n        \"Google's Neural Machine Translation System\" :cite:`wu2016google`.\n        \"\"\"", "\n", "\n", "modifier", "=", "(", "(", "(", "5", "+", "len", "(", "beam", ".", "next_ys", ")", ")", "**", "alpha", ")", "/", "\n", "(", "(", "5", "+", "1", ")", "**", "alpha", ")", ")", "\n", "return", "(", "logprobs", "/", "modifier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.length_average": [[70, 75], ["len"], "methods", ["None"], ["", "def", "length_average", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        Returns the average probability of tokens in a sequence.\n        \"\"\"", "\n", "return", "logprobs", "/", "len", "(", "beam", ".", "next_ys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.penalties.PenaltyBuilder.length_none": [[76, 81], ["None"], "methods", ["None"], ["", "def", "length_none", "(", "self", ",", "beam", ",", "logprobs", ",", "alpha", "=", "0.", ",", "beta", "=", "0.", ")", ":", "\n", "        ", "\"\"\"\n        Returns unmodified scores.\n        \"\"\"", "\n", "return", "logprobs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.stacked_rnn.StackedLSTM.__init__": [[12, 21], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "stacked_rnn.StackedLSTM.layers.append", "torch.LSTMCell", "torch.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "LSTMCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.stacked_rnn.StackedLSTM.forward": [[22, 37], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "stacked_rnn.StackedLSTM.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_feed", ",", "hidden", ")", ":", "\n", "        ", "h_0", ",", "c_0", "=", "hidden", "\n", "h_1", ",", "c_1", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", ",", "c_1_i", "=", "layer", "(", "input_feed", ",", "(", "h_0", "[", "i", "]", ",", "c_0", "[", "i", "]", ")", ")", "\n", "input_feed", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input_feed", "=", "self", ".", "dropout", "(", "input_feed", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "c_1", "+=", "[", "c_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "c_1", "=", "torch", ".", "stack", "(", "c_1", ")", "\n", "\n", "return", "input_feed", ",", "(", "h_1", ",", "c_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.stacked_rnn.StackedGRU.__init__": [[45, 54], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "range", "stacked_rnn.StackedGRU.layers.append", "torch.GRUCell", "torch.GRUCell"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "GRUCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.stacked_rnn.StackedGRU.forward": [[55, 66], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "stacked_rnn.StackedGRU.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_feed", ",", "hidden", ")", ":", "\n", "        ", "h_1", "=", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", "=", "layer", "(", "input_feed", ",", "hidden", "[", "0", "]", "[", "i", "]", ")", "\n", "input_feed", "=", "h_1_i", "\n", "if", "i", "+", "1", "!=", "self", ".", "num_layers", ":", "\n", "                ", "input_feed", "=", "self", ".", "dropout", "(", "input_feed", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "return", "input_feed", ",", "(", "h_1", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model.NMTModel.__init__": [[16, 21], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["\n", "def", "__init__", "(", "self", ",", "encoder", ",", "rk_encoder", ",", "decoder", ",", "multigpu", "=", "False", ",", "rk_to_src_attn", "=", "False", ")", ":", "\n", "        ", "self", ".", "multigpu", "=", "multigpu", "\n", "super", "(", "NMTModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "rk_encoder", "=", "rk_encoder", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model.NMTModel.forward": [[22, 58], ["model.NMTModel.encoder", "model.NMTModel.decoder.init_decoder_state", "model.NMTModel.decoder"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoder.init_decoder_state"], ["self", ".", "decoder", "=", "decoder", "\n", "\n", "self", ".", "rk_to_src_attn", "=", "rk_to_src_attn", "\n", "\n", "", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "src_lengths", ",", "dec_state", "=", "None", ",", "retrieved_keys", "=", "None", ",", "rk_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"Forward propagate a `src` and `tgt` pair for training.\n        Possible initialized with a beginning decoder state.\n\n        Args:\n            src (:obj:`Tensor`):\n                a source sequence passed to encoder.\n                typically for inputs this will be a padded :obj:`LongTensor`\n                of size `[len x batch x features]`. however, may be an\n                image or other generic input depending on encoder.\n            tgt (:obj:`LongTensor`):\n                 a target sequence of size `[tgt_len x batch]`.\n            lengths(:obj:`LongTensor`): the src lengths, pre-padding `[batch]`.\n            dec_state (:obj:`DecoderState`, optional): initial decoder state\n        Returns:\n            (:obj:`FloatTensor`, `dict`, :obj:`onmt.Models.DecoderState`):\n\n                 * decoder output `[tgt_len x batch x hidden]`\n                 * dictionary attention dists of `[tgt_len x batch x src_len]`\n                 * final decoder state\n        \"\"\"", "\n", "tgt", "=", "tgt", "[", ":", "-", "1", "]", "# exclude last target from inputs", "\n", "\n", "enc_final", ",", "memory_bank", "=", "self", ".", "encoder", "(", "src", ",", "src_lengths", ")", "\n", "enc_state", "=", "self", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "memory_bank", ",", "enc_final", ")", "\n", "\n", "rk_memory_bank", "=", "None", "\n", "rk_final_state", "=", "None", "\n", "if", "self", ".", "rk_encoder", "is", "not", "None", ":", "\n", "            ", "rk_final_state", ",", "rk_memory_bank", "=", "self", ".", "rk_encoder", "(", "retrieved_keys", ",", "rk_lengths", ")", "\n", "if", "self", ".", "rk_to_src_attn", ":", "\n", "                ", "rk_final_state", "=", "torch", ".", "cat", "(", "[", "rk_final_state", "[", "0", "]", ",", "rk_final_state", "[", "1", "]", "]", ",", "dim", "=", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model.SelectorModel.__init__": [[86, 90], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "selector", ",", "multigpu", "=", "False", ")", ":", "\n", "        ", "self", ".", "multigpu", "=", "multigpu", "\n", "super", "(", "SelectorModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "selector", "=", "selector", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model.SelectorModel.forward": [[91, 106], ["model.SelectorModel.selector"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", ")", ":", "\n", "        ", "\"\"\"Forward propagate a `src`\n        Args:\n            src (:obj:`LongTensor`):\n                a source sequence passed to encoder.\n                typically for inputs this will be a padded :obj:`LongTensor`\n                of size `[len x batch x features]`.\n            lengths(:obj:`LongTensor`): the src lengths, pre-padding `[batch]`.\n        Returns:\n            (:obj:`FloatTensor`, :obj:`FloatTensor`):\n                 * logits output of the selector `[src_len, batch]`\n                 * importance scores output of the selector `[src_len, batch]`\n        \"\"\"", "\n", "logits", ",", "probs", ",", "_", ",", "_", "=", "self", ".", "selector", "(", "src", ",", "lengths", ")", "\n", "return", "logits", ",", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model.E2EModel.__init__": [[120, 136], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "rk_encoder", ",", "selector", ",", "decoder", ",", "multigpu", "=", "False", ",", "e2e_type", "=", "\"separate_enc_sel\"", ",", "\n", "use_gt_sel_probs", "=", "False", ",", "rk_to_src_attn", "=", "False", ")", ":", "\n", "        ", "assert", "e2e_type", "in", "[", "\"separate_enc_sel\"", ",", "\"share_enc_sel\"", "]", "\n", "\n", "self", ".", "multigpu", "=", "multigpu", "\n", "super", "(", "E2EModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "e2e_type", "=", "e2e_type", "\n", "if", "e2e_type", "==", "\"separate_enc_sel\"", ":", "\n", "            ", "self", ".", "encoder", "=", "encoder", "\n", "", "self", ".", "selector", "=", "selector", "\n", "self", ".", "rk_encoder", "=", "rk_encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n", "self", ".", "use_gt_sel_probs", "=", "use_gt_sel_probs", "\n", "self", ".", "rk_to_src_attn", "=", "rk_to_src_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model.E2EModel.forward": [[137, 201], ["model.E2EModel.decoder.init_decoder_state", "model.E2EModel.decoder", "model.E2EModel.selector", "model.E2EModel.encoder", "model.E2EModel.selector", "model.E2EModel.rk_encoder", "gt_probs.float.float.float", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rk_final_state.squeeze.squeeze.squeeze"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.decoders.transformer.TransformerDecoder.init_decoder_state"], ["", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "lengths", ",", "dec_state", "=", "None", ",", "gt_probs", "=", "None", ",", "retrieved_keys", "=", "None", ",", "rk_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"Forward propagate a `src` and `tgt` pair for training.\n        Possible initialized with a beginning decoder state.\n\n        Args:\n            src (:obj:`Tensor`):\n                a source sequence passed to encoder.\n                typically for inputs this will be a padded :obj:`LongTensor`\n                of size `[src_len x batch x features]`. however, may be an\n                image or other generic input depending on encoder.\n            tgt (:obj:`LongTensor`):\n                 a target sequence of size `[tgt_len x batch]`.\n            lengths(:obj:`LongTensor`): the src lengths, pre-padding `[batch]`.\n            dec_state (:obj:`DecoderState`, optional): initial decoder state.\n            gt_probs (:obj:`LongTensor`): the ground-truth importance scores, `[src_len x batch]`\n            retrieved_keys (:obj:`LongTensor`): the retrieved keyphrases, `[rk_len x batch]`\n            rk_lengths (:obj:`LongTensor`): the retrieved keyphrase lengths, `[rk_len x batch]`\n        Returns:\n            (:obj:`FloatTensor`, `dict`, :obj:`onmt.Models.DecoderState`, :obj:`FloatTensor`, :obj:`FloatTensor`):\n                 * decoder output `[tgt_len x batch x hidden]`\n                 * dictionary attention dists of `[tgt_len x batch x src_len]`\n                 * final decoder state\n                 * logits output of the selector `[src_len, batch]`\n                 * importance scores output of the selector `[src_len, batch]`\n        \"\"\"", "\n", "tgt", "=", "tgt", "[", ":", "-", "1", "]", "# exclude last target from inputs", "\n", "\n", "if", "self", ".", "e2e_type", "==", "'separate_enc_sel'", ":", "\n", "            ", "logits", ",", "probs", ",", "_", ",", "_", ",", "=", "self", ".", "selector", "(", "src", ",", "lengths", ")", "\n", "enc_final", ",", "memory_bank", ",", "=", "self", ".", "encoder", "(", "src", ",", "lengths", ")", "\n", "", "else", ":", "\n", "            ", "logits", ",", "probs", ",", "enc_final", ",", "memory_bank", "=", "self", ".", "selector", "(", "src", ",", "lengths", ")", "\n", "\n", "", "rk_memory_bank", "=", "None", "\n", "rk_final_state", "=", "None", "\n", "if", "self", ".", "rk_encoder", "is", "not", "None", ":", "\n", "            ", "rk_final_state", ",", "rk_memory_bank", "=", "self", ".", "rk_encoder", "(", "retrieved_keys", ",", "rk_lengths", ")", "\n", "if", "self", ".", "rk_to_src_attn", ":", "\n", "                ", "rk_final_state", "=", "torch", ".", "cat", "(", "[", "rk_final_state", "[", "0", "]", ",", "rk_final_state", "[", "1", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "rk_final_state", "=", "rk_final_state", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "                ", "rk_final_state", "=", "None", "\n", "\n", "# use the gound-truth binary importance score of each source text token", "\n", "", "", "if", "gt_probs", "is", "not", "None", "and", "self", ".", "use_gt_sel_probs", ":", "\n", "            ", "gt_probs", "=", "(", "gt_probs", "==", "2", ")", "\n", "gt_probs", "=", "gt_probs", ".", "float", "(", ")", "\n", "probs", "=", "gt_probs", "\n", "\n", "", "enc_state", "=", "self", ".", "decoder", ".", "init_decoder_state", "(", "src", ",", "memory_bank", ",", "enc_final", ")", "\n", "decoder_outputs", ",", "dec_state", ",", "attns", "=", "self", ".", "decoder", "(", "tgt", ",", "memory_bank", ",", "rk_memory_bank", ",", "\n", "enc_state", "if", "dec_state", "is", "None", "\n", "else", "dec_state", ",", "\n", "memory_lengths", "=", "lengths", ",", "\n", "rk_memory_lengths", "=", "rk_lengths", ",", "\n", "probs", "=", "probs", ",", "\n", "rk_final_state", "=", "rk_final_state", ")", "\n", "if", "self", ".", "multigpu", ":", "\n", "# Not yet supported on multi-gpu", "\n", "            ", "dec_state", "=", "None", "\n", "attns", "=", "None", "\n", "", "return", "decoder_outputs", ",", "attns", ",", "dec_state", ",", "logits", ",", "probs", "", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.CheckSRU.__init__": [[17, 19], ["argparse.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "option_strings", ",", "dest", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CheckSRU", ",", "self", ")", ".", "__init__", "(", "option_strings", ",", "dest", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.CheckSRU.__call__": [[20, 25], ["setattr", "sru.check_sru_requirement"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.check_sru_requirement"], ["", "def", "__call__", "(", "self", ",", "parser", ",", "namespace", ",", "values", ",", "option_string", "=", "None", ")", ":", "\n", "        ", "if", "values", "==", "'SRU'", ":", "\n", "            ", "check_sru_requirement", "(", "abort", "=", "True", ")", "\n", "# Check pass, set the args.", "\n", "", "setattr", "(", "namespace", ",", "self", ".", "dest", ",", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU_Compute.__init__": [[381, 387], ["SRU_Compute.maybe_load_sru_mod", "torch.autograd.Function.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU_Compute.maybe_load_sru_mod", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "activation_type", ",", "d_out", ",", "bidirectional", "=", "False", ")", ":", "\n", "        ", "SRU_Compute", ".", "maybe_load_sru_mod", "(", ")", "\n", "super", "(", "SRU_Compute", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "activation_type", "=", "activation_type", "\n", "self", ".", "d_out", "=", "d_out", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU_Compute.maybe_load_sru_mod": [[388, 394], ["sru.load_sru_mod"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.load_sru_mod"], ["", "@", "staticmethod", "\n", "def", "maybe_load_sru_mod", "(", ")", ":", "\n", "        ", "global", "SRU_FWD_FUNC", "\n", "\n", "if", "SRU_FWD_FUNC", "is", "None", ":", "\n", "            ", "load_sru_mod", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU_Compute.forward": [[395, 439], ["x.size", "min", "x.new", "x.new", "FUNC", "sru.SRU_Compute.save_for_backward", "x.size", "u.size", "x.new().zero_", "x.dim", "x.dim", "x.dim", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.new", "u.contiguous().data_ptr", "bias.data_ptr", "init_.contiguous().data_ptr", "x.new.data_ptr", "x.new.data_ptr", "x.contiguous().data_ptr", "mask_h.data_ptr", "u.contiguous", "init_.contiguous", "x.contiguous"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "u", ",", "x", ",", "bias", ",", "init", "=", "None", ",", "mask_h", "=", "None", ")", ":", "\n", "        ", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "length", "=", "x", ".", "size", "(", "0", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "1", "\n", "batch", "=", "x", ".", "size", "(", "-", "2", ")", "\n", "d", "=", "self", ".", "d_out", "\n", "k", "=", "u", ".", "size", "(", "-", "1", ")", "//", "d", "\n", "k_", "=", "k", "//", "2", "if", "self", ".", "bidirectional", "else", "k", "\n", "ncols", "=", "batch", "*", "d", "*", "bidir", "\n", "thread_per_block", "=", "min", "(", "512", ",", "ncols", ")", "\n", "num_block", "=", "(", "ncols", "-", "1", ")", "//", "thread_per_block", "+", "1", "\n", "\n", "init_", "=", "x", ".", "new", "(", "ncols", ")", ".", "zero_", "(", ")", "if", "init", "is", "None", "else", "init", "\n", "size", "=", "(", "length", ",", "batch", ",", "d", "*", "bidir", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "(", "batch", ",", "d", "*", "bidir", ")", "\n", "c", "=", "x", ".", "new", "(", "*", "size", ")", "\n", "h", "=", "x", ".", "new", "(", "*", "size", ")", "\n", "\n", "FUNC", "=", "SRU_FWD_FUNC", "if", "not", "self", ".", "bidirectional", "else", "SRU_BiFWD_FUNC", "\n", "FUNC", "(", "args", "=", "[", "\n", "u", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "x", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "bias", ".", "data_ptr", "(", ")", ",", "\n", "init_", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "mask_h", ".", "data_ptr", "(", ")", "if", "mask_h", "is", "not", "None", "else", "0", ",", "\n", "length", ",", "\n", "batch", ",", "\n", "d", ",", "\n", "k_", ",", "\n", "h", ".", "data_ptr", "(", ")", ",", "\n", "c", ".", "data_ptr", "(", ")", ",", "\n", "self", ".", "activation_type", "]", ",", "\n", "block", "=", "(", "thread_per_block", ",", "1", ",", "1", ")", ",", "grid", "=", "(", "num_block", ",", "1", ",", "1", ")", ",", "\n", "stream", "=", "SRU_STREAM", "\n", ")", "\n", "\n", "self", ".", "save_for_backward", "(", "u", ",", "x", ",", "bias", ",", "init", ",", "mask_h", ")", "\n", "self", ".", "intermediate", "=", "c", "\n", "if", "x", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "last_hidden", "=", "c", "\n", "", "elif", "self", ".", "bidirectional", ":", "\n", "# -> directions x batch x dim", "\n", "            ", "last_hidden", "=", "torch", ".", "stack", "(", "(", "c", "[", "-", "1", ",", ":", ",", ":", "d", "]", ",", "c", "[", "0", ",", ":", ",", "d", ":", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "last_hidden", "=", "c", "[", "-", "1", "]", "\n", "", "return", "h", ",", "last_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU_Compute.backward": [[440, 491], ["x.size", "min", "u.new", "x.new", "x.new", "FUNC", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.size", "u.size", "x.new().zero_", "x.new", "x.new.sum().view", "x.dim", "u.size", "x.new", "x.size", "u.contiguous().data_ptr", "bias.data_ptr", "init_.contiguous().data_ptr", "c.data_ptr", "grad_h.contiguous().data_ptr", "torch.cat.contiguous().data_ptr", "torch.cat.contiguous().data_ptr", "u.new.data_ptr", "x.new.data_ptr", "x.new.data_ptr", "x.new.sum", "x.contiguous().data_ptr", "mask_h.data_ptr", "grad_x.data_ptr", "u.contiguous", "init_.contiguous", "grad_h.contiguous", "torch.cat.contiguous", "torch.cat.contiguous", "x.contiguous"], "methods", ["None"], ["", "def", "backward", "(", "self", ",", "grad_h", ",", "grad_last", ")", ":", "\n", "        ", "if", "self", ".", "bidirectional", ":", "\n", "            ", "grad_last", "=", "torch", ".", "cat", "(", "(", "grad_last", "[", "0", "]", ",", "grad_last", "[", "1", "]", ")", ",", "1", ")", "\n", "", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "u", ",", "x", ",", "bias", ",", "init", ",", "mask_h", "=", "self", ".", "saved_tensors", "\n", "c", "=", "self", ".", "intermediate", "\n", "length", "=", "x", ".", "size", "(", "0", ")", "if", "x", ".", "dim", "(", ")", "==", "3", "else", "1", "\n", "batch", "=", "x", ".", "size", "(", "-", "2", ")", "\n", "d", "=", "self", ".", "d_out", "\n", "k", "=", "u", ".", "size", "(", "-", "1", ")", "//", "d", "\n", "k_", "=", "k", "//", "2", "if", "self", ".", "bidirectional", "else", "k", "\n", "ncols", "=", "batch", "*", "d", "*", "bidir", "\n", "thread_per_block", "=", "min", "(", "512", ",", "ncols", ")", "\n", "num_block", "=", "(", "ncols", "-", "1", ")", "//", "thread_per_block", "+", "1", "\n", "\n", "init_", "=", "x", ".", "new", "(", "ncols", ")", ".", "zero_", "(", ")", "if", "init", "is", "None", "else", "init", "\n", "grad_u", "=", "u", ".", "new", "(", "*", "u", ".", "size", "(", ")", ")", "\n", "grad_bias", "=", "x", ".", "new", "(", "2", ",", "batch", ",", "d", "*", "bidir", ")", "\n", "grad_init", "=", "x", ".", "new", "(", "batch", ",", "d", "*", "bidir", ")", "\n", "\n", "# For DEBUG", "\n", "# size = (length, batch, x.size(-1)) \\", "\n", "#         if x.dim() == 3 else (batch, x.size(-1))", "\n", "# grad_x = x.new(*x.size()) if k_ == 3 else x.new(*size).zero_()", "\n", "\n", "# Normal use", "\n", "grad_x", "=", "x", ".", "new", "(", "*", "x", ".", "size", "(", ")", ")", "if", "k_", "==", "3", "else", "None", "\n", "\n", "FUNC", "=", "SRU_BWD_FUNC", "if", "not", "self", ".", "bidirectional", "else", "SRU_BiBWD_FUNC", "\n", "FUNC", "(", "args", "=", "[", "\n", "u", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "x", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "bias", ".", "data_ptr", "(", ")", ",", "\n", "init_", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "mask_h", ".", "data_ptr", "(", ")", "if", "mask_h", "is", "not", "None", "else", "0", ",", "\n", "c", ".", "data_ptr", "(", ")", ",", "\n", "grad_h", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "grad_last", ".", "contiguous", "(", ")", ".", "data_ptr", "(", ")", ",", "\n", "length", ",", "\n", "batch", ",", "\n", "d", ",", "\n", "k_", ",", "\n", "grad_u", ".", "data_ptr", "(", ")", ",", "\n", "grad_x", ".", "data_ptr", "(", ")", "if", "k_", "==", "3", "else", "0", ",", "\n", "grad_bias", ".", "data_ptr", "(", ")", ",", "\n", "grad_init", ".", "data_ptr", "(", ")", ",", "\n", "self", ".", "activation_type", "]", ",", "\n", "block", "=", "(", "thread_per_block", ",", "1", ",", "1", ")", ",", "grid", "=", "(", "num_block", ",", "1", ",", "1", ")", ",", "\n", "stream", "=", "SRU_STREAM", "\n", ")", "\n", "return", "grad_u", ",", "grad_x", ",", "grad_bias", ".", "sum", "(", "1", ")", ".", "view", "(", "-", "1", ")", ",", "grad_init", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRUCell.__init__": [[494, 515], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "sru.SRUCell.init_weight", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRUCell.init_weight"], ["    ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "dropout", "=", "0", ",", "rnn_dropout", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "use_tanh", "=", "1", ",", "use_relu", "=", "0", ")", ":", "\n", "        ", "super", "(", "SRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in", "=", "n_in", "\n", "self", ".", "n_out", "=", "n_out", "\n", "self", ".", "rnn_dropout", "=", "rnn_dropout", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "activation_type", "=", "2", "if", "use_relu", "else", "(", "1", "if", "use_tanh", "else", "0", ")", "\n", "\n", "out_size", "=", "n_out", "*", "2", "if", "bidirectional", "else", "n_out", "\n", "k", "=", "4", "if", "n_in", "!=", "out_size", "else", "3", "\n", "self", ".", "size_per_dir", "=", "n_out", "*", "k", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "n_in", ",", "\n", "self", ".", "size_per_dir", "*", "2", "if", "bidirectional", "else", "self", ".", "size_per_dir", "\n", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "n_out", "*", "4", "if", "bidirectional", "else", "n_out", "*", "2", "\n", ")", ")", "\n", "self", ".", "init_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRUCell.init_weight": [[516, 520], ["sru.SRUCell.weight.data.uniform_", "sru.SRUCell.bias.data.zero_"], "methods", ["None"], ["", "def", "init_weight", "(", "self", ")", ":", "\n", "        ", "val_range", "=", "(", "3.0", "/", "self", ".", "n_in", ")", "**", "0.5", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "val_range", ",", "val_range", ")", "\n", "self", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRUCell.set_bias": [[521, 527], ["sru.SRUCell.bias.data[].zero_().add_", "sru.SRUCell.bias.data[].zero_().add_", "sru.SRUCell.bias.data[].zero_", "sru.SRUCell.bias.data[].zero_"], "methods", ["None"], ["", "def", "set_bias", "(", "self", ",", "bias_val", "=", "0", ")", ":", "\n", "        ", "n_out", "=", "self", ".", "n_out", "\n", "if", "self", ".", "bidirectional", ":", "\n", "            ", "self", ".", "bias", ".", "data", "[", "n_out", "*", "2", ":", "]", ".", "zero_", "(", ")", ".", "add_", "(", "bias_val", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", ".", "data", "[", "n_out", ":", "]", ".", "zero_", "(", ")", ".", "add_", "(", "bias_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRUCell.forward": [[528, 561], ["input.size", "x_2d.mm", "input.data.new().zero_", "sru.SRUCell.get_dropout_mask_", "x.contiguous().view", "sru.SRUCell.get_dropout_mask_", "input.dim", "input.dim", "sru.SRUCell.expand_as", "x.dim", "sru.SRU_Compute", "sru.SRU_Compute", "input.data.new", "x.contiguous"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRUCell.get_dropout_mask_", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRUCell.get_dropout_mask_"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "c0", "=", "None", ")", ":", "\n", "        ", "assert", "input", ".", "dim", "(", ")", "==", "2", "or", "input", ".", "dim", "(", ")", "==", "3", "\n", "n_in", ",", "n_out", "=", "self", ".", "n_in", ",", "self", ".", "n_out", "\n", "batch", "=", "input", ".", "size", "(", "-", "2", ")", "\n", "if", "c0", "is", "None", ":", "\n", "            ", "c0", "=", "input", ".", "data", ".", "new", "(", "\n", "batch", ",", "n_out", "if", "not", "self", ".", "bidirectional", "else", "n_out", "*", "2", "\n", ")", ".", "zero_", "(", ")", "\n", "\n", "", "if", "self", ".", "training", "and", "(", "self", ".", "rnn_dropout", ">", "0", ")", ":", "\n", "            ", "mask", "=", "self", ".", "get_dropout_mask_", "(", "(", "batch", ",", "n_in", ")", ",", "self", ".", "rnn_dropout", ")", "\n", "x", "=", "input", "*", "mask", ".", "expand_as", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "input", "\n", "\n", "", "x_2d", "=", "x", "if", "x", ".", "dim", "(", ")", "==", "2", "else", "x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "n_in", ")", "\n", "u", "=", "x_2d", ".", "mm", "(", "self", ".", "weight", ")", "\n", "\n", "if", "self", ".", "training", "and", "(", "self", ".", "dropout", ">", "0", ")", ":", "\n", "            ", "bidir", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "mask_h", "=", "self", ".", "get_dropout_mask_", "(", "\n", "(", "batch", ",", "n_out", "*", "bidir", ")", ",", "self", ".", "dropout", ")", "\n", "h", ",", "c", "=", "SRU_Compute", "(", "self", ".", "activation_type", ",", "n_out", ",", "\n", "self", ".", "bidirectional", ")", "(", "\n", "u", ",", "input", ",", "self", ".", "bias", ",", "c0", ",", "mask_h", "\n", ")", "\n", "", "else", ":", "\n", "            ", "h", ",", "c", "=", "SRU_Compute", "(", "self", ".", "activation_type", ",", "n_out", ",", "\n", "self", ".", "bidirectional", ")", "(", "\n", "u", ",", "input", ",", "self", ".", "bias", ",", "c0", "\n", ")", "\n", "\n", "", "return", "h", ",", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRUCell.get_dropout_mask_": [[562, 565], ["w.new().bernoulli_().div_", "w.new().bernoulli_", "w.new"], "methods", ["None"], ["", "def", "get_dropout_mask_", "(", "self", ",", "size", ",", "p", ")", ":", "\n", "        ", "w", "=", "self", ".", "weight", ".", "data", "\n", "return", "w", ".", "new", "(", "*", "size", ")", ".", "bernoulli_", "(", "1", "-", "p", ")", ".", "div_", "(", "1", "-", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU.__init__": [[589, 616], ["sru.check_sru_requirement", "torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "range", "sru.SRUCell", "sru.SRU.rnn_lst.append"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.check_sru_requirement", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "\n", "num_layers", "=", "2", ",", "dropout", "=", "0", ",", "rnn_dropout", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "use_tanh", "=", "1", ",", "use_relu", "=", "0", ")", ":", "\n", "# An entry check here, will catch on train side and translate side", "\n", "# if requirements are not satisfied.", "\n", "        ", "check_sru_requirement", "(", "abort", "=", "True", ")", "\n", "super", "(", "SRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in", "=", "input_size", "\n", "self", ".", "n_out", "=", "hidden_size", "\n", "self", ".", "depth", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "rnn_dropout", "=", "rnn_dropout", "\n", "self", ".", "rnn_lst", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "out_size", "=", "hidden_size", "*", "2", "if", "bidirectional", "else", "hidden_size", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "sru_cell", "=", "SRUCell", "(", "\n", "n_in", "=", "self", ".", "n_in", "if", "i", "==", "0", "else", "self", ".", "out_size", ",", "\n", "n_out", "=", "self", ".", "n_out", ",", "\n", "dropout", "=", "dropout", "if", "i", "+", "1", "!=", "num_layers", "else", "0", ",", "\n", "rnn_dropout", "=", "rnn_dropout", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "use_tanh", "=", "use_tanh", ",", "\n", "use_relu", "=", "use_relu", ",", "\n", ")", "\n", "self", ".", "rnn_lst", ".", "append", "(", "sru_cell", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU.set_bias": [[617, 620], ["l.set_bias"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU.set_bias"], ["", "", "def", "set_bias", "(", "self", ",", "bias_val", "=", "0", ")", ":", "\n", "        ", "for", "l", "in", "self", ".", "rnn_lst", ":", "\n", "            ", "l", ".", "set_bias", "(", "bias_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.SRU.forward": [[621, 653], ["enumerate", "input.dim", "input.data.new().zero_", "isinstance", "rnn", "lstc.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "c0.dim", "h.squeeze", "input.data.new", "range", "c0.chunk", "input.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "c0", "=", "None", ",", "return_hidden", "=", "True", ")", ":", "\n", "        ", "assert", "input", ".", "dim", "(", ")", "==", "3", "# (len, batch, n_in)", "\n", "dir_", "=", "2", "if", "self", ".", "bidirectional", "else", "1", "\n", "if", "c0", "is", "None", ":", "\n", "            ", "zeros", "=", "input", ".", "data", ".", "new", "(", "\n", "input", ".", "size", "(", "1", ")", ",", "self", ".", "n_out", "*", "dir_", "\n", ")", ".", "zero_", "(", ")", "\n", "c0", "=", "[", "zeros", "for", "i", "in", "range", "(", "self", ".", "depth", ")", "]", "\n", "", "else", ":", "\n", "            ", "if", "isinstance", "(", "c0", ",", "tuple", ")", ":", "\n", "# RNNDecoderState wraps hidden as a tuple.", "\n", "                ", "c0", "=", "c0", "[", "0", "]", "\n", "", "assert", "c0", ".", "dim", "(", ")", "==", "3", "# (depth, batch, dir_*n_out)", "\n", "c0", "=", "[", "h", ".", "squeeze", "(", "0", ")", "for", "h", "in", "c0", ".", "chunk", "(", "self", ".", "depth", ",", "0", ")", "]", "\n", "\n", "", "prevx", "=", "input", "\n", "lstc", "=", "[", "]", "\n", "for", "i", ",", "rnn", "in", "enumerate", "(", "self", ".", "rnn_lst", ")", ":", "\n", "            ", "h", ",", "c", "=", "rnn", "(", "prevx", ",", "c0", "[", "i", "]", ")", "\n", "prevx", "=", "h", "\n", "lstc", ".", "append", "(", "c", ")", "\n", "\n", "", "if", "self", ".", "bidirectional", ":", "\n", "# fh -> (layers*directions) x batch x dim", "\n", "            ", "fh", "=", "torch", ".", "cat", "(", "lstc", ")", "\n", "", "else", ":", "\n", "            ", "fh", "=", "torch", ".", "stack", "(", "lstc", ")", "\n", "\n", "", "if", "return_hidden", ":", "\n", "            ", "return", "prevx", ",", "fh", "\n", "", "else", ":", "\n", "            ", "return", "prevx", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.check_sru_requirement": [[32, 70], ["re.compile", "os.getenv", "torch.cuda.is_available", "torch.cuda.is_available", "AssertionError", "re.match", "AssertionError", "platform.system", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "subprocess.check_output", "AssertionError"], "function", ["None"], ["", "", "def", "check_sru_requirement", "(", "abort", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Return True if check pass; if check fails and abort is True,\n    raise an Exception, othereise return False.\n    \"\"\"", "\n", "\n", "# Check 1.", "\n", "try", ":", "\n", "        ", "if", "platform", ".", "system", "(", ")", "==", "'Windows'", ":", "\n", "            ", "subprocess", ".", "check_output", "(", "'pip freeze | findstr cupy'", ",", "shell", "=", "True", ")", "\n", "subprocess", ".", "check_output", "(", "'pip freeze | findstr pynvrtc'", ",", "\n", "shell", "=", "True", ")", "\n", "", "else", ":", "# Unix-like systems", "\n", "            ", "subprocess", ".", "check_output", "(", "'pip freeze | grep -w cupy'", ",", "shell", "=", "True", ")", "\n", "subprocess", ".", "check_output", "(", "'pip freeze | grep -w pynvrtc'", ",", "\n", "shell", "=", "True", ")", "\n", "", "", "except", "subprocess", ".", "CalledProcessError", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires 'cupy' and 'pynvrtc' \"", "\n", "\"python packages installed.\"", ")", "\n", "\n", "# Check 2.", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "is", "False", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires pytorch built with cuda.\"", ")", "\n", "\n", "# Check 3.", "\n", "", "pattern", "=", "re", ".", "compile", "(", "\".*cuda/lib.*\"", ")", "\n", "ld_path", "=", "os", ".", "getenv", "(", "'LD_LIBRARY_PATH'", ",", "\"\"", ")", "\n", "if", "re", ".", "match", "(", "pattern", ",", "ld_path", ")", "is", "None", ":", "\n", "        ", "if", "not", "abort", ":", "\n", "            ", "return", "False", "\n", "", "raise", "AssertionError", "(", "\"Using SRU requires setting cuda lib path, e.g. \"", "\n", "\"export LD_LIBRARY_PATH=/usr/local/cuda/lib64.\"", ")", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.load_sru_mod": [[353, 377], ["sru.check_sru_requirement", "torch.device", "torch.device", "torch.rand().to", "torch.rand().to", "Program", "Program.compile", "function.Module", "function.Module.load", "function.Module.get_function", "function.Module.get_function", "function.Module.get_function", "function.Module.get_function", "collections.namedtuple", "collections.namedtuple.", "SRU_CODE.encode", "bytes", "torch.rand", "torch.rand", "sru_prog.compile.encode", "torch.cuda.current_stream", "torch.cuda.current_stream"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.sru.check_sru_requirement", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.translate.translation_server.ServerModel.load"], ["def", "load_sru_mod", "(", ")", ":", "\n", "    ", "global", "SRU_FWD_FUNC", ",", "SRU_BWD_FUNC", ",", "SRU_BiFWD_FUNC", ",", "SRU_BiBWD_FUNC", "\n", "global", "SRU_STREAM", "\n", "if", "check_sru_requirement", "(", ")", ":", "\n", "        ", "from", "cupy", ".", "cuda", "import", "function", "\n", "from", "pynvrtc", ".", "compiler", "import", "Program", "\n", "\n", "# This sets up device to use.", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "tmp_", "=", "torch", ".", "rand", "(", "1", ",", "1", ")", ".", "to", "(", "device", ")", "\n", "\n", "sru_prog", "=", "Program", "(", "SRU_CODE", ".", "encode", "(", "'utf-8'", ")", ",", "\n", "'sru_prog.cu'", ".", "encode", "(", "'utf-8'", ")", ")", "\n", "sru_ptx", "=", "sru_prog", ".", "compile", "(", ")", "\n", "sru_mod", "=", "function", ".", "Module", "(", ")", "\n", "sru_mod", ".", "load", "(", "bytes", "(", "sru_ptx", ".", "encode", "(", ")", ")", ")", "\n", "\n", "SRU_FWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_fwd'", ")", "\n", "SRU_BWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bwd'", ")", "\n", "SRU_BiFWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bi_fwd'", ")", "\n", "SRU_BiBWD_FUNC", "=", "sru_mod", ".", "get_function", "(", "'sru_bi_bwd'", ")", "\n", "\n", "stream", "=", "namedtuple", "(", "'Stream'", ",", "[", "'ptr'", "]", ")", "\n", "SRU_STREAM", "=", "stream", "(", "ptr", "=", "torch", ".", "cuda", ".", "current_stream", "(", ")", ".", "cuda_stream", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ModelSaverBase.__init__": [[30, 42], ["collections.deque"], "methods", ["None"], ["model", ",", "\n", "model_opt", ",", "\n", "fields", ",", "\n", "optim", ",", "\n", "opt", ".", "save_checkpoint_steps", ",", "\n", "opt", ".", "keep_checkpoint", ")", "\n", "", "return", "model_saver", "\n", "\n", "\n", "", "class", "ModelSaverBase", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ModelSaverBase.maybe_save": [[43, 62], ["model_saver.ModelSaverBase._save", "model_saver.ModelSaverBase.checkpoint_queue.append", "len", "model_saver.ModelSaverBase.checkpoint_queue.popleft", "model_saver.ModelSaverBase._rm_checkpoint"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ReRankerModelSaver._save", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ReRankerModelSaver._rm_checkpoint"], ["\n", "\n", "def", "__init__", "(", "self", ",", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "base_path", "=", "base_path", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "keep_checkpoint", "=", "keep_checkpoint", "\n", "self", ".", "save_checkpoint_steps", "=", "save_checkpoint_steps", "\n", "\n", "if", "keep_checkpoint", ">", "0", ":", "\n", "            ", "self", ".", "checkpoint_queue", "=", "deque", "(", "[", "]", ",", "maxlen", "=", "keep_checkpoint", ")", "\n", "\n", "", "", "def", "maybe_save", "(", "self", ",", "step", ",", "stats", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ModelSaverBase._save": [[63, 74], ["NotImplementedError"], "methods", ["None"], ["\n", "if", "self", ".", "keep_checkpoint", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "if", "step", "%", "self", ".", "save_checkpoint_steps", "!=", "0", ":", "\n", "            ", "return", "\n", "# changed for KE_KG", "\n", "", "chkpt", ",", "chkpt_name", "=", "self", ".", "_save", "(", "step", ",", "stats", ")", "\n", "\n", "if", "self", ".", "keep_checkpoint", ">", "0", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ModelSaverBase._rm_checkpoint": [[75, 84], ["NotImplementedError"], "methods", ["None"], ["            ", "if", "len", "(", "self", ".", "checkpoint_queue", ")", "==", "self", ".", "checkpoint_queue", ".", "maxlen", ":", "\n", "                ", "todel", "=", "self", ".", "checkpoint_queue", ".", "popleft", "(", ")", "\n", "self", ".", "_rm_checkpoint", "(", "todel", ")", "\n", "", "self", ".", "checkpoint_queue", ".", "append", "(", "chkpt_name", ")", "\n", "\n", "", "", "def", "_save", "(", "self", ",", "step", ",", "stats", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ModelSaver.__init__": [[91, 96], ["model_saver.ModelSaverBase.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["\n", "", "def", "_rm_checkpoint", "(", "self", ",", "name", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ModelSaver._save": [[97, 125], ["real_model.state_dict", "real_generator.state_dict", "onmt.utils.logging.logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "isinstance", "onmt.inputters.save_fields_to_vocab", "real_model.state_dict.items", "stats.gen_ppl", "stats.gen_accuracy"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.save_fields_to_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_ppl", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_accuracy"], ["\n", "raise", "NotImplementedError", "(", ")", "\n", "\n", "\n", "", "", "class", "ModelSaver", "(", "ModelSaverBase", ")", ":", "\n", "    ", "\"\"\"\n        Simple model saver to filesystem\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", "=", "0", ")", ":", "\n", "        ", "super", "(", "ModelSaver", ",", "self", ")", ".", "__init__", "(", "\n", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", ")", "\n", "\n", "", "def", "_save", "(", "self", ",", "step", ",", "stats", "=", "None", ")", ":", "\n", "        ", "real_model", "=", "(", "self", ".", "model", ".", "module", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "nn", ".", "DataParallel", ")", "\n", "else", "self", ".", "model", ")", "\n", "real_generator", "=", "(", "real_model", ".", "generator", ".", "module", "\n", "if", "isinstance", "(", "real_model", ".", "generator", ",", "nn", ".", "DataParallel", ")", "\n", "else", "real_model", ".", "generator", ")", "\n", "\n", "model_state_dict", "=", "real_model", ".", "state_dict", "(", ")", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "model_state_dict", ".", "items", "(", ")", "\n", "if", "'generator'", "not", "in", "k", "}", "\n", "generator_state_dict", "=", "real_generator", ".", "state_dict", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ModelSaver._rm_checkpoint": [[126, 128], ["os.remove"], "methods", ["None"], ["checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'generator'", ":", "generator_state_dict", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.E2EModelSaver.__init__": [[152, 157], ["model_saver.ModelSaverBase.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", "=", "0", ")", ":", "\n", "        ", "super", "(", "E2EModelSaver", ",", "self", ")", ".", "__init__", "(", "\n", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.E2EModelSaver._save": [[158, 188], ["real_model.state_dict", "real_generator.state_dict", "onmt.utils.logging.logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "isinstance", "onmt.inputters.save_fields_to_vocab", "real_model.state_dict.items", "stats.gen_ppl", "stats.merged_ave_loss", "stats.sel_ave_loss", "stats.incons_ave_loss", "stats.sel_f1_score", "stats.gen_accuracy"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.save_fields_to_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_ppl", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.merged_ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.incons_ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_f1_score", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.gen_accuracy"], ["", "def", "_save", "(", "self", ",", "step", ",", "stats", "=", "None", ")", ":", "\n", "        ", "real_model", "=", "(", "self", ".", "model", ".", "module", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "nn", ".", "DataParallel", ")", "\n", "else", "self", ".", "model", ")", "\n", "real_generator", "=", "(", "real_model", ".", "generator", ".", "module", "\n", "if", "isinstance", "(", "real_model", ".", "generator", ",", "nn", ".", "DataParallel", ")", "\n", "else", "real_model", ".", "generator", ")", "\n", "\n", "model_state_dict", "=", "real_model", ".", "state_dict", "(", ")", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "model_state_dict", ".", "items", "(", ")", "\n", "if", "'generator'", "not", "in", "k", "}", "\n", "generator_state_dict", "=", "real_generator", ".", "state_dict", "(", ")", "\n", "checkpoint", "=", "{", "\n", "'end2end_model'", ":", "model_state_dict", ",", "\n", "'generator'", ":", "generator_state_dict", ",", "\n", "'vocab'", ":", "onmt", ".", "inputters", ".", "save_fields_to_vocab", "(", "self", ".", "fields", ")", ",", "\n", "'opt'", ":", "self", ".", "model_opt", ",", "\n", "'optim'", ":", "self", ".", "optim", ",", "\n", "}", "\n", "\n", "if", "not", "stats", ":", "\n", "            ", "checkpoint_path", "=", "'%s_step_%d.pt'", "%", "(", "self", ".", "base_path", ",", "step", ")", "\n", "", "else", ":", "\n", "            ", "checkpoint_path", "=", "'%s_genPPL_%.3f_aveMLoss_%.3f_aveSelLoss_%.4f_aveIncLoss_%.3f'", "'_selF1_%.3f_genAcc_%.2f_step_%d.pt'", "%", "(", "self", ".", "base_path", ",", "stats", ".", "gen_ppl", "(", ")", ",", "stats", ".", "merged_ave_loss", "(", ")", ",", "stats", ".", "sel_ave_loss", "(", ")", ",", "\n", "stats", ".", "incons_ave_loss", "(", ")", ",", "stats", ".", "sel_f1_score", "(", ")", ",", "stats", ".", "gen_accuracy", "(", ")", ",", "step", ")", "\n", "", "logger", ".", "info", "(", "\"Saving end2end checkpoint \"", "+", "checkpoint_path", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "checkpoint_path", ")", "\n", "return", "checkpoint", ",", "checkpoint_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.E2EModelSaver._rm_checkpoint": [[189, 191], ["os.remove"], "methods", ["None"], ["", "def", "_rm_checkpoint", "(", "self", ",", "name", ")", ":", "\n", "        ", "os", ".", "remove", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.SelectorModelSaver.__init__": [[198, 203], ["model_saver.ModelSaverBase.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", "=", "0", ")", ":", "\n", "        ", "super", "(", "SelectorModelSaver", ",", "self", ")", ".", "__init__", "(", "\n", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.SelectorModelSaver._save": [[204, 227], ["real_model.state_dict", "onmt.utils.logging.logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "onmt.inputters.save_fields_to_vocab", "real_model.state_dict.items", "stats.sel_ave_loss", "stats.sel_f1_score"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.save_fields_to_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.E2EStatistics.sel_f1_score"], ["", "def", "_save", "(", "self", ",", "step", ",", "stats", "=", "None", ")", ":", "\n", "        ", "real_model", "=", "(", "self", ".", "model", ".", "module", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "nn", ".", "DataParallel", ")", "\n", "else", "self", ".", "model", ")", "\n", "\n", "model_state_dict", "=", "real_model", ".", "state_dict", "(", ")", "\n", "# TODO: remove this line?", "\n", "model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "model_state_dict", ".", "items", "(", ")", "}", "\n", "checkpoint", "=", "{", "\n", "'selector'", ":", "model_state_dict", ",", "\n", "'vocab'", ":", "onmt", ".", "inputters", ".", "save_fields_to_vocab", "(", "self", ".", "fields", ")", ",", "\n", "'opt'", ":", "self", ".", "model_opt", "}", "\n", "# 'vocab': onmt.inputters.save_fields_to_vocab(self.fields),", "\n", "# 'opt': self.model_opt,", "\n", "# 'optim': self.optim,", "\n", "if", "not", "stats", ":", "\n", "            ", "checkpoint_path", "=", "'%s_step_%d.pt'", "%", "(", "self", ".", "base_path", ",", "step", ")", "\n", "", "else", ":", "\n", "            ", "checkpoint_path", "=", "'%s_aveSelLoss_%5.4f_selF1_%4.3f_step_%d.pt'", "%", "(", "self", ".", "base_path", ",", "stats", ".", "sel_ave_loss", "(", ")", ",", "stats", ".", "sel_f1_score", "(", ")", ",", "step", ")", "\n", "", "logger", ".", "info", "(", "\"Saving selector checkpoint \"", "+", "checkpoint_path", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "checkpoint_path", ")", "\n", "return", "checkpoint", ",", "checkpoint_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.SelectorModelSaver._rm_checkpoint": [[228, 230], ["os.remove"], "methods", ["None"], ["", "def", "_rm_checkpoint", "(", "self", ",", "name", ")", ":", "\n", "        ", "os", ".", "remove", "(", "name", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.build_model_saver": [[11, 20], ["model_saver.ReRankerModelSaver"], "function", ["None"], ["def", "build_model_saver", "(", "model_opt", ",", "opt", ",", "model", ",", "fields", ",", "optim", ")", ":", "\n", "    ", "if", "model_opt", ".", "key_model", "==", "'key_selector'", ":", "\n", "        ", "model_saver", "=", "SelectorModelSaver", "(", "opt", ".", "save_model", ",", "\n", "model", ",", "\n", "model_opt", ",", "\n", "fields", ",", "\n", "optim", ",", "\n", "opt", ".", "save_checkpoint_steps", ",", "\n", "opt", ".", "keep_checkpoint", ")", "\n", "", "elif", "model_opt", ".", "key_model", "==", "\"key_end2end\"", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model.ReRankerModel.__init__": [[69, 73], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["rk_final_state", "=", "rk_final_state", ")", "\n", "if", "self", ".", "multigpu", ":", "\n", "# Not yet supported on multi-gpu", "\n", "            ", "dec_state", "=", "None", "\n", "attns", "=", "None", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model.ReRankerModel.forward": [[74, 98], ["model.ReRankerModel.reranker"], "methods", ["None"], ["", "return", "decoder_outputs", ",", "attns", ",", "dec_state", "\n", "\n", "\n", "", "", "class", "SelectorModel", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"\n    Core trainable object in OpenNMT. Implements a trainable interface\n\n    Args:\n      selector (:obj:``): an selector object\n      multi<gpu (bool): setup for multigpu support\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "selector", ",", "multigpu", "=", "False", ")", ":", "\n", "        ", "self", ".", "multigpu", "=", "multigpu", "\n", "super", "(", "SelectorModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "selector", "=", "selector", "\n", "\n", "", "def", "forward", "(", "self", ",", "src", ",", "lengths", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ReRankerModelSaver.__init__": [[135, 140], ["model_saver.ModelSaverBase.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["            ", "checkpoint_path", "=", "'%s_step_%d.pt'", "%", "(", "self", ".", "base_path", ",", "step", ")", "\n", "", "else", ":", "\n", "            ", "checkpoint_path", "=", "'%s_genPPL_%6.3f_genAcc_%4.2f_step_%d.pt'", "%", "(", "self", ".", "base_path", ",", "stats", ".", "gen_ppl", "(", ")", ",", "stats", ".", "gen_accuracy", "(", ")", ",", "step", ")", "\n", "", "logger", ".", "info", "(", "\"Saving s2s generator checkpoint \"", "+", "checkpoint_path", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "checkpoint_path", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ReRankerModelSaver._save": [[141, 166], ["real_model.state_dict", "onmt.utils.logging.logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "isinstance", "onmt.inputters.save_fields_to_vocab", "real_model.state_dict.items", "stats.ave_loss", "stats.total_acc", "stats.posi_acc", "stats.neg_acc"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.optimizers.MultipleOptimizer.state_dict", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.save_fields_to_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.ave_loss", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.total_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.posi_acc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.statistics.ReRankerStatistics.neg_acc"], ["return", "checkpoint", ",", "checkpoint_path", "\n", "\n", "", "def", "_rm_checkpoint", "(", "self", ",", "name", ")", ":", "\n", "        ", "os", ".", "remove", "(", "name", ")", "\n", "\n", "\n", "", "", "class", "E2EModelSaver", "(", "ModelSaverBase", ")", ":", "\n", "    ", "\"\"\"\n        Simple model saver to filesystem\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", "=", "0", ")", ":", "\n", "        ", "super", "(", "E2EModelSaver", ",", "self", ")", ".", "__init__", "(", "\n", "base_path", ",", "model", ",", "model_opt", ",", "fields", ",", "optim", ",", "\n", "save_checkpoint_steps", ",", "keep_checkpoint", ")", "\n", "\n", "", "def", "_save", "(", "self", ",", "step", ",", "stats", "=", "None", ")", ":", "\n", "        ", "real_model", "=", "(", "self", ".", "model", ".", "module", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "nn", ".", "DataParallel", ")", "\n", "else", "self", ".", "model", ")", "\n", "real_generator", "=", "(", "real_model", ".", "generator", ".", "module", "\n", "if", "isinstance", "(", "real_model", ".", "generator", ",", "nn", ".", "DataParallel", ")", "\n", "else", "real_model", ".", "generator", ")", "\n", "\n", "model_state_dict", "=", "real_model", ".", "state_dict", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.models.model_saver.ReRankerModelSaver._rm_checkpoint": [[167, 169], ["os.remove"], "methods", ["None"], ["model_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "model_state_dict", ".", "items", "(", ")", "\n", "if", "'generator'", "not", "in", "k", "}", "\n", "generator_state_dict", "=", "real_generator", ".", "state_dict", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.cnn_encoder.CNNEncoder.__init__": [[18, 27], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.Linear", "onmt.utils.cnn_factory.StackedCNN"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "hidden_size", ",", "\n", "cnn_kernel_width", ",", "dropout", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "CNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "input_size", "=", "embeddings", ".", "embedding_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "cnn", "=", "StackedCNN", "(", "num_layers", ",", "hidden_size", ",", "\n", "cnn_kernel_width", ",", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.cnn_encoder.CNNEncoder.forward": [[28, 44], ["cnn_encoder.CNNEncoder._check_args", "cnn_encoder.CNNEncoder.embeddings", "emb.transpose().contiguous.transpose().contiguous.transpose().contiguous", "emb.transpose().contiguous.transpose().contiguous.view", "cnn_encoder.CNNEncoder.linear", "onmt.utils.cnn_factory.shape_transform.view", "onmt.utils.cnn_factory.shape_transform", "cnn_encoder.CNNEncoder.cnn", "emb.transpose().contiguous.transpose().contiguous.size", "emb.transpose().contiguous.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose().contiguous", "cnn_encoder.CNNEncoder.squeeze().transpose().contiguous", "emb.transpose().contiguous.transpose().contiguous.transpose", "emb.transpose().contiguous.transpose().contiguous.size", "emb.transpose().contiguous.transpose().contiguous.size", "onmt.utils.cnn_factory.shape_transform.squeeze().transpose", "cnn_encoder.CNNEncoder.squeeze().transpose", "onmt.utils.cnn_factory.shape_transform.squeeze", "cnn_encoder.CNNEncoder.squeeze"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.cnn_factory.shape_transform"], ["", "def", "forward", "(", "self", ",", "input", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "\"\"\" See :obj:`onmt.modules.EncoderBase.forward()`\"\"\"", "\n", "self", ".", "_check_args", "(", "input", ",", "lengths", ",", "hidden", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "input", ")", "\n", "# s_len, batch, emb_dim = emb.size()", "\n", "\n", "emb", "=", "emb", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "emb_reshape", "=", "emb", ".", "view", "(", "emb", ".", "size", "(", "0", ")", "*", "emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "emb_remap", "=", "self", ".", "linear", "(", "emb_reshape", ")", "\n", "emb_remap", "=", "emb_remap", ".", "view", "(", "emb", ".", "size", "(", "0", ")", ",", "emb", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "emb_remap", "=", "shape_transform", "(", "emb_remap", ")", "\n", "out", "=", "self", ".", "cnn", "(", "emb_remap", ")", "\n", "\n", "return", "emb_remap", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "out", ".", "squeeze", "(", "3", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.encoder.EncoderBase._check_args": [[35, 40], ["src.size", "lengths.size", "onmt.utils.misc.aeq"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.aeq"], ["def", "_check_args", "(", "self", ",", "src", ",", "lengths", "=", "None", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "_", ",", "n_batch", ",", "_", "=", "src", ".", "size", "(", ")", "\n", "if", "lengths", "is", "not", "None", ":", "\n", "            ", "n_batch_", ",", "=", "lengths", ".", "size", "(", ")", "\n", "aeq", "(", "n_batch", ",", "n_batch_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.encoder.EncoderBase.forward": [[41, 55], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            src (:obj:`LongTensor`):\n               padded sequences of sparse indices `[src_len x batch x nfeat]`\n            lengths (:obj:`LongTensor`): length of each sequence `[batch]`\n\n\n        Returns:\n            (tuple of :obj:`FloatTensor`, :obj:`FloatTensor`):\n                * final encoder state, used to initialize decoder\n                * memory bank for attention, `[src_len x batch x hidden]`\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RNNEncoder.__init__": [[27, 52], ["onmt.encoders.encoder.EncoderBase.__init__", "onmt.utils.rnn_factory.rnn_factory", "rnn_encoder.RNNEncoder._initialize_bridge"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.rnn_factory.rnn_factory", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RKRNNEncoder._initialize_bridge"], ["\n", "def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "use_bridge", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "embeddings", "is", "not", "None", "\n", "\n", "# self.use_retrieved_keys = use_retrieved_keys", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "assert", "hidden_size", "%", "num_directions", "==", "0", "\n", "hidden_size", "=", "hidden_size", "//", "num_directions", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n", "self", ".", "rnn", ",", "self", ".", "no_pack_padded_seq", "=", "rnn_factory", "(", "rnn_type", ",", "\n", "input_size", "=", "embeddings", ".", "embedding_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", "if", "num_layers", "!=", "1", "else", "0.0", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n", "# Initialize the bridge layer", "\n", "self", ".", "use_bridge", "=", "use_bridge", "\n", "if", "self", ".", "use_bridge", ":", "\n", "            ", "self", ".", "_initialize_bridge", "(", "rnn_type", ",", "\n", "hidden_size", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RNNEncoder.forward": [[53, 74], ["rnn_encoder.RNNEncoder._check_args", "rnn_encoder.RNNEncoder.embeddings", "rnn_encoder.RNNEncoder.rnn", "lengths.view().tolist.view().tolist.view().tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "rnn_encoder.RNNEncoder._bridge", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "lengths.view().tolist.view().tolist.view"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RKRNNEncoder._bridge"], ["num_layers", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "src", ",", "src_lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`EncoderBase.forward()`\"", "\n", "self", ".", "_check_args", "(", "src", ",", "src_lengths", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "# s_len, batch, emb_dim = emb.size()", "\n", "\n", "packed_emb", "=", "emb", "\n", "if", "src_lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "# Lengths data is wrapped inside a Tensor.", "\n", "            ", "src_lengths", "=", "src_lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "packed_emb", "=", "pack", "(", "emb", ",", "src_lengths", ")", "\n", "\n", "", "memory_bank", ",", "encoder_final", "=", "self", ".", "rnn", "(", "packed_emb", ")", "\n", "\n", "if", "src_lengths", "is", "not", "None", "and", "not", "self", ".", "no_pack_padded_seq", ":", "\n", "            ", "memory_bank", "=", "unpack", "(", "memory_bank", ")", "[", "0", "]", "\n", "\n", "", "if", "self", ".", "use_bridge", ":", "\n", "            ", "encoder_final", "=", "self", ".", "_bridge", "(", "encoder_final", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RNNEncoder._initialize_bridge": [[75, 89], ["torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "range"], "methods", ["None"], ["\n", "", "return", "encoder_final", ",", "memory_bank", "\n", "\n", "", "def", "_initialize_bridge", "(", "self", ",", "rnn_type", ",", "\n", "hidden_size", ",", "\n", "num_layers", ")", ":", "\n", "\n", "# LSTM has hidden and cell state, other only one", "\n", "        ", "number_of_states", "=", "2", "if", "rnn_type", "==", "\"LSTM\"", "else", "1", "\n", "# Total number of states", "\n", "self", ".", "total_hidden_dim", "=", "hidden_size", "*", "num_layers", "\n", "\n", "# Build a linear layer for each", "\n", "self", ".", "bridge", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "total_hidden_dim", ",", "\n", "self", ".", "total_hidden_dim", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RNNEncoder._bridge": [[90, 108], ["isinstance", "states.size", "linear", "torch.relu().view", "torch.relu().view", "tuple", "rnn_encoder.RNNEncoder._bridge.bottle_hidden"], "methods", ["None"], ["bias", "=", "True", ")", "\n", "for", "_", "in", "range", "(", "number_of_states", ")", "]", ")", "\n", "\n", "", "def", "_bridge", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "\"\"\"\n        Forward hidden state through bridge\n        \"\"\"", "\n", "def", "bottle_hidden", "(", "linear", ",", "states", ")", ":", "\n", "            ", "\"\"\"\n            Transform from 3D to 2D, apply linear and return initial size\n            \"\"\"", "\n", "size", "=", "states", ".", "size", "(", ")", "\n", "result", "=", "linear", "(", "states", ".", "view", "(", "-", "1", ",", "self", ".", "total_hidden_dim", ")", ")", "\n", "return", "F", ".", "relu", "(", "result", ")", ".", "view", "(", "size", ")", "\n", "\n", "", "if", "isinstance", "(", "hidden", ",", "tuple", ")", ":", "# LSTM", "\n", "            ", "outs", "=", "tuple", "(", "[", "bottle_hidden", "(", "layer", ",", "hidden", "[", "ix", "]", ")", "\n", "for", "ix", ",", "layer", "in", "enumerate", "(", "self", ".", "bridge", ")", "]", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RKRNNEncoder.__init__": [[126, 151], ["onmt.encoders.encoder.EncoderBase.__init__", "onmt.utils.rnn_factory.rnn_factory", "rnn_encoder.RKRNNEncoder._initialize_bridge"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.rnn_factory.rnn_factory", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RKRNNEncoder._initialize_bridge"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ",", "\n", "use_bridge", "=", "False", ")", ":", "\n", "        ", "super", "(", "RKRNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "embeddings", "is", "not", "None", "\n", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "assert", "hidden_size", "%", "num_directions", "==", "0", "\n", "hidden_size", "=", "hidden_size", "//", "num_directions", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n", "self", ".", "rk_rnn", ",", "self", ".", "rk_no_pack_padded_seq", "=", "rnn_factory", "(", "rnn_type", ",", "\n", "input_size", "=", "embeddings", ".", "embedding_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", "if", "num_layers", "!=", "1", "else", "0.0", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n", "# Initialize the bridge layer", "\n", "self", ".", "use_bridge", "=", "use_bridge", "\n", "if", "self", ".", "use_bridge", ":", "\n", "            ", "self", ".", "_initialize_bridge", "(", "rnn_type", ",", "\n", "hidden_size", ",", "\n", "num_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RKRNNEncoder.forward": [[152, 184], ["rnn_encoder.RKRNNEncoder._check_args", "retrieved_keys.size", "rnn_encoder.RKRNNEncoder.embeddings", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "rnn_encoder.RKRNNEncoder.index_select", "rnn_encoder.RKRNNEncoder.rk_rnn", "sorted_rk_lengths.view().tolist.view().tolist.view().tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "rk_memory_bank.index_select.index_select.index_select", "rnn_encoder.RKRNNEncoder.index_select", "rnn_encoder.RKRNNEncoder._bridge", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "sorted_rk_lengths.view().tolist.view().tolist.view"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RKRNNEncoder._bridge"], ["", "", "def", "forward", "(", "self", ",", "retrieved_keys", ",", "rk_lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`EncoderBase.forward()`\"", "\n", "# encoding retrieved keyphrases", "\n", "assert", "retrieved_keys", "is", "not", "None", "\n", "self", ".", "_check_args", "(", "retrieved_keys", ",", "rk_lengths", ")", "\n", "\n", "rk_len", ",", "_", ",", "_", "=", "retrieved_keys", ".", "size", "(", ")", "\n", "# print('rk_len: {}'.format(rk_len))", "\n", "rk_emb", "=", "self", ".", "embeddings", "(", "retrieved_keys", ")", "\n", "# rk_len, batch, emb_dim = rk_emb.size()", "\n", "# print(rk_len)", "\n", "\n", "# sort retrieved keys w.r.t rk_lengths", "\n", "sorted_rk_lengths", ",", "idx_sort", "=", "torch", ".", "sort", "(", "rk_lengths", ",", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "_", ",", "idx_unsort", "=", "torch", ".", "sort", "(", "idx_sort", ",", "dim", "=", "0", ")", "\n", "\n", "rk_packed_emb", "=", "rk_emb", ".", "index_select", "(", "1", ",", "idx_sort", ")", "\n", "if", "rk_lengths", "is", "not", "None", "and", "not", "self", ".", "rk_no_pack_padded_seq", ":", "\n", "            ", "sorted_rk_lengths", "=", "sorted_rk_lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "rk_packed_emb", "=", "pack", "(", "rk_packed_emb", ",", "sorted_rk_lengths", ")", "\n", "\n", "", "rk_memory_bank", ",", "rk_encoder_final", "=", "self", ".", "rk_rnn", "(", "rk_packed_emb", ")", "\n", "\n", "if", "rk_lengths", "is", "not", "None", "and", "not", "self", ".", "rk_no_pack_padded_seq", ":", "\n", "            ", "rk_memory_bank", "=", "unpack", "(", "rk_memory_bank", ")", "[", "0", "]", "\n", "rk_memory_bank", "=", "rk_memory_bank", ".", "index_select", "(", "1", ",", "idx_unsort", ")", "\n", "rk_encoder_final", "=", "rk_encoder_final", ".", "index_select", "(", "1", ",", "idx_unsort", ")", "\n", "\n", "", "if", "self", ".", "use_bridge", ":", "\n", "            ", "rk_encoder_final", "=", "self", ".", "_bridge", "(", "rk_encoder_final", ")", "\n", "\n", "", "return", "rk_encoder_final", ",", "rk_memory_bank", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RKRNNEncoder._initialize_bridge": [[185, 199], ["torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "range"], "methods", ["None"], ["", "def", "_initialize_bridge", "(", "self", ",", "rnn_type", ",", "\n", "hidden_size", ",", "\n", "num_layers", ")", ":", "\n", "\n", "# LSTM has hidden and cell state, other only one", "\n", "        ", "number_of_states", "=", "2", "if", "rnn_type", "==", "\"LSTM\"", "else", "1", "\n", "# Total number of states", "\n", "self", ".", "total_hidden_dim", "=", "hidden_size", "*", "num_layers", "\n", "\n", "# Build a linear layer for each", "\n", "self", ".", "bridge", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "total_hidden_dim", ",", "\n", "self", ".", "total_hidden_dim", ",", "\n", "bias", "=", "True", ")", "\n", "for", "_", "in", "range", "(", "number_of_states", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.rnn_encoder.RKRNNEncoder._bridge": [[200, 218], ["isinstance", "states.size", "linear", "torch.relu().view", "torch.relu().view", "torch.relu().view", "tuple", "rnn_encoder.RKRNNEncoder._bridge.bottle_hidden"], "methods", ["None"], ["", "def", "_bridge", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "\"\"\"\n        Forward hidden state through bridge\n        \"\"\"", "\n", "def", "bottle_hidden", "(", "linear", ",", "states", ")", ":", "\n", "            ", "\"\"\"\n            Transform from 3D to 2D, apply linear and return initial size\n            \"\"\"", "\n", "size", "=", "states", ".", "size", "(", ")", "\n", "result", "=", "linear", "(", "states", ".", "view", "(", "-", "1", ",", "self", ".", "total_hidden_dim", ")", ")", "\n", "return", "F", ".", "relu", "(", "result", ")", ".", "view", "(", "size", ")", "\n", "\n", "", "if", "isinstance", "(", "hidden", ",", "tuple", ")", ":", "# LSTM", "\n", "            ", "outs", "=", "tuple", "(", "[", "bottle_hidden", "(", "layer", ",", "hidden", "[", "ix", "]", ")", "\n", "for", "ix", ",", "layer", "in", "enumerate", "(", "self", ".", "bridge", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "outs", "=", "bottle_hidden", "(", "self", ".", "bridge", "[", "0", "]", ",", "hidden", ")", "\n", "", "return", "outs", "", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.audio_encoder.AudioEncoder.__init__": [[22, 44], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "int", "int", "int", "torch.LSTM", "torch.LSTM", "math.floor", "math.floor", "math.floor"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "bidirectional", ",", "rnn_size", ",", "dropout", ",", "\n", "sample_rate", ",", "window_size", ")", ":", "\n", "        ", "super", "(", "AudioEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "self", ".", "hidden_size", "=", "rnn_size", "\n", "\n", "self", ".", "layer1", "=", "nn", ".", "Conv2d", "(", "1", ",", "32", ",", "kernel_size", "=", "(", "41", ",", "11", ")", ",", "\n", "padding", "=", "(", "0", ",", "10", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "self", ".", "batch_norm1", "=", "nn", ".", "BatchNorm2d", "(", "32", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "(", "21", ",", "11", ")", ",", "\n", "padding", "=", "(", "0", ",", "0", ")", ",", "stride", "=", "(", "2", ",", "1", ")", ")", "\n", "self", ".", "batch_norm2", "=", "nn", ".", "BatchNorm2d", "(", "32", ")", "\n", "\n", "input_size", "=", "int", "(", "math", ".", "floor", "(", "(", "sample_rate", "*", "window_size", ")", "/", "2", ")", "+", "1", ")", "\n", "input_size", "=", "int", "(", "math", ".", "floor", "(", "input_size", "-", "41", ")", "/", "2", "+", "1", ")", "\n", "input_size", "=", "int", "(", "math", ".", "floor", "(", "input_size", "-", "21", ")", "/", "2", "+", "1", ")", "\n", "input_size", "*=", "32", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "input_size", ",", "rnn_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.audio_encoder.AudioEncoder.load_pretrained_vectors": [[45, 48], ["None"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\" Pass in needed options only when modify function definition.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.audio_encoder.AudioEncoder.forward": [[49, 73], ["audio_encoder.AudioEncoder.batch_norm1", "torch.hardtanh", "torch.hardtanh", "audio_encoder.AudioEncoder.batch_norm2", "torch.hardtanh", "torch.hardtanh", "src.transpose().transpose.transpose().transpose.size", "src.transpose().transpose.transpose().transpose.size", "src.transpose().transpose.transpose().transpose.view", "src.transpose().transpose.transpose().transpose.transpose().transpose", "audio_encoder.AudioEncoder.rnn", "audio_encoder.AudioEncoder.layer1", "audio_encoder.AudioEncoder.layer2", "src.transpose().transpose.transpose().transpose.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`onmt.encoders.encoder.EncoderBase.forward()`\"", "\n", "# (batch_size, 1, nfft, t)", "\n", "# layer 1", "\n", "src", "=", "self", ".", "batch_norm1", "(", "self", ".", "layer1", "(", "src", "[", ":", ",", ":", ",", ":", ",", ":", "]", ")", ")", "\n", "\n", "# (batch_size, 32, nfft/2, t/2)", "\n", "src", "=", "F", ".", "hardtanh", "(", "src", ",", "0", ",", "20", ",", "inplace", "=", "True", ")", "\n", "\n", "# (batch_size, 32, nfft/2/2, t/2)", "\n", "# layer 2", "\n", "src", "=", "self", ".", "batch_norm2", "(", "self", ".", "layer2", "(", "src", ")", ")", "\n", "\n", "# (batch_size, 32, nfft/2/2, t/2)", "\n", "src", "=", "F", ".", "hardtanh", "(", "src", ",", "0", ",", "20", ",", "inplace", "=", "True", ")", "\n", "\n", "batch_size", "=", "src", ".", "size", "(", "0", ")", "\n", "length", "=", "src", ".", "size", "(", "3", ")", "\n", "src", "=", "src", ".", "view", "(", "batch_size", ",", "-", "1", ",", "length", ")", "\n", "src", "=", "src", ".", "transpose", "(", "0", ",", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "src", ")", "\n", "\n", "return", "hidden", ",", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.mean_encoder.MeanEncoder.__init__": [[15, 19], ["onmt.encoders.encoder.EncoderBase.__init__"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "MeanEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.mean_encoder.MeanEncoder.forward": [[20, 30], ["mean_encoder.MeanEncoder._check_args", "mean_encoder.MeanEncoder.embeddings", "mean_encoder.MeanEncoder.size", "mean_encoder.MeanEncoder.mean().expand", "mean_encoder.MeanEncoder.mean"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.encoder.EncoderBase._check_args"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`EncoderBase.forward()`\"", "\n", "self", ".", "_check_args", "(", "src", ",", "lengths", ")", "\n", "\n", "emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "_", ",", "batch", ",", "emb_dim", "=", "emb", ".", "size", "(", ")", "\n", "mean", "=", "emb", ".", "mean", "(", "0", ")", ".", "expand", "(", "self", ".", "num_layers", ",", "batch", ",", "emb_dim", ")", "\n", "memory_bank", "=", "emb", "\n", "encoder_final", "=", "(", "mean", ",", "mean", ")", "\n", "return", "encoder_final", ",", "memory_bank", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.image_encoder.ImageEncoder.__init__": [[19, 48], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["def", "__init__", "(", "self", ",", "num_layers", ",", "bidirectional", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "ImageEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "self", ".", "hidden_size", "=", "rnn_size", "\n", "\n", "self", ".", "layer1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer3", "=", "nn", ".", "Conv2d", "(", "128", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer4", "=", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer5", "=", "nn", ".", "Conv2d", "(", "256", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "layer6", "=", "nn", ".", "Conv2d", "(", "512", ",", "512", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "padding", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ")", "\n", "\n", "self", ".", "batch_norm1", "=", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", "self", ".", "batch_norm2", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "self", ".", "batch_norm3", "=", "nn", ".", "BatchNorm2d", "(", "512", ")", "\n", "\n", "src_size", "=", "512", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "src_size", ",", "rnn_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "self", ".", "pos_lut", "=", "nn", ".", "Embedding", "(", "1000", ",", "src_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.image_encoder.ImageEncoder.load_pretrained_vectors": [[49, 52], ["None"], "methods", ["None"], ["", "def", "load_pretrained_vectors", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\" Pass in needed options only when modify function definition.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.image_encoder.ImageEncoder.forward": [[53, 109], ["torch.relu.size", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "image_encoder.ImageEncoder.layer1", "image_encoder.ImageEncoder.layer2", "image_encoder.ImageEncoder.batch_norm1", "image_encoder.ImageEncoder.layer4", "image_encoder.ImageEncoder.batch_norm2", "image_encoder.ImageEncoder.batch_norm3", "torch.relu.size", "src[].transpose().transpose", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "torch.Tensor().type_as().long().fill_", "image_encoder.ImageEncoder.pos_lut", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "image_encoder.ImageEncoder.rnn", "all_outputs.append", "image_encoder.ImageEncoder.layer3", "image_encoder.ImageEncoder.layer5", "image_encoder.ImageEncoder.layer6", "src[].transpose", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "torch.Tensor().type_as().long", "image_encoder.ImageEncoder.view", "image_encoder.ImageEncoder.size", "image_encoder.ImageEncoder.size", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor().type_as", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "lengths", "=", "None", ")", ":", "\n", "        ", "\"See :obj:`onmt.encoders.encoder.EncoderBase.forward()`\"", "\n", "\n", "batch_size", "=", "src", ".", "size", "(", "0", ")", "\n", "# (batch_size, 64, imgH, imgW)", "\n", "# layer 1", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "layer1", "(", "src", "[", ":", ",", ":", ",", ":", ",", ":", "]", "-", "0.5", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 64, imgH/2, imgW/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "# (batch_size, 128, imgH/2, imgW/2)", "\n", "# layer 2", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "layer2", "(", "src", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 128, imgH/2/2, imgW/2/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "#  (batch_size, 256, imgH/2/2, imgW/2/2)", "\n", "# layer 3", "\n", "# batch norm 1", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "batch_norm1", "(", "self", ".", "layer3", "(", "src", ")", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 256, imgH/2/2, imgW/2/2)", "\n", "# layer4", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "layer4", "(", "src", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 256, imgH/2/2/2, imgW/2/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "1", ",", "2", ")", ",", "stride", "=", "(", "1", ",", "2", ")", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2)", "\n", "# layer 5", "\n", "# batch norm 2", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "batch_norm2", "(", "self", ".", "layer5", "(", "src", ")", ")", ",", "True", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2/2)", "\n", "src", "=", "F", ".", "max_pool2d", "(", "src", ",", "kernel_size", "=", "(", "2", ",", "1", ")", ",", "stride", "=", "(", "2", ",", "1", ")", ")", "\n", "\n", "# (batch_size, 512, imgH/2/2/2, imgW/2/2/2)", "\n", "src", "=", "F", ".", "relu", "(", "self", ".", "batch_norm3", "(", "self", ".", "layer6", "(", "src", ")", ")", ",", "True", ")", "\n", "\n", "# # (batch_size, 512, H, W)", "\n", "all_outputs", "=", "[", "]", "\n", "for", "row", "in", "range", "(", "src", ".", "size", "(", "2", ")", ")", ":", "\n", "            ", "inp", "=", "src", "[", ":", ",", ":", ",", "row", ",", ":", "]", ".", "transpose", "(", "0", ",", "2", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "row_vec", "=", "torch", ".", "Tensor", "(", "batch_size", ")", ".", "type_as", "(", "inp", ".", "data", ")", ".", "long", "(", ")", ".", "fill_", "(", "row", ")", "\n", "pos_emb", "=", "self", ".", "pos_lut", "(", "row_vec", ")", "\n", "with_pos", "=", "torch", ".", "cat", "(", "\n", "(", "pos_emb", ".", "view", "(", "1", ",", "pos_emb", ".", "size", "(", "0", ")", ",", "pos_emb", ".", "size", "(", "1", ")", ")", ",", "inp", ")", ",", "0", ")", "\n", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "with_pos", ")", "\n", "all_outputs", ".", "append", "(", "outputs", ")", "\n", "", "out", "=", "torch", ".", "cat", "(", "all_outputs", ",", "0", ")", "\n", "\n", "return", "hidden_t", ",", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.transformer.TransformerEncoderLayer.__init__": [[26, 34], ["torch.Module.__init__", "onmt.modules.MultiHeadedAttention", "onmt.modules.position_ffn.PositionwiseFeedForward", "onmt.modules.LayerNorm", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["\n", "\n", "def", "__init__", "(", "self", ",", "d_model", ",", "heads", ",", "d_ff", ",", "dropout", ",", "\n", "self_attn_type", "=", "\"scaled-dot\"", ")", ":", "\n", "        ", "super", "(", "TransformerDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "self_attn_type", "=", "self_attn_type", "\n", "\n", "if", "self_attn_type", "==", "\"scaled-dot\"", ":", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.transformer.TransformerEncoderLayer.forward": [[35, 53], ["transformer.TransformerEncoderLayer.layer_norm", "transformer.TransformerEncoderLayer.self_attn", "transformer.TransformerEncoderLayer.feed_forward", "transformer.TransformerEncoderLayer.dropout"], "methods", ["None"], ["            ", "self", ".", "self_attn", "=", "onmt", ".", "modules", ".", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "", "elif", "self_attn_type", "==", "\"average\"", ":", "\n", "            ", "self", ".", "self_attn", "=", "onmt", ".", "modules", ".", "AverageAttention", "(", "\n", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "\n", "", "self", ".", "context_attn", "=", "onmt", ".", "modules", ".", "MultiHeadedAttention", "(", "\n", "heads", ",", "d_model", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "feed_forward", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "dropout", ")", "\n", "self", ".", "layer_norm_1", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "layer_norm_2", "=", "onmt", ".", "modules", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "mask", "=", "self", ".", "_get_attn_subsequent_mask", "(", "MAX_SIZE", ")", "\n", "# Register self.mask as a buffer in TransformerDecoderLayer, so", "\n", "# it gets TransformerDecoderLayer's cuda behavior automatically.", "\n", "self", ".", "register_buffer", "(", "'mask'", ",", "mask", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "inputs", ",", "memory_bank", ",", "src_pad_mask", ",", "tgt_pad_mask", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.transformer.TransformerEncoder.__init__": [[87, 97], ["onmt.encoders.encoder.EncoderBase.__init__", "torch.ModuleList", "onmt.modules.LayerNorm", "transformer.TransformerEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__"], ["\n", "", "query", "=", "self", ".", "drop", "(", "query", ")", "+", "inputs", "\n", "\n", "query_norm", "=", "self", ".", "layer_norm_2", "(", "query", ")", "\n", "mid", ",", "attn", "=", "self", ".", "context_attn", "(", "memory_bank", ",", "memory_bank", ",", "query_norm", ",", "\n", "mask", "=", "src_pad_mask", ",", "\n", "layer_cache", "=", "layer_cache", ",", "\n", "type", "=", "\"context\"", ")", "\n", "output", "=", "self", ".", "feed_forward", "(", "self", ".", "drop", "(", "mid", ")", "+", "query", ")", "\n", "\n", "return", "output", ",", "attn", ",", "all_input", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.transformer.TransformerEncoder.forward": [[98, 116], ["transformer.TransformerEncoder._check_args", "transformer.TransformerEncoder.embeddings", "transformer.TransformerEncoder.transpose().contiguous", "src[].transpose", "src[].transpose.size", "src[].transpose.data.eq().unsqueeze().expand", "range", "transformer.TransformerEncoder.layer_norm", "transformer.TransformerEncoder.transpose().contiguous", "transformer.TransformerEncoder.transpose", "src[].transpose.data.eq().unsqueeze", "transformer.TransformerEncoder.transpose", "src[].transpose.data.eq"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.encoder.EncoderBase._check_args"], ["\n", "", "def", "_get_attn_subsequent_mask", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"\n        Get an attention mask to avoid using the subsequent info.\n\n        Args:\n            size: int\n\n        Returns:\n            (`LongTensor`):\n\n            * subsequent_mask `[1 x size x size]`\n        \"\"\"", "\n", "attn_shape", "=", "(", "1", ",", "size", ",", "size", ")", "\n", "subsequent_mask", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "attn_shape", ")", ",", "k", "=", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "subsequent_mask", "=", "torch", ".", "from_numpy", "(", "subsequent_mask", ")", "\n", "return", "subsequent_mask", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.data_utils.get_tokens": [[10, 27], ["re.sub", "list", "filter", "re.sub.split", "filter", "re.split", "re.match", "len"], "function", ["None"], ["def", "get_tokens", "(", "text", ",", "fine_grad", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Need use the same word tokenizer between keywords and source context\n    keep [_<>,\\(\\)\\.\\'%], replace digits to <digit>, split by [^a-zA-Z0-9_<>,\\(\\)\\.\\'%]\n    \"\"\"", "\n", "text", "=", "re", ".", "sub", "(", "r'[\\r\\n\\t]'", ",", "''", ",", "text", ")", "\n", "text", "=", "''", ".", "join", "(", "list", "(", "filter", "(", "lambda", "x", ":", "x", "in", "PRINTABLE", ",", "text", ")", ")", ")", "\n", "if", "fine_grad", ":", "\n", "# tokenize by non-letters", "\n", "# Although we have will use corenlp for tokenizing later,", "\n", "# we still use the following tokenizer for fine granularity", "\n", "        ", "tokens", "=", "filter", "(", "lambda", "w", ":", "len", "(", "w", ")", ">", "0", ",", "re", ".", "split", "(", "r'[^a-zA-Z0-9_<>,\\(\\)\\.\\'%]'", ",", "text", ")", ")", "\n", "", "else", ":", "\n", "        ", "tokens", "=", "text", ".", "split", "(", ")", "\n", "# replace the digit terms with <digit>", "\n", "", "tokens", "=", "[", "w", "if", "not", "re", ".", "match", "(", "'^\\d+$'", ",", "w", ")", "else", "DIGIT", "for", "w", "in", "tokens", "]", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.data_utils.process_keyphrase": [[29, 46], ["keyword_str.replace", "re.sub.replace", "re.sub", "data_utils.get_tokens", "keyword.strip", "re.sub.split", "len", "len"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.data_utils.get_tokens"], ["", "def", "process_keyphrase", "(", "keyword_str", ",", "limit_num", "=", "True", ",", "fine_grad", "=", "True", ")", ":", "\n", "# replace some noise characters", "\n", "    ", "keyphrases", "=", "keyword_str", ".", "replace", "(", "'?'", ",", "''", ")", "\n", "# retrieved keyphrases are split by '<eos>'", "\n", "keyphrases", "=", "keyphrases", ".", "replace", "(", "'<eos>'", ",", "';'", ")", "\n", "# replace abbreviations", "\n", "keyphrases", "=", "re", ".", "sub", "(", "r'\\(.*?\\)'", ",", "''", ",", "keyphrases", ")", "\n", "# Note: keyword should be applied the same tokenizer as the source did", "\n", "keyphrases", "=", "[", "get_tokens", "(", "keyword", ".", "strip", "(", ")", ",", "fine_grad", ")", "for", "keyword", "in", "keyphrases", ".", "split", "(", "';'", ")", "]", "\n", "\n", "# ['key1a key1b', 'key2a key2b']", "\n", "if", "limit_num", ":", "\n", "        ", "keyphrases", "=", "[", "' '", ".", "join", "(", "key", ")", "for", "key", "in", "keyphrases", "if", "0", "<", "len", "(", "key", ")", "<=", "MAX_KEYWORD_LEN", "]", "\n", "", "else", ":", "\n", "        ", "keyphrases", "=", "[", "' '", ".", "join", "(", "key", ")", "for", "key", "in", "keyphrases", "if", "0", "<", "len", "(", "key", ")", "]", "\n", "\n", "", "return", "keyphrases", "\n", "", ""]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.train.main": [[14, 25], ["AssertionError", "AssertionError", "len", "onmt.train_multi.main", "onmt.train_single.main"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.main", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.main"], ["def", "main", "(", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "rnn_type", "==", "\"SRU\"", "and", "not", "opt", ".", "gpuid", ":", "\n", "        ", "raise", "AssertionError", "(", "\"Using SRU requires -gpuid set.\"", ")", "\n", "\n", "", "if", "opt", ".", "epochs", ":", "\n", "        ", "raise", "AssertionError", "(", "\"-epochs is deprecated please use -train_steps.\"", ")", "\n", "\n", "", "if", "len", "(", "opt", ".", "gpuid", ")", ">", "1", ":", "\n", "        ", "multi_main", "(", "opt", ")", "\n", "", "else", ":", "\n", "        ", "single_main", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.merge_rerank.get_extracted_keys_fr_line": [[18, 59], ["src_line.strip().split.strip().split", "float", "max", "len", "len", "len", "len", "ex_keys.append", "ex_probs.append", "round", "len", "src_line.strip().split.strip", "sel_probs_line.strip().split", "max", "sorted", "ex_key.append", "ex_prob.append", "len", "ex_keys.append", "ex_probs.append", "sum", "len", "zip", "sel_probs_line.strip"], "function", ["None"], ["def", "get_extracted_keys_fr_line", "(", "src_line", ",", "sel_probs_line", ",", "prob_th", "=", "0.7", ",", "ratio_th", "=", "0.3", ")", ":", "\n", "    ", "ex_keys", "=", "[", "]", "\n", "ex_probs", "=", "[", "]", "\n", "src_line", "=", "src_line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "sel_probs_line", "=", "[", "float", "(", "prob", ")", "for", "prob", "in", "sel_probs_line", ".", "strip", "(", ")", ".", "split", "(", "' ; '", ")", "]", "\n", "if", "max", "(", "sel_probs_line", ")", "<", "prob_th", ":", "\n", "        ", "prob_th", "=", "max", "(", "sel_probs_line", ")", "*", "0.8", "\n", "", "assert", "len", "(", "src_line", ")", "==", "len", "(", "sel_probs_line", ")", "\n", "idx", "=", "0", "\n", "previous_idx", "=", "-", "1", "\n", "ex_key", "=", "[", "]", "\n", "ex_prob", "=", "[", "]", "\n", "while", "idx", "<", "len", "(", "src_line", ")", ":", "\n", "        ", "if", "sel_probs_line", "[", "idx", "]", ">=", "prob_th", ":", "\n", "            ", "if", "idx", "==", "(", "previous_idx", "+", "1", ")", "or", "previous_idx", "==", "-", "1", ":", "\n", "                ", "ex_key", ".", "append", "(", "src_line", "[", "idx", "]", ")", "\n", "ex_prob", ".", "append", "(", "sel_probs_line", "[", "idx", "]", ")", "\n", "", "else", ":", "\n", "                ", "ex_key", "=", "[", "src_line", "[", "idx", "]", "]", "\n", "ex_prob", "=", "[", "sel_probs_line", "[", "idx", "]", "]", "\n", "", "previous_idx", "=", "idx", "\n", "", "elif", "len", "(", "ex_key", ")", "!=", "0", ":", "\n", "            ", "ex_keys", ".", "append", "(", "' '", ".", "join", "(", "ex_key", ")", ")", "\n", "ex_probs", ".", "append", "(", "ex_prob", ")", "\n", "\n", "previous_idx", "=", "-", "1", "\n", "ex_key", "=", "[", "]", "\n", "ex_prob", "=", "[", "]", "\n", "", "idx", "+=", "1", "\n", "", "if", "len", "(", "ex_key", ")", "!=", "0", ":", "\n", "        ", "ex_keys", ".", "append", "(", "' '", ".", "join", "(", "ex_key", ")", ")", "\n", "ex_probs", ".", "append", "(", "ex_prob", ")", "\n", "\n", "", "mean_ex_probs", "=", "[", "round", "(", "sum", "(", "ex_prob", ")", "/", "len", "(", "ex_prob", ")", ",", "5", ")", "for", "ex_prob", "in", "ex_probs", "]", "\n", "ranked_ex_keys_pair", "=", "[", "(", "x", ",", "prob", ")", "for", "x", ",", "prob", "in", "\n", "sorted", "(", "zip", "(", "ex_keys", ",", "mean_ex_probs", ")", ",", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "reverse", "=", "True", ")", "]", "\n", "ranked_ex_keys", "=", "[", "pair", "[", "0", "]", "for", "pair", "in", "ranked_ex_keys_pair", "]", "\n", "ranked_ex_probs", "=", "[", "pair", "[", "1", "]", "for", "pair", "in", "ranked_ex_keys_pair", "]", "\n", "assert", "len", "(", "ranked_ex_keys", ")", "!=", "0", "\n", "\n", "return", "ranked_ex_keys", ",", "ranked_ex_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.merge_rerank.get_extracted_keys": [[61, 72], ["open", "open.readlines", "open", "open.readlines", "open", "zip", "merge_rerank.get_extracted_keys_fr_line", "open.write"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.merge_rerank.get_extracted_keys_fr_line"], ["", "def", "get_extracted_keys", "(", "opt", ")", ":", "\n", "    ", "src_file", "=", "open", "(", "opt", ".", "src", ",", "encoding", "=", "'utf-8'", ")", "\n", "src_lines", "=", "src_file", ".", "readlines", "(", ")", "\n", "sel_probs", "=", "open", "(", "opt", ".", "sel_probs", ",", "encoding", "=", "'utf-8'", ")", "\n", "sel_probs_lines", "=", "sel_probs", ".", "readlines", "(", ")", "\n", "\n", "sel_keys_out", "=", "open", "(", "opt", ".", "sel_keys_output", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "for", "src_line", ",", "sel_probs_line", "in", "zip", "(", "src_lines", ",", "sel_probs_lines", ")", ":", "\n", "        ", "ex_keys", ",", "ex_probs", "=", "get_extracted_keys_fr_line", "(", "src_line", ",", "sel_probs_line", ")", "\n", "# mul_ex_probs = [round(numpy.prod(ex_prob), 5) for ex_prob in ex_probs]", "\n", "sel_keys_out", ".", "write", "(", "' ; '", ".", "join", "(", "ex_keys", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.merge_rerank.main1": [[74, 277], ["onmt.reranker.reranker_scorer.build_reranker_scorer", "open", "open.readlines", "open", "open.readlines", "logger.info", "open", "open.readlines", "open", "open.readlines", "open", "open", "open", "int", "range", "open.close", "open.close", "open.close", "logger.info", "evaluation_utils.evaluate_func", "len", "len", "len", "len", "open", "open.readlines", "open", "open.readlines", "open", "open.readlines", "len", "len", "min", "len", "zip", "len", "len", "len", "int", "range", "zip", "set", "open.write", "open.write", "len", "len", "len", "len", "logger.info", "tgt_line.strip().split", "gen_scores_line.strip().split", "key.strip.strip", "zip", "merge_rerank.get_extracted_keys_fr_line", "open.write", "math.ceil", "min", "onmt.reranker.reranker_scorer.build_reranker_scorer.scoring", "round", "len", "len", "round", "len", "len", "len", "len", "len", "len", "str", "len", "len", "len", "expand_tgt.append", "gen_scores.append", "rk_line.strip().split", "rsc_line.strip().split", "key.strip.strip", "round", "round", "len", "zip", "sorted", "sorted", "sorted", "tgt_line.strip", "gen_scores_line.strip", "float", "len", "expand_rk.append", "rk_scores.append", "sum", "sum", "sum", "sum", "len", "gt_keys_line.strip().split", "zip", "zip", "sorted", "sorted", "gen_sc.strip", "rk_line.strip", "rsc_line.strip", "float", "STEMMER.stem", "STEMMER.stem", "STEMMER.stem", "STEMMER.stem", "zip", "zip", "rk_sc.strip", "w.strip", "key.strip.split", "w.strip", "key.strip.split", "w.strip", "key.strip.split", "w.strip", "key.strip.split", "gt_keys_line.strip"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.build_reranker_scorer", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.evaluate_func", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.merge_rerank.get_extracted_keys_fr_line", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.scoring"], ["", "", "def", "main1", "(", "opt", ",", "logger", ")", ":", "\n", "    ", "reranker_scorer", "=", "build_reranker_scorer", "(", "opt", ")", "\n", "\n", "src_file", "=", "open", "(", "opt", ".", "src", ",", "encoding", "=", "'utf-8'", ")", "\n", "src_lines", "=", "src_file", ".", "readlines", "(", ")", "\n", "tgt_file", "=", "open", "(", "opt", ".", "tgt", ",", "encoding", "=", "'utf-8'", ")", "\n", "tgt_lines", "=", "tgt_file", ".", "readlines", "(", ")", "\n", "assert", "len", "(", "src_lines", ")", "==", "len", "(", "tgt_lines", ")", "\n", "logger", ".", "info", "(", "'Reranking {} ... '", ".", "format", "(", "opt", ".", "tgt", ")", ")", "\n", "\n", "# generated keyphrases", "\n", "gen_scores_file", "=", "open", "(", "opt", ".", "gen_scores", ",", "encoding", "=", "'utf-8'", ")", "\n", "gen_scores_lines", "=", "gen_scores_file", ".", "readlines", "(", ")", "\n", "assert", "len", "(", "tgt_lines", ")", "==", "len", "(", "gen_scores_lines", ")", "\n", "\n", "# retrieved keyphrases", "\n", "if", "opt", ".", "merge_rk_keys", ":", "\n", "        ", "retrieved_keys", "=", "open", "(", "opt", ".", "retrieved_keys", ",", "encoding", "=", "'utf-8'", ")", "\n", "rk_lines", "=", "retrieved_keys", ".", "readlines", "(", ")", "\n", "assert", "len", "(", "src_lines", ")", "==", "len", "(", "rk_lines", ")", "\n", "\n", "retrieved_scores", "=", "open", "(", "opt", ".", "retrieved_scores", ",", "encoding", "=", "'utf-8'", ")", "\n", "rsc_lines", "=", "retrieved_scores", ".", "readlines", "(", ")", "\n", "assert", "len", "(", "src_lines", ")", "==", "len", "(", "rsc_lines", ")", "\n", "\n", "# extracted key words", "\n", "", "if", "opt", ".", "merge_ex_keys", ":", "\n", "        ", "sel_probs", "=", "open", "(", "opt", ".", "sel_probs", ",", "encoding", "=", "'utf-8'", ")", "\n", "sel_probs_lines", "=", "sel_probs", ".", "readlines", "(", ")", "\n", "\n", "# ground_truth keywords", "\n", "", "gt_keys", "=", "open", "(", "opt", ".", "kpg_tgt", ",", "encoding", "=", "'utf-8'", ")", "\n", "gt_keys_lines", "=", "gt_keys", ".", "readlines", "(", ")", "\n", "assert", "len", "(", "src_lines", ")", "==", "len", "(", "gt_keys_lines", ")", "\n", "\n", "sel_keys_out", "=", "open", "(", "opt", ".", "sel_keys_output", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "out_file", "=", "open", "(", "opt", ".", "reranked_scores_output", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "reranked_out_file", "=", "open", "(", "opt", ".", "output", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n", "report_every", "=", "int", "(", "min", "(", "len", "(", "src_lines", ")", "/", "10", ",", "200", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "src_lines", ")", ")", ":", "\n", "        ", "if", "(", "i", "+", "1", ")", "%", "report_every", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "'{} papers complete!'", ".", "format", "(", "i", "+", "1", ")", ")", "\n", "", "src_line", "=", "src_lines", "[", "i", "]", "\n", "tgt_line", "=", "tgt_lines", "[", "i", "]", "\n", "gen_scores_line", "=", "gen_scores_lines", "[", "i", "]", "\n", "gt_keys_line", "=", "gt_keys_lines", "[", "i", "]", "\n", "\n", "# get the predicted keys and scores by the generator", "\n", "gen_scores", "=", "[", "]", "\n", "expand_tgt", "=", "[", "]", "\n", "for", "key", ",", "gen_sc", "in", "zip", "(", "tgt_line", ".", "strip", "(", ")", ".", "split", "(", "' ; '", ")", ",", "gen_scores_line", ".", "strip", "(", ")", ".", "split", "(", "' ; '", ")", ")", ":", "\n", "            ", "key", "=", "key", ".", "strip", "(", ")", "\n", "if", "len", "(", "key", ")", ">", "2", ":", "\n", "                ", "expand_tgt", ".", "append", "(", "key", ")", "\n", "gen_scores", ".", "append", "(", "float", "(", "gen_sc", ".", "strip", "(", ")", ")", ")", "\n", "", "", "gen_num", "=", "len", "(", "expand_tgt", ")", "\n", "\n", "# get the predicted keys and scores by the retriever", "\n", "rk_scores", "=", "[", "]", "\n", "expand_rk", "=", "[", "]", "\n", "if", "opt", ".", "merge_rk_keys", ":", "\n", "            ", "rk_line", "=", "rk_lines", "[", "i", "]", "\n", "rsc_line", "=", "rsc_lines", "[", "i", "]", "\n", "for", "key", ",", "rk_sc", "in", "zip", "(", "rk_line", ".", "strip", "(", ")", ".", "split", "(", "' <eos> '", ")", ",", "rsc_line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", ":", "\n", "                ", "key", "=", "key", ".", "strip", "(", ")", "\n", "if", "len", "(", "key", ")", ">", "2", ":", "\n", "                    ", "expand_rk", ".", "append", "(", "key", ")", "\n", "rk_scores", ".", "append", "(", "float", "(", "rk_sc", ".", "strip", "(", ")", ")", ")", "\n", "", "", "", "rk_num", "=", "len", "(", "expand_rk", ")", "\n", "\n", "# get the extracted keys and predicted scores by the extactor", "\n", "ex_keys", "=", "[", "]", "\n", "ex_scores", "=", "[", "]", "\n", "if", "opt", ".", "merge_ex_keys", ":", "\n", "            ", "sel_probs_line", "=", "sel_probs_lines", "[", "i", "]", "\n", "ex_keys", ",", "ex_scores", "=", "get_extracted_keys_fr_line", "(", "src_line", ",", "sel_probs_line", ")", "\n", "# store the extracted keys", "\n", "sel_keys_out", ".", "write", "(", "' ; '", ".", "join", "(", "ex_keys", ")", "+", "'\\n'", ")", "\n", "", "ex_num", "=", "len", "(", "ex_keys", ")", "\n", "\n", "expand_src", "=", "[", "src_line", "]", "*", "(", "gen_num", "+", "rk_num", "+", "ex_num", ")", "\n", "merged_tgt", "=", "expand_tgt", "+", "expand_rk", "+", "ex_keys", "\n", "\n", "# dynamically give weights to rk_scores", "\n", "rescaled_rk_scores", "=", "[", "]", "\n", "if", "rk_num", "!=", "0", ":", "\n", "            ", "rk_lambda", "=", "(", "sum", "(", "gen_scores", ")", "/", "gen_num", ")", "/", "(", "sum", "(", "rk_scores", ")", "/", "rk_num", ")", "\n", "rescaled_rk_scores", "=", "[", "round", "(", "rk_sc", "*", "rk_lambda", ",", "5", ")", "for", "rk_sc", "in", "rk_scores", "]", "\n", "# dynamically give weights to ex_scores", "\n", "", "rescaled_ex_scores", "=", "[", "]", "\n", "if", "ex_num", "!=", "0", ":", "\n", "            ", "ex_lambda", "=", "(", "(", "sum", "(", "gen_scores", ")", "/", "gen_num", ")", "/", "(", "sum", "(", "ex_scores", ")", "/", "ex_num", ")", ")", "\n", "rescaled_ex_scores", "=", "[", "round", "(", "ex_sc", "*", "ex_lambda", ",", "5", ")", "for", "ex_sc", "in", "ex_scores", "]", "\n", "\n", "", "merged_scores", "=", "gen_scores", "+", "rescaled_rk_scores", "+", "rescaled_ex_scores", "\n", "\n", "scored_triplets", "=", "[", "]", "\n", "loop_num", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "merged_tgt", ")", "/", "100", ")", ")", "\n", "for", "loop_idx", "in", "range", "(", "loop_num", ")", ":", "\n", "            ", "start_idx", "=", "loop_idx", "*", "100", "\n", "end_idx", "=", "min", "(", "(", "loop_idx", "+", "1", ")", "*", "100", ",", "len", "(", "merged_tgt", ")", ")", "\n", "scored_triplets_tmp", "=", "reranker_scorer", ".", "scoring", "(", "src_data_iter", "=", "expand_src", "[", "start_idx", ":", "end_idx", "]", ",", "\n", "tgt_data_iter", "=", "merged_tgt", "[", "start_idx", ":", "end_idx", "]", ")", "\n", "scored_triplets", "=", "scored_triplets", "+", "scored_triplets_tmp", "\n", "\n", "", "reranker_scores", "=", "[", "round", "(", "triplet", "[", "'score'", "]", ",", "5", ")", "for", "triplet", "in", "scored_triplets", "]", "\n", "assert", "len", "(", "reranker_scores", ")", "==", "len", "(", "merged_scores", ")", "\n", "rescaled_scores", "=", "[", "round", "(", "re_sc", "*", "mg_sc", ",", "8", ")", "for", "re_sc", ",", "mg_sc", "in", "zip", "(", "reranker_scores", ",", "merged_scores", ")", "]", "\n", "\n", "# get the statistics of the gen_keys and rk_keys", "\n", "if", "opt", ".", "merge_with_stemmer", ":", "\n", "            ", "stemmed_expand_tgt", "=", "[", "' '", ".", "join", "(", "[", "STEMMER", ".", "stem", "(", "w", ".", "strip", "(", ")", ")", "for", "w", "in", "key", ".", "split", "(", ")", "]", ")", "for", "key", "in", "expand_tgt", "]", "\n", "stemmed_rk_keys", "=", "[", "' '", ".", "join", "(", "[", "STEMMER", ".", "stem", "(", "w", ".", "strip", "(", ")", ")", "for", "w", "in", "key", ".", "split", "(", ")", "]", ")", "for", "key", "in", "expand_rk", "]", "\n", "stemmed_ex_keys", "=", "[", "' '", ".", "join", "(", "[", "STEMMER", ".", "stem", "(", "w", ".", "strip", "(", ")", ")", "for", "w", "in", "key", ".", "split", "(", ")", "]", ")", "for", "key", "in", "ex_keys", "]", "\n", "stemmed_mg_keys", "=", "stemmed_expand_tgt", "+", "stemmed_rk_keys", "+", "stemmed_ex_keys", "\n", "", "else", ":", "\n", "            ", "stemmed_expand_tgt", "=", "expand_tgt", "\n", "stemmed_rk_keys", "=", "expand_rk", "\n", "stemmed_ex_keys", "=", "ex_keys", "\n", "stemmed_mg_keys", "=", "stemmed_expand_tgt", "+", "stemmed_rk_keys", "+", "stemmed_ex_keys", "\n", "# stemmed_gt_keys_set = gt_keys_line.strip().split(' ; ')", "\n", "\n", "", "stem_map", "=", "{", "}", "\n", "for", "stemmed_key", ",", "key", "in", "zip", "(", "stemmed_mg_keys", ",", "merged_tgt", ")", ":", "\n", "            ", "if", "stemmed_key", "not", "in", "stem_map", ":", "\n", "                ", "stem_map", "[", "stemmed_key", "]", "=", "key", "\n", "\n", "", "", "stemmed_gt_keys_set", "=", "set", "(", "\n", "[", "' '", ".", "join", "(", "[", "STEMMER", ".", "stem", "(", "w", ".", "strip", "(", ")", ")", "for", "w", "in", "key", ".", "split", "(", ")", "]", ")", "for", "key", "in", "gt_keys_line", ".", "strip", "(", ")", ".", "split", "(", "' ; '", ")", "]", ")", "\n", "\n", "# get the reranked results W/O merging the duplicates among gen_keys, rk_keys and ex_keys", "\n", "no_merge_sc_reranked_pair", "=", "[", "(", "x", ",", "sc", ")", "for", "x", ",", "sc", "in", "sorted", "(", "\n", "zip", "(", "stemmed_mg_keys", ",", "rescaled_scores", ")", ",", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "\n", "reverse", "=", "True", ")", "]", "\n", "no_merge_sc_reranked_tgt", "=", "[", "x", "for", "x", ",", "_", "in", "no_merge_sc_reranked_pair", "]", "\n", "\n", "no_merge_sc_reranked_gen_pair", "=", "[", "(", "x", ",", "sc", ")", "for", "x", ",", "sc", "in", "sorted", "(", "\n", "zip", "(", "stemmed_mg_keys", "[", ":", "gen_num", "]", ",", "rescaled_scores", "[", ":", "gen_num", "]", ")", ",", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "\n", "reverse", "=", "True", ")", "]", "\n", "assert", "len", "(", "no_merge_sc_reranked_gen_pair", ")", "==", "len", "(", "expand_tgt", ")", "\n", "\n", "no_merge_sc_reranked_rk_pair", "=", "[", "]", "\n", "if", "opt", ".", "merge_rk_keys", ":", "\n", "            ", "no_merge_sc_reranked_rk_pair", "=", "[", "(", "x", ",", "sc", ")", "for", "x", ",", "sc", "in", "sorted", "(", "\n", "zip", "(", "stemmed_mg_keys", "[", "gen_num", ":", "gen_num", "+", "rk_num", "]", ",", "rescaled_scores", "[", "gen_num", ":", "gen_num", "+", "rk_num", "]", ")", ",", "\n", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "reverse", "=", "True", ")", "]", "\n", "", "assert", "len", "(", "no_merge_sc_reranked_rk_pair", ")", "==", "len", "(", "expand_rk", ")", "\n", "\n", "no_merge_sc_reranked_ex_pair", "=", "[", "]", "\n", "if", "opt", ".", "merge_ex_keys", ":", "\n", "            ", "no_merge_sc_reranked_ex_pair", "=", "[", "(", "x", ",", "sc", ")", "for", "x", ",", "sc", "in", "sorted", "(", "\n", "zip", "(", "stemmed_mg_keys", "[", "gen_num", "+", "rk_num", ":", "]", ",", "rescaled_scores", "[", "gen_num", "+", "rk_num", ":", "]", ")", ",", "key", "=", "lambda", "pair", ":", "pair", "[", "1", "]", ",", "\n", "reverse", "=", "True", ")", "]", "\n", "", "assert", "len", "(", "no_merge_sc_reranked_ex_pair", ")", "==", "len", "(", "ex_keys", ")", "\n", "\n", "# get the reranked results W/ merging the duplicates between gen_keys and rk_keys", "\n", "final_candies_set", "=", "{", "}", "\n", "sc_from_rk", "=", "{", "}", "\n", "sc_from_ex", "=", "{", "}", "\n", "for", "stemmed_mg_tgt", ",", "sc", "in", "no_merge_sc_reranked_gen_pair", ":", "\n", "            ", "if", "stemmed_mg_tgt", "not", "in", "final_candies_set", ":", "\n", "                ", "final_candies_set", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "sc_from_rk", "[", "stemmed_mg_tgt", "]", "=", "0.0", "\n", "sc_from_ex", "[", "stemmed_mg_tgt", "]", "=", "0.0", "\n", "\n", "", "", "if", "opt", ".", "merge_rk_keys", ":", "\n", "            ", "for", "stemmed_mg_tgt", ",", "sc", "in", "no_merge_sc_reranked_rk_pair", ":", "\n", "                ", "if", "stemmed_mg_tgt", "in", "final_candies_set", ":", "\n", "                    ", "if", "sc_from_rk", "[", "stemmed_mg_tgt", "]", "==", "0.0", ":", "\n", "                        ", "final_candies_set", "[", "stemmed_mg_tgt", "]", "+=", "sc", "\n", "sc_from_rk", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "", "", "else", ":", "\n", "                    ", "final_candies_set", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "sc_from_rk", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "sc_from_ex", "[", "stemmed_mg_tgt", "]", "=", "0.0", "\n", "\n", "", "", "", "if", "opt", ".", "merge_ex_keys", ":", "\n", "            ", "for", "stemmed_mg_tgt", ",", "sc", "in", "no_merge_sc_reranked_ex_pair", ":", "\n", "                ", "if", "stemmed_mg_tgt", "in", "final_candies_set", ":", "\n", "                    ", "if", "sc_from_ex", "[", "stemmed_mg_tgt", "]", "==", "0.0", ":", "\n", "                        ", "final_candies_set", "[", "stemmed_mg_tgt", "]", "+=", "sc", "\n", "sc_from_ex", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "", "", "else", ":", "\n", "                    ", "final_candies_set", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "sc_from_ex", "[", "stemmed_mg_tgt", "]", "=", "sc", "\n", "\n", "", "", "", "fn_reranked_tgt", "=", "[", "x", "for", "x", "in", "sorted", "(", "final_candies_set", ",", "key", "=", "final_candies_set", ".", "get", ",", "reverse", "=", "True", ")", "]", "\n", "\n", "# store the final scores of each keyphrase candidate", "\n", "scores_str", "=", "[", "str", "(", "final_candies_set", "[", "fn_key", "]", ")", "for", "fn_key", "in", "fn_reranked_tgt", "]", "\n", "score_line", "=", "' ; '", ".", "join", "(", "scores_str", ")", "+", "'\\n'", "\n", "out_file", ".", "write", "(", "score_line", ")", "\n", "# store the final merged and reranked keyphrase candidates", "\n", "fn_reranked_tgt", "=", "[", "stem_map", "[", "fn_key", "]", "for", "fn_key", "in", "fn_reranked_tgt", "]", "\n", "fn_reranked_tgt_line", "=", "' ; '", ".", "join", "(", "fn_reranked_tgt", ")", "+", "'\\n'", "\n", "reranked_out_file", ".", "write", "(", "fn_reranked_tgt_line", ")", "\n", "", "reranked_out_file", ".", "close", "(", ")", "\n", "out_file", ".", "close", "(", ")", "\n", "sel_keys_out", ".", "close", "(", ")", "\n", "logger", ".", "info", "(", "'{} papers complete!'", ".", "format", "(", "len", "(", "src_lines", ")", ")", ")", "\n", "# evaluate the final predictions", "\n", "evaluate_func", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.check_existing_pt_files": [[20, 31], ["glob.glob", "sys.stderr.write", "sys.exit"], "function", ["None"], ["def", "check_existing_pt_files", "(", "opt", ")", ":", "\n", "    ", "\"\"\" Checking if there are existing .pt files to avoid tampering \"\"\"", "\n", "# We will use glob.glob() to find sharded {train|valid}.[0-9]*.pt", "\n", "# when training, so check to avoid tampering with existing pt files", "\n", "# or mixing them up.", "\n", "for", "t", "in", "[", "'train'", ",", "'valid'", ",", "'vocab'", "]", ":", "\n", "        ", "pattern", "=", "opt", ".", "save_data", "+", "'.'", "+", "t", "+", "'*.pt'", "\n", "if", "glob", ".", "glob", "(", "pattern", ")", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "\"Please backup existing pt file: %s, \"", "\n", "\"to avoid tampering!\\n\"", "%", "pattern", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.parse_args": [[33, 48], ["argparse.ArgumentParser", "onmt.add_md_help_argument", "onmt.preprocess_opts", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "preprocess.check_existing_pt_files"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.add_md_help_argument", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.preprocess_opts", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.parse_args", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.check_existing_pt_files"], ["", "", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "\"\"\" Parsing arguments \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "'preprocess.py'", ",", "\n", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "\n", "opts", ".", "add_md_help_argument", "(", "parser", ")", "\n", "opts", ".", "preprocess_opts", "(", "parser", ")", "\n", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "seed", ")", "\n", "\n", "check_existing_pt_files", "(", "opt", ")", "\n", "\n", "return", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.build_save_in_shards": [[50, 126], ["os.path.getsize", "onmt.ShardedTextCorpusIterator", "onmt.ShardedTextCorpusIterator", "onmt.ShardedTextCorpusIterator", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "inputters.ShardedTextCorpusIterator.hit_end", "onmt.TextDataset", "onmt.utils.logging.logger.info", "torch.save", "ret_list.append"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.text_dataset.ShardedTextCorpusIterator.hit_end"], ["", "def", "build_save_in_shards", "(", "src_corpus", ",", "tgt_corpus", ",", "key_indicators", ",", "retrieved_keys", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", ":", "\n", "    ", "\"\"\"\n    Divide the big corpus into shards, and build dataset separately.\n    This is currently only for data_type=='text'.\n\n    The reason we do this is to avoid taking up too much memory due\n    to sucking in a huge corpus file.\n\n    To tackle this, we only read in part of the corpus file of size\n    `max_shard_size`(actually it is multiples of 64 bytes that equals\n    or is slightly larger than this size), and process it into dataset,\n    then write it to disk along the way. By doing this, we only focus on\n    part of the corpus at any moment, thus effectively reducing memory use.\n    According to test, this method can reduce memory footprint by ~50%.\n\n    Note! As we process along the shards, previous shards might still\n    stay in memory, but since we are done with them, and no more\n    reference to them, if there is memory tight situation, the OS could\n    easily reclaim these memory.\n\n    If `max_shard_size` is 0 or is larger than the corpus size, it is\n    effectively preprocessed into one dataset, i.e. no sharding.\n\n    NOTE! `max_shard_size` is measuring the input corpus size, not the\n    output pt file size. So a shard pt file consists of examples of size\n    2 * `max_shard_size`(source + target).\n    \"\"\"", "\n", "\n", "corpus_size", "=", "os", ".", "path", ".", "getsize", "(", "src_corpus", ")", "\n", "if", "corpus_size", ">", "10", "*", "(", "1024", "**", "2", ")", "and", "opt", ".", "max_shard_size", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\"Warning. The corpus %s is larger than 10M bytes, \"", "\n", "\"you can set '-max_shard_size' to process it by \"", "\n", "\"small shards to use less memory.\"", "%", "src_corpus", ")", "\n", "\n", "", "if", "opt", ".", "max_shard_size", "!=", "0", ":", "\n", "        ", "logger", ".", "info", "(", "' * divide corpus into shards and build dataset '", "\n", "'separately (shard_size = %d bytes).'", "\n", "%", "opt", ".", "max_shard_size", ")", "\n", "\n", "", "ret_list", "=", "[", "]", "\n", "src_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "src_corpus", ",", "opt", ".", "src_seq_length_trunc", ",", "\n", "\"src\"", ",", "opt", ".", "max_shard_size", ")", "\n", "\n", "# KE-KG-KR-M: add for KE", "\n", "key_indicators_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "key_indicators", ",", "opt", ".", "src_seq_length_trunc", ",", "\n", "\"key_indicators\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "# KE-KG-KR-M: add for RK", "\n", "retrieved_keys_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "retrieved_keys", ",", "0", ",", "\n", "\"retrieved_keys\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "\n", "tgt_iter", "=", "inputters", ".", "ShardedTextCorpusIterator", "(", "\n", "tgt_corpus", ",", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "\"tgt\"", ",", "opt", ".", "max_shard_size", ",", "\n", "assoc_iter", "=", "src_iter", ")", "\n", "\n", "index", "=", "0", "\n", "while", "not", "src_iter", ".", "hit_end", "(", ")", ":", "\n", "        ", "index", "+=", "1", "\n", "dataset", "=", "inputters", ".", "TextDataset", "(", "\n", "fields", ",", "src_iter", ",", "key_indicators_iter", ",", "retrieved_keys_iter", ",", "tgt_iter", ",", "\n", "src_iter", ".", "num_feats", ",", "tgt_iter", ".", "num_feats", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ")", "\n", "\n", "# We save fields in vocab.pt separately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.{:d}.pt\"", ".", "format", "(", "\n", "opt", ".", "save_data", ",", "corpus_type", ",", "index", ")", "\n", "logger", ".", "info", "(", "\" * saving %s data shard to %s. %d examples.\"", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.build_save_dataset": [[128, 176], ["onmt.build_dataset", "onmt.utils.logging.logger.info", "torch.save", "preprocess.build_save_in_shards"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.build_save_in_shards"], ["torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "ret_list", ".", "append", "(", "pt_file", ")", "\n", "\n", "", "return", "ret_list", "\n", "\n", "\n", "", "def", "build_save_dataset", "(", "corpus_type", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "\"\"\" Building and saving the dataset \"\"\"", "\n", "assert", "corpus_type", "in", "[", "'train'", ",", "'valid'", "]", "\n", "\n", "if", "corpus_type", "==", "'train'", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "train_src", "\n", "tgt_corpus", "=", "opt", ".", "train_tgt", "\n", "# KE-KG-KR-M: add for KE", "\n", "key_indicators", "=", "opt", ".", "train_key_indicators", "\n", "# KE-KG-KR-M: add for RK", "\n", "retrieved_keys", "=", "opt", ".", "train_retrieved_keys", "\n", "", "else", ":", "\n", "        ", "src_corpus", "=", "opt", ".", "valid_src", "\n", "tgt_corpus", "=", "opt", ".", "valid_tgt", "\n", "# KE-KG-KR-M: add for KE", "\n", "key_indicators", "=", "opt", ".", "valid_key_indicators", "\n", "# KE-KG-KR-M: add for RK", "\n", "retrieved_keys", "=", "opt", ".", "valid_retrieved_keys", "\n", "\n", "# Currently we only do preprocess sharding for corpus: data_type=='text'.", "\n", "", "if", "opt", ".", "data_type", "==", "'text'", ":", "\n", "        ", "return", "build_save_in_shards", "(", "\n", "src_corpus", ",", "tgt_corpus", ",", "key_indicators", ",", "retrieved_keys", ",", "fields", ",", "\n", "corpus_type", ",", "opt", ")", "\n", "\n", "# For data_type == 'img' or 'audio', currently we don't do", "\n", "# preprocess sharding. We only build a monolithic dataset.", "\n", "# But since the interfaces are uniform, it would be not hard", "\n", "# to do this should users need this feature.", "\n", "", "dataset", "=", "inputters", ".", "build_dataset", "(", "\n", "fields", ",", "opt", ".", "data_type", ",", "\n", "src_path", "=", "src_corpus", ",", "\n", "tgt_path", "=", "tgt_corpus", ",", "\n", "src_dir", "=", "opt", ".", "src_dir", ",", "\n", "src_seq_length", "=", "opt", ".", "src_seq_length", ",", "\n", "tgt_seq_length", "=", "opt", ".", "tgt_seq_length", ",", "\n", "src_seq_length_trunc", "=", "opt", ".", "src_seq_length_trunc", ",", "\n", "tgt_seq_length_trunc", "=", "opt", ".", "tgt_seq_length_trunc", ",", "\n", "dynamic_dict", "=", "opt", ".", "dynamic_dict", ",", "\n", "sample_rate", "=", "opt", ".", "sample_rate", ",", "\n", "window_size", "=", "opt", ".", "window_size", ",", "\n", "window_stride", "=", "opt", ".", "window_stride", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.build_save_vocab": [[178, 192], ["onmt.build_vocab", "torch.save", "onmt.save_fields_to_vocab"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.save_fields_to_vocab"], ["\n", "# We save fields in vocab.pt seperately, so make it empty.", "\n", "dataset", ".", "fields", "=", "[", "]", "\n", "\n", "pt_file", "=", "\"{:s}.{:s}.pt\"", ".", "format", "(", "opt", ".", "save_data", ",", "corpus_type", ")", "\n", "logger", ".", "info", "(", "\" * saving %s dataset to %s.\"", "%", "(", "corpus_type", ",", "pt_file", ")", ")", "\n", "torch", ".", "save", "(", "dataset", ",", "pt_file", ")", "\n", "\n", "return", "[", "pt_file", "]", "\n", "\n", "\n", "", "def", "build_save_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ")", ":", "\n", "    ", "\"\"\" Building and saving the vocab \"\"\"", "\n", "fields", "=", "inputters", ".", "build_vocab", "(", "train_dataset", ",", "fields", ",", "opt", ".", "data_type", ",", "\n", "opt", ".", "share_vocab", ",", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.main": [[194, 217], ["preprocess.parse_args", "onmt.utils.logging.init_logger", "onmt.utils.logging.logger.info", "onmt.get_num_features", "onmt.get_num_features", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.utils.logging.logger.info", "onmt.get_fields", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset", "onmt.utils.logging.logger.info", "preprocess.build_save_vocab", "onmt.utils.logging.logger.info", "preprocess.build_save_dataset"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.parse_args", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.logging.init_logger", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_num_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.audio_dataset.AudioDataset.get_fields", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.build_save_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.build_save_vocab", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.preprocess.build_save_dataset"], ["opt", ".", "src_vocab_size", ",", "\n", "opt", ".", "src_words_min_frequency", ",", "\n", "opt", ".", "tgt_vocab", ",", "\n", "opt", ".", "tgt_vocab_size", ",", "\n", "opt", ".", "tgt_words_min_frequency", ")", "\n", "\n", "# Can't save fields, so remove/reconstruct at training time.", "\n", "vocab_file", "=", "opt", ".", "save_data", "+", "'.vocab.pt'", "\n", "torch", ".", "save", "(", "inputters", ".", "save_fields_to_vocab", "(", "fields", ")", ",", "vocab_file", ")", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "opt", "=", "parse_args", "(", ")", "\n", "init_logger", "(", "opt", ".", "log_file", ")", "\n", "logger", ".", "info", "(", "\"Extracting features...\"", ")", "\n", "\n", "src_nfeats", "=", "inputters", ".", "get_num_features", "(", "\n", "opt", ".", "data_type", ",", "opt", ".", "train_src", ",", "'src'", ")", "\n", "tgt_nfeats", "=", "inputters", ".", "get_num_features", "(", "\n", "opt", ".", "data_type", ",", "opt", ".", "train_tgt", ",", "'tgt'", ")", "\n", "logger", ".", "info", "(", "\" * number of source features: %d.\"", "%", "src_nfeats", ")", "\n", "logger", ".", "info", "(", "\" * number of target features: %d.\"", "%", "tgt_nfeats", ")", "\n", "\n", "logger", ".", "info", "(", "\"Building `Fields` object...\"", ")", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.evaluate_func": [[12, 186], ["open", "open.readlines", "open", "open.readlines", "open", "open.readlines", "PorterStemmer", "zip", "print", "print", "print", "print", "print", "print", "print", "print", "print", "evaluation_utils.map_score_fc", "evaluation_utils.map_score_fc", "evaluation_utils.map_score_fc", "evaluation_utils.micro_ave_fc", "evaluation_utils.micro_ave_fc", "evaluation_utils.micro_ave_fc", "len", "len", "len", "len", "data_utils.process_keyphrase", "data_utils.process_keyphrase.replace", "data_utils.process_keyphrase", "set", "set", "set", "context.strip.split", "set", "set", "present_target_lens_list.append", "absent_target_lens_list.append", "total_target_lens_list.append", "len", "len", "len", "len", "len", "macro_metrics[].append", "macro_metrics[].append", "macro_metrics[].append", "print", "data_utils.process_keyphrase.strip", "data_utils.process_keyphrase.strip", "data_utils.get_tokens", "context.strip.strip", "len", "len", "len", "len", "len", "len", "len", "total_correctly_matched_at[].append", "present_correctly_matched_at[].append", "absent_correctly_matched_at[].append", "evaluation_utils.macro_metric_fc", "evaluation_utils.macro_metric_fc", "evaluation_utils.macro_metric_fc", "opts.kpg_tgt.lower", "tgt.split", "evaluation_utils.in_context2", "set.add", "set.add", "evaluation_utils.in_context2", "time.strftime", "PorterStemmer.stem", "len", "pred.split", "total_preds.append", "present_preds.append", "set.add", "total_preds.append", "absent_preds.append", "set.add", "context.strip.strip().split", "PorterStemmer.stem", "pred.split", "int", "int", "int", "PorterStemmer.stem", "keyphrase.split", "context.strip.strip", "keyphrase.split", "keyphrase.split"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.map_score_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.map_score_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.map_score_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.micro_ave_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.micro_ave_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.micro_ave_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.data_utils.process_keyphrase", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.data_utils.process_keyphrase", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.data_utils.get_tokens", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.macro_metric_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.macro_metric_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.macro_metric_fc", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.in_context2", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.in_context2"], ["def", "evaluate_func", "(", "opts", ",", "do_stem", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    calculate the macro-averaged precesion, recall and F1 score\n    \"\"\"", "\n", "context_file", "=", "open", "(", "opts", ".", "kpg_context", ",", "encoding", "=", "'utf-8'", ")", "\n", "context_lines", "=", "context_file", ".", "readlines", "(", ")", "\n", "\n", "target_file", "=", "open", "(", "opts", ".", "kpg_tgt", ",", "encoding", "=", "'utf-8'", ")", "\n", "target_lines", "=", "target_file", ".", "readlines", "(", ")", "\n", "\n", "preds_file", "=", "open", "(", "opts", ".", "output", ",", "encoding", "=", "'utf-8'", ")", "\n", "preds_lines", "=", "preds_file", ".", "readlines", "(", ")", "\n", "\n", "# the number of examples should be the same", "\n", "assert", "len", "(", "context_lines", ")", "==", "len", "(", "preds_lines", ")", "\n", "assert", "len", "(", "preds_lines", ")", "==", "len", "(", "target_lines", ")", "\n", "\n", "stemmer", "=", "PorterStemmer", "(", ")", "\n", "num_groundtruth", "=", "0", "\n", "num_present_groundtruth", "=", "0", "\n", "num_absent_groundtruth", "=", "0", "\n", "min_num_present_preds", "=", "1000", "\n", "min_num_absent_preds", "=", "1000", "\n", "ave_num_present_preds", "=", "0", "\n", "ave_num_absent_preds", "=", "0", "\n", "\n", "macro_metrics", "=", "{", "'total'", ":", "[", "]", ",", "'present'", ":", "[", "]", ",", "'absent'", ":", "[", "]", "}", "\n", "cnt", "=", "1", "\n", "present_correctly_matched_at", "=", "{", "'5'", ":", "[", "]", ",", "'10'", ":", "[", "]", ",", "'15'", ":", "[", "]", ",", "'50'", ":", "[", "]", "}", "\n", "absent_correctly_matched_at", "=", "{", "'5'", ":", "[", "]", ",", "'10'", ":", "[", "]", ",", "'15'", ":", "[", "]", ",", "'50'", ":", "[", "]", "}", "\n", "total_correctly_matched_at", "=", "{", "'5'", ":", "[", "]", ",", "'10'", ":", "[", "]", ",", "'15'", ":", "[", "]", ",", "'50'", ":", "[", "]", "}", "\n", "present_target_lens_list", "=", "[", "]", "\n", "absent_target_lens_list", "=", "[", "]", "\n", "total_target_lens_list", "=", "[", "]", "\n", "for", "context", ",", "targets", ",", "preds", "in", "zip", "(", "context_lines", ",", "target_lines", ",", "preds_lines", ")", ":", "\n", "        ", "if", "cnt", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "time", ".", "strftime", "(", "'%H:%M:%S'", ")", "+", "': {} papers evaluation complete!'", ".", "format", "(", "cnt", ")", ")", "\n", "# preprocess predictions and targets to a list ['key1a key1b', 'key2a key2b']", "\n", "", "targets", "=", "process_keyphrase", "(", "targets", ".", "strip", "(", ")", ",", "limit_num", "=", "False", ",", "fine_grad", "=", "True", ")", "\n", "preds", "=", "preds", ".", "replace", "(", "opts", ".", "splitter", ",", "';'", ")", "\n", "preds", "=", "process_keyphrase", "(", "preds", ".", "strip", "(", ")", ",", "limit_num", "=", "False", ",", "fine_grad", "=", "True", ")", "\n", "# preprocess context in a fine-gradularity: [word1, word2,..., wordk,...]", "\n", "context", "=", "' '", ".", "join", "(", "get_tokens", "(", "context", ",", "fine_grad", "=", "True", ")", ")", "\n", "\n", "# stem words in context, target, pred, if needed", "\n", "if", "do_stem", ":", "\n", "            ", "context", "=", "' '", ".", "join", "(", "[", "stemmer", ".", "stem", "(", "w", ")", "for", "w", "in", "context", ".", "strip", "(", ")", ".", "split", "(", ")", "]", ")", "\n", "# the gold keyphrases of SemEval testing dataset are already stemmed", "\n", "if", "'semeval'", "in", "opts", ".", "kpg_tgt", ".", "lower", "(", ")", ":", "\n", "                ", "targets", "=", "[", "' '", ".", "join", "(", "[", "w", "for", "w", "in", "keyphrase", ".", "split", "(", ")", "]", ")", "for", "keyphrase", "in", "targets", "]", "\n", "", "else", ":", "\n", "                ", "targets", "=", "[", "' '", ".", "join", "(", "[", "stemmer", ".", "stem", "(", "w", ")", "for", "w", "in", "keyphrase", ".", "split", "(", ")", "]", ")", "for", "keyphrase", "in", "targets", "]", "\n", "", "preds", "=", "[", "' '", ".", "join", "(", "[", "stemmer", ".", "stem", "(", "w", ")", "for", "w", "in", "keyphrase", ".", "split", "(", ")", "]", ")", "for", "keyphrase", "in", "preds", "]", "\n", "", "else", ":", "\n", "            ", "context", "=", "context", ".", "strip", "(", ")", "\n", "\n", "", "if", "opts", ".", "filter_dot_comma_unk", ":", "\n", "            ", "targets", "=", "[", "keyphrase", "for", "keyphrase", "in", "targets", "if", "','", "not", "in", "keyphrase", "and", "'.'", "not", "in", "keyphrase", "and", "'<unk>'", "not", "in", "keyphrase", "]", "\n", "preds", "=", "[", "keyphrase", "for", "keyphrase", "in", "preds", "if", "','", "not", "in", "keyphrase", "and", "'.'", "not", "in", "keyphrase", "and", "'<unk>'", "not", "in", "keyphrase", "]", "\n", "\n", "# get the present_tgt_keyphrase, absent_tgt_keyphrase", "\n", "", "present_tgt_set", "=", "set", "(", ")", "\n", "absent_tgt_set", "=", "set", "(", ")", "\n", "total_tgt_set", "=", "set", "(", "targets", ")", "\n", "context_list", "=", "context", ".", "split", "(", ")", "\n", "\n", "for", "tgt", "in", "targets", ":", "\n", "            ", "if", "opts", ".", "match_method", "==", "'word_match'", ":", "\n", "                ", "tgt_list", "=", "tgt", ".", "split", "(", ")", "\n", "match", "=", "in_context2", "(", "context_list", ",", "tgt_list", ")", "\n", "", "else", ":", "\n", "                ", "match", "=", "tgt", "in", "context", "\n", "", "if", "match", ":", "\n", "                ", "present_tgt_set", ".", "add", "(", "tgt", ")", "\n", "", "else", ":", "\n", "                ", "absent_tgt_set", ".", "add", "(", "tgt", ")", "\n", "\n", "", "", "present_preds", "=", "[", "]", "\n", "present_preds_set", "=", "set", "(", ")", "\n", "absent_preds", "=", "[", "]", "\n", "absent_preds_set", "=", "set", "(", ")", "\n", "\n", "total_preds", "=", "[", "]", "\n", "\n", "single_word_maxnum", "=", "opts", ".", "single_word_maxnum", "\n", "# split to present and absent predictions and also delete the repeated predictions", "\n", "for", "pred", "in", "preds", ":", "\n", "# # only keep single_word_maxnum single word keyphrase", "\n", "# single_word_maxnum = -1 means we keep all the single word phrase", "\n", "            ", "if", "single_word_maxnum", "!=", "-", "1", "and", "len", "(", "pred", ".", "split", "(", ")", ")", "==", "1", ":", "\n", "                ", "if", "single_word_maxnum", ">", "0", ":", "\n", "                    ", "single_word_maxnum", "-=", "1", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "", "", "if", "opts", ".", "match_method", "==", "'word_match'", ":", "\n", "                ", "match", "=", "in_context2", "(", "context_list", ",", "pred", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "match", "=", "pred", "in", "context", "\n", "", "if", "match", ":", "\n", "                ", "if", "pred", "not", "in", "present_preds_set", ":", "\n", "                    ", "total_preds", ".", "append", "(", "pred", ")", "\n", "present_preds", ".", "append", "(", "pred", ")", "\n", "present_preds_set", ".", "add", "(", "pred", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "pred", "not", "in", "absent_preds_set", ":", "\n", "                    ", "total_preds", ".", "append", "(", "pred", ")", "\n", "absent_preds", ".", "append", "(", "pred", ")", "\n", "absent_preds_set", ".", "add", "(", "pred", ")", "\n", "\n", "# store the nums", "\n", "", "", "", "present_target_lens_list", ".", "append", "(", "len", "(", "present_tgt_set", ")", ")", "\n", "absent_target_lens_list", ".", "append", "(", "len", "(", "absent_tgt_set", ")", ")", "\n", "total_target_lens_list", ".", "append", "(", "len", "(", "total_tgt_set", ")", ")", "\n", "num_groundtruth", "+=", "len", "(", "targets", ")", "\n", "num_present_groundtruth", "+=", "len", "(", "present_tgt_set", ")", "\n", "num_absent_groundtruth", "+=", "len", "(", "absent_tgt_set", ")", "\n", "\n", "if", "len", "(", "present_preds_set", ")", "<", "min_num_present_preds", ":", "\n", "            ", "min_num_present_preds", "=", "len", "(", "present_preds_set", ")", "\n", "", "if", "len", "(", "absent_preds_set", ")", "<", "min_num_absent_preds", ":", "\n", "            ", "min_num_absent_preds", "=", "len", "(", "absent_preds_set", ")", "\n", "\n", "", "ave_num_present_preds", "+=", "len", "(", "present_preds_set", ")", "\n", "ave_num_absent_preds", "+=", "len", "(", "absent_preds_set", ")", "\n", "\n", "# get the correctly_matched", "\n", "total_correctly_matched", "=", "[", "1", "if", "total_pred", "in", "total_tgt_set", "else", "0", "for", "total_pred", "in", "total_preds", "]", "\n", "# get the total_correctly_matched_at", "\n", "for", "at_key", "in", "total_correctly_matched_at", ":", "\n", "            ", "total_correctly_matched_at", "[", "at_key", "]", ".", "append", "(", "total_correctly_matched", "[", ":", "int", "(", "at_key", ")", "]", ")", "\n", "\n", "# get the correctly_matched", "\n", "", "present_correctly_matched", "=", "[", "1", "if", "present_pred", "in", "present_tgt_set", "else", "0", "for", "present_pred", "in", "present_preds", "]", "\n", "# get the present_correctly_matched_at", "\n", "for", "at_key", "in", "present_correctly_matched_at", ":", "\n", "            ", "present_correctly_matched_at", "[", "at_key", "]", ".", "append", "(", "present_correctly_matched", "[", ":", "int", "(", "at_key", ")", "]", ")", "\n", "\n", "", "absent_correctly_matched", "=", "[", "1", "if", "absent_pred", "in", "absent_tgt_set", "else", "0", "for", "absent_pred", "in", "absent_preds", "]", "\n", "# get the present_correctly_matched_at", "\n", "for", "at_key", "in", "absent_correctly_matched_at", ":", "\n", "            ", "absent_correctly_matched_at", "[", "at_key", "]", ".", "append", "(", "absent_correctly_matched", "[", ":", "int", "(", "at_key", ")", "]", ")", "\n", "\n", "# macro metric calculating", "\n", "", "macro_metrics", "[", "'total'", "]", ".", "append", "(", "\n", "macro_metric_fc", "(", "total_tgt_set", ",", "total_correctly_matched", ")", ")", "\n", "macro_metrics", "[", "'present'", "]", ".", "append", "(", "\n", "macro_metric_fc", "(", "present_tgt_set", ",", "present_correctly_matched", ")", ")", "\n", "\n", "macro_metrics", "[", "'absent'", "]", ".", "append", "(", "\n", "macro_metric_fc", "(", "absent_tgt_set", ",", "absent_correctly_matched", ")", ")", "\n", "\n", "cnt", "+=", "1", "\n", "\n", "# compute the corpus evaluation", "\n", "", "print", "(", "'#(Ground-truth Keyphrase)=%d'", "%", "num_groundtruth", ")", "\n", "print", "(", "'#(Present Ground-truth Keyphrase)=%d'", "%", "num_present_groundtruth", ")", "\n", "print", "(", "'#(Absent Ground-truth Keyphrase)=%d'", "%", "num_absent_groundtruth", ")", "\n", "\n", "print", "(", "'#(Total Num of Present Preds Per Example)=%d'", "%", "ave_num_present_preds", ")", "\n", "print", "(", "'#(Total Num of Absent Preds Per Example)=%d'", "%", "ave_num_absent_preds", ")", "\n", "print", "(", "'#(Ave Num of Present Preds Per Example)=%d'", "%", "(", "ave_num_present_preds", "/", "(", "cnt", "-", "1", ")", ")", ")", "\n", "print", "(", "'#(Ave Num of Absent Preds Per Example)=%d'", "%", "(", "ave_num_absent_preds", "/", "(", "cnt", "-", "1", ")", ")", ")", "\n", "print", "(", "'#(Min Num of Present Preds Per Example)=%d'", "%", "min_num_present_preds", ")", "\n", "print", "(", "'#(Min Num of Absent Preds Per Example)=%d'", "%", "min_num_absent_preds", ")", "\n", "\n", "# calculate and print the MAP metrics, some code are borrowed from the internet", "\n", "map_score_fc", "(", "total_correctly_matched_at", ",", "total_target_lens_list", ",", "keyphrase_type", "=", "'total'", ")", "\n", "map_score_fc", "(", "present_correctly_matched_at", ",", "present_target_lens_list", ",", "keyphrase_type", "=", "'present'", ")", "\n", "map_score_fc", "(", "absent_correctly_matched_at", ",", "absent_target_lens_list", ",", "keyphrase_type", "=", "'absent'", ")", "\n", "\n", "# calculate and print the Micro and Macro averaged F1, P, R metrics", "\n", "micro_ave_fc", "(", "macro_metrics", "[", "'total'", "]", ",", "keyphrase_type", "=", "'total'", ")", "\n", "micro_ave_fc", "(", "macro_metrics", "[", "'present'", "]", ",", "keyphrase_type", "=", "'present'", ")", "\n", "micro_ave_fc", "(", "macro_metrics", "[", "'absent'", "]", ",", "keyphrase_type", "=", "'absent'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.in_context2": [[188, 197], ["range", "len", "len", "len"], "function", ["None"], ["", "def", "in_context2", "(", "context_list", ",", "tgt_list", ")", ":", "\n", "    ", "match", "=", "False", "\n", "for", "c_idx", "in", "range", "(", "len", "(", "context_list", ")", "-", "len", "(", "tgt_list", ")", "+", "1", ")", ":", "\n", "        ", "context_piece", "=", "' '", ".", "join", "(", "context_list", "[", "c_idx", ":", "c_idx", "+", "len", "(", "tgt_list", ")", "]", ")", "\n", "tgt_piece", "=", "' '", ".", "join", "(", "tgt_list", ")", "\n", "if", "context_piece", "==", "tgt_piece", ":", "\n", "            ", "match", "=", "True", "\n", "break", "\n", "", "", "return", "match", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.precision_at_k": [[199, 226], ["numpy.mean", "ValueError", "numpy.asarray"], "function", ["None"], ["", "def", "precision_at_k", "(", "r", ",", "k", ")", ":", "\n", "    ", "\"\"\"Score is precision @ k\n    Relevance is binary (nonzero is relevant).\n    >>> r = [0, 0, 1]\n    >>> precision_at_k(r, 1)\n    0.0\n    >>> precision_at_k(r, 2)\n    0.0\n    >>> precision_at_k(r, 3)\n    0.33333333333333331\n    >>> precision_at_k(r, 4)\n    Traceback (most recent call last):\n        File \"<stdin>\", line 1, in ?\n    ValueError: Relevance score length < k\n    Args:\n        r: Relevance scores (list or numpy) in rank order\n            (first element is the first item)\n    Returns:\n        Precision @ k\n    Raises:\n        ValueError: len(r) must be >= k\n    \"\"\"", "\n", "assert", "k", ">=", "1", "\n", "r", "=", "np", ".", "asarray", "(", "r", ")", "[", ":", "k", "]", "!=", "0", "\n", "if", "r", ".", "size", "!=", "k", ":", "\n", "        ", "raise", "ValueError", "(", "'Relevance score length < k'", ")", "\n", "", "return", "np", ".", "mean", "(", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.average_precision": [[228, 251], ["numpy.asarray", "evaluation_utils.precision_at_k", "numpy.mean", "range", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.precision_at_k"], ["", "def", "average_precision", "(", "r", ",", "target_num", "=", "None", ")", ":", "\n", "    ", "\"\"\"Score is average precision (area under PR curve)\n    Relevance is binary (nonzero is relevant).\n    >>> r = [1, 1, 0, 1, 0, 1, 0, 0, 0, 1]\n    >>> delta_r = 1. / sum(r)\n    >>> sum([sum(r[:x + 1]) / (x + 1.) * delta_r for x, y in enumerate(r) if y])\n    0.7833333333333333\n    >>> average_precision(r)\n    0.78333333333333333\n    Args:\n        r: Relevance scores (list or numpy) in rank order\n            (first element is the first item)\n    Returns:\n        Average precision\n    \"\"\"", "\n", "r", "=", "np", ".", "asarray", "(", "r", ")", "!=", "0", "\n", "out", "=", "[", "precision_at_k", "(", "r", ",", "k", "+", "1", ")", "for", "k", "in", "range", "(", "r", ".", "size", ")", "if", "r", "[", "k", "]", "]", "\n", "if", "not", "out", ":", "\n", "        ", "return", "0.", "\n", "", "if", "target_num", ":", "\n", "        ", "return", "np", ".", "sum", "(", "out", ")", "*", "1.0", "/", "target_num", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "mean", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.mean_average_precision": [[253, 272], ["numpy.mean", "numpy.mean", "evaluation_utils.average_precision", "evaluation_utils.average_precision", "zip"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.average_precision", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.average_precision"], ["", "", "def", "mean_average_precision", "(", "rs", ",", "target_nums_list", ")", ":", "\n", "    ", "\"\"\"Score is mean average precision\n    Relevance is binary (nonzero is relevant).\n    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1]]\n    >>> mean_average_precision(rs)\n    0.78333333333333333\n    >>> rs = [[1, 1, 0, 1, 0, 1, 0, 0, 0, 1], [0]]\n    >>> mean_average_precision(rs)\n    0.39166666666666666\n    Args:\n        rs: Iterator of relevance scores (list or numpy) in rank order\n            (first element is the first item)\n    Returns:\n        Mean average precision\n    \"\"\"", "\n", "if", "target_nums_list", ":", "\n", "        ", "return", "np", ".", "mean", "(", "[", "average_precision", "(", "r", ",", "target_num", ")", "for", "r", ",", "target_num", "in", "zip", "(", "rs", ",", "target_nums_list", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "mean", "(", "[", "average_precision", "(", "r", ")", "for", "r", "in", "rs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.map_score_fc": [[274, 285], ["print", "evaluation_utils.mean_average_precision", "evaluation_utils.mean_average_precision", "evaluation_utils.mean_average_precision", "evaluation_utils.mean_average_precision", "print", "print"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.mean_average_precision", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.mean_average_precision", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.mean_average_precision", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.mean_average_precision"], ["", "", "def", "map_score_fc", "(", "correctly_matched_at", ",", "target_lens_list", "=", "None", ",", "keyphrase_type", "=", "''", ")", ":", "\n", "    ", "assert", "keyphrase_type", "!=", "''", "\n", "print", "(", "'\\nBegin'", "+", "'='", "*", "20", "+", "keyphrase_type", "+", "'='", "*", "20", "+", "'Begin'", ")", "\n", "map_5", "=", "mean_average_precision", "(", "correctly_matched_at", "[", "'5'", "]", ",", "target_lens_list", ")", "\n", "map_10", "=", "mean_average_precision", "(", "correctly_matched_at", "[", "'10'", "]", ",", "target_lens_list", ")", "\n", "map_15", "=", "mean_average_precision", "(", "correctly_matched_at", "[", "'15'", "]", ",", "target_lens_list", ")", "\n", "map_50", "=", "mean_average_precision", "(", "correctly_matched_at", "[", "'50'", "]", ",", "target_lens_list", ")", "\n", "\n", "output_str", "=", "'MAP_%s:\\t\\t@5=%f, @10=%f, @15=%f, @50=%f'", "%", "(", "keyphrase_type", ",", "map_5", ",", "map_10", ",", "map_15", ",", "map_50", ")", "\n", "print", "(", "output_str", ")", "\n", "print", "(", "'End'", "+", "'='", "*", "20", "+", "keyphrase_type", "+", "'='", "*", "20", "+", "'End'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.macro_metric_fc": [[287, 310], ["len", "len", "sum", "float", "float", "len", "sum", "float", "float", "float", "sum", "len"], "function", ["None"], ["", "def", "macro_metric_fc", "(", "tgt_set", ",", "correctly_matched", ")", ":", "\n", "    ", "metric_dict", "=", "{", "}", "\n", "for", "number_to_predict", "in", "[", "5", ",", "10", ",", "15", ",", "50", "]", ":", "\n", "        ", "metric_dict", "[", "'target_number'", "]", "=", "len", "(", "tgt_set", ")", "\n", "metric_dict", "[", "'prediction_number'", "]", "=", "len", "(", "correctly_matched", ")", "\n", "metric_dict", "[", "'correct_number@%d'", "%", "number_to_predict", "]", "=", "sum", "(", "correctly_matched", "[", ":", "number_to_predict", "]", ")", "\n", "\n", "metric_dict", "[", "'p@%d'", "%", "number_to_predict", "]", "=", "float", "(", "sum", "(", "correctly_matched", "[", ":", "number_to_predict", "]", ")", ")", "/", "float", "(", "\n", "number_to_predict", ")", "\n", "\n", "if", "len", "(", "tgt_set", ")", "!=", "0", ":", "\n", "            ", "metric_dict", "[", "'r@%d'", "%", "number_to_predict", "]", "=", "float", "(", "sum", "(", "correctly_matched", "[", ":", "number_to_predict", "]", ")", ")", "/", "float", "(", "\n", "len", "(", "tgt_set", ")", ")", "\n", "", "else", ":", "\n", "            ", "metric_dict", "[", "'r@%d'", "%", "number_to_predict", "]", "=", "0", "\n", "\n", "", "if", "metric_dict", "[", "'p@%d'", "%", "number_to_predict", "]", "+", "metric_dict", "[", "'r@%d'", "%", "number_to_predict", "]", "!=", "0", ":", "\n", "            ", "metric_dict", "[", "'f1@%d'", "%", "number_to_predict", "]", "=", "2", "*", "metric_dict", "[", "'p@%d'", "%", "number_to_predict", "]", "*", "metric_dict", "[", "\n", "'r@%d'", "%", "number_to_predict", "]", "/", "float", "(", "\n", "metric_dict", "[", "'p@%d'", "%", "number_to_predict", "]", "+", "metric_dict", "[", "'r@%d'", "%", "number_to_predict", "]", ")", "\n", "", "else", ":", "\n", "            ", "metric_dict", "[", "'f1@%d'", "%", "number_to_predict", "]", "=", "0", "\n", "", "", "return", "metric_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.Merge.evaluation_utils.micro_ave_fc": [[312, 359], ["print", "len", "sum", "sum", "sum", "print", "print", "print", "print", "float", "float", "float", "float", "float", "float", "min", "sum", "sum", "sum", "float", "float", "float"], "function", ["None"], ["", "def", "micro_ave_fc", "(", "macro_metrics", ",", "keyphrase_type", "=", "'total'", ")", ":", "\n", "    ", "print", "(", "'\\nBegin'", "+", "'='", "*", "20", "+", "keyphrase_type", "+", "'='", "*", "20", "+", "'Begin'", ")", "\n", "real_test_size", "=", "len", "(", "macro_metrics", ")", "\n", "overall_score", "=", "{", "}", "\n", "for", "k", "in", "[", "5", ",", "10", ",", "15", ",", "50", "]", ":", "\n", "        ", "correct_number", "=", "sum", "(", "[", "m", "[", "'correct_number@%d'", "%", "k", "]", "for", "m", "in", "macro_metrics", "]", ")", "\n", "overall_target_number", "=", "sum", "(", "[", "m", "[", "'target_number'", "]", "for", "m", "in", "macro_metrics", "]", ")", "\n", "overall_prediction_number", "=", "sum", "(", "[", "min", "(", "m", "[", "'prediction_number'", "]", ",", "k", ")", "for", "m", "in", "macro_metrics", "]", ")", "\n", "\n", "# Compute the Macro Measures, by averaging the macro-score of each prediction", "\n", "overall_score", "[", "'p@%d'", "%", "k", "]", "=", "float", "(", "sum", "(", "[", "m", "[", "'p@%d'", "%", "k", "]", "for", "m", "in", "macro_metrics", "]", ")", ")", "/", "float", "(", "real_test_size", ")", "\n", "overall_score", "[", "'r@%d'", "%", "k", "]", "=", "float", "(", "sum", "(", "[", "m", "[", "'r@%d'", "%", "k", "]", "for", "m", "in", "macro_metrics", "]", ")", ")", "/", "float", "(", "real_test_size", ")", "\n", "overall_score", "[", "'f1@%d'", "%", "k", "]", "=", "float", "(", "sum", "(", "[", "m", "[", "'f1@%d'", "%", "k", "]", "for", "m", "in", "macro_metrics", "]", ")", ")", "/", "float", "(", "real_test_size", ")", "\n", "\n", "# Print basic statistics", "\n", "output_str", "=", "'Overall - valid testing data=%d, Number of Target=%d/%d, Number of Prediction=%d, Number of Correct=%d'", "%", "(", "\n", "real_test_size", ",", "\n", "overall_target_number", ",", "overall_target_number", ",", "\n", "overall_prediction_number", ",", "correct_number", "\n", ")", "\n", "print", "(", "output_str", ")", "\n", "# Print Macro-average performance", "\n", "output_str", "=", "'Macro_%s_%d:\\t\\tP@%d=%f, R@%d=%f, F1@%d=%f'", "%", "(", "\n", "keyphrase_type", ",", "k", ",", "\n", "k", ",", "overall_score", "[", "'p@%d'", "%", "k", "]", ",", "\n", "k", ",", "overall_score", "[", "'r@%d'", "%", "k", "]", ",", "\n", "k", ",", "overall_score", "[", "'f1@%d'", "%", "k", "]", "\n", ")", "\n", "print", "(", "output_str", ")", "\n", "\n", "# Print Micro-average performance", "\n", "overall_score", "[", "'micro_p@%d'", "%", "k", "]", "=", "correct_number", "/", "float", "(", "overall_prediction_number", ")", "if", "overall_prediction_number", "!=", "0", "else", "0", "\n", "overall_score", "[", "'micro_r@%d'", "%", "k", "]", "=", "correct_number", "/", "float", "(", "overall_target_number", ")", "if", "overall_prediction_number", "!=", "0", "else", "0", "\n", "if", "overall_score", "[", "'micro_p@%d'", "%", "k", "]", "+", "overall_score", "[", "'micro_r@%d'", "%", "k", "]", ">", "0", ":", "\n", "            ", "overall_score", "[", "'micro_f1@%d'", "%", "k", "]", "=", "2", "*", "overall_score", "[", "'micro_p@%d'", "%", "k", "]", "*", "overall_score", "[", "\n", "'micro_r@%d'", "%", "k", "]", "/", "float", "(", "overall_score", "[", "'micro_p@%d'", "%", "k", "]", "+", "overall_score", "[", "'micro_r@%d'", "%", "k", "]", ")", "\n", "", "else", ":", "\n", "            ", "overall_score", "[", "'micro_f1@%d'", "%", "k", "]", "=", "0", "\n", "\n", "", "output_str", "=", "'Micro_%s_%d:\\t\\tP@%d=%f, R@%d=%f, F1@%d=%f'", "%", "(", "\n", "keyphrase_type", ",", "k", ",", "\n", "k", ",", "overall_score", "[", "'micro_p@%d'", "%", "k", "]", ",", "\n", "k", ",", "overall_score", "[", "'micro_r@%d'", "%", "k", "]", ",", "\n", "k", ",", "overall_score", "[", "'micro_f1@%d'", "%", "k", "]", "\n", ")", "\n", "print", "(", "output_str", ")", "\n", "print", "(", "'End'", "+", "'='", "*", "20", "+", "keyphrase_type", "+", "'='", "*", "20", "+", "'End'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.rnn_reranker.RNNReRanker.__init__": [[30, 66], ["onmt.encoders.encoder.EncoderBase.__init__", "onmt.utils.rnn_factory.rnn_factory", "onmt.utils.rnn_factory.rnn_factory", "rnn_reranker.RNNReRanker._mlp_layers", "rnn_reranker.RNNReRanker._mlp_layers", "rnn_reranker.RNNReRanker._mlp_layers", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.rnn_factory.rnn_factory", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.rnn_factory.rnn_factory", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.rnn_reranker.RNNReRanker._mlp_layers", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.rnn_reranker.RNNReRanker._mlp_layers", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.rnn_reranker.RNNReRanker._mlp_layers"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "bidirectional", ",", "num_layers", ",", "\n", "hidden_size", ",", "dropout", "=", "0.0", ",", "embeddings", "=", "None", ")", ":", "\n", "        ", "super", "(", "RNNReRanker", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "embeddings", "is", "not", "None", "\n", "assert", "bidirectional", "\n", "\n", "num_directions", "=", "2", "if", "bidirectional", "else", "1", "\n", "assert", "hidden_size", "%", "num_directions", "==", "0", "\n", "hidden_size", "=", "hidden_size", "//", "num_directions", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "embeddings", "=", "embeddings", "\n", "\n", "self", ".", "src_rnn", ",", "self", ".", "src_no_pack_padded_seq", "=", "rnn_factory", "(", "rnn_type", ",", "\n", "input_size", "=", "embeddings", ".", "embedding_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", "if", "num_layers", ">", "1", "else", "0.0", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n", "self", ".", "tgt_rnn", ",", "self", ".", "tgt_no_pack_padded_seq", "=", "rnn_factory", "(", "rnn_type", ",", "\n", "input_size", "=", "embeddings", ".", "embedding_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", "if", "num_layers", ">", "1", "else", "0.0", ",", "\n", "bidirectional", "=", "bidirectional", ")", "\n", "\n", "self", ".", "mlp_f", "=", "self", ".", "_mlp_layers", "(", "2", "*", "self", ".", "hidden_size", ",", "2", "*", "self", ".", "hidden_size", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "mlp_g", "=", "self", ".", "_mlp_layers", "(", "4", "*", "self", ".", "hidden_size", ",", "2", "*", "self", ".", "hidden_size", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "mlp_h", "=", "self", ".", "_mlp_layers", "(", "4", "*", "self", ".", "hidden_size", ",", "2", "*", "self", ".", "hidden_size", ",", "dropout", "=", "dropout", ")", "\n", "\n", "self", ".", "final_linear", "=", "nn", ".", "Linear", "(", "2", "*", "self", ".", "hidden_size", ",", "1", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "dropout_m", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.rnn_reranker.RNNReRanker._mlp_layers": [[67, 78], ["mlp_layers.append", "mlp_layers.append", "mlp_layers.append", "mlp_layers.append", "mlp_layers.append", "mlp_layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["None"], ["", "def", "_mlp_layers", "(", "self", ",", "input_dim", ",", "output_dim", ",", "dropout", ")", ":", "\n", "        ", "mlp_layers", "=", "[", "]", "\n", "mlp_layers", ".", "append", "(", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "mlp_layers", ".", "append", "(", "nn", ".", "Linear", "(", "\n", "input_dim", ",", "output_dim", ",", "bias", "=", "True", ")", ")", "\n", "mlp_layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "mlp_layers", ".", "append", "(", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "mlp_layers", ".", "append", "(", "nn", ".", "Linear", "(", "\n", "output_dim", ",", "output_dim", ",", "bias", "=", "True", ")", ")", "\n", "mlp_layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "mlp_layers", ")", "# * used to unpack list", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.rnn_reranker.RNNReRanker.forward": [[79, 220], ["isinstance", "rnn_reranker.RNNReRanker._check_args", "rnn_reranker.RNNReRanker._check_args", "rnn_reranker.RNNReRanker.embeddings", "rnn_reranker.RNNReRanker.size", "rnn_reranker.RNNReRanker.src_rnn", "rnn_reranker.RNNReRanker.embeddings", "rnn_reranker.RNNReRanker.size", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "rnn_reranker.RNNReRanker.index_select", "rnn_reranker.RNNReRanker.tgt_rnn", "onmt.utils.misc.sequence_mask", "onmt.utils.misc.sequence_mask", "src_memory_bank.transpose().contiguous", "tgt_memory_bank.index_select.index_select.transpose().contiguous", "src_memory_bank.transpose().contiguous.size", "tgt_memory_bank.index_select.transpose().contiguous.size", "rnn_reranker.RNNReRanker.mlp_f", "rnn_reranker.RNNReRanker.mlp_f", "f1.view.view.view", "f2.view.view.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm.masked_fill", "torch.bmm.masked_fill", "torch.bmm.masked_fill", "score1.contiguous.contiguous.contiguous", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.bmm.transpose", "torch.bmm.transpose", "torch.bmm.transpose", "score2.contiguous.contiguous.masked_fill", "score2.contiguous.contiguous.contiguous", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rnn_reranker.RNNReRanker.mlp_g", "rnn_reranker.RNNReRanker.mlp_g", "g1.view.view.view", "g2.view.view.view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rnn_reranker.RNNReRanker.mlp_h", "rnn_reranker.RNNReRanker.final_linear", "rnn_reranker.RNNReRanker.sigmoid", "isinstance", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "sorted_tgt_lengths.view().tolist.view().tolist.view().tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "tgt_memory_bank.index_select.index_select.index_select", "tgt_encoder_final.index_select.index_select.index_select", "src_memory_bank.transpose().contiguous.view", "tgt_memory_bank.index_select.transpose().contiguous.view", "f2.view.view.transpose", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "onmt.utils.misc.sequence_mask.unsqueeze().float", "onmt.utils.misc.sequence_mask.unsqueeze().float", "src_lengths.view().tolist", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "src_memory_bank.transpose", "tgt_memory_bank.index_select.index_select.transpose", "float", "torch.softmax", "torch.softmax", "torch.softmax", "float", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "sorted_tgt_lengths.view().tolist.view().tolist.view", "score1.contiguous.contiguous.view", "score2.contiguous.contiguous.view", "onmt.utils.misc.sequence_mask.unsqueeze", "onmt.utils.misc.sequence_mask.unsqueeze", "src_lengths.view", "onmt.utils.misc.sequence_mask.unsqueeze", "onmt.utils.misc.sequence_mask.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.encoders.encoder.EncoderBase._check_args", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.sequence_mask", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.utils.misc.sequence_mask"], ["", "def", "forward", "(", "self", ",", "input", ",", "lengths_", "=", "None", ")", ":", "\n", "        ", "assert", "isinstance", "(", "input", ",", "tuple", ")", "\n", "src", ",", "tgt", "=", "input", "\n", "\n", "if", "lengths_", "is", "not", "None", ":", "\n", "            ", "assert", "isinstance", "(", "lengths_", ",", "tuple", ")", "\n", "src_lengths", ",", "tgt_lengths", "=", "lengths_", "\n", "", "else", ":", "\n", "            ", "src_lengths", "=", "None", "\n", "tgt_lengths", "=", "None", "\n", "\n", "", "\"See :obj:`EncoderBase.forward()`\"", "\n", "self", ".", "_check_args", "(", "src", ",", "src_lengths", ")", "\n", "self", ".", "_check_args", "(", "tgt", ",", "tgt_lengths", ")", "\n", "\n", "# encoding the src", "\n", "emb", "=", "self", ".", "embeddings", "(", "src", ")", "\n", "src_len", ",", "batch_size", ",", "_", "=", "emb", ".", "size", "(", ")", "\n", "\n", "packed_emb", "=", "emb", "\n", "if", "src_lengths", "is", "not", "None", "and", "not", "self", ".", "src_no_pack_padded_seq", ":", "\n", "# Lengths data is wrapped inside a Tensor.", "\n", "# src_lengths = src_lengths.view(-1).tolist()", "\n", "            ", "packed_emb", "=", "pack", "(", "emb", ",", "src_lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "# encoder_final: [2(directions), batch_size, hidden_dim]", "\n", "# memory_bank: [seq_len, batch_size, 2 * hidden_dim]", "\n", "", "src_memory_bank", ",", "src_encoder_final", "=", "self", ".", "src_rnn", "(", "packed_emb", ")", "\n", "\n", "if", "src_lengths", "is", "not", "None", "and", "not", "self", ".", "src_no_pack_padded_seq", ":", "\n", "            ", "src_memory_bank", "=", "unpack", "(", "src_memory_bank", ")", "[", "0", "]", "\n", "\n", "# encoding the tgt", "\n", "", "emb", "=", "self", ".", "embeddings", "(", "tgt", ")", "\n", "tgt_len", ",", "batch_size", ",", "_", "=", "emb", ".", "size", "(", ")", "\n", "\n", "# sort retrieved keys w.r.t tgt_lengths", "\n", "sorted_tgt_lengths", ",", "idx_sort", "=", "torch", ".", "sort", "(", "tgt_lengths", ",", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "_", ",", "idx_unsort", "=", "torch", ".", "sort", "(", "idx_sort", ",", "dim", "=", "0", ")", "\n", "\n", "packed_emb", "=", "emb", ".", "index_select", "(", "1", ",", "idx_sort", ")", "\n", "if", "tgt_lengths", "is", "not", "None", "and", "not", "self", ".", "tgt_no_pack_padded_seq", ":", "\n", "            ", "sorted_tgt_lengths", "=", "sorted_tgt_lengths", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "packed_emb", "=", "pack", "(", "packed_emb", ",", "sorted_tgt_lengths", ")", "\n", "\n", "", "tgt_memory_bank", ",", "tgt_encoder_final", "=", "self", ".", "tgt_rnn", "(", "packed_emb", ")", "\n", "\n", "if", "tgt_lengths", "is", "not", "None", "and", "not", "self", ".", "tgt_no_pack_padded_seq", ":", "\n", "            ", "tgt_memory_bank", "=", "unpack", "(", "tgt_memory_bank", ")", "[", "0", "]", "\n", "tgt_memory_bank", "=", "tgt_memory_bank", ".", "index_select", "(", "1", ",", "idx_unsort", ")", "\n", "tgt_encoder_final", "=", "tgt_encoder_final", ".", "index_select", "(", "1", ",", "idx_unsort", ")", "\n", "\n", "# if self.use_bridge:", "\n", "#     src_encoder_final = self._bridge(src_encoder_final)", "\n", "#     tgt_encoder_final = self._bridge(tgt_encoder_final)", "\n", "\n", "# attention", "\n", "", "'''\n            sent_linear: batch_size x length x hidden_size\n        '''", "\n", "src_mask", "=", "sequence_mask", "(", "src_lengths", ",", "max_len", "=", "src_len", ")", "# [batch, src_len]", "\n", "#src_mask = src_mask.unsqueeze(2)  # Make it broadcastable. [batch, src_len, 1]", "\n", "tgt_mask", "=", "sequence_mask", "(", "tgt_lengths", ",", "max_len", "=", "tgt_len", ")", "# [batch, tgt_len]", "\n", "#tgt_mask = tgt_mask.unsqueeze(1)  # Make it broadcastable. [batch, 1, tgt_len]", "\n", "#final_mask = torch.bmm(src_mask.unsqueeze(2).float(), tgt_mask.unsqueeze(1).float()).byte()    # [batch, src_len, tgt_len]", "\n", "\n", "sent1_linear", "=", "src_memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "sent2_linear", "=", "tgt_memory_bank", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "len1", "=", "sent1_linear", ".", "size", "(", "1", ")", "\n", "len2", "=", "sent2_linear", ".", "size", "(", "1", ")", "\n", "assert", "src_len", "==", "len1", "\n", "assert", "tgt_len", "==", "len2", "\n", "\n", "'''attend'''", "\n", "\n", "f1", "=", "self", ".", "mlp_f", "(", "sent1_linear", ".", "view", "(", "-", "1", ",", "2", "*", "self", ".", "hidden_size", ")", ")", "\n", "f2", "=", "self", ".", "mlp_f", "(", "sent2_linear", ".", "view", "(", "-", "1", ",", "2", "*", "self", ".", "hidden_size", ")", ")", "\n", "\n", "f1", "=", "f1", ".", "view", "(", "-", "1", ",", "len1", ",", "2", "*", "self", ".", "hidden_size", ")", "\n", "# batch_size x len1 x hidden_size", "\n", "f2", "=", "f2", ".", "view", "(", "-", "1", ",", "len2", ",", "2", "*", "self", ".", "hidden_size", ")", "\n", "# batch_size x len2 x hidden_size", "\n", "\n", "score", "=", "torch", ".", "bmm", "(", "f1", ",", "f2", ".", "transpose", "(", "1", ",", "2", ")", ")", "# batch_size x len1 x len2", "\n", "\n", "#score1 = score", "\n", "score1", "=", "score", ".", "masked_fill", "(", "(", "1", "-", "tgt_mask", ".", "unsqueeze", "(", "1", ")", ")", ".", "byte", "(", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# e_{ij} batch_size x len1 x len2", "\n", "score1", "=", "score1", ".", "contiguous", "(", ")", "\n", "\n", "prob1", "=", "F", ".", "softmax", "(", "score1", ".", "view", "(", "-", "1", ",", "len2", ")", ",", "dim", "=", "-", "1", ")", ".", "view", "(", "-", "1", ",", "len1", ",", "len2", ")", "\n", "# batch_size x len1 x len2", "\n", "\n", "score2", "=", "score", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# e_{ij} batch_size x len2 x len1", "\n", "score2", "=", "score2", ".", "masked_fill", "(", "(", "1", "-", "src_mask", ".", "unsqueeze", "(", "1", ")", ")", ".", "byte", "(", ")", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "score2", "=", "score2", ".", "contiguous", "(", ")", "\n", "# e_{ji} batch_size x len2 x len1", "\n", "prob2", "=", "F", ".", "softmax", "(", "score2", ".", "view", "(", "-", "1", ",", "len1", ")", ",", "dim", "=", "-", "1", ")", ".", "view", "(", "-", "1", ",", "len2", ",", "len1", ")", "\n", "# batch_size x len2 x len1", "\n", "\n", "sent1_combine", "=", "torch", ".", "cat", "(", "\n", "(", "sent1_linear", ",", "torch", ".", "bmm", "(", "prob1", ",", "sent2_linear", ")", ")", ",", "2", ")", "\n", "# batch_size x len1 x (hidden_size x 4)", "\n", "sent2_combine", "=", "torch", ".", "cat", "(", "\n", "(", "sent2_linear", ",", "torch", ".", "bmm", "(", "prob2", ",", "sent1_linear", ")", ")", ",", "2", ")", "\n", "# batch_size x len2 x (hidden_size x 4)", "\n", "\n", "'''sum'''", "\n", "g1", "=", "self", ".", "mlp_g", "(", "sent1_combine", ".", "view", "(", "-", "1", ",", "4", "*", "self", ".", "hidden_size", ")", ")", "\n", "g2", "=", "self", ".", "mlp_g", "(", "sent2_combine", ".", "view", "(", "-", "1", ",", "4", "*", "self", ".", "hidden_size", ")", ")", "\n", "g1", "=", "g1", ".", "view", "(", "-", "1", ",", "len1", ",", "2", "*", "self", ".", "hidden_size", ")", "\n", "g1", "=", "g1", "*", "src_mask", ".", "unsqueeze", "(", "2", ")", ".", "float", "(", ")", "\n", "# batch_size x len1 x (hidden_size * 2)", "\n", "g2", "=", "g2", ".", "view", "(", "-", "1", ",", "len2", ",", "2", "*", "self", ".", "hidden_size", ")", "\n", "g2", "=", "g2", "*", "tgt_mask", ".", "unsqueeze", "(", "2", ")", ".", "float", "(", ")", "\n", "# batch_size x len2 x (hidden_size * 2)", "\n", "\n", "sent1_output", "=", "torch", ".", "sum", "(", "g1", ",", "1", ")", "# batch_size x 1 x (hidden_size * 2)", "\n", "# sent1_output = torch.squeeze(sent1_output, 1)", "\n", "sent2_output", "=", "torch", ".", "sum", "(", "g2", ",", "1", ")", "# batch_size x 1 x (hidden_size * 2)", "\n", "# sent2_output = torch.squeeze(sent2_output, 1)", "\n", "\n", "input_combine", "=", "torch", ".", "cat", "(", "(", "sent1_output", ",", "sent2_output", ")", ",", "1", ")", "\n", "# batch_size x (4 * hidden_size)", "\n", "h", "=", "self", ".", "mlp_h", "(", "input_combine", ")", "\n", "# batch_size * (2 *hidden_size)", "\n", "\n", "# if sample_id == 15:", "\n", "#     print '-2 layer'", "\n", "#     print h.data[:, 100:150]", "\n", "\n", "logits", "=", "self", ".", "final_linear", "(", "h", ")", "\n", "# batch_size", "\n", "\n", "# print 'final layer'", "\n", "# print h.data", "\n", "\n", "probs", "=", "self", ".", "sigmoid", "(", "logits", ")", "\n", "\n", "return", "logits", ",", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.__init__": [[41, 51], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "model_opt", ",", "model", ",", "fields", ",", "out_file", "=", "None", ",", "logger", "=", "None", ")", ":", "\n", "        ", "self", ".", "logger", "=", "logger", "\n", "self", ".", "gpu", "=", "opt", ".", "gpu", "\n", "self", ".", "cuda", "=", "opt", ".", "gpu", ">", "-", "1", "\n", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "fields", "=", "fields", "\n", "self", ".", "out_file", "=", "out_file", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.ReRankerScorer.scoring": [[52, 104], ["onmt.build_dataset", "onmt.build_dataset", "onmt.build_dataset", "onmt.build_dataset", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.OrderedIterator", "onmt.OrderedIterator", "len", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "onmt.make_features", "reranker_scorer.ReRankerScorer.model", "torch.sort", "probs.index_select", "range", "orig_probs[].data.item", "scored_triplets.append"], "methods", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.build_dataset", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.inputters.inputter.make_features"], ["", "def", "scoring", "(", "self", ",", "src_data_path", "=", "None", ",", "src_data_iter", "=", "None", ",", "tgt_data_path", "=", "None", ",", "tgt_data_iter", "=", "None", ",", "batch_size", "=", "32", ")", ":", "\n", "        ", "if", "src_data_iter", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "len", "(", "src_data_iter", ")", "\n", "", "assert", "batch_size", "!=", "0", "\n", "data", "=", "inputters", ".", "build_dataset", "(", "self", ".", "fields", ",", "\n", "'text'", ",", "\n", "src_path", "=", "src_data_path", ",", "\n", "src_data_iter", "=", "src_data_iter", ",", "\n", "tgt_path", "=", "tgt_data_path", ",", "\n", "tgt_data_iter", "=", "tgt_data_iter", ",", "\n", "use_filter_pred", "=", "False", ",", "\n", "dynamic_dict", "=", "False", ")", "\n", "\n", "if", "self", ".", "cuda", ":", "\n", "            ", "cur_device", "=", "\"cuda\"", "\n", "", "else", ":", "\n", "            ", "cur_device", "=", "\"cpu\"", "\n", "\n", "", "data_iter", "=", "inputters", ".", "OrderedIterator", "(", "\n", "dataset", "=", "data", ",", "device", "=", "cur_device", ",", "\n", "batch_size", "=", "batch_size", ",", "train", "=", "False", ",", "sort", "=", "False", ",", "\n", "sort_within_batch", "=", "True", ",", "shuffle", "=", "False", ")", "\n", "\n", "scored_triplets", "=", "[", "]", "\n", "for", "batch", "in", "data_iter", ":", "\n", "            ", "src", "=", "inputters", ".", "make_features", "(", "batch", ",", "'src'", ",", "'text'", ")", "# [src_len, batch_size, num_features]", "\n", "_", ",", "src_lengths", "=", "batch", ".", "src", "\n", "\n", "tgt", "=", "inputters", ".", "make_features", "(", "batch", ",", "'tgt'", ",", "'text'", ")", "# [tgt_len, batch_size, num_features]", "\n", "_", ",", "tgt_lengths", "=", "batch", ".", "tgt", "\n", "\n", "logits", ",", "probs", "=", "self", ".", "model", "(", "src", ",", "tgt", ",", "src_lengths", ",", "tgt_lengths", ")", "\n", "\n", "# Sorting", "\n", "inds", ",", "perm", "=", "torch", ".", "sort", "(", "batch", ".", "indices", ".", "data", ")", "\n", "\n", "# orig_src = batch.src[0].data.index_select(1, perm)", "\n", "# orig_tgt = batch.tgt[0].data.index_select(1, perm)", "\n", "orig_probs", "=", "probs", ".", "index_select", "(", "0", ",", "perm", ")", "\n", "\n", "for", "b", "in", "range", "(", "batch", ".", "batch_size", ")", ":", "\n", "                ", "src_raw", "=", "data", ".", "examples", "[", "inds", "[", "b", "]", "]", ".", "src", "\n", "tgt_raw", "=", "data", ".", "examples", "[", "inds", "[", "b", "]", "]", ".", "tgt", "\n", "final_score", "=", "orig_probs", "[", "b", "]", ".", "data", ".", "item", "(", ")", "\n", "scored_triplets", ".", "append", "(", "{", "'src'", ":", "src_raw", ",", "'tgt'", ":", "tgt_raw", ",", "'score'", ":", "final_score", "}", ")", "\n", "# if final_score > 0.5:", "\n", "#     print('=' * 30)", "\n", "#     print('src: {}'.format(' '.join(src_raw)))", "\n", "#     print('tgt: {}; score: {}'.format(' '.join(tgt_raw), final_score))", "\n", "#     print('=' * 30)", "\n", "\n", "", "", "return", "scored_triplets", "\n", "\n"]], "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.reranker.reranker_scorer.build_reranker_scorer": [[21, 37], ["argparse.ArgumentParser", "onmt.opts.model_opts", "onmt.opts.model_opts", "onmt.opts.model_opts", "onmt.opts.model_opts", "onmt.model_builder.load_test_model", "onmt.model_builder.load_test_model", "onmt.model_builder.load_test_model", "onmt.model_builder.load_test_model", "reranker_scorer.ReRankerScorer", "torch.cuda.set_device", "argparse.ArgumentParser.parse_known_args"], "function", ["home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.model_opts", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.model_opts", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.model_opts", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.opts.model_opts", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.load_test_model", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.load_test_model", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.load_test_model", "home.repos.pwc.inspect_result.Chen-Wang-CUHK_KG-KE-KR-M.onmt.model_builder.load_test_model"], ["def", "build_reranker_scorer", "(", "opt", ",", "logger", "=", "None", ")", ":", "\n", "# out_file = codecs.open(opt.output, 'w+', 'utf-8')", "\n", "\n", "    ", "if", "opt", ".", "gpu", ">", "-", "1", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu", ")", "\n", "\n", "", "dummy_parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'train.py'", ")", "\n", "onmt", ".", "opts", ".", "model_opts", "(", "dummy_parser", ")", "\n", "dummy_opt", "=", "dummy_parser", ".", "parse_known_args", "(", "[", "]", ")", "[", "0", "]", "\n", "\n", "fields", ",", "model", ",", "model_opt", "=", "onmt", ".", "model_builder", ".", "load_test_model", "(", "opt", ",", "dummy_opt", ".", "__dict__", ")", "\n", "\n", "reranker_scorer", "=", "ReRankerScorer", "(", "opt", ",", "model_opt", ",", "model", ",", "fields", ",", "logger", "=", "logger", ")", "\n", "\n", "return", "reranker_scorer", "\n", "\n"]]}