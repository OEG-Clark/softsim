{"home.repos.pwc.inspect_result.whu-zqh_kgan.None.nn_utils.get_batch_input": [[6, 29], ["pandas.DataFrame.from_dict", "list", "batch_input_var.append", "numpy.array", "batch_input_var.append", "numpy.array", "print"], "function", ["None"], ["def", "get_batch_input", "(", "dataset", ",", "bs", ",", "args", ",", "idx", "=", "None", ",", "all", "=", "False", ")", ":", "\n", "    ", "if", "all", ":", "\n", "        ", "batch_input", "=", "dataset", "\n", "", "else", ":", "\n", "        ", "batch_input", "=", "dataset", "[", "idx", "*", "bs", ":", "(", "idx", "+", "1", ")", "*", "bs", "]", "\n", "", "batch_data", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "batch_input", ")", "\n", "if", "args", ".", "model", "==", "'RGAT'", ":", "\n", "        ", "target_fields", "=", "[", "'wids'", ",", "'tids'", ",", "'dep_tag_ids'", ",", "'y'", ",", "'pw'", "]", "\n", "", "elif", "args", ".", "model", "in", "[", "'ASGCN'", ",", "'KGNN'", "]", ":", "\n", "        ", "target_fields", "=", "[", "'wids'", ",", "'tids'", ",", "'y'", ",", "'pw'", ",", "'adj'", ",", "'mask'", "]", "\n", "", "else", ":", "\n", "        ", "target_fields", "=", "[", "'wids'", ",", "'tids'", ",", "'y'", ",", "'pw'", "]", "\n", "", "batch_input_var", "=", "[", "]", "\n", "for", "key", "in", "target_fields", ":", "\n", "        ", "data", "=", "list", "(", "batch_data", "[", "key", "]", ".", "values", ")", "\n", "if", "key", "in", "[", "'pw'", "]", ":", "\n", "            ", "batch_input_var", ".", "append", "(", "np", ".", "array", "(", "data", ",", "dtype", "=", "'float32'", ")", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "batch_input_var", ".", "append", "(", "np", ".", "array", "(", "data", ",", "dtype", "=", "'int32'", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "print", "(", "batch_data", "[", "key", "]", ".", "values", ")", "\n", "", "", "", "return", "batch_input_var", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.nn_utils.get_batch_input_inference": [[30, 55], ["pandas.DataFrame.from_dict", "list", "batch_input_var.append", "numpy.array", "batch_input_var.append", "batch_input_var.append", "numpy.array", "print"], "function", ["None"], ["", "def", "get_batch_input_inference", "(", "dataset", ",", "bs", ",", "args", ",", "idx", "=", "None", ",", "all", "=", "False", ")", ":", "\n", "    ", "if", "all", ":", "\n", "        ", "batch_input", "=", "dataset", "\n", "", "else", ":", "\n", "        ", "batch_input", "=", "dataset", "[", "idx", "*", "bs", ":", "(", "idx", "+", "1", ")", "*", "bs", "]", "\n", "", "batch_data", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "batch_input", ")", "\n", "if", "args", ".", "model", "==", "'RGAT'", ":", "\n", "        ", "target_fields", "=", "[", "'wids'", ",", "'tids'", ",", "'dep_tag_ids'", ",", "'y'", ",", "'pw'", "]", "\n", "", "elif", "args", ".", "model", "in", "[", "'ASGCN'", ",", "'KGNN'", "]", ":", "\n", "        ", "target_fields", "=", "[", "'words'", ",", "'twords'", ",", "'wids'", ",", "'tids'", ",", "'y'", ",", "'pw'", ",", "'adj'", ",", "'mask'", "]", "\n", "", "else", ":", "\n", "        ", "target_fields", "=", "[", "'wids'", ",", "'tids'", ",", "'y'", ",", "'pw'", "]", "\n", "", "batch_input_var", "=", "[", "]", "\n", "for", "key", "in", "target_fields", ":", "\n", "        ", "data", "=", "list", "(", "batch_data", "[", "key", "]", ".", "values", ")", "\n", "if", "key", "in", "[", "'pw'", "]", ":", "\n", "            ", "batch_input_var", ".", "append", "(", "np", ".", "array", "(", "data", ",", "dtype", "=", "'float32'", ")", ")", "\n", "", "elif", "key", "in", "[", "'words'", ",", "'twords'", "]", ":", "\n", "            ", "batch_input_var", ".", "append", "(", "data", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "batch_input_var", ".", "append", "(", "np", ".", "array", "(", "data", ",", "dtype", "=", "'int32'", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "print", "(", "batch_data", "[", "key", "]", ".", "values", ")", "\n", "", "", "", "return", "batch_input_var", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.nn_utils.get_batch_input_bert": [[56, 79], ["pandas.DataFrame.from_dict", "list", "batch_input_var.append", "numpy.array", "batch_input_var.append", "numpy.array", "print"], "function", ["None"], ["", "def", "get_batch_input_bert", "(", "dataset", ",", "bs", ",", "args", ",", "idx", "=", "None", ",", "all", "=", "False", ")", ":", "\n", "    ", "if", "all", ":", "\n", "        ", "batch_input", "=", "dataset", "\n", "", "else", ":", "\n", "        ", "batch_input", "=", "dataset", "[", "idx", "*", "bs", ":", "(", "idx", "+", "1", ")", "*", "bs", "]", "\n", "", "batch_data", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "batch_input", ")", "\n", "if", "args", ".", "model", "==", "'RGAT'", ":", "\n", "        ", "target_fields", "=", "[", "'bert_token'", ",", "'bert_token_aspect'", ",", "'dep_tag_ids'", ",", "'y'", ",", "'pw'", "]", "\n", "", "elif", "args", ".", "model", "in", "[", "'ASGCN'", ",", "'KGNN'", "]", ":", "\n", "        ", "target_fields", "=", "[", "'bert_token'", ",", "'bert_token_aspect'", ",", "'y'", ",", "'pw'", ",", "'adj'", ",", "'mask'", "]", "\n", "", "else", ":", "\n", "        ", "target_fields", "=", "[", "'bert_token'", ",", "'bert_token_aspect'", ",", "'y'", ",", "'pw'", "]", "\n", "", "batch_input_var", "=", "[", "]", "\n", "for", "key", "in", "target_fields", ":", "\n", "        ", "data", "=", "list", "(", "batch_data", "[", "key", "]", ".", "values", ")", "\n", "if", "key", "in", "[", "'pw'", "]", ":", "\n", "            ", "batch_input_var", ".", "append", "(", "np", ".", "array", "(", "data", ",", "dtype", "=", "'float32'", ")", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "batch_input_var", ".", "append", "(", "np", ".", "array", "(", "data", ",", "dtype", "=", "'int32'", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "print", "(", "batch_data", "[", "key", "]", ".", "values", ")", "\n", "", "", "", "return", "batch_input_var", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total._reset_params": [[31, 39], ["model.parameters", "len", "torch.init.xavier_uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "math.sqrt"], "function", ["None"], ["def", "_reset_params", "(", "model", ")", ":", "\n", "    ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "p", ".", "requires_grad", ":", "\n", "            ", "if", "len", "(", "p", ".", "shape", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "p", ")", "\n", "", "else", ":", "\n", "                ", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "p", ".", "shape", "[", "0", "]", ")", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "p", ",", "a", "=", "-", "stdv", ",", "b", "=", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.train": [[40, 160], ["math.ceil", "math.ceil", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model.RGAT.RGAT.train", "range", "result_store_test[].index", "print", "utils.build_dataset", "model.KGNN.KGNN", "main_total._reset_params", "model.RGAT.RGAT.cuda", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adagrad", "torch.optim.Adagrad", "torch.optim.Adagrad", "time.time", "numpy.random.shuffle", "range", "time.time", "train_time.append", "result_store_test[].append", "result_store_test[].append", "print", "sum", "len", "max", "max", "max", "utils.build_dataset", "utils.build_dataset", "model.GCAE.GCAE", "filter", "filter", "model.RGAT.RGAT.train", "F.cross_entropy.backward", "torch.optim.Adagrad.step", "sklearn.metrics.f1_score", "model.ATAE_LSTM.ATAE_LSTM", "model.RGAT.RGAT.parameters", "model.RGAT.RGAT.parameters", "torch.optim.Adagrad.zero_grad", "nn_utils.get_batch_input", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model.RGAT.RGAT.", "torch.cross_entropy", "train_y.cpu", "torch.argmax().cpu", "torch.argmax().cpu", "torch.argmax().cpu", "main_total.eval", "print", "model.ASGCN.ASGCN", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.optim.Adagrad.zero_grad", "nn_utils.get_batch_input", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model.RGAT.RGAT.", "torch.cross_entropy", "nn_utils.get_batch_input", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model.RGAT.RGAT.", "torch.cross_entropy", "model.RGAT.RGAT.state_dict", "torch.save", "torch.save", "torch.save", "max", "max", "model.IAN.IAN", "train_x.cuda", "train_xt.cuda", "train_y.cuda", "train_pw.cuda", "train_adj.cuda", "train_mask.cuda", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.argmax", "torch.argmax", "torch.argmax", "F.cross_entropy.item", "model.TNet.TNet_LF", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "train_x.cuda", "train_xt.cuda", "train_tag.cuda", "train_y.cuda", "train_pw.cuda", "train_x.cuda", "train_xt.cuda", "train_y.cuda", "train_pw.cuda", "[].view", "model.RGAT.RGAT", "print", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "train_y.size", "len", "torch.max", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.train", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_dataset", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total._reset_params", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_dataset", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_dataset", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.train", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.nn_utils.get_batch_input", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.eval", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.nn_utils.get_batch_input", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.nn_utils.get_batch_input", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "", "", "", "def", "train", "(", "args", ",", "times", "=", "0", ")", ":", "\n", "    ", "if", "args", ".", "model", "==", "'KGNN'", ":", "\n", "        ", "dataset", ",", "embeddings", ",", "graph_embeddings", ",", "n_train", ",", "n_test", "=", "build_dataset", "(", "args", "=", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'RGAT'", ":", "\n", "        ", "dataset", ",", "embeddings", ",", "n_train", ",", "n_test", ",", "dep_vocab", "=", "build_dataset", "(", "args", "=", "args", ")", "\n", "", "else", ":", "\n", "        ", "dataset", ",", "embeddings", ",", "n_train", ",", "n_test", "=", "build_dataset", "(", "args", "=", "args", ")", "\n", "\n", "", "args", ".", "embeddings", "=", "embeddings", "\n", "if", "args", ".", "model", "==", "'KGNN'", ":", "\n", "        ", "args", ".", "graph_embeddings", "=", "graph_embeddings", "\n", "", "n_train_batches", "=", "math", ".", "ceil", "(", "n_train", "/", "args", ".", "bs", ")", "\n", "n_test_batches", "=", "math", ".", "ceil", "(", "n_test", "/", "args", ".", "bs", ")", "\n", "train_set", ",", "test_set", "=", "dataset", "\n", "\n", "if", "args", ".", "model", "==", "'KGNN'", ":", "\n", "        ", "model", "=", "KGNN", "(", "args", ")", "\n", "_reset_params", "(", "model", ")", "\n", "", "elif", "args", ".", "model", "==", "'GCAE'", ":", "\n", "        ", "model", "=", "GCAE", "(", "args", "=", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'ATAE'", ":", "\n", "        ", "model", "=", "ATAE_LSTM", "(", "args", "=", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'ASGCN'", ":", "\n", "        ", "model", "=", "ASGCN", "(", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'IAN'", ":", "\n", "        ", "model", "=", "IAN", "(", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'TNet'", ":", "\n", "        ", "model", "=", "TNet_LF", "(", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'RGAT'", ":", "\n", "        ", "model", "=", "RGAT", "(", "args", ",", "dep_tag_num", "=", "len", "(", "dep_vocab", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'model error'", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "# model = torch.nn.DataParallel(model, device_ids=[0, 1])", "\n", "# total_num = sum(p.numel() for p in model.parameters())", "\n", "# trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)", "\n", "\n", "", "train_time", "=", "[", "]", "\n", "result_store_test", "=", "[", "[", "]", ",", "[", "]", "]", "\n", "if", "args", ".", "model", "in", "[", "'ASGCN'", ",", "'KGNN'", ",", "'RGAT'", "]", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ",", "lr", "=", "args", ".", "learning_rate", ")", "\n", "", "else", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adagrad", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ",", "lr", "=", "args", ".", "learning_rate", ")", "\n", "\n", "", "save_acc", ",", "save_f1", "=", "0.0", ",", "0.0", "\n", "model", ".", "train", "(", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "args", ".", "n_epoch", "+", "1", ")", ":", "\n", "        ", "beg", "=", "time", ".", "time", "(", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "train_set", ")", "\n", "max_acc", ",", "max_f1", "=", "0", ",", "0", "\n", "for", "j", "in", "range", "(", "n_train_batches", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "if", "args", ".", "model", "in", "[", "'KGNN'", ",", "'ASGCN'", "]", ":", "\n", "                ", "optimizer", ".", "zero_grad", "(", ")", "\n", "train_x", ",", "train_xt", ",", "train_y", ",", "train_pw", ",", "train_adj", ",", "train_mask", "=", "get_batch_input", "(", "dataset", "=", "train_set", ",", "bs", "=", "args", ".", "bs", ",", "args", "=", "args", ",", "idx", "=", "j", ")", "\n", "train_x", ",", "train_xt", ",", "train_y", ",", "train_pw", ",", "train_adj", ",", "train_mask", "=", "torch", ".", "from_numpy", "(", "train_x", ")", ",", "torch", ".", "from_numpy", "(", "\n", "train_xt", ")", ",", "torch", ".", "from_numpy", "(", "train_y", ")", ".", "long", "(", ")", ",", "torch", ".", "from_numpy", "(", "train_pw", ")", ",", "torch", ".", "from_numpy", "(", "train_adj", ")", ",", "torch", ".", "from_numpy", "(", "train_mask", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "train_x", ",", "train_xt", ",", "train_y", ",", "train_pw", ",", "train_adj", ",", "train_mask", "=", "train_x", ".", "cuda", "(", ")", ",", "train_xt", ".", "cuda", "(", ")", ",", "train_y", ".", "cuda", "(", ")", ",", "train_pw", ".", "cuda", "(", ")", ",", "train_adj", ".", "cuda", "(", ")", ",", "train_mask", ".", "cuda", "(", ")", "\n", "# logit,logit2,logit3,logit4 = model(train_x, train_xt, train_pw, train_adj, train_mask)", "\n", "# loss = F.cross_entropy(logit, train_y)+F.cross_entropy(logit2, train_y)+F.cross_entropy(logit3, train_y)+F.cross_entropy(logit4, train_y)", "\n", "", "logit", "=", "model", "(", "train_x", ",", "train_xt", ",", "train_pw", ",", "train_adj", ",", "train_mask", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logit", ",", "train_y", ")", "\n", "", "elif", "args", ".", "model", "==", "'RGAT'", ":", "\n", "                ", "optimizer", ".", "zero_grad", "(", ")", "\n", "train_x", ",", "train_xt", ",", "train_tag", ",", "train_y", ",", "train_pw", "=", "get_batch_input", "(", "dataset", "=", "train_set", ",", "bs", "=", "args", ".", "bs", ",", "args", "=", "args", ",", "\n", "idx", "=", "j", ")", "\n", "train_x", ",", "train_xt", ",", "train_tag", ",", "train_y", ",", "train_pw", "=", "torch", ".", "from_numpy", "(", "train_x", ")", ",", "torch", ".", "from_numpy", "(", "\n", "train_xt", ")", ",", "torch", ".", "from_numpy", "(", "train_tag", ")", ",", "torch", ".", "from_numpy", "(", "train_y", ")", ".", "long", "(", ")", ",", "torch", ".", "from_numpy", "(", "train_pw", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "train_x", ",", "train_xt", ",", "train_tag", ",", "train_y", ",", "train_pw", "=", "train_x", ".", "cuda", "(", ")", ",", "train_xt", ".", "cuda", "(", ")", ",", "train_tag", ".", "cuda", "(", ")", ",", "train_y", ".", "cuda", "(", ")", ",", "train_pw", ".", "cuda", "(", ")", "\n", "", "logit", "=", "model", "(", "train_x", ",", "train_xt", ",", "train_tag", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logit", ",", "train_y", ")", "\n", "", "else", ":", "\n", "# optimizer.zero_grad()", "\n", "                ", "train_x", ",", "train_xt", ",", "train_y", ",", "train_pw", "=", "get_batch_input", "(", "dataset", "=", "train_set", ",", "bs", "=", "args", ".", "bs", ",", "args", "=", "args", ",", "idx", "=", "j", ")", "\n", "train_x", ",", "train_xt", ",", "train_y", ",", "train_pw", "=", "torch", ".", "from_numpy", "(", "train_x", ")", ",", "torch", ".", "from_numpy", "(", "\n", "train_xt", ")", ",", "torch", ".", "from_numpy", "(", "train_y", ")", ".", "long", "(", ")", ",", "torch", ".", "from_numpy", "(", "train_pw", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "train_x", ",", "train_xt", ",", "train_y", ",", "train_pw", "=", "train_x", ".", "cuda", "(", ")", ",", "train_xt", ".", "cuda", "(", ")", ",", "train_y", ".", "cuda", "(", ")", ",", "train_pw", ".", "cuda", "(", ")", "\n", "", "logit", "=", "model", "(", "train_x", ",", "train_xt", ",", "train_pw", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logit", ",", "train_y", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "corrects", "=", "(", "torch", ".", "max", "(", "logit", ",", "1", ")", "[", "1", "]", ".", "view", "(", "train_y", ".", "size", "(", ")", ")", ".", "data", "==", "train_y", ".", "data", ")", ".", "sum", "(", ")", "\n", "accuracy", "=", "100.0", "*", "corrects", "/", "train_y", ".", "shape", "[", "0", "]", "\n", "f1", "=", "metrics", ".", "f1_score", "(", "train_y", ".", "cpu", "(", ")", ",", "torch", ".", "argmax", "(", "logit", ",", "-", "1", ")", ".", "cpu", "(", ")", ",", "labels", "=", "[", "0", ",", "1", ",", "2", "]", ",", "average", "=", "'macro'", ")", "\n", "# if j % (n_train_batches - 1) == 0:", "\n", "if", "j", "%", "10", "==", "0", ":", "\n", "                ", "eval_acc", ",", "eval_f1", "=", "eval", "(", "model", ",", "args", ",", "test_set", ",", "n_test_batches", ")", "\n", "if", "max_acc", "<", "eval_acc", ":", "\n", "                    ", "max_acc", "=", "eval_acc", "\n", "", "if", "max_f1", "<", "eval_f1", ":", "\n", "                    ", "max_f1", "=", "eval_f1", "\n", "\n", "", "if", "save_acc", "<", "eval_acc", ":", "\n", "                    ", "save_acc", "=", "eval_acc", "\n", "model_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "# del model_dict['embed.weight']", "\n", "# del model_dict['graph_embed.weight']", "\n", "torch", ".", "save", "(", "model_dict", ",", "'./model_weight/temp/{}_{}_time{}.pth'", ".", "format", "(", "args", ".", "model", ",", "args", ".", "ds_name", ",", "times", ")", ")", "\n", "", "if", "save_f1", "<", "eval_f1", ":", "\n", "                    ", "save_f1", "=", "eval_f1", "\n", "\n", "", "print", "(", "\n", "'\\r - loss: {:.6f} f1:{:.4f} acc: {:.4f}%({}/{})'", ".", "format", "(", "loss", ".", "item", "(", ")", ",", "f1", ",", "accuracy", ",", "corrects", ",", "\n", "train_y", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "", "test_acc", ",", "test_f1", "=", "max_acc", ",", "max_f1", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "train_time", ".", "append", "(", "end", "-", "beg", ")", "\n", "result_store_test", "[", "0", "]", ".", "append", "(", "test_acc", ")", "\n", "result_store_test", "[", "1", "]", ".", "append", "(", "test_f1", ")", "\n", "print", "(", "\"In Epoch %s: test_accuracy: %.2f, test_macro-f1: %.2f\\n\"", "%", "(", "i", ",", "test_acc", "*", "100", ",", "test_f1", "*", "100", ")", ")", "\n", "", "avg_time", "=", "sum", "(", "train_time", ")", "/", "len", "(", "train_time", ")", "\n", "best_index_acc", "=", "result_store_test", "[", "0", "]", ".", "index", "(", "max", "(", "result_store_test", "[", "0", "]", ")", ")", "\n", "print", "(", "\"Runs: %s Best model in Epoch %s: test accuracy: %.2f, macro-f1: %.2f ,avg_time: %.2f\\n\"", "%", "(", "times", ",", "\n", "best_index_acc", "+", "1", ",", "max", "(", "result_store_test", "[", "0", "]", ")", "*", "100", ",", "max", "(", "result_store_test", "[", "1", "]", ")", "*", "100", ",", "avg_time", ")", ")", "\n", "return", "max", "(", "result_store_test", "[", "0", "]", ")", ",", "max", "(", "result_store_test", "[", "1", "]", ")", ",", "avg_time", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.train_bert": [[161, 250], ["len", "len", "math.ceil", "math.ceil", "BertModel.from_pretrained", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "model.KGNN.KGNN_BERT.train", "range", "result_store_test[].index", "print", "print", "utils.build_dataset", "utils.build_dataset", "ASGCN_BERT", "main_total._reset_params", "model.KGNN.KGNN_BERT.cuda", "filter", "time.time", "numpy.random.shuffle", "range", "print", "time.time", "train_time.append", "result_store_test[].append", "result_store_test[].append", "print", "print", "sum", "len", "max", "max", "max", "model.KGNN.KGNN_BERT", "main_total._reset_params", "model.KGNN.KGNN_BERT.parameters", "model.KGNN.KGNN_BERT.train", "torch.optim.Adam.zero_grad", "nn_utils.get_batch_input_bert", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model.KGNN.KGNN_BERT.", "torch.cross_entropy", "F.cross_entropy.backward", "torch.optim.Adam.step", "sklearn.metrics.f1_score", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "train_y.cpu", "torch.argmax().cpu", "torch.argmax().cpu", "torch.argmax().cpu", "main_total.eval_bert", "print", "max", "max", "max", "max", "train_x.cuda", "train_xt.cuda", "train_y.cuda", "train_pw.cuda", "train_adj.cuda", "train_mask.cuda", "model.KGNN.KGNN_BERT.state_dict", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.argmax", "torch.argmax", "torch.argmax", "torch.save", "torch.save", "torch.save", "F.cross_entropy.item", "[].view", "model.state_dict.", "train_y.size", "torch.max", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.train", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_dataset", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_dataset", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total._reset_params", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total._reset_params", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.train", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.nn_utils.get_batch_input_bert", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.eval_bert", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "train_bert", "(", "args", ",", "path", ",", "is_save", "=", "False", ",", "is_bert", "=", "True", ")", ":", "\n", "    ", "if", "args", ".", "model", "==", "'KGNN'", ":", "\n", "        ", "dataset", ",", "graph_embeddings", ",", "n_train", ",", "n_test", "=", "build_dataset", "(", "args", "=", "args", ",", "is_bert", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "dataset", ",", "n_train", ",", "n_test", "=", "build_dataset", "(", "args", "=", "args", ",", "is_bert", "=", "True", ")", "\n", "\n", "", "args", ".", "sent_len", "=", "len", "(", "dataset", "[", "0", "]", "[", "0", "]", "[", "'wids'", "]", ")", "\n", "args", ".", "target_len", "=", "len", "(", "dataset", "[", "0", "]", "[", "0", "]", "[", "'tids'", "]", ")", "\n", "if", "args", ".", "model", "==", "'KGNN'", ":", "\n", "        ", "args", ".", "graph_embeddings", "=", "graph_embeddings", "\n", "", "n_train_batches", "=", "math", ".", "ceil", "(", "n_train", "/", "args", ".", "bs", ")", "\n", "n_test_batches", "=", "math", ".", "ceil", "(", "n_test", "/", "args", ".", "bs", ")", "\n", "train_set", ",", "test_set", "=", "dataset", "\n", "\n", "bert", "=", "BertModel", ".", "from_pretrained", "(", "r'../bert-base-uncased'", ")", "\n", "if", "args", ".", "model", "==", "'ASGCN'", ":", "\n", "        ", "model", "=", "ASGCN_BERT", "(", "bert", "=", "bert", ",", "args", "=", "args", ")", "\n", "_reset_params", "(", "model", ")", "\n", "", "elif", "args", ".", "model", "==", "'KGNN'", ":", "\n", "        ", "model", "=", "KGNN_BERT", "(", "bert", "=", "bert", ",", "args", "=", "args", ")", "\n", "_reset_params", "(", "model", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "# model = torch.nn.DataParallel(model, device_ids=[0, 1])", "\n", "", "train_time", "=", "[", "]", "\n", "result_store_test", "=", "[", "[", "]", ",", "[", "]", "]", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ",", "lr", "=", "args", ".", "learning_rate", ")", "#,weight_decay=0.0001", "\n", "model", ".", "train", "(", ")", "\n", "save_acc", ",", "save_f1", "=", "0.0", ",", "0.0", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "args", ".", "n_epoch", "+", "1", ")", ":", "\n", "        ", "beg", "=", "time", ".", "time", "(", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "train_set", ")", "\n", "max_acc", ",", "max_f1", "=", "0", ",", "0", "\n", "for", "j", "in", "range", "(", "n_train_batches", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "######bert######", "\n", "train_x", ",", "train_xt", ",", "train_y", ",", "train_pw", ",", "train_adj", ",", "train_mask", "=", "get_batch_input_bert", "(", "dataset", "=", "train_set", ",", "bs", "=", "args", ".", "bs", ",", "\n", "args", "=", "args", ",", "idx", "=", "j", ")", "\n", "train_x", ",", "train_xt", ",", "train_y", ",", "train_pw", ",", "train_adj", ",", "train_mask", "=", "torch", ".", "from_numpy", "(", "train_x", ")", ",", "torch", ".", "from_numpy", "(", "\n", "train_xt", ")", ",", "torch", ".", "from_numpy", "(", "train_y", ")", ".", "long", "(", ")", ",", "torch", ".", "from_numpy", "(", "train_pw", ")", ",", "torch", ".", "from_numpy", "(", "\n", "train_adj", ")", ",", "torch", ".", "from_numpy", "(", "train_mask", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "train_x", ",", "train_xt", ",", "train_y", ",", "train_pw", ",", "train_adj", ",", "train_mask", "=", "train_x", ".", "cuda", "(", ")", ",", "train_xt", ".", "cuda", "(", ")", ",", "train_y", ".", "cuda", "(", ")", ",", "train_pw", ".", "cuda", "(", ")", ",", "train_adj", ".", "cuda", "(", ")", ",", "train_mask", ".", "cuda", "(", ")", "\n", "", "logit", "=", "model", "(", "train_x", ",", "train_xt", ",", "train_pw", ",", "train_adj", ",", "train_mask", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logit", ",", "train_y", ")", "\n", "######bert######", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "corrects", "=", "(", "torch", ".", "max", "(", "logit", ",", "1", ")", "[", "1", "]", ".", "view", "(", "train_y", ".", "size", "(", ")", ")", ".", "data", "==", "train_y", ".", "data", ")", ".", "sum", "(", ")", "\n", "accuracy", "=", "100.0", "*", "corrects", "/", "train_y", ".", "shape", "[", "0", "]", "\n", "f1", "=", "metrics", ".", "f1_score", "(", "train_y", ".", "cpu", "(", ")", ",", "torch", ".", "argmax", "(", "logit", ",", "-", "1", ")", ".", "cpu", "(", ")", ",", "labels", "=", "[", "0", ",", "1", ",", "2", "]", ",", "average", "=", "'macro'", ")", "\n", "if", "j", "%", "(", "n_train_batches", "-", "1", ")", "==", "0", ":", "\n", "# if j % 10 == 0:", "\n", "                ", "eval_acc", ",", "eval_f1", "=", "eval_bert", "(", "model", ",", "args", ",", "test_set", ",", "n_test_batches", ")", "\n", "if", "max_acc", "<", "eval_acc", ":", "\n", "                    ", "max_acc", "=", "eval_acc", "\n", "", "if", "max_f1", "<", "eval_f1", ":", "\n", "                    ", "max_f1", "=", "eval_f1", "\n", "\n", "", "if", "save_acc", "<", "eval_acc", ":", "\n", "                    ", "save_acc", "=", "eval_acc", "\n", "model_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "if", "is_save", ":", "\n", "                        ", "torch", ".", "save", "(", "model_dict", "(", ")", ",", "save_path", ")", "\n", "", "", "if", "max_f1", "<", "eval_f1", ":", "\n", "                    ", "max_f1", "=", "eval_f1", "\n", "", "", "if", "j", "%", "10", "==", "0", ":", "\n", "                ", "print", "(", "\n", "'\\r - loss: {:.6f} f1:{:.4f} acc: {:.4f}%({}/{})'", ".", "format", "(", "loss", ".", "item", "(", ")", ",", "f1", ",", "accuracy", ",", "corrects", ",", "\n", "train_y", ".", "shape", "[", "0", "]", ")", ")", "\n", "", "", "print", "(", "'\\nEvaluation - acc: {:.4f} f1: {:.4f} '", ".", "format", "(", "max_acc", ",", "max_f1", ")", ")", "\n", "test_acc", ",", "test_f1", "=", "max_acc", ",", "max_f1", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "train_time", ".", "append", "(", "end", "-", "beg", ")", "\n", "result_store_test", "[", "0", "]", ".", "append", "(", "test_acc", ")", "\n", "result_store_test", "[", "1", "]", ".", "append", "(", "test_f1", ")", "\n", "print", "(", "\"In Epoch %s: val_accuracy: %.2f, val_macro-f1: %.2f, cost %f s\\n\"", "%", "(", "\n", "i", ",", "max_acc", "*", "100", ",", "max_f1", "*", "100", ",", "end", "-", "beg", ")", ")", "\n", "print", "(", "\"In Epoch %s: test_accuracy: %.2f, test_macro-f1: %.2f\\n\"", "%", "(", "i", ",", "test_acc", "*", "100", ",", "test_f1", "*", "100", ")", ")", "\n", "", "avg_time", "=", "sum", "(", "train_time", ")", "/", "len", "(", "train_time", ")", "\n", "best_index_acc", "=", "result_store_test", "[", "0", "]", ".", "index", "(", "max", "(", "result_store_test", "[", "0", "]", ")", ")", "\n", "print", "(", "\"Best val model: val accuracy: %.2f, macro-f1: %.2f \"", "%", "(", "max", "(", "result_store_val", "[", "0", "]", ")", ",", "max", "(", "result_store_val", "[", "1", "]", ")", ")", ")", "\n", "print", "(", "\"Best model in Epoch %s: test accuracy: %.2f, macro-f1: %.2f ,avg_time: %.2f\\n\"", "%", "(", "\n", "best_index_acc", "+", "1", ",", "max", "(", "result_store_test", "[", "0", "]", ")", ",", "max", "(", "result_store_test", "[", "1", "]", ")", ",", "avg_time", ")", ")", "\n", "return", "max", "(", "result_store_test", "[", "0", "]", ")", ",", "max", "(", "result_store_test", "[", "1", "]", ")", ",", "avg_time", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.eval": [[251, 321], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "sklearn.metrics.f1_score", "F.cross_entropy.item", "test_y.size", "F.cross_entropy.item", "torch.cat.cpu", "torch.argmax().cpu", "torch.argmax().cpu", "torch.argmax().cpu", "nn_utils.get_batch_input_inference", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model", "torch.cross_entropy", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "nn_utils.get_batch_input", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model", "torch.cross_entropy", "nn_utils.get_batch_input", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model", "torch.cross_entropy", "torch.argmax", "torch.argmax", "torch.argmax", "test_x.cuda", "test_xt.cuda", "test_y.cuda", "test_pw.cuda", "test_adj.cuda", "test_mask.cuda", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "test_x.cuda", "test_xt.cuda", "test_tag.cuda", "test_y.cuda", "test_pw.cuda", "test_x.cuda", "test_xt.cuda", "test_y.cuda", "test_pw.cuda", "[].view", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "test_y.size", "torch.max", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.eval", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.nn_utils.get_batch_input_inference", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.nn_utils.get_batch_input", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.nn_utils.get_batch_input", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "eval", "(", "model", ",", "args", ",", "test_set", ",", "n_test_batches", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "t_targets_all", ",", "t_outputs_all", "=", "None", ",", "None", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "corrects", ",", "f1", ",", "avg_loss", ",", "size", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "loss", "=", "None", "\n", "for", "j", "in", "range", "(", "n_test_batches", ")", ":", "\n", "            ", "if", "args", ".", "model", "in", "[", "'KGNN'", ",", "'ASGCN'", "]", ":", "\n", "                ", "test_words", ",", "test_twords", ",", "test_x", ",", "test_xt", ",", "test_y", ",", "test_pw", ",", "test_adj", ",", "test_mask", "=", "get_batch_input_inference", "(", "dataset", "=", "test_set", ",", "bs", "=", "args", ".", "bs", ",", "args", "=", "args", ",", "idx", "=", "j", ")", "\n", "test_x", ",", "test_xt", ",", "test_y", ",", "test_pw", ",", "test_adj", ",", "test_mask", "=", "torch", ".", "from_numpy", "(", "test_x", ")", ",", "torch", ".", "from_numpy", "(", "\n", "test_xt", ")", ",", "torch", ".", "from_numpy", "(", "test_y", ")", ".", "long", "(", ")", ",", "torch", ".", "from_numpy", "(", "test_pw", ")", ",", "torch", ".", "from_numpy", "(", "test_adj", ")", ",", "torch", ".", "from_numpy", "(", "test_mask", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "test_x", ",", "test_xt", ",", "test_y", ",", "test_pw", ",", "test_adj", ",", "test_mask", "=", "test_x", ".", "cuda", "(", ")", ",", "test_xt", ".", "cuda", "(", ")", ",", "test_y", ".", "cuda", "(", ")", ",", "test_pw", ".", "cuda", "(", ")", ",", "test_adj", ".", "cuda", "(", ")", ",", "test_mask", ".", "cuda", "(", ")", "\n", "# logit,logit2,logit3,logit4 = model(test_x, test_xt, test_pw, test_adj, test_mask)", "\n", "# loss = F.cross_entropy(logit, test_y, reduction='sum')+0.1*F.cross_entropy(logit2, test_y, reduction='sum')+\\", "\n", "#        0.1*F.cross_entropy(logit3, test_y, reduction='sum')+0.1*F.cross_entropy(logit4, test_y, reduction='sum')", "\n", "", "logit", "=", "model", "(", "test_x", ",", "test_xt", ",", "test_pw", ",", "test_adj", ",", "test_mask", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logit", ",", "test_y", ",", "reduction", "=", "'sum'", ")", "\n", "\n", "# with open('KGAN_restaurant_result.txt','a',encoding='utf-8') as f:", "\n", "#     logit2,logit3,logit4=logit2.tolist(),logit3.tolist(),logit4.tolist()", "\n", "#     predict=torch.max(logit, 1)[1].view(test_y.size()).data", "\n", "#     for idx in range(args.bs):", "\n", "#         s_c=['%.2f' % i for i in logit3[idx][:len(test_words[idx])]]", "\n", "#         s_s=['%.2f' % i for i in logit2[idx][:len(test_words[idx])]]", "\n", "#         s_k=['%.2f' % i for i in logit4[idx][:len(test_words[idx])]]", "\n", "#         f.write('Sentence-words:'+'\\t'.join(test_words[idx])+'\\n')", "\n", "#         f.write('aspect terms:'+'\\t'.join(test_twords[idx])+'\\n')", "\n", "#         f.write('contextual:'+'\\t'.join(s_c)+'\\n')", "\n", "#         f.write('syntactic:'+'\\t'.join(s_s)+'\\n')", "\n", "#         f.write('knowledge:'+'\\t'.join(s_k)+'\\n')", "\n", "#         f.write('Label: '+str(test_y[idx])+'\\t'+'Prediction: '+str(predict[idx])+'\\t')", "\n", "#         f.write('True' if test_y[idx].data==predict[idx] else 'False')", "\n", "#         f.write('\\n'+'\\n')", "\n", "\n", "", "elif", "args", ".", "model", "==", "'RGAT'", ":", "\n", "                ", "test_x", ",", "test_xt", ",", "test_tag", ",", "test_y", ",", "test_pw", "=", "get_batch_input", "(", "dataset", "=", "test_set", ",", "bs", "=", "args", ".", "bs", ",", "args", "=", "args", ",", "\n", "idx", "=", "j", ")", "\n", "test_x", ",", "test_xt", ",", "test_tag", ",", "test_y", ",", "test_pw", "=", "torch", ".", "from_numpy", "(", "test_x", ")", ",", "torch", ".", "from_numpy", "(", "test_xt", ")", ",", "torch", ".", "from_numpy", "(", "test_tag", ")", ",", "torch", ".", "from_numpy", "(", "test_y", ")", ".", "long", "(", ")", ",", "torch", ".", "from_numpy", "(", "test_pw", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "test_x", ",", "test_xt", ",", "test_tag", ",", "test_y", ",", "test_pw", "=", "test_x", ".", "cuda", "(", ")", ",", "test_xt", ".", "cuda", "(", ")", ",", "test_tag", ".", "cuda", "(", ")", ",", "test_y", ".", "cuda", "(", ")", ",", "test_pw", ".", "cuda", "(", ")", "\n", "", "logit", "=", "model", "(", "test_x", ",", "test_xt", ",", "test_tag", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logit", ",", "test_y", ",", "reduction", "=", "'sum'", ")", "\n", "", "else", ":", "\n", "                ", "test_x", ",", "test_xt", ",", "test_y", ",", "test_pw", "=", "get_batch_input", "(", "dataset", "=", "test_set", ",", "bs", "=", "args", ".", "bs", ",", "args", "=", "args", ",", "\n", "idx", "=", "j", ")", "\n", "test_x", ",", "test_xt", ",", "test_y", ",", "test_pw", "=", "torch", ".", "from_numpy", "(", "test_x", ")", ",", "torch", ".", "from_numpy", "(", "test_xt", ")", ",", "torch", ".", "from_numpy", "(", "\n", "test_y", ")", ".", "long", "(", ")", ",", "torch", ".", "from_numpy", "(", "test_pw", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "test_x", ",", "test_xt", ",", "test_y", ",", "test_pw", "=", "test_x", ".", "cuda", "(", ")", ",", "test_xt", ".", "cuda", "(", ")", ",", "test_y", ".", "cuda", "(", ")", ",", "test_pw", ".", "cuda", "(", ")", "\n", "", "logit", "=", "model", "(", "test_x", ",", "test_xt", ",", "test_pw", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logit", ",", "test_y", ",", "reduction", "=", "'sum'", ")", "\n", "", "avg_loss", "+=", "loss", ".", "item", "(", ")", "\n", "size", "+=", "test_y", ".", "size", "(", "0", ")", "\n", "corrects", "+=", "(", "torch", ".", "max", "(", "logit", ",", "1", ")", "\n", "[", "1", "]", ".", "view", "(", "test_y", ".", "size", "(", ")", ")", ".", "data", "==", "test_y", ".", "data", ")", ".", "sum", "(", ")", "\n", "if", "t_targets_all", "is", "None", ":", "\n", "                ", "t_targets_all", "=", "test_y", "\n", "t_outputs_all", "=", "logit", "\n", "", "else", ":", "\n", "                ", "t_targets_all", "=", "torch", ".", "cat", "(", "(", "t_targets_all", ",", "test_y", ")", ",", "dim", "=", "0", ")", "\n", "t_outputs_all", "=", "torch", ".", "cat", "(", "(", "t_outputs_all", ",", "logit", ")", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "avg_loss", "=", "loss", ".", "item", "(", ")", "/", "size", "\n", "accuracy", "=", "1.0", "*", "corrects", "/", "size", "\n", "F1", "=", "metrics", ".", "f1_score", "(", "t_targets_all", ".", "cpu", "(", ")", ",", "torch", ".", "argmax", "(", "t_outputs_all", ",", "-", "1", ")", ".", "cpu", "(", ")", ",", "labels", "=", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "average", "=", "'macro'", ")", "\n", "", "return", "accuracy", ",", "F1", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.eval_bert": [[322, 354], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "len", "sklearn.metrics.f1_score", "nn_utils.get_batch_input_bert", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model", "torch.cross_entropy", "F.cross_entropy.item", "torch.cat.cpu", "torch.argmax().cpu", "torch.argmax().cpu", "torch.argmax().cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "test_x.cuda", "test_xt.cuda", "test_y.cuda", "test_pw.cuda", "test_adj.cuda", "test_mask.cuda", "torch.argmax", "torch.argmax", "torch.argmax", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "[].view", "test_y.size", "torch.max", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.eval", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.nn_utils.get_batch_input_bert", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "eval_bert", "(", "model", ",", "args", ",", "test_set", ",", "n_test_batches", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "t_targets_all", ",", "t_outputs_all", "=", "None", ",", "None", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "corrects", ",", "f1", ",", "avg_loss", "=", "0", ",", "0", ",", "0", "\n", "loss", "=", "None", "\n", "for", "j", "in", "range", "(", "n_test_batches", ")", ":", "\n", "######bert######", "\n", "            ", "test_x", ",", "test_xt", ",", "test_y", ",", "test_pw", ",", "test_adj", ",", "test_mask", "=", "get_batch_input_bert", "(", "\n", "dataset", "=", "test_set", ",", "bs", "=", "args", ".", "bs", ",", "args", "=", "args", ",", "idx", "=", "j", ")", "\n", "test_x", ",", "test_xt", ",", "test_y", ",", "test_pw", ",", "test_adj", ",", "test_mask", "=", "torch", ".", "from_numpy", "(", "test_x", ")", ",", "torch", ".", "from_numpy", "(", "\n", "test_xt", ")", ",", "torch", ".", "from_numpy", "(", "test_y", ")", ".", "long", "(", ")", ",", "torch", ".", "from_numpy", "(", "test_pw", ")", ",", "torch", ".", "from_numpy", "(", "\n", "test_adj", ")", ",", "torch", ".", "from_numpy", "(", "test_mask", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "test_x", ",", "test_xt", ",", "test_y", ",", "test_pw", ",", "test_adj", ",", "test_mask", "=", "test_x", ".", "cuda", "(", ")", ",", "test_xt", ".", "cuda", "(", ")", ",", "test_y", ".", "cuda", "(", ")", ",", "test_pw", ".", "cuda", "(", ")", ",", "test_adj", ".", "cuda", "(", ")", ",", "test_mask", ".", "cuda", "(", ")", "\n", "", "logit", "=", "model", "(", "test_x", ",", "test_xt", ",", "test_pw", ",", "test_adj", ",", "test_mask", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logit", ",", "test_y", ",", "reduction", "=", "'sum'", ")", "\n", "avg_loss", "+=", "loss", ".", "item", "(", ")", "\n", "corrects", "+=", "(", "torch", ".", "max", "(", "logit", ",", "1", ")", "\n", "[", "1", "]", ".", "view", "(", "test_y", ".", "size", "(", ")", ")", ".", "data", "==", "test_y", ".", "data", ")", ".", "sum", "(", ")", "\n", "if", "t_targets_all", "is", "None", ":", "\n", "                ", "t_targets_all", "=", "test_y", "\n", "t_outputs_all", "=", "logit", "\n", "", "else", ":", "\n", "                ", "t_targets_all", "=", "torch", ".", "cat", "(", "(", "t_targets_all", ",", "test_y", ")", ",", "dim", "=", "0", ")", "\n", "t_outputs_all", "=", "torch", ".", "cat", "(", "(", "t_outputs_all", ",", "logit", ")", ",", "dim", "=", "0", ")", "\n", "", "", "size", "=", "len", "(", "test_set", ")", "\n", "accuracy", "=", "1.0", "*", "corrects", "/", "size", "\n", "F1", "=", "metrics", ".", "f1_score", "(", "t_targets_all", ".", "cpu", "(", ")", ",", "torch", ".", "argmax", "(", "t_outputs_all", ",", "-", "1", ")", ".", "cpu", "(", ")", ",", "labels", "=", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "average", "=", "'macro'", ")", "\n", "", "return", "accuracy", ",", "F1", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.inference": [[355, 410], ["utils.build_dataset", "len", "len", "math.ceil", "BertModel.from_pretrained", "model.GCAE.GCAE_Bert().cuda", "model.RGAT.RGAT.load_state_dict", "main_total.eval_bert", "math.ceil", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.load", "torch.load", "torch.load", "model.RGAT.RGAT.state_dict", "model.state_dict.update", "model.RGAT.RGAT.load_state_dict", "time.time", "main_total.eval", "time.time", "print", "torch.load", "torch.load", "torch.load", "utils.build_dataset", "model.KGNN.KGNN", "main_total._reset_params", "model.RGAT.RGAT.cuda", "model.GCAE.GCAE_Bert", "utils.build_dataset", "utils.build_dataset", "model.GCAE.GCAE", "torch.load.items", "model.ATAE_LSTM.ATAE_LSTM", "model.ASGCN.ASGCN", "model.IAN.IAN", "model.TNet.TNet_LF", "model.RGAT.RGAT", "print", "len"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_dataset", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.eval_bert", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total.eval", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_dataset", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.main_total._reset_params", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_dataset", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_dataset"], ["", "def", "inference", "(", "args", ",", "model_path", "=", "None", ")", ":", "\n", "    ", "if", "args", ".", "is_bert", "==", "1", ":", "\n", "        ", "dataset", ",", "n_train", ",", "n_test", "=", "build_dataset", "(", "ds_name", "=", "args", ".", "ds_name", ",", "bs", "=", "args", ".", "bs", ",", "dim_w", "=", "args", ".", "dim_w", ",", "\n", "is_bert", "=", "True", ")", "\n", "\n", "args", ".", "sent_len", "=", "len", "(", "dataset", "[", "0", "]", "[", "0", "]", "[", "'wids'", "]", ")", "\n", "args", ".", "target_len", "=", "len", "(", "dataset", "[", "0", "]", "[", "0", "]", "[", "'tids'", "]", ")", "\n", "n_test_batches", "=", "math", ".", "ceil", "(", "n_test", "/", "args", ".", "bs", ")", "\n", "train_set", ",", "test_set", "=", "dataset", "\n", "bert", "=", "BertModel", ".", "from_pretrained", "(", "r'../bert-base-uncased'", ")", "\n", "model", "=", "GCAE_Bert", "(", "bert", "=", "bert", ")", ".", "cuda", "(", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_path", ")", ")", "\n", "test_acc", ",", "test_f1", "=", "eval_bert", "(", "model", ",", "args", ",", "test_set", ",", "n_test_batches", ",", "is_bert", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "model", "==", "'KGNN'", ":", "\n", "            ", "dataset", ",", "embeddings", ",", "graph_embeddings", ",", "n_train", ",", "n_test", "=", "build_dataset", "(", "args", "=", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'RGAT'", ":", "\n", "            ", "dataset", ",", "embeddings", ",", "n_train", ",", "n_test", ",", "dep_vocab", "=", "build_dataset", "(", "args", "=", "args", ")", "\n", "", "else", ":", "\n", "            ", "dataset", ",", "embeddings", ",", "n_train", ",", "n_test", "=", "build_dataset", "(", "args", "=", "args", ")", "\n", "", "args", ".", "embeddings", "=", "embeddings", "\n", "if", "args", ".", "model", "==", "'KGNN'", ":", "\n", "            ", "args", ".", "graph_embeddings", "=", "graph_embeddings", "\n", "", "n_test_batches", "=", "math", ".", "ceil", "(", "n_test", "/", "args", ".", "bs", ")", "\n", "train_set", ",", "test_set", "=", "dataset", "\n", "if", "args", ".", "model", "==", "'KGNN'", ":", "\n", "            ", "model", "=", "KGNN", "(", "args", ")", "\n", "_reset_params", "(", "model", ")", "\n", "", "elif", "args", ".", "model", "==", "'GCAE'", ":", "\n", "            ", "model", "=", "GCAE", "(", "args", "=", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'ATAE'", ":", "\n", "            ", "model", "=", "ATAE_LSTM", "(", "args", "=", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'ASGCN'", ":", "\n", "            ", "model", "=", "ASGCN", "(", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'IAN'", ":", "\n", "            ", "model", "=", "IAN", "(", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'TNet'", ":", "\n", "            ", "model", "=", "TNet_LF", "(", "args", ")", "\n", "", "elif", "args", ".", "model", "==", "'RGAT'", ":", "\n", "            ", "model", "=", "RGAT", "(", "args", ",", "dep_tag_num", "=", "len", "(", "dep_vocab", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'model error'", ")", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "", "save_dict", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "'cuda'", ")", "\n", "model_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "pretrained_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "save_dict", ".", "items", "(", ")", "if", "k", "in", "model_dict", "}", "\n", "model_dict", ".", "update", "(", "pretrained_dict", ")", "\n", "model", ".", "load_state_dict", "(", "model_dict", ")", "\n", "# model.load_state_dict(torch.load(model_path,map_location='cuda'))", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "test_acc", ",", "test_f1", "=", "eval", "(", "model", ",", "args", ",", "test_set", ",", "n_test_batches", ")", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'test_time: %.4f'", "%", "(", "end_time", "-", "start_time", ")", ")", "\n", "", "return", "test_acc", ",", "test_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_dataset": [[13, 19], ["len", "new_dataset.extend"], "function", ["None"], ["def", "pad_dataset", "(", "dataset", ",", "bs", ")", ":", "\n", "    ", "n_records", "=", "len", "(", "dataset", ")", "\n", "n_padded", "=", "bs", "-", "n_records", "%", "bs", "\n", "new_dataset", "=", "[", "t", "for", "t", "in", "dataset", "]", "\n", "new_dataset", ".", "extend", "(", "dataset", "[", ":", "n_padded", "]", ")", "\n", "return", "new_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq": [[20, 31], ["len", "range", "numpy.pad", "isinstance", "len", "[].append"], "function", ["None"], ["", "def", "pad_seq", "(", "dataset", ",", "field", ",", "max_len", ",", "symbol", ")", ":", "\n", "    ", "n_records", "=", "len", "(", "dataset", ")", "\n", "for", "i", "in", "range", "(", "n_records", ")", ":", "\n", "        ", "if", "field", "==", "'adj'", ":", "\n", "            ", "dataset", "[", "i", "]", "[", "field", "]", "=", "np", ".", "pad", "(", "dataset", "[", "i", "]", "[", "field", "]", ",", "(", "(", "0", ",", "max_len", "-", "dataset", "[", "i", "]", "[", "field", "]", ".", "shape", "[", "0", "]", ")", ",", "(", "0", ",", "max_len", "-", "dataset", "[", "i", "]", "[", "field", "]", ".", "shape", "[", "0", "]", ")", ")", ",", "'constant'", ")", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "dataset", "[", "i", "]", "[", "field", "]", ",", "list", ")", "\n", "while", "len", "(", "dataset", "[", "i", "]", "[", "field", "]", ")", "<", "max_len", ":", "\n", "                ", "dataset", "[", "i", "]", "[", "field", "]", ".", "append", "(", "symbol", ")", "\n", "", "", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read": [[32, 86], ["open", "line.strip().split", "range", "line.strip", "words.copy", "target_words.copy", "len", "len", "d.copy", "len", "dataset.append", "line.strip", "words.append", "target_words.append", "words.append", "d.append", "d.append", "t.strip", "t.strip", "line.strip().split.index"], "function", ["None"], ["", "def", "read", "(", "path", ")", ":", "\n", "    ", "dataset", "=", "[", "]", "\n", "sid", "=", "0", "# id", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf-8'", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "record", "=", "{", "}", "\n", "tokens", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "words", ",", "target_words", "=", "[", "]", ",", "[", "]", "\n", "d", "=", "[", "]", "\n", "find_label", "=", "False", "\n", "for", "t", "in", "tokens", ":", "\n", "                ", "if", "'/p'", "in", "t", "or", "'/n'", "in", "t", "or", "'/0'", "in", "t", ":", "\n", "                    ", "end", "=", "'xx'", "\n", "y", "=", "0", "\n", "if", "'/p'", "in", "t", ":", "\n", "                        ", "end", "=", "'/p'", "\n", "y", "=", "0", "\n", "", "elif", "'/n'", "in", "t", ":", "\n", "                        ", "end", "=", "'/n'", "\n", "y", "=", "1", "\n", "", "elif", "'/0'", "in", "t", ":", "\n", "                        ", "end", "=", "'/0'", "\n", "y", "=", "2", "\n", "", "words", ".", "append", "(", "t", ".", "strip", "(", "end", ")", ")", "\n", "target_words", ".", "append", "(", "t", ".", "strip", "(", "end", ")", ")", "\n", "\n", "if", "not", "find_label", ":", "\n", "                        ", "find_label", "=", "True", "\n", "record", "[", "'y'", "]", "=", "y", "\n", "left_most", "=", "right_most", "=", "tokens", ".", "index", "(", "t", ")", "\n", "", "else", ":", "\n", "                        ", "right_most", "+=", "1", "\n", "", "", "else", ":", "\n", "                    ", "words", ".", "append", "(", "t", ")", "\n", "", "", "if", "not", "find_label", ":", "\n", "                ", "record", "[", "'y'", "]", "=", "None", "\n", "", "for", "pos", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "pos", "<", "left_most", ":", "\n", "                    ", "d", ".", "append", "(", "right_most", "-", "pos", ")", "\n", "", "else", ":", "\n", "                    ", "d", ".", "append", "(", "pos", "-", "left_most", ")", "\n", "", "", "record", "[", "'sent'", "]", "=", "line", ".", "strip", "(", ")", "\n", "record", "[", "'words'", "]", "=", "words", ".", "copy", "(", ")", "\n", "record", "[", "'twords'", "]", "=", "target_words", ".", "copy", "(", ")", "\n", "record", "[", "'wc'", "]", "=", "len", "(", "words", ")", "\n", "record", "[", "'wct'", "]", "=", "len", "(", "record", "[", "'twords'", "]", ")", "\n", "record", "[", "'dist'", "]", "=", "d", ".", "copy", "(", ")", "\n", "record", "[", "'sid'", "]", "=", "sid", "\n", "record", "[", "'beg'", "]", "=", "left_most", "\n", "record", "[", "'end'", "]", "=", "right_most", "+", "1", "\n", "sid", "+=", "1", "\n", "if", "record", "[", "'y'", "]", "is", "not", "None", ":", "\n", "                ", "dataset", ".", "append", "(", "record", ")", "\n", "", "", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.load_data": [[87, 120], ["os.path.exists", "utils.read", "utils.read", "utils.pad_seq", "utils.pad_seq", "utils.calculate_position_weight", "utils.calculate_position_weight", "utils.build_vocab", "utils.set_wid", "utils.set_wid", "utils.set_tid", "utils.set_tid", "numpy.savez", "numpy.save", "numpy.load", "numpy.load().tolist", "max", "max", "max", "max", "set_tid.tolist", "set_tid.tolist", "max", "max", "max", "max", "numpy.load"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.calculate_position_weight", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.calculate_position_weight", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_vocab", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_wid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_wid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tid"], ["", "def", "load_data", "(", "ds_name", ")", ":", "\n", "    ", "data_npz", "=", "'dataset_npy/dataset_%s.npz'", "%", "ds_name", "\n", "vocab_npy", "=", "'dataset_npy/vocab_%s.npy'", "%", "ds_name", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "data_npz", ")", ":", "\n", "        ", "train_file", "=", "'./dataset/%s/train.txt'", "%", "ds_name", "\n", "test_file", "=", "'./dataset/%s/test.txt'", "%", "ds_name", "\n", "train_set", "=", "read", "(", "path", "=", "train_file", ")", "\n", "test_set", "=", "read", "(", "path", "=", "test_file", ")", "\n", "train_wc", "=", "[", "t", "[", "'wc'", "]", "for", "t", "in", "train_set", "]", "\n", "test_wc", "=", "[", "t", "[", "'wc'", "]", "for", "t", "in", "test_set", "]", "\n", "max_len", "=", "max", "(", "train_wc", ")", "if", "max", "(", "train_wc", ")", ">", "max", "(", "test_wc", ")", "else", "max", "(", "test_wc", ")", "\n", "train_t_wc", "=", "[", "t", "[", "'wct'", "]", "for", "t", "in", "train_set", "]", "\n", "test_t_wc", "=", "[", "t", "[", "'wct'", "]", "for", "t", "in", "test_set", "]", "\n", "max_len_target", "=", "max", "(", "train_t_wc", ")", "if", "max", "(", "train_t_wc", ")", ">", "max", "(", "test_t_wc", ")", "else", "max", "(", "test_t_wc", ")", "\n", "train_set", "=", "pad_seq", "(", "dataset", "=", "train_set", ",", "field", "=", "'dist'", ",", "max_len", "=", "max_len", ",", "symbol", "=", "-", "1", ")", "\n", "test_set", "=", "pad_seq", "(", "dataset", "=", "test_set", ",", "field", "=", "'dist'", ",", "max_len", "=", "max_len", ",", "symbol", "=", "-", "1", ")", "\n", "train_set", "=", "calculate_position_weight", "(", "dataset", "=", "train_set", ")", "\n", "test_set", "=", "calculate_position_weight", "(", "dataset", "=", "test_set", ")", "\n", "vocab", "=", "build_vocab", "(", "dataset", "=", "train_set", "+", "test_set", ")", "\n", "train_set", "=", "set_wid", "(", "dataset", "=", "train_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len", ")", "\n", "test_set", "=", "set_wid", "(", "dataset", "=", "test_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len", ")", "\n", "train_set", "=", "set_tid", "(", "dataset", "=", "train_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len_target", ")", "\n", "test_set", "=", "set_tid", "(", "dataset", "=", "test_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len_target", ")", "\n", "dataset", "=", "[", "train_set", ",", "test_set", "]", "\n", "np", ".", "savez", "(", "data_npz", ",", "train", "=", "train_set", ",", "test", "=", "test_set", ")", "\n", "np", ".", "save", "(", "vocab_npy", ",", "vocab", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "np", ".", "load", "(", "data_npz", ",", "allow_pickle", "=", "True", ")", "\n", "train_set", ",", "test_set", "=", "dataset", "[", "'train'", "]", ",", "dataset", "[", "'test'", "]", "\n", "train_set", ",", "test_set", "=", "train_set", ".", "tolist", "(", ")", ",", "test_set", ".", "tolist", "(", ")", "\n", "dataset", "=", "[", "train_set", ",", "test_set", "]", "\n", "vocab", "=", "np", ".", "load", "(", "vocab_npy", ",", "allow_pickle", "=", "True", ")", ".", "tolist", "(", ")", "\n", "", "return", "dataset", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read_dep": [[121, 181], ["open", "line.strip().split", "range", "line.strip", "words.copy", "target_words.copy", "model.rgat_file.read_dep_graph.process_graph", "len", "len", "d.copy", "len", "dataset.append", "line.strip", "words.append", "target_words.append", "mask.append", "words.append", "mask.append", "d.append", "d.append", "t.strip", "t.strip", "line.strip().split.index"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.process_graph"], ["", "def", "read_dep", "(", "path", ")", ":", "\n", "    ", "dataset", "=", "[", "]", "\n", "sid", "=", "0", "# id", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf-8'", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "record", "=", "{", "}", "\n", "tokens", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "words", ",", "target_words", "=", "[", "]", ",", "[", "]", "\n", "d", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "find_label", "=", "False", "\n", "for", "t", "in", "tokens", ":", "\n", "                ", "if", "'/p'", "in", "t", "or", "'/n'", "in", "t", "or", "'/0'", "in", "t", ":", "\n", "                    ", "end", "=", "'xx'", "\n", "y", "=", "0", "\n", "if", "'/p'", "in", "t", ":", "\n", "                        ", "end", "=", "'/p'", "\n", "y", "=", "0", "\n", "", "elif", "'/n'", "in", "t", ":", "\n", "                        ", "end", "=", "'/n'", "\n", "y", "=", "1", "\n", "", "elif", "'/0'", "in", "t", ":", "\n", "                        ", "end", "=", "'/0'", "\n", "y", "=", "2", "\n", "", "words", ".", "append", "(", "t", ".", "strip", "(", "end", ")", ")", "\n", "target_words", ".", "append", "(", "t", ".", "strip", "(", "end", ")", ")", "\n", "mask", ".", "append", "(", "1", ")", "\n", "\n", "if", "not", "find_label", ":", "\n", "                        ", "find_label", "=", "True", "\n", "record", "[", "'y'", "]", "=", "y", "\n", "left_most", "=", "right_most", "=", "tokens", ".", "index", "(", "t", ")", "\n", "", "else", ":", "\n", "                        ", "right_most", "+=", "1", "\n", "", "", "else", ":", "\n", "                    ", "words", ".", "append", "(", "t", ")", "\n", "mask", ".", "append", "(", "0", ")", "\n", "", "", "if", "not", "find_label", ":", "\n", "                ", "record", "[", "'y'", "]", "=", "None", "\n", "", "for", "pos", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "pos", "<", "left_most", ":", "\n", "                    ", "d", ".", "append", "(", "right_most", "-", "pos", ")", "\n", "", "else", ":", "\n", "                    ", "d", ".", "append", "(", "pos", "-", "left_most", ")", "\n", "", "", "record", "[", "'sent'", "]", "=", "line", ".", "strip", "(", ")", "\n", "record", "[", "'words'", "]", "=", "words", ".", "copy", "(", ")", "\n", "record", "[", "'twords'", "]", "=", "target_words", ".", "copy", "(", ")", "\n", "sentence", "=", "' '", ".", "join", "(", "words", ")", "\n", "record", "[", "'adj'", "]", "=", "process_graph", "(", "sentence", ")", "\n", "record", "[", "'mask'", "]", "=", "mask", "\n", "record", "[", "'wc'", "]", "=", "len", "(", "words", ")", "\n", "record", "[", "'wct'", "]", "=", "len", "(", "record", "[", "'twords'", "]", ")", "\n", "record", "[", "'dist'", "]", "=", "d", ".", "copy", "(", ")", "\n", "record", "[", "'sid'", "]", "=", "sid", "\n", "record", "[", "'beg'", "]", "=", "left_most", "\n", "record", "[", "'end'", "]", "=", "right_most", "+", "1", "\n", "sid", "+=", "1", "\n", "if", "record", "[", "'y'", "]", "is", "not", "None", ":", "\n", "                ", "dataset", ".", "append", "(", "record", ")", "\n", "", "", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.load_data_dep": [[182, 219], ["os.path.exists", "utils.read_dep", "utils.read_dep", "utils.pad_seq", "utils.pad_seq", "utils.pad_seq", "utils.pad_seq", "utils.pad_seq", "utils.pad_seq", "utils.calculate_position_weight", "utils.calculate_position_weight", "utils.build_vocab", "utils.set_wid", "utils.set_wid", "utils.set_tid", "utils.set_tid", "numpy.savez", "numpy.save", "numpy.load", "numpy.load().tolist", "max", "max", "max", "max", "set_tid.tolist", "set_tid.tolist", "max", "max", "max", "max", "numpy.load"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read_dep", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read_dep", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.calculate_position_weight", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.calculate_position_weight", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_vocab", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_wid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_wid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tid"], ["", "def", "load_data_dep", "(", "ds_name", ")", ":", "\n", "    ", "data_npz", "=", "'dataset_npy/dataset_%s_dep.npz'", "%", "ds_name", "\n", "vocab_npy", "=", "'dataset_npy/vocab_%s_dep.npy'", "%", "ds_name", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "data_npz", ")", ":", "\n", "        ", "train_file", "=", "'./dataset/%s/train.txt'", "%", "ds_name", "\n", "test_file", "=", "'./dataset/%s/test.txt'", "%", "ds_name", "\n", "train_set", "=", "read_dep", "(", "path", "=", "train_file", ")", "\n", "test_set", "=", "read_dep", "(", "path", "=", "test_file", ")", "\n", "train_wc", "=", "[", "t", "[", "'wc'", "]", "for", "t", "in", "train_set", "]", "\n", "test_wc", "=", "[", "t", "[", "'wc'", "]", "for", "t", "in", "test_set", "]", "\n", "max_len", "=", "max", "(", "train_wc", ")", "if", "max", "(", "train_wc", ")", ">", "max", "(", "test_wc", ")", "else", "max", "(", "test_wc", ")", "\n", "train_t_wc", "=", "[", "t", "[", "'wct'", "]", "for", "t", "in", "train_set", "]", "\n", "test_t_wc", "=", "[", "t", "[", "'wct'", "]", "for", "t", "in", "test_set", "]", "\n", "max_len_target", "=", "max", "(", "train_t_wc", ")", "if", "max", "(", "train_t_wc", ")", ">", "max", "(", "test_t_wc", ")", "else", "max", "(", "test_t_wc", ")", "\n", "train_set", "=", "pad_seq", "(", "dataset", "=", "train_set", ",", "field", "=", "'dist'", ",", "max_len", "=", "max_len", ",", "symbol", "=", "-", "1", ")", "\n", "test_set", "=", "pad_seq", "(", "dataset", "=", "test_set", ",", "field", "=", "'dist'", ",", "max_len", "=", "max_len", ",", "symbol", "=", "-", "1", ")", "\n", "train_set", "=", "pad_seq", "(", "dataset", "=", "train_set", ",", "field", "=", "'adj'", ",", "max_len", "=", "max_len", ",", "symbol", "=", "-", "1", ")", "\n", "test_set", "=", "pad_seq", "(", "dataset", "=", "test_set", ",", "field", "=", "'adj'", ",", "max_len", "=", "max_len", ",", "symbol", "=", "-", "1", ")", "\n", "train_set", "=", "pad_seq", "(", "dataset", "=", "train_set", ",", "field", "=", "'mask'", ",", "max_len", "=", "max_len", ",", "symbol", "=", "0", ")", "\n", "test_set", "=", "pad_seq", "(", "dataset", "=", "test_set", ",", "field", "=", "'mask'", ",", "max_len", "=", "max_len", ",", "symbol", "=", "0", ")", "\n", "train_set", "=", "calculate_position_weight", "(", "dataset", "=", "train_set", ",", "re_aspect", "=", "True", ")", "\n", "test_set", "=", "calculate_position_weight", "(", "dataset", "=", "test_set", ",", "re_aspect", "=", "True", ")", "\n", "vocab", "=", "build_vocab", "(", "dataset", "=", "train_set", "+", "test_set", ")", "\n", "train_set", "=", "set_wid", "(", "dataset", "=", "train_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len", ")", "\n", "test_set", "=", "set_wid", "(", "dataset", "=", "test_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len", ")", "\n", "train_set", "=", "set_tid", "(", "dataset", "=", "train_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len_target", ")", "\n", "test_set", "=", "set_tid", "(", "dataset", "=", "test_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len_target", ")", "\n", "dataset", "=", "[", "train_set", ",", "test_set", "]", "\n", "np", ".", "savez", "(", "data_npz", ",", "train", "=", "train_set", ",", "test", "=", "test_set", ")", "\n", "np", ".", "save", "(", "vocab_npy", ",", "vocab", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "np", ".", "load", "(", "data_npz", ",", "allow_pickle", "=", "True", ")", "\n", "train_set", ",", "test_set", "=", "dataset", "[", "'train'", "]", ",", "dataset", "[", "'test'", "]", "\n", "train_set", ",", "test_set", "=", "train_set", ".", "tolist", "(", ")", ",", "test_set", ".", "tolist", "(", ")", "\n", "dataset", "=", "[", "train_set", ",", "test_set", "]", "\n", "vocab", "=", "np", ".", "load", "(", "vocab_npy", ",", "allow_pickle", "=", "True", ")", ".", "tolist", "(", ")", "\n", "", "return", "dataset", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.load_rgat_data": [[220, 274], ["os.path.exists", "model.rgat_file.read_rgat_data.get_dataset", "model.rgat_file.read_rgat_data.get_rolled_and_unrolled_data", "model.rgat_file.read_rgat_data.get_rolled_and_unrolled_data", "os.path.exists", "model.rgat_file.read_rgat_data.convert_data", "model.rgat_file.read_rgat_data.convert_data", "utils.pad_seq", "utils.pad_seq", "utils.calculate_position_weight", "utils.calculate_position_weight", "utils.build_vocab", "utils.set_tag", "utils.set_tag", "utils.set_wid", "utils.set_wid", "utils.set_tid", "utils.set_tid", "numpy.savez", "numpy.save", "numpy.save", "numpy.load", "numpy.load().tolist", "numpy.load().tolist", "model.rgat_file.read_rgat_data.build_dep_tag_vocab", "max", "max", "max", "max", "len", "len", "max", "max", "set_tid.tolist", "set_tid.tolist", "open", "pickle.load", "open", "pickle.dump", "max", "max", "max", "max", "max", "max", "numpy.load", "numpy.load"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.get_dataset", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.get_rolled_and_unrolled_data", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.get_rolled_and_unrolled_data", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.convert_data", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.convert_data", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.calculate_position_weight", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.calculate_position_weight", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_vocab", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tag", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tag", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_wid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_wid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tid", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.build_dep_tag_vocab"], ["", "def", "load_rgat_data", "(", "ds_name", ")", ":", "\n", "    ", "data_npz", "=", "'./rgat_data/dataset_%s.npz'", "%", "ds_name", "\n", "vocab_npy", "=", "'./rgat_data/vocab_%s.npy'", "%", "ds_name", "\n", "tag_vocab_npy", "=", "'./rgat_data/tag_vocab_%s.npy'", "%", "ds_name", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "data_npz", ")", ":", "\n", "        ", "train", ",", "test", "=", "get_dataset", "(", "ds_name", ")", "\n", "multi_hop", "=", "True", "\n", "add_non_connect", "=", "True", "\n", "max_hop", "=", "4", "\n", "_", ",", "train_all_unrolled", ",", "_", ",", "_", "=", "get_rolled_and_unrolled_data", "(", "train", ",", "multi_hop", ",", "add_non_connect", ",", "max_hop", ")", "\n", "_", ",", "test_all_unrolled", ",", "_", ",", "_", "=", "get_rolled_and_unrolled_data", "(", "test", ",", "multi_hop", ",", "add_non_connect", ",", "max_hop", ")", "\n", "data", "=", "train_all_unrolled", "+", "test_all_unrolled", "\n", "if", "os", ".", "path", ".", "exists", "(", "'./rgat_data/dep_tag_vocab_%s.pkl'", "%", "ds_name", ")", ":", "\n", "            ", "with", "open", "(", "'./rgat_data/dep_tag_vocab_%s.pkl'", "%", "ds_name", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "dep_tag_vocab", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "dep_tag_vocab", "=", "build_dep_tag_vocab", "(", "data", ",", "min_freq", "=", "0", ")", "\n", "with", "open", "(", "'./rgat_data/dep_tag_vocab_%s.pkl'", "%", "ds_name", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "dep_tag_vocab", ",", "f", ",", "-", "1", ")", "\n", "", "", "train_set", "=", "convert_data", "(", "train_all_unrolled", ")", "\n", "test_set", "=", "convert_data", "(", "test_all_unrolled", ")", "\n", "train_wc", "=", "[", "t", "[", "'wc'", "]", "for", "t", "in", "train_set", "]", "\n", "test_wc", "=", "[", "t", "[", "'wc'", "]", "for", "t", "in", "test_set", "]", "\n", "max_len", "=", "max", "(", "train_wc", ")", "if", "max", "(", "train_wc", ")", ">", "max", "(", "test_wc", ")", "else", "max", "(", "test_wc", ")", "\n", "train_t_wc", "=", "[", "t", "[", "'wct'", "]", "for", "t", "in", "train_set", "]", "\n", "test_t_wc", "=", "[", "t", "[", "'wct'", "]", "for", "t", "in", "test_set", "]", "\n", "max_len_target", "=", "max", "(", "train_t_wc", ")", "if", "max", "(", "train_t_wc", ")", ">", "max", "(", "test_t_wc", ")", "else", "max", "(", "test_t_wc", ")", "\n", "train_tag", "=", "[", "len", "(", "t", "[", "'dep_tag'", "]", ")", "for", "t", "in", "train_set", "]", "\n", "test_tag", "=", "[", "len", "(", "t", "[", "'dep_tag'", "]", ")", "for", "t", "in", "test_set", "]", "\n", "max_len_tag", "=", "max", "(", "train_tag", ")", "if", "max", "(", "train_tag", ")", ">", "max", "(", "test_tag", ")", "else", "max", "(", "test_tag", ")", "\n", "train_set", "=", "pad_seq", "(", "dataset", "=", "train_set", ",", "field", "=", "'dist'", ",", "max_len", "=", "max_len", ",", "symbol", "=", "-", "1", ")", "\n", "test_set", "=", "pad_seq", "(", "dataset", "=", "test_set", ",", "field", "=", "'dist'", ",", "max_len", "=", "max_len", ",", "symbol", "=", "-", "1", ")", "\n", "train_set", "=", "calculate_position_weight", "(", "dataset", "=", "train_set", ")", "\n", "test_set", "=", "calculate_position_weight", "(", "dataset", "=", "test_set", ")", "\n", "vocab", "=", "build_vocab", "(", "dataset", "=", "train_set", "+", "test_set", ")", "\n", "train_set", "=", "set_tag", "(", "dataset", "=", "train_set", ",", "vocab", "=", "dep_tag_vocab", "[", "'stoi'", "]", ",", "max_len", "=", "max_len_tag", ")", "\n", "test_set", "=", "set_tag", "(", "dataset", "=", "test_set", ",", "vocab", "=", "dep_tag_vocab", "[", "'stoi'", "]", ",", "max_len", "=", "max_len_tag", ")", "\n", "train_set", "=", "set_wid", "(", "dataset", "=", "train_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len", ")", "\n", "test_set", "=", "set_wid", "(", "dataset", "=", "test_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len", ")", "\n", "train_set", "=", "set_tid", "(", "dataset", "=", "train_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len_target", ")", "\n", "test_set", "=", "set_tid", "(", "dataset", "=", "test_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len_target", ")", "\n", "dataset", "=", "[", "train_set", ",", "test_set", "]", "\n", "tag_vocab", "=", "dep_tag_vocab", "[", "'itos'", "]", "\n", "np", ".", "savez", "(", "data_npz", ",", "train", "=", "train_set", ",", "test", "=", "test_set", ")", "\n", "np", ".", "save", "(", "vocab_npy", ",", "vocab", ")", "\n", "np", ".", "save", "(", "tag_vocab_npy", ",", "dep_tag_vocab", "[", "'itos'", "]", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "np", ".", "load", "(", "data_npz", ",", "allow_pickle", "=", "True", ")", "\n", "train_set", ",", "test_set", "=", "dataset", "[", "'train'", "]", ",", "dataset", "[", "'test'", "]", "\n", "train_set", ",", "test_set", "=", "train_set", ".", "tolist", "(", ")", ",", "test_set", ".", "tolist", "(", ")", "\n", "dataset", "=", "[", "train_set", ",", "test_set", "]", "\n", "vocab", "=", "np", ".", "load", "(", "vocab_npy", ",", "allow_pickle", "=", "True", ")", ".", "tolist", "(", ")", "\n", "tag_vocab", "=", "np", ".", "load", "(", "tag_vocab_npy", ",", "allow_pickle", "=", "True", ")", ".", "tolist", "(", ")", "\n", "", "return", "dataset", ",", "vocab", ",", "tag_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read_bert": [[275, 337], ["open", "line.strip().split", "range", "bert_tokenizer.tokenize", "bert_tokenizer.tokenize", "bert_tokenizer.convert_tokens_to_ids", "bert_tokenizer.convert_tokens_to_ids", "line.strip", "words.copy", "target_words.copy", "len", "len", "len", "len", "d.copy", "record[].append", "record[].insert", "len", "dataset.append", "line.strip", "words.append", "target_words.append", "words.append", "d.append", "d.append", "words.copy", "target_words.copy", "t.strip", "t.strip", "line.strip().split.index"], "function", ["None"], ["", "def", "read_bert", "(", "path", ")", ":", "\n", "    ", "dataset", "=", "[", "]", "\n", "sid", "=", "0", "# id", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf-8'", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "record", "=", "{", "}", "\n", "tokens", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "words", ",", "target_words", "=", "[", "]", ",", "[", "]", "\n", "d", "=", "[", "]", "\n", "find_label", "=", "False", "\n", "for", "t", "in", "tokens", ":", "\n", "                ", "if", "'/p'", "in", "t", "or", "'/n'", "in", "t", "or", "'/0'", "in", "t", ":", "\n", "                    ", "end", "=", "'xx'", "\n", "y", "=", "0", "\n", "if", "'/p'", "in", "t", ":", "\n", "                        ", "end", "=", "'/p'", "\n", "y", "=", "0", "\n", "", "elif", "'/n'", "in", "t", ":", "\n", "                        ", "end", "=", "'/n'", "\n", "y", "=", "1", "\n", "", "elif", "'/0'", "in", "t", ":", "\n", "                        ", "end", "=", "'/0'", "\n", "y", "=", "2", "\n", "", "words", ".", "append", "(", "t", ".", "strip", "(", "end", ")", ")", "\n", "target_words", ".", "append", "(", "t", ".", "strip", "(", "end", ")", ")", "\n", "\n", "if", "not", "find_label", ":", "\n", "                        ", "find_label", "=", "True", "\n", "record", "[", "'y'", "]", "=", "y", "\n", "left_most", "=", "right_most", "=", "tokens", ".", "index", "(", "t", ")", "\n", "", "else", ":", "\n", "                        ", "right_most", "+=", "1", "\n", "", "", "else", ":", "\n", "                    ", "words", ".", "append", "(", "t", ")", "\n", "", "", "if", "not", "find_label", ":", "\n", "                ", "record", "[", "'y'", "]", "=", "None", "\n", "", "for", "pos", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "pos", "<", "left_most", ":", "\n", "                    ", "d", ".", "append", "(", "right_most", "-", "pos", ")", "\n", "", "else", ":", "\n", "                    ", "d", ".", "append", "(", "pos", "-", "left_most", ")", "\n", "", "", "bert_sentence", "=", "bert_tokenizer", ".", "tokenize", "(", "' '", ".", "join", "(", "words", ".", "copy", "(", ")", ")", ")", "\n", "bert_aspect", "=", "bert_tokenizer", ".", "tokenize", "(", "' '", ".", "join", "(", "target_words", ".", "copy", "(", ")", ")", ")", "\n", "record", "[", "'bert_token'", "]", "=", "bert_tokenizer", ".", "convert_tokens_to_ids", "(", "[", "'[CLS]'", "]", "+", "bert_sentence", "+", "[", "'[SEP]'", "]", ")", "\n", "record", "[", "'bert_token_aspect'", "]", "=", "bert_tokenizer", ".", "convert_tokens_to_ids", "(", "[", "'[CLS]'", "]", "+", "bert_aspect", "+", "[", "'[SEP]'", "]", ")", "\n", "record", "[", "'sent'", "]", "=", "line", ".", "strip", "(", ")", "\n", "record", "[", "'words'", "]", "=", "words", ".", "copy", "(", ")", "\n", "record", "[", "'twords'", "]", "=", "target_words", ".", "copy", "(", ")", "\n", "record", "[", "'wc'", "]", "=", "len", "(", "words", ")", "\n", "record", "[", "'wct'", "]", "=", "len", "(", "record", "[", "'twords'", "]", ")", "\n", "record", "[", "'bert_len'", "]", "=", "len", "(", "record", "[", "'bert_token'", "]", ")", "\n", "record", "[", "'bert_as_len'", "]", "=", "len", "(", "record", "[", "'bert_token_aspect'", "]", ")", "\n", "record", "[", "'dist'", "]", "=", "d", ".", "copy", "(", ")", "\n", "record", "[", "'dist'", "]", ".", "append", "(", "-", "1", ")", "\n", "record", "[", "'dist'", "]", ".", "insert", "(", "0", ",", "-", "1", ")", "\n", "record", "[", "'sid'", "]", "=", "sid", "\n", "record", "[", "'beg'", "]", "=", "left_most", "\n", "record", "[", "'end'", "]", "=", "right_most", "+", "1", "\n", "sid", "+=", "1", "\n", "if", "record", "[", "'y'", "]", "is", "not", "None", ":", "\n", "                ", "dataset", ".", "append", "(", "record", ")", "\n", "", "", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.load_data_bert": [[338, 376], ["utils.read_bert", "utils.read_bert", "print", "len", "len", "range", "range", "utils.pad_seq", "utils.pad_seq", "utils.calculate_position_weight", "utils.calculate_position_weight", "utils.build_vocab", "utils.set_wid", "utils.set_wid", "utils.set_tid", "utils.set_tid", "max", "max", "max", "max", "max", "max", "[].extend", "[].extend", "[].extend", "[].extend", "max", "max", "max", "max", "max", "max", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read_bert", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read_bert", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.calculate_position_weight", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.calculate_position_weight", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_vocab", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_wid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_wid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tid"], ["", "def", "load_data_bert", "(", "ds_name", ")", ":", "\n", "    ", "train_file", "=", "'./dataset/%s/train.txt'", "%", "ds_name", "\n", "test_file", "=", "'./dataset/%s/test.txt'", "%", "ds_name", "\n", "train_set", "=", "read_bert", "(", "path", "=", "train_file", ")", "\n", "test_set", "=", "read_bert", "(", "path", "=", "test_file", ")", "\n", "train_wc", "=", "[", "t", "[", "'wc'", "]", "for", "t", "in", "train_set", "]", "\n", "test_wc", "=", "[", "t", "[", "'wc'", "]", "for", "t", "in", "test_set", "]", "\n", "train_t_wc", "=", "[", "t", "[", "'wct'", "]", "for", "t", "in", "train_set", "]", "\n", "test_t_wc", "=", "[", "t", "[", "'wct'", "]", "for", "t", "in", "test_set", "]", "\n", "max_len_target", "=", "max", "(", "train_t_wc", ")", "if", "max", "(", "train_t_wc", ")", ">", "max", "(", "test_t_wc", ")", "else", "max", "(", "test_t_wc", ")", "\n", "#######bert######", "\n", "train_bert_len", "=", "[", "t", "[", "'bert_len'", "]", "for", "t", "in", "train_set", "]", "\n", "test_bert_len", "=", "[", "t", "[", "'bert_len'", "]", "for", "t", "in", "test_set", "]", "\n", "max_bert_len", "=", "max", "(", "train_bert_len", ")", "if", "max", "(", "train_bert_len", ")", ">", "max", "(", "test_bert_len", ")", "else", "max", "(", "test_bert_len", ")", "\n", "train_bert_as_len", "=", "[", "t", "[", "'bert_as_len'", "]", "for", "t", "in", "train_set", "]", "\n", "test_bert_as_len", "=", "[", "t", "[", "'bert_as_len'", "]", "for", "t", "in", "test_set", "]", "\n", "max_bert_as_len", "=", "max", "(", "train_bert_as_len", ")", "if", "max", "(", "train_bert_as_len", ")", ">", "max", "(", "test_bert_as_len", ")", "else", "max", "(", "test_bert_as_len", ")", "\n", "print", "(", "max_bert_len", ",", "max_bert_as_len", ")", "\n", "num1", "=", "len", "(", "train_set", ")", "\n", "num2", "=", "len", "(", "test_set", ")", "\n", "for", "i", "in", "range", "(", "num1", ")", ":", "\n", "        ", "train_set", "[", "i", "]", "[", "'bert_token'", "]", ".", "extend", "(", "[", "0", "]", "*", "(", "max_bert_len", "-", "len", "(", "train_set", "[", "i", "]", "[", "'bert_token'", "]", ")", ")", ")", "\n", "train_set", "[", "i", "]", "[", "'bert_token_aspect'", "]", ".", "extend", "(", "[", "0", "]", "*", "(", "max_bert_as_len", "-", "len", "(", "train_set", "[", "i", "]", "[", "'bert_token_aspect'", "]", ")", ")", ")", "\n", "", "for", "i", "in", "range", "(", "num2", ")", ":", "\n", "        ", "test_set", "[", "i", "]", "[", "'bert_token'", "]", ".", "extend", "(", "[", "0", "]", "*", "(", "max_bert_len", "-", "len", "(", "test_set", "[", "i", "]", "[", "'bert_token'", "]", ")", ")", ")", "\n", "test_set", "[", "i", "]", "[", "'bert_token_aspect'", "]", ".", "extend", "(", "[", "0", "]", "*", "(", "max_bert_as_len", "-", "len", "(", "test_set", "[", "i", "]", "[", "'bert_token_aspect'", "]", ")", ")", ")", "\n", "#######bert######", "\n", "", "train_set", "=", "pad_seq", "(", "dataset", "=", "train_set", ",", "field", "=", "'dist'", ",", "max_len", "=", "max_bert_len", ",", "symbol", "=", "-", "1", ")", "\n", "test_set", "=", "pad_seq", "(", "dataset", "=", "test_set", ",", "field", "=", "'dist'", ",", "max_len", "=", "max_bert_len", ",", "symbol", "=", "-", "1", ")", "\n", "train_set", "=", "calculate_position_weight", "(", "dataset", "=", "train_set", ")", "\n", "test_set", "=", "calculate_position_weight", "(", "dataset", "=", "test_set", ")", "\n", "vocab", "=", "build_vocab", "(", "dataset", "=", "train_set", "+", "test_set", ")", "\n", "train_set", "=", "set_wid", "(", "dataset", "=", "train_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_bert_len", ")", "\n", "test_set", "=", "set_wid", "(", "dataset", "=", "test_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_bert_len", ")", "\n", "train_set", "=", "set_tid", "(", "dataset", "=", "train_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len_target", ")", "\n", "test_set", "=", "set_tid", "(", "dataset", "=", "test_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_len_target", ")", "\n", "dataset", "=", "[", "train_set", ",", "test_set", "]", "\n", "return", "dataset", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read_dep_bert": [[377, 449], ["open", "line.strip().split", "range", "line.strip", "words.copy", "target_words.copy", "model.rgat_file.read_dep_graph.process_graph", "record[].append", "record[].insert", "len", "len", "d.copy", "record[].append", "record[].insert", "len", "bert_tokenizer.convert_tokens_to_ids", "bert_tokenizer.convert_tokens_to_ids", "dataset.append", "line.strip", "words.append", "target_words.append", "mask.append", "words.append", "mask.append", "d.append", "d.append", "roberta_tokenizer.convert_tokens_to_ids", "roberta_tokenizer.convert_tokens_to_ids", "bert_sentence.copy", "t.strip", "t.strip", "line.strip().split.index", "bert_tokenizer.tokenize", "bert_tokenizer.tokenize", "roberta_tokenizer.tokenize", "roberta_tokenizer.tokenize", "words.copy", "target_words.copy", "words.copy", "target_words.copy"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.process_graph"], ["", "def", "read_dep_bert", "(", "path", ",", "is_bert", ")", ":", "\n", "    ", "dataset", "=", "[", "]", "\n", "sid", "=", "0", "# id", "\n", "with", "open", "(", "path", ",", "encoding", "=", "'utf-8'", ")", "as", "fp", ":", "\n", "        ", "for", "line", "in", "fp", ":", "\n", "            ", "record", "=", "{", "}", "\n", "tokens", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "words", ",", "target_words", "=", "[", "]", ",", "[", "]", "\n", "d", "=", "[", "]", "\n", "mask", "=", "[", "]", "\n", "find_label", "=", "False", "\n", "for", "t", "in", "tokens", ":", "\n", "                ", "if", "'/p'", "in", "t", "or", "'/n'", "in", "t", "or", "'/0'", "in", "t", ":", "\n", "                    ", "end", "=", "'xx'", "\n", "y", "=", "0", "\n", "if", "'/p'", "in", "t", ":", "\n", "                        ", "end", "=", "'/p'", "\n", "y", "=", "0", "\n", "", "elif", "'/n'", "in", "t", ":", "\n", "                        ", "end", "=", "'/n'", "\n", "y", "=", "1", "\n", "", "elif", "'/0'", "in", "t", ":", "\n", "                        ", "end", "=", "'/0'", "\n", "y", "=", "2", "\n", "", "words", ".", "append", "(", "t", ".", "strip", "(", "end", ")", ")", "\n", "target_words", ".", "append", "(", "t", ".", "strip", "(", "end", ")", ")", "\n", "mask", ".", "append", "(", "1", ")", "\n", "if", "not", "find_label", ":", "\n", "                        ", "find_label", "=", "True", "\n", "record", "[", "'y'", "]", "=", "y", "\n", "left_most", "=", "right_most", "=", "tokens", ".", "index", "(", "t", ")", "\n", "", "else", ":", "\n", "                        ", "right_most", "+=", "1", "\n", "", "", "else", ":", "\n", "                    ", "words", ".", "append", "(", "t", ")", "\n", "mask", ".", "append", "(", "0", ")", "\n", "", "", "if", "not", "find_label", ":", "\n", "                ", "record", "[", "'y'", "]", "=", "None", "\n", "", "for", "pos", "in", "range", "(", "len", "(", "tokens", ")", ")", ":", "\n", "                ", "if", "pos", "<", "left_most", ":", "\n", "                    ", "d", ".", "append", "(", "right_most", "-", "pos", ")", "\n", "", "else", ":", "\n", "                    ", "d", ".", "append", "(", "pos", "-", "left_most", ")", "\n", "", "", "if", "is_bert", "==", "1", ":", "\n", "                ", "bert_sentence", "=", "[", "'[CLS]'", "]", "+", "bert_tokenizer", ".", "tokenize", "(", "' '", ".", "join", "(", "words", ".", "copy", "(", ")", ")", ")", "+", "[", "'[SEP]'", "]", "\n", "bert_aspect", "=", "[", "'[CLS]'", "]", "+", "bert_tokenizer", ".", "tokenize", "(", "' '", ".", "join", "(", "target_words", ".", "copy", "(", ")", ")", ")", "+", "[", "'[SEP]'", "]", "\n", "record", "[", "'bert_token'", "]", "=", "bert_tokenizer", ".", "convert_tokens_to_ids", "(", "bert_sentence", ")", "\n", "record", "[", "'bert_token_aspect'", "]", "=", "bert_tokenizer", ".", "convert_tokens_to_ids", "(", "bert_aspect", ")", "\n", "", "elif", "is_bert", "==", "2", ":", "\n", "                ", "bert_sentence", "=", "[", "'<s>'", "]", "+", "roberta_tokenizer", ".", "tokenize", "(", "' '", ".", "join", "(", "words", ".", "copy", "(", ")", ")", ")", "+", "[", "'</s>'", "]", "\n", "bert_aspect", "=", "[", "'<s>'", "]", "+", "roberta_tokenizer", ".", "tokenize", "(", "' '", ".", "join", "(", "target_words", ".", "copy", "(", ")", ")", ")", "+", "[", "'</s>'", "]", "\n", "record", "[", "'bert_token'", "]", "=", "roberta_tokenizer", ".", "convert_tokens_to_ids", "(", "bert_sentence", ")", "\n", "record", "[", "'bert_token_aspect'", "]", "=", "roberta_tokenizer", ".", "convert_tokens_to_ids", "(", "bert_aspect", ")", "\n", "", "record", "[", "'sent'", "]", "=", "line", ".", "strip", "(", ")", "\n", "record", "[", "'words'", "]", "=", "words", ".", "copy", "(", ")", "\n", "record", "[", "'twords'", "]", "=", "target_words", ".", "copy", "(", ")", "\n", "record", "[", "'adj'", "]", "=", "process_graph", "(", "' '", ".", "join", "(", "bert_sentence", ".", "copy", "(", ")", ")", ")", "\n", "record", "[", "'mask'", "]", "=", "mask", "\n", "record", "[", "'mask'", "]", ".", "append", "(", "0", ")", "\n", "record", "[", "'mask'", "]", ".", "insert", "(", "0", ",", "0", ")", "\n", "record", "[", "'bert_len'", "]", "=", "len", "(", "record", "[", "'bert_token'", "]", ")", "\n", "record", "[", "'bert_as_len'", "]", "=", "len", "(", "record", "[", "'bert_token_aspect'", "]", ")", "\n", "record", "[", "'dist'", "]", "=", "d", ".", "copy", "(", ")", "\n", "record", "[", "'dist'", "]", ".", "append", "(", "-", "1", ")", "\n", "record", "[", "'dist'", "]", ".", "insert", "(", "0", ",", "-", "1", ")", "\n", "record", "[", "'sid'", "]", "=", "sid", "\n", "record", "[", "'beg'", "]", "=", "left_most", "\n", "record", "[", "'end'", "]", "=", "right_most", "+", "1", "\n", "sid", "+=", "1", "\n", "if", "record", "[", "'y'", "]", "is", "not", "None", ":", "\n", "                ", "dataset", ".", "append", "(", "record", ")", "\n", "", "", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.load_data_dep_bert": [[450, 504], ["os.path.exists", "utils.read_dep_bert", "utils.read_dep_bert", "print", "len", "len", "range", "range", "utils.pad_seq", "utils.pad_seq", "utils.pad_seq", "utils.pad_seq", "utils.pad_seq", "utils.pad_seq", "utils.calculate_position_weight", "utils.calculate_position_weight", "utils.build_vocab", "utils.set_wid", "utils.set_wid", "utils.set_tid", "utils.set_tid", "numpy.savez", "numpy.save", "numpy.load", "numpy.load().tolist", "max", "max", "max", "max", "[].extend", "[].extend", "[].extend", "[].extend", "set_tid.tolist", "set_tid.tolist", "max", "max", "max", "max", "numpy.load", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read_dep_bert", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.read_dep_bert", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_seq", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.calculate_position_weight", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.calculate_position_weight", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_vocab", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_wid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_wid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tid", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tid"], ["", "def", "load_data_dep_bert", "(", "ds_name", ",", "is_bert", ")", ":", "\n", "    ", "if", "is_bert", "==", "1", ":", "\n", "        ", "data_npz", "=", "'dataset_npy/dataset_%s_dep_bert.npz'", "%", "ds_name", "\n", "vocab_npy", "=", "'dataset_npy/vocab_%s_dep_bert.npy'", "%", "ds_name", "\n", "", "elif", "is_bert", "==", "2", ":", "\n", "        ", "data_npz", "=", "'dataset_npy/dataset_%s_dep_roberta.npz'", "%", "ds_name", "\n", "vocab_npy", "=", "'dataset_npy/vocab_%s_dep_roberta.npy'", "%", "ds_name", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "data_npz", ")", ":", "\n", "        ", "train_file", "=", "'./dataset/%s/train.txt'", "%", "ds_name", "\n", "test_file", "=", "'./dataset/%s/test.txt'", "%", "ds_name", "\n", "train_set", "=", "read_dep_bert", "(", "path", "=", "train_file", ",", "is_bert", "=", "is_bert", ")", "\n", "test_set", "=", "read_dep_bert", "(", "path", "=", "test_file", ",", "is_bert", "=", "is_bert", ")", "\n", "\n", "#######bert######", "\n", "train_bert_len", "=", "[", "t", "[", "'bert_len'", "]", "for", "t", "in", "train_set", "]", "\n", "test_bert_len", "=", "[", "t", "[", "'bert_len'", "]", "for", "t", "in", "test_set", "]", "\n", "max_bert_len", "=", "max", "(", "train_bert_len", ")", "if", "max", "(", "train_bert_len", ")", ">", "max", "(", "test_bert_len", ")", "else", "max", "(", "test_bert_len", ")", "\n", "train_bert_as_len", "=", "[", "t", "[", "'bert_as_len'", "]", "for", "t", "in", "train_set", "]", "\n", "test_bert_as_len", "=", "[", "t", "[", "'bert_as_len'", "]", "for", "t", "in", "test_set", "]", "\n", "max_bert_as_len", "=", "max", "(", "train_bert_as_len", ")", "if", "max", "(", "train_bert_as_len", ")", ">", "max", "(", "test_bert_as_len", ")", "else", "max", "(", "test_bert_as_len", ")", "\n", "print", "(", "max_bert_len", ",", "max_bert_as_len", ")", "\n", "num1", "=", "len", "(", "train_set", ")", "\n", "num2", "=", "len", "(", "test_set", ")", "\n", "for", "i", "in", "range", "(", "num1", ")", ":", "\n", "            ", "train_set", "[", "i", "]", "[", "'bert_token'", "]", ".", "extend", "(", "[", "0", "]", "*", "(", "max_bert_len", "-", "len", "(", "train_set", "[", "i", "]", "[", "'bert_token'", "]", ")", ")", ")", "\n", "train_set", "[", "i", "]", "[", "'bert_token_aspect'", "]", ".", "extend", "(", "[", "0", "]", "*", "(", "max_bert_as_len", "-", "len", "(", "train_set", "[", "i", "]", "[", "'bert_token_aspect'", "]", ")", ")", ")", "\n", "", "for", "i", "in", "range", "(", "num2", ")", ":", "\n", "            ", "test_set", "[", "i", "]", "[", "'bert_token'", "]", ".", "extend", "(", "[", "0", "]", "*", "(", "max_bert_len", "-", "len", "(", "test_set", "[", "i", "]", "[", "'bert_token'", "]", ")", ")", ")", "\n", "test_set", "[", "i", "]", "[", "'bert_token_aspect'", "]", ".", "extend", "(", "[", "0", "]", "*", "(", "max_bert_as_len", "-", "len", "(", "test_set", "[", "i", "]", "[", "'bert_token_aspect'", "]", ")", ")", ")", "\n", "#######bert######", "\n", "\n", "", "train_set", "=", "pad_seq", "(", "dataset", "=", "train_set", ",", "field", "=", "'dist'", ",", "max_len", "=", "max_bert_len", ",", "symbol", "=", "-", "1", ")", "\n", "test_set", "=", "pad_seq", "(", "dataset", "=", "test_set", ",", "field", "=", "'dist'", ",", "max_len", "=", "max_bert_len", ",", "symbol", "=", "-", "1", ")", "\n", "train_set", "=", "pad_seq", "(", "dataset", "=", "train_set", ",", "field", "=", "'adj'", ",", "max_len", "=", "max_bert_len", ",", "symbol", "=", "-", "1", ")", "\n", "test_set", "=", "pad_seq", "(", "dataset", "=", "test_set", ",", "field", "=", "'adj'", ",", "max_len", "=", "max_bert_len", ",", "symbol", "=", "-", "1", ")", "\n", "train_set", "=", "pad_seq", "(", "dataset", "=", "train_set", ",", "field", "=", "'mask'", ",", "max_len", "=", "max_bert_len", ",", "symbol", "=", "0", ")", "\n", "test_set", "=", "pad_seq", "(", "dataset", "=", "test_set", ",", "field", "=", "'mask'", ",", "max_len", "=", "max_bert_len", ",", "symbol", "=", "0", ")", "\n", "train_set", "=", "calculate_position_weight", "(", "dataset", "=", "train_set", ")", "\n", "test_set", "=", "calculate_position_weight", "(", "dataset", "=", "test_set", ")", "\n", "vocab", "=", "build_vocab", "(", "dataset", "=", "train_set", "+", "test_set", ")", "\n", "train_set", "=", "set_wid", "(", "dataset", "=", "train_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_bert_len", ")", "\n", "test_set", "=", "set_wid", "(", "dataset", "=", "test_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_bert_len", ")", "\n", "train_set", "=", "set_tid", "(", "dataset", "=", "train_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_bert_as_len", ")", "\n", "test_set", "=", "set_tid", "(", "dataset", "=", "test_set", ",", "vocab", "=", "vocab", ",", "max_len", "=", "max_bert_as_len", ")", "\n", "dataset", "=", "[", "train_set", ",", "test_set", "]", "\n", "np", ".", "savez", "(", "data_npz", ",", "train", "=", "train_set", ",", "test", "=", "test_set", ")", "\n", "np", ".", "save", "(", "vocab_npy", ",", "vocab", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "np", ".", "load", "(", "data_npz", ",", "allow_pickle", "=", "True", ")", "\n", "train_set", ",", "test_set", "=", "dataset", "[", "'train'", "]", ",", "dataset", "[", "'test'", "]", "\n", "train_set", ",", "test_set", "=", "train_set", ".", "tolist", "(", ")", ",", "test_set", ".", "tolist", "(", ")", "\n", "dataset", "=", "[", "train_set", ",", "test_set", "]", "\n", "vocab", "=", "np", ".", "load", "(", "vocab_npy", ",", "allow_pickle", "=", "True", ")", ".", "tolist", "(", ")", "\n", "", "return", "dataset", ",", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_vocab": [[505, 519], ["len", "range"], "function", ["None"], ["", "def", "build_vocab", "(", "dataset", ")", ":", "\n", "    ", "vocab", "=", "{", "}", "\n", "idx", "=", "1", "\n", "n_records", "=", "len", "(", "dataset", ")", "\n", "for", "i", "in", "range", "(", "n_records", ")", ":", "\n", "        ", "for", "w", "in", "dataset", "[", "i", "]", "[", "'words'", "]", ":", "\n", "            ", "if", "w", "not", "in", "vocab", ":", "\n", "                ", "vocab", "[", "w", "]", "=", "idx", "\n", "idx", "+=", "1", "\n", "", "", "for", "w", "in", "dataset", "[", "i", "]", "[", "'twords'", "]", ":", "\n", "            ", "if", "w", "not", "in", "vocab", ":", "\n", "                ", "vocab", "[", "w", "]", "=", "idx", "\n", "idx", "+=", "1", "\n", "", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_vocab_pre": [[520, 530], ["len", "range"], "function", ["None"], ["", "def", "build_vocab_pre", "(", "dataset", ")", ":", "\n", "    ", "vocab", "=", "{", "}", "\n", "idx", "=", "1", "\n", "n_records", "=", "len", "(", "dataset", ")", "\n", "for", "i", "in", "range", "(", "n_records", ")", ":", "\n", "        ", "for", "w", "in", "dataset", "[", "i", "]", "[", "'words'", "]", ":", "\n", "            ", "if", "w", "not", "in", "vocab", ":", "\n", "                ", "vocab", "[", "w", "]", "=", "idx", "\n", "idx", "+=", "1", "\n", "", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_wid": [[531, 537], ["len", "range", "utils.word2id"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.word2id"], ["", "def", "set_wid", "(", "dataset", ",", "vocab", ",", "max_len", ")", ":", "\n", "    ", "n_records", "=", "len", "(", "dataset", ")", "\n", "for", "i", "in", "range", "(", "n_records", ")", ":", "\n", "        ", "sent", "=", "dataset", "[", "i", "]", "[", "'words'", "]", "\n", "dataset", "[", "i", "]", "[", "'wids'", "]", "=", "word2id", "(", "vocab", ",", "sent", ",", "max_len", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tag": [[538, 544], ["len", "range", "utils.word2id"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.word2id"], ["", "def", "set_tag", "(", "dataset", ",", "vocab", ",", "max_len", ")", ":", "\n", "    ", "n_records", "=", "len", "(", "dataset", ")", "\n", "for", "i", "in", "range", "(", "n_records", ")", ":", "\n", "        ", "sent", "=", "dataset", "[", "i", "]", "[", "'dep_tag'", "]", "\n", "dataset", "[", "i", "]", "[", "'dep_tag_ids'", "]", "=", "word2id", "(", "vocab", ",", "sent", ",", "max_len", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.set_tid": [[545, 551], ["len", "range", "utils.word2id"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.word2id"], ["", "def", "set_tid", "(", "dataset", ",", "vocab", ",", "max_len", ")", ":", "\n", "    ", "n_records", "=", "len", "(", "dataset", ")", "\n", "for", "i", "in", "range", "(", "n_records", ")", ":", "\n", "        ", "sent", "=", "dataset", "[", "i", "]", "[", "'twords'", "]", "\n", "dataset", "[", "i", "]", "[", "'tids'", "]", "=", "word2id", "(", "vocab", ",", "sent", ",", "max_len", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.word2id": [[552, 565], ["len", "len", "wids.append", "wids.append", "wids.append"], "function", ["None"], ["", "def", "word2id", "(", "vocab", ",", "sent", ",", "max_len", ")", ":", "\n", "    ", "wids", "=", "[", "]", "\n", "for", "w", "in", "sent", ":", "\n", "        ", "try", ":", "\n", "            ", "wids", ".", "append", "(", "vocab", "[", "w", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "wids", ".", "append", "(", "0", ")", "\n", "#wids = [vocab[w] for w in sent]", "\n", "", "", "if", "len", "(", "wids", ")", ">", "max_len", ":", "\n", "        ", "wids", "=", "wids", "[", ":", "max_len", "]", "\n", "", "while", "len", "(", "wids", ")", "<", "max_len", ":", "\n", "        ", "wids", ".", "append", "(", "0", ")", "\n", "", "return", "wids", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.get_embedding": [[566, 633], ["os.path.exists", "numpy.zeros", "pickle.dump", "pickle.load", "os.path.exists", "numpy.zeros", "pickle.dump", "pickle.load", "open", "open", "open", "open", "open", "open", "print", "line.strip().split", "line.strip().split", "len", "len", "line.strip", "line.strip", "float", "float"], "function", ["None"], ["", "def", "get_embedding", "(", "vocab", ",", "ds_name", ",", "args", ",", "types", ")", ":", "\n", "    ", "emb_file", "=", "\"glove.840B.300d.txt\"", "\n", "pkl", "=", "'embeddings/%s_840B.pkl'", "%", "ds_name", "\n", "n_emb", "=", "0", "\n", "graph_emb", "=", "0", "\n", "if", "types", "!=", "'only_graph'", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "pkl", ")", ":", "\n", "            ", "embeddings", "=", "np", ".", "zeros", "(", "(", "len", "(", "vocab", ")", "+", "1", ",", "args", ".", "dim_w", ")", ",", "dtype", "=", "'float32'", ")", "\n", "with", "open", "(", "emb_file", ",", "encoding", "=", "'utf-8'", ")", "as", "fp", ":", "\n", "                ", "for", "line", "in", "fp", ":", "\n", "                    ", "eles", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "w", "=", "eles", "[", "0", "]", "\n", "n_emb", "+=", "1", "\n", "if", "w", "in", "vocab", ":", "\n", "                        ", "try", ":", "\n", "                            ", "embeddings", "[", "vocab", "[", "w", "]", "]", "=", "[", "float", "(", "v", ")", "for", "v", "in", "eles", "[", "1", ":", "]", "]", "\n", "", "except", "ValueError", ":", "\n", "                            ", "pass", "\n", "", "", "", "", "pickle", ".", "dump", "(", "embeddings", ",", "open", "(", "pkl", ",", "'wb'", ")", ")", "\n", "", "else", ":", "\n", "            ", "embeddings", "=", "pickle", ".", "load", "(", "open", "(", "pkl", ",", "'rb'", ")", ")", "\n", "\n", "", "", "if", "types", "==", "'only_graph'", ":", "\n", "        ", "if", "args", ".", "ds_name", "==", "'14semeval_laptop'", ":", "\n", "            ", "graph_file", "=", "'embeddings/entity_embeddings_analogy_400.txt'", "\n", "if", "args", ".", "is_bert", "==", "0", ":", "\n", "                ", "graph_pkl", "=", "'embeddings/%s_graph_analogy.pkl'", "%", "ds_name", "\n", "", "else", ":", "\n", "                ", "graph_pkl", "=", "'embeddings/%s_graph_analogy_bert.pkl'", "%", "ds_name", "\n", "# graph_pkl = 'embeddings/%s_graph_analogy_roberta.pkl' % ds_name", "\n", "", "", "elif", "args", ".", "ds_name", "==", "'14semeval_rest'", ":", "\n", "            ", "graph_file", "=", "'embeddings/entity_embeddings_distmult_200.txt'", "\n", "if", "args", ".", "is_bert", "==", "0", ":", "\n", "                ", "graph_pkl", "=", "'embeddings/%s_graph_dismult.pkl'", "%", "ds_name", "\n", "", "else", ":", "\n", "                ", "graph_pkl", "=", "'embeddings/%s_graph_dismult_bert.pkl'", "%", "ds_name", "\n", "# graph_pkl = 'embeddings/%s_graph_dismult_roberta.pkl' % ds_name", "\n", "", "", "elif", "args", ".", "ds_name", "==", "'Twitter'", ":", "\n", "            ", "graph_file", "=", "'embeddings/entity_embeddings_distmult_200.txt'", "\n", "if", "args", ".", "is_bert", "==", "0", ":", "\n", "                ", "graph_pkl", "=", "'embeddings/%s_graph_dismult.pkl'", "%", "ds_name", "\n", "", "else", ":", "\n", "                ", "graph_pkl", "=", "'embeddings/%s_graph_dismult_bert.pkl'", "%", "ds_name", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "graph_pkl", ")", ":", "\n", "            ", "graph_embeddings", "=", "np", ".", "zeros", "(", "(", "len", "(", "vocab", ")", "+", "1", ",", "args", ".", "dim_k", ")", ",", "dtype", "=", "'float32'", ")", "\n", "with", "open", "(", "graph_file", ",", "encoding", "=", "'utf-8'", ")", "as", "fp", ":", "\n", "                ", "for", "line", "in", "fp", ":", "\n", "                    ", "eles", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "w", "=", "eles", "[", "0", "]", "\n", "graph_emb", "+=", "1", "\n", "if", "w", "in", "vocab", ":", "\n", "                        ", "try", ":", "\n", "                            ", "graph_embeddings", "[", "vocab", "[", "w", "]", "]", "=", "[", "float", "(", "v", ")", "for", "v", "in", "eles", "[", "1", ":", "]", "]", "\n", "", "except", "ValueError", ":", "\n", "                            ", "pass", "\n", "", "", "", "", "pickle", ".", "dump", "(", "graph_embeddings", ",", "open", "(", "graph_pkl", ",", "'wb'", ")", ")", "\n", "", "else", ":", "\n", "            ", "graph_embeddings", "=", "pickle", ".", "load", "(", "open", "(", "graph_pkl", ",", "'rb'", ")", ")", "\n", "", "", "if", "types", "==", "'only_graph'", ":", "\n", "        ", "return", "graph_embeddings", "\n", "", "elif", "types", "==", "'only_word'", ":", "\n", "        ", "return", "embeddings", "\n", "", "elif", "types", "==", "'all'", ":", "\n", "        ", "return", "embeddings", ",", "graph_embeddings", "\n", "", "else", ":", "\n", "        ", "print", "(", "'error! Please input the correct types!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.build_dataset": [[635, 697], ["len", "len", "utils.pad_dataset", "utils.pad_dataset", "utils.get_embedding", "range", "numpy.array", "utils.load_data_dep_bert", "utils.load_data_bert", "utils.load_rgat_data", "len", "utils.get_embedding", "range", "numpy.array", "utils.get_embedding", "random.uniform", "int", "range", "numpy.array", "utils.load_data_dep", "utils.load_data", "numpy.random.uniform", "len", "len", "numpy.count_nonzero", "numpy.random.uniform", "open", "enumerate", "len", "numpy.random.uniform", "numpy.count_nonzero", "f.readlines", "numpy.count_nonzero", "numpy.random.uniform", "random.uniform", "print", "line.strip"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_dataset", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.pad_dataset", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.get_embedding", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.load_data_dep_bert", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.load_data_bert", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.load_rgat_data", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.get_embedding", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.get_embedding", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.load_data_dep", "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.load_data"], ["", "", "def", "build_dataset", "(", "args", ",", "is_bert", "=", "False", ")", ":", "\n", "    ", "if", "is_bert", ":", "\n", "        ", "if", "args", ".", "model", "in", "[", "'ASGCN'", ",", "'KGNN'", "]", ":", "\n", "            ", "dataset", ",", "vocab", "=", "load_data_dep_bert", "(", "ds_name", "=", "args", ".", "ds_name", ",", "is_bert", "=", "args", ".", "is_bert", ")", "\n", "", "else", ":", "\n", "            ", "dataset", ",", "vocab", "=", "load_data_bert", "(", "ds_name", "=", "args", ".", "ds_name", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "args", ".", "model", "==", "'RGAT'", ":", "\n", "            ", "dataset", ",", "vocab", ",", "dep_vocab", "=", "load_rgat_data", "(", "ds_name", "=", "args", ".", "ds_name", ")", "\n", "", "elif", "args", ".", "model", "in", "[", "'ASGCN'", ",", "'KGNN'", "]", ":", "\n", "            ", "dataset", ",", "vocab", "=", "load_data_dep", "(", "ds_name", "=", "args", ".", "ds_name", ")", "\n", "", "else", ":", "\n", "            ", "dataset", ",", "vocab", "=", "load_data", "(", "ds_name", "=", "args", ".", "ds_name", ")", "\n", "", "", "n_train", "=", "len", "(", "dataset", "[", "0", "]", ")", "\n", "n_test", "=", "len", "(", "dataset", "[", "1", "]", ")", "\n", "\n", "train_set", "=", "pad_dataset", "(", "dataset", "=", "dataset", "[", "0", "]", ",", "bs", "=", "args", ".", "bs", ")", "\n", "test_set", "=", "pad_dataset", "(", "dataset", "=", "dataset", "[", "1", "]", ",", "bs", "=", "args", ".", "bs", ")", "\n", "\n", "if", "is_bert", "is", "False", ":", "\n", "        ", "embeddings", "=", "get_embedding", "(", "vocab", ",", "args", ".", "ds_name", ",", "args", ",", "types", "=", "'only_word'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "embeddings", ")", ")", ":", "\n", "            ", "if", "i", "and", "np", ".", "count_nonzero", "(", "embeddings", "[", "i", "]", ")", "==", "0", ":", "\n", "                ", "embeddings", "[", "i", "]", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ",", "embeddings", ".", "shape", "[", "1", "]", ")", "\n", "", "", "embeddings", "=", "np", ".", "array", "(", "embeddings", ",", "dtype", "=", "'float32'", ")", "\n", "if", "args", ".", "model", "==", "'KGNN'", ":", "\n", "            ", "graph_embeddings", "=", "get_embedding", "(", "vocab", ",", "args", ".", "ds_name", ",", "args", ",", "types", "=", "'only_graph'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "graph_embeddings", ")", ")", ":", "\n", "                ", "if", "i", "and", "np", ".", "count_nonzero", "(", "graph_embeddings", "[", "i", "]", ")", "==", "0", ":", "\n", "                    ", "graph_embeddings", "[", "i", "]", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ",", "graph_embeddings", ".", "shape", "[", "1", "]", ")", "\n", "", "", "graph_embeddings", "=", "np", ".", "array", "(", "graph_embeddings", ",", "dtype", "=", "'float32'", ")", "\n", "return", "[", "train_set", ",", "test_set", "]", ",", "embeddings", ",", "graph_embeddings", ",", "n_train", ",", "n_test", "\n", "", "elif", "args", ".", "model", "==", "'RGAT'", ":", "\n", "            ", "return", "[", "train_set", ",", "test_set", "]", ",", "embeddings", ",", "n_train", ",", "n_test", ",", "dep_vocab", "\n", "", "else", ":", "\n", "            ", "return", "[", "train_set", ",", "test_set", "]", ",", "embeddings", ",", "n_train", ",", "n_test", "\n", "", "", "else", ":", "\n", "        ", "if", "args", ".", "model", "==", "'KGNN'", ":", "\n", "            ", "bert_vocab", "=", "{", "}", "\n", "if", "args", ".", "is_bert", "==", "1", ":", "\n", "                ", "with", "open", "(", "r'bert-base-uncased/vocab.txt'", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "                    ", "for", "num", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "                        ", "bert_vocab", "[", "line", ".", "strip", "(", ")", "]", "=", "num", "\n", "", "", "", "graph_embeddings", "=", "get_embedding", "(", "bert_vocab", ",", "args", ".", "ds_name", ",", "args", ",", "types", "=", "'only_graph'", ")", "\n", "#### add noise in knowledge graph embeddings, if percent is not zero ###", "\n", "percent", "=", "0.00", "\n", "threshold", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "noise", "=", "int", "(", "len", "(", "vocab", ")", "*", "percent", ")", "\n", "noise_num", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "graph_embeddings", ")", ")", ":", "\n", "                ", "if", "i", "and", "np", ".", "count_nonzero", "(", "graph_embeddings", "[", "i", "]", ")", "==", "0", ":", "\n", "                    ", "graph_embeddings", "[", "i", "]", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ",", "graph_embeddings", ".", "shape", "[", "1", "]", ")", "\n", "", "elif", "random", ".", "uniform", "(", "0", ",", "1", ")", "<", "threshold", "and", "noise_num", "<", "noise", ":", "\n", "                    ", "graph_embeddings", "[", "i", "]", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ",", "graph_embeddings", ".", "shape", "[", "1", "]", ")", "\n", "noise_num", "+=", "1", "\n", "", "elif", "noise_num", "==", "noise", ":", "\n", "                    ", "print", "(", "'Introduce {} percent of noise'", ".", "format", "(", "percent", ")", ")", "\n", "noise_num", "+=", "1", "\n", "", "", "graph_embeddings", "=", "np", ".", "array", "(", "graph_embeddings", ",", "dtype", "=", "'float32'", ")", "\n", "return", "[", "train_set", ",", "test_set", "]", ",", "graph_embeddings", ",", "n_train", ",", "n_test", "\n", "", "else", ":", "\n", "            ", "return", "[", "train_set", ",", "test_set", "]", ",", "n_train", ",", "n_test", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.None.utils.calculate_position_weight": [[699, 722], ["len", "range", "[].extend", "weights.append", "weights.append", "weights.append", "weights.append", "weights.append", "weights.append", "float", "float"], "function", ["None"], ["", "", "", "def", "calculate_position_weight", "(", "dataset", ",", "re_aspect", "=", "False", ")", ":", "\n", "    ", "tmax", "=", "40", "\n", "n_tuples", "=", "len", "(", "dataset", ")", "\n", "for", "i", "in", "range", "(", "n_tuples", ")", ":", "\n", "        ", "dataset", "[", "i", "]", "[", "'pw'", "]", "=", "[", "]", "\n", "weights", "=", "[", "]", "\n", "for", "w", "in", "dataset", "[", "i", "]", "[", "'dist'", "]", ":", "\n", "            ", "if", "re_aspect", ":", "\n", "                ", "if", "w", "<=", "0", ":", "\n", "                    ", "weights", ".", "append", "(", "0.0", ")", "\n", "", "elif", "w", ">", "tmax", ":", "\n", "                    ", "weights", ".", "append", "(", "0.0", ")", "\n", "", "else", ":", "\n", "                    ", "weights", ".", "append", "(", "1.0", "-", "float", "(", "w", ")", "/", "tmax", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "w", "==", "-", "1", ":", "\n", "                    ", "weights", ".", "append", "(", "0.0", ")", "\n", "", "elif", "w", ">", "tmax", ":", "\n", "                    ", "weights", ".", "append", "(", "0.0", ")", "\n", "", "else", ":", "\n", "                    ", "weights", ".", "append", "(", "1.0", "-", "float", "(", "w", ")", "/", "tmax", ")", "\n", "", "", "", "dataset", "[", "i", "]", "[", "'pw'", "]", ".", "extend", "(", "weights", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.GCAE.GCAE.__init__": [[7, 23], ["torch.Module.__init__", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "len", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "GCAE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "C", "=", "3", "\n", "D", "=", "300", "\n", "Co", "=", "100", "\n", "Ks", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "Ka", "=", "[", "2", ",", "3", "]", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "from_numpy", "(", "args", ".", "embeddings", ")", ".", "float", "(", ")", ")", "\n", "self", ".", "convs1", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "D", ",", "Co", ",", "K", ",", "padding", "=", "K", "-", "2", ")", "for", "K", "in", "Ks", "]", ")", "\n", "self", ".", "convs2", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "D", ",", "Co", ",", "K", ",", "padding", "=", "K", "-", "2", ")", "for", "K", "in", "Ks", "]", ")", "\n", "self", ".", "convs3", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "D", ",", "Co", ",", "K", ",", "padding", "=", "K", "-", "2", ")", "for", "K", "in", "[", "3", "]", "]", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "len", "(", "Ks", ")", "*", "Co", ",", "C", ")", "\n", "self", ".", "fc_aspect", "=", "nn", ".", "Linear", "(", "100", ",", "Co", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.GCAE.GCAE.forward": [[24, 39], ["GCAE.GCAE.embed", "GCAE.GCAE.embed", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "GCAE.GCAE.dropout", "GCAE.GCAE.fc3", "GCAE.GCAE.long", "aspect.long", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "conv", "conv", "zip", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "GCAE.GCAE.transpose", "conv", "GCAE.GCAE.fc_aspect().unsqueeze", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "a.size", "GCAE.GCAE.transpose", "i.size", "GCAE.GCAE.fc_aspect"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "forward", "(", "self", ",", "feature", ",", "aspect", ",", "offset", "=", "None", ")", ":", "\n", "        ", "text", ",", "aspect", "=", "feature", ".", "long", "(", ")", ",", "aspect", ".", "long", "(", ")", "\n", "feature", "=", "self", ".", "embed", "(", "text", ")", "# (N, L, D)", "\n", "aspect_v", "=", "self", ".", "embed", "(", "aspect", ")", "# (N, L', D)", "\n", "aa", "=", "[", "F", ".", "relu", "(", "conv", "(", "aspect_v", ".", "transpose", "(", "1", ",", "2", ")", ")", ")", "for", "conv", "in", "self", ".", "convs3", "]", "# [(N,Co,L), ...]*len(Ks)", "\n", "aa", "=", "[", "F", ".", "max_pool1d", "(", "a", ",", "a", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "a", "in", "aa", "]", "\n", "aspect_v", "=", "torch", ".", "cat", "(", "aa", ",", "1", ")", "\n", "x", "=", "[", "torch", ".", "tanh", "(", "conv", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ")", ")", "for", "conv", "in", "self", ".", "convs1", "]", "# [(N,Co,L), ...]*len(Ks)", "\n", "y", "=", "[", "F", ".", "relu", "(", "conv", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ")", "+", "self", ".", "fc_aspect", "(", "aspect_v", ")", ".", "unsqueeze", "(", "2", ")", ")", "for", "conv", "in", "self", ".", "convs2", "]", "\n", "x", "=", "[", "i", "*", "j", "for", "i", ",", "j", "in", "zip", "(", "x", ",", "y", ")", "]", "\n", "x", "=", "[", "F", ".", "max_pool1d", "(", "i", ",", "i", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "i", "in", "x", "]", "# [(N,Co), ...]*len(Ks)", "\n", "x", "=", "torch", ".", "cat", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "# (N,len(Ks)*Co)", "\n", "logit", "=", "self", ".", "fc3", "(", "x", ")", "# (N,C)", "\n", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.GCAE.GCAE_Bert.__init__": [[41, 58], ["torch.Module.__init__", "layers.squeeze_embedding.SqueezeEmbedding", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "len"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert", ")", ":", "\n", "        ", "super", "(", "GCAE_Bert", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert", "=", "bert", "\n", "self", ".", "squeeze_embedding", "=", "SqueezeEmbedding", "(", ")", "\n", "C", "=", "3", "\n", "D", "=", "768", "\n", "Co", "=", "100", "\n", "Ks", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "Ka", "=", "[", "2", ",", "3", "]", "\n", "self", ".", "convs1", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "D", ",", "Co", ",", "K", ")", "for", "K", "in", "Ks", "]", ")", "\n", "self", ".", "convs2", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "D", ",", "Co", ",", "K", ")", "for", "K", "in", "Ks", "]", ")", "\n", "self", ".", "convs3", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv1d", "(", "D", ",", "Co", ",", "K", ",", "padding", "=", "K", "-", "2", ")", "for", "K", "in", "[", "3", "]", "]", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "len", "(", "Ks", ")", "*", "Co", ",", "C", ")", "\n", "self", ".", "fc_aspect", "=", "nn", ".", "Linear", "(", "100", ",", "Co", ")", "\n", "self", ".", "drop_bert", "=", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.GCAE.GCAE_Bert.forward": [[59, 86], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "GCAE.GCAE_Bert.squeeze_embedding", "GCAE.GCAE_Bert.bert", "GCAE.GCAE_Bert.drop_bert", "GCAE.GCAE_Bert.squeeze_embedding", "GCAE.GCAE_Bert.bert", "GCAE.GCAE_Bert.drop_bert", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "GCAE.GCAE_Bert.dropout", "GCAE.GCAE_Bert.fc2", "bert_token.long", "bert_token_aspect.long", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "conv", "conv", "zip", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "GCAE.GCAE_Bert.transpose", "conv", "GCAE.GCAE_Bert.fc_aspect().unsqueeze", "torch.max_pool1d", "torch.max_pool1d", "torch.max_pool1d", "a.size", "GCAE.GCAE_Bert.transpose", "i.size", "GCAE.GCAE_Bert.fc_aspect"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "forward", "(", "self", ",", "bert_token", ",", "bert_token_aspect", ",", "offset", ")", ":", "\n", "# BERT encoding", "\n", "        ", "bert_token", ",", "bert_token_aspect", "=", "bert_token", ".", "long", "(", ")", ",", "bert_token_aspect", ".", "long", "(", ")", "\n", "context_len", "=", "torch", ".", "sum", "(", "bert_token", "!=", "0", ",", "dim", "=", "-", "1", ")", "\n", "target_len", "=", "torch", ".", "sum", "(", "bert_token_aspect", "!=", "0", ",", "dim", "=", "-", "1", ")", "\n", "context", "=", "self", ".", "squeeze_embedding", "(", "bert_token", ",", "context_len", ")", "\n", "#context,target=bert_token, bert_token_aspect", "\n", "text_embed", ",", "_", "=", "self", ".", "bert", "(", "context", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "feature", "=", "self", ".", "drop_bert", "(", "text_embed", ")", "\n", "\n", "target", "=", "self", ".", "squeeze_embedding", "(", "bert_token_aspect", ",", "target_len", ")", "\n", "aspect_embed", ",", "_", "=", "self", ".", "bert", "(", "target", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "aspect_v", "=", "self", ".", "drop_bert", "(", "aspect_embed", ")", "\n", "\n", "aa", "=", "[", "F", ".", "relu", "(", "conv", "(", "aspect_v", ".", "transpose", "(", "1", ",", "2", ")", ")", ")", "for", "conv", "in", "self", ".", "convs3", "]", "# [(N,Co,L), ...]*len(Ks)", "\n", "aa", "=", "[", "F", ".", "max_pool1d", "(", "a", ",", "a", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "a", "in", "aa", "]", "\n", "aspect_v", "=", "torch", ".", "cat", "(", "aa", ",", "1", ")", "\n", "x", "=", "[", "torch", ".", "tanh", "(", "conv", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ")", ")", "for", "conv", "in", "self", ".", "convs1", "]", "# [(N,Co,L), ...]*len(Ks)", "\n", "y", "=", "[", "F", ".", "relu", "(", "conv", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ")", "+", "self", ".", "fc_aspect", "(", "aspect_v", ")", ".", "unsqueeze", "(", "2", ")", ")", "for", "conv", "in", "self", ".", "convs2", "]", "\n", "x", "=", "[", "i", "*", "j", "for", "i", ",", "j", "in", "zip", "(", "x", ",", "y", ")", "]", "\n", "\n", "x", "=", "[", "F", ".", "max_pool1d", "(", "i", ",", "i", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "for", "i", "in", "x", "]", "# [(N,Co), ...]*len(Ks)", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "# (N,len(Ks)*Co)", "\n", "logit", "=", "self", ".", "fc2", "(", "x", ")", "# (N,C)", "\n", "return", "logit", "\n", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.IAN.IAN.__init__": [[6, 15], ["torch.nn.Module.__init__", "torch.nn.Embedding.from_pretrained", "layers.dynamic_rnn.DynamicLSTM", "layers.dynamic_rnn.DynamicLSTM", "layers.attention.Attention", "layers.attention.Attention", "torch.nn.Linear", "torch.from_numpy().float().cuda", "torch.from_numpy().float", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "IAN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "from_numpy", "(", "args", ".", "embeddings", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ",", "freeze", "=", "True", ")", "\n", "self", ".", "lstm_context", "=", "DynamicLSTM", "(", "300", ",", "300", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "lstm_aspect", "=", "DynamicLSTM", "(", "300", ",", "300", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "attention_aspect", "=", "Attention", "(", "300", ",", "score_function", "=", "'bi_linear'", ")", "\n", "self", ".", "attention_context", "=", "Attention", "(", "300", ",", "score_function", "=", "'bi_linear'", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "300", "*", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.IAN.IAN.forward": [[16, 47], ["torch.sum().cpu", "torch.sum().cpu", "IAN.IAN.embed", "IAN.IAN.embed", "IAN.IAN.lstm_context", "IAN.IAN.lstm_aspect", "torch.cuda.is_available", "torch.sum", "torch.div", "torch.cuda.is_available", "torch.sum", "torch.div", "IAN.IAN.attention_aspect", "aspect_final.squeeze.squeeze.squeeze", "IAN.IAN.attention_context", "context_final.squeeze.squeeze.squeeze", "torch.cat", "IAN.IAN.dense", "feature.long", "IAN.IAN.long", "torch.tensor().cuda", "torch.tensor", "torch.tensor.view", "torch.tensor().cuda", "torch.tensor", "torch.tensor.view", "torch.sum", "torch.sum", "torch.tensor.size", "torch.tensor.size", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "forward", "(", "self", ",", "feature", ",", "aspect", ",", "offset", ")", ":", "\n", "        ", "text_raw_indices", ",", "aspect_indices", ",", "offset", "=", "feature", ".", "long", "(", ")", ",", "aspect", ".", "long", "(", ")", ",", "offset", "\n", "text_raw_len", "=", "torch", ".", "sum", "(", "text_raw_indices", "!=", "0", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", "\n", "aspect_len", "=", "torch", ".", "sum", "(", "aspect_indices", "!=", "0", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", "\n", "\n", "context", "=", "self", ".", "embed", "(", "text_raw_indices", ")", "\n", "aspect", "=", "self", ".", "embed", "(", "aspect_indices", ")", "\n", "context", ",", "(", "_", ",", "_", ")", "=", "self", ".", "lstm_context", "(", "context", ",", "text_raw_len", ")", "\n", "aspect", ",", "(", "_", ",", "_", ")", "=", "self", ".", "lstm_aspect", "(", "aspect", ",", "aspect_len", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "aspect_len", "=", "torch", ".", "tensor", "(", "aspect_len", ",", "dtype", "=", "torch", ".", "float", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "aspect_len", "=", "torch", ".", "tensor", "(", "aspect_len", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "aspect_pool", "=", "torch", ".", "sum", "(", "aspect", ",", "dim", "=", "1", ")", "\n", "aspect_pool", "=", "torch", ".", "div", "(", "aspect_pool", ",", "aspect_len", ".", "view", "(", "aspect_len", ".", "size", "(", "0", ")", ",", "1", ")", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "text_raw_len", "=", "torch", ".", "tensor", "(", "text_raw_len", ",", "dtype", "=", "torch", ".", "float", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "text_raw_len", "=", "torch", ".", "tensor", "(", "text_raw_len", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "context_pool", "=", "torch", ".", "sum", "(", "context", ",", "dim", "=", "1", ")", "\n", "context_pool", "=", "torch", ".", "div", "(", "context_pool", ",", "text_raw_len", ".", "view", "(", "text_raw_len", ".", "size", "(", "0", ")", ",", "1", ")", ")", "\n", "\n", "aspect_final", ",", "_", "=", "self", ".", "attention_aspect", "(", "aspect", ",", "context_pool", ")", "\n", "aspect_final", "=", "aspect_final", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "context_final", ",", "_", "=", "self", ".", "attention_context", "(", "context", ",", "aspect_pool", ")", "\n", "context_final", "=", "context_final", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "(", "aspect_final", ",", "context_final", ")", ",", "dim", "=", "-", "1", ")", "\n", "out", "=", "self", ".", "dense", "(", "x", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ATAE_LSTM.ATAE_LSTM.__init__": [[9, 17], ["torch.Module.__init__", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "layers.squeeze_embedding.SqueezeEmbedding", "layers.dynamic_rnn.DynamicLSTM", "layers.attention.NoQueryAttention", "torch.Linear", "torch.Linear", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "ATAE_LSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "from_numpy", "(", "args", ".", "embeddings", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ",", "freeze", "=", "True", ")", "\n", "self", ".", "squeeze_embedding", "=", "SqueezeEmbedding", "(", ")", "\n", "self", ".", "lstm", "=", "DynamicLSTM", "(", "300", "*", "2", ",", "300", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "attention", "=", "NoQueryAttention", "(", "300", "+", "300", ",", "score_function", "=", "'bi_linear'", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "300", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ATAE_LSTM.ATAE_LSTM.forward": [[19, 42], ["torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.max", "torch.max", "torch.max", "torch.max", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "ATAE_LSTM.ATAE_LSTM.embed", "ATAE_LSTM.ATAE_LSTM.squeeze_embedding", "ATAE_LSTM.ATAE_LSTM.embed", "torch.div", "torch.div", "torch.div", "torch.div", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ATAE_LSTM.ATAE_LSTM.lstm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ATAE_LSTM.ATAE_LSTM.attention", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "ATAE_LSTM.ATAE_LSTM.fc3", "context.long", "torch.unsqueeze().expand.long", "torch.unsqueeze().expand.long", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.tensor.view", "torch.tensor.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.tensor.size", "torch.tensor.size", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "forward", "(", "self", ",", "context", ",", "aspect", ",", "offset", ")", ":", "\n", "        ", "text_raw_indices", ",", "aspect_indices", ",", "offset", "=", "context", ".", "long", "(", ")", ",", "aspect", ".", "long", "(", ")", ",", "offset", "\n", "x_len", "=", "torch", ".", "sum", "(", "text_raw_indices", "!=", "0", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", "\n", "x_len_max", "=", "torch", ".", "max", "(", "x_len", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "aspect_len", "=", "torch", ".", "tensor", "(", "torch", ".", "sum", "(", "aspect_indices", "!=", "0", ",", "dim", "=", "-", "1", ")", ",", "dtype", "=", "torch", ".", "float", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "aspect_len", "=", "torch", ".", "tensor", "(", "torch", ".", "sum", "(", "aspect_indices", "!=", "0", ",", "dim", "=", "-", "1", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "x", "=", "self", ".", "embed", "(", "text_raw_indices", ")", "\n", "x", "=", "self", ".", "squeeze_embedding", "(", "x", ",", "x_len", ")", "\n", "aspect", "=", "self", ".", "embed", "(", "aspect_indices", ")", "\n", "aspect_pool", "=", "torch", ".", "div", "(", "torch", ".", "sum", "(", "aspect", ",", "dim", "=", "1", ")", ",", "aspect_len", ".", "view", "(", "aspect_len", ".", "size", "(", "0", ")", ",", "1", ")", ")", "\n", "aspect", "=", "torch", ".", "unsqueeze", "(", "aspect_pool", ",", "dim", "=", "1", ")", ".", "expand", "(", "-", "1", ",", "x_len_max", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "aspect", ",", "x", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "h", ",", "(", "_", ",", "_", ")", "=", "self", ".", "lstm", "(", "x", ",", "x_len", ")", "\n", "ha", "=", "torch", ".", "cat", "(", "(", "h", ",", "aspect", ")", ",", "dim", "=", "-", "1", ")", "\n", "_", ",", "score", "=", "self", ".", "attention", "(", "ha", ")", "\n", "\n", "output", "=", "torch", ".", "squeeze", "(", "torch", ".", "bmm", "(", "score", ",", "h", ")", ",", "dim", "=", "1", ")", "\n", "\n", "out", "=", "self", ".", "fc3", "(", "output", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ATAE_LSTM.ATAE_LSTM_Bert.__init__": [[44, 53], ["torch.Module.__init__", "layers.squeeze_embedding.SqueezeEmbedding", "layers.dynamic_rnn.DynamicLSTM", "torch.Linear", "torch.Linear", "layers.attention.NoQueryAttention", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert", ")", ":", "\n", "        ", "super", "(", "ATAE_LSTM_Bert", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert", "=", "bert", "\n", "self", ".", "squeeze_embedding", "=", "SqueezeEmbedding", "(", ")", "\n", "self", ".", "lstm", "=", "DynamicLSTM", "(", "768", "*", "2", ",", "300", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "fc_aspect", "=", "nn", ".", "Linear", "(", "768", ",", "300", ")", "\n", "self", ".", "attention", "=", "NoQueryAttention", "(", "300", "+", "300", ",", "score_function", "=", "'bi_linear'", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "300", ",", "3", ")", "\n", "self", ".", "drop_bert", "=", "nn", ".", "Dropout", "(", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ATAE_LSTM.ATAE_LSTM_Bert.forward": [[54, 80], ["torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "ATAE_LSTM.ATAE_LSTM_Bert.bert", "ATAE_LSTM.ATAE_LSTM_Bert.drop_bert", "ATAE_LSTM.ATAE_LSTM_Bert.squeeze_embedding", "ATAE_LSTM.ATAE_LSTM_Bert.bert", "ATAE_LSTM.ATAE_LSTM_Bert.drop_bert", "torch.div", "torch.div", "torch.div", "torch.div", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ATAE_LSTM.ATAE_LSTM_Bert.lstm", "ATAE_LSTM.ATAE_LSTM_Bert.fc_aspect", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ATAE_LSTM.ATAE_LSTM_Bert.attention", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "ATAE_LSTM.ATAE_LSTM_Bert.fc", "bert_token.long", "bert_token_aspect.long", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.tensor.view", "torch.tensor.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.max", "torch.max", "torch.max", "torch.max", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.tensor.size", "torch.tensor.size", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "forward", "(", "self", ",", "bert_token", ",", "bert_token_aspect", ",", "offset", ")", ":", "\n", "# BERT encoding", "\n", "        ", "text_raw_indices", ",", "aspect_indices", "=", "bert_token", ".", "long", "(", ")", ",", "bert_token_aspect", ".", "long", "(", ")", "\n", "x_len", "=", "torch", ".", "sum", "(", "text_raw_indices", "!=", "0", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", "\n", "x_len_max", "=", "torch", ".", "max", "(", "x_len", ")", ".", "item", "(", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "aspect_len", "=", "torch", ".", "tensor", "(", "torch", ".", "sum", "(", "aspect_indices", "!=", "0", ",", "dim", "=", "-", "1", ")", ",", "dtype", "=", "torch", ".", "float", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "aspect_len", "=", "torch", ".", "tensor", "(", "torch", ".", "sum", "(", "aspect_indices", "!=", "0", ",", "dim", "=", "-", "1", ")", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "x", ",", "_", "=", "self", ".", "bert", "(", "text_raw_indices", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "x", "=", "self", ".", "drop_bert", "(", "x", ")", "\n", "x", "=", "self", ".", "squeeze_embedding", "(", "x", ",", "x_len", ")", "\n", "aspect", ",", "_", "=", "self", ".", "bert", "(", "aspect_indices", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "aspect", "=", "self", ".", "drop_bert", "(", "aspect", ")", "\n", "aspect_pool", "=", "torch", ".", "div", "(", "torch", ".", "sum", "(", "aspect", ",", "dim", "=", "1", ")", ",", "aspect_len", ".", "view", "(", "aspect_len", ".", "size", "(", "0", ")", ",", "1", ")", ")", "\n", "aspect", "=", "torch", ".", "unsqueeze", "(", "aspect_pool", ",", "dim", "=", "1", ")", ".", "expand", "(", "-", "1", ",", "x_len_max", ",", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "aspect", ",", "x", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "h", ",", "(", "_", ",", "_", ")", "=", "self", ".", "lstm", "(", "x", ",", "x_len", ")", "\n", "aspect", "=", "self", ".", "fc_aspect", "(", "aspect", ")", "\n", "ha", "=", "torch", ".", "cat", "(", "(", "h", ",", "aspect", ")", ",", "dim", "=", "-", "1", ")", "\n", "_", ",", "score", "=", "self", ".", "attention", "(", "ha", ")", "\n", "output", "=", "torch", ".", "squeeze", "(", "torch", ".", "bmm", "(", "score", ",", "h", ")", ",", "dim", "=", "1", ")", "\n", "\n", "out", "=", "self", ".", "fc", "(", "output", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.TNet.Absolute_Position_Embedding.__init__": [[7, 11], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "size", "=", "None", ",", "mode", "=", "'sum'", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "mode", "=", "mode", "\n", "super", "(", "Absolute_Position_Embedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.TNet.Absolute_Position_Embedding.forward": [[12, 24], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "range", "int", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_.unsqueeze", "torch.FloatTensor().zero_.unsqueeze", "x.size", "x.size", "x.size", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "forward", "(", "self", ",", "x", ",", "offset", ")", ":", "\n", "        ", "if", "(", "self", ".", "size", "is", "None", ")", "or", "(", "self", ".", "mode", "==", "'sum'", ")", ":", "\n", "            ", "self", ".", "size", "=", "int", "(", "x", ".", "size", "(", "-", "1", ")", ")", "\n", "", "batch_size", ",", "seq_len", "=", "x", ".", "size", "(", ")", "[", "0", "]", ",", "x", ".", "size", "(", ")", "[", "1", "]", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "weight", "=", "torch", ".", "FloatTensor", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ")", ".", "zero_", "(", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "torch", ".", "FloatTensor", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ")", ".", "zero_", "(", ")", "\n", "", "for", "i", "in", "range", "(", "offset", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "weight", "[", "i", "]", "=", "offset", "[", "i", "]", "[", ":", "x", ".", "shape", "[", "1", "]", "]", "\n", "", "x", "=", "weight", ".", "unsqueeze", "(", "2", ")", "*", "x", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.TNet.Absolute_Position_Embedding.weight_matrix": [[26, 37], ["range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "range", "range", "range", "weight[].append", "weight[].append"], "methods", ["None"], ["", "def", "weight_matrix", "(", "self", ",", "pos_inx", ",", "batch_size", ",", "seq_len", ")", ":", "\n", "        ", "weight", "=", "[", "[", "]", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "pos_inx", "[", "i", "]", ")", ":", "\n", "                ", "relative_pos", "=", "pos_inx", "[", "i", "]", "-", "j", "\n", "weight", "[", "i", "]", ".", "append", "(", "1", "-", "relative_pos", "/", "40", ")", "\n", "", "for", "j", "in", "range", "(", "pos_inx", "[", "i", "]", ",", "seq_len", ")", ":", "\n", "                ", "relative_pos", "=", "j", "-", "pos_inx", "[", "i", "]", "\n", "weight", "[", "i", "]", ".", "append", "(", "1", "-", "relative_pos", "/", "40", ")", "\n", "", "", "weight", "=", "torch", ".", "tensor", "(", "weight", ")", "\n", "return", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.TNet.TNet_LF.__init__": [[39, 53], ["torch.nn.Module.__init__", "print", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding.from_pretrained", "TNet.Absolute_Position_Embedding", "layers.dynamic_rnn.DynamicLSTM", "layers.dynamic_rnn.DynamicLSTM", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "TNet_LF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "print", "(", "\"this is TNet_LF model\"", ")", "\n", "V", "=", "300", "\n", "D", "=", "300", "\n", "C", "=", "3", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "from_numpy", "(", "args", ".", "embeddings", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ",", "freeze", "=", "True", ")", "\n", "self", ".", "position", "=", "Absolute_Position_Embedding", "(", ")", "\n", "HD", "=", "300", "\n", "self", ".", "lstm1", "=", "DynamicLSTM", "(", "300", ",", "300", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "self", ".", "lstm2", "=", "DynamicLSTM", "(", "300", ",", "300", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "self", ".", "convs3", "=", "nn", ".", "Conv1d", "(", "2", "*", "HD", ",", "50", ",", "3", ",", "padding", "=", "1", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "4", "*", "HD", ",", "2", "*", "HD", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "50", ",", "C", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.TNet.TNet_LF.get_aspect_index": [[54, 65], ["aspect_len.cpu().numpy.cpu().numpy.cpu().numpy", "td_len.cpu().numpy.cpu().numpy.cpu().numpy", "range", "aspect_index.append", "aspect_len.cpu().numpy.cpu().numpy.cpu", "td_len.cpu().numpy.cpu().numpy.cpu"], "methods", ["None"], ["", "def", "get_aspect_index", "(", "self", ",", "aspect_len", ",", "td_len", ")", ":", "\n", "        ", "aspect_index", "=", "[", "]", "\n", "aspect_len", "=", "aspect_len", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "td_len", "=", "td_len", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "i", "in", "range", "(", "aspect_len", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "a", "=", "td_len", "[", "i", "]", "-", "aspect_len", "[", "i", "]", "\n", "", "except", "ValueError", ":", "\n", "                ", "a", "=", "0", "\n", "", "aspect_index", ".", "append", "(", "a", ")", "\n", "", "return", "aspect_index", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.TNet.TNet_LF.forward": [[66, 88], ["torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "TNet.TNet_LF.embed", "TNet.TNet_LF.embed", "TNet.TNet_LF.lstm1", "TNet.TNet_LF.lstm2", "TNet.TNet_LF.transpose", "e.transpose.transpose.transpose", "range", "torch.relu", "torch.relu", "torch.max_pool1d().squeeze", "torch.max_pool1d().squeeze", "TNet.TNet_LF.fc", "TNet.TNet_LF.long", "TNet.TNet_LF.long", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.cat().transpose", "torch.relu", "torch.relu", "TNet.TNet_LF.position().transpose", "TNet.TNet_LF.convs3", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "e.transpose.transpose.transpose", "TNet.TNet_LF.fc1().transpose", "torch.max_pool1d", "torch.max_pool1d", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "TNet.TNet_LF.position", "torch.max_pool1d().squeeze.size", "TNet.TNet_LF.fc1", "TNet.TNet_LF.transpose"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "forward", "(", "self", ",", "feature", ",", "aspect", ",", "offset", ")", ":", "\n", "        ", "text_raw_indices", ",", "aspect_indices", ",", "offset", "=", "feature", ".", "long", "(", ")", ",", "aspect", ".", "long", "(", ")", ",", "offset", "\n", "feature_len", "=", "torch", ".", "sum", "(", "text_raw_indices", "!=", "0", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", "\n", "aspect_len", "=", "torch", ".", "sum", "(", "aspect_indices", "!=", "0", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", "\n", "feature", "=", "self", ".", "embed", "(", "text_raw_indices", ")", "\n", "aspect", "=", "self", ".", "embed", "(", "aspect_indices", ")", "\n", "v", ",", "(", "_", ",", "_", ")", "=", "self", ".", "lstm1", "(", "feature", ",", "feature_len", ")", "\n", "e", ",", "(", "_", ",", "_", ")", "=", "self", ".", "lstm2", "(", "aspect", ",", "aspect_len", ")", "\n", "v", "=", "v", ".", "transpose", "(", "1", ",", "2", ")", "\n", "e", "=", "e", ".", "transpose", "(", "1", ",", "2", ")", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "            ", "a", "=", "torch", ".", "bmm", "(", "e", ".", "transpose", "(", "1", ",", "2", ")", ",", "v", ")", "\n", "a", "=", "F", ".", "softmax", "(", "a", ",", "1", ")", "# (aspect_len,context_len)", "\n", "aspect_mid", "=", "torch", ".", "bmm", "(", "e", ",", "a", ")", "\n", "aspect_mid", "=", "torch", ".", "cat", "(", "(", "aspect_mid", ",", "v", ")", ",", "dim", "=", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "aspect_mid", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "aspect_mid", ")", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "v", "=", "aspect_mid", "+", "v", "\n", "v", "=", "self", ".", "position", "(", "v", ".", "transpose", "(", "1", ",", "2", ")", ",", "offset", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "", "z", "=", "F", ".", "relu", "(", "self", ".", "convs3", "(", "v", ")", ")", "# [(N,Co,L), ...]*len(Ks)", "\n", "z", "=", "F", ".", "max_pool1d", "(", "z", ",", "z", ".", "size", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "\n", "out", "=", "self", ".", "fc", "(", "z", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.GraphConvolution.__init__": [[7, 16], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "ASGCN.GraphConvolution.register_parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "GraphConvolution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "in_features", ",", "out_features", ")", ",", "requires_grad", "=", "True", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "out_features", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.GraphConvolution.forward": [[17, 25], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "text", ",", "adj", ")", ":", "\n", "        ", "hidden", "=", "torch", ".", "matmul", "(", "text", ",", "self", ".", "weight", ")", "\n", "denom", "=", "torch", ".", "sum", "(", "adj", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "+", "1", "\n", "output", "=", "torch", ".", "matmul", "(", "adj", ",", "hidden", ")", "/", "denom", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "return", "output", "+", "self", ".", "bias", "\n", "", "else", ":", "\n", "            ", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN.__init__": [[27, 39], ["torch.Module.__init__", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "layers.dynamic_rnn.DynamicLSTM", "ASGCN.GraphConvolution", "ASGCN.GraphConvolution", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "ASGCN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "embed", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "from_numpy", "(", "args", ".", "embeddings", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ",", "freeze", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "from_numpy", "(", "args", ".", "embeddings", ")", ".", "float", "(", ")", ",", "freeze", "=", "True", ")", "\n", "", "self", ".", "text_lstm", "=", "DynamicLSTM", "(", "300", ",", "300", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "self", ".", "gc1", "=", "GraphConvolution", "(", "2", "*", "300", ",", "2", "*", "300", ")", "\n", "self", ".", "gc2", "=", "GraphConvolution", "(", "2", "*", "300", ",", "2", "*", "300", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "2", "*", "300", ",", "3", ")", "\n", "self", ".", "text_embed_dropout", "=", "nn", ".", "Dropout", "(", "0.3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN.location_feature": [[40, 49], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "range", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_.unsqueeze", "torch.FloatTensor().zero_.unsqueeze", "torch.FloatTensor().zero_.unsqueeze", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "location_feature", "(", "self", ",", "feature", ",", "offset", ")", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "weight", "=", "torch", ".", "FloatTensor", "(", "feature", ".", "shape", "[", "0", "]", ",", "feature", ".", "shape", "[", "1", "]", ")", ".", "zero_", "(", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "torch", ".", "FloatTensor", "(", "feature", ".", "shape", "[", "0", "]", ",", "feature", ".", "shape", "[", "1", "]", ")", ".", "zero_", "(", ")", "\n", "", "for", "i", "in", "range", "(", "offset", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "weight", "[", "i", "]", "=", "offset", "[", "i", "]", "[", ":", "feature", ".", "shape", "[", "1", "]", "]", "\n", "", "feature", "=", "weight", ".", "unsqueeze", "(", "2", ")", "*", "feature", "\n", "return", "feature", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN.forward": [[50, 68], ["torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "ASGCN.ASGCN.embed", "ASGCN.ASGCN.text_embed_dropout", "ASGCN.ASGCN.text_lstm", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "ASGCN.ASGCN.location_feature", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "ASGCN.ASGCN.fc2", "feature.long", "aspect.long", "adj.float", "mask.long", "ASGCN.ASGCN.gc1", "ASGCN.ASGCN.gc2", "text_out.transpose", "torch.matmul.sum", "torch.matmul.sum", "torch.matmul.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "ASGCN.ASGCN.location_feature", "ASGCN.ASGCN.location_feature", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN_BERT.location_feature", "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN_BERT.location_feature", "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN_BERT.location_feature"], ["", "def", "forward", "(", "self", ",", "feature", ",", "aspect", ",", "offset", ",", "adj", ",", "mask", ")", ":", "\n", "        ", "feature", ",", "aspect", ",", "offset", ",", "adj", ",", "mask", "=", "feature", ".", "long", "(", ")", ",", "aspect", ".", "long", "(", ")", ",", "offset", ",", "adj", ".", "float", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "text_len", "=", "torch", ".", "sum", "(", "feature", "!=", "0", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", "\n", "text", "=", "self", ".", "embed", "(", "feature", ")", "\n", "text", "=", "self", ".", "text_embed_dropout", "(", "text", ")", "\n", "text_out", ",", "(", "_", ",", "_", ")", "=", "self", ".", "text_lstm", "(", "text", ",", "text_len", ")", "\n", "seq_len", "=", "text_out", ".", "shape", "[", "1", "]", "\n", "adj", "=", "adj", "[", ":", ",", ":", "seq_len", ",", ":", "seq_len", "]", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "gc1", "(", "self", ".", "location_feature", "(", "text_out", ",", "offset", ")", ",", "adj", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "gc2", "(", "self", ".", "location_feature", "(", "x", ",", "offset", ")", ",", "adj", ")", ")", "\n", "# x = F.relu(self.gc1(text_out, adj))", "\n", "# x = F.relu(self.gc2(x, adj))", "\n", "x", "=", "self", ".", "location_feature", "(", "x", ",", "mask", ")", "\n", "alpha_mat", "=", "torch", ".", "matmul", "(", "x", ",", "text_out", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "alpha", "=", "F", ".", "softmax", "(", "alpha_mat", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ",", "dim", "=", "2", ")", "\n", "x", "=", "torch", ".", "matmul", "(", "alpha", ",", "text_out", ")", ".", "squeeze", "(", "1", ")", "# batch_size x 2*hidden_dim", "\n", "output", "=", "self", ".", "fc2", "(", "x", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN_BERT.__init__": [[70, 80], ["torch.Module.__init__", "layers.dynamic_rnn.DynamicLSTM", "ASGCN.GraphConvolution", "ASGCN.GraphConvolution", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert", ",", "args", ")", ":", "\n", "        ", "super", "(", "ASGCN_BERT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "bert", "=", "bert", "\n", "h_num", "=", "300", "\n", "self", ".", "text_lstm", "=", "DynamicLSTM", "(", "768", ",", "h_num", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", "\n", "self", ".", "gc1", "=", "GraphConvolution", "(", "2", "*", "h_num", ",", "2", "*", "h_num", ")", "\n", "self", ".", "gc2", "=", "GraphConvolution", "(", "2", "*", "h_num", ",", "2", "*", "h_num", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "2", "*", "h_num", ",", "3", ")", "\n", "self", ".", "text_embed_dropout", "=", "nn", ".", "Dropout", "(", "args", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN_BERT.location_feature": [[81, 90], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "range", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_().cuda", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_.unsqueeze", "torch.FloatTensor().zero_.unsqueeze", "torch.FloatTensor().zero_.unsqueeze", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "location_feature", "(", "self", ",", "feature", ",", "offset", ")", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "weight", "=", "torch", ".", "FloatTensor", "(", "feature", ".", "shape", "[", "0", "]", ",", "feature", ".", "shape", "[", "1", "]", ")", ".", "zero_", "(", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "weight", "=", "torch", ".", "FloatTensor", "(", "feature", ".", "shape", "[", "0", "]", ",", "feature", ".", "shape", "[", "1", "]", ")", ".", "zero_", "(", ")", "\n", "", "for", "i", "in", "range", "(", "offset", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "weight", "[", "i", "]", "=", "offset", "[", "i", "]", "[", ":", "feature", ".", "shape", "[", "1", "]", "]", "\n", "", "feature", "=", "weight", ".", "unsqueeze", "(", "2", ")", "*", "feature", "\n", "return", "feature", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN_BERT.forward": [[91, 113], ["torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "ASGCN.ASGCN_BERT.bert", "ASGCN.ASGCN_BERT.text_embed_dropout", "ASGCN.ASGCN_BERT.text_lstm", "ASGCN.ASGCN_BERT.text_embed_dropout", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "ASGCN.ASGCN_BERT.location_feature", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "torch.matmul().squeeze", "ASGCN.ASGCN_BERT.text_embed_dropout", "ASGCN.ASGCN_BERT.fc2", "feature.long", "aspect.long", "adj.float", "mask.long", "ASGCN.ASGCN_BERT.gc1", "ASGCN.ASGCN_BERT.gc2", "ASGCN.ASGCN_BERT.transpose", "torch.matmul.sum", "torch.matmul.sum", "torch.matmul.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "ASGCN.ASGCN_BERT.location_feature", "ASGCN.ASGCN_BERT.location_feature", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN_BERT.location_feature", "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN_BERT.location_feature", "home.repos.pwc.inspect_result.whu-zqh_kgan.model.ASGCN.ASGCN_BERT.location_feature"], ["", "def", "forward", "(", "self", ",", "feature", ",", "aspect", ",", "offset", ",", "adj", ",", "mask", ")", ":", "\n", "        ", "feature", ",", "aspect", ",", "offset", ",", "adj", ",", "mask", "=", "feature", ".", "long", "(", ")", ",", "aspect", ".", "long", "(", ")", ",", "offset", ",", "adj", ".", "float", "(", ")", ",", "mask", ".", "long", "(", ")", "\n", "# a=np.array(mask.tolist())", "\n", "text_len", "=", "torch", ".", "sum", "(", "feature", "!=", "0", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", "\n", "text", ",", "_", "=", "self", ".", "bert", "(", "feature", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "text", "=", "self", ".", "text_embed_dropout", "(", "text", ")", "\n", "text_out", ",", "(", "_", ",", "_", ")", "=", "self", ".", "text_lstm", "(", "text", ",", "text_len", ")", "\n", "text_out", "=", "self", ".", "text_embed_dropout", "(", "text_out", ")", "\n", "seq_len", "=", "text_out", ".", "shape", "[", "1", "]", "\n", "adj", "=", "adj", "[", ":", ",", ":", "seq_len", ",", ":", "seq_len", "]", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "gc1", "(", "self", ".", "location_feature", "(", "text_out", ",", "offset", ")", ",", "adj", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "gc2", "(", "self", ".", "location_feature", "(", "x", ",", "offset", ")", ",", "adj", ")", ")", "\n", "# x = F.relu(self.gc1(text_out, adj))", "\n", "# x = F.relu(self.gc2(x, adj))", "\n", "x", "=", "self", ".", "location_feature", "(", "x", ",", "mask", ")", "\n", "# b=np.array(x.tolist())", "\n", "alpha_mat", "=", "torch", ".", "matmul", "(", "x", ",", "text_out", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "alpha", "=", "F", ".", "softmax", "(", "alpha_mat", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ",", "dim", "=", "2", ")", "\n", "x", "=", "torch", ".", "matmul", "(", "alpha", ",", "text_out", ")", ".", "squeeze", "(", "1", ")", "# batch_size x 2*hidden_dim", "\n", "x", "=", "self", ".", "text_embed_dropout", "(", "x", ")", "\n", "output", "=", "self", ".", "fc2", "(", "x", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.RGAT.RGAT.__init__": [[12, 64], ["torch.Module.__init__", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.Dropout", "torch.Dropout", "torch.Tanh", "torch.Tanh", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Embedding", "torch.Embedding", "range", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "model.rgat_file.model_utils.Highway", "model.rgat_file.model_utils.Highway", "model.rgat_file.model_utils.RelationAttention().cuda", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "range", "model.rgat_file.model_utils.LinearAttention().cuda", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "model.rgat_file.model_utils.RelationAttention", "range", "model.rgat_file.model_utils.DotprodAttention().cuda", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "model.rgat_file.model_utils.LinearAttention", "range", "model.rgat_file.model_utils.DotprodAttention", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "dep_tag_num", ")", ":", "\n", "        ", "super", "(", "RGAT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "embed", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "from_numpy", "(", "args", ".", "embeddings", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ",", "freeze", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "from_numpy", "(", "args", ".", "embeddings", ")", ".", "float", "(", ")", ",", "freeze", "=", "True", ")", "\n", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.7", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "embedding_dim", "=", "300", "\n", "num_layer", "=", "1", "\n", "hidden_sizes", "=", "300", "\n", "num_heads", "=", "7", "\n", "final_hidden_size", "=", "300", "\n", "num_classes", "=", "3", "\n", "highway", "=", "True", "\n", "self", ".", "gat_attention_type", "=", "'dotprod'", "\n", "num_mlps", "=", "2", "\n", "\n", "if", "highway", ":", "\n", "            ", "self", ".", "highway_dep", "=", "Highway", "(", "num_layer", ",", "embedding_dim", ")", "\n", "self", ".", "highway", "=", "Highway", "(", "num_layer", ",", "embedding_dim", ")", "\n", "\n", "", "self", ".", "text_bilstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "embedding_dim", ",", "hidden_size", "=", "hidden_sizes", ",", "\n", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ",", "num_layers", "=", "num_layer", ")", "\n", "\n", "self", ".", "aspect_bilstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "embedding_dim", ",", "hidden_size", "=", "hidden_sizes", ",", "\n", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ",", "num_layers", "=", "num_layer", ")", "\n", "\n", "gcn_input_dim", "=", "hidden_sizes", "*", "2", "\n", "\n", "self", ".", "gat_dep", "=", "[", "RelationAttention", "(", "in_dim", "=", "embedding_dim", ")", ".", "cuda", "(", ")", "for", "i", "in", "range", "(", "num_heads", ")", "]", "\n", "if", "self", ".", "gat_attention_type", "==", "'linear'", ":", "\n", "            ", "self", ".", "gat", "=", "[", "LinearAttention", "(", "in_dim", "=", "gcn_input_dim", ",", "mem_dim", "=", "gcn_input_dim", ")", ".", "cuda", "(", ")", "for", "i", "in", "range", "(", "num_heads", ")", "]", "# we prefer to keep the dimension unchanged", "\n", "", "elif", "self", ".", "gat_attention_type", "==", "'dotprod'", ":", "\n", "            ", "self", ".", "gat", "=", "[", "DotprodAttention", "(", ")", ".", "cuda", "(", ")", "for", "i", "in", "range", "(", "num_heads", ")", "]", "\n", "", "else", ":", "\n", "# reshaped gcn", "\n", "            ", "self", ".", "gat", "=", "nn", ".", "Linear", "(", "gcn_input_dim", ",", "gcn_input_dim", ")", "\n", "\n", "", "self", ".", "dep_embed", "=", "nn", ".", "Embedding", "(", "dep_tag_num", ",", "embedding_dim", ")", "\n", "\n", "last_hidden_size", "=", "hidden_sizes", "*", "4", "\n", "\n", "layers", "=", "[", "\n", "nn", ".", "Linear", "(", "last_hidden_size", ",", "final_hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "]", "\n", "for", "_", "in", "range", "(", "num_mlps", "-", "1", ")", ":", "\n", "            ", "layers", "+=", "[", "nn", ".", "Linear", "(", "final_hidden_size", ",", "\n", "final_hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "]", "\n", "", "self", ".", "fcs", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "fc_final", "=", "nn", ".", "Linear", "(", "final_hidden_size", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.RGAT.RGAT.forward": [[65, 110], ["RGAT.RGAT.embed", "RGAT.RGAT.embed", "RGAT.RGAT.dropout", "RGAT.RGAT.dropout", "RGAT.RGAT.highway", "RGAT.RGAT.highway", "RGAT.RGAT.text_bilstm", "RGAT.RGAT.aspect_bilstm", "aspect_feature.mean.mean.mean", "RGAT.RGAT.dep_embed", "RGAT.RGAT.highway_dep", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dep_out.mean.mean.mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "RGAT.RGAT.dropout", "RGAT.RGAT.fcs", "RGAT.RGAT.fc_final", "sentence.long", "aspect.long", "dep_tags.long", "g().unsqueeze", "RGAT.RGAT.gat", "fmask.unsqueeze.unsqueeze.unsqueeze", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gat_out.mean.mean.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "g().unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "g", "g"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sentence", ",", "aspect", ",", "dep_tags", ")", ":", "\n", "        ", "sentence", ",", "aspect", ",", "dep_tags", "=", "sentence", ".", "long", "(", ")", ",", "aspect", ".", "long", "(", ")", ",", "dep_tags", ".", "long", "(", ")", "\n", "fmask", "=", "(", "torch", ".", "zeros_like", "(", "sentence", ")", "!=", "sentence", ")", ".", "float", "(", ")", "# (N\ufffd\ufffdL)", "\n", "dmask", "=", "(", "torch", ".", "zeros_like", "(", "dep_tags", ")", "!=", "dep_tags", ")", ".", "float", "(", ")", "# (N ,L)", "\n", "\n", "feature", "=", "self", ".", "embed", "(", "sentence", ")", "# (N, L, D)", "\n", "aspect_feature", "=", "self", ".", "embed", "(", "aspect", ")", "# (N, L', D)", "\n", "feature", "=", "self", ".", "dropout", "(", "feature", ")", "\n", "aspect_feature", "=", "self", ".", "dropout", "(", "aspect_feature", ")", "\n", "\n", "feature", "=", "self", ".", "highway", "(", "feature", ")", "\n", "aspect_feature", "=", "self", ".", "highway", "(", "aspect_feature", ")", "\n", "\n", "feature", ",", "_", "=", "self", ".", "text_bilstm", "(", "feature", ")", "# (N,L,D)", "\n", "aspect_feature", ",", "_", "=", "self", ".", "aspect_bilstm", "(", "aspect_feature", ")", "#(N,L,D)", "\n", "\n", "aspect_feature", "=", "aspect_feature", ".", "mean", "(", "dim", "=", "1", ")", "# (N, D)", "\n", "\n", "############################################################################################", "\n", "# do gat thing", "\n", "dep_feature", "=", "self", ".", "dep_embed", "(", "dep_tags", ")", "\n", "dep_feature", "=", "self", ".", "highway_dep", "(", "dep_feature", ")", "\n", "\n", "dep_out", "=", "[", "g", "(", "feature", ",", "dep_feature", ",", "fmask", ")", ".", "unsqueeze", "(", "1", ")", "for", "g", "in", "self", ".", "gat_dep", "]", "# (N, 1, D) * num_heads", "\n", "dep_out", "=", "torch", ".", "cat", "(", "dep_out", ",", "dim", "=", "1", ")", "# (N, H, D)", "\n", "dep_out", "=", "dep_out", ".", "mean", "(", "dim", "=", "1", ")", "# (N, D)", "\n", "\n", "if", "self", ".", "gat_attention_type", "==", "'gcn'", ":", "\n", "            ", "gat_out", "=", "self", ".", "gat", "(", "feature", ")", "# (N, L, D)", "\n", "fmask", "=", "fmask", ".", "unsqueeze", "(", "2", ")", "\n", "gat_out", "=", "gat_out", "*", "fmask", "\n", "gat_out", "=", "F", ".", "relu", "(", "torch", ".", "sum", "(", "gat_out", ",", "dim", "=", "1", ")", ")", "# (N, D)", "\n", "\n", "", "else", ":", "\n", "            ", "gat_out", "=", "[", "g", "(", "feature", ",", "aspect_feature", ",", "fmask", ")", ".", "unsqueeze", "(", "1", ")", "for", "g", "in", "self", ".", "gat", "]", "\n", "gat_out", "=", "torch", ".", "cat", "(", "gat_out", ",", "dim", "=", "1", ")", "\n", "gat_out", "=", "gat_out", ".", "mean", "(", "dim", "=", "1", ")", "\n", "\n", "", "feature_out", "=", "torch", ".", "cat", "(", "[", "dep_out", ",", "gat_out", "]", ",", "dim", "=", "1", ")", "# (N, D')", "\n", "# feature_out = gat_out", "\n", "#############################################################################################", "\n", "x", "=", "self", ".", "dropout", "(", "feature_out", ")", "\n", "x", "=", "self", ".", "fcs", "(", "x", ")", "\n", "logit", "=", "self", ".", "fc_final", "(", "x", ")", "\n", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.RGAT.GAT.__init__": [[115, 162], ["torch.Module.__init__", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.Dropout", "torch.Dropout", "torch.Tanh", "torch.Tanh", "model.rgat_file.model_utils.Highway", "torch.LSTM", "torch.LSTM", "range", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float().cuda", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "model.rgat_file.model_utils.LinearAttention().cuda", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "range", "model.rgat_file.model_utils.DotprodAttention().cuda", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "model.rgat_file.model_utils.LinearAttention", "range", "model.rgat_file.model_utils.DotprodAttention", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "dep_tag_num", ")", ":", "\n", "        ", "super", "(", "GAT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "embedding_dim", "=", "300", "\n", "num_layer", "=", "2", "\n", "hidden_sizes", "=", "300", "\n", "num_heads", "=", "7", "\n", "final_hidden_size", "=", "300", "\n", "num_classes", "=", "3", "\n", "dropout", "=", "0.8", "\n", "highway", "=", "True", "\n", "self", ".", "gat_attention_type", "=", "'dotprod'", "\n", "num_mlps", "=", "2", "\n", "num_embeddings", ",", "embed_dim", "=", "args", ".", "embeddings", ".", "shape", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "embed", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "from_numpy", "(", "args", ".", "embeddings", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", ",", "freeze", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "from_numpy", "(", "args", ".", "embeddings", ")", ".", "float", "(", ")", ",", "freeze", "=", "False", ")", "\n", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "self", ".", "highway", "=", "Highway", "(", "num_layer", ",", "embedding_dim", ")", "\n", "\n", "self", ".", "bilstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "embedding_dim", ",", "hidden_size", "=", "hidden_sizes", ",", "\n", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ",", "num_layers", "=", "num_layer", ")", "\n", "gcn_input_dim", "=", "hidden_sizes", "*", "2", "\n", "\n", "# if args.gat:", "\n", "if", "self", ".", "gat_attention_type", "==", "'linear'", ":", "\n", "            ", "self", ".", "gat", "=", "[", "LinearAttention", "(", "in_dim", "=", "gcn_input_dim", ",", "mem_dim", "=", "gcn_input_dim", ")", ".", "cuda", "(", ")", "for", "i", "in", "range", "(", "num_heads", ")", "]", "# we prefer to keep the dimension unchanged", "\n", "", "elif", "self", ".", "gat_attention_type", "==", "'dotprod'", ":", "\n", "            ", "self", ".", "gat", "=", "[", "DotprodAttention", "(", ")", ".", "cuda", "(", ")", "for", "i", "in", "range", "(", "num_heads", ")", "]", "\n", "", "else", ":", "\n", "# reshaped gcn", "\n", "            ", "self", ".", "gat", "=", "nn", ".", "Linear", "(", "gcn_input_dim", ",", "gcn_input_dim", ")", "\n", "\n", "\n", "", "last_hidden_size", "=", "hidden_sizes", "*", "2", "\n", "\n", "layers", "=", "[", "\n", "nn", ".", "Linear", "(", "last_hidden_size", ",", "final_hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "]", "\n", "for", "_", "in", "range", "(", "num_mlps", "-", "1", ")", ":", "\n", "            ", "layers", "+=", "[", "nn", ".", "Linear", "(", "final_hidden_size", ",", "\n", "final_hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "]", "\n", "", "self", ".", "fcs", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "fc_final", "=", "nn", ".", "Linear", "(", "final_hidden_size", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.RGAT.GAT.forward": [[163, 201], ["RGAT.GAT.embed", "RGAT.GAT.embed", "RGAT.GAT.dropout", "RGAT.GAT.dropout", "RGAT.GAT.highway", "RGAT.GAT.highway", "RGAT.GAT.bilstm", "RGAT.GAT.bilstm", "aspect_feature.mean.mean.mean", "RGAT.GAT.dropout", "RGAT.GAT.fcs", "RGAT.GAT.fc_final", "RGAT.GAT.gat", "fmask.unsqueeze.unsqueeze.unsqueeze", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gat_out.mean.mean.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "g().unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "g"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sentence", ",", "aspect", ",", "dep_tags", ")", ":", "\n", "        ", "fmask", "=", "(", "torch", ".", "zeros_like", "(", "sentence", ")", "!=", "sentence", ")", ".", "float", "(", ")", "\n", "dmask", "=", "(", "torch", ".", "zeros_like", "(", "dep_tags", ")", "!=", "dep_tags", ")", ".", "float", "(", ")", "\n", "\n", "feature", "=", "self", ".", "embed", "(", "sentence", ")", "# (N, L, D)", "\n", "aspect_feature", "=", "self", ".", "embed", "(", "aspect", ")", "# (N, L', D)", "\n", "feature", "=", "self", ".", "dropout", "(", "feature", ")", "\n", "aspect_feature", "=", "self", ".", "dropout", "(", "aspect_feature", ")", "\n", "\n", "\n", "feature", "=", "self", ".", "highway", "(", "feature", ")", "\n", "aspect_feature", "=", "self", ".", "highway", "(", "aspect_feature", ")", "\n", "\n", "feature", ",", "_", "=", "self", ".", "bilstm", "(", "feature", ")", "# (N,L,D)", "\n", "aspect_feature", ",", "_", "=", "self", ".", "bilstm", "(", "aspect_feature", ")", "#(N,L,D)", "\n", "\n", "aspect_feature", "=", "aspect_feature", ".", "mean", "(", "dim", "=", "1", ")", "# (N, D)", "\n", "\n", "############################################################################################", "\n", "\n", "if", "self", ".", "gat_attention_type", "==", "'gcn'", ":", "\n", "            ", "gat_out", "=", "self", ".", "gat", "(", "feature", ")", "# (N, L, D)", "\n", "fmask", "=", "fmask", ".", "unsqueeze", "(", "2", ")", "\n", "gat_out", "=", "gat_out", "*", "fmask", "\n", "gat_out", "=", "F", ".", "relu", "(", "torch", ".", "sum", "(", "gat_out", ",", "dim", "=", "1", ")", ")", "# (N, D)", "\n", "\n", "", "else", ":", "\n", "            ", "gat_out", "=", "[", "g", "(", "feature", ",", "aspect_feature", ",", "fmask", ")", ".", "unsqueeze", "(", "1", ")", "for", "g", "in", "self", ".", "gat", "]", "\n", "gat_out", "=", "torch", ".", "cat", "(", "gat_out", ",", "dim", "=", "1", ")", "\n", "gat_out", "=", "gat_out", ".", "mean", "(", "dim", "=", "1", ")", "\n", "\n", "", "feature_out", "=", "gat_out", "# (N, D')", "\n", "# feature_out = gat_out", "\n", "#############################################################################################", "\n", "x", "=", "self", ".", "dropout", "(", "feature_out", ")", "\n", "x", "=", "self", ".", "fcs", "(", "x", ")", "\n", "logit", "=", "self", ".", "fc_final", "(", "x", ")", "\n", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.model.RGAT.rnn_zero_state": [[202, 210], ["Variable", "torch.zeros", "torch.zeros", "Variable.cuda", "Variable.cuda"], "function", ["None"], ["", "", "def", "rnn_zero_state", "(", "batch_size", ",", "hidden_dim", ",", "num_layers", ",", "bidirectional", "=", "True", ",", "use_cuda", "=", "True", ")", ":", "\n", "    ", "total_layers", "=", "num_layers", "*", "2", "if", "bidirectional", "else", "num_layers", "\n", "state_shape", "=", "(", "total_layers", ",", "batch_size", ",", "hidden_dim", ")", "\n", "h0", "=", "c0", "=", "Variable", "(", "torch", ".", "zeros", "(", "*", "state_shape", ")", ",", "requires_grad", "=", "False", ")", "\n", "if", "use_cuda", ":", "\n", "        ", "return", "h0", ".", "cuda", "(", ")", ",", "c0", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "h0", ",", "c0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.RelationAttention.__init__": [[10, 17], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", "=", "300", ",", "hidden_dim", "=", "64", ")", ":", "\n", "# in_dim: the dimension fo query vector", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "in_dim", ",", "hidden_dim", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.RelationAttention.forward": [[18, 35], ["model_utils.RelationAttention.fc1", "model_utils.RelationAttention.relu", "model_utils.RelationAttention.fc2", "Q.unsqueeze.unsqueeze.squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "Q.unsqueeze.unsqueeze.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "out.squeeze.squeeze.squeeze", "model_utils.mask_logits", "feature.transpose"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.mask_logits"], ["", "def", "forward", "(", "self", ",", "feature", ",", "dep_tags_v", ",", "dmask", ")", ":", "\n", "        ", "'''\n        C feature/context [N, L, D]\n        Q dep_tags_v          [N, L, D]\n        mask dmask          [N, L]\n        '''", "\n", "Q", "=", "self", ".", "fc1", "(", "dep_tags_v", ")", "\n", "Q", "=", "self", ".", "relu", "(", "Q", ")", "\n", "Q", "=", "self", ".", "fc2", "(", "Q", ")", "# (N, L, 1)", "\n", "Q", "=", "Q", ".", "squeeze", "(", "2", ")", "\n", "Q", "=", "F", ".", "softmax", "(", "mask_logits", "(", "Q", ",", "dmask", ")", ",", "dim", "=", "1", ")", "\n", "\n", "Q", "=", "Q", ".", "unsqueeze", "(", "2", ")", "\n", "out", "=", "torch", ".", "bmm", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ",", "Q", ")", "\n", "out", "=", "out", ".", "squeeze", "(", "2", ")", "\n", "# out = F.sigmoid(out)", "\n", "return", "out", "# ([N, L])", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.LinearAttention.__init__": [[41, 47], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["def", "__init__", "(", "self", ",", "in_dim", "=", "300", ",", "mem_dim", "=", "300", ")", ":", "\n", "# in dim, the dimension of query vector", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "in_dim", ",", "mem_dim", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "mem_dim", "*", "2", ",", "1", ")", "\n", "self", ".", "leakyrelu", "=", "nn", ".", "LeakyReLU", "(", "1e-2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.LinearAttention.forward": [[48, 73], ["model_utils.LinearAttention.linear", "model_utils.LinearAttention.unsqueeze", "model_utils.LinearAttention.expand_as", "model_utils.LinearAttention.linear", "model_utils.LinearAttention.linear", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_utils.LinearAttention.fc", "dmask.unsqueeze.unsqueeze.unsqueeze", "model_utils.mask_logits", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "out.squeeze.squeeze.squeeze", "model_utils.LinearAttention.transpose"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.mask_logits"], ["", "def", "forward", "(", "self", ",", "feature", ",", "aspect_v", ",", "dmask", ")", ":", "\n", "        ", "'''\n        C feature/context [N, L, D]\n        Q dep_tags_v          [N, D]\n        mask dmask          [N, L]\n        '''", "\n", "\n", "Q", "=", "self", ".", "linear", "(", "aspect_v", ")", "# (N, D)", "\n", "Q", "=", "Q", ".", "unsqueeze", "(", "1", ")", "# (N, 1, D)", "\n", "Q", "=", "Q", ".", "expand_as", "(", "feature", ")", "# (N, L, D)", "\n", "Q", "=", "self", ".", "linear", "(", "Q", ")", "# (N, L, D)", "\n", "feature", "=", "self", ".", "linear", "(", "feature", ")", "# (N, L, D)", "\n", "\n", "att_feature", "=", "torch", ".", "cat", "(", "[", "feature", ",", "Q", "]", ",", "dim", "=", "2", ")", "# (N, L, 2D)", "\n", "att_weight", "=", "self", ".", "fc", "(", "att_feature", ")", "# (N, L, 1)", "\n", "dmask", "=", "dmask", ".", "unsqueeze", "(", "2", ")", "# (N, L, 1)", "\n", "att_weight", "=", "mask_logits", "(", "att_weight", ",", "dmask", ")", "# (N, L ,1)", "\n", "\n", "attention", "=", "F", ".", "softmax", "(", "att_weight", ",", "dim", "=", "1", ")", "# (N, L, 1)", "\n", "\n", "out", "=", "torch", ".", "bmm", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ",", "attention", ")", "# (N, D, 1)", "\n", "out", "=", "out", ".", "squeeze", "(", "2", ")", "\n", "# out = F.sigmoid(out)", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.DotprodAttention.__init__": [[76, 78], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.DotprodAttention.forward": [[79, 98], ["Q.unsqueeze.unsqueeze.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "dmask.unsqueeze.unsqueeze.unsqueeze", "model_utils.mask_logits", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "out.squeeze.squeeze.squeeze", "feature.transpose"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.mask_logits"], ["", "def", "forward", "(", "self", ",", "feature", ",", "aspect_v", ",", "dmask", ")", ":", "\n", "        ", "'''\n        C feature/context [N, L, D]\n        Q dep_tags_v          [N, D]\n        mask dmask          [N, L]\n        '''", "\n", "\n", "Q", "=", "aspect_v", "\n", "Q", "=", "Q", ".", "unsqueeze", "(", "2", ")", "# (N, D, 1)", "\n", "dot_prod", "=", "torch", ".", "bmm", "(", "feature", ",", "Q", ")", "# (N, L, 1)", "\n", "dmask", "=", "dmask", ".", "unsqueeze", "(", "2", ")", "# (N, D, 1)", "\n", "attention_weight", "=", "mask_logits", "(", "dot_prod", ",", "dmask", ")", "# (N, L ,1)", "\n", "attention", "=", "F", ".", "softmax", "(", "attention_weight", ",", "dim", "=", "1", ")", "# (N, L, 1)", "\n", "\n", "out", "=", "torch", ".", "bmm", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ",", "attention", ")", "# (N, D, 1)", "\n", "out", "=", "out", ".", "squeeze", "(", "2", ")", "\n", "# out = F.sigmoid(out)", "\n", "# (N, D), ([N, L]), (N, L, 1)", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.Highway.__init__": [[100, 107], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "range", "range"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layer_num", ",", "dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_num", "=", "layer_num", "\n", "self", ".", "linear", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "for", "_", "in", "range", "(", "layer_num", ")", "]", ")", "\n", "self", ".", "gate", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "for", "_", "in", "range", "(", "layer_num", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.Highway.forward": [[108, 114], ["range", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.relu", "torch.relu", "torch.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "layer_num", ")", ":", "\n", "            ", "gate", "=", "F", ".", "sigmoid", "(", "self", ".", "gate", "[", "i", "]", "(", "x", ")", ")", "\n", "nonlinear", "=", "F", ".", "relu", "(", "self", ".", "linear", "[", "i", "]", "(", "x", ")", ")", "\n", "x", "=", "gate", "*", "nonlinear", "+", "(", "1", "-", "gate", ")", "*", "x", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.DepparseMultiHeadAttention.__init__": [[117, 126], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "h", "=", "6", ",", "Co", "=", "300", ",", "cat", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "Co", "//", "h", "\n", "self", ".", "h", "=", "h", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "Co", ",", "Co", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc2s", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "1", ")", "for", "_", "in", "range", "(", "h", ")", "]", ")", "\n", "self", ".", "cat", "=", "cat", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.DepparseMultiHeadAttention.forward": [[127, 154], ["dep_tags_v.size", "model_utils.DepparseMultiHeadAttention.fc1().view", "model_utils.DepparseMultiHeadAttention.relu", "Q.transpose.transpose.transpose", "l().squeeze().transpose", "torch.softmax().unsqueeze", "torch.softmax().unsqueeze", "torch.softmax().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model_utils.DepparseMultiHeadAttention.fc1", "zip", "l().squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "model_utils.mask_logits", "l", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "feature.transpose", "feature.transpose"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.mask_logits"], ["", "def", "forward", "(", "self", ",", "feature", ",", "dep_tags_v", ",", "dmask", ")", ":", "\n", "        ", "'''\n        C feature/context [N, L, D]\n        Q dep_tags_v          [N, L, D]\n        mask dmask          [N, L]\n        '''", "\n", "nbatches", "=", "dep_tags_v", ".", "size", "(", "0", ")", "\n", "Q", "=", "self", ".", "fc1", "(", "dep_tags_v", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", ",", "\n", "self", ".", "hidden_size", ")", "# [N, L, #heads, hidden_size]", "\n", "Q", "=", "self", ".", "relu", "(", "Q", ")", "\n", "Q", "=", "Q", ".", "transpose", "(", "0", ",", "2", ")", "# [#heads, L, N, hidden_size]", "\n", "Q", "=", "[", "l", "(", "q", ")", ".", "squeeze", "(", "2", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "for", "l", ",", "q", "in", "zip", "(", "self", ".", "fc2s", ",", "Q", ")", "]", "# [N, L] * #heads", "\n", "# Q = Q.squeeze(2)", "\n", "Q", "=", "[", "F", ".", "softmax", "(", "mask_logits", "(", "q", ",", "dmask", ")", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "for", "q", "in", "Q", "]", "# [N, L, 1] * #heads", "\n", "\n", "# Q = Q.unsqueeze(2)", "\n", "if", "self", ".", "cat", ":", "\n", "            ", "out", "=", "torch", ".", "cat", "(", "\n", "[", "torch", ".", "bmm", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ",", "q", ")", ".", "squeeze", "(", "2", ")", "for", "q", "in", "Q", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "bmm", "(", "feature", ".", "transpose", "(", "1", ",", "2", ")", ",", "q", ")", ".", "squeeze", "(", "2", ")", "for", "q", "in", "Q", "]", ",", "dim", "=", "2", ")", "\n", "out", "=", "torch", ".", "sum", "(", "out", ",", "dim", "=", "2", ")", "\n", "# out = out.squeeze(2)", "\n", "", "return", "out", ",", "Q", "[", "0", "]", "# ([N, L]) one head", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.model_utils.mask_logits": [[6, 8], ["None"], "function", ["None"], ["def", "mask_logits", "(", "target", ",", "mask", ")", ":", "\n", "    ", "return", "target", "*", "mask", "+", "(", "1", "-", "mask", ")", "*", "(", "-", "1e30", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.WhitespaceTokenizer.__init__": [[9, 11], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vocab", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.WhitespaceTokenizer.__call__": [[12, 16], ["text.split", "spacy.tokens.Doc", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "text", ")", ":", "\n", "        ", "words", "=", "text", ".", "split", "(", ")", "\n", "spaces", "=", "[", "True", "]", "*", "len", "(", "words", ")", "\n", "return", "Doc", "(", "self", ".", "vocab", ",", "words", "=", "words", ",", "spaces", "=", "spaces", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.Tree.__init__": [[22, 46], ["isinstance", "enumerate", "read_dep_graph.Tree", "read_dep_graph.Tree.children.append", "child.getValue"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.Tree.getValue"], ["    ", "def", "__init__", "(", "self", ",", "value", ",", "parent", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "list", ")", ":", "\n", "            ", "self", ".", "value", "=", "0", "\n", "self", ".", "parent", "=", "None", "\n", "self", ".", "children", "=", "[", "]", "\n", "# \u83b7\u53d6\u5217\u8868\u91cc\u6bcf\u4e2a\u8def\u5f84", "\n", "for", "path", "in", "value", ":", "\n", "# \u6784\u5efa\u7236\u7ed3\u70b9\u548c\u5b69\u5b50\u7ed3\u70b9", "\n", "                ", "parent", "=", "self", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "path", ")", ":", "\n", "                    ", "node", "=", "None", "\n", "for", "child", "in", "parent", ".", "children", ":", "\n", "                        ", "if", "v", "==", "child", ".", "getValue", "(", ")", ":", "\n", "                            ", "node", "=", "child", "\n", "break", "\n", "", "", "if", "node", "==", "None", ":", "\n", "                        ", "node", "=", "Tree", "(", "v", ",", "parent", ")", "\n", "parent", ".", "children", ".", "append", "(", "node", ")", "\n", "", "parent", "=", "node", "\n", "", "", "", "else", ":", "\n", "# \u8be5\u903b\u8f91\u4e00\u822c\u53ea\u7531\u6b64\u6784\u9020\u5668\u6267\u884c\uff0c\u800c\u4e0d\u7531\u5916\u90e8\u521b\u5efa\u5bf9\u8c61\u65f6\u76f4\u63a5\u6267\u884c", "\n", "            ", "self", ".", "value", "=", "value", "\n", "self", ".", "parent", "=", "parent", "\n", "self", ".", "children", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.Tree.getValue": [[47, 50], ["None"], "methods", ["None"], ["", "", "def", "getValue", "(", "self", ")", ":", "\n", "        ", "\"\"\"\u83b7\u53d6\u7ed3\u70b9\u503c\"\"\"", "\n", "return", "self", ".", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.Tree.getChildren": [[51, 54], ["None"], "methods", ["None"], ["", "def", "getChildren", "(", "self", ")", ":", "\n", "        ", "\"\"\"\u83b7\u53d6\u5b69\u5b50\u7ed3\u70b9\"\"\"", "\n", "return", "self", ".", "children", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.Tree.getParent": [[55, 58], ["None"], "methods", ["None"], ["", "def", "getParent", "(", "self", ")", ":", "\n", "        ", "\"\"\"\u83b7\u53d6\u7236\u7ed3\u70b9\"\"\"", "\n", "return", "self", ".", "parent", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.get_senticnet_tree": [[59, 73], ["model.rgat_file.senticnet5.senticnet.items", "read_dep_graph.Tree", "print", "value.append", "enumerate", "values.append", "value.append", "value.append", "j.replace"], "function", ["None"], ["", "", "def", "get_senticnet_tree", "(", ")", ":", "\n", "    ", "values", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "senticnet", ".", "items", "(", ")", ":", "\n", "        ", "value", "=", "[", "]", "\n", "value", ".", "append", "(", "k", ")", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "v", ")", ":", "\n", "            ", "if", "'#'", "in", "j", ":", "\n", "                ", "value", ".", "append", "(", "j", ".", "replace", "(", "'#'", ",", "''", ")", ")", "\n", "", "if", "i", ">=", "8", ":", "\n", "                ", "value", ".", "append", "(", "j", ")", "\n", "", "", "values", ".", "append", "(", "value", ")", "\n", "", "get_senticnet_tree", "=", "Tree", "(", "value", "=", "values", "[", ":", "2", "]", ",", "parent", "=", "'a_little'", ")", "\n", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.dependency_adj_matrix": [[76, 88], ["nlp", "text.split", "numpy.zeros().astype", "len", "len", "numpy.zeros", "list", "len", "len"], "function", ["None"], ["", "def", "dependency_adj_matrix", "(", "text", ")", ":", "\n", "    ", "tokens", "=", "nlp", "(", "text", ")", "\n", "words", "=", "text", ".", "split", "(", ")", "\n", "matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "words", ")", ",", "len", "(", "words", ")", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "assert", "len", "(", "words", ")", "==", "len", "(", "list", "(", "tokens", ")", ")", "\n", "\n", "for", "token", "in", "tokens", ":", "\n", "        ", "matrix", "[", "token", ".", "i", "]", "[", "token", ".", "i", "]", "=", "1", "\n", "for", "child", "in", "token", ".", "children", ":", "\n", "            ", "matrix", "[", "token", ".", "i", "]", "[", "child", ".", "i", "]", "=", "1", "\n", "matrix", "[", "child", ".", "i", "]", "[", "token", ".", "i", "]", "=", "1", "\n", "", "", "return", "matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.knowledge_adj_matrix": [[110, 136], ["nlp", "text.split", "len", "numpy.zeros().astype", "len", "len", "list", "numpy.zeros", "[].replace", "[].replace", "tags.keys", "tags.keys", "[].replace", "[].replace", "len", "len", "len", "len", "tags.keys", "tags.keys"], "function", ["None"], ["", "def", "knowledge_adj_matrix", "(", "text", ")", ":", "\n", "    ", "tokens", "=", "nlp", "(", "text", ")", "\n", "words", "=", "text", ".", "split", "(", ")", "\n", "assert", "len", "(", "words", ")", "==", "len", "(", "list", "(", "tokens", ")", ")", "\n", "tags", "=", "{", "}", "\n", "num", "=", "len", "(", "words", ")", "\n", "for", "token", "in", "tokens", ":", "\n", "        ", "try", ":", "\n", "            ", "for", "sem", "in", "senticnet", "[", "token", ".", "text", "]", "[", "8", ":", "]", ":", "\n", "                ", "if", "sem", "not", "in", "tags", ".", "keys", "(", ")", ":", "\n", "                    ", "tags", "[", "sem", "]", "=", "num", "\n", "num", "+=", "1", "\n", "", "", "for", "mod", "in", "[", "senticnet", "[", "token", ".", "text", "]", "[", "4", "]", ".", "replace", "(", "'#'", ",", "''", ")", ",", "senticnet", "[", "token", ".", "text", "]", "[", "5", "]", ".", "replace", "(", "'#'", ",", "''", ")", "]", ":", "\n", "                ", "if", "mod", "not", "in", "tags", ".", "keys", "(", ")", ":", "\n", "                    ", "tags", "[", "mod", "]", "=", "num", "\n", "num", "+=", "1", "\n", "", "", "tag", "=", "senticnet", "[", "token", ".", "text", "]", "[", "8", ":", "]", "+", "[", "senticnet", "[", "token", ".", "text", "]", "[", "4", "]", ".", "replace", "(", "'#'", ",", "''", ")", ",", "senticnet", "[", "token", ".", "text", "]", "[", "5", "]", ".", "replace", "(", "'#'", ",", "''", ")", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "continue", "\n", "", "", "matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "words", ")", "+", "len", "(", "tags", ".", "keys", "(", ")", ")", ",", "len", "(", "words", ")", "+", "len", "(", "tags", ".", "keys", "(", ")", ")", ")", ")", ".", "astype", "(", "'float32'", ")", "\n", "for", "token", "in", "tokens", ":", "\n", "        ", "matrix", "[", "token", ".", "i", "]", "[", "token", ".", "i", "]", "=", "1", "\n", "for", "t", "in", "tag", ":", "\n", "            ", "matrix", "[", "token", ".", "i", "]", "[", "tags", "[", "t", "]", "]", "=", "1", "\n", "matrix", "[", "tags", "[", "t", "]", "]", "[", "token", ".", "i", "]", "=", "1", "\n", "", "", "return", "matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.process_graph": [[137, 141], ["read_dep_graph.dependency_adj_matrix"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_dep_graph.dependency_adj_matrix"], ["", "def", "process_graph", "(", "text", ")", ":", "\n", "    ", "syntactic_adj_matrix", "=", "dependency_adj_matrix", "(", "text", ")", "\n", "# common_adj_matrix = knowledge_adj_matrix(text)", "\n", "return", "syntactic_adj_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.read_sentence_depparsed": [[6, 10], ["open", "json.load"], "function", ["None"], ["def", "read_sentence_depparsed", "(", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.get_dataset": [[11, 27], ["list", "list", "read_rgat_data.read_sentence_depparsed", "read_rgat_data.read_sentence_depparsed"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.read_sentence_depparsed", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.read_sentence_depparsed"], ["", "", "def", "get_dataset", "(", "dataset_name", ")", ":", "\n", "    ", "rest_train", "=", "'./rgat_data/semeval14/Restaurants_Train_v2_biaffine_depparsed_with_energy.json'", "\n", "rest_test", "=", "'./rgat_data/semeval14/Restaurants_Test_Gold_biaffine_depparsed_with_energy.json'", "\n", "\n", "laptop_train", "=", "'./rgat_data/semeval14/Laptop_Train_v2_biaffine_depparsed.json'", "\n", "laptop_test", "=", "'./rgat_data/semeval14/Laptops_Test_Gold_biaffine_depparsed.json'", "\n", "\n", "twitter_train", "=", "'./rgat_data/twitter/train_biaffine.json'", "\n", "twitter_test", "=", "'./rgat_data/twitter/test_biaffine.json'", "\n", "ds_train", "=", "{", "'14semeval_rest'", ":", "rest_train", ",", "\n", "'14semeval_laptop'", ":", "laptop_train", ",", "'Twitter'", ":", "twitter_train", "}", "\n", "ds_test", "=", "{", "'14semeval_rest'", ":", "rest_test", ",", "\n", "'14semeval_laptop'", ":", "laptop_test", ",", "'Twitter'", ":", "twitter_test", "}", "\n", "train", "=", "list", "(", "read_sentence_depparsed", "(", "ds_train", "[", "dataset_name", "]", ")", ")", "\n", "test", "=", "list", "(", "read_sentence_depparsed", "(", "ds_test", "[", "dataset_name", "]", ")", ")", "\n", "return", "train", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.get_rolled_and_unrolled_data": [[28, 137], ["collections.defaultdict", "collections.defaultdict", "range", "all_rolled.append", "x.lower", "len", "[].lower", "nltk.word_tokenize", "aspects.append", "sentiments.append", "froms.append", "tos.append", "read_rgat_data.reshape_dependency_tree_new", "dep_tags.append", "dep_index.append", "dep_dirs.append", "all_unrolled.append", "len", "mixed_rolled.append", "enumerate", "len", "[].split", "e[].index", "print", "read_rgat_data.reshape_dependency_tree_new", "len", "mixed_unrolled.append", "e[].index", "len", "print", "print", "set", "len", "map"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.reshape_dependency_tree_new", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.reshape_dependency_tree_new"], ["", "def", "get_rolled_and_unrolled_data", "(", "input_data", ",", "multi_hop", ",", "add_non_connect", ",", "max_hop", ")", ":", "\n", "\n", "# A hand-picked set of part of speech tags that we see contributes to ABSA.", "\n", "    ", "opinionated_tags", "=", "[", "'JJ'", ",", "'JJR'", ",", "'JJS'", ",", "'RB'", ",", "'RBR'", ",", "\n", "'RBS'", ",", "'VB'", ",", "'VBD'", ",", "'VBG'", ",", "'VBN'", ",", "'VBP'", ",", "'VBZ'", "]", "\n", "\n", "all_rolled", "=", "[", "]", "\n", "all_unrolled", "=", "[", "]", "\n", "mixed_rolled", "=", "[", "]", "\n", "mixed_unrolled", "=", "[", "]", "\n", "\n", "unrolled", "=", "[", "]", "\n", "mixed", "=", "[", "]", "\n", "unrolled_ours", "=", "[", "]", "\n", "mixed_ours", "=", "[", "]", "\n", "\n", "# Make sure the tree is successfully built.", "\n", "zero_dep_counter", "=", "0", "\n", "\n", "# Sentiment counters", "\n", "total_counter", "=", "defaultdict", "(", "int", ")", "\n", "mixed_counter", "=", "defaultdict", "(", "int", ")", "\n", "sentiments_lookup", "=", "{", "'negative'", ":", "0", ",", "'positive'", ":", "1", ",", "'neutral'", ":", "2", "}", "\n", "\n", "tree_samples", "=", "[", "]", "\n", "# for seeking 'but' examples", "\n", "for", "e", "in", "input_data", ":", "\n", "        ", "e", "[", "'tokens'", "]", "=", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "e", "[", "'tokens'", "]", "]", "\n", "aspects", "=", "[", "]", "\n", "sentiments", "=", "[", "]", "\n", "froms", "=", "[", "]", "\n", "tos", "=", "[", "]", "\n", "dep_tags", "=", "[", "]", "\n", "dep_index", "=", "[", "]", "\n", "dep_dirs", "=", "[", "]", "\n", "\n", "# Classify based on POS-tags", "\n", "\n", "pos_class", "=", "e", "[", "'tags'", "]", "\n", "\n", "# Iterate through aspects in a sentence and reshape the dependency tree.", "\n", "for", "i", "in", "range", "(", "len", "(", "e", "[", "'aspect_sentiment'", "]", ")", ")", ":", "\n", "            ", "aspect", "=", "e", "[", "'aspect_sentiment'", "]", "[", "i", "]", "[", "0", "]", ".", "lower", "(", ")", "\n", "# We would tokenize the aspect while at it.", "\n", "aspect", "=", "word_tokenize", "(", "aspect", ")", "\n", "sentiment", "=", "sentiments_lookup", "[", "e", "[", "'aspect_sentiment'", "]", "[", "i", "]", "[", "1", "]", "]", "\n", "frm", "=", "e", "[", "'from_to'", "]", "[", "i", "]", "[", "0", "]", "\n", "to", "=", "e", "[", "'from_to'", "]", "[", "i", "]", "[", "1", "]", "\n", "\n", "aspects", ".", "append", "(", "aspect", ")", "\n", "sentiments", ".", "append", "(", "sentiment", ")", "\n", "froms", ".", "append", "(", "frm", ")", "\n", "tos", ".", "append", "(", "to", ")", "\n", "\n", "# Center on the aspect.", "\n", "dep_tag", ",", "dep_idx", ",", "dep_dir", "=", "reshape_dependency_tree_new", "(", "frm", ",", "to", ",", "e", "[", "'dependencies'", "]", ",", "\n", "multi_hop", "=", "multi_hop", ",", "add_non_connect", "=", "add_non_connect", ",", "tokens", "=", "e", "[", "'tokens'", "]", ",", "max_hop", "=", "max_hop", ")", "\n", "\n", "# Because of tokenizer differences, aspect opsitions are off, so we find the index and try again.", "\n", "if", "len", "(", "dep_tag", ")", "==", "0", ":", "\n", "                ", "zero_dep_counter", "+=", "1", "\n", "as_sent", "=", "e", "[", "'aspect_sentiment'", "]", "[", "i", "]", "[", "0", "]", ".", "split", "(", ")", "\n", "as_start", "=", "e", "[", "'tokens'", "]", ".", "index", "(", "as_sent", "[", "0", "]", ")", "\n", "# print(e['tokens'], e['aspect_sentiment'], e['dependencies'],as_sent[0])", "\n", "as_end", "=", "e", "[", "'tokens'", "]", ".", "index", "(", "\n", "as_sent", "[", "-", "1", "]", ")", "if", "len", "(", "as_sent", ")", ">", "1", "else", "as_start", "+", "1", "\n", "print", "(", "\"Debugging: as_start as_end \"", ",", "as_start", ",", "as_end", ")", "\n", "dep_tag", ",", "dep_idx", ",", "dep_dir", "=", "reshape_dependency_tree_new", "(", "as_start", ",", "as_end", ",", "e", "[", "'dependencies'", "]", ",", "\n", "multi_hop", "=", "multi_hop", ",", "add_non_connect", "=", "add_non_connect", ",", "tokens", "=", "e", "[", "'tokens'", "]", ",", "max_hop", "=", "max_hop", ")", "\n", "if", "len", "(", "dep_tag", ")", "==", "0", ":", "# for debugging", "\n", "                    ", "print", "(", "\"Debugging: zero_dep\"", ",", "\n", "e", "[", "'aspect_sentiment'", "]", "[", "i", "]", "[", "0", "]", ",", "e", "[", "'tokens'", "]", ")", "\n", "print", "(", "\"Debugging: \"", ".", "e", "[", "'dependencies'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "zero_dep_counter", "-=", "1", "\n", "\n", "", "", "dep_tags", ".", "append", "(", "dep_tag", ")", "\n", "dep_index", ".", "append", "(", "dep_idx", ")", "\n", "dep_dirs", ".", "append", "(", "dep_dir", ")", "\n", "\n", "total_counter", "[", "e", "[", "'aspect_sentiment'", "]", "[", "i", "]", "[", "1", "]", "]", "+=", "1", "\n", "\n", "# Unrolling", "\n", "all_unrolled", ".", "append", "(", "\n", "{", "'sentence'", ":", "e", "[", "'tokens'", "]", ",", "'tags'", ":", "e", "[", "'tags'", "]", ",", "'pos_class'", ":", "pos_class", ",", "'aspect'", ":", "aspect", ",", "'sentiment'", ":", "sentiment", ",", "\n", "'predicted_dependencies'", ":", "e", "[", "'predicted_dependencies'", "]", ",", "'predicted_heads'", ":", "e", "[", "'predicted_heads'", "]", ",", "\n", "'from'", ":", "frm", ",", "'to'", ":", "to", ",", "'dep_tag'", ":", "dep_tag", ",", "'dep_idx'", ":", "dep_idx", ",", "'dep_dir'", ":", "dep_dir", ",", "'dependencies'", ":", "e", "[", "'dependencies'", "]", "}", ")", "\n", "\n", "\n", "# All sentences with multiple aspects and sentiments rolled.", "\n", "", "all_rolled", ".", "append", "(", "\n", "{", "'sentence'", ":", "e", "[", "'tokens'", "]", ",", "'tags'", ":", "e", "[", "'tags'", "]", ",", "'pos_class'", ":", "pos_class", ",", "'aspects'", ":", "aspects", ",", "'sentiments'", ":", "sentiments", ",", "\n", "'from'", ":", "froms", ",", "'to'", ":", "tos", ",", "'dep_tags'", ":", "dep_tags", ",", "'dep_index'", ":", "dep_index", ",", "'dependencies'", ":", "e", "[", "'dependencies'", "]", "}", ")", "\n", "\n", "# Ignore sentences with single aspect or no aspect", "\n", "if", "len", "(", "e", "[", "'aspect_sentiment'", "]", ")", "and", "len", "(", "set", "(", "map", "(", "lambda", "x", ":", "x", "[", "1", "]", ",", "e", "[", "'aspect_sentiment'", "]", ")", ")", ")", ">", "1", ":", "\n", "            ", "mixed_rolled", ".", "append", "(", "\n", "{", "'sentence'", ":", "e", "[", "'tokens'", "]", ",", "'tags'", ":", "e", "[", "'tags'", "]", ",", "'pos_class'", ":", "pos_class", ",", "'aspects'", ":", "aspects", ",", "'sentiments'", ":", "sentiments", ",", "\n", "'from'", ":", "froms", ",", "'to'", ":", "tos", ",", "'dep_tags'", ":", "dep_tags", ",", "'dep_index'", ":", "dep_index", ",", "'dependencies'", ":", "e", "[", "'dependencies'", "]", "}", ")", "\n", "\n", "# Unrolling", "\n", "for", "i", ",", "as_sent", "in", "enumerate", "(", "e", "[", "'aspect_sentiment'", "]", ")", ":", "\n", "                ", "mixed_counter", "[", "as_sent", "[", "1", "]", "]", "+=", "1", "\n", "mixed_unrolled", ".", "append", "(", "\n", "{", "'sentence'", ":", "e", "[", "'tokens'", "]", ",", "'tags'", ":", "e", "[", "'tags'", "]", ",", "'pos_class'", ":", "pos_class", ",", "'aspect'", ":", "aspects", "[", "i", "]", ",", "'sentiment'", ":", "sentiments", "[", "i", "]", ",", "\n", "'from'", ":", "froms", "[", "i", "]", ",", "'to'", ":", "tos", "[", "i", "]", ",", "'dep_tag'", ":", "dep_tags", "[", "i", "]", ",", "'dep_idx'", ":", "dep_index", "[", "i", "]", ",", "'dependencies'", ":", "e", "[", "'dependencies'", "]", "}", ")", "\n", "\n", "\n", "", "", "", "return", "all_rolled", ",", "all_unrolled", ",", "mixed_rolled", ",", "mixed_unrolled", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.reshape_dependency_tree_new": [[139, 229], ["range", "enumerate", "enumerate", "len", "len", "copy.deepcopy", "dep_tag.append", "dep_dir.append", "dep_idx.append", "sorted", "len", "len", "dep_tag.append", "dep_dir.append", "dep_idx.append", "enumerate", "dep_idx.append", "str", "dep_tag.append", "dep_dir.append", "dep_tag.append", "dep_dir.append", "dep_idx.append", "str", "dep_tag.append", "dep_dir.append", "dep_tag.append", "dep_dir.append", "dep_idx.append", "str", "dep_tag.append", "dep_dir.append", "dep_tag.append", "dep_dir.append", "dep_idx.append", "str", "dep_tag.append", "dep_dir.append", "dep_tag.append", "dep_dir.append", "str", "str"], "function", ["None"], ["", "def", "reshape_dependency_tree_new", "(", "as_start", ",", "as_end", ",", "dependencies", ",", "multi_hop", "=", "False", ",", "add_non_connect", "=", "False", ",", "tokens", "=", "None", ",", "max_hop", "=", "5", ")", ":", "\n", "    ", "'''\n    Adding multi hops\n    This function is at the core of our algo, it reshape the dependency tree and center on the aspect.\n    In open-sourced edition, I choose not to take energy(the soft prediction of dependency from parser)\n    into consideration. For it requires tweaking allennlp's source code, and the energy is space-consuming.\n    And there are no significant difference in performance between the soft and the hard(with non-connect) version.\n\n    '''", "\n", "dep_tag", "=", "[", "]", "\n", "dep_idx", "=", "[", "]", "\n", "dep_dir", "=", "[", "]", "\n", "# 1 hop", "\n", "\n", "for", "i", "in", "range", "(", "as_start", ",", "as_end", ")", ":", "\n", "        ", "for", "dep", "in", "dependencies", ":", "\n", "            ", "if", "i", "==", "dep", "[", "1", "]", "-", "1", ":", "\n", "# not root, not aspect", "\n", "                ", "if", "(", "dep", "[", "2", "]", "-", "1", "<", "as_start", "or", "dep", "[", "2", "]", "-", "1", ">=", "as_end", ")", "and", "dep", "[", "2", "]", "!=", "0", "and", "dep", "[", "2", "]", "-", "1", "not", "in", "dep_idx", ":", "\n", "                    ", "if", "str", "(", "dep", "[", "0", "]", ")", "!=", "'punct'", ":", "# and tokens[dep[2] - 1] not in stopWords", "\n", "                        ", "dep_tag", ".", "append", "(", "dep", "[", "0", "]", ")", "\n", "dep_dir", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "dep_tag", ".", "append", "(", "'<pad>'", ")", "\n", "dep_dir", ".", "append", "(", "0", ")", "\n", "", "dep_idx", ".", "append", "(", "dep", "[", "2", "]", "-", "1", ")", "\n", "", "", "elif", "i", "==", "dep", "[", "2", "]", "-", "1", ":", "\n", "# not root, not aspect", "\n", "                ", "if", "(", "dep", "[", "1", "]", "-", "1", "<", "as_start", "or", "dep", "[", "1", "]", "-", "1", ">=", "as_end", ")", "and", "dep", "[", "1", "]", "!=", "0", "and", "dep", "[", "1", "]", "-", "1", "not", "in", "dep_idx", ":", "\n", "                    ", "if", "str", "(", "dep", "[", "0", "]", ")", "!=", "'punct'", ":", "# and tokens[dep[1] - 1] not in stopWords", "\n", "                        ", "dep_tag", ".", "append", "(", "dep", "[", "0", "]", ")", "\n", "dep_dir", ".", "append", "(", "2", ")", "\n", "", "else", ":", "\n", "                        ", "dep_tag", ".", "append", "(", "'<pad>'", ")", "\n", "dep_dir", ".", "append", "(", "0", ")", "\n", "", "dep_idx", ".", "append", "(", "dep", "[", "1", "]", "-", "1", ")", "\n", "\n", "", "", "", "", "if", "multi_hop", ":", "\n", "        ", "current_hop", "=", "2", "\n", "added", "=", "True", "\n", "while", "current_hop", "<=", "max_hop", "and", "len", "(", "dep_idx", ")", "<", "len", "(", "tokens", ")", "and", "added", ":", "\n", "            ", "added", "=", "False", "\n", "dep_idx_temp", "=", "deepcopy", "(", "dep_idx", ")", "\n", "for", "i", "in", "dep_idx_temp", ":", "\n", "                ", "for", "dep", "in", "dependencies", ":", "\n", "                    ", "if", "i", "==", "dep", "[", "1", "]", "-", "1", ":", "\n", "# not root, not aspect", "\n", "                        ", "if", "(", "dep", "[", "2", "]", "-", "1", "<", "as_start", "or", "dep", "[", "2", "]", "-", "1", ">=", "as_end", ")", "and", "dep", "[", "2", "]", "!=", "0", "and", "dep", "[", "2", "]", "-", "1", "not", "in", "dep_idx", ":", "\n", "                            ", "if", "str", "(", "dep", "[", "0", "]", ")", "!=", "'punct'", ":", "# and tokens[dep[2] - 1] not in stopWords", "\n", "                                ", "dep_tag", ".", "append", "(", "'ncon_'", "+", "str", "(", "current_hop", ")", ")", "\n", "dep_dir", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                                ", "dep_tag", ".", "append", "(", "'<pad>'", ")", "\n", "dep_dir", ".", "append", "(", "0", ")", "\n", "", "dep_idx", ".", "append", "(", "dep", "[", "2", "]", "-", "1", ")", "\n", "added", "=", "True", "\n", "", "", "elif", "i", "==", "dep", "[", "2", "]", "-", "1", ":", "\n", "# not root, not aspect", "\n", "                        ", "if", "(", "dep", "[", "1", "]", "-", "1", "<", "as_start", "or", "dep", "[", "1", "]", "-", "1", ">=", "as_end", ")", "and", "dep", "[", "1", "]", "!=", "0", "and", "dep", "[", "1", "]", "-", "1", "not", "in", "dep_idx", ":", "\n", "                            ", "if", "str", "(", "dep", "[", "0", "]", ")", "!=", "'punct'", ":", "# and tokens[dep[1] - 1] not in stopWords", "\n", "                                ", "dep_tag", ".", "append", "(", "'ncon_'", "+", "str", "(", "current_hop", ")", ")", "\n", "dep_dir", ".", "append", "(", "2", ")", "\n", "", "else", ":", "\n", "                                ", "dep_tag", ".", "append", "(", "'<pad>'", ")", "\n", "dep_dir", ".", "append", "(", "0", ")", "\n", "", "dep_idx", ".", "append", "(", "dep", "[", "1", "]", "-", "1", ")", "\n", "added", "=", "True", "\n", "", "", "", "", "current_hop", "+=", "1", "\n", "\n", "", "", "if", "add_non_connect", ":", "\n", "        ", "for", "idx", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "            ", "if", "idx", "not", "in", "dep_idx", "and", "(", "idx", "<", "as_start", "or", "idx", ">=", "as_end", ")", ":", "\n", "                ", "dep_tag", ".", "append", "(", "'non-connect'", ")", "\n", "dep_dir", ".", "append", "(", "0", ")", "\n", "dep_idx", ".", "append", "(", "idx", ")", "\n", "\n", "# add aspect and index, to make sure length matches len(tokens)", "\n", "", "", "", "for", "idx", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "if", "idx", "not", "in", "dep_idx", ":", "\n", "            ", "dep_tag", ".", "append", "(", "'<pad>'", ")", "\n", "dep_dir", ".", "append", "(", "0", ")", "\n", "dep_idx", ".", "append", "(", "idx", ")", "\n", "\n", "", "", "index", "=", "[", "i", "[", "0", "]", "for", "i", "in", "sorted", "(", "enumerate", "(", "dep_idx", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "]", "\n", "dep_tag", "=", "[", "dep_tag", "[", "i", "]", "for", "i", "in", "index", "]", "\n", "dep_idx", "=", "[", "dep_idx", "[", "i", "]", "for", "i", "in", "index", "]", "\n", "dep_dir", "=", "[", "dep_dir", "[", "i", "]", "for", "i", "in", "index", "]", "\n", "\n", "assert", "len", "(", "tokens", ")", "==", "len", "(", "dep_idx", ")", ",", "'length wrong'", "\n", "return", "dep_tag", ",", "dep_idx", ",", "dep_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data._default_unk_index": [[230, 232], ["None"], "function", ["None"], ["", "def", "_default_unk_index", "(", ")", ":", "\n", "    ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.build_dep_tag_vocab": [[233, 257], ["collections.Counter", "max", "sorted", "sorted.sort", "collections.defaultdict", "collections.defaultdict.update", "collections.Counter.update", "collections.Counter.items", "itos.append", "len", "len", "enumerate"], "function", ["None"], ["", "def", "build_dep_tag_vocab", "(", "data", ",", "vocab_size", "=", "1000", ",", "min_freq", "=", "0", ")", ":", "\n", "    ", "counter", "=", "Counter", "(", ")", "\n", "for", "d", "in", "data", ":", "\n", "        ", "tags", "=", "d", "[", "'dep_tag'", "]", "\n", "counter", ".", "update", "(", "tags", ")", "\n", "\n", "", "itos", "=", "[", "'<pad>'", ",", "'<unk>'", "]", "\n", "min_freq", "=", "max", "(", "min_freq", ",", "1", ")", "\n", "\n", "# sort by frequency, then alphabetically", "\n", "words_and_frequencies", "=", "sorted", "(", "counter", ".", "items", "(", ")", ",", "key", "=", "lambda", "tup", ":", "tup", "[", "0", "]", ")", "\n", "words_and_frequencies", ".", "sort", "(", "key", "=", "lambda", "tup", ":", "tup", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "for", "word", ",", "freq", "in", "words_and_frequencies", ":", "\n", "        ", "if", "freq", "<", "min_freq", "or", "len", "(", "itos", ")", "==", "vocab_size", ":", "\n", "            ", "break", "\n", "", "if", "word", "==", "'<pad>'", ":", "\n", "            ", "continue", "\n", "", "itos", ".", "append", "(", "word", ")", "\n", "# stoi is simply a reverse dict for itos", "\n", "", "stoi", "=", "defaultdict", "(", "_default_unk_index", ")", "\n", "stoi", ".", "update", "(", "{", "tok", ":", "i", "for", "i", ",", "tok", "in", "enumerate", "(", "itos", ")", "}", ")", "\n", "\n", "return", "{", "'itos'", ":", "itos", ",", "'stoi'", ":", "stoi", ",", "'len'", ":", "len", "(", "itos", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.read_rgat_data.convert_data": [[258, 284], ["range", "len", "len", "d.copy", "new_dataset.append", "len", "d.append", "d.append"], "function", ["None"], ["", "def", "convert_data", "(", "dataset", ")", ":", "\n", "    ", "new_dataset", "=", "[", "]", "\n", "sid", "=", "0", "\n", "for", "i", "in", "dataset", ":", "\n", "        ", "record", "=", "{", "}", "\n", "d", "=", "[", "]", "\n", "for", "pos", "in", "range", "(", "len", "(", "i", "[", "'sentence'", "]", ")", ")", ":", "\n", "            ", "if", "pos", "<", "i", "[", "'from'", "]", ":", "\n", "                ", "d", ".", "append", "(", "i", "[", "'to'", "]", "-", "pos", ")", "\n", "", "else", ":", "\n", "                ", "d", ".", "append", "(", "pos", "-", "i", "[", "'from'", "]", ")", "\n", "", "", "record", "[", "'y'", "]", "=", "i", "[", "'sentiment'", "]", "\n", "record", "[", "'sent'", "]", "=", "' '", ".", "join", "(", "i", "[", "'sentence'", "]", ")", "\n", "record", "[", "'words'", "]", "=", "i", "[", "'sentence'", "]", "\n", "record", "[", "'twords'", "]", "=", "i", "[", "'aspect'", "]", "\n", "record", "[", "'dep_tag'", "]", "=", "i", "[", "'dep_tag'", "]", "\n", "record", "[", "'deg_dir'", "]", "=", "i", "[", "'dep_dir'", "]", "\n", "record", "[", "'wc'", "]", "=", "len", "(", "i", "[", "'sentence'", "]", ")", "\n", "record", "[", "'wct'", "]", "=", "len", "(", "record", "[", "'twords'", "]", ")", "\n", "record", "[", "'dist'", "]", "=", "d", ".", "copy", "(", ")", "\n", "record", "[", "'sid'", "]", "=", "sid", "\n", "record", "[", "'beg'", "]", "=", "i", "[", "'from'", "]", "\n", "record", "[", "'end'", "]", "=", "i", "[", "'to'", "]", "\n", "sid", "=", "sid", "+", "1", "\n", "new_dataset", ".", "append", "(", "record", ")", "\n", "", "return", "new_dataset", "\n", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.__init__": [[17, 21], ["list"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "parent", "=", "None", "\n", "self", ".", "num_children", "=", "0", "\n", "self", ".", "children", "=", "list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.add_child": [[22, 26], ["tree.Tree.children.append"], "methods", ["None"], ["", "def", "add_child", "(", "self", ",", "child", ")", ":", "\n", "        ", "child", ".", "parent", "=", "self", "\n", "self", ".", "num_children", "+=", "1", "\n", "self", ".", "children", ".", "append", "(", "child", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size": [[27, 35], ["getattr", "range", "tree.Tree.children[].size"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "size", "(", "self", ")", ":", "\n", "        ", "if", "getattr", "(", "self", ",", "'_size'", ")", ":", "\n", "            ", "return", "self", ".", "_size", "\n", "", "count", "=", "1", "\n", "for", "i", "in", "range", "(", "self", ".", "num_children", ")", ":", "\n", "            ", "count", "+=", "self", ".", "children", "[", "i", "]", ".", "size", "(", ")", "\n", "", "self", ".", "_size", "=", "count", "\n", "return", "self", ".", "_size", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.depth": [[36, 48], ["getattr", "range", "tree.Tree.children[].depth"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.depth"], ["", "def", "depth", "(", "self", ")", ":", "\n", "        ", "if", "getattr", "(", "self", ",", "'_depth'", ")", ":", "\n", "            ", "return", "self", ".", "_depth", "\n", "", "count", "=", "0", "\n", "if", "self", ".", "num_children", ">", "0", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "num_children", ")", ":", "\n", "                ", "child_depth", "=", "self", ".", "children", "[", "i", "]", ".", "depth", "(", ")", "\n", "if", "child_depth", ">", "count", ":", "\n", "                    ", "count", "=", "child_depth", "\n", "", "", "count", "+=", "1", "\n", "", "self", ".", "_depth", "=", "count", "\n", "return", "self", ".", "_depth", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.__iter__": [[49, 54], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "yield", "self", "\n", "for", "c", "in", "self", ".", "children", ":", "\n", "            ", "for", "x", "in", "c", ":", "\n", "                ", "yield", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.head_to_tree": [[56, 157], ["head[].tolist", "range", "set", "set", "set.union().difference", "subj_ancestors.union().difference.add", "range", "range", "tree.Tree", "len", "set.intersection_update", "len", "len", "nodes[].add_child", "range", "range", "set.add", "set", "set.intersection_update", "set.add", "list", "set.union", "range", "tree.Tree", "range", "nodes[].add_child", "stack.append", "enumerate", "reversed", "int"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.add_child", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.add_child"], ["", "", "", "", "def", "head_to_tree", "(", "head", ",", "len_", ",", "prune", ",", "subj_pos", ",", "obj_pos", ")", ":", "\n", "    ", "\"\"\"\n    Convert a sequence of head indexes into a tree object.\n    \"\"\"", "\n", "head", "=", "head", "[", ":", "len_", "]", ".", "tolist", "(", ")", "\n", "root", "=", "None", "\n", "\n", "if", "prune", "<", "0", ":", "\n", "        ", "nodes", "=", "[", "Tree", "(", ")", "for", "_", "in", "head", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "nodes", ")", ")", ":", "\n", "            ", "h", "=", "head", "[", "i", "]", "\n", "nodes", "[", "i", "]", ".", "idx", "=", "i", "\n", "nodes", "[", "i", "]", ".", "dist", "=", "-", "1", "# just a filler", "\n", "if", "h", "==", "0", ":", "\n", "                ", "root", "=", "nodes", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "nodes", "[", "h", "-", "1", "]", ".", "add_child", "(", "nodes", "[", "i", "]", ")", "\n", "", "", "", "else", ":", "\n", "# find dependency path", "\n", "        ", "subj_pos", "=", "[", "i", "for", "i", "in", "range", "(", "len_", ")", "if", "subj_pos", "[", "i", "]", "==", "0", "]", "\n", "obj_pos", "=", "[", "i", "for", "i", "in", "range", "(", "len_", ")", "if", "obj_pos", "[", "i", "]", "==", "0", "]", "\n", "\n", "cas", "=", "None", "\n", "\n", "subj_ancestors", "=", "set", "(", "subj_pos", ")", "\n", "for", "s", "in", "subj_pos", ":", "\n", "            ", "h", "=", "head", "[", "s", "]", "\n", "tmp", "=", "[", "s", "]", "\n", "while", "h", ">", "0", ":", "\n", "                ", "tmp", "+=", "[", "h", "-", "1", "]", "\n", "subj_ancestors", ".", "add", "(", "h", "-", "1", ")", "\n", "h", "=", "head", "[", "h", "-", "1", "]", "\n", "\n", "", "if", "cas", "is", "None", ":", "\n", "                ", "cas", "=", "set", "(", "tmp", ")", "\n", "", "else", ":", "\n", "                ", "cas", ".", "intersection_update", "(", "tmp", ")", "\n", "\n", "", "", "obj_ancestors", "=", "set", "(", "obj_pos", ")", "\n", "for", "o", "in", "obj_pos", ":", "\n", "            ", "h", "=", "head", "[", "o", "]", "\n", "tmp", "=", "[", "o", "]", "\n", "while", "h", ">", "0", ":", "\n", "                ", "tmp", "+=", "[", "h", "-", "1", "]", "\n", "obj_ancestors", ".", "add", "(", "h", "-", "1", ")", "\n", "h", "=", "head", "[", "h", "-", "1", "]", "\n", "", "cas", ".", "intersection_update", "(", "tmp", ")", "\n", "\n", "# find lowest common ancestor", "\n", "", "if", "len", "(", "cas", ")", "==", "1", ":", "\n", "            ", "lca", "=", "list", "(", "cas", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "child_count", "=", "{", "k", ":", "0", "for", "k", "in", "cas", "}", "\n", "for", "ca", "in", "cas", ":", "\n", "                ", "if", "head", "[", "ca", "]", ">", "0", "and", "head", "[", "ca", "]", "-", "1", "in", "cas", ":", "\n", "                    ", "child_count", "[", "head", "[", "ca", "]", "-", "1", "]", "+=", "1", "\n", "\n", "# the LCA has no child in the CA set", "\n", "", "", "for", "ca", "in", "cas", ":", "\n", "                ", "if", "child_count", "[", "ca", "]", "==", "0", ":", "\n", "                    ", "lca", "=", "ca", "\n", "break", "\n", "\n", "", "", "", "path_nodes", "=", "subj_ancestors", ".", "union", "(", "obj_ancestors", ")", ".", "difference", "(", "cas", ")", "\n", "path_nodes", ".", "add", "(", "lca", ")", "\n", "\n", "# compute distance to path_nodes", "\n", "dist", "=", "[", "-", "1", "if", "i", "not", "in", "path_nodes", "else", "0", "for", "i", "in", "range", "(", "len_", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "len_", ")", ":", "\n", "            ", "if", "dist", "[", "i", "]", "<", "0", ":", "\n", "                ", "stack", "=", "[", "i", "]", "\n", "while", "stack", "[", "-", "1", "]", ">=", "0", "and", "stack", "[", "-", "1", "]", "not", "in", "path_nodes", ":", "\n", "                    ", "stack", ".", "append", "(", "head", "[", "stack", "[", "-", "1", "]", "]", "-", "1", ")", "\n", "\n", "", "if", "stack", "[", "-", "1", "]", "in", "path_nodes", ":", "\n", "                    ", "for", "d", ",", "j", "in", "enumerate", "(", "reversed", "(", "stack", ")", ")", ":", "\n", "                        ", "dist", "[", "j", "]", "=", "d", "\n", "", "", "else", ":", "\n", "                    ", "for", "j", "in", "stack", ":", "\n", "                        ", "if", "j", ">=", "0", "and", "dist", "[", "j", "]", "<", "0", ":", "\n", "                            ", "dist", "[", "j", "]", "=", "int", "(", "1e4", ")", "# aka infinity", "\n", "\n", "", "", "", "", "", "highest_node", "=", "lca", "\n", "nodes", "=", "[", "Tree", "(", ")", "if", "dist", "[", "i", "]", "<=", "prune", "else", "None", "for", "i", "in", "range", "(", "len_", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "nodes", ")", ")", ":", "\n", "            ", "if", "nodes", "[", "i", "]", "is", "None", ":", "\n", "                ", "continue", "\n", "", "h", "=", "head", "[", "i", "]", "\n", "nodes", "[", "i", "]", ".", "idx", "=", "i", "\n", "nodes", "[", "i", "]", ".", "dist", "=", "dist", "[", "i", "]", "\n", "if", "h", ">", "0", "and", "i", "!=", "highest_node", ":", "\n", "                ", "assert", "nodes", "[", "h", "-", "1", "]", "is", "not", "None", "\n", "nodes", "[", "h", "-", "1", "]", ".", "add_child", "(", "nodes", "[", "i", "]", ")", "\n", "\n", "", "", "root", "=", "nodes", "[", "highest_node", "]", "\n", "\n", "", "assert", "root", "is", "not", "None", "\n", "return", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.tree_to_adj": [[159, 184], ["numpy.zeros", "len"], "function", ["None"], ["", "def", "tree_to_adj", "(", "sent_len", ",", "tree", ",", "directed", "=", "False", ",", "self_loop", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Convert a tree object to an (numpy) adjacency matrix.\n    \"\"\"", "\n", "ret", "=", "np", ".", "zeros", "(", "(", "sent_len", ",", "sent_len", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "queue", "=", "[", "tree", "]", "\n", "idx", "=", "[", "]", "\n", "while", "len", "(", "queue", ")", ">", "0", ":", "\n", "        ", "t", ",", "queue", "=", "queue", "[", "0", "]", ",", "queue", "[", "1", ":", "]", "\n", "\n", "idx", "+=", "[", "t", ".", "idx", "]", "\n", "\n", "for", "c", "in", "t", ".", "children", ":", "\n", "            ", "ret", "[", "t", ".", "idx", ",", "c", ".", "idx", "]", "=", "1", "\n", "", "queue", "+=", "t", ".", "children", "\n", "\n", "", "if", "not", "directed", ":", "\n", "        ", "ret", "=", "ret", "+", "ret", ".", "T", "\n", "\n", "", "if", "self_loop", ":", "\n", "        ", "for", "i", "in", "idx", ":", "\n", "            ", "ret", "[", "i", ",", "i", "]", "=", "1", "\n", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.tree_to_dist": [[186, 193], ["numpy.ones"], "function", ["None"], ["", "def", "tree_to_dist", "(", "sent_len", ",", "tree", ")", ":", "\n", "    ", "ret", "=", "-", "1", "*", "np", ".", "ones", "(", "sent_len", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "for", "node", "in", "tree", ":", "\n", "        ", "ret", "[", "node", ".", "idx", "]", "=", "node", ".", "dist", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.inputs_to_tree_reps": [[195, 224], ["max", "dep_heads.cpu().numpy.cpu().numpy", "numpy.concatenate", "torch.from_numpy", "subj_pos.cpu().numpy.cpu().numpy", "obj_pos.cpu().numpy.cpu().numpy", "tree.head_to_tree", "tree_to_adj().reshape", "dep_heads.cpu().numpy.cpu", "range", "subj_pos.cpu().numpy.cpu", "obj_pos.cpu().numpy.cpu", "len", "tree.tree_to_adj"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.head_to_tree", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.tree_to_adj"], ["", "def", "inputs_to_tree_reps", "(", "args", ",", "dep_heads", ",", "l", ",", "prune", ",", "subj_pos", "=", "None", ",", "obj_pos", "=", "None", ")", ":", "\n", "    ", "'''\n    Read the code.\n    Inputs:\n        head: predicted_heads\n        l: (masks.data.cpu().numpy() == 0).astype(np.int64).sum(1) get the text length in each sentence. For that we have text_len\n            masks = torch.eq(words, 0)  (pads are zerors)\n        maxlen: max(l), is just sentence.shape(1), we have that when batching.\n        prune: we don't prune, set to -1.\n        subj_pos:\n        obj_pos:\n\n    head_to_tree: return the root.\n\n    '''", "\n", "maxlen", "=", "max", "(", "l", ")", "\n", "dep_heads", "=", "dep_heads", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "subj_pos", ":", "\n", "        ", "subj_pos", "=", "subj_pos", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "if", "obj_pos", ":", "\n", "        ", "obj_pos", "=", "obj_pos", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "trees", "=", "[", "head_to_tree", "(", "dep_heads", "[", "i", "]", ",", "l", "[", "i", "]", ",", "prune", ",", "\n", "None", ",", "None", ")", "for", "i", "in", "range", "(", "len", "(", "l", ")", ")", "]", "\n", "adj", "=", "[", "tree_to_adj", "(", "maxlen", ",", "tree", ",", "directed", "=", "False", ",", "self_loop", "=", "False", ")", ".", "reshape", "(", "\n", "1", ",", "maxlen", ",", "maxlen", ")", "for", "tree", "in", "trees", "]", "\n", "adj", "=", "np", ".", "concatenate", "(", "adj", ",", "axis", "=", "0", ")", "\n", "adj", "=", "torch", ".", "from_numpy", "(", "adj", ")", "\n", "return", "adj", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.inputs_to_deprel_adj": [[226, 249], ["max", "dep_heads.cpu().numpy.cpu().numpy", "dep_rel.cpu().numpy.cpu().numpy", "numpy.concatenate", "torch.from_numpy", "numpy.concatenate", "torch.from_numpy", "tree.head_rel_to_tree", "tree_to_adj().reshape", "tree_to_rel_adj().reshape", "dep_heads.cpu().numpy.cpu", "dep_rel.cpu().numpy.cpu", "range", "len", "tree.tree_to_adj", "tree.tree_to_rel_adj"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.head_rel_to_tree", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.tree_to_adj", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.tree_to_rel_adj"], ["", "def", "inputs_to_deprel_adj", "(", "args", ",", "dep_heads", ",", "dep_rel", ",", "l", ",", ")", ":", "\n", "    ", "\"\"\"\n    Inputs:\n        head: predicted_heads, used to form adj matrix. adj can be used to mask the logits of the rel_adj matrix.\n        dep_rel: the corresponding relation. if a_ij = 1, r_ij = label. others will be masked, if set to ncon, then adj will not be used as mask.\n        l: text_len\n\n    \"\"\"", "\n", "maxlen", "=", "max", "(", "l", ")", "\n", "dep_heads", "=", "dep_heads", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "dep_rel", "=", "dep_rel", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "trees", "=", "[", "head_rel_to_tree", "(", "dep_heads", "[", "i", "]", ",", "dep_rel", "[", "i", "]", ",", "l", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "l", ")", ")", "]", "\n", "adj", "=", "[", "tree_to_adj", "(", "maxlen", ",", "tree", ",", "directed", "=", "False", ",", "self_loop", "=", "False", ")", ".", "reshape", "(", "\n", "1", ",", "maxlen", ",", "maxlen", ")", "for", "tree", "in", "trees", "]", "\n", "rel_adj", "=", "[", "tree_to_rel_adj", "(", "maxlen", ",", "tree", ",", "directed", "=", "False", ",", "self_loop", "=", "False", ")", ".", "reshape", "(", "\n", "1", ",", "maxlen", ",", "maxlen", ")", "for", "tree", "in", "trees", "]", "\n", "\n", "adj", "=", "np", ".", "concatenate", "(", "adj", ",", "axis", "=", "0", ")", "\n", "adj", "=", "torch", ".", "from_numpy", "(", "adj", ")", "\n", "rel_adj", "=", "np", ".", "concatenate", "(", "rel_adj", ",", "axis", "=", "0", ")", "\n", "rel_adj", "=", "torch", ".", "from_numpy", "(", "rel_adj", ")", "\n", "return", "adj", ",", "rel_adj", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.head_rel_to_tree": [[251, 271], ["head[].tolist", "range", "tree.Tree", "len", "nodes[].add_child"], "function", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.add_child"], ["", "def", "head_rel_to_tree", "(", "head", ",", "rel", ",", "len_", ")", ":", "\n", "    ", "\"\"\"\n    Convert a sequence of head indexes into a tree object.\n    \"\"\"", "\n", "head", "=", "head", "[", ":", "len_", "]", ".", "tolist", "(", ")", "\n", "root", "=", "None", "\n", "\n", "nodes", "=", "[", "Tree", "(", ")", "for", "_", "in", "head", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "nodes", ")", ")", ":", "\n", "        ", "h", "=", "head", "[", "i", "]", "\n", "nodes", "[", "i", "]", ".", "idx", "=", "i", "\n", "nodes", "[", "i", "]", ".", "rel", "=", "rel", "[", "i", "]", "\n", "nodes", "[", "i", "]", ".", "dist", "=", "-", "1", "# just a filler", "\n", "if", "h", "==", "0", ":", "\n", "            ", "root", "=", "nodes", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "nodes", "[", "h", "-", "1", "]", ".", "add_child", "(", "nodes", "[", "i", "]", ")", "\n", "\n", "", "", "return", "root", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.tree_to_rel_adj": [[272, 297], ["numpy.zeros", "len"], "function", ["None"], ["", "def", "tree_to_rel_adj", "(", "sent_len", ",", "tree", ",", "directed", "=", "False", ",", "self_loop", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Convert a tree object to an (numpy) dep_rel labeled adjacency matrix.\n    \"\"\"", "\n", "ret", "=", "np", ".", "zeros", "(", "(", "sent_len", ",", "sent_len", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "queue", "=", "[", "tree", "]", "\n", "idx", "=", "[", "]", "\n", "while", "len", "(", "queue", ")", ">", "0", ":", "\n", "        ", "t", ",", "queue", "=", "queue", "[", "0", "]", ",", "queue", "[", "1", ":", "]", "\n", "\n", "idx", "+=", "[", "t", ".", "idx", "]", "\n", "\n", "for", "c", "in", "t", ".", "children", ":", "\n", "            ", "ret", "[", "t", ".", "idx", ",", "c", ".", "idx", "]", "=", "t", ".", "rel", "\n", "", "queue", "+=", "t", ".", "children", "\n", "\n", "", "if", "not", "directed", ":", "\n", "        ", "ret", "=", "ret", "+", "ret", ".", "T", "\n", "\n", "", "if", "self_loop", ":", "\n", "        ", "for", "i", "in", "idx", ":", "\n", "            ", "ret", "[", "i", ",", "i", "]", "=", "1", "\n", "\n", "", "", "return", "ret", "\n", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.point_wise_feed_forward.PositionwiseFeedForward.__init__": [[11, 19], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Dropout", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["def", "__init__", "(", "self", ",", "d_hid", ",", "d_inner_hid", "=", "None", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "d_inner_hid", "is", "None", ":", "\n", "            ", "d_inner_hid", "=", "d_hid", "\n", "", "self", ".", "w_1", "=", "nn", ".", "Conv1d", "(", "d_hid", ",", "d_inner_hid", ",", "1", ")", "# position-wise", "\n", "self", ".", "w_2", "=", "nn", ".", "Conv1d", "(", "d_inner_hid", ",", "d_hid", ",", "1", ")", "# position-wise", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.point_wise_feed_forward.PositionwiseFeedForward.forward": [[20, 25], ["point_wise_feed_forward.PositionwiseFeedForward.relu", "point_wise_feed_forward.PositionwiseFeedForward.w_2().transpose", "point_wise_feed_forward.PositionwiseFeedForward.dropout", "point_wise_feed_forward.PositionwiseFeedForward.w_1", "x.transpose", "point_wise_feed_forward.PositionwiseFeedForward.w_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", "=", "self", ".", "relu", "(", "self", ".", "w_1", "(", "x", ".", "transpose", "(", "1", ",", "2", ")", ")", ")", "\n", "output", "=", "self", ".", "w_2", "(", "output", ")", ".", "transpose", "(", "2", ",", "1", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.squeeze_embedding.SqueezeEmbedding.__init__": [[15, 18], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["def", "__init__", "(", "self", ",", "batch_first", "=", "True", ")", ":", "\n", "        ", "super", "(", "SqueezeEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.squeeze_embedding.SqueezeEmbedding.forward": [[19, 39], ["[].long", "[].long", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_len", ")", ":", "\n", "        ", "\"\"\"\n        sequence -> sort -> pad and pack -> unpack ->unsort\n        :param x: sequence embedding vectors\n        :param x_len: numpy/tensor list\n        :return:\n        \"\"\"", "\n", "\"\"\"sort\"\"\"", "\n", "x_sort_idx", "=", "torch", ".", "sort", "(", "-", "x_len", ")", "[", "1", "]", ".", "long", "(", ")", "\n", "x_unsort_idx", "=", "torch", ".", "sort", "(", "x_sort_idx", ")", "[", "1", "]", ".", "long", "(", ")", "\n", "x_len", "=", "x_len", "[", "x_sort_idx", "]", "\n", "x", "=", "x", "[", "x_sort_idx", "]", "\n", "\"\"\"pack\"\"\"", "\n", "x_emb_p", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "x", ",", "x_len", ",", "batch_first", "=", "self", ".", "batch_first", ")", "\n", "\"\"\"unpack: out\"\"\"", "\n", "out", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "x_emb_p", ",", "batch_first", "=", "self", ".", "batch_first", ")", "# (sequence, lengths)", "\n", "out", "=", "out", "[", "0", "]", "#", "\n", "\"\"\"unsort\"\"\"", "\n", "out", "=", "out", "[", "x_unsort_idx", "]", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.attention.Attention.__init__": [[13, 42], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "attention.Attention.reset_parameters", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "torch.Parameter", "attention.Attention.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__", "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.attention.Attention.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "hidden_dim", "=", "None", ",", "out_dim", "=", "None", ",", "n_head", "=", "1", ",", "score_function", "=", "'dot_product'", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "''' Attention Mechanism\n        :param embed_dim:\n        :param hidden_dim:\n        :param out_dim:\n        :param n_head: num of head (Multi-Head Attention)\n        :param score_function: scaled_dot_product / mlp (concat) / bi_linear (general dot)\n        :return (?, q_len, out_dim,)\n        '''", "\n", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "hidden_dim", "is", "None", ":", "\n", "            ", "hidden_dim", "=", "embed_dim", "//", "n_head", "\n", "", "if", "out_dim", "is", "None", ":", "\n", "            ", "out_dim", "=", "embed_dim", "\n", "", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "score_function", "=", "score_function", "\n", "self", ".", "w_k", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "n_head", "*", "hidden_dim", ")", "\n", "self", ".", "w_q", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "n_head", "*", "hidden_dim", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "n_head", "*", "hidden_dim", ",", "out_dim", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "if", "score_function", "==", "'mlp'", ":", "\n", "            ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_dim", "*", "2", ")", ")", "\n", "", "elif", "self", ".", "score_function", "==", "'bi_linear'", ":", "\n", "            ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_dim", ",", "hidden_dim", ")", ")", "\n", "", "else", ":", "# dot_product / scaled_dot_product", "\n", "            ", "self", ".", "register_parameter", "(", "'weight'", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.attention.Attention.reset_parameters": [[43, 47], ["math.sqrt", "attention.Attention.weight.data.uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "self", ".", "hidden_dim", ")", "\n", "if", "self", ".", "weight", "is", "not", "None", ":", "\n", "            ", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.attention.Attention.forward": [[48, 91], ["attention.Attention.w_k().view", "kx.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "attention.Attention.w_q().view", "qx.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attention.Attention.proj", "attention.Attention.dropout", "len", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "len", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "kx.permute().contiguous().view.permute().contiguous().view.permute", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "attention.Attention.w_k", "kx.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "attention.Attention.w_q", "qx.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "kx.permute().contiguous().view.permute().contiguous().view.permute", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "math.sqrt", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tanh", "torch.tanh", "torch.tanh", "kx.permute().contiguous().view.permute().contiguous().view.permute", "qx.permute().contiguous().view.permute().contiguous().view.permute", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "kx.permute().contiguous().view.permute().contiguous().view.permute", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "RuntimeError", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "k", ",", "q", ")", ":", "\n", "        ", "if", "len", "(", "q", ".", "shape", ")", "==", "2", ":", "# q_len missing", "\n", "            ", "q", "=", "torch", ".", "unsqueeze", "(", "q", ",", "dim", "=", "1", ")", "\n", "", "if", "len", "(", "k", ".", "shape", ")", "==", "2", ":", "# k_len missing", "\n", "            ", "k", "=", "torch", ".", "unsqueeze", "(", "k", ",", "dim", "=", "1", ")", "\n", "", "mb_size", "=", "k", ".", "shape", "[", "0", "]", "# ?", "\n", "k_len", "=", "k", ".", "shape", "[", "1", "]", "\n", "q_len", "=", "q", ".", "shape", "[", "1", "]", "\n", "# k: (?, k_len, embed_dim,)", "\n", "# q: (?, q_len, embed_dim,)", "\n", "# kx: (n_head*?, k_len, hidden_dim)", "\n", "# qx: (n_head*?, q_len, hidden_dim)", "\n", "# score: (n_head*?, q_len, k_len,)", "\n", "# output: (?, q_len, out_dim,)", "\n", "kx", "=", "self", ".", "w_k", "(", "k", ")", ".", "view", "(", "mb_size", ",", "k_len", ",", "self", ".", "n_head", ",", "self", ".", "hidden_dim", ")", "\n", "kx", "=", "kx", ".", "permute", "(", "2", ",", "0", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "k_len", ",", "self", ".", "hidden_dim", ")", "\n", "qx", "=", "self", ".", "w_q", "(", "q", ")", ".", "view", "(", "mb_size", ",", "q_len", ",", "self", ".", "n_head", ",", "self", ".", "hidden_dim", ")", "\n", "qx", "=", "qx", ".", "permute", "(", "2", ",", "0", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "q_len", ",", "self", ".", "hidden_dim", ")", "\n", "if", "self", ".", "score_function", "==", "'dot_product'", ":", "\n", "            ", "kt", "=", "kx", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "score", "=", "torch", ".", "bmm", "(", "qx", ",", "kt", ")", "\n", "", "elif", "self", ".", "score_function", "==", "'scaled_dot_product'", ":", "\n", "            ", "kt", "=", "kx", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "qkt", "=", "torch", ".", "bmm", "(", "qx", ",", "kt", ")", "\n", "score", "=", "torch", ".", "div", "(", "qkt", ",", "math", ".", "sqrt", "(", "self", ".", "hidden_dim", ")", ")", "\n", "", "elif", "self", ".", "score_function", "==", "'mlp'", ":", "\n", "            ", "kxx", "=", "torch", ".", "unsqueeze", "(", "kx", ",", "dim", "=", "1", ")", ".", "expand", "(", "-", "1", ",", "q_len", ",", "-", "1", ",", "-", "1", ")", "\n", "qxx", "=", "torch", ".", "unsqueeze", "(", "qx", ",", "dim", "=", "2", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "k_len", ",", "-", "1", ")", "\n", "kq", "=", "torch", ".", "cat", "(", "(", "kxx", ",", "qxx", ")", ",", "dim", "=", "-", "1", ")", "# (n_head*?, q_len, k_len, hidden_dim*2)", "\n", "# kq = torch.unsqueeze(kx, dim=1) + torch.unsqueeze(qx, dim=2)", "\n", "score", "=", "F", ".", "tanh", "(", "torch", ".", "matmul", "(", "kq", ",", "self", ".", "weight", ")", ")", "\n", "", "elif", "self", ".", "score_function", "==", "'bi_linear'", ":", "\n", "            ", "qw", "=", "torch", ".", "matmul", "(", "qx", ",", "self", ".", "weight", ")", "\n", "kt", "=", "kx", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "score", "=", "torch", ".", "bmm", "(", "qw", ",", "kt", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "'invalid score_function'", ")", "\n", "", "score", "=", "F", ".", "softmax", "(", "score", ",", "dim", "=", "-", "1", ")", "\n", "output", "=", "torch", ".", "bmm", "(", "score", ",", "kx", ")", "# (n_head*?, q_len, hidden_dim)", "\n", "output", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "output", ",", "mb_size", ",", "dim", "=", "0", ")", ",", "dim", "=", "-", "1", ")", "# (?, q_len, n_head*hidden_dim)", "\n", "output", "=", "self", ".", "proj", "(", "output", ")", "# (?, q_len, out_dim)", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "return", "output", ",", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.attention.NoQueryAttention.__init__": [[95, 100], ["attention.Attention.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "attention.NoQueryAttention.reset_q", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__", "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.attention.NoQueryAttention.reset_q"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "hidden_dim", "=", "None", ",", "out_dim", "=", "None", ",", "n_head", "=", "1", ",", "score_function", "=", "'dot_product'", ",", "q_len", "=", "1", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "NoQueryAttention", ",", "self", ")", ".", "__init__", "(", "embed_dim", ",", "hidden_dim", ",", "out_dim", ",", "n_head", ",", "score_function", ",", "dropout", ")", "\n", "self", ".", "q_len", "=", "q_len", "\n", "self", ".", "q", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "q_len", ",", "embed_dim", ")", ")", "\n", "self", ".", "reset_q", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.attention.NoQueryAttention.reset_q": [[101, 104], ["attention.NoQueryAttention.q.data.uniform_", "math.sqrt"], "methods", ["None"], ["", "def", "reset_q", "(", "self", ")", ":", "\n", "        ", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "self", ".", "embed_dim", ")", "\n", "self", ".", "q", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.attention.NoQueryAttention.forward": [[105, 109], ["attention.NoQueryAttention.q.expand", "attention.Attention.forward"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.multi_head_attention.MultiHeadAttention.forward"], ["", "def", "forward", "(", "self", ",", "k", ",", "**", "kwargs", ")", ":", "\n", "        ", "mb_size", "=", "k", ".", "shape", "[", "0", "]", "\n", "q", "=", "self", ".", "q", ".", "expand", "(", "mb_size", ",", "-", "1", ",", "-", "1", ")", "\n", "return", "super", "(", "NoQueryAttention", ",", "self", ")", ".", "forward", "(", "k", ",", "q", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.dynamic_rnn.DynamicLSTM.__init__": [[12, 49], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.GRU", "torch.GRU", "torch.RNN", "torch.RNN"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "num_layers", "=", "1", ",", "bias", "=", "True", ",", "batch_first", "=", "True", ",", "dropout", "=", "0", ",", "\n", "bidirectional", "=", "False", ",", "only_use_last_hidden_state", "=", "False", ",", "rnn_type", "=", "'LSTM'", ")", ":", "\n", "        ", "\"\"\"\n        LSTM which can hold variable length sequence, use like TensorFlow's RNN(input, length...).\n\n        :param input_size:The number of expected features in the input x\n        :param hidden_size:The number of features in the hidden state h\n        :param num_layers:Number of recurrent layers.\n        :param bias:If False, then the layer does not use bias weights b_ih and b_hh. Default: True\n        :param batch_first:If True, then the input and output tensors are provided as (batch, seq, feature)\n        :param dropout:If non-zero, introduces a dropout layer on the outputs of each RNN layer except the last layer\n        :param bidirectional:If True, becomes a bidirectional RNN. Default: False\n        :param rnn_type: {LSTM, GRU, RNN}\n        \"\"\"", "\n", "super", "(", "DynamicLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "only_use_last_hidden_state", "=", "only_use_last_hidden_state", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "self", ".", "RNN", "=", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "input_size", ",", "hidden_size", "=", "hidden_size", ",", "num_layers", "=", "num_layers", ",", "\n", "bias", "=", "bias", ",", "batch_first", "=", "batch_first", ",", "dropout", "=", "dropout", ",", "bidirectional", "=", "bidirectional", ")", "\n", "", "elif", "self", ".", "rnn_type", "==", "'GRU'", ":", "\n", "            ", "self", ".", "RNN", "=", "nn", ".", "GRU", "(", "\n", "input_size", "=", "input_size", ",", "hidden_size", "=", "hidden_size", ",", "num_layers", "=", "num_layers", ",", "\n", "bias", "=", "bias", ",", "batch_first", "=", "batch_first", ",", "dropout", "=", "dropout", ",", "bidirectional", "=", "bidirectional", ")", "\n", "", "elif", "self", ".", "rnn_type", "==", "'RNN'", ":", "\n", "            ", "self", ".", "RNN", "=", "nn", ".", "RNN", "(", "\n", "input_size", "=", "input_size", ",", "hidden_size", "=", "hidden_size", ",", "num_layers", "=", "num_layers", ",", "\n", "bias", "=", "bias", ",", "batch_first", "=", "batch_first", ",", "dropout", "=", "dropout", ",", "bidirectional", "=", "bidirectional", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.layers.dynamic_rnn.DynamicLSTM.forward": [[51, 93], ["dynamic_rnn.DynamicLSTM.RNN.flatten_parameters", "[].long", "[].long", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "dynamic_rnn.DynamicLSTM.RNN", "dynamic_rnn.DynamicLSTM.RNN", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "x_len", ")", ":", "\n", "        ", "\"\"\"\n        sequence -> sort -> pad and pack ->process using RNN -> unpack ->unsort\n\n        :param x: sequence embedding vectors\n        :param x_len: numpy/tensor list\n        :return:\n        \"\"\"", "\n", "\"\"\"sort\"\"\"", "\n", "self", ".", "RNN", ".", "flatten_parameters", "(", ")", "\n", "x_sort_idx", "=", "torch", ".", "sort", "(", "-", "x_len", ")", "[", "1", "]", ".", "long", "(", ")", "\n", "x_unsort_idx", "=", "torch", ".", "sort", "(", "x_sort_idx", ")", "[", "1", "]", ".", "long", "(", ")", "\n", "x_len", "=", "x_len", "[", "x_sort_idx", "]", "\n", "x", "=", "x", "[", "x_sort_idx", "]", "\n", "\"\"\"pack\"\"\"", "\n", "x_emb_p", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "x", ",", "x_len", ",", "batch_first", "=", "self", ".", "batch_first", ")", "\n", "\n", "# process using the selected RNN", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "out_pack", ",", "(", "ht", ",", "ct", ")", "=", "self", ".", "RNN", "(", "x_emb_p", ",", "None", ")", "\n", "", "else", ":", "\n", "            ", "out_pack", ",", "ht", "=", "self", ".", "RNN", "(", "x_emb_p", ",", "None", ")", "\n", "ct", "=", "None", "\n", "", "\"\"\"unsort: h\"\"\"", "\n", "ht", "=", "torch", ".", "transpose", "(", "ht", ",", "0", ",", "1", ")", "[", "\n", "x_unsort_idx", "]", "# (num_layers * num_directions, batch, hidden_size) -> (batch, ...)", "\n", "ht", "=", "torch", ".", "transpose", "(", "ht", ",", "0", ",", "1", ")", "\n", "\n", "if", "self", ".", "only_use_last_hidden_state", ":", "\n", "            ", "return", "ht", "\n", "", "else", ":", "\n", "            ", "\"\"\"unpack: out\"\"\"", "\n", "out", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "out_pack", ",", "batch_first", "=", "self", ".", "batch_first", ")", "# (sequence, lengths)", "\n", "out", "=", "out", "[", "0", "]", "#", "\n", "out", "=", "out", "[", "x_unsort_idx", "]", "\n", "\"\"\"unsort: out c\"\"\"", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "                ", "ct", "=", "torch", ".", "transpose", "(", "ct", ",", "0", ",", "1", ")", "[", "\n", "x_unsort_idx", "]", "# (num_layers * num_directions, batch, hidden_size) -> (batch, ...)", "\n", "ct", "=", "torch", ".", "transpose", "(", "ct", ",", "0", ",", "1", ")", "\n", "\n", "", "return", "out", ",", "(", "ht", ",", "ct", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.utils.squash.squash": [[3, 7], ["torch.sum", "torch.sqrt"], "function", ["None"], ["def", "squash", "(", "x", ",", "dim", "=", "-", "1", ")", ":", "\n", "    ", "squared", "=", "torch", ".", "sum", "(", "x", "*", "x", ",", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "\n", "scale", "=", "torch", ".", "sqrt", "(", "squared", ")", "/", "(", "1.0", "+", "squared", ")", "\n", "return", "scale", "*", "x", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.utils.loss.CapsuleLoss.__init__": [[7, 11], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "smooth", "=", "0.1", ",", "lamda", "=", "0.6", ")", ":", "\n", "        ", "super", "(", "CapsuleLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "smooth", "=", "smooth", "\n", "self", ".", "lamda", "=", "lamda", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.utils.loss.CapsuleLoss.forward": [[12, 20], ["torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "one_hot.scatter.scatter.scatter", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "loss.sum.sum.sum", "loss.sum.sum.mean", "target.unsqueeze", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "one_hot", "=", "torch", ".", "zeros_like", "(", "input", ")", ".", "to", "(", "input", ".", "device", ")", "\n", "one_hot", "=", "one_hot", ".", "scatter", "(", "1", ",", "target", ".", "unsqueeze", "(", "-", "1", ")", ",", "1", ")", "\n", "a", "=", "torch", ".", "max", "(", "torch", ".", "zeros_like", "(", "input", ")", ".", "to", "(", "input", ".", "device", ")", ",", "1", "-", "self", ".", "smooth", "-", "input", ")", "\n", "b", "=", "torch", ".", "max", "(", "torch", ".", "zeros_like", "(", "input", ")", ".", "to", "(", "input", ".", "device", ")", ",", "input", "-", "self", ".", "smooth", ")", "\n", "loss", "=", "one_hot", "*", "a", "*", "a", "+", "self", ".", "lamda", "*", "(", "1", "-", "one_hot", ")", "*", "b", "*", "b", "\n", "loss", "=", "loss", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", "return", "loss", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.utils.loss.CrossEntropyLoss_LSR.__init__": [[23, 27], ["torch.nn.Module.__init__", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "para_LSR", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "CrossEntropyLoss_LSR", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "para_LSR", "=", "para_LSR", "\n", "self", ".", "logSoftmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.utils.loss.CrossEntropyLoss_LSR._toOneHot_smooth": [[28, 35], ["range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "_toOneHot_smooth", "(", "self", ",", "label", ",", "batchsize", ",", "classes", ")", ":", "\n", "        ", "prob", "=", "self", ".", "para_LSR", "*", "1.0", "/", "classes", "\n", "one_hot_label", "=", "torch", ".", "zeros", "(", "batchsize", ",", "classes", ")", "+", "prob", "\n", "for", "i", "in", "range", "(", "batchsize", ")", ":", "\n", "            ", "index", "=", "label", "[", "i", "]", "\n", "one_hot_label", "[", "i", ",", "index", "]", "+=", "(", "1.0", "-", "self", ".", "para_LSR", ")", "\n", "", "return", "one_hot_label", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.utils.loss.CrossEntropyLoss_LSR.forward": [[36, 44], ["pre.size", "torch.sum.CrossEntropyLoss_LSR._toOneHot_smooth().to", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.CrossEntropyLoss_LSR._toOneHot_smooth", "torch.sum.CrossEntropyLoss_LSR.logSoftmax"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.utils.loss.CrossEntropyLoss_LSR._toOneHot_smooth"], ["", "def", "forward", "(", "self", ",", "pre", ",", "label", ",", "size_average", "=", "True", ")", ":", "\n", "        ", "b", ",", "c", "=", "pre", ".", "size", "(", ")", "\n", "one_hot_label", "=", "self", ".", "_toOneHot_smooth", "(", "label", ",", "b", ",", "c", ")", ".", "to", "(", "pre", ".", "device", ")", "\n", "loss", "=", "torch", ".", "sum", "(", "-", "one_hot_label", "*", "self", ".", "logSoftmax", "(", "pre", ")", ",", "dim", "=", "1", ")", "\n", "if", "size_average", ":", "\n", "            ", "return", "torch", ".", "mean", "(", "loss", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "sum", "(", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.utils.loss.SmoothCrossEntropy.__init__": [[47, 51], ["torch.nn.Module.__init__", "torch.nn.KLDivLoss", "torch.nn.KLDivLoss"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "smooth", "=", "0.08", ")", ":", "\n", "        ", "super", "(", "SmoothCrossEntropy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "kldiv", "=", "nn", ".", "KLDivLoss", "(", ")", "\n", "self", ".", "smooth", "=", "smooth", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.utils.loss.SmoothCrossEntropy.forward": [[52, 60], ["torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "one_hot.scatter.scatter.scatter", "loss.mean", "target.unsqueeze", "torch.log_softmax", "torch.log_softmax", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "input.max", "input.size"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "one_hot", "=", "torch", ".", "zeros_like", "(", "input", ")", ".", "to", "(", "input", ".", "device", ")", "\n", "one_hot", "=", "one_hot", ".", "scatter", "(", "1", ",", "target", ".", "unsqueeze", "(", "-", "1", ")", ",", "1", ")", "\n", "target", "=", "(", "1", "-", "self", ".", "smooth", ")", "*", "one_hot", "+", "self", ".", "smooth", "/", "(", "input", ".", "size", "(", "1", ")", "-", "1", ")", "*", "(", "1", "-", "one_hot", ")", "\n", "# target = target + torch.rand_like(target).to(target.device) * 0.001", "\n", "input", "=", "input", "-", "input", ".", "max", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", "\n", "loss", "=", "-", "target", "*", "F", ".", "log_softmax", "(", "input", ",", "dim", "=", "-", "1", ")", "\n", "return", "loss", ".", "mean", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.utils.sentence_clip.sentence_clip": [[3, 8], ["mask.long().sum", "mask.long().sum.max().item", "mask.long", "mask.long().sum.max"], "function", ["None"], ["def", "sentence_clip", "(", "sentence", ")", ":", "\n", "    ", "mask", "=", "(", "sentence", "!=", "PAD_INDEX", ")", "\n", "sentence_lens", "=", "mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", "max_len", "=", "sentence_lens", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "return", "sentence", "[", ":", ",", ":", "max_len", "]", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.tanh_concat_attention.TanhConcatAttention.__init__": [[8, 14], ["src.module.attention.attention.Attention.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "query_size", ",", "key_size", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "TanhConcatAttention", ",", "self", ")", ".", "__init__", "(", "dropout", ")", "\n", "self", ".", "query_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "query_size", ",", "1", ")", ")", "\n", "self", ".", "key_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "key_size", ",", "1", ")", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "query_weights", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "key_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.tanh_concat_attention.TanhConcatAttention._score": [[15, 26], ["query.matmul().expand.matmul().expand.matmul().expand", "key.matmul().transpose().expand.matmul().transpose().expand.matmul().transpose().expand", "torch.tanh", "query.matmul().expand.matmul().expand.size", "query.matmul().expand.matmul().expand.size", "key.matmul().transpose().expand.matmul().transpose().expand.size", "query.matmul().expand.matmul().expand.matmul", "key.matmul().transpose().expand.matmul().transpose().expand.matmul().transpose", "key.matmul().transpose().expand.matmul().transpose().expand.matmul"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "_score", "(", "self", ",", "query", ",", "key", ")", ":", "\n", "        ", "\"\"\"\n        query: FloatTensor (batch_size, num_queries, query_size)\n        key: FloatTensor (batch_size, time_step, key_size)\n        \"\"\"", "\n", "batch_size", ",", "num_queries", ",", "time_step", "=", "query", ".", "size", "(", "0", ")", ",", "query", ".", "size", "(", "1", ")", ",", "key", ".", "size", "(", "1", ")", "\n", "query", "=", "query", ".", "matmul", "(", "self", ".", "query_weights", ")", ".", "expand", "(", "batch_size", ",", "num_queries", ",", "time_step", ")", "\n", "key", "=", "key", ".", "matmul", "(", "self", ".", "key_weights", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "expand", "(", "batch_size", ",", "num_queries", ",", "time_step", ")", "\n", "score", "=", "query", "+", "key", "\n", "score", "=", "torch", ".", "tanh", "(", "score", ")", "\n", "return", "score", "", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.concat_attention.ConcatAttention.__init__": [[8, 14], ["src.module.attention.attention.Attention.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "query_size", ",", "key_size", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "ConcatAttention", ",", "self", ")", ".", "__init__", "(", "dropout", ")", "\n", "self", ".", "query_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "query_size", ",", "1", ")", ")", "\n", "self", ".", "key_weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "key_size", ",", "1", ")", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "query_weights", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "key_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.concat_attention.ConcatAttention._score": [[15, 25], ["query.matmul().expand.matmul().expand.matmul().expand", "key.matmul().transpose().expand.matmul().transpose().expand.matmul().transpose().expand", "query.matmul().expand.matmul().expand.size", "query.matmul().expand.matmul().expand.size", "key.matmul().transpose().expand.matmul().transpose().expand.size", "query.matmul().expand.matmul().expand.matmul", "key.matmul().transpose().expand.matmul().transpose().expand.matmul().transpose", "key.matmul().transpose().expand.matmul().transpose().expand.matmul"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "_score", "(", "self", ",", "query", ",", "key", ")", ":", "\n", "        ", "\"\"\"\n        query: FloatTensor (batch_size, num_queries, query_size)\n        key: FloatTensor (batch_size, time_step, key_size)\n        \"\"\"", "\n", "batch_size", ",", "num_queries", ",", "time_step", "=", "query", ".", "size", "(", "0", ")", ",", "query", ".", "size", "(", "1", ")", ",", "key", ".", "size", "(", "1", ")", "\n", "query", "=", "query", ".", "matmul", "(", "self", ".", "query_weights", ")", ".", "expand", "(", "batch_size", ",", "num_queries", ",", "time_step", ")", "\n", "key", "=", "key", ".", "matmul", "(", "self", ".", "key_weights", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "expand", "(", "batch_size", ",", "num_queries", ",", "time_step", ")", "\n", "score", "=", "query", "+", "key", "\n", "return", "score", "", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.mlp_attention.MlpAttention.__init__": [[8, 14], ["src.module.attention.attention.Attention.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.init.xavier_uniform_", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "query_size", ",", "key_size", ",", "out_size", "=", "100", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "MlpAttention", ",", "self", ")", ".", "__init__", "(", "dropout", ")", "\n", "self", ".", "query_projection", "=", "nn", ".", "Linear", "(", "query_size", ",", "out_size", ")", "\n", "self", ".", "key_projection", "=", "nn", ".", "Linear", "(", "key_size", ",", "out_size", ")", "\n", "self", ".", "v", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "out_size", ",", "1", ")", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.mlp_attention.MlpAttention._score": [[15, 25], ["mlp_attention.MlpAttention.query_projection().unsqueeze().expand", "mlp_attention.MlpAttention.key_projection().unsqueeze().expand", "torch.tanh().matmul().squeeze", "mlp_attention.MlpAttention.size", "mlp_attention.MlpAttention.size", "mlp_attention.MlpAttention.size", "mlp_attention.MlpAttention.v.size", "mlp_attention.MlpAttention.query_projection().unsqueeze", "mlp_attention.MlpAttention.key_projection().unsqueeze", "torch.tanh().matmul", "mlp_attention.MlpAttention.query_projection", "mlp_attention.MlpAttention.key_projection", "torch.tanh"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "_score", "(", "self", ",", "query", ",", "key", ")", ":", "\n", "        ", "\"\"\"\n        query: FloatTensor (batch_size, num_queries, query_size)\n        key: FloatTensor (batch_size, time_step, key_size)\n        \"\"\"", "\n", "batch_size", ",", "num_queries", ",", "time_step", ",", "out_size", "=", "query", ".", "size", "(", "0", ")", ",", "query", ".", "size", "(", "1", ")", ",", "key", ".", "size", "(", "1", ")", ",", "self", ".", "v", ".", "size", "(", "0", ")", "\n", "query", "=", "self", ".", "query_projection", "(", "query", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "batch_size", ",", "num_queries", ",", "time_step", ",", "out_size", ")", "\n", "key", "=", "self", ".", "key_projection", "(", "key", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_queries", ",", "time_step", ",", "out_size", ")", "\n", "score", "=", "torch", ".", "tanh", "(", "query", "+", "key", ")", ".", "matmul", "(", "self", ".", "v", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "return", "score", "", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.no_query_attention.NoQueryAttention.__init__": [[7, 13], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.init.xavier_uniform_", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "query_size", ",", "attention", ")", ":", "\n", "        ", "super", "(", "NoQueryAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "query_size", "=", "query_size", "\n", "self", ".", "query", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "query_size", ")", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "query", ")", "\n", "self", ".", "attention", "=", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.no_query_attention.NoQueryAttention.forward": [[14, 18], ["key.size", "no_query_attention.NoQueryAttention.query.expand", "no_query_attention.NoQueryAttention.attention"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "forward", "(", "self", ",", "key", ",", "value", ",", "mask", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "key", ".", "size", "(", "0", ")", "\n", "query", "=", "self", ".", "query", ".", "expand", "(", "batch_size", ",", "self", ".", "query_size", ")", "\n", "return", "self", ".", "attention", "(", "query", ",", "key", ",", "value", ",", "mask", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.scaled_dot_attention.ScaledDotAttention.__init__": [[6, 8], ["src.module.attention.attention.Attention.__init__"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "ScaledDotAttention", ",", "self", ")", ".", "__init__", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.scaled_dot_attention.ScaledDotAttention._score": [[9, 16], ["query.size", "key.size", "query.matmul", "math.sqrt", "key.transpose", "query.size"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "_score", "(", "self", ",", "query", ",", "key", ")", ":", "\n", "        ", "\"\"\"\n        query: FloatTensor (batch_size, num_queries, query_size)\n        key: FloatTensor (batch_size, time_step, key_size)\n        \"\"\"", "\n", "assert", "query", ".", "size", "(", "2", ")", "==", "key", ".", "size", "(", "2", ")", "\n", "return", "query", ".", "matmul", "(", "key", ".", "transpose", "(", "1", ",", "2", ")", ")", "/", "math", ".", "sqrt", "(", "query", ".", "size", "(", "2", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.attention.Attention.__init__": [[10, 13], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["\n", "\n", "class", "Attention", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "hidden_dim", "=", "None", ",", "out_dim", "=", "None", ",", "n_head", "=", "1", ",", "score_function", "=", "'dot_product'", ",", "dropout", "=", "0", ")", ":", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.attention.Attention.forward": [[14, 37], ["attention.Attention._score", "attention.Attention._weights_normalize", "torch.dropout", "torch.dropout.matmul", "len", "query.unsqueeze.unsqueeze.unsqueeze", "output.squeeze.squeeze.squeeze", "query.unsqueeze.unsqueeze.size", "len", "mask.unsqueeze.unsqueeze.unsqueeze", "mask.unsqueeze.unsqueeze.size", "mask.unsqueeze.unsqueeze.size", "query.unsqueeze.unsqueeze.size"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention._score", "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.attention.Attention._weights_normalize", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["        ", "''' Attention Mechanism\n        :param embed_dim:\n        :param hidden_dim:\n        :param out_dim:\n        :param n_head: num of head (Multi-Head Attention)\n        :param score_function: scaled_dot_product / mlp (concat) / bi_linear (general dot)\n        :return (?, q_len, out_dim,)\n        '''", "\n", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "hidden_dim", "is", "None", ":", "\n", "            ", "hidden_dim", "=", "embed_dim", "//", "n_head", "\n", "", "if", "out_dim", "is", "None", ":", "\n", "            ", "out_dim", "=", "embed_dim", "\n", "", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "score_function", "=", "score_function", "\n", "self", ".", "w_k", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "n_head", "*", "hidden_dim", ")", "\n", "self", ".", "w_q", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "n_head", "*", "hidden_dim", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "n_head", "*", "hidden_dim", ",", "out_dim", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "if", "score_function", "==", "'mlp'", ":", "\n", "            ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_dim", "*", "2", ")", ")", "\n", "", "elif", "self", ".", "score_function", "==", "'bi_linear'", ":", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.attention.Attention._score": [[38, 40], ["NotImplementedError"], "methods", ["None"], ["            ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_dim", ",", "hidden_dim", ")", ")", "\n", "", "else", ":", "# dot_product / scaled_dot_product", "\n", "            ", "self", ".", "register_parameter", "(", "'weight'", ",", "None", ")", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.attention.Attention._weights_normalize": [[41, 46], ["torch.softmax", "score.masked_fill.masked_fill.masked_fill"], "methods", ["None"], ["", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "self", ".", "hidden_dim", ")", "\n", "if", "self", ".", "weight", "is", "not", "None", ":", "\n", "            ", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.attention.Attention.get_attention_weights": [[47, 63], ["attention.Attention._score", "attention.Attention._weights_normalize", "torch.dropout", "len", "query.unsqueeze.unsqueeze.unsqueeze", "weights.squeeze.squeeze.squeeze", "query.unsqueeze.unsqueeze.size", "len", "mask.unsqueeze.unsqueeze.unsqueeze", "mask.unsqueeze.unsqueeze.size", "mask.unsqueeze.unsqueeze.size", "query.unsqueeze.unsqueeze.size"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention._score", "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.attention.Attention._weights_normalize", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["\n", "", "", "def", "forward", "(", "self", ",", "k", ",", "q", ")", ":", "\n", "        ", "if", "len", "(", "q", ".", "shape", ")", "==", "2", ":", "# q_len missing", "\n", "            ", "q", "=", "torch", ".", "unsqueeze", "(", "q", ",", "dim", "=", "1", ")", "\n", "", "if", "len", "(", "k", ".", "shape", ")", "==", "2", ":", "# k_len missing", "\n", "            ", "k", "=", "torch", ".", "unsqueeze", "(", "k", ",", "dim", "=", "1", ")", "\n", "", "mb_size", "=", "k", ".", "shape", "[", "0", "]", "# ?", "\n", "k_len", "=", "k", ".", "shape", "[", "1", "]", "\n", "q_len", "=", "q", ".", "shape", "[", "1", "]", "\n", "# k: (?, k_len, embed_dim,)", "\n", "# q: (?, q_len, embed_dim,)", "\n", "# kx: (n_head*?, k_len, hidden_dim)", "\n", "# qx: (n_head*?, q_len, hidden_dim)", "\n", "# score: (n_head*?, q_len, k_len,)", "\n", "# output: (?, q_len, out_dim,)", "\n", "kx", "=", "self", ".", "w_k", "(", "k", ")", ".", "view", "(", "mb_size", ",", "k_len", ",", "self", ".", "n_head", ",", "self", ".", "hidden_dim", ")", "\n", "kx", "=", "kx", ".", "permute", "(", "2", ",", "0", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "k_len", ",", "self", ".", "hidden_dim", ")", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.tanh_bilinear_attention.TanhBilinearAttention.__init__": [[8, 13], ["layers.module.attention.attention.Attention.__init__", "torch.nn.Parameter", "torch.nn.init.xavier_uniform_", "torch.nn.Parameter", "torch.FloatTensor", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "query_size", ",", "key_size", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "TanhBilinearAttention", ",", "self", ")", ".", "__init__", "(", "dropout", ")", "\n", "self", ".", "weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "query_size", ",", "key_size", ")", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "weights", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.tanh_bilinear_attention.TanhBilinearAttention._score": [[14, 21], ["torch.tanh", "query.matmul().matmul", "key.transpose", "query.matmul"], "methods", ["None"], ["", "def", "_score", "(", "self", ",", "query", ",", "key", ")", ":", "\n", "        ", "\"\"\"\n        query: FloatTensor (batch_size, num_queries, query_size)\n        key: FloatTensor (batch_size, time_step, key_size)\n        \"\"\"", "\n", "score", "=", "torch", ".", "tanh", "(", "query", ".", "matmul", "(", "self", ".", "weights", ")", ".", "matmul", "(", "key", ".", "transpose", "(", "1", ",", "2", ")", ")", "+", "self", ".", "bias", ")", "\n", "return", "score", "", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.multi_head_attention.MultiHeadAttention.__init__": [[7, 24], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.Linear", "torch.nn.init.xavier_normal_", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "attention", ",", "num_heads", ",", "hidden_size", ",", "key_size", "=", "'default'", ",", "value_size", "=", "'default'", ",", "out_size", "=", "'default'", ")", ":", "\n", "        ", "key_size", "=", "hidden_size", "//", "num_heads", "if", "key_size", "==", "'default'", "else", "key_size", "\n", "value_size", "=", "hidden_size", "//", "num_heads", "if", "value_size", "==", "'default'", "else", "value_size", "\n", "out_size", "=", "hidden_size", "if", "out_size", "==", "'default'", "else", "out_size", "\n", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "key_size", "=", "key_size", "\n", "self", ".", "value_size", "=", "value_size", "\n", "self", ".", "query_projection", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "num_heads", "*", "key_size", ")", "\n", "self", ".", "key_projection", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "num_heads", "*", "key_size", ")", "\n", "self", ".", "value_projection", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "num_heads", "*", "value_size", ")", "\n", "init", ".", "normal_", "(", "self", ".", "query_projection", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "math", ".", "sqrt", "(", "2.0", "/", "(", "hidden_size", "+", "key_size", ")", ")", ")", "\n", "init", ".", "normal_", "(", "self", ".", "key_projection", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "math", ".", "sqrt", "(", "2.0", "/", "(", "hidden_size", "+", "key_size", ")", ")", ")", "\n", "init", ".", "normal_", "(", "self", ".", "value_projection", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "math", ".", "sqrt", "(", "2.0", "/", "(", "hidden_size", "+", "value_size", ")", ")", ")", "\n", "self", ".", "output_projection", "=", "nn", ".", "Linear", "(", "num_heads", "*", "value_size", ",", "out_size", ")", "\n", "init", ".", "xavier_normal_", "(", "self", ".", "output_projection", ".", "weight", ")", "\n", "self", ".", "attention", "=", "attention", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.multi_head_attention.MultiHeadAttention.forward": [[25, 62], ["multi_head_attention.MultiHeadAttention.query_projection().view", "multi_head_attention.MultiHeadAttention.key_projection().view", "multi_head_attention.MultiHeadAttention.value_projection().view", "query.unsqueeze.unsqueeze.permute().contiguous().view", "key.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "value.permute().contiguous().view.permute().contiguous().view.permute().contiguous().view", "multi_head_attention.MultiHeadAttention.attention", "output.squeeze.squeeze.view", "output.squeeze.squeeze.permute().contiguous().view", "multi_head_attention.MultiHeadAttention.output_projection", "len", "query.unsqueeze.unsqueeze.unsqueeze", "query.unsqueeze.unsqueeze.size", "query.unsqueeze.unsqueeze.size", "key.permute().contiguous().view.permute().contiguous().view.size", "output.squeeze.squeeze.squeeze", "query.unsqueeze.unsqueeze.size", "len", "mask.unsqueeze().repeat().view.unsqueeze().repeat().view.unsqueeze", "multi_head_attention.MultiHeadAttention.query_projection", "multi_head_attention.MultiHeadAttention.key_projection", "multi_head_attention.MultiHeadAttention.value_projection", "len", "mask.unsqueeze().repeat().view.unsqueeze().repeat().view.unsqueeze().repeat().view", "mask.unsqueeze().repeat().view.unsqueeze().repeat().view.unsqueeze().repeat().view", "query.unsqueeze.unsqueeze.permute().contiguous", "key.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "value.permute().contiguous().view.permute().contiguous().view.permute().contiguous", "output.squeeze.squeeze.permute().contiguous", "mask.unsqueeze().repeat().view.unsqueeze().repeat().view.size", "mask.unsqueeze().repeat().view.unsqueeze().repeat().view.size", "query.unsqueeze.unsqueeze.size", "mask.unsqueeze().repeat().view.unsqueeze().repeat().view.size", "mask.unsqueeze().repeat().view.unsqueeze().repeat().view.unsqueeze().repeat", "mask.unsqueeze().repeat().view.unsqueeze().repeat().view.unsqueeze().repeat", "query.unsqueeze.unsqueeze.permute", "key.permute().contiguous().view.permute().contiguous().view.permute", "value.permute().contiguous().view.permute().contiguous().view.permute", "output.squeeze.squeeze.permute", "mask.unsqueeze().repeat().view.unsqueeze().repeat().view.unsqueeze", "mask.unsqueeze().repeat().view.unsqueeze().repeat().view.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        query: FloatTensor (batch_size, hidden_size) or (batch_size, num_queries, hidden_size)\n        key: FloatTensor (batch_size, time_step, hidden_size)\n        value: FloatTensor (batch_size, time_step, hidden_size)\n        mask: ByteTensor (batch_size, time_step) or ByteTensor (batch_size, num_queries, time_step)\n        subsequent_mask: ByteTensor (num_queries, time_step)\n        \"\"\"", "\n", "single_query", "=", "False", "\n", "if", "len", "(", "query", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "            ", "query", "=", "query", ".", "unsqueeze", "(", "1", ")", "\n", "single_query", "=", "True", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "mask", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "                ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "assert", "mask", ".", "size", "(", "1", ")", "==", "query", ".", "size", "(", "1", ")", "\n", "", "", "num_heads", ",", "key_size", ",", "value_size", "=", "self", ".", "num_heads", ",", "self", ".", "key_size", ",", "self", ".", "value_size", "\n", "batch_size", ",", "num_queries", ",", "time_step", "=", "query", ".", "size", "(", "0", ")", ",", "query", ".", "size", "(", "1", ")", ",", "key", ".", "size", "(", "1", ")", "\n", "query", "=", "self", ".", "query_projection", "(", "query", ")", ".", "view", "(", "batch_size", ",", "num_queries", ",", "num_heads", ",", "key_size", ")", "\n", "key", "=", "self", ".", "key_projection", "(", "key", ")", ".", "view", "(", "batch_size", ",", "time_step", ",", "num_heads", ",", "key_size", ")", "\n", "value", "=", "self", ".", "value_projection", "(", "value", ")", ".", "view", "(", "batch_size", ",", "time_step", ",", "num_heads", ",", "value_size", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "mask", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "                ", "mask", "=", "mask", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "num_heads", ",", "1", ",", "1", ")", ".", "view", "(", "-", "1", ",", "time_step", ")", "\n", "", "else", ":", "\n", "                ", "mask", "=", "mask", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "num_heads", ",", "1", ",", "1", ",", "1", ")", ".", "view", "(", "-", "1", ",", "num_queries", ",", "time_step", ")", "\n", "", "", "query", "=", "query", ".", "permute", "(", "2", ",", "0", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "num_queries", ",", "key_size", ")", "\n", "key", "=", "key", ".", "permute", "(", "2", ",", "0", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "time_step", ",", "key_size", ")", "\n", "value", "=", "value", ".", "permute", "(", "2", ",", "0", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "time_step", ",", "value_size", ")", "\n", "output", "=", "self", ".", "attention", "(", "query", ",", "key", ",", "value", ",", "mask", ")", "\n", "output", "=", "output", ".", "view", "(", "num_heads", ",", "batch_size", ",", "num_queries", ",", "value_size", ")", "\n", "output", "=", "output", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "num_queries", ",", "-", "1", ")", "\n", "output", "=", "self", ".", "output_projection", "(", "output", ")", "\n", "if", "single_query", ":", "\n", "            ", "output", "=", "output", ".", "squeeze", "(", "1", ")", "\n", "", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.dot_attention.DotAttention.__init__": [[5, 7], ["layers.module.attention.attention.Attention.__init__"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "DotAttention", ",", "self", ")", ".", "__init__", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.dot_attention.DotAttention._score": [[8, 15], ["query.matmul", "query.size", "key.size", "key.transpose"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size", "home.repos.pwc.inspect_result.whu-zqh_kgan.rgat_file.tree.Tree.size"], ["", "def", "_score", "(", "self", ",", "query", ",", "key", ")", ":", "\n", "        ", "\"\"\"\n        query: FloatTensor (batch_size, num_queries, query_size)\n        key: FloatTensor (batch_size, time_step, key_size)\n        \"\"\"", "\n", "assert", "query", ".", "size", "(", "2", ")", "==", "key", ".", "size", "(", "2", ")", "\n", "return", "query", ".", "matmul", "(", "key", ".", "transpose", "(", "1", ",", "2", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__": [[8, 12], ["layers.module.attention.attention.Attention.__init__", "torch.nn.Parameter", "torch.nn.init.xavier_uniform_", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention.__init__"], ["    ", "def", "__init__", "(", "self", ",", "query_size", ",", "key_size", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "BilinearAttention", ",", "self", ")", ".", "__init__", "(", "dropout", ")", "\n", "self", ".", "weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "query_size", ",", "key_size", ")", ")", "\n", "init", ".", "xavier_uniform_", "(", "self", ".", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.whu-zqh_kgan.attention.bilinear_attention.BilinearAttention._score": [[13, 20], ["query.matmul().matmul", "key.transpose", "query.matmul"], "methods", ["None"], ["", "def", "_score", "(", "self", ",", "query", ",", "key", ")", ":", "\n", "        ", "\"\"\"\n        query: FloatTensor (batch_size, num_queries, query_size)\n        key: FloatTensor (batch_size, time_step, key_size)\n        \"\"\"", "\n", "score", "=", "query", ".", "matmul", "(", "self", ".", "weights", ")", ".", "matmul", "(", "key", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "return", "score", "", "", "", ""]]}