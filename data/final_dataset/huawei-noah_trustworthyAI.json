{"home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.src.main.main": [[39, 311], ["helpers.dir_utils.create_dir", "helpers.log_helper.LogHelper.setup", "logging.getLogger", "logging.getLogger.info", "logging.getLogger.info", "helpers.config_graph.get_config", "helpers.dir_utils.create_dir", "helpers.dir_utils.create_dir", "helpers.dir_utils.create_dir", "helpers.dir_utils.create_dir", "helpers.tf_utils.set_seed", "logging.getLogger.info", "models.Actor", "rewards.get_Reward", "logging.getLogger.info", "tensorflow.train.Saver", "logging.getLogger.info", "tensorflow.ConfigProto", "data_loader.DataGenerator_read_data", "ValueError", "helpers.lambda_utils.BIC_lambdas", "logging.getLogger.info", "logging.getLogger.info", "tensorflow.Session", "sess.run", "logging.getLogger.info", "float", "tensorflow.summary.FileWriter", "logging.getLogger.info", "range", "logging.getLogger.info", "tf.train.Saver.save", "datetime.datetime.now().strftime", "platform.python_version", "vars", "tensorflow.global_variables", "tensorflow.global_variables_initializer", "data_loader.DataGenerator_read_data.train_batch", "sess.run", "rewards.get_Reward.cal_rewards", "float", "numpy.mean", "sess.run", "lambda1s.append", "lambda2s.append", "rewards_avg_baseline.append", "rewards_batches.append", "reward_max_per_batch.append", "graphss.append", "probsss.append", "max_rewards.append", "numpy.round", "numpy.round", "sess.run", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "matplotlib.savefig", "matplotlib.close", "matplotlib.figure", "plt.figure.suptitle", "plt.figure.add_subplot", "fig.add_subplot.set_title", "fig.add_subplot.imshow", "plt.figure.add_subplot", "fig.add_subplot.set_title", "fig.add_subplot.imshow", "matplotlib.savefig", "matplotlib.close", "rewards.get_Reward.update_all_scores", "rewards.get_Reward.update_scores", "rewards.get_Reward.update_scores", "rewards.get_Reward.update_scores", "numpy.save", "pandas.DataFrame().to_csv", "pandas.DataFrame().to_csv", "pandas.DataFrame().to_csv", "pandas.DataFrame().to_csv", "pandas.DataFrame().to_csv", "min", "min", "logging.getLogger.info", "helpers.analyze_utils.convert_graph_int_to_adj_mat", "helpers.analyze_utils.count_accuracy", "helpers.analyze_utils.count_accuracy", "accuracy_res.append", "accuracy_res_pruned.append", "numpy.save", "numpy.save", "logging.getLogger.info", "logging.getLogger.info", "tf.train.Saver.save", "logging.getLogger.info", "datetime.datetime.now", "tensorflow.shape", "rewards.get_Reward.update_scores", "tf.summary.FileWriter.add_summary", "numpy.around().astype", "numpy.array", "numpy.int32", "numpy.array", "numpy.array", "numpy.array", "pytz.timezone", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "helpers.analyze_utils.graph_prunned_by_coef", "numpy.array", "max", "numpy.around", "numpy.array", "helpers.analyze_utils.graph_prunned_by_coef_2nd", "numpy.transpose", "int", "helpers.cam_with_pruning_cam.pruning_cam", "numpy.array"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.dir_utils.create_dir", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.log_helper.LogHelper.setup", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.config_graph.get_config", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.dir_utils.create_dir", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.dir_utils.create_dir", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.dir_utils.create_dir", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.dir_utils.create_dir", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.set_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.lambda_utils.BIC_lambdas", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.dataset_read_data.DataGenerator.train_batch", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.cal_rewards", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.update_all_scores", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.update_scores", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.update_scores", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.update_scores", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.convert_graph_int_to_adj_mat", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.count_accuracy", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.count_accuracy", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.update_scores", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.graph_prunned_by_coef", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.graph_prunned_by_coef_2nd", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.cam_with_pruning_cam.pruning_cam"], ["# Save the configuration for logging purpose", "\n", "save_yaml_config", "(", "args", ",", "path", "=", "'{}/config.yaml'", ".", "format", "(", "output_dir", ")", ")", "\n", "\n", "# Reproducibility", "\n", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# Get dataset", "\n", "dataset", "=", "SyntheticDataset", "(", "args", ".", "n", ",", "args", ".", "d", ",", "args", ".", "graph_type", ",", "args", ".", "degree", ",", "args", ".", "sem_type", ",", "\n", "args", ".", "noise_scale", ",", "args", ".", "dataset_type", ",", "args", ".", "x_dim", ")", "\n", "_logger", ".", "info", "(", "'Finished generating dataset'", ")", "\n", "\n", "model", "=", "GAE", "(", "args", ".", "n", ",", "args", ".", "d", ",", "args", ".", "x_dim", ",", "args", ".", "seed", ",", "args", ".", "num_encoder_layers", ",", "args", ".", "num_decoder_layers", ",", "\n", "args", ".", "hidden_size", ",", "args", ".", "latent_dim", ",", "args", ".", "l1_graph_penalty", ",", "args", ".", "use_float64", ")", "\n", "model", ".", "print_summary", "(", "print_func", "=", "model", ".", "logger", ".", "info", ")", "\n", "\n", "trainer", "=", "ALTrainer", "(", "args", ".", "init_rho", ",", "args", ".", "rho_thres", ",", "args", ".", "h_thres", ",", "args", ".", "rho_multiply", ",", "\n", "args", ".", "init_iter", ",", "args", ".", "learning_rate", ",", "args", ".", "h_tol", ",", "\n", "args", ".", "early_stopping", ",", "args", ".", "early_stopping_thres", ")", "\n", "W_est", "=", "trainer", ".", "train", "(", "model", ",", "dataset", ".", "X", ",", "dataset", ".", "W", ",", "args", ".", "graph_thres", ",", "\n", "args", ".", "max_iter", ",", "args", ".", "iter_step", ",", "output_dir", ")", "\n", "_logger", ".", "info", "(", "'Finished training model'", ")", "\n", "\n", "# Save raw recovered graph, ground truth and observational data after training", "\n", "np", ".", "save", "(", "'{}/true_graph.npy'", ".", "format", "(", "output_dir", ")", ",", "dataset", ".", "W", ")", "\n", "np", ".", "save", "(", "'{}/observational_data.npy'", ".", "format", "(", "output_dir", ")", ",", "dataset", ".", "X", ")", "\n", "np", ".", "save", "(", "'{}/final_raw_recovered_graph.npy'", ".", "format", "(", "output_dir", ")", ",", "W_est", ")", "\n", "\n", "# Plot raw recovered graph", "\n", "plot_recovered_graph", "(", "W_est", ",", "dataset", ".", "W", ",", "\n", "save_name", "=", "'{}/raw_recovered_graph.png'", ".", "format", "(", "output_dir", ")", ")", "\n", "\n", "_logger", ".", "info", "(", "'Filter by constant threshold'", ")", "\n", "W_est", "=", "W_est", "/", "np", ".", "max", "(", "np", ".", "abs", "(", "W_est", ")", ")", "# Normalize", "\n", "\n", "# Plot thresholded recovered graph", "\n", "W_est", "[", "np", ".", "abs", "(", "W_est", ")", "<", "args", ".", "graph_thres", "]", "=", "0", "# Thresholding", "\n", "plot_recovered_graph", "(", "W_est", ",", "dataset", ".", "W", ",", "\n", "save_name", "=", "'{}/thresholded_recovered_graph.png'", ".", "format", "(", "output_dir", ")", ")", "\n", "results_thresholded", "=", "count_accuracy", "(", "dataset", ".", "W", ",", "W_est", ")", "\n", "_logger", ".", "info", "(", "'Results after thresholding by {}: {}'", ".", "format", "(", "args", ".", "graph_thres", ",", "results_thresholded", ")", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.trainers.al_trainer.ALTrainer.__init__": [[24, 35], ["None"], "methods", ["None"], ["self", ".", "early_stopping", "=", "early_stopping", "\n", "self", ".", "early_stopping_thres", "=", "early_stopping_thres", "\n", "\n", "", "def", "train", "(", "self", ",", "model", ",", "X", ",", "W", ",", "graph_thres", ",", "max_iter", ",", "iter_step", ",", "output_dir", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.trainers.al_trainer.ALTrainer.train": [[36, 84], ["model.sess.run", "range", "tensorflow.global_variables_initializer", "float", "numpy.copy", "al_trainer.ALTrainer.train_step", "numpy.max", "numpy.abs", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.trainers.al_trainer.Trainer.train_step"], ["\n", "# Create directory to save the raw recovered graph in each iteration", "\n", "create_dir", "(", "'{}/raw_recovered_graph'", ".", "format", "(", "output_dir", ")", ")", "\n", "\n", "model", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "rho", ",", "alpha", ",", "h", ",", "h_new", "=", "self", ".", "init_rho", ",", "0.0", ",", "np", ".", "inf", ",", "np", ".", "inf", "\n", "prev_W_est", ",", "prev_mse", "=", "None", ",", "float", "(", "'inf'", ")", "\n", "\n", "self", ".", "_logger", ".", "info", "(", "'Started training for {} iterations'", ".", "format", "(", "max_iter", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "max_iter", "+", "1", ")", ":", "\n", "            ", "while", "rho", "<", "self", ".", "rho_thres", ":", "\n", "                ", "self", ".", "_logger", ".", "info", "(", "'rho {:.3E}, alpha {:.3E}'", ".", "format", "(", "rho", ",", "alpha", ")", ")", "\n", "loss_new", ",", "mse_new", ",", "h_new", ",", "W_new", "=", "self", ".", "train_step", "(", "model", ",", "iter_step", ",", "X", ",", "rho", ",", "alpha", ")", "\n", "if", "h_new", ">", "self", ".", "h_thres", "*", "h", ":", "\n", "                    ", "rho", "*=", "self", ".", "rho_multiply", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "\n", "", "", "if", "self", ".", "early_stopping", ":", "\n", "                ", "if", "mse_new", "/", "prev_mse", ">", "self", ".", "early_stopping_thres", "and", "h_new", "<=", "1e-7", ":", "\n", "# MSE increases too much, revert back to original graph and perform early stopping", "\n", "# Only perform this early stopping when h_new is sufficiently small", "\n", "# (i.e., at least smaller than 1e-7)", "\n", "                    ", "return", "prev_W_est", "\n", "", "else", ":", "\n", "                    ", "prev_W_est", "=", "W_new", "\n", "prev_mse", "=", "mse_new", "\n", "\n", "# Intermediate outputs", "\n", "", "", "self", ".", "log_and_save_intermediate_outputs", "(", "i", ",", "W", ",", "W_new", ",", "graph_thres", ",", "loss_new", ",", "mse_new", ",", "h_new", ",", "output_dir", ")", "\n", "\n", "W_est", ",", "h", "=", "W_new", ",", "h_new", "\n", "alpha", "+=", "rho", "*", "h", "\n", "if", "h", "<=", "self", ".", "h_tol", "and", "i", ">", "self", ".", "init_iter", ":", "\n", "                ", "self", ".", "_logger", ".", "info", "(", "'Early stopping at {}-th iteration'", ".", "format", "(", "i", ")", ")", "\n", "break", "\n", "\n", "# Save model", "\n", "", "", "model_dir", "=", "'{}/model/'", ".", "format", "(", "output_dir", ")", "\n", "model", ".", "save", "(", "model_dir", ")", "\n", "self", ".", "_logger", ".", "info", "(", "'Model saved to {}'", ".", "format", "(", "model_dir", ")", ")", "\n", "\n", "return", "W_est", "\n", "\n", "", "def", "train_step", "(", "self", ",", "model", ",", "iter_step", ",", "X", ",", "rho", ",", "alpha", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.trainers.al_trainer.ALTrainer.train_step": [[85, 95], ["range", "model.sess.run"], "methods", ["None"], ["        ", "\"\"\"\n        Solve the suboptimization problem in each iteration\n        \"\"\"", "\n", "for", "_", "in", "range", "(", "iter_step", ")", ":", "\n", "            ", "_", ",", "curr_loss", ",", "curr_mse", ",", "curr_h", ",", "curr_W", "=", "model", ".", "sess", ".", "run", "(", "[", "model", ".", "train_op", ",", "model", ".", "loss", ",", "model", ".", "mse_loss", ",", "model", ".", "h", ",", "model", ".", "W_prime", "]", ",", "\n", "feed_dict", "=", "{", "model", ".", "X", ":", "X", ",", "\n", "model", ".", "rho", ":", "rho", ",", "\n", "model", ".", "alpha", ":", "alpha", ",", "\n", "model", ".", "lr", ":", "self", ".", "learning_rate", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.trainers.al_trainer.ALTrainer.log_and_save_intermediate_outputs": [[98, 111], ["numpy.copy", "helpers.analyze_utils.count_accuracy", "al_trainer.ALTrainer._logger.info", "numpy.save", "numpy.max", "numpy.abs", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.count_accuracy", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save"], ["", "def", "log_and_save_intermediate_outputs", "(", "self", ",", "i", ",", "W_true", ",", "W_est", ",", "graph_thres", ",", "loss", ",", "mse", ",", "h", ",", "output_dir", ")", ":", "\n", "# Evaluate the learned W in each iteration after thresholding", "\n", "        ", "W_thresholded", "=", "np", ".", "copy", "(", "W_est", ")", "\n", "W_thresholded", "=", "W_thresholded", "/", "np", ".", "max", "(", "np", ".", "abs", "(", "W_thresholded", ")", ")", "\n", "W_thresholded", "[", "np", ".", "abs", "(", "W_thresholded", ")", "<", "graph_thres", "]", "=", "0", "\n", "results", "=", "count_accuracy", "(", "W_true", ",", "W_thresholded", ")", "\n", "\n", "# Logging", "\n", "self", ".", "_logger", ".", "info", "(", "'[Iter {}] loss {:.3E}, mse {:.3E}, acyclic {:.3E}, shd {}, tpr {:.3f}, fdr {:.3f}, pred_size {}'", ".", "format", "(", "\n", "i", ",", "loss", ",", "mse", ",", "h", ",", "results", "[", "'shd'", "]", ",", "results", "[", "'tpr'", "]", ",", "results", "[", "'fdr'", "]", ",", "results", "[", "'pred_size'", "]", ")", ")", "\n", "\n", "# Save the raw recovered graph in each iteration", "\n", "np", ".", "save", "(", "'{}/raw_recovered_graph/graph_iteration_{}.npy'", ".", "format", "(", "output_dir", ",", "i", ")", ",", "W_est", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.trainers.al_trainer.Trainer.__init__": [[32, 48], ["torch.tensor", "torch.tensor", "torch.optim.Adam", "al_trainer.Trainer.model.parameters"], "methods", ["None"], ["\n", "# Create directory to save the raw recovered graph in each iteration", "\n", "create_dir", "(", "'{}/raw_recovered_graph'", ".", "format", "(", "output_dir", ")", ")", "\n", "\n", "model", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "rho", ",", "alpha", ",", "h", ",", "h_new", "=", "self", ".", "init_rho", ",", "0.0", ",", "np", ".", "inf", ",", "np", ".", "inf", "\n", "prev_W_est", ",", "prev_mse", "=", "None", ",", "float", "(", "'inf'", ")", "\n", "\n", "self", ".", "_logger", ".", "info", "(", "'Started training for {} iterations'", ".", "format", "(", "max_iter", ")", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.trainers.al_trainer.Trainer.train": [[49, 83], ["range", "logging.info", "helpers.utils.compute_acyclicity", "logging.info", "logging.info", "h_new.detach().cpu", "al_trainer.Trainer.train_step", "helpers.utils.convert_logits_to_sigmoid", "w_logits_new.detach", "h_new.detach"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.compute_acyclicity", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.trainers.al_trainer.Trainer.train_step", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.convert_logits_to_sigmoid"], ["for", "i", "in", "range", "(", "1", ",", "max_iter", "+", "1", ")", ":", "\n", "            ", "while", "rho", "<", "self", ".", "rho_thres", ":", "\n", "                ", "self", ".", "_logger", ".", "info", "(", "'rho {:.3E}, alpha {:.3E}'", ".", "format", "(", "rho", ",", "alpha", ")", ")", "\n", "loss_new", ",", "mse_new", ",", "h_new", ",", "W_new", "=", "self", ".", "train_step", "(", "model", ",", "iter_step", ",", "X", ",", "rho", ",", "alpha", ")", "\n", "if", "h_new", ">", "self", ".", "h_thres", "*", "h", ":", "\n", "                    ", "rho", "*=", "self", ".", "rho_multiply", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "\n", "", "", "if", "self", ".", "early_stopping", ":", "\n", "                ", "if", "mse_new", "/", "prev_mse", ">", "self", ".", "early_stopping_thres", "and", "h_new", "<=", "1e-7", ":", "\n", "# MSE increases too much, revert back to original graph and perform early stopping", "\n", "# Only perform this early stopping when h_new is sufficiently small", "\n", "# (i.e., at least smaller than 1e-7)", "\n", "                    ", "return", "prev_W_est", "\n", "", "else", ":", "\n", "                    ", "prev_W_est", "=", "W_new", "\n", "prev_mse", "=", "mse_new", "\n", "\n", "# Intermediate outputs", "\n", "", "", "self", ".", "log_and_save_intermediate_outputs", "(", "i", ",", "W", ",", "W_new", ",", "graph_thres", ",", "loss_new", ",", "mse_new", ",", "h_new", ",", "output_dir", ")", "\n", "\n", "W_est", ",", "h", "=", "W_new", ",", "h_new", "\n", "alpha", "+=", "rho", "*", "h", "\n", "if", "h", "<=", "self", ".", "h_tol", "and", "i", ">", "self", ".", "init_iter", ":", "\n", "                ", "self", ".", "_logger", ".", "info", "(", "'Early stopping at {}-th iteration'", ".", "format", "(", "i", ")", ")", "\n", "break", "\n", "\n", "# Save model", "\n", "", "", "model_dir", "=", "'{}/model/'", ".", "format", "(", "output_dir", ")", "\n", "model", ".", "save", "(", "model_dir", ")", "\n", "self", ".", "_logger", ".", "info", "(", "'Model saved to {}'", ".", "format", "(", "model_dir", ")", ")", "\n", "\n", "return", "W_est", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.trainers.al_trainer.Trainer.train_step": [[84, 100], ["range", "al_trainer.Trainer.model", "al_trainer.Trainer.optimizer.zero_grad", "curr_loss.backward", "al_trainer.Trainer.optimizer.step", "logging.info", "curr_loss.detach"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.TrExpScipy.backward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy.step"], ["", "def", "train_step", "(", "self", ",", "model", ",", "iter_step", ",", "X", ",", "rho", ",", "alpha", ")", ":", "\n", "        ", "\"\"\"\n        Solve the suboptimization problem in each iteration\n        \"\"\"", "\n", "for", "_", "in", "range", "(", "iter_step", ")", ":", "\n", "            ", "_", ",", "curr_loss", ",", "curr_mse", ",", "curr_h", ",", "curr_W", "=", "model", ".", "sess", ".", "run", "(", "[", "model", ".", "train_op", ",", "model", ".", "loss", ",", "model", ".", "mse_loss", ",", "model", ".", "h", ",", "model", ".", "W_prime", "]", ",", "\n", "feed_dict", "=", "{", "model", ".", "X", ":", "X", ",", "\n", "model", ".", "rho", ":", "rho", ",", "\n", "model", ".", "alpha", ":", "alpha", ",", "\n", "model", ".", "lr", ":", "self", ".", "learning_rate", "}", ")", "\n", "\n", "", "return", "curr_loss", ",", "curr_mse", ",", "curr_h", ",", "curr_W", "\n", "\n", "", "def", "log_and_save_intermediate_outputs", "(", "self", ",", "i", ",", "W_true", ",", "W_est", ",", "graph_thres", ",", "loss", ",", "mse", ",", "h", ",", "output_dir", ")", ":", "\n", "# Evaluate the learned W in each iteration after thresholding", "\n", "        ", "W_thresholded", "=", "np", ".", "copy", "(", "W_est", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.__init__": [[13, 34], ["tensorflow.keras.initializers.glorot_uniform", "gae.GAE._build", "gae.GAE._init_session", "gae.GAE._init_saver"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._build", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._init_session", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._init_saver"], ["def", "__init__", "(", "self", ",", "n", ",", "d", ",", "x_dim", ",", "seed", "=", "8", ",", "num_encoder_layers", "=", "1", ",", "num_decoder_layers", "=", "1", ",", "hidden_size", "=", "5", ",", "\n", "latent_dim", "=", "1", ",", "l1_graph_penalty", "=", "0", ",", "use_float64", "=", "False", ")", ":", "\n", "        ", "self", ".", "print_summary", "=", "print_summary", "# Print summary for tensorflow variables", "\n", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "d", "=", "d", "\n", "self", ".", "x_dim", "=", "x_dim", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "num_encoder_layers", "=", "num_encoder_layers", "\n", "self", ".", "num_decoder_layers", "=", "num_decoder_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "latent_dim", "=", "latent_dim", "\n", "self", ".", "l1_graph_penalty", "=", "l1_graph_penalty", "\n", "self", ".", "tf_float_type", "=", "tf", ".", "dtypes", ".", "float64", "if", "use_float64", "else", "tf", ".", "dtypes", ".", "float32", "\n", "\n", "# Initializer (for reproducibility)", "\n", "self", ".", "initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", "\n", "\n", "self", ".", "_build", "(", ")", "\n", "self", ".", "_init_session", "(", ")", "\n", "self", ".", "_init_saver", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE._init_session": [[35, 46], ["helpers.tf_utils.is_cuda_available", "tensorflow.Session", "tensorflow.Session", "tensorflow.ConfigProto", "tensorflow.GPUOptions"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.is_cuda_available"], ["", "def", "_init_session", "(", "self", ")", ":", "\n", "        ", "if", "is_cuda_available", "(", ")", ":", "\n", "# Use GPU", "\n", "            ", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "\n", "per_process_gpu_memory_fraction", "=", "0.5", ",", "\n", "allow_growth", "=", "True", ",", "\n", ")", "\n", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE._init_saver": [[47, 49], ["tensorflow.train.Saver"], "methods", ["None"], ["", "", "def", "_init_saver", "(", "self", ")", ":", "\n", "        ", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE._build": [[50, 75], ["tensorflow.reset_default_graph", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.Variable", "gae.GAE._preprocess_graph", "gae.GAE._get_mse_loss", "tensorflow.train.AdamOptimizer().minimize", "gae.GAE._logger.debug", "tensorflow.random.uniform", "tensorflow.linalg.trace", "tensorflow.linalg.expm", "tensorflow.train.AdamOptimizer", "tensorflow.norm"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_model.MaskedModel._preprocess_graph", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_model.MaskedModel._get_mse_loss"], ["", "def", "_build", "(", "self", ")", ":", "\n", "        ", "tf", ".", "reset_default_graph", "(", ")", "\n", "\n", "# Placeholders", "\n", "self", ".", "rho", "=", "tf", ".", "placeholder", "(", "self", ".", "tf_float_type", ")", "\n", "self", ".", "alpha", "=", "tf", ".", "placeholder", "(", "self", ".", "tf_float_type", ")", "\n", "self", ".", "lr", "=", "tf", ".", "placeholder", "(", "self", ".", "tf_float_type", ")", "\n", "self", ".", "X", "=", "tf", ".", "placeholder", "(", "self", ".", "tf_float_type", ",", "shape", "=", "[", "self", ".", "n", ",", "self", ".", "d", ",", "self", ".", "x_dim", "]", ")", "\n", "\n", "# Variable for estimating graph", "\n", "W", "=", "tf", ".", "Variable", "(", "tf", ".", "random", ".", "uniform", "(", "[", "self", ".", "d", ",", "self", ".", "d", "]", ",", "minval", "=", "-", "0.1", ",", "maxval", "=", "0.1", ",", "\n", "dtype", "=", "self", ".", "tf_float_type", ",", "seed", "=", "self", ".", "seed", ")", ")", "\n", "self", ".", "W_prime", "=", "self", ".", "_preprocess_graph", "(", "W", ")", "\n", "\n", "# Losses", "\n", "self", ".", "mse_loss", "=", "self", ".", "_get_mse_loss", "(", "self", ".", "X", ",", "self", ".", "W_prime", ")", "\n", "self", ".", "h", "=", "tf", ".", "linalg", ".", "trace", "(", "tf", ".", "linalg", ".", "expm", "(", "self", ".", "W_prime", "*", "self", ".", "W_prime", ")", ")", "-", "self", ".", "d", "# Acyclicity", "\n", "self", ".", "loss", "=", "0.5", "/", "self", ".", "n", "*", "self", ".", "mse_loss", "+", "self", ".", "l1_graph_penalty", "*", "tf", ".", "norm", "(", "self", ".", "W_prime", ",", "ord", "=", "1", ")", "+", "self", ".", "alpha", "*", "self", ".", "h", "+", "0.5", "*", "self", ".", "rho", "*", "self", ".", "h", "*", "self", ".", "h", "\n", "\n", "# Train", "\n", "self", ".", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n", "self", ".", "_logger", ".", "debug", "(", "'Finished building Tensorflow graph'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE._preprocess_graph": [[76, 79], ["tensorflow.matrix_set_diag", "tensorflow.zeros"], "methods", ["None"], ["", "def", "_preprocess_graph", "(", "self", ",", "W", ")", ":", "\n", "# Mask the diagonal entries of graph", "\n", "        ", "return", "tf", ".", "matrix_set_diag", "(", "W", ",", "tf", ".", "zeros", "(", "W", ".", "shape", "[", "0", "]", ",", "dtype", "=", "self", ".", "tf_float_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE._get_mse_loss": [[80, 86], ["gae.GAE._encoder_forward", "tensorflow.einsum", "gae.GAE._decoder_forward", "tensorflow.square", "tensorflow.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._encoder_forward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._decoder_forward"], ["", "def", "_get_mse_loss", "(", "self", ",", "X", ",", "W_prime", ")", ":", "\n", "        ", "X_prime", "=", "self", ".", "_encoder_forward", "(", "X", ")", "\n", "X_prime", "=", "tf", ".", "einsum", "(", "'ijk,jl->ilk'", ",", "X_prime", ",", "W_prime", ")", "\n", "X_prime", "=", "self", ".", "_decoder_forward", "(", "X_prime", ")", "\n", "\n", "return", "tf", ".", "square", "(", "tf", ".", "linalg", ".", "norm", "(", "X", "-", "X_prime", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE._encoder_forward": [[87, 91], ["gae.GAE._flatten_forward"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._flatten_forward"], ["", "def", "_encoder_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_flatten_forward", "(", "x", ",", "self", ".", "num_encoder_layers", ",", "self", ".", "hidden_size", ",", "\n", "input_dim", "=", "self", ".", "x_dim", ",", "\n", "output_dim", "=", "self", ".", "latent_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE._decoder_forward": [[92, 96], ["gae.GAE._flatten_forward"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._flatten_forward"], ["", "def", "_decoder_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_flatten_forward", "(", "x", ",", "self", ".", "num_decoder_layers", ",", "self", ".", "hidden_size", ",", "\n", "input_dim", "=", "self", ".", "latent_dim", ",", "\n", "output_dim", "=", "self", ".", "x_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE._flatten_forward": [[97, 109], ["tensorflow.reshape", "range", "tensorflow.reshape", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LeakyReLU"], "methods", ["None"], ["", "def", "_flatten_forward", "(", "self", ",", "x", ",", "num_hidden_layers", ",", "hidden_size", ",", "input_dim", ",", "output_dim", ")", ":", "\n", "        ", "if", "num_hidden_layers", "==", "0", ":", "\n", "            ", "return", "x", "\n", "", "else", ":", "\n", "            ", "flatten", "=", "tf", ".", "reshape", "(", "x", ",", "shape", "=", "(", "-", "1", ",", "input_dim", ")", ")", "\n", "for", "_", "in", "range", "(", "num_hidden_layers", ")", ":", "# Hidden layer", "\n", "                ", "flatten", "=", "Dense", "(", "hidden_size", ",", "activation", "=", "None", ",", "kernel_initializer", "=", "self", ".", "initializer", ")", "(", "flatten", ")", "\n", "flatten", "=", "LeakyReLU", "(", "alpha", "=", "0.05", ")", "(", "flatten", ")", "\n", "\n", "", "flatten", "=", "Dense", "(", "output_dim", ",", "kernel_initializer", "=", "self", ".", "initializer", ")", "(", "flatten", ")", "# Final output layer", "\n", "\n", "return", "tf", ".", "reshape", "(", "flatten", ",", "shape", "=", "(", "self", ".", "n", ",", "self", ".", "d", ",", "output_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save": [[110, 113], ["helpers.dir_utils.create_dir", "gae.GAE.saver.save"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.dir_utils.create_dir", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save"], ["", "", "def", "save", "(", "self", ",", "model_dir", ")", ":", "\n", "        ", "create_dir", "(", "model_dir", ")", "\n", "self", ".", "saver", ".", "save", "(", "self", ".", "sess", ",", "'{}/model'", ".", "format", "(", "model_dir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.logger": [[114, 120], ["NotImplementedError"], "methods", ["None"], ["", "@", "property", "\n", "def", "logger", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "_logger", "\n", "", "except", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'self._logger does not exist!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.actor_graph.Actor.__init__": [[30, 175], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "critic.Critic", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.MSELoss", "torch.MSELoss", "torch.MSELoss", "encoder.TransformerEncoder", "decoder.SingleLayerDecoder", "encoder.GATEncoder", "NotImplementedError", "decoder.TransformerDecoder", "pow", "decoder.BilinearDecoder", "actor_graph.Actor.encoder.parameters", "actor_graph.Actor.decoder.parameters", "actor_graph.Actor.critic.parameters", "decoder.NTNDecoder", "NotImplementedError"], "methods", ["None"], ["self", ".", "batch_size", "=", "config", ".", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "config", ".", "max_length", "\n", "self", ".", "input_dimension", "=", "config", ".", "input_dimension", "\n", "\n", "# Reward config", "\n", "self", ".", "avg_baseline", "=", "tf", ".", "Variable", "(", "config", ".", "init_baseline", ",", "trainable", "=", "False", ",", "\n", "name", "=", "\"moving_avg_baseline\"", ")", "# moving baseline for Reinforce", "\n", "self", ".", "alpha", "=", "config", ".", "alpha", "# moving average update", "\n", "\n", "# Training config (actor)", "\n", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step\"", ")", "# global step", "\n", "self", ".", "lr1_start", "=", "config", ".", "lr1_start", "# initial learning rate", "\n", "self", ".", "lr1_decay_rate", "=", "config", ".", "lr1_decay_rate", "# learning rate decay rate", "\n", "self", ".", "lr1_decay_step", "=", "config", ".", "lr1_decay_step", "# learning rate decay step", "\n", "\n", "# Training config (critic)", "\n", "self", ".", "global_step2", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ",", "name", "=", "\"global_step2\"", ")", "# global step", "\n", "self", ".", "lr2_start", "=", "config", ".", "lr1_start", "# initial learning rate", "\n", "self", ".", "lr2_decay_rate", "=", "config", ".", "lr1_decay_rate", "# learning rate decay rate", "\n", "self", ".", "lr2_decay_step", "=", "config", ".", "lr1_decay_step", "# learning rate decay step", "\n", "\n", "# Tensor block holding the input sequences [Batch Size, Sequence Length, Features]", "\n", "self", ".", "input_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "self", ".", "batch_size", ",", "self", ".", "max_length", ",", "self", ".", "input_dimension", "]", ",", "\n", "name", "=", "\"input_coordinates\"", ")", "\n", "self", ".", "reward_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "self", ".", "batch_size", "]", ",", "name", "=", "'input_rewards'", ")", "\n", "self", ".", "graphs_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "self", ".", "batch_size", ",", "self", ".", "max_length", ",", "self", ".", "max_length", "]", ",", "name", "=", "'input_graphs'", ")", "\n", "\n", "self", ".", "build_permutation", "(", ")", "\n", "self", ".", "build_critic", "(", ")", "\n", "self", ".", "build_reward", "(", ")", "\n", "self", ".", "build_optim", "(", ")", "\n", "self", ".", "merged", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n", "", "def", "build_permutation", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder\"", ")", ":", "\n", "            ", "if", "self", ".", "config", ".", "encoder_type", "==", "'TransformerEncoder'", ":", "\n", "                ", "encoder", "=", "TransformerEncoder", "(", "self", ".", "config", ",", "self", ".", "is_train", ")", "\n", "", "elif", "self", ".", "config", ".", "encoder_type", "==", "'GATEncoder'", ":", "\n", "                ", "encoder", "=", "GATEncoder", "(", "self", ".", "config", ",", "self", ".", "is_train", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'Current encoder type is not implemented yet!'", ")", "\n", "", "self", ".", "encoder_output", "=", "encoder", ".", "encode", "(", "self", ".", "input_", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'decoder'", ")", ":", "\n", "            ", "if", "self", ".", "config", ".", "decoder_type", "==", "'SingleLayerDecoder'", ":", "\n", "                ", "self", ".", "decoder", "=", "SingleLayerDecoder", "(", "self", ".", "config", ",", "self", ".", "is_train", ")", "\n", "", "elif", "self", ".", "config", ".", "decoder_type", "==", "'TransformerDecoder'", ":", "\n", "                ", "self", ".", "decoder", "=", "TransformerDecoder", "(", "self", ".", "config", ",", "self", ".", "is_train", ")", "\n", "", "elif", "self", ".", "config", ".", "decoder_type", "==", "'BilinearDecoder'", ":", "\n", "                ", "self", ".", "decoder", "=", "BilinearDecoder", "(", "self", ".", "config", ",", "self", ".", "is_train", ")", "\n", "", "elif", "self", ".", "config", ".", "decoder_type", "==", "'NTNDecoder'", ":", "\n", "                ", "self", ".", "decoder", "=", "NTNDecoder", "(", "self", ".", "config", ",", "self", ".", "is_train", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'Current decoder type is not implemented yet!'", ")", "\n", "\n", "", "self", ".", "samples", ",", "self", ".", "scores", ",", "self", ".", "entropy", "=", "self", ".", "decoder", ".", "decode", "(", "self", ".", "encoder_output", ")", "\n", "\n", "# self.samples is seq_lenthg * batch size * seq_length", "\n", "# cal cross entropy loss * reward", "\n", "graphs_gen", "=", "tf", ".", "transpose", "(", "tf", ".", "stack", "(", "self", ".", "samples", ")", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "\n", "self", ".", "graphs", "=", "graphs_gen", "\n", "self", ".", "graph_batch", "=", "tf", ".", "reduce_mean", "(", "graphs_gen", ",", "axis", "=", "0", ")", "\n", "logits_for_rewards", "=", "tf", ".", "stack", "(", "self", ".", "scores", ")", "\n", "entropy_for_rewards", "=", "tf", ".", "stack", "(", "self", ".", "entropy", ")", "\n", "entropy_for_rewards", "=", "tf", ".", "transpose", "(", "entropy_for_rewards", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "logits_for_rewards", "=", "tf", ".", "transpose", "(", "logits_for_rewards", ",", "[", "1", ",", "0", ",", "2", "]", ")", "\n", "self", ".", "test_scores", "=", "tf", ".", "sigmoid", "(", "logits_for_rewards", ")", "[", ":", "2", "]", "\n", "log_probss", "=", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "labels", "=", "self", ".", "graphs_", ",", "logits", "=", "logits_for_rewards", ")", "\n", "self", ".", "log_softmax", "=", "tf", ".", "reduce_mean", "(", "log_probss", ",", "axis", "=", "[", "1", ",", "2", "]", ")", "\n", "self", ".", "entropy_regularization", "=", "tf", ".", "reduce_mean", "(", "entropy_for_rewards", ",", "axis", "=", "[", "1", ",", "2", "]", ")", "\n", "\n", "variable_summaries", "(", "'log_softmax'", ",", "self", ".", "log_softmax", ",", "with_max_min", "=", "True", ")", "\n", "\n", "", "", "def", "build_critic", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"critic\"", ")", ":", "\n", "# Critic predicts reward (parametric baseline for REINFORCE)", "\n", "            ", "self", ".", "critic", "=", "Critic", "(", "self", ".", "config", ",", "self", ".", "is_train", ")", "\n", "self", ".", "critic", ".", "predict_rewards", "(", "self", ".", "encoder_output", ")", "\n", "\n", "variable_summaries", "(", "'predictions'", ",", "self", ".", "critic", ".", "predictions", ",", "with_max_min", "=", "True", ")", "\n", "\n", "", "", "def", "build_reward", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "'environment'", ")", ":", "\n", "            ", "self", ".", "reward", "=", "self", ".", "reward_", "\n", "variable_summaries", "(", "'reward'", ",", "self", ".", "reward", ",", "with_max_min", "=", "True", ")", "\n", "\n", "\n", "", "", "def", "build_optim", "(", "self", ")", ":", "\n", "# Update moving_mean and moving_variance for batch normalization layers", "\n", "        ", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "update_ops", ")", ":", "\n", "            ", "with", "tf", ".", "name_scope", "(", "'baseline'", ")", ":", "\n", "# Update baseline", "\n", "                ", "reward_mean", ",", "reward_var", "=", "tf", ".", "nn", ".", "moments", "(", "self", ".", "reward", ",", "axes", "=", "[", "0", "]", ")", "\n", "self", ".", "reward_batch", "=", "reward_mean", "\n", "self", ".", "base_op", "=", "tf", ".", "assign", "(", "self", ".", "avg_baseline", ",", "\n", "self", ".", "alpha", "*", "self", ".", "avg_baseline", "+", "(", "1.0", "-", "self", ".", "alpha", ")", "*", "reward_mean", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'average baseline'", ",", "self", ".", "avg_baseline", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'reinforce'", ")", ":", "\n", "# Actor learning rate", "\n", "                ", "self", ".", "lr1", "=", "tf", ".", "train", ".", "exponential_decay", "(", "self", ".", "lr1_start", ",", "self", ".", "global_step", ",", "self", ".", "lr1_decay_step", ",", "\n", "self", ".", "lr1_decay_rate", ",", "staircase", "=", "False", ",", "name", "=", "\"learning_rate1\"", ")", "\n", "# Optimizer", "\n", "self", ".", "opt1", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "lr1", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.99", ",", "epsilon", "=", "0.0000001", ")", "\n", "# Discounted reward", "\n", "self", ".", "reward_baseline", "=", "tf", ".", "stop_gradient", "(", "\n", "self", ".", "reward", "-", "self", ".", "avg_baseline", "-", "self", ".", "critic", ".", "predictions", ")", "# [Batch size, 1]", "\n", "variable_summaries", "(", "'reward_baseline'", ",", "self", ".", "reward_baseline", ",", "with_max_min", "=", "True", ")", "\n", "# Loss", "\n", "self", ".", "loss1", "=", "tf", ".", "reduce_mean", "(", "self", ".", "reward_baseline", "*", "self", ".", "log_softmax", ",", "0", ")", "-", "1", "*", "self", ".", "lr1", "*", "tf", ".", "reduce_mean", "(", "self", ".", "entropy_regularization", ",", "0", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'loss1'", ",", "self", ".", "loss1", ")", "\n", "# Minimize step", "\n", "gvs", "=", "self", ".", "opt1", ".", "compute_gradients", "(", "self", ".", "loss1", ")", "\n", "capped_gvs", "=", "[", "(", "tf", ".", "clip_by_norm", "(", "grad", ",", "1.", ")", ",", "var", ")", "for", "grad", ",", "var", "in", "gvs", "if", "grad", "is", "not", "None", "]", "# L2 clip", "\n", "self", ".", "train_step1", "=", "self", ".", "opt1", ".", "apply_gradients", "(", "capped_gvs", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "'state_value'", ")", ":", "\n", "# Critic learning rate", "\n", "                ", "self", ".", "lr2", "=", "tf", ".", "train", ".", "exponential_decay", "(", "self", ".", "lr2_start", ",", "self", ".", "global_step2", ",", "self", ".", "lr2_decay_step", ",", "\n", "self", ".", "lr2_decay_rate", ",", "staircase", "=", "False", ",", "name", "=", "\"learning_rate1\"", ")", "\n", "# Optimizer", "\n", "self", ".", "opt2", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "lr2", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.99", ",", "epsilon", "=", "0.0000001", ")", "\n", "# Loss", "\n", "weights_", "=", "1.0", "# weights_ = tf.exp(self.log_softmax-tf.reduce_max(self.log_softmax)) # probs / max_prob", "\n", "self", ".", "loss2", "=", "tf", ".", "losses", ".", "mean_squared_error", "(", "self", ".", "reward", "-", "self", ".", "avg_baseline", ",", "self", ".", "critic", ".", "predictions", ",", "\n", "weights", "=", "weights_", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'loss2'", ",", "self", ".", "loss2", ")", "\n", "# Minimize step", "\n", "gvs2", "=", "self", ".", "opt2", ".", "compute_gradients", "(", "self", ".", "loss2", ")", "\n", "capped_gvs2", "=", "[", "(", "tf", ".", "clip_by_norm", "(", "grad", ",", "1.", ")", ",", "var", ")", "for", "grad", ",", "var", "in", "gvs2", "if", "grad", "is", "not", "None", "]", "# L2 clip", "\n", "self", ".", "train_step2", "=", "self", ".", "opt1", ".", "apply_gradients", "(", "capped_gvs2", ",", "global_step", "=", "self", ".", "global_step2", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.actor_graph.Actor.build_permutation": [[176, 209], ["actor_graph.Actor.encoder", "actor_graph.Actor.decoder", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "entropy_for_rewards.permute.permute.permute", "logits_for_rewards.permute.permute.permute", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "actor_graph.Actor.build_critic", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.actor_graph.Actor.build_critic"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.actor_graph.Actor.build_critic": [[210, 219], ["critic.Critic", "actor_graph.Actor.critic"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.actor_graph.Actor.build_reward": [[220, 225], ["actor_graph.Actor.build_optim"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.actor_graph.Actor.build_optim"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.actor_graph.Actor.build_optim": [[226, 254], ["actor_graph.Actor.avg_baseline.to", "actor_graph.Actor.criterion", "actor_graph.Actor.opt1.zero_grad", "actor_graph.Actor.loss1.backward", "actor_graph.Actor.loss2.backward", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "torch.utils.clip_grad_norm_", "actor_graph.Actor.opt1.step", "actor_graph.Actor.lr1_scheduler.step", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.std", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "list", "list", "list", "actor_graph.Actor.critic.parameters", "actor_graph.Actor.lr1_scheduler.get_last_lr", "actor_graph.Actor.encoder.parameters", "actor_graph.Actor.decoder.parameters"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.TrExpScipy.backward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.TrExpScipy.backward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy.step", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy.step"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.actor_graph.variable_summaries": [[11, 21], ["tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.name_scope", "tensorflow.sqrt", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.reduce_mean", "tensorflow.reduce_max", "tensorflow.reduce_min", "tensorflow.square"], "function", ["None"], ["def", "variable_summaries", "(", "name", ",", "var", ",", "with_max_min", "=", "False", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "name", ")", ":", "\n", "        ", "mean", "=", "tf", ".", "reduce_mean", "(", "var", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'mean'", ",", "mean", ")", "\n", "with", "tf", ".", "name_scope", "(", "'stddev'", ")", ":", "\n", "            ", "stddev", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "var", "-", "mean", ")", ")", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "'stddev'", ",", "stddev", ")", "\n", "if", "with_max_min", "==", "True", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "'max'", ",", "tf", ".", "reduce_max", "(", "var", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'min'", ",", "tf", ".", "reduce_min", "(", "var", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.critic.Critic.__init__": [[22, 46], ["torch.Module.__init__", "torch.Linear().to", "torch.Linear().to", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.Sequential().to", "torch.Sequential().to", "torch.Linear().to", "torch.Linear().to", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["\n", "# Baseline setup", "\n", "self", ".", "init_baseline", "=", "0.", "\n", "\n", "", "def", "predict_rewards", "(", "self", ",", "encoder_output", ")", ":", "\n", "# [Batch size, Sequence Length, Num_neurons] to [Batch size, Num_neurons]", "\n", "        ", "frame", "=", "tf", ".", "reduce_mean", "(", "encoder_output", ",", "1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"ffn\"", ")", ":", "\n", "# ffn 1", "\n", "            ", "h0", "=", "tf", ".", "layers", ".", "dense", "(", "frame", ",", "self", ".", "num_neurons", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "kernel_initializer", "=", "self", ".", "initializer", ")", "\n", "# ffn 2", "\n", "w1", "=", "tf", ".", "get_variable", "(", "\"w1\"", ",", "[", "self", ".", "num_neurons", ",", "1", "]", ",", "initializer", "=", "self", ".", "initializer", ")", "\n", "b1", "=", "tf", ".", "Variable", "(", "self", ".", "init_baseline", ",", "name", "=", "\"b1\"", ")", "\n", "self", ".", "predictions", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "h0", ",", "w1", ")", "+", "b1", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.critic.Critic.predict_rewards": [[26, 37], ["tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.squeeze", "tensorflow.matmul"], "methods", ["None"], ["", "def", "predict_rewards", "(", "self", ",", "encoder_output", ")", ":", "\n", "# [Batch size, Sequence Length, Num_neurons] to [Batch size, Num_neurons]", "\n", "        ", "frame", "=", "tf", ".", "reduce_mean", "(", "encoder_output", ",", "1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"ffn\"", ")", ":", "\n", "# ffn 1", "\n", "            ", "h0", "=", "tf", ".", "layers", ".", "dense", "(", "frame", ",", "self", ".", "num_neurons", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "kernel_initializer", "=", "self", ".", "initializer", ")", "\n", "# ffn 2", "\n", "w1", "=", "tf", ".", "get_variable", "(", "\"w1\"", ",", "[", "self", ".", "num_neurons", ",", "1", "]", ",", "initializer", "=", "self", ".", "initializer", ")", "\n", "b1", "=", "tf", ".", "Variable", "(", "self", ".", "init_baseline", ",", "name", "=", "\"b1\"", ")", "\n", "self", ".", "predictions", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "h0", ",", "w1", ")", "+", "b1", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel.__init__": [[24, 44], ["tensorflow.keras.initializers.glorot_uniform", "model.GAEModel._build", "model.GAEModel._init_session", "model.GAEModel._init_saver"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._build", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._init_session", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._init_saver"], ["    ", "def", "__init__", "(", "self", ",", "n", ",", "d", ",", "x_dim", ",", "seed", "=", "8", ",", "num_encoder_layers", "=", "1", ",", "\n", "num_decoder_layers", "=", "1", ",", "hidden_size", "=", "5", ",", "latent_dim", "=", "1", ",", "\n", "l1_graph_penalty", "=", "0", ",", "use_float64", "=", "False", ")", ":", "\n", "        ", "self", ".", "n", "=", "n", "\n", "self", ".", "d", "=", "d", "\n", "self", ".", "x_dim", "=", "x_dim", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "num_encoder_layers", "=", "num_encoder_layers", "\n", "self", ".", "num_decoder_layers", "=", "num_decoder_layers", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "latent_dim", "=", "latent_dim", "\n", "self", ".", "l1_graph_penalty", "=", "l1_graph_penalty", "\n", "self", ".", "tf_float_type", "=", "tf", ".", "dtypes", ".", "float64", "if", "use_float64", "else", "tf", ".", "dtypes", ".", "float32", "\n", "\n", "# Initializer (for reproducibility)", "\n", "self", ".", "initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "glorot_uniform", "(", "seed", "=", "self", ".", "seed", ")", "\n", "\n", "self", ".", "_build", "(", ")", "\n", "self", ".", "_init_session", "(", ")", "\n", "self", ".", "_init_saver", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._init_session": [[45, 56], ["helpers.tf_utils.is_cuda_available", "tensorflow.Session", "tensorflow.Session", "tensorflow.ConfigProto", "tensorflow.GPUOptions"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.is_cuda_available"], ["", "def", "_init_session", "(", "self", ")", ":", "\n", "        ", "if", "is_cuda_available", "(", ")", ":", "\n", "# Use GPU", "\n", "            ", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "gpu_options", "=", "tf", ".", "GPUOptions", "(", "\n", "per_process_gpu_memory_fraction", "=", "0.5", ",", "\n", "allow_growth", "=", "True", ",", "\n", ")", "\n", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._init_saver": [[57, 59], ["tensorflow.train.Saver"], "methods", ["None"], ["", "", "def", "_init_saver", "(", "self", ")", ":", "\n", "        ", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._build": [[60, 80], ["tensorflow.reset_default_graph", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.Variable", "model.GAEModel._preprocess_graph", "model.GAEModel._get_mse_loss", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.random.uniform", "tensorflow.linalg.trace", "tensorflow.linalg.expm", "tensorflow.train.AdamOptimizer", "tensorflow.norm"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_model.MaskedModel._preprocess_graph", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_model.MaskedModel._get_mse_loss"], ["", "def", "_build", "(", "self", ")", ":", "\n", "        ", "tf", ".", "reset_default_graph", "(", ")", "\n", "\n", "self", ".", "rho", "=", "tf", ".", "placeholder", "(", "self", ".", "tf_float_type", ")", "\n", "self", ".", "alpha", "=", "tf", ".", "placeholder", "(", "self", ".", "tf_float_type", ")", "\n", "self", ".", "lr", "=", "tf", ".", "placeholder", "(", "self", ".", "tf_float_type", ")", "\n", "\n", "self", ".", "X", "=", "tf", ".", "placeholder", "(", "self", ".", "tf_float_type", ",", "shape", "=", "[", "self", ".", "n", ",", "self", ".", "d", ",", "self", ".", "x_dim", "]", ")", "\n", "W", "=", "tf", ".", "Variable", "(", "tf", ".", "random", ".", "uniform", "(", "[", "self", ".", "d", ",", "self", ".", "d", "]", ",", "minval", "=", "-", "0.1", ",", "maxval", "=", "0.1", ",", "\n", "dtype", "=", "self", ".", "tf_float_type", ",", "seed", "=", "self", ".", "seed", ")", ")", "\n", "\n", "self", ".", "W_prime", "=", "self", ".", "_preprocess_graph", "(", "W", ")", "\n", "self", ".", "mse_loss", "=", "self", ".", "_get_mse_loss", "(", "self", ".", "X", ",", "self", ".", "W_prime", ")", "\n", "\n", "self", ".", "h", "=", "tf", ".", "linalg", ".", "trace", "(", "tf", ".", "linalg", ".", "expm", "(", "self", ".", "W_prime", "*", "self", ".", "W_prime", ")", ")", "-", "self", ".", "d", "# Acyclicity", "\n", "self", ".", "loss", "=", "0.5", "/", "self", ".", "n", "*", "self", ".", "mse_loss", "+", "self", ".", "l1_graph_penalty", "*", "tf", ".", "norm", "(", "self", ".", "W_prime", ",", "ord", "=", "1", ")", "+", "self", ".", "alpha", "*", "self", ".", "h", "+", "0.5", "*", "self", ".", "rho", "*", "self", ".", "h", "*", "self", ".", "h", "\n", "\n", "self", ".", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "self", ".", "lr", ")", ".", "minimize", "(", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._preprocess_graph": [[81, 84], ["tensorflow.matrix_set_diag", "tensorflow.zeros"], "methods", ["None"], ["", "def", "_preprocess_graph", "(", "self", ",", "W", ")", ":", "\n", "# Mask the diagonal entries of graph", "\n", "        ", "return", "tf", ".", "matrix_set_diag", "(", "W", ",", "tf", ".", "zeros", "(", "W", ".", "shape", "[", "0", "]", ",", "dtype", "=", "self", ".", "tf_float_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._get_mse_loss": [[85, 91], ["model.GAEModel._encoder_forward", "tensorflow.einsum", "model.GAEModel._decoder_forward", "tensorflow.square", "tensorflow.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._encoder_forward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._decoder_forward"], ["", "def", "_get_mse_loss", "(", "self", ",", "X", ",", "W_prime", ")", ":", "\n", "        ", "X_prime", "=", "self", ".", "_encoder_forward", "(", "X", ")", "\n", "X_prime", "=", "tf", ".", "einsum", "(", "'ijk,jl->ilk'", ",", "X_prime", ",", "W_prime", ")", "\n", "X_prime", "=", "self", ".", "_decoder_forward", "(", "X_prime", ")", "\n", "\n", "return", "tf", ".", "square", "(", "tf", ".", "linalg", ".", "norm", "(", "X", "-", "X_prime", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._encoder_forward": [[92, 96], ["model.GAEModel._flatten_forward"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._flatten_forward"], ["", "def", "_encoder_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_flatten_forward", "(", "x", ",", "self", ".", "num_encoder_layers", ",", "self", ".", "hidden_size", ",", "\n", "input_dim", "=", "self", ".", "x_dim", ",", "\n", "output_dim", "=", "self", ".", "latent_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._decoder_forward": [[97, 101], ["model.GAEModel._flatten_forward"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._flatten_forward"], ["", "def", "_decoder_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_flatten_forward", "(", "x", ",", "self", ".", "num_decoder_layers", ",", "self", ".", "hidden_size", ",", "\n", "input_dim", "=", "self", ".", "latent_dim", ",", "\n", "output_dim", "=", "self", ".", "x_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.model.GAEModel._flatten_forward": [[102, 114], ["tensorflow.reshape", "range", "tensorflow.reshape", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LeakyReLU"], "methods", ["None"], ["", "def", "_flatten_forward", "(", "self", ",", "x", ",", "num_hidden_layers", ",", "hidden_size", ",", "input_dim", ",", "output_dim", ")", ":", "\n", "        ", "if", "num_hidden_layers", "==", "0", ":", "\n", "            ", "return", "x", "\n", "", "else", ":", "\n", "            ", "flatten", "=", "tf", ".", "reshape", "(", "x", ",", "shape", "=", "(", "-", "1", ",", "input_dim", ")", ")", "\n", "for", "_", "in", "range", "(", "num_hidden_layers", ")", ":", "# Hidden layer", "\n", "                ", "flatten", "=", "Dense", "(", "hidden_size", ",", "activation", "=", "None", ",", "kernel_initializer", "=", "self", ".", "initializer", ")", "(", "flatten", ")", "\n", "flatten", "=", "LeakyReLU", "(", "alpha", "=", "0.05", ")", "(", "flatten", ")", "\n", "\n", "", "flatten", "=", "Dense", "(", "output_dim", ",", "kernel_initializer", "=", "self", ".", "initializer", ")", "(", "flatten", ")", "# Final output layer", "\n", "\n", "return", "tf", ".", "reshape", "(", "flatten", ",", "shape", "=", "(", "self", ".", "n", ",", "self", ".", "d", ",", "output_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.critic.Critic.forward": [[47, 56], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "critic.Critic.h0_layer", "critic.Critic.layer1", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "encoder_output.detach"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.encoders.LSTMEncoder.__init__": [[34, 47], ["_base_network.BaseEncoder.__init__", "torch.LSTM().to", "torch.LSTM().to", "torch.LSTM().to", "torch.LSTM", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "embed_dim", ",", "device", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "LSTMEncoder", ",", "self", ")", ".", "__init__", "(", "input_dim", "=", "input_dim", ",", "\n", "embed_dim", "=", "embed_dim", ",", "\n", "device", "=", "device", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "hidden_dim", "=", "embed_dim", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_size", "=", "self", ".", "hidden_dim", ",", "\n", "hidden_size", "=", "self", ".", "hidden_dim", ",", "\n", "num_layers", "=", "1", ",", "\n", "bias", "=", "True", ",", "\n", "batch_first", "=", "True", "\n", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.encoders.LSTMEncoder.forward": [[48, 62], ["x.permute.permute.permute", "encoders.LSTMEncoder.embedding().permute", "encoders.LSTMEncoder.lstm", "encoders.LSTMEncoder.embedding"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        x:\n            [Batch Size, Sequence Length, Features]\n        \"\"\"", "\n", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "output", "=", "self", ".", "embedding", "(", "x", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "output", ",", "(", "_", ",", "_", ")", "=", "self", ".", "lstm", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.encoders.MLPEncoder.__init__": [[70, 80], ["_base_network.BaseEncoder.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "embed_dim", ",", "hidden_dim", ",", "\n", "device", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "MLPEncoder", ",", "self", ")", ".", "__init__", "(", "input_dim", "=", "input_dim", ",", "\n", "embed_dim", "=", "embed_dim", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "device", "=", "device", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "embed_dim", "=", "embed_dim", "# also is output_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.encoders.MLPEncoder.forward": [[81, 88], ["x.permute.permute.permute", "encoders.MLPEncoder.embedding", "encoders.MLPEncoder.feedforward_conv1d", "encoders.MLPEncoder.bn().permute", "encoders.MLPEncoder.bn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "output", "=", "self", ".", "embedding", "(", "x", ")", "\n", "output", "=", "self", ".", "feedforward_conv1d", "(", "output", ")", "\n", "output", "=", "self", ".", "bn", "(", "output", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.encoders.TransformerEncoder.__init__": [[93, 110], ["_base_network.BaseEncoder.__init__", "encoders.MultiHeadAttention"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "embed_dim", ",", "hidden_dim", ",", "\n", "heads", "=", "8", ",", "blocks", "=", "3", ",", "device", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "TransformerEncoder", ",", "self", ")", ".", "__init__", "(", "input_dim", "=", "input_dim", ",", "\n", "embed_dim", "=", "embed_dim", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "device", "=", "device", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "heads", "=", "heads", "\n", "self", ".", "embed_dim", "=", "embed_dim", "# also is output_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "blocks", "=", "blocks", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "attention", "=", "MultiHeadAttention", "(", "input_dim", "=", "embed_dim", ",", "\n", "output_dim", "=", "embed_dim", ",", "\n", "heads", "=", "heads", ",", "\n", "dropout_rate", "=", "0.0", ",", "\n", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.encoders.TransformerEncoder.forward": [[111, 122], ["x.permute.permute.permute", "encoders.TransformerEncoder.embedding().permute", "range", "encoders.TransformerEncoder.attention", "enc.permute.permute.permute", "encoders.TransformerEncoder.feedforward_conv1d", "encoders.TransformerEncoder.bn().permute", "encoders.TransformerEncoder.embedding", "encoders.TransformerEncoder.bn"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Attention.attention"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "output", "=", "self", ".", "embedding", "(", "x", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "enc", "=", "self", ".", "attention", "(", "output", ")", "\n", "enc", "=", "enc", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "output", "=", "self", ".", "feedforward_conv1d", "(", "enc", ")", "\n", "output", "+=", "enc", "# Residual connection", "\n", "output", "=", "self", ".", "bn", "(", "output", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.encoders.MultiHeadAttention.__init__": [[142, 170], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU().to", "torch.ReLU().to", "torch.ReLU().to", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU().to", "torch.ReLU().to", "torch.ReLU().to", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU().to", "torch.ReLU().to", "torch.ReLU().to", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "heads", "=", "8", ",", "dropout_rate", "=", "0.1", ",", "\n", "device", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "heads", "=", "heads", "\n", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "w_q", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "input_dim", ",", "\n", "out_features", "=", "output_dim", ",", "\n", "device", "=", "device", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ".", "to", "(", "device", "=", "device", ")", "\n", ")", "\n", "self", ".", "w_k", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "input_dim", ",", "\n", "out_features", "=", "output_dim", ",", "\n", "device", "=", "device", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ".", "to", "(", "device", "=", "device", ")", "\n", ")", "\n", "self", ".", "w_v", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "input_dim", ",", "\n", "out_features", "=", "output_dim", ",", "\n", "device", "=", "device", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ".", "to", "(", "device", "=", "device", ")", "\n", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "output_dim", ",", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.encoders.MultiHeadAttention.forward": [[171, 214], ["encoders.MultiHeadAttention.w_q", "encoders.MultiHeadAttention.w_k", "encoders.MultiHeadAttention.w_v", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.softmax", "torch.dropout", "torch.dropout", "torch.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoders.MultiHeadAttention.bn().permute", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "encoders.MultiHeadAttention.bn", "encoders.MultiHeadAttention.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "Q", "=", "self", ".", "w_q", "(", "x", ")", "# [batch_size, seq_length, n_hidden]", "\n", "K", "=", "self", ".", "w_k", "(", "x", ")", "\n", "V", "=", "self", ".", "w_v", "(", "x", ")", "\n", "\n", "# Split and concat", "\n", "Q_", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "Q", ",", "\n", "split_size_or_sections", "=", "Q", ".", "shape", "[", "2", "]", "//", "self", ".", "heads", ",", "\n", "dim", "=", "2", ")", ",", "\n", "dim", "=", "0", ")", "\n", "K_", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "K", ",", "\n", "split_size_or_sections", "=", "K", ".", "shape", "[", "2", "]", "//", "self", ".", "heads", ",", "\n", "dim", "=", "2", ")", ",", "\n", "dim", "=", "0", ")", "\n", "V_", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "V", ",", "\n", "split_size_or_sections", "=", "V", ".", "shape", "[", "2", "]", "//", "self", ".", "heads", ",", "\n", "dim", "=", "2", ")", ",", "\n", "dim", "=", "0", ")", "\n", "# Multiplication # [num_heads*batch_size, seq_length, seq_length]", "\n", "output", "=", "torch", ".", "matmul", "(", "Q_", ",", "K_", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "\n", "# Scale", "\n", "output", "=", "output", "/", "(", "K_", ".", "shape", "[", "-", "1", "]", "**", "0.5", ")", "\n", "\n", "# Activation  # [num_heads*batch_size, seq_length, seq_length]", "\n", "output", "=", "F", ".", "softmax", "(", "output", ",", "dim", "=", "1", ")", "\n", "\n", "# Dropouts", "\n", "output", "=", "F", ".", "dropout", "(", "output", ",", "p", "=", "self", ".", "dropout_rate", ")", "\n", "\n", "# Weighted sum # [num_heads*batch_size, seq_length, n_hidden/num_heads]", "\n", "output", "=", "torch", ".", "matmul", "(", "output", ",", "V_", ")", "\n", "\n", "# Restore shape", "\n", "output", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "output", ",", "\n", "split_size_or_sections", "=", "output", ".", "shape", "[", "0", "]", "//", "self", ".", "heads", ",", "\n", "dim", "=", "0", ")", ",", "\n", "dim", "=", "2", ")", "# [batch_size, seq_length, n_hidden]", "\n", "# Residual connection", "\n", "output", "+=", "x", "# [batch_size, seq_length, n_hidden]", "\n", "output", "=", "self", ".", "bn", "(", "output", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.decoders.LSTMDecoder.__init__": [[26, 37], ["_base_network.PointerDecoder.__init__", "torch.LSTMCell", "torch.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "hidden_dim", ",", "device", "=", "None", ")", "->", "None", ":", "\n", "# input of Decoder is output of Encoder, e.g. embed_dim", "\n", "        ", "super", "(", "LSTMDecoder", ",", "self", ")", ".", "__init__", "(", "input_dim", "=", "input_dim", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "device", "=", "device", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "lstm_cell", "=", "nn", ".", "LSTMCell", "(", "input_size", "=", "hidden_dim", ",", "\n", "hidden_size", "=", "hidden_dim", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.decoders.LSTMDecoder.forward": [[38, 72], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "range", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.stack().squeeze.append", "torch.stack().squeeze.append", "torch.stack().squeeze.append", "torch.stack().squeeze.append", "torch.stack().squeeze.append", "torch.stack().squeeze.append", "decoders.LSTMDecoder.step_decode", "action_list.append", "prob_list.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models._base_network.PointerDecoder.step_decode"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "tuple", ":", "\n", "        ", "\"\"\"\"\"\"", "\n", "self", ".", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "self", ".", "seq_length", "=", "x", ".", "shape", "[", "1", "]", "\n", "self", ".", "encoder_output", "=", "x", "# \u4fdd\u5b58\u8d77\u6765\u6709\u7528", "\n", "\n", "s_i", "=", "torch", ".", "mean", "(", "x", ",", "1", ")", "\n", "hi_ci", "=", "(", "torch", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "hidden_dim", ")", ",", "device", "=", "s_i", ".", "device", ")", ",", "\n", "torch", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "hidden_dim", ")", ",", "device", "=", "s_i", ".", "device", ")", ")", "\n", "h_list", "=", "[", "]", "\n", "c_list", "=", "[", "]", "\n", "s_list", "=", "[", "]", "\n", "action_list", "=", "[", "]", "\n", "prob_list", "=", "[", "]", "\n", "for", "step", "in", "range", "(", "self", ".", "seq_length", ")", ":", "\n", "            ", "h_list", ".", "append", "(", "hi_ci", "[", "0", "]", ")", "\n", "c_list", ".", "append", "(", "hi_ci", "[", "1", "]", ")", "\n", "s_list", ".", "append", "(", "s_i", ")", "\n", "\n", "s_i", ",", "hi_ci", ",", "pos", ",", "prob", "=", "self", ".", "step_decode", "(", "input", "=", "s_i", ",", "state", "=", "hi_ci", ")", "\n", "\n", "action_list", ".", "append", "(", "pos", ")", "\n", "prob_list", ".", "append", "(", "prob", ")", "\n", "\n", "", "h_list", "=", "torch", ".", "stack", "(", "h_list", ",", "dim", "=", "1", ")", ".", "squeeze", "(", ")", "# [Batch,seq_length,hidden]", "\n", "c_list", "=", "torch", ".", "stack", "(", "c_list", ",", "dim", "=", "1", ")", ".", "squeeze", "(", ")", "# [Batch,seq_length,hidden]", "\n", "s_list", "=", "torch", ".", "stack", "(", "s_list", ",", "dim", "=", "1", ")", ".", "squeeze", "(", ")", "# [Batch,seq_length,hidden]", "\n", "\n", "# Stack visited indices", "\n", "actions", "=", "torch", ".", "stack", "(", "action_list", ",", "dim", "=", "1", ")", "# [Batch,seq_length]", "\n", "mask_scores", "=", "torch", ".", "stack", "(", "prob_list", ",", "dim", "=", "1", ")", "# [Batch,seq_length,seq_length]", "\n", "self", ".", "mask", "=", "torch", ".", "zeros", "(", "1", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "return", "actions", ",", "mask_scores", ",", "s_list", ",", "h_list", ",", "c_list", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.decoders.MLPDecoder.__init__": [[77, 85], ["_base_network.PointerDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "hidden_dim", ",", "device", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "MLPDecoder", ",", "self", ")", ".", "__init__", "(", "input_dim", "=", "input_dim", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "device", "=", "device", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "mlp", "=", "self", ".", "feedforward_mlp", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.decoders.MLPDecoder.forward": [[86, 111], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "range", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.stack().squeeze.append", "torch.stack().squeeze.append", "decoders.MLPDecoder.step_decode", "action_list.append", "prob_list.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models._base_network.PointerDecoder.step_decode"], ["", "def", "forward", "(", "self", ",", "x", ")", "->", "tuple", ":", "\n", "\n", "        ", "self", ".", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "self", ".", "seq_length", "=", "x", ".", "shape", "[", "1", "]", "\n", "self", ".", "encoder_output", "=", "x", "\n", "\n", "s_i", "=", "torch", ".", "mean", "(", "x", ",", "1", ")", "\n", "\n", "s_list", "=", "[", "]", "\n", "action_list", "=", "[", "]", "\n", "prob_list", "=", "[", "]", "\n", "for", "step", "in", "range", "(", "self", ".", "seq_length", ")", ":", "\n", "            ", "s_list", ".", "append", "(", "s_i", ")", "\n", "s_i", ",", "_", ",", "pos", ",", "prob", "=", "self", ".", "step_decode", "(", "input", "=", "s_i", ",", "state", "=", "None", ")", "\n", "\n", "action_list", ".", "append", "(", "pos", ")", "\n", "prob_list", ".", "append", "(", "prob", ")", "\n", "", "s_list", "=", "torch", ".", "stack", "(", "s_list", ",", "dim", "=", "1", ")", ".", "squeeze", "(", ")", "# [Batch,seq_length,hidden]", "\n", "\n", "# Stack visited indices", "\n", "actions", "=", "torch", ".", "stack", "(", "action_list", ",", "dim", "=", "1", ")", "# [Batch,seq_length]", "\n", "mask_scores", "=", "torch", ".", "stack", "(", "prob_list", ",", "dim", "=", "1", ")", "# [Batch,seq_length,seq_length]", "\n", "self", ".", "mask", "=", "torch", ".", "zeros", "(", "1", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "return", "actions", ",", "mask_scores", ",", "s_list", ",", "s_list", ",", "s_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models._base_network.BaseEncoder.__init__": [[26, 53], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "embed_dim", ",", "hidden_dim", "=", "1024", ",", "\n", "device", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "BaseEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "embed_dim", "is", "None", ":", "\n", "            ", "embed_dim", "=", "input_dim", "\n", "\n", "# this layer just for Encoder", "\n", "", "self", ".", "embedding", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "input_dim", ",", "\n", "out_channels", "=", "embed_dim", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "device", "=", "device", ")", ",", "\n", ")", "\n", "if", "self", ".", "__class__", ".", "__name__", "in", "[", "'TransformerEncoder'", ",", "'MLPEncoder'", "]", ":", "\n", "# this layer just for ``TransformerEncoder`` and ``MLPEncoder``.", "\n", "            ", "self", ".", "feedforward_conv1d", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "embed_dim", ",", "\n", "out_channels", "=", "hidden_dim", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "device", "=", "device", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "hidden_dim", ",", "\n", "out_channels", "=", "embed_dim", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "device", "=", "device", ")", ",", "\n", ")", "\n", "", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "embed_dim", ",", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models._base_network.BaseDecoder.__init__": [[57, 72], ["torch.Module.__init__", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "hidden_dim", ",", "device", "=", "None", ")", "->", "None", ":", "\n", "# input_dim is embed_dim", "\n", "        ", "super", "(", "BaseDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "self", ".", "__class__", ".", "__name__", "==", "'MLPDecoder'", ":", "\n", "# this layer just for MLPDecoder", "\n", "            ", "self", ".", "feedforward_mlp", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "input_dim", ",", "\n", "out_features", "=", "hidden_dim", ",", "\n", "device", "=", "device", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "in_features", "=", "hidden_dim", ",", "\n", "out_features", "=", "input_dim", ",", "\n", "device", "=", "device", ")", "\n", ")", "\n", "", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "num_features", "=", "input_dim", ",", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models._base_network.PointerDecoder.__init__": [[77, 112], ["_base_network.BaseDecoder.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "hidden_dim", ",", "device", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "PointerDecoder", ",", "self", ")", ".", "__init__", "(", "input_dim", "=", "input_dim", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "device", "=", "device", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "positions", "=", "[", "]", "# store visited cities for reward", "\n", "self", ".", "mask", "=", "torch", ".", "zeros", "(", "1", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "mask_scores", "=", "[", "]", "\n", "# Attention mechanism -- glimpse  _encoder_glimpse", "\n", "self", ".", "conv1d_ref_g", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "input_dim", ",", "\n", "out_channels", "=", "hidden_dim", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "device", "=", "device", ")", "\n", "self", ".", "w_q_g", "=", "nn", ".", "Linear", "(", "in_features", "=", "hidden_dim", ",", "\n", "out_features", "=", "hidden_dim", ",", "\n", "bias", "=", "False", ",", "\n", "device", "=", "device", ")", "\n", "self", ".", "v_g", "=", "nn", ".", "Linear", "(", "in_features", "=", "hidden_dim", ",", "\n", "out_features", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "device", "=", "device", ")", "\n", "# Pointer mechanism  _encoder_pointer", "\n", "self", ".", "conv1d_ref_p", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "input_dim", ",", "\n", "out_channels", "=", "hidden_dim", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "device", "=", "device", ")", "\n", "self", ".", "w_q_p", "=", "nn", ".", "Linear", "(", "in_features", "=", "hidden_dim", ",", "\n", "out_features", "=", "hidden_dim", ",", "\n", "bias", "=", "False", ",", "\n", "device", "=", "device", ")", "\n", "self", ".", "v_p", "=", "nn", ".", "Linear", "(", "in_features", "=", "hidden_dim", ",", "\n", "out_features", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models._base_network.PointerDecoder.step_decode": [[113, 157], ["_base_network.PointerDecoder.pointer_net", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical.sample().long", "torch.distributions.categorical.Categorical.sample().long", "torch.distributions.categorical.Categorical.sample().long", "torch.distributions.categorical.Categorical.sample().long.reshape().repeat", "_base_network.PointerDecoder.lstm_cell", "torch.one_hot", "torch.one_hot", "torch.one_hot", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "_base_network.PointerDecoder.mlp().squeeze", "TypeError", "torch.distributions.categorical.Categorical.sample", "torch.distributions.categorical.Categorical.sample", "torch.distributions.categorical.Categorical.sample", "torch.distributions.categorical.Categorical.sample().long.reshape", "_base_network.PointerDecoder.mlp"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models._base_network.PointerDecoder.pointer_net", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["", "def", "step_decode", "(", "self", ",", "input", ",", "state", "=", "None", ")", "->", "tuple", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        input:\n            Encoder's output\n        state: tuple, None\n            (h, c) for Pointer and None for MLP\n\n        Returns\n        -------\n        output: tuple\n\n        \"\"\"", "\n", "\n", "if", "self", ".", "__class__", ".", "__name__", "==", "'LSTMDecoder'", ":", "\n", "# Run the cell on a combination of the previous input and state", "\n", "            ", "h", ",", "c", "=", "self", ".", "lstm_cell", "(", "input", ",", "state", ")", "\n", "output", "=", "h", "\n", "state", "=", "(", "h", ",", "c", ")", "\n", "", "elif", "self", ".", "__class__", ".", "__name__", "==", "'MLPDecoder'", ":", "\n", "            ", "output", "=", "self", ".", "mlp", "(", "input", ")", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "f'Supported subclass of PointerDecoder is one of '", "\n", "f'[`LSTMDecoder`, `MLPDecoder`], but got'", "\n", "f'``{self.__class__.__name__}``.'", ")", "\n", "\n", "# [batch_size, time_sequence]", "\n", "", "masked_scores", "=", "self", ".", "pointer_net", "(", "self", ".", "encoder_output", ",", "output", ")", "\n", "\n", "# Multinomial distribution", "\n", "prob", "=", "Categorical", "(", "logits", "=", "masked_scores", ")", "\n", "\n", "# Sample from distribution", "\n", "action", "=", "prob", ".", "sample", "(", ")", ".", "long", "(", ")", "\n", "\n", "self", ".", "mask", "=", "self", ".", "mask", "+", "F", ".", "one_hot", "(", "action", ",", "self", ".", "seq_length", ")", "\n", "\n", "# Retrieve decoder's new input", "\n", "action_index", "=", "action", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "hidden_dim", ")", "\n", "next_input", "=", "torch", ".", "gather", "(", "self", ".", "encoder_output", ",", "0", ",", "action_index", ")", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "return", "next_input", ",", "state", ",", "action", ",", "masked_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models._base_network.PointerDecoder.pointer_net": [[158, 195], ["_base_network.PointerDecoder.conv1d_ref_g().permute", "_base_network.PointerDecoder.w_q_g().unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.softmax", "torch.softmax", "torch.softmax", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "_base_network.PointerDecoder.conv1d_ref_p().permute", "_base_network.PointerDecoder.w_q_p().unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "_base_network.PointerDecoder.v_g", "torch.softmax.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "_base_network.PointerDecoder.v_p", "_base_network.PointerDecoder.conv1d_ref_g", "_base_network.PointerDecoder.w_q_g", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "_base_network.PointerDecoder.conv1d_ref_p", "_base_network.PointerDecoder.w_q_p", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "ref.permute", "ref.permute"], "methods", ["None"], ["", "def", "pointer_net", "(", "self", ",", "ref", ",", "query", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Attention mechanism + Pointer mechanism\n\n        Parameters\n        ----------\n        ref: torch.Tensor\n            encoder_states\n        query: torch.Tensor\n            decoder_states\n        \"\"\"", "\n", "\n", "# Attention mechanism", "\n", "encoder_ref_g", "=", "self", ".", "conv1d_ref_g", "(", "\n", "ref", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "encoder_query_g", "=", "self", ".", "w_q_g", "(", "query", ")", ".", "unsqueeze", "(", "1", ")", "\n", "scores_g", "=", "torch", ".", "mean", "(", "\n", "self", ".", "v_g", "(", "torch", ".", "tanh", "(", "encoder_ref_g", "+", "encoder_query_g", ")", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "attention_g", "=", "F", ".", "softmax", "(", "scores_g", "-", "self", ".", "mask", "*", "1e9", ",", "dim", "=", "-", "1", ")", "\n", "\n", "glimpse", "=", "torch", ".", "mul", "(", "ref", ",", "attention_g", ".", "unsqueeze", "(", "2", ")", ")", "\n", "glimpse", "=", "torch", ".", "sum", "(", "glimpse", ",", "dim", "=", "1", ")", "+", "query", "\n", "\n", "# Pointer mechanism", "\n", "encoder_ref_p", "=", "self", ".", "conv1d_ref_p", "(", "\n", "ref", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "encoder_query_p", "=", "self", ".", "w_q_p", "(", "glimpse", ")", ".", "unsqueeze", "(", "1", ")", "\n", "scores_p", "=", "torch", ".", "mean", "(", "\n", "self", ".", "v_p", "(", "torch", ".", "tanh", "(", "encoder_ref_p", "+", "encoder_query_p", ")", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "if", "self", ".", "__class__", ".", "__name__", "==", "'MLPDecoder'", ":", "\n", "            ", "scores_p", "=", "10.0", "*", "torch", ".", "tanh", "(", "scores_p", ")", "\n", "", "masked_scores", "=", "scores_p", "-", "self", ".", "mask", "*", "1e9", "\n", "\n", "return", "masked_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models._base_network.PointerDecoder.log_softmax": [[196, 221], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "_base_network.PointerDecoder.encoder_output.unsqueeze", "encoder_output_ex.reshape.reshape.repeat", "encoder_output_ex.reshape.reshape.reshape", "_base_network.PointerDecoder.pointer_net", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical", "torch.distributions.categorical.Categorical.log_prob", "torch.distributions.categorical.Categorical.log_prob", "torch.distributions.categorical.Categorical.log_prob", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "_base_network.PointerDecoder.lstm_cell", "position.reshape", "_base_network.PointerDecoder.mlp", "TypeError"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models._base_network.PointerDecoder.pointer_net"], ["", "def", "log_softmax", "(", "self", ",", "input", ",", "position", ",", "mask", ",", "state_0", ",", "state_1", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "if", "self", ".", "__class__", ".", "__name__", "==", "'LSTMDecoder'", ":", "\n", "            ", "state", "=", "state_0", ",", "state_1", "\n", "h", ",", "c", "=", "self", ".", "lstm_cell", "(", "input", ",", "state", ")", "\n", "output", "=", "h", "\n", "", "elif", "self", ".", "__class__", ".", "__name__", "==", "'MLPDecoder'", ":", "\n", "            ", "output", "=", "self", ".", "mlp", "(", "input", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "f'Supported subclass of PointerDecoder is one of '", "\n", "f'[`LSTMDecoder`, `MLPDecoder`], but got'", "\n", "f'``{self.__class__.__name__}``.'", ")", "\n", "", "self", ".", "mask", "=", "torch", ".", "tensor", "(", "mask", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "# encoder_output_expand", "\n", "encoder_output_ex", "=", "self", ".", "encoder_output", ".", "unsqueeze", "(", "1", ")", "\n", "encoder_output_ex", "=", "encoder_output_ex", ".", "repeat", "(", "1", ",", "self", ".", "seq_length", ",", "1", ",", "1", ")", "\n", "encoder_output_ex", "=", "encoder_output_ex", ".", "reshape", "(", "-", "1", ",", "self", ".", "seq_length", ",", "self", ".", "hidden_dim", ")", "\n", "masked_scores", "=", "self", ".", "pointer_net", "(", "encoder_output_ex", ",", "output", ")", "\n", "\n", "prob", "=", "Categorical", "(", "logits", "=", "masked_scores", ")", "\n", "log_softmax", "=", "prob", ".", "log_prob", "(", "position", ".", "reshape", "(", "-", "1", ",", ")", ")", "\n", "self", ".", "mask", "=", "torch", ".", "zeros", "(", "1", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "return", "log_softmax", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_nn.MaskedNN.__init__": [[22, 31], ["torch.Module.__init__", "masked_nn.MaskedNN._init_nn"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_nn.MaskedNN._init_nn"], ["    ", "def", "__init__", "(", "self", ",", "mask", ",", "hidden_layers", ",", "hidden_dim", ",", "\n", "device", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "MaskedNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mask", "=", "mask", "# use mask to determine input dimension", "\n", "self", ".", "hidden_layers", "=", "hidden_layers", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "_init_nn", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_nn.MaskedNN.forward": [[32, 51], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "choice", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            possible parents\n        choice: str of int\n            current sub-note y\n\n        Returns\n        -------\n        output: torch.Tensor\n            shape = (n,)\n        \"\"\"", "\n", "\n", "output", "=", "self", ".", "nets", "[", "choice", "]", "(", "x", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_nn.MaskedNN._init_nn": [[52, 79], ["range", "torch.ModuleDict", "torch.ModuleDict", "len", "range", "torch.Linear().to", "torch.Linear().to", "torch.Sequential.append", "torch.Sequential", "torch.Sequential", "torch.where", "torch.where", "torch.where", "torch.where", "torch.Sequential", "torch.Sequential", "torch.Sequential.append", "int", "torch.Linear().to", "torch.Linear().to", "torch.LeakyReLU().to", "torch.LeakyReLU().to", "torch.Linear", "torch.Linear", "str", "torch.Linear", "torch.Linear", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["None"], ["", "def", "_init_nn", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initialize net for each node\"\"\"", "\n", "\n", "md", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "mask", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "pns_parents", "=", "torch", ".", "where", "(", "self", ".", "mask", "[", ":", ",", "i", "]", "==", "1", ")", "[", "0", "]", "\n", "first_input_dim", "=", "len", "(", "[", "int", "(", "j", ")", "for", "j", "in", "pns_parents", "if", "j", "!=", "i", "]", ")", "\n", "if", "first_input_dim", "==", "0", ":", "# Root node, don't have to build NN in this case", "\n", "                ", "continue", "\n", "", "reg_nn", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "hidden_layers", ")", ":", "\n", "                ", "input_dim", "=", "self", ".", "hidden_dim", "\n", "if", "j", "==", "0", ":", "\n", "                    ", "input_dim", "=", "first_input_dim", "\n", "", "func", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "input_dim", ",", "\n", "out_features", "=", "self", ".", "hidden_dim", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.05", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", ")", "\n", "reg_nn", ".", "append", "(", "func", ")", "\n", "", "output_layer", "=", "nn", ".", "Linear", "(", "in_features", "=", "self", ".", "hidden_dim", ",", "\n", "out_features", "=", "1", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "reg_nn", ".", "append", "(", "output_layer", ")", "\n", "reg_nn", "=", "nn", ".", "Sequential", "(", "*", "reg_nn", ")", "\n", "\n", "md", "[", "str", "(", "i", ")", "]", "=", "reg_nn", "\n", "", "self", ".", "nets", "=", "nn", ".", "ModuleDict", "(", "md", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_quadratic_regression.MaskedQuadraticRegression.__init__": [[24, 32], ["torch.Module.__init__", "masked_quadratic_regression.MaskedQuadraticRegression._init_weight"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_quadratic_regression.MaskedQuadraticRegression._init_weight"], ["    ", "def", "__init__", "(", "self", ",", "mask", ",", "n_samples", ",", "n_nodes", ",", "device", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "MaskedQuadraticRegression", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mask", "=", "mask", "\n", "self", ".", "n_samples", "=", "n_samples", "\n", "self", ".", "n_nodes", "=", "n_nodes", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "_init_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_quadratic_regression.MaskedQuadraticRegression.forward": [[33, 70], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "x.unsqueeze", "x.unsqueeze", "helpers.utils.generate_upper_triangle_indices", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.nn.init.uniform_().requires_grad_", "torch.nn.init.uniform_().requires_grad_", "torch.nn.init.uniform_().requires_grad_", "torch.nn.init.uniform_().requires_grad_", "masked_quadratic_regression.MaskedQuadraticRegression.w3.to", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.square", "torch.square", "torch.square", "torch.square", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "len"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.generate_upper_triangle_indices"], ["", "def", "forward", "(", "self", ",", "x", ",", "choice", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            shape = (n, d - 1)\n\n        Returns\n        -------\n        output: torch.Tensor\n            a vector of shape = (n,)\n        \"\"\"", "\n", "\n", "output", "=", "torch", ".", "zeros", "(", "self", ".", "n_samples", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "# Linear terms", "\n", "output", "+=", "torch", ".", "sum", "(", "self", ".", "weight", "[", "choice", "]", "[", "'w1'", "]", "*", "x", ",", "dim", "=", "1", ")", "\n", "\n", "# Squared terms", "\n", "output", "+=", "torch", ".", "sum", "(", "self", ".", "weight", "[", "choice", "]", "[", "'w2'", "]", "*", "torch", ".", "square", "(", "x", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# Cross terms", "\n", "x_", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "y_", "=", "x", ".", "unsqueeze", "(", "2", ")", "\n", "target_indices", "=", "generate_upper_triangle_indices", "(", "x", ".", "shape", "[", "1", "]", ")", "\n", "all_cross_terms", "=", "torch", ".", "reshape", "(", "x_", "*", "y_", ",", "(", "self", ".", "n_samples", ",", "-", "1", ")", ")", "\n", "combinations_cross_terms", "=", "all_cross_terms", "[", ":", ",", "target_indices", "]", "\n", "self", ".", "w3", "=", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "torch", ".", "Tensor", "(", "len", "(", "target_indices", ")", ",", ")", ",", "\n", "a", "=", "-", "0.05", ",", "b", "=", "0.05", ")", ".", "requires_grad_", "(", "True", ")", "\n", "self", ".", "w3", "=", "self", ".", "w3", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "output", "+=", "torch", ".", "sum", "(", "self", ".", "w3", "*", "combinations_cross_terms", ",", "dim", "=", "1", ")", "\n", "\n", "# # Bias term", "\n", "# b = torch.randn(self.n_samples)", "\n", "# output += b", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_quadratic_regression.MaskedQuadraticRegression._init_weight": [[71, 91], ["range", "len", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.where", "torch.where", "torch.where", "torch.where", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.init.uniform_.to", "torch.nn.init.uniform_.to", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.init.uniform_.to", "torch.nn.init.uniform_.to", "int", "str"], "methods", ["None"], ["", "def", "_init_weight", "(", "self", ")", ":", "\n", "\n", "        ", "md", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "mask", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "w", "=", "{", "}", "\n", "pns_parents", "=", "torch", ".", "where", "(", "self", ".", "mask", "[", ":", ",", "i", "]", "==", "1", ")", "[", "0", "]", "\n", "first_input_dim", "=", "len", "(", "[", "int", "(", "j", ")", "for", "j", "in", "pns_parents", "if", "j", "!=", "i", "]", ")", "\n", "if", "first_input_dim", "==", "0", ":", "\n", "                ", "continue", "\n", "", "w1", "=", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "torch", ".", "Tensor", "(", "first_input_dim", ",", ")", ",", "\n", "a", "=", "-", "0.05", ",", "b", "=", "0.05", ")", "\n", "self", ".", "w1", "=", "torch", ".", "nn", ".", "Parameter", "(", "w1", ".", "to", "(", "device", "=", "self", ".", "device", ")", ")", "\n", "w2", "=", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "torch", ".", "Tensor", "(", "first_input_dim", ",", ")", ",", "\n", "a", "=", "-", "0.05", ",", "b", "=", "0.05", ")", "\n", "self", ".", "w2", "=", "torch", ".", "nn", ".", "Parameter", "(", "w2", ".", "to", "(", "device", "=", "self", ".", "device", ")", ")", "\n", "w", "[", "'w1'", "]", "=", "self", ".", "w1", "\n", "w", "[", "'w2'", "]", "=", "self", ".", "w2", "\n", "md", "[", "str", "(", "i", ")", "]", "=", "w", "\n", "\n", "", "self", ".", "weight", "=", "md", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_model.MaskedModel.__init__": [[25, 58], ["super().__init__", "torch.manual_seed", "torch.nn.init.uniform_", "torch.nn.Parameter", "masked_nn.MaskedNN", "torch.Tensor", "torch.nn.init.uniform_.to", "masked_quadratic_regression.MaskedQuadraticRegression", "TypeError"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_type", ",", "n_samples", ",", "n_nodes", ",", "pns_mask", ",", "hidden_layers", ",", "\n", "hidden_dim", ",", "l1_graph_penalty", ",", "seed", ",", "device", ")", "->", "None", ":", "\n", "        ", "super", "(", "MaskedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model_type", "=", "model_type", "\n", "self", ".", "n_samples", "=", "n_samples", "\n", "self", ".", "n_nodes", "=", "n_nodes", "\n", "self", ".", "pns_mask", "=", "pns_mask", "\n", "self", ".", "hidden_layers", "=", "hidden_layers", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "l1_graph_penalty", "=", "l1_graph_penalty", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "device", "=", "device", "\n", "\n", "if", "self", ".", "model_type", "==", "'nn'", ":", "\n", "            ", "self", ".", "masked_model", "=", "MaskedNN", "(", "mask", "=", "self", ".", "pns_mask", ",", "\n", "hidden_layers", "=", "self", ".", "hidden_layers", ",", "\n", "hidden_dim", "=", "self", ".", "hidden_dim", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "", "elif", "self", ".", "model_type", "==", "'qr'", ":", "# quadratic regression", "\n", "            ", "self", ".", "masked_model", "=", "MaskedQuadraticRegression", "(", "\n", "mask", "=", "self", ".", "pns_mask", ",", "\n", "n_samples", "=", "self", ".", "n_samples", ",", "\n", "n_nodes", "=", "self", ".", "n_nodes", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "f\"The argument `model_type` must be one of\"", "\n", "f\"['nn', 'qr'], but got {self.model_type}.\"", ")", "\n", "", "torch", ".", "manual_seed", "(", "self", ".", "seed", ")", "\n", "w", "=", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "torch", ".", "Tensor", "(", "self", ".", "n_nodes", ",", "self", ".", "n_nodes", ")", ",", "\n", "a", "=", "-", "1e-10", ",", "b", "=", "1e-10", ")", "\n", "self", ".", "w", "=", "torch", ".", "nn", ".", "Parameter", "(", "w", ".", "to", "(", "device", "=", "self", ".", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_model.MaskedModel.forward": [[59, 72], ["masked_model.MaskedModel._preprocess_graph", "masked_model.MaskedModel._get_mse_loss", "torch.trace", "torch.matrix_exp", "torch.linalg.norm"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_model.MaskedModel._preprocess_graph", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_model.MaskedModel._get_mse_loss"], ["", "def", "forward", "(", "self", ",", "x", ",", "rho", ",", "alpha", ",", "temperature", ")", "->", "tuple", ":", "\n", "\n", "        ", "w_prime", "=", "self", ".", "_preprocess_graph", "(", "self", ".", "w", ",", "tau", "=", "temperature", ",", "\n", "seed", "=", "self", ".", "seed", ")", "\n", "w_prime", "=", "self", ".", "pns_mask", "*", "w_prime", "\n", "mse_loss", "=", "self", ".", "_get_mse_loss", "(", "x", ",", "w_prime", ")", "\n", "h", "=", "(", "torch", ".", "trace", "(", "torch", ".", "matrix_exp", "(", "w_prime", "*", "w_prime", ")", ")", "-", "self", ".", "n_nodes", ")", "\n", "loss", "=", "(", "0.5", "/", "self", ".", "n_samples", "*", "mse_loss", "\n", "+", "self", ".", "l1_graph_penalty", "*", "torch", ".", "linalg", ".", "norm", "(", "w_prime", ",", "ord", "=", "1", ")", "\n", "+", "alpha", "*", "h", "\n", "+", "0.5", "*", "rho", "*", "h", "*", "h", ")", "\n", "\n", "return", "loss", ",", "h", ",", "self", ".", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_model.MaskedModel._preprocess_graph": [[73, 80], ["helpers.utils.gumbel_sigmoid", "torch.eye"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.gumbel_sigmoid"], ["", "def", "_preprocess_graph", "(", "self", ",", "w", ",", "tau", ",", "seed", "=", "0", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "w_prob", "=", "gumbel_sigmoid", "(", "w", ",", "temperature", "=", "tau", ",", "seed", "=", "seed", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "w_prob", "=", "(", "1.", "-", "torch", ".", "eye", "(", "w", ".", "shape", "[", "0", "]", ",", "device", "=", "self", ".", "device", ")", ")", "*", "w_prob", "\n", "\n", "return", "w_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.masked_model.MaskedModel._get_mse_loss": [[81, 103], ["range", "masked_model.MaskedModel.masked_model", "torch.where", "int", "len", "torch.sum", "str", "torch.square", "masked_model.MaskedModel.squeeze"], "methods", ["None"], ["", "def", "_get_mse_loss", "(", "self", ",", "x", ",", "w_prime", ")", ":", "\n", "        ", "\"\"\"\n        Different model for different nodes to use masked features to predict\n        value for each node.\n        \"\"\"", "\n", "\n", "mse_loss", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "n_nodes", ")", ":", "\n", "# Get possible PNS parents and also remove diagonal element", "\n", "            ", "pns_parents", "=", "torch", ".", "where", "(", "self", ".", "pns_mask", "[", ":", ",", "i", "]", "==", "1", ")", "[", "0", "]", "\n", "possible_parents", "=", "[", "int", "(", "j", ")", "for", "j", "in", "pns_parents", "if", "j", "!=", "i", "]", "\n", "if", "len", "(", "possible_parents", ")", "==", "0", ":", "# Root node, don't have to build NN in this case", "\n", "                ", "continue", "\n", "", "curr_x", "=", "x", "[", ":", ",", "possible_parents", "]", "# Features for current node", "\n", "curr_y", "=", "x", "[", ":", ",", "i", "]", "# Label for current node", "\n", "curr_w", "=", "w_prime", "[", "possible_parents", ",", "i", "]", "# Mask for current node", "\n", "curr_masked_x", "=", "curr_x", "*", "curr_w", "# Broadcasting", "\n", "curr_y_pred", "=", "self", ".", "masked_model", "(", "curr_masked_x", ",", "choice", "=", "str", "(", "i", ")", ")", "# Use masked features to predict value of current node", "\n", "\n", "mse_loss", "=", "mse_loss", "+", "torch", ".", "sum", "(", "torch", ".", "square", "(", "curr_y_pred", ".", "squeeze", "(", ")", "-", "curr_y", ")", ")", "\n", "\n", "", "return", "mse_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.Task.to_dict": [[82, 101], ["task_db.Task.create_time.strftime", "task_db.Task.update_time.strftime", "json.loads"], "methods", ["None"], ["def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Obtains the key-value pair information of an attribute field.\n\n        Returns\n        -------\n        {}\n        \"\"\"", "\n", "return", "{", "\"task_id\"", ":", "self", ".", "task_id", ",", "\n", "\"task_type\"", ":", "self", ".", "task_type", ",", "\n", "\"task_name\"", ":", "self", ".", "task_name", ",", "\n", "\"file_name\"", ":", "self", ".", "dataset", ",", "\n", "\"create_time\"", ":", "self", ".", "create_time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", ",", "\n", "\"update_time\"", ":", "self", ".", "update_time", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", ",", "\n", "\"consumed_time\"", ":", "self", ".", "consumed_time", ",", "\n", "\"task_status\"", ":", "self", ".", "task_status", ",", "\n", "\"performance\"", ":", "json", ".", "loads", "(", "self", ".", "performance", ")", "if", "self", ".", "performance", "\n", "else", "{", "}", ",", "\n", "\"label\"", ":", "self", ".", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.__init__": [[112, 114], ["web.models.models.get_session"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.models.get_session"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "session", "=", "get_session", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.__del__": [[115, 117], ["task_db.TaskApi.session.close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "session", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.list_tasks": [[118, 133], ["task_db.TaskApi.session.query", "task_db.TaskApi.all", "list", "list.append", "task.to_dict"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.Task.to_dict"], ["", "def", "list_tasks", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Obtaining Task List Information.\n\n        Returns\n        -------\n        tasks_list: list\n            task list\n        \"\"\"", "\n", "query", "=", "self", ".", "session", ".", "query", "(", "Task", ")", "\n", "tasks", "=", "query", ".", "all", "(", ")", "\n", "tasks_list", "=", "list", "(", ")", "\n", "for", "task", "in", "tasks", ":", "\n", "            ", "tasks_list", ".", "append", "(", "task", ".", "to_dict", "(", ")", ")", "\n", "", "return", "tasks_list", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task": [[134, 151], ["task_db.TaskApi.session.query().filter_by", "task_db.TaskApi.first", "task_db.TaskApi.session.query"], "methods", ["None"], ["", "def", "get_task", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "\"\"\"\n        Searching for Tasks by Task ID.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n\n        Returns\n        -------\n        task: dict\n            Task Fields.\n        \"\"\"", "\n", "query", "=", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter_by", "(", "task_id", "=", "task_id", ")", "\n", "task", "=", "query", ".", "first", "(", ")", "\n", "return", "task", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_performance": [[152, 171], ["task_db.TaskApi.get_task", "json.loads"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task"], ["", "def", "get_performance", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "\"\"\"\n        Obtains performance field information based on task ID.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n\n        Returns\n        -------\n        : dict\n        If there is performance information, the performance information dictionary is returned. Otherwise, None is returned.\n        \"\"\"", "\n", "task", "=", "self", ".", "get_task", "(", "task_id", ")", "\n", "if", "task", ".", "performance", ":", "\n", "            ", "return", "json", ".", "loads", "(", "task", ".", "performance", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_label": [[172, 190], ["task_db.TaskApi.get_task"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task"], ["", "", "def", "get_label", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "\"\"\"\n        Obtains built-in data name or real image file name.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n        Returns\n        -------\n        :str\n            Realistic Map Fields.\n        \"\"\"", "\n", "task", "=", "self", ".", "get_task", "(", "task_id", ")", "\n", "if", "task", ":", "\n", "            ", "return", "task", ".", "label", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.delete_tasks": [[191, 236], ["task_db.TaskApi.get_task", "task_db.TaskApi.get_task_name", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.join", "os.path.exists", "os.path.join", "os.path.exists", "task_db.TaskApi.session.delete", "task_db.TaskApi.session.commit", "os.remove", "os.remove", "os.remove", "os.remove", "os.remove", "str", "shutil.rmtree", "os.remove", "str", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_name"], ["", "", "def", "delete_tasks", "(", "self", ",", "task_ids", ")", ":", "\n", "        ", "\"\"\"\n        Delete tasks based on the task IDs list.\n\n        Parameters\n        ----------\n        task_ids: list\n            task id list.\n        Returns\n        -------\n\n        \"\"\"", "\n", "for", "task_id", "in", "task_ids", ":", "\n", "            ", "task", "=", "self", ".", "get_task", "(", "task_id", ")", "\n", "if", "task", ":", "\n", "                ", "data", "=", "task", ".", "dataset", "\n", "task_name", "=", "self", ".", "get_task_name", "(", "task_id", ")", "\n", "sample_path", "=", "os", ".", "path", ".", "join", "(", "data", ",", "\"datasets\"", ",", "str", "(", "task_id", ")", "+", "\"_\"", "+", "task_name", "+", "\".csv\"", ")", "\n", "true_dag_path", "=", "os", ".", "path", ".", "join", "(", "data", ",", "\"true\"", ",", "str", "(", "task_id", ")", "+", "\"_\"", "+", "task_name", "+", "\".npz\"", ")", "\n", "node_relationship_path", "=", "os", ".", "path", ".", "join", "(", "data", ",", "\"node_relationship_\"", "+", "str", "(", "task_id", ")", "+", "\"_\"", "+", "task_name", "+", "\".csv\"", ")", "\n", "topo_path", "=", "os", ".", "path", ".", "join", "(", "data", ",", "\"topo_\"", "+", "str", "(", "task_id", ")", "+", "\"_\"", "+", "task_name", "+", "\".npz\"", ")", "\n", "download_file", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "str", "(", "task_id", ")", "+", "\".zip\"", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "sample_path", ")", ":", "\n", "                    ", "os", ".", "remove", "(", "sample_path", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "true_dag_path", ")", ":", "\n", "                    ", "os", ".", "remove", "(", "true_dag_path", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "node_relationship_path", ")", ":", "\n", "                    ", "os", ".", "remove", "(", "node_relationship_path", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "topo_path", ")", ":", "\n", "                    ", "os", ".", "remove", "(", "topo_path", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "download_file", ")", ":", "\n", "                    ", "os", ".", "remove", "(", "download_file", ")", "\n", "\n", "", "result_data", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "\"task\"", ",", "str", "(", "task_id", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "result_data", ")", ":", "\n", "                    ", "shutil", ".", "rmtree", "(", "result_data", ")", "\n", "\n", "", "download_file", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "\"task\"", ",", "str", "(", "task_id", ")", "+", "\".zip\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "download_file", ")", ":", "\n", "                    ", "os", ".", "remove", "(", "download_file", ")", "\n", "\n", "", "self", ".", "session", ".", "delete", "(", "task", ")", "\n", "self", ".", "session", ".", "commit", "(", ")", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.add_task": [[237, 271], ["datetime.datetime.now", "task_db.Task", "task_db.TaskApi.session.add", "task_db.TaskApi.session.commit", "task_db.TaskApi.session.query().filter().update", "task_db.TaskApi.session.commit", "task_db.TaskApi.session.query().filter", "task_db.TaskApi.session.query"], "methods", ["None"], ["", "def", "add_task", "(", "self", ",", "task_type", ",", "task_name", ",", "task_id", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Create or update a task.\n\n        Parameters\n        ----------\n        task_type: int\n            1 or 2.\n        task_name: str\n            The user enters a character string.\n        task_id: int\n            task key in the database.\n        Returns\n        -------\n        task_id: int\n            task key in the database.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "if", "task_id", "is", "None", ":", "\n", "                ", "create_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "task", "=", "Task", "(", "task_type", "=", "task_type", ",", "task_name", "=", "task_name", ",", "create_time", "=", "create_time", ")", "\n", "self", ".", "session", ".", "add", "(", "task", ")", "\n", "self", ".", "session", ".", "commit", "(", ")", "\n", "task_id", "=", "task", ".", "task_id", "\n", "", "else", ":", "\n", "                ", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter", "(", "\n", "Task", ".", "task_id", "==", "task_id", ")", ".", "update", "(", "{", "\n", "Task", ".", "task_name", ":", "task_name", "\n", "}", ")", "\n", "self", ".", "session", ".", "commit", "(", ")", "\n", "", "", "except", "DatabaseError", ":", "\n", "            ", "return", "None", "\n", "\n", "", "return", "task_id", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_performance": [[272, 293], ["task_db.TaskApi.session.query().filter_by().first", "json.dumps", "task_db.TaskApi.session.commit", "task_db.TaskApi.session.query().filter_by", "task_db.TaskApi.session.query"], "methods", ["None"], ["", "def", "update_performance", "(", "self", ",", "task_id", ",", "label_path", ",", "evaluation_metrics", ")", ":", "\n", "        ", "\"\"\"\n        Update Performance Fields.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n        label_path: str\n            Realistic path string or built-in data name.\n        evaluation_metrics: dict\n            Evaluation indicator key-value pair.\n        Returns\n        -------\n\n        \"\"\"", "\n", "query", "=", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter_by", "(", "task_id", "=", "task_id", ")", ".", "first", "(", ")", "\n", "query", ".", "label", "=", "label_path", "\n", "query", ".", "performance", "=", "json", ".", "dumps", "(", "evaluation_metrics", ")", "\n", "self", ".", "session", ".", "commit", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_est_dag": [[294, 312], ["task_db.TaskApi.session.query().filter_by().first", "json.dumps", "task_db.TaskApi.session.commit", "est_dag.tolist", "task_db.TaskApi.session.query().filter_by", "task_db.TaskApi.session.query"], "methods", ["None"], ["", "def", "update_est_dag", "(", "self", ",", "task_id", ",", "est_dag", ")", ":", "\n", "        ", "\"\"\"\n        Update Prediction Chart.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n        est_dag: str\n            Prediction Graph String.\n        Returns\n        -------\n\n        \"\"\"", "\n", "query", "=", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter_by", "(", "task_id", "=", "task_id", ")", ".", "first", "(", ")", "\n", "query", ".", "est_dag", "=", "json", ".", "dumps", "(", "est_dag", ".", "tolist", "(", ")", ")", "\n", "self", ".", "session", ".", "commit", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_true_dag": [[313, 333], ["task_db.TaskApi.session.query().filter_by().first", "json.dumps", "task_db.TaskApi.session.commit", "true_dag.tolist", "task_db.TaskApi.session.query().filter_by", "task_db.TaskApi.session.query"], "methods", ["None"], ["", "def", "update_true_dag", "(", "self", ",", "task_id", ",", "true_dag", ")", ":", "\n", "        ", "\"\"\"\n        Update Realistic Graph String.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n        true_dag: str\n            Realistic Graph String.\n        Returns\n        -------\n\n        \"\"\"", "\n", "if", "true_dag", "is", "None", ":", "\n", "            ", "return", "False", "\n", "", "query", "=", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter_by", "(", "task_id", "=", "task_id", ")", ".", "first", "(", ")", "\n", "query", ".", "true_dag", "=", "json", ".", "dumps", "(", "true_dag", ".", "tolist", "(", ")", ")", "\n", "self", ".", "session", ".", "commit", "(", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_est_dag": [[334, 352], ["task_db.TaskApi.get_task", "numpy.array", "json.loads"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task"], ["", "def", "get_est_dag", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "\"\"\"\n        Obtains  Prediction Chart.\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n\n        Returns\n        -------\n        :np.array or None\n\n        \"\"\"", "\n", "task", "=", "self", ".", "get_task", "(", "task_id", ")", "\n", "if", "task", ".", "est_dag", ":", "\n", "            ", "return", "np", ".", "array", "(", "json", ".", "loads", "(", "task", ".", "est_dag", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_true_dag": [[353, 371], ["task_db.TaskApi.get_task", "numpy.array", "json.loads"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task"], ["", "", "def", "get_true_dag", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "\"\"\"\n        Obtains  Realistic Graph String.\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n\n        Returns\n        -------\n        :np.array or None\n\n        \"\"\"", "\n", "task", "=", "self", ".", "get_task", "(", "task_id", ")", "\n", "if", "task", ".", "true_dag", ":", "\n", "            ", "return", "np", ".", "array", "(", "json", ".", "loads", "(", "task", ".", "true_dag", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_type": [[372, 391], ["task_db.TaskApi.get_task"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task"], ["", "", "def", "get_task_type", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "\"\"\"\n        Obtains task type.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n\n        Returns\n        -------\n        :int\n            1 or 2.\n        \"\"\"", "\n", "task", "=", "self", ".", "get_task", "(", "task_id", ")", "\n", "if", "task", ".", "task_type", ":", "\n", "            ", "return", "task", ".", "task_type", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_name": [[392, 410], ["task_db.TaskApi.get_task"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task"], ["", "", "def", "get_task_name", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "\"\"\"\n        Obtains task name.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n\n        Returns\n        -------\n        : str\n        \"\"\"", "\n", "task", "=", "self", ".", "get_task", "(", "task_id", ")", "\n", "if", "task", ".", "task_name", ":", "\n", "            ", "return", "task", ".", "task_name", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_simulation_name": [[411, 425], ["task_db.TaskApi.session.query().filter_by", "task_db.TaskApi.all", "list", "list.append", "task_db.TaskApi.session.query", "str"], "methods", ["None"], ["", "", "def", "get_simulation_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Obtains the built-in data name list.\n        Returns\n        -------\n        name_list: list\n            Data generated by a data generation task in the task list.\n        \"\"\"", "\n", "query", "=", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter_by", "(", "task_type", "=", "\"1\"", ")", "\n", "tasks", "=", "query", ".", "all", "(", ")", "\n", "name_list", "=", "list", "(", ")", "\n", "for", "task", "in", "tasks", ":", "\n", "            ", "name_list", ".", "append", "(", "str", "(", "task", ".", "task_id", ")", "+", "\"_\"", "+", "task", ".", "task_name", ")", "\n", "", "return", "name_list", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status": [[426, 444], ["task_db.TaskApi.session.query().filter().update", "task_db.TaskApi.session.commit", "task_db.TaskApi.session.query().filter", "task_db.TaskApi.session.query"], "methods", ["None"], ["", "def", "update_task_status", "(", "self", ",", "task_id", ",", "status", ")", ":", "\n", "        ", "\"\"\"\n        Update task status.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n        status: str\n            task status.\n\n        Returns\n        -------\n\n        \"\"\"", "\n", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter", "(", "Task", ".", "task_id", "==", "task_id", ")", ".", "update", "(", "{", "\n", "Task", ".", "task_status", ":", "status", "}", ")", "\n", "self", ".", "session", ".", "commit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time": [[445, 465], ["datetime.datetime.now", "task_db.TaskApi.session.query().filter().update", "task_db.TaskApi.session.commit", "task_db.TaskApi.session.query().filter", "round", "consumed_time.total_seconds", "task_db.TaskApi.session.query"], "methods", ["None"], ["", "def", "update_consumed_time", "(", "self", ",", "task_id", ",", "start_time", ")", ":", "\n", "        ", "\"\"\"\n        Update consumed time.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n        start_time: datetime.datetime\n            Task Start Time.\n\n        Returns\n        -------\n\n        \"\"\"", "\n", "end_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "consumed_time", "=", "end_time", "-", "start_time", "\n", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter", "(", "Task", ".", "task_id", "==", "task_id", ")", ".", "update", "(", "{", "\n", "Task", ".", "consumed_time", ":", "round", "(", "consumed_time", ".", "total_seconds", "(", ")", ",", "2", ")", "}", ")", "\n", "self", ".", "session", ".", "commit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_update_time": [[466, 484], ["task_db.TaskApi.session.query().filter_by().first", "task_db.TaskApi.session.commit", "task_db.TaskApi.session.query().filter_by", "task_db.TaskApi.session.query"], "methods", ["None"], ["", "def", "update_update_time", "(", "self", ",", "task_id", ",", "update_time", ")", ":", "\n", "        ", "\"\"\"\n        Update task update time.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n        update_time: datetime.datetime\n            Task update time.\n        Returns\n        -------\n\n        \"\"\"", "\n", "query", "=", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter_by", "(", "task_id", "=", "task_id", ")", ".", "first", "(", ")", "\n", "query", ".", "update_time", "=", "update_time", "\n", "self", ".", "session", ".", "commit", "(", ")", "\n", "return", "True", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.models.get_engine": [[23, 34], ["sqlalchemy.create_engine"], "function", ["None"], ["\n", "import", "math", "\n", "\n", "import", "torch", "\n", "import", "torch", ".", "nn", "as", "nn", "\n", "import", "numpy", "as", "np", "\n", "from", ".", "utils", ".", "locally_connected", "import", "LocallyConnected", "\n", "\n", "\n", "torch", ".", "set_default_dtype", "(", "torch", ".", "double", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.models.get_session_maker": [[36, 52], ["sqlalchemy.orm.sessionmaker"], "function", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dims", ",", "bias", "=", "True", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Multilayer perceptron.\n\n        Parameters\n        ----------\n        dims: tuple\n            Network shape parameters\n        bias:\n            Indicates whether to use weight deviation.\n        device: option, default: None\n            torch.device('cpu') or torch.device('cuda')\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "dims", ")", ">=", "2", "\n", "assert", "dims", "[", "-", "1", "]", "==", "1", "\n", "d", "=", "dims", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.models.get_session": [[54, 66], ["models.get_engine", "models.get_session_maker", "get_session_maker."], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.models.get_engine", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.models.get_session_maker"], ["# fc1: variable splitting for l1", "\n", "self", ".", "fc1_pos", "=", "nn", ".", "Linear", "(", "d", ",", "d", "*", "dims", "[", "1", "]", ",", "bias", "=", "bias", ")", "\n", "self", ".", "fc1_neg", "=", "nn", ".", "Linear", "(", "d", ",", "d", "*", "dims", "[", "1", "]", ",", "bias", "=", "bias", ")", "\n", "self", ".", "fc1_pos", ".", "weight", ".", "bounds", "=", "self", ".", "_bounds", "(", ")", "\n", "self", ".", "fc1_neg", ".", "weight", ".", "bounds", "=", "self", ".", "_bounds", "(", ")", "\n", "# fc2: local linear layers", "\n", "layers", "=", "[", "]", "\n", "for", "l", "in", "range", "(", "len", "(", "dims", ")", "-", "2", ")", ":", "\n", "            ", "layers", ".", "append", "(", "LocallyConnected", "(", "d", ",", "dims", "[", "l", "+", "1", "]", ",", "dims", "[", "l", "+", "2", "]", ",", "bias", "=", "bias", ")", ")", "\n", "", "self", ".", "fc2", "=", "nn", ".", "ModuleList", "(", "layers", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n", "", "def", "_bounds", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.__init__": [[42, 45], ["web.models.models.get_session"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.models.get_session"], ["def", "__init__", "(", "self", ",", "name_path", "=", "None", ")", ":", "\n", "        ", "self", ".", "name_path", "=", "name_path", "\n", "self", ".", "session", "=", "get_session", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.__del__": [[46, 48], ["base_class.DataSetApi.session.close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "session", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.get_inline_dataset_names": [[49, 58], ["web.models.task_db.TaskApi().get_simulation_name", "web.models.task_db.TaskApi"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_simulation_name"], ["", "@", "classmethod", "\n", "def", "get_inline_dataset_names", "(", "cls", ")", ":", "\n", "        ", "\"\"\"\n        Combine the task ID and task name into a built-in dataset and obtain the list of built-in dataset names.        Returns\n        -------\n\n        \"\"\"", "\n", "dataset_names", "=", "TaskApi", "(", ")", ".", "get_simulation_name", "(", ")", "\n", "return", "dataset_names", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.set_dataset_info": [[59, 79], ["base_class.DataSetApi.session.query().filter().update", "base_class.DataSetApi.session.commit", "base_class.DataSetApi.session.query().filter", "base_class.DataSetApi.session.query"], "methods", ["None"], ["", "def", "set_dataset_info", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "\"\"\"\n        Update the dataset field of the database.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n        Returns\n        -------\n             True or False\n        \"\"\"", "\n", "try", ":", "\n", "            ", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter", "(", "Task", ".", "task_id", "==", "task_id", ")", ".", "update", "(", "{", "\n", "Task", ".", "dataset", ":", "self", ".", "name_path", "\n", "}", ")", "\n", "self", ".", "session", ".", "commit", "(", ")", "\n", "return", "True", "\n", "", "except", "DatabaseError", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.check_dataset": [[80, 107], ["os.path.isfile", "str", "pandas.read_excel", "pandas.read_csv", "pandas.read_csv.dtypes.unique", "len", "pandas.read_csv.dtypes.unique"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "check_dataset", "(", "cls", ",", "path", ")", ":", "\n", "        ", "\"\"\"\n        Check whether the data file exists.\n\n        Parameters\n        ----------\n        path: str\n            Data File Name.\n\n        Returns\n        -------\n            True or False\n        \"\"\"", "\n", "if", "os", ".", "path", ".", "isfile", "(", "path", ")", ":", "\n", "            ", "if", "'.xls'", "in", "path", ":", "\n", "                ", "data_df", "=", "pd", ".", "read_excel", "(", "path", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "", "elif", "'.csv'", "in", "path", ":", "\n", "                ", "data_df", "=", "pd", ".", "read_csv", "(", "path", ")", "\n", "", "else", ":", "\n", "                ", "return", "None", "\n", "\n", "", "data_type", "=", "str", "(", "data_df", ".", "dtypes", ".", "unique", "(", ")", "[", "0", "]", ")", "\n", "if", "len", "(", "data_df", ".", "dtypes", ".", "unique", "(", ")", ")", "==", "1", "and", "(", "'float'", "in", "data_type", "or", "'int'", "in", "data_type", ")", ":", "\n", "                ", "return", "data_df", ".", "shape", "[", "1", "]", "\n", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.get_dataset": [[108, 127], ["web.models.task_db.TaskApi().get_task", "web.models.task_db.TaskApi"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task"], ["", "@", "classmethod", "\n", "def", "get_dataset", "(", "cls", ",", "task_id", ")", ":", "\n", "        ", "\"\"\"\n        Obtaining Data File Names.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n        Returns\n        -------\n        dataset: str\n            name(inline) or dataset path(customize)\n        \"\"\"", "\n", "task", "=", "TaskApi", "(", ")", ".", "get_task", "(", "task_id", ")", "\n", "if", "task", ":", "\n", "            ", "dataset", "=", "task", ".", "dataset", "\n", "return", "dataset", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.AlgorithmApi.__init__": [[145, 149], ["web.models.models.get_session"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.models.get_session"], ["def", "__init__", "(", "self", ",", "name", ",", "params", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "session", "=", "get_session", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.AlgorithmApi.__del__": [[150, 152], ["base_class.AlgorithmApi.session.close"], "methods", ["None"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "session", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.AlgorithmApi.get_algorithm_names": [[153, 165], ["list", "example.example.INLINE_ALGORITHMS.keys"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_algorithm_names", "(", "cls", ")", ":", "\n", "        ", "\"\"\"\n        Obtains the list of all algorithm names.\n\n        Returns\n        -------\n        algorithm_names: list\n            List of all algorithm names\n        \"\"\"", "\n", "algorithm_names", "=", "list", "(", "INLINE_ALGORITHMS", ".", "keys", "(", ")", ")", "\n", "return", "algorithm_names", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.AlgorithmApi.set_algorithm_info": [[166, 196], ["base_class.AlgorithmApi.session.query().filter().update", "base_class.AlgorithmApi.session.commit", "base_class.AlgorithmApi.session.query().filter().first", "json.loads", "base_class.AlgorithmApi.session.query().filter", "base_class.AlgorithmApi.session.query().filter", "base_class.AlgorithmApi.session.query", "base_class.AlgorithmApi.session.query"], "methods", ["None"], ["", "def", "set_algorithm_info", "(", "self", ",", "task_id", ")", ":", "\n", "        ", "\"\"\"\n        Create or update algorithm info of a task.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n        Returns\n        -------\n        tuple (HTML status code, dict)\n            dict, task info\n        \"\"\"", "\n", "try", ":", "\n", "            ", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter", "(", "Task", ".", "task_id", "==", "task_id", ")", ".", "update", "(", "{", "\n", "Task", ".", "algorithm", ":", "self", ".", "name", ",", "\n", "Task", ".", "parameters", ":", "self", ".", "params", "\n", "}", ")", "\n", "\n", "self", ".", "session", ".", "commit", "(", ")", "\n", "task", "=", "self", ".", "session", ".", "query", "(", "Task", ")", ".", "filter", "(", "Task", ".", "task_id", "==", "task_id", ")", ".", "first", "(", ")", "\n", "task_info", "=", "{", "'task_id'", ":", "task", ".", "task_id", ",", "\n", "'task_name'", ":", "task", ".", "task_name", ",", "\n", "'dataset'", ":", "task", ".", "dataset", ",", "\n", "'algorithm'", ":", "task", ".", "algorithm", ",", "\n", "'parameters'", ":", "json", ".", "loads", "(", "task", ".", "parameters", ")", ",", "\n", "}", "\n", "return", "200", ",", "task_info", "\n", "", "except", "DatabaseError", ":", "\n", "            ", "return", "400", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.AlgorithmApi.get_algorithm_params": [[197, 213], ["web.common.utils.algorithm_parameters"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.algorithm_parameters"], ["", "", "@", "classmethod", "\n", "def", "get_algorithm_params", "(", "cls", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Obtaining Algorithm Parameter Configuration Items\n\n        Parameters\n        ----------\n        name: str\n            algorithm name.\n        Returns\n        -------\n        params: dict\n            Key-value pair of the parameter name and default value.\n        \"\"\"", "\n", "params", "=", "algorithm_parameters", "(", "name", ")", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.AlgorithmApi.get_algorithm": [[214, 233], ["web.models.task_db.TaskApi().get_task", "json.loads", "web.models.task_db.TaskApi"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task"], ["", "@", "classmethod", "\n", "def", "get_algorithm", "(", "cls", ",", "task_id", ")", ":", "\n", "        ", "\"\"\"\n        Obtain the algorithm and parameters of the task.\n\n        Parameters\n        ----------\n        task_id: int\n            task key in the database.\n        Returns\n        -------\n            {'name': ***, 'parameters': {}}\n        \"\"\"", "\n", "task", "=", "TaskApi", "(", ")", ".", "get_task", "(", "task_id", ")", "\n", "if", "task", ".", "algorithm", "and", "task", ".", "parameters", ":", "\n", "            ", "algorithm", "=", "task", ".", "algorithm", "\n", "parameters", "=", "json", ".", "loads", "(", "task", ".", "parameters", ")", "\n", "return", "{", "'algorithm'", ":", "algorithm", ",", "'parameters'", ":", "parameters", "}", "\n", "", "return", "{", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_pendulum.CausalVAE.__init__": [[20, 44], ["getattr.Module.__init__", "numpy.array", "getattr", "getattr.Encoder", "getattr.Decoder_DAG", "getattr.DagLayer", "getattr.Attention", "getattr.MaskLayer", "getattr.MaskLayer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nn", "=", "'mask'", ",", "name", "=", "'vae'", ",", "z_dim", "=", "16", ",", "z1_dim", "=", "4", ",", "z2_dim", "=", "4", ",", "inference", "=", "False", ",", "alpha", "=", "0.3", ",", "beta", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "z1_dim", "=", "z1_dim", "\n", "self", ".", "z2_dim", "=", "z2_dim", "\n", "self", ".", "channel", "=", "4", "\n", "self", ".", "scale", "=", "np", ".", "array", "(", "[", "[", "0", ",", "44", "]", ",", "[", "100", ",", "40", "]", ",", "[", "6.5", ",", "3.5", "]", ",", "[", "10", ",", "5", "]", "]", ")", "\n", "# Small note: unfortunate name clash with torch.nn", "\n", "# nn here refers to the specific architecture file found in", "\n", "# codebase/models/nns/*.py", "\n", "nn", "=", "getattr", "(", "nns", ",", "nn", ")", "\n", "self", ".", "enc", "=", "nn", ".", "Encoder", "(", "self", ".", "z_dim", ",", "self", ".", "channel", ")", "\n", "self", ".", "dec", "=", "nn", ".", "Decoder_DAG", "(", "self", ".", "z_dim", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", "\n", "self", ".", "dag", "=", "nn", ".", "DagLayer", "(", "self", ".", "z1_dim", ",", "self", ".", "z1_dim", ",", "i", "=", "inference", ")", "\n", "#self.cause = nn.CausalLayer(self.z_dim, self.z1_dim, self.z2_dim)", "\n", "self", ".", "attn", "=", "nn", ".", "Attention", "(", "self", ".", "z1_dim", ")", "\n", "self", ".", "mask_z", "=", "nn", ".", "MaskLayer", "(", "self", ".", "z_dim", ")", "\n", "self", ".", "mask_u", "=", "nn", ".", "MaskLayer", "(", "self", ".", "z1_dim", ",", "z1_dim", "=", "1", ")", "\n", "\n", "# Set prior as fixed parameter attached to Module", "\n", "self", ".", "z_prior_m", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "z_prior_v", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "z_prior", "=", "(", "self", ".", "z_prior_m", ",", "self", ".", "z_prior_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_pendulum.CausalVAE.negative_elbo_bound": [[45, 117], ["mask_vae_pendulum.CausalVAE.enc.encode", "mask_vae_pendulum.CausalVAE.dag.calculate_dag", "mask_vae_pendulum.CausalVAE.dec.decode_sep", "codebase.utils.log_bernoulli_with_logits", "codebase.utils.condition_prior", "torch.ones().to", "codebase.utils.conditional_sample_gaussian", "torch.zeros().to", "range", "torch.mean", "torch.zeros().to", "torch.zeros().to", "range", "torch.nn.MSELoss", "x.to", "q_m.reshape", "torch.ones().to", "q_m.to", "torch.ones().to", "decode_m.reshape", "mask_vae_pendulum.CausalVAE.dag.mask_u", "mask_vae_pendulum.CausalVAE.mask_z.mix().reshape().to", "mask_vae_pendulum.CausalVAE.mask_u.mix().to", "codebase.utils.conditional_sample_gaussian", "codebase.utils.conditional_sample_gaussian.reshape", "label.to", "decoded_bernoulli_logits.reshape", "torch.mean", "torch.zeros", "torch.ones", "cp_m.to", "torch.ones().to.to", "codebase.utils.kl_normal", "torch.mean", "torch.nn.MSELoss.", "decoded_bernoulli_logits.reshape", "label.size", "mask_vae_pendulum.CausalVAE.dag.mask_z().reshape", "decode_v.reshape", "label.to", "mask_vae_pendulum.CausalVAE.attn.attention", "x.size", "q_m.size", "q_m.size", "torch.ones", "torch.zeros", "q_m.view().to", "q_v.view().to", "p_m.view().to", "p_v.view().to", "torch.zeros", "torch.zeros", "label.float().to", "x.size", "torch.ones", "torch.ones", "torch.ones().to", "mask_vae_pendulum.CausalVAE.mask_z.mix().reshape", "decode_m.reshape().to", "q_m.reshape().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "mask_vae_pendulum.CausalVAE.mask_u.mix", "codebase.utils.kl_normal", "codebase.utils.kl_normal", "q_m.size", "q_m.size", "mask_vae_pendulum.CausalVAE.dag.mask_z", "codebase.utils.conditional_sample_gaussian.size", "q_m.view", "q_v.view", "p_m.view", "p_v.view", "decode_m[].to", "cp_v[].to", "cp_m[].to", "cp_v[].to", "f_z1[].to", "cp_v[].to", "cp_m[].to", "cp_v[].to", "label.float", "q_m.size", "q_m.size", "torch.ones", "decode_m.to", "q_m.size", "q_m.size", "mask_vae_pendulum.CausalVAE.mask_z.mix", "decode_m.reshape", "q_m.reshape", "torch.ones", "torch.ones", "torch.ones", "q_m.size", "q_m.size", "q_m.size", "q_m.size", "q_m.size", "q_m.size", "q_m.size", "q_m.size"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Encoder.encode", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.calculate_dag", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder_DAG.decode_sep", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_bernoulli_with_logits", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.condition_prior", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.conditional_sample_gaussian", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.mask_u", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.conditional_sample_gaussian", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.kl_normal", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Attention.attention", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Mix.mix", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.kl_normal", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.kl_normal", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.mask_z", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Mix.mix"], ["", "def", "negative_elbo_bound", "(", "self", ",", "x", ",", "label", ",", "mask", "=", "None", ",", "sample", "=", "False", ",", "adj", "=", "None", ",", "alpha", "=", "0.3", ",", "beta", "=", "1", ",", "lambdav", "=", "0.001", ")", ":", "\n", "        ", "\"\"\"\n        Computes the Evidence Lower Bound, KL and, Reconstruction costs\n\n        Args:\n            x: tensor: (batch, dim): Observations\n\n        Returns:\n            nelbo: tensor: (): Negative evidence lower bound\n            kl: tensor: (): ELBO KL divergence to prior\n            rec: tensor: (): ELBO Reconstruction term\n        \"\"\"", "\n", "assert", "label", ".", "size", "(", ")", "[", "1", "]", "==", "self", ".", "z1_dim", "\n", "\n", "q_m", ",", "q_v", "=", "self", ".", "enc", ".", "encode", "(", "x", ".", "to", "(", "device", ")", ")", "\n", "q_m", ",", "q_v", "=", "q_m", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ",", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", ".", "to", "(", "device", ")", "\n", "\n", "decode_m", ",", "decode_v", "=", "self", ".", "dag", ".", "calculate_dag", "(", "q_m", ".", "to", "(", "device", ")", ",", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", ".", "to", "(", "device", ")", ")", "\n", "decode_m", ",", "decode_v", "=", "decode_m", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ",", "decode_v", "\n", "if", "sample", "==", "False", ":", "\n", "          ", "if", "mask", "!=", "None", "and", "mask", "<", "2", ":", "\n", "              ", "z_mask", "=", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", ".", "to", "(", "device", ")", "*", "adj", "\n", "decode_m", "[", ":", ",", "mask", ",", ":", "]", "=", "z_mask", "[", ":", ",", "mask", ",", ":", "]", "\n", "decode_v", "[", ":", ",", "mask", ",", ":", "]", "=", "z_mask", "[", ":", ",", "mask", ",", ":", "]", "\n", "", "m_zm", ",", "m_zv", "=", "self", ".", "dag", ".", "mask_z", "(", "decode_m", ".", "to", "(", "device", ")", ")", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ",", "decode_v", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", "\n", "m_u", "=", "self", ".", "dag", ".", "mask_u", "(", "label", ".", "to", "(", "device", ")", ")", "\n", "\n", "f_z", "=", "self", ".", "mask_z", ".", "mix", "(", "m_zm", ")", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ".", "to", "(", "device", ")", "\n", "e_tilde", "=", "self", ".", "attn", ".", "attention", "(", "decode_m", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ".", "to", "(", "device", ")", ",", "q_m", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ".", "to", "(", "device", ")", ")", "[", "0", "]", "\n", "if", "mask", "!=", "None", "and", "mask", "<", "2", ":", "\n", "              ", "z_mask", "=", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", ".", "to", "(", "device", ")", "*", "adj", "\n", "e_tilde", "[", ":", ",", "mask", ",", ":", "]", "=", "z_mask", "[", ":", ",", "mask", ",", ":", "]", "\n", "\n", "", "f_z1", "=", "f_z", "+", "e_tilde", "\n", "if", "mask", "!=", "None", "and", "mask", "==", "2", ":", "\n", "              ", "z_mask", "=", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", ".", "to", "(", "device", ")", "*", "adj", "\n", "f_z1", "[", ":", ",", "mask", ",", ":", "]", "=", "z_mask", "[", ":", ",", "mask", ",", ":", "]", "\n", "m_zv", "[", ":", ",", "mask", ",", ":", "]", "=", "z_mask", "[", ":", ",", "mask", ",", ":", "]", "\n", "", "if", "mask", "!=", "None", "and", "mask", "==", "3", ":", "\n", "              ", "z_mask", "=", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", ".", "to", "(", "device", ")", "*", "adj", "\n", "f_z1", "[", ":", ",", "mask", ",", ":", "]", "=", "z_mask", "[", ":", ",", "mask", ",", ":", "]", "\n", "m_zv", "[", ":", ",", "mask", ",", ":", "]", "=", "z_mask", "[", ":", ",", "mask", ",", ":", "]", "\n", "", "g_u", "=", "self", ".", "mask_u", ".", "mix", "(", "m_u", ")", ".", "to", "(", "device", ")", "\n", "z_given_dag", "=", "ut", ".", "conditional_sample_gaussian", "(", "f_z1", ",", "m_zv", "*", "lambdav", ")", "\n", "\n", "", "decoded_bernoulli_logits", ",", "x1", ",", "x2", ",", "x3", ",", "x4", "=", "self", ".", "dec", ".", "decode_sep", "(", "z_given_dag", ".", "reshape", "(", "[", "z_given_dag", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z_dim", "]", ")", ",", "label", ".", "to", "(", "device", ")", ")", "\n", "\n", "rec", "=", "ut", ".", "log_bernoulli_with_logits", "(", "x", ",", "decoded_bernoulli_logits", ".", "reshape", "(", "x", ".", "size", "(", ")", ")", ")", "\n", "rec", "=", "-", "torch", ".", "mean", "(", "rec", ")", "\n", "\n", "p_m", ",", "p_v", "=", "torch", ".", "zeros", "(", "q_m", ".", "size", "(", ")", ")", ",", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", ")", "\n", "cp_m", ",", "cp_v", "=", "ut", ".", "condition_prior", "(", "self", ".", "scale", ",", "label", ",", "self", ".", "z2_dim", ")", "\n", "cp_v", "=", "torch", ".", "ones", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ".", "to", "(", "device", ")", "\n", "cp_z", "=", "ut", ".", "conditional_sample_gaussian", "(", "cp_m", ".", "to", "(", "device", ")", ",", "cp_v", ".", "to", "(", "device", ")", ")", "\n", "kl", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "device", ")", "\n", "kl", "=", "alpha", "*", "ut", ".", "kl_normal", "(", "q_m", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", ",", "q_v", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", ",", "p_m", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", ",", "p_v", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "z1_dim", ")", ":", "\n", "            ", "kl", "=", "kl", "+", "beta", "*", "ut", ".", "kl_normal", "(", "decode_m", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_v", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_m", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_v", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ")", "\n", "", "kl", "=", "torch", ".", "mean", "(", "kl", ")", "\n", "mask_kl", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "device", ")", "\n", "mask_kl2", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "            ", "mask_kl", "=", "mask_kl", "+", "1", "*", "ut", ".", "kl_normal", "(", "f_z1", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_v", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_m", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_v", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ")", "\n", "\n", "\n", "", "u_loss", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "mask_l", "=", "torch", ".", "mean", "(", "mask_kl", ")", "+", "u_loss", "(", "g_u", ",", "label", ".", "float", "(", ")", ".", "to", "(", "device", ")", ")", "\n", "nelbo", "=", "rec", "+", "kl", "+", "mask_l", "\n", "\n", "return", "nelbo", ",", "kl", ",", "rec", ",", "decoded_bernoulli_logits", ".", "reshape", "(", "x", ".", "size", "(", ")", ")", ",", "z_given_dag", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_pendulum.CausalVAE.loss": [[118, 130], ["mask_vae_pendulum.CausalVAE.negative_elbo_bound", "dict"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.negative_elbo_bound"], ["", "def", "loss", "(", "self", ",", "x", ")", ":", "\n", "        ", "nelbo", ",", "kl", ",", "rec", "=", "self", ".", "negative_elbo_bound", "(", "x", ")", "\n", "loss", "=", "nelbo", "\n", "\n", "summaries", "=", "dict", "(", "(", "\n", "(", "'train/loss'", ",", "nelbo", ")", ",", "\n", "(", "'gen/elbo'", ",", "-", "nelbo", ")", ",", "\n", "(", "'gen/kl_z'", ",", "kl", ")", ",", "\n", "(", "'gen/rec'", ",", "rec", ")", ",", "\n", ")", ")", "\n", "\n", "return", "loss", ",", "summaries", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_pendulum.CausalVAE.sample_sigmoid": [[131, 134], ["mask_vae_pendulum.CausalVAE.sample_z", "mask_vae_pendulum.CausalVAE.compute_sigmoid_given"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.sample_z", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.compute_sigmoid_given"], ["", "def", "sample_sigmoid", "(", "self", ",", "batch", ")", ":", "\n", "        ", "z", "=", "self", ".", "sample_z", "(", "batch", ")", "\n", "return", "self", ".", "compute_sigmoid_given", "(", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_pendulum.CausalVAE.compute_sigmoid_given": [[135, 138], ["mask_vae_pendulum.CausalVAE.dec.decode", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder.decode"], ["", "def", "compute_sigmoid_given", "(", "self", ",", "z", ")", ":", "\n", "        ", "logits", "=", "self", ".", "dec", ".", "decode", "(", "z", ")", "\n", "return", "torch", ".", "sigmoid", "(", "logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_pendulum.CausalVAE.sample_z": [[139, 143], ["codebase.utils.sample_gaussian", "mask_vae_pendulum.CausalVAE.z_prior[].expand", "mask_vae_pendulum.CausalVAE.z_prior[].expand"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.sample_gaussian"], ["", "def", "sample_z", "(", "self", ",", "batch", ")", ":", "\n", "        ", "return", "ut", ".", "sample_gaussian", "(", "\n", "self", ".", "z_prior", "[", "0", "]", ".", "expand", "(", "batch", ",", "self", ".", "z_dim", ")", ",", "\n", "self", ".", "z_prior", "[", "1", "]", ".", "expand", "(", "batch", ",", "self", ".", "z_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_pendulum.CausalVAE.sample_x": [[144, 147], ["mask_vae_pendulum.CausalVAE.sample_z", "mask_vae_pendulum.CausalVAE.sample_x_given"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.sample_z", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.sample_x_given"], ["", "def", "sample_x", "(", "self", ",", "batch", ")", ":", "\n", "        ", "z", "=", "self", ".", "sample_z", "(", "batch", ")", "\n", "return", "self", ".", "sample_x_given", "(", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_pendulum.CausalVAE.sample_x_given": [[148, 150], ["torch.bernoulli", "mask_vae_pendulum.CausalVAE.compute_sigmoid_given"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.compute_sigmoid_given"], ["", "def", "sample_x_given", "(", "self", ",", "z", ")", ":", "\n", "        ", "return", "torch", ".", "bernoulli", "(", "self", ".", "compute_sigmoid_given", "(", "z", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.__init__": [[20, 40], ["getattr.Module.__init__", "numpy.array", "getattr", "getattr.Encoder", "getattr.Decoder_DAG", "getattr.DagLayer", "getattr.Attention", "getattr.MaskLayer", "getattr.MaskLayer", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nn", "=", "'mask'", ",", "name", "=", "'vae'", ",", "z_dim", "=", "16", ",", "z1_dim", "=", "4", ",", "z2_dim", "=", "4", ",", "inference", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "z1_dim", "=", "z1_dim", "\n", "self", ".", "z2_dim", "=", "z2_dim", "\n", "self", ".", "channel", "=", "4", "\n", "self", ".", "scale", "=", "np", ".", "array", "(", "[", "[", "20", ",", "15", "]", ",", "[", "2", ",", "2", "]", ",", "[", "59.5", ",", "26.5", "]", ",", "[", "10.5", ",", "4.5", "]", "]", ")", "\n", "\n", "nn", "=", "getattr", "(", "nns", ",", "nn", ")", "\n", "self", ".", "enc", "=", "nn", ".", "Encoder", "(", "self", ".", "z_dim", ",", "self", ".", "channel", ")", "\n", "self", ".", "dec", "=", "nn", ".", "Decoder_DAG", "(", "self", ".", "z_dim", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", "\n", "self", ".", "dag", "=", "nn", ".", "DagLayer", "(", "self", ".", "z1_dim", ",", "self", ".", "z1_dim", ",", "i", "=", "inference", ")", "\n", "self", ".", "attn", "=", "nn", ".", "Attention", "(", "self", ".", "z2_dim", ")", "\n", "self", ".", "mask_z", "=", "nn", ".", "MaskLayer", "(", "self", ".", "z_dim", ",", "concept", "=", "self", ".", "z1_dim", ")", "\n", "self", ".", "mask_u", "=", "nn", ".", "MaskLayer", "(", "self", ".", "z1_dim", ",", "concept", "=", "self", ".", "z1_dim", ",", "z1_dim", "=", "1", ")", "\n", "\n", "self", ".", "z_prior_m", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "z_prior_v", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "z_prior", "=", "(", "self", ".", "z_prior_m", ",", "self", ".", "z_prior_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.negative_elbo_bound": [[41, 107], ["mask_vae_flow.CausalVAE.enc.encode", "mask_vae_flow.CausalVAE.dag.calculate_dag", "mask_vae_flow.CausalVAE.dec.decode_sep", "codebase.utils.log_bernoulli_with_logits", "codebase.utils.condition_prior", "torch.ones().to", "codebase.utils.conditional_sample_gaussian", "torch.zeros().to", "range", "torch.mean", "torch.zeros().to", "torch.zeros().to", "range", "torch.nn.MSELoss", "x.to", "q_m.reshape", "torch.ones().to", "q_m.to", "torch.ones().to", "decode_m.reshape", "mask_vae_flow.CausalVAE.dag.mask_u", "mask_vae_flow.CausalVAE.mask_z.mix().reshape().to", "mask_vae_flow.CausalVAE.mask_u.mix().to", "torch.ones().to", "codebase.utils.conditional_sample_gaussian", "codebase.utils.conditional_sample_gaussian.reshape", "label.to", "decoded_bernoulli_logits.reshape", "torch.mean", "torch.zeros", "torch.ones", "cp_m.to", "torch.ones().to.to", "codebase.utils.kl_normal", "torch.mean", "torch.nn.MSELoss.", "decoded_bernoulli_logits.reshape", "label.size", "mask_vae_flow.CausalVAE.dag.mask_z().reshape", "decode_v.reshape", "label.to", "mask_vae_flow.CausalVAE.attn.attention", "x.size", "q_m.size", "q_m.size", "torch.ones", "torch.zeros", "q_m.view().to", "q_v.view().to", "p_m.view().to", "p_v.view().to", "torch.zeros", "torch.zeros", "label.float().to", "x.size", "torch.ones", "torch.ones", "torch.ones().to", "mask_vae_flow.CausalVAE.mask_z.mix().reshape", "decode_m.reshape().to", "q_m.reshape().to", "torch.ones().to", "mask_vae_flow.CausalVAE.mask_u.mix", "torch.ones", "codebase.utils.kl_normal", "codebase.utils.kl_normal", "q_m.size", "q_m.size", "mask_vae_flow.CausalVAE.dag.mask_z", "codebase.utils.conditional_sample_gaussian.size", "q_m.view", "q_v.view", "p_m.view", "p_v.view", "decode_m[].to", "cp_v[].to", "cp_m[].to", "cp_v[].to", "f_z1[].to", "cp_v[].to", "cp_m[].to", "cp_v[].to", "label.float", "q_m.size", "q_m.size", "torch.ones", "decode_m.to", "q_m.size", "q_m.size", "mask_vae_flow.CausalVAE.mask_z.mix", "decode_m.reshape", "q_m.reshape", "torch.ones", "q_m.size", "q_m.size", "q_m.size", "q_m.size", "q_m.size", "q_m.size", "q_m.size"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Encoder.encode", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.calculate_dag", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder_DAG.decode_sep", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_bernoulli_with_logits", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.condition_prior", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.conditional_sample_gaussian", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.mask_u", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.conditional_sample_gaussian", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.kl_normal", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Attention.attention", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Mix.mix", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.kl_normal", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.kl_normal", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.mask_z", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Mix.mix"], ["", "def", "negative_elbo_bound", "(", "self", ",", "x", ",", "label", ",", "mask", "=", "None", ",", "sample", "=", "False", ",", "adj", "=", "None", ",", "lambdav", "=", "0.001", ")", ":", "\n", "        ", "\"\"\"\n        Computes the Evidence Lower Bound, KL and, Reconstruction costs\n\n        Args:\n            x: tensor: (batch, dim): Observations\n\n        Returns:\n            nelbo: tensor: (): Negative evidence lower bound\n            kl: tensor: (): ELBO KL divergence to prior\n            rec: tensor: (): ELBO Reconstruction term\n        \"\"\"", "\n", "assert", "label", ".", "size", "(", ")", "[", "1", "]", "==", "self", ".", "z1_dim", "\n", "\n", "q_m", ",", "q_v", "=", "self", ".", "enc", ".", "encode", "(", "x", ".", "to", "(", "device", ")", ")", "\n", "q_m", ",", "q_v", "=", "q_m", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ",", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", ".", "to", "(", "device", ")", "\n", "\n", "decode_m", ",", "decode_v", "=", "self", ".", "dag", ".", "calculate_dag", "(", "q_m", ".", "to", "(", "device", ")", ",", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", ".", "to", "(", "device", ")", ")", "\n", "decode_m", ",", "decode_v", "=", "decode_m", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ",", "decode_v", "\n", "if", "sample", "==", "False", ":", "\n", "          ", "if", "mask", "!=", "None", "and", "mask", "in", "[", "0", ",", "1", ",", "3", "]", ":", "\n", "              ", "z_mask", "=", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", ".", "to", "(", "device", ")", "*", "adj", "\n", "decode_m", "[", ":", ",", "mask", ",", ":", "]", "=", "z_mask", "[", ":", ",", "mask", ",", ":", "]", "\n", "decode_v", "[", ":", ",", "mask", ",", ":", "]", "=", "z_mask", "[", ":", ",", "mask", ",", ":", "]", "\n", "", "m_zm", ",", "m_zv", "=", "self", ".", "dag", ".", "mask_z", "(", "decode_m", ".", "to", "(", "device", ")", ")", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ",", "decode_v", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", "\n", "m_u", "=", "self", ".", "dag", ".", "mask_u", "(", "label", ".", "to", "(", "device", ")", ")", "\n", "#mask", "\n", "\n", "f_z", "=", "self", ".", "mask_z", ".", "mix", "(", "m_zm", ")", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "e_tilde", "=", "self", ".", "attn", ".", "attention", "(", "decode_m", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ".", "to", "(", "device", ")", ",", "q_m", ".", "reshape", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ".", "to", "(", "device", ")", ")", "[", "0", "]", "\n", "\n", "f_z1", "=", "f_z", "+", "e_tilde", "\n", "if", "mask", "!=", "None", "and", "mask", "==", "2", ":", "\n", "              ", "z_mask", "=", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", ")", ".", "to", "(", "device", ")", "*", "adj", "\n", "f_z1", "[", ":", ",", "mask", ",", ":", "]", "=", "z_mask", "[", ":", ",", "mask", ",", ":", "]", "\n", "m_zv", "[", ":", ",", "mask", ",", ":", "]", "=", "z_mask", "[", ":", ",", "mask", ",", ":", "]", "\n", "", "g_u", "=", "self", ".", "mask_u", ".", "mix", "(", "m_u", ")", ".", "to", "(", "device", ")", "\n", "\n", "m_zv", "=", "torch", ".", "ones", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ".", "to", "(", "device", ")", "\n", "z_given_dag", "=", "ut", ".", "conditional_sample_gaussian", "(", "f_z1", ",", "q_v", "*", "lambdav", ")", "\n", "\n", "", "decoded_bernoulli_logits", ",", "x1", ",", "x2", ",", "x3", ",", "x4", "=", "self", ".", "dec", ".", "decode_sep", "(", "z_given_dag", ".", "reshape", "(", "[", "z_given_dag", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z_dim", "]", ")", ",", "label", ".", "to", "(", "device", ")", ")", "\n", "\n", "rec", "=", "ut", ".", "log_bernoulli_with_logits", "(", "x", ",", "decoded_bernoulli_logits", ".", "reshape", "(", "x", ".", "size", "(", ")", ")", ")", "\n", "rec", "=", "-", "torch", ".", "mean", "(", "rec", ")", "\n", "\n", "p_m", ",", "p_v", "=", "torch", ".", "zeros", "(", "q_m", ".", "size", "(", ")", ")", ",", "torch", ".", "ones", "(", "q_m", ".", "size", "(", ")", ")", "\n", "cp_m", ",", "cp_v", "=", "ut", ".", "condition_prior", "(", "self", ".", "scale", ",", "label", ",", "self", ".", "z2_dim", ")", "\n", "\n", "cp_v", "=", "torch", ".", "ones", "(", "[", "q_m", ".", "size", "(", ")", "[", "0", "]", ",", "self", ".", "z1_dim", ",", "self", ".", "z2_dim", "]", ")", ".", "to", "(", "device", ")", "\n", "cp_z", "=", "ut", ".", "conditional_sample_gaussian", "(", "cp_m", ".", "to", "(", "device", ")", ",", "cp_v", ".", "to", "(", "device", ")", ")", "\n", "kl", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "device", ")", "\n", "kl", "=", "0.3", "*", "ut", ".", "kl_normal", "(", "q_m", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", ",", "q_v", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", ",", "p_m", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", ",", "p_v", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "z1_dim", ")", ":", "\n", "            ", "kl", "=", "kl", "+", "1", "*", "ut", ".", "kl_normal", "(", "decode_m", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_v", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_m", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_v", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ")", "\n", "", "kl", "=", "torch", ".", "mean", "(", "kl", ")", "\n", "mask_kl", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "device", ")", "\n", "mask_kl2", "=", "torch", ".", "zeros", "(", "1", ")", ".", "to", "(", "device", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "z1_dim", ")", ":", "\n", "            ", "mask_kl", "=", "mask_kl", "+", "1", "*", "ut", ".", "kl_normal", "(", "f_z1", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_v", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_m", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ",", "cp_v", "[", ":", ",", "i", ",", ":", "]", ".", "to", "(", "device", ")", ")", "\n", "", "u_loss", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "mask_l", "=", "torch", ".", "mean", "(", "mask_kl", ")", "+", "u_loss", "(", "g_u", ",", "label", ".", "float", "(", ")", ".", "to", "(", "device", ")", ")", "\n", "nelbo", "=", "rec", "+", "kl", "+", "mask_l", "\n", "return", "nelbo", ",", "kl", ",", "rec", ",", "decoded_bernoulli_logits", ".", "reshape", "(", "x", ".", "size", "(", ")", ")", ",", "z_given_dag", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.loss": [[109, 121], ["mask_vae_flow.CausalVAE.negative_elbo_bound", "dict"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.negative_elbo_bound"], ["", "def", "loss", "(", "self", ",", "x", ")", ":", "\n", "        ", "nelbo", ",", "kl", ",", "rec", "=", "self", ".", "negative_elbo_bound", "(", "x", ")", "\n", "loss", "=", "nelbo", "\n", "\n", "summaries", "=", "dict", "(", "(", "\n", "(", "'train/loss'", ",", "nelbo", ")", ",", "\n", "(", "'gen/elbo'", ",", "-", "nelbo", ")", ",", "\n", "(", "'gen/kl_z'", ",", "kl", ")", ",", "\n", "(", "'gen/rec'", ",", "rec", ")", ",", "\n", ")", ")", "\n", "\n", "return", "loss", ",", "summaries", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.sample_sigmoid": [[122, 125], ["mask_vae_flow.CausalVAE.sample_z", "mask_vae_flow.CausalVAE.compute_sigmoid_given"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.sample_z", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.compute_sigmoid_given"], ["", "def", "sample_sigmoid", "(", "self", ",", "batch", ")", ":", "\n", "        ", "z", "=", "self", ".", "sample_z", "(", "batch", ")", "\n", "return", "self", ".", "compute_sigmoid_given", "(", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.compute_sigmoid_given": [[126, 129], ["mask_vae_flow.CausalVAE.dec.decode", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder.decode"], ["", "def", "compute_sigmoid_given", "(", "self", ",", "z", ")", ":", "\n", "        ", "logits", "=", "self", ".", "dec", ".", "decode", "(", "z", ")", "\n", "return", "torch", ".", "sigmoid", "(", "logits", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.sample_z": [[130, 134], ["codebase.utils.sample_gaussian", "mask_vae_flow.CausalVAE.z_prior[].expand", "mask_vae_flow.CausalVAE.z_prior[].expand"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.sample_gaussian"], ["", "def", "sample_z", "(", "self", ",", "batch", ")", ":", "\n", "        ", "return", "ut", ".", "sample_gaussian", "(", "\n", "self", ".", "z_prior", "[", "0", "]", ".", "expand", "(", "batch", ",", "self", ".", "z_dim", ")", ",", "\n", "self", ".", "z_prior", "[", "1", "]", ".", "expand", "(", "batch", ",", "self", ".", "z_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.sample_x": [[135, 138], ["mask_vae_flow.CausalVAE.sample_z", "mask_vae_flow.CausalVAE.sample_x_given"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.sample_z", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.sample_x_given"], ["", "def", "sample_x", "(", "self", ",", "batch", ")", ":", "\n", "        ", "z", "=", "self", ".", "sample_z", "(", "batch", ")", "\n", "return", "self", ".", "sample_x_given", "(", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.sample_x_given": [[139, 141], ["torch.bernoulli", "mask_vae_flow.CausalVAE.compute_sigmoid_given"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.mask_vae_flow.CausalVAE.compute_sigmoid_given"], ["", "def", "sample_x_given", "(", "self", ",", "z", ")", ":", "\n", "        ", "return", "torch", ".", "bernoulli", "(", "self", ".", "compute_sigmoid_given", "(", "z", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.synthetic_dataset.SyntheticDataset.__init__": [[13, 27], ["synthetic_dataset.SyntheticDataset._setup", "synthetic_dataset.SyntheticDataset._logger.debug"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.synthetic_dataset.SyntheticDataset._setup"], ["def", "__init__", "(", "self", ",", "n", ",", "d", ",", "graph_type", ",", "degree", ",", "sem_type", ",", "noise_scale", "=", "1.0", ",", "\n", "dataset_type", "=", "'nonlinear_1'", ",", "x_dim", "=", "1", ")", ":", "\n", "        ", "self", ".", "n", "=", "n", "\n", "self", ".", "d", "=", "d", "\n", "self", ".", "graph_type", "=", "graph_type", "\n", "self", ".", "degree", "=", "degree", "\n", "self", ".", "sem_type", "=", "sem_type", "\n", "self", ".", "noise_scale", "=", "noise_scale", "\n", "self", ".", "dataset_type", "=", "dataset_type", "\n", "self", ".", "x_dim", "=", "x_dim", "\n", "self", ".", "w_range", "=", "(", "0.5", ",", "2.0", ")", "\n", "\n", "self", ".", "_setup", "(", ")", "\n", "self", ".", "_logger", ".", "debug", "(", "'Finished setting up dataset class'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.synthetic_dataset.SyntheticDataset._setup": [[28, 34], ["synthetic_dataset.SyntheticDataset.simulate_random_dag", "synthetic_dataset.SyntheticDataset.simulate_sem"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.synthetic_dataset.SyntheticDataset.simulate_random_dag", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.synthetic_dataset.SyntheticDataset.simulate_sem"], ["", "def", "_setup", "(", "self", ")", ":", "\n", "        ", "self", ".", "W", "=", "SyntheticDataset", ".", "simulate_random_dag", "(", "self", ".", "d", ",", "self", ".", "degree", ",", "\n", "self", ".", "graph_type", ",", "self", ".", "w_range", ")", "\n", "\n", "self", ".", "X", "=", "SyntheticDataset", ".", "simulate_sem", "(", "self", ".", "W", ",", "self", ".", "n", ",", "self", ".", "sem_type", ",", "self", ".", "noise_scale", ",", "\n", "self", ".", "dataset_type", ",", "self", ".", "x_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.synthetic_dataset.SyntheticDataset.simulate_random_dag": [[35, 73], ["numpy.random.permutation", "numpy.random.permutation.T.dot().dot", "numpy.random.uniform", "numpy.tril", "numpy.eye", "float", "int", "numpy.zeros", "range", "numpy.random.permutation.T.dot", "round", "numpy.random.choice", "bag.append", "bag.extend", "numpy.tril", "ValueError", "numpy.random.rand", "numpy.ones", "numpy.random.rand"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "simulate_random_dag", "(", "d", ",", "degree", ",", "graph_type", ",", "w_range", ")", ":", "\n", "        ", "\"\"\"Simulate random DAG with some expected degree.\n\n        Args:\n            d: number of nodes\n            degree: expected node degree, in + out\n            graph_type: {erdos-renyi, barabasi-albert, full}\n            w_range: weight range +/- (low, high)\n\n        Returns:\n            W: weighted DAG\n        \"\"\"", "\n", "if", "graph_type", "==", "'erdos-renyi'", ":", "\n", "            ", "prob", "=", "float", "(", "degree", ")", "/", "(", "d", "-", "1", ")", "\n", "B", "=", "np", ".", "tril", "(", "(", "np", ".", "random", ".", "rand", "(", "d", ",", "d", ")", "<", "prob", ")", ".", "astype", "(", "float", ")", ",", "k", "=", "-", "1", ")", "\n", "", "elif", "graph_type", "==", "'barabasi-albert'", ":", "\n", "            ", "m", "=", "int", "(", "round", "(", "degree", "/", "2", ")", ")", "\n", "B", "=", "np", ".", "zeros", "(", "[", "d", ",", "d", "]", ")", "\n", "bag", "=", "[", "0", "]", "\n", "for", "ii", "in", "range", "(", "1", ",", "d", ")", ":", "\n", "                ", "dest", "=", "np", ".", "random", ".", "choice", "(", "bag", ",", "size", "=", "m", ")", "\n", "for", "jj", "in", "dest", ":", "\n", "                    ", "B", "[", "ii", ",", "jj", "]", "=", "1", "\n", "", "bag", ".", "append", "(", "ii", ")", "\n", "bag", ".", "extend", "(", "dest", ")", "\n", "", "", "elif", "graph_type", "==", "'full'", ":", "# ignore degree, only for experimental use", "\n", "            ", "B", "=", "np", ".", "tril", "(", "np", ".", "ones", "(", "[", "d", ",", "d", "]", ")", ",", "k", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'unknown graph type'", ")", "\n", "# random permutation", "\n", "", "P", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "eye", "(", "d", ",", "d", ")", ")", "# permutes first axis only", "\n", "B_perm", "=", "P", ".", "T", ".", "dot", "(", "B", ")", ".", "dot", "(", "P", ")", "\n", "U", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "w_range", "[", "0", "]", ",", "high", "=", "w_range", "[", "1", "]", ",", "size", "=", "[", "d", ",", "d", "]", ")", "\n", "U", "[", "np", ".", "random", ".", "rand", "(", "d", ",", "d", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "W", "=", "(", "B_perm", "!=", "0", ")", ".", "astype", "(", "float", ")", "*", "U", "\n", "\n", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.synthetic_dataset.SyntheticDataset.simulate_sem": [[74, 121], ["networkx.DiGraph", "numpy.zeros", "list", "networkx.topological_sort", "len", "list", "range", "networkx.DiGraph.predecessors", "numpy.cos().dot", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "numpy.cos", "ValueError", "numpy.random.normal", "numpy.random.normal", "numpy.random.normal", "numpy.cos().dot", "numpy.random.normal", "numpy.random.normal", "numpy.cos", "numpy.sin"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "simulate_sem", "(", "W", ",", "n", ",", "sem_type", ",", "noise_scale", "=", "1.0", ",", "dataset_type", "=", "'nonlinear_1'", ",", "x_dim", "=", "1", ")", ":", "\n", "        ", "\"\"\"Simulate samples from SEM with specified type of noise.\n\n        Args:\n            W: weigthed DAG\n            n: number of samples\n            sem_type: {linear-gauss,linear-exp,linear-gumbel}\n            noise_scale: scale parameter of noise distribution in linear SEM\n\n        Returns:\n            X: [n,d] sample matrix\n        \"\"\"", "\n", "G", "=", "nx", ".", "DiGraph", "(", "W", ")", "\n", "d", "=", "W", ".", "shape", "[", "0", "]", "\n", "X", "=", "np", ".", "zeros", "(", "[", "n", ",", "d", ",", "x_dim", "]", ")", "\n", "ordered_vertices", "=", "list", "(", "nx", ".", "topological_sort", "(", "G", ")", ")", "\n", "assert", "len", "(", "ordered_vertices", ")", "==", "d", "\n", "for", "j", "in", "ordered_vertices", ":", "\n", "            ", "parents", "=", "list", "(", "G", ".", "predecessors", "(", "j", ")", ")", "\n", "if", "dataset_type", "==", "'nonlinear_1'", ":", "\n", "                ", "eta", "=", "np", ".", "cos", "(", "X", "[", ":", ",", "parents", ",", "0", "]", "+", "1", ")", ".", "dot", "(", "W", "[", "parents", ",", "j", "]", ")", "\n", "", "elif", "dataset_type", "==", "'nonlinear_2'", ":", "\n", "                ", "eta", "=", "(", "X", "[", ":", ",", "parents", ",", "0", "]", "+", "0.5", ")", ".", "dot", "(", "W", "[", "parents", ",", "j", "]", ")", "\n", "", "elif", "dataset_type", "==", "'nonlinear_3'", ":", "# Combined version of nonlinear_1 and nonlinear_2", "\n", "                ", "eta", "=", "np", ".", "cos", "(", "X", "[", ":", ",", "parents", ",", "0", "]", "+", "1", ")", ".", "dot", "(", "W", "[", "parents", ",", "j", "]", ")", "+", "0.5", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown linear data type'", ")", "\n", "\n", "", "if", "sem_type", "==", "'linear-gauss'", ":", "\n", "                ", "if", "dataset_type", "==", "'nonlinear_1'", ":", "\n", "                    ", "X", "[", ":", ",", "j", ",", "0", "]", "=", "eta", "+", "np", ".", "random", ".", "normal", "(", "scale", "=", "noise_scale", ",", "size", "=", "n", ")", "\n", "", "elif", "dataset_type", "in", "(", "'nonlinear_2'", ",", "'nonlinear_3'", ")", ":", "\n", "                    ", "X", "[", ":", ",", "j", ",", "0", "]", "=", "2.", "*", "np", ".", "sin", "(", "eta", ")", "+", "eta", "+", "np", ".", "random", ".", "normal", "(", "scale", "=", "noise_scale", ",", "size", "=", "n", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "if", "x_dim", ">", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "x_dim", "-", "1", ")", ":", "\n", "                ", "X", "[", ":", ",", ":", ",", "i", "+", "1", "]", "=", "np", ".", "random", ".", "normal", "(", "scale", "=", "noise_scale", ",", "size", "=", "1", ")", "*", "X", "[", ":", ",", ":", ",", "0", "]", "+", "np", ".", "random", ".", "normal", "(", "scale", "=", "noise_scale", ",", "size", "=", "1", ")", "+", "np", ".", "random", ".", "normal", "(", "scale", "=", "noise_scale", ",", "size", "=", "(", "n", ",", "d", ")", ")", "\n", "\n", "", "X", "[", ":", ",", ":", ",", "0", "]", "=", "np", ".", "random", ".", "normal", "(", "scale", "=", "noise_scale", ",", "size", "=", "1", ")", "*", "X", "[", ":", ",", ":", ",", "0", "]", "+", "np", ".", "random", ".", "normal", "(", "scale", "=", "noise_scale", ",", "size", "=", "1", ")", "+", "np", ".", "random", ".", "normal", "(", "scale", "=", "noise_scale", ",", "size", "=", "(", "n", ",", "d", ")", ")", "\n", "", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.dataset_read_data.DataGenerator.__init__": [[24, 41], ["numpy.int32", "sklearn.preprocessing.StandardScaler().fit_transform", "numpy.zeros", "numpy.transpose", "numpy.abs", "sklearn.preprocessing.StandardScaler"], "methods", ["None"], ["            ", "gtrue", "=", "np", ".", "load", "(", "solution_path", ")", "\n", "if", "transpose_flag", ":", "\n", "                ", "gtrue", "=", "np", ".", "transpose", "(", "gtrue", ")", "\n", "\n", "# (i,j)=1 => node i -> node j", "\n", "", "", "self", ".", "true_graph", "=", "np", ".", "int32", "(", "np", ".", "abs", "(", "gtrue", ")", ">", "1e-3", ")", "\n", "\n", "", "def", "gen_instance_graph", "(", "self", ",", "max_length", ",", "dimension", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "seq", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "datasize", ",", "size", "=", "(", "dimension", ")", ")", "\n", "input_", "=", "self", ".", "inputdata", "[", "seq", "]", "\n", "return", "input_", ".", "T", "\n", "\n", "# Generate random batch for training procedure", "\n", "", "def", "train_batch", "(", "self", ",", "batch_size", ",", "max_length", ",", "dimension", ")", ":", "\n", "        ", "input_batch", "=", "[", "]", "\n", "\n", "for", "_", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "input_", "=", "self", ".", "gen_instance_graph", "(", "max_length", ",", "dimension", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.dataset_read_data.DataGenerator.gen_instance_graph": [[42, 46], ["numpy.random.randint"], "methods", ["None"], ["input_batch", ".", "append", "(", "input_", ")", "\n", "\n", "", "return", "input_batch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.dataset_read_data.DataGenerator.train_batch": [[48, 56], ["range", "dataset_read_data.DataGenerator.gen_instance_graph", "input_batch.append"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.dataset_read_data.DataGenerator.gen_instance_graph"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.tf_utils.is_cuda_available": [[22, 24], ["tensorflow.test.is_gpu_available"], "function", ["None"], ["", "except", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.tf_utils.set_seed": [[26, 39], ["random.seed", "numpy.random.seed", "tensorflow.set_random_seed", "str"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.set_random_seed"], ["", "", "def", "tensor_description", "(", "var", ")", ":", "\n", "    ", "\"\"\"\n    Returns a compact and informative string about a tensor.\n    Args:\n      var: A tensor variable.\n    Returns:\n      a string with type and size, e.g.: (float32 1x8x8x1024).\n    \n    Referred from:\n    - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/model_analyzer.py\n    \"\"\"", "\n", "description", "=", "'('", "+", "str", "(", "var", ".", "dtype", ".", "name", ")", "+", "' '", "\n", "sizes", "=", "var", ".", "get_shape", "(", ")", "\n", "for", "i", ",", "size", "in", "enumerate", "(", "sizes", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.tf_utils.tensor_description": [[41, 60], ["var.get_shape", "enumerate", "str", "str", "len"], "function", ["None"], ["if", "i", "<", "len", "(", "sizes", ")", "-", "1", ":", "\n", "            ", "description", "+=", "'x'", "\n", "", "", "description", "+=", "')'", "\n", "return", "description", "\n", "\n", "\n", "", "def", "print_summary", "(", "print_func", ")", ":", "\n", "    ", "\"\"\"\n    Print a summary table of the network structure\n    Referred from:\n    - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/model_analyzer.py\n    \"\"\"", "\n", "variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "\n", "print_func", "(", "'Model summary:'", ")", "\n", "print_func", "(", "'---------'", ")", "\n", "print_func", "(", "'Variables: name (type shape) [size]'", ")", "\n", "print_func", "(", "'---------'", ")", "\n", "\n", "total_size", "=", "0", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.tf_utils.print_summary": [[47, 73], ["tensorflow.trainable_variables", "print_func", "print_func", "print_func", "print_func", "print_func", "print_func", "print_func", "var.get_shape().num_elements", "tf_utils.tensor_description", "var.get_shape"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.tensor_description"], ["", "def", "print_summary", "(", "print_func", ")", ":", "\n", "    ", "\"\"\"\n    Print a summary table of the network structure\n    Referred from:\n    - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/python/slim/model_analyzer.py\n    \"\"\"", "\n", "variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "\n", "print_func", "(", "'Model summary:'", ")", "\n", "print_func", "(", "'---------'", ")", "\n", "print_func", "(", "'Variables: name (type shape) [size]'", ")", "\n", "print_func", "(", "'---------'", ")", "\n", "\n", "total_size", "=", "0", "\n", "total_bytes", "=", "0", "\n", "for", "var", "in", "variables", ":", "\n", "# if var.num_elements() is None or [] assume size 0.", "\n", "        ", "var_size", "=", "var", ".", "get_shape", "(", ")", ".", "num_elements", "(", ")", "or", "0", "\n", "var_bytes", "=", "var_size", "*", "var", ".", "dtype", ".", "size", "\n", "total_size", "+=", "var_size", "\n", "total_bytes", "+=", "var_bytes", "\n", "\n", "print_func", "(", "'{} {} [{}, bytes: {}]'", ".", "format", "(", "var", ".", "name", ",", "tensor_description", "(", "var", ")", ",", "var_size", ",", "var_bytes", ")", ")", "\n", "\n", "", "print_func", "(", "'Total size of variables: {}'", ".", "format", "(", "total_size", ")", ")", "\n", "print_func", "(", "'Total bytes of variables: {}'", ".", "format", "(", "total_bytes", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.count_accuracy": [[158, 219], ["numpy.flatnonzero", "numpy.flatnonzero", "numpy.flatnonzero", "numpy.concatenate", "numpy.intersect1d", "numpy.setdiff1d", "numpy.setdiff1d", "numpy.intersect1d", "len", "numpy.tril", "numpy.flatnonzero", "numpy.flatnonzero", "numpy.setdiff1d", "numpy.setdiff1d", "numpy.flatnonzero", "numpy.intersect1d", "numpy.concatenate", "numpy.setdiff1d", "numpy.concatenate", "len", "len", "float", "max", "float", "max", "float", "max", "numpy.add", "numpy.tril", "len", "len", "len", "numpy.tril", "len", "len", "len", "len", "len", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.plot_recovered_graph": [[128, 138], ["matplotlib.figure", "plt.figure.add_subplot", "fig.add_subplot.set_title", "fig.add_subplot.imshow", "plt.figure.add_subplot", "fig.add_subplot.set_title", "fig.add_subplot.imshow", "matplotlib.savefig"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.log_helper.LogHelper.setup": [[11, 39], ["logging.basicConfig", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger().addHandler", "logging.getLogger", "logging.getLogger.info", "pytz.utc.localize", "pytz.timezone", "pytz.utc.localize.astimezone", "utc.localize.astimezone.timetuple", "logging.Formatter", "logging.getLogger.critical", "logging.getLevelName", "datetime.datetime.datetime.utcnow", "logging.getLogger"], "methods", ["None"], ["\n", "log_format", "=", "'%(asctime)s %(levelname)s - %(name)s - %(message)s'", "\n", "\n", "@", "staticmethod", "\n", "def", "setup", "(", "log_path", ",", "level_str", "=", "'INFO'", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "\n", "filename", "=", "log_path", ",", "\n", "level", "=", "logging", ".", "getLevelName", "(", "level_str", ")", ",", "\n", "format", "=", "LogHelper", ".", "log_format", ",", "\n", ")", "\n", "\n", "def", "customTime", "(", "*", "args", ")", ":", "\n", "            ", "utc_dt", "=", "utc", ".", "localize", "(", "datetime", ".", "utcnow", "(", ")", ")", "\n", "my_tz", "=", "timezone", "(", "\"Asia/Hong_Kong\"", ")", "\n", "converted", "=", "utc_dt", ".", "astimezone", "(", "my_tz", ")", "\n", "return", "converted", ".", "timetuple", "(", ")", "\n", "\n", "", "logging", ".", "Formatter", ".", "converter", "=", "customTime", "\n", "\n", "# Set up logging to console", "\n", "console", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "console", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "console", ".", "setFormatter", "(", "logging", ".", "Formatter", "(", "LogHelper", ".", "log_format", ")", ")", "\n", "# Add the console handler to the root logger", "\n", "logging", ".", "getLogger", "(", "''", ")", ".", "addHandler", "(", "console", ")", "\n", "\n", "# Log for unhandled exception", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "sys", ".", "excepthook", "=", "lambda", "*", "ex", ":", "logger", ".", "critical", "(", "'Unhandled exception'", ",", "exc_info", "=", "ex", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.config_utils.load_yaml_config": [[6, 13], ["open", "range", "yaml.safe_load", "infile.readline"], "function", ["None"], ["def", "load_yaml_config", "(", "path", ",", "skip_lines", "=", "0", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "'r'", ")", "as", "infile", ":", "\n", "        ", "for", "i", "in", "range", "(", "skip_lines", ")", ":", "\n", "# Skip some lines (e.g., namespace at the first line)", "\n", "            ", "_", "=", "infile", ".", "readline", "(", ")", "\n", "\n", "", "return", "yaml", ".", "safe_load", "(", "infile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.config_utils.save_yaml_config": [[15, 18], ["open", "yaml.dump"], "function", ["None"], ["", "", "def", "save_yaml_config", "(", "config", ",", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "dump", "(", "config", ",", "outfile", ",", "default_flow_style", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.config_utils.get_args": [[20, 164], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "##### General settings #####", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1230", ",", "\n", "help", "=", "'Random seed'", ")", "\n", "\n", "##### Dataset settings #####", "\n", "parser", ".", "add_argument", "(", "'--n'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "3000", ",", "\n", "help", "=", "'Number of samples'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--d'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "20", ",", "\n", "help", "=", "'Number of nodes'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--graph_type'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'erdos-renyi'", ",", "\n", "help", "=", "'Type of graph'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--degree'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "3", ",", "\n", "help", "=", "'Degree of graph'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--sem_type'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'linear-gauss'", ",", "\n", "help", "=", "'Type of sem'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--noise_scale'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1.0", ",", "\n", "help", "=", "'Variance of Gaussian Noise'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--dataset_type'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'nonlinear_1'", ",", "\n", "help", "=", "'Choose between nonlinear_1, nonlinear_2, nonlinear_3'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--x_dim'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "'Dimension of vector for X'", ")", "\n", "\n", "##### Model settings #####", "\n", "parser", ".", "add_argument", "(", "'--num_encoder_layers'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "\n", "help", "=", "'Number of hidden layers for encoder'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--num_decoder_layers'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "\n", "help", "=", "'Number of hidden layers for decoder'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--hidden_size'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "16", ",", "\n", "help", "=", "'Hidden size for NN layers'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--latent_dim'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "'Latent dimension for autoencoder'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--l1_graph_penalty'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1.0", ",", "\n", "help", "=", "'L1 penalty for sparse graph. Set to 0 to disable'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--use_float64'", ",", "\n", "type", "=", "bool", ",", "\n", "default", "=", "True", ",", "\n", "help", "=", "'Whether to use tf.float64 or tf.float32 during training'", ")", "\n", "\n", "##### Training settings #####", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1e-3", ",", "\n", "help", "=", "'Learning rate for Adam optimizer'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--max_iter'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "20", ",", "\n", "help", "=", "'Number of iterations for training/optimization'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--iter_step'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "300", ",", "\n", "help", "=", "'Number of steps for each iteration'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--init_iter'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "5", ",", "\n", "help", "=", "'Initial iterations to disable early stopping'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--h_tol'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1e-12", ",", "\n", "help", "=", "'Tolerance for acyclicity constraint'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--init_rho'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1.0", ",", "\n", "help", "=", "'Initial value for rho'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--rho_thres'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1e+18", ",", "\n", "help", "=", "'Threshold for rho'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--h_thres'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.25", ",", "\n", "help", "=", "'Threshold for h'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--rho_multiply'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "10", ",", "\n", "help", "=", "'Multiplication to amplify rho each time'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--early_stopping'", ",", "\n", "type", "=", "bool", ",", "\n", "default", "=", "True", ",", "\n", "help", "=", "'Whether to use early stopping'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--early_stopping_thres'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1.15", ",", "\n", "help", "=", "'Threshold ratio for early stopping'", ")", "\n", "\n", "##### Other settings #####", "\n", "parser", ".", "add_argument", "(", "'--graph_thres'", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.2", ",", "\n", "help", "=", "'Threshold to filter out small values in graph'", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", "args", "=", "sys", ".", "argv", "[", "1", ":", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.dir_utils.create_dir": [[9, 23], ["os.path.exists", "pathlib.Path().mkdir", "_logger.critical", "sys.exit", "pathlib.Path"], "function", ["None"], ["    ", "\"\"\"\n    Create directory if it does not exist\n    \"\"\"", "\n", "try", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "dir_path", ")", ":", "\n", "            ", "pathlib", ".", "Path", "(", "dir_path", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "return", "0", "\n", "", "except", "Exception", "as", "err", ":", "\n", "        ", "_logger", ".", "critical", "(", "'Creating directories error: {0}'", ".", "format", "(", "err", ")", ")", "\n", "exit", "(", "-", "1", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.cam_with_pruning_cam.CAM": [[36, 105], ["rpy2.robjects.packages.SignatureTranslatedAnonymousPackage", "min", "rpy2.robjects.numpy2ri.py2rpy", "rpy2.r.computeScoreMat", "rpy2.r.matrix", "rpy2.r.matrix", "numpy.array", "round", "robjects.r.computeScoreMat.rx", "robjects.r.computeScoreMat.rx", "sum", "rpy2.r.arrayInd", "rpy2.r.matrix", "rpy2.r.which", "rpy2.r.which", "scoreVec.append", "edgeList.append", "rpy2.r.updateScoreMat", "pns_type", "numpy.ones", "rpy2.robjects.numpy2ri.py2rpy", "rpy2.robjects.vectors.ListVector", "float", "rpy2.robjects.packages.SignatureTranslatedAnonymousPackage.whichMax", "rpy2.r.dim", "rpy2.robjects.vectors.IntVector", "robjects.r.updateScoreMat.rx", "float", "float", "float", "sum", "list", "scoreNodes.rx", "rpy2.robjects.vectors.ListVector", "float", "float", "robjects.r.matrix.rx", "robjects.r.matrix.rx", "rpy2.r.t"], "function", ["None"], ["def", "CAM", "(", "XX", ",", "pns_type", "=", "None", ",", "pns_thres", "=", "None", ",", "adj_after_pns", "=", "None", ",", "pruning_type", "=", "None", ")", ":", "\n", "# XX is a numpy array", "\n", "\n", "    ", "string", "=", "'''\n    asSparseMatrix <- function(d){\n        return(as(matrix(0, d, d), \"sparseMatrix\"))\n    }\n\n    whichMax <- function(input){\n        return(which.max(input))\n    }\n    '''", "\n", "selfpack", "=", "SignatureTranslatedAnonymousPackage", "(", "string", ",", "\"selfpack\"", ")", "\n", "\n", "n", ",", "d", "=", "XX", ".", "shape", "\n", "maxNumParents", "=", "min", "(", "d", "-", "1", ",", "round", "(", "n", "/", "20", ")", ")", "\n", "X", "=", "numpy2ri", ".", "py2rpy", "(", "XX", ")", "\n", "\n", "if", "pns_type", "!=", "None", ":", "\n", "        ", "if", "pns_thres", "!=", "None", "&", "pns_thres", ">=", "0", "&", "pns_thres", "<=", "1", ":", "\n", "            ", "selMat", "=", "pns_type", "(", "X", ",", "pns_thres", "=", "pns_thres", ",", "verbose", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "\n", "", "", "else", ":", "\n", "        ", "if", "adj_after_pns", "==", "None", ":", "\n", "            ", "selMat", "=", "np", ".", "ones", "(", "(", "d", ",", "d", ")", ")", "\n", "", "else", ":", "\n", "            ", "selMat", "=", "adj_after_pns", "\n", "\n", "", "", "computeScoreMatTmp", "=", "robjects", ".", "r", ".", "computeScoreMat", "(", "X", ",", "scoreName", "=", "'SEMGAM'", ",", "\n", "numParents", "=", "1", ",", "numCores", "=", "1", ",", "output", "=", "False", ",", "\n", "selMat", "=", "numpy2ri", ".", "py2rpy", "(", "selMat", ")", ",", "\n", "parsScore", "=", "ListVector", "(", "{", "'numBasisFcts'", ":", "10", "}", ")", ",", "intervMat", "=", "float", "(", "'nan'", ")", ",", "\n", "intervData", "=", "False", ")", "\n", "scoreVec", "=", "[", "]", "\n", "edgeList", "=", "[", "]", "\n", "pathMatrix", "=", "robjects", ".", "r", ".", "matrix", "(", "0", ",", "d", ",", "d", ")", "\n", "# Adj = selfpack.asSparseMatrix(d)", "\n", "Adj", "=", "robjects", ".", "r", ".", "matrix", "(", "0", ",", "d", ",", "d", ")", "\n", "scoreNodes", "=", "computeScoreMatTmp", ".", "rx", "(", "'scoreEmptyNodes'", ")", "[", "0", "]", "\n", "scoreMat", "=", "computeScoreMatTmp", ".", "rx", "(", "'scoreMat'", ")", "[", "0", "]", "\n", "counterUpdate", "=", "0", "\n", "while", "(", "sum", "(", "scoreMat", ".", "ro", "!=", "-", "float", "(", "'inf'", ")", ")", ">", "0", ")", ":", "\n", "# print(sum(scoreMat.ro != -float('inf')))", "\n", "        ", "ix_max", "=", "robjects", ".", "r", ".", "arrayInd", "(", "selfpack", ".", "whichMax", "(", "scoreMat", ")", ",", "\n", "robjects", ".", "r", ".", "dim", "(", "scoreMat", ")", ")", "\n", "ix_max_backward", "=", "robjects", ".", "r", ".", "matrix", "(", "IntVector", "(", "[", "ix_max", "[", "1", "]", ",", "ix_max", "[", "0", "]", "]", ")", ",", "1", ",", "2", ")", "\n", "Adj", ".", "rx", "[", "ix_max", "]", "=", "1", "\n", "scoreNodes", ".", "rx", "[", "ix_max", "[", "1", "]", "]", "=", "scoreNodes", ".", "rx", "(", "ix_max", "[", "1", "]", ")", ".", "ro", "+", "scoreMat", ".", "rx", "(", "ix_max", ")", "\n", "scoreMat", ".", "rx", "[", "ix_max", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "pathMatrix", ".", "rx", "[", "ix_max", "[", "0", "]", ",", "ix_max", "[", "1", "]", "]", "=", "1", "\n", "DescOfNewChild", "=", "robjects", ".", "r", ".", "which", "(", "pathMatrix", ".", "rx", "(", "ix_max", "[", "1", "]", ",", "True", ")", ".", "ro", "==", "1", ")", "\n", "AncOfNewChild", "=", "robjects", ".", "r", ".", "which", "(", "pathMatrix", ".", "rx", "(", "True", ",", "ix_max", "[", "0", "]", ")", ".", "ro", "==", "1", ")", "\n", "pathMatrix", ".", "rx", "[", "AncOfNewChild", ",", "DescOfNewChild", "]", "=", "1", "\n", "scoreMat", ".", "rx", "[", "robjects", ".", "r", ".", "t", "(", "pathMatrix", ")", ".", "ro", "==", "1", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "scoreMat", ".", "rx", "[", "ix_max", "[", "1", "]", ",", "ix_max", "[", "0", "]", "]", "=", "-", "float", "(", "'inf'", ")", "\n", "scoreVec", ".", "append", "(", "sum", "(", "scoreNodes", ")", ")", "\n", "edgeList", ".", "append", "(", "list", "(", "ix_max", ")", ")", "\n", "scoreMat", "=", "robjects", ".", "r", ".", "updateScoreMat", "(", "scoreMat", ",", "X", ",", "scoreName", "=", "'SEMGAM'", ",", "i", "=", "ix_max", "[", "0", "]", ",", "j", "=", "ix_max", "[", "1", "]", ",", "\n", "scoreNodes", "=", "scoreNodes", ",", "Adj", "=", "Adj", ",", "numCores", "=", "1", ",", "output", "=", "False", ",", "\n", "maxNumParents", "=", "maxNumParents", ",", "parsScore", "=", "ListVector", "(", "{", "'numBasisFcts'", ":", "10", "}", ")", ",", "\n", "intervMat", "=", "float", "(", "'nan'", ")", ",", "intervData", "=", "False", ")", "\n", "counterUpdate", "=", "counterUpdate", "+", "1", "\n", "\n", "", "if", "pruning_type", "!=", "None", ":", "\n", "# Adj is the out put", "\n", "        ", "pass", "\n", "\n", "", "return", "np", ".", "array", "(", "Adj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.cam_with_pruning_cam._pruning": [[107, 126], ["rpy2.robjects.vectors.ListVector", "rpy2.r.matrix", "rpy2.r.matrix", "rpy2.r.matrix", "range", "numpy.array", "rpy2.robjects.numpy2ri.py2rpy", "rpy2.robjects.numpy2ri.py2rpy", "rpy2.r.which", "rpy2.r.length", "rpy2.r.cbind", "pruneMethod", "robjects.r.which.rx", "robjects.r.matrix.rx", "robjects.r.matrix.rx", "robjects.r.matrix.rx"], "function", ["None"], ["", "def", "_pruning", "(", "X", ",", "G", ",", "pruneMethod", "=", "robjects", ".", "r", ".", "selGam", ",", "\n", "pruneMethodPars", "=", "ListVector", "(", "{", "'cutOffPVal'", ":", "0.001", ",", "'numBasisFcts'", ":", "10", "}", ")", ",", "output", "=", "False", ")", ":", "\n", "# X is a r matrix", "\n", "# G is a python numpy array adj matrix,", "\n", "\n", "    ", "d", "=", "G", ".", "shape", "[", "0", "]", "\n", "X", "=", "robjects", ".", "r", ".", "matrix", "(", "numpy2ri", ".", "py2rpy", "(", "X", ")", ",", "ncol", "=", "d", ")", "\n", "G", "=", "robjects", ".", "r", ".", "matrix", "(", "numpy2ri", ".", "py2rpy", "(", "G", ")", ",", "d", ",", "d", ")", "\n", "finalG", "=", "robjects", ".", "r", ".", "matrix", "(", "0", ",", "d", ",", "d", ")", "\n", "for", "i", "in", "range", "(", "d", ")", ":", "\n", "        ", "parents", "=", "robjects", ".", "r", ".", "which", "(", "G", ".", "rx", "(", "True", ",", "i", "+", "1", ")", ".", "ro", "==", "1", ")", "\n", "lenpa", "=", "robjects", ".", "r", ".", "length", "(", "parents", ")", "[", "0", "]", "\n", "if", "lenpa", ">", "0", ":", "\n", "            ", "Xtmp", "=", "robjects", ".", "r", ".", "cbind", "(", "X", ".", "rx", "(", "True", ",", "parents", ")", ",", "X", ".", "rx", "(", "True", ",", "i", "+", "1", ")", ")", "\n", "selectedPar", "=", "pruneMethod", "(", "Xtmp", ",", "k", "=", "lenpa", "+", "1", ",", "pars", "=", "pruneMethodPars", ",", "output", "=", "output", ")", "\n", "finalParents", "=", "parents", ".", "rx", "(", "selectedPar", ")", "\n", "finalG", ".", "rx", "[", "finalParents", ",", "i", "+", "1", "]", "=", "1", "\n", "\n", "", "", "return", "np", ".", "array", "(", "finalG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.cam_with_pruning_cam.pruning_cam": [[128, 134], ["rpy2.robjects.numpy2ri.py2rpy", "cam_with_pruning_cam._pruning", "rpy2.robjects.vectors.ListVector"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.cam_with_pruning_cam._pruning"], ["", "def", "pruning_cam", "(", "XX", ",", "Adj", ")", ":", "\n", "    ", "X2", "=", "numpy2ri", ".", "py2rpy", "(", "XX", ")", "\n", "Adj", "=", "_pruning", "(", "X", "=", "X2", ",", "G", "=", "Adj", ",", "pruneMethod", "=", "robjects", ".", "r", ".", "selGam", ",", "\n", "pruneMethodPars", "=", "ListVector", "(", "{", "'cutOffPVal'", ":", "0.001", ",", "'numBasisFcts'", ":", "10", "}", ")", ",", "output", "=", "False", ")", "\n", "\n", "return", "Adj", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.get_training_time": [[8, 25], ["open", "f.readlines", "reversed", "datetime.datetime.strptime", "datetime.datetime.strptime", "range", "len", "len"], "function", ["None"], ["\n", "B_true", "=", "W_true", "!=", "0", "\n", "B", "=", "W_est", "!=", "0", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.graph_prunned_by_coef": [[21, 55], ["len", "sklearn.linear_model.LinearRegression", "range", "numpy.float32", "sklearn.linear_model.LinearRegression.fit", "numpy.zeros", "range", "W.append", "numpy.abs", "numpy.sum", "W.append", "numpy.abs", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit"], ["\n", "B_true", "=", "W_true", "!=", "0", "\n", "B", "=", "W_est", "!=", "0", "\n", "B_und", "=", "None", "if", "W_und", "is", "None", "else", "W_und", "\n", "d", "=", "B", ".", "shape", "[", "0", "]", "\n", "\n", "# linear index of nonzeros", "\n", "if", "B_und", "is", "not", "None", ":", "\n", "        ", "pred_und", "=", "np", ".", "flatnonzero", "(", "B_und", ")", "\n", "", "pred", "=", "np", ".", "flatnonzero", "(", "B", ")", "\n", "cond", "=", "np", ".", "flatnonzero", "(", "B_true", ")", "\n", "cond_reversed", "=", "np", ".", "flatnonzero", "(", "B_true", ".", "T", ")", "\n", "cond_skeleton", "=", "np", ".", "concatenate", "(", "[", "cond", ",", "cond_reversed", "]", ")", "\n", "# true pos", "\n", "true_pos", "=", "np", ".", "intersect1d", "(", "pred", ",", "cond", ",", "assume_unique", "=", "True", ")", "\n", "if", "B_und", "is", "not", "None", ":", "\n", "# treat undirected edge favorably", "\n", "        ", "true_pos_und", "=", "np", ".", "intersect1d", "(", "pred_und", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "true_pos", "=", "np", ".", "concatenate", "(", "[", "true_pos", ",", "true_pos_und", "]", ")", "\n", "# false pos", "\n", "", "false_pos", "=", "np", ".", "setdiff1d", "(", "pred", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "if", "B_und", "is", "not", "None", ":", "\n", "        ", "false_pos_und", "=", "np", ".", "setdiff1d", "(", "pred_und", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "false_pos", "=", "np", ".", "concatenate", "(", "[", "false_pos", ",", "false_pos_und", "]", ")", "\n", "# reverse", "\n", "", "extra", "=", "np", ".", "setdiff1d", "(", "pred", ",", "cond", ",", "assume_unique", "=", "True", ")", "\n", "reverse", "=", "np", ".", "intersect1d", "(", "extra", ",", "cond_reversed", ",", "assume_unique", "=", "True", ")", "\n", "# compute ratio", "\n", "pred_size", "=", "len", "(", "pred", ")", "\n", "if", "B_und", "is", "not", "None", ":", "\n", "        ", "pred_size", "+=", "len", "(", "pred_und", ")", "\n", "", "cond_neg_size", "=", "0.5", "*", "d", "*", "(", "d", "-", "1", ")", "-", "len", "(", "cond", ")", "\n", "fdr", "=", "float", "(", "len", "(", "reverse", ")", "+", "len", "(", "false_pos", ")", ")", "/", "max", "(", "pred_size", ",", "1", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.graph_prunned_by_coef_2nd": [[57, 99], ["len", "sklearn.linear_model.LinearRegression", "sklearn.preprocessing.PolynomialFeatures", "range", "sklearn.linear_model.LinearRegression.fit", "numpy.zeros", "range", "W.append", "numpy.sum", "W.append", "sklearn.preprocessing.PolynomialFeatures.fit_transform", "sklearn.preprocessing.PolynomialFeatures.get_feature_names", "numpy.zeros", "enumerate", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit"], ["fpr", "=", "float", "(", "len", "(", "reverse", ")", "+", "len", "(", "false_pos", ")", ")", "/", "max", "(", "cond_neg_size", ",", "1", ")", "\n", "# structural hamming distance", "\n", "B_lower", "=", "np", ".", "tril", "(", "B", "+", "B", ".", "T", ")", "\n", "if", "B_und", "is", "not", "None", ":", "\n", "        ", "B_lower", "+=", "np", ".", "tril", "(", "B_und", "+", "B_und", ".", "T", ")", "\n", "", "pred_lower", "=", "np", ".", "flatnonzero", "(", "B_lower", ")", "\n", "cond_lower", "=", "np", ".", "flatnonzero", "(", "np", ".", "tril", "(", "B_true", "+", "B_true", ".", "T", ")", ")", "\n", "extra_lower", "=", "np", ".", "setdiff1d", "(", "pred_lower", ",", "cond_lower", ",", "assume_unique", "=", "True", ")", "\n", "missing_lower", "=", "np", ".", "setdiff1d", "(", "cond_lower", ",", "pred_lower", ",", "assume_unique", "=", "True", ")", "\n", "shd", "=", "len", "(", "extra_lower", ")", "+", "len", "(", "missing_lower", ")", "+", "len", "(", "reverse", ")", "\n", "\n", "return", "{", "\n", "'fdr'", ":", "fdr", ",", "\n", "'tpr'", ":", "tpr", ",", "\n", "'fpr'", ":", "fpr", ",", "\n", "'shd'", ":", "shd", ",", "\n", "'pred_size'", ":", "pred_size", "\n", "}", "\n", "\n", "\n", "", "def", "plot_recovered_graph", "(", "W_est", ",", "W", ",", "save_name", "=", "None", ")", ":", "\n", "    ", "fig", ",", "(", "ax1", ",", "ax2", ")", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "8", ",", "3", ")", ",", "ncols", "=", "2", ")", "\n", "\n", "ax1", ".", "set_title", "(", "'recovered_graph'", ")", "\n", "map1", "=", "ax1", ".", "imshow", "(", "W_est", ",", "cmap", "=", "'Greys'", ",", "interpolation", "=", "'none'", ")", "\n", "fig", ".", "colorbar", "(", "map1", ",", "ax", "=", "ax1", ")", "\n", "\n", "ax2", ".", "set_title", "(", "'true_graph'", ")", "\n", "map2", "=", "ax2", ".", "imshow", "(", "W", ",", "cmap", "=", "'Greys'", ",", "interpolation", "=", "'none'", ")", "\n", "fig", ".", "colorbar", "(", "map2", ",", "ax", "=", "ax2", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "if", "save_name", "is", "not", "None", ":", "\n", "        ", "fig", ".", "savefig", "(", "save_name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.visualize_result": [[107, 115], ["analyze_utils.plot_recovered_graph", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.plot_recovered_graph"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.get_config": [[117, 126], ["open", "f.readlines", "eval", "[].split", "line.split"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.get_true_graph_int": [[140, 149], ["open", "f.readlines", "eval", "[].split", "line.split"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.convert_graph_int_to_adj_mat": [[101, 106], ["numpy.array", "list", "map", "numpy.base_repr", "len", "len", "numpy.base_repr"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.config_graph.add_argument_group": [[9, 13], ["parser.add_argument_group", "arg_lists.append"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.config_graph.add_argument_group"], ["def", "add_argument_group", "(", "name", ")", ":", "\n", "    ", "arg", "=", "parser", ".", "add_argument_group", "(", "name", ")", "\n", "arg_lists", ".", "append", "(", "arg", ")", "\n", "return", "arg", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.config_graph.str2bool": [[15, 17], ["v.lower"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "return", "v", ".", "lower", "(", ")", "in", "(", "'true'", ",", "'1'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.config_graph.get_config": [[89, 92], ["parser.parse_known_args"], "function", ["None"], ["def", "get_config", "(", ")", ":", "\n", "    ", "config", ",", "unparsed", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "return", "config", ",", "unparsed", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.config_graph.print_config": [[94, 116], ["config_graph.get_config", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.config_graph.get_config"], ["", "def", "print_config", "(", ")", ":", "\n", "    ", "config", ",", "_", "=", "get_config", "(", ")", "\n", "print", "(", "'\\n'", ")", "\n", "print", "(", "'Data Config:'", ")", "\n", "print", "(", "'* Batch size:'", ",", "config", ".", "batch_size", ")", "\n", "print", "(", "'* Sequence length:'", ",", "config", ".", "max_length", ")", "\n", "print", "(", "'* City coordinates:'", ",", "config", ".", "input_dimension", ")", "\n", "print", "(", "'\\n'", ")", "\n", "print", "(", "'Network Config:'", ")", "\n", "print", "(", "'* Restored model:'", ",", "config", ".", "restore_model", ")", "\n", "print", "(", "'* Actor hidden_dim (embed / num neurons):'", ",", "config", ".", "hidden_dim", ")", "\n", "print", "(", "'* Actor tan clipping:'", ",", "config", ".", "C", ")", "\n", "print", "(", "'\\n'", ")", "\n", "if", "config", ".", "inference_mode", "==", "False", ":", "\n", "        ", "print", "(", "'Training Config:'", ")", "\n", "print", "(", "'* Nb epoch:'", ",", "config", ".", "nb_epoch", ")", "\n", "print", "(", "'* Temperature:'", ",", "config", ".", "temperature", ")", "\n", "print", "(", "'* Actor learning rate (init,decay_step,decay_rate):'", ",", "config", ".", "lr1_start", ",", "config", ".", "lr1_decay_step", ",", "config", ".", "lr1_decay_rate", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Testing Config:'", ")", "\n", "print", "(", "'* Summary writer log dir:'", ",", "config", ".", "log_dir", ")", "\n", "print", "(", "'\\n'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.lambda_utils.BIC_input_graph": [[23, 63], ["sklearn.preprocessing.PolynomialFeatures", "range", "sklearn.linear_model.LinearRegression", "sklearn.gaussian_process.GaussianProcessRegressor", "list", "numpy.sum", "numpy.log", "numpy.sum", "numpy.mean", "sklearn.gaussian_process.GaussianProcessRegressor.fit", "sklearn.gaussian_process.GaussianProcessRegressor.predict", "numpy.square", "RSS_ls.append", "RSS_ls.append", "numpy.sum", "numpy.abs", "sklearn.preprocessing.PolynomialFeatures.fit_transform", "numpy.median", "numpy.sum", "numpy.log", "scipy.spatial.distance.pdist", "numpy.array"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.GPRMine.predict"], ["        ", "y_", "=", "X", "[", ":", ",", "[", "i", "]", "]", "\n", "inds_x", "=", "list", "(", "np", ".", "abs", "(", "g", "[", "i", "]", ")", ">", "0.1", ")", "\n", "\n", "if", "np", ".", "sum", "(", "inds_x", ")", "<", "0.1", ":", "\n", "            ", "y_pred", "=", "np", ".", "mean", "(", "y_", ")", "\n", "", "else", ":", "\n", "            ", "X_", "=", "X", "[", ":", ",", "inds_x", "]", "\n", "if", "reg_type", "==", "'QR'", ":", "\n", "                ", "X_", "=", "poly", ".", "fit_transform", "(", "X_", ")", "[", ":", ",", "1", ":", "]", "\n", "", "elif", "reg_type", "==", "'GPR'", ":", "\n", "                ", "med_w", "=", "np", ".", "median", "(", "pdist", "(", "X_", ",", "'euclidean'", ")", ")", "\n", "X_", "=", "X_", "/", "med_w", "\n", "", "reg", ".", "fit", "(", "X_", ",", "y_", ")", "\n", "y_pred", "=", "reg", ".", "predict", "(", "X_", ")", "\n", "", "RSSi", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "y_", "-", "y_pred", ")", ")", "\n", "\n", "if", "reg_type", "==", "'GPR'", ":", "\n", "            ", "RSS_ls", ".", "append", "(", "RSSi", "+", "1.0", ")", "\n", "", "else", ":", "\n", "            ", "RSS_ls", ".", "append", "(", "RSSi", ")", "\n", "\n", "", "", "if", "score_type", "==", "'BIC'", ":", "\n", "        ", "return", "np", ".", "log", "(", "np", ".", "sum", "(", "RSS_ls", ")", "/", "n", "+", "1e-8", ")", "\n", "", "elif", "score_type", "==", "'BIC_different_var'", ":", "\n", "        ", "return", "np", ".", "sum", "(", "np", ".", "log", "(", "np", ".", "array", "(", "RSS_ls", ")", "/", "n", ")", "+", "1e-8", ")", "\n", "\n", "\n", "", "", "def", "BIC_lambdas", "(", "X", ",", "gl", "=", "None", ",", "gu", "=", "None", ",", "gtrue", "=", "None", ",", "reg_type", "=", "'LR'", ",", "score_type", "=", "'BIC'", ")", ":", "\n", "    ", "\"\"\"\n    :param X: dataset\n    :param gl: input graph to get score lower bound\n    :param gu: input graph to get score upper bound\n    :param gtrue: input true graph\n    :param reg_type:\n    :param score_type:\n    :return: score lower bound, score upper bound, true score (only for monitoring)\n    \"\"\"", "\n", "\n", "n", ",", "d", "=", "X", ".", "shape", "\n", "\n", "if", "score_type", "==", "'BIC'", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.lambda_utils.BIC_lambdas": [[65, 106], ["lambda_utils.BIC_input_graph", "lambda_utils.BIC_input_graph", "numpy.ones", "range", "numpy.zeros", "print", "print", "print", "numpy.log", "lambda_utils.BIC_input_graph", "lambda_utils.BIC_input_graph", "numpy.log", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.lambda_utils.BIC_input_graph", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.lambda_utils.BIC_input_graph", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.lambda_utils.BIC_input_graph", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.lambda_utils.BIC_input_graph"], ["", "elif", "score_type", "==", "'BIC_different_var'", ":", "\n", "        ", "bic_penalty", "=", "np", ".", "log", "(", "n", ")", "/", "n", "\n", "\n", "# default gl for BIC score: complete graph (except digonals)", "\n", "", "if", "gl", "is", "None", ":", "\n", "        ", "g_ones", "=", "np", ".", "ones", "(", "(", "d", ",", "d", ")", ")", "\n", "for", "i", "in", "range", "(", "d", ")", ":", "\n", "            ", "g_ones", "[", "i", ",", "i", "]", "=", "0", "\n", "", "gl", "=", "g_ones", "\n", "\n", "# default gu for BIC score: empty graph", "\n", "", "if", "gu", "is", "None", ":", "\n", "        ", "gu", "=", "np", ".", "zeros", "(", "(", "d", ",", "d", ")", ")", "\n", "\n", "", "sl", "=", "BIC_input_graph", "(", "X", ",", "gl", ",", "reg_type", ",", "score_type", ")", "\n", "su", "=", "BIC_input_graph", "(", "X", ",", "gu", ",", "reg_type", ",", "score_type", ")", "\n", "\n", "if", "gtrue", "is", "None", ":", "\n", "        ", "strue", "=", "sl", "-", "10", "\n", "", "else", ":", "\n", "        ", "print", "(", "BIC_input_graph", "(", "X", ",", "gtrue", ",", "reg_type", ",", "score_type", ")", ")", "\n", "print", "(", "gtrue", ")", "\n", "print", "(", "bic_penalty", ")", "\n", "strue", "=", "BIC_input_graph", "(", "X", ",", "gtrue", ",", "reg_type", ",", "score_type", ")", "+", "np", ".", "sum", "(", "gtrue", ")", "*", "bic_penalty", "\n", "\n", "", "return", "sl", ",", "su", ",", "strue", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.torch_utils.is_cuda_available": [[22, 24], ["torch.cuda.is_available"], "function", ["None"], ["def", "is_cuda_available", "(", ")", ":", "\n", "    ", "return", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.torch_utils.set_seed": [[26, 43], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "str"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "\"\"\"\n    Referred from:\n    - https://stackoverflow.com/questions/38469632/tensorflow-non-repeatable-results\n    \"\"\"", "\n", "# Reproducibility", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "# torch.backends.cudnn.deterministic = True", "\n", "# torch.backends.cudnn.benchmark = True", "\n", "try", ":", "\n", "        ", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.convert_logits_to_sigmoid": [[20, 27], ["torch.sigmoid", "torch.eye"], "function", ["None"], ["# See the License for the specific language governing permissions and", "\n", "# limitations under the License.", "\n", "\n", "import", "os", "\n", "import", "random", "\n", "import", "torch", "\n", "import", "numpy", "as", "np", "\n", "import", "networkx", "as", "nx", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.compute_acyclicity": [[29, 38], ["torch.trace", "torch.matrix_exp"], "function", ["None"], ["\n", "def", "is_cuda_available", "(", ")", ":", "\n", "    ", "return", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n", "\n", "", "def", "set_seed", "(", "seed", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.sample_gumbel": [[40, 49], ["torch.tensor", "torch.manual_seed", "torch.rand", "torch.log", "numpy.arange", "numpy.arange", "torch.log"], "function", ["None"], ["\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "try", ":", "\n", "        ", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.gumbel_sigmoid": [[51, 59], ["torch.sigmoid", "utils.sample_gumbel", "utils.sample_gumbel"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.sample_gumbel", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.sample_gumbel"], ["        ", "pass", "\n", "\n", "\n", "", "", "def", "is_dag", "(", "B", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.generate_upper_triangle_indices": [[61, 70], ["numpy.arange().reshape", "torch.tensor", "torch.zeros", "numpy.arange", "torch.triu"], "function", ["None"], ["\n", "return", "nx", ".", "is_directed_acyclic_graph", "(", "nx", ".", "DiGraph", "(", "B", ")", ")", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.callback_after_training": [[72, 82], ["utils.convert_logits_to_sigmoid", "convert_logits_to_sigmoid.clone", "numpy.arange", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.convert_logits_to_sigmoid"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.tensor_description": [[84, 106], ["var.get_shape", "enumerate", "str", "str", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.transformer_encoder.TransformerEncoder.__init__": [[81, 93], ["tensorflow.contrib.layers.xavier_initializer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "is_train", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "config", ".", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "config", ".", "max_length", "# input sequence length (number of cities)", "\n", "self", ".", "input_dimension", "=", "config", ".", "input_dimension", "# dimension of input, multiply 2 for expanding dimension to input complex value to tf, add 1 token", "\n", "\n", "self", ".", "input_embed", "=", "config", ".", "hidden_dim", "# dimension of embedding space (actor)", "\n", "self", ".", "num_heads", "=", "config", ".", "num_heads", "\n", "self", ".", "num_stacks", "=", "config", ".", "num_stacks", "\n", "\n", "self", ".", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "# variables initializer", "\n", "\n", "self", ".", "is_training", "=", "is_train", "#not config.inference_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.transformer_encoder.TransformerEncoder.encode": [[94, 115], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.conv1d", "tensorflow.layers.batch_normalization", "tensorflow.variable_scope", "range", "tensorflow.variable_scope", "transformer_encoder.multihead_attention", "transformer_encoder.feedforward"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.transformer_decoder.multihead_attention", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.transformer_decoder.feedforward"], ["", "def", "encode", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"embedding\"", ")", ":", "\n", "# Embed input sequence", "\n", "          ", "W_embed", "=", "tf", ".", "get_variable", "(", "\"weights\"", ",", "[", "1", ",", "self", ".", "input_dimension", ",", "self", ".", "input_embed", "]", ",", "initializer", "=", "self", ".", "initializer", ")", "\n", "self", ".", "embedded_input", "=", "tf", ".", "nn", ".", "conv1d", "(", "inputs", ",", "W_embed", ",", "1", ",", "\"VALID\"", ",", "name", "=", "\"embedded_input\"", ")", "\n", "# Batch Normalization", "\n", "self", ".", "enc", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "self", ".", "embedded_input", ",", "axis", "=", "2", ",", "training", "=", "self", ".", "is_training", ",", "name", "=", "'layer_norm'", ",", "reuse", "=", "None", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"stack\"", ")", ":", "\n", "# Blocks", "\n", "          ", "for", "i", "in", "range", "(", "self", ".", "num_stacks", ")", ":", "# num blocks", "\n", "              ", "with", "tf", ".", "variable_scope", "(", "\"block_{}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "# Multihead Attention", "\n", "                  ", "self", ".", "enc", "=", "multihead_attention", "(", "self", ".", "enc", ",", "num_units", "=", "self", ".", "input_embed", ",", "num_heads", "=", "self", ".", "num_heads", ",", "dropout_rate", "=", "0.0", ",", "is_training", "=", "self", ".", "is_training", ")", "\n", "\n", "# Feed Forward", "\n", "self", ".", "enc", "=", "feedforward", "(", "self", ".", "enc", ",", "num_units", "=", "[", "4", "*", "self", ".", "input_embed", ",", "self", ".", "input_embed", "]", ",", "is_training", "=", "self", ".", "is_training", ")", "\n", "\n", "# Return the output activations [Batch size, Sequence Length, Num_neurons] as tensors.", "\n", "", "", "self", ".", "encoder_output", "=", "self", ".", "enc", "### NOTE: encoder_output is the ref for attention ###", "\n", "return", "self", ".", "encoder_output", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.transformer_encoder.multihead_attention": [[15, 54], ["tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.layers.dropout", "tensorflow.matmul", "tensorflow.concat", "tensorflow.layers.batch_normalization", "tensorflow.split", "tensorflow.split", "tensorflow.split", "tensorflow.transpose", "tensorflow.split", "tensorflow.convert_to_tensor", "tf.concat.get_shape().as_list", "tf.concat.get_shape"], "function", ["None"], ["def", "multihead_attention", "(", "inputs", ",", "num_units", "=", "None", ",", "num_heads", "=", "16", ",", "dropout_rate", "=", "0.1", ",", "is_training", "=", "True", ")", ":", "\n", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"multihead_attention\"", ",", "reuse", "=", "None", ")", ":", "\n", "\n", "# Linear projections", "\n", "        ", "Q", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", ",", "num_units", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "# [batch_size, seq_length, n_hidden]", "\n", "K", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", ",", "num_units", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "# [batch_size, seq_length, n_hidden]", "\n", "V", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", ",", "num_units", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "# Split and concat", "\n", "Q_", "=", "tf", ".", "concat", "(", "tf", ".", "split", "(", "Q", ",", "num_heads", ",", "axis", "=", "2", ")", ",", "axis", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "K_", "=", "tf", ".", "concat", "(", "tf", ".", "split", "(", "K", ",", "num_heads", ",", "axis", "=", "2", ")", ",", "axis", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "V_", "=", "tf", ".", "concat", "(", "tf", ".", "split", "(", "V", ",", "num_heads", ",", "axis", "=", "2", ")", ",", "axis", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "\n", "# Multiplication", "\n", "outputs", "=", "tf", ".", "matmul", "(", "Q_", ",", "tf", ".", "transpose", "(", "K_", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "# num_heads*[batch_size, seq_length, seq_length]", "\n", "\n", "# Scale", "\n", "outputs", "=", "outputs", "/", "(", "K_", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "**", "0.5", ")", "\n", "\n", "# Activation", "\n", "outputs", "=", "tf", ".", "nn", ".", "softmax", "(", "outputs", ")", "# num_heads*[batch_size, seq_length, seq_length]", "\n", "\n", "# Dropouts", "\n", "outputs", "=", "tf", ".", "layers", ".", "dropout", "(", "outputs", ",", "rate", "=", "dropout_rate", ",", "training", "=", "tf", ".", "convert_to_tensor", "(", "is_training", ")", ")", "\n", "\n", "# Weighted sum", "\n", "outputs", "=", "tf", ".", "matmul", "(", "outputs", ",", "V_", ")", "# num_heads*[batch_size, seq_length, n_hidden/num_heads]", "\n", "\n", "# Restore shape", "\n", "outputs", "=", "tf", ".", "concat", "(", "tf", ".", "split", "(", "outputs", ",", "num_heads", ",", "axis", "=", "0", ")", ",", "axis", "=", "2", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "# Residual connection", "\n", "outputs", "+=", "inputs", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "# Normalize", "\n", "outputs", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "outputs", ",", "axis", "=", "2", ",", "training", "=", "is_training", ",", "name", "=", "'ln'", ",", "reuse", "=", "None", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.transformer_encoder.feedforward": [[59, 77], ["tensorflow.variable_scope", "tensorflow.layers.conv1d", "tensorflow.layers.conv1d", "tensorflow.layers.batch_normalization"], "function", ["None"], ["", "def", "feedforward", "(", "inputs", ",", "num_units", "=", "[", "2048", ",", "512", "]", ",", "is_training", "=", "True", ")", ":", "\n", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"ffn\"", ",", "reuse", "=", "None", ")", ":", "\n", "# Inner layer", "\n", "        ", "params", "=", "{", "\"inputs\"", ":", "inputs", ",", "\"filters\"", ":", "num_units", "[", "0", "]", ",", "\"kernel_size\"", ":", "1", ",", "\"activation\"", ":", "tf", ".", "nn", ".", "relu", ",", "\"use_bias\"", ":", "True", "}", "\n", "outputs", "=", "tf", ".", "layers", ".", "conv1d", "(", "**", "params", ")", "\n", "\n", "# Readout layer", "\n", "params", "=", "{", "\"inputs\"", ":", "outputs", ",", "\"filters\"", ":", "num_units", "[", "1", "]", ",", "\"kernel_size\"", ":", "1", ",", "\"activation\"", ":", "None", ",", "\"use_bias\"", ":", "True", "}", "\n", "outputs", "=", "tf", ".", "layers", ".", "conv1d", "(", "**", "params", ")", "\n", "\n", "# Residual connection", "\n", "outputs", "+=", "inputs", "\n", "\n", "# Normalize", "\n", "outputs", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "outputs", ",", "axis", "=", "2", ",", "training", "=", "is_training", ",", "name", "=", "'ln'", ",", "reuse", "=", "None", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.gat_encoder.GATEncoder.__init__": [[40, 53], ["tensorflow.contrib.layers.xavier_initializer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "is_train", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "config", ".", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "config", ".", "max_length", "# input sequence length (number of cities)", "\n", "self", ".", "input_dimension", "=", "config", ".", "input_dimension", "# dimension of input, multiply 2 for expanding dimension to input complex value to tf, add 1 token", "\n", "\n", "self", ".", "hidden_dim", "=", "config", ".", "hidden_dim", "# dimension of embedding space (actor)", "\n", "self", ".", "num_heads", "=", "config", ".", "num_heads", "\n", "self", ".", "num_stacks", "=", "config", ".", "num_stacks", "\n", "self", ".", "residual", "=", "config", ".", "residual", "\n", "\n", "self", ".", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "# variables initializer", "\n", "\n", "self", ".", "is_training", "=", "is_train", "#not config.inference_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.gat_encoder.GATEncoder.encode": [[54, 71], ["range", "range", "tensorflow.concat", "attns.append", "gat_encoder.attn_head"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.gat_encoder.attn_head"], ["", "def", "encode", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        input shape: (batch_size, max_length, input_dimension)\n        output shape: (batch_size, max_length, input_embed)\n        \"\"\"", "\n", "# First stack", "\n", "head_hidden_dim", "=", "self", ".", "hidden_dim", "/", "self", ".", "num_heads", "\n", "h_1", "=", "inputs", "\n", "for", "_", "in", "range", "(", "self", ".", "num_stacks", ")", ":", "\n", "            ", "attns", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "num_heads", ")", ":", "\n", "                ", "attns", ".", "append", "(", "attn_head", "(", "h_1", ",", "out_sz", "=", "head_hidden_dim", ",", "activation", "=", "tf", ".", "nn", ".", "elu", ",", "\n", "in_drop", "=", "0", ",", "coef_drop", "=", "0", ",", "residual", "=", "self", ".", "residual", ")", ")", "\n", "", "h_1", "=", "tf", ".", "concat", "(", "attns", ",", "axis", "=", "-", "1", ")", "\n", "#             h_1 = tf.add_n(attns) / self.num_heads    # Another way to aggregate attention head", "\n", "\n", "", "return", "h_1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.gat_encoder.attn_head": [[7, 36], ["tensorflow.name_scope", "tensorflow.layers.conv1d", "tensorflow.layers.conv1d", "tensorflow.layers.conv1d", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.contrib.layers.bias_add", "activation", "tensorflow.nn.dropout", "tensorflow.transpose", "tensorflow.nn.leaky_relu", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.layers.conv1d"], "function", ["None"], ["def", "attn_head", "(", "seq", ",", "out_sz", ",", "activation", ",", "in_drop", "=", "0.0", ",", "coef_drop", "=", "0.0", ",", "residual", "=", "False", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "'my_attn'", ")", ":", "\n", "        ", "if", "in_drop", "!=", "0.0", ":", "\n", "            ", "seq", "=", "tf", ".", "nn", ".", "dropout", "(", "seq", ",", "1.0", "-", "in_drop", ")", "\n", "\n", "", "seq_fts", "=", "tf", ".", "layers", ".", "conv1d", "(", "seq", ",", "out_sz", ",", "1", ",", "use_bias", "=", "False", ")", "\n", "\n", "# simplest self-attention possible", "\n", "f_1", "=", "tf", ".", "layers", ".", "conv1d", "(", "seq_fts", ",", "1", ",", "1", ")", "\n", "f_2", "=", "tf", ".", "layers", ".", "conv1d", "(", "seq_fts", ",", "1", ",", "1", ")", "\n", "logits", "=", "f_1", "+", "tf", ".", "transpose", "(", "f_2", ",", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "coefs", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "nn", ".", "leaky_relu", "(", "logits", ")", ")", "\n", "\n", "if", "coef_drop", "!=", "0.0", ":", "\n", "            ", "coefs", "=", "tf", ".", "nn", ".", "dropout", "(", "coefs", ",", "1.0", "-", "coef_drop", ")", "\n", "", "if", "in_drop", "!=", "0.0", ":", "\n", "            ", "seq_fts", "=", "tf", ".", "nn", ".", "dropout", "(", "seq_fts", ",", "1.0", "-", "in_drop", ")", "\n", "\n", "", "vals", "=", "tf", ".", "matmul", "(", "coefs", ",", "seq_fts", ")", "\n", "ret", "=", "tf", ".", "contrib", ".", "layers", ".", "bias_add", "(", "vals", ")", "\n", "\n", "# residual connection", "\n", "if", "residual", ":", "\n", "            ", "if", "seq", ".", "shape", "[", "-", "1", "]", "!=", "ret", ".", "shape", "[", "-", "1", "]", ":", "\n", "                ", "ret", "=", "ret", "+", "tf", ".", "layers", ".", "conv1d", "(", "seq", ",", "ret", ".", "shape", "[", "-", "1", "]", ",", "1", ")", "# activation", "\n", "", "else", ":", "\n", "                ", "ret", "=", "ret", "+", "seq", "\n", "\n", "", "", "return", "activation", "(", "ret", ")", "# activation", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.AttnHead.__init__": [[23, 51], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "encoder.AttnHead.reset_parameters", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "hidden_dim", ",", "out_sz", ",", "device", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "_seq_fts", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "hidden_dim", ",", "\n", "out_channels", "=", "out_sz", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "bias", "=", "False", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "self", ".", "_f_1", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "out_sz", ",", "\n", "out_channels", "=", "1", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "_f_2", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "out_sz", ",", "\n", "out_channels", "=", "1", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "self", ".", "_ret", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "hidden_dim", ",", "\n", "out_channels", "=", "out_sz", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "self", ".", "_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ",", "device", "=", "self", ".", "device", ")", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.AttnHead.reset_parameters": [[52, 54], ["torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "_bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.AttnHead.forward": [[55, 87], ["torch.dropout.permute", "encoder.AttnHead._seq_fts", "encoder.AttnHead._f_1", "encoder.AttnHead._f_2", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.elu", "torch.elu", "torch.elu", "torch.dropout", "torch.dropout", "torch.dropout", "encoder.AttnHead.permute", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout.permute", "torch.dropout.permute", "encoder.AttnHead._ret().permute", "torch.dropout.permute", "torch.dropout.permute", "encoder.AttnHead._ret"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "seq", ",", "in_drop", "=", "0.0", ",", "coef_drop", "=", "0.0", ",", "residual", "=", "False", ")", ":", "\n", "\n", "        ", "seq", "=", "seq", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "if", "in_drop", "!=", "0.0", ":", "\n", "            ", "seq", "=", "F", ".", "dropout", "(", "seq", ",", "in_drop", ")", "\n", "\n", "", "seq_fts", "=", "self", ".", "_seq_fts", "(", "seq", ")", "\n", "\n", "# simplest self-attention possible", "\n", "f_1", "=", "self", ".", "_f_1", "(", "seq_fts", ")", "\n", "f_2", "=", "self", ".", "_f_2", "(", "seq_fts", ")", "\n", "\n", "logits", "=", "f_1", "+", "f_2", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "coefs", "=", "F", ".", "softmax", "(", "F", ".", "leaky_relu", "(", "logits", ")", ")", "\n", "\n", "if", "coef_drop", "!=", "0.0", ":", "\n", "            ", "coefs", "=", "F", ".", "dropout", "(", "coefs", ",", "coef_drop", ")", "\n", "", "if", "in_drop", "!=", "0.0", ":", "\n", "            ", "seq_fts", "=", "F", ".", "dropout", "(", "seq_fts", ",", "in_drop", ")", "\n", "\n", "", "vals", "=", "torch", ".", "matmul", "(", "coefs", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ",", "seq_fts", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "ret", "=", "vals", "+", "self", ".", "_bias", "\n", "\n", "# residual connection", "\n", "if", "residual", ":", "\n", "            ", "if", "seq", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "shape", "[", "-", "1", "]", "!=", "ret", ".", "shape", "[", "-", "1", "]", ":", "\n", "                ", "ret", "=", "ret", "+", "self", ".", "_ret", "(", "seq", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# activation", "\n", "", "else", ":", "\n", "                ", "ret", "=", "ret", "+", "seq", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "", "", "return", "F", ".", "elu", "(", "ret", ")", "# activation", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.GATEncoder.__init__": [[91, 111], ["torch.Module.__init__", "int", "encoder.AttnHead"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "max_length", ",", "input_dimension", ",", "hidden_dim", ",", "\n", "num_heads", ",", "num_stacks", ",", "residual", ",", "is_train", ",", "device", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "max_length", "# input sequence length (number of cities)", "\n", "self", ".", "input_dimension", "=", "input_dimension", "# dimension of input, multiply 2 for expanding dimension to input complex value to tf, add 1 token", "\n", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "# dimension of embedding space (actor)", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "num_stacks", "=", "num_stacks", "\n", "self", ".", "residual", "=", "residual", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_training", "=", "is_train", "#not self.inference_mode", "\n", "\n", "self", ".", "head_hidden_dim", "=", "int", "(", "self", ".", "hidden_dim", "/", "self", ".", "num_heads", ")", "\n", "\n", "self", ".", "attn_head", "=", "AttnHead", "(", "\n", "self", ".", "hidden_dim", ",", "self", ".", "head_hidden_dim", ",", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.GATEncoder.forward": [[112, 126], ["range", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attns.append", "encoder.GATEncoder.attn_head"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.gat_encoder.attn_head"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        input shape: (batch_size, max_length, input_dimension)\n        output shape: (batch_size, max_length, input_embed)\n        \"\"\"", "\n", "# First stack", "\n", "h_1", "=", "inputs", "\n", "for", "_", "in", "range", "(", "self", ".", "num_stacks", ")", ":", "\n", "            ", "attns", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "num_heads", ")", ":", "\n", "                ", "attns", ".", "append", "(", "self", ".", "attn_head", "(", "h_1", ",", "in_drop", "=", "0", ",", "coef_drop", "=", "0", ",", "residual", "=", "self", ".", "residual", ")", ")", "\n", "", "h_1", "=", "torch", ".", "cat", "(", "attns", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "return", "h_1", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.MultiheadAttention.__init__": [[138, 153], ["torch.Module.__init__", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dimension", ",", "num_units", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "# Linear projections", "\n", "# Q_layer = nn.Linear(in_features=input_dimension, out_features=num_units)", "\n", "self", ".", "Q_layer", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_dimension", ",", "out_features", "=", "num_units", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "K_layer", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_dimension", ",", "out_features", "=", "num_units", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "V_layer", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_dimension", ",", "out_features", "=", "num_units", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Normalize", "\n", "self", ".", "bn_layer", "=", "nn", ".", "BatchNorm1d", "(", "input_dimension", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.MultiheadAttention.forward": [[154, 195], ["inputs.permute.permute.permute", "encoder.MultiheadAttention.Q_layer", "encoder.MultiheadAttention.K_layer", "encoder.MultiheadAttention.V_layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.softmax", "torch.dropout", "torch.dropout", "torch.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.MultiheadAttention.permute", "encoder.MultiheadAttention.bn_layer", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "int", "int", "int", "int"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "num_heads", "=", "16", ",", "dropout_rate", "=", "0.1", ",", "is_training", "=", "True", ")", ":", "\n", "\n", "        ", "input_dimension", "=", "inputs", ".", "shape", "[", "1", "]", "\n", "inputs", "=", "inputs", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "Q", "=", "self", ".", "Q_layer", "(", "inputs", ")", "# [batch_size, seq_length, n_hidden]", "\n", "K", "=", "self", ".", "K_layer", "(", "inputs", ")", "# [batch_size, seq_length, n_hidden]", "\n", "V", "=", "self", ".", "V_layer", "(", "inputs", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "# Split and concat", "\n", "Q_", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "Q", ",", "int", "(", "input_dimension", "/", "num_heads", ")", ",", "dim", "=", "2", ")", ",", "dim", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "K_", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "K", ",", "int", "(", "input_dimension", "/", "num_heads", ")", ",", "dim", "=", "2", ")", ",", "dim", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "V_", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "V", ",", "int", "(", "input_dimension", "/", "num_heads", ")", ",", "dim", "=", "2", ")", ",", "dim", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "\n", "# Multiplication", "\n", "outputs", "=", "torch", ".", "matmul", "(", "Q_", ",", "K_", ".", "permute", "(", "[", "0", ",", "2", ",", "1", "]", ")", ")", "# num_heads*[batch_size, seq_length, seq_length]", "\n", "\n", "# Scale", "\n", "outputs", "=", "outputs", "/", "(", "K_", ".", "shape", "[", "-", "1", "]", "**", "0.5", ")", "\n", "\n", "# Activation", "\n", "outputs", "=", "F", ".", "softmax", "(", "outputs", ")", "# num_heads*[batch_size, seq_length, seq_length]", "\n", "\n", "# Dropouts", "\n", "outputs", "=", "F", ".", "dropout", "(", "outputs", ",", "p", "=", "dropout_rate", ",", "training", "=", "is_training", ")", "\n", "\n", "# Weighted sum", "\n", "outputs", "=", "torch", ".", "matmul", "(", "outputs", ",", "V_", ")", "# num_heads*[batch_size, seq_length, n_hidden/num_heads]", "\n", "\n", "# Restore shape", "\n", "outputs", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "outputs", ",", "int", "(", "outputs", ".", "shape", "[", "0", "]", "/", "num_heads", ")", ",", "dim", "=", "0", ")", ",", "dim", "=", "2", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "# Residual connection", "\n", "outputs", "=", "outputs", "+", "inputs", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "outputs", "=", "outputs", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "# Normalize", "\n", "outputs", "=", "self", ".", "bn_layer", "(", "outputs", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.FeedForward.__init__": [[201, 217], ["torch.Module.__init__", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_units", "=", "[", "2048", ",", "512", "]", ",", "device", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "# Inner layer", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "num_units", "[", "1", "]", ",", "\n", "out_channels", "=", "num_units", "[", "0", "]", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "bias", "=", "True", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# Readout layer", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "num_units", "[", "0", "]", ",", "\n", "out_channels", "=", "num_units", "[", "1", "]", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "bias", "=", "True", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "bn_layer1", "=", "nn", ".", "BatchNorm1d", "(", "num_units", "[", "1", "]", ")", ".", "to", "(", "self", ".", "device", ")", "# \u4f20\u5165\u901a\u9053\u6570", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.FeedForward.forward": [[218, 231], ["encoder.FeedForward.conv1", "torch.relu", "torch.relu", "torch.relu", "encoder.FeedForward.conv2", "encoder.FeedForward.bn_layer1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "conv1", "(", "inputs", ")", "\n", "outputs", "=", "F", ".", "relu", "(", "outputs", ")", "\n", "\n", "outputs", "=", "self", ".", "conv2", "(", "outputs", ")", "\n", "\n", "# Residual connection", "\n", "outputs", "+=", "inputs", "\n", "\n", "outputs", "=", "self", ".", "bn_layer1", "(", "outputs", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.TransformerEncoder.__init__": [[235, 273], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "encoder.TransformerEncoder.reset_parameters", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "range", "range", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "encoder.MultiheadAttention", "encoder.TransformerEncoder.multihead_attention.append", "encoder.FeedForward", "encoder.TransformerEncoder.feedforward.append", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "max_length", ",", "input_dimension", ",", "hidden_dim", ",", "\n", "num_heads", ",", "num_stacks", ",", "is_train", ",", "device", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "max_length", "# input sequence length (number of cities)", "\n", "# dimension of input, multiply 2 for expanding dimension to input complex value to tf, add 1 token", "\n", "self", ".", "input_dimension", "=", "input_dimension", "\n", "\n", "self", ".", "input_embed", "=", "hidden_dim", "# dimension of embedding space (actor)", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "num_stacks", "=", "num_stacks", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_training", "=", "is_train", "# not self.inference_mode", "\n", "\n", "# self._emb_params = LayerParams(self, 'emb', self.device)", "\n", "self", ".", "emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "(", "1", ",", "self", ".", "input_dimension", ",", "\n", "self", ".", "input_embed", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "# Batch Normalization", "\n", "self", ".", "bn_layer2", "=", "nn", ".", "BatchNorm1d", "(", "self", ".", "input_dimension", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# attention", "\n", "self", ".", "multihead_attention", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_stacks", ")", ":", "# num blocks", "\n", "            ", "multihead_attention", "=", "MultiheadAttention", "(", "self", ".", "input_dimension", ",", "\n", "num_units", "=", "self", ".", "input_embed", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "multihead_attention", ".", "append", "(", "multihead_attention", ")", "\n", "\n", "# FeedForward", "\n", "", "self", ".", "feedforward", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_stacks", ")", ":", "# num blocks", "\n", "            ", "feedforward", "=", "FeedForward", "(", "num_units", "=", "[", "4", "*", "self", ".", "input_embed", ",", "self", ".", "input_embed", "]", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "feedforward", ".", "append", "(", "feedforward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.TransformerEncoder.reset_parameters": [[274, 276], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["None"], ["", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "emb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.encoder.encoder.TransformerEncoder.forward": [[277, 308], ["inputs.permute.permute.permute", "W_embed.permute", "torch.conv1d", "torch.conv1d", "torch.conv1d", "encoder.TransformerEncoder.bn_layer2", "range", "encoder.TransformerEncoder.encoder_output.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "inputs", "=", "inputs", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "# Embed input sequence", "\n", "# W_embed = self._emb_params.get_weights((1, self.input_dimension, self.input_embed))", "\n", "W_embed", "=", "self", ".", "emb", "\n", "\n", "# conv1 = nn.Conv1d(in_channels=self.input_dimension, out_channels=self.input_embed, kernel_size=1)", "\n", "# self.embedded_input = conv1(inputs)", "\n", "W_embed_", "=", "W_embed", ".", "permute", "(", "2", ",", "1", ",", "0", ")", "\n", "# self.embedded_input = F.conv1d(inputs, W_embed_, stride=1, padding='valid')", "\n", "self", ".", "embedded_input", "=", "F", ".", "conv1d", "(", "inputs", ",", "W_embed_", ",", "stride", "=", "1", ")", "\n", "\n", "# Batch Normalization", "\n", "self", ".", "enc", "=", "self", ".", "bn_layer2", "(", "self", ".", "embedded_input", ")", "\n", "\n", "# Blocks", "\n", "for", "i", "in", "range", "(", "self", ".", "num_stacks", ")", ":", "# num blocks", "\n", "\n", "            ", "self", ".", "enc", "=", "self", ".", "multihead_attention", "[", "i", "]", "(", "self", ".", "enc", ",", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "dropout_rate", "=", "0.0", ",", "is_training", "=", "self", ".", "is_training", ")", "\n", "# Feed Forward", "\n", "self", ".", "enc", "=", "self", ".", "feedforward", "[", "i", "]", "(", "self", ".", "enc", ")", "\n", "\n", "# Return the output activations [Batch size, Sequence Length, Num_neurons] as tensors.", "\n", "", "self", ".", "encoder_output", "=", "self", ".", "enc", "### NOTE: encoder_output is the ref for attention ###", "\n", "\n", "self", ".", "encoder_output", "=", "self", ".", "encoder_output", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "return", "self", ".", "encoder_output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder_graph.Pointer_decoder.__init__": [[11, 84], ["tensorflow.transpose", "tensorflow.contrib.layers.xavier_initializer", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.get_variable", "tensorflow.tile", "tensorflow.get_variable", "encoder_output.get_shape().as_list", "encoder_output.get_shape().as_list", "encoder_output.get_shape().as_list", "tensorflow.tile", "tensorflow.reduce_mean", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "encoder_output.get_shape", "encoder_output.get_shape", "encoder_output.get_shape"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "encoder_output", ",", "config", ")", ":", "\n", "#######################################", "\n", "########## Reference vectors ##########", "\n", "#######################################", "\n", "\n", "        ", "self", ".", "encoder_output", "=", "encoder_output", "# Tensor [Batch size x time steps x cell.state_size] to attend to", "\n", "self", ".", "h", "=", "tf", ".", "transpose", "(", "self", ".", "encoder_output", ",", "[", "1", ",", "0", ",", "2", "]", ")", "# [Batch size x time steps x cell.state_size] to [time steps x Batch size x cell.state_size]", "\n", "\n", "############################", "\n", "########## Config ##########", "\n", "############################", "\n", "\n", "batch_size", "=", "encoder_output", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", "# batch size", "\n", "self", ".", "seq_length", "=", "encoder_output", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "# sequence length", "\n", "n_hidden", "=", "encoder_output", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "2", "]", "# num_neurons", "\n", "\n", "self", ".", "inference_mode", "=", "config", ".", "inference_mode", "# True for inference, False for training", "\n", "self", ".", "temperature", "=", "config", ".", "temperature", "# temperature parameter", "\n", "self", ".", "C", "=", "config", ".", "C", "# logit clip", "\n", "\n", "##########################################", "\n", "########## Decoder's parameters ##########", "\n", "##########################################", "\n", "\n", "# Variables initializer", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "\n", "\n", "# Decoder LSTM cell        ", "\n", "self", ".", "cell", "=", "LSTMCell", "(", "n_hidden", ",", "initializer", "=", "initializer", ")", "\n", "\n", "# Decoder initial input is 'GO', a variable tensor", "\n", "first_input", "=", "tf", ".", "get_variable", "(", "\"GO\"", ",", "[", "1", ",", "n_hidden", "]", ",", "initializer", "=", "initializer", ")", "\n", "self", ".", "decoder_first_input", "=", "tf", ".", "tile", "(", "first_input", ",", "[", "batch_size", ",", "1", "]", ")", "\n", "\n", "# Decoder initial state (tuple) is trainable", "\n", "first_state", "=", "tf", ".", "get_variable", "(", "\"GO_state1\"", ",", "[", "1", ",", "n_hidden", "]", ",", "initializer", "=", "initializer", ")", "\n", "self", ".", "decoder_initial_state", "=", "tf", ".", "tile", "(", "first_state", ",", "[", "batch_size", ",", "1", "]", ")", ",", "tf", ".", "reduce_mean", "(", "self", ".", "encoder_output", ",", "1", ")", "\n", "\n", "# Attending mechanism", "\n", "with", "tf", ".", "variable_scope", "(", "\"glimpse\"", ")", "as", "glimpse", ":", "\n", "            ", "self", ".", "W_ref_g", "=", "tf", ".", "get_variable", "(", "\"W_ref_g\"", ",", "[", "1", ",", "n_hidden", ",", "n_hidden", "]", ",", "initializer", "=", "initializer", ")", "\n", "self", ".", "W_q_g", "=", "tf", ".", "get_variable", "(", "\"W_q_g\"", ",", "[", "n_hidden", ",", "n_hidden", "]", ",", "initializer", "=", "initializer", ")", "\n", "self", ".", "v_g", "=", "tf", ".", "get_variable", "(", "\"v_g\"", ",", "[", "n_hidden", "]", ",", "initializer", "=", "initializer", ")", "\n", "\n", "# Pointing mechanism", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"pointer\"", ")", "as", "pointer", ":", "\n", "            ", "self", ".", "W_ref", "=", "tf", ".", "get_variable", "(", "\"W_ref\"", ",", "[", "1", ",", "n_hidden", ",", "n_hidden", "]", ",", "initializer", "=", "initializer", ")", "\n", "self", ".", "W_q", "=", "tf", ".", "get_variable", "(", "\"W_q\"", ",", "[", "n_hidden", ",", "n_hidden", "]", ",", "initializer", "=", "initializer", ")", "\n", "self", ".", "v", "=", "tf", ".", "get_variable", "(", "\"v\"", ",", "[", "n_hidden", "]", ",", "initializer", "=", "initializer", ")", "\n", "\n", "######################################", "\n", "########## Decoder's output ##########", "\n", "######################################", "\n", "\n", "", "self", ".", "log_softmax", "=", "[", "]", "# store log(p_theta(pi(t)|pi(<t),s)) for backprop", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "positions", "=", "[", "]", "# store visited cities for reward", "\n", "self", ".", "attending", "=", "[", "]", "# for vizualition", "\n", "self", ".", "pointing", "=", "[", "]", "# for vizualition", "\n", "\n", "self", ".", "s_check", "=", "0", "\n", "self", ".", "i_check", "=", "0", "\n", "\n", "########################################", "\n", "########## Initialize process ##########", "\n", "########################################", "\n", "\n", "# Keep track of first city", "\n", "self", ".", "first_city_hot", "=", "0", "###########", "\n", "\n", "# Keep track of visited cities", "\n", "self", ".", "mask", "=", "0", "\n", "self", ".", "mask_scores", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder_graph.Pointer_decoder.attention": [[87, 117], ["tensorflow.nn.conv1d", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.nn.softmax", "decoder_graph.Pointer_decoder.attending.append", "tensorflow.multiply", "tensorflow.nn.conv1d", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.nn.softmax", "decoder_graph.Pointer_decoder.pointing.append", "tensorflow.matmul", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.matmul", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.tanh"], "methods", ["None"], ["", "def", "attention", "(", "self", ",", "ref", ",", "query", ")", ":", "\n", "\n", "# Attending mechanism", "\n", "        ", "encoded_ref_g", "=", "tf", ".", "nn", ".", "conv1d", "(", "ref", ",", "self", ".", "W_ref_g", ",", "1", ",", "\"VALID\"", ",", "name", "=", "\"encoded_ref_g\"", ")", "# [Batch size, seq_length, n_hidden]", "\n", "encoded_query_g", "=", "tf", ".", "expand_dims", "(", "tf", ".", "matmul", "(", "query", ",", "self", ".", "W_q_g", ",", "name", "=", "\"encoded_query_g\"", ")", ",", "1", ")", "# [Batch size, 1, n_hidden]", "\n", "scores_g", "=", "tf", ".", "reduce_sum", "(", "self", ".", "v_g", "*", "tf", ".", "tanh", "(", "encoded_ref_g", "+", "encoded_query_g", ")", ",", "[", "-", "1", "]", ",", "name", "=", "\"scores_g\"", ")", "# [Batch size, seq_length]", "\n", "\n", "# Attend to current city and cities to visit only (Apply mask)", "\n", "attention_g", "=", "tf", ".", "nn", ".", "softmax", "(", "scores_g", "-", "100000000.", "*", "self", ".", "mask", ",", "name", "=", "\"attention_g\"", ")", "###########", "\n", "#attention_g = tf.nn.softmax(scores_g, name='attention_g') # why self.first_city? so remove for our use", "\n", "self", ".", "attending", ".", "append", "(", "attention_g", ")", "\n", "\n", "# 1 glimpse = Linear combination of reference vectors (defines new query vector)", "\n", "glimpse", "=", "tf", ".", "multiply", "(", "ref", ",", "tf", ".", "expand_dims", "(", "attention_g", ",", "2", ")", ")", "\n", "glimpse", "=", "tf", ".", "reduce_sum", "(", "glimpse", ",", "1", ")", "+", "query", "########### Residual connection", "\n", "\n", "# Pointing mechanism with 1 glimpse", "\n", "encoded_ref", "=", "tf", ".", "nn", ".", "conv1d", "(", "ref", ",", "self", ".", "W_ref", ",", "1", ",", "\"VALID\"", ",", "name", "=", "\"encoded_ref\"", ")", "# [Batch size, seq_length, n_hidden]", "\n", "encoded_query", "=", "tf", ".", "expand_dims", "(", "tf", ".", "matmul", "(", "glimpse", ",", "self", ".", "W_q", ",", "name", "=", "\"encoded_query\"", ")", ",", "1", ")", "# [Batch size, 1, n_hidden]", "\n", "scores", "=", "tf", ".", "reduce_sum", "(", "self", ".", "v", "*", "tf", ".", "tanh", "(", "encoded_ref", "+", "encoded_query", ")", ",", "[", "-", "1", "]", ",", "name", "=", "\"scores\"", ")", "# [Batch size, seq_length]", "\n", "if", "self", ".", "inference_mode", "==", "True", ":", "\n", "            ", "scores", "=", "scores", "/", "self", ".", "temperature", "# control diversity of sampling (inference mode)", "\n", "", "scores", "=", "self", ".", "C", "*", "tf", ".", "tanh", "(", "scores", ")", "# control entropy", "\n", "\n", "# Point to cities to visit only (Apply mask)", "\n", "masked_scores", "=", "scores", "-", "100000000.", "*", "self", ".", "mask", "# [Batch size, seq_length]", "\n", "pointing", "=", "tf", ".", "nn", ".", "softmax", "(", "masked_scores", ",", "name", "=", "\"attention\"", ")", "# [Batch size, Seq_length]", "\n", "self", ".", "pointing", ".", "append", "(", "pointing", ")", "\n", "\n", "return", "masked_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder_graph.Pointer_decoder.decode": [[119, 152], ["tensorflow.variable_scope", "decoder_graph.Pointer_decoder.cell", "tensorflow.cast", "tensorflow.one_hot", "decoder_graph.Pointer_decoder.attention", "tensorflow.contrib.distributions.Bernoulli", "tensorflow.contrib.distributions.Bernoulli.sample", "decoder_graph.Pointer_decoder.samples.append", "decoder_graph.Pointer_decoder.mask_scores.append", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.ones", "tensorflow.one_hot", "tensorflow.gather", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Attention.attention", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["", "def", "decode", "(", "self", ",", "prev_state", ",", "prev_input", ",", "timestep", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"loop\"", ")", ":", "\n", "            ", "if", "timestep", ">", "0", ":", "\n", "                ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "# Run the cell on a combination of the previous input and state", "\n", "", "output", ",", "state", "=", "self", ".", "cell", "(", "prev_input", ",", "prev_state", ")", "\n", "\n", "# mask before masked-scores", "\n", "position", "=", "tf", ".", "ones", "(", "[", "prev_input", ".", "shape", "[", "0", "]", "]", ")", "*", "timestep", "\n", "position", "=", "tf", ".", "cast", "(", "position", ",", "tf", ".", "int32", ")", "\n", "\n", "# Update mask", "\n", "self", ".", "mask", "=", "tf", ".", "one_hot", "(", "position", ",", "self", ".", "seq_length", ")", "\n", "\n", "# Attention mechanism", "\n", "masked_scores", "=", "self", ".", "attention", "(", "self", ".", "encoder_output", ",", "output", ")", "\n", "\n", "# we cast to Bernoulli and sample", "\n", "prob", "=", "distr", ".", "Bernoulli", "(", "masked_scores", ")", "\n", "sampled_arr", "=", "prob", ".", "sample", "(", ")", "# Batch_size, seqlenght for just one node", "\n", "\n", "self", ".", "samples", ".", "append", "(", "sampled_arr", ")", "\n", "self", ".", "mask_scores", ".", "append", "(", "masked_scores", ")", "\n", "\n", "if", "timestep", "==", "0", ":", "\n", "                ", "self", ".", "first_city", "=", "position", "\n", "self", ".", "first_city_hot", "=", "tf", ".", "one_hot", "(", "self", ".", "first_city", ",", "self", ".", "seq_length", ")", "\n", "\n", "# Retrieve decoder's new input", "\n", "", "new_decoder_input", "=", "tf", ".", "gather", "(", "self", ".", "h", ",", "position", ")", "[", "0", "]", "\n", "\n", "return", "state", ",", "new_decoder_input", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder_graph.Pointer_decoder.loop_decode": [[153, 174], ["range", "decoder_graph.Pointer_decoder.positions.append", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "tensorflow.cast", "decoder_graph.Pointer_decoder.decode"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder.decode"], ["", "", "def", "loop_decode", "(", "self", ")", ":", "\n", "# decoder_initial_state: Tuple Tensor (c,h) of size [batch_size x cell.state_size]", "\n", "# decoder_first_input: Tensor [batch_size x cell.state_size]", "\n", "\n", "# Loop the decoding process and collect results", "\n", "        ", "s", ",", "i", "=", "self", ".", "decoder_initial_state", ",", "tf", ".", "cast", "(", "self", ".", "decoder_first_input", ",", "tf", ".", "float32", ")", "\n", "for", "step", "in", "range", "(", "self", ".", "seq_length", ")", ":", "\n", "            ", "s", ",", "i", "=", "self", ".", "decode", "(", "s", ",", "i", ",", "step", ")", "\n", "\n", "# Return to start", "\n", "", "self", ".", "positions", ".", "append", "(", "self", ".", "first_city", ")", "\n", "\n", "# Stack visited indices", "\n", "self", ".", "positions", "=", "tf", ".", "stack", "(", "self", ".", "positions", ",", "axis", "=", "1", ")", "# [Batch,seq_length+1]", "\n", "\n", "# Stack attending & pointing distribution", "\n", "self", ".", "attending", "=", "tf", ".", "stack", "(", "self", ".", "attending", ",", "axis", "=", "1", ")", "# [Batch,seq_length,seq_length]", "\n", "self", ".", "pointing", "=", "tf", ".", "stack", "(", "self", ".", "pointing", ",", "axis", "=", "1", ")", "# [Batch,seq_length,seq_length]", "\n", "\n", "# Return stacked lists of visited_indices and log_softmax for backprop", "\n", "return", "self", ".", "samples", ",", "self", ".", "mask_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder_graph.Pointer_decoder.loop_decode_for_test": [[175, 196], ["range", "decoder_graph.Pointer_decoder.positions.append", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "tensorflow.cast", "decoder_graph.Pointer_decoder.decode"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder.decode"], ["", "def", "loop_decode_for_test", "(", "self", ")", ":", "\n", "# decoder_initial_state: Tuple Tensor (c,h) of size [batch_size x cell.state_size]", "\n", "# decoder_first_input: Tensor [batch_size x cell.state_size]", "\n", "\n", "# Loop the decoding process and collect results", "\n", "        ", "s", ",", "i", "=", "self", ".", "decoder_initial_state", ",", "tf", ".", "cast", "(", "self", ".", "decoder_first_input", ",", "tf", ".", "float32", ")", "\n", "for", "step", "in", "range", "(", "self", ".", "seq_length", ")", ":", "\n", "            ", "s", ",", "i", "=", "self", ".", "decode", "(", "s", ",", "i", ",", "step", ")", "\n", "\n", "# Return to start", "\n", "", "self", ".", "positions", ".", "append", "(", "self", ".", "first_city", ")", "\n", "\n", "# Stack visited indices", "\n", "self", ".", "positions", "=", "tf", ".", "stack", "(", "self", ".", "positions", ",", "axis", "=", "1", ")", "# [Batch,seq_length+1]", "\n", "\n", "# Stack attending & pointing distribution", "\n", "self", ".", "attending", "=", "tf", ".", "stack", "(", "self", ".", "attending", ",", "axis", "=", "1", ")", "# [Batch,seq_length,seq_length]", "\n", "self", ".", "pointing", "=", "tf", ".", "stack", "(", "self", ".", "pointing", ",", "axis", "=", "1", ")", "# [Batch,seq_length,seq_length]", "\n", "\n", "# Return stacked lists of visited_indices and log_softmax for backprop", "\n", "return", "self", ".", "samples", ",", "self", ".", "mask_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.transformer_decoder.TransformerDecoder.__init__": [[77, 111], ["tensorflow.contrib.layers.xavier_initializer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "is_train", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "config", ".", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "config", ".", "max_length", "# input sequence length (number of cities)", "\n", "self", ".", "input_dimension", "=", "config", ".", "hidden_dim", "#input_dimension*2+1 # dimension of input, multiply 2 for expanding dimension to input complex value to tf, add 1 high priority token, 1 pointing", "\n", "\n", "self", ".", "input_embed", "=", "config", ".", "hidden_dim", "# dimension of embedding space (actor)", "\n", "self", ".", "num_heads", "=", "config", ".", "num_heads", "\n", "self", ".", "num_stacks", "=", "config", ".", "num_stacks", "\n", "self", ".", "max_length", "=", "config", ".", "max_length", "\n", "\n", "self", ".", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "# variables initializer", "\n", "\n", "\n", "self", ".", "is_training", "=", "is_train", "\n", "\n", "\n", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "\n", "\n", "\n", "########################################", "\n", "########## Initialize process ##########", "\n", "########################################", "\n", "\n", "\n", "\n", "\n", "# Keep track of visited cities", "\n", "self", ".", "mask", "=", "0", "\n", "self", ".", "mask_scores", "=", "[", "]", "\n", "\n", "self", ".", "entropy", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.transformer_decoder.TransformerDecoder.decode": [[114, 187], ["tensorflow.reduce_mean", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.conv1d", "tensorflow.layers.batch_normalization", "tensorflow.variable_scope", "range", "tensorflow.layers.conv1d", "range", "tensorflow.tile", "tensorflow.cast", "tensorflow.one_hot", "tensorflow.contrib.distributions.Bernoulli", "tensorflow.contrib.distributions.Bernoulli.sample", "transformer_decoder.TransformerDecoder.samples.append", "transformer_decoder.TransformerDecoder.mask_scores.append", "transformer_decoder.TransformerDecoder.entropy.append", "tensorflow.expand_dims", "tensorflow.variable_scope", "transformer_decoder.multihead_attention", "transformer_decoder.feedforward", "tensorflow.ones", "tensorflow.contrib.distributions.Bernoulli.entropy"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.transformer_decoder.multihead_attention", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.transformer_decoder.feedforward"], ["", "def", "decode", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "# Tensor blocks holding the input sequences [Batch Size, Sequence Length, Features]", "\n", "# self.input_ = tf.placeholder(tf.float32, [self.batch_size, self.max_length, self.input_dimension], name=\"input_raw\")", "\n", "\n", "# with tf.variable_scope(\"embedding_MCS\"):", "\n", "#   # Embed input sequence", "\n", "#   W_embed =tf.get_variable(\"weights\",[1,self.input_dimension, self.input_embed], initializer=self.initializer)", "\n", "#   self.embedded_input = tf.nn.conv1d(inputs, W_embed, 1, \"VALID\", name=\"embedded_input\")", "\n", "#   # Batch Normalization", "\n", "#   self.enc = tf.layers.batch_normalization(self.embedded_input, axis=2, training=self.is_training, name='layer_norm', reuse=None)", "\n", "\n", "\n", "\n", "        ", "all_user_embedding", "=", "tf", ".", "reduce_mean", "(", "inputs", ",", "1", ")", "\n", "inputs_with_all_user_embedding", "=", "tf", ".", "concat", "(", "[", "inputs", ",", "\n", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "all_user_embedding", ",", "1", ")", ",", "[", "1", ",", "self", ".", "max_length", ",", "1", "]", ")", "]", ",", "-", "1", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"embedding_MCS\"", ")", ":", "\n", "# Embed input sequence", "\n", "          ", "W_embed", "=", "tf", ".", "get_variable", "(", "\"weights\"", ",", "[", "1", ",", "self", ".", "input_embed", ",", "self", ".", "input_embed", "]", ",", "initializer", "=", "self", ".", "initializer", ")", "#self.input_dimension*2", "\n", "self", ".", "embedded_input", "=", "tf", ".", "nn", ".", "conv1d", "(", "inputs", ",", "W_embed", ",", "1", ",", "\"VALID\"", ",", "name", "=", "\"embedded_input\"", ")", "\n", "# Batch Normalization", "\n", "self", ".", "enc", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "self", ".", "embedded_input", ",", "axis", "=", "2", ",", "training", "=", "self", ".", "is_training", ",", "name", "=", "'layer_norm'", ",", "reuse", "=", "None", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"stack_MCS\"", ")", ":", "\n", "# Blocks", "\n", "          ", "for", "i", "in", "range", "(", "self", ".", "num_stacks", ")", ":", "# num blocks", "\n", "              ", "with", "tf", ".", "variable_scope", "(", "\"block_{}\"", ".", "format", "(", "i", ")", ")", ":", "\n", "### Multihead Attention", "\n", "                  ", "self", ".", "enc", "=", "multihead_attention", "(", "self", ".", "enc", ",", "num_units", "=", "self", ".", "input_embed", ",", "num_heads", "=", "self", ".", "num_heads", ",", "dropout_rate", "=", "0.0", ",", "is_training", "=", "self", ".", "is_training", ")", "\n", "\n", "### Feed Forward", "\n", "self", ".", "enc", "=", "feedforward", "(", "self", ".", "enc", ",", "num_units", "=", "[", "self", ".", "input_embed", ",", "self", ".", "input_embed", "]", ",", "is_training", "=", "self", ".", "is_training", ")", "\n", "\n", "# Return the output activations [Batch size, Sequence Length, Num_neurons] as tensors.", "\n", "# self.encoder_output = self.enc ### NOTE: encoder_output is the ref for attention ###", "\n", "# Readout layer", "\n", "", "", "params", "=", "{", "\"inputs\"", ":", "self", ".", "enc", ",", "\"filters\"", ":", "self", ".", "max_length", ",", "\"kernel_size\"", ":", "1", ",", "\"activation\"", ":", "None", ",", "\"use_bias\"", ":", "True", "}", "\n", "\n", "\n", "self", ".", "adj_prob", "=", "tf", ".", "layers", ".", "conv1d", "(", "**", "params", ")", "\n", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "# Multinomial distribution", "\n", "# prob_test = tf.convert_to_tensor(np.array([[0,0.9,0.1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0] for i in range(32)]), dtype = tf.float32)", "\n", "# prob_test = tf.Print(prob_test, ['prob_test  value is', prob_test], summarize=100)", "\n", "\n", "            ", "position", "=", "tf", ".", "ones", "(", "[", "inputs", ".", "shape", "[", "0", "]", "]", ")", "*", "i", "\n", "position", "=", "tf", ".", "cast", "(", "position", ",", "tf", ".", "int32", ")", "\n", "\n", "# Update mask", "\n", "self", ".", "mask", "=", "tf", ".", "one_hot", "(", "position", ",", "self", ".", "max_length", ")", "\n", "\n", "\n", "masked_score", "=", "self", ".", "adj_prob", "[", ":", ",", "i", ",", ":", "]", "-", "100000000.", "*", "self", ".", "mask", "\n", "prob", "=", "distr", ".", "Bernoulli", "(", "masked_score", ")", "#probs input probability, logit input log_probability", "\n", "\n", "sampled_arr", "=", "prob", ".", "sample", "(", ")", "# Batch_size, seqlenght for just one node", "\n", "\n", "self", ".", "samples", ".", "append", "(", "sampled_arr", ")", "\n", "self", ".", "mask_scores", ".", "append", "(", "masked_score", ")", "\n", "\n", "self", ".", "entropy", ".", "append", "(", "prob", ".", "entropy", "(", ")", ")", "\n", "\n", "\n", "\n", "# self.mcs_prob = tf.Print(self.mcs_prob, ['self.mcs_prob  value is', self.mcs_prob], summarize=100)", "\n", "\n", "# self.mcs_sampling=tf.cast(tf.arg_max(self.mcs_prob, -1), tf.int32)", "\n", "\n", "", "return", "self", ".", "samples", ",", "self", ".", "mask_scores", ",", "self", ".", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.transformer_decoder.multihead_attention": [[10, 49], ["tensorflow.variable_scope", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.matmul", "tensorflow.nn.softmax", "tensorflow.layers.dropout", "tensorflow.matmul", "tensorflow.concat", "tensorflow.layers.batch_normalization", "tensorflow.split", "tensorflow.split", "tensorflow.split", "tensorflow.transpose", "tensorflow.split", "tensorflow.convert_to_tensor", "tf.concat.get_shape().as_list", "tf.concat.get_shape"], "function", ["None"], ["def", "multihead_attention", "(", "inputs", ",", "num_units", "=", "None", ",", "num_heads", "=", "16", ",", "dropout_rate", "=", "0.1", ",", "is_training", "=", "True", ")", ":", "\n", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"multihead_attention\"", ",", "reuse", "=", "None", ")", ":", "\n", "\n", "# Linear projections", "\n", "        ", "Q", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", ",", "num_units", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "# [batch_size, seq_length, n_hidden]", "\n", "K", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", ",", "num_units", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "# [batch_size, seq_length, n_hidden]", "\n", "V", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", ",", "num_units", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "# Split and concat", "\n", "Q_", "=", "tf", ".", "concat", "(", "tf", ".", "split", "(", "Q", ",", "num_heads", ",", "axis", "=", "2", ")", ",", "axis", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "K_", "=", "tf", ".", "concat", "(", "tf", ".", "split", "(", "K", ",", "num_heads", ",", "axis", "=", "2", ")", ",", "axis", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "V_", "=", "tf", ".", "concat", "(", "tf", ".", "split", "(", "V", ",", "num_heads", ",", "axis", "=", "2", ")", ",", "axis", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "\n", "# Multiplication", "\n", "outputs", "=", "tf", ".", "matmul", "(", "Q_", ",", "tf", ".", "transpose", "(", "K_", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "# num_heads*[batch_size, seq_length, seq_length]", "\n", "\n", "# Scale", "\n", "outputs", "=", "outputs", "/", "(", "K_", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "**", "0.5", ")", "\n", "\n", "# Activation", "\n", "outputs", "=", "tf", ".", "nn", ".", "softmax", "(", "outputs", ")", "# num_heads*[batch_size, seq_length, seq_length]", "\n", "\n", "# Dropouts", "\n", "outputs", "=", "tf", ".", "layers", ".", "dropout", "(", "outputs", ",", "rate", "=", "dropout_rate", ",", "training", "=", "tf", ".", "convert_to_tensor", "(", "is_training", ")", ")", "\n", "\n", "# Weighted sum", "\n", "outputs", "=", "tf", ".", "matmul", "(", "outputs", ",", "V_", ")", "# num_heads*[batch_size, seq_length, n_hidden/num_heads]", "\n", "\n", "# Restore shape", "\n", "outputs", "=", "tf", ".", "concat", "(", "tf", ".", "split", "(", "outputs", ",", "num_heads", ",", "axis", "=", "0", ")", ",", "axis", "=", "2", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "# Residual connection", "\n", "outputs", "+=", "inputs", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "# Normalize", "\n", "outputs", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "outputs", ",", "axis", "=", "2", ",", "training", "=", "is_training", ",", "name", "=", "'ln'", ",", "reuse", "=", "None", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.transformer_decoder.feedforward": [[54, 72], ["tensorflow.variable_scope", "tensorflow.layers.conv1d", "tensorflow.layers.conv1d", "tensorflow.layers.batch_normalization"], "function", ["None"], ["", "def", "feedforward", "(", "inputs", ",", "num_units", "=", "[", "2048", ",", "512", "]", ",", "is_training", "=", "True", ")", ":", "\n", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"ffn\"", ",", "reuse", "=", "None", ")", ":", "\n", "# Inner layer", "\n", "        ", "params", "=", "{", "\"inputs\"", ":", "inputs", ",", "\"filters\"", ":", "num_units", "[", "0", "]", ",", "\"kernel_size\"", ":", "1", ",", "\"activation\"", ":", "tf", ".", "nn", ".", "relu", ",", "\"use_bias\"", ":", "True", "}", "\n", "outputs", "=", "tf", ".", "layers", ".", "conv1d", "(", "**", "params", ")", "\n", "\n", "# Readout layer", "\n", "params", "=", "{", "\"inputs\"", ":", "outputs", ",", "\"filters\"", ":", "num_units", "[", "1", "]", ",", "\"kernel_size\"", ":", "1", ",", "\"activation\"", ":", "tf", ".", "nn", ".", "relu", ",", "\"use_bias\"", ":", "True", "}", "\n", "outputs", "=", "tf", ".", "layers", ".", "conv1d", "(", "**", "params", ")", "\n", "\n", "# Residual connection", "\n", "outputs", "+=", "inputs", "\n", "\n", "# Normalize", "\n", "outputs", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "outputs", ",", "axis", "=", "2", ",", "training", "=", "is_training", ",", "name", "=", "'ln'", ",", "reuse", "=", "None", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.single_layer_decoder.SingleLayerDecoder.__init__": [[7, 26], ["tensorflow.contrib.layers.xavier_initializer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "is_train", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "config", ".", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "config", ".", "max_length", "# input sequence length (number of cities)", "\n", "self", ".", "input_dimension", "=", "config", ".", "hidden_dim", "\n", "self", ".", "input_embed", "=", "config", ".", "hidden_dim", "# dimension of embedding space (actor)", "\n", "self", ".", "max_length", "=", "config", ".", "max_length", "\n", "self", ".", "decoder_hidden_dim", "=", "config", ".", "decoder_hidden_dim", "\n", "self", ".", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "# variables initializer", "\n", "self", ".", "decoder_activation", "=", "config", ".", "decoder_activation", "\n", "self", ".", "use_bias", "=", "config", ".", "use_bias", "\n", "self", ".", "bias_initial_value", "=", "config", ".", "bias_initial_value", "\n", "self", ".", "use_bias_constant", "=", "config", ".", "use_bias_constant", "\n", "\n", "self", ".", "is_training", "=", "is_train", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "mask", "=", "0", "\n", "self", ".", "mask_scores", "=", "[", "]", "\n", "self", ".", "entropy", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.single_layer_decoder.SingleLayerDecoder.decode": [[27, 81], ["tensorflow.einsum", "tensorflow.einsum", "tensorflow.tile", "tensorflow.tile", "tensorflow.einsum", "range", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.nn.tanh", "tensorflow.get_variable", "tensorflow.cast", "tensorflow.one_hot", "tensorflow.contrib.distributions.Bernoulli", "tensorflow.contrib.distributions.Bernoulli.sample", "single_layer_decoder.SingleLayerDecoder.samples.append", "single_layer_decoder.SingleLayerDecoder.mask_scores.append", "single_layer_decoder.SingleLayerDecoder.entropy.append", "tensorflow.nn.relu", "tensorflow.constant", "tensorflow.Variable", "tensorflow.ones", "tensorflow.contrib.distributions.Bernoulli.entropy", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["", "def", "decode", "(", "self", ",", "encoder_output", ")", ":", "\n", "# encoder_output is a tensor of size [batch_size, max_length, input_embed]", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'singe_layer_nn'", ")", ":", "\n", "            ", "W_l", "=", "tf", ".", "get_variable", "(", "'weights_left'", ",", "[", "self", ".", "input_embed", ",", "self", ".", "decoder_hidden_dim", "]", ",", "initializer", "=", "self", ".", "initializer", ")", "\n", "W_r", "=", "tf", ".", "get_variable", "(", "'weights_right'", ",", "[", "self", ".", "input_embed", ",", "self", ".", "decoder_hidden_dim", "]", ",", "initializer", "=", "self", ".", "initializer", ")", "\n", "U", "=", "tf", ".", "get_variable", "(", "'U'", ",", "[", "self", ".", "decoder_hidden_dim", "]", ",", "initializer", "=", "self", ".", "initializer", ")", "# Aggregate across decoder hidden dim", "\n", "\n", "", "dot_l", "=", "tf", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "encoder_output", ",", "W_l", ")", "\n", "dot_r", "=", "tf", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "encoder_output", ",", "W_r", ")", "\n", "\n", "tiled_l", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "dot_l", ",", "axis", "=", "2", ")", ",", "(", "1", ",", "1", ",", "self", ".", "max_length", ",", "1", ")", ")", "\n", "tiled_r", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "dot_r", ",", "axis", "=", "1", ")", ",", "(", "1", ",", "self", ".", "max_length", ",", "1", ",", "1", ")", ")", "\n", "\n", "if", "self", ".", "decoder_activation", "==", "'tanh'", ":", "# Original implementation by paper", "\n", "            ", "final_sum", "=", "tf", ".", "nn", ".", "tanh", "(", "tiled_l", "+", "tiled_r", ")", "\n", "", "elif", "self", ".", "decoder_activation", "==", "'relu'", ":", "\n", "            ", "final_sum", "=", "tf", ".", "nn", ".", "relu", "(", "tiled_l", "+", "tiled_r", ")", "\n", "", "elif", "self", ".", "decoder_activation", "==", "'none'", ":", "# Without activation function", "\n", "            ", "final_sum", "=", "tiled_l", "+", "tiled_r", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'Current decoder activation is not implemented yet'", ")", "\n", "\n", "# final_sum is of shape (batch_size, max_length, max_length, decoder_hidden_dim)", "\n", "", "logits", "=", "tf", ".", "einsum", "(", "'ijkl, l->ijk'", ",", "final_sum", ",", "U", ")", "# Readability", "\n", "\n", "if", "self", ".", "bias_initial_value", "is", "None", ":", "# Randomly initialize the learnable bias", "\n", "            ", "self", ".", "logit_bias", "=", "tf", ".", "get_variable", "(", "'logit_bias'", ",", "[", "1", "]", ")", "\n", "", "elif", "self", ".", "use_bias_constant", ":", "# Constant bias", "\n", "            ", "self", ".", "logit_bias", "=", "tf", ".", "constant", "(", "[", "self", ".", "bias_initial_value", "]", ",", "tf", ".", "float32", ",", "name", "=", "'logit_bias'", ")", "\n", "", "else", ":", "# Learnable bias with initial value", "\n", "            ", "self", ".", "logit_bias", "=", "tf", ".", "Variable", "(", "[", "self", ".", "bias_initial_value", "]", ",", "tf", ".", "float32", ",", "name", "=", "'logit_bias'", ")", "\n", "\n", "", "if", "self", ".", "use_bias", ":", "# Bias to control sparsity/density", "\n", "            ", "logits", "+=", "self", ".", "logit_bias", "\n", "\n", "", "self", ".", "adj_prob", "=", "logits", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "            ", "position", "=", "tf", ".", "ones", "(", "[", "encoder_output", ".", "shape", "[", "0", "]", "]", ")", "*", "i", "\n", "position", "=", "tf", ".", "cast", "(", "position", ",", "tf", ".", "int32", ")", "\n", "\n", "# Update mask", "\n", "self", ".", "mask", "=", "tf", ".", "one_hot", "(", "position", ",", "self", ".", "max_length", ")", "\n", "\n", "masked_score", "=", "self", ".", "adj_prob", "[", ":", ",", "i", ",", ":", "]", "-", "100000000.", "*", "self", ".", "mask", "\n", "prob", "=", "distr", ".", "Bernoulli", "(", "masked_score", ")", "# probs input probability, logit input log_probability", "\n", "\n", "sampled_arr", "=", "prob", ".", "sample", "(", ")", "# Batch_size, seqlenght for just one node", "\n", "\n", "self", ".", "samples", ".", "append", "(", "sampled_arr", ")", "\n", "self", ".", "mask_scores", ".", "append", "(", "masked_score", ")", "\n", "self", ".", "entropy", ".", "append", "(", "prob", ".", "entropy", "(", ")", ")", "\n", "\n", "", "return", "self", ".", "samples", ",", "self", ".", "mask_scores", ",", "self", ".", "entropy", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.ntn_decoder.NTNDecoder.__init__": [[7, 25], ["tensorflow.contrib.layers.xavier_initializer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "is_train", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "config", ".", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "config", ".", "max_length", "# input sequence length (number of cities)", "\n", "self", ".", "input_dimension", "=", "config", ".", "hidden_dim", "\n", "self", ".", "input_embed", "=", "config", ".", "hidden_dim", "# dimension of embedding space (actor)", "\n", "self", ".", "max_length", "=", "config", ".", "max_length", "\n", "self", ".", "decoder_hidden_dim", "=", "config", ".", "decoder_hidden_dim", "\n", "self", ".", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "# variables initializer", "\n", "self", ".", "decoder_activation", "=", "config", ".", "decoder_activation", "\n", "self", ".", "use_bias", "=", "config", ".", "use_bias", "\n", "self", ".", "bias_initial_value", "=", "config", ".", "bias_initial_value", "\n", "self", ".", "use_bias_constant", "=", "config", ".", "use_bias_constant", "\n", "self", ".", "is_training", "=", "is_train", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "mask", "=", "0", "\n", "self", ".", "mask_scores", "=", "[", "]", "\n", "self", ".", "entropy", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.ntn_decoder.NTNDecoder.decode": [[26, 88], ["tensorflow.einsum", "tensorflow.einsum", "tensorflow.tile", "tensorflow.tile", "tensorflow.einsum", "tensorflow.einsum", "range", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.nn.tanh", "tensorflow.get_variable", "tensorflow.cast", "tensorflow.one_hot", "tensorflow.contrib.distributions.Bernoulli", "tensorflow.contrib.distributions.Bernoulli.sample", "ntn_decoder.NTNDecoder.samples.append", "ntn_decoder.NTNDecoder.mask_scores.append", "ntn_decoder.NTNDecoder.entropy.append", "tensorflow.nn.relu", "tensorflow.constant", "tensorflow.Variable", "tensorflow.ones", "tensorflow.contrib.distributions.Bernoulli.entropy", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["", "def", "decode", "(", "self", ",", "encoder_output", ")", ":", "\n", "# encoder_output is a tensor of size [batch_size, max_length, input_embed]", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'ntn'", ")", ":", "\n", "            ", "W", "=", "tf", ".", "get_variable", "(", "'bilinear_weights'", ",", "[", "self", ".", "input_embed", ",", "self", ".", "input_embed", ",", "self", ".", "decoder_hidden_dim", "]", ",", "\n", "initializer", "=", "self", ".", "initializer", ")", "\n", "W_l", "=", "tf", ".", "get_variable", "(", "'weights_left'", ",", "[", "self", ".", "input_embed", ",", "self", ".", "decoder_hidden_dim", "]", ",", "\n", "initializer", "=", "self", ".", "initializer", ")", "\n", "W_r", "=", "tf", ".", "get_variable", "(", "'weights_right'", ",", "[", "self", ".", "input_embed", ",", "self", ".", "decoder_hidden_dim", "]", ",", "\n", "initializer", "=", "self", ".", "initializer", ")", "\n", "U", "=", "tf", ".", "get_variable", "(", "'U'", ",", "[", "self", ".", "decoder_hidden_dim", "]", ",", "initializer", "=", "self", ".", "initializer", ")", "\n", "B", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "self", ".", "decoder_hidden_dim", "]", ",", "initializer", "=", "self", ".", "initializer", ")", "\n", "\n", "# Compute linear output with shape (batch_size, max_length, max_length, decoder_hidden_dim)", "\n", "", "dot_l", "=", "tf", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "encoder_output", ",", "W_l", ")", "\n", "dot_r", "=", "tf", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "encoder_output", ",", "W_r", ")", "\n", "tiled_l", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "dot_l", ",", "axis", "=", "2", ")", ",", "(", "1", ",", "1", ",", "self", ".", "max_length", ",", "1", ")", ")", "\n", "tiled_r", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "dot_r", ",", "axis", "=", "1", ")", ",", "(", "1", ",", "self", ".", "max_length", ",", "1", ",", "1", ")", ")", "\n", "linear_sum", "=", "tiled_l", "+", "tiled_r", "\n", "\n", "# Compute bilinear product with shape (batch_size, max_length, max_length, decoder_hidden_dim)", "\n", "bilinear_product", "=", "tf", ".", "einsum", "(", "'ijk, knl, imn->ijml'", ",", "encoder_output", ",", "W", ",", "encoder_output", ")", "\n", "\n", "if", "self", ".", "decoder_activation", "==", "'tanh'", ":", "# Original implementation by paper", "\n", "            ", "final_sum", "=", "tf", ".", "nn", ".", "tanh", "(", "bilinear_product", "+", "linear_sum", "+", "B", ")", "\n", "", "elif", "self", ".", "decoder_activation", "==", "'relu'", ":", "\n", "            ", "final_sum", "=", "tf", ".", "nn", ".", "relu", "(", "bilinear_product", "+", "linear_sum", "+", "B", ")", "\n", "", "elif", "self", ".", "decoder_activation", "==", "'none'", ":", "# Without activation function", "\n", "            ", "final_sum", "=", "bilinear_product", "+", "linear_sum", "+", "B", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'Current decoder activation is not implemented yet'", ")", "\n", "\n", "", "logits", "=", "tf", ".", "einsum", "(", "'ijkl, l->ijk'", ",", "final_sum", ",", "U", ")", "# Readability", "\n", "\n", "if", "self", ".", "bias_initial_value", "is", "None", ":", "# Randomly initialize the learnable bias", "\n", "            ", "self", ".", "logit_bias", "=", "tf", ".", "get_variable", "(", "'logit_bias'", ",", "[", "1", "]", ")", "\n", "", "elif", "self", ".", "use_bias_constant", ":", "# Constant bias", "\n", "            ", "self", ".", "logit_bias", "=", "tf", ".", "constant", "(", "[", "self", ".", "bias_initial_value", "]", ",", "tf", ".", "float32", ",", "name", "=", "'logit_bias'", ")", "\n", "", "else", ":", "# Learnable bias with initial value", "\n", "            ", "self", ".", "logit_bias", "=", "tf", ".", "Variable", "(", "[", "self", ".", "bias_initial_value", "]", ",", "tf", ".", "float32", ",", "name", "=", "'logit_bias'", ")", "\n", "\n", "", "if", "self", ".", "use_bias", ":", "# Bias to control sparsity/density", "\n", "            ", "logits", "+=", "self", ".", "logit_bias", "\n", "\n", "", "self", ".", "adj_prob", "=", "logits", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "            ", "position", "=", "tf", ".", "ones", "(", "[", "encoder_output", ".", "shape", "[", "0", "]", "]", ")", "*", "i", "\n", "position", "=", "tf", ".", "cast", "(", "position", ",", "tf", ".", "int32", ")", "\n", "\n", "# Update mask", "\n", "self", ".", "mask", "=", "tf", ".", "one_hot", "(", "position", ",", "self", ".", "max_length", ")", "\n", "\n", "masked_score", "=", "self", ".", "adj_prob", "[", ":", ",", "i", ",", ":", "]", "-", "100000000.", "*", "self", ".", "mask", "\n", "prob", "=", "distr", ".", "Bernoulli", "(", "masked_score", ")", "# probs input probability, logit input log_probability", "\n", "\n", "sampled_arr", "=", "prob", ".", "sample", "(", ")", "# Batch_size, seqlenght for just one node", "\n", "\n", "self", ".", "samples", ".", "append", "(", "sampled_arr", ")", "\n", "self", ".", "mask_scores", ".", "append", "(", "masked_score", ")", "\n", "self", ".", "entropy", ".", "append", "(", "prob", ".", "entropy", "(", ")", ")", "\n", "\n", "", "return", "self", ".", "samples", ",", "self", ".", "mask_scores", ",", "self", ".", "entropy", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.bilinear_decoder.BilinearDecoder.__init__": [[7, 23], ["tensorflow.contrib.layers.xavier_initializer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "is_train", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "config", ".", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "config", ".", "max_length", "# input sequence length (number of cities)", "\n", "self", ".", "input_dimension", "=", "config", ".", "hidden_dim", "\n", "self", ".", "input_embed", "=", "config", ".", "hidden_dim", "# dimension of embedding space (actor)", "\n", "self", ".", "max_length", "=", "config", ".", "max_length", "\n", "self", ".", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "# variables initializer", "\n", "self", ".", "use_bias", "=", "config", ".", "use_bias", "\n", "self", ".", "bias_initial_value", "=", "config", ".", "bias_initial_value", "\n", "self", ".", "use_bias_constant", "=", "config", ".", "use_bias_constant", "\n", "self", ".", "is_training", "=", "is_train", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "mask", "=", "0", "\n", "self", ".", "mask_scores", "=", "[", "]", "\n", "self", ".", "entropy", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.bilinear_decoder.BilinearDecoder.decode": [[24, 60], ["tensorflow.einsum", "range", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.cast", "tensorflow.one_hot", "tensorflow.contrib.distributions.Bernoulli", "tensorflow.contrib.distributions.Bernoulli.sample", "bilinear_decoder.BilinearDecoder.samples.append", "bilinear_decoder.BilinearDecoder.mask_scores.append", "bilinear_decoder.BilinearDecoder.entropy.append", "tensorflow.constant", "tensorflow.Variable", "tensorflow.ones", "tensorflow.contrib.distributions.Bernoulli.entropy"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["", "def", "decode", "(", "self", ",", "encoder_output", ")", ":", "\n", "# encoder_output is a tensor of size [batch_size, max_length, input_embed]", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'bilinear'", ")", ":", "\n", "            ", "W", "=", "tf", ".", "get_variable", "(", "'bilinear_weights'", ",", "[", "self", ".", "input_embed", ",", "self", ".", "input_embed", "]", ",", "initializer", "=", "self", ".", "initializer", ")", "\n", "\n", "", "logits", "=", "tf", ".", "einsum", "(", "'ijk, kn, imn->ijm'", ",", "encoder_output", ",", "W", ",", "encoder_output", ")", "# Readability", "\n", "\n", "if", "self", ".", "bias_initial_value", "is", "None", ":", "# Randomly initialize the learnable bias", "\n", "            ", "self", ".", "logit_bias", "=", "tf", ".", "get_variable", "(", "'logit_bias'", ",", "[", "1", "]", ")", "\n", "", "elif", "self", ".", "use_bias_constant", ":", "# Constant bias", "\n", "            ", "self", ".", "logit_bias", "=", "tf", ".", "constant", "(", "[", "self", ".", "bias_initial_value", "]", ",", "tf", ".", "float32", ",", "name", "=", "'logit_bias'", ")", "\n", "", "else", ":", "# Learnable bias with initial value", "\n", "            ", "self", ".", "logit_bias", "=", "tf", ".", "Variable", "(", "[", "self", ".", "bias_initial_value", "]", ",", "tf", ".", "float32", ",", "name", "=", "'logit_bias'", ")", "\n", "\n", "", "if", "self", ".", "use_bias", ":", "# Bias to control sparsity/density", "\n", "            ", "logits", "+=", "self", ".", "logit_bias", "\n", "\n", "", "self", ".", "adj_prob", "=", "logits", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "            ", "position", "=", "tf", ".", "ones", "(", "[", "encoder_output", ".", "shape", "[", "0", "]", "]", ")", "*", "i", "\n", "position", "=", "tf", ".", "cast", "(", "position", ",", "tf", ".", "int32", ")", "\n", "\n", "# Update mask", "\n", "self", ".", "mask", "=", "tf", ".", "one_hot", "(", "position", ",", "self", ".", "max_length", ")", "\n", "\n", "masked_score", "=", "self", ".", "adj_prob", "[", ":", ",", "i", ",", ":", "]", "-", "100000000.", "*", "self", ".", "mask", "\n", "prob", "=", "distr", ".", "Bernoulli", "(", "masked_score", ")", "# probs input probability, logit input log_probability", "\n", "\n", "sampled_arr", "=", "prob", ".", "sample", "(", ")", "# Batch_size, seqlenght for just one node", "\n", "\n", "self", ".", "samples", ".", "append", "(", "sampled_arr", ")", "\n", "self", ".", "mask_scores", ".", "append", "(", "masked_score", ")", "\n", "self", ".", "entropy", ".", "append", "(", "prob", ".", "entropy", "(", ")", ")", "\n", "\n", "", "return", "self", ".", "samples", ",", "self", ".", "mask_scores", ",", "self", ".", "entropy", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.BilinearDecoder.__init__": [[24, 44], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "decoder.BilinearDecoder.reset_parameters", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "max_length", ",", "hidden_dim", ",", "use_bias", ",", "\n", "bias_initial_value", ",", "use_bias_constant", ",", "is_train", ",", "\n", "device", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "max_length", "# input sequence length (number of cities)", "\n", "self", ".", "input_dimension", "=", "hidden_dim", "\n", "self", ".", "input_embed", "=", "hidden_dim", "# dimension of embedding space (actor)", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "bias_initial_value", "=", "bias_initial_value", "\n", "self", ".", "use_bias_constant", "=", "use_bias_constant", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_training", "=", "is_train", "\n", "\n", "self", ".", "_W", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "(", "self", ".", "input_embed", ",", "self", ".", "input_embed", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "_l", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.BilinearDecoder.reset_parameters": [[45, 56], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "_W", ")", "# variables initializer", "\n", "\n", "if", "self", ".", "bias_initial_value", "is", "None", ":", "# Randomly initialize the learnable bias", "\n", "            ", "bias_initial_value", "=", "torch", ".", "randn", "(", "[", "1", "]", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "", "elif", "self", ".", "use_bias_constant", ":", "# Constant bias", "\n", "            ", "bias_initial_value", "=", "self", ".", "bias_initial_value", "\n", "", "else", ":", "# Learnable bias with initial value", "\n", "            ", "bias_initial_value", "=", "self", ".", "bias_initial_value", "\n", "\n", "", "nn", ".", "init", ".", "constant_", "(", "self", ".", "_l", ",", "bias_initial_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.BilinearDecoder.forward": [[57, 97], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "range", "position.long.long.long", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli.sample", "decoder.BilinearDecoder.samples.append", "decoder.BilinearDecoder.mask_scores.append", "decoder.BilinearDecoder.entropy.append", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "position.long.long.view", "torch.Bernoulli.entropy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["", "def", "forward", "(", "self", ",", "encoder_output", ")", ":", "\n", "# encoder_output is a tensor of size [batch_size, max_length, input_embed]", "\n", "\n", "        ", "W", "=", "self", ".", "_W", "\n", "\n", "logits", "=", "torch", ".", "einsum", "(", "'ijk, kn, imn->ijm'", ",", "encoder_output", ",", "W", ",", "encoder_output", ")", "# Readability", "\n", "\n", "self", ".", "logit_bias", "=", "self", ".", "_l", "\n", "\n", "if", "self", ".", "use_bias", ":", "# Bias to control sparsity/density", "\n", "            ", "logits", "+=", "self", ".", "logit_bias", "\n", "\n", "", "self", ".", "adj_prob", "=", "logits", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "mask", "=", "0", "\n", "self", ".", "mask_scores", "=", "[", "]", "\n", "self", ".", "entropy", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "\n", "            ", "position", "=", "torch", ".", "ones", "(", "[", "encoder_output", ".", "shape", "[", "0", "]", "]", ",", "\n", "device", "=", "self", ".", "device", ")", "*", "i", "\n", "position", "=", "position", ".", "long", "(", ")", "\n", "\n", "# Update mask", "\n", "self", ".", "mask", "=", "torch", ".", "zeros", "(", "(", "encoder_output", ".", "shape", "[", "0", "]", ",", "self", ".", "max_length", ")", ",", "\n", "device", "=", "self", ".", "device", ")", ".", "scatter_", "(", "1", ",", "position", ".", "view", "(", "encoder_output", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "1", ")", "\n", "\n", "masked_score", "=", "self", ".", "adj_prob", "[", ":", ",", "i", ",", ":", "]", "-", "100000000.", "*", "self", ".", "mask", "\n", "prob", "=", "distr", ".", "Bernoulli", "(", "logits", "=", "masked_score", ")", "# probs input probability, logit input log_probability", "\n", "\n", "sampled_arr", "=", "prob", ".", "sample", "(", ")", "# Batch_size, seqlenght for just one node", "\n", "sampled_arr", ".", "requires_grad", "=", "True", "\n", "\n", "self", ".", "samples", ".", "append", "(", "sampled_arr", ")", "\n", "self", ".", "mask_scores", ".", "append", "(", "masked_score", ")", "\n", "self", ".", "entropy", ".", "append", "(", "prob", ".", "entropy", "(", ")", ")", "\n", "\n", "", "return", "self", ".", "samples", ",", "self", ".", "mask_scores", ",", "self", ".", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.NTNDecoder.__init__": [[101, 132], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "decoder.NTNDecoder.reset_parameters", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "max_length", ",", "hidden_dim", ",", "\n", "decoder_hidden_dim", ",", "decoder_activation", ",", "use_bias", ",", "\n", "bias_initial_value", ",", "use_bias_constant", ",", "is_train", ",", "device", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "max_length", "# input sequence length (number of cities)", "\n", "self", ".", "input_dimension", "=", "hidden_dim", "\n", "self", ".", "input_embed", "=", "hidden_dim", "# dimension of embedding space (actor)", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "decoder_hidden_dim", "=", "decoder_hidden_dim", "\n", "self", ".", "decoder_activation", "=", "decoder_activation", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "bias_initial_value", "=", "bias_initial_value", "\n", "self", ".", "use_bias_constant", "=", "use_bias_constant", "\n", "self", ".", "is_training", "=", "is_train", "\n", "self", ".", "device", "=", "device", "\n", "\n", "if", "self", ".", "decoder_activation", "==", "'tanh'", ":", "# Original implementation by paper", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "", "elif", "self", ".", "decoder_activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "", "self", ".", "_w", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "(", "self", ".", "input_embed", ",", "self", ".", "input_embed", ",", "self", ".", "decoder_hidden_dim", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "_wl", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "(", "self", ".", "input_embed", ",", "self", ".", "decoder_hidden_dim", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "_wr", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "(", "self", ".", "input_embed", ",", "self", ".", "decoder_hidden_dim", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "_u", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "(", "self", ".", "decoder_hidden_dim", ",", "1", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "_b", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "(", "self", ".", "decoder_hidden_dim", ",", "1", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "_l", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.NTNDecoder.reset_parameters": [[133, 148], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "_w", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "_wl", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "_wr", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "_u", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "_b", ")", "\n", "\n", "if", "self", ".", "bias_initial_value", "is", "None", ":", "# Randomly initialize the learnable bias", "\n", "            ", "bias_initial_value", "=", "torch", ".", "randn", "(", "[", "1", "]", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "", "elif", "self", ".", "use_bias_constant", ":", "# Constant bias", "\n", "            ", "bias_initial_value", "=", "self", ".", "bias_initial_value", "\n", "", "else", ":", "# Learnable bias with initial value", "\n", "            ", "bias_initial_value", "=", "self", ".", "bias_initial_value", "\n", "\n", "", "nn", ".", "init", ".", "constant_", "(", "self", ".", "_l", ",", "bias_initial_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.NTNDecoder.forward": [[149, 212], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "range", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "decoder.NTNDecoder.activation", "U.view", "position.long.long.long", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli.sample", "decoder.NTNDecoder.samples.append", "decoder.NTNDecoder.mask_scores.append", "decoder.NTNDecoder.entropy.append", "decoder.NTNDecoder.activation", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "position.long.long.view", "torch.Bernoulli.entropy", "B.view", "NotImplementedError", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "B.view", "B.view"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["", "def", "forward", "(", "self", ",", "encoder_output", ")", ":", "\n", "# encoder_output is a tensor of size [batch_size, max_length, input_embed]", "\n", "\n", "        ", "W", "=", "self", ".", "_w", "\n", "W_l", "=", "self", ".", "_wl", "\n", "W_r", "=", "self", ".", "_wr", "\n", "U", "=", "self", ".", "_u", "\n", "B", "=", "self", ".", "_b", "\n", "\n", "# Compute linear output with shape (batch_size, max_length, max_length, decoder_hidden_dim)", "\n", "dot_l", "=", "torch", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "encoder_output", ",", "W_l", ")", "\n", "dot_r", "=", "torch", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "encoder_output", ",", "W_r", ")", "\n", "\n", "tiled_l", "=", "torch", ".", "Tensor", ".", "repeat", "(", "torch", ".", "unsqueeze", "(", "dot_l", ",", "dim", "=", "2", ")", ",", "(", "1", ",", "1", ",", "self", ".", "max_length", ",", "1", ")", ")", "\n", "tiled_r", "=", "torch", ".", "Tensor", ".", "repeat", "(", "torch", ".", "unsqueeze", "(", "dot_r", ",", "dim", "=", "1", ")", ",", "(", "1", ",", "self", ".", "max_length", ",", "1", ",", "1", ")", ")", "\n", "\n", "linear_sum", "=", "tiled_l", "+", "tiled_r", "\n", "\n", "# Compute bilinear product with shape (batch_size, max_length, max_length, decoder_hidden_dim)", "\n", "bilinear_product", "=", "torch", ".", "einsum", "(", "'ijk, knl, imn->ijml'", ",", "encoder_output", ",", "W", ",", "encoder_output", ")", "\n", "\n", "if", "self", ".", "decoder_activation", "==", "'tanh'", ":", "# Original implementation by paper", "\n", "            ", "final_sum", "=", "self", ".", "activation", "(", "bilinear_product", "+", "linear_sum", "+", "B", ".", "view", "(", "self", ".", "decoder_hidden_dim", ")", ")", "\n", "", "elif", "self", ".", "decoder_activation", "==", "'relu'", ":", "\n", "            ", "final_sum", "=", "self", ".", "activation", "(", "bilinear_product", "+", "linear_sum", "+", "B", ".", "view", "(", "self", ".", "decoder_hidden_dim", ")", ")", "\n", "", "elif", "self", ".", "decoder_activation", "==", "'none'", ":", "# Without activation function", "\n", "            ", "final_sum", "=", "bilinear_product", "+", "linear_sum", "+", "B", ".", "view", "(", "self", ".", "decoder_hidden_dim", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'Current decoder activation is not implemented yet'", ")", "\n", "\n", "", "logits", "=", "torch", ".", "einsum", "(", "'ijkl, l->ijk'", ",", "final_sum", ",", "U", ".", "view", "(", "self", ".", "decoder_hidden_dim", ")", ")", "# Readability", "\n", "\n", "self", ".", "logit_bias", "=", "self", ".", "_l", "\n", "\n", "if", "self", ".", "use_bias", ":", "# Bias to control sparsity/density", "\n", "            ", "logits", "+=", "self", ".", "logit_bias", "\n", "\n", "", "self", ".", "adj_prob", "=", "logits", "\n", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "mask", "=", "0", "\n", "self", ".", "mask_scores", "=", "[", "]", "\n", "self", ".", "entropy", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "            ", "position", "=", "torch", ".", "ones", "(", "[", "encoder_output", ".", "shape", "[", "0", "]", "]", ",", "\n", "device", "=", "self", ".", "device", ")", "*", "i", "\n", "position", "=", "position", ".", "long", "(", ")", "\n", "# Update mask", "\n", "self", ".", "mask", "=", "torch", ".", "zeros", "(", "(", "encoder_output", ".", "shape", "[", "0", "]", ",", "self", ".", "max_length", ")", ",", "\n", "device", "=", "self", ".", "device", ")", ".", "scatter_", "(", "1", ",", "position", ".", "view", "(", "encoder_output", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "1", ")", "\n", "\n", "masked_score", "=", "self", ".", "adj_prob", "[", ":", ",", "i", ",", ":", "]", "-", "100000000.", "*", "self", ".", "mask", "\n", "prob", "=", "distr", ".", "Bernoulli", "(", "logits", "=", "masked_score", ")", "# probs input probability, logit input log_probability", "\n", "\n", "sampled_arr", "=", "prob", ".", "sample", "(", ")", "# Batch_size, seqlenght for just one node", "\n", "sampled_arr", ".", "requires_grad", "=", "True", "\n", "\n", "self", ".", "samples", ".", "append", "(", "sampled_arr", ")", "\n", "self", ".", "mask_scores", ".", "append", "(", "masked_score", ")", "\n", "self", ".", "entropy", ".", "append", "(", "prob", ".", "entropy", "(", ")", ")", "\n", "\n", "", "return", "self", ".", "samples", ",", "self", ".", "mask_scores", ",", "self", ".", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.SingleLayerDecoder.__init__": [[216, 245], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "decoder.SingleLayerDecoder.reset_parameters", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "max_length", ",", "input_dimension", ",", "input_embed", ",", "\n", "decoder_hidden_dim", ",", "decoder_activation", ",", "use_bias", ",", "\n", "bias_initial_value", ",", "use_bias_constant", ",", "is_train", ",", "device", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "max_length", "# input sequence length (number of cities)", "\n", "self", ".", "input_dimension", "=", "input_dimension", "\n", "self", ".", "input_embed", "=", "input_embed", "# dimension of embedding space (actor)", "\n", "self", ".", "decoder_hidden_dim", "=", "decoder_hidden_dim", "\n", "self", ".", "decoder_activation", "=", "decoder_activation", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "bias_initial_value", "=", "bias_initial_value", "\n", "self", ".", "use_bias_constant", "=", "use_bias_constant", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_training", "=", "is_train", "\n", "\n", "if", "self", ".", "decoder_activation", "==", "'tanh'", ":", "# Original implementation by paper", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "", "elif", "self", ".", "decoder_activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "", "self", ".", "_wl", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "(", "self", ".", "input_embed", ",", "self", ".", "decoder_hidden_dim", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "_wr", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "(", "self", ".", "input_embed", ",", "self", ".", "decoder_hidden_dim", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "_u", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "(", "self", ".", "decoder_hidden_dim", ",", "1", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "_l", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.SingleLayerDecoder.reset_parameters": [[246, 259], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn().numpy", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "_wl", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "_wr", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "_u", ")", "\n", "\n", "if", "self", ".", "bias_initial_value", "is", "None", ":", "# Randomly initialize the learnable bias", "\n", "            ", "bias_initial_value", "=", "torch", ".", "randn", "(", "[", "1", "]", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "", "elif", "self", ".", "use_bias_constant", ":", "# Constant bias", "\n", "            ", "bias_initial_value", "=", "self", ".", "bias_initial_value", "\n", "", "else", ":", "# Learnable bias with initial value", "\n", "            ", "bias_initial_value", "=", "self", ".", "bias_initial_value", "\n", "\n", "", "nn", ".", "init", ".", "constant_", "(", "self", ".", "_l", ",", "bias_initial_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.SingleLayerDecoder.forward": [[260, 317], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.Tensor.repeat", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "range", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "decoder.SingleLayerDecoder.activation", "U.view", "position.long.long.long", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "decoder.SingleLayerDecoder.mask.to", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli.sample", "decoder.SingleLayerDecoder.samples.append", "decoder.SingleLayerDecoder.mask_scores.append", "decoder.SingleLayerDecoder.entropy.append", "decoder.SingleLayerDecoder.activation", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "position.long.long.view", "torch.Bernoulli.entropy", "NotImplementedError", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["", "def", "forward", "(", "self", ",", "encoder_output", ")", ":", "\n", "# encoder_output is a tensor of size [batch_size, max_length, input_embed]", "\n", "        ", "W_l", "=", "self", ".", "_wl", "\n", "W_r", "=", "self", ".", "_wr", "\n", "U", "=", "self", ".", "_u", "\n", "\n", "dot_l", "=", "torch", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "encoder_output", ",", "W_l", ")", "\n", "dot_r", "=", "torch", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "encoder_output", ",", "W_r", ")", "\n", "\n", "tiled_l", "=", "torch", ".", "Tensor", ".", "repeat", "(", "torch", ".", "unsqueeze", "(", "dot_l", ",", "dim", "=", "2", ")", ",", "(", "1", ",", "1", ",", "self", ".", "max_length", ",", "1", ")", ")", "\n", "tiled_r", "=", "torch", ".", "Tensor", ".", "repeat", "(", "torch", ".", "unsqueeze", "(", "dot_r", ",", "dim", "=", "1", ")", ",", "(", "1", ",", "self", ".", "max_length", ",", "1", ",", "1", ")", ")", "\n", "\n", "if", "self", ".", "decoder_activation", "==", "'tanh'", ":", "# Original implementation by paper", "\n", "            ", "final_sum", "=", "self", ".", "activation", "(", "tiled_l", "+", "tiled_r", ")", "\n", "", "elif", "self", ".", "decoder_activation", "==", "'relu'", ":", "\n", "            ", "final_sum", "=", "self", ".", "activation", "(", "tiled_l", "+", "tiled_r", ")", "\n", "", "elif", "self", ".", "decoder_activation", "==", "'none'", ":", "# Without activation function", "\n", "            ", "final_sum", "=", "tiled_l", "+", "tiled_r", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'Current decoder activation is not implemented yet'", ")", "\n", "\n", "# final_sum is of shape (batch_size, max_length, max_length, decoder_hidden_dim)", "\n", "", "logits", "=", "torch", ".", "einsum", "(", "'ijkl, l->ijk'", ",", "final_sum", ",", "U", ".", "view", "(", "self", ".", "decoder_hidden_dim", ")", ")", "# Readability", "\n", "\n", "self", ".", "logit_bias", "=", "self", ".", "_l", "\n", "\n", "if", "self", ".", "use_bias", ":", "# Bias to control sparsity/density", "\n", "            ", "logits", "+=", "self", ".", "logit_bias", "\n", "\n", "", "self", ".", "adj_prob", "=", "logits", "\n", "\n", "self", ".", "mask", "=", "0", "\n", "self", ".", "samples", "=", "[", "]", "\n", "self", ".", "mask_scores", "=", "[", "]", "\n", "self", ".", "entropy", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "            ", "position", "=", "torch", ".", "ones", "(", "[", "encoder_output", ".", "shape", "[", "0", "]", "]", ",", "\n", "device", "=", "self", ".", "device", ")", "*", "i", "\n", "position", "=", "position", ".", "long", "(", ")", "\n", "\n", "# Update mask", "\n", "self", ".", "mask", "=", "torch", ".", "zeros", "(", "(", "encoder_output", ".", "shape", "[", "0", "]", ",", "self", ".", "max_length", ")", ",", "\n", "device", "=", "self", ".", "device", ")", ".", "scatter_", "(", "1", ",", "position", ".", "view", "(", "encoder_output", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "1", ")", "\n", "self", ".", "mask", "=", "self", ".", "mask", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "masked_score", "=", "self", ".", "adj_prob", "[", ":", ",", "i", ",", ":", "]", "-", "100000000.", "*", "self", ".", "mask", "\n", "prob", "=", "distr", ".", "Bernoulli", "(", "logits", "=", "masked_score", ")", "# probs input probability, logit input log_probability", "\n", "\n", "sampled_arr", "=", "prob", ".", "sample", "(", ")", "# Batch_size, seqlenght for just one node", "\n", "sampled_arr", ".", "requires_grad", "=", "True", "\n", "\n", "self", ".", "samples", ".", "append", "(", "sampled_arr", ")", "\n", "self", ".", "mask_scores", ".", "append", "(", "masked_score", ")", "\n", "self", ".", "entropy", ".", "append", "(", "prob", ".", "entropy", "(", ")", ")", "\n", "\n", "", "return", "self", ".", "samples", ",", "self", ".", "mask_scores", ",", "self", ".", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.MultiheadAttention.__init__": [[321, 340], ["torch.Module.__init__", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dimension", ",", "num_units", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# Linear projections", "\n", "# Q_layer = nn.Linear(in_features=input_dimension, out_features=num_units)", "\n", "self", ".", "Q_layer", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_dimension", ",", "\n", "out_features", "=", "num_units", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "K_layer", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_dimension", ",", "\n", "out_features", "=", "num_units", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "V_layer", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "in_features", "=", "input_dimension", ",", "\n", "out_features", "=", "num_units", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Normalize", "\n", "self", ".", "bn_layer", "=", "nn", ".", "BatchNorm1d", "(", "input_dimension", ")", ".", "to", "(", "self", ".", "device", ")", "# \u4f20\u5165\u901a\u9053\u6570", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.MultiheadAttention.forward": [[341, 382], ["inputs.permute.permute.permute", "decoder.MultiheadAttention.Q_layer", "decoder.MultiheadAttention.K_layer", "decoder.MultiheadAttention.V_layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder.MultiheadAttention.permute", "decoder.MultiheadAttention.bn_layer", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "int", "int", "int", "int"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "num_heads", "=", "16", ",", "dropout_rate", "=", "0.1", ",", "is_training", "=", "True", ")", ":", "\n", "\n", "        ", "input_dimension", "=", "inputs", ".", "shape", "[", "1", "]", "\n", "inputs", "=", "inputs", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "Q", "=", "self", ".", "Q_layer", "(", "inputs", ")", "# [batch_size, seq_length, n_hidden]", "\n", "K", "=", "self", ".", "K_layer", "(", "inputs", ")", "# [batch_size, seq_length, n_hidden]", "\n", "V", "=", "self", ".", "V_layer", "(", "inputs", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "# Split and concat", "\n", "Q_", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "Q", ",", "int", "(", "input_dimension", "/", "num_heads", ")", ",", "dim", "=", "2", ")", ",", "dim", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "K_", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "K", ",", "int", "(", "input_dimension", "/", "num_heads", ")", ",", "dim", "=", "2", ")", ",", "dim", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "V_", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "V", ",", "int", "(", "input_dimension", "/", "num_heads", ")", ",", "dim", "=", "2", ")", ",", "dim", "=", "0", ")", "# [batch_size, seq_length, n_hidden/num_heads]", "\n", "\n", "# Multiplication", "\n", "outputs", "=", "torch", ".", "matmul", "(", "Q_", ",", "K_", ".", "permute", "(", "[", "0", ",", "2", ",", "1", "]", ")", ")", "# num_heads*[batch_size, seq_length, seq_length]", "\n", "\n", "# Scale", "\n", "outputs", "=", "outputs", "/", "(", "K_", ".", "shape", "[", "-", "1", "]", "**", "0.5", ")", "\n", "\n", "# Activation", "\n", "outputs", "=", "F", ".", "softmax", "(", "outputs", ")", "# num_heads*[batch_size, seq_length, seq_length]", "\n", "\n", "# Dropouts", "\n", "outputs", "=", "F", ".", "dropout", "(", "outputs", ",", "p", "=", "dropout_rate", ",", "training", "=", "is_training", ")", "\n", "\n", "# Weighted sum", "\n", "outputs", "=", "torch", ".", "matmul", "(", "outputs", ",", "V_", ")", "# num_heads*[batch_size, seq_length, n_hidden/num_heads]", "\n", "\n", "# Restore shape", "\n", "outputs", "=", "torch", ".", "cat", "(", "torch", ".", "split", "(", "outputs", ",", "int", "(", "outputs", ".", "shape", "[", "0", "]", "/", "num_heads", ")", ",", "dim", "=", "0", ")", ",", "dim", "=", "2", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "# Residual connection", "\n", "outputs", "=", "outputs", "+", "inputs", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "outputs", "=", "outputs", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "# Normalize", "\n", "outputs", "=", "self", ".", "bn_layer", "(", "outputs", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.FeedForward.__init__": [[388, 405], ["torch.Module.__init__", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_units", "=", "(", "2048", ",", "512", ")", ",", "device", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# Inner layer", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "num_units", "[", "1", "]", ",", "\n", "out_channels", "=", "num_units", "[", "0", "]", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "bias", "=", "True", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# Readout layer", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "num_units", "[", "0", "]", ",", "\n", "out_channels", "=", "num_units", "[", "1", "]", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "bias", "=", "True", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "bn_layer", "=", "nn", ".", "BatchNorm1d", "(", "num_units", "[", "1", "]", ")", ".", "to", "(", "self", ".", "device", ")", "# \u4f20\u5165\u901a\u9053\u6570", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.FeedForward.forward": [[407, 420], ["decoder.FeedForward.conv1", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "decoder.FeedForward.conv2", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "decoder.FeedForward.bn_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "conv1", "(", "inputs", ")", "\n", "outputs", "=", "F", ".", "relu", "(", "outputs", ")", "\n", "outputs", "=", "self", ".", "conv2", "(", "outputs", ")", "\n", "outputs", "=", "F", ".", "relu", "(", "outputs", ")", "\n", "\n", "# Residual connection", "\n", "outputs", "=", "outputs", "+", "inputs", "\n", "\n", "outputs", "=", "self", ".", "bn_layer", "(", "outputs", ")", "# [batch_size, seq_length, n_hidden]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.TransformerDecoder.__init__": [[424, 461], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "decoder.TransformerDecoder.reset_parameters", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.BatchNorm1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "torch.Conv1d().to", "decoder.MultiheadAttention", "decoder.FeedForward", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "max_length", ",", "hidden_dim", ",", "\n", "num_heads", ",", "num_stacks", ",", "is_train", ",", "device", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "# batch size", "\n", "self", ".", "max_length", "=", "max_length", "# input sequence length (number of cities)", "\n", "# input_dimension*2+1 # dimension of input, multiply 2 for expanding dimension to input complex value to tf, add 1 high priority token, 1 pointing", "\n", "self", ".", "input_dimension", "=", "hidden_dim", "\n", "self", ".", "input_embed", "=", "hidden_dim", "# dimension of embedding space (actor)", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "num_stacks", "=", "num_stacks", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "is_training", "=", "is_train", "\n", "\n", "# self._emb_params = LayerParams(self, 'emb', self.device)", "\n", "self", ".", "emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "(", "1", ",", "self", ".", "input_embed", ",", "self", ".", "input_embed", ")", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n", "# Batch Normalization", "\n", "self", ".", "bn_layer", "=", "nn", ".", "BatchNorm1d", "(", "self", ".", "input_dimension", ")", ".", "to", "(", "self", ".", "device", ")", "# \u4f20\u5165\u901a\u9053\u6570", "\n", "\n", "# conv1d", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "in_channels", "=", "self", ".", "input_embed", ",", "\n", "out_channels", "=", "self", ".", "max_length", ",", "\n", "kernel_size", "=", "(", "1", ",", ")", ",", "\n", "bias", "=", "True", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# attention", "\n", "self", ".", "multihead_attention", "=", "MultiheadAttention", "(", "self", ".", "input_dimension", ",", "\n", "num_units", "=", "self", ".", "input_embed", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "# feedforward", "\n", "self", ".", "feedforward", "=", "FeedForward", "(", "num_units", "=", "[", "self", ".", "input_embed", ",", "self", ".", "input_embed", "]", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.TransformerDecoder.reset_parameters": [[462, 464], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "emb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.decoder.TransformerDecoder.forward": [[465, 520], ["inputs.permute.permute.permute", "W_embed.permute", "torch.conv1d", "torch.conv1d", "torch.conv1d", "torch.conv1d", "decoder.TransformerDecoder.bn_layer", "range", "decoder.TransformerDecoder.conv1", "decoder.TransformerDecoder.adj_prob.permute", "inputs.permute.permute.permute", "range", "decoder.TransformerDecoder.multihead_attention", "decoder.TransformerDecoder.feedforward", "position.long.long.long", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.zeros().scatter_", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli", "torch.Bernoulli.sample", "decoder.TransformerDecoder.samples.append", "decoder.TransformerDecoder.mask_scores.append", "decoder.TransformerDecoder.entropy.append", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "position.long.long.view", "torch.Bernoulli.entropy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.transformer_decoder.multihead_attention", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.decoder.transformer_decoder.feedforward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "inputs", "=", "inputs", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "# Embed input sequence", "\n", "W_embed", "=", "self", ".", "emb", "\n", "W_embed_", "=", "W_embed", ".", "permute", "(", "2", ",", "1", ",", "0", ")", "\n", "self", ".", "embedded_input", "=", "F", ".", "conv1d", "(", "inputs", ",", "W_embed_", ",", "stride", "=", "1", ")", "\n", "\n", "# Batch Normalization", "\n", "self", ".", "enc", "=", "self", ".", "bn_layer", "(", "self", ".", "embedded_input", ")", "\n", "\n", "# Blocks", "\n", "for", "i", "in", "range", "(", "self", ".", "num_stacks", ")", ":", "# num blocks", "\n", "### Multihead Attention", "\n", "            ", "self", ".", "enc", "=", "self", ".", "multihead_attention", "(", "self", ".", "enc", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "dropout_rate", "=", "0.0", ",", "\n", "is_training", "=", "self", ".", "is_training", ")", "\n", "\n", "### Feed Forward", "\n", "self", ".", "enc", "=", "self", ".", "feedforward", "(", "self", ".", "enc", ")", "\n", "\n", "# Readout layer", "\n", "", "self", ".", "adj_prob", "=", "self", ".", "conv1", "(", "self", ".", "enc", ")", "\n", "self", ".", "adj_prob", "=", "self", ".", "adj_prob", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "########################################", "\n", "########## Initialize process ##########", "\n", "########################################", "\n", "# Keep track of visited cities", "\n", "self", ".", "mask", "=", "0", "\n", "self", ".", "mask_scores", "=", "[", "]", "\n", "self", ".", "entropy", "=", "[", "]", "\n", "self", ".", "samples", "=", "[", "]", "\n", "\n", "inputs", "=", "inputs", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "max_length", ")", ":", "\n", "            ", "position", "=", "torch", ".", "ones", "(", "[", "inputs", ".", "shape", "[", "0", "]", "]", ",", "device", "=", "self", ".", "device", ")", "*", "i", "\n", "position", "=", "position", ".", "long", "(", ")", "\n", "# Update mask", "\n", "self", ".", "mask", "=", "torch", ".", "zeros", "(", "(", "inputs", ".", "shape", "[", "0", "]", ",", "self", ".", "max_length", ")", ",", "\n", "device", "=", "self", ".", "device", ")", ".", "scatter_", "(", "1", ",", "position", ".", "view", "(", "inputs", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "1", ")", "\n", "\n", "masked_score", "=", "self", ".", "adj_prob", "[", ":", ",", "i", ",", ":", "]", "-", "100000000.", "*", "self", ".", "mask", "\n", "prob", "=", "distr", ".", "Bernoulli", "(", "logits", "=", "masked_score", ")", "# probs input probability, logit input log_probability", "\n", "\n", "sampled_arr", "=", "prob", ".", "sample", "(", ")", "# Batch_size, seqlenght for just one node", "\n", "sampled_arr", ".", "requires_grad", "=", "True", "\n", "\n", "self", ".", "samples", ".", "append", "(", "sampled_arr", ")", "\n", "self", ".", "mask_scores", ".", "append", "(", "masked_score", ")", "\n", "self", ".", "entropy", ".", "append", "(", "prob", ".", "entropy", "(", ")", ")", "\n", "\n", "", "return", "self", ".", "samples", ",", "self", ".", "mask_scores", ",", "self", ".", "entropy", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.__init__": [[28, 54], ["numpy.ones", "sklearn.preprocessing.PolynomialFeatures", "numpy.log", "ValueError", "ValueError"], "methods", ["None"], ["self", ".", "lambda1_upper", "=", "lambda1_upper", "\n", "self", ".", "bic_penalty", "=", "np", ".", "log", "(", "inputdata", ".", "shape", "[", "0", "]", ")", "/", "inputdata", ".", "shape", "[", "0", "]", "\n", "\n", "if", "score_type", "not", "in", "(", "'BIC'", ",", "'BIC_different_var'", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Reward type not supported.'", ")", "\n", "", "if", "reg_type", "not", "in", "(", "'LR'", ",", "'QR'", ",", "'GPR'", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Reg type not supported'", ")", "\n", "", "self", ".", "score_type", "=", "score_type", "\n", "self", ".", "reg_type", "=", "reg_type", "\n", "\n", "self", ".", "ones", "=", "np", ".", "ones", "(", "(", "inputdata", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "poly", "=", "PolynomialFeatures", "(", ")", "\n", "\n", "", "def", "cal_rewards", "(", "self", ",", "graphs", ",", "lambda1", ",", "lambda2", ")", ":", "\n", "        ", "rewards_batches", "=", "[", "]", "\n", "\n", "for", "graphi", "in", "graphs", ":", "\n", "            ", "reward_", "=", "self", ".", "calculate_reward_single_graph", "(", "graphi", ",", "lambda1", ",", "lambda2", ")", "\n", "rewards_batches", ".", "append", "(", "reward_", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "rewards_batches", ")", "\n", "\n", "\n", "####### regression ", "\n", "\n", "", "def", "calculate_yerr", "(", "self", ",", "X_train", ",", "y_train", ")", ":", "\n", "        ", "if", "self", ".", "reg_type", "==", "'LR'", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.cal_rewards": [[55, 63], ["numpy.array", "Reward_BIC.get_Reward.calculate_reward_single_graph", "rewards_batches.append"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_reward_single_graph"], ["            ", "return", "self", ".", "calculate_LR", "(", "X_train", ",", "y_train", ")", "\n", "", "elif", "self", ".", "reg_type", "==", "'QR'", ":", "\n", "            ", "return", "self", ".", "calculate_QR", "(", "X_train", ",", "y_train", ")", "\n", "", "elif", "self", ".", "reg_type", "==", "'GPR'", ":", "\n", "            ", "return", "self", ".", "calculate_GPR", "(", "X_train", ",", "y_train", ")", "\n", "", "else", ":", "\n", "# raise value error", "\n", "            ", "assert", "False", ",", "'Regressor not supported'", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.calculate_yerr": [[67, 77], ["Reward_BIC.get_Reward.calculate_LR", "Reward_BIC.get_Reward.calculate_QR", "Reward_BIC.get_Reward.calculate_GPR"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_LR", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_QR", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_GPR"], ["XtX", "=", "X", ".", "T", ".", "dot", "(", "X", ")", "\n", "Xty", "=", "X", ".", "T", ".", "dot", "(", "y_train", ")", "\n", "theta", "=", "np", ".", "linalg", ".", "solve", "(", "XtX", ",", "Xty", ")", "\n", "y_err", "=", "X", ".", "dot", "(", "theta", ")", "-", "y_train", "\n", "return", "y_err", "\n", "\n", "", "def", "calculate_QR", "(", "self", ",", "X_train", ",", "y_train", ")", ":", "\n", "        ", "X_train", "=", "self", ".", "poly", ".", "fit_transform", "(", "X_train", ")", "[", ":", ",", "1", ":", "]", "\n", "return", "self", ".", "calculate_LR", "(", "X_train", ",", "y_train", ")", "\n", "\n", "", "def", "calculate_GPR", "(", "self", ",", "X_train", ",", "y_train", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.calculate_LR": [[79, 86], ["numpy.hstack", "numpy.hstack.T.dot", "numpy.hstack.T.dot", "numpy.linalg.solve", "numpy.hstack.dot"], "methods", ["None"], ["gpr", "=", "GPR", "(", ")", ".", "fit", "(", "X_train", "/", "med_w", ",", "y_train", ")", "\n", "return", "y_train", ".", "reshape", "(", "-", "1", ",", "1", ")", "-", "gpr", ".", "predict", "(", "X_train", "/", "med_w", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "####### score calculations", "\n", "\n", "", "def", "calculate_reward_single_graph", "(", "self", ",", "graph_batch", ",", "lambda1", ",", "lambda2", ")", ":", "\n", "        ", "graph_to_int", "=", "[", "]", "\n", "graph_to_int2", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.calculate_QR": [[87, 90], ["Reward_BIC.get_Reward.calculate_LR", "Reward_BIC.get_Reward.poly.fit_transform"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_LR"], ["\n", "for", "i", "in", "range", "(", "self", ".", "maxlen", ")", ":", "\n", "            ", "graph_batch", "[", "i", "]", "[", "i", "]", "=", "0", "\n", "tt", "=", "np", ".", "int32", "(", "graph_batch", "[", "i", "]", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.calculate_GPR": [[91, 95], ["numpy.median", "sklearn.gaussian_process.GaussianProcessRegressor.fit", "scipy.spatial.distance.pdist", "y_train.reshape", "sklearn.gaussian_process.GaussianProcessRegressor.fit.predict().reshape", "sklearn.gaussian_process.GaussianProcessRegressor", "sklearn.gaussian_process.GaussianProcessRegressor.fit.predict"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.GPRMine.predict"], ["graph_to_int", ".", "append", "(", "self", ".", "baseint", "*", "i", "+", "np", ".", "int", "(", "''", ".", "join", "(", "[", "str", "(", "ad", ")", "for", "ad", "in", "tt", "]", ")", ",", "2", ")", ")", "\n", "graph_to_int2", ".", "append", "(", "np", ".", "int", "(", "''", ".", "join", "(", "[", "str", "(", "ad", ")", "for", "ad", "in", "tt", "]", ")", ",", "2", ")", ")", "\n", "\n", "", "graph_batch_to_tuple", "=", "tuple", "(", "graph_to_int2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.calculate_reward_single_graph": [[98, 164], ["range", "tuple", "range", "Reward_BIC.get_Reward.score_transform", "numpy.int32", "graph_to_int.append", "graph_to_int2.append", "numpy.sum", "RSS_ls.append", "numpy.trace", "Reward_BIC.get_Reward._logger.info", "int", "Reward_BIC.get_Reward.penalized_score", "RSS_ls.append", "numpy.sum", "Reward_BIC.get_Reward.calculate_yerr", "numpy.square", "numpy.log", "scipy.linalg.expm", "int", "numpy.mean", "numpy.sum", "numpy.array", "float", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.log", "numpy.sum", "str", "numpy.sum", "str", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.score_transform", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.penalized_score", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_yerr"], ["return", "self", ".", "penalized_score", "(", "score_cyc", ",", "lambda1", ",", "lambda2", ")", ",", "score_cyc", "[", "0", "]", ",", "score_cyc", "[", "1", "]", "\n", "\n", "", "RSS_ls", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "maxlen", ")", ":", "\n", "            ", "col", "=", "graph_batch", "[", "i", "]", "\n", "if", "graph_to_int", "[", "i", "]", "in", "self", ".", "d_RSS", ":", "\n", "                ", "RSS_ls", ".", "append", "(", "self", ".", "d_RSS", "[", "graph_to_int", "[", "i", "]", "]", ")", "\n", "continue", "\n", "\n", "# no parents, then simply use mean", "\n", "", "if", "np", ".", "sum", "(", "col", ")", "<", "0.1", ":", "\n", "                ", "y_err", "=", "self", ".", "inputdata", "[", ":", ",", "i", "]", "\n", "y_err", "=", "y_err", "-", "np", ".", "mean", "(", "y_err", ")", "\n", "\n", "", "else", ":", "\n", "                ", "cols_TrueFalse", "=", "col", ">", "0.5", "\n", "X_train", "=", "self", ".", "inputdata", "[", ":", ",", "cols_TrueFalse", "]", "\n", "y_train", "=", "self", ".", "inputdata", "[", ":", ",", "i", "]", "\n", "y_err", "=", "self", ".", "calculate_yerr", "(", "X_train", ",", "y_train", ")", "\n", "\n", "", "RSSi", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "y_err", ")", ")", "\n", "\n", "# if the regresors include the true parents, GPR would result in very samll values, e.g., 10^-13", "\n", "# so we add 1.0, which does not affect the monotoniticy of the score", "\n", "if", "self", ".", "reg_type", "==", "'GPR'", ":", "\n", "                ", "RSSi", "+=", "1.0", "\n", "\n", "", "RSS_ls", ".", "append", "(", "RSSi", ")", "\n", "self", ".", "d_RSS", "[", "graph_to_int", "[", "i", "]", "]", "=", "RSSi", "\n", "\n", "", "if", "self", ".", "score_type", "==", "'BIC'", ":", "\n", "            ", "BIC", "=", "np", ".", "log", "(", "np", ".", "sum", "(", "RSS_ls", ")", "/", "self", ".", "n_samples", "+", "1e-8", ")", "+", "np", ".", "sum", "(", "graph_batch", ")", "*", "self", ".", "bic_penalty", "/", "self", ".", "maxlen", "\n", "", "elif", "self", ".", "score_type", "==", "'BIC_different_var'", ":", "\n", "            ", "BIC", "=", "np", ".", "sum", "(", "np", ".", "log", "(", "np", ".", "array", "(", "RSS_ls", ")", "/", "self", ".", "n_samples", "+", "1e-8", ")", ")", "+", "np", ".", "sum", "(", "graph_batch", ")", "*", "self", ".", "bic_penalty", "\n", "\n", "", "score", "=", "self", ".", "score_transform", "(", "BIC", ")", "\n", "cycness", "=", "np", ".", "trace", "(", "matrix_exponential", "(", "np", ".", "array", "(", "graph_batch", ")", ")", ")", "-", "self", ".", "maxlen", "\n", "reward", "=", "score", "+", "lambda1", "*", "np", ".", "float", "(", "cycness", ">", "1e-5", ")", "+", "lambda2", "*", "cycness", "\n", "\n", "if", "self", ".", "l1_graph_reg", ">", "0", ":", "\n", "            ", "reward", "=", "reward", "+", "self", ".", "l1_grapha_reg", "*", "np", ".", "sum", "(", "graph_batch", ")", "\n", "score", "=", "score", "+", "self", ".", "l1_grapha_reg", "*", "np", ".", "sum", "(", "graph_batch", ")", "\n", "\n", "", "self", ".", "d", "[", "graph_batch_to_tuple", "]", "=", "(", "score", ",", "cycness", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "'BIC: {}, cycness: {}, returned reward: {}'", ".", "format", "(", "BIC", ",", "cycness", ",", "final_score", ")", ")", "\n", "\n", "", "return", "reward", ",", "score", ",", "cycness", "\n", "\n", "#### helper", "\n", "\n", "", "def", "score_transform", "(", "self", ",", "s", ")", ":", "\n", "        ", "return", "(", "s", "-", "self", ".", "sl", ")", "/", "(", "self", ".", "su", "-", "self", ".", "sl", ")", "*", "self", ".", "lambda1_upper", "\n", "\n", "", "def", "penalized_score", "(", "self", ",", "score_cyc", ",", "lambda1", ",", "lambda2", ")", ":", "\n", "        ", "score", ",", "cyc", "=", "score_cyc", "\n", "return", "score", "+", "lambda1", "*", "np", ".", "float", "(", "cyc", ">", "1e-5", ")", "+", "lambda2", "*", "cyc", "\n", "\n", "", "def", "update_scores", "(", "self", ",", "score_cycs", ",", "lambda1", ",", "lambda2", ")", ":", "\n", "        ", "ls", "=", "[", "]", "\n", "for", "score_cyc", "in", "score_cycs", ":", "\n", "            ", "ls", ".", "append", "(", "self", ".", "penalized_score", "(", "score_cyc", ",", "lambda1", ",", "lambda2", ")", ")", "\n", "", "return", "ls", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.score_transform": [[167, 169], ["None"], "methods", ["None"], ["        ", "score_cycs", "=", "list", "(", "self", ".", "d", ".", "items", "(", ")", ")", "\n", "ls", "=", "[", "]", "\n", "for", "graph_int", ",", "score_cyc", "in", "score_cycs", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.penalized_score": [[170, 173], ["float"], "methods", ["None"], ["            ", "ls", ".", "append", "(", "(", "graph_int", ",", "(", "self", ".", "penalized_score", "(", "score_cyc", ",", "lambda1", ",", "lambda2", ")", ",", "score_cyc", "[", "0", "]", ",", "score_cyc", "[", "1", "]", ")", ")", ")", "\n", "", "return", "sorted", "(", "ls", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", "[", "0", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.update_scores": [[174, 179], ["ls.append", "Reward_BIC.get_Reward.penalized_score"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.penalized_score"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.rewards.Reward_BIC.get_Reward.update_all_scores": [[180, 186], ["list", "sorted", "Reward_BIC.get_Reward.d.items", "ls.append", "Reward_BIC.get_Reward.penalized_score"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.penalized_score"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Datasets.synthetic_datasets.generate_W": [[9, 22], ["numpy.float32", "numpy.tril", "numpy.round", "numpy.random.uniform", "numpy.random.rand", "numpy.random.randn"], "function", ["None"], ["def", "generate_W", "(", "d", "=", "6", ",", "prob", "=", "0.5", ",", "low", "=", "0.5", ",", "high", "=", "2.0", ")", ":", "\n", "    ", "\"\"\"\n    generate a random weighted adjaceecy matrix\n    :param d: number of nodes\n    :param prob: prob of existing an edge\n    :return:\n    \"\"\"", "\n", "g_random", "=", "np", ".", "float32", "(", "np", ".", "random", ".", "rand", "(", "d", ",", "d", ")", "<", "prob", ")", "\n", "g_random", "=", "np", ".", "tril", "(", "g_random", ",", "-", "1", ")", "\n", "U", "=", "np", ".", "round", "(", "np", ".", "random", ".", "uniform", "(", "low", "=", "low", ",", "high", "=", "high", ",", "size", "=", "[", "d", ",", "d", "]", ")", ",", "1", ")", "\n", "U", "[", "np", ".", "random", ".", "randn", "(", "d", ",", "d", ")", "<", "0", "]", "*=", "-", "1", "\n", "W", "=", "(", "g_random", "!=", "0", ")", ".", "astype", "(", "float", ")", "*", "U", "\n", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Datasets.synthetic_datasets.gen_data_given_model": [[24, 88], ["numpy.allclose", "numpy.zeros", "range", "copy.deepcopy", "copy.deepcopy", "numpy.sum", "numpy.tril", "numpy.where", "numpy.random.randn", "numpy.random.permutation", "numpy.abs", "numpy.sign", "numpy.diag", "numpy.random.rand", "numpy.abs", "numpy.std", "numpy.random.randn", "np.zeros.dot"], "function", ["None"], ["", "def", "gen_data_given_model", "(", "b", ",", "s", ",", "c", ",", "n_samples", "=", "10", ",", "noise_type", "=", "'lingam'", ",", "permutate", "=", "False", ")", ":", "\n", "    ", "\"\"\"Generate artificial data based on the given model.\n       Based on ICA-LiNGAM codes.\n       https://github.com/cdt15/lingam\n    Parameters\n    ----------\n    b : numpy.ndarray, shape=(n_features, n_features)\n        Strictly lower triangular coefficient matrix.\n        NOTE: Each row of `b` corresponds to each variable, i.e., X = BX.\n    s : numpy.ndarray, shape=(n_features,)\n        Scales of disturbance variables.\n    c : numpy.ndarray, shape=(n_features,)\n        Means of observed variables.\n\n    Returns\n    -------\n    xs, b_, c_ : Tuple\n        `xs` is observation matrix, where `xs.shape==(n_samples, n_features)`.\n        `b_` is permuted coefficient matrix. Note that rows of `b_` correspond\n        to columns of `xs`. `c_` if permuted mean vectors.\n    \"\"\"", "\n", "\n", "n_vars", "=", "b", ".", "shape", "[", "0", "]", "\n", "\n", "# Check args", "\n", "assert", "(", "b", ".", "shape", "==", "(", "n_vars", ",", "n_vars", ")", ")", "\n", "assert", "(", "s", ".", "shape", "==", "(", "n_vars", ",", ")", ")", "\n", "assert", "(", "np", ".", "sum", "(", "np", ".", "abs", "(", "np", ".", "diag", "(", "b", ")", ")", ")", "==", "0", ")", "\n", "np", ".", "allclose", "(", "b", ",", "np", ".", "tril", "(", "b", ")", ")", "\n", "\n", "if", "noise_type", "==", "'lingam'", ":", "\n", "# Nonlinearity exponent, selected to lie in [0.5, 0.8] or [1.2, 2.0].", "\n", "# (<1 gives subgaussian, >1 gives supergaussian)", "\n", "        ", "q", "=", "np", ".", "random", ".", "rand", "(", "n_vars", ")", "*", "1.1", "+", "0.5", "\n", "ixs", "=", "np", ".", "where", "(", "q", ">", "0.8", ")", "\n", "q", "[", "ixs", "]", "=", "q", "[", "ixs", "]", "+", "0.4", "\n", "\n", "# Generates disturbance variables", "\n", "ss", "=", "np", ".", "random", ".", "randn", "(", "n_samples", ",", "n_vars", ")", "\n", "ss", "=", "np", ".", "sign", "(", "ss", ")", "*", "(", "np", ".", "abs", "(", "ss", ")", "**", "q", ")", "\n", "\n", "# Normalizes the disturbance variables to have the appropriate scales", "\n", "ss", "=", "ss", "/", "np", ".", "std", "(", "ss", ",", "axis", "=", "0", ")", "*", "s", "\n", "\n", "", "elif", "noise_type", "==", "'gaussian'", ":", "\n", "        ", "ss", "=", "np", ".", "random", ".", "randn", "(", "n_samples", ",", "n_vars", ")", "*", "s", "\n", "\n", "# Generate the data one component at a time", "\n", "", "xs", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", "n_vars", ")", ")", "\n", "for", "i", "in", "range", "(", "n_vars", ")", ":", "\n", "# NOTE: columns of xs and ss correspond to rows of b", "\n", "        ", "xs", "[", ":", ",", "i", "]", "=", "ss", "[", ":", ",", "i", "]", "+", "xs", ".", "dot", "(", "b", "[", "i", ",", ":", "]", ")", "+", "c", "[", "i", "]", "\n", "\n", "# Permute variables", "\n", "", "b_", "=", "deepcopy", "(", "b", ")", "\n", "c_", "=", "deepcopy", "(", "c", ")", "\n", "if", "permutate", ":", "\n", "        ", "p", "=", "np", ".", "random", ".", "permutation", "(", "n_vars", ")", "\n", "xs", "[", ":", ",", ":", "]", "=", "xs", "[", ":", ",", "p", "]", "\n", "b_", "[", ":", ",", ":", "]", "=", "b_", "[", "p", ",", ":", "]", "\n", "b_", "[", ":", ",", ":", "]", "=", "b_", "[", ":", ",", "p", "]", "\n", "c_", "[", ":", "]", "=", "c", "[", "p", "]", "\n", "\n", "", "return", "xs", ",", "b_", ",", "c_", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Datasets.synthetic_datasets.gen_data_given_model_2nd_order": [[90, 192], ["numpy.allclose", "numpy.zeros", "sklearn.preprocessing.PolynomialFeatures", "range", "copy.deepcopy", "copy.deepcopy", "numpy.sum", "numpy.tril", "numpy.where", "numpy.random.randn", "int", "numpy.array", "numpy.random.permutation", "numpy.abs", "numpy.sign", "numpy.abs", "numpy.sum", "newb.append", "sklearn.preprocessing.PolynomialFeatures.fit_transform", "numpy.round", "numpy.sum", "numpy.zeros", "range", "newb.append", "numpy.diag", "numpy.random.rand", "numpy.abs", "numpy.std", "numpy.random.randn", "numpy.zeros", "numpy.random.uniform", "sklearn.preprocessing.PolynomialFeatures.get_feature_names", "enumerate", "numpy.random.randn", "numpy.random.randn", "numpy.abs"], "function", ["None"], ["", "def", "gen_data_given_model_2nd_order", "(", "b", ",", "s", ",", "c", ",", "n_samples", "=", "10", ",", "noise_type", "=", "'lingam'", ",", "permutate", "=", "False", ")", ":", "\n", "    ", "\"\"\"Generate artificial data based on the given model.\n       Quadratic functions\n\n    Parameters\n    ----------\n    b : numpy.ndarray, shape=(n_features, n_features)\n        Strictly lower triangular coefficient matrix.\n        NOTE: Each row of `b` corresponds to each variable, i.e., X = BX.\n    s : numpy.ndarray, shape=(n_features,)\n        Scales of disturbance variables.\n    c : numpy.ndarray, shape=(n_features,)\n        Means of observed variables.\n\n    Returns\n    -------\n    xs, b_, c_ : Tuple\n        `xs` is observation matrix, where `xs.shape==(n_samples, n_features)`.\n        `b_` is permuted coefficient matrix. Note that rows of `b_` correspond\n        to columns of `xs`. `c_` if permuted mean vectors.\n\n    \"\"\"", "\n", "# rng = np.random.RandomState(random_state)", "\n", "n_vars", "=", "b", ".", "shape", "[", "0", "]", "\n", "\n", "# Check args", "\n", "assert", "(", "b", ".", "shape", "==", "(", "n_vars", ",", "n_vars", ")", ")", "\n", "assert", "(", "s", ".", "shape", "==", "(", "n_vars", ",", ")", ")", "\n", "assert", "(", "np", ".", "sum", "(", "np", ".", "abs", "(", "np", ".", "diag", "(", "b", ")", ")", ")", "==", "0", ")", "\n", "np", ".", "allclose", "(", "b", ",", "np", ".", "tril", "(", "b", ")", ")", "\n", "\n", "if", "noise_type", "==", "'lingam'", ":", "\n", "# Nonlinearity exponent, selected to lie in [0.5, 0.8] or [1.2, 2.0].", "\n", "# (<1 gives subgaussian, >1 gives supergaussian)", "\n", "        ", "q", "=", "np", ".", "random", ".", "rand", "(", "n_vars", ")", "*", "1.1", "+", "0.5", "\n", "ixs", "=", "np", ".", "where", "(", "q", ">", "0.8", ")", "\n", "q", "[", "ixs", "]", "=", "q", "[", "ixs", "]", "+", "0.4", "\n", "\n", "# Generates disturbance variables", "\n", "ss", "=", "np", ".", "random", ".", "randn", "(", "n_samples", ",", "n_vars", ")", "\n", "ss", "=", "np", ".", "sign", "(", "ss", ")", "*", "(", "np", ".", "abs", "(", "ss", ")", "**", "q", ")", "\n", "\n", "# Normalizes the disturbance variables to have the appropriate scales", "\n", "ss", "=", "ss", "/", "np", ".", "std", "(", "ss", ",", "axis", "=", "0", ")", "*", "s", "\n", "\n", "", "elif", "noise_type", "==", "'gaussian'", ":", "\n", "\n", "        ", "ss", "=", "np", ".", "random", ".", "randn", "(", "n_samples", ",", "n_vars", ")", "*", "s", "\n", "# Generate the data one component at a time", "\n", "\n", "", "xs", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", "n_vars", ")", ")", "\n", "poly", "=", "PolynomialFeatures", "(", ")", "\n", "newb", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "n_vars", ")", ":", "\n", "# NOTE: columns of xs and ss correspond to rows of b", "\n", "        ", "xs", "[", ":", ",", "i", "]", "=", "ss", "[", ":", ",", "i", "]", "+", "c", "[", "i", "]", "\n", "col", "=", "b", "[", "i", "]", "\n", "col_false_true", "=", "np", ".", "abs", "(", "col", ")", ">", "0.3", "\n", "len_parents", "=", "int", "(", "np", ".", "sum", "(", "col_false_true", ")", ")", "\n", "if", "len_parents", "==", "0", ":", "\n", "            ", "newb", ".", "append", "(", "np", ".", "zeros", "(", "n_vars", ",", ")", ")", "\n", "continue", "\n", "", "else", ":", "\n", "            ", "X_parents", "=", "xs", "[", ":", ",", "col_false_true", "]", "\n", "X_2nd", "=", "poly", ".", "fit_transform", "(", "X_parents", ")", "\n", "X_2nd", "=", "X_2nd", "[", ":", ",", "1", ":", "]", "\n", "dd", "=", "X_2nd", ".", "shape", "[", "1", "]", "\n", "U", "=", "np", ".", "round", "(", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "1.5", ",", "size", "=", "[", "dd", ",", "]", ")", ",", "1", ")", "\n", "U", "[", "np", ".", "random", ".", "randn", "(", "dd", ",", ")", "<", "0", "]", "*=", "-", "1", "\n", "U", "[", "np", ".", "random", ".", "randn", "(", "dd", ",", ")", "<", "0", "]", "*=", "0", "\n", "X_sum", "=", "np", ".", "sum", "(", "U", "*", "X_2nd", ",", "axis", "=", "1", ")", "\n", "xs", "[", ":", ",", "i", "]", "=", "xs", "[", ":", ",", "i", "]", "+", "X_sum", "\n", "\n", "# remove zero-weight variables", "\n", "X_train_expand_names", "=", "poly", ".", "get_feature_names", "(", ")", "[", "1", ":", "]", "\n", "cj", "=", "0", "\n", "new_reg_coeff", "=", "np", ".", "zeros", "(", "n_vars", ",", ")", "\n", "\n", "# hard coding; to be optimized for reading", "\n", "for", "ci", "in", "range", "(", "n_vars", ")", ":", "\n", "                ", "if", "col_false_true", "[", "ci", "]", ":", "\n", "                    ", "xxi", "=", "'x{}'", ".", "format", "(", "cj", ")", "\n", "for", "iii", ",", "xxx", "in", "enumerate", "(", "X_train_expand_names", ")", ":", "\n", "                        ", "if", "xxi", "in", "xxx", ":", "\n", "                            ", "if", "np", ".", "abs", "(", "U", "[", "iii", "]", ")", ">", "0.3", ":", "\n", "                                ", "new_reg_coeff", "[", "ci", "]", "=", "1.0", "\n", "break", "\n", "", "", "", "cj", "+=", "1", "\n", "", "", "newb", ".", "append", "(", "new_reg_coeff", ")", "\n", "\n", "# Permute variables", "\n", "", "", "b_", "=", "deepcopy", "(", "np", ".", "array", "(", "newb", ")", ")", "\n", "c_", "=", "deepcopy", "(", "c", ")", "\n", "if", "permutate", ":", "\n", "        ", "p", "=", "np", ".", "random", ".", "permutation", "(", "n_vars", ")", "\n", "xs", "[", ":", ",", ":", "]", "=", "xs", "[", ":", ",", "p", "]", "\n", "b_", "[", ":", ",", ":", "]", "=", "b_", "[", "p", ",", ":", "]", "\n", "b_", "[", ":", ",", ":", "]", "=", "b_", "[", ":", ",", "p", "]", "\n", "c_", "[", ":", "]", "=", "c", "[", "p", "]", "\n", "\n", "", "return", "xs", ",", "b_", ",", "c_", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.BuiltinDataSet.__init__": [[108, 112], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_data", "=", "None", "\n", "self", ".", "_true_graph_matrix", "=", "None", "\n", "self", ".", "_topology_matrix", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.BuiltinDataSet.load": [[113, 115], ["None"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.BuiltinDataSet.data": [[116, 119], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_data", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.BuiltinDataSet.true_graph_matrix": [[120, 123], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "true_graph_matrix", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_true_graph_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.BuiltinDataSet.topology_matrix": [[124, 127], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "topology_matrix", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_topology_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.IID_Test.__init__": [[134, 136], ["builtin_dataset.BuiltinDataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.IID_Test.load": [[137, 144], ["simulator.DAG.erdos_renyi", "simulator.IIDSimulation"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.Topology.erdos_renyi"], ["", "def", "load", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "weighted_random_dag", "=", "DAG", ".", "erdos_renyi", "(", "n_nodes", "=", "10", ",", "n_edges", "=", "20", ",", "\n", "weight_range", "=", "(", "0.5", ",", "2.0", ")", ",", "\n", "seed", "=", "1", ")", "\n", "dataset", "=", "IIDSimulation", "(", "W", "=", "weighted_random_dag", ",", "n", "=", "2000", ",", "\n", "method", "=", "'linear'", ",", "sem_type", "=", "'gauss'", ")", "\n", "self", ".", "_true_graph_matrix", ",", "self", ".", "_data", "=", "dataset", ".", "B", ",", "dataset", ".", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.THP_Test.__init__": [[151, 153], ["builtin_dataset.BuiltinDataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.THP_Test.load": [[154, 161], ["simulator.THPSimulation.DAG.erdos_renyi", "simulator.THPSimulation.Topology.erdos_renyi", "simulator.THPSimulation.THPSimulation", "simulator.THPSimulation.THPSimulation.simulate"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.Topology.erdos_renyi", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.Topology.erdos_renyi", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.THPSimulation.simulate"], ["", "def", "load", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_true_graph_matrix", "=", "DAG", ".", "erdos_renyi", "(", "n_nodes", "=", "10", ",", "n_edges", "=", "10", ")", "\n", "self", ".", "_topology_matrix", "=", "Topology", ".", "erdos_renyi", "(", "n_nodes", "=", "20", ",", "n_edges", "=", "20", ")", "\n", "simulator", "=", "THPSimulation", "(", "self", ".", "_true_graph_matrix", ",", "self", ".", "_topology_matrix", ",", "\n", "mu_range", "=", "(", "0.00005", ",", "0.0001", ")", ",", "\n", "alpha_range", "=", "(", "0.005", ",", "0.007", ")", ")", "\n", "self", ".", "_data", "=", "simulator", ".", "simulate", "(", "T", "=", "25000", ",", "max_hop", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.RealDataSet.__init__": [[165, 171], ["builtin_dataset.BuiltinDataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "url", "=", "None", "\n", "self", ".", "tar_file", "=", "None", "\n", "self", ".", "md5", "=", "None", "\n", "self", ".", "file_list", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.RealDataSet.load": [[172, 191], ["builtin_dataset._check_exist", "builtin_dataset._read_data", "builtin_dataset._read_data", "builtin_dataset._download", "builtin_dataset._check_exist", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset._check_exist", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset._read_data", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset._read_data", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset._download", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset._check_exist"], ["", "def", "load", "(", "self", ",", "root", "=", "None", ",", "download", "=", "False", ")", ":", "\n", "\n", "        ", "if", "root", "is", "None", ":", "\n", "            ", "root", "=", "'./'", "\n", "\n", "", "if", "_check_exist", "(", "root", ",", "self", ".", "tar_file", ",", "self", ".", "file_list", ")", ":", "\n", "            ", "self", ".", "_data", ",", "self", ".", "_true_graph_matrix", ",", "self", ".", "_topology_matrix", "=", "_read_data", "(", "root", ",", "self", ".", "tar_file", ",", "self", ".", "file_list", ")", "\n", "return", "\n", "\n", "", "if", "download", ":", "\n", "            ", "_download", "(", "root", ",", "self", ".", "url", ",", "self", ".", "tar_file", ",", "self", ".", "md5", ")", "\n", "\n", "", "if", "not", "_check_exist", "(", "root", ",", "self", ".", "tar_file", ",", "self", ".", "file_list", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset not found.'", "+", "\n", "' You can use download=True to download it.'", ")", "\n", "\n", "", "self", ".", "_data", ",", "self", ".", "_true_graph_matrix", ",", "self", ".", "_topology_matrix", "=", "_read_data", "(", "root", ",", "self", ".", "tar_file", ",", "self", ".", "file_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.V18_N55_Wireless.__init__": [[199, 205], ["builtin_dataset.RealDataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "url", "=", "[", "'https://raw.githubusercontent.com/gcastle-hub/dataset/master/alarm/'", "]", "\n", "self", ".", "tar_file", "=", "\"18V_55N_Wireless.tar.gz\"", "\n", "self", ".", "md5", "=", "\"36ee135b86c8dbe09668d9284c23575b\"", "\n", "self", ".", "file_list", "=", "[", "'Alarm.csv'", ",", "'DAG.npy'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.V24_N439_Microwave.__init__": [[213, 219], ["builtin_dataset.RealDataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "url", "=", "[", "'https://raw.githubusercontent.com/gcastle-hub/dataset/master/alarm/'", "]", "\n", "self", ".", "tar_file", "=", "\"24V_439N_Microwave.tar.gz\"", "\n", "self", ".", "md5", "=", "\"b4c8b32d34c04a86aa93c7259f7d086c\"", "\n", "self", ".", "file_list", "=", "[", "'Alarm.csv'", ",", "'DAG.npy'", ",", "'Topology.npy'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.V25_N474_Microwave.__init__": [[227, 233], ["builtin_dataset.RealDataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "url", "=", "[", "'https://raw.githubusercontent.com/gcastle-hub/dataset/master/alarm/'", "]", "\n", "self", ".", "tar_file", "=", "\"25V_474N_Microwave.tar.gz\"", "\n", "self", ".", "md5", "=", "\"51f43ed622d4b44ef6daf8fabf81e162\"", "\n", "self", ".", "file_list", "=", "[", "'Alarm.csv'", ",", "'DAG.npy'", ",", "'Topology.npy'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset._check_exist": [[30, 38], ["os.path.join", "os.path.exists", "all", "filename.split", "builtin_dataset._check_integrity", "os.path.join"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset._check_integrity"], ["def", "_check_exist", "(", "root", ",", "filename", ",", "files", ")", ":", "\n", "    ", "path_exist", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "processed_folder_exists", "=", "os", ".", "path", ".", "exists", "(", "path_exist", ")", "\n", "if", "not", "processed_folder_exists", ":", "\n", "        ", "return", "False", "\n", "\n", "", "return", "all", "(", "\n", "_check_integrity", "(", "os", ".", "path", ".", "join", "(", "path_exist", ",", "file", ")", ")", "for", "file", "in", "files", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset._check_integrity": [[41, 52], ["hashlib.md5", "os.path.isfile", "open", "hashlib.md5.update", "hashlib.md5.hexdigest", "f.read"], "function", ["None"], ["", "def", "_check_integrity", "(", "fpath", ",", "md5", "=", "None", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "isfile", "(", "fpath", ")", ":", "\n", "        ", "return", "False", "\n", "", "if", "md5", "is", "None", ":", "\n", "        ", "return", "True", "\n", "\n", "", "md5f", "=", "hashlib", ".", "md5", "(", ")", "\n", "with", "open", "(", "fpath", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "md5f", ".", "update", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "return", "md5", "==", "md5f", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset._read_data": [[54, 70], ["os.path.join", "len", "result.append", "filename.split", "os.path.join", "result.append", "file.split", "pandas.read_csv", "os.path.join", "result.append", "file.split", "numpy.load"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.RealDataSet.load"], ["", "def", "_read_data", "(", "root", ",", "filename", ",", "files", ")", ":", "\n", "    ", "path_exist", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "\n", "result", "=", "[", "]", "\n", "for", "file", "in", "files", ":", "\n", "        ", "if", "file", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", "==", "'csv'", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "path_exist", ",", "file", ")", "\n", "result", ".", "append", "(", "pd", ".", "read_csv", "(", "file_path", ")", ")", "\n", "", "elif", "file", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", "==", "'npy'", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "path_exist", ",", "file", ")", "\n", "result", ".", "append", "(", "np", ".", "load", "(", "file_path", ")", ")", "\n", "\n", "", "", "if", "len", "(", "result", ")", "==", "2", ":", "\n", "        ", "result", ".", "append", "(", "None", ")", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset._download": [[72, 104], ["os.makedirs", "os.path.join", "RuntimeError", "builtin_dataset._check_integrity", "RuntimeError", "print", "urllib.request.urlopen", "tarfile.open", "tarfile.open.getnames", "tarfile.open.close", "urllib.request.Request", "open", "fh.write", "tarfile.open.extract", "print", "urllib.request.urlopen.read"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset._check_integrity"], ["", "def", "_download", "(", "root", ",", "url", ",", "filename", ",", "md5", ")", ":", "\n", "    ", "\"\"\"Download the datasets if it doesn't exist already.\"\"\"", "\n", "\n", "os", ".", "makedirs", "(", "root", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# download files", "\n", "for", "mirror", "in", "url", ":", "\n", "        ", "filepath", "=", "\"{}{}\"", ".", "format", "(", "mirror", ",", "filename", ")", "\n", "savegz", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", "\n", "try", ":", "\n", "            ", "print", "(", "\"Downloading {}\"", ".", "format", "(", "filepath", ")", ")", "\n", "response", "=", "urllib", ".", "request", ".", "urlopen", "(", "urllib", ".", "request", ".", "Request", "(", "filepath", ",", "headers", "=", "{", "\"User-Agent\"", ":", "USER_AGENT", "}", ")", ")", "\n", "with", "open", "(", "savegz", ",", "\"wb\"", ")", "as", "fh", ":", "\n", "                ", "fh", ".", "write", "(", "response", ".", "read", "(", ")", ")", "\n", "\n", "", "tar", "=", "tarfile", ".", "open", "(", "savegz", ")", "\n", "names", "=", "tar", ".", "getnames", "(", ")", "\n", "for", "name", "in", "names", ":", "\n", "                ", "tar", ".", "extract", "(", "name", ",", "path", "=", "root", ")", "\n", "", "tar", ".", "close", "(", ")", "\n", "", "except", "URLError", "as", "error", ":", "\n", "            ", "print", "(", "\"Failed to download (trying next):\\n{}\"", ".", "format", "(", "error", ")", ")", "\n", "continue", "\n", "", "break", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"Error downloading {}\"", ".", "format", "(", "filename", ")", ")", "\n", "\n", "# check integrity of downloaded file", "\n", "", "if", "not", "_check_integrity", "(", "savegz", ",", "md5", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"File not found or corrupted.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._random_permutation": [[50, 55], ["numpy.random.permutation", "numpy.eye"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "_random_permutation", "(", "M", ")", ":", "\n", "# np.random.permutation permutes first axis only", "\n", "        ", "P", "=", "np", ".", "random", ".", "permutation", "(", "np", ".", "eye", "(", "M", ".", "shape", "[", "0", "]", ")", ")", "\n", "return", "P", ".", "T", "@", "M", "@", "P", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._random_acyclic_orientation": [[56, 61], ["numpy.tril", "simulator.DAG._random_permutation", "simulator.DAG._random_permutation"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._random_permutation", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._random_permutation"], ["", "@", "staticmethod", "\n", "def", "_random_acyclic_orientation", "(", "B_und", ")", ":", "\n", "        ", "B", "=", "np", ".", "tril", "(", "DAG", ".", "_random_permutation", "(", "B_und", ")", ",", "k", "=", "-", "1", ")", "\n", "B_perm", "=", "DAG", ".", "_random_permutation", "(", "B", ")", "\n", "return", "B_perm", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._graph_to_adjmat": [[62, 65], ["networkx.to_numpy_matrix"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_graph_to_adjmat", "(", "G", ")", ":", "\n", "        ", "return", "nx", ".", "to_numpy_matrix", "(", "G", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._BtoW": [[66, 72], ["numpy.random.uniform", "numpy.random.rand"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_BtoW", "(", "B", ",", "d", ",", "w_range", ")", ":", "\n", "        ", "U", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "w_range", "[", "0", "]", ",", "high", "=", "w_range", "[", "1", "]", ",", "size", "=", "[", "d", ",", "d", "]", ")", "\n", "U", "[", "np", ".", "random", ".", "rand", "(", "d", ",", "d", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "W", "=", "(", "B", "!=", "0", ")", ".", "astype", "(", "float", ")", "*", "U", "\n", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._low_rank_dag": [[73, 159], ["numpy.triu", "numpy.sum", "random.sample", "random.sample.sort", "list", "list", "numpy.sum", "set", "set", "set", "set", "numpy.transpose", "networkx.Graph", "networkx.Graph.add_nodes_from", "networkx.Graph.add_edges_from", "networkx.bipartite.maximum_matching", "numpy.array", "range", "numpy.zeros", "numpy.zeros", "copy.deepcopy.transpose", "float", "range", "set", "sampled_ch.append", "numpy.tril", "numpy.nonzero", "range", "len", "set", "networkx.Graph.remove_edge", "networkx.bipartite.maximum_matching", "len", "new_edges[].sort", "numpy.sum", "numpy.transpose", "numpy.array", "copy.deepcopy", "range", "set", "set", "set", "set", "set", "numpy.ix_", "numpy.ones", "numpy.ix_", "range", "networkx.bipartite.maximum_matching.keys", "random.sample", "numpy.nonzero", "RuntimeError", "random.sample", "random.sample", "range", "range", "range", "numpy.transpose.tolist", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["", "@", "staticmethod", "\n", "def", "_low_rank_dag", "(", "d", ",", "degree", ",", "rank", ")", ":", "\n", "        ", "\"\"\"\n        Simulate random low rank DAG with some expected degree.\n\n        Parameters\n        ----------\n        d: int\n            Number of nodes.\n        degree: int\n            Expected node degree, in + out.\n        rank: int\n            Maximum rank (rank < d-1).\n\n        Return\n        ------\n        B: np.nparray\n            Initialize DAG.\n        \"\"\"", "\n", "prob", "=", "float", "(", "degree", ")", "/", "(", "d", "-", "1", ")", "\n", "B", "=", "np", ".", "triu", "(", "(", "np", ".", "random", ".", "rand", "(", "d", ",", "d", ")", "<", "prob", ")", ".", "astype", "(", "float", ")", ",", "k", "=", "1", ")", "\n", "total_edge_num", "=", "np", ".", "sum", "(", "B", "==", "1", ")", "\n", "sampled_pa", "=", "sample", "(", "range", "(", "d", "-", "1", ")", ",", "rank", ")", "\n", "sampled_pa", ".", "sort", "(", "reverse", "=", "True", ")", "\n", "sampled_ch", "=", "[", "]", "\n", "for", "i", "in", "sampled_pa", ":", "\n", "            ", "candidate", "=", "set", "(", "range", "(", "i", "+", "1", ",", "d", ")", ")", "\n", "candidate", "=", "candidate", "-", "set", "(", "sampled_ch", ")", "\n", "sampled_ch", ".", "append", "(", "sample", "(", "candidate", ",", "1", ")", "[", "0", "]", ")", "\n", "B", "[", "i", ",", "sampled_ch", "[", "-", "1", "]", "]", "=", "1", "\n", "", "remaining_pa", "=", "list", "(", "set", "(", "range", "(", "d", ")", ")", "-", "set", "(", "sampled_pa", ")", ")", "\n", "remaining_ch", "=", "list", "(", "set", "(", "range", "(", "d", ")", ")", "-", "set", "(", "sampled_ch", ")", ")", "\n", "B", "[", "np", ".", "ix_", "(", "remaining_pa", ",", "remaining_ch", ")", "]", "=", "0", "\n", "after_matching_edge_num", "=", "np", ".", "sum", "(", "B", "==", "1", ")", "\n", "\n", "# delta = total_edge_num - after_matching_edge_num", "\n", "# mask B", "\n", "maskedB", "=", "B", "+", "np", ".", "tril", "(", "np", ".", "ones", "(", "(", "d", ",", "d", ")", ")", ")", "\n", "maskedB", "[", "np", ".", "ix_", "(", "remaining_pa", ",", "remaining_ch", ")", "]", "=", "1", "\n", "B", "[", "maskedB", "==", "0", "]", "=", "1", "\n", "\n", "remaining_ch_set", "=", "set", "(", "[", "i", "+", "d", "for", "i", "in", "remaining_ch", "]", ")", "\n", "sampled_ch_set", "=", "set", "(", "[", "i", "+", "d", "for", "i", "in", "sampled_ch", "]", ")", "\n", "remaining_pa_set", "=", "set", "(", "remaining_pa", ")", "\n", "sampled_pa_set", "=", "set", "(", "sampled_pa", ")", "\n", "\n", "edges", "=", "np", ".", "transpose", "(", "np", ".", "nonzero", "(", "B", ")", ")", "\n", "edges", "[", ":", ",", "1", "]", "+=", "d", "\n", "bigraph", "=", "nx", ".", "Graph", "(", ")", "\n", "bigraph", ".", "add_nodes_from", "(", "range", "(", "2", "*", "d", ")", ")", "\n", "bigraph", ".", "add_edges_from", "(", "edges", ")", "\n", "M", "=", "nx", ".", "bipartite", ".", "maximum_matching", "(", "bigraph", ",", "top_nodes", "=", "range", "(", "d", ")", ")", "\n", "while", "len", "(", "M", ")", ">", "2", "*", "rank", ":", "\n", "            ", "keys", "=", "set", "(", "M", ".", "keys", "(", ")", ")", "\n", "rmv_cand", "=", "keys", "&", "(", "remaining_pa_set", "|", "remaining_ch_set", ")", "\n", "p", "=", "sample", "(", "rmv_cand", ",", "1", ")", "[", "0", "]", "\n", "c", "=", "M", "[", "p", "]", "\n", "# destroy p-c", "\n", "bigraph", ".", "remove_edge", "(", "p", ",", "c", ")", "\n", "M", "=", "nx", ".", "bipartite", ".", "maximum_matching", "(", "bigraph", ",", "top_nodes", "=", "range", "(", "d", ")", ")", "\n", "\n", "", "new_edges", "=", "np", ".", "array", "(", "bigraph", ".", "edges", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "new_edges", ")", ")", ":", "\n", "            ", "new_edges", "[", "i", ",", "]", ".", "sort", "(", ")", "\n", "", "new_edges", "[", ":", ",", "1", "]", "-=", "d", "\n", "\n", "BB", "=", "np", ".", "zeros", "(", "(", "d", ",", "d", ")", ")", "\n", "B", "=", "np", ".", "zeros", "(", "(", "d", ",", "d", ")", ")", "\n", "BB", "[", "new_edges", "[", ":", ",", "0", "]", ",", "new_edges", "[", ":", ",", "1", "]", "]", "=", "1", "\n", "\n", "if", "np", ".", "sum", "(", "BB", "==", "1", ")", ">", "total_edge_num", ":", "\n", "            ", "delta", "=", "total_edge_num", "-", "rank", "\n", "BB", "[", "sampled_pa", ",", "sampled_ch", "]", "=", "0", "\n", "rmv_cand_edges", "=", "np", ".", "transpose", "(", "np", ".", "nonzero", "(", "BB", ")", ")", "\n", "if", "delta", "<=", "0", ":", "\n", "                ", "raise", "RuntimeError", "(", "r'Number of edges is below the rank, please \\\n                                   set a larger edge or degree \\\n                                   (you can change seed or increase degree).'", ")", "\n", "", "selected", "=", "np", ".", "array", "(", "sample", "(", "rmv_cand_edges", ".", "tolist", "(", ")", ",", "delta", ")", ")", "\n", "B", "[", "selected", "[", ":", ",", "0", "]", ",", "selected", "[", ":", ",", "1", "]", "]", "=", "1", "\n", "B", "[", "sampled_pa", ",", "sampled_ch", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "B", "=", "deepcopy", "(", "BB", ")", "\n", "\n", "", "B", "=", "B", ".", "transpose", "(", ")", "\n", "return", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG.erdos_renyi": [[160, 175], ["simulator.set_random_seed", "networkx.erdos_renyi_graph", "simulator.DAG._graph_to_adjmat", "simulator.DAG._random_acyclic_orientation", "simulator.DAG._BtoW"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.set_random_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._graph_to_adjmat", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._random_acyclic_orientation", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._BtoW"], ["", "@", "staticmethod", "\n", "def", "erdos_renyi", "(", "n_nodes", ",", "n_edges", ",", "weight_range", "=", "None", ",", "seed", "=", "None", ")", ":", "\n", "\n", "        ", "assert", "n_nodes", ">", "0", "\n", "set_random_seed", "(", "seed", ")", "\n", "# Erdos-Renyi", "\n", "creation_prob", "=", "(", "2", "*", "n_edges", ")", "/", "(", "n_nodes", "**", "2", ")", "\n", "G_und", "=", "nx", ".", "erdos_renyi_graph", "(", "n", "=", "n_nodes", ",", "p", "=", "creation_prob", ",", "seed", "=", "seed", ")", "\n", "B_und", "=", "DAG", ".", "_graph_to_adjmat", "(", "G_und", ")", "\n", "B", "=", "DAG", ".", "_random_acyclic_orientation", "(", "B_und", ")", "\n", "if", "weight_range", "is", "None", ":", "\n", "            ", "return", "B", "\n", "", "else", ":", "\n", "            ", "W", "=", "DAG", ".", "_BtoW", "(", "B", ",", "n_nodes", ",", "weight_range", ")", "\n", "", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG.scale_free": [[176, 191], ["simulator.set_random_seed", "int", "networkx.barabasi_albert_graph", "simulator.DAG._graph_to_adjmat", "simulator.DAG._random_acyclic_orientation", "round", "simulator.DAG._BtoW"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.set_random_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._graph_to_adjmat", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._random_acyclic_orientation", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._BtoW"], ["", "@", "staticmethod", "\n", "def", "scale_free", "(", "n_nodes", ",", "n_edges", ",", "weight_range", "=", "None", ",", "seed", "=", "None", ")", ":", "\n", "\n", "        ", "assert", "(", "n_nodes", ">", "0", "and", "n_edges", ">=", "n_nodes", "and", "n_edges", "<", "n_nodes", "*", "n_nodes", ")", "\n", "set_random_seed", "(", "seed", ")", "\n", "# Scale-free, Barabasi-Albert", "\n", "m", "=", "int", "(", "round", "(", "n_edges", "/", "n_nodes", ")", ")", "\n", "G_und", "=", "nx", ".", "barabasi_albert_graph", "(", "n", "=", "n_nodes", ",", "m", "=", "m", ")", "\n", "B_und", "=", "DAG", ".", "_graph_to_adjmat", "(", "G_und", ")", "\n", "B", "=", "DAG", ".", "_random_acyclic_orientation", "(", "B_und", ")", "\n", "if", "weight_range", "is", "None", ":", "\n", "            ", "return", "B", "\n", "", "else", ":", "\n", "            ", "W", "=", "DAG", ".", "_BtoW", "(", "B", ",", "n_nodes", ",", "weight_range", ")", "\n", "", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG.bipartite": [[192, 209], ["simulator.set_random_seed", "int", "networkx.algorithms.bipartite.random_graph", "simulator.DAG._graph_to_adjmat", "simulator.DAG._random_acyclic_orientation", "simulator.DAG._BtoW"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.set_random_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._graph_to_adjmat", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._random_acyclic_orientation", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._BtoW"], ["", "@", "staticmethod", "\n", "def", "bipartite", "(", "n_nodes", ",", "n_edges", ",", "split_ratio", "=", "0.2", ",", "weight_range", "=", "None", ",", "seed", "=", "None", ")", ":", "\n", "\n", "        ", "assert", "n_nodes", ">", "0", "\n", "set_random_seed", "(", "seed", ")", "\n", "# Bipartite, Sec 4.1 of (Gu, Fu, Zhou, 2018)", "\n", "n_top", "=", "int", "(", "split_ratio", "*", "n_nodes", ")", "\n", "n_bottom", "=", "n_nodes", "-", "n_top", "\n", "creation_prob", "=", "n_edges", "/", "(", "n_top", "*", "n_bottom", ")", "\n", "G_und", "=", "bipartite", ".", "random_graph", "(", "n_top", ",", "n_bottom", ",", "p", "=", "creation_prob", ",", "directed", "=", "True", ")", "\n", "B_und", "=", "DAG", ".", "_graph_to_adjmat", "(", "G_und", ")", "\n", "B", "=", "DAG", ".", "_random_acyclic_orientation", "(", "B_und", ")", "\n", "if", "weight_range", "is", "None", ":", "\n", "            ", "return", "B", "\n", "", "else", ":", "\n", "            ", "W", "=", "DAG", ".", "_BtoW", "(", "B", ",", "n_nodes", ",", "weight_range", ")", "\n", "", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG.hierarchical": [[210, 227], ["simulator.set_random_seed", "numpy.tril", "random.sample", "random.sample.sort", "range", "float", "range", "simulator.DAG._BtoW", "numpy.random.rand"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.set_random_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._BtoW"], ["", "@", "staticmethod", "\n", "def", "hierarchical", "(", "n_nodes", ",", "degree", "=", "5", ",", "graph_level", "=", "5", ",", "weight_range", "=", "None", ",", "seed", "=", "None", ")", ":", "\n", "\n", "        ", "assert", "n_nodes", ">", "1", "\n", "set_random_seed", "(", "seed", ")", "\n", "prob", "=", "float", "(", "degree", ")", "/", "(", "n_nodes", "-", "1", ")", "\n", "B", "=", "np", ".", "tril", "(", "(", "np", ".", "random", ".", "rand", "(", "n_nodes", ",", "n_nodes", ")", "<", "prob", ")", ".", "astype", "(", "float", ")", ",", "k", "=", "-", "1", ")", "\n", "point", "=", "sample", "(", "range", "(", "n_nodes", "-", "1", ")", ",", "graph_level", "-", "1", ")", "\n", "point", ".", "sort", "(", ")", "\n", "point", "=", "[", "0", "]", "+", "[", "x", "+", "1", "for", "x", "in", "point", "]", "+", "[", "n_nodes", "]", "\n", "for", "i", "in", "range", "(", "graph_level", ")", ":", "\n", "            ", "B", "[", "point", "[", "i", "]", ":", "point", "[", "i", "+", "1", "]", ",", "point", "[", "i", "]", ":", "point", "[", "i", "+", "1", "]", "]", "=", "0", "\n", "", "if", "weight_range", "is", "None", ":", "\n", "            ", "return", "B", "\n", "", "else", ":", "\n", "            ", "W", "=", "DAG", ".", "_BtoW", "(", "B", ",", "n_nodes", ",", "weight_range", ")", "\n", "", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG.low_rank": [[228, 239], ["simulator.set_random_seed", "simulator.DAG._low_rank_dag", "simulator.DAG._BtoW"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.set_random_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._low_rank_dag", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.DAG._BtoW"], ["", "@", "staticmethod", "\n", "def", "low_rank", "(", "n_nodes", ",", "degree", "=", "1", ",", "rank", "=", "5", ",", "weight_range", "=", "None", ",", "seed", "=", "None", ")", ":", "\n", "\n", "        ", "assert", "n_nodes", ">", "0", "\n", "set_random_seed", "(", "seed", ")", "\n", "B", "=", "DAG", ".", "_low_rank_dag", "(", "n_nodes", ",", "degree", ",", "rank", ")", "\n", "if", "weight_range", "is", "None", ":", "\n", "            ", "return", "B", "\n", "", "else", ":", "\n", "            ", "W", "=", "DAG", ".", "_BtoW", "(", "B", ",", "n_nodes", ",", "weight_range", ")", "\n", "", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.IIDSimulation.__init__": [[260, 271], ["logging.info", "simulator.IIDSimulation._simulate_linear_sem", "simulator.IIDSimulation._simulate_nonlinear_sem"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.IIDSimulation._simulate_linear_sem", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.IIDSimulation._simulate_nonlinear_sem"], ["def", "__init__", "(", "self", ",", "W", ",", "n", "=", "1000", ",", "method", "=", "'linear'", ",", "\n", "sem_type", "=", "'gauss'", ",", "noise_scale", "=", "1.0", ")", ":", "\n", "\n", "        ", "self", ".", "B", "=", "(", "W", "!=", "0", ")", ".", "astype", "(", "int", ")", "\n", "if", "method", "==", "'linear'", ":", "\n", "            ", "self", ".", "X", "=", "IIDSimulation", ".", "_simulate_linear_sem", "(", "\n", "W", ",", "n", ",", "sem_type", ",", "noise_scale", ")", "\n", "", "elif", "method", "==", "'nonlinear'", ":", "\n", "            ", "self", ".", "X", "=", "IIDSimulation", ".", "_simulate_nonlinear_sem", "(", "\n", "W", ",", "n", ",", "sem_type", ",", "noise_scale", ")", "\n", "", "logging", ".", "info", "(", "'Finished synthetic dataset'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.IIDSimulation._simulate_linear_sem": [[272, 343], ["networkx.from_numpy_matrix", "numpy.isinf", "list", "numpy.zeros", "numpy.ones", "numpy.isscalar", "networkx.is_directed_acyclic_graph", "ValueError", "networkx.topological_sort", "len", "list", "simulator.IIDSimulation._simulate_linear_sem._simulate_single_equation"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_simulate_linear_sem", "(", "W", ",", "n", ",", "sem_type", ",", "noise_scale", ")", ":", "\n", "        ", "\"\"\"\n        Simulate samples from linear SEM with specified type of noise.\n        For uniform, noise z ~ uniform(-a, a), where a = noise_scale.\n\n        Parameters\n        ----------\n        W: np.ndarray\n            [d, d] weighted adj matrix of DAG.\n        n: int\n            Number of samples, n=inf mimics population risk.\n        sem_type: str \n            gauss, exp, gumbel, uniform, logistic.\n        noise_scale: float \n            Scale parameter of noise distribution in linear SEM.\n        \n        Return\n        ------\n        X: np.ndarray\n            [n, d] sample matrix, [d, d] if n=inf\n        \"\"\"", "\n", "def", "_simulate_single_equation", "(", "X", ",", "w", ",", "scale", ")", ":", "\n", "            ", "\"\"\"X: [n, num of parents], w: [num of parents], x: [n]\"\"\"", "\n", "if", "sem_type", "==", "'gauss'", ":", "\n", "                ", "z", "=", "np", ".", "random", ".", "normal", "(", "scale", "=", "scale", ",", "size", "=", "n", ")", "\n", "x", "=", "X", "@", "w", "+", "z", "\n", "", "elif", "sem_type", "==", "'exp'", ":", "\n", "                ", "z", "=", "np", ".", "random", ".", "exponential", "(", "scale", "=", "scale", ",", "size", "=", "n", ")", "\n", "x", "=", "X", "@", "w", "+", "z", "\n", "", "elif", "sem_type", "==", "'gumbel'", ":", "\n", "                ", "z", "=", "np", ".", "random", ".", "gumbel", "(", "scale", "=", "scale", ",", "size", "=", "n", ")", "\n", "x", "=", "X", "@", "w", "+", "z", "\n", "", "elif", "sem_type", "==", "'uniform'", ":", "\n", "                ", "z", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "scale", ",", "high", "=", "scale", ",", "size", "=", "n", ")", "\n", "x", "=", "X", "@", "w", "+", "z", "\n", "", "elif", "sem_type", "==", "'logistic'", ":", "\n", "                ", "x", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "sigmoid", "(", "X", "@", "w", ")", ")", "*", "1.0", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown sem type. In a linear model, \\\n                                 the options are as follows: gauss, exp, \\\n                                 gumbel, uniform, logistic.'", ")", "\n", "", "return", "x", "\n", "\n", "", "d", "=", "W", ".", "shape", "[", "0", "]", "\n", "if", "noise_scale", "is", "None", ":", "\n", "            ", "scale_vec", "=", "np", ".", "ones", "(", "d", ")", "\n", "", "elif", "np", ".", "isscalar", "(", "noise_scale", ")", ":", "\n", "            ", "scale_vec", "=", "noise_scale", "*", "np", ".", "ones", "(", "d", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "noise_scale", ")", "!=", "d", ":", "\n", "                ", "raise", "ValueError", "(", "'noise scale must be a scalar or has length d'", ")", "\n", "", "scale_vec", "=", "noise_scale", "\n", "", "G_nx", "=", "nx", ".", "from_numpy_matrix", "(", "W", ",", "create_using", "=", "nx", ".", "DiGraph", ")", "\n", "if", "not", "nx", ".", "is_directed_acyclic_graph", "(", "G_nx", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'W must be a DAG'", ")", "\n", "", "if", "np", ".", "isinf", "(", "n", ")", ":", "# population risk for linear gauss SEM", "\n", "            ", "if", "sem_type", "==", "'gauss'", ":", "\n", "# make 1/d X'X = true cov", "\n", "                ", "X", "=", "np", ".", "sqrt", "(", "d", ")", "*", "np", ".", "diag", "(", "scale_vec", ")", "@", "np", ".", "linalg", ".", "inv", "(", "np", ".", "eye", "(", "d", ")", "-", "W", ")", "\n", "return", "X", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'population risk not available'", ")", "\n", "# empirical risk", "\n", "", "", "ordered_vertices", "=", "list", "(", "nx", ".", "topological_sort", "(", "G_nx", ")", ")", "\n", "assert", "len", "(", "ordered_vertices", ")", "==", "d", "\n", "X", "=", "np", ".", "zeros", "(", "[", "n", ",", "d", "]", ")", "\n", "for", "j", "in", "ordered_vertices", ":", "\n", "            ", "parents", "=", "list", "(", "G_nx", ".", "predecessors", "(", "j", ")", ")", "\n", "X", "[", ":", ",", "j", "]", "=", "_simulate_single_equation", "(", "X", "[", ":", ",", "parents", "]", ",", "W", "[", "parents", ",", "j", "]", ",", "scale_vec", "[", "j", "]", ")", "\n", "", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.IIDSimulation._simulate_nonlinear_sem": [[344, 423], ["numpy.zeros", "networkx.from_numpy_matrix", "list", "simulator.IIDSimulation._simulate_quad_sem", "numpy.random.normal", "numpy.ones", "numpy.isscalar", "networkx.topological_sort", "len", "list", "simulator.IIDSimulation._simulate_linear_sem._simulate_single_equation"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.IIDSimulation._simulate_quad_sem"], ["", "@", "staticmethod", "\n", "def", "_simulate_nonlinear_sem", "(", "W", ",", "n", ",", "sem_type", ",", "noise_scale", ")", ":", "\n", "        ", "\"\"\"\n        Simulate samples from nonlinear SEM.\n\n        Parameters\n        ----------\n        B: np.ndarray\n            [d, d] binary adj matrix of DAG.\n        n: int\n            Number of samples.\n        sem_type: str\n            mlp, mim, gp, gp-add, or quadratic.\n        noise_scale: float\n            Scale parameter of noise distribution in linear SEM.\n\n        Return\n        ------\n        X: np.ndarray\n            [n, d] sample matrix\n        \"\"\"", "\n", "if", "sem_type", "==", "'quadratic'", ":", "\n", "            ", "return", "IIDSimulation", ".", "_simulate_quad_sem", "(", "W", ",", "n", ",", "noise_scale", ")", "\n", "\n", "", "def", "_simulate_single_equation", "(", "X", ",", "scale", ")", ":", "\n", "            ", "\"\"\"X: [n, num of parents], x: [n]\"\"\"", "\n", "z", "=", "np", ".", "random", ".", "normal", "(", "scale", "=", "scale", ",", "size", "=", "n", ")", "\n", "pa_size", "=", "X", ".", "shape", "[", "1", "]", "\n", "if", "pa_size", "==", "0", ":", "\n", "                ", "return", "z", "\n", "", "if", "sem_type", "==", "'mlp'", ":", "\n", "                ", "hidden", "=", "100", "\n", "W1", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ",", "size", "=", "[", "pa_size", ",", "hidden", "]", ")", "\n", "W1", "[", "np", ".", "random", ".", "rand", "(", "*", "W1", ".", "shape", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "W2", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ",", "size", "=", "hidden", ")", "\n", "W2", "[", "np", ".", "random", ".", "rand", "(", "hidden", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "x", "=", "sigmoid", "(", "X", "@", "W1", ")", "@", "W2", "+", "z", "\n", "", "elif", "sem_type", "==", "'mim'", ":", "\n", "                ", "w1", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ",", "size", "=", "pa_size", ")", "\n", "w1", "[", "np", ".", "random", ".", "rand", "(", "pa_size", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "w2", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ",", "size", "=", "pa_size", ")", "\n", "w2", "[", "np", ".", "random", ".", "rand", "(", "pa_size", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "w3", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "2.0", ",", "size", "=", "pa_size", ")", "\n", "w3", "[", "np", ".", "random", ".", "rand", "(", "pa_size", ")", "<", "0.5", "]", "*=", "-", "1", "\n", "x", "=", "np", ".", "tanh", "(", "X", "@", "w1", ")", "+", "np", ".", "cos", "(", "X", "@", "w2", ")", "+", "np", ".", "sin", "(", "X", "@", "w3", ")", "+", "z", "\n", "", "elif", "sem_type", "==", "'gp'", ":", "\n", "                ", "from", "sklearn", ".", "gaussian_process", "import", "GaussianProcessRegressor", "\n", "gp", "=", "GaussianProcessRegressor", "(", ")", "\n", "x", "=", "gp", ".", "sample_y", "(", "X", ",", "random_state", "=", "None", ")", ".", "flatten", "(", ")", "+", "z", "\n", "", "elif", "sem_type", "==", "'gp-add'", ":", "\n", "                ", "from", "sklearn", ".", "gaussian_process", "import", "GaussianProcessRegressor", "\n", "gp", "=", "GaussianProcessRegressor", "(", ")", "\n", "x", "=", "sum", "(", "[", "gp", ".", "sample_y", "(", "X", "[", ":", ",", "i", ",", "None", "]", ",", "random_state", "=", "None", ")", ".", "flatten", "(", ")", "\n", "for", "i", "in", "range", "(", "X", ".", "shape", "[", "1", "]", ")", "]", ")", "+", "z", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown sem type. In a nonlinear model, \\\n                                 the options are as follows: mlp, mim, \\\n                                 gp, gp-add, or quadratic.'", ")", "\n", "", "return", "x", "\n", "\n", "", "B", "=", "(", "W", "!=", "0", ")", ".", "astype", "(", "int", ")", "\n", "d", "=", "B", ".", "shape", "[", "0", "]", "\n", "if", "noise_scale", "is", "None", ":", "\n", "            ", "scale_vec", "=", "np", ".", "ones", "(", "d", ")", "\n", "", "elif", "np", ".", "isscalar", "(", "noise_scale", ")", ":", "\n", "            ", "scale_vec", "=", "noise_scale", "*", "np", ".", "ones", "(", "d", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "noise_scale", ")", "!=", "d", ":", "\n", "                ", "raise", "ValueError", "(", "'noise scale must be a scalar or has length d'", ")", "\n", "", "scale_vec", "=", "noise_scale", "\n", "\n", "", "X", "=", "np", ".", "zeros", "(", "[", "n", ",", "d", "]", ")", "\n", "G_nx", "=", "nx", ".", "from_numpy_matrix", "(", "B", ",", "create_using", "=", "nx", ".", "DiGraph", ")", "\n", "ordered_vertices", "=", "list", "(", "nx", ".", "topological_sort", "(", "G_nx", ")", ")", "\n", "assert", "len", "(", "ordered_vertices", ")", "==", "d", "\n", "for", "j", "in", "ordered_vertices", ":", "\n", "            ", "parents", "=", "list", "(", "G_nx", ".", "predecessors", "(", "j", ")", ")", "\n", "X", "[", ":", ",", "j", "]", "=", "_simulate_single_equation", "(", "X", "[", ":", ",", "parents", "]", ",", "scale_vec", "[", "j", "]", ")", "\n", "", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.IIDSimulation._simulate_quad_sem": [[424, 531], ["networkx.DiGraph", "numpy.zeros", "list", "networkx.topological_sort", "len", "list", "numpy.random.randint", "numpy.random.uniform", "numpy.random.randint", "networkx.DiGraph.predecessors", "len", "numpy.zeros", "numpy.random.normal", "len", "numpy.zeros", "set", "simulator.IIDSimulation._simulate_quad_sem.generate_quadratic_coef"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_simulate_quad_sem", "(", "W", ",", "n", ",", "noise_scale", ")", ":", "\n", "        ", "\"\"\"\n        Simulate samples from SEM with specified type of noise.\n        Coefficient is randomly drawn but specifically designed \n        to avoid overflow issues.\n\n        Parameters\n        ----------\n        W: np.ndarray\n            weigthed DAG.\n        n: int\n            Number of samples.\n        noise_scale: float\n            Scale parameter of noise distribution in linear SEM.\n\n        Return\n        ------\n        X: np.ndarray\n            [n,d] sample matrix\n        \"\"\"", "\n", "def", "generate_quadratic_coef", "(", "random_zero", "=", "True", ")", ":", "\n", "            ", "if", "random_zero", "and", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "2", ")", ":", "\n", "                ", "return", "0", "\n", "", "else", ":", "\n", "                ", "coef", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.5", ",", "high", "=", "1", ")", "\n", "if", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "2", ")", ":", "\n", "                    ", "coef", "*=", "-", "1", "\n", "", "return", "coef", "\n", "\n", "", "", "G", "=", "nx", ".", "DiGraph", "(", "W", ")", "\n", "d", "=", "W", ".", "shape", "[", "0", "]", "\n", "X", "=", "np", ".", "zeros", "(", "[", "n", ",", "d", "]", ")", "\n", "ordered_vertices", "=", "list", "(", "nx", ".", "topological_sort", "(", "G", ")", ")", "\n", "assert", "len", "(", "ordered_vertices", ")", "==", "d", "\n", "for", "j", "in", "ordered_vertices", ":", "\n", "            ", "parents", "=", "list", "(", "G", ".", "predecessors", "(", "j", ")", ")", "\n", "\n", "if", "len", "(", "parents", ")", "==", "0", ":", "\n", "                ", "eta", "=", "np", ".", "zeros", "(", "[", "n", "]", ")", "\n", "", "elif", "len", "(", "parents", ")", "==", "1", ":", "\n", "# We don't generate random zero coefficient if there is only one parent", "\n", "                ", "eta", "=", "np", ".", "zeros", "(", "[", "n", "]", ")", "\n", "used_parents", "=", "set", "(", ")", "\n", "p", "=", "parents", "[", "0", "]", "\n", "num_terms", "=", "0", "\n", "\n", "# Linear term", "\n", "coef", "=", "generate_quadratic_coef", "(", "random_zero", "=", "False", ")", "\n", "if", "coef", "!=", "0", ":", "\n", "                    ", "eta", "+=", "coef", "*", "X", "[", ":", ",", "p", "]", "\n", "used_parents", ".", "add", "(", "p", ")", "\n", "num_terms", "+=", "1", "\n", "\n", "# Squared term", "\n", "", "coef", "=", "generate_quadratic_coef", "(", "random_zero", "=", "False", ")", "\n", "if", "coef", "!=", "0", ":", "\n", "                    ", "eta", "+=", "coef", "*", "np", ".", "square", "(", "X", "[", ":", ",", "p", "]", ")", "\n", "used_parents", ".", "add", "(", "p", ")", "\n", "num_terms", "+=", "1", "\n", "\n", "", "if", "num_terms", ">", "0", ":", "\n", "                    ", "eta", "/=", "num_terms", "# Compute average", "\n", "\n", "# Remove parent if both coef is zero", "\n", "", "if", "p", "not", "in", "used_parents", ":", "\n", "                    ", "W", "[", "p", ",", "j", "]", "=", "0", "\n", "", "", "else", ":", "# More than 1 parent", "\n", "                ", "eta", "=", "np", ".", "zeros", "(", "[", "n", "]", ")", "\n", "used_parents", "=", "set", "(", ")", "\n", "num_terms", "=", "0", "\n", "\n", "for", "p", "in", "parents", ":", "\n", "# Linear terms", "\n", "                    ", "coef", "=", "generate_quadratic_coef", "(", "random_zero", "=", "True", ")", "\n", "if", "coef", ">", "0", ":", "\n", "                        ", "eta", "+=", "coef", "*", "X", "[", ":", ",", "p", "]", "\n", "used_parents", ".", "add", "(", "p", ")", "\n", "num_terms", "+=", "1", "\n", "\n", "# Squared terms", "\n", "", "coef", "=", "generate_quadratic_coef", "(", "random_zero", "=", "True", ")", "\n", "if", "coef", ">", "0", ":", "\n", "                        ", "eta", "+=", "coef", "*", "np", ".", "square", "(", "X", "[", ":", ",", "p", "]", ")", "\n", "used_parents", ".", "add", "(", "p", ")", "\n", "num_terms", "+=", "1", "\n", "\n", "# Cross terms", "\n", "", "", "for", "p1", ",", "p2", "in", "combinations", "(", "parents", ",", "2", ")", ":", "\n", "                    ", "coef", "=", "generate_quadratic_coef", "(", "random_zero", "=", "True", ")", "\n", "if", "coef", ">", "0", ":", "\n", "                        ", "eta", "+=", "coef", "*", "X", "[", ":", ",", "p1", "]", "*", "X", "[", ":", ",", "p2", "]", "\n", "used_parents", ".", "add", "(", "p1", ")", "\n", "used_parents", ".", "add", "(", "p2", ")", "\n", "num_terms", "+=", "1", "\n", "\n", "", "", "if", "num_terms", ">", "0", ":", "\n", "                    ", "eta", "/=", "num_terms", "# Compute average", "\n", "\n", "# Remove parent if both coef is zero", "\n", "", "unused_parents", "=", "set", "(", "parents", ")", "-", "used_parents", "\n", "if", "p", "in", "unused_parents", ":", "\n", "                    ", "W", "[", "p", ",", "j", "]", "=", "0", "\n", "\n", "", "", "X", "[", ":", ",", "j", "]", "=", "eta", "+", "np", ".", "random", ".", "normal", "(", "scale", "=", "noise_scale", ",", "size", "=", "n", ")", "\n", "\n", "", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.Topology.erdos_renyi": [[542, 565], ["networkx.erdos_renyi_graph", "networkx.to_numpy_matrix"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "erdos_renyi", "(", "n_nodes", ",", "n_edges", ",", "seed", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Generate topology matrix\n\n        Parameters\n        ----------\n        n_nodes : int, greater than 0\n            The number of nodes.\n        n_edges : int, greater than 0\n            Use to calculate probability for edge creation.\n        seed : integer, random_state, or None (default)\n            Indicator of random number generation state.\n\n        Returns\n        -------\n        B: np.matrix\n        \"\"\"", "\n", "assert", "n_nodes", ">", "0", ",", "'The number of nodes must be greater than 0.'", "\n", "creation_prob", "=", "(", "2", "*", "n_edges", ")", "/", "(", "n_nodes", "**", "2", ")", "\n", "G", "=", "nx", ".", "erdos_renyi_graph", "(", "n", "=", "n_nodes", ",", "p", "=", "creation_prob", ",", "seed", "=", "seed", ")", "\n", "B", "=", "nx", ".", "to_numpy_matrix", "(", "G", ")", "\n", "return", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.THPSimulation.__init__": [[583, 602], ["networkx.from_numpy_matrix", "isinstance", "isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "causal_matrix", ",", "topology_matrix", ",", "\n", "mu_range", "=", "(", "0.00005", ",", "0.0001", ")", ",", "alpha_range", "=", "(", "0.005", ",", "0.007", ")", ")", ":", "\n", "\n", "        ", "assert", "(", "isinstance", "(", "causal_matrix", ",", "np", ".", "ndarray", ")", "and", "\n", "causal_matrix", ".", "ndim", "==", "2", "and", "\n", "causal_matrix", ".", "shape", "[", "0", "]", "==", "causal_matrix", ".", "shape", "[", "1", "]", ")", ",", "'casual_matrix should be np.matrix object, two dimension, square.'", "\n", "assert", "(", "isinstance", "(", "topology_matrix", ",", "np", ".", "ndarray", ")", "and", "\n", "topology_matrix", ".", "ndim", "==", "2", "and", "\n", "topology_matrix", ".", "shape", "[", "0", "]", "==", "topology_matrix", ".", "shape", "[", "1", "]", ")", ",", "'topology_matrix should be np.matrix object, two dimension, square.'", "\n", "\n", "self", ".", "_causal_matrix", "=", "(", "causal_matrix", "!=", "0", ")", ".", "astype", "(", "int", ")", "\n", "\n", "self", ".", "_topo", "=", "nx", ".", "from_numpy_matrix", "(", "topology_matrix", ",", "\n", "create_using", "=", "nx", ".", "Graph", ")", "\n", "\n", "self", ".", "_mu_range", "=", "mu_range", "\n", "self", ".", "_alpha_range", "=", "alpha_range", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.THPSimulation.simulate": [[603, 646], ["numpy.random.uniform", "numpy.random.uniform", "dict", "dict.copy", "dict.copy", "dict.copy.items", "pandas.concat", "numpy.ones", "simulator.THPSimulation._trigger_events", "sum", "dict", "tqdm.tqdm.tqdm", "pandas.DataFrame", "pandas.DataFrame.insert", "Xn_list.append", "map", "range", "pandas.DataFrame.reindex", "dict.copy.values", "simulator.THPSimulation._get_k_hop_neighbors", "simulator.THPSimulation._trigger_events"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.THPSimulation._trigger_events", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.THPSimulation._get_k_hop_neighbors", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.THPSimulation._trigger_events"], ["", "def", "simulate", "(", "self", ",", "T", ",", "max_hop", "=", "1", ",", "beta", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        Generate simulation data.\n        \"\"\"", "\n", "N", "=", "self", ".", "_causal_matrix", ".", "shape", "[", "0", "]", "\n", "\n", "mu", "=", "np", ".", "random", ".", "uniform", "(", "*", "self", ".", "_mu_range", ",", "N", ")", "\n", "\n", "alpha", "=", "np", ".", "random", ".", "uniform", "(", "*", "self", ".", "_alpha_range", ",", "[", "N", ",", "N", "]", ")", "\n", "alpha", "=", "alpha", "*", "self", ".", "_causal_matrix", "\n", "alpha", "=", "np", ".", "ones", "(", "[", "max_hop", "+", "1", ",", "N", ",", "N", "]", ")", "*", "alpha", "\n", "\n", "immigrant_events", "=", "dict", "(", ")", "\n", "for", "node", "in", "self", ".", "_topo", ".", "nodes", ":", "\n", "            ", "immigrant_events", "[", "node", "]", "=", "self", ".", "_trigger_events", "(", "mu", ",", "0", ",", "T", ",", "beta", ")", "\n", "\n", "", "base_events", "=", "immigrant_events", ".", "copy", "(", ")", "\n", "events", "=", "immigrant_events", ".", "copy", "(", ")", "\n", "while", "sum", "(", "map", "(", "len", ",", "base_events", ".", "values", "(", ")", ")", ")", "!=", "0", ":", "\n", "            ", "offspring_events", "=", "dict", "(", ")", "\n", "for", "node", "in", "tqdm", "(", "self", ".", "_topo", ".", "nodes", ")", ":", "\n", "                ", "offspring_events", "[", "node", "]", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "max_hop", "+", "1", ")", ":", "\n", "                    ", "k_base_events", "=", "[", "]", "\n", "for", "neighbor", "in", "self", ".", "_get_k_hop_neighbors", "(", "\n", "self", ".", "_topo", ",", "node", ",", "k", ")", ":", "\n", "                        ", "k_base_events", "+=", "base_events", "[", "neighbor", "]", "\n", "", "k_new_events", "=", "[", "self", ".", "_trigger_events", "(", "\n", "alpha", "[", "k", ",", "i", "]", ",", "start_time", ",", "duration", ",", "beta", ")", "\n", "for", "(", "i", ",", "start_time", ",", "duration", ")", "in", "k_base_events", "]", "\n", "for", "event_group", "in", "k_new_events", ":", "\n", "                        ", "offspring_events", "[", "node", "]", "+=", "event_group", "\n", "", "", "events", "[", "node", "]", "+=", "offspring_events", "[", "node", "]", "\n", "", "base_events", "=", "offspring_events", "\n", "\n", "", "Xn_list", "=", "[", "]", "\n", "for", "node", ",", "event_group", "in", "events", ".", "items", "(", ")", ":", "\n", "            ", "Xn", "=", "pd", ".", "DataFrame", "(", "event_group", ",", "\n", "columns", "=", "[", "'event'", ",", "'timestamp'", ",", "'duration'", "]", ")", "\n", "Xn", ".", "insert", "(", "0", ",", "'node'", ",", "node", ")", "\n", "Xn_list", ".", "append", "(", "Xn", ".", "reindex", "(", "columns", "=", "[", "'event'", ",", "'timestamp'", ",", "'node'", "]", ")", ")", "\n", "", "X", "=", "pd", ".", "concat", "(", "Xn_list", ",", "sort", "=", "False", ",", "ignore_index", "=", "True", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.THPSimulation._trigger_events": [[647, 662], ["enumerate", "round", "numpy.max().round", "events.append", "numpy.random.exponential", "numpy.max", "numpy.random.exponential"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_trigger_events", "(", "intensity_vec", ",", "start_time", ",", "duration", ",", "beta", ")", ":", "\n", "\n", "        ", "events", "=", "[", "]", "\n", "for", "i", ",", "intensity", "in", "enumerate", "(", "intensity_vec", ")", ":", "\n", "            ", "if", "intensity", ":", "\n", "                ", "trigger_time", "=", "start_time", "\n", "while", "True", ":", "\n", "                    ", "trigger_time", "=", "round", "(", "trigger_time", "+", "np", ".", "random", ".", "exponential", "(", "\n", "1", "/", "intensity", ")", ")", "\n", "if", "trigger_time", ">", "start_time", "+", "duration", ":", "\n", "                        ", "break", "\n", "", "sub_duration", "=", "(", "np", ".", "max", "(", "(", "0", ",", "np", ".", "random", ".", "exponential", "(", "beta", ")", ")", ")", ")", ".", "round", "(", ")", "\n", "events", ".", "append", "(", "(", "i", ",", "trigger_time", ",", "sub_duration", ")", ")", "\n", "", "", "", "return", "events", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.THPSimulation._get_k_hop_neighbors": [[663, 671], ["set", "set", "networkx.single_source_dijkstra_path_length().keys", "networkx.single_source_dijkstra_path_length().keys", "networkx.single_source_dijkstra_path_length", "networkx.single_source_dijkstra_path_length"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_k_hop_neighbors", "(", "G", ",", "node", ",", "k", ")", ":", "\n", "        ", "if", "k", "==", "0", ":", "\n", "            ", "return", "{", "node", "}", "\n", "", "else", ":", "\n", "            ", "return", "(", "set", "(", "nx", ".", "single_source_dijkstra_path_length", "(", "G", ",", "node", ",", "k", ")", ".", "keys", "(", ")", ")", "\n", "-", "set", "(", "nx", ".", "single_source_dijkstra_path_length", "(", "\n", "G", ",", "node", ",", "k", "-", "1", ")", ".", "keys", "(", ")", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.set_random_seed": [[37, 40], ["random.seed", "numpy.random.seed"], "function", ["None"], ["def", "set_random_seed", "(", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.loader.load_dataset": [[19, 53], ["loader.load", "builtin_dataset.DataSetRegistry.meta.keys", "ValueError", "builtin_dataset.DataSetRegistry.meta.get"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.RealDataSet.load"], ["def", "load_dataset", "(", "name", "=", "'IID_Test'", ",", "root", "=", "None", ",", "download", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    A function for loading some well-known datasets.\n\n    Parameters\n    ----------\n    name: class, default='IID_Test'\n        Dataset name, independent and identically distributed (IID),\n        Topological Hawkes Process (THP) and real datasets.\n    root: str\n        Root directory in which the dataset will be saved.\n    download: bool\n        If true, downloads the dataset from the internet and\n        puts it in root directory. If dataset is already downloaded, it is not\n        downloaded again.\n\n    Return\n    ------\n    out: tuple\n        true_graph_matrix: numpy.matrix\n            adjacency matrix for the target causal graph.\n        topology_matrix: numpy.matrix\n            adjacency matrix for the topology.\n        data: pandas.core.frame.DataFrame\n            standard trainning dataset.\n    \"\"\"", "\n", "\n", "if", "name", "not", "in", "DataSetRegistry", ".", "meta", ".", "keys", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'The dataset {} has not been registered, you can use'", "\n", "' '", "'castle.datasets.__builtin_dataset__'", "' to get registered '", "\n", "'dataset list'", ".", "format", "(", "name", ")", ")", "\n", "", "loader", "=", "DataSetRegistry", ".", "meta", ".", "get", "(", "name", ")", "(", ")", "\n", "loader", ".", "load", "(", "root", ",", "download", ")", "\n", "return", "loader", ".", "data", ",", "loader", ".", "true_graph_matrix", ",", "loader", ".", "topology_matrix", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.notears.low_rank.NotearsLowRank.__init__": [[67, 77], ["castle.common.BaseLearner.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "w_init", "=", "None", ",", "max_iter", "=", "15", ",", "h_tol", "=", "1e-6", ",", "\n", "rho_max", "=", "1e+20", ",", "w_threshold", "=", "0.3", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "w_init", "=", "w_init", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "self", ".", "h_tol", "=", "h_tol", "\n", "self", ".", "rho_max", "=", "rho_max", "\n", "self", ".", "w_threshold", "=", "w_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.notears.low_rank.NotearsLowRank.learn": [[78, 121], ["castle.common.Tensor", "castle.common.Tensor", "castle.common.Tensor", "low_rank.NotearsLowRank.notears_low_rank", "numpy.zeros", "numpy.random.uniform", "print", "abs"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.notears.low_rank.NotearsLowRank.notears_low_rank"], ["", "def", "learn", "(", "self", ",", "data", ",", "rank", ",", "columns", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Set up and run the NotearsLowRank algorithm.\n\n        Parameters\n        ----------\n        data: castle.Tensor or numpy.ndarray\n            The castle.Tensor or numpy.ndarray format data you want to learn.\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        rank: int\n            The rank of data.\n        \"\"\"", "\n", "X", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "n", ",", "d", "=", "X", ".", "shape", "\n", "random_cnt", "=", "0", "\n", "total_cnt", "=", "0", "\n", "while", "total_cnt", "<=", "20", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "total_cnt", "==", "0", ":", "\n", "                    ", "w_init_", "=", "np", ".", "zeros", "(", "(", "d", ",", "d", ")", ")", "\n", "", "else", ":", "\n", "                    ", "w_init_", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.3", ",", "0.3", ",", "(", "d", ",", "d", ")", ")", "\n", "\n", "", "w_est2", "=", "self", ".", "notears_low_rank", "(", "X", ",", "rank", ",", "w_init_", ")", "\n", "causal_matrix", "=", "(", "abs", "(", "w_est2", ")", ">", "self", ".", "w_threshold", ")", ".", "astype", "(", "int", ")", "\n", "\n", "random_cnt", "+=", "1", "\n", "total_cnt", "+=", "1", "\n", "if", "random_cnt", ">=", "1", ":", "\n", "                    ", "break", "\n", "\n", "", "", "except", "ValueError", ":", "\n", "                ", "print", "(", "total_cnt", ",", "'NAN error'", ")", "\n", "total_cnt", "+=", "1", "\n", "\n", "", "", "self", ".", "weight_causal_matrix", "=", "Tensor", "(", "w_est2", ",", "\n", "index", "=", "X", ".", "columns", ",", "\n", "columns", "=", "X", ".", "columns", ")", "\n", "self", ".", "causal_matrix", "=", "Tensor", "(", "causal_matrix", ",", "index", "=", "X", ".", "columns", ",", "\n", "columns", "=", "X", ".", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.notears.low_rank.NotearsLowRank.notears_low_rank": [[122, 251], ["numpy.linalg.svd", "u[].dot().reshape", "vt[].transpose().reshape", "numpy.hstack", "numpy.copy", "logging.info", "range", "numpy.copy", "numpy.matmul", "w_est2.reshape.reshape.reshape", "logging.info", "len", "u.reshape.reshape.reshape", "v.reshape.reshape.reshape", "numpy.matmul", "low_rank.NotearsLowRank.notears_low_rank._h"], "methods", ["None"], ["", "def", "notears_low_rank", "(", "self", ",", "X", ",", "rank", ",", "w_init", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Solve min_W ell(W; X) s.t. h(W) = 0 using augmented Lagrangian.\n\n        Parameters\n        ----------\n        X: [n,d] sample matrix\n            max_iter: max number of dual ascent steps.\n        rank: int\n            The rank of data.\n        w_init: None or numpy.ndarray\n            Initialized weight matrix\n\n        Return\n        ------\n        W_est: np.ndarray\n            estimate [d,d] dag matrix\n        \"\"\"", "\n", "def", "_h", "(", "W", ")", ":", "\n", "            ", "return", "np", ".", "trace", "(", "slin", ".", "expm", "(", "W", "*", "W", ")", ")", "-", "d", "\n", "\n", "", "def", "_func", "(", "uv", ")", ":", "\n", "# L = 0.5/n * || X (I - UV) ||_F^2 + rho/2*h^2 + alpha*h", "\n", "            ", "nn", "=", "len", "(", "uv", ")", "\n", "u", "=", "uv", "[", "0", ":", "nn", "//", "2", "]", "\n", "u", "=", "u", ".", "reshape", "(", "(", "d", ",", "-", "1", ")", ")", "\n", "v", "=", "uv", "[", "nn", "//", "2", ":", "]", "\n", "v", "=", "v", ".", "reshape", "(", "(", "d", ",", "-", "1", ")", ")", "\n", "W", "=", "np", ".", "matmul", "(", "u", ",", "v", ".", "transpose", "(", ")", ")", "\n", "loss", "=", "0.5", "/", "n", "*", "np", ".", "square", "(", "np", ".", "linalg", ".", "norm", "(", "X", ".", "dot", "(", "np", ".", "eye", "(", "d", ",", "d", ")", "-", "W", ")", ",", "'fro'", ")", ")", "\n", "h", "=", "_h", "(", "W", ")", "\n", "return", "loss", "+", "0.5", "*", "rho", "*", "h", "*", "h", "+", "alpha", "*", "h", "\n", "\n", "", "def", "_lik", "(", "u", ",", "v", ")", ":", "\n", "            ", "u", "=", "u", ".", "reshape", "(", "(", "d", ",", "-", "1", ")", ")", "\n", "v", "=", "v", ".", "reshape", "(", "(", "d", ",", "-", "1", ")", ")", "\n", "W", "=", "np", ".", "matmul", "(", "u", ",", "v", ".", "transpose", "(", ")", ")", "\n", "loss", "=", "0.5", "/", "n", "*", "np", ".", "square", "(", "np", ".", "linalg", ".", "norm", "(", "X", ".", "dot", "(", "np", ".", "eye", "(", "d", ",", "d", ")", "-", "W", ")", ",", "'fro'", ")", ")", "\n", "return", "loss", "\n", "\n", "", "def", "_grad", "(", "uv", ")", ":", "\n", "            ", "nn", "=", "len", "(", "uv", ")", "\n", "u", "=", "uv", "[", "0", ":", "nn", "//", "2", "]", "\n", "v", "=", "uv", "[", "nn", "//", "2", ":", "]", "\n", "gd", "=", "np", ".", "zeros", "(", "nn", ")", "\n", "gd", "[", "0", ":", "nn", "//", "2", "]", "=", "_grad_u", "(", "u", ",", "v", ")", "\n", "gd", "[", "nn", "//", "2", ":", "]", "=", "_grad_v", "(", "v", ",", "u", ")", "\n", "return", "gd", "\n", "\n", "", "def", "_grad_u", "(", "u", ",", "v", ")", ":", "\n", "# -2\u22c5X\u22a4\u22c5(X\u2212X\u22c5U\u22c5V\u22a4)\u22c5V", "\n", "# ( expm(t2) .* 2(u*v') ) * v, t2 = vu' .* vu'", "\n", "            ", "u", "=", "u", ".", "reshape", "(", "(", "d", ",", "-", "1", ")", ")", "\n", "v", "=", "v", ".", "reshape", "(", "(", "d", ",", "-", "1", ")", ")", "\n", "W", "=", "np", ".", "matmul", "(", "u", ",", "v", ".", "transpose", "(", ")", ")", "\n", "loss_grad", "=", "-", "1.0", "/", "n", "*", "X", ".", "T", ".", "dot", "(", "X", ")", ".", "dot", "(", "np", ".", "eye", "(", "d", ",", "d", ")", "-", "W", ")", ".", "dot", "(", "v", ")", "\n", "E", "=", "slin", ".", "expm", "(", "W", "*", "W", ")", "# expm(t2)'", "\n", "obj_grad", "=", "loss_grad", "+", "(", "rho", "*", "(", "np", ".", "trace", "(", "E", ")", "-", "d", ")", "+", "alpha", ")", "*", "2", "*", "np", ".", "matmul", "(", "E", ".", "T", "*", "W", ",", "v", ")", "\n", "return", "obj_grad", ".", "flatten", "(", ")", "\n", "\n", "", "def", "_grad_v", "(", "v", ",", "u", ")", ":", "\n", "# \u22122\u22c5(X\u22a4\u2212V\u22c5U\u22a4\u22c5X\u22a4)\u22c5X\u22c5U", "\n", "# ( expm(t1) .* 2(v*u') ) * u, t1 = uv' .* uv'", "\n", "            ", "u", "=", "u", ".", "reshape", "(", "(", "d", ",", "-", "1", ")", ")", "\n", "v", "=", "v", ".", "reshape", "(", "(", "d", ",", "-", "1", ")", ")", "\n", "W", "=", "np", ".", "matmul", "(", "v", ",", "u", ".", "transpose", "(", ")", ")", "\n", "loss_grad", "=", "-", "1.0", "/", "n", "*", "(", "np", ".", "eye", "(", "d", ",", "d", ")", "-", "W", ")", ".", "dot", "(", "X", ".", "T", ")", ".", "dot", "(", "X", ")", ".", "dot", "(", "u", ")", "\n", "E", "=", "slin", ".", "expm", "(", "W", "*", "W", ")", "# expm(t1)'", "\n", "obj_grad", "=", "loss_grad", "+", "(", "rho", "*", "(", "np", ".", "trace", "(", "E", ")", "-", "d", ")", "+", "alpha", ")", "*", "2", "*", "np", ".", "matmul", "(", "E", ".", "T", "*", "W", ",", "u", ")", "\n", "return", "obj_grad", ".", "flatten", "(", ")", "\n", "\n", "", "n", ",", "d", "=", "X", ".", "shape", "\n", "r", "=", "rank", "\n", "if", "w_init", "is", "None", ":", "\n", "            ", "w_init", "=", "np", ".", "zeros", "(", "(", "d", ",", "d", ")", ")", "\n", "\n", "", "u", ",", "s", ",", "vt", "=", "np", ".", "linalg", ".", "svd", "(", "w_init", ")", "\n", "u_new", "=", "u", "[", ":", ",", "range", "(", "r", ")", "]", ".", "dot", "(", "np", ".", "diag", "(", "s", "[", "range", "(", "r", ")", "]", ")", ")", ".", "reshape", "(", "d", "*", "r", ")", "\n", "v_new", "=", "vt", "[", "range", "(", "r", ")", ",", ":", "]", ".", "transpose", "(", ")", ".", "reshape", "(", "d", "*", "r", ")", "\n", "\n", "if", "np", ".", "sum", "(", "np", ".", "abs", "(", "u_new", ")", ")", "<=", "1e-6", "and", "np", ".", "sum", "(", "np", ".", "abs", "(", "v_new", ")", ")", "<=", "1e-6", ":", "\n", "            ", "raise", "ValueError", "(", "'nearly zero gradient; input new initialized W'", ")", "\n", "\n", "", "rho", ",", "alpha", ",", "h", ",", "h_new", "=", "1.0", ",", "0.0", ",", "np", ".", "inf", ",", "np", ".", "inf", "\n", "uv_new", "=", "np", ".", "hstack", "(", "(", "u_new", ",", "v_new", ")", ")", "\n", "uv_est", "=", "np", ".", "copy", "(", "uv_new", ")", "\n", "# bnds = [(0, 0) if i == j else (None, None) for i in range(d) for j in range(d)]", "\n", "\n", "logging", ".", "info", "(", "'[start]: n={}, d={}, iter_={}, h_={}, rho_={}'", ".", "format", "(", "n", ",", "d", ",", "self", ".", "max_iter", ",", "self", ".", "h_tol", ",", "self", ".", "rho_max", ")", ")", "\n", "\n", "for", "flag", "in", "range", "(", "-", "1", ",", "self", ".", "max_iter", ")", ":", "\n", "            ", "if", "flag", ">=", "0", ":", "\n", "                ", "while", "rho", "<=", "self", ".", "rho_max", ":", "\n", "                    ", "sol", "=", "sopt", ".", "minimize", "(", "_func", ",", "uv_est", ",", "method", "=", "'TNC'", ",", "\n", "jac", "=", "_grad", ",", "options", "=", "{", "'disp'", ":", "False", "}", ")", "\n", "\n", "uv_new", "=", "sol", ".", "x", "\n", "h_new", "=", "_h", "(", "np", ".", "matmul", "(", "uv_new", "[", "0", ":", "d", "*", "r", "]", ".", "reshape", "(", "(", "d", ",", "r", ")", ")", ",", "\n", "uv_new", "[", "d", "*", "r", ":", "]", ".", "reshape", "(", "(", "d", ",", "r", ")", ")", ".", "transpose", "(", ")", ")", ")", "\n", "\n", "logging", ".", "debug", "(", "\n", "'[iter {}] h={:.3e}, loss={:.3f}, rho={:.1e}'", ".", "format", "(", "flag", ",", "h_new", ",", "_func", "(", "uv_new", ")", ",", "rho", ")", ")", "\n", "\n", "if", "h_new", ">", "0.25", "*", "h", ":", "\n", "                        ", "rho", "*=", "10", "\n", "", "else", ":", "\n", "                        ", "break", "\n", "\n", "", "", "", "uv_est", ",", "h", "=", "uv_new", ",", "h_new", "\n", "\n", "#############################", "\n", "if", "flag", ">=", "0", ":", "\n", "                ", "alpha", "+=", "rho", "*", "h", "\n", "\n", "", "if", "flag", ">=", "3", "and", "h", "<=", "self", ".", "h_tol", ":", "\n", "                ", "break", "\n", "\n", "", "", "uv_new2", "=", "np", ".", "copy", "(", "uv_new", ")", "\n", "w_est2", "=", "np", ".", "matmul", "(", "uv_new2", "[", "0", ":", "d", "*", "r", "]", ".", "reshape", "(", "(", "d", ",", "r", ")", ")", ",", "\n", "uv_new2", "[", "d", "*", "r", ":", "]", ".", "reshape", "(", "(", "d", ",", "r", ")", ")", ".", "transpose", "(", ")", ")", "\n", "w_est2", "=", "w_est2", ".", "reshape", "(", "(", "d", ",", "d", ")", ")", "\n", "\n", "logging", ".", "info", "(", "'FINISHED'", ")", "\n", "\n", "return", "w_est2", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.notears.linear.Notears.__init__": [[75, 90], ["castle.common.BaseLearner.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "lambda1", "=", "0.1", ",", "\n", "loss_type", "=", "'l2'", ",", "\n", "max_iter", "=", "100", ",", "\n", "h_tol", "=", "1e-8", ",", "\n", "rho_max", "=", "1e+16", ",", "\n", "w_threshold", "=", "0.3", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "lambda1", "=", "lambda1", "\n", "self", ".", "loss_type", "=", "loss_type", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "self", ".", "h_tol", "=", "h_tol", "\n", "self", ".", "rho_max", "=", "rho_max", "\n", "self", ".", "w_threshold", "=", "w_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.notears.linear.Notears.learn": [[91, 116], ["castle.common.Tensor", "linear.Notears.notears_linear", "castle.common.Tensor", "castle.common.Tensor", "abs"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.notears.linear.Notears.notears_linear"], ["", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Set up and run the Notears algorithm.\n\n        Parameters\n        ----------\n        data: castle.Tensor or numpy.ndarray\n            The castle.Tensor or numpy.ndarray format data you want to learn.\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        \"\"\"", "\n", "X", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "W_est", "=", "self", ".", "notears_linear", "(", "X", ",", "lambda1", "=", "self", ".", "lambda1", ",", "\n", "loss_type", "=", "self", ".", "loss_type", ",", "\n", "max_iter", "=", "self", ".", "max_iter", ",", "\n", "h_tol", "=", "self", ".", "h_tol", ",", "\n", "rho_max", "=", "self", ".", "rho_max", ")", "\n", "causal_matrix", "=", "(", "abs", "(", "W_est", ")", ">", "self", ".", "w_threshold", ")", ".", "astype", "(", "int", ")", "\n", "self", ".", "weight_causal_matrix", "=", "Tensor", "(", "W_est", ",", "\n", "index", "=", "X", ".", "columns", ",", "\n", "columns", "=", "X", ".", "columns", ")", "\n", "self", ".", "causal_matrix", "=", "Tensor", "(", "causal_matrix", ",", "index", "=", "X", ".", "columns", ",", "\n", "columns", "=", "X", ".", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.notears.linear.Notears.notears_linear": [[117, 222], ["logging.info", "range", "linear.Notears.notears_linear._adj"], "methods", ["None"], ["", "def", "notears_linear", "(", "self", ",", "X", ",", "lambda1", ",", "loss_type", ",", "max_iter", ",", "h_tol", ",", "\n", "rho_max", ")", ":", "\n", "        ", "\"\"\"\n        Solve min_W L(W; X) + lambda1 \u2016W\u2016_1 s.t. h(W) = 0 using \n        augmented Lagrangian.\n\n        Parameters\n        ----------\n        X: np.ndarray \n            n*d sample matrix\n\n        Return\n        ------\n        W_est: np.ndarray\n            d*d estimated DAG\n        \"\"\"", "\n", "def", "_loss", "(", "W", ")", ":", "\n", "            ", "\"\"\"Evaluate value and gradient of loss.\"\"\"", "\n", "M", "=", "X", "@", "W", "\n", "if", "loss_type", "==", "'l2'", ":", "\n", "                ", "R", "=", "X", "-", "M", "\n", "loss", "=", "0.5", "/", "X", ".", "shape", "[", "0", "]", "*", "(", "R", "**", "2", ")", ".", "sum", "(", ")", "\n", "G_loss", "=", "-", "1.0", "/", "X", ".", "shape", "[", "0", "]", "*", "X", ".", "T", "@", "R", "\n", "", "elif", "loss_type", "==", "'logistic'", ":", "\n", "                ", "loss", "=", "1.0", "/", "X", ".", "shape", "[", "0", "]", "*", "(", "np", ".", "logaddexp", "(", "0", ",", "M", ")", "-", "X", "*", "M", ")", ".", "sum", "(", ")", "\n", "G_loss", "=", "1.0", "/", "X", ".", "shape", "[", "0", "]", "*", "X", ".", "T", "@", "(", "sigmoid", "(", "M", ")", "-", "X", ")", "\n", "", "elif", "loss_type", "==", "'poisson'", ":", "\n", "                ", "S", "=", "np", ".", "exp", "(", "M", ")", "\n", "loss", "=", "1.0", "/", "X", ".", "shape", "[", "0", "]", "*", "(", "S", "-", "X", "*", "M", ")", ".", "sum", "(", ")", "\n", "G_loss", "=", "1.0", "/", "X", ".", "shape", "[", "0", "]", "*", "X", ".", "T", "@", "(", "S", "-", "X", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'unknown loss type'", ")", "\n", "", "return", "loss", ",", "G_loss", "\n", "\n", "", "def", "_h", "(", "W", ")", ":", "\n", "            ", "\"\"\"\n            Evaluate value and gradient of acyclicity constraint.\n            \"\"\"", "\n", "#     E = slin.expm(W * W)  # (Zheng et al. 2018)", "\n", "#     h = np.trace(E) - d", "\n", "M", "=", "np", ".", "eye", "(", "d", ")", "+", "W", "*", "W", "/", "d", "# (Yu et al. 2019)", "\n", "E", "=", "np", ".", "linalg", ".", "matrix_power", "(", "M", ",", "d", "-", "1", ")", "\n", "h", "=", "(", "E", ".", "T", "*", "M", ")", ".", "sum", "(", ")", "-", "d", "\n", "G_h", "=", "E", ".", "T", "*", "W", "*", "2", "\n", "return", "h", ",", "G_h", "\n", "\n", "", "def", "_adj", "(", "w", ")", ":", "\n", "            ", "\"\"\"\n            Convert doubled variables ([2 d^2] array) back to original \n            variables ([d, d] matrix).\n            \"\"\"", "\n", "return", "(", "w", "[", ":", "d", "*", "d", "]", "-", "w", "[", "d", "*", "d", ":", "]", ")", ".", "reshape", "(", "[", "d", ",", "d", "]", ")", "\n", "\n", "", "def", "_func", "(", "w", ")", ":", "\n", "            ", "\"\"\"\n            Evaluate value and gradient of augmented Lagrangian for \n            doubled variables ([2 d^2] array).\n            \"\"\"", "\n", "W", "=", "_adj", "(", "w", ")", "\n", "loss", ",", "G_loss", "=", "_loss", "(", "W", ")", "\n", "h", ",", "G_h", "=", "_h", "(", "W", ")", "\n", "obj", "=", "loss", "+", "0.5", "*", "rho", "*", "h", "*", "h", "+", "alpha", "*", "h", "+", "lambda1", "*", "w", ".", "sum", "(", ")", "\n", "G_smooth", "=", "G_loss", "+", "(", "rho", "*", "h", "+", "alpha", ")", "*", "G_h", "\n", "g_obj", "=", "np", ".", "concatenate", "(", "(", "G_smooth", "+", "lambda1", ",", "-", "G_smooth", "+", "lambda1", ")", ",", "\n", "axis", "=", "None", ")", "\n", "return", "obj", ",", "g_obj", "\n", "\n", "", "n", ",", "d", "=", "X", ".", "shape", "\n", "# double w_est into (w_pos, w_neg)", "\n", "w_est", ",", "rho", ",", "alpha", ",", "h", "=", "np", ".", "zeros", "(", "2", "*", "d", "*", "d", ")", ",", "1.0", ",", "0.0", ",", "np", ".", "inf", "\n", "bnds", "=", "[", "(", "0", ",", "0", ")", "if", "i", "==", "j", "else", "(", "0", ",", "None", ")", "for", "_", "in", "range", "(", "2", ")", "\n", "for", "i", "in", "range", "(", "d", ")", "for", "j", "in", "range", "(", "d", ")", "]", "\n", "if", "loss_type", "==", "'l2'", ":", "\n", "            ", "X", "=", "X", "-", "np", ".", "mean", "(", "X", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "\n", "", "logging", ".", "info", "(", "'[start]: n={}, d={}, iter_={}, h_={}, rho_={}'", ".", "format", "(", "n", ",", "d", ",", "max_iter", ",", "h_tol", ",", "rho_max", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "max_iter", ")", ":", "\n", "            ", "w_new", ",", "h_new", "=", "None", ",", "None", "\n", "while", "rho", "<", "rho_max", ":", "\n", "                ", "sol", "=", "sopt", ".", "minimize", "(", "_func", ",", "w_est", ",", "method", "=", "'L-BFGS-B'", ",", "\n", "jac", "=", "True", ",", "bounds", "=", "bnds", ")", "\n", "w_new", "=", "sol", ".", "x", "\n", "h_new", ",", "_", "=", "_h", "(", "_adj", "(", "w_new", ")", ")", "\n", "\n", "logging", ".", "info", "(", "\n", "'[iter {}] h={:.3e}, loss={:.3f}, rho={:.1e}'", ".", "format", "(", "i", ",", "h_new", ",", "_func", "(", "w_est", ")", "[", "0", "]", ",", "rho", ")", ")", "\n", "\n", "if", "h_new", ">", "0.25", "*", "h", ":", "\n", "                    ", "rho", "*=", "10", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "w_est", ",", "h", "=", "w_new", ",", "h_new", "\n", "alpha", "+=", "rho", "*", "h", "\n", "\n", "if", "h", "<=", "h_tol", "or", "rho", ">=", "rho_max", ":", "\n", "                ", "break", "\n", "\n", "", "", "W_est", "=", "_adj", "(", "w_est", ")", "\n", "\n", "logging", ".", "info", "(", "'FINISHED'", ")", "\n", "\n", "return", "W_est", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.MLPModel.__init__": [[36, 65], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "models.MLPModel._bounds", "models.MLPModel._bounds", "range", "torch.ModuleList", "torch.ModuleList", "len", "layers.append", "len", "utils.locally_connected.LocallyConnected"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel._bounds", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel._bounds"], ["    ", "def", "__init__", "(", "self", ",", "dims", ",", "bias", "=", "True", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Multilayer perceptron.\n\n        Parameters\n        ----------\n        dims: tuple\n            Network shape parameters\n        bias:\n            Indicates whether to use weight deviation.\n        device: option, default: None\n            torch.device('cpu') or torch.device('cuda')\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "dims", ")", ">=", "2", "\n", "assert", "dims", "[", "-", "1", "]", "==", "1", "\n", "d", "=", "dims", "[", "0", "]", "\n", "self", ".", "dims", "=", "dims", "\n", "# fc1: variable splitting for l1", "\n", "self", ".", "fc1_pos", "=", "nn", ".", "Linear", "(", "d", ",", "d", "*", "dims", "[", "1", "]", ",", "bias", "=", "bias", ")", "\n", "self", ".", "fc1_neg", "=", "nn", ".", "Linear", "(", "d", ",", "d", "*", "dims", "[", "1", "]", ",", "bias", "=", "bias", ")", "\n", "self", ".", "fc1_pos", ".", "weight", ".", "bounds", "=", "self", ".", "_bounds", "(", ")", "\n", "self", ".", "fc1_neg", ".", "weight", ".", "bounds", "=", "self", ".", "_bounds", "(", ")", "\n", "# fc2: local linear layers", "\n", "layers", "=", "[", "]", "\n", "for", "l", "in", "range", "(", "len", "(", "dims", ")", "-", "2", ")", ":", "\n", "            ", "layers", ".", "append", "(", "LocallyConnected", "(", "d", ",", "dims", "[", "l", "+", "1", "]", ",", "dims", "[", "l", "+", "2", "]", ",", "bias", "=", "bias", ")", ")", "\n", "", "self", ".", "fc2", "=", "nn", ".", "ModuleList", "(", "layers", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.MLPModel._bounds": [[66, 78], ["range", "range", "range", "bounds.append"], "methods", ["None"], ["", "def", "_bounds", "(", "self", ")", ":", "\n", "        ", "d", "=", "self", ".", "dims", "[", "0", "]", "\n", "bounds", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "d", ")", ":", "\n", "            ", "for", "m", "in", "range", "(", "self", ".", "dims", "[", "1", "]", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "d", ")", ":", "\n", "                    ", "if", "i", "==", "j", ":", "\n", "                        ", "bound", "=", "(", "0", ",", "0", ")", "\n", "", "else", ":", "\n", "                        ", "bound", "=", "(", "0", ",", "None", ")", "\n", "", "bounds", ".", "append", "(", "bound", ")", "\n", "", "", "", "return", "bounds", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.MLPModel.forward": [[79, 87], ["fc.view", "fc.squeeze", "models.MLPModel.fc1_pos", "models.MLPModel.fc1_neg", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "# [n, d] -> [n, d]", "\n", "        ", "x", "=", "self", ".", "fc1_pos", "(", "x", ")", "-", "self", ".", "fc1_neg", "(", "x", ")", "# [n, d * m1]", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "dims", "[", "0", "]", ",", "self", ".", "dims", "[", "1", "]", ")", "# [n, d, m1]", "\n", "for", "fc", "in", "self", ".", "fc2", ":", "\n", "            ", "x", "=", "torch", ".", "sigmoid", "(", "x", ")", "# [n, d, m1]", "\n", "x", "=", "fc", "(", "x", ")", "# [n, d, m2]", "\n", "", "x", "=", "x", ".", "squeeze", "(", "dim", "=", "2", ")", "# [n, d]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.MLPModel.h_func": [[88, 106], ["fc1_weight.view.view.view", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.matrix_power", "torch.matrix_power", "torch.matrix_power", "torch.matrix_power", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.matrix_power.t", "torch.matrix_power.t"], "methods", ["None"], ["", "def", "h_func", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Constrain 2-norm-squared of fc1 weights along m1 dim to be a DAG.\n\n        Returns\n        -------\n\n        \"\"\"", "\n", "d", "=", "self", ".", "dims", "[", "0", "]", "\n", "fc1_weight", "=", "self", ".", "fc1_pos", ".", "weight", "-", "self", ".", "fc1_neg", ".", "weight", "# [j * m1, i]", "\n", "fc1_weight", "=", "fc1_weight", ".", "view", "(", "d", ",", "-", "1", ",", "d", ")", "# [j, m1, i]", "\n", "A", "=", "torch", ".", "sum", "(", "fc1_weight", "*", "fc1_weight", ",", "dim", "=", "1", ")", ".", "t", "(", ")", "# [i, j]", "\n", "# h = trace_expm(A) - d  # (Zheng et al. 2018)", "\n", "init_e", "=", "torch", ".", "eye", "(", "d", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "M", "=", "init_e", "+", "A", "/", "d", "# (Yu et al. 2019)", "\n", "E", "=", "torch", ".", "matrix_power", "(", "M", ",", "d", "-", "1", ")", "\n", "h", "=", "(", "E", ".", "t", "(", ")", "*", "M", ")", ".", "sum", "(", ")", "-", "d", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.MLPModel.l2_reg": [[107, 121], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "l2_reg", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Take 2-norm-squared of all parameters.\n\n        Returns\n        -------\n\n        \"\"\"", "\n", "reg", "=", "0.", "\n", "fc1_weight", "=", "self", ".", "fc1_pos", ".", "weight", "-", "self", ".", "fc1_neg", ".", "weight", "# [j * m1, i]", "\n", "reg", "+=", "torch", ".", "sum", "(", "fc1_weight", "**", "2", ")", "\n", "for", "fc", "in", "self", ".", "fc2", ":", "\n", "            ", "reg", "+=", "torch", ".", "sum", "(", "fc", ".", "weight", "**", "2", ")", "\n", "", "return", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.MLPModel.fc1_l1_reg": [[122, 132], ["torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "fc1_l1_reg", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Take l1 norm of fc1 weight.\n\n        Returns\n        -------\n\n        \"\"\"", "\n", "reg", "=", "torch", ".", "sum", "(", "self", ".", "fc1_pos", ".", "weight", "+", "self", ".", "fc1_neg", ".", "weight", ")", "\n", "return", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.MLPModel.fc1_to_adj": [[133, 149], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "fc1_weight.view.view.view", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "W.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "W.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "W.cpu().detach().numpy.cpu().detach().numpy.cpu"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "fc1_to_adj", "(", "self", ")", "->", "np", ".", "ndarray", ":", "# [j * m1, i] -> [i, j]", "\n", "        ", "\"\"\"\n        Get W from fc1 weights, take 2-norm over m1 dim.\n\n        Returns\n        -------\n\n        \"\"\"", "\n", "d", "=", "self", ".", "dims", "[", "0", "]", "\n", "fc1_weight", "=", "self", ".", "fc1_pos", ".", "weight", "-", "self", ".", "fc1_neg", ".", "weight", "# [j * m1, i]", "\n", "fc1_weight", "=", "fc1_weight", ".", "view", "(", "d", ",", "-", "1", ",", "d", ")", "# [j, m1, i]", "\n", "A", "=", "torch", ".", "sum", "(", "fc1_weight", "*", "fc1_weight", ",", "dim", "=", "1", ")", ".", "t", "(", ")", "# [i, j]", "\n", "W", "=", "torch", ".", "sqrt", "(", "A", ")", "# [i, j]", "\n", "W", "=", "W", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "# [i, j]", "\n", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.__init__": [[166, 177], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "models.SobolevModel._bounds", "models.SobolevModel._bounds", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel._bounds", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel._bounds"], ["def", "__init__", "(", "self", ",", "d", ",", "k", ",", "bias", "=", "False", ",", "device", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "d", ",", "self", ".", "k", "=", "d", ",", "k", "\n", "self", ".", "fc1_pos", "=", "nn", ".", "Linear", "(", "d", "*", "k", ",", "d", ",", "bias", "=", "bias", ")", "# ik -> j", "\n", "self", ".", "fc1_neg", "=", "nn", ".", "Linear", "(", "d", "*", "k", ",", "d", ",", "bias", "=", "bias", ")", "\n", "self", ".", "fc1_pos", ".", "weight", ".", "bounds", "=", "self", ".", "_bounds", "(", ")", "\n", "self", ".", "fc1_neg", ".", "weight", ".", "bounds", "=", "self", ".", "_bounds", "(", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "fc1_pos", ".", "weight", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "fc1_neg", ".", "weight", ")", "\n", "self", ".", "l2_reg_store", "=", "None", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel._bounds": [[178, 190], ["range", "range", "range", "bounds.append"], "methods", ["None"], ["", "def", "_bounds", "(", "self", ")", ":", "\n", "# weight shape [j, ik]", "\n", "        ", "bounds", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "self", ".", "d", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "d", ")", ":", "\n", "                ", "for", "_", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "                    ", "if", "i", "==", "j", ":", "\n", "                        ", "bound", "=", "(", "0", ",", "0", ")", "\n", "", "else", ":", "\n", "                        ", "bound", "=", "(", "0", ",", "None", ")", "\n", "", "bounds", ".", "append", "(", "bound", ")", "\n", "", "", "", "return", "bounds", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.sobolev_basis": [[191, 200], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "bases.view.view.view", "seq.append", "torch.sin", "torch.sin", "torch.sin", "torch.sin"], "methods", ["None"], ["", "def", "sobolev_basis", "(", "self", ",", "x", ")", ":", "# [n, d] -> [n, dk]", "\n", "        ", "seq", "=", "[", "]", "\n", "for", "kk", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "            ", "mu", "=", "2.0", "/", "(", "2", "*", "kk", "+", "1", ")", "/", "math", ".", "pi", "# sobolev basis", "\n", "psi", "=", "mu", "*", "torch", ".", "sin", "(", "x", "/", "mu", ")", "\n", "seq", ".", "append", "(", "psi", ")", "# [n, d] * k", "\n", "", "bases", "=", "torch", ".", "stack", "(", "seq", ",", "dim", "=", "2", ")", "# [n, d, k]", "\n", "bases", "=", "bases", ".", "view", "(", "-", "1", ",", "self", ".", "d", "*", "self", ".", "k", ")", "# [n, dk]", "\n", "return", "bases", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.forward": [[201, 206], ["models.SobolevModel.sobolev_basis", "models.SobolevModel.fc1_pos", "models.SobolevModel.fc1_neg", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.sobolev_basis"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "# [n, d] -> [n, d]", "\n", "        ", "bases", "=", "self", ".", "sobolev_basis", "(", "x", ")", "# [n, dk]", "\n", "x", "=", "self", ".", "fc1_pos", "(", "bases", ")", "-", "self", ".", "fc1_neg", "(", "bases", ")", "# [n, d]", "\n", "self", ".", "l2_reg_store", "=", "torch", ".", "sum", "(", "x", "**", "2", ")", "/", "x", ".", "shape", "[", "0", "]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.h_func": [[207, 217], ["fc1_weight.view.view.view", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.matrix_power", "torch.matrix_power", "torch.matrix_power", "torch.matrix_power", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.matrix_power.t", "torch.matrix_power.t"], "methods", ["None"], ["", "def", "h_func", "(", "self", ")", ":", "\n", "        ", "fc1_weight", "=", "self", ".", "fc1_pos", ".", "weight", "-", "self", ".", "fc1_neg", ".", "weight", "# [j, ik]", "\n", "fc1_weight", "=", "fc1_weight", ".", "view", "(", "self", ".", "d", ",", "self", ".", "d", ",", "self", ".", "k", ")", "# [j, i, k]", "\n", "A", "=", "torch", ".", "sum", "(", "fc1_weight", "*", "fc1_weight", ",", "dim", "=", "2", ")", ".", "t", "(", ")", "# [i, j]", "\n", "# h = trace_expm(A) - d  # (Zheng et al. 2018)", "\n", "init_e", "=", "torch", ".", "eye", "(", "self", ".", "d", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "M", "=", "init_e", "+", "A", "/", "self", ".", "d", "# (Yu et al. 2019)", "\n", "E", "=", "torch", ".", "matrix_power", "(", "M", ",", "self", ".", "d", "-", "1", ")", "\n", "h", "=", "(", "E", ".", "t", "(", ")", "*", "M", ")", ".", "sum", "(", ")", "-", "self", ".", "d", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.l2_reg": [[218, 221], ["None"], "methods", ["None"], ["", "def", "l2_reg", "(", "self", ")", ":", "\n", "        ", "reg", "=", "self", ".", "l2_reg_store", "\n", "return", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.fc1_l1_reg": [[222, 225], ["torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "fc1_l1_reg", "(", "self", ")", ":", "\n", "        ", "reg", "=", "torch", ".", "sum", "(", "self", ".", "fc1_pos", ".", "weight", "+", "self", ".", "fc1_neg", ".", "weight", ")", "\n", "return", "reg", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.fc1_to_adj": [[226, 234], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "fc1_weight.view.view.view", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sum().t", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "W.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "W.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "W.cpu().detach().numpy.cpu().detach().numpy.cpu"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "fc1_to_adj", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "fc1_weight", "=", "self", ".", "fc1_pos", ".", "weight", "-", "self", ".", "fc1_neg", ".", "weight", "# [j, ik]", "\n", "fc1_weight", "=", "fc1_weight", ".", "view", "(", "self", ".", "d", ",", "self", ".", "d", ",", "self", ".", "k", ")", "# [j, i, k]", "\n", "A", "=", "torch", ".", "sum", "(", "fc1_weight", "*", "fc1_weight", ",", "dim", "=", "2", ")", ".", "t", "(", ")", "# [i, j]", "\n", "W", "=", "torch", ".", "sqrt", "(", "A", ")", "# [i, j]", "\n", "W", "=", "W", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "# [i, j]", "\n", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.squared_loss": [[236, 254], ["torch.sum", "torch.sum"], "function", ["None"], ["", "", "def", "squared_loss", "(", "output", ",", "target", ")", ":", "\n", "    ", "\"\"\"\n    Least squares loss function.\n\n    Parameters\n    ----------\n    output: torch.tenser\n        network output\n    target: torch.tenser\n        raw input\n    Returns\n    -------\n    : torch.tenser\n        loss value\n    \"\"\"", "\n", "n", "=", "target", ".", "shape", "[", "0", "]", "\n", "loss", "=", "0.5", "/", "n", "*", "torch", ".", "sum", "(", "(", "output", "-", "target", ")", "**", "2", ")", "\n", "return", "loss", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.nonlinear.NotearsNonlinear.__init__": [[99, 142], ["castle.common.BaseLearner.__init__", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "logging.info", "logging.info", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "lambda1", ":", "float", "=", "0.01", ",", "\n", "lambda2", ":", "float", "=", "0.01", ",", "\n", "max_iter", ":", "int", "=", "100", ",", "\n", "h_tol", ":", "float", "=", "1e-8", ",", "\n", "rho_max", ":", "float", "=", "1e+16", ",", "\n", "w_threshold", ":", "float", "=", "0.3", ",", "\n", "hidden_layer", ":", "int", "=", "1", ",", "\n", "hidden_units", ":", "int", "=", "10", ",", "\n", "bias", ":", "bool", "=", "True", ",", "\n", "model_type", ":", "str", "=", "\"mlp\"", ",", "\n", "device_type", ":", "str", "=", "\"cpu\"", ",", "\n", "device_ids", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "lambda1", "=", "lambda1", "\n", "self", ".", "lambda2", "=", "lambda2", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "self", ".", "h_tol", "=", "h_tol", "\n", "self", ".", "rho_max", "=", "rho_max", "\n", "self", ".", "w_threshold", "=", "w_threshold", "\n", "self", ".", "hidden_layer", "=", "hidden_layer", "\n", "self", ".", "hidden_units", "=", "hidden_units", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "model_type", "=", "model_type", "\n", "self", ".", "device_type", "=", "device_type", "\n", "self", ".", "device_ids", "=", "device_ids", "\n", "self", ".", "rho", ",", "self", ".", "alpha", ",", "self", ".", "h", "=", "1.0", ",", "0.0", ",", "np", ".", "inf", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'GPU is available.'", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "'GPU is unavailable.'", ")", "\n", "if", "self", ".", "device_type", "==", "'gpu'", ":", "\n", "                ", "raise", "ValueError", "(", "\"GPU is unavailable, \"", "\n", "\"please set device_type = 'cpu'.\"", ")", "\n", "", "", "if", "self", ".", "device_type", "==", "'gpu'", ":", "\n", "            ", "if", "self", ".", "device_ids", ":", "\n", "                ", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "self", ".", "device_ids", ")", "\n", "", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.nonlinear.NotearsNonlinear.learn": [[143, 167], ["castle.common.Tensor", "nonlinear.NotearsNonlinear.get_model", "nonlinear.NotearsNonlinear.notears_nonlinear", "castle.common.Tensor", "castle.common.Tensor", "abs"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.nonlinear.NotearsNonlinear.get_model", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.nonlinear.NotearsNonlinear.notears_nonlinear"], ["", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Set up and run the NotearsNonlinear algorithm.\n\n        Parameters\n        ----------\n        data: castle.Tensor or numpy.ndarray\n            The castle.Tensor or numpy.ndarray format data you want to learn.\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        \"\"\"", "\n", "X", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "input_dim", "=", "X", ".", "shape", "[", "1", "]", "\n", "model", "=", "self", ".", "get_model", "(", "input_dim", ")", "\n", "if", "model", ":", "\n", "            ", "W_est", "=", "self", ".", "notears_nonlinear", "(", "model", ",", "X", ")", "\n", "\n", "causal_matrix", "=", "(", "abs", "(", "W_est", ")", ">", "self", ".", "w_threshold", ")", ".", "astype", "(", "int", ")", "\n", "self", ".", "weight_causal_matrix", "=", "Tensor", "(", "W_est", ",", "\n", "index", "=", "X", ".", "columns", ",", "\n", "columns", "=", "X", ".", "columns", ")", "\n", "self", ".", "causal_matrix", "=", "Tensor", "(", "causal_matrix", ",", "index", "=", "X", ".", "columns", ",", "columns", "=", "X", ".", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.nonlinear.NotearsNonlinear.dual_ascent_step": [[168, 212], ["utils.lbfgsb_scipy.LBFGSBScipy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "model.to.to.parameters", "X_torch.to.to.to", "utils.lbfgsb_scipy.LBFGSBScipy.step", "utils.lbfgsb_scipy.LBFGSBScipy.zero_grad", "model.to.to.", "models.squared_loss", "model.to.to.h_func", "primal_obj.backward", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model.to.to.to", "model.to.to.h_func().item", "model.to.to.l2_reg", "model.to.to.fc1_l1_reg", "model.to.to.h_func"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy.step", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.squared_loss", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.h_func", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.TrExpScipy.backward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.l2_reg", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.fc1_l1_reg", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.h_func"], ["", "", "def", "dual_ascent_step", "(", "self", ",", "model", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        Perform one step of dual ascent in augmented Lagrangian.\n\n        Parameters\n        ----------\n        model: nn.Module\n            network model\n        X: torch.tenser\n            sample data\n\n        Returns\n        -------\n        :tuple\n            cycle control parameter\n        \"\"\"", "\n", "h_new", "=", "None", "\n", "optimizer", "=", "LBFGSBScipy", "(", "model", ".", "parameters", "(", ")", ")", "\n", "X_torch", "=", "torch", ".", "from_numpy", "(", "X", ")", "\n", "while", "self", ".", "rho", "<", "self", ".", "rho_max", ":", "\n", "            ", "X_torch", "=", "X_torch", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "def", "closure", "(", ")", ":", "\n", "                ", "optimizer", ".", "zero_grad", "(", ")", "\n", "X_hat", "=", "model", "(", "X_torch", ")", "\n", "loss", "=", "squared_loss", "(", "X_hat", ",", "X_torch", ")", "\n", "h_val", "=", "model", ".", "h_func", "(", ")", "\n", "penalty", "=", "0.5", "*", "self", ".", "rho", "*", "h_val", "*", "h_val", "+", "self", ".", "alpha", "*", "h_val", "\n", "l2_reg", "=", "0.5", "*", "self", ".", "lambda2", "*", "model", ".", "l2_reg", "(", ")", "\n", "l1_reg", "=", "self", ".", "lambda1", "*", "model", ".", "fc1_l1_reg", "(", ")", "\n", "primal_obj", "=", "loss", "+", "penalty", "+", "l2_reg", "+", "l1_reg", "\n", "primal_obj", ".", "backward", "(", ")", "\n", "return", "primal_obj", "\n", "\n", "", "optimizer", ".", "step", "(", "closure", ",", "self", ".", "device", ")", "# NOTE: updates model in-place", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "h_new", "=", "model", ".", "h_func", "(", ")", ".", "item", "(", ")", "\n", "", "if", "h_new", ">", "0.25", "*", "self", ".", "h", ":", "\n", "                ", "self", ".", "rho", "*=", "10", "\n", "", "else", ":", "\n", "                ", "break", "\n", "", "", "self", ".", "alpha", "+=", "self", ".", "rho", "*", "h_new", "\n", "self", ".", "h", "=", "h_new", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.nonlinear.NotearsNonlinear.notears_nonlinear": [[213, 246], ["logging.info", "range", "model.fc1_to_adj", "logging.info", "nonlinear.NotearsNonlinear.dual_ascent_step", "logging.debug"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.models.SobolevModel.fc1_to_adj", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.nonlinear.NotearsNonlinear.dual_ascent_step"], ["", "def", "notears_nonlinear", "(", "self", ",", "\n", "model", ":", "nn", ".", "Module", ",", "\n", "X", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "\"\"\"\n        notaears frame entrance.\n\n        Parameters\n        ----------\n        model: nn.Module\n            network model\n        X: castle.Tensor or numpy.ndarray\n            sample data\n\n        Returns\n        -------\n        :tuple\n            Prediction Graph Matrix Coefficients.\n        \"\"\"", "\n", "logging", ".", "info", "(", "'[start]: n={}, d={}, iter_={}, h_={}, rho_={}'", ".", "format", "(", "X", ".", "shape", "[", "0", "]", ",", "X", ".", "shape", "[", "1", "]", ",", "self", ".", "max_iter", ",", "self", ".", "h_tol", ",", "self", ".", "rho_max", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "self", ".", "max_iter", ")", ":", "\n", "            ", "self", ".", "dual_ascent_step", "(", "model", ",", "X", ")", "\n", "\n", "logging", ".", "debug", "(", "'[iter {}] h={:.3e}, rho={:.1e}'", ".", "format", "(", "_", ",", "self", ".", "h", ",", "self", ".", "rho", ")", ")", "\n", "\n", "if", "self", ".", "h", "<=", "self", ".", "h_tol", "or", "self", ".", "rho", ">=", "self", ".", "rho_max", ":", "\n", "                ", "break", "\n", "", "", "W_est", "=", "model", ".", "fc1_to_adj", "(", ")", "\n", "\n", "logging", ".", "info", "(", "'FINISHED'", ")", "\n", "\n", "return", "W_est", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.nonlinear.NotearsNonlinear.get_model": [[247, 268], ["models.MLPModel().to", "models.SobolevModel().to", "logging.info", "models.MLPModel", "models.SobolevModel"], "methods", ["None"], ["", "def", "get_model", "(", "self", ",", "input_dim", ")", ":", "\n", "        ", "\"\"\"\n            Choose a different model.\n        Parameters\n        ----------\n        input_dim: int\n            Enter the number of data dimensions.\n\n        Returns\n        -------\n\n        \"\"\"", "\n", "if", "self", ".", "model_type", "==", "\"mlp\"", ":", "\n", "            ", "model", "=", "MLPModel", "(", "dims", "=", "[", "input_dim", ",", "self", ".", "hidden_units", ",", "self", ".", "hidden_layer", "]", ",", "bias", "=", "self", ".", "bias", ",", "device", "=", "self", ".", "device", ")", ".", "to", "(", "\n", "self", ".", "device", ")", "\n", "return", "model", "\n", "", "elif", "self", ".", "model_type", "==", "\"sob\"", ":", "\n", "            ", "model", "=", "SobolevModel", "(", "input_dim", ",", "k", "=", "self", ".", "hidden_units", ",", "bias", "=", "self", ".", "bias", ",", "device", "=", "self", ".", "device", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "return", "model", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "f'Unsupported model type {self.model_type}.'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.golem.GOLEM.__init__": [[91, 126], ["castle.common.BaseLearner.__init__", "argparse.ArgumentParser", "argparse.ArgumentParser.parse_args", "torch.device"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "B_init", "=", "None", ",", "\n", "lambda_1", "=", "2e-2", ",", "\n", "lambda_2", "=", "5.0", ",", "\n", "equal_variances", "=", "True", ",", "\n", "non_equal_variances", "=", "True", ",", "\n", "learning_rate", "=", "1e-3", ",", "\n", "num_iter", "=", "1e+5", ",", "\n", "checkpoint_iter", "=", "5000", ",", "\n", "seed", "=", "1", ",", "\n", "graph_thres", "=", "0.3", ",", "\n", "device_type", "=", "'cpu'", ",", "\n", "device_ids", "=", "0", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Configuration'", ")", "\n", "self", ".", "config", "=", "parser", ".", "parse_args", "(", "args", "=", "[", "]", ")", "\n", "self", ".", "config", ".", "B_init", "=", "B_init", "\n", "self", ".", "config", ".", "lambda_1", "=", "lambda_1", "\n", "self", ".", "config", ".", "lambda_2", "=", "lambda_2", "\n", "self", ".", "config", ".", "equal_variances", "=", "equal_variances", "\n", "self", ".", "config", ".", "non_equal_variances", "=", "non_equal_variances", "\n", "self", ".", "config", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "config", ".", "num_iter", "=", "num_iter", "\n", "self", ".", "config", ".", "checkpoint_iter", "=", "checkpoint_iter", "\n", "self", ".", "config", ".", "seed", "=", "seed", "\n", "self", ".", "config", ".", "graph_thres", "=", "graph_thres", "\n", "self", ".", "config", ".", "device_type", "=", "device_type", "\n", "self", ".", "config", ".", "device_ids", "=", "device_ids", "\n", "\n", "if", "not", "is_cuda_available", ":", "\n", "            ", "self", ".", "config", ".", "device_type", "=", "'cpu'", "\n", "\n", "", "if", "self", ".", "config", ".", "device_type", "==", "'gpu'", ":", "\n", "            ", "self", ".", "config", ".", "device", "=", "torch", ".", "device", "(", "type", "=", "'cuda'", ",", "index", "=", "self", ".", "config", ".", "device_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.golem.GOLEM.learn": [[127, 167], ["castle.common.Tensor", "golem.GOLEM._golem", "castle.common.Tensor"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.golem.GOLEM._golem"], ["", "", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Set up and run the GOLEM algorithm.\n\n        Parameters\n        ----------\n        data: castle.Tensor or numpy.ndarray\n            The castle.Tensor or numpy.ndarray format data you want to learn.\n        X: numpy.ndarray\n            [n, d] data matrix.\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        lambda_1: float\n            Coefficient of L1 penalty.\n        lambda_2: float\n            Coefficient of DAG penalty.\n        equal_variances: bool\n            Whether to assume equal noise variances\n            for likelibood objective. Default: True.\n        num_iter:int\n            Number of iterations for training.\n        learning_rate: float\n            Learning rate of Adam optimizer. Default: 1e-3.\n        seed: int\n            Random seed. Default: 1.\n        checkpoint_iter: int\n            Number of iterations between each checkpoint.\n            Set to None to disable. Default: None.\n        B_init: numpy.ndarray or None\n            [d, d] weighted matrix for initialization.\n            Set to None to disable. Default: None.\n        \"\"\"", "\n", "config", "=", "self", ".", "config", "\n", "\n", "X", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "causal_matrix", "=", "self", ".", "_golem", "(", "X", ",", "config", ")", "\n", "self", ".", "causal_matrix", "=", "Tensor", "(", "causal_matrix", ",", "index", "=", "X", ".", "columns", ",", "\n", "columns", "=", "X", ".", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.golem.GOLEM._golem": [[168, 229], ["golem_utils.utils.set_seed", "torch.optim.Adam", "logging.info", "range", "torch.Tensor().cuda", "torch.Tensor", "golem_utils.GolemModel().cuda", "golem_utils.GolemModel", "golem_utils.GolemModel.parameters", "golem_utils.GolemModel.", "golem_utils.train.postprocess", "golem_utils.train.postprocess", "int", "int", "golem.GOLEM.train_op.zero_grad", "golem.GOLEM.loss.backward", "golem.GOLEM.train_op.step", "logging.info", "B_est.cpu().detach().numpy", "B_est.detach().numpy", "torch.Tensor", "golem_utils.GolemModel", "B_est.cpu().detach", "B_est.detach", "B_est.cpu"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.set_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.train.postprocess", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.train.postprocess", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.TrExpScipy.backward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy.step"], ["", "def", "_golem", "(", "self", ",", "X", ",", "args", ")", ":", "\n", "        ", "\"\"\"\n        Solve the unconstrained optimization problem of GOLEM, which involves\n        GolemModel and GolemTrainer.\n\n        Parameters\n        ----------\n        X: numpy.ndarray\n            [n, d] data matrix.\n        \n        Return\n        ------\n        B_result: np.ndarray\n            [d, d] estimated weighted matrix.\n        \n        Hyperparameters\n        ---------------\n        (1) GOLEM-NV: equal_variances=False, lambda_1=2e-3, lambda_2=5.0.\n        (2) GOLEM-EV: equal_variances=True, lambda_1=2e-2, lambda_2=5.0.\n        \"\"\"", "\n", "set_seed", "(", "args", ".", "seed", ")", "\n", "n", ",", "d", "=", "X", ".", "shape", "\n", "if", "args", ".", "device_type", "==", "'gpu'", ":", "\n", "            ", "X", "=", "torch", ".", "Tensor", "(", "X", ")", ".", "cuda", "(", "args", ".", "device_ids", ")", "\n", "", "else", ":", "\n", "            ", "X", "=", "torch", ".", "Tensor", "(", "X", ")", "\n", "\n", "# Set up model", "\n", "", "if", "args", ".", "device_type", "==", "'gpu'", ":", "\n", "            ", "model", "=", "GolemModel", "(", "args", ",", "n", ",", "d", ",", "args", ".", "lambda_1", ",", "args", ".", "lambda_2", ",", "\n", "args", ".", "equal_variances", ",", "args", ".", "B_init", ")", ".", "cuda", "(", "args", ".", "device_ids", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "GolemModel", "(", "args", ",", "n", ",", "d", ",", "args", ".", "lambda_1", ",", "args", ".", "lambda_2", ",", "\n", "args", ".", "equal_variances", ",", "args", ".", "B_init", ")", "\n", "", "self", ".", "train_op", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "learning_rate", ")", "\n", "\n", "logging", ".", "info", "(", "\"Started training for {} iterations.\"", ".", "format", "(", "int", "(", "args", ".", "num_iter", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "int", "(", "args", ".", "num_iter", ")", "+", "1", ")", ":", "\n", "            ", "model", "(", "X", ")", "\n", "score", ",", "likelihood", ",", "h", ",", "B_est", "=", "model", ".", "score", ",", "model", ".", "likelihood", ",", "model", ".", "h", ",", "model", ".", "B", "\n", "\n", "if", "i", ">", "0", ":", "# Do not train here, only perform evaluation", "\n", "# Optimizer", "\n", "                ", "self", ".", "loss", "=", "score", "\n", "self", ".", "train_op", ".", "zero_grad", "(", ")", "\n", "self", ".", "loss", ".", "backward", "(", ")", "\n", "self", ".", "train_op", ".", "step", "(", ")", "\n", "\n", "", "if", "args", ".", "checkpoint_iter", "is", "not", "None", "and", "i", "%", "args", ".", "checkpoint_iter", "==", "0", ":", "\n", "                ", "logging", ".", "info", "(", "\"[Iter {}] score={:.3f}, likelihood={:.3f}, h={:.1e}\"", ".", "format", "(", "i", ",", "score", ",", "likelihood", ",", "h", ")", ")", "\n", "\n", "# Post-process estimated solution and compute results", "\n", "", "", "if", "args", ".", "device_type", "==", "'gpu'", ":", "\n", "            ", "B_processed", "=", "postprocess", "(", "B_est", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "graph_thres", "=", "0.3", ")", "\n", "", "else", ":", "\n", "            ", "B_processed", "=", "postprocess", "(", "B_est", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "graph_thres", "=", "0.3", ")", "\n", "\n", "", "B_result", "=", "(", "B_processed", "!=", "0", ")", ".", "astype", "(", "int", ")", "\n", "\n", "return", "B_result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.gran_dag.NormalizationData.__init__": [[56, 83], ["numpy.random.RandomState", "numpy.arange", "isinstance", "torch.as_tensor().type", "gran_dag.NormalizationData.data_set.size", "gran_dag.NormalizationData.random.shuffle", "int", "TypeError", "torch.as_tensor", "torch.mean", "torch.std"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "normalize", "=", "False", ",", "mean", "=", "None", ",", "std", "=", "None", ",", "\n", "shuffle", "=", "False", ",", "train_size", "=", "0.8", ",", "train", "=", "True", ",", "random_seed", "=", "42", ")", ":", "\n", "        ", "self", ".", "random", "=", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", "\n", "\n", "shuffle_idx", "=", "np", ".", "arange", "(", "data", ".", "shape", "[", "0", "]", ")", "\n", "if", "shuffle", ":", "\n", "            ", "self", ".", "random", ".", "shuffle", "(", "shuffle_idx", ")", "\n", "\n", "", "if", "isinstance", "(", "train_size", ",", "float", ")", ":", "\n", "            ", "train_samples", "=", "int", "(", "data", ".", "shape", "[", "0", "]", "*", "train_size", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\"The param train_size must be float < 1\"", ")", "\n", "", "if", "train", ":", "\n", "            ", "data", "=", "data", "[", "shuffle_idx", "[", ":", "train_samples", "]", "]", "\n", "", "else", ":", "\n", "            ", "data", "=", "data", "[", "shuffle_idx", "[", "train_samples", ":", "]", "]", "\n", "# as tensor", "\n", "", "self", ".", "data_set", "=", "torch", ".", "as_tensor", "(", "data", ")", ".", "type", "(", "torch", ".", "Tensor", ")", "\n", "\n", "# Normalize data", "\n", "self", ".", "mean", ",", "self", ".", "std", "=", "mean", ",", "std", "\n", "if", "normalize", ":", "\n", "            ", "if", "mean", "is", "None", "or", "std", "is", "None", ":", "\n", "                ", "self", ".", "mean", "=", "torch", ".", "mean", "(", "self", ".", "data_set", ",", "0", ",", "keepdim", "=", "True", ")", "\n", "self", ".", "std", "=", "torch", ".", "std", "(", "self", ".", "data_set", ",", "0", ",", "keepdim", "=", "True", ")", "\n", "", "self", ".", "data_set", "=", "(", "self", ".", "data_set", "-", "self", ".", "mean", ")", "/", "self", ".", "std", "\n", "", "self", ".", "n_samples", "=", "self", ".", "data_set", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.gran_dag.NormalizationData.sample": [[84, 104], ["gran_dag.NormalizationData.random.choice", "numpy.arange", "torch.ones_like", "int", "torch.as_tensor().long", "int", "torch.as_tensor"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"sampling from self.dataset\n\n        Parameters\n        ----------\n        batch_size : int\n            batch size of sample\n\n        Returns\n        -------\n        samples : torch.Tensor\n            sample data after sampling\n        torch.ones_like(samples): torch.Tensor\n        \"\"\"", "\n", "sample_idxs", "=", "self", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "int", "(", "self", ".", "n_samples", ")", ")", ",", "\n", "size", "=", "(", "int", "(", "batch_size", ")", ",", ")", ",", "\n", "replace", "=", "False", ")", "\n", "samples", "=", "self", ".", "data_set", "[", "torch", ".", "as_tensor", "(", "sample_idxs", ")", ".", "long", "(", ")", "]", "\n", "\n", "return", "samples", ",", "torch", ".", "ones_like", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.gran_dag.GraNDAG.__init__": [[190, 244], ["castle.common.BaseLearner.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "\n", "hidden_num", "=", "2", ",", "\n", "hidden_dim", "=", "10", ",", "\n", "batch_size", "=", "64", ",", "\n", "lr", "=", "0.001", ",", "\n", "iterations", "=", "10000", ",", "\n", "model_name", "=", "'NonLinGaussANM'", ",", "\n", "nonlinear", "=", "'leaky-relu'", ",", "\n", "optimizer", "=", "'rmsprop'", ",", "\n", "h_threshold", "=", "1e-8", ",", "\n", "device_type", "=", "'cpu'", ",", "\n", "use_pns", "=", "False", ",", "\n", "pns_thresh", "=", "0.75", ",", "\n", "num_neighbors", "=", "None", ",", "\n", "normalize", "=", "False", ",", "\n", "precision", "=", "False", ",", "\n", "random_seed", "=", "42", ",", "\n", "jac_thresh", "=", "True", ",", "\n", "lambda_init", "=", "0.0", ",", "\n", "mu_init", "=", "0.001", ",", "\n", "omega_lambda", "=", "0.0001", ",", "\n", "omega_mu", "=", "0.9", ",", "\n", "stop_crit_win", "=", "100", ",", "\n", "edge_clamp_range", "=", "0.0001", ",", "\n", "norm_prod", "=", "'paths'", ",", "\n", "square_prod", "=", "False", ")", ":", "\n", "        ", "super", "(", "GraNDAG", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "hidden_num", "=", "hidden_num", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "iterations", "=", "iterations", "\n", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "nonlinear", "=", "nonlinear", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "h_threshold", "=", "h_threshold", "\n", "self", ".", "device_type", "=", "device_type", "\n", "self", ".", "use_pns", "=", "use_pns", "\n", "self", ".", "pns_thresh", "=", "pns_thresh", "\n", "self", ".", "num_neighbors", "=", "num_neighbors", "\n", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "precision", "=", "precision", "\n", "self", ".", "random_seed", "=", "random_seed", "\n", "self", ".", "jac_thresh", "=", "jac_thresh", "\n", "self", ".", "lambda_init", "=", "lambda_init", "\n", "self", ".", "mu_init", "=", "mu_init", "\n", "self", ".", "omega_lambda", "=", "omega_lambda", "\n", "self", ".", "omega_mu", "=", "omega_mu", "\n", "self", ".", "stop_crit_win", "=", "stop_crit_win", "\n", "self", ".", "edge_clamp_range", "=", "edge_clamp_range", "\n", "self", ".", "norm_prod", "=", "norm_prod", "\n", "self", ".", "square_prod", "=", "square_prod", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.gran_dag.GraNDAG.learn": [[245, 332], ["torch.manual_seed", "numpy.random.seed", "castle.common.Tensor", "gran_dag.NormalizationData", "gran_dag.NormalizationData", "gran_dag.GraNDAG._train", "gran_dag.GraNDAG._to_dag", "castle.common.Tensor", "ValueError", "base.NonlinearGauss", "gran_dag.neighbors_selection", "gran_dag.GraNDAG.model.adjacency.detach().numpy", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "ValueError", "base.NonlinearGaussANM", "ValueError", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "gran_dag.GraNDAG.model.adjacency.detach"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GraNDAG._train", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GraNDAG._to_dag", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.neighbors_selection"], ["", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Set up and run the Gran-DAG algorithm\n\n        Parameters\n        ----------\n        data: numpy.ndarray or Tensor\n            include Tensor.data\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        \"\"\"", "\n", "\n", "# Control as much randomness as possible", "\n", "torch", ".", "manual_seed", "(", "self", ".", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "random_seed", ")", "\n", "\n", "# Use gpu", "\n", "if", "self", ".", "device_type", "==", "'gpu'", ":", "\n", "            ", "if", "self", ".", "precision", ":", "\n", "                ", "torch", ".", "set_default_tensor_type", "(", "'torch.cuda.FloatTensor'", ")", "\n", "", "else", ":", "\n", "                ", "torch", ".", "set_default_tensor_type", "(", "'torch.cuda.DoubleTensor'", ")", "\n", "", "", "elif", "self", ".", "device_type", "==", "'cpu'", ":", "\n", "            ", "if", "self", ".", "precision", ":", "\n", "                ", "torch", ".", "set_default_tensor_type", "(", "'torch.FloatTensor'", ")", "\n", "", "else", ":", "\n", "                ", "torch", ".", "set_default_tensor_type", "(", "'torch.DoubleTensor'", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Parameter device_type must be 'cpu' or 'gpu'.\"", ")", "\n", "\n", "# create learning model and ground truth model", "\n", "", "data", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "if", "data", ".", "shape", "[", "1", "]", "!=", "self", ".", "input_dim", ":", "\n", "            ", "raise", "ValueError", "(", "\"The number of variables is `{}`, \"", "\n", "\"the param input_dim is `{}`, \"", "\n", "\"they must be consistent\"", "\n", "\".\"", ".", "format", "(", "data", ".", "shape", "[", "1", "]", ",", "self", ".", "input_dim", ")", ")", "\n", "\n", "", "if", "self", ".", "model_name", "==", "\"NonLinGauss\"", ":", "\n", "            ", "self", ".", "model", "=", "NonlinearGauss", "(", "input_dim", "=", "self", ".", "input_dim", ",", "\n", "hidden_num", "=", "self", ".", "hidden_num", ",", "\n", "hidden_dim", "=", "self", ".", "hidden_dim", ",", "\n", "output_dim", "=", "2", ",", "\n", "nonlinear", "=", "self", ".", "nonlinear", ",", "\n", "norm_prod", "=", "self", ".", "norm_prod", ",", "\n", "square_prod", "=", "self", ".", "square_prod", ")", "\n", "", "elif", "self", ".", "model_name", "==", "\"NonLinGaussANM\"", ":", "\n", "            ", "self", ".", "model", "=", "NonlinearGaussANM", "(", "input_dim", "=", "self", ".", "input_dim", ",", "\n", "hidden_num", "=", "self", ".", "hidden_num", ",", "\n", "hidden_dim", "=", "self", ".", "hidden_dim", ",", "\n", "output_dim", "=", "1", ",", "\n", "nonlinear", "=", "self", ".", "nonlinear", ",", "\n", "norm_prod", "=", "self", ".", "norm_prod", ",", "\n", "square_prod", "=", "self", ".", "square_prod", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"self.model has to be in {NonLinGauss, NonLinGaussANM}\"", ")", "\n", "\n", "# create NormalizationData", "\n", "", "train_data", "=", "NormalizationData", "(", "data", ",", "train", "=", "True", ",", "\n", "normalize", "=", "self", ".", "normalize", ")", "\n", "test_data", "=", "NormalizationData", "(", "data", ",", "train", "=", "False", ",", "\n", "normalize", "=", "self", ".", "normalize", ",", "\n", "mean", "=", "train_data", ".", "mean", ",", "\n", "std", "=", "train_data", ".", "std", ")", "\n", "\n", "# apply preliminary neighborhood selection if input_dim > 50", "\n", "if", "self", ".", "use_pns", ":", "\n", "            ", "if", "self", ".", "num_neighbors", "is", "None", ":", "\n", "                ", "num_neighbors", "=", "self", ".", "input_dim", "\n", "", "else", ":", "\n", "                ", "num_neighbors", "=", "self", ".", "num_neighbors", "\n", "\n", "", "self", ".", "model", "=", "neighbors_selection", "(", "model", "=", "self", ".", "model", ",", "all_samples", "=", "data", ",", "\n", "num_neighbors", "=", "num_neighbors", ",", "\n", "thresh", "=", "self", ".", "pns_thresh", ")", "\n", "\n", "# update self.model by train", "\n", "", "self", ".", "_train", "(", "train_data", "=", "train_data", ",", "test_data", "=", "test_data", ")", "\n", "\n", "# update self.model by run _to_dag", "\n", "self", ".", "_to_dag", "(", "train_data", ")", "\n", "\n", "self", ".", "_causal_matrix", "=", "Tensor", "(", "self", ".", "model", ".", "adjacency", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "\n", "index", "=", "data", ".", "columns", ",", "\n", "columns", "=", "data", ".", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.gran_dag.GraNDAG._train": [[333, 479], ["numpy.zeros", "tqdm.tqdm.tqdm", "torch.optim.SGD", "range", "gran_dag.GraNDAG.model.train", "train_data.sample", "gran_dag.GraNDAG.model.get_parameters", "nlls.append", "gran_dag.GraNDAG.model.eval", "gran_dag.GraNDAG.model.get_w_adj", "base.compute_constraint", "torch.optim.SGD.zero_grad", "aug_lagrangian.backward", "torch.optim.SGD.step", "gran_dag.GraNDAG.detach().cpu().numpy().astype", "mus.append", "lambdas.append", "not_nlls.append", "aug_lagrangians.append", "grad_norms.append", "gran_dag.GraNDAG.model.parameters", "torch.optim.RMSprop", "NotImplementedError", "torch.mean", "loss.item", "aug_lagrangian.item", "gran_dag.GraNDAG.model.get_grad_norm().item", "gran_dag.GraNDAG.model.parameters", "gran_dag.GraNDAG.model.compute_log_likelihood", "torch.no_grad", "gran_dag.GraNDAG.detach().cpu().numpy", "torch.no_grad", "test_data.sample", "nlls_val.append", "aug_lagrangians_val.append", "hs.append", "torch.no_grad", "base.compute_constraint.item", "aug_lagrangian.item", "gran_dag.GraNDAG.model.get_grad_norm", "torch.mean", "loss_val.item", "min", "max", "abs", "base.compute_constraint.item", "base.compute_constraint.item", "len", "torch.no_grad", "torch.optim.RMSprop", "torch.optim.SGD", "gran_dag.GraNDAG.detach().cpu", "base.compute_constraint.item", "gran_dag.GraNDAG.model.compute_log_likelihood", "gran_dag.GraNDAG.model.parameters", "gran_dag.GraNDAG.model.parameters", "gran_dag.GraNDAG.detach", "base.compute_constraint.item", "base.compute_constraint.item"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.train", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_parameters", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_w_adj", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.compute_constraint", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.TrExpScipy.backward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy.step", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.compute_log_likelihood", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_grad_norm", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.compute_log_likelihood"], ["", "def", "_train", "(", "self", ",", "train_data", ",", "test_data", ")", ":", "\n", "        ", "\"\"\"\n        Applying augmented Lagrangian to solve the continuous constrained problem.\n\n        Parameters\n        ----------\n        train_data: NormalizationData\n            train samples\n        test_data: NormalizationData object\n            test samples for validation\n        \"\"\"", "\n", "\n", "# initialize stuff for learning loop", "\n", "aug_lagrangians", "=", "[", "]", "\n", "aug_lagrangian_ma", "=", "[", "0.0", "]", "*", "(", "self", ".", "iterations", "+", "1", ")", "\n", "aug_lagrangians_val", "=", "[", "]", "\n", "grad_norms", "=", "[", "]", "\n", "grad_norm_ma", "=", "[", "0.0", "]", "*", "(", "self", ".", "iterations", "+", "1", ")", "\n", "\n", "w_adjs", "=", "np", ".", "zeros", "(", "(", "self", ".", "iterations", ",", "\n", "self", ".", "input_dim", ",", "\n", "self", ".", "input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "hs", "=", "[", "]", "\n", "not_nlls", "=", "[", "]", "# Augmented Lagrangian minus (pseudo) NLL", "\n", "nlls", "=", "[", "]", "# NLL on train", "\n", "nlls_val", "=", "[", "]", "# NLL on validation", "\n", "\n", "# Augmented Lagrangian stuff", "\n", "mu", "=", "self", ".", "mu_init", "\n", "lamb", "=", "self", ".", "lambda_init", "\n", "mus", "=", "[", "]", "\n", "lambdas", "=", "[", "]", "\n", "\n", "if", "self", ".", "optimizer", "==", "\"sgd\"", ":", "\n", "            ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "optimizer", "==", "\"rmsprop\"", ":", "\n", "            ", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"optimizer {} is not implemented\"", "\n", ".", "format", "(", "self", ".", "optimizer", ")", ")", "\n", "\n", "# Learning loop:", "\n", "", "for", "iter", "in", "tqdm", "(", "range", "(", "self", ".", "iterations", ")", ",", "desc", "=", "'Training Iterations'", ")", ":", "\n", "# compute loss", "\n", "            ", "self", ".", "model", ".", "train", "(", ")", "\n", "x", ",", "_", "=", "train_data", ".", "sample", "(", "self", ".", "batch_size", ")", "\n", "# Initialize weights and bias", "\n", "weights", ",", "biases", ",", "extra_params", "=", "self", ".", "model", ".", "get_parameters", "(", "mode", "=", "\"wbx\"", ")", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "\n", "self", ".", "model", ".", "compute_log_likelihood", "(", "x", ",", "weights", ",", "biases", ",", "extra_params", ")", ")", "\n", "nlls", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "# constraint related", "\n", "w_adj", "=", "self", ".", "model", ".", "get_w_adj", "(", ")", "\n", "h", "=", "compute_constraint", "(", "self", ".", "model", ",", "w_adj", ")", "\n", "\n", "# compute augmented Lagrangian", "\n", "aug_lagrangian", "=", "loss", "+", "0.5", "*", "mu", "*", "h", "**", "2", "+", "lamb", "*", "h", "\n", "\n", "# optimization step on augmented lagrangian", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "aug_lagrangian", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# clamp edges", "\n", "if", "self", ".", "edge_clamp_range", "!=", "0", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "to_keep", "=", "(", "w_adj", ">", "self", ".", "edge_clamp_range", ")", "*", "1", "\n", "self", ".", "model", ".", "adjacency", "*=", "to_keep", "\n", "\n", "# logging", "\n", "", "", "w_adjs", "[", "iter", ",", ":", ",", ":", "]", "=", "w_adj", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "mus", ".", "append", "(", "mu", ")", "\n", "lambdas", ".", "append", "(", "lamb", ")", "\n", "not_nlls", ".", "append", "(", "0.5", "*", "mu", "*", "h", ".", "item", "(", ")", "**", "2", "+", "lamb", "*", "h", ".", "item", "(", ")", ")", "\n", "\n", "# compute augmented lagrangian moving average", "\n", "aug_lagrangians", ".", "append", "(", "aug_lagrangian", ".", "item", "(", ")", ")", "\n", "aug_lagrangian_ma", "[", "iter", "+", "1", "]", "=", "aug_lagrangian_ma", "[", "iter", "]", "+", "0.01", "*", "(", "aug_lagrangian", ".", "item", "(", ")", "-", "\n", "aug_lagrangian_ma", "[", "iter", "]", ")", "\n", "grad_norms", ".", "append", "(", "self", ".", "model", ".", "get_grad_norm", "(", "\"wbx\"", ")", ".", "item", "(", ")", ")", "\n", "grad_norm_ma", "[", "iter", "+", "1", "]", "=", "grad_norm_ma", "[", "iter", "]", "+", "0.01", "*", "(", "grad_norms", "[", "-", "1", "]", "-", "grad_norm_ma", "[", "iter", "]", ")", "\n", "\n", "# compute loss on whole validation set", "\n", "if", "iter", "%", "self", ".", "stop_crit_win", "==", "0", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "x", ",", "_", "=", "test_data", ".", "sample", "(", "test_data", ".", "n_samples", ")", "\n", "loss_val", "=", "-", "torch", ".", "mean", "(", "self", ".", "model", ".", "compute_log_likelihood", "(", "x", ",", "\n", "weights", ",", "\n", "biases", ",", "\n", "extra_params", ")", ")", "\n", "nlls_val", ".", "append", "(", "loss_val", ".", "item", "(", ")", ")", "\n", "aug_lagrangians_val", ".", "append", "(", "[", "iter", ",", "loss_val", "+", "not_nlls", "[", "-", "1", "]", "]", ")", "\n", "\n", "# compute delta for lambda", "\n", "", "", "if", "iter", ">=", "2", "*", "self", ".", "stop_crit_win", "and", "iter", "%", "(", "2", "*", "self", ".", "stop_crit_win", ")", "==", "0", ":", "\n", "                ", "t0", "=", "aug_lagrangians_val", "[", "-", "3", "]", "[", "1", "]", "\n", "t_half", "=", "aug_lagrangians_val", "[", "-", "2", "]", "[", "1", "]", "\n", "t1", "=", "aug_lagrangians_val", "[", "-", "1", "]", "[", "1", "]", "\n", "\n", "# if the validation loss went up and down,", "\n", "# do not update lagrangian and penalty coefficients.", "\n", "if", "not", "(", "min", "(", "t0", ",", "t1", ")", "<", "t_half", "<", "max", "(", "t0", ",", "t1", ")", ")", ":", "\n", "                    ", "delta_lambda", "=", "-", "np", ".", "inf", "\n", "", "else", ":", "\n", "                    ", "delta_lambda", "=", "(", "t1", "-", "t0", ")", "/", "self", ".", "stop_crit_win", "\n", "", "", "else", ":", "\n", "                ", "delta_lambda", "=", "-", "np", ".", "inf", "# do not update lambda nor mu", "\n", "\n", "# Does the augmented lagrangian converged?", "\n", "", "if", "h", ">", "self", ".", "h_threshold", ":", "\n", "# if we have found a stationary point of the augmented loss", "\n", "                ", "if", "abs", "(", "delta_lambda", ")", "<", "self", ".", "omega_lambda", "or", "delta_lambda", ">", "0", ":", "\n", "                    ", "lamb", "+=", "mu", "*", "h", ".", "item", "(", ")", "\n", "\n", "# Did the constraint improve sufficiently?", "\n", "hs", ".", "append", "(", "h", ".", "item", "(", ")", ")", "\n", "if", "len", "(", "hs", ")", ">=", "2", ":", "\n", "                        ", "if", "hs", "[", "-", "1", "]", ">", "hs", "[", "-", "2", "]", "*", "self", ".", "omega_mu", ":", "\n", "                            ", "mu", "*=", "10", "\n", "\n", "# little hack to make sure the moving average is going down.", "\n", "", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "gap_in_not_nll", "=", "0.5", "*", "mu", "*", "h", ".", "item", "(", ")", "**", "2", "+", "lamb", "*", "h", ".", "item", "(", ")", "-", "not_nlls", "[", "-", "1", "]", "\n", "aug_lagrangian_ma", "[", "iter", "+", "1", "]", "+=", "gap_in_not_nll", "\n", "aug_lagrangians_val", "[", "-", "1", "]", "[", "1", "]", "+=", "gap_in_not_nll", "\n", "\n", "", "if", "self", ".", "optimizer", "==", "\"rmsprop\"", ":", "\n", "                        ", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "lr", ")", "\n", "", "else", ":", "\n", "                        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "lr", ")", "\n", "", "", "", "else", ":", "\n", "# Final clamping of all edges == 0", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "to_keep", "=", "(", "w_adj", ">", "0", ")", ".", "type", "(", "torch", ".", "Tensor", ")", "\n", "self", ".", "model", ".", "adjacency", "*=", "to_keep", "\n", "\n", "", "return", "self", ".", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.gran_dag.GraNDAG._to_dag": [[480, 513], ["gran_dag.GraNDAG.model.eval", "gran_dag.GraNDAG.detach().cpu().numpy", "base.compute_jacobian_avg().t", "gran_dag.GraNDAG.model.get_w_adj", "torch.no_grad", "numpy.unique", "enumerate", "gran_dag.GraNDAG.detach().cpu", "torch.Tensor", "base.is_acyclic", "base.compute_jacobian_avg", "gran_dag.GraNDAG.model.adjacency.copy_", "gran_dag.GraNDAG.detach"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_w_adj", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.is_acyclic", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.compute_jacobian_avg"], ["", "", "", "def", "_to_dag", "(", "self", ",", "train_data", ")", ":", "\n", "        ", "\"\"\"\n        1- If some entries of A_\\phi == 0, also mask them\n        (This can happen with stochastic proximal gradient descent)\n        2- Remove edges (from weaker to stronger) until a DAG is obtained.\n\n        Parameters\n        ----------\n        train_data : NormalizationData\n            train samples\n        \"\"\"", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "if", "self", ".", "jac_thresh", ":", "\n", "            ", "A", "=", "compute_jacobian_avg", "(", "self", ".", "model", ",", "train_data", ",", "\n", "train_data", ".", "n_samples", ")", ".", "t", "(", ")", "\n", "", "else", ":", "\n", "            ", "A", "=", "self", ".", "model", ".", "get_w_adj", "(", ")", "\n", "", "A", "=", "A", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Find the smallest threshold that removes all cycle-inducing edges", "\n", "            ", "thresholds", "=", "np", ".", "unique", "(", "A", ")", "\n", "epsilon", "=", "1e-8", "\n", "for", "step", ",", "t", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "                ", "to_keep", "=", "torch", ".", "Tensor", "(", "A", ">", "t", "+", "epsilon", ")", "\n", "new_adj", "=", "self", ".", "model", ".", "adjacency", "*", "to_keep", "\n", "if", "is_acyclic", "(", "new_adj", ")", ":", "\n", "                    ", "self", ".", "model", ".", "adjacency", ".", "copy_", "(", "new_adj", ")", "\n", "break", "\n", "\n", "", "", "", "return", "self", ".", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.gran_dag.neighbors_selection": [[515, 541], ["model.adjacency.detach().cpu().numpy", "gran_dag._pns", "torch.no_grad", "model.adjacency.copy_", "model.adjacency.detach().cpu", "torch.Tensor", "model.adjacency.detach"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag._pns"], ["", "", "def", "neighbors_selection", "(", "model", ",", "all_samples", ",", "num_neighbors", ",", "thresh", ")", ":", "\n", "    ", "\"\"\"\n    Preliminary neighborhood selection\n    After pns, just model.adjacency is changed. if nodes > 50, use it.\n\n    Parameters\n    ----------\n    model: model object\n    all_samples: array-like\n        2 dimensional array include all samples\n    num_neighbors: integer\n        variable number or neighbors number you want\n    thresh: float\n        apply for sklearn.feature_selection.SelectFromModel\n\n    Returns\n    -------\n    out: model\n    \"\"\"", "\n", "\n", "model_adj", "=", "model", ".", "adjacency", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "model_adj", "=", "_pns", "(", "model_adj", ",", "all_samples", ",", "num_neighbors", ",", "thresh", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "model", ".", "adjacency", ".", "copy_", "(", "torch", ".", "Tensor", "(", "model_adj", ")", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.gran_dag._pns": [[543, 578], ["tqdm.tqdm", "range", "numpy.copy", "sklearn.ensemble.ExtraTreesRegressor", "sklearn.ensemble.ExtraTreesRegressor.fit", "sklearn.feature_selection.SelectFromModel", "sklearn.feature_selection.SelectFromModel.get_support"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit"], ["", "def", "_pns", "(", "model_adj", ",", "all_samples", ",", "num_neighbors", ",", "thresh", ")", ":", "\n", "    ", "\"\"\"Preliminary neighborhood selection\n\n    Parameters\n    ----------\n    model_adj : numpy.ndarray\n        adjacency matrix, all element is 1\n    all_samples: numpy.ndarray\n        2 dimensional array include all samples\n    num_neighbors: integer\n        variable number or neighbors number you want\n    thresh: float\n        apply for sklearn.feature_selection.SelectFromModel\n\n    Returns\n    -------\n    model_adj : numpy.ndarray\n        adjacency matrix, after pns process\n    \"\"\"", "\n", "\n", "num_nodes", "=", "all_samples", ".", "shape", "[", "1", "]", "\n", "\n", "for", "node", "in", "tqdm", "(", "range", "(", "num_nodes", ")", ",", "desc", "=", "'Preliminary neighborhood selection'", ")", ":", "\n", "        ", "x_other", "=", "np", ".", "copy", "(", "all_samples", ")", "\n", "x_other", "[", ":", ",", "node", "]", "=", "0", "\n", "extraTree", "=", "ExtraTreesRegressor", "(", "n_estimators", "=", "500", ")", "\n", "extraTree", ".", "fit", "(", "x_other", ",", "all_samples", "[", ":", ",", "node", "]", ")", "\n", "selected_reg", "=", "SelectFromModel", "(", "extraTree", ",", "\n", "threshold", "=", "\"{}*mean\"", ".", "format", "(", "thresh", ")", ",", "\n", "prefit", "=", "True", ",", "\n", "max_features", "=", "num_neighbors", ")", "\n", "mask_selected", "=", "selected_reg", ".", "get_support", "(", "indices", "=", "False", ")", "\n", "model_adj", "[", ":", ",", "node", "]", "*=", "mask_selected", "\n", "\n", "", "return", "model_adj", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.rl.RL.__init__": [[146, 244], ["castle.common.BaseLearner.__init__", "torch.cuda.is_available", "logging.info", "logging.info", "torch.device", "torch.device", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "encoder_type", "=", "'TransformerEncoder'", ",", "\n", "hidden_dim", "=", "64", ",", "\n", "num_heads", "=", "16", ",", "\n", "num_stacks", "=", "6", ",", "\n", "residual", "=", "False", ",", "\n", "decoder_type", "=", "'SingleLayerDecoder'", ",", "\n", "decoder_activation", "=", "'tanh'", ",", "\n", "decoder_hidden_dim", "=", "16", ",", "\n", "use_bias", "=", "False", ",", "\n", "use_bias_constant", "=", "False", ",", "\n", "bias_initial_value", "=", "False", ",", "\n", "batch_size", "=", "64", ",", "\n", "input_dimension", "=", "64", ",", "\n", "normalize", "=", "False", ",", "\n", "transpose", "=", "False", ",", "\n", "score_type", "=", "'BIC'", ",", "\n", "reg_type", "=", "'LR'", ",", "\n", "lambda_iter_num", "=", "1000", ",", "\n", "lambda_flag_default", "=", "True", ",", "\n", "score_bd_tight", "=", "False", ",", "\n", "lambda1_update", "=", "1.0", ",", "\n", "lambda2_update", "=", "10", ",", "\n", "score_lower", "=", "0.0", ",", "\n", "score_upper", "=", "0.0", ",", "\n", "lambda2_lower", "=", "-", "1.0", ",", "\n", "lambda2_upper", "=", "-", "1.0", ",", "\n", "seed", "=", "8", ",", "\n", "nb_epoch", "=", "20000", ",", "\n", "lr1_start", "=", "0.001", ",", "\n", "lr1_decay_step", "=", "5000", ",", "\n", "lr1_decay_rate", "=", "0.96", ",", "\n", "alpha", "=", "0.99", ",", "\n", "init_baseline", "=", "-", "1.0", ",", "\n", "temperature", "=", "3.0", ",", "\n", "C", "=", "10.0", ",", "\n", "l1_graph_reg", "=", "0.0", ",", "\n", "inference_mode", "=", "True", ",", "\n", "verbose", "=", "False", ",", "\n", "device_type", "=", "'cpu'", ",", "\n", "device_ids", "=", "0", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder_type", "=", "encoder_type", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "num_stacks", "=", "num_stacks", "\n", "self", ".", "residual", "=", "residual", "\n", "self", ".", "decoder_type", "=", "decoder_type", "\n", "self", ".", "decoder_activation", "=", "decoder_activation", "\n", "self", ".", "decoder_hidden_dim", "=", "decoder_hidden_dim", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "use_bias_constant", "=", "use_bias_constant", "\n", "self", ".", "bias_initial_value", "=", "bias_initial_value", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "input_dimension", "=", "input_dimension", "\n", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "transpose", "=", "transpose", "\n", "self", ".", "score_type", "=", "score_type", "\n", "self", ".", "reg_type", "=", "reg_type", "\n", "self", ".", "lambda_iter_num", "=", "lambda_iter_num", "\n", "self", ".", "lambda_flag_default", "=", "lambda_flag_default", "\n", "self", ".", "score_bd_tight", "=", "score_bd_tight", "\n", "self", ".", "lambda1_update", "=", "lambda1_update", "\n", "self", ".", "lambda2_update", "=", "lambda2_update", "\n", "self", ".", "score_lower", "=", "score_lower", "\n", "self", ".", "score_upper", "=", "score_upper", "\n", "self", ".", "lambda2_lower", "=", "lambda2_lower", "\n", "self", ".", "lambda2_upper", "=", "lambda2_upper", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "nb_epoch", "=", "nb_epoch", "\n", "self", ".", "lr1_start", "=", "lr1_start", "\n", "self", ".", "lr1_decay_step", "=", "lr1_decay_step", "\n", "self", ".", "lr1_decay_rate", "=", "lr1_decay_rate", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "init_baseline", "=", "init_baseline", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "C", "=", "C", "\n", "self", ".", "l1_graph_reg", "=", "l1_graph_reg", "\n", "self", ".", "inference_mode", "=", "inference_mode", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "device_type", "=", "device_type", "\n", "self", ".", "device_ids", "=", "device_ids", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'GPU is available.'", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "'GPU is unavailable.'", ")", "\n", "if", "self", ".", "device_type", "==", "'gpu'", ":", "\n", "                ", "raise", "ValueError", "(", "\"GPU is unavailable, \"", "\n", "\"please set device_type = 'cpu'.\"", ")", "\n", "", "", "if", "self", ".", "device_type", "==", "'gpu'", ":", "\n", "            ", "if", "self", ".", "device_ids", ":", "\n", "                ", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "self", ".", "device_ids", ")", "\n", "", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.rl.RL.learn": [[245, 268], ["castle.common.Tensor", "rl.RL._rl"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.rl.RL._rl"], ["", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ",", "dag", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Set up and run the RL algorithm.\n\n        Parameters\n        ----------\n        data: castle.Tensor or numpy.ndarray\n            The castle.Tensor or numpy.ndarray format data you want to learn.\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        dag : ndarray\n            two-dimensional, prior matrix\n        \"\"\"", "\n", "\n", "self", ".", "dag", "=", "dag", "\n", "X", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "self", ".", "data_size", "=", "X", ".", "shape", "[", "0", "]", "\n", "self", ".", "max_length", "=", "X", ".", "shape", "[", "1", "]", "\n", "\n", "causal_matrix", "=", "self", ".", "_rl", "(", "X", ")", "\n", "self", ".", "causal_matrix", "=", "causal_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.rl.RL._rl": [[269, 466], ["helpers.torch_utils.set_seed", "logging.info", "models.Actor", "rewards.get_Reward", "logging.info", "float", "logging.info", "tqdm.tqdm.tqdm", "logging.info", "data_loader.DataGenerator_read_data", "data_loader.DataGenerator_read_data", "helpers.lambda_utils.BIC_lambdas", "logging.info", "logging.info", "range", "data_loader.DataGenerator_read_data.train_batch", "torch.from_numpy().to", "models.Actor.build_permutation", "rewards.get_Reward.cal_rewards", "models.Actor.build_reward", "float", "numpy.mean", "lambda1s.append", "lambda2s.append", "rewards_avg_baseline.append", "rewards_batches.append", "reward_max_per_batch.append", "graphss.append", "probsss.append", "max_rewards.append", "platform.python_version", "logging.info", "logging.info", "graphs_feed.cpu().detach().numpy", "logging.info", "logging.info", "logging.info", "rewards.get_Reward.update_all_scores", "min", "min", "logging.info", "helpers.analyze_utils.convert_graph_int_to_adj_mat", "numpy.round", "numpy.round", "torch.from_numpy", "rewards.get_Reward.update_scores", "numpy.int64", "numpy.array", "castle.metrics.MetricsDAG", "castle.metrics.MetricsDAG", "logging.info", "logging.info", "numpy.array", "graphs_feed.cpu().detach", "[].to", "helpers.analyze_utils.graph_prunned_by_coef", "numpy.array", "helpers.analyze_utils.graph_prunned_by_coef_2nd", "graphs_feed.cpu", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.set_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.lambda_utils.BIC_lambdas", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.data_loader.dataset_read_data.DataGenerator.train_batch", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.actor_graph.Actor.build_permutation", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.cal_rewards", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.actor_graph.Actor.build_reward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.update_all_scores", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.convert_graph_int_to_adj_mat", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.update_scores", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.graph_prunned_by_coef", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.analyze_utils.graph_prunned_by_coef_2nd"], ["", "def", "_rl", "(", "self", ",", "X", ")", ":", "\n", "# Reproducibility", "\n", "        ", "set_seed", "(", "self", ".", "seed", ")", "\n", "\n", "logging", ".", "info", "(", "'Python version is {}'", ".", "format", "(", "platform", ".", "python_version", "(", ")", ")", ")", "\n", "\n", "# input data", "\n", "if", "self", ".", "dag", ":", "\n", "            ", "training_set", "=", "DataGenerator_read_data", "(", "\n", "X", ",", "self", ".", "dag", ",", "self", ".", "normalize", ",", "self", ".", "transpose", ")", "\n", "", "else", ":", "\n", "            ", "training_set", "=", "DataGenerator_read_data", "(", "\n", "X", ",", "None", ",", "self", ".", "normalize", ",", "self", ".", "transpose", ")", "\n", "\n", "# set penalty weights", "\n", "", "score_type", "=", "self", ".", "score_type", "\n", "reg_type", "=", "self", ".", "reg_type", "\n", "\n", "if", "self", ".", "lambda_flag_default", ":", "\n", "            ", "sl", ",", "su", ",", "strue", "=", "BIC_lambdas", "(", "training_set", ".", "inputdata", ",", "None", ",", "None", ",", "None", ",", "reg_type", ",", "score_type", ")", "\n", "lambda1", "=", "0", "\n", "lambda1_upper", "=", "5", "\n", "lambda1_update_add", "=", "1", "\n", "lambda2", "=", "1", "/", "(", "10", "**", "(", "np", ".", "round", "(", "self", ".", "max_length", "/", "3", ")", ")", ")", "\n", "lambda2_upper", "=", "0.01", "\n", "lambda2_update_mul", "=", "10", "\n", "lambda_iter_num", "=", "self", ".", "lambda_iter_num", "\n", "\n", "# test initialized score", "\n", "logging", ".", "info", "(", "'Original sl: {}, su: {}, strue: {}'", ".", "format", "(", "sl", ",", "su", ",", "strue", ")", ")", "\n", "logging", ".", "info", "(", "'Transfomed sl: {}, su: {}, lambda2: {}, true: {}'", ".", "format", "(", "sl", ",", "su", ",", "lambda2", ",", "\n", "(", "strue", "-", "sl", ")", "/", "(", "su", "-", "sl", ")", "*", "lambda1_upper", ")", ")", "\n", "", "else", ":", "\n", "# test choices for the case with mannualy provided bounds", "\n", "# not fully tested", "\n", "            ", "sl", "=", "self", ".", "score_lower", "\n", "su", "=", "self", ".", "score_upper", "\n", "if", "self", ".", "score_bd_tight", ":", "\n", "                ", "lambda1", "=", "2", "\n", "lambda1_upper", "=", "2", "\n", "", "else", ":", "\n", "                ", "lambda1", "=", "0", "\n", "lambda1_upper", "=", "5", "\n", "lambda1_update_add", "=", "1", "\n", "", "lambda2", "=", "1", "/", "(", "10", "**", "(", "np", ".", "round", "(", "self", ".", "max_length", "/", "3", ")", ")", ")", "\n", "lambda2_upper", "=", "0.01", "\n", "lambda2_update_mul", "=", "self", ".", "lambda2_update", "\n", "lambda_iter_num", "=", "self", ".", "lambda_iter_num", "\n", "\n", "# actor", "\n", "", "actor", "=", "Actor", "(", "encoder_type", "=", "self", ".", "encoder_type", ",", "\n", "hidden_dim", "=", "self", ".", "hidden_dim", ",", "\n", "max_length", "=", "self", ".", "max_length", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "num_stacks", "=", "self", ".", "num_stacks", ",", "\n", "residual", "=", "self", ".", "residual", ",", "\n", "decoder_type", "=", "self", ".", "decoder_type", ",", "\n", "decoder_activation", "=", "self", ".", "decoder_activation", ",", "\n", "decoder_hidden_dim", "=", "self", ".", "decoder_hidden_dim", ",", "\n", "use_bias", "=", "self", ".", "use_bias", ",", "\n", "use_bias_constant", "=", "self", ".", "use_bias_constant", ",", "\n", "bias_initial_value", "=", "self", ".", "bias_initial_value", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "input_dimension", "=", "self", ".", "input_dimension", ",", "\n", "lr1_start", "=", "self", ".", "lr1_start", ",", "\n", "lr1_decay_step", "=", "self", ".", "lr1_decay_step", ",", "\n", "lr1_decay_rate", "=", "self", ".", "lr1_decay_rate", ",", "\n", "alpha", "=", "self", ".", "alpha", ",", "\n", "init_baseline", "=", "self", ".", "init_baseline", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "callreward", "=", "get_Reward", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ",", "\n", "self", ".", "input_dimension", ",", "training_set", ".", "inputdata", ",", "\n", "sl", ",", "su", ",", "lambda1_upper", ",", "score_type", ",", "reg_type", ",", "\n", "self", ".", "l1_graph_reg", ",", "False", ")", "\n", "logging", ".", "info", "(", "'Finished creating training dataset and reward class'", ")", "\n", "\n", "# Initialize useful variables", "\n", "rewards_avg_baseline", "=", "[", "]", "\n", "rewards_batches", "=", "[", "]", "\n", "reward_max_per_batch", "=", "[", "]", "\n", "\n", "lambda1s", "=", "[", "]", "\n", "lambda2s", "=", "[", "]", "\n", "\n", "graphss", "=", "[", "]", "\n", "probsss", "=", "[", "]", "\n", "max_rewards", "=", "[", "]", "\n", "max_reward", "=", "float", "(", "'-inf'", ")", "\n", "max_reward_score_cyc", "=", "(", "lambda1_upper", "+", "1", ",", "0", ")", "\n", "\n", "logging", ".", "info", "(", "'Starting training.'", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "1", ",", "self", ".", "nb_epoch", "+", "1", ")", ")", ":", "\n", "\n", "            ", "if", "self", ".", "verbose", ":", "\n", "                ", "logging", ".", "info", "(", "'Start training for {}-th epoch'", ".", "format", "(", "i", ")", ")", "\n", "\n", "", "input_batch", "=", "training_set", ".", "train_batch", "(", "self", ".", "batch_size", ",", "self", ".", "max_length", ",", "self", ".", "input_dimension", ")", "\n", "inputs", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "input_batch", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Test tensor shape", "\n", "if", "i", "==", "1", ":", "\n", "                ", "logging", ".", "info", "(", "'Shape of actor.input: {}'", ".", "format", "(", "inputs", ".", "shape", ")", ")", "\n", "\n", "# actor", "\n", "", "actor", ".", "build_permutation", "(", "inputs", ")", "\n", "graphs_feed", "=", "actor", ".", "graphs_", "\n", "\n", "reward_feed", "=", "callreward", ".", "cal_rewards", "(", "graphs_feed", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "lambda1", ",", "lambda2", ")", "# np.array", "\n", "actor", ".", "build_reward", "(", "reward_", "=", "-", "torch", ".", "from_numpy", "(", "reward_feed", ")", "[", ":", ",", "0", "]", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "\n", "# max reward, max reward per batch", "\n", "max_reward", "=", "-", "callreward", ".", "update_scores", "(", "[", "max_reward_score_cyc", "]", ",", "lambda1", ",", "lambda2", ")", "[", "0", "]", "\n", "max_reward_batch", "=", "float", "(", "'inf'", ")", "\n", "max_reward_batch_score_cyc", "=", "(", "0", ",", "0", ")", "\n", "\n", "for", "reward_", ",", "score_", ",", "cyc_", "in", "reward_feed", ":", "\n", "                ", "if", "reward_", "<", "max_reward_batch", ":", "\n", "                    ", "max_reward_batch", "=", "reward_", "\n", "max_reward_batch_score_cyc", "=", "(", "score_", ",", "cyc_", ")", "\n", "\n", "", "", "max_reward_batch", "=", "-", "max_reward_batch", "\n", "\n", "if", "max_reward", "<", "max_reward_batch", ":", "\n", "                ", "max_reward", "=", "max_reward_batch", "\n", "max_reward_score_cyc", "=", "max_reward_batch_score_cyc", "\n", "\n", "# for average reward per batch", "\n", "", "reward_batch_score_cyc", "=", "np", ".", "mean", "(", "reward_feed", "[", ":", ",", "1", ":", "]", ",", "axis", "=", "0", ")", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "logging", ".", "info", "(", "'Finish calculating reward for current batch of graph'", ")", "\n", "\n", "", "score_test", ",", "probs", ",", "graph_batch", ",", "reward_batch", ",", "reward_avg_baseline", "=", "actor", ".", "test_scores", ",", "actor", ".", "log_softmax", ",", "actor", ".", "graph_batch", ",", "actor", ".", "reward_batch", ",", "actor", ".", "avg_baseline", "\n", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "logging", ".", "info", "(", "'Finish updating actor and critic network using reward calculated'", ")", "\n", "\n", "", "lambda1s", ".", "append", "(", "lambda1", ")", "\n", "lambda2s", ".", "append", "(", "lambda2", ")", "\n", "\n", "rewards_avg_baseline", ".", "append", "(", "reward_avg_baseline", ")", "\n", "rewards_batches", ".", "append", "(", "reward_batch_score_cyc", ")", "\n", "reward_max_per_batch", ".", "append", "(", "max_reward_batch_score_cyc", ")", "\n", "\n", "graphss", ".", "append", "(", "graph_batch", ")", "\n", "probsss", ".", "append", "(", "probs", ")", "\n", "max_rewards", ".", "append", "(", "max_reward_score_cyc", ")", "\n", "\n", "# logging", "\n", "if", "i", "==", "1", "or", "i", "%", "500", "==", "0", ":", "\n", "                ", "logging", ".", "info", "(", "'[iter {}] reward_batch: {:.4}, max_reward: {:.4}, max_reward_batch: {:.4}'", ".", "format", "(", "i", ",", "\n", "reward_batch", ",", "max_reward", ",", "max_reward_batch", ")", ")", "\n", "\n", "# update lambda1, lamda2", "\n", "", "if", "i", "==", "1", "or", "i", "%", "lambda_iter_num", "==", "0", ":", "\n", "                ", "ls_kv", "=", "callreward", ".", "update_all_scores", "(", "lambda1", ",", "lambda2", ")", "\n", "\n", "graph_int", ",", "score_min", ",", "cyc_min", "=", "np", ".", "int64", "(", "ls_kv", "[", "0", "]", "[", "0", "]", ")", ",", "ls_kv", "[", "0", "]", "[", "1", "]", "[", "1", "]", ",", "ls_kv", "[", "0", "]", "[", "1", "]", "[", "-", "1", "]", "\n", "\n", "if", "cyc_min", "<", "1e-5", ":", "\n", "                    ", "lambda1_upper", "=", "score_min", "\n", "", "lambda1", "=", "min", "(", "lambda1", "+", "lambda1_update_add", ",", "lambda1_upper", ")", "\n", "lambda2", "=", "min", "(", "lambda2", "*", "lambda2_update_mul", ",", "lambda2_upper", ")", "\n", "logging", ".", "info", "(", "'[iter {}] lambda1 {:.4}, upper {:.4}, lambda2 {:.4}, upper {:.4}, score_min {:.4}, cyc_min {:.4}'", ".", "format", "(", "i", ",", "\n", "lambda1", "*", "1.0", ",", "lambda1_upper", "*", "1.0", ",", "lambda2", "*", "1.0", ",", "lambda2_upper", "*", "1.0", ",", "score_min", "*", "1.0", ",", "cyc_min", "*", "1.0", ")", ")", "\n", "\n", "graph_batch", "=", "convert_graph_int_to_adj_mat", "(", "graph_int", ")", "\n", "\n", "if", "reg_type", "==", "'LR'", ":", "\n", "                    ", "graph_batch_pruned", "=", "np", ".", "array", "(", "graph_prunned_by_coef", "(", "graph_batch", ",", "training_set", ".", "inputdata", ")", ")", "\n", "", "elif", "reg_type", "==", "'QR'", ":", "\n", "                    ", "graph_batch_pruned", "=", "np", ".", "array", "(", "graph_prunned_by_coef_2nd", "(", "graph_batch", ",", "training_set", ".", "inputdata", ")", ")", "\n", "\n", "", "if", "self", ".", "dag", ":", "\n", "                    ", "met", "=", "MetricsDAG", "(", "graph_batch", ".", "T", ",", "training_set", ".", "true_graph", ")", "\n", "met2", "=", "MetricsDAG", "(", "graph_batch_pruned", ".", "T", ",", "training_set", ".", "true_graph", ")", "\n", "acc_est", "=", "met", ".", "metrics", "\n", "acc_est2", "=", "met2", ".", "metrics", "\n", "\n", "fdr", ",", "tpr", ",", "fpr", ",", "shd", ",", "nnz", "=", "acc_est", "[", "'fdr'", "]", ",", "acc_est", "[", "'tpr'", "]", ",", "acc_est", "[", "'fpr'", "]", ",", "acc_est", "[", "'shd'", "]", ",", "acc_est", "[", "'nnz'", "]", "\n", "fdr2", ",", "tpr2", ",", "fpr2", ",", "shd2", ",", "nnz2", "=", "acc_est2", "[", "'fdr'", "]", ",", "acc_est2", "[", "'tpr'", "]", ",", "acc_est2", "[", "'fpr'", "]", ",", "acc_est2", "[", "'shd'", "]", ",", "acc_est2", "[", "'nnz'", "]", "\n", "\n", "logging", ".", "info", "(", "'before pruning: fdr {}, tpr {}, fpr {}, shd {}, nnz {}'", ".", "format", "(", "fdr", ",", "tpr", ",", "fpr", ",", "shd", ",", "nnz", ")", ")", "\n", "logging", ".", "info", "(", "'after  pruning: fdr {}, tpr {}, fpr {}, shd {}, nnz {}'", ".", "format", "(", "fdr2", ",", "tpr2", ",", "fpr2", ",", "shd2", ",", "nnz2", ")", ")", "\n", "\n", "", "", "", "logging", ".", "info", "(", "'Training COMPLETED !'", ")", "\n", "\n", "return", "graph_batch_pruned", ".", "T", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.corl.CORL.__init__": [[125, 186], ["castle.common.BaseLearner.__init__", "argparse.ArgumentParser", "argparse.ArgumentParser.parse_args", "torch.cuda.is_available", "torch.tensor", "logging.info", "logging.info", "torch.device", "torch.device", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", "=", "64", ",", "input_dim", "=", "100", ",", "embed_dim", "=", "256", ",", "\n", "normalize", "=", "False", ",", "\n", "encoder_name", "=", "'transformer'", ",", "\n", "encoder_heads", "=", "8", ",", "\n", "encoder_blocks", "=", "3", ",", "\n", "encoder_dropout_rate", "=", "0.1", ",", "\n", "decoder_name", "=", "'lstm'", ",", "\n", "reward_mode", "=", "'episodic'", ",", "\n", "reward_score_type", "=", "'BIC'", ",", "\n", "reward_regression_type", "=", "'LR'", ",", "\n", "reward_gpr_alpha", "=", "1.0", ",", "\n", "iteration", "=", "10000", ",", "\n", "actor_lr", "=", "1e-4", ",", "\n", "critic_lr", "=", "1e-3", ",", "\n", "alpha", "=", "0.99", ",", "# for score function", "\n", "init_baseline", "=", "-", "1.0", ",", "\n", "random_seed", "=", "0", ",", "\n", "device_type", "=", "'cpu'", ",", "\n", "device_ids", "=", "0", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Configuration'", ")", "\n", "self", ".", "config", "=", "parser", ".", "parse_args", "(", "args", "=", "[", "]", ")", "\n", "self", ".", "config", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "config", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "config", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "config", ".", "normalize", "=", "normalize", "\n", "self", ".", "config", ".", "encoder_name", "=", "encoder_name", "\n", "self", ".", "config", ".", "encoder_heads", "=", "encoder_heads", "\n", "self", ".", "config", ".", "encoder_blocks", "=", "encoder_blocks", "\n", "self", ".", "config", ".", "encoder_dropout_rate", "=", "encoder_dropout_rate", "\n", "self", ".", "config", ".", "decoder_name", "=", "decoder_name", "\n", "self", ".", "config", ".", "reward_mode", "=", "reward_mode", "\n", "self", ".", "config", ".", "reward_score_type", "=", "reward_score_type", "\n", "self", ".", "config", ".", "reward_regression_type", "=", "reward_regression_type", "\n", "self", ".", "config", ".", "reward_gpr_alpha", "=", "reward_gpr_alpha", "\n", "self", ".", "config", ".", "iteration", "=", "iteration", "\n", "self", ".", "config", ".", "actor_lr", "=", "actor_lr", "\n", "self", ".", "config", ".", "critic_lr", "=", "critic_lr", "\n", "self", ".", "config", ".", "alpha", "=", "alpha", "\n", "self", ".", "config", ".", "init_baseline", "=", "init_baseline", "\n", "self", ".", "config", ".", "random_seed", "=", "random_seed", "\n", "self", ".", "device_type", "=", "device_type", "\n", "self", ".", "device_ids", "=", "device_ids", "\n", "if", "reward_mode", "==", "'dense'", ":", "\n", "            ", "self", ".", "avg_baseline", "=", "torch", ".", "tensor", "(", "init_baseline", ",", "requires_grad", "=", "False", ")", "\n", "\n", "", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'GPU is available.'", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "'GPU is unavailable.'", ")", "\n", "if", "self", ".", "device_type", "==", "'gpu'", ":", "\n", "                ", "raise", "ValueError", "(", "\"GPU is unavailable, \"", "\n", "\"please set device_type = 'cpu'.\"", ")", "\n", "", "", "if", "self", ".", "device_type", "==", "'gpu'", ":", "\n", "            ", "if", "self", ".", "device_ids", ":", "\n", "                ", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "self", ".", "device_ids", ")", "\n", "", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.corl.CORL.learn": [[188, 221], ["castle.common.Tensor", "getattr", "corl.CORL._rl_search", "castle.common.Tensor", "ValueError"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.corl.CORL._rl_search"], ["", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Set up and run the Causal discovery with Ordering-based Reinforcement\n        Learning algorithm.\n\n        Parameters\n        ----------\n        data: castle.Tensor or numpy.ndarray\n            The castle.Tensor or numpy.ndarray format data you want to learn.\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        Other Parameters:\n            dag_mask : ndarray\n                two-dimensional array with [0, 1], shape = [n_nodes, n_nodes].\n                (i, j) indicated element `0` denotes there must be no edge\n                between nodes `i` and `j` , the element `1` indicates that\n                there may or may not be an edge.\n        \"\"\"", "\n", "\n", "X", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "self", ".", "config", ".", "n_samples", "=", "X", ".", "shape", "[", "0", "]", "\n", "self", ".", "config", ".", "seq_length", "=", "X", ".", "shape", "[", "1", "]", "# seq_length == n_nodes", "\n", "if", "X", ".", "shape", "[", "1", "]", ">", "self", ".", "config", ".", "batch_size", ":", "\n", "            ", "raise", "ValueError", "(", "f'The `batch_size` must greater than or equal to '", "\n", "f'`n_nodes`, but got '", "\n", "f'batch_size: {self.config.batch_size}, '", "\n", "f'n_nodes: {self.config.seq_length}.'", ")", "\n", "", "self", ".", "dag_mask", "=", "getattr", "(", "kwargs", ",", "'dag_mask'", ",", "None", ")", "\n", "causal_matrix", "=", "self", ".", "_rl_search", "(", "X", ")", "\n", "self", ".", "causal_matrix", "=", "Tensor", "(", "causal_matrix", ",", "\n", "index", "=", "X", ".", "columns", ",", "\n", "columns", "=", "X", ".", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.corl.CORL._rl_search": [[222, 395], ["corl.set_seed", "logging.info", "utils.data_loader.DataGenerator", "frame.Actor", "frame.Reward", "torch.optim.Adam", "float", "logging.info", "logging.info", "logging.info", "castle.common.Tensor", "tqdm.tqdm.tqdm", "frame.EpisodicCritic", "frame.DenseCritic", "range", "utils.data_loader.DataGenerator.draw_batch", "frame.Actor.encode", "frame.Actor.decode", "range", "numpy.stack", "numpy.stack", "frame.Reward.cal_rewards", "s_list.reshape", "h_list.reshape", "c_list.reshape", "numpy.stack.reshape", "frame.Actor.decoder.log_softmax", "torch.optim.Adam.zero_grad", "frame.score_function.dense_actor_loss.backward", "frame.score_function.dense_critic_loss.backward", "torch.optim.Adam.step", "platform.python_version", "utils.data_loader.DataGenerator.dataset.cpu().detach().numpy", "numpy.ones", "numpy.eye", "utils.graph_analysis.get_graph_from_order", "numpy.zeros", "numpy.stack.append", "actions.cpu", "torch.sum.reshape", "frame.DenseCritic.predict_env", "frame.DenseCritic.predict_tgt", "frame.DenseCritic.soft_replacement", "frame.score_function.episodic_actor_loss", "frame.score_function.episodic_critic_loss", "logging.info", "frame.Reward.update_all_scores", "logging.info", "utils.graph_analysis.get_graph_from_order", "frame.Actor.encoder.parameters", "frame.Actor.decoder.parameters", "frame.DenseCritic.parameters", "actions[].cpu", "numpy.stack.append", "torch.sum", "numpy.mean", "frame.DenseCritic.predict_reward", "frame.score_function.dense_actor_loss", "frame.score_function.dense_critic_loss", "ValueError", "utils.graph_analysis.pruning_by_coef", "utils.data_loader.DataGenerator.dataset.cpu().detach", "numpy.zeros.copy", "numpy.eye", "torch.tensor", "torch.tensor", "utils.data_loader.DataGenerator.dataset.cpu().detach().numpy", "utils.graph_analysis.pruning_by_coef_2nd", "ValueError", "utils.data_loader.DataGenerator.dataset.cpu().detach().numpy", "utils.data_loader.DataGenerator.dataset.cpu", "utils.data_loader.DataGenerator.dataset.cpu().detach", "utils.data_loader.DataGenerator.dataset.cpu().detach", "utils.data_loader.DataGenerator.dataset.cpu", "utils.data_loader.DataGenerator.dataset.cpu"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.set_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.data_loader.DataGenerator.draw_batch", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Encoder.encode", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder.decode", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.cal_rewards", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models._base_network.PointerDecoder.log_softmax", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.TrExpScipy.backward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.TrExpScipy.backward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy.step", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.graph_analysis.get_graph_from_order", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._critic.EpisodicCritic.predict_env", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._critic.EpisodicCritic.predict_tgt", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._critic.EpisodicCritic.soft_replacement", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame.score_function.episodic_actor_loss", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame.score_function.episodic_critic_loss", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.update_all_scores", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.graph_analysis.get_graph_from_order", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._critic.DenseCritic.predict_reward", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame.score_function.dense_actor_loss", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame.score_function.dense_critic_loss", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.graph_analysis.pruning_by_coef", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.graph_analysis.pruning_by_coef_2nd"], ["", "def", "_rl_search", "(", "self", ",", "X", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Search DAG with ordering-based reinforcement learning\n\n        Parameters\n        ----------\n        X: numpy.ndarray\n            The numpy.ndarray format data you want to learn.\n        \"\"\"", "\n", "\n", "set_seed", "(", "self", ".", "config", ".", "random_seed", ")", "\n", "logging", ".", "info", "(", "'Python version is {}'", ".", "format", "(", "platform", ".", "python_version", "(", ")", ")", ")", "\n", "\n", "# generate observed data", "\n", "data_generator", "=", "DataGenerator", "(", "dataset", "=", "X", ",", "\n", "normalize", "=", "self", ".", "config", ".", "normalize", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "# Instantiating an Actor", "\n", "actor", "=", "Actor", "(", "input_dim", "=", "self", ".", "config", ".", "input_dim", ",", "\n", "embed_dim", "=", "self", ".", "config", ".", "embed_dim", ",", "\n", "encoder_blocks", "=", "self", ".", "config", ".", "encoder_blocks", ",", "\n", "encoder_heads", "=", "self", ".", "config", ".", "encoder_heads", ",", "\n", "encoder_name", "=", "self", ".", "config", ".", "encoder_name", ",", "\n", "decoder_name", "=", "self", ".", "config", ".", "decoder_name", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "# Instantiating an Critic", "\n", "if", "self", ".", "config", ".", "reward_mode", "==", "'episodic'", ":", "\n", "            ", "critic", "=", "EpisodicCritic", "(", "input_dim", "=", "self", ".", "config", ".", "embed_dim", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "critic", "=", "DenseCritic", "(", "input_dim", "=", "self", ".", "config", ".", "embed_dim", ",", "\n", "output_dim", "=", "self", ".", "config", ".", "embed_dim", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "# Instantiating an Reward", "\n", "", "reward", "=", "Reward", "(", "input_data", "=", "data_generator", ".", "dataset", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "\n", "reward_mode", "=", "self", ".", "config", ".", "reward_mode", ",", "\n", "score_type", "=", "self", ".", "config", ".", "reward_score_type", ",", "\n", "regression_type", "=", "self", ".", "config", ".", "reward_regression_type", ",", "\n", "alpha", "=", "self", ".", "config", ".", "reward_gpr_alpha", ")", "\n", "# Instantiating an Optimizer", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "[", "\n", "{", "\n", "'params'", ":", "actor", ".", "encoder", ".", "parameters", "(", ")", ",", "'lr'", ":", "self", ".", "config", ".", "actor_lr", "\n", "}", ",", "\n", "{", "\n", "'params'", ":", "actor", ".", "decoder", ".", "parameters", "(", ")", ",", "'lr'", ":", "self", ".", "config", ".", "actor_lr", "\n", "}", ",", "\n", "{", "\n", "'params'", ":", "critic", ".", "parameters", "(", ")", ",", "'lr'", ":", "self", ".", "config", ".", "critic_lr", "\n", "}", "\n", "]", ")", "\n", "\n", "# initial max_reward", "\n", "max_reward", "=", "float", "(", "'-inf'", ")", "\n", "\n", "logging", ".", "info", "(", "f'Shape of input batch: {self.config.batch_size}, '", "\n", "f'{self.config.seq_length}, {self.config.input_dim}'", ")", "\n", "logging", ".", "info", "(", "f'Shape of input batch: {self.config.batch_size}, '", "\n", "f'{self.config.seq_length}, {self.config.embed_dim}'", ")", "\n", "logging", ".", "info", "(", "'Starting training.'", ")", "\n", "\n", "graph_batch_pruned", "=", "Tensor", "(", "np", ".", "ones", "(", "(", "self", ".", "config", ".", "seq_length", ",", "\n", "self", ".", "config", ".", "seq_length", ")", ")", "-", "\n", "np", ".", "eye", "(", "self", ".", "config", ".", "seq_length", ")", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "1", ",", "self", ".", "config", ".", "iteration", "+", "1", ")", ")", ":", "\n", "# generate one batch input", "\n", "            ", "input_batch", "=", "data_generator", ".", "draw_batch", "(", "batch_size", "=", "self", ".", "config", ".", "batch_size", ",", "\n", "dimension", "=", "self", ".", "config", ".", "input_dim", ")", "\n", "# (batch_size, n_nodes, input_dim)", "\n", "encoder_output", "=", "actor", ".", "encode", "(", "input", "=", "input_batch", ")", "\n", "decoder_output", "=", "actor", ".", "decode", "(", "input", "=", "encoder_output", ")", "\n", "actions", ",", "mask_scores", ",", "s_list", ",", "h_list", ",", "c_list", "=", "decoder_output", "\n", "\n", "batch_graphs", "=", "[", "]", "\n", "action_mask_s", "=", "[", "]", "\n", "for", "m", "in", "range", "(", "actions", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "zero_matrix", "=", "get_graph_from_order", "(", "actions", "[", "m", "]", ".", "cpu", "(", ")", ")", "\n", "action_mask", "=", "np", ".", "zeros", "(", "zero_matrix", ".", "shape", "[", "0", "]", ")", "\n", "for", "act", "in", "actions", "[", "m", "]", ":", "\n", "                    ", "action_mask_s", ".", "append", "(", "action_mask", ".", "copy", "(", ")", ")", "\n", "action_mask", "+=", "np", ".", "eye", "(", "zero_matrix", ".", "shape", "[", "0", "]", ")", "[", "act", "]", "\n", "", "batch_graphs", ".", "append", "(", "zero_matrix", ")", "\n", "", "batch_graphs", "=", "np", ".", "stack", "(", "batch_graphs", ")", "# 64*10*10", "\n", "action_mask_s", "=", "np", ".", "stack", "(", "action_mask_s", ")", "\n", "\n", "# Reward", "\n", "reward_output", "=", "reward", ".", "cal_rewards", "(", "batch_graphs", ",", "actions", ".", "cpu", "(", ")", ")", "\n", "reward_list", ",", "normal_batch_reward", ",", "max_reward_batch", ",", "td_target", "=", "reward_output", "\n", "\n", "if", "max_reward", "<", "max_reward_batch", ":", "\n", "                ", "max_reward", "=", "max_reward_batch", "\n", "\n", "# Critic", "\n", "", "prev_input", "=", "s_list", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "config", ".", "embed_dim", ")", ")", "\n", "prev_state_0", "=", "h_list", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "config", ".", "embed_dim", ")", ")", "\n", "prev_state_1", "=", "c_list", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "config", ".", "embed_dim", ")", ")", "\n", "\n", "action_mask_", "=", "action_mask_s", ".", "reshape", "(", "(", "-", "1", ",", "self", ".", "config", ".", "seq_length", ")", ")", "\n", "log_softmax", "=", "actor", ".", "decoder", ".", "log_softmax", "(", "input", "=", "prev_input", ",", "\n", "position", "=", "actions", ",", "\n", "mask", "=", "action_mask_", ",", "\n", "state_0", "=", "prev_state_0", ",", "\n", "state_1", "=", "prev_state_1", ")", "\n", "log_softmax", "=", "log_softmax", ".", "reshape", "(", "(", "self", ".", "config", ".", "batch_size", ",", "\n", "self", ".", "config", ".", "seq_length", ")", ")", ".", "T", "\n", "if", "self", ".", "config", ".", "reward_mode", "==", "'episodic'", ":", "\n", "                ", "critic", ".", "predict_env", "(", "stats_x", "=", "s_list", "[", ":", ",", ":", "-", "1", ",", ":", "]", ")", "\n", "critic", ".", "predict_tgt", "(", "stats_y", "=", "s_list", "[", ":", ",", "1", ":", ",", ":", "]", ")", "\n", "critic", ".", "soft_replacement", "(", ")", "\n", "td_target", "=", "td_target", "[", ":", ":", "-", "1", "]", "[", ":", "-", "1", "]", "\n", "\n", "actor_loss", "=", "Score_Func", ".", "episodic_actor_loss", "(", "\n", "td_target", "=", "torch", ".", "tensor", "(", "td_target", ")", ",", "\n", "prediction_env", "=", "critic", ".", "prediction_env", ",", "\n", "log_softmax", "=", "log_softmax", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "critic_loss", "=", "Score_Func", ".", "episodic_critic_loss", "(", "\n", "td_target", "=", "torch", ".", "tensor", "(", "td_target", ")", ",", "\n", "prediction_env", "=", "critic", ".", "prediction_env", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "", "elif", "self", ".", "config", ".", "reward_mode", "==", "'dense'", ":", "\n", "                ", "log_softmax", "=", "torch", ".", "sum", "(", "log_softmax", ",", "0", ")", "\n", "reward_mean", "=", "np", ".", "mean", "(", "normal_batch_reward", ")", "\n", "self", ".", "avg_baseline", "=", "self", ".", "config", ".", "alpha", "*", "self", ".", "avg_baseline", "+", "(", "1.0", "-", "self", ".", "config", ".", "alpha", ")", "*", "reward_mean", "\n", "predict_reward", "=", "critic", ".", "predict_reward", "(", "encoder_output", "=", "encoder_output", ")", "\n", "\n", "actor_loss", "=", "Score_Func", ".", "dense_actor_loss", "(", "normal_batch_reward", ",", "\n", "self", ".", "avg_baseline", ",", "\n", "predict_reward", ",", "\n", "log_softmax", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "critic_loss", "=", "Score_Func", ".", "dense_critic_loss", "(", "normal_batch_reward", ",", "\n", "self", ".", "avg_baseline", ",", "\n", "predict_reward", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"reward_mode must be one of ['episodic', \"", "\n", "f\"'dense'], but got {self.config.reward_mode}.\"", ")", "\n", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "actor_loss", ".", "backward", "(", ")", "\n", "critic_loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# logging", "\n", "if", "i", "==", "1", "or", "i", "%", "consts", ".", "LOG_FREQUENCY", "==", "0", ":", "\n", "                ", "logging", ".", "info", "(", "'[iter {}] max_reward: {:.4}, '", "\n", "'max_reward_batch: {:.4}'", ".", "format", "(", "i", ",", "max_reward", ",", "\n", "max_reward_batch", ")", ")", "\n", "", "if", "i", "==", "1", "or", "i", "%", "consts", ".", "LOG_FREQUENCY", "==", "0", ":", "\n", "                ", "ls_kv", "=", "reward", ".", "update_all_scores", "(", ")", "\n", "score_min", ",", "graph_int_key", "=", "ls_kv", "[", "0", "]", "[", "1", "]", "[", "0", "]", ",", "ls_kv", "[", "0", "]", "[", "0", "]", "\n", "logging", ".", "info", "(", "'[iter {}] score_min {:.4}'", ".", "format", "(", "i", ",", "score_min", "*", "1.0", ")", ")", "\n", "graph_batch", "=", "get_graph_from_order", "(", "graph_int_key", ",", "\n", "dag_mask", "=", "self", ".", "dag_mask", ")", "\n", "\n", "if", "self", ".", "config", ".", "reward_regression_type", "==", "'LR'", ":", "\n", "                    ", "graph_batch_pruned", "=", "pruning_by_coef", "(", "\n", "graph_batch", ",", "data_generator", ".", "dataset", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "", "elif", "self", ".", "config", ".", "reward_regression_type", "==", "'QR'", ":", "\n", "                    ", "graph_batch_pruned", "=", "pruning_by_coef_2nd", "(", "\n", "graph_batch", ",", "data_generator", ".", "dataset", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"reward_regression_type must be one of \"", "\n", "f\"['LR', 'QR'], but got \"", "\n", "f\"{self.config.reward_regression_type}.\"", ")", "\n", "\n", "", "", "", "return", "graph_batch_pruned", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.corl.set_seed": [[34, 47], ["random.seed", "numpy.random.seed", "torch.manual_seed", "str"], "function", ["None"], ["def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "\"\"\"\n    Referred from:\n    - https://stackoverflow.com/questions/38469632/tensorflow-non-repeatable-results\n    \"\"\"", "\n", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "try", ":", "\n", "        ", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.mcsl.MCSL.__init__": [[112, 153], ["castle.common.base.BaseLearner.__init__", "torch.cuda.is_available", "logging.info", "logging.info", "torch.device", "torch.device", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "model_type", "=", "'nn'", ",", "hidden_layers", "=", "4", ",", "hidden_dim", "=", "16", ",", "\n", "graph_thresh", "=", "0.5", ",", "l1_graph_penalty", "=", "2e-3", ",", "learning_rate", "=", "3e-2", ",", "\n", "max_iter", "=", "25", ",", "iter_step", "=", "1000", ",", "init_iter", "=", "2", ",", "h_tol", "=", "1e-10", ",", "\n", "init_rho", "=", "1e-5", ",", "rho_thresh", "=", "1e14", ",", "h_thresh", "=", "0.25", ",", "\n", "rho_multiply", "=", "10", ",", "temperature", "=", "0.2", ",", "device_type", "=", "'cpu'", ",", "\n", "device_ids", "=", "'0'", ",", "random_seed", "=", "1230", ")", "->", "None", ":", "\n", "        ", "super", "(", "MCSL", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "model_type", "=", "model_type", "\n", "self", ".", "hidden_layers", "=", "hidden_layers", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "graph_thresh", "=", "graph_thresh", "\n", "self", ".", "l1_graph_penalty", "=", "l1_graph_penalty", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "self", ".", "iter_step", "=", "iter_step", "\n", "self", ".", "init_iter", "=", "init_iter", "\n", "self", ".", "h_tol", "=", "h_tol", "\n", "self", ".", "init_rho", "=", "init_rho", "\n", "self", ".", "rho_thresh", "=", "rho_thresh", "\n", "self", ".", "h_thresh", "=", "h_thresh", "\n", "self", ".", "rho_multiply", "=", "rho_multiply", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "device_type", "=", "device_type", "\n", "self", ".", "device_ids", "=", "device_ids", "\n", "self", ".", "random_seed", "=", "random_seed", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "logging", ".", "info", "(", "'GPU is available.'", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "'GPU is unavailable.'", ")", "\n", "if", "self", ".", "device_type", "==", "'gpu'", ":", "\n", "                ", "raise", "ValueError", "(", "\"GPU is unavailable, \"", "\n", "\"please set device_type = 'cpu'.\"", ")", "\n", "", "", "if", "self", ".", "device_type", "==", "'gpu'", ":", "\n", "            ", "if", "self", ".", "device_ids", ":", "\n", "                ", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "str", "(", "self", ".", "device_ids", ")", "\n", "", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "", "else", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.mcsl.MCSL.learn": [[154, 188], ["castle.common.base.Tensor", "mcsl.MCSL._mcsl", "castle.common.base.Tensor", "castle.common.base.Tensor", "torch.ones", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.mcsl.MCSL._mcsl"], ["", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ",", "pns_mask", "=", "None", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Set up and run the MCSL algorithm.\n\n        Parameters\n        ----------\n        data: castle.Tensor or numpy.ndarray\n            The castle.Tensor or numpy.ndarray format data you want to learn.\n        columns: Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        pns_mask: array_like or None\n            The mask matrix.\n            array with element in {0, 1}, ``0`` denotes has no edge in i -> j,\n            ``1`` denotes maybe has edge in i -> j or not.\n        \"\"\"", "\n", "\n", "x", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "self", ".", "n_samples", ",", "self", ".", "n_nodes", "=", "x", ".", "shape", "\n", "if", "pns_mask", "is", "None", ":", "\n", "            ", "pns_mask", "=", "torch", ".", "ones", "(", "[", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "1", "]", "]", ",", "device", "=", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "pns_mask", "=", "torch", ".", "tensor", "(", "pns_mask", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "", "causal_matrix", ",", "causal_matrix_weight", "=", "self", ".", "_mcsl", "(", "x", ",", "pns_mask", ")", "\n", "\n", "self", ".", "causal_matrix_weight", "=", "Tensor", "(", "causal_matrix_weight", ",", "\n", "index", "=", "x", ".", "columns", ",", "\n", "columns", "=", "x", ".", "columns", "\n", ")", "\n", "self", ".", "causal_matrix", "=", "Tensor", "(", "causal_matrix", ",", "\n", "index", "=", "x", ".", "columns", ",", "\n", "columns", "=", "x", ".", "columns", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.mcsl.MCSL._mcsl": [[190, 232], ["mcsl.set_seed", "models.masked_model.MaskedModel", "trainers.al_trainer.Trainer", "trainers.al_trainer.Trainer.train", "helpers.utils.callback_after_training", "isinstance", "torch.tensor", "w_est.detach().cpu().numpy", "w_est_weight.detach().cpu().numpy", "w_est.detach().cpu", "w_est_weight.detach().cpu", "w_est.detach", "w_est_weight.detach"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.set_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.train", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.helpers.utils.callback_after_training"], ["", "def", "_mcsl", "(", "self", ",", "x", ",", "pns_mask", ")", "->", "tuple", ":", "\n", "        ", "\"\"\"\n        Starting model of MCSL.\n\n        Parameters\n        ----------\n        x: torch.Tensor\n            The torch.Tensor data you want to learn.\n        pns_mask: torch.Tensor\n            The mask matrix.\n        \"\"\"", "\n", "\n", "set_seed", "(", "self", ".", "random_seed", ")", "\n", "\n", "model", "=", "MaskedModel", "(", "model_type", "=", "self", ".", "model_type", ",", "\n", "n_samples", "=", "self", ".", "n_samples", ",", "\n", "n_nodes", "=", "self", ".", "n_nodes", ",", "\n", "pns_mask", "=", "pns_mask", ",", "\n", "hidden_layers", "=", "self", ".", "hidden_layers", ",", "\n", "hidden_dim", "=", "self", ".", "hidden_dim", ",", "\n", "l1_graph_penalty", "=", "self", ".", "l1_graph_penalty", ",", "\n", "seed", "=", "self", ".", "random_seed", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "trainer", "=", "Trainer", "(", "model", "=", "model", ",", "\n", "learning_rate", "=", "self", ".", "learning_rate", ",", "\n", "init_rho", "=", "self", ".", "init_rho", ",", "\n", "rho_thresh", "=", "self", ".", "rho_thresh", ",", "\n", "h_thresh", "=", "self", ".", "h_thresh", ",", "\n", "rho_multiply", "=", "self", ".", "rho_multiply", ",", "\n", "init_iter", "=", "self", ".", "init_iter", ",", "\n", "h_tol", "=", "self", ".", "h_tol", ",", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "\n", "if", "not", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "x", "=", "torch", ".", "tensor", "(", "x", ",", "device", "=", "self", ".", "device", ")", "\n", "", "w_logits", "=", "trainer", ".", "train", "(", "x", ",", "self", ".", "max_iter", ",", "self", ".", "iter_step", ")", "\n", "\n", "w_est", ",", "w_est_weight", "=", "callback_after_training", "(", "w_logits", ",", "\n", "self", ".", "temperature", ",", "\n", "self", ".", "graph_thresh", ")", "\n", "return", "w_est", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "w_est_weight", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.torch.mcsl.set_seed": [[29, 42], ["random.seed", "numpy.random.seed", "torch.manual_seed", "str"], "function", ["None"], ["def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "\"\"\"\n    Referred from:\n    - https://stackoverflow.com/questions/38469632/tensorflow-non-repeatable-results\n    \"\"\"", "\n", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "try", ":", "\n", "        ", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "", "finally", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.__init__": [[40, 57], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "locally_connected.LocallyConnected.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Parameter", "torch.Parameter", "locally_connected.LocallyConnected.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.reset_parameters"], ["def", "__init__", "(", "self", ",", "num_linear", ",", "input_features", ",", "output_features", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "LocallyConnected", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_linear", "=", "num_linear", "\n", "self", ".", "input_features", "=", "input_features", "\n", "self", ".", "output_features", "=", "output_features", "\n", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_linear", ",", "\n", "input_features", ",", "\n", "output_features", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_linear", ",", "output_features", ")", ")", "\n", "", "else", ":", "\n", "# You should always register all possible parameters, but the", "\n", "# optional ones can be None if you want.", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.reset_parameters": [[58, 65], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "math.sqrt", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "k", "=", "1.0", "/", "self", ".", "input_features", "\n", "bound", "=", "math", ".", "sqrt", "(", "k", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "weight", ",", "-", "bound", ",", "bound", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "bias", ",", "-", "bound", ",", "bound", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.forward": [[66, 74], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "out.squeeze.squeeze.squeeze", "input_x.unsqueeze", "locally_connected.LocallyConnected.weight.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_x", ":", "torch", ".", "Tensor", ")", ":", "\n", "# [n, d, 1, m2] = [n, d, 1, m1] @ [1, d, m1, m2]", "\n", "        ", "out", "=", "torch", ".", "matmul", "(", "input_x", ".", "unsqueeze", "(", "dim", "=", "2", ")", ",", "self", ".", "weight", ".", "unsqueeze", "(", "dim", "=", "0", ")", ")", "\n", "out", "=", "out", ".", "squeeze", "(", "dim", "=", "2", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "# [n, d, m2] += [d, m2]", "\n", "            ", "out", "+=", "self", ".", "bias", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.extra_repr": [[75, 88], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        (Optional)Set the extra information about this module. You can test\n        it by printing an object of this class.\n\n        Returns\n        -------\n\n        \"\"\"", "\n", "\n", "return", "'num_linear={}, in_features={}, out_features={}, bias={}'", ".", "format", "(", "\n", "self", ".", "num_linear", ",", "self", ".", "in_features", ",", "self", ".", "out_features", ",", "\n", "self", ".", "bias", "is", "not", "None", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy.__init__": [[28, 38], ["dict", "super().__init__", "sum", "len", "ValueError", "p.numel"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", ")", "\n", "super", "(", "LBFGSBScipy", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n", "if", "len", "(", "self", ".", "param_groups", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"LBFGSBScipy doesn't support per-parameter options\"", "\n", "\" (parameter groups)\"", ")", "\n", "\n", "", "self", ".", "_params", "=", "self", ".", "param_groups", "[", "0", "]", "[", "'params'", "]", "\n", "self", ".", "_numel", "=", "sum", "(", "[", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "_params", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy._gather_flat_grad": [[39, 50], ["torch.cat", "views.append", "p.data.new().zero_", "p.grad.data.to_dense().view", "p.grad.data.view", "p.data.new", "p.data.numel", "p.grad.data.to_dense"], "methods", ["None"], ["", "def", "_gather_flat_grad", "(", "self", ")", ":", "\n", "        ", "views", "=", "[", "]", "\n", "for", "p", "in", "self", ".", "_params", ":", "\n", "            ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                ", "view", "=", "p", ".", "data", ".", "new", "(", "p", ".", "data", ".", "numel", "(", ")", ")", ".", "zero_", "(", ")", "\n", "", "elif", "p", ".", "grad", ".", "data", ".", "is_sparse", ":", "\n", "                ", "view", "=", "p", ".", "grad", ".", "data", ".", "to_dense", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "view", "=", "p", ".", "grad", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "views", ".", "append", "(", "view", ")", "\n", "", "return", "torch", ".", "cat", "(", "views", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy._gather_flat_bounds": [[51, 60], ["hasattr", "p.numel"], "methods", ["None"], ["", "def", "_gather_flat_bounds", "(", "self", ")", ":", "\n", "        ", "bounds", "=", "[", "]", "\n", "for", "p", "in", "self", ".", "_params", ":", "\n", "            ", "if", "hasattr", "(", "p", ",", "'bounds'", ")", ":", "\n", "                ", "b", "=", "p", ".", "bounds", "\n", "", "else", ":", "\n", "                ", "b", "=", "[", "(", "None", ",", "None", ")", "]", "*", "p", ".", "numel", "(", ")", "\n", "", "bounds", "+=", "b", "\n", "", "return", "bounds", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy._gather_flat_params": [[61, 70], ["torch.cat", "views.append", "p.data.to_dense().view", "p.data.view", "p.data.to_dense"], "methods", ["None"], ["", "def", "_gather_flat_params", "(", "self", ")", ":", "\n", "        ", "views", "=", "[", "]", "\n", "for", "p", "in", "self", ".", "_params", ":", "\n", "            ", "if", "p", ".", "data", ".", "is_sparse", ":", "\n", "                ", "view", "=", "p", ".", "data", ".", "to_dense", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "view", "=", "p", ".", "data", ".", "view", "(", "-", "1", ")", "\n", "", "views", ".", "append", "(", "view", ")", "\n", "", "return", "torch", ".", "cat", "(", "views", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy._distribute_flat_params": [[71, 79], ["p.numel", "params[].view_as"], "methods", ["None"], ["", "def", "_distribute_flat_params", "(", "self", ",", "params", ")", ":", "\n", "        ", "offset", "=", "0", "\n", "for", "p", "in", "self", ".", "_params", ":", "\n", "            ", "numel", "=", "p", ".", "numel", "(", ")", "\n", "# view as to avoid deprecated pointwise semantics", "\n", "p", ".", "data", "=", "params", "[", "offset", ":", "offset", "+", "numel", "]", ".", "view_as", "(", "p", ".", "data", ")", "\n", "offset", "+=", "numel", "\n", "", "assert", "offset", "==", "self", ".", "_numel", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy.step": [[80, 120], ["lbfgsb_scipy.LBFGSBScipy._gather_flat_params", "initial_params.cpu().detach().numpy.cpu().detach().numpy.cpu().detach().numpy", "lbfgsb_scipy.LBFGSBScipy._gather_flat_bounds", "scipy.minimize", "torch.from_numpy", "final_params.to.to.to", "lbfgsb_scipy.LBFGSBScipy._distribute_flat_params", "len", "torch.from_numpy", "flat_params.to().to.to().to.to().to", "lbfgsb_scipy.LBFGSBScipy._distribute_flat_params", "closure", "loss.item.item.item", "lbfgsb_scipy.LBFGSBScipy._gather_flat_grad().cpu().detach().numpy", "torch.get_default_dtype", "lbfgsb_scipy.LBFGSBScipy.astype", "initial_params.cpu().detach().numpy.cpu().detach().numpy.cpu().detach", "flat_params.to().to.to().to.to", "lbfgsb_scipy.LBFGSBScipy._gather_flat_grad().cpu().detach", "torch.get_default_dtype", "initial_params.cpu().detach().numpy.cpu().detach().numpy.cpu", "lbfgsb_scipy.LBFGSBScipy._gather_flat_grad().cpu", "lbfgsb_scipy.LBFGSBScipy._gather_flat_grad"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy._gather_flat_params", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy._gather_flat_bounds", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy._distribute_flat_params", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy._distribute_flat_params", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.lbfgsb_scipy.LBFGSBScipy._gather_flat_grad"], ["", "def", "step", "(", "self", ",", "closure", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        Performs a single optimization step.\n\n        Parameters\n        ----------\n        closure: callable\n            A closure that reevaluates the model and returns the loss.\n        device: option, default: None\n            torch.device('cpu') or torch.device('cuda').\n\n        \"\"\"", "\n", "\n", "assert", "len", "(", "self", ".", "param_groups", ")", "==", "1", "\n", "\n", "def", "wrapped_closure", "(", "flat_params", ")", ":", "\n", "            ", "\"\"\"closure must call zero_grad() and backward()\"\"\"", "\n", "flat_params", "=", "torch", ".", "from_numpy", "(", "flat_params", ")", "\n", "flat_params", "=", "flat_params", ".", "to", "(", "torch", ".", "get_default_dtype", "(", ")", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "_distribute_flat_params", "(", "flat_params", ")", "\n", "loss", "=", "closure", "(", ")", "\n", "loss", "=", "loss", ".", "item", "(", ")", "\n", "flat_grad", "=", "self", ".", "_gather_flat_grad", "(", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "return", "loss", ",", "flat_grad", ".", "astype", "(", "'float64'", ")", "\n", "\n", "", "initial_params", "=", "self", ".", "_gather_flat_params", "(", ")", "\n", "initial_params", "=", "initial_params", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "bounds", "=", "self", ".", "_gather_flat_bounds", "(", ")", "\n", "\n", "# Magic", "\n", "sol", "=", "sopt", ".", "minimize", "(", "wrapped_closure", ",", "\n", "initial_params", ",", "\n", "method", "=", "'L-BFGS-B'", ",", "\n", "jac", "=", "True", ",", "\n", "bounds", "=", "bounds", ")", "\n", "\n", "final_params", "=", "torch", ".", "from_numpy", "(", "sol", ".", "x", ")", "\n", "final_params", "=", "final_params", ".", "to", "(", "torch", ".", "get_default_dtype", "(", ")", ")", "\n", "self", ".", "_distribute_flat_params", "(", "final_params", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.data_loader.DataGenerator.__init__": [[35, 46], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.normalize", "torch.normalize"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "normalize", "=", "False", ",", "device", "=", "None", ")", "->", "None", ":", "\n", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "data_size", ",", "self", ".", "n_nodes", "=", "self", ".", "dataset", ".", "shape", "\n", "self", ".", "dataset", "=", "torch", ".", "tensor", "(", "self", ".", "dataset", ",", "\n", "requires_grad", "=", "True", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "self", ".", "dataset", "=", "F", ".", "normalize", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.data_loader.DataGenerator._draw_single_sample": [[47, 53], ["numpy.random.randint"], "methods", ["None"], ["", "", "def", "_draw_single_sample", "(", "self", ",", "dimension", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "        ", "index", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "data_size", ",", "size", "=", "dimension", ")", "\n", "single_sample", "=", "self", ".", "dataset", "[", "index", "]", "# [dimension, n_nodes]", "\n", "\n", "return", "single_sample", ".", "T", "# [n_nodes, dimension]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.data_loader.DataGenerator.draw_batch": [[54, 71], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "data_loader.DataGenerator._draw_single_sample", "batch.append"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.data_loader.DataGenerator._draw_single_sample"], ["", "def", "draw_batch", "(", "self", ",", "batch_size", ",", "dimension", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Draw batch sample\n\n        Parameters\n        ----------\n        batch_size: int\n            Draw ``batch_size`` single_samples\n        dimension: int\n            Draw ``dimension`` samples to represent node features\n        \"\"\"", "\n", "\n", "batch", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "single_sample", "=", "self", ".", "_draw_single_sample", "(", "dimension", "=", "dimension", ")", "\n", "batch", ".", "append", "(", "single_sample", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.graph_analysis.get_graph_from_order": [[22, 68], ["len", "numpy.zeros", "range", "numpy.int32", "numpy.ones", "numpy.eye", "numpy.abs"], "function", ["None"], ["def", "get_graph_from_order", "(", "sequence", ",", "dag_mask", "=", "None", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Generate a fully-connected DAG based on a sequence.\n\n\n    Parameters\n    ----------\n    sequence: iterable\n        An ordering of nodes, the set of nodes that precede node vj\n        denotes potencial parent nodes of vj.\n    dag_mask : ndarray\n        two-dimensional array with [0, 1], shape = [n_nodes, n_nodes].\n        (i, j) indicated element `0` denotes there must be no edge\n        between nodes `i` and `j` , the element `1` indicates that\n        there may or may not be an edge.\n\n    Returns\n    -------\n    out:\n        graph matrix\n\n    Examples\n    --------\n    >>> order = [2, 0, 1, 3]\n    >>> graph = get_graph_from_order(sequence=order)\n    >>> print(graph)\n        [[0. 1. 0. 1.]\n         [0. 0. 0. 1.]\n         [1. 1. 0. 1.]\n         [0. 0. 0. 0.]]\n    \"\"\"", "\n", "\n", "num_node", "=", "len", "(", "sequence", ")", "\n", "init_graph", "=", "np", ".", "zeros", "(", "(", "num_node", ",", "num_node", ")", ")", "\n", "for", "i", "in", "range", "(", "num_node", "-", "1", ")", ":", "\n", "        ", "pa_node", "=", "sequence", "[", "i", "]", "\n", "sub_node", "=", "sequence", "[", "i", "+", "1", ":", "]", "\n", "init_graph", "[", "pa_node", ",", "sub_node", "]", "=", "1", "\n", "", "if", "dag_mask", "is", "None", ":", "\n", "        ", "gtrue_mask", "=", "np", ".", "ones", "(", "[", "num_node", ",", "num_node", "]", ")", "-", "np", ".", "eye", "(", "num_node", ")", "\n", "", "else", ":", "\n", "        ", "gtrue_mask", "=", "dag_mask", "\n", "", "dag_mask", "=", "np", ".", "int32", "(", "np", ".", "abs", "(", "gtrue_mask", ")", ">", "1e-3", ")", "\n", "init_graph", "=", "init_graph", "*", "dag_mask", "\n", "\n", "return", "init_graph", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.graph_analysis.cover_rate": [[70, 75], ["numpy.sum", "numpy.float32"], "function", ["None"], ["", "def", "cover_rate", "(", "graph", ",", "graph_true", ")", "->", "np", ".", "ndarray", ":", "\n", "\n", "    ", "error", "=", "graph", "-", "graph_true", "\n", "\n", "return", "np", ".", "sum", "(", "np", ".", "float32", "(", "error", ">", "-", "0.1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.graph_analysis.pruning_by_coef": [[77, 113], ["sklearn.linear_model.LinearRegression", "range", "numpy.float32", "sklearn.linear_model.LinearRegression.fit", "numpy.zeros", "range", "W.append", "numpy.abs", "numpy.sum", "W.append", "numpy.sum", "numpy.abs", "numpy.zeros", "numpy.square", "sklearn.linear_model.LinearRegression.predict"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.GPRMine.predict"], ["", "def", "pruning_by_coef", "(", "graph_batch", ",", "X", ",", "thresh", "=", "0.3", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    for a given graph, pruning the edge according to edge weights;\n    linear regression for each causal regression for edge weights and\n    then thresholding\n    \"\"\"", "\n", "\n", "n", ",", "d", "=", "X", ".", "shape", "\n", "reg", "=", "LinearRegression", "(", ")", "\n", "W", "=", "[", "]", "\n", "\n", "loss", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "d", ")", ":", "\n", "        ", "col", "=", "np", ".", "abs", "(", "graph_batch", "[", "i", "]", ")", ">", "0.1", "\n", "if", "np", ".", "sum", "(", "col", ")", "<=", "0.1", ":", "\n", "            ", "W", ".", "append", "(", "np", ".", "zeros", "(", "d", ")", ")", "\n", "continue", "\n", "\n", "", "X_train", "=", "X", "[", ":", ",", "col", "]", "\n", "\n", "y", "=", "X", "[", ":", ",", "i", "]", "\n", "reg", ".", "fit", "(", "X_train", ",", "y", ")", "\n", "loss", "+=", "0.5", "/", "n", "*", "np", ".", "sum", "(", "np", ".", "square", "(", "reg", ".", "predict", "(", "X_train", ")", "-", "y", ")", ")", "\n", "reg_coeff", "=", "reg", ".", "coef_", "\n", "\n", "cj", "=", "0", "\n", "new_reg_coeff", "=", "np", ".", "zeros", "(", "d", ",", ")", "\n", "for", "ci", "in", "range", "(", "d", ")", ":", "\n", "            ", "if", "col", "[", "ci", "]", ":", "\n", "                ", "new_reg_coeff", "[", "ci", "]", "=", "reg_coeff", "[", "cj", "]", "\n", "cj", "+=", "1", "\n", "\n", "", "", "W", ".", "append", "(", "new_reg_coeff", ")", "\n", "\n", "", "return", "np", ".", "float32", "(", "np", ".", "abs", "(", "W", ")", ">", "thresh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.graph_analysis.pruning_by_coef_2nd": [[115, 156], ["len", "sklearn.linear_model.LinearRegression", "sklearn.preprocessing.PolynomialFeatures", "range", "numpy.array", "sklearn.linear_model.LinearRegression.fit", "numpy.zeros", "range", "W.append", "numpy.sum", "W.append", "sklearn.preprocessing.PolynomialFeatures.fit_transform", "sklearn.preprocessing.PolynomialFeatures.get_feature_names", "numpy.zeros", "enumerate", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit"], ["", "def", "pruning_by_coef_2nd", "(", "graph_batch", ",", "X", ",", "thresh", "=", "0.3", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    for a given graph, pruning the edge according to edge weights;\n    quadratic regression for each causal regression for edge weights and then\n    thresholding\n    \"\"\"", "\n", "\n", "d", "=", "len", "(", "graph_batch", ")", "\n", "reg", "=", "LinearRegression", "(", ")", "\n", "poly", "=", "PolynomialFeatures", "(", ")", "\n", "W", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "d", ")", ":", "\n", "        ", "col", "=", "graph_batch", "[", "i", "]", ">", "0.1", "\n", "if", "np", ".", "sum", "(", "col", ")", "<=", "0.1", ":", "\n", "            ", "W", ".", "append", "(", "np", ".", "zeros", "(", "d", ")", ")", "\n", "continue", "\n", "\n", "", "X_train", "=", "X", "[", ":", ",", "col", "]", "\n", "X_train_expand", "=", "poly", ".", "fit_transform", "(", "X_train", ")", "[", ":", ",", "1", ":", "]", "\n", "X_train_expand_names", "=", "poly", ".", "get_feature_names", "(", ")", "[", "1", ":", "]", "\n", "\n", "y", "=", "X", "[", ":", ",", "i", "]", "\n", "reg", ".", "fit", "(", "X_train_expand", ",", "y", ")", "\n", "reg_coeff", "=", "reg", ".", "coef_", "\n", "\n", "cj", "=", "0", "\n", "new_reg_coeff", "=", "np", ".", "zeros", "(", "d", ",", ")", "\n", "\n", "for", "ci", "in", "range", "(", "d", ")", ":", "\n", "            ", "if", "col", "[", "ci", "]", ":", "\n", "                ", "xxi", "=", "'x{}'", ".", "format", "(", "cj", ")", "\n", "for", "iii", ",", "xxx", "in", "enumerate", "(", "X_train_expand_names", ")", ":", "\n", "                    ", "if", "xxi", "in", "xxx", ":", "\n", "                        ", "if", "np", ".", "abs", "(", "reg_coeff", "[", "iii", "]", ")", ">", "thresh", ":", "\n", "                            ", "new_reg_coeff", "[", "ci", "]", "=", "1.0", "\n", "break", "\n", "", "", "", "cj", "+=", "1", "\n", "", "", "W", ".", "append", "(", "new_reg_coeff", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "W", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.validation.Validation.validate_type": [[29, 52], ["isinstance", "TypeError", "type"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "validate_type", "(", "x", ",", "valid_type", ")", ":", "\n", "        ", "\"\"\"\n        Check whether an object is an instance of `valid_type`.\n\n        Parameters\n        ----------\n        x: object\n            object to be verified\n        valid_type: type or tuple of type\n            A tuple, as in ``validate_type(x, (A, B, ...))``, may be given as\n            the target to check against. This is equivalent to\n            ``validate_type(x, A) or  validate_type(x, B) or ...`` etc.\n\n        Returns\n        -------\n        out: True or raise TypeError\n        \"\"\"", "\n", "\n", "if", "isinstance", "(", "x", ",", "valid_type", ")", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "f'Expected type of {x} is an instance '", "\n", "f'of {valid_type}, but got ``{type(x)}``.'", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.validation.Validation.validate_value": [[54, 77], ["ValueError"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "validate_value", "(", "x", ",", "valid_value", ")", ":", "\n", "        ", "\"\"\"\n        Check whether an object's value is one of `valid_type`.\n\n        Parameters\n        ----------\n        x: object\n            object to be verified\n        valid_value: tuple, list\n            A tuple, as in ``validate_value(x, (A, B, ...))``, may be given as\n            the target to check against. This is equivalent to\n            ``validate_value(x, A) or validate_value(x, B) or ...`` etc.\n\n        Returns\n        -------\n        out: True or raise TypeError\n        \"\"\"", "\n", "\n", "if", "x", "in", "valid_value", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Expected `x` is one of {valid_value}, '", "\n", "f'but got ``{x}``.'", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.validation.Validation.to_device": [[79, 98], ["isinstance", "out.append", "len", "tuple", "torch.tensor", "isinstance", "each.to.to.to", "TypeError", "type"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "to_device", "(", "*", "args", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"transfer all of ``args`` to ``device``\"\"\"", "\n", "\n", "out", "=", "[", "]", "\n", "for", "each", "in", "args", ":", "\n", "            ", "if", "isinstance", "(", "each", ",", "np", ".", "ndarray", ")", ":", "\n", "                ", "each", "=", "torch", ".", "tensor", "(", "each", ",", "device", "=", "device", ")", "\n", "", "elif", "isinstance", "(", "each", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "each", "=", "each", ".", "to", "(", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "f\"Expected type of the args is ``np.ndarray` \"", "\n", "f\"or ``torch.Tensor``, \"", "\n", "f\"but got ``{type(each)}``.\"", ")", "\n", "", "out", ".", "append", "(", "each", ")", "\n", "", "if", "len", "(", "out", ")", ">", "1", ":", "\n", "            ", "return", "tuple", "(", "out", ")", "\n", "", "else", ":", "\n", "            ", "return", "out", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.base._BaseLiNGAM.__init__": [[29, 33], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Construct a _BaseLiNGAM model.\"\"\"", "\n", "self", ".", "_causal_order", "=", "None", "\n", "self", ".", "_adjacency_matrix", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.base._BaseLiNGAM.fit": [[34, 51], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "fit", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        Subclasses should implement this method!\n        Fit the model to X.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.base._BaseLiNGAM.estimate_total_effect": [[52, 92], ["sklearn.utils.check_array", "base._BaseLiNGAM._causal_order.index", "base._BaseLiNGAM._causal_order.index", "predictors.extend", "sklearn.linear_model.LinearRegression", "sklearn.linear_model.LinearRegression.fit", "warnings.warn", "numpy.where", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.Tensor.index", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.Tensor.index", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit"], ["", "def", "estimate_total_effect", "(", "self", ",", "X", ",", "from_index", ",", "to_index", ")", ":", "\n", "        ", "\"\"\"\n        Estimate total effect using causal model.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Original data, where n_samples is the number of samples\n            and n_features is the number of features.\n        from_index : \n            Index of source variable to estimate total effect.\n        to_index : \n            Index of destination variable to estimate total effect.\n\n        Returns\n        -------\n        total_effect : float\n            Estimated total effect.\n        \"\"\"", "\n", "# Check parameters", "\n", "X", "=", "check_array", "(", "X", ")", "\n", "\n", "# Check from/to causal order", "\n", "from_order", "=", "self", ".", "_causal_order", ".", "index", "(", "from_index", ")", "\n", "to_order", "=", "self", ".", "_causal_order", ".", "index", "(", "to_index", ")", "\n", "if", "from_order", ">", "to_order", ":", "\n", "            ", "warnings", ".", "warn", "(", "f'The estimated causal effect may be incorrect because '", "\n", "f'the causal order of the destination variable (to_index={to_index}) '", "\n", "f'is earlier than the source variable (from_index={from_index}).'", ")", "\n", "\n", "# from_index + parents indices", "\n", "", "parents", "=", "np", ".", "where", "(", "np", ".", "abs", "(", "self", ".", "_adjacency_matrix", "[", "from_index", "]", ")", ">", "0", ")", "[", "0", "]", "\n", "predictors", "=", "[", "from_index", "]", "\n", "predictors", ".", "extend", "(", "parents", ")", "\n", "\n", "# Estimate total effect", "\n", "lr", "=", "LinearRegression", "(", ")", "\n", "lr", ".", "fit", "(", "X", "[", ":", ",", "predictors", "]", ",", "X", "[", ":", ",", "to_index", "]", ")", "\n", "\n", "return", "lr", ".", "coef_", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.base._BaseLiNGAM._estimate_adjacency_matrix": [[93, 115], ["numpy.zeros", "range", "len", "base._BaseLiNGAM.predict_adaptive_lasso"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.base._BaseLiNGAM.predict_adaptive_lasso"], ["", "def", "_estimate_adjacency_matrix", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        Estimate adjacency matrix by causal order.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"", "\n", "B", "=", "np", ".", "zeros", "(", "[", "X", ".", "shape", "[", "1", "]", ",", "X", ".", "shape", "[", "1", "]", "]", ",", "dtype", "=", "'float64'", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "_causal_order", ")", ")", ":", "\n", "            ", "B", "[", "self", ".", "_causal_order", "[", "i", "]", ",", "self", ".", "_causal_order", "[", ":", "i", "]", "]", "=", "_BaseLiNGAM", ".", "predict_adaptive_lasso", "(", "\n", "X", ",", "self", ".", "_causal_order", "[", ":", "i", "]", ",", "self", ".", "_causal_order", "[", "i", "]", ")", "\n", "\n", "", "self", ".", "_adjacency_matrix", "=", "B", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.base._BaseLiNGAM.causal_order_": [[116, 128], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "causal_order_", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Estimated causal ordering.\n\n        Returns\n        -------\n        causal_order_ : array-like, shape (n_features)\n            The causal order of fitted model, where \n            n_features is the number of features.\n        \"\"\"", "\n", "return", "self", ".", "_causal_order", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.base._BaseLiNGAM.adjacency_matrix_": [[129, 141], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "adjacency_matrix_", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Estimated adjacency matrix.\n\n        Returns\n        -------\n        adjacency_matrix_ : array-like, shape (n_features, n_features)\n            The adjacency matrix B of fitted model, where \n            n_features is the number of features.\n        \"\"\"", "\n", "return", "self", ".", "_adjacency_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.base._BaseLiNGAM.predict_adaptive_lasso": [[142, 168], ["sklearn.linear_model.LinearRegression", "sklearn.linear_model.LinearRegression.fit", "numpy.power", "sklearn.linear_model.LassoLarsIC", "sklearn.linear_model.LassoLarsIC.fit", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit"], ["", "@", "staticmethod", "\n", "def", "predict_adaptive_lasso", "(", "X", ",", "predictors", ",", "target", ",", "gamma", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"\n        Predict with Adaptive Lasso.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n        predictors : array-like, shape (n_predictors)\n            Indices of predictor variable.\n        target : int\n            Index of target variable.\n\n        Returns\n        -------\n        coef : array-like, shape (n_features)\n            Coefficients of predictor variable.\n        \"\"\"", "\n", "lr", "=", "LinearRegression", "(", ")", "\n", "lr", ".", "fit", "(", "X", "[", ":", ",", "predictors", "]", ",", "X", "[", ":", ",", "target", "]", ")", "\n", "weight", "=", "np", ".", "power", "(", "np", ".", "abs", "(", "lr", ".", "coef_", ")", ",", "gamma", ")", "\n", "reg", "=", "LassoLarsIC", "(", "criterion", "=", "'bic'", ")", "\n", "reg", ".", "fit", "(", "X", "[", ":", ",", "predictors", "]", "*", "weight", ",", "X", "[", ":", ",", "target", "]", ")", "\n", "return", "reg", ".", "coef_", "*", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.bootstrap.BootstrapMixin.bootstrap": [[24, 65], ["sklearn.utils.check_array", "isinstance", "numpy.zeros", "numpy.zeros", "range", "bootstrap.BootstrapResult", "ValueError", "bootstrap.BootstrapMixin.fit", "enumerate", "ValueError", "sklearn.utils.resample", "bootstrap.BootstrapMixin.estimate_total_effect"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.base._BaseLiNGAM.estimate_total_effect"], ["def", "bootstrap", "(", "self", ",", "X", ",", "n_sampling", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate the statistical reliability of DAG based on the bootstrapping.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where ``n_samples`` is the number of samples\n            and ``n_features`` is the number of features.\n        n_sampling : int\n            Number of bootstrapping samples.\n\n        Returns\n        -------\n        result : BootstrapResult\n            Returns the result of bootstrapping.\n        \"\"\"", "\n", "# Check parameters", "\n", "X", "=", "check_array", "(", "X", ")", "\n", "\n", "if", "isinstance", "(", "n_sampling", ",", "(", "numbers", ".", "Integral", ",", "np", ".", "integer", ")", ")", ":", "\n", "            ", "if", "not", "0", "<", "n_sampling", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'n_sampling must be an integer greater than 0.'", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'n_sampling must be an integer greater than 0.'", ")", "\n", "\n", "# Bootstrapping", "\n", "", "adjacency_matrices", "=", "np", ".", "zeros", "(", "[", "n_sampling", ",", "X", ".", "shape", "[", "1", "]", ",", "X", ".", "shape", "[", "1", "]", "]", ")", "\n", "total_effects", "=", "np", ".", "zeros", "(", "[", "n_sampling", ",", "X", ".", "shape", "[", "1", "]", ",", "X", ".", "shape", "[", "1", "]", "]", ")", "\n", "for", "i", "in", "range", "(", "n_sampling", ")", ":", "\n", "            ", "self", ".", "fit", "(", "resample", "(", "X", ")", ")", "\n", "adjacency_matrices", "[", "i", "]", "=", "self", ".", "_adjacency_matrix", "\n", "\n", "# Calculate total effects", "\n", "for", "c", ",", "from_", "in", "enumerate", "(", "self", ".", "_causal_order", ")", ":", "\n", "                ", "for", "to", "in", "self", ".", "_causal_order", "[", "c", "+", "1", ":", "]", ":", "\n", "                    ", "total_effects", "[", "i", ",", "to", ",", "from_", "]", "=", "self", ".", "estimate_total_effect", "(", "\n", "X", ",", "from_", ",", "to", ")", "\n", "\n", "", "", "", "return", "BootstrapResult", "(", "adjacency_matrices", ",", "total_effects", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.bootstrap.BootstrapResult.__init__": [[70, 83], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "adjacency_matrices", ",", "total_effects", ")", ":", "\n", "        ", "\"\"\"\n        Construct a BootstrapResult.\n\n        Parameters\n        ----------\n        adjacency_matrices : array-like, shape (n_sampling)\n            The adjacency matrix list by bootstrapping.\n        total_effects : array-like, shape (n_sampling)\n            The total effects list by bootstrapping.\n        \"\"\"", "\n", "self", ".", "_adjacency_matrices", "=", "adjacency_matrices", "\n", "self", ".", "_total_effects", "=", "total_effects", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.bootstrap.BootstrapResult.adjacency_matrices_": [[84, 96], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "adjacency_matrices_", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The adjacency matrix list by bootstrapping.\n\n        Returns\n        -------\n        adjacency_matrices_ : array-like, shape (n_sampling)\n            The adjacency matrix list, where ``n_sampling`` is\n            the number of bootstrap sampling.\n        \"\"\"", "\n", "return", "self", ".", "_adjacency_matrices", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.bootstrap.BootstrapResult.total_effects_": [[97, 109], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "total_effects_", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        The total effect list by bootstrapping.\n\n        Returns\n        -------\n        total_effects_ : array-like, shape (n_sampling)\n            The total effect list, where ``n_sampling`` is\n            the number of bootstrap sampling.\n        \"\"\"", "\n", "return", "self", ".", "_total_effects", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.bootstrap.BootstrapResult.get_causal_direction_counts": [[110, 181], ["isinstance", "numpy.nan_to_num", "numpy.concatenate", "numpy.unique", "numpy.argsort", "numpy.array", "numpy.concatenate.append", "len", "directions[].tolist", "directions[].tolist", "counts.tolist", "directions[].tolist", "ValueError", "ValueError", "ValueError", "numpy.where", "numpy.vstack", "numpy.array().astype", "numpy.abs", "numpy.array", "numpy.sign"], "methods", ["None"], ["", "def", "get_causal_direction_counts", "(", "self", ",", "n_directions", "=", "None", ",", "min_causal_effect", "=", "None", ",", "split_by_causal_effect_sign", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Get causal direction count as a result of bootstrapping.\n\n        Parameters\n        ----------\n        n_directions : int, optional (default=None)\n            If int, then The top ``n_directions`` items are included in the result\n        min_causal_effect : float, optional (default=None)\n            Threshold for detecting causal direction.\n            If float, then causal directions with absolute values of causal effects less than ``min_causal_effect`` are excluded.\n        split_by_causal_effect_sign : boolean, optional (default=False)\n            If True, then causal directions are split depending on the sign of the causal effect.\n\n        Returns\n        -------\n        causal_direction_counts : dict\n            List of causal directions sorted by count in descending order.\n            The dictionary has the following format::\n            {'from': [n_directions], 'to': [n_directions], 'count': [n_directions]}\n            where ``n_directions`` is the number of causal directions.\n        \"\"\"", "\n", "# Check parameters", "\n", "if", "isinstance", "(", "n_directions", ",", "(", "numbers", ".", "Integral", ",", "np", ".", "integer", ")", ")", ":", "\n", "            ", "if", "not", "0", "<", "n_directions", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'n_directions must be an integer greater than 0'", ")", "\n", "", "", "elif", "n_directions", "is", "None", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'n_directions must be an integer greater than 0'", ")", "\n", "\n", "", "if", "min_causal_effect", "is", "None", ":", "\n", "            ", "min_causal_effect", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "if", "not", "0.0", "<", "min_causal_effect", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'min_causal_effect must be an value greater than 0.'", ")", "\n", "\n", "# Count causal directions", "\n", "", "", "directions", "=", "[", "]", "\n", "for", "am", "in", "np", ".", "nan_to_num", "(", "self", ".", "_adjacency_matrices", ")", ":", "\n", "            ", "direction", "=", "np", ".", "array", "(", "np", ".", "where", "(", "np", ".", "abs", "(", "am", ")", ">", "min_causal_effect", ")", ")", "\n", "if", "split_by_causal_effect_sign", ":", "\n", "                ", "signs", "=", "np", ".", "array", "(", "[", "np", ".", "sign", "(", "am", "[", "i", "]", "[", "j", "]", ")", "\n", "for", "i", ",", "j", "in", "direction", ".", "T", "]", ")", ".", "astype", "(", "'int64'", ")", ".", "T", "\n", "direction", "=", "np", ".", "vstack", "(", "[", "direction", ",", "signs", "]", ")", "\n", "", "directions", ".", "append", "(", "direction", ".", "T", ")", "\n", "", "directions", "=", "np", ".", "concatenate", "(", "directions", ")", "\n", "\n", "if", "len", "(", "directions", ")", "==", "0", ":", "\n", "            ", "cdc", "=", "{", "'from'", ":", "[", "]", ",", "'to'", ":", "[", "]", ",", "'count'", ":", "[", "]", "}", "\n", "if", "split_by_causal_effect_sign", ":", "\n", "                ", "cdc", "[", "'sign'", "]", "=", "[", "]", "\n", "", "return", "cdc", "\n", "\n", "", "directions", ",", "counts", "=", "np", ".", "unique", "(", "directions", ",", "axis", "=", "0", ",", "return_counts", "=", "True", ")", "\n", "sort_order", "=", "np", ".", "argsort", "(", "-", "counts", ")", "\n", "sort_order", "=", "sort_order", "[", ":", "n_directions", "]", "if", "n_directions", "is", "not", "None", "else", "sort_order", "\n", "counts", "=", "counts", "[", "sort_order", "]", "\n", "directions", "=", "directions", "[", "sort_order", "]", "\n", "\n", "cdc", "=", "{", "\n", "'from'", ":", "directions", "[", ":", ",", "1", "]", ".", "tolist", "(", ")", ",", "\n", "'to'", ":", "directions", "[", ":", ",", "0", "]", ".", "tolist", "(", ")", ",", "\n", "'count'", ":", "counts", ".", "tolist", "(", ")", "\n", "}", "\n", "if", "split_by_causal_effect_sign", ":", "\n", "            ", "cdc", "[", "'sign'", "]", "=", "directions", "[", ":", ",", "2", "]", ".", "tolist", "(", ")", "\n", "\n", "", "return", "cdc", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.bootstrap.BootstrapResult.get_directed_acyclic_graph_counts": [[182, 251], ["isinstance", "numpy.nan_to_num", "numpy.unique", "numpy.argsort", "dags.append", "counts.tolist", "ValueError", "ValueError", "ValueError", "numpy.abs", "numpy.array", "numpy.zeros_like().astype", "numpy.where", "numpy.sign().astype", "[].tolist", "[].tolist", "[].tolist", "[].tolist", "numpy.zeros_like", "numpy.sign", "numpy.where", "numpy.where", "numpy.array", "numpy.where", "numpy.where", "numpy.where"], "methods", ["None"], ["", "def", "get_directed_acyclic_graph_counts", "(", "self", ",", "n_dags", "=", "None", ",", "min_causal_effect", "=", "None", ",", "split_by_causal_effect_sign", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Get DAGs count as a result of bootstrapping.\n\n        Parameters\n        ----------\n        n_dags : int, optional (default=None)\n            If int, then The top ``n_dags`` items are included in the result\n        min_causal_effect : float, optional (default=None)\n            Threshold for detecting causal direction.\n            If float, then causal directions with absolute values of causal effects less than ``min_causal_effect`` are excluded.\n        split_by_causal_effect_sign : boolean, optional (default=False)\n            If True, then causal directions are split depending on the sign of the causal effect.\n\n        Returns\n        -------\n        directed_acyclic_graph_counts : dict\n            List of directed acyclic graphs sorted by count in descending order.\n            The dictionary has the following format::\n            {'dag': [n_dags], 'count': [n_dags]}.\n            where ``n_dags`` is the number of directed acyclic graphs.\n        \"\"\"", "\n", "# Check parameters", "\n", "if", "isinstance", "(", "n_dags", ",", "(", "numbers", ".", "Integral", ",", "np", ".", "integer", ")", ")", ":", "\n", "            ", "if", "not", "0", "<", "n_dags", ":", "\n", "                ", "raise", "ValueError", "(", "'n_dags must be an integer greater than 0'", ")", "\n", "", "", "elif", "n_dags", "is", "None", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'n_dags must be an integer greater than 0'", ")", "\n", "\n", "", "if", "min_causal_effect", "is", "None", ":", "\n", "            ", "min_causal_effect", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "if", "not", "0.0", "<", "min_causal_effect", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'min_causal_effect must be an value greater than 0.'", ")", "\n", "\n", "# Count directed acyclic graphs", "\n", "", "", "dags", "=", "[", "]", "\n", "for", "am", "in", "np", ".", "nan_to_num", "(", "self", ".", "_adjacency_matrices", ")", ":", "\n", "            ", "dag", "=", "np", ".", "abs", "(", "am", ")", ">", "min_causal_effect", "\n", "if", "split_by_causal_effect_sign", ":", "\n", "                ", "direction", "=", "np", ".", "array", "(", "np", ".", "where", "(", "dag", ")", ")", "\n", "signs", "=", "np", ".", "zeros_like", "(", "dag", ")", ".", "astype", "(", "'int64'", ")", "\n", "for", "i", ",", "j", "in", "direction", ".", "T", ":", "\n", "                    ", "signs", "[", "i", "]", "[", "j", "]", "=", "np", ".", "sign", "(", "am", "[", "i", "]", "[", "j", "]", ")", ".", "astype", "(", "'int64'", ")", "\n", "", "dag", "=", "signs", "\n", "", "dags", ".", "append", "(", "dag", ")", "\n", "\n", "", "dags", ",", "counts", "=", "np", ".", "unique", "(", "dags", ",", "axis", "=", "0", ",", "return_counts", "=", "True", ")", "\n", "sort_order", "=", "np", ".", "argsort", "(", "-", "counts", ")", "\n", "sort_order", "=", "sort_order", "[", ":", "n_dags", "]", "if", "n_dags", "is", "not", "None", "else", "sort_order", "\n", "counts", "=", "counts", "[", "sort_order", "]", "\n", "dags", "=", "dags", "[", "sort_order", "]", "\n", "\n", "if", "split_by_causal_effect_sign", ":", "\n", "            ", "dags", "=", "[", "{", "\n", "'from'", ":", "np", ".", "where", "(", "dag", ")", "[", "1", "]", ".", "tolist", "(", ")", ",", "\n", "'to'", ":", "np", ".", "where", "(", "dag", ")", "[", "0", "]", ".", "tolist", "(", ")", ",", "\n", "'sign'", ":", "[", "dag", "[", "i", "]", "[", "j", "]", "for", "i", ",", "j", "in", "np", ".", "array", "(", "np", ".", "where", "(", "dag", ")", ")", ".", "T", "]", "}", "for", "dag", "in", "dags", "]", "\n", "", "else", ":", "\n", "            ", "dags", "=", "[", "{", "\n", "'from'", ":", "np", ".", "where", "(", "dag", ")", "[", "1", "]", ".", "tolist", "(", ")", ",", "\n", "'to'", ":", "np", ".", "where", "(", "dag", ")", "[", "0", "]", ".", "tolist", "(", ")", "}", "for", "dag", "in", "dags", "]", "\n", "\n", "", "return", "{", "\n", "'dag'", ":", "dags", ",", "\n", "'count'", ":", "counts", ".", "tolist", "(", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.bootstrap.BootstrapResult.get_probabilities": [[253, 287], ["numpy.nan_to_num", "numpy.zeros", "numpy.where", "len", "int", "numpy.hsplit", "ValueError", "int", "numpy.abs"], "methods", ["None"], ["", "def", "get_probabilities", "(", "self", ",", "min_causal_effect", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Get bootstrap probability.\n\n        Parameters\n        ----------\n        min_causal_effect : float, optional (default=None)\n            Threshold for detecting causal direction.\n            If float, then causal directions with absolute values of causal effects less than ``min_causal_effect`` are excluded.\n\n        Returns\n        -------\n        probabilities : array-like\n            List of bootstrap probability matrix.\n        \"\"\"", "\n", "# check parameters", "\n", "if", "min_causal_effect", "is", "None", ":", "\n", "            ", "min_causal_effect", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "if", "not", "0.0", "<", "min_causal_effect", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'min_causal_effect must be an value greater than 0.'", ")", "\n", "\n", "", "", "adjacency_matrices", "=", "np", ".", "nan_to_num", "(", "self", ".", "_adjacency_matrices", ")", "\n", "shape", "=", "adjacency_matrices", "[", "0", "]", ".", "shape", "\n", "bp", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "for", "B", "in", "adjacency_matrices", ":", "\n", "            ", "bp", "+=", "np", ".", "where", "(", "np", ".", "abs", "(", "B", ")", ">", "min_causal_effect", ",", "1", ",", "0", ")", "\n", "", "bp", "=", "bp", "/", "len", "(", "adjacency_matrices", ")", "\n", "\n", "if", "int", "(", "shape", "[", "1", "]", "/", "shape", "[", "0", "]", ")", "==", "1", ":", "\n", "            ", "return", "bp", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "hsplit", "(", "bp", ",", "int", "(", "shape", "[", "1", "]", "/", "shape", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.bootstrap.BootstrapResult.get_causal_effects": [[288, 343], ["numpy.array", "numpy.zeros", "enumerate", "numpy.argsort", "numpy.sum", "len", "numpy.where", "numpy.where", "numpy.median", "dirs[].tolist", "dirs[].tolist", "numpy.zeros.tolist", "probs.tolist", "ValueError", "numpy.where", "numpy.abs", "numpy.abs", "numpy.abs"], "methods", ["None"], ["", "", "def", "get_causal_effects", "(", "self", ",", "min_causal_effect", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Get total effects list.\n\n        Parameters\n        ----------\n        min_causal_effect : float, optional (default=None)\n            Threshold for detecting causal direction.\n            If float, then causal directions with absolute values of causal effects less than ``min_causal_effect`` are excluded.\n\n        Returns\n        -------\n        causal_effects : dict\n            List of bootstrap causal effect sorted by probability in descending order.\n            The dictionary has the following format::\n            {'from': [n_directions], 'to': [n_directions], 'effect': [n_directions], 'probability': [n_directions]}\n            where ``n_directions`` is the number of causal directions.\n        \"\"\"", "\n", "# Check parameters", "\n", "if", "min_causal_effect", "is", "None", ":", "\n", "            ", "min_causal_effect", "=", "0.0", "\n", "", "else", ":", "\n", "            ", "if", "not", "0.0", "<", "min_causal_effect", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'min_causal_effect must be an value greater than 0.'", ")", "\n", "\n", "# Calculate probability", "\n", "", "", "probs", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "np", ".", "abs", "(", "self", ".", "_total_effects", ")", ">", "\n", "min_causal_effect", ",", "1", ",", "0", ")", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "[", "0", "]", "\n", "probs", "=", "probs", "/", "len", "(", "self", ".", "_total_effects", ")", "\n", "\n", "# Causal directions", "\n", "dirs", "=", "np", ".", "array", "(", "np", ".", "where", "(", "np", ".", "abs", "(", "probs", ")", ">", "0", ")", ")", "\n", "probs", "=", "probs", "[", "dirs", "[", "0", "]", ",", "dirs", "[", "1", "]", "]", "\n", "\n", "# Calculate median effect without zero", "\n", "effects", "=", "np", ".", "zeros", "(", "dirs", ".", "shape", "[", "1", "]", ")", "\n", "for", "i", ",", "(", "to", ",", "from_", ")", "in", "enumerate", "(", "dirs", ".", "T", ")", ":", "\n", "            ", "idx", "=", "np", ".", "where", "(", "np", ".", "abs", "(", "self", ".", "_total_effects", "[", ":", ",", "to", ",", "from_", "]", ")", ">", "0", ")", "\n", "effects", "[", "i", "]", "=", "np", ".", "median", "(", "self", ".", "_total_effects", "[", ":", ",", "to", ",", "from_", "]", "[", "idx", "]", ")", "\n", "\n", "# Sort by probability", "\n", "", "order", "=", "np", ".", "argsort", "(", "-", "probs", ")", "\n", "dirs", "=", "dirs", ".", "T", "[", "order", "]", "\n", "effects", "=", "effects", "[", "order", "]", "\n", "probs", "=", "probs", "[", "order", "]", "\n", "\n", "ce", "=", "{", "\n", "'from'", ":", "dirs", "[", ":", ",", "1", "]", ".", "tolist", "(", ")", ",", "\n", "'to'", ":", "dirs", "[", ":", ",", "0", "]", ".", "tolist", "(", ")", ",", "\n", "'effect'", ":", "effects", ".", "tolist", "(", ")", ",", "\n", "'probability'", ":", "probs", ".", "tolist", "(", ")", "\n", "}", "\n", "\n", "return", "ce", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.golem_model.GolemModel.__init__": [[36, 72], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "n", ",", "d", ",", "lambda_1", ",", "lambda_2", ",", "equal_variances", ",", "B_init", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialize self.\n\n        Parameters\n        ----------\n        n: int\n            Number of samples.\n        d: int\n            Number of nodes.\n        lambda_1: float\n            Coefficient of L1 penalty.\n        lambda_2: float\n            Coefficient of DAG penalty.\n        equal_variances: bool\n            Whether to assume equal noise variances\n            for likelibood objective. Default: True.\n        B_init: numpy.ndarray or None\n            [d, d] weighted matrix for initialization. \n            Set to None to disable. Default: None.\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "d", "=", "d", "\n", "self", ".", "lambda_1", "=", "lambda_1", "\n", "self", ".", "lambda_2", "=", "lambda_2", "\n", "self", ".", "equal_variances", "=", "equal_variances", "\n", "self", ".", "B_init", "=", "B_init", "\n", "\n", "if", "self", ".", "B_init", "is", "not", "None", ":", "\n", "            ", "self", ".", "_B", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "B_init", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_B", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "d", ",", "self", ".", "d", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.golem_model.GolemModel.forward": [[73, 85], ["golem_model.GolemModel._preprocess", "golem_model.GolemModel._compute_likelihood", "golem_model.GolemModel._compute_L1_penalty", "golem_model.GolemModel._compute_h"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.golem_model.GolemModel._preprocess", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.golem_model.GolemModel._compute_likelihood", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.golem_model.GolemModel._compute_L1_penalty", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.golem_model.GolemModel._compute_h"], ["", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"Build tensorflow graph.\"\"\"", "\n", "# Placeholders and variables", "\n", "self", ".", "X", "=", "X", "\n", "self", ".", "B", "=", "self", ".", "_preprocess", "(", "self", ".", "_B", ")", "\n", "\n", "# Likelihood, penalty terms and score", "\n", "self", ".", "likelihood", "=", "self", ".", "_compute_likelihood", "(", ")", "\n", "self", ".", "L1_penalty", "=", "self", ".", "_compute_L1_penalty", "(", ")", "\n", "self", ".", "h", "=", "self", ".", "_compute_h", "(", ")", "\n", "self", ".", "score", "=", "(", "self", ".", "likelihood", "+", "self", ".", "lambda_1", "*", "self", ".", "L1_penalty", "\n", "+", "self", ".", "lambda_2", "*", "self", ".", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.golem_model.GolemModel._preprocess": [[86, 103], ["torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "methods", ["None"], ["", "def", "_preprocess", "(", "self", ",", "B", ")", ":", "\n", "        ", "\"\"\"\n        Set the diagonals of B to zero.\n\n        Parameters\n        ----------\n        B: tf.Tensor\n            [d, d] weighted matrix.\n\n        Return\n        ------\n        torch.Tensor: [d, d] weighted matrix.\n        \"\"\"", "\n", "if", "self", ".", "args", ".", "device_type", "==", "'gpu'", ":", "\n", "            ", "return", "(", "1.", "-", "torch", ".", "eye", "(", "self", ".", "d", ")", ")", ".", "cuda", "(", "self", ".", "args", ".", "device_ids", ")", "*", "B", "\n", "", "else", ":", "\n", "            ", "return", "(", "1.", "-", "torch", ".", "eye", "(", "self", ".", "d", ")", ")", "*", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.golem_model.GolemModel._compute_likelihood": [[104, 130], ["torch.log", "torch.log", "torch.log", "torch.log", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.log", "torch.log", "torch.log", "torch.log", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.linalg.slogdet", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.linalg.norm", "torch.linalg.norm", "torch.linalg.norm", "torch.linalg.norm", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.linalg.norm", "torch.linalg.norm", "torch.linalg.norm", "torch.linalg.norm", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.eye().cuda", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.square", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "methods", ["None"], ["", "", "def", "_compute_likelihood", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Compute (negative log) likelihood in the linear Gaussian case.\n\n        Return\n        ------\n        torch.Tensor: Likelihood term (scalar-valued).\n        \"\"\"", "\n", "if", "self", ".", "equal_variances", ":", "# Assuming equal noise variances", "\n", "            ", "if", "self", ".", "args", ".", "device_type", "==", "'gpu'", ":", "\n", "                ", "return", "(", "0.5", "*", "self", ".", "d", "\n", "*", "torch", ".", "log", "(", "torch", ".", "square", "(", "torch", ".", "linalg", ".", "norm", "(", "self", ".", "X", "-", "self", ".", "X", "@", "self", ".", "B", ")", ")", ")", "\n", "-", "torch", ".", "linalg", ".", "slogdet", "(", "torch", ".", "eye", "(", "self", ".", "d", ")", ".", "cuda", "(", "self", ".", "args", ".", "device_ids", ")", "-", "self", ".", "B", ")", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "return", "(", "0.5", "*", "self", ".", "d", "\n", "*", "torch", ".", "log", "(", "torch", ".", "square", "(", "torch", ".", "linalg", ".", "norm", "(", "self", ".", "X", "-", "self", ".", "X", "@", "self", ".", "B", ")", ")", ")", "\n", "-", "torch", ".", "linalg", ".", "slogdet", "(", "torch", ".", "eye", "(", "self", ".", "d", ")", "-", "self", ".", "B", ")", "[", "1", "]", ")", "\n", "", "", "else", ":", "# Assuming non-equal noise variances", "\n", "            ", "if", "self", ".", "args", ".", "device_type", "==", "'gpu'", ":", "\n", "                ", "return", "(", "0.5", "\n", "*", "torch", ".", "sum", "(", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "square", "(", "self", ".", "X", "-", "self", ".", "X", "@", "self", ".", "B", ")", ",", "axis", "=", "0", ")", ")", ")", "\n", "-", "torch", ".", "linalg", ".", "slogdet", "(", "torch", ".", "eye", "(", "self", ".", "d", ")", ".", "cuda", "(", "self", ".", "args", ".", "device_ids", ")", "-", "self", ".", "B", ")", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "return", "(", "0.5", "\n", "*", "torch", ".", "sum", "(", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "square", "(", "self", ".", "X", "-", "self", ".", "X", "@", "self", ".", "B", ")", ",", "axis", "=", "0", ")", ")", ")", "\n", "-", "torch", ".", "linalg", ".", "slogdet", "(", "torch", ".", "eye", "(", "self", ".", "d", ")", "-", "self", ".", "B", ")", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.golem_model.GolemModel._compute_L1_penalty": [[131, 140], ["torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "", "", "def", "_compute_L1_penalty", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Compute L1 penalty.\n\n        Return\n        ------\n        tf.Tensor: L1 penalty term (scalar-valued).\n        \"\"\"", "\n", "return", "torch", ".", "norm", "(", "self", ".", "B", ",", "p", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.golem_model.GolemModel._compute_h": [[141, 150], ["torch.trace", "torch.trace", "torch.trace", "torch.trace", "torch.matrix_exp", "torch.matrix_exp", "torch.matrix_exp", "torch.matrix_exp"], "methods", ["None"], ["", "def", "_compute_h", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Compute DAG penalty.\n\n        Return\n        ------\n        torch.Tensor: DAG penalty term (scalar-valued).\n        \"\"\"", "\n", "return", "torch", ".", "trace", "(", "torch", ".", "matrix_exp", "(", "self", ".", "B", "*", "self", ".", "B", ")", ")", "-", "self", ".", "d", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.train.threshold_till_dag": [[27, 66], ["utils.is_dag", "numpy.copy", "numpy.where", "list", "sorted", "zip", "utils.is_dag", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.is_dag", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.is_dag"], ["def", "threshold_till_dag", "(", "B", ")", ":", "\n", "    ", "\"\"\"\n    Remove the edges with smallest absolute weight until a DAG is obtained.\n\n    Parameters\n    ----------\n    B: numpy.ndarray\n        [d, d] weighted matrix.\n\n    Return\n    ------\n    B: numpy.ndarray\n        [d, d] weighted matrix of DAG.\n    dag_thres: float\n        Minimum threshold to obtain DAG.\n    \"\"\"", "\n", "if", "is_dag", "(", "B", ")", ":", "\n", "        ", "return", "B", ",", "0", "\n", "\n", "", "B", "=", "np", ".", "copy", "(", "B", ")", "\n", "# Get the indices with non-zero weight", "\n", "nonzero_indices", "=", "np", ".", "where", "(", "B", "!=", "0", ")", "\n", "# Each element in the list is a tuple (weight, j, i)", "\n", "weight_indices_ls", "=", "list", "(", "zip", "(", "B", "[", "nonzero_indices", "]", ",", "\n", "nonzero_indices", "[", "0", "]", ",", "\n", "nonzero_indices", "[", "1", "]", ")", ")", "\n", "# Sort based on absolute weight", "\n", "sorted_weight_indices_ls", "=", "sorted", "(", "weight_indices_ls", ",", "key", "=", "lambda", "tup", ":", "abs", "(", "tup", "[", "0", "]", ")", ")", "\n", "\n", "for", "weight", ",", "j", ",", "i", "in", "sorted_weight_indices_ls", ":", "\n", "        ", "if", "is_dag", "(", "B", ")", ":", "\n", "# A DAG is found", "\n", "            ", "break", "\n", "\n", "# Remove edge with smallest absolute weight", "\n", "", "B", "[", "j", ",", "i", "]", "=", "0", "\n", "dag_thres", "=", "abs", "(", "weight", ")", "\n", "\n", "", "return", "B", ",", "dag_thres", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.train.postprocess": [[68, 92], ["numpy.copy", "train.threshold_till_dag", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.train.threshold_till_dag"], ["", "def", "postprocess", "(", "B", ",", "graph_thres", "=", "0.3", ")", ":", "\n", "    ", "\"\"\"\n    Post-process estimated solution:\n        (1) Thresholding.\n        (2) Remove the edges with smallest absolute weight until a DAG\n            is obtained.\n\n    Parameters\n    ----------\n    B: numpy.ndarray\n        [d, d] weighted matrix.\n    graph_thres: float\n        Threshold for weighted matrix. Default: 0.3.\n\n    Return\n    ------\n    B: numpy.ndarray\n        [d, d] weighted matrix of DAG.\n    \"\"\"", "\n", "B", "=", "np", ".", "copy", "(", "B", ")", "\n", "B", "[", "np", ".", "abs", "(", "B", ")", "<=", "graph_thres", "]", "=", "0", "# Thresholding", "\n", "B", ",", "_", "=", "threshold_till_dag", "(", "B", ")", "\n", "\n", "return", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.is_cuda_available": [[30, 32], ["torch.cuda.is_available"], "function", ["None"], ["def", "is_cuda_available", "(", ")", ":", "\n", "    ", "return", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.set_seed": [[34, 52], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "str"], "function", ["None"], ["", "def", "set_seed", "(", "seed", ")", ":", "\n", "    ", "\"\"\"\n    Set random seed for reproducibility.\n\n    Parameters\n    ----------\n    seed: int\n        Random seed.\n    \"\"\"", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "try", ":", "\n", "        ", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.is_dag": [[54, 64], ["networkx.is_directed_acyclic_graph", "networkx.DiGraph"], "function", ["None"], ["", "", "def", "is_dag", "(", "B", ")", ":", "\n", "    ", "\"\"\"\n    Check whether B corresponds to a DAG.\n\n    Parameters\n    ----------\n    B: numpy.ndarray\n        [d, d] binary or weighted matrix.\n    \"\"\"", "\n", "return", "nx", ".", "is_directed_acyclic_graph", "(", "nx", ".", "DiGraph", "(", "B", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.tensorflow.gae.GAE.__init__": [[100, 143], ["castle.common.BaseLearner.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["", "else", ":", "\n", "            ", "flatten", "=", "tf", ".", "reshape", "(", "x", ",", "shape", "=", "(", "-", "1", ",", "input_dim", ")", ")", "\n", "for", "_", "in", "range", "(", "num_hidden_layers", ")", ":", "# Hidden layer", "\n", "                ", "flatten", "=", "Dense", "(", "hidden_size", ",", "activation", "=", "None", ",", "kernel_initializer", "=", "self", ".", "initializer", ")", "(", "flatten", ")", "\n", "flatten", "=", "LeakyReLU", "(", "alpha", "=", "0.05", ")", "(", "flatten", ")", "\n", "\n", "", "flatten", "=", "Dense", "(", "output_dim", ",", "kernel_initializer", "=", "self", ".", "initializer", ")", "(", "flatten", ")", "# Final output layer", "\n", "\n", "return", "tf", ".", "reshape", "(", "flatten", ",", "shape", "=", "(", "self", ".", "n", ",", "self", ".", "d", ",", "output_dim", ")", ")", "\n", "\n", "", "", "def", "save", "(", "self", ",", "model_dir", ")", ":", "\n", "        ", "create_dir", "(", "model_dir", ")", "\n", "self", ".", "saver", ".", "save", "(", "self", ".", "sess", ",", "'{}/model'", ".", "format", "(", "model_dir", ")", ")", "\n", "\n", "", "@", "property", "\n", "def", "logger", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "_logger", "\n", "", "except", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'self._logger does not exist!'", ")", "\n", "\n", "\n", "", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "n", ",", "d", "=", "3000", ",", "20", "\n", "\n", "model", "=", "GAE", "(", "n", ",", "d", ",", "x_dim", "=", "1", ")", "\n", "model", ".", "print_summary", "(", "print", ")", "\n", "\n", "print", "(", "'\\nVariables needed by trainer:'", ")", "\n", "print", "(", "'model.sess: {}'", ".", "format", "(", "model", ".", "sess", ")", ")", "\n", "print", "(", "'model.train_op: {}'", ".", "format", "(", "model", ".", "train_op", ")", ")", "\n", "print", "(", "'model.loss: {}'", ".", "format", "(", "model", ".", "loss", ")", ")", "\n", "print", "(", "'model.mse_loss: {}'", ".", "format", "(", "model", ".", "mse_loss", ")", ")", "\n", "print", "(", "'model.h: {}'", ".", "format", "(", "model", ".", "h", ")", ")", "\n", "print", "(", "'model.W_prime: {}'", ".", "format", "(", "model", ".", "W_prime", ")", ")", "\n", "print", "(", "'model.X: {}'", ".", "format", "(", "model", ".", "X", ")", ")", "\n", "print", "(", "'model.rho: {}'", ".", "format", "(", "model", ".", "rho", ")", ")", "\n", "print", "(", "'model.alpha: {}'", ".", "format", "(", "model", ".", "alpha", ")", ")", "\n", "print", "(", "'model.lr: {}'", ".", "format", "(", "model", ".", "lr", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.tensorflow.gae.GAE.learn": [[144, 173], ["castle.common.Tensor", "gae.GAE._gae", "castle.common.Tensor", "castle.common.Tensor", "castle.common.Tensor", "castle.common.Tensor.reshape", "abs"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.tensorflow.gae.GAE._gae"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.tensorflow.gae.GAE._gae": [[174, 200], ["helpers.tf_utils.set_seed", "models.GAEModel", "trainers.ALTrainer", "trainers.ALTrainer.train", "numpy.max", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.set_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.train"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.TrExpScipy.forward": [[26, 41], ["torch.no_grad", "scipy.linalg.expm", "torch.as_tensor", "ctx.save_for_backward", "torch.trace", "input.detach().cpu().numpy", "input.detach().cpu", "input.detach"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# send tensor to cpu in numpy format and compute expm using scipy", "\n", "            ", "expm_input", "=", "expm", "(", "input", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "# transform back into a tensor", "\n", "expm_input", "=", "torch", ".", "as_tensor", "(", "expm_input", ")", "\n", "if", "input", ".", "is_cuda", ":", "\n", "# expm_input = expm_input.cuda()", "\n", "                ", "assert", "expm_input", ".", "is_cuda", "\n", "# save expm_input to use in backward", "\n", "", "ctx", ".", "save_for_backward", "(", "expm_input", ")", "\n", "\n", "# return the trace", "\n", "return", "torch", ".", "trace", "(", "expm_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.TrExpScipy.backward": [[42, 47], ["torch.no_grad", "expm_input.t"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "expm_input", ",", "=", "ctx", ".", "saved_tensors", "\n", "return", "expm_input", ".", "t", "(", ")", "*", "grad_output", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.compute_constraint": [[49, 53], ["TrExpScipy.apply"], "function", ["None"], ["", "", "", "def", "compute_constraint", "(", "model", ",", "w_adj", ")", ":", "\n", "    ", "assert", "(", "w_adj", ">=", "0", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "all", "(", ")", "\n", "h", "=", "TrExpScipy", ".", "apply", "(", "w_adj", ")", "-", "model", ".", "input_dim", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.is_acyclic": [[58, 68], ["numpy.eye", "range", "numpy.matmul", "adjacency.asnumpy", "numpy.trace"], "function", ["None"], ["\n", "prod", "=", "np", ".", "eye", "(", "adjacency", ".", "shape", "[", "0", "]", ")", "\n", "for", "_", "in", "range", "(", "1", ",", "adjacency", ".", "shape", "[", "0", "]", "+", "1", ")", ":", "\n", "        ", "prod", "=", "np", ".", "matmul", "(", "adjacency", ",", "prod", ")", "\n", "if", "np", ".", "trace", "(", "prod", ")", "!=", "0", ":", "\n", "            ", "return", "False", "\n", "", "", "return", "True", "\n", "\n", "\n", "", "def", "compute_A_phi", "(", "model", ",", "norm", "=", "\"none\"", ",", "square", "=", "False", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.compute_A_phi": [[70, 119], ["mindspore.eye", "enumerate", "mindspore.ops.reduce_sum", "model.get_parameters", "mindspore.eye", "mindspore.ops.reduce_sum", "mindspore.ops.absolute", "mindspore.ops.expand_dims", "mindspore.ops.mul", "mindspore.ops.matmul", "mindspore.ops.matmul", "mindspore.eye", "ops.matmul.transpose", "model.adjacency.transpose", "mindspore.ops.expand_dims", "mindspore.ops.mul", "mindspore.ops.matmul", "mindspore.ops.matmul", "mindspore.eye", "ops.expand_dims.transpose", "mindspore.ops.ones_like", "mindspore.ops.ones_like"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_parameters"], ["\n", "weights", "=", "model", ".", "get_parameters", "(", "mode", "=", "'w'", ")", "[", "0", "]", "\n", "prod", "=", "torch", ".", "eye", "(", "model", ".", "input_dim", ")", "\n", "if", "norm", "!=", "\"none\"", ":", "\n", "        ", "prod_norm", "=", "torch", ".", "eye", "(", "model", ".", "input_dim", ")", "\n", "", "for", "i", ",", "w", "in", "enumerate", "(", "weights", ")", ":", "\n", "        ", "if", "square", ":", "\n", "            ", "w", "=", "w", "**", "2", "\n", "", "else", ":", "\n", "            ", "w", "=", "torch", ".", "abs", "(", "w", ")", "\n", "", "if", "i", "==", "0", ":", "\n", "            ", "prod", "=", "torch", ".", "einsum", "(", "\"tij,ljt,jk->tik\"", ",", "w", ",", "\n", "model", ".", "adjacency", ".", "unsqueeze", "(", "0", ")", ",", "prod", ")", "\n", "if", "norm", "!=", "\"none\"", ":", "\n", "                ", "tmp", "=", "1.", "-", "torch", ".", "eye", "(", "model", ".", "input_dim", ")", ".", "unsqueeze", "(", "0", ")", "\n", "prod_norm", "=", "torch", ".", "einsum", "(", "\"tij,ljt,jk->tik\"", ",", "\n", "torch", ".", "ones_like", "(", "w", ")", ".", "detach", "(", ")", ",", "tmp", ",", "\n", "prod_norm", ")", "\n", "", "", "else", ":", "\n", "            ", "prod", "=", "torch", ".", "einsum", "(", "\"tij,tjk->tik\"", ",", "w", ",", "prod", ")", "\n", "if", "norm", "!=", "\"none\"", ":", "\n", "                ", "prod_norm", "=", "torch", ".", "einsum", "(", "\"tij,tjk->tik\"", ",", "\n", "torch", ".", "ones_like", "(", "w", ")", ".", "detach", "(", ")", ",", "\n", "prod_norm", ")", "\n", "\n", "# sum over density parameter axis", "\n", "", "", "", "prod", "=", "torch", ".", "sum", "(", "prod", ",", "1", ")", "\n", "if", "norm", "==", "\"paths\"", ":", "\n", "        ", "prod_norm", "=", "torch", ".", "sum", "(", "prod_norm", ",", "1", ")", "\n", "denominator", "=", "prod_norm", "+", "torch", ".", "eye", "(", "model", ".", "input_dim", ")", "# avoid / 0 on diagonal", "\n", "return", "(", "prod", "/", "denominator", ")", ".", "t", "(", ")", "\n", "", "elif", "norm", "==", "\"none\"", ":", "\n", "        ", "return", "prod", ".", "t", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "\n", "", "", "def", "compute_jacobian_avg", "(", "model", ",", "data_manager", ",", "batch_size", ")", ":", "\n", "    ", "\"\"\"\n    compute the average Jacobian of learned model\n    \"\"\"", "\n", "jac_avg", "=", "torch", ".", "zeros", "(", "model", ".", "input_dim", ",", "model", ".", "input_dim", ")", "\n", "\n", "# sample", "\n", "x", ",", "do_mask", "=", "data_manager", ".", "sample", "(", "batch_size", ")", "\n", "x", ".", "requires_grad", "=", "True", "\n", "\n", "# compute loss", "\n", "weights", ",", "biases", ",", "extra_params", "=", "model", ".", "get_parameters", "(", "mode", "=", "\"wbx\"", ")", "\n", "log_probs", "=", "model", ".", "compute_log_likelihood", "(", "x", ",", "weights", ",", "biases", ",", "extra_params", ",", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.compute_jacobian_avg": [[121, 140], ["mindspore.zeros", "data_manager.sample", "model.set_train", "range", "mindspore.zeros", "mindspore.ops.reduce_mean", "dag_optimizer.GradNetWrtX", "mindspore.ops.absolute"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["log_probs", "=", "torch", ".", "unbind", "(", "log_probs", ",", "1", ")", "\n", "\n", "# compute jacobian of the loss", "\n", "for", "i", "in", "range", "(", "model", ".", "input_dim", ")", ":", "\n", "        ", "tmp", "=", "torch", ".", "autograd", ".", "grad", "(", "log_probs", "[", "i", "]", ",", "x", ",", "retain_graph", "=", "True", ",", "\n", "grad_outputs", "=", "torch", ".", "ones", "(", "batch_size", ")", ")", "[", "0", "]", "\n", "jac_avg", "[", "i", ",", ":", "]", "=", "torch", ".", "abs", "(", "tmp", ")", ".", "mean", "(", "0", ")", "\n", "\n", "", "return", "jac_avg", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.__init__": [[30, 75], ["mindspore.Cell.__init__", "mindspore.Normal", "mindspore.Normal", "mindspore.Normal", "layer_list.insert", "layer_list.append", "list", "list", "enumerate", "mindspore.ParameterTuple", "mindspore.ParameterTuple", "mindspore.ParameterTuple", "mindspore.ParameterTuple", "mindspore.ParameterTuple", "mindspore.ParameterTuple", "base_model.BaseModel.reset_params", "mindspore.ones", "mindspore.ones", "mindspore.ones", "mindspore.eye", "mindspore.eye", "mindspore.eye", "list.append", "list.append", "mindspore.Parameter", "mindspore.Parameter", "mindspore.Parameter", "mindspore.Parameter", "mindspore.Parameter", "mindspore.Parameter", "mindspore.zeros", "mindspore.zeros", "mindspore.zeros", "mindspore.zeros", "mindspore.zeros", "mindspore.zeros", "str", "str"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.reset_params"], ["\n", "        ", "super", "(", "BaseModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "hidden_num", "=", "hidden_num", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "nonlinear", "=", "nonlinear", "\n", "self", ".", "norm_prod", "=", "norm_prod", "\n", "self", ".", "square_prod", "=", "square_prod", "\n", "\n", "self", ".", "weights", "=", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "biases", "=", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "extra_params", "=", "[", "]", "\n", "# Those parameter might be learnable, but they do not depend on parents.", "\n", "\n", "# initialize current adjacency matrix", "\n", "self", ".", "adjacency", "=", "torch", ".", "ones", "(", "(", "self", ".", "input_dim", ",", "self", ".", "input_dim", ")", ")", "-", "torch", ".", "eye", "(", "self", ".", "input_dim", ")", "\n", "\n", "self", ".", "zero_weights_ratio", "=", "0.", "\n", "self", ".", "numel_weights", "=", "0", "\n", "\n", "# Generate layer_list", "\n", "layer_list", "=", "[", "self", ".", "hidden_dim", "]", "*", "self", ".", "hidden_num", "\n", "layer_list", ".", "insert", "(", "0", ",", "self", ".", "input_dim", ")", "\n", "layer_list", ".", "append", "(", "self", ".", "output_dim", ")", "\n", "\n", "# Instantiate the parameters of each layer in the model of each variable", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "layer_list", "[", ":", "-", "1", "]", ")", ":", "\n", "            ", "in_dim", "=", "item", "\n", "out_dim", "=", "layer_list", "[", "i", "+", "1", "]", "\n", "self", ".", "weights", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "input_dim", ",", "\n", "out_dim", ",", "\n", "in_dim", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "biases", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "input_dim", ",", "\n", "out_dim", ")", ",", "\n", "requires_grad", "=", "True", ")", ")", "\n", "self", ".", "numel_weights", "+=", "self", ".", "input_dim", "*", "out_dim", "*", "in_dim", "\n", "\n", "", "", "def", "forward_given_params", "(", "self", ",", "x", ",", "weights", ",", "biases", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.forward_given_params": [[171, 208], ["range", "mindspore.ops.Unstack", "mindspore.ops.Unstack", "mindspore.ops.Unstack", "mindspore.ops.expand_dims", "mindspore.ops.expand_dims", "mindspore.ops.expand_dims", "mindspore.ops.mul", "mindspore.ops.mul", "mindspore.ops.mul", "mindspore.ops.expand_dims", "mindspore.ops.expand_dims", "mindspore.ops.expand_dims", "base_model.BaseModel.adjacency.transpose", "mindspore.ops.expand_dims", "mindspore.ops.expand_dims", "mindspore.ops.expand_dims", "mindspore.ops.matmul().squeeze", "mindspore.ops.matmul().squeeze", "mindspore.ops.matmul().squeeze", "mindspore.ops.matmul().squeeze", "mindspore.ops.matmul().squeeze", "mindspore.ops.matmul().squeeze", "mindspore.LeakyReLU", "mindspore.LeakyReLU", "mindspore.LeakyReLU", "mindspore.Sigmoid", "mindspore.Sigmoid", "mindspore.Sigmoid", "mindspore.ops.matmul", "mindspore.ops.matmul", "mindspore.ops.matmul", "mindspore.ops.matmul", "mindspore.ops.matmul", "mindspore.ops.matmul", "mindspore.ops.expand_dims", "mindspore.ops.expand_dims", "mindspore.ops.expand_dims"], "methods", ["None"], ["\n", "", "if", "'b'", "in", "mode", ":", "\n", "                ", "for", "i", ",", "b", "in", "enumerate", "(", "self", ".", "biases", ")", ":", "\n", "                    ", "b", ".", "copy_", "(", "params", "[", "k", "]", "[", "i", "]", ")", "\n", "", "k", "+=", "1", "\n", "\n", "", "if", "'x'", "in", "mode", "and", "len", "(", "self", ".", "extra_params", ")", ">", "0", ":", "\n", "                ", "for", "i", ",", "ep", "in", "enumerate", "(", "self", ".", "extra_params", ")", ":", "\n", "                    ", "if", "ep", ".", "requires_grad", ":", "\n", "                        ", "ep", ".", "copy_", "(", "params", "[", "k", "]", "[", "i", "]", ")", "\n", "", "", "k", "+=", "1", "\n", "\n", "", "", "", "def", "get_grad_norm", "(", "self", ",", "mode", "=", "\"wbx\"", ")", ":", "\n", "        ", "\"\"\"Will get only parameters with requires_grad == True\n\n        Parameters\n        ----------\n        mode: str\n            w=weights, b=biases, x=extra_params (order is irrelevant)\n        Returns\n        -------\n        out : tuple\n            corresponding dicts of parameters\n        \"\"\"", "\n", "\n", "grad_norm", "=", "torch", ".", "zeros", "(", "1", ")", "\n", "\n", "if", "'w'", "in", "mode", ":", "\n", "            ", "for", "w", "in", "self", ".", "weights", ":", "\n", "                ", "grad_norm", "+=", "torch", ".", "sum", "(", "w", ".", "grad", "**", "2", ")", "\n", "\n", "", "", "if", "'b'", "in", "mode", ":", "\n", "            ", "for", "j", ",", "b", "in", "enumerate", "(", "self", ".", "biases", ")", ":", "\n", "                ", "grad_norm", "+=", "torch", ".", "sum", "(", "b", ".", "grad", "**", "2", ")", "\n", "\n", "", "", "if", "'x'", "in", "mode", ":", "\n", "            ", "for", "ep", "in", "self", ".", "extra_params", ":", "\n", "                ", "if", "ep", ".", "requires_grad", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_w_adj": [[220, 223], ["dag_optimizer.compute_A_phi"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.compute_A_phi"], ["def", "__init__", "(", "self", ",", "\n", "input_dim", ",", "\n", "hidden_num", ",", "\n", "hidden_dim", ",", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.reset_params": [[224, 237], ["range", "enumerate", "enumerate", "mindspore.common.initializer.initializer", "mindspore.common.initializer.initializer", "mindspore.common.initializer.initializer", "mindspore.zeros", "mindspore.zeros", "mindspore.zeros", "mindspore.common.initializer.XavierUniform", "mindspore.common.initializer.XavierUniform", "mindspore.common.initializer.XavierUniform"], "methods", ["None"], ["output_dim", ",", "\n", "nonlinear", "=", "\"leaky-relu\"", ",", "\n", "norm_prod", "=", "'paths'", ",", "\n", "square_prod", "=", "False", ")", ":", "\n", "        ", "super", "(", "LearnableModel", ",", "self", ")", ".", "__init__", "(", "input_dim", "=", "input_dim", ",", "\n", "hidden_num", "=", "hidden_num", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "output_dim", "=", "output_dim", ",", "\n", "nonlinear", "=", "nonlinear", ",", "\n", "norm_prod", "=", "norm_prod", ",", "\n", "square_prod", "=", "square_prod", ")", "\n", "\n", "self", ".", "reset_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_parameters": [[238, 273], ["list", "list.append", "enumerate", "list.append", "list.append", "weights.append", "biases.append", "extra_params.append"], "methods", ["None"], ["", "def", "compute_log_likelihood", "(", "self", ",", "x", ",", "weights", ",", "biases", ",", "extra_params", ",", "\n", "detach", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Return log-likelihood of the model for each example.\n        WARNING: This is really a joint distribution\n            only if the DAGness constraint on the mask is satisfied.\n            Otherwise the joint does not integrate to one.\n\n        Parameters\n        ----------\n        x: tuple\n            (batch_size, input_dim)\n        weights: list of tensor\n            that are coherent with self.weights\n        biases: list of tensor\n            that are coherent with self.biases\n        extra_params: list of tensor\n            that are coherent with self.extra_params\n        detach: bool, default False\n        Returns\n        -------\n        (batch_size, input_dim) log-likelihoods\n        \"\"\"", "\n", "density_params", "=", "self", ".", "forward_given_params", "(", "x", ",", "weights", ",", "biases", ")", "\n", "\n", "if", "len", "(", "extra_params", ")", "!=", "0", ":", "\n", "            ", "extra_params", "=", "self", ".", "transform_extra_params", "(", "self", ".", "extra_params", ")", "\n", "", "log_probs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "input_dim", ")", ":", "\n", "            ", "density_param", "=", "list", "(", "torch", ".", "unbind", "(", "density_params", "[", "i", "]", ",", "1", ")", ")", "\n", "if", "len", "(", "extra_params", ")", "!=", "0", ":", "\n", "                ", "density_param", ".", "extend", "(", "list", "(", "torch", ".", "unbind", "(", "extra_params", "[", "i", "]", ",", "0", ")", ")", ")", "\n", "", "conditional", "=", "self", ".", "get_distribution", "(", "density_param", ")", "\n", "x_d", "=", "x", "[", ":", ",", "i", "]", ".", "detach", "(", ")", "if", "detach", "else", "x", "[", ":", ",", "i", "]", "\n", "log_probs", ".", "append", "(", "conditional", ".", "log_prob", "(", "x_d", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.set_parameters": [[274, 306], ["range", "range", "enumerate", "range", "range", "len", "len", "len"], "methods", ["None"], ["", "return", "torch", ".", "cat", "(", "log_probs", ",", "1", ")", "\n", "\n", "", "def", "get_distribution", "(", "self", ",", "dp", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "def", "transform_extra_params", "(", "self", ",", "extra_params", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "\n", "", "", "class", "NonlinearGauss", "(", "LearnableModel", ")", ":", "\n", "    ", "\"\"\"Class of learnable models based on NonlinearGauss\n\n    Parameters\n    ----------\n    input_dim : int\n        number of features\n    hidden_num : int\n        number of hidden layers\n    hidden_dim : int\n        dimension of per hidden layer\n    output_dim : int\n    nonlinear : str, default 'leaky-relu'\n        Nonlinear activation function\n    norm_prod : str, default 'paths'\n    square_prod : bool, default False\n        whether use square_prod\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "\n", "input_dim", ",", "\n", "hidden_num", ",", "\n", "hidden_dim", ",", "\n", "output_dim", ",", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_grad_norm": [[183, 212], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "enumerate", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "", "", "def", "get_grad_norm", "(", "self", ",", "mode", "=", "\"wbx\"", ")", ":", "\n", "        ", "\"\"\"Will get only parameters with requires_grad == True\n\n        Parameters\n        ----------\n        mode: str\n            w=weights, b=biases, x=extra_params (order is irrelevant)\n        Returns\n        -------\n        out : tuple\n            corresponding dicts of parameters\n        \"\"\"", "\n", "\n", "grad_norm", "=", "torch", ".", "zeros", "(", "1", ")", "\n", "\n", "if", "'w'", "in", "mode", ":", "\n", "            ", "for", "w", "in", "self", ".", "weights", ":", "\n", "                ", "grad_norm", "+=", "torch", ".", "sum", "(", "w", ".", "grad", "**", "2", ")", "\n", "\n", "", "", "if", "'b'", "in", "mode", ":", "\n", "            ", "for", "j", ",", "b", "in", "enumerate", "(", "self", ".", "biases", ")", ":", "\n", "                ", "grad_norm", "+=", "torch", ".", "sum", "(", "b", ".", "grad", "**", "2", ")", "\n", "\n", "", "", "if", "'x'", "in", "mode", ":", "\n", "            ", "for", "ep", "in", "self", ".", "extra_params", ":", "\n", "                ", "if", "ep", ".", "requires_grad", ":", "\n", "                    ", "grad_norm", "+=", "torch", ".", "sum", "(", "ep", ".", "grad", "**", "2", ")", "\n", "\n", "", "", "", "return", "torch", ".", "sqrt", "(", "grad_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_distribution": [[307, 309], ["None"], "methods", ["None"], ["nonlinear", "=", "\"leaky-relu\"", ",", "\n", "norm_prod", "=", "'paths'", ",", "\n", "square_prod", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.LearnableModel.__init__": [[314, 333], ["base_model.BaseModel.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["nonlinear", "=", "nonlinear", ",", "\n", "norm_prod", "=", "norm_prod", ",", "\n", "square_prod", "=", "square_prod", ")", "\n", "\n", "", "def", "get_distribution", "(", "self", ",", "dp", ")", ":", "\n", "        ", "return", "distributions", ".", "normal", ".", "Normal", "(", "dp", "[", "0", "]", ",", "torch", ".", "exp", "(", "dp", "[", "1", "]", ")", ")", "\n", "\n", "\n", "", "", "class", "NonlinearGaussANM", "(", "LearnableModel", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.LearnableModel.compute_log_likelihood": [[238, 275], ["base_model.LearnableModel.forward_given_params", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "base_model.LearnableModel.transform_extra_params", "list", "base_model.LearnableModel.get_distribution", "log_probs.append", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "len", "list.extend", "x[].detach", "base_model.LearnableModel.log_prob().unsqueeze", "list", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "torch.unbind", "base_model.LearnableModel.log_prob"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.forward_given_params", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.NonlinearGaussANM.transform_extra_params", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.NonlinearGaussANM.get_distribution"], ["", "def", "compute_log_likelihood", "(", "self", ",", "x", ",", "weights", ",", "biases", ",", "extra_params", ",", "\n", "detach", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Return log-likelihood of the model for each example.\n        WARNING: This is really a joint distribution\n            only if the DAGness constraint on the mask is satisfied.\n            Otherwise the joint does not integrate to one.\n\n        Parameters\n        ----------\n        x: tuple\n            (batch_size, input_dim)\n        weights: list of tensor\n            that are coherent with self.weights\n        biases: list of tensor\n            that are coherent with self.biases\n        extra_params: list of tensor\n            that are coherent with self.extra_params\n        detach: bool, default False\n        Returns\n        -------\n        (batch_size, input_dim) log-likelihoods\n        \"\"\"", "\n", "density_params", "=", "self", ".", "forward_given_params", "(", "x", ",", "weights", ",", "biases", ")", "\n", "\n", "if", "len", "(", "extra_params", ")", "!=", "0", ":", "\n", "            ", "extra_params", "=", "self", ".", "transform_extra_params", "(", "self", ".", "extra_params", ")", "\n", "", "log_probs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "input_dim", ")", ":", "\n", "            ", "density_param", "=", "list", "(", "torch", ".", "unbind", "(", "density_params", "[", "i", "]", ",", "1", ")", ")", "\n", "if", "len", "(", "extra_params", ")", "!=", "0", ":", "\n", "                ", "density_param", ".", "extend", "(", "list", "(", "torch", ".", "unbind", "(", "extra_params", "[", "i", "]", ",", "0", ")", ")", ")", "\n", "", "conditional", "=", "self", ".", "get_distribution", "(", "density_param", ")", "\n", "x_d", "=", "x", "[", ":", ",", "i", "]", ".", "detach", "(", ")", "if", "detach", "else", "x", "[", ":", ",", "i", "]", "\n", "log_probs", ".", "append", "(", "conditional", ".", "log_prob", "(", "x_d", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "log_probs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.LearnableModel.get_distribution": [[334, 336], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.LearnableModel.transform_extra_params": [[279, 281], ["None"], "methods", ["None"], ["", "def", "transform_extra_params", "(", "self", ",", "extra_params", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.NonlinearGauss.__init__": [[366, 385], ["base_model.LearnableModel.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["requires_grad", "=", "True", ")", ")", "\n", "\n", "", "", "def", "get_distribution", "(", "self", ",", "dp", ")", ":", "\n", "        ", "return", "distributions", ".", "normal", ".", "Normal", "(", "dp", "[", "0", "]", ",", "dp", "[", "1", "]", ")", "\n", "\n", "", "def", "transform_extra_params", "(", "self", ",", "extra_params", ")", ":", "\n", "        ", "transformed_extra_params", "=", "[", "]", "\n", "for", "extra_param", "in", "extra_params", ":", "\n", "            ", "transformed_extra_params", ".", "append", "(", "torch", ".", "exp", "(", "extra_param", ")", ")", "\n", "", "return", "transformed_extra_params", "# returns std_dev", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.NonlinearGauss.get_distribution": [[386, 388], ["base_model.NonlinearGauss.normal.log_prob", "mindspore.ops.exp", "mindspore.ops.exp", "mindspore.ops.exp"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.NonlinearGaussANM.__init__": [[418, 450], ["base_model.LearnableModel.__init__", "numpy.ones", "numpy.random.shuffle", "list", "enumerate", "mindspore.ParameterTuple", "mindspore.ParameterTuple", "mindspore.ParameterTuple", "list.append", "mindspore.Parameter", "mindspore.Parameter", "mindspore.Parameter", "mindspore.Tensor", "mindspore.Tensor", "mindspore.Tensor", "numpy.log().reshape", "str", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.NonlinearGaussANM.get_distribution": [[451, 453], ["base_model.NonlinearGaussANM.normal.log_prob", "mindspore.ops.exp", "mindspore.ops.exp", "mindspore.ops.exp"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.NonlinearGaussANM.transform_extra_params": [[371, 376], ["transformed_extra_params.append", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "def", "transform_extra_params", "(", "self", ",", "extra_params", ")", ":", "\n", "        ", "transformed_extra_params", "=", "[", "]", "\n", "for", "extra_param", "in", "extra_params", ":", "\n", "            ", "transformed_extra_params", ".", "append", "(", "torch", ".", "exp", "(", "extra_param", ")", ")", "\n", "", "return", "transformed_extra_params", "# returns std_dev", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.GradNetWrtX.__init__": [[31, 36], ["mindspore.Cell.__init__", "mindspore.ops.GradOperation", "mindspore.ops.GradOperation", "mindspore.Tensor", "mindspore.Tensor"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["# transform back into a tensor", "\n", "expm_input", "=", "torch", ".", "as_tensor", "(", "expm_input", ")", "\n", "if", "input", ".", "is_cuda", ":", "\n", "# expm_input = expm_input.cuda()", "\n", "                ", "assert", "expm_input", ".", "is_cuda", "\n", "# save expm_input to use in backward", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.GradNetWrtX.construct": [[37, 56], ["dag_optimizer.GradNetWrtX.grad_op", "dag_optimizer.GradNetWrtX."], "methods", ["None"], ["", "ctx", ".", "save_for_backward", "(", "expm_input", ")", "\n", "\n", "# return the trace", "\n", "return", "torch", ".", "trace", "(", "expm_input", ")", "\n", "\n", "", "", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "expm_input", ",", "=", "ctx", ".", "saved_tensors", "\n", "return", "expm_input", ".", "t", "(", ")", "*", "grad_output", "\n", "\n", "\n", "", "", "", "def", "compute_constraint", "(", "model", ",", "w_adj", ")", ":", "\n", "    ", "assert", "(", "w_adj", ">=", "0", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "all", "(", ")", "\n", "h", "=", "TrExpScipy", ".", "apply", "(", "w_adj", ")", "-", "model", ".", "input_dim", "\n", "return", "h", "\n", "\n", "\n", "", "def", "is_acyclic", "(", "adjacency", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.construct": [[76, 94], ["base_model.BaseModel.compute_log_likelihood", "base_model.BaseModel.get_w_adj", "base_model.BaseModel.compute_constraint", "mindspore.ops.reduce_mean", "mindspore.ops.reduce_mean", "mindspore.ops.reduce_mean"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.compute_log_likelihood", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_w_adj", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.compute_constraint"], ["\n", "\n", "for", "k", "in", "range", "(", "self", ".", "hidden_num", "+", "1", ")", ":", "\n", "# apply affine operator", "\n", "            ", "if", "k", "==", "0", ":", "\n", "                ", "adj", "=", "self", ".", "adjacency", ".", "unsqueeze", "(", "0", ")", "\n", "x", "=", "torch", ".", "einsum", "(", "\"tij,ljt,bj->bti\"", ",", "weights", "[", "k", "]", ",", "adj", ",", "x", ")", "+", "biases", "[", "k", "]", "\n", "", "else", ":", "\n", "                ", "x", "=", "torch", ".", "einsum", "(", "\"tij,btj->bti\"", ",", "weights", "[", "k", "]", ",", "x", ")", "+", "biases", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.compute_constraint": [[95, 114], ["base_model.BaseModel.get_matrix_exp", "mindspore.trace", "mindspore.trace", "mindspore.trace"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_matrix_exp"], ["# apply non-linearity", "\n", "", "if", "k", "!=", "self", ".", "hidden_num", ":", "\n", "                ", "if", "self", ".", "nonlinear", "==", "\"leaky-relu\"", ":", "\n", "                    ", "x", "=", "F", ".", "leaky_relu", "(", "x", ")", "\n", "", "else", ":", "\n", "                    ", "x", "=", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n", "", "", "", "return", "torch", ".", "unbind", "(", "x", ",", "1", ")", "\n", "\n", "", "def", "get_w_adj", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get weighted adjacency matrix\"\"\"", "\n", "return", "compute_A_phi", "(", "self", ",", "norm", "=", "self", ".", "norm_prod", ",", "square", "=", "self", ".", "square_prod", ")", "\n", "\n", "", "def", "reset_params", "(", "self", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "node", "in", "range", "(", "self", ".", "input_dim", ")", ":", "\n", "                ", "for", "i", ",", "w", "in", "enumerate", "(", "self", ".", "weights", ")", ":", "\n", "                    ", "w", "=", "w", "[", "node", "]", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "\n", "w", ",", "gain", "=", "nn", ".", "init", ".", "calculate_gain", "(", "'leaky_relu'", ")", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_matrix_exp": [[115, 137], ["mindspore.zeros", "mindspore.zeros", "mindspore.zeros", "mindspore.eye", "mindspore.eye", "mindspore.eye", "mindspore.norm", "mindspore.norm", "mindspore.norm", "mindspore.matmul", "mindspore.matmul", "mindspore.matmul"], "methods", ["None"], ["", "for", "i", ",", "b", "in", "enumerate", "(", "self", ".", "biases", ")", ":", "\n", "                    ", "b", "=", "b", "[", "node", "]", "\n", "b", ".", "zero_", "(", ")", "\n", "\n", "", "", "", "", "def", "get_parameters", "(", "self", ",", "mode", "=", "\"wbx\"", ")", ":", "\n", "        ", "\"\"\"Will get only parameters with requires_grad == True\n\n        Parameters\n        ----------\n        mode: str\n            w=weights, b=biases, x=extra_params (order is irrelevant)\n        Returns\n        -------\n        out : tuple\n            corresponding dicts of parameters\n        \"\"\"", "\n", "\n", "params", "=", "[", "]", "\n", "\n", "if", "'w'", "in", "mode", ":", "\n", "            ", "weights", "=", "[", "]", "\n", "for", "w", "in", "self", ".", "weights", ":", "\n", "                ", "weights", ".", "append", "(", "w", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.compute_log_likelihood": [[138, 170], ["base_model.BaseModel.get_parameters", "base_model.BaseModel.forward_given_params", "range", "log_probs.append", "mindspore.ops.Concat", "mindspore.ops.Concat", "mindspore.ops.Concat", "len", "base_model.BaseModel.get_distribution", "base_model.BaseModel.get_distribution", "mindspore.ops.expand_dims", "mindspore.ops.expand_dims", "mindspore.ops.expand_dims", "density_params[].view", "mindspore.ops.Unstack", "mindspore.ops.Unstack", "mindspore.ops.Unstack"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_parameters", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.forward_given_params", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.NonlinearGaussANM.get_distribution", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.NonlinearGaussANM.get_distribution"], ["", "params", ".", "append", "(", "weights", ")", "\n", "", "if", "'b'", "in", "mode", ":", "\n", "            ", "biases", "=", "[", "]", "\n", "for", "j", ",", "b", "in", "enumerate", "(", "self", ".", "biases", ")", ":", "\n", "                ", "biases", ".", "append", "(", "b", ")", "\n", "", "params", ".", "append", "(", "biases", ")", "\n", "\n", "", "if", "'x'", "in", "mode", ":", "\n", "            ", "extra_params", "=", "[", "]", "\n", "for", "ep", "in", "self", ".", "extra_params", ":", "\n", "                ", "if", "ep", ".", "requires_grad", ":", "\n", "                    ", "extra_params", ".", "append", "(", "ep", ")", "\n", "", "", "params", ".", "append", "(", "extra_params", ")", "\n", "\n", "", "return", "tuple", "(", "params", ")", "\n", "\n", "", "def", "set_parameters", "(", "self", ",", "params", ",", "mode", "=", "\"wbx\"", ")", ":", "\n", "        ", "\"\"\"Will set only parameters with requires_grad == True\n\n        Parameters\n        ----------\n        params : tuple of parameter lists to set,\n            the order should be coherent with `get_parameters`\n        mode : str\n            w=weights, b=biases, x=extra_params (order is irrelevant)\n        \"\"\"", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "k", "=", "0", "\n", "if", "'w'", "in", "mode", ":", "\n", "                ", "for", "i", ",", "w", "in", "enumerate", "(", "self", ".", "weights", ")", ":", "\n", "                    ", "w", ".", "copy_", "(", "params", "[", "k", "]", "[", "i", "]", ")", "\n", "", "k", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_trainable_params": [[209, 219], ["list", "list", "base_model.BaseModel.parameters_and_names", "list.append"], "methods", ["None"], ["                    ", "grad_norm", "+=", "torch", ".", "sum", "(", "ep", ".", "grad", "**", "2", ")", "\n", "\n", "", "", "", "return", "torch", ".", "sqrt", "(", "grad_norm", ")", "\n", "\n", "", "def", "get_distribution", "(", "self", ",", "density_params", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "\n", "", "", "class", "LearnableModel", "(", "BaseModel", ")", ":", "\n", "    ", "\"\"\"Class for other learnable Models, disable instantiation.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.__init__": [[60, 87], ["numpy.random.RandomState", "numpy.arange", "isinstance", "mindspore.Tensor.astype", "mindspore.Tensor.astype", "gran_dag.NormalizationData.random.shuffle", "int", "TypeError", "mindspore.Tensor", "mindspore.Tensor", "mindspore.mean", "mindspore.mean", "mindspore.std", "mindspore.std"], "methods", ["None"], ["shuffle_idx", "=", "np", ".", "arange", "(", "data", ".", "shape", "[", "0", "]", ")", "\n", "if", "shuffle", ":", "\n", "            ", "self", ".", "random", ".", "shuffle", "(", "shuffle_idx", ")", "\n", "\n", "", "if", "isinstance", "(", "train_size", ",", "float", ")", ":", "\n", "            ", "train_samples", "=", "int", "(", "data", ".", "shape", "[", "0", "]", "*", "train_size", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\"The param train_size must be float < 1\"", ")", "\n", "", "if", "train", ":", "\n", "            ", "data", "=", "data", "[", "shuffle_idx", "[", ":", "train_samples", "]", "]", "\n", "", "else", ":", "\n", "            ", "data", "=", "data", "[", "shuffle_idx", "[", "train_samples", ":", "]", "]", "\n", "# as tensor", "\n", "", "self", ".", "data_set", "=", "torch", ".", "as_tensor", "(", "data", ")", ".", "type", "(", "torch", ".", "Tensor", ")", "\n", "\n", "# Normalize data", "\n", "self", ".", "mean", ",", "self", ".", "std", "=", "mean", ",", "std", "\n", "if", "normalize", ":", "\n", "            ", "if", "mean", "is", "None", "or", "std", "is", "None", ":", "\n", "                ", "self", ".", "mean", "=", "torch", ".", "mean", "(", "self", ".", "data_set", ",", "0", ",", "keepdim", "=", "True", ")", "\n", "self", ".", "std", "=", "torch", ".", "std", "(", "self", ".", "data_set", ",", "0", ",", "keepdim", "=", "True", ")", "\n", "", "self", ".", "data_set", "=", "(", "self", ".", "data_set", "-", "self", ".", "mean", ")", "/", "self", ".", "std", "\n", "", "self", ".", "n_samples", "=", "self", ".", "data_set", ".", "size", "(", "0", ")", "\n", "\n", "", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample": [[88, 109], ["gran_dag.NormalizationData.random.choice", "numpy.arange", "mindspore.ops.ones_like", "mindspore.ops.ones_like", "int", "mindspore.Tensor", "mindspore.Tensor", "int"], "methods", ["None"], ["\n", "sample_idxs", "=", "self", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "int", "(", "self", ".", "n_samples", ")", ")", ",", "\n", "size", "=", "(", "int", "(", "batch_size", ")", ",", ")", ",", "\n", "replace", "=", "False", ")", "\n", "samples", "=", "self", ".", "data_set", "[", "torch", ".", "as_tensor", "(", "sample_idxs", ")", ".", "long", "(", ")", "]", "\n", "\n", "return", "samples", ",", "torch", ".", "ones_like", "(", "samples", ")", "\n", "\n", "\n", "", "", "class", "GraNDAG", "(", "BaseLearner", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GranLoss.__init__": [[115, 117], ["mindspore.nn.loss.loss.LossBase.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GranLoss.construct": [[118, 121], ["gran_dag.GranLoss.get_loss"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GraNDAG.__init__": [[212, 266], ["castle.common.BaseLearner.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["stop_crit_win", "=", "100", ",", "\n", "edge_clamp_range", "=", "0.0001", ",", "\n", "norm_prod", "=", "'paths'", ",", "\n", "square_prod", "=", "False", ")", ":", "\n", "        ", "super", "(", "GraNDAG", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "hidden_num", "=", "hidden_num", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "iterations", "=", "iterations", "\n", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "nonlinear", "=", "nonlinear", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "h_threshold", "=", "h_threshold", "\n", "self", ".", "device_type", "=", "device_type", "\n", "self", ".", "use_pns", "=", "use_pns", "\n", "self", ".", "pns_thresh", "=", "pns_thresh", "\n", "self", ".", "num_neighbors", "=", "num_neighbors", "\n", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "precision", "=", "precision", "\n", "self", ".", "random_seed", "=", "random_seed", "\n", "self", ".", "jac_thresh", "=", "jac_thresh", "\n", "self", ".", "lambda_init", "=", "lambda_init", "\n", "self", ".", "mu_init", "=", "mu_init", "\n", "self", ".", "omega_lambda", "=", "omega_lambda", "\n", "self", ".", "omega_mu", "=", "omega_mu", "\n", "self", ".", "stop_crit_win", "=", "stop_crit_win", "\n", "self", ".", "edge_clamp_range", "=", "edge_clamp_range", "\n", "self", ".", "norm_prod", "=", "norm_prod", "\n", "self", ".", "square_prod", "=", "square_prod", "\n", "\n", "", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Set up and run the Gran-DAG algorithm\n\n        Parameters\n        ----------\n        data: numpy.ndarray or Tensor\n            include Tensor.data\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        \"\"\"", "\n", "\n", "# Control as much randomness as possible", "\n", "torch", ".", "manual_seed", "(", "self", ".", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "random_seed", ")", "\n", "\n", "# Use gpu", "\n", "if", "self", ".", "device_type", "==", "'gpu'", ":", "\n", "            ", "if", "self", ".", "precision", ":", "\n", "                ", "torch", ".", "set_default_tensor_type", "(", "'torch.cuda.FloatTensor'", ")", "\n", "", "else", ":", "\n", "                ", "torch", ".", "set_default_tensor_type", "(", "'torch.cuda.DoubleTensor'", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GraNDAG.learn": [[267, 355], ["mindspore.set_seed", "mindspore.set_seed", "mindspore.context.set_context", "mindspore.context.set_context", "mindspore.context.set_context", "mindspore.context.set_context", "mindspore.Tensor", "mindspore.Tensor", "gran_dag.NormalizationData", "gran_dag.NormalizationData", "gran_dag.GraNDAG._train", "gran_dag.GraNDAG._to_dag", "mindspore.Tensor", "mindspore.Tensor", "gran_dag.GraNDAG.device_type.lower", "gran_dag.GraNDAG.device_type.upper", "ValueError", "ValueError", "base.NonlinearGauss", "gran_dag.neighbors_selection", "gran_dag.GraNDAG.model.adjacency.asnumpy", "base.NonlinearGaussANM", "ValueError"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.set_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.golem_utils.utils.set_seed", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GraNDAG._train", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GraNDAG._to_dag", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.neighbors_selection"], ["", "", "elif", "self", ".", "device_type", "==", "'cpu'", ":", "\n", "            ", "if", "self", ".", "precision", ":", "\n", "                ", "torch", ".", "set_default_tensor_type", "(", "'torch.FloatTensor'", ")", "\n", "", "else", ":", "\n", "                ", "torch", ".", "set_default_tensor_type", "(", "'torch.DoubleTensor'", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Parameter device_type must be 'cpu' or 'gpu'.\"", ")", "\n", "\n", "# create learning model and ground truth model", "\n", "", "data", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "if", "data", ".", "shape", "[", "1", "]", "!=", "self", ".", "input_dim", ":", "\n", "            ", "raise", "ValueError", "(", "\"The number of variables is `{}`, \"", "\n", "\"the param input_dim is `{}`, \"", "\n", "\"they must be consistent\"", "\n", "\".\"", ".", "format", "(", "data", ".", "shape", "[", "1", "]", ",", "self", ".", "input_dim", ")", ")", "\n", "\n", "", "if", "self", ".", "model_name", "==", "\"NonLinGauss\"", ":", "\n", "            ", "self", ".", "model", "=", "NonlinearGauss", "(", "input_dim", "=", "self", ".", "input_dim", ",", "\n", "hidden_num", "=", "self", ".", "hidden_num", ",", "\n", "hidden_dim", "=", "self", ".", "hidden_dim", ",", "\n", "output_dim", "=", "2", ",", "\n", "nonlinear", "=", "self", ".", "nonlinear", ",", "\n", "norm_prod", "=", "self", ".", "norm_prod", ",", "\n", "square_prod", "=", "self", ".", "square_prod", ")", "\n", "", "elif", "self", ".", "model_name", "==", "\"NonLinGaussANM\"", ":", "\n", "            ", "self", ".", "model", "=", "NonlinearGaussANM", "(", "input_dim", "=", "self", ".", "input_dim", ",", "\n", "hidden_num", "=", "self", ".", "hidden_num", ",", "\n", "hidden_dim", "=", "self", ".", "hidden_dim", ",", "\n", "output_dim", "=", "1", ",", "\n", "nonlinear", "=", "self", ".", "nonlinear", ",", "\n", "norm_prod", "=", "self", ".", "norm_prod", ",", "\n", "square_prod", "=", "self", ".", "square_prod", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"self.model has to be in {NonLinGauss, NonLinGaussANM}\"", ")", "\n", "\n", "# create NormalizationData", "\n", "", "train_data", "=", "NormalizationData", "(", "data", ",", "train", "=", "True", ",", "\n", "normalize", "=", "self", ".", "normalize", ")", "\n", "test_data", "=", "NormalizationData", "(", "data", ",", "train", "=", "False", ",", "\n", "normalize", "=", "self", ".", "normalize", ",", "\n", "mean", "=", "train_data", ".", "mean", ",", "\n", "std", "=", "train_data", ".", "std", ")", "\n", "\n", "# apply preliminary neighborhood selection if input_dim > 50", "\n", "if", "self", ".", "use_pns", ":", "\n", "            ", "if", "self", ".", "num_neighbors", "is", "None", ":", "\n", "                ", "num_neighbors", "=", "self", ".", "input_dim", "\n", "", "else", ":", "\n", "                ", "num_neighbors", "=", "self", ".", "num_neighbors", "\n", "\n", "", "self", ".", "model", "=", "neighbors_selection", "(", "model", "=", "self", ".", "model", ",", "all_samples", "=", "data", ",", "\n", "num_neighbors", "=", "num_neighbors", ",", "\n", "thresh", "=", "self", ".", "pns_thresh", ")", "\n", "\n", "# update self.model by train", "\n", "", "self", ".", "_train", "(", "train_data", "=", "train_data", ",", "test_data", "=", "test_data", ")", "\n", "\n", "# update self.model by run _to_dag", "\n", "self", ".", "_to_dag", "(", "train_data", ")", "\n", "\n", "self", ".", "_causal_matrix", "=", "Tensor", "(", "self", ".", "model", ".", "adjacency", ".", "detach", "(", ")", ".", "numpy", "(", ")", ",", "\n", "index", "=", "data", ".", "columns", ",", "\n", "columns", "=", "data", ".", "columns", ")", "\n", "\n", "", "def", "_train", "(", "self", ",", "train_data", ",", "test_data", ")", ":", "\n", "        ", "\"\"\"\n        Applying augmented Lagrangian to solve the continuous constrained problem.\n\n        Parameters\n        ----------\n        train_data: NormalizationData\n            train samples\n        test_data: NormalizationData object\n            test samples for validation\n        \"\"\"", "\n", "\n", "# initialize stuff for learning loop", "\n", "aug_lagrangians", "=", "[", "]", "\n", "aug_lagrangian_ma", "=", "[", "0.0", "]", "*", "(", "self", ".", "iterations", "+", "1", ")", "\n", "aug_lagrangians_val", "=", "[", "]", "\n", "grad_norms", "=", "[", "]", "\n", "grad_norm_ma", "=", "[", "0.0", "]", "*", "(", "self", ".", "iterations", "+", "1", ")", "\n", "\n", "w_adjs", "=", "np", ".", "zeros", "(", "(", "self", ".", "iterations", ",", "\n", "self", ".", "input_dim", ",", "\n", "self", ".", "input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GraNDAG._train": [[356, 469], ["gran_dag.GraNDAG.model.get_trainable_params", "gran_dag.GranLoss", "mindspore.WithLossCell", "mindspore.WithLossCell", "mindspore.TrainOneStepCell", "mindspore.TrainOneStepCell", "tqdm.tqdm.tqdm", "mindspore.optim.SGD", "mindspore.optim.SGD", "range", "train_data.sample", "gran_dag.GraNDAG._create_dataset", "gran_dag.GraNDAG.model.get_w_adj", "scipy.linalg.expm", "gran_dag.GraNDAG.model.set_train", "mindspore.TrainOneStepCell.", "gran_dag.GraNDAG.model.set_train", "not_nlls.append", "mindspore.optim.RMSProp", "mindspore.optim.RMSProp", "ValueError", "x.asnumpy", "gran_dag.GraNDAG.asnumpy", "numpy.trace", "test_data.sample", "aug_lagrangians_val.append", "mindspore.ops.reduce_mean", "mindspore.ops.reduce_mean", "hs.append", "gran_dag.GraNDAG.model.get_trainable_params", "gran_dag.GranLoss", "mindspore.WithLossCell", "mindspore.WithLossCell", "mindspore.TrainOneStepCell", "mindspore.TrainOneStepCell", "list", "gran_dag.GraNDAG.model.compute_log_likelihood", "min", "max", "abs", "len", "mindspore.optim.RMSProp", "mindspore.optim.RMSProp", "mindspore.optim.SGD", "mindspore.optim.SGD", "loss_val.asnumpy().item", "loss_val.asnumpy"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_trainable_params", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GraNDAG._create_dataset", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_w_adj", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_trainable_params", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.compute_log_likelihood"], ["hs", "=", "[", "]", "\n", "not_nlls", "=", "[", "]", "# Augmented Lagrangian minus (pseudo) NLL", "\n", "nlls", "=", "[", "]", "# NLL on train", "\n", "nlls_val", "=", "[", "]", "# NLL on validation", "\n", "\n", "# Augmented Lagrangian stuff", "\n", "mu", "=", "self", ".", "mu_init", "\n", "lamb", "=", "self", ".", "lambda_init", "\n", "mus", "=", "[", "]", "\n", "lambdas", "=", "[", "]", "\n", "\n", "if", "self", ".", "optimizer", "==", "\"sgd\"", ":", "\n", "            ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "optimizer", "==", "\"rmsprop\"", ":", "\n", "            ", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"optimizer {} is not implemented\"", "\n", ".", "format", "(", "self", ".", "optimizer", ")", ")", "\n", "\n", "# Learning loop:", "\n", "", "for", "iter", "in", "tqdm", "(", "range", "(", "self", ".", "iterations", ")", ",", "desc", "=", "'Training Iterations'", ")", ":", "\n", "# compute loss", "\n", "            ", "self", ".", "model", ".", "train", "(", ")", "\n", "x", ",", "_", "=", "train_data", ".", "sample", "(", "self", ".", "batch_size", ")", "\n", "# Initialize weights and bias", "\n", "weights", ",", "biases", ",", "extra_params", "=", "self", ".", "model", ".", "get_parameters", "(", "mode", "=", "\"wbx\"", ")", "\n", "loss", "=", "-", "torch", ".", "mean", "(", "\n", "self", ".", "model", ".", "compute_log_likelihood", "(", "x", ",", "weights", ",", "biases", ",", "extra_params", ")", ")", "\n", "nlls", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "# constraint related", "\n", "w_adj", "=", "self", ".", "model", ".", "get_w_adj", "(", ")", "\n", "h", "=", "compute_constraint", "(", "self", ".", "model", ",", "w_adj", ")", "\n", "\n", "# compute augmented Lagrangian", "\n", "aug_lagrangian", "=", "loss", "+", "0.5", "*", "mu", "*", "h", "**", "2", "+", "lamb", "*", "h", "\n", "\n", "# optimization step on augmented lagrangian", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "aug_lagrangian", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# clamp edges", "\n", "if", "self", ".", "edge_clamp_range", "!=", "0", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "to_keep", "=", "(", "w_adj", ">", "self", ".", "edge_clamp_range", ")", "*", "1", "\n", "self", ".", "model", ".", "adjacency", "*=", "to_keep", "\n", "\n", "# logging", "\n", "", "", "w_adjs", "[", "iter", ",", ":", ",", ":", "]", "=", "w_adj", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "mus", ".", "append", "(", "mu", ")", "\n", "lambdas", ".", "append", "(", "lamb", ")", "\n", "not_nlls", ".", "append", "(", "0.5", "*", "mu", "*", "h", ".", "item", "(", ")", "**", "2", "+", "lamb", "*", "h", ".", "item", "(", ")", ")", "\n", "\n", "# compute augmented lagrangian moving average", "\n", "aug_lagrangians", ".", "append", "(", "aug_lagrangian", ".", "item", "(", ")", ")", "\n", "aug_lagrangian_ma", "[", "iter", "+", "1", "]", "=", "aug_lagrangian_ma", "[", "iter", "]", "+", "0.01", "*", "(", "aug_lagrangian", ".", "item", "(", ")", "-", "\n", "aug_lagrangian_ma", "[", "iter", "]", ")", "\n", "grad_norms", ".", "append", "(", "self", ".", "model", ".", "get_grad_norm", "(", "\"wbx\"", ")", ".", "item", "(", ")", ")", "\n", "grad_norm_ma", "[", "iter", "+", "1", "]", "=", "grad_norm_ma", "[", "iter", "]", "+", "0.01", "*", "(", "grad_norms", "[", "-", "1", "]", "-", "grad_norm_ma", "[", "iter", "]", ")", "\n", "\n", "# compute loss on whole validation set", "\n", "if", "iter", "%", "self", ".", "stop_crit_win", "==", "0", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "x", ",", "_", "=", "test_data", ".", "sample", "(", "test_data", ".", "n_samples", ")", "\n", "loss_val", "=", "-", "torch", ".", "mean", "(", "self", ".", "model", ".", "compute_log_likelihood", "(", "x", ",", "\n", "weights", ",", "\n", "biases", ",", "\n", "extra_params", ")", ")", "\n", "nlls_val", ".", "append", "(", "loss_val", ".", "item", "(", ")", ")", "\n", "aug_lagrangians_val", ".", "append", "(", "[", "iter", ",", "loss_val", "+", "not_nlls", "[", "-", "1", "]", "]", ")", "\n", "\n", "# compute delta for lambda", "\n", "", "", "if", "iter", ">=", "2", "*", "self", ".", "stop_crit_win", "and", "iter", "%", "(", "2", "*", "self", ".", "stop_crit_win", ")", "==", "0", ":", "\n", "                ", "t0", "=", "aug_lagrangians_val", "[", "-", "3", "]", "[", "1", "]", "\n", "t_half", "=", "aug_lagrangians_val", "[", "-", "2", "]", "[", "1", "]", "\n", "t1", "=", "aug_lagrangians_val", "[", "-", "1", "]", "[", "1", "]", "\n", "\n", "# if the validation loss went up and down,", "\n", "# do not update lagrangian and penalty coefficients.", "\n", "if", "not", "(", "min", "(", "t0", ",", "t1", ")", "<", "t_half", "<", "max", "(", "t0", ",", "t1", ")", ")", ":", "\n", "                    ", "delta_lambda", "=", "-", "np", ".", "inf", "\n", "", "else", ":", "\n", "                    ", "delta_lambda", "=", "(", "t1", "-", "t0", ")", "/", "self", ".", "stop_crit_win", "\n", "", "", "else", ":", "\n", "                ", "delta_lambda", "=", "-", "np", ".", "inf", "# do not update lambda nor mu", "\n", "\n", "# Does the augmented lagrangian converged?", "\n", "", "if", "h", ">", "self", ".", "h_threshold", ":", "\n", "# if we have found a stationary point of the augmented loss", "\n", "                ", "if", "abs", "(", "delta_lambda", ")", "<", "self", ".", "omega_lambda", "or", "delta_lambda", ">", "0", ":", "\n", "                    ", "lamb", "+=", "mu", "*", "h", ".", "item", "(", ")", "\n", "\n", "# Did the constraint improve sufficiently?", "\n", "hs", ".", "append", "(", "h", ".", "item", "(", ")", ")", "\n", "if", "len", "(", "hs", ")", ">=", "2", ":", "\n", "                        ", "if", "hs", "[", "-", "1", "]", ">", "hs", "[", "-", "2", "]", "*", "self", ".", "omega_mu", ":", "\n", "                            ", "mu", "*=", "10", "\n", "\n", "# little hack to make sure the moving average is going down.", "\n", "", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "gap_in_not_nll", "=", "0.5", "*", "mu", "*", "h", ".", "item", "(", ")", "**", "2", "+", "lamb", "*", "h", ".", "item", "(", ")", "-", "not_nlls", "[", "-", "1", "]", "\n", "aug_lagrangian_ma", "[", "iter", "+", "1", "]", "+=", "gap_in_not_nll", "\n", "aug_lagrangians_val", "[", "-", "1", "]", "[", "1", "]", "+=", "gap_in_not_nll", "\n", "\n", "", "if", "self", ".", "optimizer", "==", "\"rmsprop\"", ":", "\n", "                        ", "optimizer", "=", "torch", ".", "optim", ".", "RMSprop", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "lr", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GraNDAG._to_dag": [[470, 503], ["mindspore.diag_indices", "mindspore.diag_indices", "numpy.unique", "enumerate", "base.compute_jacobian_avg().transpose", "gran_dag.GraNDAG.model.get_w_adj", "gran_dag.GraNDAG.asnumpy", "base.is_acyclic", "base.compute_jacobian_avg"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.base_model.BaseModel.get_w_adj", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.is_acyclic", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.base.dag_optimizer.compute_jacobian_avg"], ["                        ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "lr", ")", "\n", "", "", "", "else", ":", "\n", "# Final clamping of all edges == 0", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "to_keep", "=", "(", "w_adj", ">", "0", ")", ".", "type", "(", "torch", ".", "Tensor", ")", "\n", "self", ".", "model", ".", "adjacency", "*=", "to_keep", "\n", "\n", "", "return", "self", ".", "model", "\n", "\n", "", "", "", "def", "_to_dag", "(", "self", ",", "train_data", ")", ":", "\n", "        ", "\"\"\"\n        1- If some entries of A_\\phi == 0, also mask them\n        (This can happen with stochastic proximal gradient descent)\n        2- Remove edges (from weaker to stronger) until a DAG is obtained.\n\n        Parameters\n        ----------\n        train_data : NormalizationData\n            train samples\n        \"\"\"", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "if", "self", ".", "jac_thresh", ":", "\n", "            ", "A", "=", "compute_jacobian_avg", "(", "self", ".", "model", ",", "train_data", ",", "\n", "train_data", ".", "n_samples", ")", ".", "t", "(", ")", "\n", "", "else", ":", "\n", "            ", "A", "=", "self", ".", "model", ".", "get_w_adj", "(", ")", "\n", "", "A", "=", "A", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Find the smallest threshold that removes all cycle-inducing edges", "\n", "            ", "thresholds", "=", "np", ".", "unique", "(", "A", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.GraNDAG._create_dataset": [[504, 528], ["mindspore.dataset.GeneratorDataset", "mindspore.dataset.GeneratorDataset", "input_data.batch.batch.batch", "range", "list", "gran_dag.GraNDAG._create_dataset.get_data"], "methods", ["None"], ["epsilon", "=", "1e-8", "\n", "for", "step", ",", "t", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "                ", "to_keep", "=", "torch", ".", "Tensor", "(", "A", ">", "t", "+", "epsilon", ")", "\n", "new_adj", "=", "self", ".", "model", ".", "adjacency", "*", "to_keep", "\n", "if", "is_acyclic", "(", "new_adj", ")", ":", "\n", "                    ", "self", ".", "model", ".", "adjacency", ".", "copy_", "(", "new_adj", ")", "\n", "break", "\n", "\n", "", "", "", "return", "self", ".", "model", "\n", "\n", "\n", "", "", "def", "neighbors_selection", "(", "model", ",", "all_samples", ",", "num_neighbors", ",", "thresh", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.neighbors_selection": [[530, 555], ["model.adjacency.asnumpy", "gran_dag._pns", "mindspore.Tensor.copy", "mindspore.Tensor"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag._pns"], ["\n", "\n", "model_adj", "=", "model", ".", "adjacency", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "model_adj", "=", "_pns", "(", "model_adj", ",", "all_samples", ",", "num_neighbors", ",", "thresh", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "model", ".", "adjacency", ".", "copy_", "(", "torch", ".", "Tensor", "(", "model_adj", ")", ")", "\n", "\n", "", "return", "model", "\n", "\n", "\n", "", "def", "_pns", "(", "model_adj", ",", "all_samples", ",", "num_neighbors", ",", "thresh", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag._pns": [[557, 593], ["tqdm.tqdm", "range", "numpy.copy", "sklearn.ensemble.ExtraTreesRegressor", "sklearn.ensemble.ExtraTreesRegressor.fit", "sklearn.feature_selection.SelectFromModel", "sklearn.feature_selection.SelectFromModel.get_support"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit"], ["\n", "\n", "num_nodes", "=", "all_samples", ".", "shape", "[", "1", "]", "\n", "\n", "for", "node", "in", "tqdm", "(", "range", "(", "num_nodes", ")", ",", "desc", "=", "'Preliminary neighborhood selection'", ")", ":", "\n", "        ", "x_other", "=", "np", ".", "copy", "(", "all_samples", ")", "\n", "x_other", "[", ":", ",", "node", "]", "=", "0", "\n", "extraTree", "=", "ExtraTreesRegressor", "(", "n_estimators", "=", "500", ")", "\n", "extraTree", ".", "fit", "(", "x_other", ",", "all_samples", "[", ":", ",", "node", "]", ")", "\n", "selected_reg", "=", "SelectFromModel", "(", "extraTree", ",", "\n", "threshold", "=", "\"{}*mean\"", ".", "format", "(", "thresh", ")", ",", "\n", "prefit", "=", "True", ",", "\n", "max_features", "=", "num_neighbors", ")", "\n", "mask_selected", "=", "selected_reg", ".", "get_support", "(", "indices", "=", "False", ")", "\n", "model_adj", "[", ":", ",", "node", "]", "*=", "mask_selected", "\n", "\n", "", "return", "model_adj", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame.score_function.episodic_actor_loss": [[23, 37], ["utils.validation.Validation.to_device", "prediction_env.detach", "torch.mean", "torch.mean"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.validation.Validation.to_device"], ["def", "episodic_actor_loss", "(", "td_target", ",", "prediction_env", ",", "log_softmax", ",", "\n", "device", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Calculate actor loss for reward type is episodic\"\"\"", "\n", "\n", "td_target", ",", "prediction_env", ",", "log_softmax", "=", "Validation", ".", "to_device", "(", "td_target", ",", "\n", "prediction_env", ",", "\n", "log_softmax", ",", "\n", "device", "=", "device", ")", "\n", "prediction_env_no_grad", "=", "prediction_env", ".", "detach", "(", ")", "\n", "advantage_no_grad", "=", "td_target", "-", "prediction_env_no_grad", ".", "T", "\n", "step_loss", "=", "advantage_no_grad", "*", "log_softmax", "[", ":", "-", "1", "]", "\n", "actor_loss", "=", "-", "torch", ".", "mean", "(", "step_loss", ")", "\n", "\n", "return", "actor_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame.score_function.episodic_critic_loss": [[39, 50], ["utils.validation.Validation.to_device", "advantage.reshape().squeeze", "torch.mean", "torch.mean", "torch.square", "torch.square", "advantage.reshape"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.validation.Validation.to_device"], ["", "def", "episodic_critic_loss", "(", "td_target", ",", "prediction_env", ",", "\n", "device", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Calculate critic loss for reward type is 'episodic'\"\"\"", "\n", "\n", "td_target", ",", "prediction_env", "=", "Validation", ".", "to_device", "(", "td_target", ",", "prediction_env", ",", "\n", "device", "=", "device", ")", "\n", "advantage", "=", "td_target", "-", "prediction_env", ".", "T", "\n", "td_error", "=", "advantage", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", ")", "\n", "critic_loss", "=", "torch", ".", "mean", "(", "torch", ".", "square", "(", "td_error", ")", ")", "\n", "\n", "return", "critic_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame.score_function.dense_actor_loss": [[52, 64], ["utils.validation.Validation.to_device", "predict_reward.detach.detach", "torch.mean", "torch.mean"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.validation.Validation.to_device"], ["", "def", "dense_actor_loss", "(", "reward", ",", "avg_baseline", ",", "predict_reward", ",", "log_softmax", ",", "\n", "device", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Calculate actor loss for reward type is 'dense'\"\"\"", "\n", "\n", "reward", ",", "avg_baseline", ",", "predict_reward", ",", "log_softmax", "=", "Validation", ".", "to_device", "(", "\n", "reward", ",", "avg_baseline", ",", "predict_reward", ",", "log_softmax", ",", "device", "=", "device", "\n", ")", "\n", "predict_reward", "=", "predict_reward", ".", "detach", "(", ")", "# [Batch size, 1]", "\n", "reward_baseline", "=", "reward", "-", "avg_baseline", "-", "predict_reward", "\n", "actor_loss", "=", "-", "torch", ".", "mean", "(", "reward_baseline", "*", "log_softmax", ",", "0", ")", "\n", "\n", "return", "actor_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame.score_function.dense_critic_loss": [[66, 77], ["utils.validation.Validation.to_device", "reward.detach.detach", "torch.mse_loss"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.validation.Validation.to_device"], ["", "def", "dense_critic_loss", "(", "reward", ",", "avg_baseline", ",", "predict_reward", ",", "\n", "device", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Calculate actor loss for reward type is 'dense'\"\"\"", "\n", "\n", "reward", ",", "avg_baseline", ",", "predict_reward", "=", "Validation", ".", "to_device", "(", "\n", "reward", ",", "avg_baseline", ",", "predict_reward", ",", "device", "=", "device", "\n", ")", "\n", "reward", "=", "reward", ".", "detach", "(", ")", "\n", "critic_loss", "=", "F", ".", "mse_loss", "(", "reward", "-", "avg_baseline", ",", "predict_reward", ")", "\n", "\n", "return", "critic_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._actor.Actor.__init__": [[54, 70], ["_actor.Actor._instantiation"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._actor.Actor._instantiation"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "embed_dim", "=", "256", ",", "\n", "encoder_name", "=", "'transformer'", ",", "\n", "encoder_blocks", "=", "3", ",", "\n", "encoder_heads", "=", "8", ",", "\n", "decoder_name", "=", "'lstm'", ",", "\n", "device", "=", "None", ")", "->", "None", ":", "\n", "\n", "        ", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "encoder_blocks", "=", "encoder_blocks", "\n", "self", ".", "encoder_heads", "=", "encoder_heads", "\n", "self", ".", "encoder_name", "=", "encoder_name", "\n", "self", ".", "decoder_name", "=", "decoder_name", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "_instantiation", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._actor.Actor._instantiation": [[71, 103], ["_actor.Actor.encoder_name.lower", "models.encoders.TransformerEncoder", "_actor.Actor.decoder_name.lower", "models.decoders.LSTMDecoder", "_actor.Actor.encoder_name.lower", "models.encoders.LSTMEncoder", "_actor.Actor.decoder_name.lower", "models.decoders.MLPDecoder", "ValueError", "_actor.Actor.encoder_name.lower", "models.encoders.MLPEncoder", "ValueError"], "methods", ["None"], ["", "def", "_instantiation", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "encoder_name", ".", "lower", "(", ")", "==", "'transformer'", ":", "\n", "            ", "self", ".", "encoder", "=", "TransformerEncoder", "(", "input_dim", "=", "self", ".", "input_dim", ",", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "hidden_dim", "=", "self", ".", "ENCODER_HIDDEN_DIM", ",", "\n", "heads", "=", "self", ".", "encoder_heads", ",", "\n", "blocks", "=", "self", ".", "encoder_blocks", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "", "elif", "self", ".", "encoder_name", ".", "lower", "(", ")", "==", "'lstm'", ":", "\n", "            ", "self", ".", "encoder", "=", "LSTMEncoder", "(", "input_dim", "=", "self", ".", "input_dim", ",", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "", "elif", "self", ".", "encoder_name", ".", "lower", "(", ")", "==", "'mlp'", ":", "\n", "            ", "self", ".", "encoder", "=", "MLPEncoder", "(", "input_dim", "=", "self", ".", "input_dim", ",", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "hidden_dim", "=", "self", ".", "ENCODER_HIDDEN_DIM", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid encoder type, expected one of '", "\n", "f'[`transformer`, `lstm`, `mlp`], but got'", "\n", "f'``{self.encoder_name}``.'", ")", "\n", "\n", "", "if", "self", ".", "decoder_name", ".", "lower", "(", ")", "==", "'lstm'", ":", "\n", "            ", "self", ".", "decoder", "=", "LSTMDecoder", "(", "input_dim", "=", "self", ".", "embed_dim", ",", "\n", "hidden_dim", "=", "self", ".", "embed_dim", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "", "elif", "self", ".", "decoder_name", ".", "lower", "(", ")", "==", "'mlp'", ":", "\n", "            ", "self", ".", "decoder", "=", "MLPDecoder", "(", "input_dim", "=", "self", ".", "embed_dim", ",", "\n", "hidden_dim", "=", "self", ".", "embed_dim", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid decoder type, expected one of '", "\n", "f'[`lstm`, `mlp`], but got ``{self.decoder_name}``.'", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._actor.Actor.encode": [[105, 124], ["_actor.Actor.encoder"], "methods", ["None"], ["", "", "def", "encode", "(", "self", ",", "input", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        draw a batch of samples from X, encode them to S and calculate\n        the initial state \u02c6s0\n\n        Parameters\n        ----------\n        input: Tensor\n            a batch samples from X\n\n        Returns\n        -------\n        out: Tensor\n            encoder_output.shape=(batch_size, n_nodes, embed_dim)\n        \"\"\"", "\n", "\n", "self", ".", "encoder_output", "=", "self", ".", "encoder", "(", "input", ")", "\n", "\n", "return", "self", ".", "encoder_output", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._actor.Actor.decode": [[125, 151], ["_actor.Actor.decoder"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "input", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Maps the state space \u02c6S to the action space A.\n\n        Parameters\n        ----------\n        input: Tensor\n            (batch_size, n_nodes, input_dim)\n            a batch of samples from X, output of Encoder.\n\n        Returns\n        -------\n        out: tuple\n            (actions, mask_scores, s_list, h_list, c_list)\n\n            Notes::\n                actions: (batch_size, n_nodes)\n                mask_scores: (batch_size, n_nodes, n_nodes)\n                s_list: input for lstm cell, (batch_size, n_nodes, embed_dim)\n                h_list: h for lstm cell, (batch_size, n_nodes, embed_dim)\n                c_list: c for lstm cell, (batch_size, n_nodes, embed_dim)\n        \"\"\"", "\n", "\n", "outputs", "=", "self", ".", "decoder", "(", "input", ")", "\n", "\n", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.GPRMine.__init__": [[28, 35], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "optimize", "=", "False", ")", ":", "\n", "        ", "self", ".", "is_fit", "=", "False", "\n", "self", ".", "train_X", ",", "self", ".", "train_y", "=", "None", ",", "None", "\n", "self", ".", "params", "=", "{", "\"l\"", ":", "1", ",", "\"sigma_f\"", ":", "1", "}", "\n", "self", ".", "optimize", "=", "optimize", "\n", "self", ".", "alpha", "=", "1e-10", "\n", "self", ".", "m", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.GPRMine.fit": [[36, 49], ["numpy.asarray", "_reward.GPRMine.kernel", "numpy.fill_diagonal", "_reward.GPRMine.copy", "scipy.linalg.cholesky", "scipy.linalg.cho_solve", "numpy.diag_indices_from"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.GPRMine.kernel"], ["", "def", "fit", "(", "self", ",", "y", ",", "median", ",", "p_eu", ")", ":", "\n", "        ", "self", ".", "train_y", "=", "np", ".", "asarray", "(", "y", ")", "\n", "K", "=", "self", ".", "kernel", "(", "median", ",", "p_eu", ")", "\n", "np", ".", "fill_diagonal", "(", "K", ",", "1", ")", "\n", "self", ".", "K_trans", "=", "K", ".", "copy", "(", ")", "\n", "K", "[", "np", ".", "diag_indices_from", "(", "K", ")", "]", "+=", "self", ".", "alpha", "\n", "# self.KK = K.copy()", "\n", "\n", "self", ".", "L_", "=", "cholesky", "(", "K", ",", "lower", "=", "True", ")", "# Line 2", "\n", "# self.L_ changed, self._K_inv needs to be recomputed", "\n", "self", ".", "_K_inv", "=", "None", "\n", "self", ".", "alpha_", "=", "cho_solve", "(", "(", "self", ".", "L_", ",", "True", ")", ",", "self", ".", "train_y", ")", "# Line 3", "\n", "self", ".", "is_fit", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.GPRMine.predict": [[50, 61], ["K_trans.dot", "print"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "return_std", "=", "False", ")", ":", "\n", "        ", "if", "not", "self", ".", "is_fit", ":", "\n", "            ", "print", "(", "\"GPR Model not fit yet.\"", ")", "\n", "return", "\n", "\n", "", "K_trans", "=", "self", ".", "K_trans", "\n", "y_mean", "=", "K_trans", ".", "dot", "(", "self", ".", "alpha_", ")", "# Line 4 (y_mean = f_star)", "\n", "if", "return_std", "==", "False", ":", "\n", "            ", "return", "y_mean", "\n", "", "else", ":", "\n", "            ", "raise", "(", "'To cal std'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.GPRMine.kernel": [[62, 67], ["numpy.exp", "scipy.spatial.distance.squareform"], "methods", ["None"], ["", "", "def", "kernel", "(", "self", ",", "median", ",", "p_eu", ")", ":", "\n", "        ", "p_eu_nor", "=", "p_eu", "/", "median", "\n", "K", "=", "np", ".", "exp", "(", "-", "0.5", "*", "p_eu_nor", ")", "\n", "K", "=", "squareform", "(", "K", ")", "\n", "return", "K", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.__init__": [[80, 123], ["utils.validation.Validation.validate_value", "utils.validation.Validation.validate_value", "sklearn.preprocessing.PolynomialFeatures", "numpy.log", "range", "sklearn.gaussian_process.kernels.WhiteKernel", "numpy.ones", "numpy.hstack", "numpy.hstack.T.dot", "sklearn.gaussian_process.kernels.RBF", "_reward.GPRMine", "range", "numpy.array", "range", "dist_matrix.append"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.validation.Validation.validate_value", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.validation.Validation.validate_value"], ["def", "__init__", "(", "self", ",", "input_data", ",", "reward_mode", "=", "'episodic'", ",", "\n", "score_type", "=", "'BIC'", ",", "regression_type", "=", "'LR'", ",", "alpha", "=", "1.0", ")", ":", "\n", "\n", "\n", "        ", "self", ".", "input_data", "=", "input_data", "\n", "self", ".", "reward_type", "=", "reward_mode", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "n_samples", "=", "input_data", ".", "shape", "[", "0", "]", "\n", "self", ".", "seq_length", "=", "input_data", ".", "shape", "[", "1", "]", "\n", "self", ".", "d", "=", "{", "}", "# store results", "\n", "self", ".", "d_RSS", "=", "[", "{", "}", "for", "_", "in", "range", "(", "self", ".", "seq_length", ")", "]", "# store RSS for reuse", "\n", "self", ".", "bic_penalty", "=", "np", ".", "log", "(", "input_data", ".", "shape", "[", "0", "]", ")", "/", "input_data", ".", "shape", "[", "0", "]", "\n", "\n", "Validation", ".", "validate_value", "(", "score_type", ",", "\n", "(", "'BIC'", ",", "'BIC_different_var'", ")", ")", "\n", "Validation", ".", "validate_value", "(", "regression_type", ",", "\n", "(", "'LR'", ",", "'QR'", ",", "'GPR'", ",", "'GPR_learnable'", ")", ")", "\n", "\n", "self", ".", "score_type", "=", "score_type", "\n", "self", ".", "regression_type", "=", "regression_type", "\n", "\n", "self", ".", "poly", "=", "PolynomialFeatures", "(", ")", "\n", "\n", "if", "self", ".", "regression_type", "==", "'GPR_learnable'", ":", "\n", "            ", "self", ".", "kernel_learnable", "=", "1.0", "*", "RBF", "(", "length_scale", "=", "1.0", ",", "\n", "length_scale_bounds", "=", "(", "1e-2", ",", "1e2", ")", ")", "+", "WhiteKernel", "(", "noise_level", "=", "1.0", ",", "\n", "noise_level_bounds", "=", "(", "\n", "1e-10", ",", "1e+1", ")", ")", "\n", "", "elif", "regression_type", "==", "'LR'", ":", "\n", "            ", "self", ".", "ones", "=", "np", ".", "ones", "(", "(", "input_data", ".", "shape", "[", "0", "]", ",", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "X", "=", "np", ".", "hstack", "(", "(", "self", ".", "input_data", ",", "self", ".", "ones", ")", ")", "\n", "self", ".", "X", "=", "X", "\n", "self", ".", "XtX", "=", "X", ".", "T", ".", "dot", "(", "X", ")", "\n", "", "elif", "regression_type", "==", "'GPR'", ":", "\n", "            ", "self", ".", "gpr", "=", "GPRMine", "(", ")", "\n", "m", "=", "input_data", ".", "shape", "[", "0", "]", "\n", "self", ".", "gpr", ".", "m", "=", "m", "\n", "dist_matrix", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "m", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "m", ")", ":", "\n", "                    ", "dist_matrix", ".", "append", "(", "(", "input_data", "[", "i", "]", "-", "input_data", "[", "j", "]", ")", "**", "2", ")", "\n", "", "", "self", ".", "dist_matrix", "=", "np", ".", "array", "(", "dist_matrix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.cal_rewards": [[124, 162], ["enumerate", "numpy.stack", "zip", "float", "reward_list.append", "numpy.stack.append", "numpy.stack", "_reward.Reward.calculate_reward_single_graph", "rewards_batches.append", "_reward.Reward.calculate_reward_single_graph", "rewards_batches.append", "numpy.transpose", "td_target.append", "ValueError"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_reward_single_graph", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_reward_single_graph"], ["", "", "def", "cal_rewards", "(", "self", ",", "graphs", ",", "positions", "=", "None", ",", "ture_flag", "=", "False", ",", "gamma", "=", "0.98", ")", ":", "\n", "        ", "rewards_batches", "=", "[", "]", "\n", "if", "not", "ture_flag", ":", "\n", "            ", "for", "graphi", ",", "position", "in", "zip", "(", "graphs", ",", "positions", ")", ":", "\n", "                ", "reward_", "=", "self", ".", "calculate_reward_single_graph", "(", "graphi", ",", "\n", "position", "=", "position", ",", "\n", "ture_flag", "=", "ture_flag", ")", "\n", "rewards_batches", ".", "append", "(", "reward_", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "graphi", "in", "graphs", ":", "\n", "                ", "reward_", "=", "self", ".", "calculate_reward_single_graph", "(", "graphi", ",", "\n", "ture_flag", "=", "ture_flag", ")", "\n", "rewards_batches", ".", "append", "(", "reward_", ")", "\n", "\n", "", "", "max_reward_batch", "=", "-", "float", "(", "'inf'", ")", "\n", "reward_list", ",", "normal_batch_reward", "=", "[", "]", ",", "[", "]", "\n", "for", "nu", ",", "(", "reward_", ",", "reward_list_", ")", "in", "enumerate", "(", "rewards_batches", ")", ":", "\n", "            ", "reward_list", ".", "append", "(", "reward_list_", ")", "\n", "normalized_reward", "=", "-", "reward_", "\n", "normal_batch_reward", ".", "append", "(", "normalized_reward", ")", "\n", "if", "normalized_reward", ">", "max_reward_batch", ":", "\n", "                ", "max_reward_batch", "=", "normalized_reward", "\n", "", "", "normal_batch_reward", "=", "np", ".", "stack", "(", "normal_batch_reward", ")", "\n", "reward_list", "=", "-", "np", ".", "stack", "(", "reward_list", ")", "\n", "\n", "if", "self", ".", "reward_type", "==", "'episodic'", ":", "\n", "            ", "G", "=", "0", "\n", "td_target", "=", "[", "]", "\n", "for", "r", "in", "np", ".", "transpose", "(", "reward_list", ",", "[", "1", ",", "0", "]", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "                ", "G", "=", "r", "+", "gamma", "*", "G", "\n", "td_target", ".", "append", "(", "G", ")", "\n", "", "", "elif", "self", ".", "reward_type", "==", "'dense'", ":", "\n", "            ", "td_target", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"reward_type must be one of ['episodic', \"", "\n", "f\"'dense'], but got ``{self.reward_type}``.\"", ")", "\n", "\n", "", "return", "reward_list", ",", "normal_batch_reward", ",", "max_reward_batch", ",", "td_target", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_yerr": [[163, 174], ["_reward.Reward.calculate_LR", "_reward.Reward.calculate_QR", "_reward.Reward.calculate_GPR", "_reward.Reward.calculate_GPR_learnable", "TypeError"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_LR", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_QR", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_GPR", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_GPR_learnable"], ["", "def", "calculate_yerr", "(", "self", ",", "X_train", ",", "y_train", ",", "XtX", "=", "None", ",", "Xty", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "regression_type", "==", "'LR'", ":", "\n", "            ", "return", "self", ".", "calculate_LR", "(", "X_train", ",", "y_train", ",", "XtX", ",", "Xty", ")", "\n", "", "elif", "self", ".", "regression_type", "==", "'QR'", ":", "\n", "            ", "return", "self", ".", "calculate_QR", "(", "X_train", ",", "y_train", ")", "\n", "", "elif", "self", ".", "regression_type", "==", "'GPR'", ":", "\n", "            ", "return", "self", ".", "calculate_GPR", "(", "y_train", ",", "XtX", ")", "\n", "", "elif", "self", ".", "regression_type", "==", "'GPR_learnable'", ":", "\n", "            ", "return", "self", ".", "calculate_GPR_learnable", "(", "X_train", ",", "y_train", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "f\"The parameter `regression_type` must be one of \"", "\n", "f\"[`LR`, `QR`, `GPR`, `GPR_learnable`], \"", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_LR": [[177, 184], ["numpy.linalg.solve", "X_train.dot"], "methods", ["None"], ["", "", "def", "calculate_LR", "(", "self", ",", "X_train", ",", "y_train", ",", "XtX", ",", "Xty", ")", ":", "\n", "        ", "\"\"\"Linear regression\"\"\"", "\n", "\n", "theta", "=", "np", ".", "linalg", ".", "solve", "(", "XtX", ",", "Xty", ")", "\n", "y_pre", "=", "X_train", ".", "dot", "(", "theta", ")", "\n", "y_err", "=", "y_pre", "-", "y_train", "\n", "return", "y_err", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_QR": [[185, 193], ["numpy.hstack", "numpy.hstack.T.dot", "numpy.hstack.T.dot", "_reward.Reward.calculate_LR", "_reward.Reward.poly.fit_transform"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_LR"], ["", "def", "calculate_QR", "(", "self", ",", "X_train", ",", "y_train", ")", ":", "\n", "        ", "\"\"\"quadratic regression\"\"\"", "\n", "\n", "X_train", "=", "self", ".", "poly", ".", "fit_transform", "(", "X_train", ")", "[", ":", ",", "1", ":", "]", "\n", "X", "=", "np", ".", "hstack", "(", "(", "X_train", ",", "self", ".", "ones", ")", ")", "\n", "XtX", "=", "X", ".", "T", ".", "dot", "(", "X", ")", "\n", "Xty", "=", "X", ".", "T", ".", "dot", "(", "y_train", ")", "\n", "return", "self", ".", "calculate_LR", "(", "X_train", ",", "y_train", ",", "XtX", ",", "Xty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_GPR": [[194, 200], ["numpy.median", "_reward.Reward.gpr.fit", "_reward.Reward.gpr.predict"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.GPRMine.predict"], ["", "def", "calculate_GPR", "(", "self", ",", "y_train", ",", "XtX", ")", ":", "\n", "        ", "p_eu", "=", "XtX", "# our K1 don't sqrt", "\n", "med_w", "=", "np", ".", "median", "(", "p_eu", ")", "\n", "self", ".", "gpr", ".", "fit", "(", "y_train", ",", "med_w", ",", "p_eu", ")", "\n", "pre", "=", "self", ".", "gpr", ".", "predict", "(", ")", "\n", "return", "y_train", "-", "pre", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_GPR_learnable": [[201, 204], ["sklearn.gaussian_process.GaussianProcessRegressor.fit", "y_train.reshape", "sklearn.gaussian_process.GaussianProcessRegressor.fit.predict().reshape", "sklearn.gaussian_process.GaussianProcessRegressor", "sklearn.gaussian_process.GaussianProcessRegressor.fit.predict"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.GPRMine.predict"], ["", "def", "calculate_GPR_learnable", "(", "self", ",", "X_train", ",", "y_train", ")", ":", "\n", "        ", "gpr", "=", "GPR", "(", "kernel", "=", "self", ".", "kernel_learnable", ",", "alpha", "=", "0.0", ")", ".", "fit", "(", "X_train", ",", "y_train", ")", "\n", "return", "y_train", ".", "reshape", "(", "-", "1", ",", "1", ")", "-", "gpr", ".", "predict", "(", "X_train", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_reward_single_graph": [[205, 241], ["list", "tuple", "range", "numpy.array", "numpy.int32", "_reward.Reward.cal_RSSi", "numpy.array.append", "numpy.log", "numpy.array", "numpy.sum", "TypeError", "numpy.array", "numpy.log", "numpy.sum", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.cal_RSSi"], ["", "def", "calculate_reward_single_graph", "(", "self", ",", "graph_batch", ",", "position", "=", "None", ",", "\n", "ture_flag", "=", "False", ")", ":", "\n", "\n", "        ", "graph_to_int2", "=", "list", "(", "np", ".", "int32", "(", "position", ")", ")", "\n", "graph_batch_to_tuple", "=", "tuple", "(", "graph_to_int2", ")", "\n", "if", "not", "ture_flag", ":", "\n", "            ", "if", "graph_batch_to_tuple", "in", "self", ".", "d", ":", "\n", "                ", "graph_score", "=", "self", ".", "d", "[", "graph_batch_to_tuple", "]", "\n", "reward", "=", "graph_score", "[", "0", "]", "\n", "return", "reward", ",", "np", ".", "array", "(", "graph_score", "[", "1", "]", ")", "\n", "\n", "", "", "RSS_ls", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "seq_length", ")", ":", "\n", "            ", "RSSi", "=", "self", ".", "cal_RSSi", "(", "i", ",", "graph_batch", ")", "\n", "RSS_ls", ".", "append", "(", "RSSi", ")", "\n", "\n", "", "RSS_ls", "=", "np", ".", "array", "(", "RSS_ls", ")", "\n", "if", "self", ".", "regression_type", "==", "'GPR'", "or", "self", ".", "regression_type", "==", "'GPR_learnable'", ":", "\n", "            ", "reward_list", "=", "RSS_ls", "[", "position", "]", "/", "self", ".", "n_samples", "\n", "", "else", ":", "\n", "            ", "reward_list", "=", "RSS_ls", "[", "position", "]", "/", "self", ".", "n_samples", "\n", "\n", "", "if", "self", ".", "score_type", "==", "'BIC'", ":", "\n", "            ", "BIC", "=", "np", ".", "log", "(", "np", ".", "sum", "(", "RSS_ls", ")", "/", "self", ".", "n_samples", "+", "1e-8", ")", "\n", "# + np.sum(graph_batch)*self.bic_penalty/self.seq_length", "\n", "", "elif", "self", ".", "score_type", "==", "'BIC_different_var'", ":", "\n", "            ", "BIC", "=", "np", ".", "sum", "(", "np", ".", "log", "(", "np", ".", "array", "(", "RSS_ls", ")", "/", "self", ".", "n_samples", "+", "1e-8", ")", ")", "\n", "# + np.sum(graph_batch)*self.bic_penalt", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "f\"The parameter `score_type` must be one of \"", "\n", "f\"[`BIC`,`BIC_different_var`], \"", "\n", "f\"but got ``{self.score_type}``.\"", ")", "\n", "", "if", "not", "ture_flag", ":", "\n", "            ", "self", ".", "d", "[", "graph_batch_to_tuple", "]", "=", "(", "BIC", ",", "reward_list", ")", "\n", "\n", "", "return", "BIC", ",", "np", ".", "array", "(", "reward_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.cal_RSSi": [[242, 287], ["str", "numpy.sum", "numpy.sum", "numpy.square", "numpy.mean", "numpy.append", "_reward.Reward.calculate_yerr", "scipy.spatial.distance.pdist", "numpy.asarray", "numpy.exp", "scipy.spatial.distance.squareform", "numpy.fill_diagonal", "scipy.spatial.distance.squareform.copy", "scipy.linalg.cholesky", "scipy.linalg.cho_solve", "scipy.spatial.distance.squareform.copy.dot", "numpy.median", "_reward.Reward.calculate_yerr", "TypeError", "numpy.diag_indices_from"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_yerr", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.calculate_yerr"], ["", "def", "cal_RSSi", "(", "self", ",", "i", ",", "graph_batch", ")", ":", "\n", "        ", "col", "=", "graph_batch", "[", "i", "]", "\n", "str_col", "=", "str", "(", "col", ")", "\n", "if", "str_col", "in", "self", ".", "d_RSS", "[", "i", "]", ":", "\n", "            ", "RSSi", "=", "self", ".", "d_RSS", "[", "i", "]", "[", "str_col", "]", "\n", "return", "RSSi", "\n", "", "if", "np", ".", "sum", "(", "col", ")", "<", "0.1", ":", "\n", "            ", "y_err", "=", "self", ".", "input_data", "[", ":", ",", "i", "]", "\n", "y_err", "=", "y_err", "-", "np", ".", "mean", "(", "y_err", ")", "\n", "", "else", ":", "\n", "            ", "cols_TrueFalse", "=", "col", ">", "0.5", "\n", "if", "self", ".", "regression_type", "==", "'LR'", ":", "\n", "                ", "cols_TrueFalse", "=", "np", ".", "append", "(", "cols_TrueFalse", ",", "True", ")", "\n", "X_train", "=", "self", ".", "X", "[", ":", ",", "cols_TrueFalse", "]", "\n", "y_train", "=", "self", ".", "X", "[", ":", ",", "i", "]", "\n", "XtX", "=", "self", ".", "XtX", "[", ":", ",", "cols_TrueFalse", "]", "[", "cols_TrueFalse", ",", ":", "]", "\n", "Xty", "=", "self", ".", "XtX", "[", ":", ",", "i", "]", "[", "cols_TrueFalse", "]", "\n", "y_err", "=", "self", ".", "calculate_yerr", "(", "X_train", ",", "y_train", ",", "XtX", ",", "Xty", ")", "\n", "", "elif", "self", ".", "regression_type", "==", "'GPR'", ":", "\n", "                ", "X_train", "=", "self", ".", "input_data", "[", ":", ",", "cols_TrueFalse", "]", "\n", "y_train", "=", "self", ".", "input_data", "[", ":", ",", "i", "]", "\n", "p_eu", "=", "pdist", "(", "X_train", ",", "'sqeuclidean'", ")", "\n", "train_y", "=", "np", ".", "asarray", "(", "y_train", ")", "\n", "p_eu_nor", "=", "p_eu", "/", "np", ".", "median", "(", "p_eu", ")", "\n", "K", "=", "np", ".", "exp", "(", "-", "0.5", "*", "p_eu_nor", ")", "\n", "K", "=", "squareform", "(", "K", ")", "\n", "np", ".", "fill_diagonal", "(", "K", ",", "1", ")", "\n", "K_trans", "=", "K", ".", "copy", "(", ")", "\n", "K", "[", "np", ".", "diag_indices_from", "(", "K", ")", "]", "+=", "self", ".", "alpha", "# 1e-10", "\n", "L_", "=", "cholesky", "(", "K", ",", "lower", "=", "True", ")", "# Line 2", "\n", "alpha_", "=", "cho_solve", "(", "(", "L_", ",", "True", ")", ",", "train_y", ")", "# Line 3", "\n", "y_mean", "=", "K_trans", ".", "dot", "(", "alpha_", ")", "# Line 4 (y_mean = f_star)", "\n", "y_err", "=", "y_train", "-", "y_mean", "\n", "", "elif", "self", ".", "regression_type", "==", "'GPR_learnable'", ":", "\n", "                ", "X_train", "=", "self", ".", "input_data", "[", ":", ",", "cols_TrueFalse", "]", "\n", "y_train", "=", "self", ".", "input_data", "[", ":", ",", "i", "]", "\n", "y_err", "=", "self", ".", "calculate_yerr", "(", "X_train", ",", "y_train", ",", "X_train", ",", "y_train", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "f\"The parameter `regression_type` must be one of \"", "\n", "f\"[`LR`, `GPR`, `GPR_learnable`], \"", "\n", "f\"but got ``{self.regression_type}``.\"", ")", "\n", "", "", "RSSi", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "y_err", ")", ")", "\n", "self", ".", "d_RSS", "[", "i", "]", "[", "str_col", "]", "=", "RSSi", "\n", "\n", "return", "RSSi", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.penalized_score": [[288, 291], ["float"], "methods", ["None"], ["", "def", "penalized_score", "(", "self", ",", "score_cyc", ",", "lambda1", "=", "1", ",", "lambda2", "=", "1", ")", ":", "\n", "        ", "score", ",", "cyc", "=", "score_cyc", "\n", "return", "score", "+", "lambda1", "*", "float", "(", "cyc", ">", "1e-5", ")", "+", "lambda2", "*", "cyc", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.update_scores": [[292, 297], ["ls.append"], "methods", ["None"], ["", "def", "update_scores", "(", "self", ",", "score_cycs", ")", ":", "\n", "        ", "ls", "=", "[", "]", "\n", "for", "score_cyc", "in", "score_cycs", ":", "\n", "            ", "ls", ".", "append", "(", "score_cyc", ")", "\n", "", "return", "ls", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.Reward.update_all_scores": [[298, 304], ["list", "sorted", "_reward.Reward.d.items", "ls.append"], "methods", ["None"], ["", "def", "update_all_scores", "(", "self", ")", ":", "\n", "        ", "score_cycs", "=", "list", "(", "self", ".", "d", ".", "items", "(", ")", ")", "\n", "ls", "=", "[", "]", "\n", "for", "graph_int", ",", "score_l", "in", "score_cycs", ":", "\n", "            ", "ls", ".", "append", "(", "(", "graph_int", ",", "(", "score_l", "[", "0", "]", ",", "score_l", "[", "-", "1", "]", ")", ")", ")", "\n", "", "return", "sorted", "(", "ls", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._critic.EpisodicCritic.__init__": [[24, 64], ["torch.ReLU", "torch.ReLU", "torch.Module.__init__", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.Parameter", "torch.Parameter", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.Parameter", "torch.Parameter", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.Parameter", "torch.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.Parameter", "torch.Parameter", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.init.xavier_uniform_.requires_grad_", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.init.xavier_uniform_.requires_grad_", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.init.xavier_uniform_.requires_grad_", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "neurons", "=", "(", "512", ",", "256", ",", "1", ")", ",", "\n", "activation", "=", "nn", ".", "ReLU", "(", ")", ",", "device", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "EpisodicCritic", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "neurons", "=", "neurons", "\n", "self", ".", "output_dim", "=", "neurons", "[", "-", "1", "]", "\n", "self", ".", "hidden_units", "=", "neurons", "[", ":", "-", "1", "]", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# trainable parameters", "\n", "env_w0", "=", "nn", ".", "init", ".", "xavier_uniform_", "(", "\n", "torch", ".", "empty", "(", "self", ".", "input_dim", ",", "self", ".", "neurons", "[", "0", "]", ",", "device", "=", "self", ".", "device", ")", "\n", ")", "\n", "self", ".", "env_w0", "=", "nn", ".", "Parameter", "(", "env_w0", ".", "requires_grad_", "(", "True", ")", ")", "\n", "\n", "env_w1", "=", "nn", ".", "init", ".", "xavier_uniform_", "(", "\n", "torch", ".", "empty", "(", "self", ".", "neurons", "[", "0", "]", ",", "self", ".", "neurons", "[", "1", "]", ",", "device", "=", "self", ".", "device", ")", "\n", ")", "\n", "self", ".", "env_w1", "=", "nn", ".", "Parameter", "(", "env_w1", ".", "requires_grad_", "(", "True", ")", ")", "\n", "\n", "env_w2", "=", "nn", ".", "init", ".", "xavier_uniform_", "(", "\n", "torch", ".", "empty", "(", "self", ".", "neurons", "[", "1", "]", ",", "self", ".", "neurons", "[", "-", "1", "]", ",", "device", "=", "self", ".", "device", ")", "\n", ")", "\n", "self", ".", "env_w2", "=", "nn", ".", "Parameter", "(", "env_w2", ".", "requires_grad_", "(", "True", ")", ")", "\n", "\n", "env_b1", "=", "torch", ".", "tensor", "(", "[", "0.", "]", ",", "requires_grad", "=", "True", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "env_b1", "=", "nn", ".", "Parameter", "(", "env_b1", ")", "\n", "\n", "# Un-trainable parameters", "\n", "self", ".", "tgt_w0", "=", "nn", ".", "init", ".", "xavier_uniform_", "(", "\n", "torch", ".", "empty", "(", "self", ".", "input_dim", ",", "self", ".", "neurons", "[", "0", "]", ",", "device", "=", "self", ".", "device", ")", "\n", ")", "\n", "self", ".", "tgt_w1", "=", "nn", ".", "init", ".", "xavier_uniform_", "(", "\n", "torch", ".", "empty", "(", "self", ".", "neurons", "[", "0", "]", ",", "self", ".", "neurons", "[", "1", "]", ",", "device", "=", "self", ".", "device", ")", "\n", ")", "\n", "self", ".", "tgt_w2", "=", "nn", ".", "init", ".", "xavier_uniform_", "(", "\n", "torch", ".", "empty", "(", "self", ".", "neurons", "[", "1", "]", ",", "self", ".", "neurons", "[", "-", "1", "]", ",", "device", "=", "self", ".", "device", ")", "\n", ")", "\n", "self", ".", "tgt_b1", "=", "torch", ".", "tensor", "(", "[", "0.", "]", ",", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._critic.EpisodicCritic.predict_env": [[65, 78], ["stats_x.detach.detach.detach", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "_critic.EpisodicCritic.activation", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "_critic.EpisodicCritic.activation", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "_critic.EpisodicCritic.activation"], "methods", ["None"], ["", "def", "predict_env", "(", "self", ",", "stats_x", ")", "->", "None", ":", "\n", "        ", "\"\"\"predict environment reward\"\"\"", "\n", "\n", "stats_x", "=", "stats_x", ".", "detach", "(", ")", "\n", "h0", "=", "torch", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "stats_x", ",", "self", ".", "env_w0", ")", "\n", "h0", "=", "self", ".", "activation", "(", "h0", ")", "\n", "h1", "=", "torch", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "h0", ",", "self", ".", "env_w1", ")", "\n", "h1", "=", "self", ".", "activation", "(", "h1", ")", "\n", "h2", "=", "torch", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "h1", ",", "self", ".", "env_w2", ")", "\n", "h2", "=", "self", ".", "activation", "(", "h2", ")", "\n", "\n", "# [batch_size, seq_length - 1]", "\n", "self", ".", "prediction_env", "=", "(", "h2", "+", "self", ".", "env_b1", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._critic.EpisodicCritic.predict_tgt": [[79, 91], ["stats_y.detach.detach.detach", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "_critic.EpisodicCritic.activation", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "_critic.EpisodicCritic.activation", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "_critic.EpisodicCritic.activation"], "methods", ["None"], ["", "def", "predict_tgt", "(", "self", ",", "stats_y", ")", "->", "None", ":", "\n", "        ", "\"\"\"predict target reward\"\"\"", "\n", "\n", "stats_y", "=", "stats_y", ".", "detach", "(", ")", "\n", "h0", "=", "torch", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "stats_y", ",", "self", ".", "tgt_w0", ")", "\n", "h0", "=", "self", ".", "activation", "(", "h0", ")", "\n", "h1", "=", "torch", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "h0", ",", "self", ".", "tgt_w1", ")", "\n", "h1", "=", "self", ".", "activation", "(", "h1", ")", "\n", "h2", "=", "torch", ".", "einsum", "(", "'ijk, kl->ijl'", ",", "h1", ",", "self", ".", "tgt_w2", ")", "\n", "h2", "=", "self", ".", "activation", "(", "h2", ")", "\n", "\n", "self", ".", "prediction_tgt", "=", "(", "h2", "+", "self", ".", "tgt_b1", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._critic.EpisodicCritic.soft_replacement": [[92, 98], ["_critic.EpisodicCritic.env_w0.detach", "_critic.EpisodicCritic.env_w1.detach", "_critic.EpisodicCritic.env_w2.detach", "_critic.EpisodicCritic.env_b1.detach"], "methods", ["None"], ["", "def", "soft_replacement", "(", "self", ")", "->", "None", ":", "\n", "# soft_replacement", "\n", "        ", "self", ".", "tgt_w0", "=", "0.95", "*", "self", ".", "tgt_w0", "+", "0.05", "*", "self", ".", "env_w0", ".", "detach", "(", ")", "\n", "self", ".", "tgt_w1", "=", "0.95", "*", "self", ".", "tgt_w1", "+", "0.05", "*", "self", ".", "env_w1", ".", "detach", "(", ")", "\n", "self", ".", "tgt_w2", "=", "0.95", "*", "self", ".", "tgt_w2", "+", "0.05", "*", "self", ".", "env_w2", ".", "detach", "(", ")", "\n", "self", ".", "tgt_b1", "=", "0.95", "*", "self", ".", "tgt_b1", "+", "0.05", "*", "self", ".", "env_b1", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._critic.DenseCritic.__init__": [[106, 121], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.rand().requires_grad_", "torch.rand().requires_grad_", "torch.rand().requires_grad_", "torch.rand().requires_grad_", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ParameterList", "torch.ParameterList", "torch.Linear", "torch.Linear", "torch.ReLU().to", "torch.ReLU().to", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "device", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "DenseCritic", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "\n", "self", ".", "h0", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "in_features", "=", "input_dim", ",", "out_features", "=", "output_dim", ",", "\n", "device", "=", "device", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ".", "to", "(", "device", "=", "device", ")", "\n", ")", "\n", "self", ".", "w1", "=", "torch", ".", "rand", "(", "self", ".", "output_dim", ",", "1", ",", "\n", "device", "=", "device", ")", ".", "requires_grad_", "(", "True", ")", "\n", "self", ".", "b1", "=", "torch", ".", "tensor", "(", "[", "0.", "]", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "self", ".", "params", "=", "nn", ".", "ParameterList", "(", "[", "nn", ".", "Parameter", "(", "self", ".", "w1", ")", ",", "\n", "nn", ".", "Parameter", "(", "self", ".", "b1", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._critic.DenseCritic.predict_reward": [[122, 130], ["torch.mean().detach", "torch.mean().detach", "torch.mean().detach", "torch.mean().detach", "_critic.DenseCritic.h0", "prediction.squeeze", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["", "def", "predict_reward", "(", "self", ",", "encoder_output", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Predict reward for `dense reward` type\"\"\"", "\n", "\n", "frame", "=", "torch", ".", "mean", "(", "encoder_output", ",", "1", ")", ".", "detach", "(", ")", "\n", "h0", "=", "self", ".", "h0", "(", "frame", ")", "\n", "prediction", "=", "torch", ".", "matmul", "(", "h0", ",", "self", ".", "w1", ")", "+", "self", ".", "b1", "\n", "\n", "return", "prediction", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM.__init__": [[72, 89], ["castle.common.BaseLearner.__init__", "isinstance", "networkx.from_numpy_matrix"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "topology_matrix", ",", "delta", "=", "0.1", ",", "epsilon", "=", "1", ",", "\n", "max_hop", "=", "0", ",", "penalty", "=", "'BIC'", ",", "max_iter", "=", "20", ")", ":", "\n", "        ", "BaseLearner", ".", "__init__", "(", "self", ")", "\n", "assert", "isinstance", "(", "topology_matrix", ",", "np", ".", "ndarray", ")", ",", "'topology_matrix should be np.matrix object'", "\n", "assert", "topology_matrix", ".", "ndim", "==", "2", ",", "'topology_matrix should be two dimension'", "\n", "assert", "topology_matrix", ".", "shape", "[", "0", "]", "==", "topology_matrix", ".", "shape", "[", "1", "]", ",", "'The topology_matrix should be square.'", "\n", "self", ".", "_topo", "=", "nx", ".", "from_numpy_matrix", "(", "topology_matrix", ",", "\n", "create_using", "=", "nx", ".", "Graph", ")", "\n", "# initialize instance variables", "\n", "self", ".", "_penalty", "=", "penalty", "\n", "self", ".", "_delta", "=", "delta", "\n", "self", ".", "_max_hop", "=", "max_hop", "\n", "self", ".", "_epsilon", "=", "epsilon", "\n", "self", ".", "_max_iter", "=", "max_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM.learn": [[90, 127], ["ttpm.TTPM._start_init", "ttpm.TTPM._hill_climb", "castle.common.Tensor", "isinstance", "TypeError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._start_init", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._hill_climb"], ["", "def", "learn", "(", "self", ",", "tensor", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Set up and run the TTPM algorithm.\n\n        Parameters\n        ----------\n        tensor:  pandas.DataFrame\n            (V 1.0.0, we'll eliminate this constraint in the next version)\n            The tensor is supposed to contain three cols:\n                ['event', 'timestamp', 'node']\n\n            Description of the three columns:\n                event: event name (type).\n                timestamp: occurrence timestamp of event, i.e., '1615962101.0'.\n                node: topological node where the event happened.\n        \"\"\"", "\n", "\n", "# data type judgment", "\n", "if", "not", "isinstance", "(", "tensor", ",", "pd", ".", "DataFrame", ")", ":", "\n", "            ", "raise", "TypeError", "(", "'The tensor type is not correct,'", "\n", "'only receive pd.DataFrame type currently.'", ")", "\n", "\n", "", "cols_list", "=", "[", "'event'", ",", "'timestamp'", ",", "'node'", "]", "\n", "for", "col", "in", "cols_list", ":", "\n", "            ", "if", "col", "not", "in", "tensor", ".", "columns", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"The data tensor should contain column with name {}\"", ".", "format", "(", "\n", "col", ")", ")", "\n", "\n", "# initialize needed values", "\n", "", "", "self", ".", "_start_init", "(", "tensor", ")", "\n", "\n", "# Generate causal matrix (DAG)", "\n", "_", ",", "raw_causal_matrix", "=", "self", ".", "_hill_climb", "(", ")", "\n", "self", ".", "_causal_matrix", "=", "Tensor", "(", "raw_causal_matrix", ",", "\n", "index", "=", "self", ".", "_matrix_names", ",", "\n", "columns", "=", "self", ".", "_matrix_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._start_init": [[128, 171], ["tensor.sort_values.sort_values.dropna", "tensor[].astype", "tensor.sort_values.sort_values.groupby().apply().reset_index", "tensor.sort_values.sort_values.reindex", "tensor.sort_values.sort_values.sort_values", "numpy.array", "ttpm.TTPM._event_names.sort", "len", "list", "ttpm.TTPM._map_event_to_index", "ttpm.TTPM._topo.subgraph", "ttpm.TTPM.tensor.groupby", "numpy.zeros", "tensor[].max", "tensor[].min", "range", "list", "ttpm.TTPM._event_names.astype", "ttpm.TTPM.tensor[].unique", "tensor.sort_values.sort_values.groupby().apply", "len", "tensor.sort_values.sort_values.groupby().apply", "tensor[].isin", "set", "len", "tensor[].unique", "tensor.sort_values.sort_values.groupby", "tensor.sort_values.sort_values.groupby", "i[].apply", "len", "numpy.exp", "ttpm.TTPM._k_hop_neibors"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._map_event_to_index", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._k_hop_neibors"], ["", "def", "_start_init", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "\"\"\"\n        Generates some required initial values.\n        \"\"\"", "\n", "tensor", ".", "dropna", "(", "axis", "=", "0", ",", "how", "=", "'any'", ",", "inplace", "=", "True", ")", "\n", "tensor", "[", "'timestamp'", "]", "=", "tensor", "[", "'timestamp'", "]", ".", "astype", "(", "float", ")", "\n", "\n", "tensor", "=", "tensor", ".", "groupby", "(", "\n", "[", "'event'", ",", "'timestamp'", ",", "'node'", "]", ")", ".", "apply", "(", "len", ")", ".", "reset_index", "(", ")", "\n", "tensor", ".", "columns", "=", "[", "'event'", ",", "'timestamp'", ",", "'node'", ",", "'times'", "]", "\n", "tensor", "=", "tensor", ".", "reindex", "(", "columns", "=", "[", "'node'", ",", "'timestamp'", ",", "'event'", ",", "'times'", "]", ")", "\n", "\n", "tensor", "=", "tensor", ".", "sort_values", "(", "[", "'node'", ",", "'timestamp'", "]", ")", "\n", "self", ".", "tensor", "=", "tensor", "[", "tensor", "[", "'node'", "]", ".", "isin", "(", "self", ".", "_topo", ".", "nodes", ")", "]", "\n", "\n", "# calculate considered events", "\n", "self", ".", "_event_names", "=", "np", ".", "array", "(", "list", "(", "set", "(", "self", ".", "tensor", "[", "'event'", "]", ")", ")", ")", "\n", "self", ".", "_event_names", ".", "sort", "(", ")", "\n", "self", ".", "_N", "=", "len", "(", "self", ".", "_event_names", ")", "\n", "self", ".", "_matrix_names", "=", "list", "(", "self", ".", "_event_names", ".", "astype", "(", "str", ")", ")", "\n", "\n", "# map event name to corresponding index value", "\n", "self", ".", "_event_indexes", "=", "self", ".", "_map_event_to_index", "(", "\n", "self", ".", "tensor", "[", "'event'", "]", ".", "values", ",", "self", ".", "_event_names", ")", "\n", "self", ".", "tensor", "[", "'event'", "]", "=", "self", ".", "_event_indexes", "\n", "\n", "self", ".", "_g", "=", "self", ".", "_topo", ".", "subgraph", "(", "self", ".", "tensor", "[", "'node'", "]", ".", "unique", "(", ")", ")", "\n", "self", ".", "_ne_grouped", "=", "self", ".", "tensor", ".", "groupby", "(", "'node'", ")", "\n", "\n", "self", ".", "_decay_effects", "=", "np", ".", "zeros", "(", "\n", "[", "len", "(", "self", ".", "_event_names", ")", ",", "self", ".", "_max_hop", "+", "1", "]", ")", "# will be used in EM.", "\n", "\n", "self", ".", "_max_s_t", "=", "tensor", "[", "'timestamp'", "]", ".", "max", "(", ")", "\n", "self", ".", "_min_s_t", "=", "tensor", "[", "'timestamp'", "]", ".", "min", "(", ")", "\n", "\n", "for", "k", "in", "range", "(", "self", ".", "_max_hop", "+", "1", ")", ":", "\n", "            ", "self", ".", "_decay_effects", "[", ":", ",", "k", "]", "=", "tensor", ".", "groupby", "(", "'event'", ")", ".", "apply", "(", "\n", "lambda", "i", ":", "(", "(", "(", "(", "1", "-", "np", ".", "exp", "(", "\n", "-", "self", ".", "_delta", "*", "(", "self", ".", "_max_s_t", "-", "i", "[", "'timestamp'", "]", ")", ")", ")", "/", "self", ".", "_delta", ")", "\n", "*", "i", "[", "'times'", "]", ")", "*", "i", "[", "'node'", "]", ".", "apply", "(", "\n", "lambda", "j", ":", "len", "(", "self", ".", "_k_hop_neibors", "(", "j", ",", "k", ")", ")", ")", ")", ".", "sum", "(", ")", ")", "\n", "# |V|x|T|", "\n", "", "self", ".", "_T", "=", "(", "self", ".", "_max_s_t", "-", "self", ".", "_min_s_t", ")", "*", "len", "(", "tensor", "[", "'node'", "]", ".", "unique", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._k_hop_neibors": [[172, 181], ["set", "set", "networkx.single_source_dijkstra_path_length().keys", "networkx.single_source_dijkstra_path_length().keys", "networkx.single_source_dijkstra_path_length", "networkx.single_source_dijkstra_path_length"], "methods", ["None"], ["", "def", "_k_hop_neibors", "(", "self", ",", "node", ",", "k", ")", ":", "\n", "\n", "        ", "if", "k", "==", "0", ":", "\n", "            ", "return", "{", "node", "}", "\n", "", "else", ":", "\n", "            ", "return", "set", "(", "nx", ".", "single_source_dijkstra_path_length", "(", "\n", "self", ".", "_g", ",", "node", ",", "k", ")", ".", "keys", "(", ")", ")", "-", "set", "(", "\n", "nx", ".", "single_source_dijkstra_path_length", "(", "\n", "self", ".", "_g", ",", "node", ",", "k", "-", "1", ")", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._map_event_to_index": [[182, 202], ["numpy.array", "list", "map", "numpy.where"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_map_event_to_index", "(", "event_names", ",", "base_event_names", ")", ":", "\n", "        ", "\"\"\"\n        Maps the event name to the corresponding index value.\n\n        Parameters\n        ----------\n        event_names: np.ndarray, shape like (52622,)\n            All occurred event names sorted by node and timestamp.\n        base_event_names: np.ndarray, shape like (10,)\n            All deduplicated and sorted event names\n\n        Returns\n        -------\n        np.ndarray: All occurred event names mapped to their corresponding index \n         in base_event_names.\n        \"\"\"", "\n", "return", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "event_name", ":", "\n", "np", ".", "where", "(", "base_event_names", "==", "event_name", ")", "[", "0", "]", "[", "0", "]", ",", "\n", "event_names", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._hill_climb": [[203, 244], ["ttpm.TTPM._get_effect_tensor_decays", "numpy.eye", "ttpm.TTPM._em", "range", "logging.info", "list", "ttpm.TTPM._one_step_change_iterator", "ttpm.TTPM._em"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._get_effect_tensor_decays", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._em", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._one_step_change_iterator", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._em"], ["", "def", "_hill_climb", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Search the best causal graph, then generate the causal matrix (DAG).\n\n        Returns\n        -------\n        result: tuple, (likelihood, alpha matrix, events vector)\n            likelihood: used as the score criteria for searching the\n                causal structure.\n            alpha matrix: the intensity of causal effect from event v\u2019 to v.\n            events vector: the exogenous base intensity of each event.\n        edge_mat: np.ndarray\n            Causal matrix.\n        \"\"\"", "\n", "self", ".", "_get_effect_tensor_decays", "(", ")", "\n", "# Initialize the adjacency matrix", "\n", "edge_mat", "=", "np", ".", "eye", "(", "self", ".", "_N", ",", "self", ".", "_N", ")", "\n", "result", "=", "self", ".", "_em", "(", "edge_mat", ")", "\n", "l_ret", "=", "result", "[", "0", "]", "\n", "\n", "for", "num_iter", "in", "range", "(", "self", ".", "_max_iter", ")", ":", "\n", "\n", "            ", "logging", ".", "info", "(", "'[iter {}]: likelihood_score = {}'", ".", "format", "(", "num_iter", ",", "l_ret", ")", ")", "\n", "\n", "stop_tag", "=", "True", "\n", "for", "new_edge_mat", "in", "list", "(", "\n", "self", ".", "_one_step_change_iterator", "(", "edge_mat", ")", ")", ":", "\n", "                ", "new_result", "=", "self", ".", "_em", "(", "new_edge_mat", ")", "\n", "new_l", "=", "new_result", "[", "0", "]", "\n", "# Termination condition:", "\n", "#   no adjacency matrix with higher likelihood appears", "\n", "if", "new_l", ">", "l_ret", ":", "\n", "                    ", "result", "=", "new_result", "\n", "l_ret", "=", "new_l", "\n", "stop_tag", "=", "False", "\n", "edge_mat", "=", "new_edge_mat", "\n", "\n", "", "", "if", "stop_tag", ":", "\n", "                ", "return", "result", ",", "edge_mat", "\n", "\n", "", "", "return", "result", ",", "edge_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._get_effect_tensor_decays": [[245, 252], ["numpy.zeros", "range", "ttpm.TTPM._get_effect_tensor_decays_each_hop", "len", "len"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._get_effect_tensor_decays_each_hop"], ["", "def", "_get_effect_tensor_decays", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "_effect_tensor_decays", "=", "np", ".", "zeros", "(", "[", "self", ".", "_max_hop", "+", "1", ",", "\n", "len", "(", "self", ".", "tensor", ")", ",", "\n", "len", "(", "self", ".", "_event_names", ")", "]", ")", "\n", "for", "k", "in", "range", "(", "self", ".", "_max_hop", "+", "1", ")", ":", "\n", "            ", "self", ".", "_get_effect_tensor_decays_each_hop", "(", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._get_effect_tensor_decays_each_hop": [[253, 297], ["numpy.zeros", "range", "len", "numpy.zeros", "numpy.exp", "ttpm.TTPM._k_hop_neibors", "pandas.concat", "neighbors_table.sort_values.sort_values.sort_values", "len", "numpy.min", "numpy.exp", "ttpm.TTPM._ne_grouped.get_group", "int"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._k_hop_neibors"], ["", "", "def", "_get_effect_tensor_decays_each_hop", "(", "self", ",", "k", ")", ":", "\n", "\n", "        ", "j", "=", "0", "\n", "pre_effect", "=", "np", ".", "zeros", "(", "self", ".", "_N", ")", "\n", "tensor_array", "=", "self", ".", "tensor", ".", "values", "\n", "for", "item_ind", "in", "range", "(", "len", "(", "self", ".", "tensor", ")", ")", ":", "\n", "            ", "sub_n", ",", "start_t", ",", "ala_i", ",", "times", "=", "tensor_array", "[", "\n", "item_ind", ",", "[", "0", ",", "1", ",", "2", ",", "3", "]", "]", "\n", "last_sub_n", ",", "last_start_t", ",", "last_ala_i", ",", "last_times", "=", "tensor_array", "[", "item_ind", "-", "1", ",", "[", "0", ",", "1", ",", "2", ",", "3", "]", "]", "\n", "if", "(", "last_sub_n", "!=", "sub_n", ")", "or", "(", "last_start_t", ">", "start_t", ")", ":", "\n", "                ", "j", "=", "0", "\n", "pre_effect", "=", "np", ".", "zeros", "(", "self", ".", "_N", ")", "\n", "try", ":", "\n", "                    ", "k_hop_neighbors_ne", "=", "self", ".", "_k_hop_neibors", "(", "sub_n", ",", "k", ")", "\n", "neighbors_table", "=", "pd", ".", "concat", "(", "\n", "[", "self", ".", "_ne_grouped", ".", "get_group", "(", "i", ")", "\n", "for", "i", "in", "k_hop_neighbors_ne", "]", ")", "\n", "neighbors_table", "=", "neighbors_table", ".", "sort_values", "(", "\n", "'timestamp'", ")", "\n", "neighbors_table_value", "=", "neighbors_table", ".", "values", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "                    ", "k_hop_neighbors_ne", "=", "[", "]", "\n", "\n", "", "if", "len", "(", "k_hop_neighbors_ne", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "cur_effect", "=", "pre_effect", "*", "np", ".", "exp", "(", "\n", "(", "np", ".", "min", "(", "(", "last_start_t", "-", "start_t", ",", "0", ")", ")", ")", "*", "self", ".", "_delta", ")", "\n", "while", "1", ":", "\n", "                ", "try", ":", "\n", "                    ", "nei_sub_n", ",", "nei_start_t", ",", "nei_ala_i", ",", "nei_times", "=", "neighbors_table_value", "[", "j", ",", ":", "]", "\n", "", "except", ":", "\n", "                    ", "break", "\n", "", "if", "nei_start_t", "<", "start_t", ":", "\n", "                    ", "cur_effect", "[", "int", "(", "nei_ala_i", ")", "]", "+=", "nei_times", "*", "np", ".", "exp", "(", "\n", "(", "nei_start_t", "-", "start_t", ")", "*", "self", ".", "_delta", ")", "\n", "j", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "break", "\n", "", "", "pre_effect", "=", "cur_effect", "\n", "\n", "self", ".", "_effect_tensor_decays", "[", "k", ",", "item_ind", "]", "=", "pre_effect", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._em": [[298, 388], ["networkx.from_numpy_matrix", "numpy.ones", "numpy.ones", "range", "networkx.is_directed_acyclic_graph", "len", "len", "set", "numpy.where", "numpy.zeros_like", "numpy.eye", "numpy.zeros", "numpy.zeros", "len", "len", "range", "ValueError", "len", "numpy.where", "numpy.zeros", "numpy.matmul", "dict", "range", "len", "len", "len", "len", "numpy.log", "edge_mat.sum", "numpy.log", "len", "ttpm.TTPM.tensor[].sum", "edge_mat.sum"], "methods", ["None"], ["", "", "def", "_em", "(", "self", ",", "edge_mat", ")", ":", "\n", "        ", "\"\"\"\n        E-M module, used to find the optimal parameters.\n\n        Parameters\n        ----------\n        edge_mat\uff1a np.ndarray\n            Adjacency matrix.\n\n        Returns\n        -------\n        likelihood: used as the score criteria for searching the\n            causal structure.\n        alpha matrix: the intensity of causal effect from event v\u2019 to v.\n        events vector: the exogenous base intensity of each event.\n        \"\"\"", "\n", "\n", "causal_g", "=", "nx", ".", "from_numpy_matrix", "(", "(", "edge_mat", "-", "np", ".", "eye", "(", "self", ".", "_N", ",", "self", ".", "_N", ")", ")", ",", "\n", "create_using", "=", "nx", ".", "DiGraph", ")", "\n", "\n", "if", "not", "nx", ".", "is_directed_acyclic_graph", "(", "causal_g", ")", ":", "\n", "            ", "return", "-", "100000000000000", ",", "np", ".", "zeros", "(", "[", "len", "(", "self", ".", "_event_names", ")", ",", "len", "(", "self", ".", "_event_names", ")", "]", ")", ",", "np", ".", "zeros", "(", "len", "(", "self", ".", "_event_names", ")", ")", "\n", "\n", "# Initialize alpha:(nxn)\uff0cmu:(nx1) and L", "\n", "", "alpha", "=", "np", ".", "ones", "(", "[", "self", ".", "_max_hop", "+", "1", ",", "len", "(", "self", ".", "_event_names", ")", ",", "\n", "len", "(", "self", ".", "_event_names", ")", "]", ")", "\n", "alpha", "=", "alpha", "*", "edge_mat", "\n", "mu", "=", "np", ".", "ones", "(", "len", "(", "self", ".", "_event_names", ")", ")", "\n", "l_init", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_event_names", ")", ")", ":", "\n", "            ", "pa_i", "=", "set", "(", "np", ".", "where", "(", "edge_mat", "[", ":", ",", "i", "]", "==", "1", ")", "[", "0", "]", ")", "\n", "li", "=", "-", "100000000000", "\n", "ind", "=", "np", ".", "where", "(", "self", ".", "_event_indexes", "==", "i", ")", "\n", "x_i", "=", "self", ".", "tensor", "[", "'times'", "]", ".", "values", "[", "ind", "]", "\n", "x_i_all", "=", "np", ".", "zeros_like", "(", "self", ".", "tensor", "[", "'times'", "]", ".", "values", ")", "\n", "x_i_all", "[", "ind", "]", "=", "x_i", "\n", "while", "1", ":", "\n", "# Calculate the first part of the likelihood", "\n", "                ", "lambda_i_sum", "=", "(", "self", ".", "_decay_effects", "\n", "*", "alpha", "[", ":", ",", ":", ",", "i", "]", ".", "T", ")", ".", "sum", "(", ")", "+", "mu", "[", "i", "]", "*", "self", ".", "_T", "\n", "\n", "# Calculate the second part of the likelihood", "\n", "lambda_for_i", "=", "np", ".", "zeros", "(", "len", "(", "self", ".", "tensor", ")", ")", "+", "mu", "[", "i", "]", "\n", "for", "k", "in", "range", "(", "self", ".", "_max_hop", "+", "1", ")", ":", "\n", "                    ", "lambda_for_i", "+=", "np", ".", "matmul", "(", "\n", "self", ".", "_effect_tensor_decays", "[", "k", ",", ":", "]", ",", "\n", "alpha", "[", "k", ",", ":", ",", "i", "]", ".", "T", ")", "\n", "", "lambda_for_i", "=", "lambda_for_i", "[", "ind", "]", "\n", "x_log_lambda", "=", "(", "x_i", "*", "np", ".", "log", "(", "lambda_for_i", ")", ")", ".", "sum", "(", ")", "\n", "new_li", "=", "-", "lambda_i_sum", "+", "x_log_lambda", "\n", "\n", "# Iteration termination condition", "\n", "delta", "=", "new_li", "-", "li", "\n", "if", "delta", "<", "0.1", ":", "\n", "                    ", "li", "=", "new_li", "\n", "l_init", "+=", "li", "\n", "pa_i_alpha", "=", "dict", "(", ")", "\n", "for", "j", "in", "pa_i", ":", "\n", "                        ", "pa_i_alpha", "[", "j", "]", "=", "alpha", "[", ":", ",", "j", ",", "i", "]", "\n", "", "break", "\n", "", "li", "=", "new_li", "\n", "# update mu", "\n", "mu", "[", "i", "]", "=", "(", "(", "mu", "[", "i", "]", "/", "lambda_for_i", ")", "*", "x_i", ")", ".", "sum", "(", ")", "/", "self", ".", "_T", "\n", "# update alpha", "\n", "for", "j", "in", "pa_i", ":", "\n", "                    ", "for", "k", "in", "range", "(", "self", ".", "_max_hop", "+", "1", ")", ":", "\n", "                        ", "upper", "=", "(", "(", "alpha", "[", "k", ",", "j", ",", "i", "]", "*", "(", "\n", "self", ".", "_effect_tensor_decays", "[", "k", ",", ":", ",", "j", "]", ")", "[", "ind", "]", "\n", "/", "lambda_for_i", ")", "*", "x_i", ")", ".", "sum", "(", ")", "\n", "lower", "=", "self", ".", "_decay_effects", "[", "j", ",", "k", "]", "\n", "if", "lower", "==", "0", ":", "\n", "                            ", "alpha", "[", "k", ",", "j", ",", "i", "]", "=", "0", "\n", "continue", "\n", "", "alpha", "[", "k", ",", "j", ",", "i", "]", "=", "upper", "/", "lower", "\n", "", "", "", "i", "+=", "1", "\n", "\n", "", "if", "self", ".", "_penalty", "==", "'AIC'", ":", "\n", "            ", "return", "l_init", "-", "(", "len", "(", "self", ".", "_event_names", ")", "\n", "+", "self", ".", "_epsilon", "*", "edge_mat", ".", "sum", "(", ")", "\n", "*", "(", "self", ".", "_max_hop", "+", "1", ")", ")", ",", "alpha", ",", "mu", "\n", "", "elif", "self", ".", "_penalty", "==", "'BIC'", ":", "\n", "            ", "return", "l_init", "-", "(", "len", "(", "self", ".", "_event_names", ")", "\n", "+", "self", ".", "_epsilon", "*", "edge_mat", ".", "sum", "(", ")", "\n", "*", "(", "self", ".", "_max_hop", "+", "1", ")", ")", "*", "np", ".", "log", "(", "\n", "self", ".", "tensor", "[", "'times'", "]", ".", "sum", "(", ")", ")", "/", "2", ",", "alpha", ",", "mu", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"The penalty's value should be BIC or AIC.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._one_step_change_iterator": [[389, 394], ["map", "itertools.product", "ttpm.TTPM._one_step_change", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._one_step_change"], ["", "", "def", "_one_step_change_iterator", "(", "self", ",", "edge_mat", ")", ":", "\n", "\n", "        ", "return", "map", "(", "lambda", "e", ":", "self", ".", "_one_step_change", "(", "edge_mat", ",", "e", ")", ",", "\n", "product", "(", "range", "(", "len", "(", "self", ".", "_event_names", ")", ")", ",", "\n", "range", "(", "len", "(", "self", ".", "_event_names", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.ttpm.ttpm.TTPM._one_step_change": [[395, 423], ["edge_mat.copy"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_one_step_change", "(", "edge_mat", ",", "e", ")", ":", "\n", "        ", "\"\"\"\n        Changes the edge value in the edge_mat.\n\n        Parameters\n        ----------\n        edge_mat: np.ndarray\n            Adjacency matrix.\n        e: tuple_like (j,i)\n\n        Returns\n        -------\n        new_edge_mat: np.ndarray\n            new value of edge\n        \"\"\"", "\n", "j", ",", "i", "=", "e", "\n", "if", "j", "==", "i", ":", "\n", "            ", "return", "edge_mat", "\n", "", "new_edge_mat", "=", "edge_mat", ".", "copy", "(", ")", "\n", "\n", "if", "new_edge_mat", "[", "j", ",", "i", "]", "==", "1", ":", "\n", "            ", "new_edge_mat", "[", "j", ",", "i", "]", "=", "0", "\n", "return", "new_edge_mat", "\n", "", "else", ":", "\n", "            ", "new_edge_mat", "[", "j", ",", "i", "]", "=", "1", "\n", "new_edge_mat", "[", "i", ",", "j", "]", "=", "0", "\n", "return", "new_edge_mat", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.pc.pc.PC.__init__": [[364, 370], ["castle.common.BaseLearner.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "variant", "=", "'original'", ",", "alpha", "=", "0.05", ",", "ci_test", "=", "'gauss'", ")", ":", "\n", "        ", "super", "(", "PC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "variant", "=", "variant", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "ci_test", "=", "ci_test", "\n", "self", ".", "causal_matrix", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.pc.pc.PC.learn": [[371, 403], ["castle.common.Tensor", "pc.find_skeleton", "castle.common.Tensor", "orient().astype", "pc.orient"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.pc.pc.find_skeleton", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.pc.pc.orient"], ["", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Set up and run the PC algorithm.\n\n        Parameters\n        ----------\n        data: array or Tensor\n            Training data\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        kwargs: [optional]\n            p_cores : int\n                number of CPU cores to be used\n            s : boolean\n                memory-efficient indicator\n            batch : int\n                number of edges per batch\n            if s is None or False, or without batch, batch=|J|.\n            |J| denote number of all pairs of adjacency vertices (X, Y) in G.\n        \"\"\"", "\n", "\n", "data", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "skeleton", ",", "sep_set", "=", "find_skeleton", "(", "data", ",", "\n", "alpha", "=", "self", ".", "alpha", ",", "\n", "ci_test", "=", "self", ".", "ci_test", ",", "\n", "variant", "=", "self", ".", "variant", ",", "\n", "**", "kwargs", ")", "\n", "\n", "self", ".", "_causal_matrix", "=", "Tensor", "(", "orient", "(", "skeleton", ",", "sep_set", ")", ".", "astype", "(", "int", ")", ",", "\n", "index", "=", "data", ".", "columns", ",", "\n", "columns", "=", "data", ".", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.pc.pc._loop": [[25, 56], ["set", "len", "itertools.combinations", "numpy.argwhere().reshape", "len", "set", "range", "numpy.argwhere"], "function", ["None"], ["def", "_loop", "(", "G", ",", "d", ")", ":", "\n", "    ", "\"\"\"\n    Check if |adj(x, G)\\{y}| < d for every pair of adjacency vertices in G\n\n    Parameters\n    ----------\n    G: numpy.ndarray\n        The undirected graph  G\n    d: int\n        depth of conditional vertices\n\n    Returns\n    -------\n    out: bool\n        if False, denote |adj(i, G)\\{j}| < d for every pair of adjacency\n        vertices in G, then finished loop.\n    \"\"\"", "\n", "\n", "assert", "G", ".", "shape", "[", "0", "]", "==", "G", ".", "shape", "[", "1", "]", "\n", "\n", "pairs", "=", "[", "(", "x", ",", "y", ")", "for", "x", ",", "y", "in", "combinations", "(", "set", "(", "range", "(", "G", ".", "shape", "[", "0", "]", ")", ")", ",", "2", ")", "]", "\n", "less_d", "=", "0", "\n", "for", "i", ",", "j", "in", "pairs", ":", "\n", "        ", "adj_i", "=", "set", "(", "np", ".", "argwhere", "(", "G", "[", "i", "]", "==", "1", ")", ".", "reshape", "(", "-", "1", ",", ")", ")", "\n", "z", "=", "adj_i", "-", "{", "j", "}", "# adj(C, i)\\{j}", "\n", "if", "len", "(", "z", ")", "<", "d", ":", "\n", "            ", "less_d", "+=", "1", "\n", "", "", "if", "less_d", "==", "len", "(", "pairs", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.pc.pc.orient": [[58, 150], ["list", "copy.deepcopy", "sep_set.keys", "range", "copy.deepcopy", "list", "itertools.combinations", "itertools.permutations", "itertools.permutations", "itertools.permutations", "itertools.permutations", "sep_set.keys", "sep_set.keys", "list", "list.remove"], "function", ["None"], ["", "", "def", "orient", "(", "skeleton", ",", "sep_set", ")", ":", "\n", "    ", "\"\"\"Extending the Skeleton to the Equivalence Class\n\n    it orients the undirected edges to form an equivalence class of DAGs.\n\n    Parameters\n    ----------\n    skeleton : array\n        The undirected graph\n    sep_set : dict\n        separation sets\n        if key is (x, y), then value is a set of other variables\n        not contains x and y\n\n    Returns\n    -------\n    out : array\n        An equivalence class of DAGs can be uniquely described\n        by a completed partially directed acyclic graph (CPDAG)\n        which includes both directed and undirected edges.\n    \"\"\"", "\n", "\n", "columns", "=", "list", "(", "range", "(", "skeleton", ".", "shape", "[", "1", "]", ")", ")", "\n", "cpdag", "=", "deepcopy", "(", "skeleton", ")", "\n", "# pre-processing", "\n", "for", "ij", "in", "sep_set", ".", "keys", "(", ")", ":", "\n", "        ", "i", ",", "j", "=", "ij", "\n", "all_k", "=", "[", "x", "for", "x", "in", "columns", "if", "x", "not", "in", "ij", "]", "\n", "for", "k", "in", "all_k", ":", "\n", "            ", "if", "cpdag", "[", "i", ",", "k", "]", "+", "cpdag", "[", "k", ",", "i", "]", "!=", "0", "and", "cpdag", "[", "k", ",", "j", "]", "+", "cpdag", "[", "j", ",", "k", "]", "!=", "0", ":", "\n", "                ", "if", "k", "not", "in", "sep_set", "[", "ij", "]", ":", "\n", "                    ", "if", "cpdag", "[", "i", ",", "k", "]", "+", "cpdag", "[", "k", ",", "i", "]", "==", "2", ":", "\n", "                        ", "cpdag", "[", "k", ",", "i", "]", "=", "0", "\n", "", "if", "cpdag", "[", "j", ",", "k", "]", "+", "cpdag", "[", "k", ",", "j", "]", "==", "2", ":", "\n", "                        ", "cpdag", "[", "k", ",", "j", "]", "=", "0", "\n", "", "", "", "", "", "while", "True", ":", "\n", "        ", "old_cpdag", "=", "deepcopy", "(", "cpdag", ")", "\n", "pairs", "=", "list", "(", "combinations", "(", "columns", ",", "2", ")", ")", "\n", "for", "ij", "in", "pairs", ":", "\n", "            ", "i", ",", "j", "=", "ij", "\n", "if", "cpdag", "[", "i", ",", "j", "]", "*", "cpdag", "[", "j", ",", "i", "]", "==", "1", ":", "\n", "# rule1", "\n", "                ", "for", "i", ",", "j", "in", "permutations", "(", "ij", ",", "2", ")", ":", "\n", "                    ", "all_k", "=", "[", "x", "for", "x", "in", "columns", "if", "x", "not", "in", "ij", "]", "\n", "for", "k", "in", "all_k", ":", "\n", "                        ", "if", "cpdag", "[", "k", ",", "i", "]", "==", "1", "and", "cpdag", "[", "i", ",", "k", "]", "==", "0", "and", "cpdag", "[", "k", ",", "j", "]", "+", "cpdag", "[", "j", ",", "k", "]", "==", "0", ":", "\n", "                            ", "cpdag", "[", "j", ",", "i", "]", "=", "0", "\n", "# rule2", "\n", "", "", "", "for", "i", ",", "j", "in", "permutations", "(", "ij", ",", "2", ")", ":", "\n", "                    ", "all_k", "=", "[", "x", "for", "x", "in", "columns", "if", "x", "not", "in", "ij", "]", "\n", "for", "k", "in", "all_k", ":", "\n", "                        ", "if", "(", "cpdag", "[", "i", ",", "k", "]", "==", "1", "and", "cpdag", "[", "k", ",", "i", "]", "==", "0", ")", "and", "(", "cpdag", "[", "k", ",", "j", "]", "==", "1", "and", "cpdag", "[", "j", ",", "k", "]", "==", "0", ")", ":", "\n", "                            ", "cpdag", "[", "j", ",", "i", "]", "=", "0", "\n", "# rule3", "\n", "", "", "", "for", "i", ",", "j", "in", "permutations", "(", "ij", ",", "2", ")", ":", "\n", "                    ", "for", "kl", "in", "sep_set", ".", "keys", "(", ")", ":", "# k and l are nonadjacent.", "\n", "                        ", "k", ",", "l", "=", "kl", "\n", "# if i\u2014\u2014k\u2014\u2014>j and  i\u2014\u2014l\u2014\u2014>j", "\n", "if", "cpdag", "[", "i", ",", "k", "]", "==", "1", "and", "cpdag", "[", "k", ",", "i", "]", "==", "1", "and", "cpdag", "[", "k", ",", "j", "]", "==", "1", "and", "cpdag", "[", "j", ",", "k", "]", "==", "0", "and", "cpdag", "[", "i", ",", "l", "]", "==", "1", "and", "cpdag", "[", "l", ",", "i", "]", "==", "1", "and", "cpdag", "[", "l", ",", "j", "]", "==", "1", "and", "cpdag", "[", "j", ",", "l", "]", "==", "0", ":", "\n", "                            ", "cpdag", "[", "j", ",", "i", "]", "=", "0", "\n", "# rule4", "\n", "", "", "", "for", "i", ",", "j", "in", "permutations", "(", "ij", ",", "2", ")", ":", "\n", "                    ", "for", "kj", "in", "sep_set", ".", "keys", "(", ")", ":", "# k and j are nonadjacent.", "\n", "                        ", "if", "j", "not", "in", "kj", ":", "\n", "                            ", "continue", "\n", "", "else", ":", "\n", "                            ", "kj", "=", "list", "(", "kj", ")", "\n", "kj", ".", "remove", "(", "j", ")", "\n", "k", "=", "kj", "[", "0", "]", "\n", "ls", "=", "[", "x", "for", "x", "in", "columns", "if", "x", "not", "in", "[", "i", ",", "j", ",", "k", "]", "]", "\n", "for", "l", "in", "ls", ":", "\n", "                                ", "if", "cpdag", "[", "k", ",", "l", "]", "==", "1", "and", "cpdag", "[", "l", ",", "k", "]", "==", "0", "and", "cpdag", "[", "i", ",", "k", "]", "==", "1", "and", "cpdag", "[", "k", ",", "i", "]", "==", "1", "and", "cpdag", "[", "l", ",", "j", "]", "==", "1", "and", "cpdag", "[", "j", ",", "l", "]", "==", "0", ":", "\n", "                                    ", "cpdag", "[", "j", ",", "i", "]", "=", "0", "\n", "", "", "", "", "", "", "", "if", "(", "cpdag", "==", "old_cpdag", ")", ".", "all", "(", ")", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "cpdag", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.pc.pc.find_skeleton": [[152, 313], ["set", "pc._loop", "set", "pc.find_skeleton.test"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.pc.pc._loop"], ["", "def", "find_skeleton", "(", "data", ",", "alpha", ",", "ci_test", ",", "variant", "=", "'original'", ",", "base_skeleton", "=", "None", ",", "\n", "p_cores", "=", "1", ",", "s", "=", "None", ",", "batch", "=", "None", ")", ":", "\n", "    ", "\"\"\"Find skeleton graph from G using PC algorithm\n\n    It learns a skeleton graph which contains only undirected edges\n    from data.\n\n    Parameters\n    ----------\n    data : array, (n_samples, n_features)\n        Dataset with a set of variables V\n    alpha : float, default 0.05\n        significant level\n    ci_test : str, callable\n        ci_test method, if str, must be one of [`gauss`, `g2`, `chi2`].\n        if callable, must return a tuple that  the last element is `p_value` ,\n        like (_, _, p_value) or (chi2, dof, p_value).\n        See more: `castle.common.independence_tests.CITest`\n    variant : str, default 'original'\n        variant of PC algorithm, contains [`original`, `stable`, `parallel`].\n        If variant == 'parallel', need to provide the flowing 3 parameters.\n    base_skeleton : array, (n_features, n_features)\n        prior matrix, must be undirected graph.\n        The two conditionals `base_skeleton[i, j] == base_skeleton[j, i]`\n        and `and base_skeleton[i, i] == 0` must be satisified which i != j.\n    p_cores : int\n        Number of CPU cores to be used\n    s : bool, default False\n        memory-efficient indicator\n    batch : int\n        number of edges per batch\n\n    if s is None or False, or without batch, batch=|J|.\n    |J| denote number of all pairs of adjacency vertices (X, Y) in G.\n\n    Returns\n    -------\n    skeleton : array\n        The undirected graph\n    seq_set : dict\n        Separation sets\n        Such as key is (x, y), then value is a set of other variables\n        not contains x and y.\n\n    Examples\n    --------\n    >>> from castle.algorithms.pc.pc import find_skeleton\n    >>> from castle.datasets import load_dataset\n\n    >>> true_dag, X = load_dataset(name='iid_test')\n    >>> skeleton, sep_set = find_skeleton(data, 0.05, 'gauss')\n    >>> print(skeleton)\n    [[0. 0. 1. 0. 0. 1. 0. 0. 0. 0.]\n     [0. 0. 0. 1. 1. 1. 1. 0. 1. 0.]\n     [1. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n     [0. 1. 0. 0. 1. 0. 0. 1. 0. 1.]\n     [0. 1. 1. 1. 0. 0. 0. 0. 0. 1.]\n     [1. 1. 0. 0. 0. 0. 0. 1. 1. 1.]\n     [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n     [0. 0. 1. 1. 0. 1. 0. 0. 0. 1.]\n     [0. 1. 0. 0. 0. 1. 0. 0. 0. 1.]\n     [0. 0. 0. 1. 1. 1. 0. 1. 1. 0.]]\n    \"\"\"", "\n", "\n", "def", "test", "(", "x", ",", "y", ")", ":", "\n", "\n", "        ", "K_x_y", "=", "1", "\n", "sub_z", "=", "None", "\n", "# On X's neighbours", "\n", "adj_x", "=", "set", "(", "np", ".", "argwhere", "(", "skeleton", "[", "x", "]", "==", "1", ")", ".", "reshape", "(", "-", "1", ",", ")", ")", "\n", "z_x", "=", "adj_x", "-", "{", "y", "}", "# adj(X, G)\\{Y}", "\n", "if", "len", "(", "z_x", ")", ">=", "d", ":", "\n", "# |adj(X, G)\\{Y}| >= d", "\n", "            ", "for", "sub_z", "in", "combinations", "(", "z_x", ",", "d", ")", ":", "\n", "                ", "sub_z", "=", "list", "(", "sub_z", ")", "\n", "_", ",", "_", ",", "p_value", "=", "ci_test", "(", "data", ",", "x", ",", "y", ",", "sub_z", ")", "\n", "if", "p_value", ">=", "alpha", ":", "\n", "                    ", "K_x_y", "=", "0", "\n", "# sep_set[(x, y)] = sub_z", "\n", "break", "\n", "", "", "if", "K_x_y", "==", "0", ":", "\n", "                ", "return", "K_x_y", ",", "sub_z", "\n", "\n", "", "", "return", "K_x_y", ",", "sub_z", "\n", "\n", "", "def", "parallel_cell", "(", "x", ",", "y", ")", ":", "\n", "\n", "# On X's neighbours", "\n", "        ", "K_x_y", ",", "sub_z", "=", "test", "(", "x", ",", "y", ")", "\n", "if", "K_x_y", "==", "1", ":", "\n", "# On Y's neighbours", "\n", "            ", "K_x_y", ",", "sub_z", "=", "test", "(", "y", ",", "x", ")", "\n", "\n", "", "return", "(", "x", ",", "y", ")", ",", "K_x_y", ",", "sub_z", "\n", "\n", "", "if", "ci_test", "==", "'gauss'", ":", "\n", "        ", "ci_test", "=", "CITest", ".", "gauss", "\n", "", "elif", "ci_test", "==", "'g2'", ":", "\n", "        ", "ci_test", "=", "CITest", ".", "g2_test", "\n", "", "elif", "ci_test", "==", "'chi2'", ":", "\n", "        ", "ci_test", "=", "CITest", ".", "chi2_test", "\n", "", "elif", "callable", "(", "ci_test", ")", ":", "\n", "        ", "ci_test", "=", "ci_test", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f'The type of param `ci_test` expect callable,'", "\n", "f'but got {type(ci_test)}.'", ")", "\n", "\n", "", "n_feature", "=", "data", ".", "shape", "[", "1", "]", "\n", "if", "base_skeleton", "is", "None", ":", "\n", "        ", "skeleton", "=", "np", ".", "ones", "(", "(", "n_feature", ",", "n_feature", ")", ")", "-", "np", ".", "eye", "(", "n_feature", ")", "\n", "", "else", ":", "\n", "        ", "row", ",", "col", "=", "np", ".", "diag_indices_from", "(", "base_skeleton", ")", "\n", "base_skeleton", "[", "row", ",", "col", "]", "=", "0", "\n", "skeleton", "=", "base_skeleton", "\n", "", "nodes", "=", "set", "(", "range", "(", "n_feature", ")", ")", "\n", "pairs", "=", "[", "(", "x", ",", "y", ")", "for", "x", ",", "y", "in", "combinations", "(", "nodes", ",", "2", ")", "]", "\n", "sep_set", "=", "{", "}", "\n", "d", "=", "-", "1", "\n", "while", "_loop", "(", "skeleton", ",", "d", ")", ":", "# until for each adj(C,i)\\{j} < l", "\n", "        ", "d", "+=", "1", "\n", "if", "variant", "==", "'stable'", ":", "\n", "            ", "C", "=", "deepcopy", "(", "skeleton", ")", "\n", "", "else", ":", "\n", "            ", "C", "=", "skeleton", "\n", "", "if", "variant", "!=", "'parallel'", ":", "\n", "            ", "for", "i", ",", "j", "in", "pairs", ":", "\n", "                ", "if", "skeleton", "[", "i", ",", "j", "]", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "adj_i", "=", "set", "(", "np", ".", "argwhere", "(", "C", "[", "i", "]", "==", "1", ")", ".", "reshape", "(", "-", "1", ",", ")", ")", "\n", "z", "=", "adj_i", "-", "{", "j", "}", "# adj(C, i)\\{j}", "\n", "if", "len", "(", "z", ")", ">=", "d", ":", "\n", "# |adj(C, i)\\{j}| >= l", "\n", "                    ", "for", "sub_z", "in", "combinations", "(", "z", ",", "d", ")", ":", "\n", "                        ", "sub_z", "=", "list", "(", "sub_z", ")", "\n", "_", ",", "_", ",", "p_value", "=", "ci_test", "(", "data", ",", "i", ",", "j", ",", "sub_z", ")", "\n", "if", "p_value", ">=", "alpha", ":", "\n", "                            ", "skeleton", "[", "i", ",", "j", "]", "=", "skeleton", "[", "j", ",", "i", "]", "=", "0", "\n", "sep_set", "[", "(", "i", ",", "j", ")", "]", "=", "sub_z", "\n", "break", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "J", "=", "[", "(", "x", ",", "y", ")", "for", "x", ",", "y", "in", "combinations", "(", "nodes", ",", "2", ")", "\n", "if", "skeleton", "[", "x", ",", "y", "]", "==", "1", "]", "\n", "if", "not", "s", "or", "not", "batch", ":", "\n", "                ", "batch", "=", "len", "(", "J", ")", "\n", "", "if", "not", "p_cores", "or", "p_cores", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "f'If variant is parallel, type of p_cores '", "\n", "f'must be int, but got {type(p_cores)}.'", ")", "\n", "", "for", "i", "in", "range", "(", "int", "(", "np", ".", "ceil", "(", "len", "(", "J", ")", "/", "batch", ")", ")", ")", ":", "\n", "                ", "each_batch", "=", "J", "[", "batch", "*", "i", ":", "batch", "*", "(", "i", "+", "1", ")", "]", "\n", "parallel_result", "=", "joblib", ".", "Parallel", "(", "n_jobs", "=", "p_cores", ",", "\n", "max_nbytes", "=", "None", ")", "(", "\n", "joblib", ".", "delayed", "(", "parallel_cell", ")", "(", "x", ",", "y", ")", "for", "x", ",", "y", "in", "\n", "each_batch", "\n", ")", "\n", "# Synchronisation Step", "\n", "for", "(", "x", ",", "y", ")", ",", "K_x_y", ",", "sub_z", "in", "parallel_result", ":", "\n", "                    ", "if", "K_x_y", "==", "0", ":", "\n", "                        ", "skeleton", "[", "x", ",", "y", "]", "=", "skeleton", "[", "y", ",", "x", "]", "=", "0", "\n", "sep_set", "[", "(", "x", ",", "y", ")", "]", "=", "sub_z", "\n", "\n", "", "", "", "", "", "return", "skeleton", ",", "sep_set", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM.__init__": [[74, 81], ["utils.base._BaseLiNGAM.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "prior_knowledge", "=", "None", ",", "measure", "=", "'pwling'", ",", "thresh", "=", "0.3", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_prior_knowledge", "=", "prior_knowledge", "\n", "self", ".", "_measure", "=", "measure", "\n", "self", ".", "_thresh", "=", "thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM.learn": [[82, 108], ["castle.common.Tensor", "direct_lingam.DirectLiNGAM.fit", "castle.common.Tensor", "castle.common.Tensor", "abs"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit"], ["", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Set up and run the DirectLiNGAM algorithm.\n\n        Parameters\n        ----------\n        data: castle.Tensor or numpy.ndarray\n            The castle.Tensor or numpy.ndarray format data you want to learn.\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        \"\"\"", "\n", "\n", "X", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "self", ".", "fit", "(", "X", ")", "\n", "\n", "weight_causal_matrix", "=", "self", ".", "adjacency_matrix_", ".", "T", "\n", "self", ".", "weight_causal_matrix", "=", "Tensor", "(", "weight_causal_matrix", ",", "\n", "index", "=", "X", ".", "columns", ",", "\n", "columns", "=", "X", ".", "columns", ")", "\n", "\n", "causal_matrix", "=", "(", "abs", "(", "self", ".", "adjacency_matrix_", ")", ">", "self", ".", "_thresh", ")", ".", "astype", "(", "int", ")", ".", "T", "\n", "self", ".", "causal_matrix", "=", "Tensor", "(", "causal_matrix", ",", "\n", "index", "=", "X", ".", "columns", ",", "\n", "columns", "=", "X", ".", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM.fit": [[109, 157], ["sklearn.utils.check_array", "numpy.arange", "numpy.copy", "range", "direct_lingam.DirectLiNGAM._estimate_adjacency_matrix", "sklearn.utils.check_array", "numpy.where", "sklearn.preprocessing.scale", "K.append", "ValueError", "direct_lingam.DirectLiNGAM._search_causal_order_kernel", "direct_lingam.DirectLiNGAM._search_causal_order", "direct_lingam.DirectLiNGAM._residual"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.base._BaseLiNGAM._estimate_adjacency_matrix", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._search_causal_order_kernel", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM._search_causal_order", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._residual"], ["", "def", "fit", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        Fit the model to X.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where ``n_samples`` is the number of samples\n            and ``n_features`` is the number of features.\n\n        Returns\n        -------\n        self : object\n            Returns the instance itself.\n        \"\"\"", "\n", "# Check parameters", "\n", "X", "=", "check_array", "(", "X", ")", "\n", "n_features", "=", "X", ".", "shape", "[", "1", "]", "\n", "\n", "if", "self", ".", "_prior_knowledge", "is", "not", "None", ":", "\n", "            ", "self", ".", "_Aknw", "=", "check_array", "(", "self", ".", "_prior_knowledge", ")", "\n", "self", ".", "_Aknw", "=", "np", ".", "where", "(", "self", ".", "_Aknw", "<", "0", ",", "np", ".", "nan", ",", "self", ".", "_Aknw", ")", "\n", "if", "(", "n_features", ",", "n_features", ")", "!=", "self", ".", "_Aknw", ".", "shape", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "'The shape of prior knowledge must be (n_features, n_features)'", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "_Aknw", "=", "None", "\n", "\n", "# Causal discovery", "\n", "", "U", "=", "np", ".", "arange", "(", "n_features", ")", "\n", "K", "=", "[", "]", "\n", "X_", "=", "np", ".", "copy", "(", "X", ")", "\n", "if", "self", ".", "_measure", "==", "'kernel'", ":", "\n", "            ", "X_", "=", "scale", "(", "X_", ")", "\n", "\n", "", "for", "_", "in", "range", "(", "n_features", ")", ":", "\n", "            ", "if", "self", ".", "_measure", "==", "'kernel'", ":", "\n", "                ", "m", "=", "self", ".", "_search_causal_order_kernel", "(", "X_", ",", "U", ")", "\n", "", "else", ":", "\n", "                ", "m", "=", "self", ".", "_search_causal_order", "(", "X_", ",", "U", ")", "\n", "", "for", "i", "in", "U", ":", "\n", "                ", "if", "i", "!=", "m", ":", "\n", "                    ", "X_", "[", ":", ",", "i", "]", "=", "self", ".", "_residual", "(", "X_", "[", ":", ",", "i", "]", ",", "X_", "[", ":", ",", "m", "]", ")", "\n", "", "", "K", ".", "append", "(", "m", ")", "\n", "U", "=", "U", "[", "U", "!=", "m", "]", "\n", "\n", "", "self", ".", "_causal_order", "=", "K", "\n", "return", "self", ".", "_estimate_adjacency_matrix", "(", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._residual": [[158, 161], ["numpy.var", "numpy.cov"], "methods", ["None"], ["", "def", "_residual", "(", "self", ",", "xi", ",", "xj", ")", ":", "\n", "        ", "\"\"\"The residual when xi is regressed on xj.\"\"\"", "\n", "return", "xi", "-", "(", "np", ".", "cov", "(", "xi", ",", "xj", ")", "[", "0", ",", "1", "]", "/", "np", ".", "var", "(", "xj", ")", ")", "*", "xj", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._entropy": [[162, 170], ["numpy.mean", "numpy.log", "numpy.mean", "numpy.exp", "numpy.log", "numpy.cosh"], "methods", ["None"], ["", "def", "_entropy", "(", "self", ",", "u", ")", ":", "\n", "        ", "\"\"\"Calculate entropy using the maximum entropy approximations.\"\"\"", "\n", "k1", "=", "79.047", "\n", "k2", "=", "7.4129", "\n", "gamma", "=", "0.37457", "\n", "return", "(", "1", "+", "np", ".", "log", "(", "2", "*", "np", ".", "pi", ")", ")", "/", "2", "-", "k1", "*", "(", "np", ".", "mean", "(", "np", ".", "log", "(", "np", ".", "cosh", "(", "u", ")", ")", ")", "-", "gamma", ")", "**", "2", "-", "k2", "*", "(", "np", ".", "mean", "(", "u", "*", "np", ".", "exp", "(", "(", "-", "u", "**", "2", ")", "/", "2", ")", ")", ")", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._diff_mutual_info": [[171, 175], ["direct_lingam.DirectLiNGAM._entropy", "direct_lingam.DirectLiNGAM._entropy", "direct_lingam.DirectLiNGAM._entropy", "direct_lingam.DirectLiNGAM._entropy", "numpy.std", "numpy.std"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._entropy", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._entropy", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._entropy", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._entropy"], ["", "def", "_diff_mutual_info", "(", "self", ",", "xi_std", ",", "xj_std", ",", "ri_j", ",", "rj_i", ")", ":", "\n", "        ", "\"\"\"Calculate the difference of the mutual informations.\"\"\"", "\n", "return", "(", "self", ".", "_entropy", "(", "xj_std", ")", "+", "self", ".", "_entropy", "(", "ri_j", "/", "np", ".", "std", "(", "ri_j", ")", ")", ")", "-", "(", "self", ".", "_entropy", "(", "xi_std", ")", "+", "self", ".", "_entropy", "(", "rj_i", "/", "np", ".", "std", "(", "rj_i", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._search_candidate": [[176, 212], ["len", "[].sum", "Uc.append", "[].sum", "Vj.append", "numpy.nansum", "U_end.append", "direct_lingam.DirectLiNGAM._Aknw[].sum", "U_end.append", "set"], "methods", ["None"], ["", "def", "_search_candidate", "(", "self", ",", "U", ")", ":", "\n", "        ", "\"\"\" Search for candidate features \"\"\"", "\n", "# If no prior knowledge is specified, nothing to do.", "\n", "if", "self", ".", "_Aknw", "is", "None", ":", "\n", "            ", "return", "U", ",", "[", "]", "\n", "\n", "# Find exogenous features", "\n", "", "Uc", "=", "[", "]", "\n", "for", "j", "in", "U", ":", "\n", "            ", "index", "=", "U", "[", "U", "!=", "j", "]", "\n", "if", "self", ".", "_Aknw", "[", "j", "]", "[", "index", "]", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "Uc", ".", "append", "(", "j", ")", "\n", "\n", "# Find endogenous features, and then find candidate features", "\n", "", "", "if", "len", "(", "Uc", ")", "==", "0", ":", "\n", "            ", "U_end", "=", "[", "]", "\n", "for", "j", "in", "U", ":", "\n", "                ", "index", "=", "U", "[", "U", "!=", "j", "]", "\n", "if", "np", ".", "nansum", "(", "self", ".", "_Aknw", "[", "j", "]", "[", "index", "]", ")", ">", "0", ":", "\n", "                    ", "U_end", ".", "append", "(", "j", ")", "\n", "\n", "# Find sink features (original)", "\n", "", "", "for", "i", "in", "U", ":", "\n", "                ", "index", "=", "U", "[", "U", "!=", "i", "]", "\n", "if", "self", ".", "_Aknw", "[", "index", ",", "i", "]", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "U_end", ".", "append", "(", "i", ")", "\n", "", "", "Uc", "=", "[", "i", "for", "i", "in", "U", "if", "i", "not", "in", "set", "(", "U_end", ")", "]", "\n", "\n", "# make V^(j)", "\n", "", "Vj", "=", "[", "]", "\n", "for", "i", "in", "U", ":", "\n", "            ", "if", "i", "in", "Uc", ":", "\n", "                ", "continue", "\n", "", "if", "self", ".", "_Aknw", "[", "i", "]", "[", "Uc", "]", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "Vj", ".", "append", "(", "i", ")", "\n", "", "", "return", "Uc", ",", "Vj", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._search_causal_order": [[213, 231], ["direct_lingam.DirectLiNGAM._search_candidate", "len", "M_list.append", "numpy.argmax", "numpy.std", "numpy.std", "direct_lingam.DirectLiNGAM._residual", "direct_lingam.DirectLiNGAM._residual", "numpy.min", "numpy.mean", "numpy.mean", "direct_lingam.DirectLiNGAM._diff_mutual_info"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._search_candidate", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._residual", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._residual", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._diff_mutual_info"], ["", "def", "_search_causal_order", "(", "self", ",", "X", ",", "U", ")", ":", "\n", "        ", "\"\"\"Search the causal ordering.\"\"\"", "\n", "Uc", ",", "Vj", "=", "self", ".", "_search_candidate", "(", "U", ")", "\n", "if", "len", "(", "Uc", ")", "==", "1", ":", "\n", "            ", "return", "Uc", "[", "0", "]", "\n", "\n", "", "M_list", "=", "[", "]", "\n", "for", "i", "in", "Uc", ":", "\n", "            ", "M", "=", "0", "\n", "for", "j", "in", "U", ":", "\n", "                ", "if", "i", "!=", "j", ":", "\n", "                    ", "xi_std", "=", "(", "X", "[", ":", ",", "i", "]", "-", "np", ".", "mean", "(", "X", "[", ":", ",", "i", "]", ")", ")", "/", "np", ".", "std", "(", "X", "[", ":", ",", "i", "]", ")", "\n", "xj_std", "=", "(", "X", "[", ":", ",", "j", "]", "-", "np", ".", "mean", "(", "X", "[", ":", ",", "j", "]", ")", ")", "/", "np", ".", "std", "(", "X", "[", ":", ",", "j", "]", ")", "\n", "ri_j", "=", "xi_std", "if", "i", "in", "Vj", "and", "j", "in", "Uc", "else", "self", ".", "_residual", "(", "xi_std", ",", "xj_std", ")", "\n", "rj_i", "=", "xj_std", "if", "j", "in", "Vj", "and", "i", "in", "Uc", "else", "self", ".", "_residual", "(", "xj_std", ",", "xi_std", ")", "\n", "M", "+=", "np", ".", "min", "(", "[", "0", ",", "self", ".", "_diff_mutual_info", "(", "xi_std", ",", "xj_std", ",", "ri_j", ",", "rj_i", ")", "]", ")", "**", "2", "\n", "", "", "M_list", ".", "append", "(", "-", "1.0", "*", "M", ")", "\n", "", "return", "Uc", "[", "np", ".", "argmax", "(", "M_list", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._mutual_information": [[232, 252], ["len", "numpy.tile", "numpy.exp", "numpy.tile", "numpy.exp", "numpy.linalg.svd", "numpy.linalg.svd", "numpy.sum", "numpy.sum", "numpy.identity", "numpy.identity", "numpy.log", "numpy.log", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["", "def", "_mutual_information", "(", "self", ",", "x1", ",", "x2", ",", "param", ")", ":", "\n", "        ", "\"\"\"Calculate the mutual informations.\"\"\"", "\n", "kappa", ",", "sigma", "=", "param", "\n", "n", "=", "len", "(", "x1", ")", "\n", "X1", "=", "np", ".", "tile", "(", "x1", ",", "(", "n", ",", "1", ")", ")", "\n", "K1", "=", "np", ".", "exp", "(", "-", "1", "/", "(", "2", "*", "sigma", "**", "2", ")", "*", "(", "X1", "**", "2", "+", "X1", ".", "T", "**", "2", "-", "2", "*", "X1", "*", "X1", ".", "T", ")", ")", "\n", "X2", "=", "np", ".", "tile", "(", "x2", ",", "(", "n", ",", "1", ")", ")", "\n", "K2", "=", "np", ".", "exp", "(", "-", "1", "/", "(", "2", "*", "sigma", "**", "2", ")", "*", "(", "X2", "**", "2", "+", "X2", ".", "T", "**", "2", "-", "2", "*", "X2", "*", "X2", ".", "T", ")", ")", "\n", "\n", "tmp1", "=", "K1", "+", "n", "*", "kappa", "*", "np", ".", "identity", "(", "n", ")", "/", "2", "\n", "tmp2", "=", "K2", "+", "n", "*", "kappa", "*", "np", ".", "identity", "(", "n", ")", "/", "2", "\n", "K_kappa", "=", "np", ".", "r_", "[", "np", ".", "c_", "[", "tmp1", "@", "tmp1", ",", "K1", "@", "K2", "]", ",", "\n", "np", ".", "c_", "[", "K2", "@", "K1", ",", "tmp2", "@", "tmp2", "]", "]", "\n", "D_kappa", "=", "np", ".", "r_", "[", "np", ".", "c_", "[", "tmp1", "@", "tmp1", ",", "np", ".", "zeros", "(", "[", "n", ",", "n", "]", ")", "]", ",", "\n", "np", ".", "c_", "[", "np", ".", "zeros", "(", "[", "n", ",", "n", "]", ")", ",", "tmp2", "@", "tmp2", "]", "]", "\n", "\n", "sigma_K", "=", "np", ".", "linalg", ".", "svd", "(", "K_kappa", ",", "compute_uv", "=", "False", ")", "\n", "sigma_D", "=", "np", ".", "linalg", ".", "svd", "(", "D_kappa", ",", "compute_uv", "=", "False", ")", "\n", "\n", "return", "(", "-", "1", "/", "2", ")", "*", "(", "np", ".", "sum", "(", "np", ".", "log", "(", "sigma_K", ")", ")", "-", "np", ".", "sum", "(", "np", ".", "log", "(", "sigma_D", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._search_causal_order_kernel": [[253, 275], ["direct_lingam.DirectLiNGAM._search_candidate", "len", "Tkernels.append", "numpy.argmin", "direct_lingam.DirectLiNGAM._mutual_information", "direct_lingam.DirectLiNGAM._residual"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._search_candidate", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._mutual_information", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.direct_lingam.DirectLiNGAM._residual"], ["", "def", "_search_causal_order_kernel", "(", "self", ",", "X", ",", "U", ")", ":", "\n", "        ", "\"\"\"Search the causal ordering by kernel method.\"\"\"", "\n", "Uc", ",", "Vj", "=", "self", ".", "_search_candidate", "(", "U", ")", "\n", "if", "len", "(", "Uc", ")", "==", "1", ":", "\n", "            ", "return", "Uc", "[", "0", "]", "\n", "\n", "", "if", "X", ".", "shape", "[", "0", "]", ">", "1000", ":", "\n", "            ", "param", "=", "[", "2e-3", ",", "0.5", "]", "\n", "", "else", ":", "\n", "            ", "param", "=", "[", "2e-2", ",", "1.0", "]", "\n", "\n", "", "Tkernels", "=", "[", "]", "\n", "for", "j", "in", "Uc", ":", "\n", "            ", "Tkernel", "=", "0", "\n", "for", "i", "in", "U", ":", "\n", "                ", "if", "i", "!=", "j", ":", "\n", "                    ", "ri_j", "=", "X", "[", ":", ",", "i", "]", "if", "j", "in", "Vj", "and", "i", "in", "Uc", "else", "self", ".", "_residual", "(", "\n", "X", "[", ":", ",", "i", "]", ",", "X", "[", ":", ",", "j", "]", ")", "\n", "Tkernel", "+=", "self", ".", "_mutual_information", "(", "X", "[", ":", ",", "j", "]", ",", "ri_j", ",", "param", ")", "\n", "", "", "Tkernels", ".", "append", "(", "Tkernel", ")", "\n", "\n", "", "return", "Uc", "[", "np", ".", "argmin", "(", "Tkernels", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.__init__": [[67, 74], ["utils.base._BaseLiNGAM.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "random_state", "=", "None", ",", "max_iter", "=", "1000", ",", "thresh", "=", "0.3", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_random_state", "=", "random_state", "\n", "self", ".", "_max_iter", "=", "max_iter", "\n", "self", ".", "_thresh", "=", "thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.learn": [[75, 97], ["castle.common.Tensor", "ica_lingam.ICALiNGAM.fit", "castle.common.Tensor", "castle.common.Tensor", "abs"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit"], ["", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Set up and run the ICALiNGAM algorithm.\n\n        ----------\n        data: castle.Tensor or numpy.ndarray\n            The castle.Tensor or numpy.ndarray format data you want to learn.\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        \"\"\"", "\n", "X", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "self", ".", "fit", "(", "X", ")", "\n", "\n", "weight_causal_matrix", "=", "self", ".", "adjacency_matrix_", ".", "T", "\n", "self", ".", "weight_causal_matrix", "=", "Tensor", "(", "weight_causal_matrix", ",", "\n", "index", "=", "X", ".", "columns", ",", "columns", "=", "X", ".", "columns", ")", "\n", "\n", "causal_matrix", "=", "(", "abs", "(", "self", ".", "adjacency_matrix_", ")", ">", "self", ".", "_thresh", ")", ".", "astype", "(", "int", ")", ".", "T", "\n", "self", ".", "causal_matrix", "=", "Tensor", "(", "causal_matrix", ",", "\n", "index", "=", "X", ".", "columns", ",", "columns", "=", "X", ".", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit": [[98, 136], ["sklearn.utils.check_array", "sklearn.decomposition.FastICA", "sklearn.decomposition.FastICA.fit", "scipy.optimize.linear_sum_assignment", "numpy.zeros_like", "ica_lingam.ICALiNGAM._estimate_causal_order", "ica_lingam.ICALiNGAM._estimate_adjacency_matrix", "numpy.diag", "numpy.eye", "numpy.abs", "len"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM._estimate_causal_order", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.base._BaseLiNGAM._estimate_adjacency_matrix"], ["", "def", "fit", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        Fit the model to X.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Training data, where ``n_samples`` is the number of samples\n            and ``n_features`` is the number of features.\n\n        Returns\n        -------\n        self : object\n            Returns the instance of self.\n        \"\"\"", "\n", "X", "=", "check_array", "(", "X", ")", "\n", "\n", "# obtain a unmixing matrix from the given data", "\n", "ica", "=", "FastICA", "(", "max_iter", "=", "self", ".", "_max_iter", ",", "random_state", "=", "self", ".", "_random_state", ")", "\n", "ica", ".", "fit", "(", "X", ")", "\n", "W_ica", "=", "ica", ".", "components_", "\n", "\n", "# obtain a permuted W_ica", "\n", "_", ",", "col_index", "=", "linear_sum_assignment", "(", "1", "/", "np", ".", "abs", "(", "W_ica", ")", ")", "\n", "PW_ica", "=", "np", ".", "zeros_like", "(", "W_ica", ")", "\n", "PW_ica", "[", "col_index", "]", "=", "W_ica", "\n", "\n", "# obtain a vector to scale", "\n", "D", "=", "np", ".", "diag", "(", "PW_ica", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "\n", "# estimate an adjacency matrix", "\n", "W_estimate", "=", "PW_ica", "/", "D", "\n", "B_estimate", "=", "np", ".", "eye", "(", "len", "(", "W_estimate", ")", ")", "-", "W_estimate", "\n", "\n", "causal_order", "=", "self", ".", "_estimate_causal_order", "(", "B_estimate", ")", "\n", "self", ".", "_causal_order", "=", "causal_order", "\n", "\n", "return", "self", ".", "_estimate_adjacency_matrix", "(", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM._search_causal_order": [[137, 176], ["numpy.arange", "len", "causal_order.append", "numpy.delete", "numpy.delete", "len", "numpy.where", "len", "numpy.arange", "len", "numpy.sum", "numpy.abs"], "methods", ["None"], ["", "def", "_search_causal_order", "(", "self", ",", "matrix", ")", ":", "\n", "        ", "\"\"\"\n        Obtain a causal order from the given matrix strictly.\n\n        Parameters\n        ----------\n        matrix : array-like, shape (n_features, n_samples)\n            Target matrix.\n\n        Return\n        ------\n        causal_order : array, shape [n_features, ]\n            A causal order of the given matrix on success, None otherwise.\n        \"\"\"", "\n", "causal_order", "=", "[", "]", "\n", "\n", "row_num", "=", "matrix", ".", "shape", "[", "0", "]", "\n", "original_index", "=", "np", ".", "arange", "(", "row_num", ")", "\n", "\n", "while", "0", "<", "len", "(", "matrix", ")", ":", "\n", "# find a row all of which elements are zero", "\n", "            ", "row_index_list", "=", "np", ".", "where", "(", "np", ".", "sum", "(", "np", ".", "abs", "(", "matrix", ")", ",", "axis", "=", "1", ")", "==", "0", ")", "[", "0", "]", "\n", "if", "len", "(", "row_index_list", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "target_index", "=", "row_index_list", "[", "0", "]", "\n", "\n", "# append i to the end of the list", "\n", "causal_order", ".", "append", "(", "original_index", "[", "target_index", "]", ")", "\n", "original_index", "=", "np", ".", "delete", "(", "original_index", ",", "target_index", ",", "axis", "=", "0", ")", "\n", "\n", "# remove the i-th row and the i-th column from matrix", "\n", "mask", "=", "np", ".", "delete", "(", "np", ".", "arange", "(", "len", "(", "matrix", ")", ")", ",", "target_index", ",", "axis", "=", "0", ")", "\n", "matrix", "=", "matrix", "[", "mask", "]", "[", ":", ",", "mask", "]", "\n", "\n", "", "if", "len", "(", "causal_order", ")", "!=", "row_num", ":", "\n", "            ", "causal_order", "=", "None", "\n", "\n", "", "return", "causal_order", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM._estimate_causal_order": [[177, 209], ["numpy.argsort", "int", "numpy.abs", "numpy.vstack", "ica_lingam.ICALiNGAM._search_causal_order", "numpy.unravel_index"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM._search_causal_order"], ["", "def", "_estimate_causal_order", "(", "self", ",", "matrix", ")", ":", "\n", "        ", "\"\"\"\n        Obtain a lower triangular from the given matrix approximately.\n\n        Parameters\n        ----------\n        matrix : array-like, shape (n_features, n_samples)\n            Target matrix.\n        \n        Return\n        ------\n        causal_order : array, shape [n_features, ]\n            A causal order of the given matrix on success, None otherwise.\n        \"\"\"", "\n", "causal_order", "=", "None", "\n", "\n", "# set the m(m + 1)/2 smallest(in absolute value) elements of the matrix to zero", "\n", "pos_list", "=", "np", ".", "argsort", "(", "np", ".", "abs", "(", "matrix", ")", ",", "axis", "=", "None", ")", "\n", "pos_list", "=", "np", ".", "vstack", "(", "np", ".", "unravel_index", "(", "pos_list", ",", "matrix", ".", "shape", ")", ")", ".", "T", "\n", "initial_zero_num", "=", "int", "(", "matrix", ".", "shape", "[", "0", "]", "*", "(", "matrix", ".", "shape", "[", "0", "]", "+", "1", ")", "/", "2", ")", "\n", "for", "i", ",", "j", "in", "pos_list", "[", ":", "initial_zero_num", "]", ":", "\n", "            ", "matrix", "[", "i", ",", "j", "]", "=", "0", "\n", "\n", "", "for", "i", ",", "j", "in", "pos_list", "[", "initial_zero_num", ":", "]", ":", "\n", "# set the smallest(in absolute value) element to zero", "\n", "            ", "matrix", "[", "i", ",", "j", "]", "=", "0", "\n", "\n", "causal_order", "=", "self", ".", "_search_causal_order", "(", "matrix", ")", "\n", "if", "causal_order", "is", "not", "None", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "causal_order", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.anm._anm.GPR.__init__": [[124, 127], ["object.__init__", "sklearn.gaussian_process.GaussianProcessRegressor"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "GPR", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "regressor", "=", "GaussianProcessRegressor", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.anm._anm.GPR.estimate": [[128, 148], ["_anm.GPR.regressor.fit", "_anm.GPR.regressor.predict"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.lingam.ica_lingam.ICALiNGAM.fit", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.frame._reward.GPRMine.predict"], ["", "def", "estimate", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "\"\"\"Fit Gaussian process regression model and predict x.\n\n        Parameters\n        ----------\n        x : array\n            Variable seen as cause\n        y: array\n            Variable seen as effect\n\n        Returns\n        -------\n        y_predict: array\n            regression predict values of x\n        \"\"\"", "\n", "\n", "self", ".", "regressor", ".", "fit", "(", "x", ",", "y", ")", "\n", "y_predict", "=", "self", ".", "regressor", ".", "predict", "(", "x", ")", "\n", "\n", "return", "y_predict", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.anm._anm.ANMNonlinear.__init__": [[206, 209], ["castle.common.BaseLearner.__init__"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["def", "__init__", "(", "self", ",", "alpha", "=", "0.05", ")", ":", "\n", "        ", "super", "(", "ANMNonlinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.anm._anm.ANMNonlinear.learn": [[210, 258], ["_anm.GPR", "castle.common.Tensor", "castle.common.Tensor", "itertools.combinations", "numpy.zeros", "range", "data[].reshape", "data[].reshape", "test_method", "_anm.ANMNonlinear.anm_estimate", "_anm.ANMNonlinear.anm_estimate"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.anm._anm.ANMNonlinear.anm_estimate", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.anm._anm.ANMNonlinear.anm_estimate"], ["", "def", "learn", "(", "self", ",", "data", ",", "columns", "=", "None", ",", "regressor", "=", "GPR", "(", ")", ",", "test_method", "=", "hsic_test", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Set up and run the ANM_Nonlinear algorithm.\n\n        Parameters\n        ----------\n        data: numpy.ndarray or Tensor\n            Training data.\n        columns : Index or array-like\n            Column labels to use for resulting tensor. Will default to\n            RangeIndex (0, 1, 2, ..., n) if no column labels are provided.\n        regressor: Class\n            Nonlinear regression estimator, if not provided, it is GPR.\n            If user defined, must implement `estimate` method. such as :\n                `regressor.estimate(x, y)`\n        test_method: callable, default test_method\n            independence test method, if not provided, it is HSIC.\n            If user defined, must accept three arguments--x, y and keyword\n            argument--alpha. such as :\n                `test_method(x, y, alpha=0.05)`\n        \"\"\"", "\n", "\n", "self", ".", "regressor", "=", "regressor", "\n", "\n", "# create learning model and ground truth model", "\n", "data", "=", "Tensor", "(", "data", ",", "columns", "=", "columns", ")", "\n", "\n", "node_num", "=", "data", ".", "shape", "[", "1", "]", "\n", "self", ".", "causal_matrix", "=", "Tensor", "(", "np", ".", "zeros", "(", "(", "node_num", ",", "node_num", ")", ")", ",", "\n", "index", "=", "data", ".", "columns", ",", "\n", "columns", "=", "data", ".", "columns", ")", "\n", "\n", "for", "i", ",", "j", "in", "combinations", "(", "range", "(", "node_num", ")", ",", "2", ")", ":", "\n", "            ", "x", "=", "data", "[", ":", ",", "i", "]", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "y", "=", "data", "[", ":", ",", "j", "]", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "flag", "=", "test_method", "(", "x", ",", "y", ",", "alpha", "=", "self", ".", "alpha", ")", "\n", "if", "flag", "==", "1", ":", "\n", "                ", "continue", "\n", "# test x-->y", "\n", "", "flag", "=", "self", ".", "anm_estimate", "(", "x", ",", "y", ",", "regressor", "=", "regressor", ",", "\n", "test_method", "=", "test_method", ")", "\n", "if", "flag", ":", "\n", "                ", "self", ".", "causal_matrix", "[", "i", ",", "j", "]", "=", "1", "\n", "# test y-->x", "\n", "", "flag", "=", "self", ".", "anm_estimate", "(", "y", ",", "x", ",", "regressor", "=", "regressor", ",", "\n", "test_method", "=", "test_method", ")", "\n", "if", "flag", ":", "\n", "                ", "self", ".", "causal_matrix", "[", "j", ",", "i", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.anm._anm.ANMNonlinear.anm_estimate": [[259, 302], ["_anm.GPR", "sklearn.preprocessing.scale().reshape", "sklearn.preprocessing.scale().reshape", "regressor.estimate", "test_method", "sklearn.preprocessing.scale", "sklearn.preprocessing.scale"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.anm._anm.GPR.estimate"], ["", "", "", "def", "anm_estimate", "(", "self", ",", "x", ",", "y", ",", "regressor", "=", "GPR", "(", ")", ",", "test_method", "=", "hsic_test", ")", ":", "\n", "        ", "\"\"\"Compute the fitness score of the ANM model in the x->y direction.\n\n        Parameters\n        ----------\n        x: array\n            Variable seen as cause\n        y: array\n            Variable seen as effect\n        regressor: Class\n            Nonlinear regression estimator, if not provided, it is GPR.\n            If user defined, must implement `estimate` method. such as :\n                `regressor.estimate(x, y)`\n        test_method: callable, default test_method\n            independence test method, if not provided, it is HSIC.\n            If user defined, must accept three arguments--x, y and keyword\n            argument--alpha. such as :\n                `test_method(x, y, alpha=0.05)`\n\n        Returns\n        -------\n        out: int, 0 or 1\n            If 1, residuals n is independent of x, then accept x --> y\n            If 0, residuals n is not independent of x, then reject x --> y\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> from castle.algorithms.anm import ANMNonlinear\n        >>> np.random.seed(1)\n        >>> x = np.random.rand(500, 2)\n        >>> anm = ANMNonlinear(alpha=0.05)\n        >>> print(anm.anm_estimate(x[:, [0]], x[:, [1]]))\n        1\n        \"\"\"", "\n", "\n", "x", "=", "scale", "(", "x", ")", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "y", "=", "scale", "(", "y", ")", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "\n", "y_predict", "=", "regressor", ".", "estimate", "(", "x", ",", "y", ")", "\n", "flag", "=", "test_method", "(", "y", "-", "y_predict", ",", "x", ",", "alpha", "=", "self", ".", "alpha", ")", "\n", "\n", "return", "flag", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.competition.submission.transform": [[22, 70], ["pandas.DataFrame().to_csv", "logging.info", "os.path.join", "range", "mat.astype", "mat.astype.flatten().tolist", "submission.transform.arr_to_string"], "function", ["None"], ["def", "transform", "(", "source", ",", "target", ",", "phase", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    This function is used to generate the submission file for the causality competition:\n    https://competition.huaweicloud.com/information/1000041487/circumstance\n    \n    Parameters\n    ----------\n    source: str\n        The source directory used to store all the .npy files.\n    target: str\n        The target directory/file used to store the submission file.\n    phase: int, {1, 2}\n        In phase 1, the number of .npy files is 20; in phase 2, the number is 24.\n    \"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "splitext", "(", "target", ")", "[", "1", "]", "==", "'.csv'", ":", "\n", "        ", "target", "=", "os", ".", "path", ".", "join", "(", "target", ",", "'submit.csv'", ")", "\n", "\n", "", "arrs", "=", "[", "]", "\n", "\n", "if", "phase", "==", "1", ":", "\n", "        ", "for", "i", "in", "range", "(", "1", ",", "21", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "arrs", ".", "append", "(", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "source", ",", "str", "(", "i", ")", "+", "'.npy'", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Cannot find '", "+", "str", "(", "i", ")", "+", "'.npy file or the file format is incorrect!'", ")", "\n", "", "", "", "elif", "phase", "==", "2", ":", "\n", "        ", "for", "i", "in", "range", "(", "1", ",", "25", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "arrs", ".", "append", "(", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "source", ",", "str", "(", "i", ")", "+", "'.npy'", ")", ")", ")", "\n", "", "except", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Cannot find '", "+", "str", "(", "i", ")", "+", "'.npy file or the file format is incorrect!'", ")", "\n", "\n", "", "", "", "def", "arr_to_string", "(", "mat", ")", ":", "\n", "        ", "mat_int", "=", "mat", ".", "astype", "(", "int", ")", "\n", "mat_flatten", "=", "mat_int", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "for", "m", "in", "mat_flatten", ":", "\n", "            ", "if", "m", "not", "in", "[", "0", ",", "1", "]", ":", "\n", "                ", "raise", "TypeError", "(", "'Any element in a numpy array is supposed to be 0 or 1.'", ")", "\n", "", "", "mat_str", "=", "' '", ".", "join", "(", "map", "(", "str", ",", "mat_flatten", ")", ")", "\n", "return", "mat_str", "\n", "\n", "", "arrs_str", "=", "[", "arr_to_string", "(", "arr", ")", "for", "arr", "in", "arrs", "]", "\n", "pd", ".", "DataFrame", "(", "arrs_str", ")", ".", "to_csv", "(", "target", ",", "index", "=", "False", ")", "\n", "\n", "logging", ".", "info", "(", "'Successfully generated the submission file: '", "+", "target", "+", "'.'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.backend.__init__.get_backend_name": [[26, 41], ["os.getenv", "TypeError", "logging.info"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.MetricsDAG.__init__": [[48, 60], ["copy.deepcopy", "copy.deepcopy", "evaluation.MetricsDAG._count_accuracy", "isinstance", "TypeError", "isinstance", "TypeError"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.MetricsDAG._count_accuracy"], ["def", "__init__", "(", "self", ",", "B_est", ",", "B_true", ")", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "B_est", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Input B_est is not numpy.ndarray!\"", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "B_true", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Input B_true is not numpy.ndarray!\"", ")", "\n", "\n", "", "self", ".", "B_est", "=", "copy", ".", "deepcopy", "(", "B_est", ")", "\n", "self", ".", "B_true", "=", "copy", ".", "deepcopy", "(", "B_true", ")", "\n", "\n", "self", ".", "metrics", "=", "MetricsDAG", ".", "_count_accuracy", "(", "self", ".", "B_est", ",", "self", ".", "B_true", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.MetricsDAG._count_accuracy": [[61, 172], ["range", "range", "numpy.flatnonzero", "numpy.flatnonzero", "numpy.flatnonzero", "numpy.flatnonzero", "numpy.concatenate", "numpy.intersect1d", "numpy.intersect1d", "numpy.concatenate", "numpy.setdiff1d", "numpy.setdiff1d", "numpy.concatenate", "numpy.setdiff1d", "numpy.intersect1d", "numpy.flatnonzero", "numpy.flatnonzero", "numpy.setdiff1d", "numpy.setdiff1d", "range", "pandas.DataFrame", "pandas.DataFrame", "evaluation.MetricsDAG._cal_gscore", "evaluation.MetricsDAG._cal_precision_recall", "len", "len", "range", "len", "len", "len", "float", "max", "float", "max", "float", "max", "numpy.tril", "numpy.tril", "len", "len", "range", "round", "len", "ValueError", "ValueError", "ValueError", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.MetricsDAG._cal_gscore", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.MetricsDAG._cal_precision_recall"], ["", "@", "staticmethod", "\n", "def", "_count_accuracy", "(", "B_est", ",", "B_true", ",", "decimal_num", "=", "4", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        B_est: np.ndarray\n            [d, d] estimate, {0, 1, -1}, -1 is undirected edge in CPDAG.\n        B_true: np.ndarray\n            [d, d] ground truth graph, {0, 1}.\n        decimal_num: int\n            Result decimal numbers.\n\n        Return\n        ------\n        metrics: dict\n            fdr: float\n                (reverse + FP) / (TP + FP)\n            tpr: float\n                TP/(TP + FN)\n            fpr: float\n                (reverse + FP) / (TN + FP)\n            shd: int\n                undirected extra + undirected missing + reverse\n            nnz: int\n                TP + FP\n            precision: float\n                TP/(TP + FP)\n            recall: float\n                TP/(TP + FN)\n            F1: float\n                2*(recall*precision)/(recall+precision)\n            gscore: float\n                max(0, (TP-FP))/(TP+FN), A score ranges from 0 to 1\n        \"\"\"", "\n", "\n", "# trans diagonal element into 0", "\n", "for", "i", "in", "range", "(", "len", "(", "B_est", ")", ")", ":", "\n", "            ", "if", "B_est", "[", "i", ",", "i", "]", "==", "1", ":", "\n", "                ", "B_est", "[", "i", ",", "i", "]", "=", "0", "\n", "", "if", "B_true", "[", "i", ",", "i", "]", "==", "1", ":", "\n", "                ", "B_true", "[", "i", ",", "i", "]", "=", "0", "\n", "\n", "# trans cpdag [0, 1] to [-1, 0, 1], -1 is undirected edge in CPDAG", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "B_est", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "B_est", "[", "i", "]", ")", ")", ":", "\n", "                ", "if", "B_est", "[", "i", ",", "j", "]", "==", "B_est", "[", "j", ",", "i", "]", "==", "1", ":", "\n", "                    ", "B_est", "[", "i", ",", "j", "]", "=", "-", "1", "\n", "B_est", "[", "j", ",", "i", "]", "=", "0", "\n", "\n", "", "", "", "if", "(", "B_est", "==", "-", "1", ")", ".", "any", "(", ")", ":", "# cpdag", "\n", "            ", "if", "not", "(", "(", "B_est", "==", "0", ")", "|", "(", "B_est", "==", "1", ")", "|", "(", "B_est", "==", "-", "1", ")", ")", ".", "all", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'B_est should take value in {0,1,-1}'", ")", "\n", "", "if", "(", "(", "B_est", "==", "-", "1", ")", "&", "(", "B_est", ".", "T", "==", "-", "1", ")", ")", ".", "any", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'undirected edge should only appear once'", ")", "\n", "", "", "else", ":", "# dag", "\n", "            ", "if", "not", "(", "(", "B_est", "==", "0", ")", "|", "(", "B_est", "==", "1", ")", ")", ".", "all", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'B_est should take value in {0,1}'", ")", "\n", "# if not is_dag(B_est):", "\n", "#     raise ValueError('B_est should be a DAG')", "\n", "", "", "d", "=", "B_true", ".", "shape", "[", "0", "]", "\n", "\n", "# linear index of nonzeros", "\n", "pred_und", "=", "np", ".", "flatnonzero", "(", "B_est", "==", "-", "1", ")", "\n", "pred", "=", "np", ".", "flatnonzero", "(", "B_est", "==", "1", ")", "\n", "cond", "=", "np", ".", "flatnonzero", "(", "B_true", ")", "\n", "cond_reversed", "=", "np", ".", "flatnonzero", "(", "B_true", ".", "T", ")", "\n", "cond_skeleton", "=", "np", ".", "concatenate", "(", "[", "cond", ",", "cond_reversed", "]", ")", "\n", "# true pos", "\n", "true_pos", "=", "np", ".", "intersect1d", "(", "pred", ",", "cond", ",", "assume_unique", "=", "True", ")", "\n", "# treat undirected edge favorably", "\n", "true_pos_und", "=", "np", ".", "intersect1d", "(", "pred_und", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "true_pos", "=", "np", ".", "concatenate", "(", "[", "true_pos", ",", "true_pos_und", "]", ")", "\n", "# false pos", "\n", "false_pos", "=", "np", ".", "setdiff1d", "(", "pred", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "false_pos_und", "=", "np", ".", "setdiff1d", "(", "pred_und", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "false_pos", "=", "np", ".", "concatenate", "(", "[", "false_pos", ",", "false_pos_und", "]", ")", "\n", "# reverse", "\n", "extra", "=", "np", ".", "setdiff1d", "(", "pred", ",", "cond", ",", "assume_unique", "=", "True", ")", "\n", "reverse", "=", "np", ".", "intersect1d", "(", "extra", ",", "cond_reversed", ",", "assume_unique", "=", "True", ")", "\n", "# compute ratio", "\n", "pred_size", "=", "len", "(", "pred", ")", "+", "len", "(", "pred_und", ")", "\n", "cond_neg_size", "=", "0.5", "*", "d", "*", "(", "d", "-", "1", ")", "-", "len", "(", "cond", ")", "\n", "fdr", "=", "float", "(", "len", "(", "reverse", ")", "+", "len", "(", "false_pos", ")", ")", "/", "max", "(", "pred_size", ",", "1", ")", "\n", "tpr", "=", "float", "(", "len", "(", "true_pos", ")", ")", "/", "max", "(", "len", "(", "cond", ")", ",", "1", ")", "\n", "fpr", "=", "float", "(", "len", "(", "reverse", ")", "+", "len", "(", "false_pos", ")", ")", "/", "max", "(", "cond_neg_size", ",", "1", ")", "\n", "# structural hamming distance", "\n", "pred_lower", "=", "np", ".", "flatnonzero", "(", "np", ".", "tril", "(", "B_est", "+", "B_est", ".", "T", ")", ")", "\n", "cond_lower", "=", "np", ".", "flatnonzero", "(", "np", ".", "tril", "(", "B_true", "+", "B_true", ".", "T", ")", ")", "\n", "extra_lower", "=", "np", ".", "setdiff1d", "(", "pred_lower", ",", "cond_lower", ",", "assume_unique", "=", "True", ")", "\n", "missing_lower", "=", "np", ".", "setdiff1d", "(", "cond_lower", ",", "pred_lower", ",", "assume_unique", "=", "True", ")", "\n", "shd", "=", "len", "(", "extra_lower", ")", "+", "len", "(", "missing_lower", ")", "+", "len", "(", "reverse", ")", "\n", "\n", "# trans cpdag [-1, 0, 1] to [0, 1], -1 is undirected edge in CPDAG", "\n", "for", "i", "in", "range", "(", "len", "(", "B_est", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "B_est", "[", "i", "]", ")", ")", ":", "\n", "                ", "if", "B_est", "[", "i", ",", "j", "]", "==", "-", "1", ":", "\n", "                    ", "B_est", "[", "i", ",", "j", "]", "=", "1", "\n", "B_est", "[", "j", ",", "i", "]", "=", "1", "\n", "\n", "", "", "", "W_p", "=", "pd", ".", "DataFrame", "(", "B_est", ")", "\n", "W_true", "=", "pd", ".", "DataFrame", "(", "B_true", ")", "\n", "\n", "gscore", "=", "MetricsDAG", ".", "_cal_gscore", "(", "W_p", ",", "W_true", ")", "\n", "precision", ",", "recall", ",", "F1", "=", "MetricsDAG", ".", "_cal_precision_recall", "(", "W_p", ",", "W_true", ")", "\n", "\n", "mt", "=", "{", "'fdr'", ":", "fdr", ",", "'tpr'", ":", "tpr", ",", "'fpr'", ":", "fpr", ",", "'shd'", ":", "shd", ",", "'nnz'", ":", "pred_size", ",", "\n", "'precision'", ":", "precision", ",", "'recall'", ":", "recall", ",", "'F1'", ":", "F1", ",", "'gscore'", ":", "gscore", "}", "\n", "for", "i", "in", "mt", ":", "\n", "            ", "mt", "[", "i", "]", "=", "round", "(", "mt", "[", "i", "]", ",", "decimal_num", ")", "\n", "\n", "", "return", "mt", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.MetricsDAG._cal_gscore": [[173, 199], ["W_true.sum().sum", "numpy.max", "W_true.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_cal_gscore", "(", "W_p", ",", "W_true", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        W_p: pd.DataDrame\n            [d, d] estimate, {0, 1, -1}, -1 is undirected edge in CPDAG.\n        W_true: pd.DataDrame\n            [d, d] ground truth graph, {0, 1}.\n        \n        Return\n        ------\n        score: float\n            max(0, (TP-FP))/(TP+FN), A score ranges from 0 to 1\n        \"\"\"", "\n", "\n", "num_true", "=", "W_true", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "assert", "num_true", "!=", "0", "\n", "\n", "# true_positives", "\n", "num_tp", "=", "(", "W_p", "+", "W_true", ")", ".", "applymap", "(", "lambda", "elem", ":", "1", "if", "elem", "==", "2", "else", "0", ")", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "# False Positives + Reversed Edges", "\n", "num_fn_r", "=", "(", "W_p", "-", "W_true", ")", ".", "applymap", "(", "lambda", "elem", ":", "1", "if", "elem", "==", "1", "else", "0", ")", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "score", "=", "np", ".", "max", "(", "(", "num_tp", "-", "num_fn_r", ",", "0", ")", ")", "/", "num_true", "\n", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.MetricsDAG._cal_precision_recall": [[200, 229], ["W_p.sum().sum", "W_true.sum().sum", "W_p.sum", "W_true.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_cal_precision_recall", "(", "W_p", ",", "W_true", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        W_p: pd.DataDrame\n            [d, d] estimate, {0, 1, -1}, -1 is undirected edge in CPDAG.\n        W_true: pd.DataDrame\n            [d, d] ground truth graph, {0, 1}.\n        \n        Return\n        ------\n        precision: float\n            TP/(TP + FP)\n        recall: float\n            TP/(TP + FN)\n        F1: float\n            2*(recall*precision)/(recall+precision)\n        \"\"\"", "\n", "\n", "assert", "(", "W_p", ".", "shape", "==", "W_true", ".", "shape", "and", "W_p", ".", "shape", "[", "0", "]", "==", "W_p", ".", "shape", "[", "1", "]", ")", "\n", "TP", "=", "(", "W_p", "+", "W_true", ")", ".", "applymap", "(", "lambda", "elem", ":", "1", "if", "elem", "==", "2", "else", "0", ")", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "TP_FP", "=", "W_p", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "TP_FN", "=", "W_true", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "precision", "=", "TP", "/", "TP_FP", "\n", "recall", "=", "TP", "/", "TP_FN", "\n", "F1", "=", "2", "*", "(", "recall", "*", "precision", ")", "/", "(", "recall", "+", "precision", ")", "\n", "\n", "return", "precision", ",", "recall", ",", "F1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.__init__": [[34, 38], ["web.common.utils.update_inline_datasets"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.update_inline_datasets"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.get_label_checkbox": [[39, 56], ["web.models.task_db.TaskApi", "web.models.task_db.TaskApi.get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_label"], ["\n", "\n", "def", "__init__", "(", "self", ",", "B_est", ",", "B_true", ")", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "B_est", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Input B_est is not numpy.ndarray!\"", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "B_true", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Input B_true is not numpy.ndarray!\"", ")", "\n", "\n", "", "self", ".", "B_est", "=", "copy", ".", "deepcopy", "(", "B_est", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.get_task_evaluation_metrics": [[57, 78], ["web.models.task_db.TaskApi", "web.models.task_db.TaskApi.get_performance", "list", "web.models.task_db.TaskApi.get_performance.keys"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_performance"], ["self", ".", "B_true", "=", "copy", ".", "deepcopy", "(", "B_true", ")", "\n", "\n", "self", ".", "metrics", "=", "MetricsDAG", ".", "_count_accuracy", "(", "self", ".", "B_est", ",", "self", ".", "B_true", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_count_accuracy", "(", "B_est", ",", "B_true", ",", "decimal_num", "=", "4", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.get_evaluation_metrics": [[79, 98], ["evaluation.Evaluation.get_task_evaluation_metrics", "list"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.get_task_evaluation_metrics"], ["\n", "\n", "# trans diagonal element into 0", "\n", "for", "i", "in", "range", "(", "len", "(", "B_est", ")", ")", ":", "\n", "            ", "if", "B_est", "[", "i", ",", "i", "]", "==", "1", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.get_task_builtin_label": [[99, 120], ["web.models.task_db.TaskApi", "web.models.task_db.TaskApi.get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_label"], ["                ", "B_est", "[", "i", ",", "i", "]", "=", "0", "\n", "", "if", "B_true", "[", "i", ",", "i", "]", "==", "1", ":", "\n", "                ", "B_true", "[", "i", ",", "i", "]", "=", "0", "\n", "\n", "# trans cpdag [0, 1] to [-1, 0, 1], -1 is undirected edge in CPDAG", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "B_est", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "B_est", "[", "i", "]", ")", ")", ":", "\n", "                ", "if", "B_est", "[", "i", ",", "j", "]", "==", "B_est", "[", "j", ",", "i", "]", "==", "1", ":", "\n", "                    ", "B_est", "[", "i", ",", "j", "]", "=", "-", "1", "\n", "B_est", "[", "j", ",", "i", "]", "=", "0", "\n", "\n", "", "", "", "if", "(", "B_est", "==", "-", "1", ")", ".", "any", "(", ")", ":", "# cpdag", "\n", "            ", "if", "not", "(", "(", "B_est", "==", "0", ")", "|", "(", "B_est", "==", "1", ")", "|", "(", "B_est", "==", "-", "1", ")", ")", ".", "all", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'B_est should take value in {0,1,-1}'", ")", "\n", "", "if", "(", "(", "B_est", "==", "-", "1", ")", "&", "(", "B_est", ".", "T", "==", "-", "1", ")", ")", ".", "any", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'undirected edge should only appear once'", ")", "\n", "", "", "else", ":", "# dag", "\n", "            ", "if", "not", "(", "(", "B_est", "==", "0", ")", "|", "(", "B_est", "==", "1", ")", ")", ".", "all", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'B_est should take value in {0,1}'", ")", "\n", "# if not is_dag(B_est):", "\n", "#     raise ValueError('B_est should be a DAG')", "\n", "", "", "d", "=", "B_true", ".", "shape", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.get_builtin_label": [[121, 136], ["evaluation.Evaluation.get_task_builtin_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.get_task_builtin_label"], ["\n", "# linear index of nonzeros", "\n", "pred_und", "=", "np", ".", "flatnonzero", "(", "B_est", "==", "-", "1", ")", "\n", "pred", "=", "np", ".", "flatnonzero", "(", "B_est", "==", "1", ")", "\n", "cond", "=", "np", ".", "flatnonzero", "(", "B_true", ")", "\n", "cond_reversed", "=", "np", ".", "flatnonzero", "(", "B_true", ".", "T", ")", "\n", "cond_skeleton", "=", "np", ".", "concatenate", "(", "[", "cond", ",", "cond_reversed", "]", ")", "\n", "# true pos", "\n", "true_pos", "=", "np", ".", "intersect1d", "(", "pred", ",", "cond", ",", "assume_unique", "=", "True", ")", "\n", "# treat undirected edge favorably", "\n", "true_pos_und", "=", "np", ".", "intersect1d", "(", "pred_und", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "true_pos", "=", "np", ".", "concatenate", "(", "[", "true_pos", ",", "true_pos_und", "]", ")", "\n", "# false pos", "\n", "false_pos", "=", "np", ".", "setdiff1d", "(", "pred", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "false_pos_und", "=", "np", ".", "setdiff1d", "(", "pred_und", ",", "cond_skeleton", ",", "assume_unique", "=", "True", ")", "\n", "false_pos", "=", "np", ".", "concatenate", "(", "[", "false_pos", ",", "false_pos_und", "]", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.get_task_customize_label": [[137, 157], ["web.models.task_db.TaskApi", "web.models.task_db.TaskApi.get_label"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_label"], ["# reverse", "\n", "extra", "=", "np", ".", "setdiff1d", "(", "pred", ",", "cond", ",", "assume_unique", "=", "True", ")", "\n", "reverse", "=", "np", ".", "intersect1d", "(", "extra", ",", "cond_reversed", ",", "assume_unique", "=", "True", ")", "\n", "# compute ratio", "\n", "pred_size", "=", "len", "(", "pred", ")", "+", "len", "(", "pred_und", ")", "\n", "cond_neg_size", "=", "0.5", "*", "d", "*", "(", "d", "-", "1", ")", "-", "len", "(", "cond", ")", "\n", "fdr", "=", "float", "(", "len", "(", "reverse", ")", "+", "len", "(", "false_pos", ")", ")", "/", "max", "(", "pred_size", ",", "1", ")", "\n", "tpr", "=", "float", "(", "len", "(", "true_pos", ")", ")", "/", "max", "(", "len", "(", "cond", ")", ",", "1", ")", "\n", "fpr", "=", "float", "(", "len", "(", "reverse", ")", "+", "len", "(", "false_pos", ")", ")", "/", "max", "(", "cond_neg_size", ",", "1", ")", "\n", "# structural hamming distance", "\n", "pred_lower", "=", "np", ".", "flatnonzero", "(", "np", ".", "tril", "(", "B_est", "+", "B_est", ".", "T", ")", ")", "\n", "cond_lower", "=", "np", ".", "flatnonzero", "(", "np", ".", "tril", "(", "B_true", "+", "B_true", ".", "T", ")", ")", "\n", "extra_lower", "=", "np", ".", "setdiff1d", "(", "pred_lower", ",", "cond_lower", ",", "assume_unique", "=", "True", ")", "\n", "missing_lower", "=", "np", ".", "setdiff1d", "(", "cond_lower", ",", "pred_lower", ",", "assume_unique", "=", "True", ")", "\n", "shd", "=", "len", "(", "extra_lower", ")", "+", "len", "(", "missing_lower", ")", "+", "len", "(", "reverse", ")", "\n", "\n", "# trans cpdag [-1, 0, 1] to [0, 1], -1 is undirected edge in CPDAG", "\n", "for", "i", "in", "range", "(", "len", "(", "B_est", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "B_est", "[", "i", "]", ")", ")", ":", "\n", "                ", "if", "B_est", "[", "i", ",", "j", "]", "==", "-", "1", ":", "\n", "                    ", "B_est", "[", "i", ",", "j", "]", "=", "1", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.check_label_dataset": [[158, 179], ["os.path.exists", "os.path.getsize"], "methods", ["None"], ["B_est", "[", "j", ",", "i", "]", "=", "1", "\n", "\n", "", "", "", "W_p", "=", "pd", ".", "DataFrame", "(", "B_est", ")", "\n", "W_true", "=", "pd", ".", "DataFrame", "(", "B_true", ")", "\n", "\n", "gscore", "=", "MetricsDAG", ".", "_cal_gscore", "(", "W_p", ",", "W_true", ")", "\n", "precision", ",", "recall", ",", "F1", "=", "MetricsDAG", ".", "_cal_precision_recall", "(", "W_p", ",", "W_true", ")", "\n", "\n", "mt", "=", "{", "'fdr'", ":", "fdr", ",", "'tpr'", ":", "tpr", ",", "'fpr'", ":", "fpr", ",", "'shd'", ":", "shd", ",", "'nnz'", ":", "pred_size", ",", "\n", "'precision'", ":", "precision", ",", "'recall'", ":", "recall", ",", "'F1'", ":", "F1", ",", "'gscore'", ":", "gscore", "}", "\n", "for", "i", "in", "mt", ":", "\n", "            ", "mt", "[", "i", "]", "=", "round", "(", "mt", "[", "i", "]", ",", "decimal_num", ")", "\n", "\n", "", "return", "mt", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_cal_gscore", "(", "W_p", ",", "W_true", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.evaluation_execute": [[180, 224], ["web.models.task_db.TaskApi", "web.models.task_db.TaskApi.get_est_dag", "dict", "castle.metrics.evaluation.MetricsDAG.metrics.items", "web.models.task_db.TaskApi", "web.models.task_db.TaskApi.update_performance", "os.path.join", "os.path.join", "example.example.read_file", "web.common.utils.save_gragh_edges", "isinstance", "web.models.task_db.TaskApi.update_true_dag", "castle.metrics.evaluation.MetricsDAG", "dict.update", "str"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_est_dag", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_performance", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.read_file", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.save_gragh_edges", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_true_dag"], ["\n", "\n", "num_true", "=", "W_true", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "assert", "num_true", "!=", "0", "\n", "\n", "# true_positives", "\n", "num_tp", "=", "(", "W_p", "+", "W_true", ")", ".", "applymap", "(", "lambda", "elem", ":", "1", "if", "elem", "==", "2", "else", "0", ")", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "# False Positives + Reversed Edges", "\n", "num_fn_r", "=", "(", "W_p", "-", "W_true", ")", ".", "applymap", "(", "lambda", "elem", ":", "1", "if", "elem", "==", "1", "else", "0", ")", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "score", "=", "np", ".", "max", "(", "(", "num_tp", "-", "num_fn_r", ",", "0", ")", ")", "/", "num_true", "\n", "\n", "return", "score", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_cal_precision_recall", "(", "W_p", ",", "W_true", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        W_p: pd.DataDrame\n            [d, d] estimate, {0, 1, -1}, -1 is undirected edge in CPDAG.\n        W_true: pd.DataDrame\n            [d, d] ground truth graph, {0, 1}.\n        \n        Return\n        ------\n        precision: float\n            TP/(TP + FP)\n        recall: float\n            TP/(TP + FN)\n        F1: float\n            2*(recall*precision)/(recall+precision)\n        \"\"\"", "\n", "\n", "assert", "(", "W_p", ".", "shape", "==", "W_true", ".", "shape", "and", "W_p", ".", "shape", "[", "0", "]", "==", "W_p", ".", "shape", "[", "1", "]", ")", "\n", "TP", "=", "(", "W_p", "+", "W_true", ")", ".", "applymap", "(", "lambda", "elem", ":", "1", "if", "elem", "==", "2", "else", "0", ")", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "TP_FP", "=", "W_p", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "TP_FN", "=", "W_true", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", ")", "\n", "precision", "=", "TP", "/", "TP_FP", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.CITest.gauss": [[29, 95], ["len", "min", "sub_index.extend", "numpy.corrcoef", "max", "math.log1p", "numpy.linalg.inv", "math.sqrt", "math.sqrt", "scipy.stats.norm.cdf", "numpy.corrcoef", "numpy.linalg.pinv", "abs", "abs"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "gauss", "(", "data", ",", "x", ",", "y", ",", "z", ")", ":", "\n", "        ", "\"\"\"Gauss test for continues data\n\n        Parameters\n        ----------\n        data : ndarray\n            The dataset on which to test the independence condition.\n        x : int\n            A variable in data set\n        y : int\n            A variable in data set\n        z : List, default []\n            A list of variable names contained in the data set different\n            from x and y. This is the separating set that (potentially)\n            makes x and y independent.\n\n        Returns\n        -------\n        _: None\n        _: None\n        p: float\n            the p-value of conditional independence.\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import pandas as pd\n        >>> np.random.seed(23)\n        >>> data = np.random.rand(2500, 4)\n\n        >>> p_value = CITest.cressie_read(data, 0, 1, [])\n        >>> print(p_value)\n        0.011609430716781555\n\n        >>> p_value = CITest.cressie_read(data, 0, 1, [3])\n        >>> print(p_value)\n        0.01137523908727811\n\n        >>> p_value = CITest.cressie_read(data, 0, 1, [2, 3])\n        >>> print(p_value)\n        0.011448214156529746\n        \"\"\"", "\n", "\n", "n", "=", "data", ".", "shape", "[", "0", "]", "\n", "k", "=", "len", "(", "z", ")", "\n", "if", "k", "==", "0", ":", "\n", "            ", "r", "=", "np", ".", "corrcoef", "(", "data", "[", ":", ",", "[", "x", ",", "y", "]", "]", ".", "T", ")", "[", "0", "]", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "sub_index", "=", "[", "x", ",", "y", "]", "\n", "sub_index", ".", "extend", "(", "z", ")", "\n", "sub_corr", "=", "np", ".", "corrcoef", "(", "data", "[", ":", ",", "sub_index", "]", ".", "T", ")", "\n", "# inverse matrix", "\n", "try", ":", "\n", "                ", "PM", "=", "np", ".", "linalg", ".", "inv", "(", "sub_corr", ")", "\n", "", "except", "np", ".", "linalg", ".", "LinAlgError", ":", "\n", "                ", "PM", "=", "np", ".", "linalg", ".", "pinv", "(", "sub_corr", ")", "\n", "", "r", "=", "-", "1", "*", "PM", "[", "0", ",", "1", "]", "/", "math", ".", "sqrt", "(", "abs", "(", "PM", "[", "0", ",", "0", "]", "*", "PM", "[", "1", ",", "1", "]", ")", ")", "\n", "", "cut_at", "=", "0.99999", "\n", "r", "=", "min", "(", "cut_at", ",", "max", "(", "-", "1", "*", "cut_at", ",", "r", ")", ")", "# make r between -1 and 1", "\n", "\n", "# Fisher\u2019s z-transform", "\n", "res", "=", "math", ".", "sqrt", "(", "n", "-", "k", "-", "3", ")", "*", ".5", "*", "math", ".", "log1p", "(", "(", "2", "*", "r", ")", "/", "(", "1", "-", "r", ")", ")", "\n", "p_value", "=", "2", "*", "(", "1", "-", "stats", ".", "norm", ".", "cdf", "(", "abs", "(", "res", ")", ")", ")", "\n", "\n", "return", "None", ",", "None", ",", "p_value", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.CITest.g2_test": [[96, 145], ["independence_tests.power_divergence"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.power_divergence"], ["", "@", "staticmethod", "\n", "def", "g2_test", "(", "data", ",", "x", ",", "y", ",", "z", ")", ":", "\n", "        ", "\"\"\"\n        G squared test for conditional independence. Also commonly known as G-test,\n        likelihood-ratio or maximum likelihood statistical significance test.\n        Tests the null hypothesis that x is independent of y given z.\n\n        Parameters\n        ----------\n        data : numpy.ndarray\n            The dataset on which to test the independence condition.\n        x : int\n            A variable in data set\n        y : int\n            A variable in data set\n        z : List, default []\n            A list of variable names contained in the data set, different from X and Y.\n            This is the separating set that (potentially) makes X and Y independent.\n\n        Returns\n        -------\n        chi2 : float\n            The test statistic.\n        dof : int\n            Degrees of freedom\n        p_value : float\n            The p-value of the test\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import pandas as pd\n        >>> np.random.seed(23)\n        >>> data = np.random.randint(0, 5, size=10000).reshape((-1, 4))\n\n        >>> chi2, dof, p_value = CITest.g2_test(data, 0, 1, [])\n        >>> print(chi2, dof, p_value)\n        20.55310657691933 16 0.19633494733361465\n\n        >>> chi2, dof, p_value = CITest.g2_test(data, 0, 1, [3])\n        >>> print(chi2, dof, p_value)\n        90.54473365450676 80 0.1971708971451276\n\n        >>> chi2, dof, p_value = CITest.g2_test(data, 0, 1, [2, 3])\n        >>> print(chi2, dof, p_value)\n        429.0926603059854 400 0.15195497920948475\n        \"\"\"", "\n", "\n", "return", "power_divergence", "(", "data", ",", "x", ",", "y", ",", "z", ",", "lambda_", "=", "'log-likelihood'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.CITest.chi2_test": [[146, 196], ["independence_tests.power_divergence"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.power_divergence"], ["", "@", "staticmethod", "\n", "def", "chi2_test", "(", "data", ",", "x", ",", "y", ",", "z", ")", ":", "\n", "        ", "\"\"\"\n        Chi-square conditional independence test.\n\n        Tests the null hypothesis that x is independent from y given z.\n\n        Parameters\n        ----------\n        data : numpy.ndarray\n            The dataset on which to test the independence condition.\n        x : int\n            A variable in data set\n        y : int\n            A variable in data set\n        z : List, default []\n            A list of variable names contained in the data set, different\n            from x and y. This is the separating set that (potentially)\n            makes x and y independent.\n\n        Returns\n        -------\n        chi2 : float\n            The test statistic.\n        dof : int\n            Degrees of freedom\n        p_value : float\n            The p-value of the test\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import pandas as pd\n        >>> np.random.seed(23)\n        >>> data = np.random.randint(0, 5, size=100).reshape((-1, 4))\n\n        >>> chi2, dof, p_value = CITest.chi2_test(data, 0, 1, [])\n        >>> print(chi2, dof, p_value)\n        20.542792795683862 16 0.19676171971325737\n\n        >>> chi2, dof, p_value = CITest.chi2_test(data, 0, 1, [3])\n        >>> print(chi2, dof, p_value)\n        90.66096270618675 80 0.19483257969931803\n\n        >>> chi2, dof, p_value = CITest.chi2_test(data, 0, 1, [2, 3])\n        >>> print(chi2, dof, p_value)\n        401.830906690841 400 0.46485969015873324\n        \"\"\"", "\n", "\n", "return", "power_divergence", "(", "data", ",", "x", ",", "y", ",", "z", ",", "lambda_", "=", "'pearson'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.CITest.freeman_tukey": [[197, 252], ["independence_tests.power_divergence"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.power_divergence"], ["", "@", "staticmethod", "\n", "def", "freeman_tukey", "(", "data", ",", "x", ",", "y", ",", "z", ")", ":", "\n", "        ", "\"\"\"\n        Freeman Tuckey test for conditional independence [1].\n\n        Tests the null hypothesis that x is independent of y given z.\n\n        References\n        ----------\n        [1] Read, Campbell B. \"Freeman\u2014Tukey chi-squared goodness-of-fit\n        statistics.\" Statistics & probability letters 18.4 (1993): 271-278.\n\n        Parameters\n        ----------\n        data : numpy.ndarray\n            The dataset on which to test the independence condition.\n        x : int\n            A variable in data set\n        y : int\n            A variable in data set\n        z : List, default []\n            A list of variable names contained in the data set, different\n            from x and y. This is the separating set that (potentially)\n            makes x and y independent.\n\n        Returns\n        -------\n        chi2 : float\n            The test statistic.\n        dof : int\n            Degrees of freedom\n        p_value : float\n            The p-value of the test\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import pandas as pd\n        >>> np.random.seed(23)\n        >>> data = np.random.randint(0, 5, size=10000).reshape((-1, 4))\n\n        >>> chi2, dof, p_value = CITest.freeman_tukey(data, 0, 1, [])\n        >>> print(chi2, dof, p_value)\n        20.586757281527213 16 0.19494739343907877\n\n        >>> chi2, dof, p_value = CITest.freeman_tukey(data, 0, 1, [3])\n        >>> print(chi2, dof, p_value)\n        91.06391187965758 80 0.18687227769183953\n\n        >>> chi2, dof, p_value = CITest.freeman_tukey(data, 0, 1, [2, 3])\n        >>> print(chi2, dof, p_value)\n        nan 400 nan\n        \"\"\"", "\n", "\n", "return", "power_divergence", "(", "data", ",", "x", ",", "y", ",", "z", ",", "lambda_", "=", "'freeman-tukey'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.CITest.modify_log_likelihood": [[253, 303], ["independence_tests.power_divergence"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.power_divergence"], ["", "@", "staticmethod", "\n", "def", "modify_log_likelihood", "(", "data", ",", "x", ",", "y", ",", "z", ")", ":", "\n", "        ", "\"\"\"\n        Modified log likelihood ratio test for conditional independence.\n\n        Tests the null hypothesis that x is independent of y given z.\n\n        Parameters\n        ----------\n        data : numpy.ndarray\n            The dataset on which to test the independence condition.\n        x : int\n            A variable in data set\n        y : int\n            A variable in data set\n        z : List, default []\n            A list of variable names contained in the data set, different\n            from x and y. This is the separating set that (potentially)\n            makes x and y independent.\n\n        Returns\n        -------\n        chi2 : float\n            The test statistic.\n        dof : int\n            Degrees of freedom\n        p_value : float\n            The p-value of the test\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import pandas as pd\n        >>> np.random.seed(23)\n        >>> data = np.random.randint(0, 5, size=10000).reshape((-1, 4))\n\n        >>> chi2, dof, p_value = CITest.modify_log_likelihood(data, 0, 1, [])\n        >>> print(chi2, dof, p_value)\n        20.639717717727184 16 0.19277870421685392\n\n        >>> chi2, dof, p_value = CITest.modify_log_likelihood(data, 0, 1, [3])\n        >>> print(chi2, dof, p_value)\n        91.97967547179121 80 0.16962335307180806\n\n        >>> chi2, dof, p_value = CITest.modify_log_likelihood(data, 0, 1, [2, 3])\n        >>> print(chi2, dof, p_value)\n        inf 400 0.0\n        \"\"\"", "\n", "\n", "return", "power_divergence", "(", "data", ",", "x", ",", "y", ",", "z", ",", "lambda_", "=", "'mod-log-likelihood'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.CITest.neyman": [[304, 358], ["independence_tests.power_divergence"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.power_divergence"], ["", "@", "staticmethod", "\n", "def", "neyman", "(", "data", ",", "x", ",", "y", ",", "z", ")", ":", "\n", "        ", "\"\"\"\n        Neyman's test for conditional independence[1].\n\n        Tests the null hypothesis that x is independent of y given z.\n\n        References\n        ----------\n        [1] https://en.wikipedia.org/wiki/Neyman%E2%80%93Pearson_lemma\n\n        Parameters\n        ----------\n        data : numpy.ndarray\n            The dataset on which to test the independence condition.\n        x : int\n            A variable in data set\n        y : int\n            A variable in data set\n        z : List, default []\n            A list of variable names contained in the data set, different\n            from x and y. This is the separating set that (potentially)\n            makes x and y independent.\n\n        Returns\n        -------\n        chi2 : float\n            The test statistic.\n        dof : int\n            Degrees of freedom\n        p_value : float\n            The p-value of the test\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import pandas as pd\n        >>> np.random.seed(23)\n        >>> data = np.random.randint(0, 5, size=10000).reshape((-1, 4))\n\n        >>> chi2, dof, p_value = CITest.neyman(data, 0, 1, [])\n        >>> print(chi2, dof, p_value)\n        20.804888528281907 16 0.1861329703686255\n\n        >>> chi2, dof, p_value = CITest.neyman(data, 0, 1, [3])\n        >>> print(chi2, dof, p_value)\n        95.07200788651971 80 0.11980672825724373\n\n        >>> chi2, dof, p_value = CITest.neyman(data, 0, 1, [2, 3])\n        >>> print(chi2, dof, p_value)\n        nan 400 nan\n        \"\"\"", "\n", "\n", "return", "power_divergence", "(", "data", ",", "x", ",", "y", ",", "z", ",", "lambda_", "=", "'neyman'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.CITest.cressie_read": [[359, 415], ["independence_tests.power_divergence"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.power_divergence"], ["", "@", "staticmethod", "\n", "def", "cressie_read", "(", "data", ",", "x", ",", "y", ",", "z", ")", ":", "\n", "        ", "\"\"\"\n        Cressie Read statistic for conditional independence[1].\n\n        Tests the null hypothesis that x is independent of y given z.\n\n        References\n        ----------\n        [1] Cressie, Noel, and Timothy RC Read.\n        \"Multinomial goodness\u2010of\u2010fit tests.\" Journal of the Royal Statistical\n        Society: Series B (Methodological) 46.3 (1984): 440-464.\n\n        Parameters\n        ----------\n        data : numpy.ndarray\n            The dataset on which to test the independence condition.\n        x : int\n            A variable in data set\n        y : int\n            A variable in data set\n        z : List, default []\n            A list of variable names contained in the data set, different\n            from x and y. This is the separating set that (potentially)\n            makes x and y independent.\n\n        Returns\n        -------\n        chi2 : float\n            The test statistic.\n        dof : int\n            Degrees of freedom\n        p_value : float\n            The p-value of the test\n\n        Examples\n        --------\n        >>> import numpy as np\n        >>> import pandas as pd\n        >>> np.random.seed(23)\n        >>> data = np.random.randint(0, 5, size=10000).reshape((-1, 4))\n\n        >>> chi2, dof, p_value = CITest.cressie_read(data, 0, 1, [])\n        >>> print(chi2, dof, p_value)\n        20.537851851639562 16 0.19696641879639076\n\n        >>> chi2, dof, p_value = CITest.cressie_read(data, 0, 1, [3])\n        >>> print(chi2, dof, p_value)\n        90.45257795422611 80 0.19903833818274186\n\n        >>> chi2, dof, p_value = CITest.cressie_read(data, 0, 1, [2, 3])\n        >>> print(chi2, dof, p_value)\n        404.24753197461905 400 0.43124831946260705\n        \"\"\"", "\n", "\n", "return", "power_divergence", "(", "data", ",", "x", ",", "y", ",", "z", ",", "lambda_", "=", "'cressie-read'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.power_divergence": [[417, 530], ["isinstance", "pandas.DataFrame", "len", "pd.DataFrame.groupby().size", "df.groupby().size.unstack", "scipy.stats.chi2_contingency", "pd.DataFrame.groupby", "scipy.stats.chi2.sf", "pd.DataFrame.groupby", "df.groupby().size", "df.groupby().size.unstack", "scipy.stats.chi2_contingency", "warnings.warn", "df.groupby"], "function", ["None"], ["", "", "def", "power_divergence", "(", "data", ",", "x", ",", "y", ",", "z", ",", "lambda_", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This function tests the null hypothesis that the categorical data.\n\n    The null hypothesis for the test is x is independent of y given z.\n    A lot of the frequency comparison based statistics\n    (eg. chi-square, G-test etc) belong to power divergence family,\n    and are special cases of this test.\n\n\n    Parameters\n    ----------\n    data : numpy.ndarray\n        The dataset on which to test the independence condition.\n    x : int\n        A variable in data set\n    y : int\n        A variable in data set\n    z : List, default []\n        A list of variable names contained in the data set, different from X and Y.\n        This is the separating set that (potentially) makes X and Y independent.\n    lambda_ : float or str, optional\n        By default, the statistic computed in this test is Pearson's\n        chi-squared statistic [2]_.  `lambda_` allows a statistic from the\n        Cressie-Read power divergence family [3]_ to be used instead.\n        For convenience, `lambda_` may be assigned one of the following\n        strings, in which case the corresponding numerical value is used::\n\n            String              Value   Description\n            \"pearson\"             1     Pearson's chi-squared statistic.\n                                        In this case, the function is\n                                        equivalent to `stats.chisquare`.\n            \"log-likelihood\"      0     Log-likelihood ratio. Also known as\n                                        the G-test [3]_.\n            \"freeman-tukey\"      -1/2   Freeman-Tukey statistic.\n            \"mod-log-likelihood\" -1     Modified log-likelihood ratio.\n            \"neyman\"             -2     Neyman's statistic.\n            \"cressie-read\"        2/3   The power recommended in [5]_.\n\n    Returns\n    -------\n    chi2 : float\n        The test statistic.\n    dof : int\n        Degrees of freedom\n    p_value : float\n            The p-value of the test\n\n    References\n    ----------\n    .. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\n           Statistics\". Chapter 8.\n           https://web.archive.org/web/20171015035606/http://faculty.vassar.edu/lowry/ch8pt1.html\n    .. [2] \"Chi-squared test\", https://en.wikipedia.org/wiki/Chi-squared_test\n    .. [3] \"G-test\", https://en.wikipedia.org/wiki/G-test\n    .. [4] Sokal, R. R. and Rohlf, F. J. \"Biometry: the principles and\n           practice of statistics in biological research\", New York: Freeman\n           (1981)\n    .. [5] Cressie, N. and Read, T. R. C., \"Multinomial Goodness-of-Fit\n           Tests\", J. Royal Stat. Soc. Series B, Vol. 46, No. 3 (1984),\n           pp. 440-464.\n\n    See Also\n    --------\n    scipy.stats.power_divergence\n    scipy.stats.chi2_contingency\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> import pandas as pd\n    >>> np.random.seed(23)\n    >>> data = np.random.randint(0, 5, size=100).reshape((-1, 4))\n    >>> data = np.concatenate([data, data.sum(axis=1).reshape(-1, 1)], axis=1)\n\n    >>> chi2, dof, p_value = power_divergence(data, 0, 1, [])\n    >>> print(chi2, dof, p_value)\n    >>> 16.005291005291006 16 0.45259159404543464\n\n    >>> chi2, dof, p_value = power_divergence(data, 0, 1, [3])\n    >>> print(chi2, dof, p_value)\n    >>> 25.333333333333336 25 0.4438225249645223\n\n    >>> chi2, dof, p_value = power_divergence(data, 0, 1, [3, 4])\n    >>> print(chi2, dof, p_value)\n    >>> 0.0 5 1.0\n    \"\"\"", "\n", "\n", "if", "not", "isinstance", "(", "data", ",", "pd", ".", "DataFrame", ")", ":", "\n", "        ", "data", "=", "pd", ".", "DataFrame", "(", "data", ")", "\n", "\n", "", "if", "len", "(", "z", ")", "==", "0", ":", "\n", "        ", "group_x_y", "=", "data", ".", "groupby", "(", "[", "x", ",", "y", "]", ")", ".", "size", "(", ")", "\n", "x_y", "=", "group_x_y", ".", "unstack", "(", "y", ",", "fill_value", "=", "0", ")", "\n", "chi2", ",", "p_value", ",", "dof", ",", "exp", "=", "stats", ".", "chi2_contingency", "(", "x_y", ",", "lambda_", "=", "lambda_", ")", "\n", "", "else", ":", "\n", "        ", "chi2", "=", "0", "\n", "dof", "=", "0", "\n", "for", "z_state", ",", "df", "in", "data", ".", "groupby", "(", "z", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "group_x_y", "=", "df", ".", "groupby", "(", "[", "x", ",", "y", "]", ")", ".", "size", "(", ")", "\n", "x_y", "=", "group_x_y", ".", "unstack", "(", "y", ",", "fill_value", "=", "0", ")", "\n", "c", ",", "_", ",", "d", ",", "_", "=", "stats", ".", "chi2_contingency", "(", "x_y", ",", "lambda_", "=", "lambda_", ")", "\n", "chi2", "+=", "c", "\n", "dof", "+=", "d", "\n", "", "except", "ValueError", ":", "\n", "                ", "warn", "(", "f\"Skipping the test {x}\\u27C2{y}|{z}. Not enough samples.\"", ")", "\n", "", "", "if", "dof", "==", "0", ":", "\n", "            ", "p_value", "=", "1.0", "\n", "", "else", ":", "\n", "            ", "p_value", "=", "stats", ".", "chi2", ".", "sf", "(", "chi2", ",", "df", "=", "dof", ")", "\n", "\n", "", "", "return", "chi2", ",", "dof", ",", "p_value", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests._rbf_dot": [[532, 548], ["numpy.sum().reshape", "numpy.tile", "dists.reshape.reshape", "numpy.sqrt", "numpy.exp", "numpy.tril", "numpy.sum", "numpy.dot", "numpy.dot", "numpy.median"], "function", ["None"], ["", "def", "_rbf_dot", "(", "x", ")", ":", "\n", "\n", "    ", "n", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "G", "=", "np", ".", "sum", "(", "x", "*", "x", ",", "1", ")", ".", "reshape", "(", "n", ",", "1", ")", "\n", "Q", "=", "np", ".", "tile", "(", "G", ",", "(", "1", ",", "n", ")", ")", "\n", "H", "=", "Q", "+", "G", ".", "T", "-", "2", "*", "np", ".", "dot", "(", "x", ",", "x", ".", "T", ")", "\n", "\n", "dists", "=", "Q", "+", "G", ".", "T", "-", "2", "*", "np", ".", "dot", "(", "x", ",", "x", ".", "T", ")", "\n", "dists", "=", "dists", "-", "np", ".", "tril", "(", "dists", ")", "\n", "dists", "=", "dists", ".", "reshape", "(", "n", "**", "2", ",", "1", ")", "\n", "deg", "=", "np", ".", "sqrt", "(", "0.5", "*", "np", ".", "median", "(", "dists", "[", "dists", ">", "0", "]", ")", ")", "\n", "\n", "H", "=", "np", ".", "exp", "(", "-", "H", "/", "2", "/", "(", "deg", "**", "2", ")", ")", "\n", "\n", "return", "H", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests.hsic_test": [[550, 626], ["independence_tests._rbf_dot", "independence_tests._rbf_dot", "numpy.dot", "numpy.dot", "numpy.ones", "numpy.identity", "numpy.dot", "numpy.dot", "numpy.sum", "numpy.diag", "numpy.diag", "numpy.std", "numpy.std", "numpy.ones", "numpy.diag", "numpy.diag", "numpy.dot", "numpy.dot", "scipy.stats.gamma.ppf", "numpy.mean", "numpy.mean", "numpy.sum", "numpy.trace", "numpy.dot", "numpy.dot"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests._rbf_dot", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.independence_tests._rbf_dot"], ["", "def", "hsic_test", "(", "x", ",", "y", ",", "alpha", "=", "0.05", ",", "normalize", "=", "True", ")", ":", "\n", "    ", "\"\"\"Hilbert-Schmidt independence criterion\n\n    HSIC with a Gaussian kernel for the independence test,\n    where we used the gamma distribution as an approximation for the\n    distribution of the HSIC.\n\n    References\n    ----------\n    https://papers.nips.cc/paper/3201-a-kernel-statistical-test-of-independence.pdf\n\n    Parameters\n    ----------\n    x: numpy array\n        Data of the first variable. (n, dim_x) numpy array.\n    y: numpy array\n        Data of the second variable. (n, dim_y) numpy array.\n    alpha : float, default 0.05\n        significance level\n    normalize: bool, default True\n        whether use data normalization\n\n    Returns\n    -------\n    out: int, 0 or 1\n        If 0, x and y are independent.\n        If 1, x and y are not independent.\n\n    Examples\n    --------\n    >>> import numpy as np\n    >>> np.random.seed(1)\n    >>> x = np.random.rand(500, 2)\n    >>> print(hsic_test(x[:, [0]], x[:, [1]]))\n    1\n\n    >>> np.random.seed(12)\n    >>> x = np.random.rand(500, 2)\n    >>> print(hsic_test(x[:, [0]], x[:, [1]]))\n    0\n    \"\"\"", "\n", "\n", "if", "normalize", ":", "\n", "        ", "x", "=", "(", "x", "-", "np", ".", "mean", "(", "x", ")", ")", "/", "np", ".", "std", "(", "x", ")", "\n", "y", "=", "(", "y", "-", "np", ".", "mean", "(", "y", ")", ")", "/", "np", ".", "std", "(", "y", ")", "\n", "\n", "", "n", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "H", "=", "np", ".", "identity", "(", "n", ")", "-", "np", ".", "ones", "(", "(", "n", ",", "n", ")", ",", "dtype", "=", "float", ")", "/", "n", "\n", "K", "=", "_rbf_dot", "(", "x", ")", "\n", "L", "=", "_rbf_dot", "(", "y", ")", "\n", "Kc", "=", "np", ".", "dot", "(", "np", ".", "dot", "(", "H", ",", "K", ")", ",", "H", ")", "\n", "Lc", "=", "np", ".", "dot", "(", "np", ".", "dot", "(", "H", ",", "L", ")", ",", "H", ")", "\n", "\n", "testStat", "=", "np", ".", "sum", "(", "Kc", ".", "T", "*", "Lc", ")", "/", "n", "\n", "\n", "varHSIC", "=", "(", "Kc", "*", "Lc", "/", "6", ")", "**", "2", "\n", "varHSIC", "=", "(", "np", ".", "sum", "(", "varHSIC", ")", "-", "np", ".", "trace", "(", "varHSIC", ")", ")", "/", "n", "/", "(", "n", "-", "1", ")", "\n", "varHSIC", "=", "varHSIC", "*", "72", "*", "(", "n", "-", "4", ")", "*", "(", "n", "-", "5", ")", "/", "n", "/", "(", "n", "-", "1", ")", "/", "(", "n", "-", "2", ")", "/", "(", "n", "-", "3", ")", "\n", "\n", "K", "=", "K", "-", "np", ".", "diag", "(", "np", ".", "diag", "(", "K", ")", ")", "\n", "L", "=", "L", "-", "np", ".", "diag", "(", "np", ".", "diag", "(", "L", ")", ")", "\n", "\n", "bone", "=", "np", ".", "ones", "(", "(", "n", ",", "1", ")", ",", "dtype", "=", "float", ")", "\n", "muX", "=", "np", ".", "dot", "(", "np", ".", "dot", "(", "bone", ".", "T", ",", "K", ")", ",", "bone", ")", "/", "n", "/", "(", "n", "-", "1", ")", "\n", "muY", "=", "np", ".", "dot", "(", "np", ".", "dot", "(", "bone", ".", "T", ",", "L", ")", ",", "bone", ")", "/", "n", "/", "(", "n", "-", "1", ")", "\n", "mHSIC", "=", "(", "1", "+", "muX", "*", "muY", "-", "muX", "-", "muY", ")", "/", "n", "\n", "al", "=", "mHSIC", "**", "2", "/", "varHSIC", "\n", "bet", "=", "varHSIC", "*", "n", "/", "mHSIC", "\n", "\n", "thresh", "=", "stats", ".", "gamma", ".", "ppf", "(", "1", "-", "alpha", ",", "al", ",", "scale", "=", "bet", ")", "[", "0", "]", "[", "0", "]", "\n", "\n", "if", "testStat", "<", "thresh", ":", "\n", "        ", "return", "1", "\n", "", "else", ":", "\n", "        ", "return", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.BaseLearner.__init__": [[25, 28], ["None"], "methods", ["None"], ["\n", "class", "_BaseLiNGAM", "(", "BootstrapMixin", ",", "metaclass", "=", "ABCMeta", ")", ":", "\n", "    ", "\"\"\"Base class for all LiNGAM algorithms.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.BaseLearner.learn": [[29, 32], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Construct a _BaseLiNGAM model.\"\"\"", "\n", "self", ".", "_causal_order", "=", "None", "\n", "self", ".", "_adjacency_matrix", "=", "None", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.BaseLearner.causal_matrix": [[37, 40], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.Tensor.__new__": [[177, 202], ["numpy.asarray().view", "TypeError", "isinstance", "range", "range", "numpy.array", "isinstance", "numpy.asarray", "isinstance", "TypeError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.Tensor.__array_finalize__": [[203, 211], ["pandas.RangeIndex", "pandas.RangeIndex", "pandas.RangeIndex"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.Tensor.index": [[216, 222], ["isinstance", "pandas.Index", "len", "ValueError", "list"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.Tensor.columns": [[227, 233], ["isinstance", "pandas.Index", "ValueError", "len", "list"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.plot_dag.GraphDAG.__init__": [[36, 54], ["GraphDAG._plot_dag", "isinstance", "TypeError", "TypeError", "ValueError", "isinstance"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.plot_dag.GraphDAG._plot_dag"], ["def", "__init__", "(", "self", ",", "est_dag", ",", "true_dag", "=", "None", ",", "show", "=", "True", ",", "save_name", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "est_dag", "=", "est_dag", "\n", "self", ".", "true_dag", "=", "true_dag", "\n", "self", ".", "show", "=", "show", "\n", "self", ".", "save_name", "=", "save_name", "\n", "\n", "if", "not", "isinstance", "(", "est_dag", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Input est_dag is not numpy.ndarray!\"", ")", "\n", "\n", "", "if", "true_dag", "is", "not", "None", "and", "not", "isinstance", "(", "true_dag", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Input true_dag is not numpy.ndarray!\"", ")", "\n", "\n", "", "if", "not", "show", "and", "save_name", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'Neither display nor save the picture! '", "+", "'Please modify the parameter show or save_name.'", ")", "\n", "\n", "", "GraphDAG", ".", "_plot_dag", "(", "self", ".", "est_dag", ",", "self", ".", "true_dag", ",", "self", ".", "show", ",", "self", ".", "save_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.plot_dag.GraphDAG._plot_dag": [[55, 115], ["isinstance", "range", "matplotlib.subplots", "ax1.set_title", "ax1.imshow", "fig.colorbar", "ax2.set_title", "ax2.imshow", "fig.colorbar", "isinstance", "len", "fig.savefig", "matplotlib.show", "range", "matplotlib.subplots", "ax1.set_title", "ax1.imshow", "fig.colorbar", "len", "fig.savefig", "matplotlib.show"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_plot_dag", "(", "est_dag", ",", "true_dag", ",", "show", "=", "True", ",", "save_name", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Plot the estimated DAG and the true DAG.\n\n        Parameters\n        ----------\n        est_dag: np.ndarray\n            The DAG matrix to be estimated.\n        true_dag: np.ndarray\n            The True DAG matrix.\n        show: bool\n            Select whether to display pictures.\n        save_name: str\n            The file name of the image to be saved.\n        \"\"\"", "\n", "\n", "if", "isinstance", "(", "true_dag", ",", "np", ".", "ndarray", ")", ":", "\n", "\n", "# trans diagonal element into 0", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "true_dag", ")", ")", ":", "\n", "                ", "if", "est_dag", "[", "i", "]", "[", "i", "]", "==", "1", ":", "\n", "                    ", "est_dag", "[", "i", "]", "[", "i", "]", "=", "0", "\n", "", "if", "true_dag", "[", "i", "]", "[", "i", "]", "==", "1", ":", "\n", "                    ", "true_dag", "[", "i", "]", "[", "i", "]", "=", "0", "\n", "\n", "# set plot size", "\n", "", "", "fig", ",", "(", "ax1", ",", "ax2", ")", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "8", ",", "3", ")", ",", "ncols", "=", "2", ")", "\n", "\n", "ax1", ".", "set_title", "(", "'est_graph'", ")", "\n", "map1", "=", "ax1", ".", "imshow", "(", "est_dag", ",", "cmap", "=", "'Greys'", ",", "interpolation", "=", "'none'", ")", "\n", "fig", ".", "colorbar", "(", "map1", ",", "ax", "=", "ax1", ")", "\n", "\n", "ax2", ".", "set_title", "(", "'true_graph'", ")", "\n", "map2", "=", "ax2", ".", "imshow", "(", "true_dag", ",", "cmap", "=", "'Greys'", ",", "interpolation", "=", "'none'", ")", "\n", "fig", ".", "colorbar", "(", "map2", ",", "ax", "=", "ax2", ")", "\n", "\n", "if", "save_name", "is", "not", "None", ":", "\n", "                ", "fig", ".", "savefig", "(", "save_name", ")", "\n", "", "if", "show", ":", "\n", "                ", "plt", ".", "show", "(", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "est_dag", ",", "np", ".", "ndarray", ")", ":", "\n", "\n", "# trans diagonal element into 0", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "est_dag", ")", ")", ":", "\n", "                ", "if", "est_dag", "[", "i", "]", "[", "i", "]", "==", "1", ":", "\n", "                    ", "est_dag", "[", "i", "]", "[", "i", "]", "=", "0", "\n", "\n", "# set plot size", "\n", "", "", "fig", ",", "ax1", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "4", ",", "3", ")", ",", "ncols", "=", "1", ")", "\n", "\n", "ax1", ".", "set_title", "(", "'est_graph'", ")", "\n", "map1", "=", "ax1", ".", "imshow", "(", "est_dag", ",", "cmap", "=", "'Greys'", ",", "interpolation", "=", "'none'", ")", "\n", "fig", ".", "colorbar", "(", "map1", ",", "ax", "=", "ax1", ")", "\n", "\n", "if", "save_name", "is", "not", "None", ":", "\n", "                ", "fig", ".", "savefig", "(", "save_name", ")", "\n", "", "if", "show", ":", "\n", "                ", "plt", ".", "show", "(", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.zip_alg_file": [[35, 58], ["os.path.join", "os.path.exists", "os.path.join", "zipfile.ZipFile", "os.walk", "zipfile.ZipFile.close", "zipfile.ZipFile.write", "os.path.join"], "function", ["None"], ["    ", "\"\"\"\n    Set random seed for reproducibility.\n\n    Parameters\n    ----------\n    seed: int\n        Random seed.\n    \"\"\"", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "try", ":", "\n", "        ", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n", "\n", "", "", "def", "is_dag", "(", "B", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.zip_data_file": [[60, 82], ["os.path.join", "zipfile.ZipFile", "os.path.join", "os.path.join", "zipfile.ZipFile.write", "zipfile.ZipFile.write", "zipfile.ZipFile.close", "str", "str"], "function", ["None"], ["\n", "return", "nx", ".", "is_directed_acyclic_graph", "(", "nx", ".", "DiGraph", "(", "B", ")", ")", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.update_param": [[84, 112], ["len", "enumerate", "reversed", "param_dict.update", "list", "utils.sem_type_set", "reversed"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.sem_type_set"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.simulate_parameters": [[114, 143], ["dict", "inspect.getfullargspec", "utils.update_param", "utils.update_param", "inspect.getfullargspec", "utils.update_param", "inspect.getfullargspec", "utils.update_param", "inspect.getfullargspec", "inspect.getfullargspec"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.update_param", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.update_param", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.update_param", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.update_param"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.sem_type_set": [[145, 167], ["list", "web.common.config.SEM_TYPE.keys"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.algorithm_parameters": [[169, 204], ["dict", "inspect.getfullargspec", "inspect.getfullargspec", "list", "utils.simulate_parameters", "len", "len", "web.common.config.SEM_TYPE.keys", "enumerate", "dict.update", "reversed", "dict.update", "alg.upper", "dict.update", "alg.upper", "inspect.isfunction"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.simulate_parameters"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.conversion_type": [[206, 237], ["utils.translation_parameters", "alg.upper", "example.example.INLINE_ALGORITHMS.keys", "inspect.getfullargspec", "translation_parameters.items", "alg.upper", "list().index", "type", "int", "list", "reversed", "list", "reversed"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.translation_parameters", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.Tensor.index"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.four_operations": [[239, 264], ["operators.items", "formula.split", "ops", "int", "int", "value_list[].strip", "value_list[].strip"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.translation_parameters": [[266, 307], ["dict", "re.compile", "re.compile", "re.compile", "re.compile", "parameters.items", "isinstance", "dict.update", "four_operations.strip", "re.compile.match", "re.compile.match", "re.compile.match", "re.compile.match", "float", "int", "four_operations.startswith", "four_operations.endswith", "tuple", "json.loads", "four_operations.lower", "four_operations.lower", "utils.four_operations"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.four_operations"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.write_result": [[309, 328], ["os.path.join", "os.path.exists", "os.makedirs", "open", "res_file.write", "os.path.join"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.save_to_file": [[330, 350], ["os.path.abspath", "file.split", "isinstance", "os.path.exists", "os.makedirs", "data.to_csv", "numpy.savetxt", "os.path.dirname"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.save_gragh_edges": [[352, 388], ["isinstance", "networkx.from_numpy_array", "list", "list", "list.append", "numpy.where", "numpy.where", "set().intersection", "hasattr", "list", "open", "res_file.write", "set", "list.append", "str", "str", "str", "json.dumps", "tem_dag.any", "tem_dag.any", "set", "range", "isinstance", "len", "len", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.set_current_language": [[390, 411], ["gettext.translation", "gettext.translation.install", "gettext.translation", "os.path.dirname", "gettext.translation.install", "os.path.abspath", "gettext.translation.install"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._": [[413, 426], ["text"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.update_inline_datasets": [[428, 446], ["os.path.join", "os.listdir", "os.path.join", "os.listdir", "os.path.exists", "os.makedirs", "os.path.join", "os.path.exists", "os.makedirs", "os.path.join", "web.common.config.INLINE_DATASETS.append", "web.common.config.INLINE_TRUE.append"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.web.main.before_first_request": [[31, 42], ["flask.request.cookies.get", "web.common.utils.set_current_language", "web.common.config.lang_str.get"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.set_current_language"], ["\n", "# Setup for logging", "\n", "output_dir", "=", "'output/{}'", ".", "format", "(", "datetime", ".", "now", "(", "timezone", "(", "'Asia/Hong_Kong'", ")", ")", ".", "strftime", "(", "'%Y-%m-%d_%H-%M-%S-%f'", ")", "[", ":", "-", "3", "]", ")", "\n", "create_dir", "(", "output_dir", ")", "\n", "LogHelper", ".", "setup", "(", "log_path", "=", "'{}/training.log'", ".", "format", "(", "output_dir", ")", ",", "\n", "level_str", "=", "'INFO'", ")", "\n", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "# Save the configuration for logging purpose", "\n", "save_yaml_config", "(", "args", ",", "path", "=", "'{}/config.yaml'", ".", "format", "(", "output_dir", ")", ")", "\n", "\n", "# Reproducibility", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.web.main.after_request": [[44, 58], ["None"], "function", ["None"], ["\n", "# Get dataset", "\n", "dataset", "=", "SyntheticDataset", "(", "args", ".", "n", ",", "args", ".", "d", ",", "args", ".", "graph_type", ",", "args", ".", "degree", ",", "args", ".", "sem_type", ",", "\n", "args", ".", "noise_scale", ",", "args", ".", "dataset_type", ",", "args", ".", "x_dim", ")", "\n", "_logger", ".", "info", "(", "'Finished generating dataset'", ")", "\n", "\n", "model", "=", "GAE", "(", "args", ".", "n", ",", "args", ".", "d", ",", "args", ".", "x_dim", ",", "args", ".", "seed", ",", "args", ".", "num_encoder_layers", ",", "args", ".", "num_decoder_layers", ",", "\n", "args", ".", "hidden_size", ",", "args", ".", "latent_dim", ",", "args", ".", "l1_graph_penalty", ",", "args", ".", "use_float64", ")", "\n", "model", ".", "print_summary", "(", "print_func", "=", "model", ".", "logger", ".", "info", ")", "\n", "\n", "trainer", "=", "ALTrainer", "(", "args", ".", "init_rho", ",", "args", ".", "rho_thres", ",", "args", ".", "h_thres", ",", "args", ".", "rho_multiply", ",", "\n", "args", ".", "init_iter", ",", "args", ".", "learning_rate", ",", "args", ".", "h_tol", ",", "\n", "args", ".", "early_stopping", ",", "args", ".", "early_stopping_thres", ")", "\n", "W_est", "=", "trainer", ".", "train", "(", "model", ",", "dataset", ".", "X", ",", "dataset", ".", "W", ",", "args", ".", "graph_thres", ",", "\n", "args", ".", "max_iter", ",", "args", ".", "iter_step", ",", "output_dir", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.web.main.get_host_ip": [[60, 76], ["socket.socket", "socket.socket.connect", "socket.socket.close", "socket.socket.getsockname"], "function", ["None"], ["\n", "# Save raw recovered graph, ground truth and observational data after training", "\n", "np", ".", "save", "(", "'{}/true_graph.npy'", ".", "format", "(", "output_dir", ")", ",", "dataset", ".", "W", ")", "\n", "np", ".", "save", "(", "'{}/observational_data.npy'", ".", "format", "(", "output_dir", ")", ",", "dataset", ".", "X", ")", "\n", "np", ".", "save", "(", "'{}/final_raw_recovered_graph.npy'", ".", "format", "(", "output_dir", ")", ",", "W_est", ")", "\n", "\n", "# Plot raw recovered graph", "\n", "plot_recovered_graph", "(", "W_est", ",", "dataset", ".", "W", ",", "\n", "save_name", "=", "'{}/raw_recovered_graph.png'", ".", "format", "(", "output_dir", ")", ")", "\n", "\n", "_logger", ".", "info", "(", "'Filter by constant threshold'", ")", "\n", "W_est", "=", "W_est", "/", "np", ".", "max", "(", "np", ".", "abs", "(", "W_est", ")", ")", "# Normalize", "\n", "\n", "# Plot thresholded recovered graph", "\n", "W_est", "[", "np", ".", "abs", "(", "W_est", ")", "<", "args", ".", "graph_thres", "]", "=", "0", "# Thresholding", "\n", "plot_recovered_graph", "(", "W_est", ",", "dataset", ".", "W", ",", "\n", "save_name", "=", "'{}/thresholded_recovered_graph.png'", ".", "format", "(", "output_dir", ")", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.run.run_alg.causal_discovery": [[28, 88], ["web.models.task_db.TaskApi", "datetime.datetime.now", "web.models.task_db.TaskApi.update_performance", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "web.models.task_db.TaskApi.update_update_time", "web.common.utils.conversion_type", "example.example.train", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "web.models.task_db.TaskApi.update_est_dag", "os.path.join", "isinstance", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "os.path.join", "web.common.utils.save_gragh_edges", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "dict", "os.path.exists", "os.makedirs", "web.models.task_db.TaskApi.update_true_dag", "os.path.join", "web.common.utils.save_gragh_edges", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "logging.warning", "str", "str"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_performance", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_update_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.conversion_type", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.train", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_est_dag", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.save_gragh_edges", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_true_dag", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.save_gragh_edges", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time"], ["def", "causal_discovery", "(", "data", ",", "true_dag", ",", "alg", "=", "'PC'", ",", "algorithm_params", "=", "None", ",", "task_id", "=", "None", ",", "topology_matrix", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Path for executing causal discovery, and update list status.\n\n    Parameters\n    ----------\n    data: pd.DataFrame or array\n        Raw data.\n    true_dag: array\n        Realistic map.\n    alg: str\n        Causal discovery algorithm.\n    algorithm_params: dict\n        Causal Discovery Algorithm Parameters.\n    task_id: int\n        task key in the database.\n    topology_matrix: numpy.ndarray\n        topology matrix only TTPM used.\n    Returns\n    -------\n\n    \"\"\"", "\n", "task_api", "=", "TaskApi", "(", ")", "\n", "try", ":", "\n", "        ", "start_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "task_api", ".", "update_performance", "(", "task_id", ",", "\"\"", ",", "dict", "(", ")", ")", "\n", "task_api", ".", "update_task_status", "(", "task_id", ",", "0.1", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "task_api", ".", "update_update_time", "(", "task_id", ",", "start_time", ")", "\n", "# algorithm", "\n", "algorithm_params", "=", "conversion_type", "(", "alg", ",", "algorithm_params", ")", "\n", "p_res", ",", "pre_dag", "=", "train", "(", "alg", ",", "data", ",", "true_dag", ",", "algorithm_params", ",", "topology_matrix", "=", "topology_matrix", ",", "plot", "=", "False", ")", "\n", "\n", "task_api", ".", "update_task_status", "(", "task_id", ",", "0.5", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "\n", "task_api", ".", "update_est_dag", "(", "task_id", ",", "p_res", ".", "causal_matrix", ")", "\n", "# pre_dag = p_res.causal_matrix", "\n", "\n", "task_path", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "'task'", ",", "task_id", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "task_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "task_path", ")", "\n", "\n", "", "if", "isinstance", "(", "true_dag", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "task_api", ".", "update_true_dag", "(", "task_id", ",", "true_dag", ")", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "\"true.txt\"", ")", "\n", "save_gragh_edges", "(", "true_dag", ",", "file_name", ")", "\n", "\n", "", "task_api", ".", "update_task_status", "(", "task_id", ",", "0.8", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "\n", "# deal result", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "\"pre.txt\"", ")", "\n", "save_gragh_edges", "(", "pre_dag", ",", "file_name", ")", "\n", "task_api", ".", "update_task_status", "(", "task_id", ",", "1.0", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "", "except", "Exception", "as", "error", ":", "\n", "        ", "task_api", ".", "update_task_status", "(", "task_id", ",", "str", "(", "error", ")", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "logger", ".", "warning", "(", "'alg run fail %s'", "%", "str", "(", "error", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.run.run_data_generation.simulate_data": [[28, 129], ["web.common.utils.translation_parameters", "web.models.task_db.TaskApi", "datetime.datetime.now", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "web.models.task_db.TaskApi.update_update_time", "web.models.task_db.TaskApi.get_task_name", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "os.path.exists", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "web.common.utils.save_to_file", "web.common.utils.save_to_file", "isinstance", "web.common.utils.save_gragh_edges", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "os.path.exists", "os.makedirs", "os.remove", "web.common.utils.save_to_file", "castle.datasets.DAG.erdos_renyi", "castle.datasets.Topology.erdos_renyi", "castle.datasets.THPSimulation", "castle.datasets.THPSimulation.simulate", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "castle.datasets.DAG.erdos_renyi", "castle.datasets.IIDSimulation", "pandas.DataFrame", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "web.models.task_db.TaskApi.update_task_status", "web.models.task_db.TaskApi.update_consumed_time", "logging.warning", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "str", "os.remove", "os.remove", "os.remove", "os.remove", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.translation_parameters", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_update_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_name", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.save_to_file", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.save_to_file", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.save_gragh_edges", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.save_to_file", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.Topology.erdos_renyi", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.Topology.erdos_renyi", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.THPSimulation.simulate", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.Topology.erdos_renyi", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_task_status", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_consumed_time"], ["def", "simulate_data", "(", "data", ",", "alg", ",", "task_id", ",", "parameters", ")", ":", "\n", "    ", "\"\"\"\n    Simulation Data Generation Entry.\n\n    Parameters\n    ----------\n    data: str\n        Path for storing generated data files.\n    alg: str\n        Generating Operator Strings.\n    task_id: int\n        task key in the database.\n    parameters: dict\n        Data generation parameters.\n    Returns\n    -------\n        True or False\n    \"\"\"", "\n", "parameters", "=", "translation_parameters", "(", "parameters", ")", "\n", "task_api", "=", "TaskApi", "(", ")", "\n", "start_time", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "task_api", ".", "update_task_status", "(", "task_id", ",", "0.1", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "task_api", ".", "update_update_time", "(", "task_id", ",", "start_time", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "data", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "data", ")", "\n", "", "task_name", "=", "task_api", ".", "get_task_name", "(", "task_id", ")", "\n", "sample_path", "=", "os", ".", "path", ".", "join", "(", "data", ",", "\"datasets\"", ",", "str", "(", "task_id", ")", "+", "\"_\"", "+", "task_name", "+", "\".csv\"", ")", "\n", "true_dag_path", "=", "os", ".", "path", ".", "join", "(", "data", ",", "\"true\"", ",", "str", "(", "task_id", ")", "+", "\"_\"", "+", "task_name", "+", "\".npz\"", ")", "\n", "node_relationship_path", "=", "os", ".", "path", ".", "join", "(", "data", ",", "\"node_relationship_\"", "+", "str", "(", "task_id", ")", "+", "\"_\"", "+", "task_name", "+", "\".csv\"", ")", "\n", "topo_path", "=", "os", ".", "path", ".", "join", "(", "data", ",", "\"topo_\"", "+", "str", "(", "task_id", ")", "+", "\"_\"", "+", "task_name", "+", "\".npz\"", ")", "\n", "task_api", ".", "update_task_status", "(", "task_id", ",", "0.2", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "\n", "topo", "=", "None", "\n", "try", ":", "\n", "        ", "if", "alg", "==", "\"EVENT\"", ":", "\n", "            ", "true_dag", "=", "DAG", ".", "erdos_renyi", "(", "n_nodes", "=", "parameters", "[", "'n_nodes'", "]", ",", "\n", "n_edges", "=", "parameters", "[", "'n_edges'", "]", ",", "\n", "weight_range", "=", "parameters", "[", "'weight_range'", "]", ",", "\n", "seed", "=", "parameters", "[", "'seed'", "]", ")", "\n", "topo", "=", "Topology", ".", "erdos_renyi", "(", "n_nodes", "=", "parameters", "[", "'Topology_n_nodes'", "]", ",", "\n", "n_edges", "=", "parameters", "[", "'Topology_n_edges'", "]", ",", "\n", "seed", "=", "parameters", "[", "'Topology_seed'", "]", ")", "\n", "simulator", "=", "THPSimulation", "(", "true_dag", ",", "topo", ",", "\n", "mu_range", "=", "parameters", "[", "'mu_range'", "]", ",", "\n", "alpha_range", "=", "parameters", "[", "'alpha_range'", "]", ")", "\n", "sample", "=", "simulator", ".", "simulate", "(", "T", "=", "parameters", "[", "'THPSimulation_simulate_T'", "]", ",", "\n", "max_hop", "=", "parameters", "[", "'THPSimulation_simulate_max_hop'", "]", ",", "\n", "beta", "=", "parameters", "[", "'THPSimulation_simulate_beta'", "]", ")", "\n", "\n", "task_api", ".", "update_task_status", "(", "task_id", ",", "0.5", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "", "else", ":", "\n", "\n", "            ", "weighted_random_dag", "=", "DAG", ".", "erdos_renyi", "(", "n_nodes", "=", "parameters", "[", "'n_nodes'", "]", ",", "\n", "n_edges", "=", "parameters", "[", "'n_edges'", "]", ",", "\n", "weight_range", "=", "parameters", "[", "'weight_range'", "]", ",", "\n", "seed", "=", "parameters", "[", "'seed'", "]", ")", "\n", "dataset", "=", "IIDSimulation", "(", "W", "=", "weighted_random_dag", ",", "\n", "n", "=", "parameters", "[", "'n'", "]", ",", "\n", "method", "=", "parameters", "[", "'method'", "]", ",", "\n", "sem_type", "=", "parameters", "[", "'sem_type'", "]", ",", "\n", "noise_scale", "=", "parameters", "[", "'noise_scale'", "]", ")", "\n", "\n", "true_dag", ",", "sample", "=", "dataset", ".", "B", ",", "dataset", ".", "X", "\n", "sample", "=", "pd", ".", "DataFrame", "(", "sample", ")", "\n", "\n", "task_api", ".", "update_task_status", "(", "task_id", ",", "0.5", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "", "", "except", "Exception", "as", "error", ":", "\n", "        ", "task_api", ".", "update_task_status", "(", "task_id", ",", "str", "(", "error", ")", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "logger", ".", "warning", "(", "'Generating simulation data failed, exp=%s'", "%", "error", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "sample_path", ")", ":", "\n", "            ", "os", ".", "remove", "(", "sample_path", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "true_dag_path", ")", ":", "\n", "            ", "os", ".", "remove", "(", "true_dag_path", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "node_relationship_path", ")", ":", "\n", "            ", "os", ".", "remove", "(", "node_relationship_path", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "topo_path", ")", ":", "\n", "            ", "os", ".", "remove", "(", "topo_path", ")", "\n", "", "return", "False", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "topo_path", ")", ":", "\n", "        ", "os", ".", "remove", "(", "topo_path", ")", "\n", "\n", "", "task_api", ".", "update_task_status", "(", "task_id", ",", "0.6", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "\n", "save_to_file", "(", "sample", ",", "sample_path", ")", "\n", "save_to_file", "(", "true_dag", ",", "true_dag_path", ")", "\n", "if", "isinstance", "(", "topo", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "save_to_file", "(", "topo", ",", "topo_path", ")", "\n", "\n", "# calculate accuracy", "\n", "", "save_gragh_edges", "(", "true_dag", ",", "node_relationship_path", ")", "\n", "task_api", ".", "update_task_status", "(", "task_id", ",", "1.0", ")", "\n", "task_api", ".", "update_consumed_time", "(", "task_id", ",", "start_time", ")", "\n", "return", "True", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.run.run.run_task": [[32, 94], ["web.models.base_class.DataSetApi.check_dataset", "threading.Thread", "threading.Thread.start", "dataset.split", "example.example.read_file", "os.path.join", "os.path.exists", "os.path.join", "os.path.exists", "os.path.sep.join", "example.example.read_file", "os.path.sep.join", "example.example.read_file", "logging.warning", "pandas.read_excel", "file_path_list[].split", "pandas.read_csv", "str"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.check_dataset", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.read_file", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.read_file", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.read_file"], ["dest", "=", "'config'", ",", "\n", "help", "=", "'You must provide the .yaml file corresponding to '", "\n", "'the simulation data or algorithm.'", ",", "\n", "default", "=", "'./example/dataset/simulate_data.yaml'", ")", "\n", "parser", ".", "add_argument", "(", "'-p'", ",", "'--plot'", ",", "\n", "dest", "=", "'plot'", ",", "\n", "help", "=", "'whether show graph.'", ",", "\n", "default", "=", "True", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "with", "open", "(", "args", ".", "config", ",", "'r'", ")", "as", "file", ":", "\n", "        ", "try", ":", "\n", "            ", "params_config", "=", "yaml", ".", "safe_load", "(", "file", ")", "\n", "", "except", "yaml", ".", "YAMLError", "as", "exc", ":", "\n", "            ", "print", "(", "exc", ")", "\n", "\n", "", "", "if", "params_config", "[", "'task_params'", "]", "[", "'task_type'", "]", "==", "1", ":", "\n", "        ", "logging", ".", "info", "(", "'Start task 1: simulate dataset.'", ")", "\n", "outer", "=", "run_simulate", "(", "config", "=", "params_config", ")", "\n", "save_to_file", "(", "outer", "[", "0", "]", ",", "\n", "file", "=", "params_config", "[", "'dataset_params'", "]", "[", "'x_file'", "]", ")", "\n", "logging", ".", "info", "(", "f\"Dataset X has been saved to \"", "\n", "f\"{params_config['dataset_params']['x_file']}.\"", ")", "\n", "save_to_file", "(", "outer", "[", "1", "]", ",", "\n", "file", "=", "params_config", "[", "'dataset_params'", "]", "[", "'dag_file'", "]", ")", "\n", "logging", ".", "info", "(", "f\"Dataset true_dag has been saved to \"", "\n", "f\"{params_config['dataset_params']['dag_file']}.\"", ")", "\n", "if", "params_config", "[", "'task_params'", "]", "[", "'algorithm'", "]", "==", "'EVENT'", ":", "\n", "            ", "save_to_file", "(", "outer", "[", "2", "]", ",", "\n", "file", "=", "params_config", "[", "'dataset_params'", "]", "[", "'topology_file'", "]", ")", "\n", "logging", ".", "info", "(", "f\"Dataset topology has been saved to \"", "\n", "f\"{params_config['dataset_params']['topology_file']}.\"", ")", "\n", "", "logging", ".", "info", "(", "'Task completed!'", ")", "\n", "", "elif", "params_config", "[", "'task_params'", "]", "[", "'task_type'", "]", "==", "2", ":", "\n", "        ", "logging", ".", "info", "(", "'Start task 2: causal discovery.'", ")", "\n", "\n", "topology", "=", "None", "\n", "if", "params_config", "[", "'dataset_params'", "]", "[", "'x_file'", "]", "is", "None", ":", "\n", "\n", "            ", "if", "params_config", "[", "'task_params'", "]", "[", "'algorithm'", "]", "==", "'TTPM'", ":", "\n", "                ", "X", ",", "true_dag", ",", "topology", "=", "load_dataset", "(", "'THP_Test'", ")", "\n", "", "else", ":", "\n", "                ", "X", ",", "true_dag", ",", "_", "=", "load_dataset", "(", "'IID_Test'", ")", "\n", "X", "=", "pd", ".", "DataFrame", "(", "X", ")", "\n", "", "", "else", ":", "\n", "            ", "X", "=", "read_file", "(", "file", "=", "params_config", "[", "'dataset_params'", "]", "[", "'x_file'", "]", ",", "\n", "header", "=", "0", ")", "\n", "true_dag", "=", "read_file", "(", "file", "=", "params_config", "[", "'dataset_params'", "]", "[", "'dag_file'", "]", ",", "\n", "header", "=", "None", ")", "\n", "\n", "", "if", "'topology_file'", "in", "params_config", "[", "'dataset_params'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "topology", "=", "read_file", "(", "file", "=", "params_config", "[", "'dataset_params'", "]", "[", "'topology_file'", "]", ",", "\n", "header", "=", "None", ")", "\n", "\n", "", "train", "(", "model_name", "=", "params_config", "[", "'task_params'", "]", "[", "'algorithm'", "]", ",", "\n", "X", "=", "X", ",", "\n", "true_dag", "=", "true_dag", ",", "\n", "model_params", "=", "params_config", "[", "'algorithm_params'", "]", ",", "\n", "topology_matrix", "=", "topology", ",", "\n", "plot", "=", "args", ".", "plot", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid value of the configuration parameter '", "\n", "'task_type, expected integer 1 or 2.'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.run.run.run_data": [[96, 121], ["threading.Thread", "threading.Thread.start"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_task_list": [[37, 57], ["task.route", "web.models.task_db.TaskApi", "web.models.task_db.TaskApi.list_tasks", "flask.jsonify"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.list_tasks"], ["@", "task", ".", "route", "(", "\"/get_task_list\"", ",", "methods", "=", "[", "\"GET\"", "]", ")", "\n", "def", "get_task_list", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Back to Task List.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n\n    ### request\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_api", "=", "TaskApi", "(", ")", "\n", "tasks", "=", "task_api", ".", "list_tasks", "(", ")", "\n", "return", "jsonify", "(", "tasks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_label_checkbox": [[59, 84], ["task.route", "flask.request.form.get", "web.metrics.evaluation.Evaluation", "web.metrics.evaluation.Evaluation.get_label_checkbox", "flask.jsonify", "int", "str"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_label_checkbox"], ["", "@", "task", ".", "route", "(", "\"/get_label_checkbox\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "get_label_checkbox", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Checking Whether Data Is Built-in Data\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "\"task_id\"", ")", "\n", "evaluation", "=", "Evaluation", "(", ")", "\n", "is_inline", "=", "evaluation", ".", "get_label_checkbox", "(", "int", "(", "task_id", ")", ")", "\n", "return", "jsonify", "(", "{", "\"is_inline\"", ":", "str", "(", "is_inline", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_evaluation_results": [[85, 110], ["task.route", "flask.request.form.get", "web.models.task_db.TaskApi", "web.models.task_db.TaskApi.get_performance", "flask.jsonify"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_performance"], ["", "@", "task", ".", "route", "(", "\"/get_evaluation_results\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "get_evaluation_results", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    >\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "\"task_id\"", ")", "\n", "task_api", "=", "TaskApi", "(", ")", "\n", "performance", "=", "task_api", ".", "get_performance", "(", "task_id", ")", "\n", "return", "jsonify", "(", "performance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_evaluation_metrics": [[112, 136], ["task.route", "flask.request.form.get", "web.metrics.evaluation.Evaluation", "flask.jsonify", "web.metrics.evaluation.Evaluation.get_evaluation_metrics", "int"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_evaluation_metrics"], ["", "@", "task", ".", "route", "(", "\"/get_evaluation_metrics\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "get_evaluation_metrics", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Obtain all evaluation indicators.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "\"task_id\"", ")", "\n", "evaluation", "=", "Evaluation", "(", ")", "\n", "return", "jsonify", "(", "evaluation", ".", "get_evaluation_metrics", "(", "int", "(", "task_id", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_builtin_label": [[138, 162], ["task.route", "flask.request.form.get", "web.metrics.evaluation.Evaluation", "flask.jsonify", "web.metrics.evaluation.Evaluation.get_builtin_label", "int"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_builtin_label"], ["", "@", "task", ".", "route", "(", "\"/get_builtin_label\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "get_builtin_label", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Obtains the built-in data name.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "\"task_id\"", ")", "\n", "evaluation", "=", "Evaluation", "(", ")", "\n", "return", "jsonify", "(", "evaluation", ".", "get_builtin_label", "(", "int", "(", "task_id", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_customize_label": [[164, 188], ["task.route", "flask.request.form.get", "web.metrics.evaluation.Evaluation", "flask.jsonify", "web.metrics.evaluation.Evaluation.get_task_customize_label", "int"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.get_task_customize_label"], ["", "@", "task", ".", "route", "(", "\"/get_customize_label\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "get_customize_label", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Obtain the path of the customized data file.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "\"task_id\"", ")", "\n", "evaluation", "=", "Evaluation", "(", ")", "\n", "return", "jsonify", "(", "evaluation", ".", "get_task_customize_label", "(", "int", "(", "task_id", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.check_label_dataset": [[190, 220], ["task.route", "flask.request.form.get", "web.metrics.evaluation.Evaluation", "web.metrics.evaluation.Evaluation.check_label_dataset", "flask.jsonify", "flask.jsonify", "web.common.utils._", "web.common.utils._"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.check_label_dataset", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._"], ["", "@", "task", ".", "route", "(", "\"/check_label_dataset\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "check_label_dataset", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Check whether the real image exists.\n    ### args\n    |      args     | nullable | request type | type |        remarks           |\n    |---------------|----------|--------------|------|--------------------------|\n    |label_data_path|  false   |    body      | str  |Checking Realistic Path   |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "label_path", "=", "request", ".", "form", ".", "get", "(", "\"label_data_path\"", ")", "\n", "evaluation", "=", "Evaluation", "(", ")", "\n", "res", "=", "evaluation", ".", "check_label_dataset", "(", "label_path", ")", "\n", "if", "res", ":", "\n", "        ", "return", "jsonify", "(", "\n", "{", "\"status\"", ":", "200", ",", "\"data\"", ":", "_", "(", "\"The verification result is true.\"", ")", "}", ")", "\n", "", "else", ":", "\n", "        ", "return", "jsonify", "(", "\n", "{", "\"status\"", ":", "400", ",", "\"data\"", ":", "_", "(", "\"The verification result is false.\"", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.execute_evaluation": [[222, 251], ["task.route", "flask.request.form.get", "flask.request.form.get", "json.loads", "web.metrics.evaluation.Evaluation", "web.metrics.evaluation.Evaluation.evaluation_execute", "flask.jsonify", "flask.request.form.get"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.metrics.evaluation.Evaluation.evaluation_execute"], ["", "", "@", "task", ".", "route", "(", "\"/execute_evaluation\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "execute_evaluation", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Perform algorithm evaluation.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n    |  label_path  |  false   |    body      | str  | Realistic map |\n    |chosen_evaluation|  false   |    body   | str  | Evaluation Indicator List |\n\n    ### request\n    ```json\n    {\"task_id\": 1, \"label_path\":xxxx, \"chosen_evaluation\":[\"F1\", \"fdr\"]}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "\"task_id\"", ")", "\n", "label_path", "=", "request", ".", "form", ".", "get", "(", "\"label_path\"", ")", "\n", "chosen_evaluation", "=", "json", ".", "loads", "(", "request", ".", "form", ".", "get", "(", "\"chosen_evaluation\"", ")", ")", "\n", "evaluation", "=", "Evaluation", "(", ")", "\n", "res", "=", "evaluation", ".", "evaluation_execute", "(", "task_id", ",", "label_path", ",", "chosen_evaluation", ")", "\n", "return", "jsonify", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.delete_tasks": [[253, 283], ["task.route", "json.loads", "web.models.task_db.TaskApi", "web.models.task_db.TaskApi.delete_tasks", "flask.request.form.get", "flask.jsonify", "flask.jsonify", "web.common.utils._", "web.common.utils._"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.delete_tasks", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._"], ["", "@", "task", ".", "route", "(", "\"/delete_tasks\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "delete_tasks", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Deleting Tasks.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | str  | task list |\n\n    ### request\n    ```json\n    {\"task_id\": [1,3,4]}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_ids", "=", "json", ".", "loads", "(", "request", ".", "form", ".", "get", "(", "\"task_id\"", ")", ")", "\n", "task_api", "=", "TaskApi", "(", ")", "\n", "delete_status", "=", "task_api", ".", "delete_tasks", "(", "task_ids", ")", "\n", "if", "delete_status", ":", "\n", "        ", "return", "jsonify", "(", "\n", "{", "\"status\"", ":", "200", ",", "\"data\"", ":", "_", "(", "\"The delete result is true.\"", ")", "}", ")", "\n", "", "else", ":", "\n", "        ", "return", "jsonify", "(", "\n", "{", "\"status\"", ":", "400", ",", "\"data\"", ":", "_", "(", "\"The delete result is false.\"", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_causal_relationship": [[285, 333], ["task.route", "flask.request.form.get", "os.path.join", "dict", "web.models.task_db.TaskApi().get_task_type", "flask.jsonify", "web.models.base_class.DataSetApi.get_dataset", "web.models.task_db.TaskApi().get_task_name", "os.path.join", "web.models.task_db.TaskApi", "open", "res_file.readlines", "dict.update", "os.walk", "web.models.task_db.TaskApi", "len", "list", "list", "list", "json.loads", "os.path.join", "tuple", "tuple", "set().intersection", "set().difference", "set().difference", "open", "res_file.readlines", "dict.update", "set", "set", "set", "str", "list", "list", "set", "set", "set", "json.loads", "dict.values", "dict.values"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_type", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.get_dataset", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_name"], ["", "", "@", "task", ".", "route", "(", "\"/get_causal_relationship\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "get_causal_relationship", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Obtains the causal relationship of a task.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "\"task_id\"", ")", "\n", "result_data", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "\"task\"", ",", "task_id", ")", "\n", "result_dict", "=", "dict", "(", ")", "\n", "\n", "task_type", "=", "TaskApi", "(", ")", ".", "get_task_type", "(", "task_id", ")", "\n", "if", "task_type", "==", "1", ":", "\n", "        ", "dataset_path", "=", "DataSetApi", ".", "get_dataset", "(", "task_id", ")", "\n", "task_name", "=", "TaskApi", "(", ")", ".", "get_task_name", "(", "task_id", ")", "\n", "dataset_file", "=", "os", ".", "path", ".", "join", "(", "dataset_path", ",", "\n", "\"node_relationship_\"", "+", "str", "(", "task_id", ")", "+", "\"_\"", "+", "task_name", "+", "\".csv\"", ")", "\n", "with", "open", "(", "dataset_file", ",", "\"r\"", ")", "as", "res_file", ":", "\n", "            ", "res_list", "=", "res_file", ".", "readlines", "(", ")", "\n", "result_dict", ".", "update", "(", "{", "dataset_file", ":", "json", ".", "loads", "(", "res_list", "[", "0", "]", ")", "}", ")", "\n", "", "", "elif", "task_type", "==", "2", ":", "\n", "        ", "for", "dir_path", ",", "_", ",", "file_names", "in", "os", ".", "walk", "(", "result_data", ")", ":", "\n", "            ", "for", "file_name", "in", "file_names", ":", "\n", "                ", "result_file", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "file_name", ")", "\n", "with", "open", "(", "result_file", ",", "\"r\"", ")", "as", "res_file", ":", "\n", "                    ", "res_list", "=", "res_file", ".", "readlines", "(", ")", "\n", "result_dict", ".", "update", "(", "{", "file_name", ":", "json", ".", "loads", "(", "res_list", "[", "0", "]", ")", "}", ")", "\n", "", "", "", "if", "len", "(", "result_dict", ")", ">", "1", ":", "\n", "            ", "pre_list", "=", "[", "tuple", "(", "pl", ")", "for", "pl", "in", "list", "(", "result_dict", ".", "values", "(", ")", ")", "[", "0", "]", "]", "\n", "true_list", "=", "[", "tuple", "(", "tl", ")", "for", "tl", "in", "list", "(", "result_dict", ".", "values", "(", ")", ")", "[", "1", "]", "]", "\n", "result_dict", "[", "\"common\"", "]", "=", "list", "(", "set", "(", "pre_list", ")", ".", "intersection", "(", "set", "(", "true_list", ")", ")", ")", "\n", "result_dict", "[", "\"pre_common\"", "]", "=", "list", "(", "set", "(", "pre_list", ")", ".", "difference", "(", "set", "(", "true_list", ")", ")", ")", "\n", "result_dict", "[", "\"true_common\"", "]", "=", "list", "(", "set", "(", "true_list", ")", ".", "difference", "(", "set", "(", "pre_list", ")", ")", ")", "\n", "", "", "return", "jsonify", "(", "result_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.set_causal_relationship": [[335, 360], ["task.route", "flask.request.form.get", "flask.request.form.get", "web.common.utils.write_result", "flask.jsonify", "web.common.utils._"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.write_result", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._"], ["", "@", "task", ".", "route", "(", "\"/set_causal_relationship\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "set_causal_relationship", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Modifying the Causality Diagram.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n    | relationship |  false   |    body      | str  | Modified Causality |\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "\"task_id\"", ")", "\n", "relationship", "=", "request", ".", "form", ".", "get", "(", "\"relationship\"", ")", "\n", "write_result", "(", "relationship", ",", "task_id", ")", "\n", "return", "jsonify", "(", "{", "'status'", ":", "200", ",", "'data'", ":", "_", "(", "'The save result is true.'", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.download_file": [[362, 407], ["task.route", "flask.request.form.get", "web.models.task_db.TaskApi", "web.models.task_db.TaskApi.get_task_type", "web.models.base_class.DataSetApi.get_dataset", "web.models.task_db.TaskApi", "web.models.task_db.TaskApi.get_task_name", "web.common.utils.zip_data_file", "flask.make_response", "flask.jsonify", "os.path.join", "web.common.utils.zip_alg_file", "flask.send_file", "web.common.utils._"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_type", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.get_dataset", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_name", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.zip_data_file", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.zip_alg_file", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._"], ["", "@", "task", ".", "route", "(", "\"/download_file\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "download_file", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Downloading task-related files in the list.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "file_name", "=", "None", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "\"task_id\"", ")", "\n", "task_api", "=", "TaskApi", "(", ")", "\n", "task_type", "=", "task_api", ".", "get_task_type", "(", "task_id", ")", "\n", "if", "task_type", "==", "1", ":", "\n", "        ", "data_path", "=", "DataSetApi", ".", "get_dataset", "(", "task_id", ")", "\n", "if", "data_path", "is", "None", ":", "\n", "            ", "data_path", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "'inline'", ")", "\n", "\n", "", "task_api", "=", "TaskApi", "(", ")", "\n", "task_name", "=", "task_api", ".", "get_task_name", "(", "task_id", ")", "\n", "file_name", "=", "zip_data_file", "(", "task_id", ",", "task_name", ",", "data_path", ")", "\n", "", "elif", "task_type", "==", "2", ":", "\n", "        ", "file_name", "=", "zip_alg_file", "(", "task_id", ")", "\n", "", "if", "file_name", ":", "\n", "        ", "response", "=", "make_response", "(", "send_file", "(", "file_name", ")", ")", "\n", "response", ".", "headers", "[", "\"Content-Disposition\"", "]", "=", "\"attachment;\"", "\"filename*=UTF-8''{utf_filename}\"", ".", "format", "(", "\n", "utf_filename", "=", "(", "task_id", "+", "\".zip\"", ")", ")", "\n", "return", "response", "\n", "", "else", ":", "\n", "        ", "return", "jsonify", "(", "\n", "{", "\"status\"", ":", "400", ",", "\"data\"", ":", "_", "(", "\"The result file does not exist.\"", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_inline_dataset_names": [[409, 438], ["task.route", "flask.request.form.get", "web.common.utils.update_inline_datasets", "web.models.base_class.DataSetApi.get_dataset", "flask.jsonify", "flask.jsonify"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.update_inline_datasets", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.get_dataset"], ["", "", "@", "task", ".", "route", "(", "'/get_inline_dataset_names'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "get_inline_dataset_names", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Obtains the built-in data name list.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 2}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "'task_id'", ")", "\n", "update_inline_datasets", "(", ")", "\n", "inline_name", "=", "INLINE_DATASETS", "\n", "selected_dataset", "=", "DataSetApi", ".", "get_dataset", "(", "task_id", ")", "\n", "if", "selected_dataset", ":", "\n", "        ", "return", "jsonify", "(", "{", "'inline_datasets'", ":", "inline_name", ",", "\n", "'selected_dataset'", ":", "selected_dataset", "}", ")", "\n", "", "return", "jsonify", "(", "{", "'inline_datasets'", ":", "inline_name", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.check_dataset": [[440, 468], ["task.route", "flask.request.form.get", "web.models.base_class.DataSetApi.check_dataset", "flask.jsonify", "flask.jsonify", "web.common.utils._"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.check_dataset", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._"], ["", "@", "task", ".", "route", "(", "'/check_dataset'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "check_dataset", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Check whether the file path exists.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    path      |  false   |    body      | str  | file path string  |\n\n    ### request\n    ```json\n    {\"path\": xxxx}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "path", "=", "request", ".", "form", ".", "get", "(", "'path'", ")", "\n", "check_result", "=", "DataSetApi", ".", "check_dataset", "(", "path", ")", "\n", "\n", "if", "check_result", ":", "\n", "        ", "return", "jsonify", "(", "{", "\"column_num\"", ":", "check_result", "}", ")", "\n", "", "else", ":", "\n", "        ", "return", "jsonify", "(", "{", "'status'", ":", "403", ",", "'data'", ":", "_", "(", "'The verification result is false.'", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_algorithm_names": [[470, 511], ["task.route", "flask.request.form.get", "web.models.base_class.AlgorithmApi.get_algorithm", "web.models.task_db.TaskApi().get_task_type", "len", "flask.jsonify", "web.models.task_db.TaskApi", "web.models.base_class.AlgorithmApi.get_algorithm_names", "flask.jsonify", "flask.jsonify", "web.common.utils._", "list", "web.common.config.SEM_TYPE.keys", "web.common.utils._", "web.common.utils._"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.AlgorithmApi.get_algorithm", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_type", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_algorithm_names", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._"], ["", "", "@", "task", ".", "route", "(", "'/get_algorithm_names'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "get_algorithm_names", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Obtains the algorithm name list.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "'task_id'", ")", "\n", "selected_algorithm", "=", "AlgorithmApi", ".", "get_algorithm", "(", "task_id", ")", "\n", "\n", "task_type", "=", "TaskApi", "(", ")", ".", "get_task_type", "(", "task_id", ")", "\n", "default", "=", "{", "1", ":", "\"IID_LINEAR\"", ",", "2", ":", "\"PC\"", "}", "\n", "\n", "if", "len", "(", "selected_algorithm", ")", "<=", "0", ":", "\n", "        ", "selected_algorithm", "=", "{", "\"algorithm\"", ":", "default", "[", "task_type", "]", "}", "\n", "\n", "", "if", "task_type", "==", "1", ":", "\n", "        ", "return", "jsonify", "(", "{", "\"name\"", ":", "_", "(", "\"Sample Distribution\"", ")", ",", "\"val\"", ":", "selected_algorithm", "[", "'algorithm'", "]", ",", "\n", "\"default\"", ":", "default", "[", "task_type", "]", ",", "\"list\"", ":", "list", "(", "SEM_TYPE", ".", "keys", "(", ")", ")", "}", ")", "\n", "", "elif", "task_type", "==", "2", ":", "\n", "        ", "algorithm_names", "=", "AlgorithmApi", ".", "get_algorithm_names", "(", ")", "\n", "return", "jsonify", "(", "{", "\"name\"", ":", "_", "(", "\"Selecting an algorithm\"", ")", ",", "\n", "\"val\"", ":", "selected_algorithm", "[", "'algorithm'", "]", ",", "\n", "\"default\"", ":", "default", "[", "task_type", "]", ",", "\n", "\"list\"", ":", "algorithm_names", "}", ")", "\n", "", "else", ":", "\n", "        ", "return", "jsonify", "(", "{", "'status'", ":", "400", ",", "'data'", ":", "_", "(", "'The task type is incorrect.'", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_algorithm_parameters": [[513, 560], ["task.route", "flask.request.form.get", "flask.request.form.get", "web.models.base_class.AlgorithmApi.get_algorithm", "dict", "web.common.utils.algorithm_parameters", "list", "web.common.utils.algorithm_parameters.items", "flask.jsonify", "len", "isinstance", "list.append", "dict.keys", "dict.update", "str", "str", "web.common.utils.sem_type_set"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.AlgorithmApi.get_algorithm", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.algorithm_parameters", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.sem_type_set"], ["", "", "@", "task", ".", "route", "(", "'/get_algorithm_parameters'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "get_algorithm_parameters", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Obtains algorithm parameters. This function is triggered when an option is selected from the Algorithm Name drop-down list.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n    |selected_algorithm|  false   |    body      | str  | algorithm string |\n    ### request\n    ```json\n    {\"task_id\": 1, \"selected_algorithm\": \"PC\"}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "'task_id'", ")", "\n", "selected_algorithm", "=", "request", ".", "form", ".", "get", "(", "'selected_algorithm'", ")", "\n", "algorithm_info", "=", "AlgorithmApi", ".", "get_algorithm", "(", "task_id", ")", "\n", "cur_params", "=", "dict", "(", ")", "\n", "if", "len", "(", "algorithm_info", ")", ">", "0", ":", "\n", "        ", "task_algorithm_name", "=", "algorithm_info", "[", "'algorithm'", "]", "\n", "if", "selected_algorithm", "==", "task_algorithm_name", ":", "\n", "            ", "cur_params", "=", "algorithm_info", "[", "'parameters'", "]", "\n", "", "", "default_parameters", "=", "algorithm_parameters", "(", "selected_algorithm", ")", "\n", "\n", "if", "not", "cur_params", ":", "\n", "        ", "cur_params", "=", "default_parameters", "\n", "\n", "", "res_list", "=", "list", "(", ")", "\n", "for", "cur_key", ",", "cur_value", "in", "default_parameters", ".", "items", "(", ")", ":", "\n", "        ", "if", "cur_key", "not", "in", "cur_params", ".", "keys", "(", ")", ":", "\n", "            ", "cur_params", ".", "update", "(", "{", "cur_key", ":", "cur_value", "}", ")", "\n", "", "if", "isinstance", "(", "cur_value", ",", "bool", ")", ":", "\n", "            ", "cur_params", "[", "cur_key", "]", "=", "str", "(", "cur_params", "[", "cur_key", "]", ")", "\n", "cur_value", "=", "str", "(", "cur_value", ")", "\n", "", "param", "=", "{", "\"name\"", ":", "cur_key", ",", "\"val\"", ":", "cur_params", "[", "cur_key", "]", ",", "\n", "\"default\"", ":", "cur_value", ",", "\n", "\"list\"", ":", "sem_type_set", "(", "cur_key", ",", "selected_algorithm", ")", "}", "\n", "res_list", ".", "append", "(", "param", ")", "\n", "", "return", "jsonify", "(", "res_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.set_dataset_info": [[562, 592], ["task.route", "flask.request.form.get", "flask.request.form.get", "web.models.base_class.DataSetApi", "web.models.base_class.DataSetApi.set_dataset_info", "flask.jsonify", "flask.jsonify", "web.common.utils._", "web.common.utils._"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.set_dataset_info", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._"], ["", "@", "task", ".", "route", "(", "'/set_dataset_info'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "set_dataset_info", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Setting Task Data Information.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n    |   name_path  |  false   |    body      | str  | task path string         |\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "'task_id'", ")", "\n", "name_path", "=", "request", ".", "form", ".", "get", "(", "'name_path'", ")", "\n", "dataset", "=", "DataSetApi", "(", "name_path", ")", "\n", "result", "=", "dataset", ".", "set_dataset_info", "(", "task_id", ")", "\n", "if", "result", ":", "\n", "        ", "return", "jsonify", "(", "{", "'status'", ":", "200", ",", "'task_id'", ":", "task_id", ",", "\n", "'data'", ":", "_", "(", "'The dataset is set successfully.'", ")", "}", ")", "\n", "", "return", "jsonify", "(", "{", "'status'", ":", "400", ",", "'task_id'", ":", "task_id", ",", "\n", "'data'", ":", "_", "(", "'The dataset fail to be set.'", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.set_algorithm_info": [[594, 626], ["task.route", "flask.request.form.get", "flask.request.form.get", "flask.request.form.get", "web.models.base_class.AlgorithmApi", "web.models.base_class.AlgorithmApi.set_algorithm_info", "flask.jsonify", "json.loads", "json.dumps.update", "json.dumps", "[].lower", "request.form.get.split"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.set_algorithm_info"], ["", "@", "task", ".", "route", "(", "'/set_algorithm_info'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "set_algorithm_info", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Set the operators and parameters of the causal discovery or data generation task.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n    |selected_algorithm|  false   |    body  | str  | algorithm string         |\n    |selected_parameters|  false   |    body      | str  | Dictionary Serialization String |\n    ### request\n    ```json\n    {\"task_id\": 1, \"selected_algorithm\": \"PC\", \"selected_parameters\":dict}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "'task_id'", ")", "\n", "algorithm_name", "=", "request", ".", "form", ".", "get", "(", "'selected_algorithm'", ")", "\n", "parameters", "=", "request", ".", "form", ".", "get", "(", "'selected_parameters'", ")", "\n", "if", "algorithm_name", "==", "'IID_NONLINEAR'", "or", "algorithm_name", "==", "'IID_LINEAR'", ":", "\n", "        ", "parameters", "=", "json", ".", "loads", "(", "parameters", ")", "\n", "parameters", ".", "update", "(", "{", "'method'", ":", "algorithm_name", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "}", ")", "\n", "parameters", "=", "json", ".", "dumps", "(", "parameters", ")", "\n", "", "algorithm", "=", "AlgorithmApi", "(", "algorithm_name", ",", "parameters", ")", "\n", "status_code", ",", "task_info", "=", "algorithm", ".", "set_algorithm_info", "(", "task_id", ")", "\n", "return", "jsonify", "(", "{", "'status'", ":", "status_code", ",", "'data'", ":", "task_info", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.run_task": [[628, 670], ["task.route", "flask.request.form.get", "web.models.base_class.DataSetApi.get_dataset", "web.models.base_class.AlgorithmApi.get_algorithm", "web.models.task_db.TaskApi().get_task_type", "flask.jsonify", "web.common.utils._", "web.common.utils._", "web.models.task_db.TaskApi", "len", "tasks.keys"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.get_dataset", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.AlgorithmApi.get_algorithm", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_type", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._"], ["", "@", "task", ".", "route", "(", "'/run_task'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "run_task", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Perform causal discovery or data generation tasks.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "result", "=", "None", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "'task_id'", ")", "\n", "dataset", "=", "DataSetApi", ".", "get_dataset", "(", "task_id", ")", "\n", "algorithm_info", "=", "AlgorithmApi", ".", "get_algorithm", "(", "task_id", ")", "\n", "tasks", "=", "{", "1", ":", "run", ".", "run_data", ",", "2", ":", "run", ".", "run_task", "}", "\n", "\n", "task_type", "=", "TaskApi", "(", ")", ".", "get_task_type", "(", "task_id", ")", "\n", "\n", "if", "dataset", "and", "len", "(", "algorithm_info", ")", ">", "0", "and", "task_type", "in", "tasks", ".", "keys", "(", ")", ":", "\n", "        ", "result", "=", "tasks", "[", "task_type", "]", "(", "task_id", ",", "dataset", ",", "\n", "algorithm_info", "[", "'algorithm'", "]", ",", "\n", "algorithm_info", "[", "'parameters'", "]", ")", "\n", "\n", "", "if", "result", ":", "\n", "        ", "status_code", "=", "200", "\n", "data", "=", "_", "(", "'The task succeeds to begin to run.'", ")", "\n", "", "else", ":", "\n", "        ", "status_code", "=", "400", "\n", "data", "=", "_", "(", "'The task fails to begin to run.'", ")", "\n", "\n", "", "return", "jsonify", "(", "{", "'status_code'", ":", "status_code", ",", "'data'", ":", "data", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_builtin_data_checkbox": [[672, 699], ["task.route", "flask.request.form.get", "web.models.base_class.DataSetApi.get_dataset", "web.models.base_class.DataSetApi.get_inline_dataset_names", "flask.jsonify", "flask.jsonify"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.get_dataset", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_inline_dataset_names"], ["", "@", "task", ".", "route", "(", "'/get_builtin_data_checkbox'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "get_builtin_data_checkbox", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Obtains the current data type.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "'task_id'", ")", "\n", "dataset", "=", "DataSetApi", ".", "get_dataset", "(", "task_id", ")", "\n", "inline_datasets", "=", "DataSetApi", ".", "get_inline_dataset_names", "(", ")", "\n", "if", "dataset", "in", "inline_datasets", ":", "\n", "        ", "return", "jsonify", "(", "{", "'is_inline'", ":", "True", "}", ")", "\n", "", "return", "jsonify", "(", "{", "'is_inline'", ":", "False", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_edit_customize_dataset_path": [[701, 729], ["task.route", "flask.request.form.get", "web.models.base_class.DataSetApi.get_dataset", "web.models.base_class.DataSetApi.get_inline_dataset_names", "flask.jsonify", "flask.jsonify"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.get_dataset", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_inline_dataset_names"], ["", "@", "task", ".", "route", "(", "'/get_edit_customize_dataset_path'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "get_edit_customize_dataset_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Obtaining a User-Defined Data Path.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "'task_id'", ")", "\n", "dataset", "=", "DataSetApi", ".", "get_dataset", "(", "task_id", ")", "\n", "inline_datasets", "=", "DataSetApi", ".", "get_inline_dataset_names", "(", ")", "\n", "if", "dataset", "not", "in", "inline_datasets", ":", "\n", "        ", "return", "jsonify", "(", "{", "'customize_path'", ":", "dataset", "}", ")", "\n", "\n", "", "return", "jsonify", "(", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.add_task": [[731, 774], ["task.route", "flask.request.form.get", "flask.request.form.get", "int", "flask.jsonify", "flask.request.form.get", "web.models.task_db.TaskApi().add_task", "web.models.base_class.DataSetApi.get_dataset", "web.models.task_db.TaskApi().add_task", "os.path.join", "os.path.join", "web.common.utils.update_inline_datasets", "web.models.task_db.TaskApi", "web.models.task_db.TaskApi"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.add_task", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.get_dataset", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.add_task", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.update_inline_datasets"], ["", "@", "task", ".", "route", "(", "'/add_task'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "add_task", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > New Task.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n    |    task_name |  false   |    body      | str  | task name                |\n    |    task_type |  false   |    body      | str  | task type                |\n    ### request\n    ```json\n    {\"task_id\": 1, \"task_name\": xxxx, \"task_type\": 2}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "'task_id'", ")", "\n", "task_name", "=", "request", ".", "form", ".", "get", "(", "'task_name'", ")", "\n", "task_type", "=", "int", "(", "request", ".", "form", ".", "get", "(", "'task_type'", ")", ")", "\n", "\n", "if", "task_id", ":", "\n", "        ", "task_id", "=", "TaskApi", "(", ")", ".", "add_task", "(", "task_type", ",", "task_name", ",", "task_id", ")", "\n", "dataset", "=", "DataSetApi", ".", "get_dataset", "(", "task_id", ")", "\n", "if", "dataset", "==", "\"\"", ":", "\n", "            ", "dataset", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "'inline'", ")", "\n", "", "", "else", ":", "\n", "        ", "task_id", "=", "TaskApi", "(", ")", ".", "add_task", "(", "task_type", ",", "task_name", ")", "\n", "\n", "if", "task_type", "==", "1", ":", "\n", "            ", "dataset", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "'inline'", ")", "\n", "", "else", ":", "\n", "            ", "update_inline_datasets", "(", ")", "\n", "if", "INLINE_DATASETS", ":", "\n", "                ", "dataset", "=", "INLINE_DATASETS", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "dataset", "=", "None", "\n", "", "", "", "return", "jsonify", "(", "{", "'task_id'", ":", "task_id", ",", "'task_path'", ":", "dataset", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.upload_config_file": [[776, 809], ["task.route", "os.path.join", "f.save", "task_view.read_task", "os.path.join", "os.path.exists", "os.rename", "web.common.utils._", "flask.jsonify", "os.remove", "str"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.read_task", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._"], ["", "@", "task", ".", "route", "(", "'/upload_config_file'", ",", "methods", "=", "[", "'POST'", "]", ")", "\n", "def", "upload_config_file", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Uploading Configuration Files.\n    ### files\n    |      files   | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    file      |  false   |    body      | str  | file name string         |\n\n    ### request\n    ```json\n    {\"file\": xxxx}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "f", "=", "request", ".", "files", "[", "'file'", "]", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "f", ".", "filename", ")", "\n", "f", ".", "save", "(", "file_name", ")", "\n", "task_id", "=", "read_task", "(", "file_name", ")", "\n", "new_file_name", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "str", "(", "task_id", ")", "+", "\"_\"", "+", "f", ".", "filename", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "new_file_name", ")", ":", "\n", "        ", "os", ".", "remove", "(", "new_file_name", ")", "\n", "", "os", ".", "rename", "(", "file_name", ",", "new_file_name", ")", "\n", "status_code", "=", "200", "\n", "data", "=", "_", "(", "'File uploaded successfully.'", ")", "\n", "\n", "return", "jsonify", "(", "{", "'status'", ":", "status_code", ",", "'data'", ":", "data", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.export_task": [[811, 845], ["task.route", "flask.request.form.get", "task_view.save_param", "web.models.task_db.TaskApi().get_task_name", "flask.make_response", "flask.jsonify", "web.models.task_db.TaskApi", "flask.send_file", "web.common.utils._"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.save_param", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_name", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._"], ["", "@", "task", ".", "route", "(", "\"/export_task\"", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "def", "export_task", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Interface for Exporting Configuration Files.\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "task_id", "=", "request", ".", "form", ".", "get", "(", "\"task_id\"", ")", "\n", "file_name", "=", "save_param", "(", "task_id", ")", "\n", "task_name", "=", "TaskApi", "(", ")", ".", "get_task_name", "(", "task_id", ")", "\n", "if", "file_name", ":", "\n", "        ", "response", "=", "make_response", "(", "send_file", "(", "file_name", ")", ")", "\n", "response", ".", "headers", "[", "\"Content-Disposition\"", "]", "=", "\"attachment;\"", "\"filename*=UTF-8''{utf_filename}\"", ".", "format", "(", "\n", "utf_filename", "=", "(", "task_name", "+", "\".yaml\"", ")", ")", "\n", "return", "response", "\n", "", "else", ":", "\n", "        ", "return", "jsonify", "(", "\n", "{", "\"status\"", ":", "400", ",", "\"data\"", ":", "_", "(", "\"The configuration file does not exist.\"", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.current_language": [[847, 878], ["task.route", "flask.request.form.get", "web.common.utils.set_current_language", "flask.jsonify", "web.common.utils._", "web.common.utils._"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.set_current_language", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils._"], ["", "", "@", "task", ".", "route", "(", "\"/current_language\"", ",", "methods", "=", "[", "\"GET\"", ",", "\"POST\"", "]", ")", "\n", "def", "current_language", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    >Switching the GUI Language\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "language", "=", "request", ".", "form", ".", "get", "(", "\"language\"", ")", "\n", "res", "=", "set_current_language", "(", "language", ")", "\n", "if", "res", ":", "\n", "        ", "status_code", "=", "200", "\n", "data", "=", "_", "(", "'The language is set successfully.'", ")", "\n", "", "else", ":", "\n", "        ", "status_code", "=", "400", "\n", "data", "=", "_", "(", "'Failed to set the language.'", ")", "\n", "\n", "", "return", "jsonify", "(", "{", "'status'", ":", "status_code", ",", "'data'", ":", "data", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_version": [[880, 903], ["task.route", "flask.jsonify"], "function", ["None"], ["", "@", "task", ".", "route", "(", "\"/get_version\"", ",", "methods", "=", "[", "\"GET\"", ",", "\"POST\"", "]", ")", "\n", "def", "get_version", "(", ")", ":", "\n", "    ", "\"\"\"\n    @@@\n    ### description\n    > Obtaining the Version Number\n    ### args\n    |      args    | nullable | request type | type |        remarks           |\n    |--------------|----------|--------------|------|--------------------------|\n    |    task_id   |  false   |    body      | int  | task key in the database |\n\n    ### request\n    ```json\n    {\"task_id\": 1}\n    ```\n    ### return\n    ```json\n    {\"status\": xxxx, \"data\": xxxx}\n    ```\n    @@@\n    \"\"\"", "\n", "return", "jsonify", "(", "{", "\"web_version\"", ":", "__version__", ",", "\n", "\"gcastle_version\"", ":", "castle", ".", "__version__", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.read_task": [[905, 953], ["open", "yaml.safe_load", "web.models.task_db.TaskApi().add_task", "web.models.base_class.AlgorithmApi", "web.models.base_class.AlgorithmApi.set_algorithm_info", "yaml.safe_load.keys", "[].upper", "params_config[].keys", "web.models.base_class.DataSetApi", "web.models.base_class.DataSetApi.set_dataset_info", "example.example.read_file", "web.models.task_db.TaskApi().update_true_dag", "os.path.join", "os.path.join", "web.common.utils.save_gragh_edges", "json.dumps", "print", "web.models.task_db.TaskApi", "web.models.task_db.TaskApi", "[].split", "os.path.join.split"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.add_task", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.set_algorithm_info", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.set_dataset_info", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.read_file", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.update_true_dag", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.save_gragh_edges"], ["", "def", "read_task", "(", "file_name", ")", ":", "\n", "    ", "\"\"\"\n    Read the configuration file and generate the task.\n\n    Parameters\n    ----------\n    file_name:str\n        profile path.\n\n    Returns\n    -------\n    task_id: int\n        task key in the database.\n    \"\"\"", "\n", "with", "open", "(", "file_name", ",", "'r'", ")", "as", "file", ":", "\n", "        ", "try", ":", "\n", "            ", "params_config", "=", "yaml", ".", "safe_load", "(", "file", ")", "\n", "if", "\"task_params\"", "in", "params_config", ".", "keys", "(", ")", ":", "\n", "                ", "alg", "=", "params_config", "[", "'task_params'", "]", "[", "'algorithm'", "]", "\n", "task_name", "=", "params_config", "[", "'task_params'", "]", "[", "'task_name'", "]", "\n", "task_type", "=", "params_config", "[", "'task_params'", "]", "[", "'task_type'", "]", "\n", "", "else", ":", "\n", "                ", "alg", "=", "file_name", ".", "split", "(", "os", ".", "path", ".", "sep", ")", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", ".", "upper", "(", ")", "\n", "task_name", "=", "alg", "\n", "task_type", "=", "2", "\n", "", "task_id", "=", "TaskApi", "(", ")", ".", "add_task", "(", "task_type", ",", "task_name", ")", "\n", "\n", "if", "\"path\"", "in", "params_config", "[", "'dataset_params'", "]", ".", "keys", "(", ")", ":", "\n", "                ", "x_file", "=", "params_config", "[", "'dataset_params'", "]", "[", "'path'", "]", "\n", "dag_file", "=", "None", "\n", "", "else", ":", "\n", "                ", "x_file", "=", "params_config", "[", "'dataset_params'", "]", "[", "'x_file'", "]", "\n", "dag_file", "=", "params_config", "[", "'dataset_params'", "]", "[", "'dag_file'", "]", "\n", "\n", "", "if", "x_file", "is", "not", "None", ":", "\n", "                ", "dataset", "=", "DataSetApi", "(", "x_file", ")", "\n", "dataset", ".", "set_dataset_info", "(", "task_id", ")", "\n", "", "if", "dag_file", "is", "not", "None", ":", "\n", "                ", "true_dag", "=", "read_file", "(", "dag_file", ")", "\n", "TaskApi", "(", ")", ".", "update_true_dag", "(", "task_id", ",", "true_dag", ")", "\n", "task_path", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "'task'", ",", "task_id", ")", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "task_path", ",", "\"true.txt\"", ")", "\n", "save_gragh_edges", "(", "true_dag", ",", "file_name", ")", "\n", "", "algorithm", "=", "AlgorithmApi", "(", "alg", ",", "json", ".", "dumps", "(", "params_config", "[", "'algorithm_params'", "]", ")", ")", "\n", "algorithm", ".", "set_algorithm_info", "(", "task_id", ")", "\n", "", "except", "yaml", ".", "YAMLError", "as", "exc", ":", "\n", "            ", "print", "(", "exc", ")", "\n", "", "", "return", "task_id", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.save_param": [[955, 1022], ["web.models.base_class.AlgorithmApi.get_algorithm", "web.models.base_class.DataSetApi.get_dataset", "web.models.task_db.TaskApi().get_task_type", "web.models.task_db.TaskApi().get_task_name", "os.path.join", "AlgorithmApi.get_algorithm.keys", "AlgorithmApi.get_algorithm.keys", "web.common.utils.conversion_type", "os.path.join", "os.path.join", "task_data.update", "open", "web.models.task_db.TaskApi", "web.models.task_db.TaskApi", "web.models.base_class.DataSetApi.get_inline_dataset_names", "os.path.join", "os.path.join", "task_data.update", "task_data.update", "os.path.join", "task_data[].update", "dumpfile.write", "DataSetApi.get_dataset.split", "os.path.join", "task_data[].update", "task_data[].update", "yaml.dump", "print"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.AlgorithmApi.get_algorithm", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.base_class.DataSetApi.get_dataset", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_type", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.task_db.TaskApi.get_task_name", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.utils.conversion_type", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.view.task_view.get_inline_dataset_names"], ["", "def", "save_param", "(", "task_id", ")", ":", "\n", "    ", "\"\"\"\n    Save the exported configuration file.\n\n    Parameters\n    ----------\n    task_id: int\n        task key in the database.\n\n    Returns\n    -------\n    filename: str\n        profile path.\n    \"\"\"", "\n", "alg", "=", "AlgorithmApi", ".", "get_algorithm", "(", "task_id", ")", "\n", "alg_name", "=", "None", "\n", "if", "'algorithm'", "in", "alg", ".", "keys", "(", ")", ":", "\n", "        ", "alg_name", "=", "alg", "[", "'algorithm'", "]", "\n", "\n", "", "alg_params", "=", "None", "\n", "if", "'parameters'", "in", "alg", ".", "keys", "(", ")", ":", "\n", "        ", "alg_params", "=", "alg", "[", "'parameters'", "]", "\n", "\n", "", "path", "=", "DataSetApi", ".", "get_dataset", "(", "task_id", ")", "\n", "task_type", "=", "TaskApi", "(", ")", ".", "get_task_type", "(", "task_id", ")", "\n", "task_name", "=", "TaskApi", "(", ")", ".", "get_task_name", "(", "task_id", ")", "\n", "task_data", "=", "{", "\n", "\"algorithm_params\"", ":", "conversion_type", "(", "alg_name", ",", "alg_params", ")", ",", "\n", "\"task_params\"", ":", "{", "\n", "\"algorithm\"", ":", "alg_name", ",", "\n", "\"task_type\"", ":", "task_type", ",", "\n", "\"task_name\"", ":", "task_name", "}", "\n", "}", "\n", "\n", "if", "task_type", "==", "2", ":", "\n", "        ", "if", "path", "in", "DataSetApi", ".", "get_inline_dataset_names", "(", ")", ":", "\n", "            ", "path_task_id", "=", "path", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "sample_path", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "\"sample_\"", "+", "path_task_id", "+", "\".csv\"", ")", "\n", "true_dag_path", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "\"true_dag_\"", "+", "path_task_id", "+", "\".npz\"", ")", "\n", "task_data", ".", "update", "(", "{", "\"dataset_params\"", ":", "{", "\"path\"", ":", "path", ",", "\n", "\"x_file\"", ":", "sample_path", ",", "\n", "\"dag_file\"", ":", "true_dag_path", "}", "}", ")", "\n", "if", "alg_name", "==", "\"TTPM\"", ":", "\n", "                ", "topo_path", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "\"topo_\"", "+", "path_task_id", "+", "\".npz\"", ")", "\n", "task_data", "[", "\"dataset_params\"", "]", ".", "update", "(", "{", "\"topology_file\"", ":", "topo_path", "}", ")", "\n", "", "", "else", ":", "\n", "            ", "task_data", ".", "update", "(", "{", "\"dataset_params\"", ":", "{", "\"x_file\"", ":", "path", ",", "\n", "\"dag_file\"", ":", "None", "}", "}", ")", "\n", "if", "alg_name", "==", "\"TTPM\"", ":", "\n", "                ", "task_data", "[", "\"dataset_params\"", "]", ".", "update", "(", "{", "\"topology_file\"", ":", "None", "}", ")", "\n", "", "", "", "else", ":", "\n", "        ", "sample_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"sample_\"", "+", "task_id", "+", "\".csv\"", ")", "\n", "true_dag_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"true_dag_\"", "+", "task_id", "+", "\".npz\"", ")", "\n", "task_data", ".", "update", "(", "{", "\"dataset_params\"", ":", "{", "\"path\"", ":", "path", ",", "\n", "\"x_file\"", ":", "sample_path", ",", "\n", "\"dag_file\"", ":", "true_dag_path", "}", "}", ")", "\n", "if", "alg_name", "==", "\"EVENT\"", ":", "\n", "            ", "topo_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"topo_\"", "+", "task_id", "+", "\".npz\"", ")", "\n", "task_data", "[", "\"dataset_params\"", "]", ".", "update", "(", "{", "\"topology_file\"", ":", "topo_path", "}", ")", "\n", "\n", "", "", "filename", "=", "os", ".", "path", ".", "join", "(", "FILE_PATH", ",", "task_name", "+", "\".yaml\"", ")", "\n", "with", "open", "(", "filename", ",", "'w'", ")", "as", "dumpfile", ":", "\n", "        ", "try", ":", "\n", "            ", "dumpfile", ".", "write", "(", "yaml", ".", "dump", "(", "task_data", ")", ")", "\n", "", "except", "yaml", ".", "YAMLError", "as", "exc", ":", "\n", "            ", "print", "(", "exc", ")", "\n", "", "", "return", "filename", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.save_to_file": [[49, 67], ["isinstance", "ValueError", "file.split", "data.to_csv", "numpy.savetxt"], "function", ["None"], ["def", "save_to_file", "(", "data", ",", "file", ")", ":", "\n", "    ", "\"\"\"save data to file\n\n    Parameters\n    ----------\n    data: array or pd.DataFrame\n        The data need to save.\n    file: str\n        where to save the data.\n    \"\"\"", "\n", "\n", "if", "file", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", "in", "[", "'csv'", ",", "'npz'", "]", ":", "\n", "        ", "if", "isinstance", "(", "data", ",", "pd", ".", "DataFrame", ")", ":", "\n", "            ", "data", ".", "to_csv", "(", "file", ",", "index", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "np", ".", "savetxt", "(", "file", ",", "data", ",", "delimiter", "=", "','", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f'Invalid file type : {file}, muse be csv.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.run_simulate": [[69, 112], ["castle.datasets.DAG.erdos_renyi", "castle.datasets.Topology.erdos_renyi", "castle.datasets.THPSimulation", "castle.datasets.THPSimulation.simulate", "castle.datasets.DAG.erdos_renyi", "castle.datasets.IIDSimulation", "pandas.DataFrame"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.Topology.erdos_renyi", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.Topology.erdos_renyi", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.THPSimulation.simulate", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.simulator.Topology.erdos_renyi"], ["", "", "def", "run_simulate", "(", "config", ")", ":", "\n", "    ", "\"\"\"this function used to run simulate data task\n\n    Parameters\n    ----------\n    config: dict\n        configuration info.\n\n    Returns\n    -------\n    out: tuple\n        (X, true_dag) or (X, true_dag, topology_matrix)\n    \"\"\"", "\n", "\n", "algo_params", "=", "config", "[", "'algorithm_params'", "]", "\n", "if", "config", "[", "'task_params'", "]", "[", "'algorithm'", "]", "==", "'EVENT'", ":", "\n", "        ", "true_dag", "=", "DAG", ".", "erdos_renyi", "(", "n_nodes", "=", "algo_params", "[", "'n_nodes'", "]", ",", "\n", "n_edges", "=", "algo_params", "[", "'n_edges'", "]", ",", "\n", "weight_range", "=", "algo_params", "[", "'weight_range'", "]", ",", "\n", "seed", "=", "algo_params", "[", "'seed'", "]", ")", "\n", "topology_matrix", "=", "Topology", ".", "erdos_renyi", "(", "n_nodes", "=", "algo_params", "[", "'Topology_n_nodes'", "]", ",", "\n", "n_edges", "=", "algo_params", "[", "'Topology_n_edges'", "]", ",", "\n", "seed", "=", "algo_params", "[", "'Topology_seed'", "]", ")", "\n", "simulator", "=", "THPSimulation", "(", "true_dag", ",", "topology_matrix", ",", "\n", "mu_range", "=", "algo_params", "[", "'mu_range'", "]", ",", "\n", "alpha_range", "=", "algo_params", "[", "'alpha_range'", "]", ")", "\n", "X", "=", "simulator", ".", "simulate", "(", "T", "=", "algo_params", "[", "'THPSimulation_simulate_T'", "]", ",", "\n", "max_hop", "=", "algo_params", "[", "'THPSimulation_simulate_max_hop'", "]", ",", "\n", "beta", "=", "algo_params", "[", "'THPSimulation_simulate_beta'", "]", ")", "\n", "\n", "return", "X", ",", "true_dag", ",", "topology_matrix", "\n", "", "else", ":", "\n", "        ", "weighted_random_dag", "=", "DAG", ".", "erdos_renyi", "(", "n_nodes", "=", "algo_params", "[", "'n_nodes'", "]", ",", "\n", "n_edges", "=", "algo_params", "[", "'n_edges'", "]", ",", "\n", "weight_range", "=", "algo_params", "[", "'weight_range'", "]", ",", "\n", "seed", "=", "algo_params", "[", "'seed'", "]", ")", "\n", "dataset", "=", "IIDSimulation", "(", "W", "=", "weighted_random_dag", ",", "\n", "n", "=", "algo_params", "[", "'n'", "]", ",", "\n", "method", "=", "algo_params", "[", "'method'", "]", ",", "\n", "sem_type", "=", "algo_params", "[", "'sem_type'", "]", ",", "\n", "noise_scale", "=", "algo_params", "[", "'noise_scale'", "]", ")", "\n", "\n", "return", "pd", ".", "DataFrame", "(", "dataset", ".", "X", ")", ",", "dataset", ".", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.read_file": [[114, 144], ["os.path.exists", "pandas.read_csv", "os.path.exists", "numpy.loadtxt", "ValueError"], "function", ["None"], ["", "", "def", "read_file", "(", "file", ",", "header", "=", "None", ",", "index_col", "=", "None", ")", ":", "\n", "    ", "\"\"\"read data from file\n\n    Parameters\n    ----------\n    file: str\n        file path of data.\n    header: None or int\n        Be used in pd.read_csv.\n        If file type is `.csv`, you must provide right header to make sure\n        contain all examples dataset.\n    index_col: None or int\n        Be used in pd.read_csv.\n        If file type is `.csv`, you must provide right index_col to make sure\n        contain all examples dataset.\n\n    Returns\n    -------\n    out: array\n        data set.\n    \"\"\"", "\n", "\n", "if", "file", "and", "file", "[", "-", "4", ":", "]", "==", "'.csv'", "and", "os", ".", "path", ".", "exists", "(", "file", ")", ":", "\n", "        ", "x", "=", "pd", ".", "read_csv", "(", "file", ",", "header", "=", "header", ",", "index_col", "=", "index_col", ")", "\n", "", "elif", "file", "and", "file", "[", "-", "4", ":", "]", "==", "'.npz'", "and", "os", ".", "path", ".", "exists", "(", "file", ")", ":", "\n", "        ", "x", "=", "np", ".", "loadtxt", "(", "file", ",", "delimiter", "=", "\",\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid file type {}.'", ".", "format", "(", "file", ")", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.example.example.train": [[146, 198], ["castle.algorithms.NotearsLowRank.learn", "model_params.get", "castle.algorithms.NotearsLowRank", "castle.algorithms.NotearsLowRank.learn", "castle.common.GraphDAG", "castle.metrics.MetricsDAG", "print", "castle.common.GraphDAG", "castle.algorithms.NotearsLowRank.learn", "model_name.upper", "ValueError", "model_name.upper"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.BaseLearner.learn", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.BaseLearner.learn", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.common.base.BaseLearner.learn"], ["", "def", "train", "(", "model_name", ",", "X", ",", "true_dag", ",", "model_params", ",", "topology_matrix", "=", "None", ",", "plot", "=", "True", ")", ":", "\n", "    ", "\"\"\"run algorithm of castle\n\n    Parameters\n    ----------\n    model_name: str\n        algorithm name\n    X: pd.DataFrame\n        train data\n    true_dag: array\n        true directed acyclic graph\n    model_params: dict\n        Parameters from configuration file\n    topology_matrix: array, default None\n        topology graph matrix\n    plot: boolean, default None\n        whether show graph.\n\n    Returns\n    -------\n    model: castle.algorithm\n        model of castle.algorithm\n    pre_dag: array\n        discovered causal matrix\n    \"\"\"", "\n", "\n", "# Instantiation algorithm and learn dag", "\n", "if", "model_name", "==", "'TTPM'", ":", "\n", "        ", "model", "=", "INLINE_ALGORITHMS", "[", "model_name", ".", "upper", "(", ")", "]", "(", "topology_matrix", ",", "**", "model_params", ")", "\n", "model", ".", "learn", "(", "X", ")", "\n", "", "elif", "model_name", "==", "'NOTEARSLOWRANK'", ":", "\n", "        ", "rank", "=", "model_params", ".", "get", "(", "'rank'", ")", "\n", "del", "model_params", "[", "'rank'", "]", "\n", "model", "=", "NotearsLowRank", "(", "**", "model_params", ")", "\n", "model", ".", "learn", "(", "X", ",", "rank", "=", "rank", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "model", "=", "INLINE_ALGORITHMS", "[", "model_name", ".", "upper", "(", ")", "]", "(", "**", "model_params", ")", "\n", "model", ".", "learn", "(", "data", "=", "X", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid algorithm name: {}.'", ".", "format", "(", "model_name", ")", ")", "\n", "\n", "", "", "pre_dag", "=", "model", ".", "causal_matrix", "\n", "if", "plot", ":", "\n", "        ", "if", "true_dag", "is", "not", "None", ":", "\n", "            ", "GraphDAG", "(", "pre_dag", ",", "true_dag", ",", "show", "=", "plot", ")", "\n", "m", "=", "MetricsDAG", "(", "pre_dag", ",", "true_dag", ")", "\n", "print", "(", "m", ".", "metrics", ")", "\n", "", "else", ":", "\n", "            ", "GraphDAG", "(", "pre_dag", ",", "show", "=", "plot", ")", "\n", "\n", "", "", "return", "model", ",", "pre_dag", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.run_pendulum.DeterministicWarmup.__init__": [[58, 62], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "n", "=", "100", ",", "t_max", "=", "1", ")", ":", "\n", "\t\t", "self", ".", "t", "=", "0", "\n", "self", ".", "t_max", "=", "t_max", "\n", "self", ".", "inc", "=", "1", "/", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.run_pendulum.DeterministicWarmup.__iter__": [[63, 65], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "\t\t", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.run_pendulum.DeterministicWarmup.__next__": [[66, 71], ["None"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "\t\t", "t", "=", "self", ".", "t", "+", "self", ".", "inc", "\n", "\n", "self", ".", "t", "=", "self", ".", "t_max", "if", "t", ">", "self", ".", "t_max", "else", "t", "\n", "return", "self", ".", "t", "\n", "", "", "layout", "=", "[", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.run_pendulum._sigmoid": [[48, 52], ["torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.inverse.size"], "function", ["None"], ["def", "_sigmoid", "(", "x", ")", ":", "\n", "    ", "I", "=", "torch", ".", "eye", "(", "x", ".", "size", "(", ")", "[", "0", "]", ")", ".", "to", "(", "device", ")", "\n", "x", "=", "torch", ".", "inverse", "(", "I", "+", "torch", ".", "exp", "(", "-", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.run_pendulum.save_model_by_name": [[92, 100], ["os.path.join", "os.path.join", "model.state_dict", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save"], ["def", "save_model_by_name", "(", "model", ",", "global_step", ")", ":", "\n", "\t", "save_dir", "=", "os", ".", "path", ".", "join", "(", "'checkpoints'", ",", "model", ".", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "\t\t", "os", ".", "makedirs", "(", "save_dir", ")", "\n", "", "file_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'model-{:05d}.pt'", ".", "format", "(", "global_step", ")", ")", "\n", "state", "=", "model", ".", "state_dict", "(", ")", "\n", "torch", ".", "save", "(", "state", ",", "file_path", ")", "\n", "print", "(", "'Saved to {}'", ".", "format", "(", "file_path", ")", ")", "\n", "", "for", "epoch", "in", "range", "(", "args", ".", "epoch_max", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.run_flow.DeterministicWarmup.__init__": [[58, 62], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "n", "=", "100", ",", "t_max", "=", "1", ")", ":", "\n", "\t\t", "self", ".", "t", "=", "0", "\n", "self", ".", "t_max", "=", "t_max", "\n", "self", ".", "inc", "=", "1", "/", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.run_flow.DeterministicWarmup.__iter__": [[63, 65], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "\t\t", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.run_flow.DeterministicWarmup.__next__": [[66, 71], ["None"], "methods", ["None"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "\t\t", "t", "=", "self", ".", "t", "+", "self", ".", "inc", "\n", "\n", "self", ".", "t", "=", "self", ".", "t_max", "if", "t", ">", "self", ".", "t_max", "else", "t", "\n", "return", "self", ".", "t", "\n", "", "", "layout", "=", "[", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.run_flow._sigmoid": [[48, 52], ["torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.inverse.size"], "function", ["None"], ["def", "_sigmoid", "(", "x", ")", ":", "\n", "    ", "I", "=", "torch", ".", "eye", "(", "x", ".", "size", "(", ")", "[", "0", "]", ")", ".", "to", "(", "device", ")", "\n", "x", "=", "torch", ".", "inverse", "(", "I", "+", "torch", ".", "exp", "(", "-", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.run_flow.save_model_by_name": [[90, 98], ["os.path.join", "os.path.join", "model.state_dict", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save"], ["def", "save_model_by_name", "(", "model", ",", "global_step", ")", ":", "\n", "\t", "save_dir", "=", "os", ".", "path", ".", "join", "(", "'checkpoints'", ",", "model", ".", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "\t\t", "os", ".", "makedirs", "(", "save_dir", ")", "\n", "", "file_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'model-{:05d}.pt'", ".", "format", "(", "global_step", ")", ")", "\n", "state", "=", "model", ".", "state_dict", "(", ")", "\n", "torch", ".", "save", "(", "state", ",", "file_path", ")", "\n", "print", "(", "'Saved to {}'", ".", "format", "(", "file_path", ")", ")", "\n", "", "for", "epoch", "in", "range", "(", "args", ".", "epoch_max", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.dataload.__init__": [[85, 89], ["os.listdir", "torchvision.transforms.Compose", "os.path.join", "torchvision.transforms.ToTensor"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.dataload.__getitem__": [[90, 101], ["PIL.Image.open", "numpy.asarray", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "utils.dataload.transforms", "numpy.asarray().reshape", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.asarray"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.dataload.__len__": [[102, 104], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.dataload_withlabel.__init__": [[116, 127], ["os.listdir", "torchvision.transforms.Compose", "os.path.join", "list", "map", "torchvision.transforms.ToTensor", "k[].split"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.dataload_withlabel.__getitem__": [[128, 146], ["torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "PIL.Image.open", "numpy.asarray", "numpy.asarray", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.asarray", "utils.dataload_withlabel.transforms", "numpy.asarray().reshape", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy.float", "torch.from_numpy.float", "torch.from_numpy.float", "torch.from_numpy.float", "numpy.asarray"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.dataload_withlabel.__len__": [[147, 149], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.prune": [[24, 28], ["torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.zeros_like().to", "torch.where", "torch.where", "torch.where", "torch.where", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["None"], ["import", "random", "\n", "import", "torch", "\n", "import", "numpy", "as", "np", "\n", "import", "networkx", "as", "nx", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.gumble_dag_loss": [[28, 32], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.gumbel_softmax", "torch.trace", "torch.trace", "torch.trace", "torch.trace", "A.size"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.gumbel_softmax"], ["\n", "\n", "def", "is_cuda_available", "(", ")", ":", "\n", "    ", "return", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.filldiag_zero": [[32, 36], ["torch.eye().byte().to", "torch.eye().byte().to", "torch.eye().byte().to", "torch.eye().byte().to", "A.masked_fill_", "torch.eye().byte", "torch.eye().byte", "torch.eye().byte", "torch.eye().byte", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "A.size", "A.size"], "function", ["None"], ["\n", "\n", "", "def", "set_seed", "(", "seed", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.matrix_poly": [[43, 46], ["torch.matrix_power", "torch.matrix_power", "torch.matrix_power", "torch.matrix_power", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.eye().to", "torch.div().to", "torch.div().to", "torch.div().to", "torch.div().to", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.div", "torch.div", "torch.div", "torch.div", "matrix.to"], "function", ["None"], ["random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.mask_threshold": [[40, 43], ["None"], "function", ["None"], ["\n", "random", ".", "seed", "(", "seed", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils._h_A": [[48, 52], ["utils.matrix_poly", "torch.trace", "torch.trace", "torch.trace", "torch.trace"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.matrix_poly"], ["try", ":", "\n", "        ", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.get_parse_args": [[54, 61], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "def", "is_dag", "(", "B", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.weights_init": [[62, 71], ["torch.init.normal_", "type", "type", "type", "torch.init.normal_", "torch.init.constant_", "type", "torch.init.kaiming_uniform_", "torch.init.constant_"], "function", ["None"], ["\n", "return", "nx", ".", "is_directed_acyclic_graph", "(", "nx", ".", "DiGraph", "(", "B", ")", ")", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.compute_theta_class": [[72, 83], ["numpy.linspace", "zip"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.read_label": [[105, 112], ["open", "f.readlines", "numpy.array", "x.replace", "numpy.array", "list", "map", "x[].strip().split", "x[].strip"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.get_partitions": [[151, 171], ["math.floor", "numpy.linspace", "zip", "numpy.append", "partitions_list.append"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.whether_num_fall_into_intevals": [[172, 185], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.Causal_Disentangled_Representation_Learning.utils.get_batch_unin_dataset_withlabel": [[187, 193], ["utils.dataload_withlabel", "torch.DataLoader"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.DeterministicWarmup.__init__": [[553, 557], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.DeterministicWarmup.__iter__": [[558, 560], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.DeterministicWarmup.__next__": [[561, 566], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.FixedSeed.__init__": [[568, 571], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.FixedSeed.__enter__": [[572, 575], ["numpy.random.get_state", "numpy.random.seed"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.FixedSeed.__exit__": [[576, 578], ["numpy.random.set_state"], "methods", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.mask_threshold": [[24, 27], ["None"], "function", ["None"], ["import", "random", "\n", "import", "torch", "\n", "import", "numpy", "as", "np", "\n", "import", "networkx", "as", "nx", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.label_cov": [[28, 31], ["torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy", "torch.from_numpy", "numpy.cov"], "function", ["None"], ["\n", "\n", "def", "is_cuda_available", "(", ")", ":", "\n", "    ", "return", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.get_labelcov_prior": [[32, 39], ["torch.zeros", "torch.zeros", "range", "torch.zeros", "torch.zeros", "cov.size", "cov.size", "cov.size"], "function", ["None"], ["\n", "\n", "", "def", "set_seed", "(", "seed", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.vector_expand": [[40, 46], ["torch.zeros().to", "torch.zeros().to", "range", "range", "torch.zeros", "torch.zeros", "v.size", "v.size", "v.size", "v.size", "v.size"], "function", ["None"], ["\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.block_matmul": [[47, 49], ["None"], "function", ["None"], ["torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "try", ":", "\n", "        ", "os", ".", "environ", "[", "'PYTHONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.multivariate_sample": [[50, 56], ["m.reshape.reshape", "torch.zeros", "torch.zeros", "range", "torch.zeros.to", "m.reshape.size", "torch.distributions.multivariate_normal.MultivariateNormal().sample", "m.reshape.size", "torch.zeros.size", "torch.distributions.multivariate_normal.MultivariateNormal", "m[].cpu", "cov[].cpu"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.mindspore.gran_dag.NormalizationData.sample"], ["", "except", ":", "\n", "        ", "pass", "\n", "\n", "\n", "", "", "def", "is_dag", "(", "B", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.kl_multinormal_cov": [[57, 65], ["torch.zeros().to", "torch.zeros().to", "range", "torch.zeros", "torch.zeros", "qm.size", "qm.size", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.log", "torch.log", "torch.log", "torch.log", "torch.trace", "torch.trace", "torch.trace", "torch.trace", "torch.det", "torch.det", "torch.det", "torch.det", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse"], "function", ["None"], ["\n", "return", "nx", ".", "is_directed_acyclic_graph", "(", "nx", ".", "DiGraph", "(", "B", ")", ")", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.conditional_sample_gaussian": [[67, 72], ["torch.randn().to", "torch.randn().to", "torch.randn", "torch.randn", "m.size"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.condition_gaussian_parameters": [[73, 80], ["torch.split", "torch.split", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.nn.functional.softplus", "torch.reshape.size"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.condition_prior": [[81, 90], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "range", "range", "label.size", "label.size", "label.size", "label.size", "label.size", "label.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "float"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.bce2": [[92, 94], ["torch.log", "torch.log", "torch.log", "torch.log"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.sample_multivariate": [[106, 111], ["torch.distributions.multivariate_normal.MultivariateNormal", "torch.distributions.multivariate_normal.MultivariateNormal"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.get_covariance_matrix": [[112, 121], ["torch.zeros().to", "torch.zeros().to", "torch.eye().to", "torch.eye().to", "range", "torch.inverse", "torch.inverse", "A.size", "A.size", "torch.zeros", "torch.zeros", "torch.eye", "torch.eye", "A.size", "torch.mm", "torch.mm", "A.size", "torch.t", "torch.t", "A.size"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.sample_gaussian": [[123, 147], ["torch.randn().to", "torch.randn().to", "torch.randn", "torch.randn"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_normal": [[148, 182], ["torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "x.size", "torch.log", "torch.log", "torch.tensor", "torch.tensor"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_normal_mixture": [[184, 212], ["z.unsqueeze.unsqueeze", "utils.log_normal", "utils.log_mean_exp"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_normal", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_mean_exp"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.gaussian_parameters": [[214, 231], ["torch.split", "torch.split", "torch.nn.functional.softplus", "h.size"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_bernoulli_with_logits": [[233, 246], ["bce().sum", "bce"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_bernoulli_with_logits_nosigmoid": [[247, 262], ["bce2().sum", "utils.bce2"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.bce2"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.kl_cat": [[266, 281], ["element_wise.sum"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.kl_normal": [[283, 301], ["element_wise.sum", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.duplicate": [[303, 315], ["x.expand().reshape", "x.expand"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_mean_exp": [[317, 329], ["utils.log_sum_exp", "numpy.log", "x.size"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_sum_exp"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_sum_exp": [[331, 345], ["torch.max", "torch.max", "max_x.unsqueeze().expand_as", "new_x.exp().sum().log", "max_x.unsqueeze", "new_x.exp().sum", "new_x.exp"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.load_model_by_name": [[347, 361], ["os.path.join", "torch.load", "torch.load", "model.load_state_dict", "print"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.RealDataSet.load", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.datasets.builtin_dataset.RealDataSet.load"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.evaluate_lower_bound": [[369, 403], ["print", "print", "print", "torch.manual_seed", "torch.manual_seed", "torch.bernoulli", "torch.bernoulli", "utils.evaluate_lower_bound.compute_metrics"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.evaluate_classifier": [[405, 417], ["isinstance", "print", "print", "print", "model.cls.classify", "print", "model.cls.classify.argmax"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.classify"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.save_model_by_name": [[419, 427], ["os.path.join", "os.path.join", "model.state_dict", "torch.save", "torch.save", "print", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.models.gae.GAE.save"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.prepare_writer": [[429, 439], ["os.path.join", "os.path.join", "utils.delete_existing", "utils.delete_existing"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.delete_existing", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.delete_existing"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.log_summaries": [[441, 443], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.delete_existing": [[450, 454], ["os.path.exists", "print", "shutil.rmtree"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.reset_weights": [[456, 461], ["m.reset_parameters"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.utils.locally_connected.LocallyConnected.reset_parameters"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.get_mnist_data": [[463, 498], ["torchvision.transforms.ToTensor", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader.dataset.train_labels.to", "torch.utils.data.DataLoader.dataset.test_labels.to", "range", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "yl.new.new", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader.dataset.train_data.to().reshape().float", "torch.utils.data.DataLoader.dataset.test_data.to().reshape().float", "utils.get_mnist_index", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.eye", "torch.utils.data.DataLoader.dataset.train_data.to().reshape", "torch.utils.data.DataLoader.dataset.test_data.to().reshape", "torch.utils.data.DataLoader.dataset.train_data.to", "torch.utils.data.DataLoader.dataset.test_data.to"], "function", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.get_mnist_index"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.get_mnist_index": [[500, 529], ["numpy.array", "numpy.array"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.get_svhn_data": [[531, 539], ["torchvision.transforms.ToTensor", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.datasets.SVHN"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.gumbel_softmax": [[541, 547], ["torch.rand_like", "torch.rand_like", "torch.nn.functional.softmax", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["None"], []], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.MaskLayer.__init__": [[55, 86], ["torch.nn.Module.__init__", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["\t", "def", "__init__", "(", "self", ",", "z_dim", ",", "concept", "=", "4", ",", "z1_dim", "=", "4", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "z1_dim", "=", "z1_dim", "\n", "self", ".", "concept", "=", "concept", "\n", "\n", "self", ".", "elu", "=", "nn", ".", "ELU", "(", ")", "\n", "self", ".", "net1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "32", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "32", ",", "z1_dim", ")", ",", "\n", ")", "\n", "self", ".", "net2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "32", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "32", ",", "z1_dim", ")", ",", "\n", ")", "\n", "self", ".", "net3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "32", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "32", ",", "z1_dim", ")", ",", "\n", ")", "\n", "self", ".", "net4", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "32", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "32", ",", "z1_dim", ")", "\n", ")", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z_dim", ",", "32", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "32", ",", "z_dim", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.MaskLayer.masked": [[87, 91], ["mask.MaskLayer.view", "mask.MaskLayer.net"], "methods", ["None"], ["", "def", "masked", "(", "self", ",", "z", ")", ":", "\n", "\t\t", "z", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", "\n", "z", "=", "self", ".", "net", "(", "z", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.MaskLayer.masked_sep": [[92, 96], ["mask.MaskLayer.view", "mask.MaskLayer.net"], "methods", ["None"], ["", "def", "masked_sep", "(", "self", ",", "z", ")", ":", "\n", "\t\t", "z", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", "\n", "z", "=", "self", ".", "net", "(", "z", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.MaskLayer.mix": [[97, 120], ["z.view", "mask.MaskLayer.net1", "mask.MaskLayer.net2", "mask.MaskLayer.net3", "zy.reshape.reshape.reshape", "mask.MaskLayer.net4", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "zy.reshape.reshape.size", "zy.reshape.reshape.size", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split"], "methods", ["None"], ["", "def", "mix", "(", "self", ",", "z", ")", ":", "\n", "\t\t", "zy", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "concept", "*", "self", ".", "z1_dim", ")", "\n", "if", "self", ".", "z1_dim", "==", "1", ":", "\n", "\t\t\t", "zy", "=", "zy", ".", "reshape", "(", "zy", ".", "size", "(", ")", "[", "0", "]", ",", "zy", ".", "size", "(", ")", "[", "1", "]", ",", "1", ")", "\n", "if", "self", ".", "concept", "==", "4", ":", "\n", "\t\t\t\t", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "zy", "[", ":", ",", "0", "]", ",", "zy", "[", ":", ",", "1", "]", ",", "zy", "[", ":", ",", "2", "]", ",", "zy", "[", ":", ",", "3", "]", "\n", "", "elif", "self", ".", "concept", "==", "3", ":", "\n", "\t\t\t\t", "zy1", ",", "zy2", ",", "zy3", "=", "zy", "[", ":", ",", "0", "]", ",", "zy", "[", ":", ",", "1", "]", ",", "zy", "[", ":", ",", "2", "]", "\n", "", "", "else", ":", "\n", "\t\t\t", "if", "self", ".", "concept", "==", "4", ":", "\n", "\t\t\t\t", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "torch", ".", "split", "(", "zy", ",", "self", ".", "z_dim", "//", "self", ".", "concept", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "concept", "==", "3", ":", "\n", "\t\t\t\t", "zy1", ",", "zy2", ",", "zy3", "=", "torch", ".", "split", "(", "zy", ",", "self", ".", "z_dim", "//", "self", ".", "concept", ",", "dim", "=", "1", ")", "\n", "", "", "rx1", "=", "self", ".", "net1", "(", "zy1", ")", "\n", "rx2", "=", "self", ".", "net2", "(", "zy2", ")", "\n", "rx3", "=", "self", ".", "net3", "(", "zy3", ")", "\n", "if", "self", ".", "concept", "==", "4", ":", "\n", "\t\t\t", "rx4", "=", "self", ".", "net4", "(", "zy4", ")", "\n", "h", "=", "torch", ".", "cat", "(", "(", "rx1", ",", "rx2", ",", "rx3", ",", "rx4", ")", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "concept", "==", "3", ":", "\n", "\t\t\t", "h", "=", "torch", ".", "cat", "(", "(", "rx1", ",", "rx2", ",", "rx3", ")", ",", "dim", "=", "1", ")", "\n", "#print(h.size())", "\n", "", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Mix.__init__": [[122, 148], ["torch.nn.Module.__init__", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["\t", "def", "__init__", "(", "self", ",", "z_dim", ",", "concept", ",", "z1_dim", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "z1_dim", "=", "z1_dim", "\n", "self", ".", "concept", "=", "concept", "\n", "\n", "self", ".", "elu", "=", "nn", ".", "ELU", "(", ")", "\n", "self", ".", "net1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "16", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "16", ",", "z1_dim", ")", ",", "\n", ")", "\n", "self", ".", "net2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "16", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "16", ",", "z1_dim", ")", ",", "\n", ")", "\n", "self", ".", "net3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "16", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "16", ",", "z1_dim", ")", ",", "\n", ")", "\n", "self", ".", "net4", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "16", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "16", ",", "z1_dim", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Mix.mix": [[151, 165], ["z.view", "mask.Mix.net1", "mask.Mix.net2", "mask.Mix.net3", "mask.Mix.net4", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "zy.reshape.reshape.reshape", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "zy.reshape.reshape.size", "zy.reshape.reshape.size"], "methods", ["None"], ["", "def", "mix", "(", "self", ",", "z", ")", ":", "\n", "\t\t", "zy", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "concept", "*", "self", ".", "z1_dim", ")", "\n", "if", "self", ".", "z1_dim", "==", "1", ":", "\n", "\t\t\t", "zy", "=", "zy", ".", "reshape", "(", "zy", ".", "size", "(", ")", "[", "0", "]", ",", "zy", ".", "size", "(", ")", "[", "1", "]", ",", "1", ")", "\n", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "zy", "[", ":", ",", "0", "]", ",", "zy", "[", ":", ",", "1", "]", ",", "zy", "[", ":", ",", "2", "]", ",", "zy", "[", ":", ",", "3", "]", "\n", "", "else", ":", "\n", "\t\t\t", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "torch", ".", "split", "(", "zy", ",", "self", ".", "z_dim", "//", "self", ".", "concept", ",", "dim", "=", "1", ")", "\n", "", "rx1", "=", "self", ".", "net1", "(", "zy1", ")", "\n", "rx2", "=", "self", ".", "net2", "(", "zy2", ")", "\n", "rx3", "=", "self", ".", "net3", "(", "zy3", ")", "\n", "rx4", "=", "self", ".", "net4", "(", "zy4", ")", "\n", "h", "=", "torch", ".", "cat", "(", "(", "rx1", ",", "rx2", ",", "rx3", ",", "rx4", ")", ",", "dim", "=", "1", ")", "\n", "#print(h.size())", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.CausalLayer.__init__": [[168, 199], ["torch.nn.Module.__init__", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["\t", "def", "__init__", "(", "self", ",", "z_dim", ",", "concept", "=", "4", ",", "z1_dim", "=", "4", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "z1_dim", "=", "z1_dim", "\n", "self", ".", "concept", "=", "concept", "\n", "\n", "self", ".", "elu", "=", "nn", ".", "ELU", "(", ")", "\n", "self", ".", "net1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "32", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "32", ",", "z1_dim", ")", ",", "\n", ")", "\n", "self", ".", "net2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "32", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "32", ",", "z1_dim", ")", ",", "\n", ")", "\n", "self", ".", "net3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "32", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "32", ",", "z1_dim", ")", ",", "\n", ")", "\n", "self", ".", "net4", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", ",", "32", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "32", ",", "z1_dim", ")", "\n", ")", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z_dim", ",", "128", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "128", ",", "z_dim", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.CausalLayer.calculate": [[201, 205], ["mask.CausalLayer.view", "mask.CausalLayer.net"], "methods", ["None"], ["", "def", "calculate", "(", "self", ",", "z", ",", "v", ")", ":", "\n", "\t\t", "z", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", "\n", "z", "=", "self", ".", "net", "(", "z", ")", "\n", "return", "z", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.CausalLayer.masked_sep": [[206, 210], ["mask.CausalLayer.view", "mask.CausalLayer.net"], "methods", ["None"], ["", "def", "masked_sep", "(", "self", ",", "z", ",", "v", ")", ":", "\n", "\t\t", "z", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "z_dim", ")", "\n", "z", "=", "self", ".", "net", "(", "z", ")", "\n", "return", "z", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.CausalLayer.calculate_dag": [[211, 225], ["z.view", "mask.CausalLayer.net1", "mask.CausalLayer.net2", "mask.CausalLayer.net3", "mask.CausalLayer.net4", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "zy.reshape.reshape.reshape", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "zy.reshape.reshape.size", "zy.reshape.reshape.size"], "methods", ["None"], ["", "def", "calculate_dag", "(", "self", ",", "z", ",", "v", ")", ":", "\n", "\t\t", "zy", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "concept", "*", "self", ".", "z1_dim", ")", "\n", "if", "self", ".", "z1_dim", "==", "1", ":", "\n", "\t\t\t", "zy", "=", "zy", ".", "reshape", "(", "zy", ".", "size", "(", ")", "[", "0", "]", ",", "zy", ".", "size", "(", ")", "[", "1", "]", ",", "1", ")", "\n", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "zy", "[", ":", ",", "0", "]", ",", "zy", "[", ":", ",", "1", "]", ",", "zy", "[", ":", ",", "2", "]", ",", "zy", "[", ":", ",", "3", "]", "\n", "", "else", ":", "\n", "\t\t\t", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "torch", ".", "split", "(", "zy", ",", "self", ".", "z_dim", "//", "self", ".", "concept", ",", "dim", "=", "1", ")", "\n", "", "rx1", "=", "self", ".", "net1", "(", "zy1", ")", "\n", "rx2", "=", "self", ".", "net2", "(", "zy2", ")", "\n", "rx3", "=", "self", ".", "net3", "(", "zy3", ")", "\n", "rx4", "=", "self", ".", "net4", "(", "zy4", ")", "\n", "h", "=", "torch", ".", "cat", "(", "(", "rx1", ",", "rx2", ",", "rx3", ",", "rx4", ")", ",", "dim", "=", "1", ")", "\n", "#print(h.size())", "\n", "return", "h", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Attention.__init__": [[228, 232], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["  ", "def", "__init__", "(", "self", ",", "in_features", ",", "bias", "=", "False", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "M", "=", "nn", ".", "Parameter", "(", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "zeros", "(", "in_features", ",", "in_features", ")", ",", "mean", "=", "0", ",", "std", "=", "1", ")", ")", "\n", "self", ".", "sigmd", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "#self.M =  nn.Parameter(torch.zeros(in_features,in_features))", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Attention.attention": [[235, 242], ["z.matmul().matmul", "mask.Attention.sigmd", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul.permute", "torch.matmul.permute", "torch.matmul.permute", "torch.matmul.permute", "z.matmul"], "methods", ["None"], ["", "def", "attention", "(", "self", ",", "z", ",", "e", ")", ":", "\n", "    ", "a", "=", "z", ".", "matmul", "(", "self", ".", "M", ")", ".", "matmul", "(", "e", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "a", "=", "self", ".", "sigmd", "(", "a", ")", "\n", "#print(self.M)", "\n", "A", "=", "torch", ".", "softmax", "(", "a", ",", "dim", "=", "1", ")", "\n", "e", "=", "torch", ".", "matmul", "(", "A", ",", "e", ")", "\n", "return", "e", ",", "A", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.__init__": [[244, 265], ["torch.nn.Linear.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "Parameter", "mask.DagLayer.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "i", "=", "False", ",", "bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "Linear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "i", "=", "i", "\n", "self", ".", "a", "=", "torch", ".", "zeros", "(", "out_features", ",", "out_features", ")", "\n", "self", ".", "a", "=", "self", ".", "a", "\n", "#self.a[0][1], self.a[0][2], self.a[0][3] = 1,1,1", "\n", "#self.a[1][2], self.a[1][3] = 1,1", "\n", "self", ".", "A", "=", "nn", ".", "Parameter", "(", "self", ".", "a", ")", "\n", "\n", "self", ".", "b", "=", "torch", ".", "eye", "(", "out_features", ")", "\n", "self", ".", "b", "=", "self", ".", "b", "\n", "self", ".", "B", "=", "nn", ".", "Parameter", "(", "self", ".", "b", ")", "\n", "\n", "self", ".", "I", "=", "nn", ".", "Parameter", "(", "torch", ".", "eye", "(", "out_features", ")", ")", "\n", "self", ".", "I", ".", "requires_grad", "=", "False", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.mask_z": [[266, 274], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "mask.DagLayer.B.t"], "methods", ["None"], ["", "", "def", "mask_z", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "B", "=", "self", ".", "A", "\n", "#if self.i:", "\n", "#    x = x.view(-1, x.size()[1], 1)", "\n", "#    x = torch.matmul((self.B+0.5).t().int().float(), x)", "\n", "#    return x", "\n", "x", "=", "torch", ".", "matmul", "(", "self", ".", "B", ".", "t", "(", ")", ",", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.mask_u": [[275, 284], ["torch.matmul.view", "torch.matmul.view", "torch.matmul.view", "torch.matmul.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "mask.DagLayer.B.t", "torch.matmul.size", "torch.matmul.size", "torch.matmul.size", "torch.matmul.size"], "methods", ["None"], ["", "def", "mask_u", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "B", "=", "self", ".", "A", "\n", "#if self.i:", "\n", "#    x = x.view(-1, x.size()[1], 1)", "\n", "#    x = torch.matmul((self.B+0.5).t().int().float(), x)", "\n", "#    return x", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", ")", "[", "1", "]", ",", "1", ")", "\n", "x", "=", "torch", ".", "matmul", "(", "self", ".", "B", ".", "t", "(", ")", ",", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.inv_cal": [[285, 293], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "x.permute().contiguous.permute().contiguous.dim", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.dim", "x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.permute"], "methods", ["None"], ["", "def", "inv_cal", "(", "self", ",", "x", ",", "v", ")", ":", "\n", "        ", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "", "x", "=", "F", ".", "linear", "(", "x", ",", "self", ".", "I", "-", "self", ".", "A", ",", "self", ".", "bias", ")", "\n", "\n", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "return", "x", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.calculate_dag": [[294, 306], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "x.permute().contiguous.permute().contiguous.dim", "x.permute().contiguous.permute().contiguous.permute", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "x.permute().contiguous.permute().contiguous.dim", "x.permute().contiguous.permute().contiguous.permute().contiguous", "mask.DagLayer.A.t", "x.permute().contiguous.permute().contiguous.permute"], "methods", ["None"], ["", "def", "calculate_dag", "(", "self", ",", "x", ",", "v", ")", ":", "\n", "#print(self.A)", "\n", "#x = F.linear(x, torch.inverse((torch.abs(self.A))+self.I), self.bias)", "\n", "\n", "        ", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "", "x", "=", "F", ".", "linear", "(", "x", ",", "torch", ".", "inverse", "(", "self", ".", "I", "-", "self", ".", "A", ".", "t", "(", ")", ")", ",", "self", ".", "bias", ")", "\n", "#print(x.size())", "\n", "\n", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "return", "x", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.calculate_cov": [[307, 316], ["codebase.utils.vector_expand", "mask.dag_left_linear", "mask.dag_left_linear", "mask.dag_right_linear", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.vector_expand", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.dag_left_linear", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.dag_left_linear", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.dag_right_linear"], ["", "def", "calculate_cov", "(", "self", ",", "x", ",", "v", ")", ":", "\n", "#print(self.A)", "\n", "        ", "v", "=", "ut", ".", "vector_expand", "(", "v", ")", "\n", "#x = F.linear(x, torch.inverse((torch.abs(self.A))+self.I), self.bias)", "\n", "x", "=", "dag_left_linear", "(", "x", ",", "torch", ".", "inverse", "(", "self", ".", "I", "-", "self", ".", "A", ")", ",", "self", ".", "bias", ")", "\n", "v", "=", "dag_left_linear", "(", "v", ",", "torch", ".", "inverse", "(", "self", ".", "I", "-", "self", ".", "A", ")", ",", "self", ".", "bias", ")", "\n", "v", "=", "dag_right_linear", "(", "v", ",", "torch", ".", "inverse", "(", "self", ".", "I", "-", "self", ".", "A", ")", ",", "self", ".", "bias", ")", "\n", "#print(v)", "\n", "return", "x", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.calculate_gaussian_ini": [[317, 330], ["print", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "x.permute().contiguous.permute().contiguous.dim", "x.permute().contiguous.permute().contiguous.permute", "v.permute().contiguous.permute().contiguous.permute", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "x.permute().contiguous.permute().contiguous.dim", "x.permute().contiguous.permute().contiguous.permute().contiguous", "v.permute().contiguous.permute().contiguous.permute().contiguous", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "x.permute().contiguous.permute().contiguous.permute", "v.permute().contiguous.permute().contiguous.permute"], "methods", ["None"], ["", "def", "calculate_gaussian_ini", "(", "self", ",", "x", ",", "v", ")", ":", "\n", "        ", "print", "(", "self", ".", "A", ")", "\n", "#x = F.linear(x, torch.inverse((torch.abs(self.A))+self.I), self.bias)", "\n", "\n", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "v", "=", "v", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "", "x", "=", "F", ".", "linear", "(", "x", ",", "torch", ".", "inverse", "(", "self", ".", "I", "-", "self", ".", "A", ")", ",", "self", ".", "bias", ")", "\n", "v", "=", "F", ".", "linear", "(", "v", ",", "torch", ".", "mul", "(", "torch", ".", "inverse", "(", "self", ".", "I", "-", "self", ".", "A", ")", ",", "torch", ".", "inverse", "(", "self", ".", "I", "-", "self", ".", "A", ")", ")", ",", "self", ".", "bias", ")", "\n", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "v", "=", "v", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "return", "x", ",", "v", "\n", "#def encode_", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.forward": [[349, 352], ["torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "*", "torch", ".", "inverse", "(", "(", "self", ".", "A", ")", "+", "self", ".", "I", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.DagLayer.calculate_gaussian": [[334, 348], ["print", "mask.dag_left_linear", "mask.dag_left_linear", "mask.dag_right_linear", "x.permute().contiguous.permute().contiguous.dim", "x.permute().contiguous.permute().contiguous.permute", "v.permute().contiguous.permute().contiguous.permute", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "torch.inverse", "x.permute().contiguous.permute().contiguous.dim", "x.permute().contiguous.permute().contiguous.permute().contiguous", "v.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.permute", "v.permute().contiguous.permute().contiguous.permute"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.dag_left_linear", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.dag_left_linear", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.dag_right_linear"], ["", "def", "calculate_gaussian", "(", "self", ",", "x", ",", "v", ")", ":", "\n", "        ", "print", "(", "self", ".", "A", ")", "\n", "#x = F.linear(x, torch.inverse((torch.abs(self.A))+self.I), self.bias)", "\n", "\n", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "v", "=", "v", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "", "x", "=", "dag_left_linear", "(", "x", ",", "torch", ".", "inverse", "(", "self", ".", "I", "-", "self", ".", "A", ")", ",", "self", ".", "bias", ")", "\n", "v", "=", "dag_left_linear", "(", "v", ",", "torch", ".", "inverse", "(", "self", ".", "I", "-", "self", ".", "A", ")", ",", "self", ".", "bias", ")", "\n", "v", "=", "dag_right_linear", "(", "v", ",", "torch", ".", "inverse", "(", "self", ".", "I", "-", "self", ".", "A", ")", ",", "self", ".", "bias", ")", "\n", "if", "x", ".", "dim", "(", ")", ">", "2", ":", "\n", "            ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "v", "=", "v", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "return", "x", ",", "v", "\n", "#def encode_", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.ConvEncoder.__init__": [[354, 386], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["\t", "def", "__init__", "(", "self", ",", "out_dim", "=", "None", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# init 96*96", "\n", "self", ".", "conv1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "3", ",", "32", ",", "4", ",", "2", ",", "1", ")", "# 48*48", "\n", "self", ".", "conv2", "=", "torch", ".", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", "# 24*24", "\n", "self", ".", "conv3", "=", "torch", ".", "nn", ".", "Conv2d", "(", "64", ",", "1", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", "\n", "#self.conv4 = torch.nn.Conv2d(128, 1, 1, 1, 0) # 54*44", "\n", "\n", "self", ".", "LReLU", "=", "torch", ".", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "\n", "self", ".", "convm", "=", "torch", ".", "nn", ".", "Conv2d", "(", "1", ",", "1", ",", "4", ",", "2", ",", "1", ")", "\n", "self", ".", "convv", "=", "torch", ".", "nn", ".", "Conv2d", "(", "1", ",", "1", ",", "4", ",", "2", ",", "1", ")", "\n", "self", ".", "mean_layer", "=", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "8", "*", "8", ",", "16", ")", "\n", ")", "# 12*12", "\n", "self", ".", "var_layer", "=", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "8", "*", "8", ",", "16", ")", "\n", ")", "\n", "# self.fc1 = torch.nn.Linear(6*6*128, 512)", "\n", "self", ".", "conv6", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "3", ",", "32", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "256", ",", "4", ",", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "128", ",", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.ConvEncoder.encode": [[388, 404], ["mask.ConvEncoder.LReLU", "mask.ConvEncoder.LReLU", "mask.ConvEncoder.LReLU", "mask.ConvEncoder.convm", "hm.view.view.view", "mask.ConvEncoder.convv", "hv.view.view.view", "mask.ConvEncoder.conv1", "mask.ConvEncoder.conv2", "mask.ConvEncoder.conv3", "mask.ConvEncoder.mean_layer", "mask.ConvEncoder.var_layer", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "x", "=", "self", ".", "LReLU", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "LReLU", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "LReLU", "(", "self", ".", "conv3", "(", "x", ")", ")", "\n", "#x = self.LReLU(self.conv4(x))", "\n", "#print(x.size())", "\n", "hm", "=", "self", ".", "convm", "(", "x", ")", "\n", "#print(hm.size())", "\n", "hm", "=", "hm", ".", "view", "(", "-", "1", ",", "8", "*", "8", ")", "\n", "hv", "=", "self", ".", "convv", "(", "x", ")", "\n", "hv", "=", "hv", ".", "view", "(", "-", "1", ",", "8", "*", "8", ")", "\n", "mu", ",", "var", "=", "self", ".", "mean_layer", "(", "hm", ")", ",", "self", ".", "var_layer", "(", "hv", ")", "\n", "var", "=", "F", ".", "softplus", "(", "var", ")", "+", "1e-8", "\n", "#var = torch.reshape(var, [-1, 16, 16])", "\n", "#print(mu.size())", "\n", "return", "mu", ",", "var", "\n", "", "def", "encode_simple", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.ConvEncoder.encode_simple": [[404, 409], ["mask.ConvEncoder.conv6", "codebase.utils.gaussian_parameters"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.gaussian_parameters"], ["", "def", "encode_simple", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "x", "=", "self", ".", "conv6", "(", "x", ")", "\n", "m", ",", "v", "=", "ut", ".", "gaussian_parameters", "(", "x", ",", "dim", "=", "1", ")", "\n", "#print(m.size())", "\n", "return", "m", ",", "v", "\n", "", "", "class", "ConvDecoder", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.ConvDecoder.__init__": [[410, 427], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["\t", "def", "__init__", "(", "self", ",", "out_dim", "=", "None", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "net6", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "16", ",", "128", ",", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "128", ",", "64", ",", "4", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "64", ",", "64", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "64", ",", "32", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "32", ",", "32", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "32", ",", "32", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "32", ",", "3", ",", "4", ",", "2", ",", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.ConvDecoder.decode_sep": [[429, 431], ["None"], "methods", ["None"], ["", "def", "decode_sep", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.ConvDecoder.decode": [[432, 436], ["mask.ConvDecoder.view", "mask.ConvDecoder.net6"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "z", ")", ":", "\n", "\t\t", "z", "=", "z", ".", "view", "(", "-", "1", ",", "16", ",", "1", ",", "1", ")", "\n", "z", "=", "self", ".", "net6", "(", "z", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.ConvDec.__init__": [[438, 467], ["torch.nn.Module.__init__", "mask.ConvDecoder", "mask.ConvDecoder", "mask.ConvDecoder", "mask.ConvDecoder", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d", "torch.nn.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["  ", "def", "__init__", "(", "self", ",", "out_dim", "=", "None", ")", ":", "\n", "    ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "concept", "=", "4", "\n", "self", ".", "z1_dim", "=", "16", "\n", "self", ".", "z_dim", "=", "64", "\n", "self", ".", "net1", "=", "ConvDecoder", "(", ")", "\n", "self", ".", "net2", "=", "ConvDecoder", "(", ")", "\n", "self", ".", "net3", "=", "ConvDecoder", "(", ")", "\n", "self", ".", "net4", "=", "ConvDecoder", "(", ")", "\n", "self", ".", "net5", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "16", ",", "512", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "512", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "1024", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "1024", ")", "\n", ")", "\n", "self", ".", "net6", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "16", ",", "128", ",", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "128", ",", "64", ",", "4", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "64", ",", "64", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "64", ",", "32", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "32", ",", "32", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "32", ",", "32", ",", "4", ",", "2", ",", "1", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ",", "\n", "nn", ".", "ConvTranspose2d", "(", "32", ",", "3", ",", "4", ",", "2", ",", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.ConvDec.decode_sep": [[469, 480], ["z.view.view.view", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "mask.ConvDec.net1.decode", "mask.ConvDec.net2.decode", "mask.ConvDec.net3.decode", "mask.ConvDec.net4.decode", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder.decode", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder.decode", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder.decode", "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder.decode"], ["", "def", "decode_sep", "(", "self", ",", "z", ",", "u", ",", "y", "=", "None", ")", ":", "\n", "    ", "z", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "concept", "*", "self", ".", "z1_dim", ")", "\n", "zy", "=", "z", "if", "y", "is", "None", "else", "torch", ".", "cat", "(", "(", "z", ",", "y", ")", ",", "dim", "=", "1", ")", "\n", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "torch", ".", "split", "(", "zy", ",", "self", ".", "z_dim", "//", "self", ".", "concept", ",", "dim", "=", "1", ")", "\n", "rx1", "=", "self", ".", "net1", ".", "decode", "(", "zy1", ")", "\n", "#print(rx1.size())", "\n", "rx2", "=", "self", ".", "net2", ".", "decode", "(", "zy2", ")", "\n", "rx3", "=", "self", ".", "net3", ".", "decode", "(", "zy3", ")", "\n", "rx4", "=", "self", ".", "net4", ".", "decode", "(", "zy4", ")", "\n", "z", "=", "(", "rx1", "+", "rx2", "+", "rx3", "+", "rx4", ")", "/", "4", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.ConvDec.decode": [[481, 487], ["mask.ConvDec.view", "mask.ConvDec.net6"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "z", ",", "u", ",", "y", "=", "None", ")", ":", "\n", "    ", "z", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "concept", "*", "self", ".", "z1_dim", ",", "1", ",", "1", ")", "\n", "z", "=", "self", ".", "net6", "(", "z", ")", "\n", "#print(z.size())", "\n", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Encoder.__init__": [[489, 505], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.LeakyReLU", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["\t", "def", "__init__", "(", "self", ",", "z_dim", ",", "channel", "=", "4", ",", "y_dim", "=", "4", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "y_dim", "=", "y_dim", "\n", "self", ".", "channel", "=", "channel", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "channel", "*", "96", "*", "96", ",", "300", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "300", "+", "y_dim", ",", "300", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "300", ",", "300", ")", "\n", "self", ".", "fc4", "=", "nn", ".", "Linear", "(", "300", ",", "2", "*", "z_dim", ")", "\n", "self", ".", "LReLU", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "channel", "*", "96", "*", "96", ",", "900", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "900", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "2", "*", "z_dim", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Encoder.conditional_encode": [[507, 516], ["mask.Encoder.view", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "l.view.view.view", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "mask.Encoder.fc4", "codebase.utils.gaussian_parameters", "mask.Encoder.fc1", "mask.Encoder.fc2", "mask.Encoder.fc3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.gaussian_parameters"], ["", "def", "conditional_encode", "(", "self", ",", "x", ",", "l", ")", ":", "\n", "\t\t", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "channel", "*", "96", "*", "96", ")", "\n", "x", "=", "F", ".", "elu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "l", "=", "l", ".", "view", "(", "-", "1", ",", "4", ")", "\n", "x", "=", "F", ".", "elu", "(", "self", ".", "fc2", "(", "torch", ".", "cat", "(", "[", "x", ",", "l", "]", ",", "dim", "=", "1", ")", ")", ")", "\n", "x", "=", "F", ".", "elu", "(", "self", ".", "fc3", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc4", "(", "x", ")", "\n", "m", ",", "v", "=", "ut", ".", "gaussian_parameters", "(", "x", ",", "dim", "=", "1", ")", "\n", "return", "m", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Encoder.encode": [[517, 524], ["xy.view.view.view", "mask.Encoder.net", "codebase.utils.gaussian_parameters", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.codebase.utils.gaussian_parameters"], ["", "def", "encode", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "\t\t", "xy", "=", "x", "if", "y", "is", "None", "else", "torch", ".", "cat", "(", "(", "x", ",", "y", ")", ",", "dim", "=", "1", ")", "\n", "xy", "=", "xy", ".", "view", "(", "-", "1", ",", "self", ".", "channel", "*", "96", "*", "96", ")", "\n", "h", "=", "self", ".", "net", "(", "xy", ")", "\n", "m", ",", "v", "=", "ut", ".", "gaussian_parameters", "(", "h", ",", "dim", "=", "1", ")", "\n", "#print(self.z_dim,m.size(),v.size())", "\n", "return", "m", ",", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder_DAG.__init__": [[527, 587], ["torch.nn.Module.__init__", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["\t", "def", "__init__", "(", "self", ",", "z_dim", ",", "concept", ",", "z1_dim", ",", "channel", "=", "4", ",", "y_dim", "=", "0", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "z1_dim", "=", "z1_dim", "\n", "self", ".", "concept", "=", "concept", "\n", "self", ".", "y_dim", "=", "y_dim", "\n", "self", ".", "channel", "=", "channel", "\n", "#print(self.channel)", "\n", "self", ".", "elu", "=", "nn", ".", "ELU", "(", ")", "\n", "self", ".", "net1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", "+", "y_dim", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "1024", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "self", ".", "channel", "*", "96", "*", "96", ")", "\n", ")", "\n", "self", ".", "net2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", "+", "y_dim", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "1024", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "self", ".", "channel", "*", "96", "*", "96", ")", "\n", ")", "\n", "self", ".", "net3", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", "+", "y_dim", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "1024", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "self", ".", "channel", "*", "96", "*", "96", ")", "\n", ")", "\n", "self", ".", "net4", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z1_dim", "+", "y_dim", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "1024", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "self", ".", "channel", "*", "96", "*", "96", ")", "\n", ")", "\n", "self", ".", "net5", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "self", ".", "channel", "*", "96", "*", "96", ")", "\n", ")", "\n", "\n", "self", ".", "net6", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z_dim", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "1024", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "1024", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "self", ".", "channel", "*", "96", "*", "96", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder_DAG.decode_condition": [[588, 599], ["z.view.view.view", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "mask.Decoder_DAG.net1", "mask.Decoder_DAG.net2", "mask.Decoder_DAG.net3", "mask.Decoder_DAG.net4", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "u[].reshape", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "u[].reshape", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "u[].reshape", "u.size", "u.size", "u.size"], "methods", ["None"], ["", "def", "decode_condition", "(", "self", ",", "z", ",", "u", ")", ":", "\n", "#z = z.view(-1,3*4)", "\n", "\t\t", "z", "=", "z", ".", "view", "(", "-", "1", ",", "3", "*", "4", ")", "\n", "z1", ",", "z2", ",", "z3", "=", "torch", ".", "split", "(", "z", ",", "self", ".", "z_dim", "//", "4", ",", "dim", "=", "1", ")", "\n", "#print(u[:,0].reshape(1,u.size()[0]).size())", "\n", "rx1", "=", "self", ".", "net1", "(", "torch", ".", "transpose", "(", "torch", ".", "cat", "(", "(", "torch", ".", "transpose", "(", "z1", ",", "1", ",", "0", ")", ",", "u", "[", ":", ",", "0", "]", ".", "reshape", "(", "1", ",", "u", ".", "size", "(", ")", "[", "0", "]", ")", ")", ",", "dim", "=", "0", ")", ",", "1", ",", "0", ")", ")", "\n", "rx2", "=", "self", ".", "net2", "(", "torch", ".", "transpose", "(", "torch", ".", "cat", "(", "(", "torch", ".", "transpose", "(", "z2", ",", "1", ",", "0", ")", ",", "u", "[", ":", ",", "1", "]", ".", "reshape", "(", "1", ",", "u", ".", "size", "(", ")", "[", "0", "]", ")", ")", ",", "dim", "=", "0", ")", ",", "1", ",", "0", ")", ")", "\n", "rx3", "=", "self", ".", "net3", "(", "torch", ".", "transpose", "(", "torch", ".", "cat", "(", "(", "torch", ".", "transpose", "(", "z3", ",", "1", ",", "0", ")", ",", "u", "[", ":", ",", "2", "]", ".", "reshape", "(", "1", ",", "u", ".", "size", "(", ")", "[", "0", "]", ")", ")", ",", "dim", "=", "0", ")", ",", "1", ",", "0", ")", ")", "\n", "\n", "h", "=", "self", ".", "net4", "(", "torch", ".", "cat", "(", "(", "rx1", ",", "rx2", ",", "rx3", ")", ",", "dim", "=", "1", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder_DAG.decode_mix": [[600, 607], ["z.contiguous.contiguous.permute", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "z.contiguous.contiguous.contiguous", "mask.Decoder_DAG.net1"], "methods", ["None"], ["", "def", "decode_mix", "(", "self", ",", "z", ")", ":", "\n", "\t\t", "z", "=", "z", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "z", "=", "torch", ".", "sum", "(", "z", ",", "dim", "=", "2", ",", "out", "=", "None", ")", "\n", "#print(z.contiguous().size())", "\n", "z", "=", "z", ".", "contiguous", "(", ")", "\n", "h", "=", "self", ".", "net1", "(", "z", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder_DAG.decode_union": [[608, 623], ["z.view.view.view", "mask.Decoder_DAG.net1", "mask.Decoder_DAG.net2", "mask.Decoder_DAG.net3", "mask.Decoder_DAG.net4", "mask.Decoder_DAG.net5", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "zy.reshape.reshape.reshape", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "zy.reshape.reshape.size", "zy.reshape.reshape.size"], "methods", ["None"], ["", "def", "decode_union", "(", "self", ",", "z", ",", "u", ",", "y", "=", "None", ")", ":", "\n", "\n", "\t\t", "z", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "concept", "*", "self", ".", "z1_dim", ")", "\n", "zy", "=", "z", "if", "y", "is", "None", "else", "torch", ".", "cat", "(", "(", "z", ",", "y", ")", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "z1_dim", "==", "1", ":", "\n", "\t\t\t", "zy", "=", "zy", ".", "reshape", "(", "zy", ".", "size", "(", ")", "[", "0", "]", ",", "zy", ".", "size", "(", ")", "[", "1", "]", ",", "1", ")", "\n", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "zy", "[", ":", ",", "0", "]", ",", "zy", "[", ":", ",", "1", "]", ",", "zy", "[", ":", ",", "2", "]", ",", "zy", "[", ":", ",", "3", "]", "\n", "", "else", ":", "\n", "\t\t\t", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "torch", ".", "split", "(", "zy", ",", "self", ".", "z_dim", "//", "self", ".", "concept", ",", "dim", "=", "1", ")", "\n", "", "rx1", "=", "self", ".", "net1", "(", "zy1", ")", "\n", "rx2", "=", "self", ".", "net2", "(", "zy2", ")", "\n", "rx3", "=", "self", ".", "net3", "(", "zy3", ")", "\n", "rx4", "=", "self", ".", "net4", "(", "zy4", ")", "\n", "h", "=", "self", ".", "net5", "(", "(", "rx1", "+", "rx2", "+", "rx3", "+", "rx4", ")", "/", "4", ")", "\n", "return", "h", ",", "h", ",", "h", ",", "h", ",", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder_DAG.decode": [[624, 628], ["z.view.view.view", "mask.Decoder_DAG.net6"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "z", ",", "u", ",", "y", "=", "None", ")", ":", "\n", "\t\t", "z", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "concept", "*", "self", ".", "z1_dim", ")", "\n", "h", "=", "self", ".", "net6", "(", "z", ")", "\n", "return", "h", ",", "h", ",", "h", ",", "h", ",", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder_DAG.decode_sep": [[629, 654], ["z.view.view.view", "mask.Decoder_DAG.net1", "mask.Decoder_DAG.net2", "mask.Decoder_DAG.net3", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "zy.reshape.reshape.reshape", "mask.Decoder_DAG.net4", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "zy.reshape.reshape.size", "zy.reshape.reshape.size", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split"], "methods", ["None"], ["", "def", "decode_sep", "(", "self", ",", "z", ",", "u", ",", "y", "=", "None", ")", ":", "\n", "\t\t", "z", "=", "z", ".", "view", "(", "-", "1", ",", "self", ".", "concept", "*", "self", ".", "z1_dim", ")", "\n", "zy", "=", "z", "if", "y", "is", "None", "else", "torch", ".", "cat", "(", "(", "z", ",", "y", ")", ",", "dim", "=", "1", ")", "\n", "\n", "if", "self", ".", "z1_dim", "==", "1", ":", "\n", "\t\t\t", "zy", "=", "zy", ".", "reshape", "(", "zy", ".", "size", "(", ")", "[", "0", "]", ",", "zy", ".", "size", "(", ")", "[", "1", "]", ",", "1", ")", "\n", "if", "self", ".", "concept", "==", "4", ":", "\n", "\t\t\t\t", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "zy", "[", ":", ",", "0", "]", ",", "zy", "[", ":", ",", "1", "]", ",", "zy", "[", ":", ",", "2", "]", ",", "zy", "[", ":", ",", "3", "]", "\n", "", "elif", "self", ".", "concept", "==", "3", ":", "\n", "\t\t\t\t", "zy1", ",", "zy2", ",", "zy3", "=", "zy", "[", ":", ",", "0", "]", ",", "zy", "[", ":", ",", "1", "]", ",", "zy", "[", ":", ",", "2", "]", "\n", "", "", "else", ":", "\n", "\t\t\t", "if", "self", ".", "concept", "==", "4", ":", "\n", "\t\t\t\t", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "torch", ".", "split", "(", "zy", ",", "self", ".", "z_dim", "//", "self", ".", "concept", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "concept", "==", "3", ":", "\n", "\t\t\t\t", "zy1", ",", "zy2", ",", "zy3", "=", "torch", ".", "split", "(", "zy", ",", "self", ".", "z_dim", "//", "self", ".", "concept", ",", "dim", "=", "1", ")", "\n", "", "", "rx1", "=", "self", ".", "net1", "(", "zy1", ")", "\n", "rx2", "=", "self", ".", "net2", "(", "zy2", ")", "\n", "rx3", "=", "self", ".", "net3", "(", "zy3", ")", "\n", "if", "self", ".", "concept", "==", "4", ":", "\n", "\t\t\t", "rx4", "=", "self", ".", "net4", "(", "zy4", ")", "\n", "h", "=", "(", "rx1", "+", "rx2", "+", "rx3", "+", "rx4", ")", "/", "self", ".", "concept", "\n", "", "elif", "self", ".", "concept", "==", "3", ":", "\n", "\t\t\t", "h", "=", "(", "rx1", "+", "rx2", "+", "rx3", ")", "/", "self", ".", "concept", "\n", "\n", "", "return", "h", ",", "h", ",", "h", ",", "h", ",", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder_DAG.decode_cat": [[655, 665], ["z.view.view.view", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "mask.Decoder_DAG.net1", "mask.Decoder_DAG.net2", "mask.Decoder_DAG.net3", "mask.Decoder_DAG.net4", "mask.Decoder_DAG.net5", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "decode_cat", "(", "self", ",", "z", ",", "u", ",", "y", "=", "None", ")", ":", "\n", "\t\t", "z", "=", "z", ".", "view", "(", "-", "1", ",", "4", "*", "4", ")", "\n", "zy", "=", "z", "if", "y", "is", "None", "else", "torch", ".", "cat", "(", "(", "z", ",", "y", ")", ",", "dim", "=", "1", ")", "\n", "zy1", ",", "zy2", ",", "zy3", ",", "zy4", "=", "torch", ".", "split", "(", "zy", ",", "1", ",", "dim", "=", "1", ")", "\n", "rx1", "=", "self", ".", "net1", "(", "zy1", ")", "\n", "rx2", "=", "self", ".", "net2", "(", "zy2", ")", "\n", "rx3", "=", "self", ".", "net3", "(", "zy3", ")", "\n", "rx4", "=", "self", ".", "net4", "(", "zy4", ")", "\n", "h", "=", "self", ".", "net5", "(", "torch", ".", "cat", "(", "(", "rx1", ",", "rx2", ",", "rx3", ",", "rx4", ")", ",", "dim", "=", "1", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder.__init__": [[668, 678], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["\t", "def", "__init__", "(", "self", ",", "z_dim", ",", "y_dim", "=", "0", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "y_dim", "=", "y_dim", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "z_dim", "+", "y_dim", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "300", ")", ",", "\n", "nn", ".", "ELU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "4", "*", "96", "*", "96", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Decoder.decode": [[680, 683], ["mask.Decoder.net", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "z", ",", "y", "=", "None", ")", ":", "\n", "\t\t", "zy", "=", "z", "if", "y", "is", "None", "else", "torch", ".", "cat", "(", "(", "z", ",", "y", ")", ",", "dim", "=", "1", ")", "\n", "return", "self", ".", "net", "(", "zy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__": [[685, 694], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.__init__"], ["\t", "def", "__init__", "(", "self", ",", "y_dim", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "y_dim", "=", "y_dim", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "784", ",", "300", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "300", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "300", ",", "y_dim", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.Classifier.classify": [[696, 698], ["mask.Classifier.net"], "methods", ["None"], ["", "def", "classify", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "return", "self", ".", "net", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.dag_right_linear": [[30, 40], ["torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "input.matmul", "input.dim", "weight.t", "weight.t"], "function", ["None"], ["def", "dag_right_linear", "(", "input", ",", "weight", ",", "bias", "=", "None", ")", ":", "\n", "    ", "if", "input", ".", "dim", "(", ")", "==", "2", "and", "bias", "is", "not", "None", ":", "\n", "# fused op is marginally faster", "\n", "        ", "ret", "=", "torch", ".", "addmm", "(", "bias", ",", "input", ",", "weight", ".", "t", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "input", ".", "matmul", "(", "weight", ".", "t", "(", ")", ")", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "output", "+=", "bias", "\n", "", "ret", "=", "output", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.nns.mask.dag_left_linear": [[41, 51], ["torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "weight.matmul", "input.dim", "weight.t"], "function", ["None"], ["", "def", "dag_left_linear", "(", "input", ",", "weight", ",", "bias", "=", "None", ")", ":", "\n", "    ", "if", "input", ".", "dim", "(", ")", "==", "2", "and", "bias", "is", "not", "None", ":", "\n", "# fused op is marginally faster", "\n", "        ", "ret", "=", "torch", ".", "addmm", "(", "bias", ",", "input", ",", "weight", ".", "t", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "weight", ".", "matmul", "(", "input", ")", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "output", "+=", "bias", "\n", "", "ret", "=", "output", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.huawei-noah_trustworthyAI.causal_data.pendulum.projection": [[21, 25], ["math.tan", "math.tan"], "function", ["None"], ["", "def", "projection", "(", "theta", ",", "phi", ",", "x", ",", "y", ",", "base", "=", "-", "0.5", ")", ":", "\n", "    ", "b", "=", "y", "-", "x", "*", "math", ".", "tan", "(", "phi", ")", "\n", "shade", "=", "(", "base", "-", "b", ")", "/", "math", ".", "tan", "(", "phi", ")", "\n", "return", "shade", "\n", "# ", "\n"]]}