{"home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model.ImageModel.__init__": [[140, 165], ["tensorflow.logging.set_verbosity", "tensorflow.Variable", "tensorflow.placeholder", "im_model.ImageModel.learning_rate.assign", "datasets.convert_to_dataset.get_split_with_text", "im_model.load_batch_with_text", "tensorflow.contrib.slim.arg_scope", "image_model.inception_v1.inception_v1", "image_model.inception_v1.inception_v1_arg_scope"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_to_dataset.get_split_with_text", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model.load_batch_with_text", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "mode", "=", "config", "[", "'mode'", "]", "\n", "dataset_dir", "=", "config", "[", "'dataset_dir'", "]", "\n", "initial_lr", "=", "config", "[", "'initial_lr'", "]", "\n", "batch_size", "=", "config", "[", "'batch_size'", "]", "\n", "final_endpoint", "=", "config", "[", "'final_endpoint'", "]", "\n", "\n", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "self", ".", "learning_rate", "=", "tf", ".", "Variable", "(", "initial_lr", ",", "trainable", "=", "False", ")", "\n", "self", ".", "lr_rate_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "self", ".", "lr_rate_assign", "=", "self", ".", "learning_rate", ".", "assign", "(", "self", ".", "lr_rate_placeholder", ")", "\n", "\n", "self", ".", "dataset", "=", "get_split_with_text", "(", "mode", ",", "dataset_dir", ")", "\n", "image_size", "=", "inception_v1", ".", "default_image_size", "\n", "images", ",", "_", ",", "texts", ",", "seq_lens", ",", "self", ".", "labels", ",", "_", ",", "_", "=", "load_batch_with_text", "(", "self", ".", "dataset", ",", "batch_size", ",", "height", "=", "image_size", ",", "\n", "width", "=", "image_size", ")", "\n", "\n", "self", ".", "nb_emotions", "=", "self", ".", "dataset", ".", "num_classes", "\n", "# Create the model, use the default arg scope to configure the batch norm parameters.", "\n", "is_training", "=", "(", "mode", "==", "'train'", ")", "\n", "with", "slim", ".", "arg_scope", "(", "inception_v1", ".", "inception_v1_arg_scope", "(", ")", ")", ":", "\n", "            ", "self", ".", "logits", ",", "_", "=", "inception_v1", ".", "inception_v1", "(", "images", ",", "final_endpoint", "=", "final_endpoint", ",", "\n", "num_classes", "=", "self", ".", "nb_emotions", ",", "is_training", "=", "is_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model.download_pretrained_model": [[27, 37], ["datasets.dataset_utils.download_and_uncompress_tarball", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.download_and_uncompress_tarball"], ["def", "download_pretrained_model", "(", "url", ",", "checkpoint_dir", ")", ":", "\n", "    ", "\"\"\"Download pretrained inception model and store it in checkpoint_dir.\n\n    Parameters:\n        url: The url containing the compressed model.\n        checkpoint_dir: The directory to save the model.\n    \"\"\"", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "checkpoint_dir", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MakeDirs", "(", "checkpoint_dir", ")", "\n", "", "dataset_utils", ".", "download_and_uncompress_tarball", "(", "url", ",", "checkpoint_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model._load_batch": [[38, 77], ["tensorflow.contrib.slim.dataset_data_provider.DatasetDataProvider", "slim.dataset_data_provider.DatasetDataProvider.get", "slim.preprocessing.inception_preprocessing.preprocess_image", "tensorflow.expand_dims", "tensorflow.image.resize_images", "tensorflow.squeeze", "tensorflow.train.batch"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.lenet_preprocessing.preprocess_image"], ["", "def", "_load_batch", "(", "dataset", ",", "batch_size", "=", "32", ",", "shuffle", "=", "True", ",", "height", "=", "299", ",", "width", "=", "299", ",", "is_training", "=", "False", ")", ":", "\n", "    ", "\"\"\"Load a single batch of data. \n    \n    Args:\n      dataset: The dataset to load.\n      batch_size: The number of images in the batch.\n      shuffle: Whether to shuffle the data sources and common queue when reading.\n      height: The size of each image after preprocessing.\n      width: The size of each image after preprocessing.\n      is_training: Whether or not we're currently training or evaluating.\n    \n    Returns:\n      images: A Tensor of size [batch_size, height, width, 3], image samples that have been preprocessed.\n      images_raw: A Tensor of size [batch_size, height, width, 3], image samples that can be used for visualization.\n      labels: A Tensor of size [batch_size], whose values range between 0 and dataset.num_classes.\n    \"\"\"", "\n", "# For validation, if you set the common_queue_capacity to something lower than", "\n", "# batch_size, which is the validation size, then your output will contain duplicates.", "\n", "data_provider", "=", "slim", ".", "dataset_data_provider", ".", "DatasetDataProvider", "(", "\n", "dataset", ",", "shuffle", "=", "shuffle", ",", "common_queue_capacity", "=", "batch_size", ",", "\n", "common_queue_min", "=", "8", ")", "\n", "image_raw", ",", "label", "=", "data_provider", ".", "get", "(", "[", "'image'", ",", "'label'", "]", ")", "\n", "\n", "# Preprocess image for usage by Inception.", "\n", "image", "=", "inception_preprocessing", ".", "preprocess_image", "(", "image_raw", ",", "height", ",", "width", ",", "is_training", "=", "is_training", ")", "\n", "\n", "# Preprocess the image for display purposes.", "\n", "image_raw", "=", "tf", ".", "expand_dims", "(", "image_raw", ",", "0", ")", "\n", "image_raw", "=", "tf", ".", "image", ".", "resize_images", "(", "image_raw", ",", "[", "height", ",", "width", "]", ")", "\n", "image_raw", "=", "tf", ".", "squeeze", "(", "image_raw", ")", "\n", "\n", "# Batch it up.", "\n", "images", ",", "images_raw", ",", "labels", "=", "tf", ".", "train", ".", "batch", "(", "\n", "[", "image", ",", "image_raw", ",", "label", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_threads", "=", "1", ",", "\n", "capacity", "=", "2", "*", "batch_size", ")", "\n", "\n", "return", "images", ",", "images_raw", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model.load_batch_with_text": [[78, 117], ["tensorflow.contrib.slim.dataset_data_provider.DatasetDataProvider", "slim.dataset_data_provider.DatasetDataProvider.get", "slim.preprocessing.inception_preprocessing.preprocess_image", "tensorflow.expand_dims", "tensorflow.image.resize_images", "tensorflow.squeeze", "tensorflow.train.batch"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.lenet_preprocessing.preprocess_image"], ["", "def", "load_batch_with_text", "(", "dataset", ",", "batch_size", "=", "32", ",", "shuffle", "=", "True", ",", "height", "=", "299", ",", "width", "=", "299", ",", "is_training", "=", "False", ")", ":", "\n", "    ", "\"\"\"Load a single batch of data. \n    \n    Args:\n      dataset: The dataset to load.\n      batch_size: The number of images in the batch.\n      shuffle: Whether to shuffle the data sources and common queue when reading.\n      height: The size of each image after preprocessing.\n      width: The size of each image after preprocessing.\n      is_training: Whether or not we're currently training or evaluating.\n    \n    Returns:\n      images: A Tensor of size [batch_size, height, width, 3], image samples that have been preprocessed.\n      images_raw: A Tensor of size [batch_size, height, width, 3], image samples that can be used for visualization.\n      labels: A Tensor of size [batch_size], whose values range between 0 and dataset.num_classes.\n    \"\"\"", "\n", "# For validation, if you set the common_queue_capacity to something lower than", "\n", "# batch_size, which is the validation size, then your output will contain duplicates.", "\n", "data_provider", "=", "slim", ".", "dataset_data_provider", ".", "DatasetDataProvider", "(", "\n", "dataset", ",", "shuffle", "=", "shuffle", ",", "common_queue_capacity", "=", "batch_size", ",", "\n", "common_queue_min", "=", "8", ")", "\n", "image_raw", ",", "text", ",", "seq_len", ",", "label", ",", "post_id", ",", "day", "=", "data_provider", ".", "get", "(", "[", "'image'", ",", "'text'", ",", "'seq_len'", ",", "'label'", ",", "'post_id'", ",", "'day'", "]", ")", "\n", "\n", "# Preprocess image for usage by Inception.", "\n", "image", "=", "inception_preprocessing", ".", "preprocess_image", "(", "image_raw", ",", "height", ",", "width", ",", "is_training", "=", "is_training", ")", "\n", "\n", "# Preprocess the image for display purposes.", "\n", "image_raw", "=", "tf", ".", "expand_dims", "(", "image_raw", ",", "0", ")", "\n", "image_raw", "=", "tf", ".", "image", ".", "resize_images", "(", "image_raw", ",", "[", "height", ",", "width", "]", ")", "\n", "image_raw", "=", "tf", ".", "squeeze", "(", "image_raw", ")", "\n", "\n", "# Batch it up.", "\n", "images", ",", "images_raw", ",", "texts", ",", "seq_lens", ",", "labels", ",", "post_ids", ",", "days", "=", "tf", ".", "train", ".", "batch", "(", "\n", "[", "image", ",", "image_raw", ",", "text", ",", "seq_len", ",", "label", ",", "post_id", ",", "day", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_threads", "=", "1", ",", "\n", "capacity", "=", "2", "*", "batch_size", ")", "\n", "\n", "return", "images", ",", "images_raw", ",", "texts", ",", "seq_lens", ",", "labels", ",", "post_ids", ",", "days", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model.get_init_fn": [[118, 138], ["tensorflow.contrib.slim.get_model_variables", "tensorflow.contrib.slim.assign_from_checkpoint_fn", "scope.strip", "os.path.join", "var.op.name.startswith", "variables_to_restore.append"], "function", ["None"], ["", "def", "get_init_fn", "(", "checkpoints_dir", ",", "model_name", "=", "'inception_v1.ckpt'", ")", ":", "\n", "    ", "\"\"\"Returns a function run by the chief worker to warm-start the training.\n    \"\"\"", "\n", "checkpoint_exclude_scopes", "=", "[", "\"InceptionV1/Logits\"", ",", "\"InceptionV1/AuxLogits\"", "]", "\n", "\n", "exclusions", "=", "[", "scope", ".", "strip", "(", ")", "for", "scope", "in", "checkpoint_exclude_scopes", "]", "\n", "\n", "variables_to_restore", "=", "[", "]", "\n", "for", "var", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "        ", "excluded", "=", "False", "\n", "for", "exclusion", "in", "exclusions", ":", "\n", "            ", "if", "var", ".", "op", ".", "name", ".", "startswith", "(", "exclusion", ")", ":", "\n", "                ", "excluded", "=", "True", "\n", "break", "\n", "", "", "if", "not", "excluded", ":", "\n", "            ", "variables_to_restore", ".", "append", "(", "var", ")", "\n", "\n", "", "", "return", "slim", ".", "assign_from_checkpoint_fn", "(", "\n", "os", ".", "path", ".", "join", "(", "checkpoints_dir", ",", "model_name", ")", ",", "\n", "variables_to_restore", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model.train_image_model": [[166, 226], ["tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "print", "tensorflow.gfile.DeleteRecursively", "tensorflow.Graph().as_default", "im_model.ImageModel", "tensorflow.contrib.slim.one_hot_encoding", "tensorflow.contrib.slim.losses.softmax_cross_entropy", "tensorflow.contrib.slim.losses.get_total_loss", "tensorflow.summary.scalar", "tensorflow.train.AdamOptimizer", "tensorflow.contrib.slim.learning.create_train_op", "tensorflow.contrib.slim.learning.train", "tensorflow.contrib.slim.python.slim.learning.train_step", "tensorflow.Graph", "session.run", "print", "im_model.get_init_fn"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model.get_init_fn"], ["", "", "", "def", "train_image_model", "(", "checkpoints_dir", ",", "train_dir", ",", "num_steps", ")", ":", "\n", "    ", "\"\"\"Fine tune the Image model, retraining Mixed_5c.\n\n    Parameters:\n        checkpoints_dir: The directory contained the pre-trained model.\n        train_dir: The directory to save the trained model.\n        num_steps: The number of steps training the model.\n    \"\"\"", "\n", "if", "tf", ".", "gfile", ".", "Exists", "(", "train_dir", ")", ":", "\n", "# Delete old model", "\n", "        ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "tf", ".", "gfile", ".", "MakeDirs", "(", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "model", "=", "ImageModel", "(", "_CONFIG", ")", "\n", "# Specify the loss function:", "\n", "one_hot_labels", "=", "slim", ".", "one_hot_encoding", "(", "model", ".", "labels", ",", "model", ".", "nb_emotions", ")", "\n", "slim", ".", "losses", ".", "softmax_cross_entropy", "(", "model", ".", "logits", ",", "one_hot_labels", ")", "\n", "total_loss", "=", "slim", ".", "losses", ".", "get_total_loss", "(", ")", "\n", "\n", "# Create some summaries to visualize the training process", "\n", "# Use tensorboard --logdir=train_dir, careful with path (add Documents/tumblr-sentiment in front of train_dir)", "\n", "# Different from the logs, because computed on different mini batch of data", "\n", "tf", ".", "summary", ".", "scalar", "(", "'Loss'", ",", "total_loss", ")", "\n", "\n", "# Specify the optimizer and create the train op:", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "model", ".", "learning_rate", ")", "\n", "train_op", "=", "slim", ".", "learning", ".", "create_train_op", "(", "total_loss", ",", "optimizer", ")", "\n", "\n", "batch_size", "=", "_CONFIG", "[", "'batch_size'", "]", "\n", "initial_lr", "=", "_CONFIG", "[", "'initial_lr'", "]", "\n", "decay_factor", "=", "_CONFIG", "[", "'decay_factor'", "]", "\n", "nb_batches", "=", "model", ".", "dataset", ".", "num_samples", "/", "batch_size", "\n", "def", "train_step_fn", "(", "session", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# Decaying learning rate every epoch", "\n", "            ", "if", "train_step_fn", ".", "step", "%", "(", "nb_batches", ")", "==", "0", ":", "\n", "                ", "lr_decay", "=", "decay_factor", "**", "train_step_fn", ".", "epoch", "\n", "session", ".", "run", "(", "model", ".", "lr_rate_assign", ",", "feed_dict", "=", "{", "model", ".", "lr_rate_placeholder", ":", "initial_lr", "*", "lr_decay", "}", ")", "\n", "print", "(", "'New learning rate: {0}'", ".", "format", "(", "initial_lr", "*", "lr_decay", ")", ")", "\n", "train_step_fn", ".", "epoch", "+=", "1", "\n", "\n", "", "total_loss", ",", "should_stop", "=", "train_step", "(", "session", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "train_step_fn", ".", "step", "+=", "1", "\n", "return", "[", "total_loss", ",", "should_stop", "]", "\n", "\n", "", "train_step_fn", ".", "step", "=", "0", "\n", "train_step_fn", ".", "epoch", "=", "0", "\n", "\n", "# Run the training:", "\n", "final_loss", "=", "slim", ".", "learning", ".", "train", "(", "\n", "train_op", ",", "\n", "logdir", "=", "train_dir", ",", "\n", "init_fn", "=", "get_init_fn", "(", "checkpoints_dir", ")", ",", "\n", "save_interval_secs", "=", "600", ",", "\n", "save_summaries_secs", "=", "600", ",", "\n", "train_step_fn", "=", "train_step_fn", ",", "\n", "number_of_steps", "=", "num_steps", ")", "\n", "\n", "", "print", "(", "'Finished training. Last batch loss {0:.3f}'", ".", "format", "(", "final_loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model.evaluate_image_model": [[227, 263], ["tensorflow.Graph().as_default", "im_model.ImageModel", "tensorflow.contrib.slim.metrics.streaming_accuracy", "tensorflow.contrib.slim.metrics.aggregate_metric_map", "names_to_values.iteritems", "os.path.join", "tensorflow.contrib.slim.evaluation.evaluation_loop", "tensorflow.cast", "tensorflow.cast", "tensorflow.summary.scalar", "tensorflow.Graph", "tensorflow.argmax", "names_to_updates.values"], "function", ["None"], ["", "def", "evaluate_image_model", "(", "checkpoint_dir", ",", "log_dir", ",", "mode", ",", "num_evals", ")", ":", "\n", "    ", "\"\"\"Visualise results with: tensorboard --logdir=logdir. Now has train/validation curves on the same plot\n    \n    Parameters:\n        checkpoint_dir: Checkpoint of the saved model during training.\n        log_dir: Directory to save logs.\n        mode: train or validation.\n        num_evals: Number of batches to evaluate (mean of the batches is displayed).\n    \"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "_CONFIG", "[", "'mode'", "]", "=", "mode", "\n", "model", "=", "ImageModel", "(", "_CONFIG", ")", "\n", "\n", "# Accuracy metrics", "\n", "accuracy", "=", "slim", ".", "metrics", ".", "streaming_accuracy", "(", "tf", ".", "cast", "(", "model", ".", "labels", ",", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "cast", "(", "tf", ".", "argmax", "(", "model", ".", "logits", ",", "1", ")", ",", "tf", ".", "int32", ")", ")", "\n", "\n", "# Choose the metrics to compute:", "\n", "names_to_values", ",", "names_to_updates", "=", "slim", ".", "metrics", ".", "aggregate_metric_map", "(", "{", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "}", ")", "\n", "\n", "for", "metric_name", ",", "metric_value", "in", "names_to_values", ".", "iteritems", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "metric_name", ",", "metric_value", ")", "\n", "\n", "", "log_dir", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "mode", ")", "\n", "\n", "# Evaluate every eval_interval_secs secs or if not specified,", "\n", "# every time the checkpoint_dir changes", "\n", "# tf.get_variable variables are also restored", "\n", "slim", ".", "evaluation", ".", "evaluation_loop", "(", "\n", "''", ",", "\n", "checkpoint_dir", ",", "\n", "log_dir", ",", "\n", "num_evals", "=", "num_evals", ",", "\n", "eval_op", "=", "names_to_updates", ".", "values", "(", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.inception_v1.inception_v1_base": [[29, 252], ["tensorflow.variable_scope", "ValueError", "slim.arg_scope", "slim.arg_scope", "slim.arg_scope", "slim.conv2d", "slim.max_pool2d", "slim.conv2d", "slim.conv2d", "slim.max_pool2d", "slim.max_pool2d", "slim.max_pool2d", "slim.arg_scope", "trunc_normal", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "trunc_normal", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d"], "function", ["None"], ["def", "inception_v1_base", "(", "inputs", ",", "\n", "final_endpoint", "=", "'Mixed_5c'", ",", "\n", "scope", "=", "'InceptionV1'", ")", ":", "\n", "  ", "\"\"\"Defines the Inception V1 base architecture.\n\n  This architecture is defined in:\n    Going deeper with convolutions\n    Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,\n    Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich.\n    http://arxiv.org/pdf/1409.4842v1.pdf.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    final_endpoint: specifies the endpoint to construct and freeze the network up to. It\n      can be one of ['Conv2d_1a_7x7', 'MaxPool_2a_3x3', 'Conv2d_2b_1x1',\n      'Conv2d_2c_3x3', 'MaxPool_3a_3x3', 'Mixed_3b', 'Mixed_3c',\n      'MaxPool_4a_3x3', 'Mixed_4b', 'Mixed_4c', 'Mixed_4d', 'Mixed_4e',\n      'Mixed_4f', 'MaxPool_5a_2x2', 'Mixed_5b', 'Mixed_5c']\n    scope: Optional variable_scope.\n\n  Returns:\n    A dictionary from components of the network to the corresponding activation.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values.\n  \"\"\"", "\n", "end_points", "=", "{", "}", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV1'", ",", "[", "inputs", "]", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.01", ")", ",", "trainable", "=", "False", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "        ", "end_point", "=", "'Conv2d_1a_7x7'", "\n", "net", "=", "slim", ".", "conv2d", "(", "inputs", ",", "64", ",", "[", "7", ",", "7", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "end_point", "=", "'MaxPool_2a_3x3'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "end_point", "=", "'Conv2d_2b_1x1'", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "end_point", "=", "'Conv2d_2c_3x3'", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "end_point", "=", "'MaxPool_3a_3x3'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_3b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "96", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "128", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "16", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "32", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "32", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_3c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "192", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "96", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'MaxPool_4a_3x3'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_4b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "96", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "208", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "16", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "48", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_4c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "160", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "112", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "224", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "24", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_4d'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "24", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_4e'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "112", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "144", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "288", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_4f'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "160", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "320", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "128", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'MaxPool_5a_2x2'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_5b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "160", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "320", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "128", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "# Retrain Mixed_5c layer", "\n", "", "", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.01", ")", ",", "trainable", "=", "True", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "        ", "end_point", "=", "'Mixed_5c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "384", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "384", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "48", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "128", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "", "", "raise", "ValueError", "(", "'Unknown final endpoint %s'", "%", "final_endpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.inception_v1.inception_v1": [[254, 310], ["tensorflow.variable_scope", "slim.arg_scope", "inception_v1.inception_v1_base", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.dropout", "slim.conv2d", "prediction_fn", "tensorflow.squeeze"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1_base"], ["", "", "def", "inception_v1", "(", "inputs", ",", "\n", "final_endpoint", "=", "'Mixed_5c'", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.8", ",", "\n", "prediction_fn", "=", "slim", ".", "softmax", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'InceptionV1'", ")", ":", "\n", "  ", "\"\"\"Defines the Inception V1 architecture.\n\n  This architecture is defined in:\n\n    Going deeper with convolutions\n    Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,\n    Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich.\n    http://arxiv.org/pdf/1409.4842v1.pdf.\n\n  The default image size used to train this network is 224x224.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    is_training: whether is training or not.\n    dropout_keep_prob: the percentage of activation values that are retained.\n    prediction_fn: a function to get predictions out of logits.\n    spatial_squeeze: if True, logits is of shape [B, C], if false logits is\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    scope: Optional variable_scope.\n\n  Returns:\n    logits: the pre-softmax activations, a tensor of size\n      [batch_size, num_classes]\n    end_points: a dictionary from components of the network to the corresponding\n      activation.\n  \"\"\"", "\n", "# Final pooling and prediction", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV1'", ",", "[", "inputs", ",", "num_classes", "]", ",", "\n", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "\n", "is_training", "=", "is_training", ")", ":", "\n", "      ", "net", ",", "end_points", "=", "inception_v1_base", "(", "inputs", ",", "final_endpoint", "=", "final_endpoint", ",", "scope", "=", "scope", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Logits'", ")", ":", "\n", "        ", "net", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "7", ",", "7", "]", ",", "stride", "=", "1", ",", "scope", "=", "'AvgPool_0a_7x7'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "\n", "dropout_keep_prob", ",", "scope", "=", "'Dropout_0b'", ")", "\n", "logits", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "scope", "=", "'Conv2d_0c_1x1'", ")", "\n", "if", "spatial_squeeze", ":", "\n", "          ", "logits", "=", "tf", ".", "squeeze", "(", "logits", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'SpatialSqueeze'", ")", "\n", "\n", "", "end_points", "[", "'Logits'", "]", "=", "logits", "\n", "end_points", "[", "'Predictions'", "]", "=", "prediction_fn", "(", "logits", ",", "scope", "=", "'Predictions'", ")", "\n", "", "", "", "return", "logits", ",", "end_points", "\n", "", "default_image_size", "=", "224", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords.ImageReader.__init__": [[61, 65], ["tensorflow.placeholder", "tensorflow.image.decode_jpeg"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers.ImageReader.decode_jpeg"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Initializes function that decodes RGB JPEG data.", "\n", "    ", "self", ".", "_decode_jpeg_data", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ")", "\n", "self", ".", "_decode_jpeg", "=", "tf", ".", "image", ".", "decode_jpeg", "(", "self", ".", "_decode_jpeg_data", ",", "channels", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords.ImageReader.read_image_dims": [[66, 69], ["convert_images_tfrecords.ImageReader.decode_jpeg"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers.ImageReader.decode_jpeg"], ["", "def", "read_image_dims", "(", "self", ",", "sess", ",", "image_data", ")", ":", "\n", "    ", "image", "=", "self", ".", "decode_jpeg", "(", "sess", ",", "image_data", ")", "\n", "return", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords.ImageReader.decode_jpeg": [[70, 76], ["sess.run", "len"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "decode_jpeg", "(", "self", ",", "sess", ",", "image_data", ")", ":", "\n", "    ", "image", "=", "sess", ".", "run", "(", "self", ".", "_decode_jpeg", ",", "\n", "feed_dict", "=", "{", "self", ".", "_decode_jpeg_data", ":", "image_data", "}", ")", "\n", "assert", "len", "(", "image", ".", "shape", ")", "==", "3", "\n", "assert", "image", ".", "shape", "[", "2", "]", "==", "3", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords._get_filenames_and_classes": [[78, 108], ["os.path.join", "os.listdir", "os.path.join", "os.path.isdir", "os.listdir", "sorted", "directories.append", "class_names.append", "os.path.join", "photo_filenames.append"], "function", ["None"], ["", "", "def", "_get_filenames_and_classes", "(", "dataset_dir", ",", "photos_subdir", "=", "'photos'", ")", ":", "\n", "  ", "\"\"\"Returns a list of filenames and inferred class names.\n\n  Parameters:\n    dataset_dir: A directory containing a subdirectory photos_subdir that \n      contains a set of subdirectories representing class names. \n      Each subdirectory should contain JPG encoded images.\n    photos_subdir: A subdirectory of dataset_dir.\n\n  Returns:\n    A list of image file paths, relative to `dataset_dir/photos_subdir` and \n    the list of subdirectories, representing class names.\n  \"\"\"", "\n", "root", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "photos_subdir", ")", "\n", "directories", "=", "[", "]", "\n", "class_names", "=", "[", "]", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "root", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "      ", "directories", ".", "append", "(", "path", ")", "\n", "class_names", ".", "append", "(", "filename", ")", "\n", "\n", "", "", "photo_filenames", "=", "[", "]", "\n", "for", "directory", "in", "directories", ":", "\n", "    ", "for", "filename", "in", "os", ".", "listdir", "(", "directory", ")", ":", "\n", "      ", "if", "filename", "!=", "'.DS_Store'", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "filename", ")", "\n", "photo_filenames", ".", "append", "(", "path", ")", "\n", "\n", "", "", "", "return", "photo_filenames", ",", "sorted", "(", "class_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords._get_dataset_filename": [[110, 114], ["os.path.join"], "function", ["None"], ["", "def", "_get_dataset_filename", "(", "dataset_dir", ",", "photos_subdir", ",", "split_name", ",", "shard_id", ")", ":", "\n", "  ", "output_filename", "=", "'tumblr_%s_%05d-of-%05d.tfrecord'", "%", "(", "\n", "split_name", ",", "shard_id", ",", "_NUM_SHARDS", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "photos_subdir", ",", "output_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords._convert_dataset": [[116, 161], ["int", "sys.stdout.write", "sys.stdout.flush", "math.ceil", "tensorflow.Graph().as_default", "convert_images_tfrecords.ImageReader", "tensorflow.Session", "range", "len", "float", "tensorflow.Graph", "convert_images_tfrecords._get_dataset_filename", "tensorflow.python_io.TFRecordWriter", "min", "range", "len", "sys.stdout.write", "sys.stdout.flush", "tensorflow.gfile.FastGFile().read", "convert_images_tfrecords.ImageReader.read_image_dims", "os.path.basename", "datasets.dataset_utils.image_to_tfexample", "tfrecord_writer.write", "os.path.dirname", "dataset_utils.image_to_tfexample.SerializeToString", "tensorflow.gfile.FastGFile", "len"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._get_dataset_filename", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers.ImageReader.read_image_dims", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.image_to_tfexample"], ["", "def", "_convert_dataset", "(", "split_name", ",", "filenames", ",", "class_names_to_ids", ",", "dataset_dir", ",", "\n", "tfrecords_subdir", "=", "'tfrecords'", ")", ":", "\n", "  ", "\"\"\"Converts the given filenames to a TFRecords dataset.\n\n  Args:\n    split_name: The name of the dataset, either 'train' or 'validation'.\n    filenames: A list of absolute paths to png or jpg images.\n    class_names_to_ids: A dictionary from class names (strings) to ids\n      (integers).\n    dataset_dir: The directory where the converted datasets are stored.\n    tfrecords_subdir: A subdirectory to save the TFRecords dataset\n  \"\"\"", "\n", "assert", "split_name", "in", "[", "'train'", ",", "'validation'", "]", "\n", "\n", "num_per_shard", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "filenames", ")", "/", "float", "(", "_NUM_SHARDS", ")", ")", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "    ", "image_reader", "=", "ImageReader", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "\n", "      ", "for", "shard_id", "in", "range", "(", "_NUM_SHARDS", ")", ":", "\n", "        ", "output_filename", "=", "_get_dataset_filename", "(", "\n", "dataset_dir", ",", "tfrecords_subdir", ",", "split_name", ",", "shard_id", ")", "\n", "\n", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "output_filename", ")", "as", "tfrecord_writer", ":", "\n", "          ", "start_ndx", "=", "shard_id", "*", "num_per_shard", "\n", "end_ndx", "=", "min", "(", "(", "shard_id", "+", "1", ")", "*", "num_per_shard", ",", "len", "(", "filenames", ")", ")", "\n", "for", "i", "in", "range", "(", "start_ndx", ",", "end_ndx", ")", ":", "\n", "            ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Converting image %d/%d shard %d'", "%", "(", "\n", "i", "+", "1", ",", "len", "(", "filenames", ")", ",", "shard_id", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "# Read the filename:", "\n", "image_data", "=", "tf", ".", "gfile", ".", "FastGFile", "(", "filenames", "[", "i", "]", ",", "'rb'", ")", ".", "read", "(", ")", "\n", "height", ",", "width", "=", "image_reader", ".", "read_image_dims", "(", "sess", ",", "image_data", ")", "\n", "\n", "class_name", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "dirname", "(", "filenames", "[", "i", "]", ")", ")", "\n", "class_id", "=", "class_names_to_ids", "[", "class_name", "]", "\n", "\n", "example", "=", "dataset_utils", ".", "image_to_tfexample", "(", "\n", "image_data", ",", "b'jpg'", ",", "height", ",", "width", ",", "class_id", ")", "\n", "tfrecord_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "\n", "", "", "", "", "", "sys", ".", "stdout", ".", "write", "(", "'\\n'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords._convert_dataset_with_text": [[162, 218], ["int", "sys.stdout.write", "sys.stdout.flush", "math.ceil", "tensorflow.Graph().as_default", "convert_images_tfrecords.ImageReader", "tensorflow.Session", "range", "len", "float", "tensorflow.Graph", "convert_images_tfrecords._get_dataset_filename", "tensorflow.python_io.TFRecordWriter", "min", "range", "len", "sys.stdout.write", "sys.stdout.flush", "tensorflow.gfile.FastGFile().read", "convert_images_tfrecords.ImageReader.read_image_dims", "os.path.basename", "os.path.basename", "int", "datetime.datetime.strptime().weekday", "datasets.dataset_utils.image_to_tfexample_with_text", "tfrecord_writer.write", "os.path.dirname", "dataset_utils.image_to_tfexample_with_text.SerializeToString", "tensorflow.gfile.FastGFile", "os.path.splitext", "datetime.datetime.strptime", "len"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._get_dataset_filename", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers.ImageReader.read_image_dims", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.image_to_tfexample_with_text"], ["", "def", "_convert_dataset_with_text", "(", "split_name", ",", "filenames", ",", "class_names_to_ids", ",", "dataset_dir", ",", "df_dict", ",", "\n", "tfrecords_subdir", "=", "'tfrecords'", ")", ":", "\n", "  ", "\"\"\"Converts the given filenames to a TFRecords dataset.\n\n  Args:\n    split_name: The name of the dataset, either 'train' or 'validation'.\n    filenames: A list of absolute paths to png or jpg images.\n    class_names_to_ids: A dictionary from class names (strings) to ids\n      (integers).\n    dataset_dir: The directory where the converted datasets are stored.\n    tfrecords_subdir: A subdirectory to save the TFRecords dataset\n  \"\"\"", "\n", "assert", "split_name", "in", "[", "'train'", ",", "'validation'", "]", "\n", "\n", "num_per_shard", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "filenames", ")", "/", "float", "(", "_NUM_SHARDS", ")", ")", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "    ", "image_reader", "=", "ImageReader", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "\n", "      ", "for", "shard_id", "in", "range", "(", "_NUM_SHARDS", ")", ":", "\n", "        ", "output_filename", "=", "_get_dataset_filename", "(", "\n", "dataset_dir", ",", "tfrecords_subdir", ",", "split_name", ",", "shard_id", ")", "\n", "\n", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "output_filename", ")", "as", "tfrecord_writer", ":", "\n", "          ", "start_ndx", "=", "shard_id", "*", "num_per_shard", "\n", "end_ndx", "=", "min", "(", "(", "shard_id", "+", "1", ")", "*", "num_per_shard", ",", "len", "(", "filenames", ")", ")", "\n", "for", "i", "in", "range", "(", "start_ndx", ",", "end_ndx", ")", ":", "\n", "            ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Converting image %d/%d shard %d'", "%", "(", "\n", "i", "+", "1", ",", "len", "(", "filenames", ")", ",", "shard_id", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "# Read the filename:", "\n", "image_data", "=", "tf", ".", "gfile", ".", "FastGFile", "(", "filenames", "[", "i", "]", ",", "'rb'", ")", ".", "read", "(", ")", "\n", "height", ",", "width", "=", "image_reader", ".", "read_image_dims", "(", "sess", ",", "image_data", ")", "\n", "\n", "class_name", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "dirname", "(", "filenames", "[", "i", "]", ")", ")", "\n", "class_id", "=", "class_names_to_ids", "[", "class_name", "]", "\n", "\n", "# Get index of the post", "\n", "base", "=", "os", ".", "path", ".", "basename", "(", "filenames", "[", "i", "]", ")", "\n", "index", "=", "(", "int", ")", "(", "os", ".", "path", ".", "splitext", "(", "base", ")", "[", "0", "]", ")", "\n", "text_data", "=", "df_dict", "[", "class_name", "]", ".", "iloc", "[", "index", "]", "[", "'text_list'", "]", "\n", "seq_len", "=", "df_dict", "[", "class_name", "]", ".", "iloc", "[", "index", "]", "[", "'text_len'", "]", "\n", "post_id", "=", "df_dict", "[", "class_name", "]", ".", "iloc", "[", "index", "]", "[", "'id'", "]", "\n", "date", "=", "df_dict", "[", "class_name", "]", ".", "iloc", "[", "index", "]", "[", "'date'", "]", "\n", "day", "=", "datetime", ".", "strptime", "(", "date", ",", "'%Y-%m-%d %H:%M:%S GMT'", ")", ".", "weekday", "(", ")", "\n", "# Convert to str, as only strings are accepted by tfexample", "\n", "#text_data = text_data.encode('ascii', 'ignore')", "\n", "\n", "example", "=", "dataset_utils", ".", "image_to_tfexample_with_text", "(", "\n", "image_data", ",", "b'jpg'", ",", "height", ",", "width", ",", "text_data", ",", "seq_len", ",", "class_id", ",", "post_id", ",", "day", ")", "\n", "tfrecord_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "\n", "", "", "", "", "", "sys", ".", "stdout", ".", "write", "(", "'\\n'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords._clean_up_temporary_files": [[220, 233], ["os.path.join", "tensorflow.gfile.DeleteRecursively"], "function", ["None"], ["", "def", "_clean_up_temporary_files", "(", "dataset_dir", ",", "photos_subdir", "=", "'photos'", ")", ":", "\n", "  ", "\"\"\"Removes temporary files used to create the dataset.\n\n  Args:\n    dataset_dir: The directory where the temporary files are stored.\n    photos_subdir: The subdirectory where the temporary files are stored.\n  \"\"\"", "\n", "#filename = _DATA_URL.split('/')[-1]", "\n", "#filepath = os.path.join(dataset_dir, filename)", "\n", "#tf.gfile.Remove(filepath)", "\n", "\n", "tmp_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "photos_subdir", ")", "\n", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "tmp_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords._dataset_exists": [[235, 243], ["range", "convert_images_tfrecords._get_dataset_filename", "tensorflow.gfile.Exists"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._get_dataset_filename"], ["", "def", "_dataset_exists", "(", "dataset_dir", ",", "photos_subdir", "=", "'photos'", ")", ":", "\n", "  ", "for", "split_name", "in", "[", "'train'", ",", "'validation'", "]", ":", "\n", "    ", "for", "shard_id", "in", "range", "(", "_NUM_SHARDS", ")", ":", "\n", "      ", "output_filename", "=", "_get_dataset_filename", "(", "\n", "dataset_dir", ",", "photos_subdir", ",", "split_name", ",", "shard_id", ")", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "output_filename", ")", ":", "\n", "        ", "return", "False", "\n", "", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords.convert_images": [[245, 290], ["convert_images_tfrecords._dataset_exists", "convert_images_tfrecords._get_filenames_and_classes", "dict", "random.seed", "random.shuffle", "convert_images_tfrecords._convert_dataset", "convert_images_tfrecords._convert_dataset", "dict", "os.path.join", "dict", "datasets.dataset_utils.write_label_file", "print", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "print", "zip", "zip", "tensorflow.gfile.Open", "zip", "os.path.join", "os.path.join", "range", "f.write", "range", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._dataset_exists", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._get_filenames_and_classes", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._convert_dataset", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._convert_dataset", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.write_label_file"], ["", "def", "convert_images", "(", "dataset_dir", ",", "num_valid", ",", "photos_subdir", "=", "'photos'", ",", "tfrecords_subdir", "=", "'tfrecords'", ")", ":", "\n", "  ", "\"\"\"Downloads the photos and convert them to TFRecords.\n\n  Parameters:\n    dataset_dir: The data directory.\n    photos_subdir: The subdirectory where the photos are stored.\n    tfrecords_subdir: The subdirectory to store the TFRecords files.\n  \"\"\"", "\n", "# Create the tfrecords_subdir if it doesn't exist", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "tfrecords_subdir", ")", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "tfrecords_subdir", ")", ")", "\n", "\n", "", "if", "_dataset_exists", "(", "dataset_dir", ",", "photos_subdir", ")", ":", "\n", "    ", "print", "(", "'Dataset files already exist. Exiting without re-creating them.'", ")", "\n", "return", "\n", "\n", "", "photo_filenames", ",", "class_names", "=", "_get_filenames_and_classes", "(", "dataset_dir", ",", "photos_subdir", ")", "\n", "class_names_to_ids", "=", "dict", "(", "zip", "(", "class_names", ",", "range", "(", "len", "(", "class_names", ")", ")", ")", ")", "\n", "\n", "# Divide into train and test:", "\n", "random", ".", "seed", "(", "_RANDOM_SEED", ")", "\n", "random", ".", "shuffle", "(", "photo_filenames", ")", "\n", "training_filenames", "=", "photo_filenames", "[", "num_valid", ":", "]", "\n", "validation_filenames", "=", "photo_filenames", "[", ":", "num_valid", "]", "\n", "\n", "# First, convert the training and validation sets.", "\n", "_convert_dataset", "(", "'train'", ",", "training_filenames", ",", "class_names_to_ids", ",", "\n", "dataset_dir", ",", "tfrecords_subdir", ")", "\n", "_convert_dataset", "(", "'validation'", ",", "validation_filenames", ",", "class_names_to_ids", ",", "\n", "dataset_dir", ",", "tfrecords_subdir", ")", "\n", "\n", "# Write the train/validation split size", "\n", "train_valid_split", "=", "dict", "(", "zip", "(", "[", "'train'", ",", "'validation'", "]", ",", "[", "len", "(", "photo_filenames", ")", "-", "num_valid", ",", "num_valid", "]", ")", ")", "\n", "train_valid_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "photos_subdir", ",", "_TRAIN_VALID_FILENAME", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "train_valid_filename", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "for", "split_name", "in", "train_valid_split", ":", "\n", "      ", "size", "=", "train_valid_split", "[", "split_name", "]", "\n", "f", ".", "write", "(", "'%s:%d\\n'", "%", "(", "split_name", ",", "size", ")", ")", "\n", "\n", "# Finally, write the labels file:", "\n", "", "", "labels_to_class_names", "=", "dict", "(", "zip", "(", "range", "(", "len", "(", "class_names", ")", ")", ",", "class_names", ")", ")", "\n", "dataset_utils", ".", "write_label_file", "(", "labels_to_class_names", ",", "dataset_dir", ",", "photos_subdir", ")", "\n", "\n", "#_clean_up_temporary_files(dataset_dir)", "\n", "print", "(", "'\\nFinished converting the dataset!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords.convert_images_with_text": [[291, 350], ["convert_images_tfrecords._dataset_exists", "convert_images_tfrecords._get_filenames_and_classes", "dict", "random.seed", "random.shuffle", "dict", "convert_images_tfrecords._convert_dataset_with_text", "convert_images_tfrecords._convert_dataset_with_text", "dict", "os.path.join", "dict", "datasets.dataset_utils.write_label_file", "print", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "print", "zip", "text_model.text_preprocessing._load_embedding_weights_word2vec", "text_model.text_preprocessing._load_embedding_weights_glove", "text_model.text_preprocessing.preprocess_one_df", "zip", "tensorflow.gfile.Open", "zip", "os.path.join", "os.path.join", "range", "f.write", "range", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._dataset_exists", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._get_filenames_and_classes", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords._convert_dataset_with_text", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords._convert_dataset_with_text", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.write_label_file", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_word2vec", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_glove", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing.preprocess_one_df"], ["", "def", "convert_images_with_text", "(", "dataset_dir", ",", "num_valid", ",", "photos_subdir", "=", "'photos'", ",", "tfrecords_subdir", "=", "'tfrecords'", ")", ":", "\n", "  ", "\"\"\"Downloads the photos and convert them to TFRecords.\n\n  Parameters:\n    dataset_dir: The data directory.\n    photos_subdir: The subdirectory where the photos are stored.\n    tfrecords_subdir: The subdirectory to store the TFRecords files.\n  \"\"\"", "\n", "# Create the tfrecords_subdir if it doesn't exist", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "tfrecords_subdir", ")", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "tfrecords_subdir", ")", ")", "\n", "\n", "", "if", "_dataset_exists", "(", "dataset_dir", ",", "photos_subdir", ")", ":", "\n", "    ", "print", "(", "'Dataset files already exist. Exiting without re-creating them.'", ")", "\n", "return", "\n", "\n", "", "photo_filenames", ",", "class_names", "=", "_get_filenames_and_classes", "(", "dataset_dir", ",", "photos_subdir", ")", "\n", "class_names_to_ids", "=", "dict", "(", "zip", "(", "class_names", ",", "range", "(", "len", "(", "class_names", ")", ")", ")", ")", "\n", "\n", "# Divide into train and test:", "\n", "random", ".", "seed", "(", "_RANDOM_SEED", ")", "\n", "random", ".", "shuffle", "(", "photo_filenames", ")", "\n", "training_filenames", "=", "photo_filenames", "[", "num_valid", ":", "]", "\n", "validation_filenames", "=", "photo_filenames", "[", ":", "num_valid", "]", "\n", "\n", "# Load dataframes", "\n", "df_dict", "=", "dict", "(", ")", "\n", "emb_name", "=", "'glove'", "\n", "text_dir", "=", "'text_model'", "\n", "emb_dir", "=", "'embedding_weights'", "\n", "filename", "=", "'glove.6B.50d.txt'", "\n", "if", "emb_name", "==", "'word2vec'", ":", "\n", "      ", "vocabulary", ",", "embedding", "=", "_load_embedding_weights_word2vec", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "", "else", ":", "\n", "      ", "vocabulary", ",", "embedding", "=", "_load_embedding_weights_glove", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "\n", "", "for", "emotion", "in", "class_names", ":", "\n", "    ", "df_dict", "[", "emotion", "]", "=", "preprocess_one_df", "(", "vocabulary", ",", "embedding", ",", "emotion", ",", "_POST_SIZE", ")", "\n", "\n", "# First, convert the training and validation sets.", "\n", "", "_convert_dataset_with_text", "(", "'train'", ",", "training_filenames", ",", "class_names_to_ids", ",", "\n", "dataset_dir", ",", "df_dict", ",", "tfrecords_subdir", ")", "\n", "_convert_dataset_with_text", "(", "'validation'", ",", "validation_filenames", ",", "class_names_to_ids", ",", "\n", "dataset_dir", ",", "df_dict", ",", "tfrecords_subdir", ")", "\n", "\n", "# Write the train/validation split size", "\n", "train_valid_split", "=", "dict", "(", "zip", "(", "[", "'train'", ",", "'validation'", "]", ",", "[", "len", "(", "photo_filenames", ")", "-", "num_valid", ",", "num_valid", "]", ")", ")", "\n", "train_valid_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "photos_subdir", ",", "_TRAIN_VALID_FILENAME", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "train_valid_filename", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "for", "split_name", "in", "train_valid_split", ":", "\n", "      ", "size", "=", "train_valid_split", "[", "split_name", "]", "\n", "f", ".", "write", "(", "'%s:%d\\n'", "%", "(", "split_name", ",", "size", ")", ")", "\n", "\n", "# Finally, write the labels file:", "\n", "", "", "labels_to_class_names", "=", "dict", "(", "zip", "(", "range", "(", "len", "(", "class_names", ")", ")", ",", "class_names", ")", ")", "\n", "dataset_utils", ".", "write_label_file", "(", "labels_to_class_names", ",", "dataset_dir", ",", "photos_subdir", ")", "\n", "\n", "#_clean_up_temporary_files(dataset_dir)", "\n", "print", "(", "'\\nFinished converting the dataset!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords._filenames_to_arrays": [[351, 367], ["numpy.vstack", "numpy.array", "scipy.misc.imread", "os.path.basename", "scipy.misc.imresize().reshape", "np.vstack.append", "np.array.append", "os.path.dirname", "scipy.misc.imresize"], "function", ["None"], ["", "def", "_filenames_to_arrays", "(", "filenames", ",", "class_names_to_ids", ")", ":", "\n", "    ", "X", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "filename", "in", "filenames", ":", "\n", "        ", "im", "=", "imread", "(", "filename", ")", "\n", "class_name", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "dirname", "(", "filename", ")", ")", "\n", "class_id", "=", "class_names_to_ids", "[", "class_name", "]", "\n", "# Might need different size as 224 is quite large", "\n", "image_size", "=", "16", "#inception.inception_v1.default_image_size", "\n", "# Resize and flatten the image", "\n", "im", "=", "imresize", "(", "im", ",", "(", "image_size", ",", "image_size", ")", ")", ".", "reshape", "(", "-", "1", ")", "\n", "X", ".", "append", "(", "im", ")", "\n", "y", ".", "append", "(", "class_id", ")", "\n", "", "X", "=", "np", ".", "vstack", "(", "X", ")", "\n", "y", "=", "np", ".", "array", "(", "y", ")", "\n", "return", "(", "X", ",", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords.get_numpy_data": [[368, 394], ["convert_images_tfrecords._get_filenames_and_classes", "dict", "random.seed", "random.shuffle", "convert_images_tfrecords._filenames_to_arrays", "convert_images_tfrecords._filenames_to_arrays", "zip", "range", "len"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._get_filenames_and_classes", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords._filenames_to_arrays", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_images_tfrecords._filenames_to_arrays"], ["", "def", "get_numpy_data", "(", "dataset_dir", ",", "num_valid", ",", "photos_subdir", "=", "'photos'", ")", ":", "\n", "  ", "\"\"\"Convert the photos to numpy data.\n\n  Parameters:\n    dataset_dir: The data directory.\n    photos_subdir: The subdirectory where the photos are stored.\n\n  Returns:\n    X_train: Training features.\n    X_valid: Validation features.\n    y_train: Training labels.\n    y_valid: Validation labels\n  \"\"\"", "\n", "photo_filenames", ",", "class_names", "=", "_get_filenames_and_classes", "(", "dataset_dir", ",", "photos_subdir", ")", "\n", "class_names_to_ids", "=", "dict", "(", "zip", "(", "class_names", ",", "range", "(", "len", "(", "class_names", ")", ")", ")", ")", "\n", "\n", "# Divide into train and test:", "\n", "random", ".", "seed", "(", "_RANDOM_SEED", ")", "\n", "random", ".", "shuffle", "(", "photo_filenames", ")", "\n", "training_filenames", "=", "photo_filenames", "[", "num_valid", ":", "]", "\n", "validation_filenames", "=", "photo_filenames", "[", ":", "num_valid", "]", "\n", "\n", "X_train", ",", "y_train", "=", "_filenames_to_arrays", "(", "training_filenames", ",", "class_names_to_ids", ")", "\n", "X_valid", ",", "y_valid", "=", "_filenames_to_arrays", "(", "validation_filenames", ",", "class_names_to_ids", ")", "\n", "\n", "return", "(", "X_train", ",", "X_valid", ",", "y_train", ",", "y_valid", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.int64_feature": [[30, 42], ["tensorflow.train.Feature", "isinstance", "tensorflow.train.Int64List"], "function", ["None"], ["def", "int64_feature", "(", "values", ")", ":", "\n", "  ", "\"\"\"Returns a TF-Feature of int64s.\n\n  Args:\n    values: A scalar or list of values.\n\n  Returns:\n    a TF-Feature.\n  \"\"\"", "\n", "if", "not", "isinstance", "(", "values", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "    ", "values", "=", "[", "values", "]", "\n", "", "return", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "values", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.bytes_feature": [[44, 54], ["tensorflow.train.Feature", "tensorflow.train.BytesList"], "function", ["None"], ["", "def", "bytes_feature", "(", "values", ")", ":", "\n", "  ", "\"\"\"Returns a TF-Feature of bytes.\n\n  Args:\n    values: A string.\n\n  Returns:\n    a TF-Feature.\n  \"\"\"", "\n", "return", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "values", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.image_to_tfexample": [[56, 63], ["tensorflow.train.Example", "tensorflow.train.Features", "dataset_utils.bytes_feature", "dataset_utils.bytes_feature", "dataset_utils.int64_feature", "dataset_utils.int64_feature", "dataset_utils.int64_feature"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.bytes_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.bytes_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.int64_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.int64_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.int64_feature"], ["", "def", "image_to_tfexample", "(", "image_data", ",", "image_format", ",", "height", ",", "width", ",", "class_id", ")", ":", "\n", "  ", "return", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "'image/encoded'", ":", "bytes_feature", "(", "image_data", ")", ",", "\n", "'image/format'", ":", "bytes_feature", "(", "image_format", ")", ",", "\n", "'image/class/label'", ":", "int64_feature", "(", "class_id", ")", ",", "\n", "'image/height'", ":", "int64_feature", "(", "height", ")", ",", "\n", "'image/width'", ":", "int64_feature", "(", "width", ")", ",", "\n", "}", ")", ")", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.image_to_tfexample_with_text": [[65, 76], ["tensorflow.train.Example", "tensorflow.train.Features", "dataset_utils.bytes_feature", "dataset_utils.bytes_feature", "dataset_utils.int64_feature", "dataset_utils.int64_feature", "dataset_utils.int64_feature", "dataset_utils.int64_feature", "dataset_utils.int64_feature", "dataset_utils.int64_feature", "dataset_utils.int64_feature"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.bytes_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.bytes_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.int64_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.int64_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.int64_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.int64_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.int64_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.int64_feature", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.int64_feature"], ["", "def", "image_to_tfexample_with_text", "(", "image_data", ",", "image_format", ",", "height", ",", "width", ",", "text_data", ",", "seq_len", ",", "class_id", ",", "post_id", ",", "day", ")", ":", "\n", "  ", "return", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "'image/encoded'", ":", "bytes_feature", "(", "image_data", ")", ",", "\n", "'image/format'", ":", "bytes_feature", "(", "image_format", ")", ",", "\n", "'image/class/label'", ":", "int64_feature", "(", "class_id", ")", ",", "\n", "'image/height'", ":", "int64_feature", "(", "height", ")", ",", "\n", "'image/width'", ":", "int64_feature", "(", "width", ")", ",", "\n", "'text'", ":", "int64_feature", "(", "text_data", ")", ",", "\n", "'seq_len'", ":", "int64_feature", "(", "seq_len", ")", ",", "\n", "'post_id'", ":", "int64_feature", "(", "post_id", ")", ",", "\n", "'day'", ":", "int64_feature", "(", "day", ")", ",", "\n", "}", ")", ")", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.download_and_uncompress_tarball": [[66, 85], ["os.path.join", "six.moves.urllib.request.urlretrieve", "print", "os.stat", "print", "tarfile.open().extractall", "tarball_url.split", "sys.stdout.write", "sys.stdout.flush", "tarfile.open", "float", "float"], "function", ["None"], ["  ", "return", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "{", "\n", "'image/encoded'", ":", "bytes_feature", "(", "image_data", ")", ",", "\n", "'image/format'", ":", "bytes_feature", "(", "image_format", ")", ",", "\n", "'image/class/label'", ":", "int64_feature", "(", "class_id", ")", ",", "\n", "'image/height'", ":", "int64_feature", "(", "height", ")", ",", "\n", "'image/width'", ":", "int64_feature", "(", "width", ")", ",", "\n", "'text'", ":", "int64_feature", "(", "text_data", ")", ",", "\n", "'seq_len'", ":", "int64_feature", "(", "seq_len", ")", ",", "\n", "'post_id'", ":", "int64_feature", "(", "post_id", ")", ",", "\n", "'day'", ":", "int64_feature", "(", "day", ")", ",", "\n", "}", ")", ")", "\n", "\n", "", "def", "download_and_uncompress_tarball", "(", "tarball_url", ",", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Downloads the `tarball_url` and uncompresses it locally.\n\n  Args:\n    tarball_url: The URL of a tarball file.\n    dataset_dir: The directory where the temporary files are stored.\n  \"\"\"", "\n", "filename", "=", "tarball_url", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.write_label_file": [[87, 101], ["os.path.join", "tensorflow.gfile.Open", "f.write"], "function", ["None"], ["\n", "def", "_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "    ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Downloading %s %.1f%%'", "%", "(", "\n", "filename", ",", "float", "(", "count", "*", "block_size", ")", "/", "float", "(", "total_size", ")", "*", "100.0", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "filepath", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "tarball_url", ",", "filepath", ",", "_progress", ")", "\n", "print", "(", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "print", "(", "'Successfully downloaded'", ",", "filename", ",", "statinfo", ".", "st_size", ",", "'bytes.'", ")", "\n", "tarfile", ".", "open", "(", "filepath", ",", "'r:gz'", ")", ".", "extractall", "(", "dataset_dir", ")", "\n", "\n", "\n", "", "def", "write_label_file", "(", "labels_to_class_names", ",", "dataset_dir", ",", "photos_subdir", ",", "\n", "filename", "=", "LABELS_FILENAME", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.has_labels": [[103, 114], ["tensorflow.gfile.Exists", "os.path.join"], "function", ["None"], ["\n", "labels_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "photos_subdir", ",", "filename", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "labels_filename", ",", "'w'", ")", "as", "f", ":", "\n", "    ", "for", "label", "in", "labels_to_class_names", ":", "\n", "      ", "class_name", "=", "labels_to_class_names", "[", "label", "]", "\n", "f", ".", "write", "(", "'%d:%s\\n'", "%", "(", "label", ",", "class_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.read_label_file": [[116, 137], ["os.path.join", "f.read().decode.split", "filter", "tensorflow.gfile.Open", "f.read().decode", "line.index", "f.read", "int"], "function", ["None"], ["", "", "", "def", "has_labels", "(", "dataset_dir", ",", "photos_subdir", ",", "filename", "=", "LABELS_FILENAME", ")", ":", "\n", "  ", "\"\"\"Specifies whether or not the dataset directory contains a label map file.\n\n  Args:\n    dataset_dir: The main directory.\n    photos_subdir: The subdirectory in which the labels file is found.\n    filename: The filename where the class names are written.\n\n  Returns:\n    `True` if the labels file exists and `False` otherwise.\n  \"\"\"", "\n", "return", "tf", ".", "gfile", ".", "Exists", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "photos_subdir", ",", "filename", ")", ")", "\n", "\n", "\n", "", "def", "read_label_file", "(", "dataset_dir", ",", "photos_subdir", ",", "filename", "=", "LABELS_FILENAME", ")", ":", "\n", "  "]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.tumblr_extraction.extract_tumblr_posts": [[4, 49], ["range", "client.tagged", "abs", "current_post.append", "current_post.append", "current_post.append", "current_post.append", "current_post.append", "current_post.append", "current_post.append", "current_post.append", "current_post.append", "current_post.append", "current_post.append", "posts.append", "elt[].replace().replace", "current_post.append", "current_post.append", "current_post.append", "posts.append", "elt[].replace().replace", "elt[].replace", "elt[].replace"], "function", ["None"], ["def", "extract_tumblr_posts", "(", "client", ",", "nb_requests", ",", "search_query", ",", "before", ",", "delta_limit", ")", ":", "\n", "    ", "\"\"\"Extract Tumblr posts with a given emotion.\n    \n    Parameters:\n        client: Authenticated Tumblr client with the pytumblr package.\n        nb_requests: Number of API request.\n        search_query: Emotion to search for.\n        before: A timestamp to search for posts before that value.\n        delta_limit: Maximum difference of timestamp between two queries.\n        \n    Returns:\n        posts: List of Tumblr posts. \n    \"\"\"", "\n", "\n", "posts", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nb_requests", ")", ":", "\n", "        ", "tagged", "=", "client", ".", "tagged", "(", "search_query", ",", "filter", "=", "'text'", ",", "before", "=", "before", ")", "\n", "for", "elt", "in", "tagged", ":", "\n", "            ", "timestamp", "=", "elt", "[", "'timestamp'", "]", "\n", "if", "(", "abs", "(", "timestamp", "-", "before", ")", "<", "delta_limit", ")", ":", "\n", "                ", "before", "=", "timestamp", "\n", "\n", "current_post", "=", "[", "]", "\n", "current_post", ".", "append", "(", "elt", "[", "'id'", "]", ")", "\n", "current_post", ".", "append", "(", "elt", "[", "'post_url'", "]", ")", "\n", "elt_type", "=", "elt", "[", "'type'", "]", "\n", "current_post", ".", "append", "(", "elt_type", ")", "\n", "current_post", ".", "append", "(", "timestamp", ")", "\n", "current_post", ".", "append", "(", "elt", "[", "'date'", "]", ")", "\n", "current_post", ".", "append", "(", "elt", "[", "'tags'", "]", ")", "\n", "current_post", ".", "append", "(", "elt", "[", "'liked'", "]", ")", "\n", "current_post", ".", "append", "(", "elt", "[", "'note_count'", "]", ")", "\n", "\n", "if", "(", "elt_type", "==", "'photo'", ")", ":", "\n", "# Only take the first image", "\n", "                    ", "current_post", ".", "append", "(", "elt", "[", "'photos'", "]", "[", "0", "]", "[", "'original_size'", "]", "[", "'url'", "]", ")", "\n", "current_post", ".", "append", "(", "elt", "[", "'caption'", "]", ".", "replace", "(", "'\\n'", ",", "' '", ")", ".", "replace", "(", "'\\r'", ",", "' '", ")", ")", "\n", "current_post", ".", "append", "(", "search_query", ")", "\n", "posts", ".", "append", "(", "current_post", ")", "\n", "", "elif", "(", "elt_type", "==", "'text'", ")", ":", "\n", "                    ", "current_post", ".", "append", "(", "np", ".", "nan", ")", "\n", "current_post", ".", "append", "(", "elt", "[", "'body'", "]", ".", "replace", "(", "'\\n'", ",", "' '", ")", ".", "replace", "(", "'\\r'", ",", "' '", ")", ")", "\n", "current_post", ".", "append", "(", "search_query", ")", "\n", "posts", ".", "append", "(", "current_post", ")", "\n", "", "", "", "", "return", "posts", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_to_dataset.get_split": [[46, 116], ["os.path.join", "slim.tfexample_decoder.TFExampleDecoder", "datasets.dataset_utils.has_labels", "os.path.join", "f.read().decode.split", "filter", "slim.dataset.Dataset", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "slim.tfexample_decoder.Image", "slim.tfexample_decoder.Tensor", "datasets.dataset_utils.read_label_file", "tensorflow.gfile.Open", "f.read().decode", "line.index", "int", "len", "tensorflow.zeros", "f.read"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.has_labels", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.read_label_file"], ["def", "get_split", "(", "split_name", ",", "dataset_dir", ",", "photos_subdir", "=", "'photos'", ",", "tfrecords_subdir", "=", "'tfrecords'", ",", "\n", "file_pattern", "=", "None", ",", "reader", "=", "None", ")", ":", "\n", "  ", "\"\"\"Gets a dataset tuple with instructions for reading tumblr data.\n\n  Args:\n    split_name: A train/validation split name.\n    dataset_dir: The base directory of the dataset sources.\n    photos_subdir: The subdirectory containing the photos.\n    tfrecords_subdir: The subdirectory containing the TFRecords files.\n    file_pattern: The file pattern to use when matching the dataset sources.\n      It is assumed that the pattern contains a '%s' string so that the split\n      name can be inserted.\n    reader: The TensorFlow reader type.\n\n  Returns:\n    A `Dataset` namedtuple.\n\n  Raises:\n    ValueError: if `split_name` is not a valid train/validation split.\n  \"\"\"", "\n", "#if split_name not in SPLITS_TO_SIZES:", "\n", "#raise ValueError('split name %s was not recognized.' % split_name)", "\n", "\n", "if", "not", "file_pattern", ":", "\n", "    ", "file_pattern", "=", "_FILE_PATTERN", "\n", "", "file_pattern", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "tfrecords_subdir", ",", "file_pattern", "%", "split_name", ")", "\n", "\n", "# Allowing None in the signature so that dataset_factory can use the default.", "\n", "if", "reader", "is", "None", ":", "\n", "    ", "reader", "=", "tf", ".", "TFRecordReader", "\n", "\n", "", "keys_to_features", "=", "{", "\n", "'image/encoded'", ":", "tf", ".", "FixedLenFeature", "(", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "''", ")", ",", "\n", "'image/format'", ":", "tf", ".", "FixedLenFeature", "(", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "'jpg'", ")", ",", "\n", "'image/class/label'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "tf", ".", "int64", ",", "default_value", "=", "tf", ".", "zeros", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "}", "\n", "\n", "items_to_handlers", "=", "{", "\n", "'image'", ":", "slim", ".", "tfexample_decoder", ".", "Image", "(", ")", ",", "\n", "'label'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'image/class/label'", ")", ",", "\n", "}", "\n", "\n", "decoder", "=", "slim", ".", "tfexample_decoder", ".", "TFExampleDecoder", "(", "\n", "keys_to_features", ",", "items_to_handlers", ")", "\n", "\n", "labels_to_names", "=", "None", "\n", "if", "dataset_utils", ".", "has_labels", "(", "dataset_dir", ",", "photos_subdir", ")", ":", "\n", "    ", "labels_to_names", "=", "dataset_utils", ".", "read_label_file", "(", "dataset_dir", ",", "photos_subdir", ")", "\n", "\n", "# Get split size", "\n", "", "train_valid_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "photos_subdir", ",", "_TRAIN_VALID_FILENAME", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "train_valid_filename", ",", "'rb'", ")", "as", "f", ":", "\n", "    ", "lines", "=", "f", ".", "read", "(", ")", ".", "decode", "(", ")", "\n", "", "lines", "=", "lines", ".", "split", "(", "'\\n'", ")", "\n", "lines", "=", "filter", "(", "None", ",", "lines", ")", "\n", "\n", "train_valid_split", "=", "{", "}", "\n", "for", "line", "in", "lines", ":", "\n", "    ", "index", "=", "line", ".", "index", "(", "':'", ")", "\n", "train_valid_split", "[", "line", "[", ":", "index", "]", "]", "=", "(", "int", ")", "(", "line", "[", "index", "+", "1", ":", "]", ")", "\n", "\n", "", "return", "slim", ".", "dataset", ".", "Dataset", "(", "\n", "data_sources", "=", "file_pattern", ",", "\n", "reader", "=", "reader", ",", "\n", "decoder", "=", "decoder", ",", "\n", "num_samples", "=", "train_valid_split", "[", "split_name", "]", ",", "\n", "items_to_descriptions", "=", "_ITEMS_TO_DESCRIPTIONS", ",", "\n", "num_classes", "=", "len", "(", "labels_to_names", ")", ",", "\n", "labels_to_names", "=", "labels_to_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_to_dataset.get_split_with_text": [[117, 199], ["os.path.join", "slim.tfexample_decoder.TFExampleDecoder", "datasets.dataset_utils.has_labels", "os.path.join", "f.read().decode.split", "filter", "slim.dataset.Dataset", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "slim.tfexample_decoder.Image", "slim.tfexample_decoder.Tensor", "slim.tfexample_decoder.Tensor", "slim.tfexample_decoder.Tensor", "slim.tfexample_decoder.Tensor", "slim.tfexample_decoder.Tensor", "datasets.dataset_utils.read_label_file", "tensorflow.gfile.Open", "f.read().decode", "line.index", "int", "len", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros", "f.read"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.has_labels", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.read_label_file"], ["", "def", "get_split_with_text", "(", "split_name", ",", "dataset_dir", ",", "photos_subdir", "=", "'photos'", ",", "tfrecords_subdir", "=", "'tfrecords'", ",", "\n", "file_pattern", "=", "None", ",", "reader", "=", "None", ")", ":", "\n", "  ", "\"\"\"Gets a dataset tuple with instructions for reading tumblr data.\n\n  Args:\n    split_name: A train/validation split name.\n    dataset_dir: The base directory of the dataset sources.\n    photos_subdir: The subdirectory containing the photos.\n    tfrecords_subdir: The subdirectory containing the TFRecords files.\n    file_pattern: The file pattern to use when matching the dataset sources.\n      It is assumed that the pattern contains a '%s' string so that the split\n      name can be inserted.\n    reader: The TensorFlow reader type.\n\n  Returns:\n    A `Dataset` namedtuple.\n\n  Raises:\n    ValueError: if `split_name` is not a valid train/validation split.\n  \"\"\"", "\n", "#if split_name not in SPLITS_TO_SIZES:", "\n", "#raise ValueError('split name %s was not recognized.' % split_name)", "\n", "\n", "if", "not", "file_pattern", ":", "\n", "    ", "file_pattern", "=", "_FILE_PATTERN", "\n", "", "file_pattern", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "tfrecords_subdir", ",", "file_pattern", "%", "split_name", ")", "\n", "\n", "# Allowing None in the signature so that dataset_factory can use the default.", "\n", "if", "reader", "is", "None", ":", "\n", "    ", "reader", "=", "tf", ".", "TFRecordReader", "\n", "\n", "", "keys_to_features", "=", "{", "\n", "'image/encoded'", ":", "tf", ".", "FixedLenFeature", "(", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "''", ")", ",", "\n", "'image/format'", ":", "tf", ".", "FixedLenFeature", "(", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "'jpg'", ")", ",", "\n", "'image/class/label'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "tf", ".", "int64", ",", "default_value", "=", "tf", ".", "zeros", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "'text'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "_POST_SIZE", "]", ",", "tf", ".", "int64", ",", "default_value", "=", "tf", ".", "zeros", "(", "[", "_POST_SIZE", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "'seq_len'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "tf", ".", "int64", ",", "default_value", "=", "tf", ".", "zeros", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "'post_id'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "tf", ".", "int64", ",", "default_value", "=", "tf", ".", "zeros", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "'day'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "tf", ".", "int64", ",", "default_value", "=", "tf", ".", "zeros", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "}", "\n", "\n", "items_to_handlers", "=", "{", "\n", "'image'", ":", "slim", ".", "tfexample_decoder", ".", "Image", "(", ")", ",", "\n", "'text'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'text'", ")", ",", "\n", "'seq_len'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'seq_len'", ")", ",", "\n", "'label'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'image/class/label'", ")", ",", "\n", "'post_id'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'post_id'", ")", ",", "\n", "'day'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'day'", ")", ",", "\n", "}", "\n", "\n", "decoder", "=", "slim", ".", "tfexample_decoder", ".", "TFExampleDecoder", "(", "\n", "keys_to_features", ",", "items_to_handlers", ")", "\n", "\n", "labels_to_names", "=", "None", "\n", "if", "dataset_utils", ".", "has_labels", "(", "dataset_dir", ",", "photos_subdir", ")", ":", "\n", "    ", "labels_to_names", "=", "dataset_utils", ".", "read_label_file", "(", "dataset_dir", ",", "photos_subdir", ")", "\n", "\n", "# Get split size", "\n", "", "train_valid_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "photos_subdir", ",", "_TRAIN_VALID_FILENAME", ")", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "train_valid_filename", ",", "'rb'", ")", "as", "f", ":", "\n", "    ", "lines", "=", "f", ".", "read", "(", ")", ".", "decode", "(", ")", "\n", "", "lines", "=", "lines", ".", "split", "(", "'\\n'", ")", "\n", "lines", "=", "filter", "(", "None", ",", "lines", ")", "\n", "\n", "train_valid_split", "=", "{", "}", "\n", "for", "line", "in", "lines", ":", "\n", "    ", "index", "=", "line", ".", "index", "(", "':'", ")", "\n", "train_valid_split", "[", "line", "[", ":", "index", "]", "]", "=", "(", "int", ")", "(", "line", "[", "index", "+", "1", ":", "]", ")", "\n", "\n", "", "return", "slim", ".", "dataset", ".", "Dataset", "(", "\n", "data_sources", "=", "file_pattern", ",", "\n", "reader", "=", "reader", ",", "\n", "decoder", "=", "decoder", ",", "\n", "num_samples", "=", "train_valid_split", "[", "split_name", "]", ",", "\n", "items_to_descriptions", "=", "_ITEMS_TO_DESCRIPTIONS", ",", "\n", "num_classes", "=", "len", "(", "labels_to_names", ")", ",", "\n", "labels_to_names", "=", "labels_to_names", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_images.download_im": [[15, 52], ["pandas.read_csv", "os.path.join", "range", "os.path.join", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "os.path.join", "os.path.join", "io.BytesIO", "PIL.Image.open", "Image.open.convert().save", "urllib.request.urlopen", "urllib.request.urlopen.read", "str", "os.path.join", "Image.open.convert"], "function", ["None"], ["def", "download_im", "(", "search_query", ",", "start", ",", "end", ",", "dataset_dir", ",", "subdir", "=", "'photos'", ")", ":", "\n", "    ", "\"\"\"Download images using the urls in the dataframe specified by the search query.\n\n    Parameters:\n        search_query: A string giving the sentiment to load the corresponding dataframe.\n        start: A start index for the loaded dataframe.\n        end: An end index for the loaded dataframe.\n        dataset_dir: A directory where the dataframes are stored.\n        subdir: A subdirectory to store the photos.\n\n    Returns:\n        Images downloaded in the directory dataset_dir/subdir/search_query, having \n        the posts ids as names.\n    \"\"\"", "\n", "# Load data", "\n", "df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "search_query", "+", "'.csv'", ")", ",", "encoding", "=", "'utf-8'", ")", "\n", "links", "=", "df", "[", "'photo'", "]", "\n", "# Create subdir if it doesn't exist", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "subdir", ")", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MakeDirs", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "subdir", ")", ")", "\n", "# Create search_query folder if it doesn't exist", "\n", "", "photos_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "subdir", ",", "search_query", ")", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "photos_dir", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MakeDirs", "(", "photos_dir", ")", "\n", "", "for", "i", "in", "range", "(", "start", ",", "end", ")", ":", "\n", "# Check for NaNs", "\n", "        ", "if", "links", "[", "i", "]", "==", "links", "[", "i", "]", ":", "\n", "# Open url and convert to JPEG image", "\n", "            ", "try", ":", "\n", "                ", "f", "=", "urlopen", "(", "links", "[", "i", "]", ")", "\n", "", "except", "Exception", ":", "\n", "                ", "continue", "\n", "", "image_file", "=", "io", ".", "BytesIO", "(", "f", ".", "read", "(", ")", ")", "\n", "im", "=", "Image", ".", "open", "(", "image_file", ")", "\n", "# The filename is the index of the image in the dataframe", "\n", "filename", "=", "str", "(", "i", ")", "+", "'.jpg'", "\n", "im", ".", "convert", "(", "'RGB'", ")", ".", "save", "(", "os", ".", "path", ".", "join", "(", "photos_dir", ",", "filename", ")", ",", "'JPEG'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_images.download_im_with_text": [[53, 102], ["text_model.text_preprocessing.preprocess_one_df", "os.path.join", "range", "text_model.text_preprocessing._load_embedding_weights_word2vec", "text_model.text_preprocessing._load_embedding_weights_glove", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "os.path.join", "os.path.join", "io.BytesIO", "PIL.Image.open", "Image.open.convert().save", "urllib.request.urlopen", "urllib.request.urlopen.read", "str", "os.path.join", "Image.open.convert"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing.preprocess_one_df", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_word2vec", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_glove"], ["", "", "", "def", "download_im_with_text", "(", "search_query", ",", "start", ",", "end", ",", "dataset_dir", "=", "'data'", ",", "subdir", "=", "'photos'", ")", ":", "\n", "    ", "\"\"\"Download images using the urls in the dataframe specified by the search query.\n\n    Parameters:\n        search_query: A string giving the sentiment to load the corresponding dataframe.\n        start: A start index for the loaded dataframe.\n        end: An end index for the loaded dataframe. -1 corresponds to the last row.\n        dataset_dir: A directory where the dataframes are stored.\n        subdir: A subdirectory to store the photos.\n\n    Returns:\n        Images downloaded in the directory dataset_dir/subdir/search_query, having \n        the posts ids as names.\n    \"\"\"", "\n", "# Load data", "\n", "emb_name", "=", "'glove'", "\n", "text_dir", "=", "'text_model'", "\n", "emb_dir", "=", "'embedding_weights'", "\n", "filename", "=", "'glove.6B.50d.txt'", "\n", "if", "emb_name", "==", "'word2vec'", ":", "\n", "        ", "vocabulary", ",", "embedding", "=", "_load_embedding_weights_word2vec", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "", "else", ":", "\n", "        ", "vocabulary", ",", "embedding", "=", "_load_embedding_weights_glove", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "\n", "", "df", "=", "preprocess_one_df", "(", "vocabulary", ",", "embedding", ",", "search_query", ",", "_POST_SIZE", ")", "\n", "if", "end", "==", "-", "1", ":", "\n", "        ", "end", "=", "df", ".", "shape", "[", "0", "]", "\n", "\n", "", "links", "=", "df", "[", "'photo'", "]", "\n", "# Create subdir if it doesn't exist", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "subdir", ")", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MakeDirs", "(", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "subdir", ")", ")", "\n", "# Create search_query folder if it doesn't exist", "\n", "", "photos_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "subdir", ",", "search_query", ")", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "photos_dir", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "MakeDirs", "(", "photos_dir", ")", "\n", "", "for", "i", "in", "range", "(", "start", ",", "end", ")", ":", "\n", "# Check for NaNs", "\n", "        ", "if", "links", "[", "i", "]", "==", "links", "[", "i", "]", ":", "\n", "# Open url and convert to JPEG image", "\n", "            ", "try", ":", "\n", "                ", "f", "=", "urlopen", "(", "links", "[", "i", "]", ")", "\n", "", "except", "Exception", ":", "\n", "                ", "continue", "\n", "", "image_file", "=", "io", ".", "BytesIO", "(", "f", ".", "read", "(", ")", ")", "\n", "im", "=", "Image", ".", "open", "(", "image_file", ")", "\n", "# The filename is the index of the image in the dataframe", "\n", "filename", "=", "str", "(", "i", ")", "+", "'.jpg'", "\n", "im", ".", "convert", "(", "'RGB'", ")", ".", "save", "(", "os", ".", "path", ".", "join", "(", "photos_dir", ",", "filename", ")", ",", "'JPEG'", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_cifar10._add_to_tfrecord": [[64, 109], ["images.reshape.reshape", "tensorflow.gfile.Open", "tensorflow.Graph().as_default", "tensorflow.placeholder", "tensorflow.image.encode_png", "six.moves.cPickle.load", "six.moves.cPickle.load", "tensorflow.Session", "range", "tensorflow.Graph", "sys.stdout.write", "sys.stdout.flush", "numpy.squeeze().transpose", "sess.run", "datasets.dataset_utils.image_to_tfexample", "tfrecord_writer.write", "dataset_utils.image_to_tfexample.SerializeToString", "numpy.squeeze"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.image_to_tfexample"], ["def", "_add_to_tfrecord", "(", "filename", ",", "tfrecord_writer", ",", "offset", "=", "0", ")", ":", "\n", "  ", "\"\"\"Loads data from the cifar10 pickle files and writes files to a TFRecord.\n\n  Args:\n    filename: The filename of the cifar10 pickle file.\n    tfrecord_writer: The TFRecord writer to use for writing.\n    offset: An offset into the absolute number of images previously written.\n\n  Returns:\n    The new offset.\n  \"\"\"", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "    ", "if", "sys", ".", "version_info", "<", "(", "3", ",", ")", ":", "\n", "      ", "data", "=", "cPickle", ".", "load", "(", "f", ")", "\n", "", "else", ":", "\n", "      ", "data", "=", "cPickle", ".", "load", "(", "f", ",", "encoding", "=", "'bytes'", ")", "\n", "\n", "", "", "images", "=", "data", "[", "b'data'", "]", "\n", "num_images", "=", "images", ".", "shape", "[", "0", "]", "\n", "\n", "images", "=", "images", ".", "reshape", "(", "(", "num_images", ",", "3", ",", "32", ",", "32", ")", ")", "\n", "labels", "=", "data", "[", "b'labels'", "]", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "    ", "image_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "uint8", ")", "\n", "encoded_image", "=", "tf", ".", "image", ".", "encode_png", "(", "image_placeholder", ")", "\n", "\n", "with", "tf", ".", "Session", "(", "''", ")", "as", "sess", ":", "\n", "\n", "      ", "for", "j", "in", "range", "(", "num_images", ")", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Reading file [%s] image %d/%d'", "%", "(", "\n", "filename", ",", "offset", "+", "j", "+", "1", ",", "offset", "+", "num_images", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "image", "=", "np", ".", "squeeze", "(", "images", "[", "j", "]", ")", ".", "transpose", "(", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "label", "=", "labels", "[", "j", "]", "\n", "\n", "png_string", "=", "sess", ".", "run", "(", "encoded_image", ",", "\n", "feed_dict", "=", "{", "image_placeholder", ":", "image", "}", ")", "\n", "\n", "example", "=", "dataset_utils", ".", "image_to_tfexample", "(", "\n", "png_string", ",", "b'png'", ",", "_IMAGE_SIZE", ",", "_IMAGE_SIZE", ",", "label", ")", "\n", "tfrecord_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "\n", "", "", "", "return", "offset", "+", "num_images", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_cifar10._get_output_filename": [[111, 122], ["None"], "function", ["None"], ["", "def", "_get_output_filename", "(", "dataset_dir", ",", "split_name", ")", ":", "\n", "  ", "\"\"\"Creates the output filename.\n\n  Args:\n    dataset_dir: The dataset directory where the dataset is stored.\n    split_name: The name of the train/test split.\n\n  Returns:\n    An absolute file path.\n  \"\"\"", "\n", "return", "'%s/cifar10_%s.tfrecord'", "%", "(", "dataset_dir", ",", "split_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_cifar10._download_and_uncompress_dataset": [[124, 143], ["os.path.join", "_DATA_URL.split", "os.path.exists", "six.moves.urllib.request.urlretrieve", "print", "os.stat", "print", "tarfile.open().extractall", "sys.stdout.write", "sys.stdout.flush", "tarfile.open", "float", "float"], "function", ["None"], ["", "def", "_download_and_uncompress_dataset", "(", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Downloads cifar10 and uncompresses it locally.\n\n  Args:\n    dataset_dir: The directory where the temporary files are stored.\n  \"\"\"", "\n", "filename", "=", "_DATA_URL", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "filename", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "    ", "def", "_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "      ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Downloading %s %.1f%%'", "%", "(", "\n", "filename", ",", "float", "(", "count", "*", "block_size", ")", "/", "float", "(", "total_size", ")", "*", "100.0", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "filepath", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "_DATA_URL", ",", "filepath", ",", "_progress", ")", "\n", "print", "(", ")", "\n", "statinfo", "=", "os", ".", "stat", "(", "filepath", ")", "\n", "print", "(", "'Successfully downloaded'", ",", "filename", ",", "statinfo", ".", "st_size", ",", "'bytes.'", ")", "\n", "tarfile", ".", "open", "(", "filepath", ",", "'r:gz'", ")", ".", "extractall", "(", "dataset_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_cifar10._clean_up_temporary_files": [[145, 157], ["os.path.join", "tensorflow.gfile.Remove", "os.path.join", "tensorflow.gfile.DeleteRecursively", "_DATA_URL.split"], "function", ["None"], ["", "", "def", "_clean_up_temporary_files", "(", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Removes temporary files used to create the dataset.\n\n  Args:\n    dataset_dir: The directory where the temporary files are stored.\n  \"\"\"", "\n", "filename", "=", "_DATA_URL", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "filename", ")", "\n", "tf", ".", "gfile", ".", "Remove", "(", "filepath", ")", "\n", "\n", "tmp_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'cifar-10-batches-py'", ")", "\n", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "tmp_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_cifar10.run": [[159, 199], ["download_and_convert_cifar10._get_output_filename", "download_and_convert_cifar10._get_output_filename", "datasets.dataset_utils.download_and_uncompress_tarball", "dict", "datasets.dataset_utils.write_label_file", "download_and_convert_cifar10._clean_up_temporary_files", "print", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "print", "tensorflow.python_io.TFRecordWriter", "range", "tensorflow.python_io.TFRecordWriter", "os.path.join", "download_and_convert_cifar10._add_to_tfrecord", "zip", "os.path.join", "download_and_convert_cifar10._add_to_tfrecord", "range", "len"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._get_output_filename", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._get_output_filename", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.download_and_uncompress_tarball", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.write_label_file", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._clean_up_temporary_files", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._add_to_tfrecord", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._add_to_tfrecord"], ["", "def", "run", "(", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Runs the download and conversion operation.\n\n  Args:\n    dataset_dir: The dataset directory where the dataset is stored.\n  \"\"\"", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "dataset_dir", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "dataset_dir", ")", "\n", "\n", "", "training_filename", "=", "_get_output_filename", "(", "dataset_dir", ",", "'train'", ")", "\n", "testing_filename", "=", "_get_output_filename", "(", "dataset_dir", ",", "'test'", ")", "\n", "\n", "if", "tf", ".", "gfile", ".", "Exists", "(", "training_filename", ")", "and", "tf", ".", "gfile", ".", "Exists", "(", "testing_filename", ")", ":", "\n", "    ", "print", "(", "'Dataset files already exist. Exiting without re-creating them.'", ")", "\n", "return", "\n", "\n", "", "dataset_utils", ".", "download_and_uncompress_tarball", "(", "_DATA_URL", ",", "dataset_dir", ")", "\n", "\n", "# First, process the training data:", "\n", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "training_filename", ")", "as", "tfrecord_writer", ":", "\n", "    ", "offset", "=", "0", "\n", "for", "i", "in", "range", "(", "_NUM_TRAIN_FILES", ")", ":", "\n", "      ", "filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "\n", "'cifar-10-batches-py'", ",", "\n", "'data_batch_%d'", "%", "(", "i", "+", "1", ")", ")", "# 1-indexed.", "\n", "offset", "=", "_add_to_tfrecord", "(", "filename", ",", "tfrecord_writer", ",", "offset", ")", "\n", "\n", "# Next, process the testing data:", "\n", "", "", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "testing_filename", ")", "as", "tfrecord_writer", ":", "\n", "    ", "filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "\n", "'cifar-10-batches-py'", ",", "\n", "'test_batch'", ")", "\n", "_add_to_tfrecord", "(", "filename", ",", "tfrecord_writer", ")", "\n", "\n", "# Finally, write the labels file:", "\n", "", "labels_to_class_names", "=", "dict", "(", "zip", "(", "range", "(", "len", "(", "_CLASS_NAMES", ")", ")", ",", "_CLASS_NAMES", ")", ")", "\n", "dataset_utils", ".", "write_label_file", "(", "labels_to_class_names", ",", "dataset_dir", ")", "\n", "\n", "_clean_up_temporary_files", "(", "dataset_dir", ")", "\n", "print", "(", "'\\nFinished converting the Cifar10 dataset!'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.mnist.get_split": [[44, 99], ["os.path.join", "slim.tfexample_decoder.TFExampleDecoder", "datasets.dataset_utils.has_labels", "slim.dataset.Dataset", "ValueError", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "slim.tfexample_decoder.Image", "slim.tfexample_decoder.Tensor", "datasets.dataset_utils.read_label_file", "tensorflow.zeros"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.has_labels", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.read_label_file"], ["def", "get_split", "(", "split_name", ",", "dataset_dir", ",", "file_pattern", "=", "None", ",", "reader", "=", "None", ")", ":", "\n", "  ", "\"\"\"Gets a dataset tuple with instructions for reading MNIST.\n\n  Args:\n    split_name: A train/test split name.\n    dataset_dir: The base directory of the dataset sources.\n    file_pattern: The file pattern to use when matching the dataset sources.\n      It is assumed that the pattern contains a '%s' string so that the split\n      name can be inserted.\n    reader: The TensorFlow reader type.\n\n  Returns:\n    A `Dataset` namedtuple.\n\n  Raises:\n    ValueError: if `split_name` is not a valid train/test split.\n  \"\"\"", "\n", "if", "split_name", "not", "in", "_SPLITS_TO_SIZES", ":", "\n", "    ", "raise", "ValueError", "(", "'split name %s was not recognized.'", "%", "split_name", ")", "\n", "\n", "", "if", "not", "file_pattern", ":", "\n", "    ", "file_pattern", "=", "_FILE_PATTERN", "\n", "", "file_pattern", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "file_pattern", "%", "split_name", ")", "\n", "\n", "# Allowing None in the signature so that dataset_factory can use the default.", "\n", "if", "reader", "is", "None", ":", "\n", "    ", "reader", "=", "tf", ".", "TFRecordReader", "\n", "\n", "", "keys_to_features", "=", "{", "\n", "'image/encoded'", ":", "tf", ".", "FixedLenFeature", "(", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "''", ")", ",", "\n", "'image/format'", ":", "tf", ".", "FixedLenFeature", "(", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "'raw'", ")", ",", "\n", "'image/class/label'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "1", "]", ",", "tf", ".", "int64", ",", "default_value", "=", "tf", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "}", "\n", "\n", "items_to_handlers", "=", "{", "\n", "'image'", ":", "slim", ".", "tfexample_decoder", ".", "Image", "(", "shape", "=", "[", "28", ",", "28", ",", "1", "]", ",", "channels", "=", "1", ")", ",", "\n", "'label'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'image/class/label'", ",", "shape", "=", "[", "]", ")", ",", "\n", "}", "\n", "\n", "decoder", "=", "slim", ".", "tfexample_decoder", ".", "TFExampleDecoder", "(", "\n", "keys_to_features", ",", "items_to_handlers", ")", "\n", "\n", "labels_to_names", "=", "None", "\n", "if", "dataset_utils", ".", "has_labels", "(", "dataset_dir", ")", ":", "\n", "    ", "labels_to_names", "=", "dataset_utils", ".", "read_label_file", "(", "dataset_dir", ")", "\n", "\n", "", "return", "slim", ".", "dataset", ".", "Dataset", "(", "\n", "data_sources", "=", "file_pattern", ",", "\n", "reader", "=", "reader", ",", "\n", "decoder", "=", "decoder", ",", "\n", "num_samples", "=", "_SPLITS_TO_SIZES", "[", "split_name", "]", ",", "\n", "num_classes", "=", "_NUM_CLASSES", ",", "\n", "items_to_descriptions", "=", "_ITEMS_TO_DESCRIPTIONS", ",", "\n", "labels_to_names", "=", "labels_to_names", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.imagenet.create_readable_names_for_imagenet_labels": [[62, 116], ["six.moves.urllib.request.urlretrieve", "len", "six.moves.urllib.request.urlretrieve", "open().readlines", "len", "s.strip", "s.strip().split", "open().readlines", "open", "len", "s.strip", "open"], "function", ["None"], ["def", "create_readable_names_for_imagenet_labels", "(", ")", ":", "\n", "  ", "\"\"\"Create a dict mapping label id to human readable string.\n\n  Returns:\n      labels_to_names: dictionary where keys are integers from to 1000\n      and values are human-readable names.\n\n  We retrieve a synset file, which contains a list of valid synset labels used\n  by ILSVRC competition. There is one synset one per line, eg.\n          #   n01440764\n          #   n01443537\n  We also retrieve a synset_to_human_file, which contains a mapping from synsets\n  to human-readable names for every synset in Imagenet. These are stored in a\n  tsv format, as follows:\n          #   n02119247    black fox\n          #   n02119359    silver fox\n  We assign each synset (in alphabetical order) an integer, starting from 1\n  (since 0 is reserved for the background class).\n\n  Code is based on\n  https://github.com/tensorflow/models/blob/master/inception/inception/data/build_imagenet_data.py#L463\n  \"\"\"", "\n", "\n", "# pylint: disable=g-line-too-long", "\n", "base_url", "=", "'https://raw.githubusercontent.com/tensorflow/models/master/inception/inception/data/'", "\n", "synset_url", "=", "'{}/imagenet_lsvrc_2015_synsets.txt'", ".", "format", "(", "base_url", ")", "\n", "synset_to_human_url", "=", "'{}/imagenet_metadata.txt'", ".", "format", "(", "base_url", ")", "\n", "\n", "filename", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "synset_url", ")", "\n", "synset_list", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "open", "(", "filename", ")", ".", "readlines", "(", ")", "]", "\n", "num_synsets_in_ilsvrc", "=", "len", "(", "synset_list", ")", "\n", "assert", "num_synsets_in_ilsvrc", "==", "1000", "\n", "\n", "filename", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "synset_to_human_url", ")", "\n", "synset_to_human_list", "=", "open", "(", "filename", ")", ".", "readlines", "(", ")", "\n", "num_synsets_in_all_imagenet", "=", "len", "(", "synset_to_human_list", ")", "\n", "assert", "num_synsets_in_all_imagenet", "==", "21842", "\n", "\n", "synset_to_human", "=", "{", "}", "\n", "for", "s", "in", "synset_to_human_list", ":", "\n", "    ", "parts", "=", "s", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "assert", "len", "(", "parts", ")", "==", "2", "\n", "synset", "=", "parts", "[", "0", "]", "\n", "human", "=", "parts", "[", "1", "]", "\n", "synset_to_human", "[", "synset", "]", "=", "human", "\n", "\n", "", "label_index", "=", "1", "\n", "labels_to_names", "=", "{", "0", ":", "'background'", "}", "\n", "for", "synset", "in", "synset_list", ":", "\n", "    ", "name", "=", "synset_to_human", "[", "synset", "]", "\n", "labels_to_names", "[", "label_index", "]", "=", "name", "\n", "label_index", "+=", "1", "\n", "\n", "", "return", "labels_to_names", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.imagenet.get_split": [[118, 194], ["os.path.join", "slim.tfexample_decoder.TFExampleDecoder", "slim.datasets.dataset_utils.has_labels", "slim.dataset.Dataset", "ValueError", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "tensorflow.VarLenFeature", "slim.tfexample_decoder.Image", "slim.tfexample_decoder.Tensor", "slim.tfexample_decoder.Tensor", "slim.tfexample_decoder.BoundingBox", "slim.tfexample_decoder.Tensor", "slim.datasets.dataset_utils.read_label_file", "imagenet.create_readable_names_for_imagenet_labels", "slim.datasets.dataset_utils.write_label_file"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.has_labels", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.read_label_file", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.imagenet.create_readable_names_for_imagenet_labels", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.write_label_file"], ["", "def", "get_split", "(", "split_name", ",", "dataset_dir", ",", "file_pattern", "=", "None", ",", "reader", "=", "None", ")", ":", "\n", "  ", "\"\"\"Gets a dataset tuple with instructions for reading ImageNet.\n\n  Args:\n    split_name: A train/test split name.\n    dataset_dir: The base directory of the dataset sources.\n    file_pattern: The file pattern to use when matching the dataset sources.\n      It is assumed that the pattern contains a '%s' string so that the split\n      name can be inserted.\n    reader: The TensorFlow reader type.\n\n  Returns:\n    A `Dataset` namedtuple.\n\n  Raises:\n    ValueError: if `split_name` is not a valid train/test split.\n  \"\"\"", "\n", "if", "split_name", "not", "in", "_SPLITS_TO_SIZES", ":", "\n", "    ", "raise", "ValueError", "(", "'split name %s was not recognized.'", "%", "split_name", ")", "\n", "\n", "", "if", "not", "file_pattern", ":", "\n", "    ", "file_pattern", "=", "_FILE_PATTERN", "\n", "", "file_pattern", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "file_pattern", "%", "split_name", ")", "\n", "\n", "# Allowing None in the signature so that dataset_factory can use the default.", "\n", "if", "reader", "is", "None", ":", "\n", "    ", "reader", "=", "tf", ".", "TFRecordReader", "\n", "\n", "", "keys_to_features", "=", "{", "\n", "'image/encoded'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "''", ")", ",", "\n", "'image/format'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "'jpeg'", ")", ",", "\n", "'image/class/label'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ",", "default_value", "=", "-", "1", ")", ",", "\n", "'image/class/text'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "dtype", "=", "tf", ".", "string", ",", "default_value", "=", "''", ")", ",", "\n", "'image/object/bbox/xmin'", ":", "tf", ".", "VarLenFeature", "(", "\n", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "'image/object/bbox/ymin'", ":", "tf", ".", "VarLenFeature", "(", "\n", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "'image/object/bbox/xmax'", ":", "tf", ".", "VarLenFeature", "(", "\n", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "'image/object/bbox/ymax'", ":", "tf", ".", "VarLenFeature", "(", "\n", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "'image/object/class/label'", ":", "tf", ".", "VarLenFeature", "(", "\n", "dtype", "=", "tf", ".", "int64", ")", ",", "\n", "}", "\n", "\n", "items_to_handlers", "=", "{", "\n", "'image'", ":", "slim", ".", "tfexample_decoder", ".", "Image", "(", "'image/encoded'", ",", "'image/format'", ")", ",", "\n", "'label'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'image/class/label'", ")", ",", "\n", "'label_text'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'image/class/text'", ")", ",", "\n", "'object/bbox'", ":", "slim", ".", "tfexample_decoder", ".", "BoundingBox", "(", "\n", "[", "'ymin'", ",", "'xmin'", ",", "'ymax'", ",", "'xmax'", "]", ",", "'image/object/bbox/'", ")", ",", "\n", "'object/label'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'image/object/class/label'", ")", ",", "\n", "}", "\n", "\n", "decoder", "=", "slim", ".", "tfexample_decoder", ".", "TFExampleDecoder", "(", "\n", "keys_to_features", ",", "items_to_handlers", ")", "\n", "\n", "labels_to_names", "=", "None", "\n", "if", "dataset_utils", ".", "has_labels", "(", "dataset_dir", ")", ":", "\n", "    ", "labels_to_names", "=", "dataset_utils", ".", "read_label_file", "(", "dataset_dir", ")", "\n", "", "else", ":", "\n", "    ", "labels_to_names", "=", "create_readable_names_for_imagenet_labels", "(", ")", "\n", "dataset_utils", ".", "write_label_file", "(", "labels_to_names", ",", "dataset_dir", ")", "\n", "\n", "", "return", "slim", ".", "dataset", ".", "Dataset", "(", "\n", "data_sources", "=", "file_pattern", ",", "\n", "reader", "=", "reader", ",", "\n", "decoder", "=", "decoder", ",", "\n", "num_samples", "=", "_SPLITS_TO_SIZES", "[", "split_name", "]", ",", "\n", "items_to_descriptions", "=", "_ITEMS_TO_DESCRIPTIONS", ",", "\n", "num_classes", "=", "_NUM_CLASSES", ",", "\n", "labels_to_names", "=", "labels_to_names", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers.ImageReader.__init__": [[55, 59], ["tensorflow.placeholder", "tensorflow.image.decode_jpeg"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers.ImageReader.decode_jpeg"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Initializes function that decodes RGB JPEG data.", "\n", "    ", "self", ".", "_decode_jpeg_data", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "string", ")", "\n", "self", ".", "_decode_jpeg", "=", "tf", ".", "image", ".", "decode_jpeg", "(", "self", ".", "_decode_jpeg_data", ",", "channels", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers.ImageReader.read_image_dims": [[60, 63], ["download_and_convert_flowers.ImageReader.decode_jpeg"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers.ImageReader.decode_jpeg"], ["", "def", "read_image_dims", "(", "self", ",", "sess", ",", "image_data", ")", ":", "\n", "    ", "image", "=", "self", ".", "decode_jpeg", "(", "sess", ",", "image_data", ")", "\n", "return", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers.ImageReader.decode_jpeg": [[64, 70], ["sess.run", "len"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "decode_jpeg", "(", "self", ",", "sess", ",", "image_data", ")", ":", "\n", "    ", "image", "=", "sess", ".", "run", "(", "self", ".", "_decode_jpeg", ",", "\n", "feed_dict", "=", "{", "self", ".", "_decode_jpeg_data", ":", "image_data", "}", ")", "\n", "assert", "len", "(", "image", ".", "shape", ")", "==", "3", "\n", "assert", "image", ".", "shape", "[", "2", "]", "==", "3", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._get_filenames_and_classes": [[72, 99], ["os.path.join", "os.listdir", "os.path.join", "os.path.isdir", "os.listdir", "sorted", "directories.append", "class_names.append", "os.path.join", "photo_filenames.append"], "function", ["None"], ["", "", "def", "_get_filenames_and_classes", "(", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Returns a list of filenames and inferred class names.\n\n  Args:\n    dataset_dir: A directory containing a set of subdirectories representing\n      class names. Each subdirectory should contain PNG or JPG encoded images.\n\n  Returns:\n    A list of image file paths, relative to `dataset_dir` and the list of\n    subdirectories, representing class names.\n  \"\"\"", "\n", "flower_root", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'flower_photos'", ")", "\n", "directories", "=", "[", "]", "\n", "class_names", "=", "[", "]", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "flower_root", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "flower_root", ",", "filename", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "      ", "directories", ".", "append", "(", "path", ")", "\n", "class_names", ".", "append", "(", "filename", ")", "\n", "\n", "", "", "photo_filenames", "=", "[", "]", "\n", "for", "directory", "in", "directories", ":", "\n", "    ", "for", "filename", "in", "os", ".", "listdir", "(", "directory", ")", ":", "\n", "      ", "path", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "filename", ")", "\n", "photo_filenames", ".", "append", "(", "path", ")", "\n", "\n", "", "", "return", "photo_filenames", ",", "sorted", "(", "class_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._get_dataset_filename": [[101, 105], ["os.path.join"], "function", ["None"], ["", "def", "_get_dataset_filename", "(", "dataset_dir", ",", "split_name", ",", "shard_id", ")", ":", "\n", "  ", "output_filename", "=", "'flowers_%s_%05d-of-%05d.tfrecord'", "%", "(", "\n", "split_name", ",", "shard_id", ",", "_NUM_SHARDS", ")", "\n", "return", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "output_filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._convert_dataset": [[107, 151], ["int", "sys.stdout.write", "sys.stdout.flush", "math.ceil", "tensorflow.Graph().as_default", "download_and_convert_flowers.ImageReader", "tensorflow.Session", "range", "len", "float", "tensorflow.Graph", "download_and_convert_flowers._get_dataset_filename", "tensorflow.python_io.TFRecordWriter", "min", "range", "len", "sys.stdout.write", "sys.stdout.flush", "tensorflow.gfile.FastGFile().read", "download_and_convert_flowers.ImageReader.read_image_dims", "os.path.basename", "datasets.dataset_utils.image_to_tfexample", "tfrecord_writer.write", "os.path.dirname", "dataset_utils.image_to_tfexample.SerializeToString", "tensorflow.gfile.FastGFile", "len"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._get_dataset_filename", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers.ImageReader.read_image_dims", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.image_to_tfexample"], ["", "def", "_convert_dataset", "(", "split_name", ",", "filenames", ",", "class_names_to_ids", ",", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Converts the given filenames to a TFRecord dataset.\n\n  Args:\n    split_name: The name of the dataset, either 'train' or 'validation'.\n    filenames: A list of absolute paths to png or jpg images.\n    class_names_to_ids: A dictionary from class names (strings) to ids\n      (integers).\n    dataset_dir: The directory where the converted datasets are stored.\n  \"\"\"", "\n", "assert", "split_name", "in", "[", "'train'", ",", "'validation'", "]", "\n", "\n", "num_per_shard", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "filenames", ")", "/", "float", "(", "_NUM_SHARDS", ")", ")", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "    ", "image_reader", "=", "ImageReader", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", "''", ")", "as", "sess", ":", "\n", "\n", "      ", "for", "shard_id", "in", "range", "(", "_NUM_SHARDS", ")", ":", "\n", "        ", "output_filename", "=", "_get_dataset_filename", "(", "\n", "dataset_dir", ",", "split_name", ",", "shard_id", ")", "\n", "\n", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "output_filename", ")", "as", "tfrecord_writer", ":", "\n", "          ", "start_ndx", "=", "shard_id", "*", "num_per_shard", "\n", "end_ndx", "=", "min", "(", "(", "shard_id", "+", "1", ")", "*", "num_per_shard", ",", "len", "(", "filenames", ")", ")", "\n", "for", "i", "in", "range", "(", "start_ndx", ",", "end_ndx", ")", ":", "\n", "            ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Converting image %d/%d shard %d'", "%", "(", "\n", "i", "+", "1", ",", "len", "(", "filenames", ")", ",", "shard_id", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "# Read the filename:", "\n", "image_data", "=", "tf", ".", "gfile", ".", "FastGFile", "(", "filenames", "[", "i", "]", ",", "'rb'", ")", ".", "read", "(", ")", "\n", "height", ",", "width", "=", "image_reader", ".", "read_image_dims", "(", "sess", ",", "image_data", ")", "\n", "\n", "class_name", "=", "os", ".", "path", ".", "basename", "(", "os", ".", "path", ".", "dirname", "(", "filenames", "[", "i", "]", ")", ")", "\n", "class_id", "=", "class_names_to_ids", "[", "class_name", "]", "\n", "\n", "example", "=", "dataset_utils", ".", "image_to_tfexample", "(", "\n", "image_data", ",", "b'jpg'", ",", "height", ",", "width", ",", "class_id", ")", "\n", "tfrecord_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "\n", "", "", "", "", "", "sys", ".", "stdout", ".", "write", "(", "'\\n'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._clean_up_temporary_files": [[153, 165], ["os.path.join", "tensorflow.gfile.Remove", "os.path.join", "tensorflow.gfile.DeleteRecursively", "_DATA_URL.split"], "function", ["None"], ["", "def", "_clean_up_temporary_files", "(", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Removes temporary files used to create the dataset.\n\n  Args:\n    dataset_dir: The directory where the temporary files are stored.\n  \"\"\"", "\n", "filename", "=", "_DATA_URL", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "filename", ")", "\n", "tf", ".", "gfile", ".", "Remove", "(", "filepath", ")", "\n", "\n", "tmp_dir", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "'flower_photos'", ")", "\n", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "tmp_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._dataset_exists": [[167, 175], ["range", "download_and_convert_flowers._get_dataset_filename", "tensorflow.gfile.Exists"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._get_dataset_filename"], ["", "def", "_dataset_exists", "(", "dataset_dir", ")", ":", "\n", "  ", "for", "split_name", "in", "[", "'train'", ",", "'validation'", "]", ":", "\n", "    ", "for", "shard_id", "in", "range", "(", "_NUM_SHARDS", ")", ":", "\n", "      ", "output_filename", "=", "_get_dataset_filename", "(", "\n", "dataset_dir", ",", "split_name", ",", "shard_id", ")", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "output_filename", ")", ":", "\n", "        ", "return", "False", "\n", "", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers.run": [[177, 212], ["download_and_convert_flowers._dataset_exists", "datasets.dataset_utils.download_and_uncompress_tarball", "download_and_convert_flowers._get_filenames_and_classes", "dict", "random.seed", "random.shuffle", "download_and_convert_flowers._convert_dataset", "download_and_convert_flowers._convert_dataset", "dict", "datasets.dataset_utils.write_label_file", "download_and_convert_flowers._clean_up_temporary_files", "print", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "print", "zip", "zip", "range", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._dataset_exists", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.download_and_uncompress_tarball", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._get_filenames_and_classes", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._convert_dataset", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_flowers._convert_dataset", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.write_label_file", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._clean_up_temporary_files"], ["", "def", "run", "(", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Runs the download and conversion operation.\n\n  Args:\n    dataset_dir: The dataset directory where the dataset is stored.\n  \"\"\"", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "dataset_dir", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "dataset_dir", ")", "\n", "\n", "", "if", "_dataset_exists", "(", "dataset_dir", ")", ":", "\n", "    ", "print", "(", "'Dataset files already exist. Exiting without re-creating them.'", ")", "\n", "return", "\n", "\n", "", "dataset_utils", ".", "download_and_uncompress_tarball", "(", "_DATA_URL", ",", "dataset_dir", ")", "\n", "photo_filenames", ",", "class_names", "=", "_get_filenames_and_classes", "(", "dataset_dir", ")", "\n", "class_names_to_ids", "=", "dict", "(", "zip", "(", "class_names", ",", "range", "(", "len", "(", "class_names", ")", ")", ")", ")", "\n", "\n", "# Divide into train and test:", "\n", "random", ".", "seed", "(", "_RANDOM_SEED", ")", "\n", "random", ".", "shuffle", "(", "photo_filenames", ")", "\n", "training_filenames", "=", "photo_filenames", "[", "_NUM_VALIDATION", ":", "]", "\n", "validation_filenames", "=", "photo_filenames", "[", ":", "_NUM_VALIDATION", "]", "\n", "\n", "# First, convert the training and validation sets.", "\n", "_convert_dataset", "(", "'train'", ",", "training_filenames", ",", "class_names_to_ids", ",", "\n", "dataset_dir", ")", "\n", "_convert_dataset", "(", "'validation'", ",", "validation_filenames", ",", "class_names_to_ids", ",", "\n", "dataset_dir", ")", "\n", "\n", "# Finally, write the labels file:", "\n", "labels_to_class_names", "=", "dict", "(", "zip", "(", "range", "(", "len", "(", "class_names", ")", ")", ",", "class_names", ")", ")", "\n", "dataset_utils", ".", "write_label_file", "(", "labels_to_class_names", ",", "dataset_dir", ")", "\n", "\n", "_clean_up_temporary_files", "(", "dataset_dir", ")", "\n", "print", "(", "'\\nFinished converting the Flowers dataset!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.cifar10.get_split": [[44, 99], ["os.path.join", "slim.tfexample_decoder.TFExampleDecoder", "datasets.dataset_utils.has_labels", "slim.dataset.Dataset", "ValueError", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "slim.tfexample_decoder.Image", "slim.tfexample_decoder.Tensor", "datasets.dataset_utils.read_label_file", "tensorflow.zeros"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.has_labels", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.read_label_file"], ["def", "get_split", "(", "split_name", ",", "dataset_dir", ",", "file_pattern", "=", "None", ",", "reader", "=", "None", ")", ":", "\n", "  ", "\"\"\"Gets a dataset tuple with instructions for reading cifar10.\n\n  Args:\n    split_name: A train/test split name.\n    dataset_dir: The base directory of the dataset sources.\n    file_pattern: The file pattern to use when matching the dataset sources.\n      It is assumed that the pattern contains a '%s' string so that the split\n      name can be inserted.\n    reader: The TensorFlow reader type.\n\n  Returns:\n    A `Dataset` namedtuple.\n\n  Raises:\n    ValueError: if `split_name` is not a valid train/test split.\n  \"\"\"", "\n", "if", "split_name", "not", "in", "SPLITS_TO_SIZES", ":", "\n", "    ", "raise", "ValueError", "(", "'split name %s was not recognized.'", "%", "split_name", ")", "\n", "\n", "", "if", "not", "file_pattern", ":", "\n", "    ", "file_pattern", "=", "_FILE_PATTERN", "\n", "", "file_pattern", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "file_pattern", "%", "split_name", ")", "\n", "\n", "# Allowing None in the signature so that dataset_factory can use the default.", "\n", "if", "not", "reader", ":", "\n", "    ", "reader", "=", "tf", ".", "TFRecordReader", "\n", "\n", "", "keys_to_features", "=", "{", "\n", "'image/encoded'", ":", "tf", ".", "FixedLenFeature", "(", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "''", ")", ",", "\n", "'image/format'", ":", "tf", ".", "FixedLenFeature", "(", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "'png'", ")", ",", "\n", "'image/class/label'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "tf", ".", "int64", ",", "default_value", "=", "tf", ".", "zeros", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "}", "\n", "\n", "items_to_handlers", "=", "{", "\n", "'image'", ":", "slim", ".", "tfexample_decoder", ".", "Image", "(", "shape", "=", "[", "32", ",", "32", ",", "3", "]", ")", ",", "\n", "'label'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'image/class/label'", ")", ",", "\n", "}", "\n", "\n", "decoder", "=", "slim", ".", "tfexample_decoder", ".", "TFExampleDecoder", "(", "\n", "keys_to_features", ",", "items_to_handlers", ")", "\n", "\n", "labels_to_names", "=", "None", "\n", "if", "dataset_utils", ".", "has_labels", "(", "dataset_dir", ")", ":", "\n", "    ", "labels_to_names", "=", "dataset_utils", ".", "read_label_file", "(", "dataset_dir", ")", "\n", "\n", "", "return", "slim", ".", "dataset", ".", "Dataset", "(", "\n", "data_sources", "=", "file_pattern", ",", "\n", "reader", "=", "reader", ",", "\n", "decoder", "=", "decoder", ",", "\n", "num_samples", "=", "SPLITS_TO_SIZES", "[", "split_name", "]", ",", "\n", "items_to_descriptions", "=", "_ITEMS_TO_DESCRIPTIONS", ",", "\n", "num_classes", "=", "_NUM_CLASSES", ",", "\n", "labels_to_names", "=", "labels_to_names", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._extract_images": [[64, 82], ["print", "gzip.open", "bytestream.read", "bytestream.read", "numpy.frombuffer", "data.reshape.reshape"], "function", ["None"], ["def", "_extract_images", "(", "filename", ",", "num_images", ")", ":", "\n", "  ", "\"\"\"Extract the images into a numpy array.\n\n  Args:\n    filename: The path to an MNIST images file.\n    num_images: The number of images in the file.\n\n  Returns:\n    A numpy array of shape [number_of_images, height, width, channels].\n  \"\"\"", "\n", "print", "(", "'Extracting images from: '", ",", "filename", ")", "\n", "with", "gzip", ".", "open", "(", "filename", ")", "as", "bytestream", ":", "\n", "    ", "bytestream", ".", "read", "(", "16", ")", "\n", "buf", "=", "bytestream", ".", "read", "(", "\n", "_IMAGE_SIZE", "*", "_IMAGE_SIZE", "*", "num_images", "*", "_NUM_CHANNELS", ")", "\n", "data", "=", "np", ".", "frombuffer", "(", "buf", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "data", "=", "data", ".", "reshape", "(", "num_images", ",", "_IMAGE_SIZE", ",", "_IMAGE_SIZE", ",", "_NUM_CHANNELS", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._extract_labels": [[84, 100], ["print", "gzip.open", "bytestream.read", "bytestream.read", "numpy.frombuffer().astype", "numpy.frombuffer"], "function", ["None"], ["", "def", "_extract_labels", "(", "filename", ",", "num_labels", ")", ":", "\n", "  ", "\"\"\"Extract the labels into a vector of int64 label IDs.\n\n  Args:\n    filename: The path to an MNIST labels file.\n    num_labels: The number of labels in the file.\n\n  Returns:\n    A numpy array of shape [number_of_labels]\n  \"\"\"", "\n", "print", "(", "'Extracting labels from: '", ",", "filename", ")", "\n", "with", "gzip", ".", "open", "(", "filename", ")", "as", "bytestream", ":", "\n", "    ", "bytestream", ".", "read", "(", "8", ")", "\n", "buf", "=", "bytestream", ".", "read", "(", "1", "*", "num_labels", ")", "\n", "labels", "=", "np", ".", "frombuffer", "(", "buf", ",", "dtype", "=", "np", ".", "uint8", ")", ".", "astype", "(", "np", ".", "int64", ")", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._add_to_tfrecord": [[102, 130], ["download_and_convert_mnist._extract_images", "download_and_convert_mnist._extract_labels", "tensorflow.Graph().as_default", "tensorflow.placeholder", "tensorflow.image.encode_png", "tensorflow.Session", "range", "tensorflow.Graph", "sys.stdout.write", "sys.stdout.flush", "sess.run", "datasets.dataset_utils.image_to_tfexample", "tfrecord_writer.write", "dataset_utils.image_to_tfexample.SerializeToString"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._extract_images", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._extract_labels", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.image_to_tfexample"], ["", "def", "_add_to_tfrecord", "(", "data_filename", ",", "labels_filename", ",", "num_images", ",", "\n", "tfrecord_writer", ")", ":", "\n", "  ", "\"\"\"Loads data from the binary MNIST files and writes files to a TFRecord.\n\n  Args:\n    data_filename: The filename of the MNIST images.\n    labels_filename: The filename of the MNIST labels.\n    num_images: The number of images in the dataset.\n    tfrecord_writer: The TFRecord writer to use for writing.\n  \"\"\"", "\n", "images", "=", "_extract_images", "(", "data_filename", ",", "num_images", ")", "\n", "labels", "=", "_extract_labels", "(", "labels_filename", ",", "num_images", ")", "\n", "\n", "shape", "=", "(", "_IMAGE_SIZE", ",", "_IMAGE_SIZE", ",", "_NUM_CHANNELS", ")", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "    ", "image", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "uint8", ",", "shape", "=", "shape", ")", "\n", "encoded_png", "=", "tf", ".", "image", ".", "encode_png", "(", "image", ")", "\n", "\n", "with", "tf", ".", "Session", "(", "''", ")", "as", "sess", ":", "\n", "      ", "for", "j", "in", "range", "(", "num_images", ")", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Converting image %d/%d'", "%", "(", "j", "+", "1", ",", "num_images", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "png_string", "=", "sess", ".", "run", "(", "encoded_png", ",", "feed_dict", "=", "{", "image", ":", "images", "[", "j", "]", "}", ")", "\n", "\n", "example", "=", "dataset_utils", ".", "image_to_tfexample", "(", "\n", "png_string", ",", "'png'", ".", "encode", "(", ")", ",", "_IMAGE_SIZE", ",", "_IMAGE_SIZE", ",", "labels", "[", "j", "]", ")", "\n", "tfrecord_writer", ".", "write", "(", "example", ".", "SerializeToString", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._get_output_filename": [[132, 143], ["None"], "function", ["None"], ["", "", "", "", "def", "_get_output_filename", "(", "dataset_dir", ",", "split_name", ")", ":", "\n", "  ", "\"\"\"Creates the output filename.\n\n  Args:\n    dataset_dir: The directory where the temporary files are stored.\n    split_name: The name of the train/test split.\n\n  Returns:\n    An absolute file path.\n  \"\"\"", "\n", "return", "'%s/mnist_%s.tfrecord'", "%", "(", "dataset_dir", ",", "split_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._download_dataset": [[145, 170], ["os.path.join", "os.path.exists", "print", "six.moves.urllib.request.urlretrieve", "print", "print", "sys.stdout.write", "sys.stdout.flush", "tensorflow.gfile.GFile", "f.size", "float", "float"], "function", ["None"], ["", "def", "_download_dataset", "(", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Downloads MNIST locally.\n\n  Args:\n    dataset_dir: The directory where the temporary files are stored.\n  \"\"\"", "\n", "for", "filename", "in", "[", "_TRAIN_DATA_FILENAME", ",", "\n", "_TRAIN_LABELS_FILENAME", ",", "\n", "_TEST_DATA_FILENAME", ",", "\n", "_TEST_LABELS_FILENAME", "]", ":", "\n", "    ", "filepath", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "filename", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filepath", ")", ":", "\n", "      ", "print", "(", "'Downloading file %s...'", "%", "filename", ")", "\n", "def", "_progress", "(", "count", ",", "block_size", ",", "total_size", ")", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "'\\r>> Downloading %.1f%%'", "%", "(", "\n", "float", "(", "count", "*", "block_size", ")", "/", "float", "(", "total_size", ")", "*", "100.0", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "filepath", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "_DATA_URL", "+", "filename", ",", "\n", "filepath", ",", "\n", "_progress", ")", "\n", "print", "(", ")", "\n", "with", "tf", ".", "gfile", ".", "GFile", "(", "filepath", ")", "as", "f", ":", "\n", "        ", "size", "=", "f", ".", "size", "(", ")", "\n", "", "print", "(", "'Successfully downloaded'", ",", "filename", ",", "size", ",", "'bytes.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._clean_up_temporary_files": [[172, 184], ["os.path.join", "tensorflow.gfile.Remove"], "function", ["None"], ["", "", "", "def", "_clean_up_temporary_files", "(", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Removes temporary files used to create the dataset.\n\n  Args:\n    dataset_dir: The directory where the temporary files are stored.\n  \"\"\"", "\n", "for", "filename", "in", "[", "_TRAIN_DATA_FILENAME", ",", "\n", "_TRAIN_LABELS_FILENAME", ",", "\n", "_TEST_DATA_FILENAME", ",", "\n", "_TEST_LABELS_FILENAME", "]", ":", "\n", "    ", "filepath", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "filename", ")", "\n", "tf", ".", "gfile", ".", "Remove", "(", "filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run": [[186, 222], ["download_and_convert_mnist._get_output_filename", "download_and_convert_mnist._get_output_filename", "download_and_convert_mnist._download_dataset", "dict", "datasets.dataset_utils.write_label_file", "download_and_convert_mnist._clean_up_temporary_files", "print", "tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.Exists", "tensorflow.gfile.Exists", "print", "tensorflow.python_io.TFRecordWriter", "os.path.join", "os.path.join", "download_and_convert_mnist._add_to_tfrecord", "tensorflow.python_io.TFRecordWriter", "os.path.join", "os.path.join", "download_and_convert_mnist._add_to_tfrecord", "zip", "range", "len"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._get_output_filename", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._get_output_filename", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._download_dataset", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.write_label_file", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._clean_up_temporary_files", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._add_to_tfrecord", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist._add_to_tfrecord"], ["", "", "def", "run", "(", "dataset_dir", ")", ":", "\n", "  ", "\"\"\"Runs the download and conversion operation.\n\n  Args:\n    dataset_dir: The dataset directory where the dataset is stored.\n  \"\"\"", "\n", "if", "not", "tf", ".", "gfile", ".", "Exists", "(", "dataset_dir", ")", ":", "\n", "    ", "tf", ".", "gfile", ".", "MakeDirs", "(", "dataset_dir", ")", "\n", "\n", "", "training_filename", "=", "_get_output_filename", "(", "dataset_dir", ",", "'train'", ")", "\n", "testing_filename", "=", "_get_output_filename", "(", "dataset_dir", ",", "'test'", ")", "\n", "\n", "if", "tf", ".", "gfile", ".", "Exists", "(", "training_filename", ")", "and", "tf", ".", "gfile", ".", "Exists", "(", "testing_filename", ")", ":", "\n", "    ", "print", "(", "'Dataset files already exist. Exiting without re-creating them.'", ")", "\n", "return", "\n", "\n", "", "_download_dataset", "(", "dataset_dir", ")", "\n", "\n", "# First, process the training data:", "\n", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "training_filename", ")", "as", "tfrecord_writer", ":", "\n", "    ", "data_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "_TRAIN_DATA_FILENAME", ")", "\n", "labels_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "_TRAIN_LABELS_FILENAME", ")", "\n", "_add_to_tfrecord", "(", "data_filename", ",", "labels_filename", ",", "60000", ",", "tfrecord_writer", ")", "\n", "\n", "# Next, process the testing data:", "\n", "", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "testing_filename", ")", "as", "tfrecord_writer", ":", "\n", "    ", "data_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "_TEST_DATA_FILENAME", ")", "\n", "labels_filename", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "_TEST_LABELS_FILENAME", ")", "\n", "_add_to_tfrecord", "(", "data_filename", ",", "labels_filename", ",", "10000", ",", "tfrecord_writer", ")", "\n", "\n", "# Finally, write the labels file:", "\n", "", "labels_to_class_names", "=", "dict", "(", "zip", "(", "range", "(", "len", "(", "_CLASS_NAMES", ")", ")", ",", "_CLASS_NAMES", ")", ")", "\n", "dataset_utils", ".", "write_label_file", "(", "labels_to_class_names", ",", "dataset_dir", ")", "\n", "\n", "_clean_up_temporary_files", "(", "dataset_dir", ")", "\n", "print", "(", "'\\nFinished converting the MNIST dataset!'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_factory.get_dataset": [[34, 58], ["datasets_map[].get_split", "ValueError"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.flowers.get_split"], ["def", "get_dataset", "(", "name", ",", "split_name", ",", "dataset_dir", ",", "file_pattern", "=", "None", ",", "reader", "=", "None", ")", ":", "\n", "  ", "\"\"\"Given a dataset name and a split_name returns a Dataset.\n\n  Args:\n    name: String, the name of the dataset.\n    split_name: A train/test split name.\n    dataset_dir: The directory where the dataset files are stored.\n    file_pattern: The file pattern to use for matching the dataset source files.\n    reader: The subclass of tf.ReaderBase. If left as `None`, then the default\n      reader defined by each dataset is used.\n\n  Returns:\n    A `Dataset` class.\n\n  Raises:\n    ValueError: If the dataset `name` is unknown.\n  \"\"\"", "\n", "if", "name", "not", "in", "datasets_map", ":", "\n", "    ", "raise", "ValueError", "(", "'Name of dataset unknown %s'", "%", "name", ")", "\n", "", "return", "datasets_map", "[", "name", "]", ".", "get_split", "(", "\n", "split_name", ",", "\n", "dataset_dir", ",", "\n", "file_pattern", ",", "\n", "reader", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.flowers.get_split": [[44, 99], ["os.path.join", "slim.tfexample_decoder.TFExampleDecoder", "slim.datasets.dataset_utils.has_labels", "slim.dataset.Dataset", "ValueError", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "slim.tfexample_decoder.Image", "slim.tfexample_decoder.Tensor", "slim.datasets.dataset_utils.read_label_file", "tensorflow.zeros"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.has_labels", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_utils.read_label_file"], ["def", "get_split", "(", "split_name", ",", "dataset_dir", ",", "file_pattern", "=", "None", ",", "reader", "=", "None", ")", ":", "\n", "  ", "\"\"\"Gets a dataset tuple with instructions for reading flowers.\n\n  Args:\n    split_name: A train/validation split name.\n    dataset_dir: The base directory of the dataset sources.\n    file_pattern: The file pattern to use when matching the dataset sources.\n      It is assumed that the pattern contains a '%s' string so that the split\n      name can be inserted.\n    reader: The TensorFlow reader type.\n\n  Returns:\n    A `Dataset` namedtuple.\n\n  Raises:\n    ValueError: if `split_name` is not a valid train/validation split.\n  \"\"\"", "\n", "if", "split_name", "not", "in", "SPLITS_TO_SIZES", ":", "\n", "    ", "raise", "ValueError", "(", "'split name %s was not recognized.'", "%", "split_name", ")", "\n", "\n", "", "if", "not", "file_pattern", ":", "\n", "    ", "file_pattern", "=", "_FILE_PATTERN", "\n", "", "file_pattern", "=", "os", ".", "path", ".", "join", "(", "dataset_dir", ",", "file_pattern", "%", "split_name", ")", "\n", "\n", "# Allowing None in the signature so that dataset_factory can use the default.", "\n", "if", "reader", "is", "None", ":", "\n", "    ", "reader", "=", "tf", ".", "TFRecordReader", "\n", "\n", "", "keys_to_features", "=", "{", "\n", "'image/encoded'", ":", "tf", ".", "FixedLenFeature", "(", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "''", ")", ",", "\n", "'image/format'", ":", "tf", ".", "FixedLenFeature", "(", "(", ")", ",", "tf", ".", "string", ",", "default_value", "=", "'png'", ")", ",", "\n", "'image/class/label'", ":", "tf", ".", "FixedLenFeature", "(", "\n", "[", "]", ",", "tf", ".", "int64", ",", "default_value", "=", "tf", ".", "zeros", "(", "[", "]", ",", "dtype", "=", "tf", ".", "int64", ")", ")", ",", "\n", "}", "\n", "\n", "items_to_handlers", "=", "{", "\n", "'image'", ":", "slim", ".", "tfexample_decoder", ".", "Image", "(", ")", ",", "\n", "'label'", ":", "slim", ".", "tfexample_decoder", ".", "Tensor", "(", "'image/class/label'", ")", ",", "\n", "}", "\n", "\n", "decoder", "=", "slim", ".", "tfexample_decoder", ".", "TFExampleDecoder", "(", "\n", "keys_to_features", ",", "items_to_handlers", ")", "\n", "\n", "labels_to_names", "=", "None", "\n", "if", "dataset_utils", ".", "has_labels", "(", "dataset_dir", ")", ":", "\n", "    ", "labels_to_names", "=", "dataset_utils", ".", "read_label_file", "(", "dataset_dir", ")", "\n", "\n", "", "return", "slim", ".", "dataset", ".", "Dataset", "(", "\n", "data_sources", "=", "file_pattern", ",", "\n", "reader", "=", "reader", ",", "\n", "decoder", "=", "decoder", ",", "\n", "num_samples", "=", "SPLITS_TO_SIZES", "[", "split_name", "]", ",", "\n", "items_to_descriptions", "=", "_ITEMS_TO_DESCRIPTIONS", ",", "\n", "num_classes", "=", "_NUM_CLASSES", ",", "\n", "labels_to_names", "=", "labels_to_names", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_embedding.TextModel.__init__": [[38, 87], ["tensorflow.logging.set_verbosity", "tensorflow.Variable", "tensorflow.placeholder", "text_embedding.TextModel.learning_rate.assign", "datasets.convert_to_dataset.get_split_with_text", "image_model.im_model.load_batch_with_text", "text_model.text_preprocessing._load_embedding_weights_glove", "dict", "numpy.concatenate", "len", "tensorflow.get_variable", "tensorflow.get_variable", "zip", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.placeholder", "tensorflow.get_variable.assign", "tensorflow.nn.embedding_lookup", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.nn.dynamic_rnn", "tensorflow.gather_nd", "tensorflow.matmul", "range", "numpy.zeros", "tensorflow.stack", "tensorflow.range", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_to_dataset.get_split_with_text", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model.load_batch_with_text", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_glove"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "mode", "=", "config", "[", "'mode'", "]", "\n", "dataset_dir", "=", "config", "[", "'dataset_dir'", "]", "\n", "text_dir", "=", "config", "[", "'text_dir'", "]", "\n", "emb_dir", "=", "config", "[", "'emb_dir'", "]", "\n", "filename", "=", "config", "[", "'filename'", "]", "\n", "initial_lr", "=", "config", "[", "'initial_lr'", "]", "\n", "batch_size", "=", "config", "[", "'batch_size'", "]", "\n", "rnn_size", "=", "config", "[", "'rnn_size'", "]", "\n", "\n", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "self", ".", "learning_rate", "=", "tf", ".", "Variable", "(", "initial_lr", ",", "trainable", "=", "False", ")", "\n", "self", ".", "lr_rate_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "self", ".", "lr_rate_assign", "=", "self", ".", "learning_rate", ".", "assign", "(", "self", ".", "lr_rate_placeholder", ")", "\n", "\n", "self", ".", "dataset", "=", "get_split_with_text", "(", "mode", ",", "dataset_dir", ")", "\n", "image_size", "=", "inception_v1", ".", "default_image_size", "\n", "images", ",", "_", ",", "texts", ",", "seq_lens", ",", "self", ".", "labels", ",", "_", ",", "_", "=", "load_batch_with_text", "(", "self", ".", "dataset", ",", "batch_size", ",", "height", "=", "image_size", ",", "\n", "width", "=", "image_size", ")", "\n", "\n", "# Text model", "\n", "vocabulary", ",", "self", ".", "embedding", "=", "_load_embedding_weights_glove", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "vocab_size", ",", "embedding_dim", "=", "self", ".", "embedding", ".", "shape", "\n", "word_to_id", "=", "dict", "(", "zip", "(", "vocabulary", ",", "range", "(", "vocab_size", ")", ")", ")", "\n", "# Unknown words = vector with zeros", "\n", "self", ".", "embedding", "=", "np", ".", "concatenate", "(", "[", "self", ".", "embedding", ",", "np", ".", "zeros", "(", "(", "1", ",", "embedding_dim", ")", ")", "]", ")", "\n", "word_to_id", "[", "'<ukn>'", "]", "=", "vocab_size", "\n", "\n", "vocab_size", "=", "len", "(", "word_to_id", ")", "\n", "self", ".", "nb_emotions", "=", "self", ".", "dataset", ".", "num_classes", "\n", "with", "tf", ".", "variable_scope", "(", "'Text'", ")", ":", "\n", "# Word embedding", "\n", "            ", "W_embedding", "=", "tf", ".", "get_variable", "(", "'W_embedding'", ",", "[", "vocab_size", ",", "embedding_dim", "]", ",", "trainable", "=", "False", ")", "\n", "self", ".", "embedding_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "vocab_size", ",", "embedding_dim", "]", ")", "\n", "self", ".", "embedding_init", "=", "W_embedding", ".", "assign", "(", "self", ".", "embedding_placeholder", ")", "\n", "input_embed", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "W_embedding", ",", "texts", ")", "\n", "#input_embed_dropout = tf.nn.dropout(input_embed, self.keep_prob)", "\n", "\n", "# LSTM", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "rnn_size", ")", "\n", "rnn_outputs", ",", "final_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell", ",", "input_embed", ",", "sequence_length", "=", "seq_lens", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Need to convert seq_lens to int32 for stack", "\n", "texts_features", "=", "tf", ".", "gather_nd", "(", "rnn_outputs", ",", "tf", ".", "stack", "(", "[", "tf", ".", "range", "(", "batch_size", ")", ",", "tf", ".", "cast", "(", "seq_lens", ",", "tf", ".", "int32", ")", "-", "1", "]", ",", "axis", "=", "1", ")", ")", "\n", "\n", "", "W_softmax", "=", "tf", ".", "get_variable", "(", "'W_softmax'", ",", "[", "rnn_size", ",", "self", ".", "nb_emotions", "]", ")", "\n", "b_softmax", "=", "tf", ".", "get_variable", "(", "'b_softmax'", ",", "[", "self", ".", "nb_emotions", "]", ")", "\n", "self", ".", "logits", "=", "tf", ".", "matmul", "(", "texts_features", ",", "W_softmax", ")", "+", "b_softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_embedding._shuffling": [[27, 30], ["numpy.random.permutation"], "function", ["None"], ["def", "_shuffling", "(", "X", ",", "y", ")", ":", "\n", "    ", "p", "=", "np", ".", "random", ".", "permutation", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "return", "X", "[", "p", "]", ",", "y", "[", "p", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_embedding._shuffling_rnn": [[32, 35], ["numpy.random.permutation"], "function", ["None"], ["", "def", "_shuffling_rnn", "(", "X", ",", "seq_len", ",", "y", ")", ":", "\n", "    ", "p", "=", "np", ".", "random", ".", "permutation", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "return", "X", "[", "p", "]", ",", "seq_len", "[", "p", "]", ",", "y", "[", "p", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_embedding.train_text_model": [[89, 151], ["tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "print", "tensorflow.gfile.DeleteRecursively", "tensorflow.Graph().as_default", "text_embedding.TextModel", "tensorflow.contrib.slim.one_hot_encoding", "tensorflow.contrib.slim.losses.softmax_cross_entropy", "tensorflow.contrib.slim.losses.get_total_loss", "tensorflow.summary.scalar", "tensorflow.train.AdamOptimizer", "tensorflow.contrib.slim.learning.create_train_op", "tensorflow.contrib.slim.learning.train", "tensorflow.contrib.slim.python.slim.learning.train_step", "tensorflow.Graph", "session.run", "print", "session.run"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "train_text_model", "(", "train_dir", ",", "num_steps", ")", ":", "\n", "    ", "\"\"\"Train rnn text model.\n\n    Parameters:\n        checkpoints_dir: The directory contained the pre-trained model.\n        train_dir: The directory to save the trained model.\n        num_steps: The number of steps training the model.\n    \"\"\"", "\n", "if", "tf", ".", "gfile", ".", "Exists", "(", "train_dir", ")", ":", "\n", "# Delete old model", "\n", "        ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "tf", ".", "gfile", ".", "MakeDirs", "(", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "model", "=", "TextModel", "(", "_CONFIG", ")", "\n", "# Specify the loss function:", "\n", "one_hot_labels", "=", "slim", ".", "one_hot_encoding", "(", "model", ".", "labels", ",", "model", ".", "nb_emotions", ")", "\n", "slim", ".", "losses", ".", "softmax_cross_entropy", "(", "model", ".", "logits", ",", "one_hot_labels", ")", "\n", "total_loss", "=", "slim", ".", "losses", ".", "get_total_loss", "(", ")", "\n", "\n", "# Create some summaries to visualize the training process", "\n", "# Use tensorboard --logdir=train_dir, careful with path (add Documents/tumblr-sentiment in front of train_dir)", "\n", "# Different from the logs, because computed on different mini batch of data", "\n", "tf", ".", "summary", ".", "scalar", "(", "'Loss'", ",", "total_loss", ")", "\n", "\n", "# Specify the optimizer and create the train op:", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "model", ".", "learning_rate", ")", "\n", "train_op", "=", "slim", ".", "learning", ".", "create_train_op", "(", "total_loss", ",", "optimizer", ")", "\n", "\n", "batch_size", "=", "_CONFIG", "[", "'batch_size'", "]", "\n", "initial_lr", "=", "_CONFIG", "[", "'initial_lr'", "]", "\n", "decay_factor", "=", "_CONFIG", "[", "'decay_factor'", "]", "\n", "nb_batches", "=", "model", ".", "dataset", ".", "num_samples", "/", "batch_size", "\n", "def", "train_step_fn", "(", "session", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# Decaying learning rate every epoch", "\n", "            ", "if", "train_step_fn", ".", "step", "%", "(", "nb_batches", ")", "==", "0", ":", "\n", "                ", "lr_decay", "=", "decay_factor", "**", "train_step_fn", ".", "epoch", "\n", "session", ".", "run", "(", "model", ".", "lr_rate_assign", ",", "feed_dict", "=", "{", "model", ".", "lr_rate_placeholder", ":", "initial_lr", "*", "lr_decay", "}", ")", "\n", "print", "(", "'New learning rate: {0}'", ".", "format", "(", "initial_lr", "*", "lr_decay", ")", ")", "\n", "train_step_fn", ".", "epoch", "+=", "1", "\n", "\n", "# Initialise embedding weights", "\n", "", "if", "train_step_fn", ".", "step", "==", "0", ":", "\n", "                ", "session", ".", "run", "(", "model", ".", "embedding_init", ",", "feed_dict", "=", "{", "model", ".", "embedding_placeholder", ":", "model", ".", "embedding", "}", ")", "\n", "", "total_loss", ",", "should_stop", "=", "train_step", "(", "session", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "train_step_fn", ".", "step", "+=", "1", "\n", "return", "[", "total_loss", ",", "should_stop", "]", "\n", "\n", "", "train_step_fn", ".", "step", "=", "0", "\n", "train_step_fn", ".", "epoch", "=", "0", "\n", "\n", "# Run the training:", "\n", "final_loss", "=", "slim", ".", "learning", ".", "train", "(", "\n", "train_op", ",", "\n", "logdir", "=", "train_dir", ",", "\n", "save_interval_secs", "=", "600", ",", "\n", "save_summaries_secs", "=", "600", ",", "\n", "train_step_fn", "=", "train_step_fn", ",", "\n", "number_of_steps", "=", "num_steps", ")", "\n", "\n", "", "print", "(", "'Finished training. Last batch loss {0:.3f}'", ".", "format", "(", "final_loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_embedding.evaluate_text_model": [[152, 188], ["tensorflow.Graph().as_default", "text_embedding.TextModel", "tensorflow.contrib.slim.metrics.streaming_accuracy", "tensorflow.contrib.slim.metrics.aggregate_metric_map", "names_to_values.iteritems", "os.path.join", "tensorflow.contrib.slim.evaluation.evaluation_loop", "tensorflow.cast", "tensorflow.cast", "tensorflow.summary.scalar", "tensorflow.Graph", "tensorflow.argmax", "names_to_updates.values"], "function", ["None"], ["", "def", "evaluate_text_model", "(", "checkpoint_dir", ",", "log_dir", ",", "mode", ",", "num_evals", ")", ":", "\n", "    ", "\"\"\"Visualise results with: tensorboard --logdir=logdir. Now has train/validation curves on the same plot\n    \n    Parameters:\n        checkpoint_dir: Checkpoint of the saved model during training.\n        log_dir: Directory to save logs.\n        mode: train or validation.\n        num_evals: Number of batches to evaluate (mean of the batches is displayed).\n    \"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "_CONFIG", "[", "'mode'", "]", "=", "mode", "\n", "model", "=", "TextModel", "(", "_CONFIG", ")", "\n", "\n", "# Accuracy metrics", "\n", "accuracy", "=", "slim", ".", "metrics", ".", "streaming_accuracy", "(", "tf", ".", "cast", "(", "model", ".", "labels", ",", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "cast", "(", "tf", ".", "argmax", "(", "model", ".", "logits", ",", "1", ")", ",", "tf", ".", "int32", ")", ")", "\n", "\n", "# Choose the metrics to compute:", "\n", "names_to_values", ",", "names_to_updates", "=", "slim", ".", "metrics", ".", "aggregate_metric_map", "(", "{", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "}", ")", "\n", "\n", "for", "metric_name", ",", "metric_value", "in", "names_to_values", ".", "iteritems", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "metric_name", ",", "metric_value", ")", "\n", "\n", "", "log_dir", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "mode", ")", "\n", "\n", "# Evaluate every eval_interval_secs secs or if not specified,", "\n", "# every time the checkpoint_dir changes", "\n", "# tf.get_variable variables are also restored", "\n", "slim", ".", "evaluation", ".", "evaluation_loop", "(", "\n", "''", ",", "\n", "checkpoint_dir", ",", "\n", "log_dir", ",", "\n", "num_evals", "=", "num_evals", ",", "\n", "eval_op", "=", "names_to_updates", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_embedding.generate_chars": [[190, 203], ["first_char.copy", "sess.run", "range", "sess.run", "samples.append"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "generate_chars", "(", "sess", ",", "model", ",", "first_char", ",", "max_iteration", ")", ":", "\n", "    ", "ops", "=", "[", "model", ".", "final_state", ",", "model", ".", "sample", "]", "\n", "current_char", "=", "first_char", ".", "copy", "(", ")", "\n", "numpy_state", "=", "sess", ".", "run", "(", "model", ".", "initial_state", ")", "\n", "samples", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "max_iteration", ")", ":", "\n", "# Sample from the multinomial distribution of the next character", "\n", "        ", "numpy_state", ",", "sample", "=", "sess", ".", "run", "(", "ops", ",", "feed_dict", "=", "{", "model", ".", "input_data", ":", "current_char", ",", "\n", "model", ".", "initial_state", ":", "numpy_state", ",", "\n", "model", ".", "keep_prob", ":", "1.0", "}", ")", "\n", "samples", ".", "append", "(", "sample", "[", "0", "]", "[", "0", "]", ")", "\n", "current_char", "=", "sample", "\n", "", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_embedding.compute_sklearn_features": [[205, 272], ["text_model.text_preprocessing.preprocess_df", "numpy.stack", "tensorflow.reset_default_graph", "len", "len", "tensorflow.Session", "print", "tensorflow.random_uniform_initializer", "sess.run", "sess.run", "sess.run", "text_embedding._shuffling", "X[].reshape", "y[].reshape", "range", "numpy.vstack", "y[].reshape.reshape", "print", "word_to_id.iteritems", "tensorflow.variable_scope", "WordModel", "tensorflow.global_variables_initializer", "tensorflow.assign", "sess.run", "h1_list.append"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing.preprocess_df", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_embedding._shuffling", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "compute_sklearn_features", "(", ")", ":", "\n", "    ", "\"\"\"Compute mean word embedding features for sklearn models.\n    \"\"\"", "\n", "text_dir", "=", "'text_model'", "\n", "emb_dir", "=", "'embedding_weights'", "\n", "filename", "=", "'glove.6B.50d.txt'", "\n", "emb_name", "=", "'glove'", "\n", "emotions", "=", "[", "'happy'", ",", "'sad'", ",", "'angry'", ",", "'scared'", ",", "'disgusted'", ",", "'surprised'", "]", "\n", "post_size", "=", "200", "\n", "df_all", ",", "word_to_id", ",", "embedding", "=", "preprocess_df", "(", "text_dir", ",", "emb_dir", ",", "filename", ",", "emb_name", ",", "emotions", ",", "post_size", ")", "\n", "\n", "X", "=", "np", ".", "stack", "(", "df_all", "[", "'text_list'", "]", ")", "\n", "y", "=", "df_all", "[", "'search_query'", "]", ".", "values", "\n", "\n", "id_to_word", "=", "{", "i", ":", "k", "for", "k", ",", "i", "in", "word_to_id", ".", "iteritems", "(", ")", "}", "\n", "config", "=", "{", "'word_to_id'", ":", "word_to_id", ",", "\n", "'id_to_word'", ":", "id_to_word", ",", "\n", "'batch_size'", ":", "128", ",", "\n", "'vocab_size'", ":", "len", "(", "word_to_id", ")", ",", "\n", "'embedding_dim'", ":", "embedding", ".", "shape", "[", "1", "]", ",", "\n", "'post_size'", ":", "post_size", ",", "\n", "'fc1_size'", ":", "16", ",", "\n", "'nb_emotions'", ":", "len", "(", "emotions", ")", ",", "\n", "'dropout'", ":", "1.0", ",", "# Proba to keep neurons", "\n", "'max_grad_norm'", ":", "5.0", ",", "# Maximum norm of gradient", "\n", "'init_scale'", ":", "0.1", ",", "# Weights initialization scale", "\n", "'initial_lr'", ":", "1e-3", ",", "\n", "'lr_decay'", ":", "0.5", ",", "\n", "'max_epoch_no_decay'", ":", "2", ",", "# Number of epochs without decaying learning rate", "\n", "'nb_epochs'", ":", "10", "}", "# Maximum number of epochs", "\n", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "print", "(", "'Computing sklearn features:'", ")", "\n", "init_scale", "=", "config", "[", "'init_scale'", "]", "\n", "initializer", "=", "tf", ".", "random_uniform_initializer", "(", "-", "init_scale", ",", "init_scale", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Model'", ",", "reuse", "=", "None", ",", "initializer", "=", "initializer", ")", ":", "\n", "            ", "config", "[", "'nb_epochs'", "]", "=", "1", "\n", "m_train", "=", "WordModel", "(", "config", ")", "\n", "", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "m_train", ".", "embedding_init", ",", "feed_dict", "=", "{", "m_train", ".", "embedding_placeholder", ":", "embedding", "}", ")", "\n", "\n", "batch_size", "=", "m_train", ".", "config", "[", "'batch_size'", "]", "\n", "initial_lr", "=", "m_train", ".", "config", "[", "'initial_lr'", "]", "\n", "\n", "nb_batches", "=", "X", ".", "shape", "[", "0", "]", "/", "batch_size", "\n", "dropout_param", "=", "1.0", "\n", "ops", "=", "m_train", ".", "h1", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "assign", "(", "m_train", ".", "learning_rate", ",", "initial_lr", ")", ")", "\n", "\n", "X", ",", "y", "=", "_shuffling", "(", "X", ",", "y", ")", "\n", "X_reshaped", "=", "X", "[", ":", "(", "nb_batches", "*", "batch_size", ")", ",", ":", "]", ".", "reshape", "(", "(", "nb_batches", ",", "batch_size", ",", "-", "1", ")", ")", "\n", "y_reshaped", "=", "y", "[", ":", "(", "nb_batches", "*", "batch_size", ")", "]", ".", "reshape", "(", "(", "nb_batches", ",", "batch_size", ")", ")", "\n", "h1_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nb_batches", ")", ":", "\n", "            ", "curr_input", "=", "X_reshaped", "[", "i", ",", ":", ",", ":", "]", "\n", "curr_target", "=", "y_reshaped", "[", "i", ",", ":", "]", "\n", "h1_features", "=", "sess", ".", "run", "(", "ops", ",", "feed_dict", "=", "{", "m_train", ".", "input_data", ":", "curr_input", ",", "\n", "m_train", ".", "target", ":", "curr_target", ",", "\n", "m_train", ".", "keep_prob", ":", "dropout_param", "}", ")", "\n", "h1_list", ".", "append", "(", "h1_features", ")", "\n", "\n", "", "X_sklearn", "=", "np", ".", "vstack", "(", "h1_list", ")", "\n", "y_sklearn", "=", "y_reshaped", ".", "reshape", "(", "(", "-", "1", ")", ")", "\n", "print", "(", "'Finished'", ")", "\n", "return", "X_sklearn", ",", "y_sklearn", "", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_glove": [[13, 36], ["open", "f.readlines", "numpy.array", "print", "os.path.join", "line.strip().split", "vocabulary.append", "np.array.append", "line.strip", "numpy.float32"], "function", ["None"], ["def", "_load_embedding_weights_glove", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", ":", "\n", "    ", "\"\"\"Load the word embedding weights from a pre-trained model.\n    \n    Parameters:\n        text_dir: The directory containing the text model.\n        emb_dir: The subdirectory containing the weights.\n        filename: The name of that text file.\n        \n    Returns:\n        vocabulary: A list containing the words in the vocabulary.\n        embedding: A numpy array of the weights.\n    \"\"\"", "\n", "vocabulary", "=", "[", "]", "\n", "embedding", "=", "[", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "row", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "# Convert to unicode", "\n", "vocabulary", ".", "append", "(", "row", "[", "0", "]", ")", "\n", "embedding", ".", "append", "(", "[", "np", ".", "float32", "(", "x", ")", "for", "x", "in", "row", "[", "1", ":", "]", "]", ")", "\n", "", "embedding", "=", "np", ".", "array", "(", "embedding", ")", "\n", "print", "(", "'Finished loading word embedding weights.'", ")", "\n", "", "return", "vocabulary", ",", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_word2vec": [[37, 55], ["os.path.join", "gensim.models.KeyedVectors.load_word2vec_format", "print"], "function", ["None"], ["", "def", "_load_embedding_weights_word2vec", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", ":", "\n", "    ", "\"\"\"Load the word embedding weights from a pre-trained model.\n    \n    Parameters:\n        text_dir: The directory containing the text model.\n        emb_dir: The subdirectory containing the weights.\n        filename: The name of the binary file.\n        \n    Returns:\n        vocabulary: A list containing the words in the vocabulary.\n        embedding: A numpy array of the weights.\n    \"\"\"", "\n", "word2vec_dir", "=", "os", ".", "path", ".", "join", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "model", "=", "gensim", ".", "models", ".", "KeyedVectors", ".", "load_word2vec_format", "(", "word2vec_dir", ",", "binary", "=", "True", ")", "\n", "vocabulary", "=", "model", ".", "index2word", "\n", "embedding", "=", "model", ".", "syn0", "\n", "print", "(", "'Finished loading word embedding weights.'", ")", "\n", "return", "vocabulary", ",", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._str_list_to_set": [[56, 63], ["str_list[].split", "set", "x.strip"], "function", ["None"], ["", "def", "_str_list_to_set", "(", "str_list", ")", ":", "\n", "    ", "\"\"\"Convert a string representation of a list such as '[happy, sun, outdoors]'\n       to a set of strings {'happy', 'sun', 'outdoors'}\n    \"\"\"", "\n", "output", "=", "str_list", "[", "1", ":", "-", "1", "]", ".", "split", "(", "','", ")", "\n", "output", "=", "set", "(", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "output", "]", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._df_with_hashtag_in_post": [[64, 70], ["df[].map", "df[].map", "df.loc[].reset_index"], "function", ["None"], ["", "def", "_df_with_hashtag_in_post", "(", "df", ",", "tag", ")", ":", "\n", "    ", "\"\"\"Make sure that the relevant hashtag is in the post.\n    \"\"\"", "\n", "df", "[", "'tags'", "]", "=", "df", "[", "'tags'", "]", ".", "map", "(", "_str_list_to_set", ")", "\n", "mask", "=", "df", "[", "'tags'", "]", ".", "map", "(", "lambda", "x", ":", "tag", "in", "x", ")", "\n", "return", "df", ".", "loc", "[", "mask", ",", ":", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._is_valid_text": [[71, 83], ["numpy.isnan", "re.compile", "re.compile.sub().lower().split", "type", "len", "re.escape", "re.compile.sub().lower", "set().intersection", "re.compile.sub", "set"], "function", ["None"], ["", "def", "_is_valid_text", "(", "paragraph", ",", "vocab_set", ")", ":", "\n", "    ", "\"\"\"Check that a post contains atleast _MIN_ENGLISH_WORDS_IN_POST words in english.\n    \"\"\"", "\n", "# Check for nan text", "\n", "if", "(", "type", "(", "paragraph", ")", "==", "float", ")", "and", "(", "np", ".", "isnan", "(", "paragraph", ")", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "regex", "=", "re", ".", "compile", "(", "'[%s]'", "%", "re", ".", "escape", "(", "_PUNCTUATION", ")", ")", "\n", "# Remove punctuation, convert to lower case before splitting", "\n", "words", "=", "regex", ".", "sub", "(", "''", ",", "paragraph", ")", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "# Check if there are atleast _MIN_ENGLISH_WORDS_IN_POST words in english", "\n", "return", "len", "(", "set", "(", "words", ")", ".", "intersection", "(", "vocab_set", ")", ")", ">", "_MIN_ENGLISH_WORDS_IN_POST", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._paragraph_to_ids": [[84, 106], ["len", "re.compile", "re.compile.sub", "re.compile", "re.compile.sub().lower().split", "len", "emotion_regex.sub.lower", "word_to_id.get", "map", "re.escape", "re.compile.sub().lower", "re.compile.sub"], "function", ["None"], ["", "", "def", "_paragraph_to_ids", "(", "paragraph", ",", "word_to_id", ",", "post_size", ",", "emotions", ")", ":", "\n", "    ", "\"\"\"Convert a paragraph to a list of ids, removing the #emotion.\n    \"\"\"", "\n", "words", "=", "[", "]", "\n", "vocab_size", "=", "len", "(", "word_to_id", ")", "\n", "\n", "# Remove emotion hashtags from the post.", "\n", "emotion_regex", "=", "re", ".", "compile", "(", "'|'", ".", "join", "(", "map", "(", "re", ".", "escape", ",", "[", "'#'", "+", "emotion", "for", "emotion", "in", "emotions", "]", ")", ")", ")", "\n", "paragraph", "=", "emotion_regex", ".", "sub", "(", "''", ",", "paragraph", ".", "lower", "(", ")", ")", "\n", "\n", "regex", "=", "re", ".", "compile", "(", "'[%s]'", "%", "re", ".", "escape", "(", "_PUNCTUATION", ")", ")", "\n", "# Remove punctuation, convert to lower case before splitting", "\n", "words", "=", "regex", ".", "sub", "(", "''", ",", "paragraph", ")", ".", "lower", "(", ")", ".", "split", "(", ")", "\n", "# Replace unknown words by an id equal to the size of the vocab", "\n", "words", "=", "[", "word_to_id", ".", "get", "(", "x", ",", "vocab_size", ")", "for", "x", "in", "words", "]", "\n", "words_len", "=", "len", "(", "words", ")", "\n", "if", "words_len", ">", "post_size", ":", "\n", "        ", "words", "=", "words", "[", ":", "post_size", "]", "\n", "words_len", "=", "post_size", "\n", "", "else", ":", "\n", "        ", "words", "=", "words", "+", "[", "vocab_size", "]", "*", "(", "post_size", "-", "words_len", ")", "\n", "", "return", "words", ",", "words_len", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing.preprocess_df": [[107, 144], ["dict", "numpy.concatenate", "pandas.DataFrame", "set", "df_all[].map", "pd.concat().reset_index.loc[].reset_index", "zip", "dict", "df_all[].map", "print", "text_preprocessing._load_embedding_weights_word2vec", "text_preprocessing._load_embedding_weights_glove", "zip", "os.path.join", "text_preprocessing._df_with_hashtag_in_post", "pandas.concat().reset_index", "zip", "range", "numpy.zeros", "pandas.read_csv", "text_preprocessing._is_valid_text", "df_all[].map", "range", "pandas.concat", "len", "text_preprocessing._paragraph_to_ids"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_word2vec", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_glove", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._df_with_hashtag_in_post", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._is_valid_text", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._paragraph_to_ids"], ["", "def", "preprocess_df", "(", "text_dir", ",", "emb_dir", ",", "filename", ",", "emb_name", ",", "emotions", ",", "post_size", ")", ":", "\n", "    ", "\"\"\"Preprocess emotion dataframes.\n    \"\"\"", "\n", "if", "emb_name", "==", "'word2vec'", ":", "\n", "        ", "vocabulary", ",", "embedding", "=", "_load_embedding_weights_word2vec", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "", "else", ":", "\n", "        ", "vocabulary", ",", "embedding", "=", "_load_embedding_weights_glove", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "", "vocab_size", ",", "embedding_dim", "=", "embedding", ".", "shape", "\n", "word_to_id", "=", "dict", "(", "zip", "(", "vocabulary", ",", "range", "(", "vocab_size", ")", ")", ")", "\n", "# Unknown words = vector with zeros", "\n", "embedding", "=", "np", ".", "concatenate", "(", "[", "embedding", ",", "np", ".", "zeros", "(", "(", "1", ",", "embedding_dim", ")", ")", "]", ")", "\n", "\n", "columns", "=", "[", "'id'", ",", "'post_url'", ",", "'type'", ",", "'timestamp'", ",", "'date'", ",", "'tags'", ",", "'liked'", ",", "\n", "'note_count'", ",", "'photo'", ",", "'text'", ",", "'search_query'", "]", "\n", "df_all", "=", "pd", ".", "DataFrame", "(", "columns", "=", "columns", ")", "\n", "for", "emotion", "in", "emotions", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "'data'", ",", "emotion", "+", "'.csv'", ")", "\n", "df_emotion", "=", "_df_with_hashtag_in_post", "(", "pd", ".", "read_csv", "(", "path", ",", "encoding", "=", "'utf-8'", ")", ",", "emotion", ")", "\n", "df_all", "=", "pd", ".", "concat", "(", "[", "df_all", ",", "df_emotion", "]", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "", "vocab_set", "=", "set", "(", "vocabulary", ")", "\n", "mask", "=", "df_all", "[", "'text'", "]", ".", "map", "(", "lambda", "x", ":", "_is_valid_text", "(", "x", ",", "vocab_set", ")", ")", "\n", "df_all", "=", "df_all", ".", "loc", "[", "mask", ",", ":", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "# Map text to ids", "\n", "df_all", "[", "'text_list'", "]", ",", "df_all", "[", "'text_len'", "]", "=", "zip", "(", "*", "df_all", "[", "'text'", "]", ".", "map", "(", "lambda", "x", ":", "\n", "_paragraph_to_ids", "(", "x", ",", "word_to_id", ",", "post_size", ",", "emotions", ")", ")", ")", "\n", "\n", "# Binarise emotions", "\n", "emotion_dict", "=", "dict", "(", "zip", "(", "emotions", ",", "range", "(", "len", "(", "emotions", ")", ")", ")", ")", "\n", "df_all", "[", "'search_query'", "]", "=", "df_all", "[", "'search_query'", "]", ".", "map", "(", "emotion_dict", ")", "\n", "\n", "# Add <ukn> word to dictionary", "\n", "word_to_id", "[", "'<ukn>'", "]", "=", "vocab_size", "\n", "print", "(", "'Finished loading dataframes.'", ")", "\n", "\n", "return", "df_all", ",", "word_to_id", ",", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing.preprocess_one_df": [[145, 173], ["dict", "os.path.join", "text_preprocessing._df_with_hashtag_in_post", "set", "df_emotion[].map", "df_emotion.loc[].reset_index.loc[].reset_index", "zip", "zip", "pandas.read_csv", "range", "text_preprocessing._is_valid_text", "df_emotion[].map", "text_preprocessing._paragraph_to_ids"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._df_with_hashtag_in_post", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._is_valid_text", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._paragraph_to_ids"], ["", "def", "preprocess_one_df", "(", "vocabulary", ",", "embedding", ",", "emotion", ",", "post_size", ")", ":", "\n", "    ", "\"\"\"Preprocess one dataframe for the image/text model.\n    \"\"\"", "\n", "vocab_size", ",", "embedding_dim", "=", "embedding", ".", "shape", "\n", "word_to_id", "=", "dict", "(", "zip", "(", "vocabulary", ",", "range", "(", "vocab_size", ")", ")", ")", "\n", "# Unknown words = vector with zeros", "\n", "#embedding = np.concatenate([embedding, np.zeros((1, embedding_dim))])", "\n", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "'data'", ",", "emotion", "+", "'.csv'", ")", "\n", "df_emotion", "=", "_df_with_hashtag_in_post", "(", "pd", ".", "read_csv", "(", "path", ",", "encoding", "=", "'utf-8'", ")", ",", "emotion", ")", "\n", "\n", "vocab_set", "=", "set", "(", "vocabulary", ")", "\n", "mask", "=", "df_emotion", "[", "'text'", "]", ".", "map", "(", "lambda", "x", ":", "_is_valid_text", "(", "x", ",", "vocab_set", ")", ")", "\n", "df_emotion", "=", "df_emotion", ".", "loc", "[", "mask", ",", ":", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "emotions", "=", "[", "'happy'", ",", "'sad'", ",", "'angry'", ",", "'scared'", ",", "'disgusted'", ",", "'surprised'", "]", "\n", "# Map text to ids", "\n", "df_emotion", "[", "'text_list'", "]", ",", "df_emotion", "[", "'text_len'", "]", "=", "zip", "(", "*", "df_emotion", "[", "'text'", "]", ".", "map", "(", "lambda", "x", ":", "\n", "_paragraph_to_ids", "(", "x", ",", "word_to_id", ",", "post_size", ",", "emotions", ")", ")", ")", "\n", "\n", "# Binarise emotions", "\n", "#emotion_dict = dict(zip(emotions, range(len(emotions))))", "\n", "#df_all['search_query'] =  df_all['search_query'].map(emotion_dict)", "\n", "\n", "# Add <ukn> word to dictionary", "\n", "#word_to_id['<ukn>'] = vocab_size", "\n", "\n", "return", "df_emotion", "#, word_to_id, embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.DeepSentiment.__init__": [[39, 106], ["tensorflow.logging.set_verbosity", "tensorflow.Variable", "tensorflow.placeholder", "im_text_rnn_model.DeepSentiment.learning_rate.assign", "datasets.convert_to_dataset.get_split_with_text", "image_model.im_model.load_batch_with_text", "text_model.text_preprocessing._load_embedding_weights_glove", "dict", "numpy.concatenate", "len", "tensorflow.concat", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.contrib.slim.arg_scope", "image_model.inception_v1.inception_v1", "zip", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.placeholder", "tensorflow.get_variable.assign", "tensorflow.nn.embedding_lookup", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.nn.dynamic_rnn", "tensorflow.gather_nd", "tensorflow.matmul", "tensorflow.matmul", "image_model.inception_v1.inception_v1_arg_scope", "range", "numpy.zeros", "tensorflow.stack", "tensorflow.range", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.convert_to_dataset.get_split_with_text", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model.load_batch_with_text", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_glove", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "mode", "=", "config", "[", "'mode'", "]", "\n", "dataset_dir", "=", "config", "[", "'dataset_dir'", "]", "\n", "text_dir", "=", "config", "[", "'text_dir'", "]", "\n", "emb_dir", "=", "config", "[", "'emb_dir'", "]", "\n", "filename", "=", "config", "[", "'filename'", "]", "\n", "initial_lr", "=", "config", "[", "'initial_lr'", "]", "\n", "batch_size", "=", "config", "[", "'batch_size'", "]", "\n", "im_features_size", "=", "config", "[", "'im_features_size'", "]", "\n", "rnn_size", "=", "config", "[", "'rnn_size'", "]", "\n", "final_endpoint", "=", "config", "[", "'final_endpoint'", "]", "\n", "fc_size", "=", "config", "[", "'fc_size'", "]", "\n", "\n", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "self", ".", "learning_rate", "=", "tf", ".", "Variable", "(", "initial_lr", ",", "trainable", "=", "False", ")", "\n", "self", ".", "lr_rate_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "self", ".", "lr_rate_assign", "=", "self", ".", "learning_rate", ".", "assign", "(", "self", ".", "lr_rate_placeholder", ")", "\n", "\n", "self", ".", "dataset", "=", "get_split_with_text", "(", "mode", ",", "dataset_dir", ")", "\n", "image_size", "=", "inception_v1", ".", "default_image_size", "\n", "images", ",", "_", ",", "texts", ",", "seq_lens", ",", "self", ".", "labels", ",", "self", ".", "post_ids", ",", "self", ".", "days", "=", "load_batch_with_text", "(", "self", ".", "dataset", ",", "batch_size", ",", "\n", "height", "=", "image_size", ",", "width", "=", "image_size", ")", "\n", "\n", "# Create the model, use the default arg scope to configure the batch norm parameters.", "\n", "is_training", "=", "(", "mode", "==", "'train'", ")", "\n", "with", "slim", ".", "arg_scope", "(", "inception_v1", ".", "inception_v1_arg_scope", "(", ")", ")", ":", "\n", "            ", "images_features", ",", "_", "=", "inception_v1", ".", "inception_v1", "(", "images", ",", "final_endpoint", "=", "final_endpoint", ",", "\n", "num_classes", "=", "im_features_size", ",", "is_training", "=", "is_training", ")", "\n", "\n", "# Text model", "\n", "", "vocabulary", ",", "self", ".", "embedding", "=", "_load_embedding_weights_glove", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "vocab_size", ",", "embedding_dim", "=", "self", ".", "embedding", ".", "shape", "\n", "word_to_id", "=", "dict", "(", "zip", "(", "vocabulary", ",", "range", "(", "vocab_size", ")", ")", ")", "\n", "# Unknown words = vector with zeros", "\n", "self", ".", "embedding", "=", "np", ".", "concatenate", "(", "[", "self", ".", "embedding", ",", "np", ".", "zeros", "(", "(", "1", ",", "embedding_dim", ")", ")", "]", ")", "\n", "word_to_id", "[", "'<ukn>'", "]", "=", "vocab_size", "\n", "\n", "vocab_size", "=", "len", "(", "word_to_id", ")", "\n", "self", ".", "nb_emotions", "=", "self", ".", "dataset", ".", "num_classes", "\n", "with", "tf", ".", "variable_scope", "(", "'Text'", ")", ":", "\n", "# Word embedding", "\n", "            ", "W_embedding", "=", "tf", ".", "get_variable", "(", "'W_embedding'", ",", "[", "vocab_size", ",", "embedding_dim", "]", ",", "trainable", "=", "False", ")", "\n", "self", ".", "embedding_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "vocab_size", ",", "embedding_dim", "]", ")", "\n", "self", ".", "embedding_init", "=", "W_embedding", ".", "assign", "(", "self", ".", "embedding_placeholder", ")", "\n", "input_embed", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "W_embedding", ",", "texts", ")", "\n", "#input_embed_dropout = tf.nn.dropout(input_embed, self.keep_prob)", "\n", "\n", "# LSTM", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "rnn_size", ")", "\n", "rnn_outputs", ",", "final_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell", ",", "input_embed", ",", "sequence_length", "=", "seq_lens", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Need to convert seq_lens to int32 for stack", "\n", "texts_features", "=", "tf", ".", "gather_nd", "(", "rnn_outputs", ",", "tf", ".", "stack", "(", "[", "tf", ".", "range", "(", "batch_size", ")", ",", "tf", ".", "cast", "(", "seq_lens", ",", "tf", ".", "int32", ")", "-", "1", "]", ",", "axis", "=", "1", ")", ")", "\n", "\n", "# Concatenate image and text features", "\n", "", "self", ".", "concat_features", "=", "tf", ".", "concat", "(", "[", "images_features", ",", "texts_features", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# Dense layer", "\n", "W_fc", "=", "tf", ".", "get_variable", "(", "'W_fc'", ",", "[", "im_features_size", "+", "rnn_size", ",", "fc_size", "]", ")", "\n", "b_fc", "=", "tf", ".", "get_variable", "(", "'b_fc'", ",", "[", "fc_size", "]", ")", "\n", "dense_layer", "=", "tf", ".", "matmul", "(", "self", ".", "concat_features", ",", "W_fc", ")", "+", "b_fc", "\n", "dense_layer_relu", "=", "tf", ".", "nn", ".", "relu", "(", "dense_layer", ")", "\n", "\n", "W_softmax", "=", "tf", ".", "get_variable", "(", "'W_softmax'", ",", "[", "fc_size", ",", "self", ".", "nb_emotions", "]", ")", "\n", "b_softmax", "=", "tf", ".", "get_variable", "(", "'b_softmax'", ",", "[", "self", ".", "nb_emotions", "]", ")", "\n", "self", ".", "logits", "=", "tf", ".", "matmul", "(", "dense_layer_relu", ",", "W_softmax", ")", "+", "b_softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.train_deep_sentiment": [[107, 170], ["tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "print", "tensorflow.gfile.DeleteRecursively", "tensorflow.Graph().as_default", "im_text_rnn_model.DeepSentiment", "tensorflow.contrib.slim.one_hot_encoding", "tensorflow.contrib.slim.losses.softmax_cross_entropy", "tensorflow.contrib.slim.losses.get_total_loss", "tensorflow.summary.scalar", "tensorflow.train.AdamOptimizer", "tensorflow.contrib.slim.learning.create_train_op", "tensorflow.contrib.slim.learning.train", "tensorflow.contrib.slim.python.slim.learning.train_step", "tensorflow.Graph", "session.run", "print", "session.run", "image_model.im_model.get_init_fn"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_model.im_model.get_init_fn"], ["", "", "def", "train_deep_sentiment", "(", "checkpoints_dir", ",", "train_dir", ",", "num_steps", ")", ":", "\n", "    ", "\"\"\"Fine tune the inception model, retraining the last layer.\n\n    Parameters:\n        dataset_dir: The directory containing the data.\n        checkpoints_dir: The directory contained the pre-trained model.\n        train_dir: The directory to save the trained model.\n        num_steps: The number of steps training the model.\n    \"\"\"", "\n", "if", "tf", ".", "gfile", ".", "Exists", "(", "train_dir", ")", ":", "\n", "# Delete old model", "\n", "        ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "train_dir", ")", "\n", "", "tf", ".", "gfile", ".", "MakeDirs", "(", "train_dir", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "model", "=", "DeepSentiment", "(", "_CONFIG", ")", "\n", "# Specify the loss function:", "\n", "one_hot_labels", "=", "slim", ".", "one_hot_encoding", "(", "model", ".", "labels", ",", "model", ".", "nb_emotions", ")", "\n", "slim", ".", "losses", ".", "softmax_cross_entropy", "(", "model", ".", "logits", ",", "one_hot_labels", ")", "\n", "total_loss", "=", "slim", ".", "losses", ".", "get_total_loss", "(", ")", "\n", "\n", "# Create some summaries to visualize the training process", "\n", "# Use tensorboard --logdir=train_dir, careful with path (add Documents/tumblr-sentiment in front of train_dir)", "\n", "# Different from the logs, because computed on different mini batch of data", "\n", "tf", ".", "summary", ".", "scalar", "(", "'Loss'", ",", "total_loss", ")", "\n", "\n", "# Specify the optimizer and create the train op:", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "model", ".", "learning_rate", ")", "\n", "train_op", "=", "slim", ".", "learning", ".", "create_train_op", "(", "total_loss", ",", "optimizer", ")", "\n", "\n", "batch_size", "=", "_CONFIG", "[", "'batch_size'", "]", "\n", "initial_lr", "=", "_CONFIG", "[", "'initial_lr'", "]", "\n", "decay_factor", "=", "_CONFIG", "[", "'decay_factor'", "]", "\n", "nb_batches", "=", "model", ".", "dataset", ".", "num_samples", "/", "batch_size", "\n", "def", "train_step_fn", "(", "session", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# Decaying learning rate every epoch", "\n", "            ", "if", "train_step_fn", ".", "step", "%", "(", "nb_batches", ")", "==", "0", ":", "\n", "                ", "lr_decay", "=", "decay_factor", "**", "train_step_fn", ".", "epoch", "\n", "session", ".", "run", "(", "model", ".", "lr_rate_assign", ",", "feed_dict", "=", "{", "model", ".", "lr_rate_placeholder", ":", "initial_lr", "*", "lr_decay", "}", ")", "\n", "print", "(", "'New learning rate: {0}'", ".", "format", "(", "initial_lr", "*", "lr_decay", ")", ")", "\n", "train_step_fn", ".", "epoch", "+=", "1", "\n", "\n", "# Initialise embedding weights", "\n", "", "if", "train_step_fn", ".", "step", "==", "0", ":", "\n", "                ", "session", ".", "run", "(", "model", ".", "embedding_init", ",", "feed_dict", "=", "{", "model", ".", "embedding_placeholder", ":", "model", ".", "embedding", "}", ")", "\n", "", "total_loss", ",", "should_stop", "=", "train_step", "(", "session", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "train_step_fn", ".", "step", "+=", "1", "\n", "return", "[", "total_loss", ",", "should_stop", "]", "\n", "\n", "", "train_step_fn", ".", "step", "=", "0", "\n", "train_step_fn", ".", "epoch", "=", "0", "\n", "\n", "# Run the training:", "\n", "final_loss", "=", "slim", ".", "learning", ".", "train", "(", "\n", "train_op", ",", "\n", "logdir", "=", "train_dir", ",", "\n", "init_fn", "=", "get_init_fn", "(", "checkpoints_dir", ")", ",", "\n", "save_interval_secs", "=", "600", ",", "\n", "save_summaries_secs", "=", "600", ",", "\n", "train_step_fn", "=", "train_step_fn", ",", "\n", "number_of_steps", "=", "num_steps", ")", "\n", "\n", "", "print", "(", "'Finished training. Last batch loss {0:.3f}'", ".", "format", "(", "final_loss", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.evaluate_deep_sentiment": [[171, 208], ["tensorflow.Graph().as_default", "_CONFIG.copy", "im_text_rnn_model.DeepSentiment", "tensorflow.contrib.slim.metrics.streaming_accuracy", "tensorflow.contrib.slim.metrics.aggregate_metric_map", "names_to_values.iteritems", "os.path.join", "tensorflow.contrib.slim.evaluation.evaluation_loop", "tensorflow.cast", "tensorflow.cast", "tensorflow.summary.scalar", "tensorflow.Graph", "tensorflow.argmax", "names_to_updates.values"], "function", ["None"], ["", "def", "evaluate_deep_sentiment", "(", "checkpoint_dir", ",", "log_dir", ",", "mode", ",", "num_evals", ")", ":", "\n", "    ", "\"\"\"Visualise results with: tensorboard --logdir=logdir. Now has train/validation curves on the same plot\n    \n    Parameters:\n        checkpoint_dir: Checkpoint of the saved model during training.\n        log_dir: Directory to save logs.\n        mode: train or validation.\n        num_evals: Number of batches to evaluate (mean of the batches is displayed).\n    \"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "config", "=", "_CONFIG", ".", "copy", "(", ")", "\n", "config", "[", "'mode'", "]", "=", "mode", "\n", "model", "=", "DeepSentiment", "(", "config", ")", "\n", "\n", "# Accuracy metrics", "\n", "accuracy", "=", "slim", ".", "metrics", ".", "streaming_accuracy", "(", "tf", ".", "cast", "(", "model", ".", "labels", ",", "tf", ".", "int32", ")", ",", "\n", "tf", ".", "cast", "(", "tf", ".", "argmax", "(", "model", ".", "logits", ",", "1", ")", ",", "tf", ".", "int32", ")", ")", "\n", "\n", "# Choose the metrics to compute:", "\n", "names_to_values", ",", "names_to_updates", "=", "slim", ".", "metrics", ".", "aggregate_metric_map", "(", "{", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "}", ")", "\n", "\n", "for", "metric_name", ",", "metric_value", "in", "names_to_values", ".", "iteritems", "(", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "metric_name", ",", "metric_value", ")", "\n", "\n", "", "log_dir", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "mode", ")", "\n", "\n", "# Evaluate every eval_interval_secs secs or if not specified,", "\n", "# every time the checkpoint_dir changes", "\n", "# tf.get_variable variables are also restored", "\n", "slim", ".", "evaluation", ".", "evaluation_loop", "(", "\n", "''", ",", "\n", "checkpoint_dir", ",", "\n", "log_dir", ",", "\n", "num_evals", "=", "num_evals", ",", "\n", "eval_op", "=", "names_to_updates", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.deprocess_image": [[209, 211], ["None"], "function", ["None"], ["", "", "def", "deprocess_image", "(", "np_image", ")", ":", "\n", "    ", "return", "(", "np_image", "-", "0.5", ")", "/", "2.0", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.blur_image": [[212, 216], ["scipy.ndimage.filters.gaussian_filter1d", "scipy.ndimage.filters.gaussian_filter1d"], "function", ["None"], ["", "def", "blur_image", "(", "np_image", ",", "sigma", "=", "1", ")", ":", "\n", "    ", "np_image", "=", "gaussian_filter1d", "(", "np_image", ",", "sigma", ",", "axis", "=", "1", ")", "\n", "np_image", "=", "gaussian_filter1d", "(", "np_image", ",", "sigma", ",", "axis", "=", "2", ")", "\n", "return", "np_image", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.class_visualisation": [[217, 340], ["tensorflow.Graph().as_default", "tensorflow.logging.set_verbosity", "tensorflow.placeholder", "text_model.text_preprocessing._load_embedding_weights_glove", "dict", "tensorflow.constant", "numpy.concatenate", "len", "tensorflow.concat", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.random_normal", "slim.preprocessing.inception_preprocessing.preprocess_image", "tensorflow.expand_dims", "tensorflow.python.training.saver.latest_checkpoint", "tensorflow.python.training.monitored_session.Scaffold", "tensorflow.python.training.monitored_session.ChiefSessionCreator", "zip", "tensorflow.contrib.slim.arg_scope", "image_model.inception_v1.inception_v1", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.get_variable", "tf.get_variable.assign", "tensorflow.nn.embedding_lookup", "tensorflow.reduce_sum", "tensorflow.where", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.matmul", "tensorflow.square", "tensorflow.gradients", "tensorflow.norm", "tensorflow.python.training.monitored_session.MonitoredSession", "session.run", "range", "tensorflow.Graph", "range", "numpy.ones", "image_model.inception_v1.inception_v1_arg_scope", "numpy.zeros", "tensorflow.cast", "tensorflow.equal", "tensorflow.ones_like", "tensorflow.matmul", "tensorflow.norm", "numpy.random.randint", "numpy.roll", "session.run", "numpy.roll", "numpy.percentile", "tensorflow.not_equal", "tensorflow.reduce_mean", "numpy.roll", "numpy.roll", "im_text_rnn_model.blur_image", "matplotlib.imshow", "matplotlib.title", "matplotlib.gcf().set_size_inches", "matplotlib.axis", "matplotlib.show", "im_text_rnn_model.deprocess_image", "matplotlib.gcf"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_glove", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.lenet_preprocessing.preprocess_image", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.blur_image", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.deprocess_image"], ["", "def", "class_visualisation", "(", "label", ",", "learning_rate", ",", "checkpoint_dir", ")", ":", "\n", "    ", "\"\"\"Visualise class with gradient ascent.\n    \n    Parameters:\n        label: Label to visualise.\n        learning_rate: Learning rate of the gradient ascent.\n        checkpoint_dir: Checkpoint of the saved model during training.\n    \"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "image_size", "=", "inception_v1", ".", "default_image_size", "\n", "image", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "1", ",", "image_size", ",", "image_size", ",", "3", "]", ")", "\n", "\n", "# Text model", "\n", "text_dir", "=", "'text_model'", "\n", "emb_dir", "=", "'embedding_weights'", "\n", "filename", "=", "'glove.6B.50d.txt'", "\n", "vocabulary", ",", "embedding", "=", "_load_embedding_weights_glove", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "vocab_size", ",", "embedding_dim", "=", "embedding", ".", "shape", "\n", "word_to_id", "=", "dict", "(", "zip", "(", "vocabulary", ",", "range", "(", "vocab_size", ")", ")", ")", "\n", "\n", "# Create text with only unknown words", "\n", "text", "=", "tf", ".", "constant", "(", "np", ".", "ones", "(", "(", "1", ",", "_POST_SIZE", ")", ",", "dtype", "=", "np", ".", "int32", ")", "*", "vocab_size", ")", "\n", "\n", "im_features_size", "=", "128", "\n", "# Create the model, use the default arg scope to configure the batch norm parameters.", "\n", "with", "slim", ".", "arg_scope", "(", "inception_v1", ".", "inception_v1_arg_scope", "(", ")", ")", ":", "\n", "            ", "images_features", ",", "_", "=", "inception_v1", ".", "inception_v1", "(", "image", ",", "num_classes", "=", "im_features_size", ",", "is_training", "=", "True", ")", "\n", "\n", "# Unknown words = vector with zeros", "\n", "", "embedding", "=", "np", ".", "concatenate", "(", "[", "embedding", ",", "np", ".", "zeros", "(", "(", "1", ",", "embedding_dim", ")", ")", "]", ")", "\n", "word_to_id", "[", "'<ukn>'", "]", "=", "vocab_size", "\n", "\n", "vocab_size", "=", "len", "(", "word_to_id", ")", "\n", "nb_emotions", "=", "6", "\n", "with", "tf", ".", "variable_scope", "(", "'Text'", ")", ":", "\n", "            ", "embedding_placeholder", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "vocab_size", ",", "embedding_dim", "]", ")", "\n", "\n", "# Word embedding", "\n", "W_embedding", "=", "tf", ".", "get_variable", "(", "'W_embedding'", ",", "[", "vocab_size", ",", "embedding_dim", "]", ",", "trainable", "=", "False", ")", "\n", "embedding_init", "=", "W_embedding", ".", "assign", "(", "embedding_placeholder", ")", "\n", "input_embed", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "W_embedding", ",", "text", ")", "\n", "#input_embed_dropout = tf.nn.dropout(input_embed, self.keep_prob)", "\n", "\n", "# Rescale the mean by the actual number of non-zero values.", "\n", "nb_finite", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "tf", ".", "not_equal", "(", "input_embed", ",", "0.0", ")", ",", "tf", ".", "float32", ")", ",", "axis", "=", "1", ")", "\n", "# If a post has zero finite elements, replace nb_finite by 1", "\n", "nb_finite", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "nb_finite", ",", "0.0", ")", ",", "tf", ".", "ones_like", "(", "nb_finite", ")", ",", "nb_finite", ")", "\n", "h1", "=", "tf", ".", "reduce_mean", "(", "input_embed", ",", "axis", "=", "1", ")", "*", "_POST_SIZE", "/", "nb_finite", "\n", "\n", "fc1_size", "=", "2048", "\n", "# Fully connected layer", "\n", "W_fc1", "=", "tf", ".", "get_variable", "(", "'W_fc1'", ",", "[", "embedding_dim", ",", "fc1_size", "]", ")", "\n", "b_fc1", "=", "tf", ".", "get_variable", "(", "'b_fc1'", ",", "[", "fc1_size", "]", ")", "\n", "texts_features", "=", "tf", ".", "matmul", "(", "h1", ",", "W_fc1", ")", "+", "b_fc1", "\n", "texts_features", "=", "tf", ".", "nn", ".", "relu", "(", "texts_features", ")", "\n", "\n", "# Concatenate image and text features", "\n", "", "concat_features", "=", "tf", ".", "concat", "(", "[", "images_features", ",", "texts_features", "]", ",", "axis", "=", "1", ")", "\n", "\n", "W_softmax", "=", "tf", ".", "get_variable", "(", "'W_softmax'", ",", "[", "im_features_size", "+", "fc1_size", ",", "nb_emotions", "]", ")", "\n", "b_softmax", "=", "tf", ".", "get_variable", "(", "'b_softmax'", ",", "[", "nb_emotions", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "concat_features", ",", "W_softmax", ")", "+", "b_softmax", "\n", "\n", "class_score", "=", "logits", "[", ":", ",", "label", "]", "\n", "l2_reg", "=", "0.001", "\n", "regularisation", "=", "l2_reg", "*", "tf", ".", "square", "(", "tf", ".", "norm", "(", "image", ")", ")", "\n", "obj_function", "=", "class_score", "-", "regularisation", "\n", "grad_obj_function", "=", "tf", ".", "gradients", "(", "obj_function", ",", "image", ")", "[", "0", "]", "\n", "grad_normalized", "=", "grad_obj_function", "/", "tf", ".", "norm", "(", "grad_obj_function", ")", "\n", "\n", "# Initialise image", "\n", "image_init", "=", "tf", ".", "random_normal", "(", "[", "image_size", ",", "image_size", ",", "3", "]", ")", "\n", "image_init", "=", "inception_preprocessing", ".", "preprocess_image", "(", "image_init", ",", "image_size", ",", "image_size", ",", "is_training", "=", "False", ")", "\n", "image_init", "=", "tf", ".", "expand_dims", "(", "image_init", ",", "0", ")", "\n", "\n", "# Load model", "\n", "checkpoint_path", "=", "tf_saver", ".", "latest_checkpoint", "(", "checkpoint_dir", ")", "\n", "scaffold", "=", "monitored_session", ".", "Scaffold", "(", "\n", "init_op", "=", "None", ",", "init_feed_dict", "=", "None", ",", "\n", "init_fn", "=", "None", ",", "saver", "=", "None", ")", "\n", "session_creator", "=", "monitored_session", ".", "ChiefSessionCreator", "(", "\n", "scaffold", "=", "scaffold", ",", "\n", "checkpoint_filename_with_path", "=", "checkpoint_path", ",", "\n", "master", "=", "''", ",", "\n", "config", "=", "None", ")", "\n", "\n", "blur_every", "=", "10", "\n", "max_jitter", "=", "16", "\n", "show_every", "=", "50", "\n", "clip_percentile", "=", "20", "\n", "\n", "with", "monitored_session", ".", "MonitoredSession", "(", "\n", "session_creator", "=", "session_creator", ",", "hooks", "=", "None", ")", "as", "session", ":", "\n", "            ", "np_image", "=", "session", ".", "run", "(", "image_init", ")", "\n", "num_iterations", "=", "500", "\n", "for", "i", "in", "range", "(", "num_iterations", ")", ":", "\n", "# Randomly jitter the image a bit", "\n", "                ", "ox", ",", "oy", "=", "np", ".", "random", ".", "randint", "(", "-", "max_jitter", ",", "max_jitter", "+", "1", ",", "2", ")", "\n", "np_image", "=", "np", ".", "roll", "(", "np", ".", "roll", "(", "np_image", ",", "ox", ",", "1", ")", ",", "oy", ",", "2", ")", "\n", "\n", "# Update image", "\n", "grad_update", "=", "session", ".", "run", "(", "grad_normalized", ",", "feed_dict", "=", "{", "image", ":", "np_image", "}", ")", "\n", "np_image", "+=", "learning_rate", "*", "grad_update", "\n", "\n", "# Undo the jitter", "\n", "np_image", "=", "np", ".", "roll", "(", "np", ".", "roll", "(", "np_image", ",", "-", "ox", ",", "1", ")", ",", "-", "oy", ",", "2", ")", "\n", "\n", "# As a regularizer, clip and periodically blur", "\n", "#np_image = np.clip(np_image, -0.2, 0.8)", "\n", "# Set pixels with small norm to zero", "\n", "min_norm", "=", "np", ".", "percentile", "(", "np_image", ",", "clip_percentile", ")", "\n", "np_image", "[", "np_image", "<", "min_norm", "]", "=", "0.0", "\n", "if", "i", "%", "blur_every", "==", "0", ":", "\n", "                    ", "np_image", "=", "blur_image", "(", "np_image", ",", "sigma", "=", "0.5", ")", "\n", "\n", "", "if", "i", "%", "show_every", "==", "0", "or", "i", "==", "(", "num_iterations", "-", "1", ")", ":", "\n", "                    ", "plt", ".", "imshow", "(", "deprocess_image", "(", "np_image", "[", "0", "]", ")", ")", "\n", "plt", ".", "title", "(", "'Iteration %d / %d'", "%", "(", "i", "+", "1", ",", "num_iterations", ")", ")", "\n", "plt", ".", "gcf", "(", ")", ".", "set_size_inches", "(", "4", ",", "4", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.correlation_matrix": [[342, 377], ["numpy.save", "numpy.save", "tensorflow.Graph().as_default", "_CONFIG.copy", "im_text_rnn_model.DeepSentiment", "tensorflow.python.training.saver.latest_checkpoint", "tensorflow.python.training.monitored_session.Scaffold", "tensorflow.python.training.monitored_session.ChiefSessionCreator", "numpy.vstack", "numpy.hstack", "tensorflow.python.training.monitored_session.MonitoredSession", "range", "tensorflow.Graph", "session.run", "posts_logits.append", "posts_labels.append"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "", "", "", "def", "correlation_matrix", "(", "nb_batches", ",", "checkpoint_dir", ")", ":", "\n", "    ", "\"\"\"Computes logits and labels of the input posts and save them as numpy files.\n    \n    Parameters:\n        checkpoint_dir: Checkpoint of the saved model during training.\n    \"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "config", "=", "_CONFIG", ".", "copy", "(", ")", "\n", "config", "[", "'mode'", "]", "=", "'validation'", "\n", "model", "=", "DeepSentiment", "(", "config", ")", "\n", "\n", "# Load model", "\n", "checkpoint_path", "=", "tf_saver", ".", "latest_checkpoint", "(", "checkpoint_dir", ")", "\n", "scaffold", "=", "monitored_session", ".", "Scaffold", "(", "\n", "init_op", "=", "None", ",", "init_feed_dict", "=", "None", ",", "\n", "init_fn", "=", "None", ",", "saver", "=", "None", ")", "\n", "session_creator", "=", "monitored_session", ".", "ChiefSessionCreator", "(", "\n", "scaffold", "=", "scaffold", ",", "\n", "checkpoint_filename_with_path", "=", "checkpoint_path", ",", "\n", "master", "=", "''", ",", "\n", "config", "=", "None", ")", "\n", "\n", "posts_logits", "=", "[", "]", "\n", "posts_labels", "=", "[", "]", "\n", "with", "monitored_session", ".", "MonitoredSession", "(", "# Generate queue", "\n", "session_creator", "=", "session_creator", ",", "hooks", "=", "None", ")", "as", "session", ":", "\n", "            ", "for", "i", "in", "range", "(", "nb_batches", ")", ":", "\n", "                ", "np_logits", ",", "np_labels", "=", "session", ".", "run", "(", "[", "model", ".", "logits", ",", "model", ".", "labels", "]", ")", "\n", "posts_logits", ".", "append", "(", "np_logits", ")", "\n", "posts_labels", ".", "append", "(", "np_labels", ")", "\n", "\n", "", "", "", "posts_logits", ",", "posts_labels", "=", "np", ".", "vstack", "(", "posts_logits", ")", ",", "np", ".", "hstack", "(", "posts_labels", ")", "\n", "np", ".", "save", "(", "'data/posts_logits.npy'", ",", "posts_logits", ")", "\n", "np", ".", "save", "(", "'data/posts_labels.npy'", ",", "posts_labels", ")", "\n", "return", "posts_logits", ",", "posts_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.word_most_relevant": [[378, 476], ["numpy.vstack", "numpy.save", "numpy.save", "tensorflow.Graph().as_default", "_CONFIG.copy", "tensorflow.logging.set_verbosity", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "text_model.text_preprocessing._load_embedding_weights_glove", "dict", "numpy.concatenate", "len", "tensorflow.concat", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.python.training.saver.latest_checkpoint", "tensorflow.python.training.monitored_session.Scaffold", "tensorflow.python.training.monitored_session.ChiefSessionCreator", "tensorflow.contrib.slim.arg_scope", "image_model.inception_v1.inception_v1", "zip", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.nn.dynamic_rnn", "tensorflow.gather_nd", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.python.training.monitored_session.MonitoredSession", "range", "tensorflow.Graph", "image_model.inception_v1.inception_v1_arg_scope", "range", "numpy.zeros", "tensorflow.stack", "len", "numpy.zeros", "numpy.ones", "np.vstack.append", "numpy.ones", "session.run", "tensorflow.range", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_glove", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "word_most_relevant", "(", "top_words", ",", "num_classes", ",", "checkpoint_dir", ")", ":", "\n", "    ", "\"\"\"Compute gradient of W_embedding to get the word most relevant to a label.\n    \n    Parameters:\n        checkpoint_dir: Checkpoint of the saved model during training.\n    \"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "config", "=", "_CONFIG", ".", "copy", "(", ")", "\n", "mode", "=", "'validation'", "\n", "dataset_dir", "=", "config", "[", "'dataset_dir'", "]", "\n", "text_dir", "=", "config", "[", "'text_dir'", "]", "\n", "emb_dir", "=", "config", "[", "'emb_dir'", "]", "\n", "filename", "=", "config", "[", "'filename'", "]", "\n", "initial_lr", "=", "config", "[", "'initial_lr'", "]", "\n", "#batch_size = config['batch_size']", "\n", "im_features_size", "=", "config", "[", "'im_features_size'", "]", "\n", "rnn_size", "=", "config", "[", "'rnn_size'", "]", "\n", "final_endpoint", "=", "config", "[", "'final_endpoint'", "]", "\n", "\n", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "batch_size", "=", "50", "\n", "image_size", "=", "inception_v1", ".", "default_image_size", "\n", "images", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "batch_size", ",", "image_size", ",", "image_size", ",", "3", "]", ")", "\n", "texts", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "batch_size", ",", "_POST_SIZE", "]", ")", "\n", "seq_lens", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "batch_size", "]", ")", "\n", "\n", "# Create the model, use the default arg scope to configure the batch norm parameters.", "\n", "is_training", "=", "(", "mode", "==", "'train'", ")", "\n", "with", "slim", ".", "arg_scope", "(", "inception_v1", ".", "inception_v1_arg_scope", "(", ")", ")", ":", "\n", "            ", "images_features", ",", "_", "=", "inception_v1", ".", "inception_v1", "(", "images", ",", "final_endpoint", "=", "final_endpoint", ",", "\n", "num_classes", "=", "im_features_size", ",", "is_training", "=", "is_training", ")", "\n", "\n", "# Text model", "\n", "", "vocabulary", ",", "embedding", "=", "_load_embedding_weights_glove", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "vocab_size", ",", "embedding_dim", "=", "embedding", ".", "shape", "\n", "word_to_id", "=", "dict", "(", "zip", "(", "vocabulary", ",", "range", "(", "vocab_size", ")", ")", ")", "\n", "# Unknown words = vector with zeros", "\n", "embedding", "=", "np", ".", "concatenate", "(", "[", "embedding", ",", "np", ".", "zeros", "(", "(", "1", ",", "embedding_dim", ")", ")", "]", ")", "\n", "word_to_id", "[", "'<ukn>'", "]", "=", "vocab_size", "\n", "\n", "vocab_size", "=", "len", "(", "word_to_id", ")", "\n", "nb_emotions", "=", "num_classes", "\n", "with", "tf", ".", "variable_scope", "(", "'Text'", ")", ":", "\n", "# Word embedding", "\n", "            ", "W_embedding", "=", "tf", ".", "get_variable", "(", "'W_embedding'", ",", "[", "vocab_size", ",", "embedding_dim", "]", ",", "trainable", "=", "False", ")", "\n", "input_embed", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "W_embedding", ",", "texts", ")", "\n", "\n", "# LSTM", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "rnn_size", ")", "\n", "rnn_outputs", ",", "final_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell", ",", "input_embed", ",", "sequence_length", "=", "seq_lens", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Need to convert seq_lens to int32 for stack", "\n", "texts_features", "=", "tf", ".", "gather_nd", "(", "rnn_outputs", ",", "tf", ".", "stack", "(", "[", "tf", ".", "range", "(", "batch_size", ")", ",", "tf", ".", "cast", "(", "seq_lens", ",", "tf", ".", "int32", ")", "-", "1", "]", ",", "axis", "=", "1", ")", ")", "\n", "\n", "# Concatenate image and text features", "\n", "", "concat_features", "=", "tf", ".", "concat", "(", "[", "images_features", ",", "texts_features", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# Dense layer", "\n", "W_fc", "=", "tf", ".", "get_variable", "(", "'W_fc'", ",", "[", "im_features_size", "+", "rnn_size", ",", "fc_size", "]", ")", "\n", "b_fc", "=", "tf", ".", "get_variable", "(", "'b_fc'", ",", "[", "fc_size", "]", ")", "\n", "dense_layer", "=", "tf", ".", "matmul", "(", "concat_features", ",", "W_fc", ")", "+", "b_fc", "\n", "dense_layer_relu", "=", "tf", ".", "nn", ".", "relu", "(", "dense_layer", ")", "\n", "\n", "W_softmax", "=", "tf", ".", "get_variable", "(", "'W_softmax'", ",", "[", "fc_size", ",", "nb_emotions", "]", ")", "\n", "b_softmax", "=", "tf", ".", "get_variable", "(", "'b_softmax'", ",", "[", "nb_emotions", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "dense_layer_relu", ",", "W_softmax", ")", "+", "b_softmax", "\n", "\n", "# Initialise image", "\n", "#image_init = tf.random_normal([image_size, image_size, 3])", "\n", "#image_init = inception_preprocessing.preprocess_image(image_init, image_size, image_size, is_training=False)", "\n", "#image_init = tf.expand_dims(image_init, 0)", "\n", "\n", "# Load model", "\n", "checkpoint_path", "=", "tf_saver", ".", "latest_checkpoint", "(", "checkpoint_dir", ")", "\n", "scaffold", "=", "monitored_session", ".", "Scaffold", "(", "\n", "init_op", "=", "None", ",", "init_feed_dict", "=", "None", ",", "\n", "init_fn", "=", "None", ",", "saver", "=", "None", ")", "\n", "session_creator", "=", "monitored_session", ".", "ChiefSessionCreator", "(", "\n", "scaffold", "=", "scaffold", ",", "\n", "checkpoint_filename_with_path", "=", "checkpoint_path", ",", "\n", "master", "=", "''", ",", "\n", "config", "=", "None", ")", "\n", "\n", "with", "monitored_session", ".", "MonitoredSession", "(", "\n", "session_creator", "=", "session_creator", ",", "hooks", "=", "None", ")", "as", "session", ":", "\n", "\n", "            ", "nb_iter", "=", "len", "(", "top_words", ")", "/", "batch_size", "\n", "scores", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nb_iter", ")", ":", "\n", "                ", "np_images", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "image_size", ",", "image_size", ",", "3", ")", ")", "\n", "np_texts", "=", "np", ".", "ones", "(", "(", "batch_size", ",", "_POST_SIZE", ")", ",", "dtype", "=", "np", ".", "int32", ")", "*", "(", "vocab_size", "-", "1", ")", "\n", "np_texts", "[", ":", ",", "0", "]", "=", "top_words", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", "\n", "np_seq_lens", "=", "np", ".", "ones", "(", "batch_size", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "scores", ".", "append", "(", "session", ".", "run", "(", "logits", ",", "feed_dict", "=", "{", "images", ":", "np_images", ",", "texts", ":", "np_texts", ",", "seq_lens", ":", "np_seq_lens", "}", ")", ")", "\n", "", "", "", "scores", "=", "np", ".", "vstack", "(", "scores", ")", "\n", "np", ".", "save", "(", "'data/top_words_scores.npy'", ",", "scores", ")", "\n", "np", ".", "save", "(", "'data/top_words.npy'", ",", "top_words", ")", "\n", "return", "scores", ",", "vocabulary", ",", "word_to_id", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.outliers_detection": [[478, 530], ["numpy.save", "numpy.save", "numpy.save", "tensorflow.Graph().as_default", "_CONFIG.copy", "im_text_rnn_model.DeepSentiment", "tensorflow.python.training.saver.latest_checkpoint", "tensorflow.python.training.monitored_session.Scaffold", "tensorflow.python.training.monitored_session.ChiefSessionCreator", "numpy.zeros", "tensorflow.python.training.monitored_session.MonitoredSession", "range", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "tensorflow.Graph", "session.run", "session.run", "numpy.linalg.norm", "range", "float", "session.run.mean"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "outliers_detection", "(", "checkpoint_dir", ")", ":", "\n", "    ", "\"\"\"Find outliers using Euclidean distance in the last dense layer.\n    \n    Parameters:\n        checkpoint_dir: Checkpoint of the saved model during training.\n    \"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "config", "=", "_CONFIG", ".", "copy", "(", ")", "\n", "config", "[", "'mode'", "]", "=", "'validation'", "\n", "model", "=", "DeepSentiment", "(", "config", ")", "\n", "\n", "# Load model", "\n", "checkpoint_path", "=", "tf_saver", ".", "latest_checkpoint", "(", "checkpoint_dir", ")", "\n", "scaffold", "=", "monitored_session", ".", "Scaffold", "(", "\n", "init_op", "=", "None", ",", "init_feed_dict", "=", "None", ",", "\n", "init_fn", "=", "None", ",", "saver", "=", "None", ")", "\n", "session_creator", "=", "monitored_session", ".", "ChiefSessionCreator", "(", "\n", "scaffold", "=", "scaffold", ",", "\n", "checkpoint_filename_with_path", "=", "checkpoint_path", ",", "\n", "master", "=", "''", ",", "\n", "config", "=", "None", ")", "\n", "\n", "im_features_size", "=", "config", "[", "'im_features_size'", "]", "\n", "rnn_size", "=", "config", "[", "'rnn_size'", "]", "\n", "dense_mean", "=", "np", ".", "zeros", "(", "(", "im_features_size", "+", "rnn_size", ")", ")", "\n", "with", "monitored_session", ".", "MonitoredSession", "(", "# Generate queue", "\n", "session_creator", "=", "session_creator", ",", "hooks", "=", "None", ")", "as", "session", ":", "\n", "            ", "batch_size", "=", "config", "[", "'batch_size'", "]", "\n", "nb_batches", "=", "model", ".", "dataset", ".", "num_samples", "/", "batch_size", "\n", "for", "i", "in", "range", "(", "nb_batches", ")", ":", "\n", "                ", "current_dense", "=", "session", ".", "run", "(", "model", ".", "concat_features", ")", "\n", "weight", "=", "float", "(", "i", ")", "*", "batch_size", "/", "(", "(", "i", "+", "1", ")", "*", "batch_size", ")", "\n", "dense_mean", "=", "weight", "*", "dense_mean", "+", "(", "1", "-", "weight", ")", "*", "current_dense", ".", "mean", "(", "axis", "=", "0", ")", "\n", "\n", "# Now look at outliers", "\n", "", "max_norms", "=", "np", ".", "zeros", "(", "(", "batch_size", ")", ")", "\n", "max_post_ids", "=", "np", ".", "zeros", "(", "(", "batch_size", ")", ")", "\n", "max_logits", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "model", ".", "dataset", ".", "num_classes", ")", ")", "\n", "for", "i", "in", "range", "(", "nb_batches", ")", ":", "\n", "                ", "current_dense", ",", "np_post_ids", ",", "current_logits", "=", "session", ".", "run", "(", "[", "model", ".", "concat_features", ",", "model", ".", "post_ids", ",", "\n", "model", ".", "logits", "]", ")", "\n", "current_diff", "=", "np", ".", "linalg", ".", "norm", "(", "current_dense", "-", "dense_mean", ",", "axis", "=", "1", ")", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "if", "current_diff", "[", "k", "]", ">", "max_norms", "[", "k", "]", ":", "\n", "                        ", "max_norms", "[", "k", "]", "=", "current_diff", "[", "k", "]", "\n", "max_post_ids", "[", "k", "]", "=", "np_post_ids", "[", "k", "]", "\n", "max_logits", "[", "k", "]", "=", "current_logits", "[", "k", "]", "\n", "\n", "", "", "", "", "", "np", ".", "save", "(", "'data/max_norms.npy'", ",", "max_norms", ")", "\n", "np", ".", "save", "(", "'data/max_post_ids.npy'", ",", "max_post_ids", ")", "\n", "np", ".", "save", "(", "'data/max_logits.npy'", ",", "max_logits", ")", "\n", "return", "max_norms", ",", "max_post_ids", ",", "max_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.day_of_week_trend": [[531, 576], ["numpy.save", "numpy.save", "numpy.save", "numpy.save", "tensorflow.Graph().as_default", "_CONFIG.copy", "im_text_rnn_model.DeepSentiment", "tensorflow.python.training.saver.latest_checkpoint", "tensorflow.python.training.monitored_session.Scaffold", "tensorflow.python.training.monitored_session.ChiefSessionCreator", "numpy.vstack", "numpy.hstack", "numpy.hstack", "numpy.hstack", "tensorflow.python.training.monitored_session.MonitoredSession", "range", "tensorflow.Graph", "session.run", "posts_logits.append", "posts_labels.append", "posts_days.append", "posts_ids.append"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "day_of_week_trend", "(", "checkpoint_dir", ")", ":", "\n", "    ", "\"\"\"Compute day of week trend.\n    \n    Parameters:\n        checkpoint_dir: Checkpoint of the saved model during training.\n    \"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "config", "=", "_CONFIG", ".", "copy", "(", ")", "\n", "config", "[", "'mode'", "]", "=", "'validation'", "\n", "model", "=", "DeepSentiment", "(", "config", ")", "\n", "\n", "# Load model", "\n", "checkpoint_path", "=", "tf_saver", ".", "latest_checkpoint", "(", "checkpoint_dir", ")", "\n", "scaffold", "=", "monitored_session", ".", "Scaffold", "(", "\n", "init_op", "=", "None", ",", "init_feed_dict", "=", "None", ",", "\n", "init_fn", "=", "None", ",", "saver", "=", "None", ")", "\n", "session_creator", "=", "monitored_session", ".", "ChiefSessionCreator", "(", "\n", "scaffold", "=", "scaffold", ",", "\n", "checkpoint_filename_with_path", "=", "checkpoint_path", ",", "\n", "master", "=", "''", ",", "\n", "config", "=", "None", ")", "\n", "\n", "posts_logits", "=", "[", "]", "\n", "posts_labels", "=", "[", "]", "\n", "posts_days", "=", "[", "]", "\n", "posts_ids", "=", "[", "]", "\n", "with", "monitored_session", ".", "MonitoredSession", "(", "# Generate queue", "\n", "session_creator", "=", "session_creator", ",", "hooks", "=", "None", ")", "as", "session", ":", "\n", "            ", "batch_size", "=", "config", "[", "'batch_size'", "]", "\n", "nb_batches", "=", "model", ".", "dataset", ".", "num_samples", "/", "batch_size", "\n", "for", "i", "in", "range", "(", "nb_batches", ")", ":", "\n", "                ", "np_logits", ",", "np_labels", ",", "np_days", ",", "np_post_ids", "=", "session", ".", "run", "(", "[", "model", ".", "logits", ",", "model", ".", "labels", ",", "\n", "model", ".", "days", ",", "model", ".", "post_ids", "]", ")", "\n", "posts_logits", ".", "append", "(", "np_logits", ")", "\n", "posts_labels", ".", "append", "(", "np_labels", ")", "\n", "posts_days", ".", "append", "(", "np_days", ")", "\n", "posts_ids", ".", "append", "(", "np_post_ids", ")", "\n", "\n", "", "", "", "posts_logits", ",", "posts_labels", "=", "np", ".", "vstack", "(", "posts_logits", ")", ",", "np", ".", "hstack", "(", "posts_labels", ")", "\n", "posts_days", ",", "posts_ids", "=", "np", ".", "hstack", "(", "posts_days", ")", ",", "np", ".", "hstack", "(", "posts_ids", ")", "\n", "np", ".", "save", "(", "'data/posts_logits_week.npy'", ",", "posts_logits", ")", "\n", "np", ".", "save", "(", "'data/posts_labels_week.npy'", ",", "posts_labels", ")", "\n", "np", ".", "save", "(", "'data/posts_days_week.npy'", ",", "posts_days", ")", "\n", "np", ".", "save", "(", "'data/posts_ids_week.npy'", ",", "posts_ids", ")", "\n", "return", "posts_logits", ",", "posts_labels", ",", "posts_days", ",", "posts_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.image_text_model.im_text_rnn_model.oasis_evaluation": [[577, 695], ["numpy.vstack", "numpy.save", "tensorflow.Graph().as_default", "_CONFIG.copy", "tensorflow.logging.set_verbosity", "tensorflow.placeholder", "slim.preprocessing.inception_preprocessing.preprocess_image", "tensorflow.expand_dims", "tensorflow.placeholder", "tensorflow.placeholder", "text_model.text_preprocessing._load_embedding_weights_glove", "dict", "numpy.concatenate", "len", "tensorflow.concat", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.python.training.saver.latest_checkpoint", "tensorflow.python.training.monitored_session.Scaffold", "tensorflow.python.training.monitored_session.ChiefSessionCreator", "pandas.read_csv", "df_oasis[].map", "df_oasis[].map", "text_model.text_preprocessing._load_embedding_weights_glove", "dict", "zip", "tensorflow.contrib.slim.arg_scope", "image_model.inception_v1.inception_v1", "zip", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.nn.dynamic_rnn", "tensorflow.gather_nd", "tensorflow.matmul", "tensorflow.matmul", "scipy.misc.imread", "zip", "tensorflow.python.training.monitored_session.MonitoredSession", "range", "tensorflow.Graph", "image_model.inception_v1.inception_v1_arg_scope", "range", "numpy.zeros", "tensorflow.stack", "scipy.misc.imresize", "im_text_rnn_model.oasis_evaluation.load_image"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.lenet_preprocessing.preprocess_image", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_glove", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.text_model.text_preprocessing._load_embedding_weights_glove", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1"], ["", "def", "oasis_evaluation", "(", "checkpoint_dir", ",", "num_classes", ")", ":", "\n", "    ", "\"\"\"Compute the logits of the OASIS dataset.\n    \n    Parameters:\n        checkpoint_dir: Checkpoint of the saved model during training.\n        num_classes: Number of classes.\n    \"\"\"", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "config", "=", "_CONFIG", ".", "copy", "(", ")", "\n", "mode", "=", "'validation'", "\n", "dataset_dir", "=", "config", "[", "'dataset_dir'", "]", "\n", "text_dir", "=", "config", "[", "'text_dir'", "]", "\n", "emb_dir", "=", "config", "[", "'emb_dir'", "]", "\n", "filename", "=", "config", "[", "'filename'", "]", "\n", "initial_lr", "=", "config", "[", "'initial_lr'", "]", "\n", "#batch_size = config['batch_size']", "\n", "im_features_size", "=", "config", "[", "'im_features_size'", "]", "\n", "rnn_size", "=", "config", "[", "'rnn_size'", "]", "\n", "final_endpoint", "=", "config", "[", "'final_endpoint'", "]", "\n", "\n", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "\n", "batch_size", "=", "1", "\n", "image_size", "=", "inception_v1", ".", "default_image_size", "\n", "images", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "image_size", ",", "image_size", ",", "3", "]", ")", "\n", "images_prep", "=", "inception_preprocessing", ".", "preprocess_image", "(", "images", ",", "image_size", ",", "image_size", ",", "is_training", "=", "False", ")", "\n", "images_prep_final", "=", "tf", ".", "expand_dims", "(", "images_prep", ",", "0", ")", "\n", "\n", "texts", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "batch_size", ",", "_POST_SIZE", "]", ")", "\n", "seq_lens", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "batch_size", "]", ")", "\n", "\n", "# Create the model, use the default arg scope to configure the batch norm parameters.", "\n", "is_training", "=", "(", "mode", "==", "'train'", ")", "\n", "with", "slim", ".", "arg_scope", "(", "inception_v1", ".", "inception_v1_arg_scope", "(", ")", ")", ":", "\n", "            ", "images_features", ",", "_", "=", "inception_v1", ".", "inception_v1", "(", "images_prep_final", ",", "final_endpoint", "=", "final_endpoint", ",", "\n", "num_classes", "=", "im_features_size", ",", "is_training", "=", "is_training", ")", "\n", "\n", "# Text model", "\n", "", "vocabulary", ",", "embedding", "=", "_load_embedding_weights_glove", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "vocab_size", ",", "embedding_dim", "=", "embedding", ".", "shape", "\n", "word_to_id", "=", "dict", "(", "zip", "(", "vocabulary", ",", "range", "(", "vocab_size", ")", ")", ")", "\n", "# Unknown words = vector with zeros", "\n", "embedding", "=", "np", ".", "concatenate", "(", "[", "embedding", ",", "np", ".", "zeros", "(", "(", "1", ",", "embedding_dim", ")", ")", "]", ")", "\n", "word_to_id", "[", "'<ukn>'", "]", "=", "vocab_size", "\n", "\n", "vocab_size", "=", "len", "(", "word_to_id", ")", "\n", "nb_emotions", "=", "num_classes", "\n", "with", "tf", ".", "variable_scope", "(", "'Text'", ")", ":", "\n", "# Word embedding", "\n", "            ", "W_embedding", "=", "tf", ".", "get_variable", "(", "'W_embedding'", ",", "[", "vocab_size", ",", "embedding_dim", "]", ",", "trainable", "=", "False", ")", "\n", "input_embed", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "W_embedding", ",", "texts", ")", "\n", "\n", "# LSTM", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicLSTMCell", "(", "rnn_size", ")", "\n", "rnn_outputs", ",", "final_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "cell", ",", "input_embed", ",", "sequence_length", "=", "seq_lens", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Need to convert seq_lens to int32 for stack", "\n", "texts_features", "=", "tf", ".", "gather_nd", "(", "rnn_outputs", ",", "tf", ".", "stack", "(", "[", "tf", ".", "range", "(", "batch_size", ")", ",", "tf", ".", "cast", "(", "seq_lens", ",", "tf", ".", "int32", ")", "-", "1", "]", ",", "axis", "=", "1", ")", ")", "\n", "\n", "# Concatenate image and text features", "\n", "", "concat_features", "=", "tf", ".", "concat", "(", "[", "images_features", ",", "texts_features", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# Dense layer", "\n", "W_fc", "=", "tf", ".", "get_variable", "(", "'W_fc'", ",", "[", "im_features_size", "+", "rnn_size", ",", "fc_size", "]", ")", "\n", "b_fc", "=", "tf", ".", "get_variable", "(", "'b_fc'", ",", "[", "fc_size", "]", ")", "\n", "dense_layer", "=", "tf", ".", "matmul", "(", "concat_features", ",", "W_fc", ")", "+", "b_fc", "\n", "dense_layer_relu", "=", "tf", ".", "nn", ".", "relu", "(", "dense_layer", ")", "\n", "\n", "W_softmax", "=", "tf", ".", "get_variable", "(", "'W_softmax'", ",", "[", "fc_size", ",", "nb_emotions", "]", ")", "\n", "b_softmax", "=", "tf", ".", "get_variable", "(", "'b_softmax'", ",", "[", "nb_emotions", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "dense_layer_relu", ",", "W_softmax", ")", "+", "b_softmax", "\n", "\n", "# Load model", "\n", "checkpoint_path", "=", "tf_saver", ".", "latest_checkpoint", "(", "checkpoint_dir", ")", "\n", "scaffold", "=", "monitored_session", ".", "Scaffold", "(", "\n", "init_op", "=", "None", ",", "init_feed_dict", "=", "None", ",", "\n", "init_fn", "=", "None", ",", "saver", "=", "None", ")", "\n", "session_creator", "=", "monitored_session", ".", "ChiefSessionCreator", "(", "\n", "scaffold", "=", "scaffold", ",", "\n", "checkpoint_filename_with_path", "=", "checkpoint_path", ",", "\n", "master", "=", "''", ",", "\n", "config", "=", "None", ")", "\n", "\n", "# Load oasis dataset", "\n", "df_oasis", "=", "pd", ".", "read_csv", "(", "'data/oasis/OASIS.csv'", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n", "def", "load_image", "(", "name", ")", ":", "\n", "            ", "im_path", "=", "'data/oasis/images/'", "+", "name", ".", "strip", "(", ")", "+", "'.jpg'", "\n", "one_im", "=", "imread", "(", "im_path", ")", "\n", "one_im", "=", "imresize", "(", "one_im", ",", "(", "(", "image_size", ",", "image_size", ",", "3", ")", ")", ")", "[", ":", ",", ":", ",", ":", "3", "]", "# to get rid of alpha channel", "\n", "return", "one_im", "\n", "\n", "", "df_oasis", "[", "'image'", "]", "=", "df_oasis", "[", "'Theme'", "]", ".", "map", "(", "lambda", "x", ":", "load_image", "(", "x", ")", ")", "\n", "\n", "df_oasis", "[", "'Theme'", "]", "=", "df_oasis", "[", "'Theme'", "]", ".", "map", "(", "lambda", "x", ":", "''", ".", "join", "(", "[", "i", "for", "i", "in", "x", "if", "not", "i", ".", "isdigit", "(", ")", "]", ")", ".", "strip", "(", ")", ")", "\n", "vocabulary", ",", "embedding", "=", "_load_embedding_weights_glove", "(", "text_dir", ",", "emb_dir", ",", "filename", ")", "\n", "word_to_id", "=", "dict", "(", "zip", "(", "vocabulary", ",", "range", "(", "len", "(", "vocabulary", ")", ")", ")", ")", "\n", "df_oasis", "[", "'text_list'", "]", ",", "df_oasis", "[", "'text_len'", "]", "=", "zip", "(", "*", "df_oasis", "[", "'Theme'", "]", ".", "map", "(", "lambda", "x", ":", "\n", "_paragraph_to_ids", "(", "x", ",", "word_to_id", ",", "\n", "_POST_SIZE", ",", "emotions", "=", "''", ")", ")", ")", "\n", "with", "monitored_session", ".", "MonitoredSession", "(", "\n", "session_creator", "=", "session_creator", ",", "hooks", "=", "None", ")", "as", "session", ":", "\n", "\n", "            ", "nb_iter", "=", "df_oasis", ".", "shape", "[", "0", "]", "/", "batch_size", "\n", "scores", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nb_iter", ")", ":", "\n", "                ", "np_images", "=", "df_oasis", "[", "'image'", "]", "[", "(", "i", "*", "batch_size", ")", ":", "(", "(", "i", "+", "1", ")", "*", "batch_size", ")", "]", "\n", "np_texts", "=", "np", ".", "vstack", "(", "df_oasis", "[", "'text_list'", "]", "[", "(", "i", "*", "batch_size", ")", ":", "(", "(", "i", "+", "1", ")", "*", "batch_size", ")", "]", ")", "\n", "np_seq_lens", "=", "df_oasis", "[", "'text_len'", "]", "[", "(", "i", "*", "batch_size", ")", ":", "(", "(", "i", "+", "1", ")", "*", "batch_size", ")", "]", ".", "values", "\n", "print", "(", "np_images", ".", "shape", ")", "\n", "session", ".", "run", "(", "images", ",", "feed_dict", "=", "{", "images", ":", "np_images", "}", ")", "\n", "print", "(", "np_texts", ".", "shape", ")", "\n", "session", ".", "run", "(", "texts", ",", "feed_dict", "=", "{", "texts", ":", "np_texts", "}", ")", "\n", "print", "(", "np_seq_lens", ".", "shape", ")", "\n", "session", ".", "run", "(", "seq_lens", ",", "feed_dict", "=", "{", "seq_lens", ":", "np_seq_lens", "}", ")", "\n", "#scores.append(session.run(logits, feed_dict={images: np_images, texts: np_texts, seq_lens: np_seq_lens}))", "\n", "", "", "", "scores", "=", "np", ".", "vstack", "(", "scores", ")", "\n", "np", ".", "save", "(", "'data/oasis_logits.npy'", ",", "scores", ")", "\n", "return", "scores", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.download_and_convert_data.main": [[56, 71], ["ValueError", "ValueError", "datasets.download_and_convert_cifar10.run", "datasets.download_and_convert_flowers.run", "datasets.download_and_convert_mnist.run", "ValueError"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["def", "main", "(", "_", ")", ":", "\n", "  ", "if", "not", "FLAGS", ".", "dataset_name", ":", "\n", "    ", "raise", "ValueError", "(", "'You must supply the dataset name with --dataset_name'", ")", "\n", "", "if", "not", "FLAGS", ".", "dataset_dir", ":", "\n", "    ", "raise", "ValueError", "(", "'You must supply the dataset directory with --dataset_dir'", ")", "\n", "\n", "", "if", "FLAGS", ".", "dataset_name", "==", "'cifar10'", ":", "\n", "    ", "download_and_convert_cifar10", ".", "run", "(", "FLAGS", ".", "dataset_dir", ")", "\n", "", "elif", "FLAGS", ".", "dataset_name", "==", "'flowers'", ":", "\n", "    ", "download_and_convert_flowers", ".", "run", "(", "FLAGS", ".", "dataset_dir", ")", "\n", "", "elif", "FLAGS", ".", "dataset_name", "==", "'mnist'", ":", "\n", "    ", "download_and_convert_mnist", ".", "run", "(", "FLAGS", ".", "dataset_dir", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "'dataset_name [%s] was not recognized.'", "%", "FLAGS", ".", "dataset_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.export_inference_graph_test.ExportInferenceGraphTest.testExportInferenceGraph": [[33, 42], ["export_inference_graph_test.ExportInferenceGraphTest.get_temp_dir", "os.path.join", "google3.third_party.tensorflow_models.slim.export_inference_graph.main", "export_inference_graph_test.ExportInferenceGraphTest.assertTrue", "tensorflow.python.platform.gfile.Exists"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.eval_image_classifier.main"], ["  ", "def", "testExportInferenceGraph", "(", "self", ")", ":", "\n", "    ", "tmpdir", "=", "self", ".", "get_temp_dir", "(", ")", "\n", "output_file", "=", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "'inception_v3.pb'", ")", "\n", "flags", "=", "tf", ".", "app", ".", "flags", ".", "FLAGS", "\n", "flags", ".", "output_file", "=", "output_file", "\n", "flags", ".", "model_name", "=", "'inception_v3'", "\n", "flags", ".", "dataset_dir", "=", "tmpdir", "\n", "export_inference_graph", ".", "main", "(", "None", ")", "\n", "self", ".", "assertTrue", "(", "gfile", ".", "Exists", "(", "output_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.train_image_classifier._configure_learning_rate": [[221, 259], ["int", "tensorflow.train.exponential_decay", "tensorflow.constant", "tensorflow.train.polynomial_decay", "ValueError"], "function", ["None"], ["def", "_configure_learning_rate", "(", "num_samples_per_epoch", ",", "global_step", ")", ":", "\n", "  ", "\"\"\"Configures the learning rate.\n\n  Args:\n    num_samples_per_epoch: The number of samples in each epoch of training.\n    global_step: The global_step tensor.\n\n  Returns:\n    A `Tensor` representing the learning rate.\n\n  Raises:\n    ValueError: if\n  \"\"\"", "\n", "decay_steps", "=", "int", "(", "num_samples_per_epoch", "/", "FLAGS", ".", "batch_size", "*", "\n", "FLAGS", ".", "num_epochs_per_decay", ")", "\n", "if", "FLAGS", ".", "sync_replicas", ":", "\n", "    ", "decay_steps", "/=", "FLAGS", ".", "replicas_to_aggregate", "\n", "\n", "", "if", "FLAGS", ".", "learning_rate_decay_type", "==", "'exponential'", ":", "\n", "    ", "return", "tf", ".", "train", ".", "exponential_decay", "(", "FLAGS", ".", "learning_rate", ",", "\n", "global_step", ",", "\n", "decay_steps", ",", "\n", "FLAGS", ".", "learning_rate_decay_factor", ",", "\n", "staircase", "=", "True", ",", "\n", "name", "=", "'exponential_decay_learning_rate'", ")", "\n", "", "elif", "FLAGS", ".", "learning_rate_decay_type", "==", "'fixed'", ":", "\n", "    ", "return", "tf", ".", "constant", "(", "FLAGS", ".", "learning_rate", ",", "name", "=", "'fixed_learning_rate'", ")", "\n", "", "elif", "FLAGS", ".", "learning_rate_decay_type", "==", "'polynomial'", ":", "\n", "    ", "return", "tf", ".", "train", ".", "polynomial_decay", "(", "FLAGS", ".", "learning_rate", ",", "\n", "global_step", ",", "\n", "decay_steps", ",", "\n", "FLAGS", ".", "end_learning_rate", ",", "\n", "power", "=", "1.0", ",", "\n", "cycle", "=", "False", ",", "\n", "name", "=", "'polynomial_decay_learning_rate'", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'learning_rate_decay_type [%s] was not recognized'", ",", "\n", "FLAGS", ".", "learning_rate_decay_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.train_image_classifier._configure_optimizer": [[261, 311], ["tensorflow.train.AdadeltaOptimizer", "tensorflow.train.AdagradOptimizer", "tensorflow.train.AdamOptimizer", "tensorflow.train.FtrlOptimizer", "tensorflow.train.MomentumOptimizer", "tensorflow.train.RMSPropOptimizer", "tensorflow.train.GradientDescentOptimizer", "ValueError"], "function", ["None"], ["", "", "def", "_configure_optimizer", "(", "learning_rate", ")", ":", "\n", "  ", "\"\"\"Configures the optimizer used for training.\n\n  Args:\n    learning_rate: A scalar or `Tensor` learning rate.\n\n  Returns:\n    An instance of an optimizer.\n\n  Raises:\n    ValueError: if FLAGS.optimizer is not recognized.\n  \"\"\"", "\n", "if", "FLAGS", ".", "optimizer", "==", "'adadelta'", ":", "\n", "    ", "optimizer", "=", "tf", ".", "train", ".", "AdadeltaOptimizer", "(", "\n", "learning_rate", ",", "\n", "rho", "=", "FLAGS", ".", "adadelta_rho", ",", "\n", "epsilon", "=", "FLAGS", ".", "opt_epsilon", ")", "\n", "", "elif", "FLAGS", ".", "optimizer", "==", "'adagrad'", ":", "\n", "    ", "optimizer", "=", "tf", ".", "train", ".", "AdagradOptimizer", "(", "\n", "learning_rate", ",", "\n", "initial_accumulator_value", "=", "FLAGS", ".", "adagrad_initial_accumulator_value", ")", "\n", "", "elif", "FLAGS", ".", "optimizer", "==", "'adam'", ":", "\n", "    ", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "\n", "learning_rate", ",", "\n", "beta1", "=", "FLAGS", ".", "adam_beta1", ",", "\n", "beta2", "=", "FLAGS", ".", "adam_beta2", ",", "\n", "epsilon", "=", "FLAGS", ".", "opt_epsilon", ")", "\n", "", "elif", "FLAGS", ".", "optimizer", "==", "'ftrl'", ":", "\n", "    ", "optimizer", "=", "tf", ".", "train", ".", "FtrlOptimizer", "(", "\n", "learning_rate", ",", "\n", "learning_rate_power", "=", "FLAGS", ".", "ftrl_learning_rate_power", ",", "\n", "initial_accumulator_value", "=", "FLAGS", ".", "ftrl_initial_accumulator_value", ",", "\n", "l1_regularization_strength", "=", "FLAGS", ".", "ftrl_l1", ",", "\n", "l2_regularization_strength", "=", "FLAGS", ".", "ftrl_l2", ")", "\n", "", "elif", "FLAGS", ".", "optimizer", "==", "'momentum'", ":", "\n", "    ", "optimizer", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "\n", "learning_rate", ",", "\n", "momentum", "=", "FLAGS", ".", "momentum", ",", "\n", "name", "=", "'Momentum'", ")", "\n", "", "elif", "FLAGS", ".", "optimizer", "==", "'rmsprop'", ":", "\n", "    ", "optimizer", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "\n", "learning_rate", ",", "\n", "decay", "=", "FLAGS", ".", "rmsprop_decay", ",", "\n", "momentum", "=", "FLAGS", ".", "momentum", ",", "\n", "epsilon", "=", "FLAGS", ".", "opt_epsilon", ")", "\n", "", "elif", "FLAGS", ".", "optimizer", "==", "'sgd'", ":", "\n", "    ", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "'Optimizer [%s] was not recognized'", ",", "FLAGS", ".", "optimizer", ")", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.train_image_classifier._get_init_fn": [[312, 359], ["tensorflow.train.latest_checkpoint", "slim.get_model_variables", "tensorflow.gfile.IsDirectory", "tensorflow.logging.info", "slim.assign_from_checkpoint_fn", "tensorflow.logging.info", "tensorflow.train.latest_checkpoint", "scope.strip", "var.op.name.startswith", "variables_to_restore.append", "FLAGS.checkpoint_exclude_scopes.split"], "function", ["None"], ["", "def", "_get_init_fn", "(", ")", ":", "\n", "  ", "\"\"\"Returns a function run by the chief worker to warm-start the training.\n\n  Note that the init_fn is only run when initializing the model during the very\n  first global step.\n\n  Returns:\n    An init function run by the supervisor.\n  \"\"\"", "\n", "if", "FLAGS", ".", "checkpoint_path", "is", "None", ":", "\n", "    ", "return", "None", "\n", "\n", "# Warn the user if a checkpoint exists in the train_dir. Then we'll be", "\n", "# ignoring the checkpoint anyway.", "\n", "", "if", "tf", ".", "train", ".", "latest_checkpoint", "(", "FLAGS", ".", "train_dir", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "info", "(", "\n", "'Ignoring --checkpoint_path because a checkpoint already exists in %s'", "\n", "%", "FLAGS", ".", "train_dir", ")", "\n", "return", "None", "\n", "\n", "", "exclusions", "=", "[", "]", "\n", "if", "FLAGS", ".", "checkpoint_exclude_scopes", ":", "\n", "    ", "exclusions", "=", "[", "scope", ".", "strip", "(", ")", "\n", "for", "scope", "in", "FLAGS", ".", "checkpoint_exclude_scopes", ".", "split", "(", "','", ")", "]", "\n", "\n", "# TODO(sguada) variables.filter_variables()", "\n", "", "variables_to_restore", "=", "[", "]", "\n", "for", "var", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "    ", "excluded", "=", "False", "\n", "for", "exclusion", "in", "exclusions", ":", "\n", "      ", "if", "var", ".", "op", ".", "name", ".", "startswith", "(", "exclusion", ")", ":", "\n", "        ", "excluded", "=", "True", "\n", "break", "\n", "", "", "if", "not", "excluded", ":", "\n", "      ", "variables_to_restore", ".", "append", "(", "var", ")", "\n", "\n", "", "", "if", "tf", ".", "gfile", ".", "IsDirectory", "(", "FLAGS", ".", "checkpoint_path", ")", ":", "\n", "    ", "checkpoint_path", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "FLAGS", ".", "checkpoint_path", ")", "\n", "", "else", ":", "\n", "    ", "checkpoint_path", "=", "FLAGS", ".", "checkpoint_path", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "'Fine-tuning from %s'", "%", "checkpoint_path", ")", "\n", "\n", "return", "slim", ".", "assign_from_checkpoint_fn", "(", "\n", "checkpoint_path", ",", "\n", "variables_to_restore", ",", "\n", "ignore_missing_vars", "=", "FLAGS", ".", "ignore_missing_vars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.train_image_classifier._get_variables_to_train": [[361, 377], ["tensorflow.trainable_variables", "tensorflow.get_collection", "variables_to_train.extend", "scope.strip", "FLAGS.trainable_scopes.split"], "function", ["None"], ["", "def", "_get_variables_to_train", "(", ")", ":", "\n", "  ", "\"\"\"Returns a list of variables to train.\n\n  Returns:\n    A list of variables to train by the optimizer.\n  \"\"\"", "\n", "if", "FLAGS", ".", "trainable_scopes", "is", "None", ":", "\n", "    ", "return", "tf", ".", "trainable_variables", "(", ")", "\n", "", "else", ":", "\n", "    ", "scopes", "=", "[", "scope", ".", "strip", "(", ")", "for", "scope", "in", "FLAGS", ".", "trainable_scopes", ".", "split", "(", "','", ")", "]", "\n", "\n", "", "variables_to_train", "=", "[", "]", "\n", "for", "scope", "in", "scopes", ":", "\n", "    ", "variables", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", ")", "\n", "variables_to_train", ".", "extend", "(", "variables", ")", "\n", "", "return", "variables_to_train", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.train_image_classifier.main": [[379, 570], ["tensorflow.logging.set_verbosity", "ValueError", "tensorflow.Graph().as_default", "deployment.model_deploy.DeploymentConfig", "datasets.dataset_factory.get_dataset", "nets.nets_factory.get_network_fn", "preprocessing.preprocessing_factory.get_preprocessing", "set", "deployment.model_deploy.create_clones", "model_deploy.DeploymentConfig.clone_scope", "tensorflow.get_collection", "tensorflow.get_collection", "slim.get_model_variables", "train_image_classifier._get_variables_to_train", "deployment.model_deploy.optimize_clones", "set.add", "tf.train.SyncReplicasOptimizer.apply_gradients", "tf.get_collection.append", "tensorflow.group", "set", "tensorflow.summary.merge", "slim.learning.train", "tensorflow.device", "slim.create_global_step", "tensorflow.device", "slim.dataset_data_provider.DatasetDataProvider", "slim.dataset_data_provider.DatasetDataProvider.get", "preprocessing_factory.get_preprocessing.", "tensorflow.train.batch", "slim.one_hot_encoding", "slim.prefetch_queue.prefetch_queue", "nets_factory.get_network_fn.", "tensorflow.losses.softmax_cross_entropy", "tensorflow.get_collection", "set.add", "set.add", "set.add", "set.add", "slim.get_model_variables", "tensorflow.train.ExponentialMovingAverage", "tensorflow.device", "train_image_classifier._configure_learning_rate", "train_image_classifier._configure_optimizer", "set.add", "tensorflow.train.SyncReplicasOptimizer", "tensorflow.summary.scalar", "tensorflow.control_dependencies", "tensorflow.identity", "tensorflow.get_collection", "list", "tensorflow.Graph", "model_deploy.DeploymentConfig.variables_device", "model_deploy.DeploymentConfig.inputs_device", "tensorflow.device", "slim.prefetch_queue.prefetch_queue.dequeue", "tensorflow.losses.softmax_cross_entropy", "tensorflow.summary.histogram", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.histogram", "model_deploy.DeploymentConfig.optimizer_device", "tensorflow.summary.scalar", "tf.get_collection.append", "train_image_classifier._get_init_fn", "model_deploy.DeploymentConfig.inputs_device", "tensorflow.nn.zero_fraction", "tensorflow.constant", "tf.train.ExponentialMovingAverage.apply"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_factory.get_dataset", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.nets_factory.get_network_fn", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.preprocessing_factory.get_preprocessing", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.train_image_classifier._get_variables_to_train", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.optimize_clones", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.train_image_classifier._configure_learning_rate", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.train_image_classifier._configure_optimizer", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.variables_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.inputs_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.optimizer_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.train_image_classifier._get_init_fn", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.inputs_device"], ["", "def", "main", "(", "_", ")", ":", "\n", "  ", "if", "not", "FLAGS", ".", "dataset_dir", ":", "\n", "    ", "raise", "ValueError", "(", "'You must supply the dataset directory with --dataset_dir'", ")", "\n", "\n", "", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "#######################", "\n", "# Config model_deploy #", "\n", "#######################", "\n", "    ", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "\n", "num_clones", "=", "FLAGS", ".", "num_clones", ",", "\n", "clone_on_cpu", "=", "FLAGS", ".", "clone_on_cpu", ",", "\n", "replica_id", "=", "FLAGS", ".", "task", ",", "\n", "num_replicas", "=", "FLAGS", ".", "worker_replicas", ",", "\n", "num_ps_tasks", "=", "FLAGS", ".", "num_ps_tasks", ")", "\n", "\n", "# Create global_step", "\n", "with", "tf", ".", "device", "(", "deploy_config", ".", "variables_device", "(", ")", ")", ":", "\n", "      ", "global_step", "=", "slim", ".", "create_global_step", "(", ")", "\n", "\n", "######################", "\n", "# Select the dataset #", "\n", "######################", "\n", "", "dataset", "=", "dataset_factory", ".", "get_dataset", "(", "\n", "FLAGS", ".", "dataset_name", ",", "FLAGS", ".", "dataset_split_name", ",", "FLAGS", ".", "dataset_dir", ")", "\n", "\n", "######################", "\n", "# Select the network #", "\n", "######################", "\n", "network_fn", "=", "nets_factory", ".", "get_network_fn", "(", "\n", "FLAGS", ".", "model_name", ",", "\n", "num_classes", "=", "(", "dataset", ".", "num_classes", "-", "FLAGS", ".", "labels_offset", ")", ",", "\n", "weight_decay", "=", "FLAGS", ".", "weight_decay", ",", "\n", "is_training", "=", "True", ")", "\n", "\n", "#####################################", "\n", "# Select the preprocessing function #", "\n", "#####################################", "\n", "preprocessing_name", "=", "FLAGS", ".", "preprocessing_name", "or", "FLAGS", ".", "model_name", "\n", "image_preprocessing_fn", "=", "preprocessing_factory", ".", "get_preprocessing", "(", "\n", "preprocessing_name", ",", "\n", "is_training", "=", "True", ")", "\n", "\n", "##############################################################", "\n", "# Create a dataset provider that loads data from the dataset #", "\n", "##############################################################", "\n", "with", "tf", ".", "device", "(", "deploy_config", ".", "inputs_device", "(", ")", ")", ":", "\n", "      ", "provider", "=", "slim", ".", "dataset_data_provider", ".", "DatasetDataProvider", "(", "\n", "dataset", ",", "\n", "num_readers", "=", "FLAGS", ".", "num_readers", ",", "\n", "common_queue_capacity", "=", "20", "*", "FLAGS", ".", "batch_size", ",", "\n", "common_queue_min", "=", "10", "*", "FLAGS", ".", "batch_size", ")", "\n", "[", "image", ",", "label", "]", "=", "provider", ".", "get", "(", "[", "'image'", ",", "'label'", "]", ")", "\n", "label", "-=", "FLAGS", ".", "labels_offset", "\n", "\n", "train_image_size", "=", "FLAGS", ".", "train_image_size", "or", "network_fn", ".", "default_image_size", "\n", "\n", "image", "=", "image_preprocessing_fn", "(", "image", ",", "train_image_size", ",", "train_image_size", ")", "\n", "\n", "images", ",", "labels", "=", "tf", ".", "train", ".", "batch", "(", "\n", "[", "image", ",", "label", "]", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_threads", "=", "FLAGS", ".", "num_preprocessing_threads", ",", "\n", "capacity", "=", "5", "*", "FLAGS", ".", "batch_size", ")", "\n", "labels", "=", "slim", ".", "one_hot_encoding", "(", "\n", "labels", ",", "dataset", ".", "num_classes", "-", "FLAGS", ".", "labels_offset", ")", "\n", "batch_queue", "=", "slim", ".", "prefetch_queue", ".", "prefetch_queue", "(", "\n", "[", "images", ",", "labels", "]", ",", "capacity", "=", "2", "*", "deploy_config", ".", "num_clones", ")", "\n", "\n", "####################", "\n", "# Define the model #", "\n", "####################", "\n", "", "def", "clone_fn", "(", "batch_queue", ")", ":", "\n", "      ", "\"\"\"Allows data parallelism by creating multiple clones of network_fn.\"\"\"", "\n", "with", "tf", ".", "device", "(", "deploy_config", ".", "inputs_device", "(", ")", ")", ":", "\n", "        ", "images", ",", "labels", "=", "batch_queue", ".", "dequeue", "(", ")", "\n", "", "logits", ",", "end_points", "=", "network_fn", "(", "images", ")", "\n", "\n", "#############################", "\n", "# Specify the loss function #", "\n", "#############################", "\n", "if", "'AuxLogits'", "in", "end_points", ":", "\n", "        ", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "\n", "logits", "=", "end_points", "[", "'AuxLogits'", "]", ",", "onehot_labels", "=", "labels", ",", "\n", "label_smoothing", "=", "FLAGS", ".", "label_smoothing", ",", "weights", "=", "0.4", ",", "scope", "=", "'aux_loss'", ")", "\n", "", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "\n", "logits", "=", "logits", ",", "onehot_labels", "=", "labels", ",", "\n", "label_smoothing", "=", "FLAGS", ".", "label_smoothing", ",", "weights", "=", "1.0", ")", "\n", "return", "end_points", "\n", "\n", "# Gather initial summaries.", "\n", "", "summaries", "=", "set", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "SUMMARIES", ")", ")", "\n", "\n", "clones", "=", "model_deploy", ".", "create_clones", "(", "deploy_config", ",", "clone_fn", ",", "[", "batch_queue", "]", ")", "\n", "first_clone_scope", "=", "deploy_config", ".", "clone_scope", "(", "0", ")", "\n", "# Gather update_ops from the first clone. These contain, for example,", "\n", "# the updates for the batch_norm variables created by network_fn.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "first_clone_scope", ")", "\n", "\n", "# Add summaries for end_points.", "\n", "end_points", "=", "clones", "[", "0", "]", ".", "outputs", "\n", "for", "end_point", "in", "end_points", ":", "\n", "      ", "x", "=", "end_points", "[", "end_point", "]", "\n", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "histogram", "(", "'activations/'", "+", "end_point", ",", "x", ")", ")", "\n", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'sparsity/'", "+", "end_point", ",", "\n", "tf", ".", "nn", ".", "zero_fraction", "(", "x", ")", ")", ")", "\n", "\n", "# Add summaries for losses.", "\n", "", "for", "loss", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "LOSSES", ",", "first_clone_scope", ")", ":", "\n", "      ", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'losses/%s'", "%", "loss", ".", "op", ".", "name", ",", "loss", ")", ")", "\n", "\n", "# Add summaries for variables.", "\n", "", "for", "variable", "in", "slim", ".", "get_model_variables", "(", ")", ":", "\n", "      ", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "histogram", "(", "variable", ".", "op", ".", "name", ",", "variable", ")", ")", "\n", "\n", "#################################", "\n", "# Configure the moving averages #", "\n", "#################################", "\n", "", "if", "FLAGS", ".", "moving_average_decay", ":", "\n", "      ", "moving_average_variables", "=", "slim", ".", "get_model_variables", "(", ")", "\n", "variable_averages", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "\n", "FLAGS", ".", "moving_average_decay", ",", "global_step", ")", "\n", "", "else", ":", "\n", "      ", "moving_average_variables", ",", "variable_averages", "=", "None", ",", "None", "\n", "\n", "#########################################", "\n", "# Configure the optimization procedure. #", "\n", "#########################################", "\n", "", "with", "tf", ".", "device", "(", "deploy_config", ".", "optimizer_device", "(", ")", ")", ":", "\n", "      ", "learning_rate", "=", "_configure_learning_rate", "(", "dataset", ".", "num_samples", ",", "global_step", ")", "\n", "optimizer", "=", "_configure_optimizer", "(", "learning_rate", ")", "\n", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'learning_rate'", ",", "learning_rate", ")", ")", "\n", "\n", "", "if", "FLAGS", ".", "sync_replicas", ":", "\n", "# If sync_replicas is enabled, the averaging will be done in the chief", "\n", "# queue runner.", "\n", "      ", "optimizer", "=", "tf", ".", "train", ".", "SyncReplicasOptimizer", "(", "\n", "opt", "=", "optimizer", ",", "\n", "replicas_to_aggregate", "=", "FLAGS", ".", "replicas_to_aggregate", ",", "\n", "variable_averages", "=", "variable_averages", ",", "\n", "variables_to_average", "=", "moving_average_variables", ",", "\n", "replica_id", "=", "tf", ".", "constant", "(", "FLAGS", ".", "task", ",", "tf", ".", "int32", ",", "shape", "=", "(", ")", ")", ",", "\n", "total_num_replicas", "=", "FLAGS", ".", "worker_replicas", ")", "\n", "", "elif", "FLAGS", ".", "moving_average_decay", ":", "\n", "# Update ops executed locally by trainer.", "\n", "      ", "update_ops", ".", "append", "(", "variable_averages", ".", "apply", "(", "moving_average_variables", ")", ")", "\n", "\n", "# Variables to train.", "\n", "", "variables_to_train", "=", "_get_variables_to_train", "(", ")", "\n", "\n", "#  and returns a train_tensor and summary_op", "\n", "total_loss", ",", "clones_gradients", "=", "model_deploy", ".", "optimize_clones", "(", "\n", "clones", ",", "\n", "optimizer", ",", "\n", "var_list", "=", "variables_to_train", ")", "\n", "# Add total_loss to summary.", "\n", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'total_loss'", ",", "total_loss", ")", ")", "\n", "\n", "# Create gradient updates.", "\n", "grad_updates", "=", "optimizer", ".", "apply_gradients", "(", "clones_gradients", ",", "\n", "global_step", "=", "global_step", ")", "\n", "update_ops", ".", "append", "(", "grad_updates", ")", "\n", "\n", "update_op", "=", "tf", ".", "group", "(", "*", "update_ops", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "update_op", "]", ")", ":", "\n", "      ", "train_tensor", "=", "tf", ".", "identity", "(", "total_loss", ",", "name", "=", "'train_op'", ")", "\n", "\n", "# Add the summaries from the first clone. These contain the summaries", "\n", "# created by model_fn and either optimize_clones() or _gather_clone_loss().", "\n", "", "summaries", "|=", "set", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "SUMMARIES", ",", "\n", "first_clone_scope", ")", ")", "\n", "\n", "# Merge all summaries together.", "\n", "summary_op", "=", "tf", ".", "summary", ".", "merge", "(", "list", "(", "summaries", ")", ",", "name", "=", "'summary_op'", ")", "\n", "\n", "\n", "###########################", "\n", "# Kicks off the training. #", "\n", "###########################", "\n", "slim", ".", "learning", ".", "train", "(", "\n", "train_tensor", ",", "\n", "logdir", "=", "FLAGS", ".", "train_dir", ",", "\n", "master", "=", "FLAGS", ".", "master", ",", "\n", "is_chief", "=", "(", "FLAGS", ".", "task", "==", "0", ")", ",", "\n", "init_fn", "=", "_get_init_fn", "(", ")", ",", "\n", "summary_op", "=", "summary_op", ",", "\n", "number_of_steps", "=", "FLAGS", ".", "max_number_of_steps", ",", "\n", "log_every_n_steps", "=", "FLAGS", ".", "log_every_n_steps", ",", "\n", "save_summaries_secs", "=", "FLAGS", ".", "save_summaries_secs", ",", "\n", "save_interval_secs", "=", "FLAGS", ".", "save_interval_secs", ",", "\n", "sync_optimizer", "=", "optimizer", "if", "FLAGS", ".", "sync_replicas", "else", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.export_inference_graph.main": [[98, 119], ["tensorflow.logging.set_verbosity", "ValueError", "tensorflow.Graph().as_default", "datasets.dataset_factory.get_dataset", "nets.nets_factory.get_network_fn", "hasattr", "tensorflow.placeholder", "nets_factory.get_network_fn.", "graph.as_graph_def", "tensorflow.python.platform.gfile.GFile", "f.write", "tensorflow.Graph", "graph.as_graph_def.SerializeToString"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_factory.get_dataset", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.nets_factory.get_network_fn"], ["def", "main", "(", "_", ")", ":", "\n", "  ", "if", "not", "FLAGS", ".", "output_file", ":", "\n", "    ", "raise", "ValueError", "(", "'You must supply the path to save to with --output_file'", ")", "\n", "", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", "as", "graph", ":", "\n", "    ", "dataset", "=", "dataset_factory", ".", "get_dataset", "(", "FLAGS", ".", "dataset_name", ",", "'validation'", ",", "\n", "FLAGS", ".", "dataset_dir", ")", "\n", "network_fn", "=", "nets_factory", ".", "get_network_fn", "(", "\n", "FLAGS", ".", "model_name", ",", "\n", "num_classes", "=", "(", "dataset", ".", "num_classes", "-", "FLAGS", ".", "labels_offset", ")", ",", "\n", "is_training", "=", "FLAGS", ".", "is_training", ")", "\n", "if", "hasattr", "(", "network_fn", ",", "'default_image_size'", ")", ":", "\n", "      ", "image_size", "=", "network_fn", ".", "default_image_size", "\n", "", "else", ":", "\n", "      ", "image_size", "=", "FLAGS", ".", "default_image_size", "\n", "", "placeholder", "=", "tf", ".", "placeholder", "(", "name", "=", "'input'", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "1", ",", "image_size", ",", "image_size", ",", "3", "]", ")", "\n", "network_fn", "(", "placeholder", ")", "\n", "graph_def", "=", "graph", ".", "as_graph_def", "(", ")", "\n", "with", "gfile", ".", "GFile", "(", "FLAGS", ".", "output_file", ",", "'wb'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "graph_def", ".", "SerializeToString", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.slim.eval_image_classifier.main": [[85, 188], ["tensorflow.logging.set_verbosity", "ValueError", "tensorflow.Graph().as_default", "slim.get_or_create_global_step", "datasets.dataset_factory.get_dataset", "nets.nets_factory.get_network_fn", "slim.dataset_data_provider.DatasetDataProvider", "slim.dataset_data_provider.DatasetDataProvider.get", "preprocessing.preprocessing_factory.get_preprocessing", "preprocessing_factory.get_preprocessing.", "tensorflow.train.batch", "nets_factory.get_network_fn.", "tensorflow.argmax", "tensorflow.squeeze", "slim.metrics.aggregate_metric_map", "names_to_values.items", "tensorflow.gfile.IsDirectory", "tensorflow.logging.info", "slim.evaluation.evaluate_once", "tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.variables_to_restore", "slim.get_variables_to_restore", "tensorflow.summary.scalar", "tensorflow.Print", "tensorflow.add_to_collection", "math.ceil", "tensorflow.train.latest_checkpoint", "tensorflow.Graph", "slim.get_model_variables", "slim.metrics.streaming_accuracy", "slim.metrics.streaming_recall_at_k", "list", "float", "names_to_updates.values"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.dataset_factory.get_dataset", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.nets_factory.get_network_fn", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.preprocessing_factory.get_preprocessing"], ["def", "main", "(", "_", ")", ":", "\n", "  ", "if", "not", "FLAGS", ".", "dataset_dir", ":", "\n", "    ", "raise", "ValueError", "(", "'You must supply the dataset directory with --dataset_dir'", ")", "\n", "\n", "", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "INFO", ")", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "    ", "tf_global_step", "=", "slim", ".", "get_or_create_global_step", "(", ")", "\n", "\n", "######################", "\n", "# Select the dataset #", "\n", "######################", "\n", "dataset", "=", "dataset_factory", ".", "get_dataset", "(", "\n", "FLAGS", ".", "dataset_name", ",", "FLAGS", ".", "dataset_split_name", ",", "FLAGS", ".", "dataset_dir", ")", "\n", "\n", "####################", "\n", "# Select the model #", "\n", "####################", "\n", "network_fn", "=", "nets_factory", ".", "get_network_fn", "(", "\n", "FLAGS", ".", "model_name", ",", "\n", "num_classes", "=", "(", "dataset", ".", "num_classes", "-", "FLAGS", ".", "labels_offset", ")", ",", "\n", "is_training", "=", "False", ")", "\n", "\n", "##############################################################", "\n", "# Create a dataset provider that loads data from the dataset #", "\n", "##############################################################", "\n", "provider", "=", "slim", ".", "dataset_data_provider", ".", "DatasetDataProvider", "(", "\n", "dataset", ",", "\n", "shuffle", "=", "False", ",", "\n", "common_queue_capacity", "=", "2", "*", "FLAGS", ".", "batch_size", ",", "\n", "common_queue_min", "=", "FLAGS", ".", "batch_size", ")", "\n", "[", "image", ",", "label", "]", "=", "provider", ".", "get", "(", "[", "'image'", ",", "'label'", "]", ")", "\n", "label", "-=", "FLAGS", ".", "labels_offset", "\n", "\n", "#####################################", "\n", "# Select the preprocessing function #", "\n", "#####################################", "\n", "preprocessing_name", "=", "FLAGS", ".", "preprocessing_name", "or", "FLAGS", ".", "model_name", "\n", "image_preprocessing_fn", "=", "preprocessing_factory", ".", "get_preprocessing", "(", "\n", "preprocessing_name", ",", "\n", "is_training", "=", "False", ")", "\n", "\n", "eval_image_size", "=", "FLAGS", ".", "eval_image_size", "or", "network_fn", ".", "default_image_size", "\n", "\n", "image", "=", "image_preprocessing_fn", "(", "image", ",", "eval_image_size", ",", "eval_image_size", ")", "\n", "\n", "images", ",", "labels", "=", "tf", ".", "train", ".", "batch", "(", "\n", "[", "image", ",", "label", "]", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "num_threads", "=", "FLAGS", ".", "num_preprocessing_threads", ",", "\n", "capacity", "=", "5", "*", "FLAGS", ".", "batch_size", ")", "\n", "\n", "####################", "\n", "# Define the model #", "\n", "####################", "\n", "logits", ",", "_", "=", "network_fn", "(", "images", ")", "\n", "\n", "if", "FLAGS", ".", "moving_average_decay", ":", "\n", "      ", "variable_averages", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "\n", "FLAGS", ".", "moving_average_decay", ",", "tf_global_step", ")", "\n", "variables_to_restore", "=", "variable_averages", ".", "variables_to_restore", "(", "\n", "slim", ".", "get_model_variables", "(", ")", ")", "\n", "variables_to_restore", "[", "tf_global_step", ".", "op", ".", "name", "]", "=", "tf_global_step", "\n", "", "else", ":", "\n", "      ", "variables_to_restore", "=", "slim", ".", "get_variables_to_restore", "(", ")", "\n", "\n", "", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "labels", "=", "tf", ".", "squeeze", "(", "labels", ")", "\n", "\n", "# Define the metrics:", "\n", "names_to_values", ",", "names_to_updates", "=", "slim", ".", "metrics", ".", "aggregate_metric_map", "(", "{", "\n", "'Accuracy'", ":", "slim", ".", "metrics", ".", "streaming_accuracy", "(", "predictions", ",", "labels", ")", ",", "\n", "'Recall_5'", ":", "slim", ".", "metrics", ".", "streaming_recall_at_k", "(", "\n", "logits", ",", "labels", ",", "5", ")", ",", "\n", "}", ")", "\n", "\n", "# Print the summaries to screen.", "\n", "for", "name", ",", "value", "in", "names_to_values", ".", "items", "(", ")", ":", "\n", "      ", "summary_name", "=", "'eval/%s'", "%", "name", "\n", "op", "=", "tf", ".", "summary", ".", "scalar", "(", "summary_name", ",", "value", ",", "collections", "=", "[", "]", ")", "\n", "op", "=", "tf", ".", "Print", "(", "op", ",", "[", "value", "]", ",", "summary_name", ")", "\n", "tf", ".", "add_to_collection", "(", "tf", ".", "GraphKeys", ".", "SUMMARIES", ",", "op", ")", "\n", "\n", "# TODO(sguada) use num_epochs=1", "\n", "", "if", "FLAGS", ".", "max_num_batches", ":", "\n", "      ", "num_batches", "=", "FLAGS", ".", "max_num_batches", "\n", "", "else", ":", "\n", "# This ensures that we make a single pass over all of the data.", "\n", "      ", "num_batches", "=", "math", ".", "ceil", "(", "dataset", ".", "num_samples", "/", "float", "(", "FLAGS", ".", "batch_size", ")", ")", "\n", "\n", "", "if", "tf", ".", "gfile", ".", "IsDirectory", "(", "FLAGS", ".", "checkpoint_path", ")", ":", "\n", "      ", "checkpoint_path", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "FLAGS", ".", "checkpoint_path", ")", "\n", "", "else", ":", "\n", "      ", "checkpoint_path", "=", "FLAGS", ".", "checkpoint_path", "\n", "\n", "", "tf", ".", "logging", ".", "info", "(", "'Evaluating %s'", "%", "checkpoint_path", ")", "\n", "\n", "slim", ".", "evaluation", ".", "evaluate_once", "(", "\n", "master", "=", "FLAGS", ".", "master", ",", "\n", "checkpoint_path", "=", "checkpoint_path", ",", "\n", "logdir", "=", "FLAGS", ".", "eval_dir", ",", "\n", "num_evals", "=", "num_batches", ",", "\n", "eval_op", "=", "list", "(", "names_to_updates", ".", "values", "(", ")", ")", ",", "\n", "variables_to_restore", "=", "variables_to_restore", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._crop": [[47, 88], ["tensorflow.shape", "tensorflow.Assert", "tensorflow.Assert", "tensorflow.to_int32", "tensorflow.reshape", "tensorflow.equal", "tensorflow.control_dependencies", "tensorflow.stack", "tensorflow.logical_and", "tensorflow.stack", "tensorflow.control_dependencies", "tensorflow.slice", "tensorflow.rank", "tensorflow.greater_equal", "tensorflow.greater_equal"], "function", ["None"], ["def", "_crop", "(", "image", ",", "offset_height", ",", "offset_width", ",", "crop_height", ",", "crop_width", ")", ":", "\n", "  ", "\"\"\"Crops the given image using the provided offsets and sizes.\n\n  Note that the method doesn't assume we know the input image size but it does\n  assume we know the input image rank.\n\n  Args:\n    image: an image of shape [height, width, channels].\n    offset_height: a scalar tensor indicating the height offset.\n    offset_width: a scalar tensor indicating the width offset.\n    crop_height: the height of the cropped image.\n    crop_width: the width of the cropped image.\n\n  Returns:\n    the cropped (and resized) image.\n\n  Raises:\n    InvalidArgumentError: if the rank is not 3 or if the image dimensions are\n      less than the crop size.\n  \"\"\"", "\n", "original_shape", "=", "tf", ".", "shape", "(", "image", ")", "\n", "\n", "rank_assertion", "=", "tf", ".", "Assert", "(", "\n", "tf", ".", "equal", "(", "tf", ".", "rank", "(", "image", ")", ",", "3", ")", ",", "\n", "[", "'Rank of image must be equal to 3.'", "]", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "rank_assertion", "]", ")", ":", "\n", "    ", "cropped_shape", "=", "tf", ".", "stack", "(", "[", "crop_height", ",", "crop_width", ",", "original_shape", "[", "2", "]", "]", ")", "\n", "\n", "", "size_assertion", "=", "tf", ".", "Assert", "(", "\n", "tf", ".", "logical_and", "(", "\n", "tf", ".", "greater_equal", "(", "original_shape", "[", "0", "]", ",", "crop_height", ")", ",", "\n", "tf", ".", "greater_equal", "(", "original_shape", "[", "1", "]", ",", "crop_width", ")", ")", ",", "\n", "[", "'Crop size greater than the image size.'", "]", ")", "\n", "\n", "offsets", "=", "tf", ".", "to_int32", "(", "tf", ".", "stack", "(", "[", "offset_height", ",", "offset_width", ",", "0", "]", ")", ")", "\n", "\n", "# Use tf.slice instead of crop_to_bounding box as it accepts tensors to", "\n", "# define the crop size.", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "size_assertion", "]", ")", ":", "\n", "    ", "image", "=", "tf", ".", "slice", "(", "image", ",", "offsets", ",", "cropped_shape", ")", "\n", "", "return", "tf", ".", "reshape", "(", "image", ",", "cropped_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._random_crop": [[90, 171], ["range", "tensorflow.Assert", "range", "tensorflow.random_uniform", "tensorflow.random_uniform", "ValueError", "len", "tensorflow.rank", "tensorflow.Assert", "rank_assertions.append", "tensorflow.control_dependencies", "tensorflow.shape", "tensorflow.logical_and", "len", "asserts.append", "tensorflow.Assert", "tensorflow.Assert", "asserts.extend", "tensorflow.control_dependencies", "tensorflow.reshape", "tensorflow.control_dependencies", "tensorflow.reshape", "vgg_preprocessing._crop", "tensorflow.equal", "tensorflow.greater_equal", "tensorflow.greater_equal", "tensorflow.control_dependencies", "tensorflow.shape", "tensorflow.equal", "tensorflow.equal"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._crop"], ["", "def", "_random_crop", "(", "image_list", ",", "crop_height", ",", "crop_width", ")", ":", "\n", "  ", "\"\"\"Crops the given list of images.\n\n  The function applies the same crop to each image in the list. This can be\n  effectively applied when there are multiple image inputs of the same\n  dimension such as:\n\n    image, depths, normals = _random_crop([image, depths, normals], 120, 150)\n\n  Args:\n    image_list: a list of image tensors of the same dimension but possibly\n      varying channel.\n    crop_height: the new height.\n    crop_width: the new width.\n\n  Returns:\n    the image_list with cropped images.\n\n  Raises:\n    ValueError: if there are multiple image inputs provided with different size\n      or the images are smaller than the crop dimensions.\n  \"\"\"", "\n", "if", "not", "image_list", ":", "\n", "    ", "raise", "ValueError", "(", "'Empty image_list.'", ")", "\n", "\n", "# Compute the rank assertions.", "\n", "", "rank_assertions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "image_list", ")", ")", ":", "\n", "    ", "image_rank", "=", "tf", ".", "rank", "(", "image_list", "[", "i", "]", ")", "\n", "rank_assert", "=", "tf", ".", "Assert", "(", "\n", "tf", ".", "equal", "(", "image_rank", ",", "3", ")", ",", "\n", "[", "'Wrong rank for tensor  %s [expected] [actual]'", ",", "\n", "image_list", "[", "i", "]", ".", "name", ",", "3", ",", "image_rank", "]", ")", "\n", "rank_assertions", ".", "append", "(", "rank_assert", ")", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "[", "rank_assertions", "[", "0", "]", "]", ")", ":", "\n", "    ", "image_shape", "=", "tf", ".", "shape", "(", "image_list", "[", "0", "]", ")", "\n", "", "image_height", "=", "image_shape", "[", "0", "]", "\n", "image_width", "=", "image_shape", "[", "1", "]", "\n", "crop_size_assert", "=", "tf", ".", "Assert", "(", "\n", "tf", ".", "logical_and", "(", "\n", "tf", ".", "greater_equal", "(", "image_height", ",", "crop_height", ")", ",", "\n", "tf", ".", "greater_equal", "(", "image_width", ",", "crop_width", ")", ")", ",", "\n", "[", "'Crop size greater than the image size.'", "]", ")", "\n", "\n", "asserts", "=", "[", "rank_assertions", "[", "0", "]", ",", "crop_size_assert", "]", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "image_list", ")", ")", ":", "\n", "    ", "image", "=", "image_list", "[", "i", "]", "\n", "asserts", ".", "append", "(", "rank_assertions", "[", "i", "]", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "rank_assertions", "[", "i", "]", "]", ")", ":", "\n", "      ", "shape", "=", "tf", ".", "shape", "(", "image", ")", "\n", "", "height", "=", "shape", "[", "0", "]", "\n", "width", "=", "shape", "[", "1", "]", "\n", "\n", "height_assert", "=", "tf", ".", "Assert", "(", "\n", "tf", ".", "equal", "(", "height", ",", "image_height", ")", ",", "\n", "[", "'Wrong height for tensor %s [expected][actual]'", ",", "\n", "image", ".", "name", ",", "height", ",", "image_height", "]", ")", "\n", "width_assert", "=", "tf", ".", "Assert", "(", "\n", "tf", ".", "equal", "(", "width", ",", "image_width", ")", ",", "\n", "[", "'Wrong width for tensor %s [expected][actual]'", ",", "\n", "image", ".", "name", ",", "width", ",", "image_width", "]", ")", "\n", "asserts", ".", "extend", "(", "[", "height_assert", ",", "width_assert", "]", ")", "\n", "\n", "# Create a random bounding box.", "\n", "#", "\n", "# Use tf.random_uniform and not numpy.random.rand as doing the former would", "\n", "# generate random numbers at graph eval time, unlike the latter which", "\n", "# generates random numbers at graph definition time.", "\n", "", "with", "tf", ".", "control_dependencies", "(", "asserts", ")", ":", "\n", "    ", "max_offset_height", "=", "tf", ".", "reshape", "(", "image_height", "-", "crop_height", "+", "1", ",", "[", "]", ")", "\n", "", "with", "tf", ".", "control_dependencies", "(", "asserts", ")", ":", "\n", "    ", "max_offset_width", "=", "tf", ".", "reshape", "(", "image_width", "-", "crop_width", "+", "1", ",", "[", "]", ")", "\n", "", "offset_height", "=", "tf", ".", "random_uniform", "(", "\n", "[", "]", ",", "maxval", "=", "max_offset_height", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "offset_width", "=", "tf", ".", "random_uniform", "(", "\n", "[", "]", ",", "maxval", "=", "max_offset_width", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "return", "[", "_crop", "(", "image", ",", "offset_height", ",", "offset_width", ",", "\n", "crop_height", ",", "crop_width", ")", "for", "image", "in", "image_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._central_crop": [[173, 196], ["outputs.append", "tensorflow.shape", "tensorflow.shape", "vgg_preprocessing._crop"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._crop"], ["", "def", "_central_crop", "(", "image_list", ",", "crop_height", ",", "crop_width", ")", ":", "\n", "  ", "\"\"\"Performs central crops of the given image list.\n\n  Args:\n    image_list: a list of image tensors of the same dimension but possibly\n      varying channel.\n    crop_height: the height of the image following the crop.\n    crop_width: the width of the image following the crop.\n\n  Returns:\n    the list of cropped images.\n  \"\"\"", "\n", "outputs", "=", "[", "]", "\n", "for", "image", "in", "image_list", ":", "\n", "    ", "image_height", "=", "tf", ".", "shape", "(", "image", ")", "[", "0", "]", "\n", "image_width", "=", "tf", ".", "shape", "(", "image", ")", "[", "1", "]", "\n", "\n", "offset_height", "=", "(", "image_height", "-", "crop_height", ")", "/", "2", "\n", "offset_width", "=", "(", "image_width", "-", "crop_width", ")", "/", "2", "\n", "\n", "outputs", ".", "append", "(", "_crop", "(", "image", ",", "offset_height", ",", "offset_width", ",", "\n", "crop_height", ",", "crop_width", ")", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._mean_image_subtraction": [[198, 229], ["tensorflow.split", "range", "tensorflow.concat", "ValueError", "image.get_shape().as_list", "len", "ValueError", "image.get_shape", "image.get_shape"], "function", ["None"], ["", "def", "_mean_image_subtraction", "(", "image", ",", "means", ")", ":", "\n", "  ", "\"\"\"Subtracts the given means from each image channel.\n\n  For example:\n    means = [123.68, 116.779, 103.939]\n    image = _mean_image_subtraction(image, means)\n\n  Note that the rank of `image` must be known.\n\n  Args:\n    image: a tensor of size [height, width, C].\n    means: a C-vector of values to subtract from each channel.\n\n  Returns:\n    the centered image.\n\n  Raises:\n    ValueError: If the rank of `image` is unknown, if `image` has a rank other\n      than three or if the number of channels in `image` doesn't match the\n      number of values in `means`.\n  \"\"\"", "\n", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "!=", "3", ":", "\n", "    ", "raise", "ValueError", "(", "'Input must be of size [height, width, C>0]'", ")", "\n", "", "num_channels", "=", "image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "if", "len", "(", "means", ")", "!=", "num_channels", ":", "\n", "    ", "raise", "ValueError", "(", "'len(means) must match the number of channels'", ")", "\n", "\n", "", "channels", "=", "tf", ".", "split", "(", "axis", "=", "2", ",", "num_or_size_splits", "=", "num_channels", ",", "value", "=", "image", ")", "\n", "for", "i", "in", "range", "(", "num_channels", ")", ":", "\n", "    ", "channels", "[", "i", "]", "-=", "means", "[", "i", "]", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "2", ",", "values", "=", "channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._smallest_size_at_least": [[231, 259], ["tensorflow.convert_to_tensor", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.cond", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.greater"], "function", ["None"], ["", "def", "_smallest_size_at_least", "(", "height", ",", "width", ",", "smallest_side", ")", ":", "\n", "  ", "\"\"\"Computes new shape with the smallest side equal to `smallest_side`.\n\n  Computes new shape with the smallest side equal to `smallest_side` while\n  preserving the original aspect ratio.\n\n  Args:\n    height: an int32 scalar tensor indicating the current height.\n    width: an int32 scalar tensor indicating the current width.\n    smallest_side: A python integer or scalar `Tensor` indicating the size of\n      the smallest side after resize.\n\n  Returns:\n    new_height: an int32 scalar tensor indicating the new height.\n    new_width: and int32 scalar tensor indicating the new width.\n  \"\"\"", "\n", "smallest_side", "=", "tf", ".", "convert_to_tensor", "(", "smallest_side", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "height", "=", "tf", ".", "to_float", "(", "height", ")", "\n", "width", "=", "tf", ".", "to_float", "(", "width", ")", "\n", "smallest_side", "=", "tf", ".", "to_float", "(", "smallest_side", ")", "\n", "\n", "scale", "=", "tf", ".", "cond", "(", "tf", ".", "greater", "(", "height", ",", "width", ")", ",", "\n", "lambda", ":", "smallest_side", "/", "width", ",", "\n", "lambda", ":", "smallest_side", "/", "height", ")", "\n", "new_height", "=", "tf", ".", "to_int32", "(", "height", "*", "scale", ")", "\n", "new_width", "=", "tf", ".", "to_int32", "(", "width", "*", "scale", ")", "\n", "return", "new_height", ",", "new_width", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._aspect_preserving_resize": [[261, 284], ["tensorflow.convert_to_tensor", "tensorflow.shape", "vgg_preprocessing._smallest_size_at_least", "tensorflow.expand_dims", "tensorflow.image.resize_bilinear", "tensorflow.squeeze", "tf.squeeze.set_shape"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._smallest_size_at_least"], ["", "def", "_aspect_preserving_resize", "(", "image", ",", "smallest_side", ")", ":", "\n", "  ", "\"\"\"Resize images preserving the original aspect ratio.\n\n  Args:\n    image: A 3-D image `Tensor`.\n    smallest_side: A python integer or scalar `Tensor` indicating the size of\n      the smallest side after resize.\n\n  Returns:\n    resized_image: A 3-D tensor containing the resized image.\n  \"\"\"", "\n", "smallest_side", "=", "tf", ".", "convert_to_tensor", "(", "smallest_side", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "shape", "=", "tf", ".", "shape", "(", "image", ")", "\n", "height", "=", "shape", "[", "0", "]", "\n", "width", "=", "shape", "[", "1", "]", "\n", "new_height", ",", "new_width", "=", "_smallest_size_at_least", "(", "height", ",", "width", ",", "smallest_side", ")", "\n", "image", "=", "tf", ".", "expand_dims", "(", "image", ",", "0", ")", "\n", "resized_image", "=", "tf", ".", "image", ".", "resize_bilinear", "(", "image", ",", "[", "new_height", ",", "new_width", "]", ",", "\n", "align_corners", "=", "False", ")", "\n", "resized_image", "=", "tf", ".", "squeeze", "(", "resized_image", ")", "\n", "resized_image", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "return", "resized_image", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing.preprocess_for_train": [[286, 317], ["tensorflow.random_uniform", "vgg_preprocessing._aspect_preserving_resize", "tf.image.random_flip_left_right.set_shape", "tensorflow.to_float", "tensorflow.image.random_flip_left_right", "vgg_preprocessing._mean_image_subtraction", "vgg_preprocessing._random_crop"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._aspect_preserving_resize", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._mean_image_subtraction", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._random_crop"], ["", "def", "preprocess_for_train", "(", "image", ",", "\n", "output_height", ",", "\n", "output_width", ",", "\n", "resize_side_min", "=", "_RESIZE_SIDE_MIN", ",", "\n", "resize_side_max", "=", "_RESIZE_SIDE_MAX", ")", ":", "\n", "  ", "\"\"\"Preprocesses the given image for training.\n\n  Note that the actual resizing scale is sampled from\n    [`resize_size_min`, `resize_size_max`].\n\n  Args:\n    image: A `Tensor` representing an image of arbitrary size.\n    output_height: The height of the image after preprocessing.\n    output_width: The width of the image after preprocessing.\n    resize_side_min: The lower bound for the smallest side of the image for\n      aspect-preserving resizing.\n    resize_side_max: The upper bound for the smallest side of the image for\n      aspect-preserving resizing.\n\n  Returns:\n    A preprocessed image.\n  \"\"\"", "\n", "resize_side", "=", "tf", ".", "random_uniform", "(", "\n", "[", "]", ",", "minval", "=", "resize_side_min", ",", "maxval", "=", "resize_side_max", "+", "1", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "image", "=", "_aspect_preserving_resize", "(", "image", ",", "resize_side", ")", "\n", "image", "=", "_random_crop", "(", "[", "image", "]", ",", "output_height", ",", "output_width", ")", "[", "0", "]", "\n", "image", ".", "set_shape", "(", "[", "output_height", ",", "output_width", ",", "3", "]", ")", "\n", "image", "=", "tf", ".", "to_float", "(", "image", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ")", "\n", "return", "_mean_image_subtraction", "(", "image", ",", "[", "_R_MEAN", ",", "_G_MEAN", ",", "_B_MEAN", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing.preprocess_for_eval": [[319, 336], ["vgg_preprocessing._aspect_preserving_resize", "tf.to_float.set_shape", "tensorflow.to_float", "vgg_preprocessing._mean_image_subtraction", "vgg_preprocessing._central_crop"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._aspect_preserving_resize", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._mean_image_subtraction", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing._central_crop"], ["", "def", "preprocess_for_eval", "(", "image", ",", "output_height", ",", "output_width", ",", "resize_side", ")", ":", "\n", "  ", "\"\"\"Preprocesses the given image for evaluation.\n\n  Args:\n    image: A `Tensor` representing an image of arbitrary size.\n    output_height: The height of the image after preprocessing.\n    output_width: The width of the image after preprocessing.\n    resize_side: The smallest side of the image for aspect-preserving resizing.\n\n  Returns:\n    A preprocessed image.\n  \"\"\"", "\n", "image", "=", "_aspect_preserving_resize", "(", "image", ",", "resize_side", ")", "\n", "image", "=", "_central_crop", "(", "[", "image", "]", ",", "output_height", ",", "output_width", ")", "[", "0", "]", "\n", "image", ".", "set_shape", "(", "[", "output_height", ",", "output_width", ",", "3", "]", ")", "\n", "image", "=", "tf", ".", "to_float", "(", "image", ")", "\n", "return", "_mean_image_subtraction", "(", "image", ",", "[", "_R_MEAN", ",", "_G_MEAN", ",", "_B_MEAN", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.vgg_preprocessing.preprocess_image": [[338, 366], ["vgg_preprocessing.preprocess_for_train", "vgg_preprocessing.preprocess_for_eval"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.preprocess_for_train", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.preprocess_for_eval"], ["", "def", "preprocess_image", "(", "image", ",", "output_height", ",", "output_width", ",", "is_training", "=", "False", ",", "\n", "resize_side_min", "=", "_RESIZE_SIDE_MIN", ",", "\n", "resize_side_max", "=", "_RESIZE_SIDE_MAX", ")", ":", "\n", "  ", "\"\"\"Preprocesses the given image.\n\n  Args:\n    image: A `Tensor` representing an image of arbitrary size.\n    output_height: The height of the image after preprocessing.\n    output_width: The width of the image after preprocessing.\n    is_training: `True` if we're preprocessing the image for training and\n      `False` otherwise.\n    resize_side_min: The lower bound for the smallest side of the image for\n      aspect-preserving resizing. If `is_training` is `False`, then this value\n      is used for rescaling.\n    resize_side_max: The upper bound for the smallest side of the image for\n      aspect-preserving resizing. If `is_training` is `False`, this value is\n      ignored. Otherwise, the resize side is sampled from\n        [resize_size_min, resize_size_max].\n\n  Returns:\n    A preprocessed image.\n  \"\"\"", "\n", "if", "is_training", ":", "\n", "    ", "return", "preprocess_for_train", "(", "image", ",", "output_height", ",", "output_width", ",", "\n", "resize_side_min", ",", "resize_side_max", ")", "\n", "", "else", ":", "\n", "    ", "return", "preprocess_for_eval", "(", "image", ",", "output_height", ",", "output_width", ",", "\n", "resize_side_min", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.preprocessing_factory.get_preprocessing": [[31, 74], ["ValueError", "preprocessing_fn_map[].preprocess_image"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.lenet_preprocessing.preprocess_image"], ["def", "get_preprocessing", "(", "name", ",", "is_training", "=", "False", ")", ":", "\n", "  ", "\"\"\"Returns preprocessing_fn(image, height, width, **kwargs).\n\n  Args:\n    name: The name of the preprocessing function.\n    is_training: `True` if the model is being used for training and `False`\n      otherwise.\n\n  Returns:\n    preprocessing_fn: A function that preprocessing a single image (pre-batch).\n      It has the following signature:\n        image = preprocessing_fn(image, output_height, output_width, ...).\n\n  Raises:\n    ValueError: If Preprocessing `name` is not recognized.\n  \"\"\"", "\n", "preprocessing_fn_map", "=", "{", "\n", "'cifarnet'", ":", "cifarnet_preprocessing", ",", "\n", "'inception'", ":", "inception_preprocessing", ",", "\n", "'inception_v1'", ":", "inception_preprocessing", ",", "\n", "'inception_v2'", ":", "inception_preprocessing", ",", "\n", "'inception_v3'", ":", "inception_preprocessing", ",", "\n", "'inception_v4'", ":", "inception_preprocessing", ",", "\n", "'inception_resnet_v2'", ":", "inception_preprocessing", ",", "\n", "'lenet'", ":", "lenet_preprocessing", ",", "\n", "'mobilenet_v1'", ":", "inception_preprocessing", ",", "\n", "'resnet_v1_50'", ":", "vgg_preprocessing", ",", "\n", "'resnet_v1_101'", ":", "vgg_preprocessing", ",", "\n", "'resnet_v1_152'", ":", "vgg_preprocessing", ",", "\n", "'vgg'", ":", "vgg_preprocessing", ",", "\n", "'vgg_a'", ":", "vgg_preprocessing", ",", "\n", "'vgg_16'", ":", "vgg_preprocessing", ",", "\n", "'vgg_19'", ":", "vgg_preprocessing", ",", "\n", "}", "\n", "\n", "if", "name", "not", "in", "preprocessing_fn_map", ":", "\n", "    ", "raise", "ValueError", "(", "'Preprocessing name [%s] was not recognized'", "%", "name", ")", "\n", "\n", "", "def", "preprocessing_fn", "(", "image", ",", "output_height", ",", "output_width", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "preprocessing_fn_map", "[", "name", "]", ".", "preprocess_image", "(", "\n", "image", ",", "output_height", ",", "output_width", ",", "is_training", "=", "is_training", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "preprocessing_fn", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.cifarnet_preprocessing.preprocess_for_train": [[30, 71], ["tensorflow.summary.image", "tensorflow.to_float", "tensorflow.random_crop", "tensorflow.image.random_flip_left_right", "tensorflow.summary.image", "tensorflow.image.random_brightness", "tensorflow.image.random_contrast", "tensorflow.image.per_image_standardization", "tensorflow.expand_dims", "tensorflow.pad", "tensorflow.expand_dims"], "function", ["None"], ["def", "preprocess_for_train", "(", "image", ",", "\n", "output_height", ",", "\n", "output_width", ",", "\n", "padding", "=", "_PADDING", ")", ":", "\n", "  ", "\"\"\"Preprocesses the given image for training.\n\n  Note that the actual resizing scale is sampled from\n    [`resize_size_min`, `resize_size_max`].\n\n  Args:\n    image: A `Tensor` representing an image of arbitrary size.\n    output_height: The height of the image after preprocessing.\n    output_width: The width of the image after preprocessing.\n    padding: The amound of padding before and after each dimension of the image.\n\n  Returns:\n    A preprocessed image.\n  \"\"\"", "\n", "tf", ".", "summary", ".", "image", "(", "'image'", ",", "tf", ".", "expand_dims", "(", "image", ",", "0", ")", ")", "\n", "\n", "# Transform the image to floats.", "\n", "image", "=", "tf", ".", "to_float", "(", "image", ")", "\n", "if", "padding", ">", "0", ":", "\n", "    ", "image", "=", "tf", ".", "pad", "(", "image", ",", "[", "[", "padding", ",", "padding", "]", ",", "[", "padding", ",", "padding", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "# Randomly crop a [height, width] section of the image.", "\n", "", "distorted_image", "=", "tf", ".", "random_crop", "(", "image", ",", "\n", "[", "output_height", ",", "output_width", ",", "3", "]", ")", "\n", "\n", "# Randomly flip the image horizontally.", "\n", "distorted_image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "distorted_image", ")", "\n", "\n", "tf", ".", "summary", ".", "image", "(", "'distorted_image'", ",", "tf", ".", "expand_dims", "(", "distorted_image", ",", "0", ")", ")", "\n", "\n", "# Because these operations are not commutative, consider randomizing", "\n", "# the order their operation.", "\n", "distorted_image", "=", "tf", ".", "image", ".", "random_brightness", "(", "distorted_image", ",", "\n", "max_delta", "=", "63", ")", "\n", "distorted_image", "=", "tf", ".", "image", ".", "random_contrast", "(", "distorted_image", ",", "\n", "lower", "=", "0.2", ",", "upper", "=", "1.8", ")", "\n", "# Subtract off the mean and divide by the variance of the pixels.", "\n", "return", "tf", ".", "image", ".", "per_image_standardization", "(", "distorted_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.cifarnet_preprocessing.preprocess_for_eval": [[73, 96], ["tensorflow.summary.image", "tensorflow.to_float", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.summary.image", "tensorflow.image.per_image_standardization", "tensorflow.expand_dims", "tensorflow.expand_dims"], "function", ["None"], ["", "def", "preprocess_for_eval", "(", "image", ",", "output_height", ",", "output_width", ")", ":", "\n", "  ", "\"\"\"Preprocesses the given image for evaluation.\n\n  Args:\n    image: A `Tensor` representing an image of arbitrary size.\n    output_height: The height of the image after preprocessing.\n    output_width: The width of the image after preprocessing.\n\n  Returns:\n    A preprocessed image.\n  \"\"\"", "\n", "tf", ".", "summary", ".", "image", "(", "'image'", ",", "tf", ".", "expand_dims", "(", "image", ",", "0", ")", ")", "\n", "# Transform the image to floats.", "\n", "image", "=", "tf", ".", "to_float", "(", "image", ")", "\n", "\n", "# Resize and crop if needed.", "\n", "resized_image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "image", ",", "\n", "output_width", ",", "\n", "output_height", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'resized_image'", ",", "tf", ".", "expand_dims", "(", "resized_image", ",", "0", ")", ")", "\n", "\n", "# Subtract off the mean and divide by the variance of the pixels.", "\n", "return", "tf", ".", "image", ".", "per_image_standardization", "(", "resized_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.cifarnet_preprocessing.preprocess_image": [[98, 115], ["cifarnet_preprocessing.preprocess_for_train", "cifarnet_preprocessing.preprocess_for_eval"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.preprocess_for_train", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.preprocess_for_eval"], ["", "def", "preprocess_image", "(", "image", ",", "output_height", ",", "output_width", ",", "is_training", "=", "False", ")", ":", "\n", "  ", "\"\"\"Preprocesses the given image.\n\n  Args:\n    image: A `Tensor` representing an image of arbitrary size.\n    output_height: The height of the image after preprocessing.\n    output_width: The width of the image after preprocessing.\n    is_training: `True` if we're preprocessing the image for training and\n      `False` otherwise.\n\n  Returns:\n    A preprocessed image.\n  \"\"\"", "\n", "if", "is_training", ":", "\n", "    ", "return", "preprocess_for_train", "(", "image", ",", "output_height", ",", "output_width", ")", "\n", "", "else", ":", "\n", "    ", "return", "preprocess_for_eval", "(", "image", ",", "output_height", ",", "output_width", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.apply_with_random_selector": [[26, 43], ["tensorflow.random_uniform", "tensorflow.python.ops.control_flow_ops.merge", "func", "range", "tensorflow.python.ops.control_flow_ops.switch", "tensorflow.equal"], "function", ["None"], ["def", "apply_with_random_selector", "(", "x", ",", "func", ",", "num_cases", ")", ":", "\n", "  ", "\"\"\"Computes func(x, sel), with sel sampled from [0...num_cases-1].\n\n  Args:\n    x: input Tensor.\n    func: Python function to apply.\n    num_cases: Python int32, number of cases to sample sel from.\n\n  Returns:\n    The result of func(x, sel), where func receives the value of the\n    selector as a python integer, but sel is sampled dynamically.\n  \"\"\"", "\n", "sel", "=", "tf", ".", "random_uniform", "(", "[", "]", ",", "maxval", "=", "num_cases", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "# Pass the real x only to one of the func calls.", "\n", "return", "control_flow_ops", ".", "merge", "(", "[", "\n", "func", "(", "control_flow_ops", ".", "switch", "(", "x", ",", "tf", ".", "equal", "(", "sel", ",", "case", ")", ")", "[", "1", "]", ",", "case", ")", "\n", "for", "case", "in", "range", "(", "num_cases", ")", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.distort_color": [[45, 97], ["tensorflow.name_scope", "tensorflow.clip_by_value", "tensorflow.image.random_brightness", "tensorflow.image.random_saturation", "tensorflow.image.random_saturation", "tensorflow.image.random_brightness", "tensorflow.image.random_brightness", "tensorflow.image.random_saturation", "tensorflow.image.random_hue", "tensorflow.image.random_contrast", "tensorflow.image.random_saturation", "tensorflow.image.random_brightness", "tensorflow.image.random_contrast", "tensorflow.image.random_hue", "tensorflow.image.random_contrast", "tensorflow.image.random_hue", "tensorflow.image.random_brightness", "tensorflow.image.random_saturation", "tensorflow.image.random_hue", "tensorflow.image.random_saturation", "tensorflow.image.random_contrast", "tensorflow.image.random_brightness", "ValueError"], "function", ["None"], ["", "def", "distort_color", "(", "image", ",", "color_ordering", "=", "0", ",", "fast_mode", "=", "True", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Distort the color of a Tensor image.\n\n  Each color distortion is non-commutative and thus ordering of the color ops\n  matters. Ideally we would randomly permute the ordering of the color ops.\n  Rather then adding that level of complication, we select a distinct ordering\n  of color ops for each preprocessing thread.\n\n  Args:\n    image: 3-D Tensor containing single image in [0, 1].\n    color_ordering: Python int, a type of distortion (valid values: 0-3).\n    fast_mode: Avoids slower ops (random_hue and random_contrast)\n    scope: Optional scope for name_scope.\n  Returns:\n    3-D Tensor color-distorted image on range [0, 1]\n  Raises:\n    ValueError: if color_ordering not in [0, 3]\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "scope", ",", "'distort_color'", ",", "[", "image", "]", ")", ":", "\n", "    ", "if", "fast_mode", ":", "\n", "      ", "if", "color_ordering", "==", "0", ":", "\n", "        ", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "32.", "/", "255.", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "", "else", ":", "\n", "        ", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "32.", "/", "255.", ")", "\n", "", "", "else", ":", "\n", "      ", "if", "color_ordering", "==", "0", ":", "\n", "        ", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "32.", "/", "255.", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_hue", "(", "image", ",", "max_delta", "=", "0.2", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "", "elif", "color_ordering", "==", "1", ":", "\n", "        ", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "32.", "/", "255.", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_hue", "(", "image", ",", "max_delta", "=", "0.2", ")", "\n", "", "elif", "color_ordering", "==", "2", ":", "\n", "        ", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_hue", "(", "image", ",", "max_delta", "=", "0.2", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "32.", "/", "255.", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "", "elif", "color_ordering", "==", "3", ":", "\n", "        ", "image", "=", "tf", ".", "image", ".", "random_hue", "(", "image", ",", "max_delta", "=", "0.2", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "32.", "/", "255.", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'color_ordering must be in [0, 3]'", ")", "\n", "\n", "# The random_* ops do not necessarily clamp.", "\n", "", "", "return", "tf", ".", "clip_by_value", "(", "image", ",", "0.0", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.distorted_bounding_box_crop": [[99, 154], ["tensorflow.name_scope", "tensorflow.image.sample_distorted_bounding_box", "tensorflow.slice", "tensorflow.shape"], "function", ["None"], ["", "", "def", "distorted_bounding_box_crop", "(", "image", ",", "\n", "bbox", ",", "\n", "min_object_covered", "=", "0.1", ",", "\n", "aspect_ratio_range", "=", "(", "0.75", ",", "1.33", ")", ",", "\n", "area_range", "=", "(", "0.05", ",", "1.0", ")", ",", "\n", "max_attempts", "=", "100", ",", "\n", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Generates cropped_image using a one of the bboxes randomly distorted.\n\n  See `tf.image.sample_distorted_bounding_box` for more documentation.\n\n  Args:\n    image: 3-D Tensor of image (it will be converted to floats in [0, 1]).\n    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n      where each coordinate is [0, 1) and the coordinates are arranged\n      as [ymin, xmin, ymax, xmax]. If num_boxes is 0 then it would use the whole\n      image.\n    min_object_covered: An optional `float`. Defaults to `0.1`. The cropped\n      area of the image must contain at least this fraction of any bounding box\n      supplied.\n    aspect_ratio_range: An optional list of `floats`. The cropped area of the\n      image must have an aspect ratio = width / height within this range.\n    area_range: An optional list of `floats`. The cropped area of the image\n      must contain a fraction of the supplied image within in this range.\n    max_attempts: An optional `int`. Number of attempts at generating a cropped\n      region of the image of the specified constraints. After `max_attempts`\n      failures, return the entire image.\n    scope: Optional scope for name_scope.\n  Returns:\n    A tuple, a 3-D Tensor cropped_image and the distorted bbox\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "scope", ",", "'distorted_bounding_box_crop'", ",", "[", "image", ",", "bbox", "]", ")", ":", "\n", "# Each bounding box has shape [1, num_boxes, box coords] and", "\n", "# the coordinates are ordered [ymin, xmin, ymax, xmax].", "\n", "\n", "# A large fraction of image datasets contain a human-annotated bounding", "\n", "# box delineating the region of the image containing the object of interest.", "\n", "# We choose to create a new bounding box for the object which is a randomly", "\n", "# distorted version of the human-annotated bounding box that obeys an", "\n", "# allowed range of aspect ratios, sizes and overlap with the human-annotated", "\n", "# bounding box. If no box is supplied, then we assume the bounding box is", "\n", "# the entire image.", "\n", "    ", "sample_distorted_bounding_box", "=", "tf", ".", "image", ".", "sample_distorted_bounding_box", "(", "\n", "tf", ".", "shape", "(", "image", ")", ",", "\n", "bounding_boxes", "=", "bbox", ",", "\n", "min_object_covered", "=", "min_object_covered", ",", "\n", "aspect_ratio_range", "=", "aspect_ratio_range", ",", "\n", "area_range", "=", "area_range", ",", "\n", "max_attempts", "=", "max_attempts", ",", "\n", "use_image_if_no_bounding_boxes", "=", "True", ")", "\n", "bbox_begin", ",", "bbox_size", ",", "distort_bbox", "=", "sample_distorted_bounding_box", "\n", "\n", "# Crop the image to the specified bounding box.", "\n", "cropped_image", "=", "tf", ".", "slice", "(", "image", ",", "bbox_begin", ",", "bbox_size", ")", "\n", "return", "cropped_image", ",", "distort_bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.preprocess_for_train": [[156, 235], ["tensorflow.name_scope", "tensorflow.image.draw_bounding_boxes", "tensorflow.summary.image", "inception_preprocessing.distorted_bounding_box_crop", "tf.multiply.set_shape", "tensorflow.image.draw_bounding_boxes", "tensorflow.summary.image", "inception_preprocessing.apply_with_random_selector", "tensorflow.summary.image", "tensorflow.image.random_flip_left_right", "inception_preprocessing.apply_with_random_selector", "tensorflow.summary.image", "tensorflow.subtract", "tensorflow.multiply", "tensorflow.constant", "tensorflow.image.convert_image_dtype", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.image.resize_images", "inception_preprocessing.distort_color"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.distorted_bounding_box_crop", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.apply_with_random_selector", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.apply_with_random_selector", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.distort_color"], ["", "", "def", "preprocess_for_train", "(", "image", ",", "height", ",", "width", ",", "bbox", ",", "\n", "fast_mode", "=", "True", ",", "\n", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Distort one image for training a network.\n\n  Distorting images provides a useful technique for augmenting the data\n  set during training in order to make the network invariant to aspects\n  of the image that do not effect the label.\n\n  Additionally it would create image_summaries to display the different\n  transformations applied to the image.\n\n  Args:\n    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be\n      [0, 1], otherwise it would converted to tf.float32 assuming that the range\n      is [0, MAX], where MAX is largest positive representable number for\n      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details).\n    height: integer\n    width: integer\n    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n      where each coordinate is [0, 1) and the coordinates are arranged\n      as [ymin, xmin, ymax, xmax].\n    fast_mode: Optional boolean, if True avoids slower transformations (i.e.\n      bi-cubic resizing, random_hue or random_contrast).\n    scope: Optional scope for name_scope.\n  Returns:\n    3-D float Tensor of distorted image used for training with range [-1, 1].\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "scope", ",", "'distort_image'", ",", "[", "image", ",", "height", ",", "width", ",", "bbox", "]", ")", ":", "\n", "    ", "if", "bbox", "is", "None", ":", "\n", "      ", "bbox", "=", "tf", ".", "constant", "(", "[", "0.0", ",", "0.0", ",", "1.0", ",", "1.0", "]", ",", "\n", "dtype", "=", "tf", ".", "float32", ",", "\n", "shape", "=", "[", "1", ",", "1", ",", "4", "]", ")", "\n", "", "if", "image", ".", "dtype", "!=", "tf", ".", "float32", ":", "\n", "      ", "image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Each bounding box has shape [1, num_boxes, box coords] and", "\n", "# the coordinates are ordered [ymin, xmin, ymax, xmax].", "\n", "", "image_with_box", "=", "tf", ".", "image", ".", "draw_bounding_boxes", "(", "tf", ".", "expand_dims", "(", "image", ",", "0", ")", ",", "\n", "bbox", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'image_with_bounding_boxes'", ",", "image_with_box", ")", "\n", "\n", "distorted_image", ",", "distorted_bbox", "=", "distorted_bounding_box_crop", "(", "image", ",", "bbox", ")", "\n", "# Restore the shape since the dynamic slice based upon the bbox_size loses", "\n", "# the third dimension.", "\n", "distorted_image", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "image_with_distorted_box", "=", "tf", ".", "image", ".", "draw_bounding_boxes", "(", "\n", "tf", ".", "expand_dims", "(", "image", ",", "0", ")", ",", "distorted_bbox", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'images_with_distorted_bounding_box'", ",", "\n", "image_with_distorted_box", ")", "\n", "\n", "# This resizing operation may distort the images because the aspect", "\n", "# ratio is not respected. We select a resize method in a round robin", "\n", "# fashion based on the thread number.", "\n", "# Note that ResizeMethod contains 4 enumerated resizing methods.", "\n", "\n", "# We select only 1 case for fast_mode bilinear.", "\n", "num_resize_cases", "=", "1", "if", "fast_mode", "else", "4", "\n", "distorted_image", "=", "apply_with_random_selector", "(", "\n", "distorted_image", ",", "\n", "lambda", "x", ",", "method", ":", "tf", ".", "image", ".", "resize_images", "(", "x", ",", "[", "height", ",", "width", "]", ",", "method", "=", "method", ")", ",", "\n", "num_cases", "=", "num_resize_cases", ")", "\n", "\n", "tf", ".", "summary", ".", "image", "(", "'cropped_resized_image'", ",", "\n", "tf", ".", "expand_dims", "(", "distorted_image", ",", "0", ")", ")", "\n", "\n", "# Randomly flip the image horizontally.", "\n", "distorted_image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "distorted_image", ")", "\n", "\n", "# Randomly distort the colors. There are 4 ways to do it.", "\n", "distorted_image", "=", "apply_with_random_selector", "(", "\n", "distorted_image", ",", "\n", "lambda", "x", ",", "ordering", ":", "distort_color", "(", "x", ",", "ordering", ",", "fast_mode", ")", ",", "\n", "num_cases", "=", "4", ")", "\n", "\n", "tf", ".", "summary", ".", "image", "(", "'final_distorted_image'", ",", "\n", "tf", ".", "expand_dims", "(", "distorted_image", ",", "0", ")", ")", "\n", "distorted_image", "=", "tf", ".", "subtract", "(", "distorted_image", ",", "0.5", ")", "\n", "distorted_image", "=", "tf", ".", "multiply", "(", "distorted_image", ",", "2.0", ")", "\n", "return", "distorted_image", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.preprocess_for_eval": [[237, 276], ["tensorflow.name_scope", "tensorflow.subtract", "tensorflow.multiply", "tensorflow.image.convert_image_dtype", "tensorflow.image.central_crop", "tensorflow.expand_dims", "tensorflow.image.resize_bilinear", "tensorflow.squeeze"], "function", ["None"], ["", "", "def", "preprocess_for_eval", "(", "image", ",", "height", ",", "width", ",", "\n", "central_fraction", "=", "0.875", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Prepare one image for evaluation.\n\n  If height and width are specified it would output an image with that size by\n  applying resize_bilinear.\n\n  If central_fraction is specified it would crop the central fraction of the\n  input image.\n\n  Args:\n    image: 3-D Tensor of image. If dtype is tf.float32 then the range should be\n      [0, 1], otherwise it would converted to tf.float32 assuming that the range\n      is [0, MAX], where MAX is largest positive representable number for\n      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details)\n    height: integer\n    width: integer\n    central_fraction: Optional Float, fraction of the image to crop.\n    scope: Optional scope for name_scope.\n  Returns:\n    3-D float Tensor of prepared image.\n  \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "scope", ",", "'eval_image'", ",", "[", "image", ",", "height", ",", "width", "]", ")", ":", "\n", "    ", "if", "image", ".", "dtype", "!=", "tf", ".", "float32", ":", "\n", "      ", "image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Crop the central region of the image with an area containing 87.5% of", "\n", "# the original image.", "\n", "", "if", "central_fraction", ":", "\n", "      ", "image", "=", "tf", ".", "image", ".", "central_crop", "(", "image", ",", "central_fraction", "=", "central_fraction", ")", "\n", "\n", "", "if", "height", "and", "width", ":", "\n", "# Resize the image to the specified height and width.", "\n", "      ", "image", "=", "tf", ".", "expand_dims", "(", "image", ",", "0", ")", "\n", "image", "=", "tf", ".", "image", ".", "resize_bilinear", "(", "image", ",", "[", "height", ",", "width", "]", ",", "\n", "align_corners", "=", "False", ")", "\n", "image", "=", "tf", ".", "squeeze", "(", "image", ",", "[", "0", "]", ")", "\n", "", "image", "=", "tf", ".", "subtract", "(", "image", ",", "0.5", ")", "\n", "image", "=", "tf", ".", "multiply", "(", "image", ",", "2.0", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.preprocess_image": [[278, 305], ["inception_preprocessing.preprocess_for_train", "inception_preprocessing.preprocess_for_eval"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.preprocess_for_train", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.inception_preprocessing.preprocess_for_eval"], ["", "", "def", "preprocess_image", "(", "image", ",", "height", ",", "width", ",", "\n", "is_training", "=", "False", ",", "\n", "bbox", "=", "None", ",", "\n", "fast_mode", "=", "True", ")", ":", "\n", "  ", "\"\"\"Pre-process one image for training or evaluation.\n\n  Args:\n    image: 3-D Tensor [height, width, channels] with the image.\n    height: integer, image expected height.\n    width: integer, image expected width.\n    is_training: Boolean. If true it would transform an image for train,\n      otherwise it would transform it for evaluation.\n    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]\n      where each coordinate is [0, 1) and the coordinates are arranged as\n      [ymin, xmin, ymax, xmax].\n    fast_mode: Optional boolean, if True avoids slower transformations.\n\n  Returns:\n    3-D float Tensor containing an appropriately scaled image\n\n  Raises:\n    ValueError: if user does not provide bounding box\n  \"\"\"", "\n", "if", "is_training", ":", "\n", "    ", "return", "preprocess_for_train", "(", "image", ",", "height", ",", "width", ",", "bbox", ",", "fast_mode", ")", "\n", "", "else", ":", "\n", "    ", "return", "preprocess_for_eval", "(", "image", ",", "height", ",", "width", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.preprocessing.lenet_preprocessing.preprocess_image": [[26, 45], ["tensorflow.to_float", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.subtract", "tensorflow.div"], "function", ["None"], ["def", "preprocess_image", "(", "image", ",", "output_height", ",", "output_width", ",", "is_training", ")", ":", "\n", "  ", "\"\"\"Preprocesses the given image.\n\n  Args:\n    image: A `Tensor` representing an image of arbitrary size.\n    output_height: The height of the image after preprocessing.\n    output_width: The width of the image after preprocessing.\n    is_training: `True` if we're preprocessing the image for training and\n      `False` otherwise.\n\n  Returns:\n    A preprocessed image.\n  \"\"\"", "\n", "image", "=", "tf", ".", "to_float", "(", "image", ")", "\n", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "\n", "image", ",", "output_width", ",", "output_height", ")", "\n", "image", "=", "tf", ".", "subtract", "(", "image", ",", "128.0", ")", "\n", "image", "=", "tf", ".", "div", "(", "image", ",", "128.0", ")", "\n", "return", "image", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeploymentConfigTest.testDefaults": [[31, 41], ["deployment.model_deploy.DeploymentConfig", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "slim.get_variables", "deployment.model_deploy.DeploymentConfig.caching_device", "deployment.model_deploy.DeploymentConfig.clone_device", "deployment.model_deploy.DeploymentConfig.clone_scope", "deployment.model_deploy.DeploymentConfig.optimizer_device", "deployment.model_deploy.DeploymentConfig.inputs_device", "deployment.model_deploy.DeploymentConfig.variables_device"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.caching_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.optimizer_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.inputs_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.variables_device"], ["  ", "def", "testDefaults", "(", "self", ")", ":", "\n", "    ", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "caching_device", "(", ")", ",", "None", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "clone_device", "(", "0", ")", ",", "'GPU:0'", ")", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "clone_scope", "(", "0", ")", ",", "''", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "optimizer_device", "(", ")", ",", "'CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "inputs_device", "(", ")", ",", "'CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "variables_device", "(", ")", ",", "'CPU:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeploymentConfigTest.testCPUonly": [[42, 51], ["deployment.model_deploy.DeploymentConfig", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "deployment.model_deploy.DeploymentConfig.caching_device", "deployment.model_deploy.DeploymentConfig.clone_device", "deployment.model_deploy.DeploymentConfig.clone_scope", "deployment.model_deploy.DeploymentConfig.optimizer_device", "deployment.model_deploy.DeploymentConfig.inputs_device", "deployment.model_deploy.DeploymentConfig.variables_device"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.caching_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.optimizer_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.inputs_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.variables_device"], ["", "def", "testCPUonly", "(", "self", ")", ":", "\n", "    ", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "clone_on_cpu", "=", "True", ")", "\n", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "caching_device", "(", ")", ",", "None", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "clone_device", "(", "0", ")", ",", "'CPU:0'", ")", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "clone_scope", "(", "0", ")", ",", "''", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "optimizer_device", "(", ")", ",", "'CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "inputs_device", "(", ")", ",", "'CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "variables_device", "(", ")", ",", "'CPU:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeploymentConfigTest.testMultiGPU": [[52, 63], ["deployment.model_deploy.DeploymentConfig", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "deployment.model_deploy.DeploymentConfig.caching_device", "deployment.model_deploy.DeploymentConfig.clone_device", "deployment.model_deploy.DeploymentConfig.clone_device", "deployment.model_deploy.DeploymentConfig.clone_scope", "deployment.model_deploy.DeploymentConfig.clone_scope", "deployment.model_deploy.DeploymentConfig.optimizer_device", "deployment.model_deploy.DeploymentConfig.inputs_device", "deployment.model_deploy.DeploymentConfig.variables_device"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.caching_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.optimizer_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.inputs_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.variables_device"], ["", "def", "testMultiGPU", "(", "self", ")", ":", "\n", "    ", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "2", ")", "\n", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "caching_device", "(", ")", ",", "None", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "clone_device", "(", "0", ")", ",", "'GPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "clone_device", "(", "1", ")", ",", "'GPU:1'", ")", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "clone_scope", "(", "0", ")", ",", "'clone_0'", ")", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "clone_scope", "(", "1", ")", ",", "'clone_1'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "optimizer_device", "(", ")", ",", "'CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "inputs_device", "(", ")", ",", "'CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "variables_device", "(", ")", ",", "'CPU:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeploymentConfigTest.testPS": [[64, 87], ["deployment.model_deploy.DeploymentConfig", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "deployment.model_deploy.DeploymentConfig.clone_device", "deployment.model_deploy.DeploymentConfig.clone_scope", "deployment.model_deploy.DeploymentConfig.optimizer_device", "deployment.model_deploy.DeploymentConfig.inputs_device", "tensorflow.device", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.no_op", "slim.variable", "deployment.model_deploy.DeploymentConfig.variables_device", "tensorflow.Variable.value", "tensorflow.Variable.value", "slim.variable.value", "deployment.model_deploy.DeploymentConfig.caching_device"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.optimizer_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.inputs_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.variables_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.caching_device"], ["", "def", "testPS", "(", "self", ")", ":", "\n", "    ", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "1", ",", "num_ps_tasks", "=", "1", ")", "\n", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "clone_device", "(", "0", ")", ",", "\n", "'/job:worker/device:GPU:0'", ")", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "clone_scope", "(", "0", ")", ",", "''", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "optimizer_device", "(", ")", ",", "\n", "'/job:worker/device:CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "inputs_device", "(", ")", ",", "\n", "'/job:worker/device:CPU:0'", ")", "\n", "with", "tf", ".", "device", "(", "deploy_config", ".", "variables_device", "(", ")", ")", ":", "\n", "      ", "a", "=", "tf", ".", "Variable", "(", "0", ")", "\n", "b", "=", "tf", ".", "Variable", "(", "0", ")", "\n", "c", "=", "tf", ".", "no_op", "(", ")", "\n", "d", "=", "slim", ".", "variable", "(", "'a'", ",", "[", "]", ",", "\n", "caching_device", "=", "deploy_config", ".", "caching_device", "(", ")", ")", "\n", "", "self", ".", "assertDeviceEqual", "(", "a", ".", "device", ",", "'/job:ps/task:0/device:CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "a", ".", "device", ",", "a", ".", "value", "(", ")", ".", "device", ")", "\n", "self", ".", "assertDeviceEqual", "(", "b", ".", "device", ",", "'/job:ps/task:0/device:CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "b", ".", "device", ",", "b", ".", "value", "(", ")", ".", "device", ")", "\n", "self", ".", "assertDeviceEqual", "(", "c", ".", "device", ",", "''", ")", "\n", "self", ".", "assertDeviceEqual", "(", "d", ".", "device", ",", "'/job:ps/task:0/device:CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "d", ".", "value", "(", ")", ".", "device", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeploymentConfigTest.testMultiGPUPS": [[88, 102], ["deployment.model_deploy.DeploymentConfig", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "deployment.model_deploy.DeploymentConfig.clone_device", "deployment.model_deploy.DeploymentConfig.clone_device", "deployment.model_deploy.DeploymentConfig.clone_scope", "deployment.model_deploy.DeploymentConfig.clone_scope", "deployment.model_deploy.DeploymentConfig.optimizer_device", "deployment.model_deploy.DeploymentConfig.inputs_device", "deployment.model_deploy.DeploymentConfig.caching_device", "tensorflow.no_op"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.optimizer_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.inputs_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.caching_device"], ["", "def", "testMultiGPUPS", "(", "self", ")", ":", "\n", "    ", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "2", ",", "num_ps_tasks", "=", "1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "caching_device", "(", ")", "(", "tf", ".", "no_op", "(", ")", ")", ",", "''", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "clone_device", "(", "0", ")", ",", "\n", "'/job:worker/device:GPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "clone_device", "(", "1", ")", ",", "\n", "'/job:worker/device:GPU:1'", ")", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "clone_scope", "(", "0", ")", ",", "'clone_0'", ")", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "clone_scope", "(", "1", ")", ",", "'clone_1'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "optimizer_device", "(", ")", ",", "\n", "'/job:worker/device:CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "inputs_device", "(", ")", ",", "\n", "'/job:worker/device:CPU:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeploymentConfigTest.testReplicasPS": [[103, 114], ["deployment.model_deploy.DeploymentConfig", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "deployment.model_deploy.DeploymentConfig.clone_device", "deployment.model_deploy.DeploymentConfig.clone_scope", "deployment.model_deploy.DeploymentConfig.optimizer_device", "deployment.model_deploy.DeploymentConfig.inputs_device"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.optimizer_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.inputs_device"], ["", "def", "testReplicasPS", "(", "self", ")", ":", "\n", "    ", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_replicas", "=", "2", ",", "\n", "num_ps_tasks", "=", "2", ")", "\n", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "clone_device", "(", "0", ")", ",", "\n", "'/job:worker/device:GPU:0'", ")", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "clone_scope", "(", "0", ")", ",", "''", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "optimizer_device", "(", ")", ",", "\n", "'/job:worker/device:CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "inputs_device", "(", ")", ",", "\n", "'/job:worker/device:CPU:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeploymentConfigTest.testReplicasMultiGPUPS": [[115, 129], ["deployment.model_deploy.DeploymentConfig", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "deployment.model_deploy.DeploymentConfig.clone_device", "deployment.model_deploy.DeploymentConfig.clone_device", "deployment.model_deploy.DeploymentConfig.clone_scope", "deployment.model_deploy.DeploymentConfig.clone_scope", "deployment.model_deploy.DeploymentConfig.optimizer_device", "deployment.model_deploy.DeploymentConfig.inputs_device"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.optimizer_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.inputs_device"], ["", "def", "testReplicasMultiGPUPS", "(", "self", ")", ":", "\n", "    ", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_replicas", "=", "2", ",", "\n", "num_clones", "=", "2", ",", "\n", "num_ps_tasks", "=", "2", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "clone_device", "(", "0", ")", ",", "\n", "'/job:worker/device:GPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "clone_device", "(", "1", ")", ",", "\n", "'/job:worker/device:GPU:1'", ")", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "clone_scope", "(", "0", ")", ",", "'clone_0'", ")", "\n", "self", ".", "assertEqual", "(", "deploy_config", ".", "clone_scope", "(", "1", ")", ",", "'clone_1'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "optimizer_device", "(", ")", ",", "\n", "'/job:worker/device:CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "deploy_config", ".", "inputs_device", "(", ")", ",", "\n", "'/job:worker/device:CPU:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeploymentConfigTest.testVariablesPS": [[130, 147], ["deployment.model_deploy.DeploymentConfig", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "model_deploy_test.DeploymentConfigTest.assertDeviceEqual", "tensorflow.device", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.no_op", "slim.variable", "deployment.model_deploy.DeploymentConfig.variables_device", "tensorflow.Variable.value", "tensorflow.Variable.value", "slim.variable.value", "deployment.model_deploy.DeploymentConfig.caching_device"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.variables_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.caching_device"], ["", "def", "testVariablesPS", "(", "self", ")", ":", "\n", "    ", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_ps_tasks", "=", "2", ")", "\n", "\n", "with", "tf", ".", "device", "(", "deploy_config", ".", "variables_device", "(", ")", ")", ":", "\n", "      ", "a", "=", "tf", ".", "Variable", "(", "0", ")", "\n", "b", "=", "tf", ".", "Variable", "(", "0", ")", "\n", "c", "=", "tf", ".", "no_op", "(", ")", "\n", "d", "=", "slim", ".", "variable", "(", "'a'", ",", "[", "]", ",", "\n", "caching_device", "=", "deploy_config", ".", "caching_device", "(", ")", ")", "\n", "\n", "", "self", ".", "assertDeviceEqual", "(", "a", ".", "device", ",", "'/job:ps/task:0/device:CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "a", ".", "device", ",", "a", ".", "value", "(", ")", ".", "device", ")", "\n", "self", ".", "assertDeviceEqual", "(", "b", ".", "device", ",", "'/job:ps/task:1/device:CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "b", ".", "device", ",", "b", ".", "value", "(", ")", ".", "device", ")", "\n", "self", ".", "assertDeviceEqual", "(", "c", ".", "device", ",", "''", ")", "\n", "self", ".", "assertDeviceEqual", "(", "d", ".", "device", ",", "'/job:ps/task:0/device:CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "d", ".", "value", "(", ")", ".", "device", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.CreatecloneTest.setUp": [[171, 182], ["numpy.random.seed", "numpy.zeros", "numpy.random.randint().astype", "model_deploy_test.CreatecloneTest.get_temp_dir", "range", "int", "numpy.random.randint", "numpy.random.randint"], "methods", ["None"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "# Create an easy training set:", "\n", "    ", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "\n", "self", ".", "_inputs", "=", "np", ".", "zeros", "(", "(", "16", ",", "4", ")", ")", "\n", "self", ".", "_labels", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "size", "=", "(", "16", ",", "1", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "_logdir", "=", "self", ".", "get_temp_dir", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "16", ")", ":", "\n", "      ", "j", "=", "int", "(", "2", "*", "self", ".", "_labels", "[", "i", "]", "+", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ")", ")", "\n", "self", ".", "_inputs", "[", "i", ",", "j", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.CreatecloneTest.testCreateLogisticClassifier": [[183, 208], ["tensorflow.Graph", "tensorflow.Graph.as_default", "tensorflow.set_random_seed", "tensorflow.constant", "tensorflow.constant", "deployment.model_deploy.DeploymentConfig", "model_deploy_test.CreatecloneTest.assertEqual", "deployment.model_deploy.create_clones", "model_deploy_test.CreatecloneTest.assertEqual", "slim.get_variables", "model_deploy_test.CreatecloneTest.assertEqual", "model_deploy_test.CreatecloneTest.assertEqual", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "model_deploy_test.CreatecloneTest.assertEqual", "tensorflow.get_collection", "model_deploy_test.CreatecloneTest.assertEqual", "slim.get_variables", "len", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "len", "slim.get_variables", "slim.losses.get_losses", "v.value"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones"], ["", "", "def", "testCreateLogisticClassifier", "(", "self", ")", ":", "\n", "    ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "self", ".", "_inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf_labels", "=", "tf", ".", "constant", "(", "self", ".", "_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "model_fn", "=", "LogisticClassifier", "\n", "clone_args", "=", "(", "tf_inputs", ",", "tf_labels", ")", "\n", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "clones", "=", "model_deploy", ".", "create_clones", "(", "deploy_config", ",", "model_fn", ",", "clone_args", ")", "\n", "clone", "=", "clones", "[", "0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "get_variables", "(", ")", ")", ",", "2", ")", "\n", "for", "v", "in", "slim", ".", "get_variables", "(", ")", ":", "\n", "        ", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "v", ".", "value", "(", ")", ".", "device", ",", "'CPU:0'", ")", "\n", "", "self", ".", "assertEqual", "(", "clone", ".", "outputs", ".", "op", ".", "name", ",", "\n", "'LogisticClassifier/fully_connected/Sigmoid'", ")", "\n", "self", ".", "assertEqual", "(", "clone", ".", "scope", ",", "''", ")", "\n", "self", ".", "assertDeviceEqual", "(", "clone", ".", "device", ",", "'GPU:0'", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "losses", ".", "get_losses", "(", ")", ")", ",", "1", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "assertEqual", "(", "update_ops", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.CreatecloneTest.testCreateSingleclone": [[209, 234], ["tensorflow.Graph", "tensorflow.Graph.as_default", "tensorflow.set_random_seed", "tensorflow.constant", "tensorflow.constant", "deployment.model_deploy.DeploymentConfig", "model_deploy_test.CreatecloneTest.assertEqual", "deployment.model_deploy.create_clones", "model_deploy_test.CreatecloneTest.assertEqual", "slim.get_variables", "model_deploy_test.CreatecloneTest.assertEqual", "model_deploy_test.CreatecloneTest.assertEqual", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "model_deploy_test.CreatecloneTest.assertEqual", "tensorflow.get_collection", "model_deploy_test.CreatecloneTest.assertEqual", "slim.get_variables", "len", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "len", "len", "slim.get_variables", "slim.losses.get_losses", "v.value"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones"], ["", "", "def", "testCreateSingleclone", "(", "self", ")", ":", "\n", "    ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "self", ".", "_inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf_labels", "=", "tf", ".", "constant", "(", "self", ".", "_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "model_fn", "=", "BatchNormClassifier", "\n", "clone_args", "=", "(", "tf_inputs", ",", "tf_labels", ")", "\n", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "clones", "=", "model_deploy", ".", "create_clones", "(", "deploy_config", ",", "model_fn", ",", "clone_args", ")", "\n", "clone", "=", "clones", "[", "0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "get_variables", "(", ")", ")", ",", "5", ")", "\n", "for", "v", "in", "slim", ".", "get_variables", "(", ")", ":", "\n", "        ", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "v", ".", "value", "(", ")", ".", "device", ",", "'CPU:0'", ")", "\n", "", "self", ".", "assertEqual", "(", "clone", ".", "outputs", ".", "op", ".", "name", ",", "\n", "'BatchNormClassifier/fully_connected/Sigmoid'", ")", "\n", "self", ".", "assertEqual", "(", "clone", ".", "scope", ",", "''", ")", "\n", "self", ".", "assertDeviceEqual", "(", "clone", ".", "device", ",", "'GPU:0'", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "losses", ".", "get_losses", "(", ")", ")", ",", "1", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "update_ops", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.CreatecloneTest.testCreateMulticlone": [[235, 262], ["tensorflow.Graph", "tensorflow.Graph.as_default", "tensorflow.set_random_seed", "tensorflow.constant", "tensorflow.constant", "deployment.model_deploy.DeploymentConfig", "model_deploy_test.CreatecloneTest.assertEqual", "deployment.model_deploy.create_clones", "model_deploy_test.CreatecloneTest.assertEqual", "slim.get_variables", "model_deploy_test.CreatecloneTest.assertEqual", "enumerate", "slim.get_variables", "len", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "len", "model_deploy_test.CreatecloneTest.assertEqual", "tensorflow.get_collection", "model_deploy_test.CreatecloneTest.assertEqual", "model_deploy_test.CreatecloneTest.assertEqual", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "slim.get_variables", "len", "v.value"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones"], ["", "", "def", "testCreateMulticlone", "(", "self", ")", ":", "\n", "    ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "self", ".", "_inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf_labels", "=", "tf", ".", "constant", "(", "self", ".", "_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "model_fn", "=", "BatchNormClassifier", "\n", "clone_args", "=", "(", "tf_inputs", ",", "tf_labels", ")", "\n", "num_clones", "=", "4", "\n", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "num_clones", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "clones", "=", "model_deploy", ".", "create_clones", "(", "deploy_config", ",", "model_fn", ",", "clone_args", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "get_variables", "(", ")", ")", ",", "5", ")", "\n", "for", "v", "in", "slim", ".", "get_variables", "(", ")", ":", "\n", "        ", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "v", ".", "value", "(", ")", ".", "device", ",", "'CPU:0'", ")", "\n", "", "self", ".", "assertEqual", "(", "len", "(", "clones", ")", ",", "num_clones", ")", "\n", "for", "i", ",", "clone", "in", "enumerate", "(", "clones", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "\n", "clone", ".", "outputs", ".", "op", ".", "name", ",", "\n", "'clone_%d/BatchNormClassifier/fully_connected/Sigmoid'", "%", "i", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "clone", ".", "scope", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "update_ops", ")", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "clone", ".", "scope", ",", "'clone_%d/'", "%", "i", ")", "\n", "self", ".", "assertDeviceEqual", "(", "clone", ".", "device", ",", "'GPU:%d'", "%", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.CreatecloneTest.testCreateOnecloneWithPS": [[263, 287], ["tensorflow.Graph", "tensorflow.Graph.as_default", "tensorflow.set_random_seed", "tensorflow.constant", "tensorflow.constant", "deployment.model_deploy.DeploymentConfig", "model_deploy_test.CreatecloneTest.assertEqual", "deployment.model_deploy.create_clones", "model_deploy_test.CreatecloneTest.assertEqual", "model_deploy_test.CreatecloneTest.assertEqual", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "model_deploy_test.CreatecloneTest.assertEqual", "model_deploy_test.CreatecloneTest.assertEqual", "slim.get_variables", "slim.get_variables", "len", "len", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "slim.get_variables", "v.value"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones"], ["", "", "", "def", "testCreateOnecloneWithPS", "(", "self", ")", ":", "\n", "    ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "self", ".", "_inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf_labels", "=", "tf", ".", "constant", "(", "self", ".", "_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "model_fn", "=", "BatchNormClassifier", "\n", "clone_args", "=", "(", "tf_inputs", ",", "tf_labels", ")", "\n", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "1", ",", "\n", "num_ps_tasks", "=", "1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "clones", "=", "model_deploy", ".", "create_clones", "(", "deploy_config", ",", "model_fn", ",", "clone_args", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "clones", ")", ",", "1", ")", "\n", "clone", "=", "clones", "[", "0", "]", "\n", "self", ".", "assertEqual", "(", "clone", ".", "outputs", ".", "op", ".", "name", ",", "\n", "'BatchNormClassifier/fully_connected/Sigmoid'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "clone", ".", "device", ",", "'/job:worker/device:GPU:0'", ")", "\n", "self", ".", "assertEqual", "(", "clone", ".", "scope", ",", "''", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "get_variables", "(", ")", ")", ",", "5", ")", "\n", "for", "v", "in", "slim", ".", "get_variables", "(", ")", ":", "\n", "        ", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'/job:ps/task:0/CPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "v", ".", "value", "(", ")", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.CreatecloneTest.testCreateMulticloneWithPS": [[288, 314], ["tensorflow.Graph", "tensorflow.Graph.as_default", "tensorflow.set_random_seed", "tensorflow.constant", "tensorflow.constant", "deployment.model_deploy.DeploymentConfig", "model_deploy_test.CreatecloneTest.assertEqual", "deployment.model_deploy.create_clones", "model_deploy_test.CreatecloneTest.assertEqual", "enumerate", "model_deploy_test.CreatecloneTest.assertEqual", "enumerate", "slim.get_variables", "len", "slim.get_variables", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "len", "model_deploy_test.CreatecloneTest.assertEqual", "model_deploy_test.CreatecloneTest.assertEqual", "model_deploy_test.CreatecloneTest.assertDeviceEqual", "slim.get_variables", "v.value"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones"], ["", "", "", "def", "testCreateMulticloneWithPS", "(", "self", ")", ":", "\n", "    ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "self", ".", "_inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf_labels", "=", "tf", ".", "constant", "(", "self", ".", "_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "model_fn", "=", "BatchNormClassifier", "\n", "clone_args", "=", "(", "tf_inputs", ",", "tf_labels", ")", "\n", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "2", ",", "\n", "num_ps_tasks", "=", "2", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "clones", "=", "model_deploy", ".", "create_clones", "(", "deploy_config", ",", "model_fn", ",", "clone_args", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "get_variables", "(", ")", ")", ",", "5", ")", "\n", "for", "i", ",", "v", "in", "enumerate", "(", "slim", ".", "get_variables", "(", ")", ")", ":", "\n", "        ", "t", "=", "i", "%", "2", "\n", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'/job:ps/task:%d/device:CPU:0'", "%", "t", ")", "\n", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "v", ".", "value", "(", ")", ".", "device", ")", "\n", "", "self", ".", "assertEqual", "(", "len", "(", "clones", ")", ",", "2", ")", "\n", "for", "i", ",", "clone", "in", "enumerate", "(", "clones", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "\n", "clone", ".", "outputs", ".", "op", ".", "name", ",", "\n", "'clone_%d/BatchNormClassifier/fully_connected/Sigmoid'", "%", "i", ")", "\n", "self", ".", "assertEqual", "(", "clone", ".", "scope", ",", "'clone_%d/'", "%", "i", ")", "\n", "self", ".", "assertDeviceEqual", "(", "clone", ".", "device", ",", "'/job:worker/device:GPU:%d'", "%", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.OptimizeclonesTest.setUp": [[318, 329], ["numpy.random.seed", "numpy.zeros", "numpy.random.randint().astype", "model_deploy_test.OptimizeclonesTest.get_temp_dir", "range", "int", "numpy.random.randint", "numpy.random.randint"], "methods", ["None"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "# Create an easy training set:", "\n", "    ", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "\n", "self", ".", "_inputs", "=", "np", ".", "zeros", "(", "(", "16", ",", "4", ")", ")", "\n", "self", ".", "_labels", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "size", "=", "(", "16", ",", "1", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "_logdir", "=", "self", ".", "get_temp_dir", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "16", ")", ":", "\n", "      ", "j", "=", "int", "(", "2", "*", "self", ".", "_labels", "[", "i", "]", "+", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ")", ")", "\n", "self", ".", "_inputs", "[", "i", ",", "j", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.OptimizeclonesTest.testCreateLogisticClassifier": [[330, 355], ["tensorflow.Graph", "tensorflow.Graph.as_default", "tensorflow.set_random_seed", "tensorflow.constant", "tensorflow.constant", "deployment.model_deploy.DeploymentConfig", "model_deploy_test.OptimizeclonesTest.assertEqual", "deployment.model_deploy.create_clones", "model_deploy_test.OptimizeclonesTest.assertEqual", "tensorflow.get_collection", "model_deploy_test.OptimizeclonesTest.assertEqual", "tensorflow.train.GradientDescentOptimizer", "deployment.model_deploy.optimize_clones", "model_deploy_test.OptimizeclonesTest.assertEqual", "model_deploy_test.OptimizeclonesTest.assertEqual", "slim.get_variables", "len", "len", "len", "model_deploy_test.OptimizeclonesTest.assertDeviceEqual", "model_deploy_test.OptimizeclonesTest.assertDeviceEqual", "slim.get_variables", "tensorflow.trainable_variables"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.optimize_clones"], ["", "", "def", "testCreateLogisticClassifier", "(", "self", ")", ":", "\n", "    ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "self", ".", "_inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf_labels", "=", "tf", ".", "constant", "(", "self", ".", "_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "model_fn", "=", "LogisticClassifier", "\n", "clone_args", "=", "(", "tf_inputs", ",", "tf_labels", ")", "\n", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "clones", "=", "model_deploy", ".", "create_clones", "(", "deploy_config", ",", "model_fn", ",", "clone_args", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "get_variables", "(", ")", ")", ",", "2", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "assertEqual", "(", "update_ops", ",", "[", "]", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", "=", "1.0", ")", "\n", "total_loss", ",", "grads_and_vars", "=", "model_deploy", ".", "optimize_clones", "(", "clones", ",", "\n", "optimizer", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "grads_and_vars", ")", ",", "len", "(", "tf", ".", "trainable_variables", "(", ")", ")", ")", "\n", "self", ".", "assertEqual", "(", "total_loss", ".", "op", ".", "name", ",", "'total_loss'", ")", "\n", "for", "g", ",", "v", "in", "grads_and_vars", ":", "\n", "        ", "self", ".", "assertDeviceEqual", "(", "g", ".", "device", ",", "'GPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'CPU:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.OptimizeclonesTest.testCreateSingleclone": [[356, 381], ["tensorflow.Graph", "tensorflow.Graph.as_default", "tensorflow.set_random_seed", "tensorflow.constant", "tensorflow.constant", "deployment.model_deploy.DeploymentConfig", "model_deploy_test.OptimizeclonesTest.assertEqual", "deployment.model_deploy.create_clones", "model_deploy_test.OptimizeclonesTest.assertEqual", "tensorflow.get_collection", "model_deploy_test.OptimizeclonesTest.assertEqual", "tensorflow.train.GradientDescentOptimizer", "deployment.model_deploy.optimize_clones", "model_deploy_test.OptimizeclonesTest.assertEqual", "model_deploy_test.OptimizeclonesTest.assertEqual", "slim.get_variables", "len", "len", "len", "len", "model_deploy_test.OptimizeclonesTest.assertDeviceEqual", "model_deploy_test.OptimizeclonesTest.assertDeviceEqual", "slim.get_variables", "tensorflow.trainable_variables"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.optimize_clones"], ["", "", "", "def", "testCreateSingleclone", "(", "self", ")", ":", "\n", "    ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "self", ".", "_inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf_labels", "=", "tf", ".", "constant", "(", "self", ".", "_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "model_fn", "=", "BatchNormClassifier", "\n", "clone_args", "=", "(", "tf_inputs", ",", "tf_labels", ")", "\n", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "clones", "=", "model_deploy", ".", "create_clones", "(", "deploy_config", ",", "model_fn", ",", "clone_args", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "get_variables", "(", ")", ")", ",", "5", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "update_ops", ")", ",", "2", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", "=", "1.0", ")", "\n", "total_loss", ",", "grads_and_vars", "=", "model_deploy", ".", "optimize_clones", "(", "clones", ",", "\n", "optimizer", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "grads_and_vars", ")", ",", "len", "(", "tf", ".", "trainable_variables", "(", ")", ")", ")", "\n", "self", ".", "assertEqual", "(", "total_loss", ".", "op", ".", "name", ",", "'total_loss'", ")", "\n", "for", "g", ",", "v", "in", "grads_and_vars", ":", "\n", "        ", "self", ".", "assertDeviceEqual", "(", "g", ".", "device", ",", "'GPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'CPU:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.OptimizeclonesTest.testCreateMulticlone": [[382, 408], ["tensorflow.Graph", "tensorflow.Graph.as_default", "tensorflow.set_random_seed", "tensorflow.constant", "tensorflow.constant", "deployment.model_deploy.DeploymentConfig", "model_deploy_test.OptimizeclonesTest.assertEqual", "deployment.model_deploy.create_clones", "model_deploy_test.OptimizeclonesTest.assertEqual", "tensorflow.get_collection", "model_deploy_test.OptimizeclonesTest.assertEqual", "tensorflow.train.GradientDescentOptimizer", "deployment.model_deploy.optimize_clones", "model_deploy_test.OptimizeclonesTest.assertEqual", "model_deploy_test.OptimizeclonesTest.assertEqual", "slim.get_variables", "len", "len", "len", "len", "model_deploy_test.OptimizeclonesTest.assertDeviceEqual", "model_deploy_test.OptimizeclonesTest.assertDeviceEqual", "slim.get_variables", "tensorflow.trainable_variables"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.optimize_clones"], ["", "", "", "def", "testCreateMulticlone", "(", "self", ")", ":", "\n", "    ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "self", ".", "_inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf_labels", "=", "tf", ".", "constant", "(", "self", ".", "_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "model_fn", "=", "BatchNormClassifier", "\n", "clone_args", "=", "(", "tf_inputs", ",", "tf_labels", ")", "\n", "num_clones", "=", "4", "\n", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "num_clones", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "clones", "=", "model_deploy", ".", "create_clones", "(", "deploy_config", ",", "model_fn", ",", "clone_args", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "get_variables", "(", ")", ")", ",", "5", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "update_ops", ")", ",", "num_clones", "*", "2", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", "=", "1.0", ")", "\n", "total_loss", ",", "grads_and_vars", "=", "model_deploy", ".", "optimize_clones", "(", "clones", ",", "\n", "optimizer", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "grads_and_vars", ")", ",", "len", "(", "tf", ".", "trainable_variables", "(", ")", ")", ")", "\n", "self", ".", "assertEqual", "(", "total_loss", ".", "op", ".", "name", ",", "'total_loss'", ")", "\n", "for", "g", ",", "v", "in", "grads_and_vars", ":", "\n", "        ", "self", ".", "assertDeviceEqual", "(", "g", ".", "device", ",", "''", ")", "\n", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'CPU:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.OptimizeclonesTest.testCreateMulticloneCPU": [[409, 436], ["tensorflow.Graph", "tensorflow.Graph.as_default", "tensorflow.set_random_seed", "tensorflow.constant", "tensorflow.constant", "deployment.model_deploy.DeploymentConfig", "model_deploy_test.OptimizeclonesTest.assertEqual", "deployment.model_deploy.create_clones", "model_deploy_test.OptimizeclonesTest.assertEqual", "tensorflow.get_collection", "model_deploy_test.OptimizeclonesTest.assertEqual", "tensorflow.train.GradientDescentOptimizer", "deployment.model_deploy.optimize_clones", "model_deploy_test.OptimizeclonesTest.assertEqual", "model_deploy_test.OptimizeclonesTest.assertEqual", "slim.get_variables", "len", "len", "len", "len", "model_deploy_test.OptimizeclonesTest.assertDeviceEqual", "model_deploy_test.OptimizeclonesTest.assertDeviceEqual", "slim.get_variables", "tensorflow.trainable_variables"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.optimize_clones"], ["", "", "", "def", "testCreateMulticloneCPU", "(", "self", ")", ":", "\n", "    ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "self", ".", "_inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf_labels", "=", "tf", ".", "constant", "(", "self", ".", "_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "model_fn", "=", "BatchNormClassifier", "\n", "model_args", "=", "(", "tf_inputs", ",", "tf_labels", ")", "\n", "num_clones", "=", "4", "\n", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "num_clones", ",", "\n", "clone_on_cpu", "=", "True", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "clones", "=", "model_deploy", ".", "create_clones", "(", "deploy_config", ",", "model_fn", ",", "model_args", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "get_variables", "(", ")", ")", ",", "5", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "update_ops", ")", ",", "num_clones", "*", "2", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", "=", "1.0", ")", "\n", "total_loss", ",", "grads_and_vars", "=", "model_deploy", ".", "optimize_clones", "(", "clones", ",", "\n", "optimizer", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "grads_and_vars", ")", ",", "len", "(", "tf", ".", "trainable_variables", "(", ")", ")", ")", "\n", "self", ".", "assertEqual", "(", "total_loss", ".", "op", ".", "name", ",", "'total_loss'", ")", "\n", "for", "g", ",", "v", "in", "grads_and_vars", ":", "\n", "        ", "self", ".", "assertDeviceEqual", "(", "g", ".", "device", ",", "''", ")", "\n", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'CPU:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.OptimizeclonesTest.testCreateOnecloneWithPS": [[437, 463], ["tensorflow.Graph", "tensorflow.Graph.as_default", "tensorflow.set_random_seed", "tensorflow.constant", "tensorflow.constant", "deployment.model_deploy.DeploymentConfig", "model_deploy_test.OptimizeclonesTest.assertEqual", "deployment.model_deploy.create_clones", "model_deploy_test.OptimizeclonesTest.assertEqual", "tensorflow.get_collection", "model_deploy_test.OptimizeclonesTest.assertEqual", "tensorflow.train.GradientDescentOptimizer", "deployment.model_deploy.optimize_clones", "model_deploy_test.OptimizeclonesTest.assertEqual", "model_deploy_test.OptimizeclonesTest.assertEqual", "slim.get_variables", "len", "len", "len", "len", "model_deploy_test.OptimizeclonesTest.assertDeviceEqual", "model_deploy_test.OptimizeclonesTest.assertDeviceEqual", "slim.get_variables", "tensorflow.trainable_variables"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.optimize_clones"], ["", "", "", "def", "testCreateOnecloneWithPS", "(", "self", ")", ":", "\n", "    ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "self", ".", "_inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf_labels", "=", "tf", ".", "constant", "(", "self", ".", "_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "model_fn", "=", "BatchNormClassifier", "\n", "model_args", "=", "(", "tf_inputs", ",", "tf_labels", ")", "\n", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "1", ",", "\n", "num_ps_tasks", "=", "1", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "clones", "=", "model_deploy", ".", "create_clones", "(", "deploy_config", ",", "model_fn", ",", "model_args", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "slim", ".", "get_variables", "(", ")", ")", ",", "5", ")", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "update_ops", ")", ",", "2", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", "=", "1.0", ")", "\n", "total_loss", ",", "grads_and_vars", "=", "model_deploy", ".", "optimize_clones", "(", "clones", ",", "\n", "optimizer", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "grads_and_vars", ")", ",", "len", "(", "tf", ".", "trainable_variables", "(", ")", ")", ")", "\n", "self", ".", "assertEqual", "(", "total_loss", ".", "op", ".", "name", ",", "'total_loss'", ")", "\n", "for", "g", ",", "v", "in", "grads_and_vars", ":", "\n", "        ", "self", ".", "assertDeviceEqual", "(", "g", ".", "device", ",", "'/job:worker/device:GPU:0'", ")", "\n", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'/job:ps/task:0/CPU:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeployTest.setUp": [[467, 478], ["numpy.random.seed", "numpy.zeros", "numpy.random.randint().astype", "model_deploy_test.DeployTest.get_temp_dir", "range", "int", "numpy.random.randint", "numpy.random.randint"], "methods", ["None"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "# Create an easy training set:", "\n", "    ", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "\n", "self", ".", "_inputs", "=", "np", ".", "zeros", "(", "(", "16", ",", "4", ")", ")", "\n", "self", ".", "_labels", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "size", "=", "(", "16", ",", "1", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "_logdir", "=", "self", ".", "get_temp_dir", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "16", ")", ":", "\n", "      ", "j", "=", "int", "(", "2", "*", "self", ".", "_labels", "[", "i", "]", "+", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ")", ")", "\n", "self", ".", "_inputs", "[", "i", ",", "j", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeployTest.testLocalTrainOp": [[479, 525], ["tensorflow.Graph", "tensorflow.Graph.as_default", "tensorflow.set_random_seed", "tensorflow.constant", "tensorflow.constant", "deployment.model_deploy.DeploymentConfig", "tensorflow.train.GradientDescentOptimizer", "model_deploy_test.DeployTest.assertEqual", "deployment.model_deploy.deploy", "tensorflow.get_collection", "model_deploy_test.DeployTest.assertEqual", "model_deploy_test.DeployTest.assertEqual", "model_deploy_test.DeployTest.assertEqual", "model_deploy_test.DeployTest.assertEqual", "model_deploy_test.DeployTest.assertEqual", "slim.get_variables", "len", "len", "tensorflow.Session", "sess.run", "sess.run", "sess.run", "model_deploy_test.DeployTest.assertAllClose", "model_deploy_test.DeployTest.assertAllClose", "range", "sess.run", "model_deploy_test.DeployTest.assertLess", "sess.run", "model_deploy_test.DeployTest.assertAllClose", "model_deploy_test.DeployTest.assertAllClose", "tensorflow.global_variables_initializer", "tensorflow.contrib.framework.get_variables_by_name", "tensorflow.contrib.framework.get_variables_by_name", "sess.run"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.deploy", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testLocalTrainOp", "(", "self", ")", ":", "\n", "    ", "g", "=", "tf", ".", "Graph", "(", ")", "\n", "with", "g", ".", "as_default", "(", ")", ":", "\n", "      ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf_inputs", "=", "tf", ".", "constant", "(", "self", ".", "_inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "tf_labels", "=", "tf", ".", "constant", "(", "self", ".", "_labels", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "model_fn", "=", "BatchNormClassifier", "\n", "model_args", "=", "(", "tf_inputs", ",", "tf_labels", ")", "\n", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "2", ",", "\n", "clone_on_cpu", "=", "True", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "learning_rate", "=", "1.0", ")", "\n", "\n", "self", ".", "assertEqual", "(", "slim", ".", "get_variables", "(", ")", ",", "[", "]", ")", "\n", "model", "=", "model_deploy", ".", "deploy", "(", "deploy_config", ",", "model_fn", ",", "model_args", ",", "\n", "optimizer", "=", "optimizer", ")", "\n", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "update_ops", ")", ",", "4", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "model", ".", "clones", ")", ",", "2", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "total_loss", ".", "op", ".", "name", ",", "'total_loss'", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "summary_op", ".", "op", ".", "name", ",", "'summary_op/summary_op'", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "train_op", ".", "op", ".", "name", ",", "'train_op'", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "moving_mean", "=", "tf", ".", "contrib", ".", "framework", ".", "get_variables_by_name", "(", "\n", "'moving_mean'", ")", "[", "0", "]", "\n", "moving_variance", "=", "tf", ".", "contrib", ".", "framework", ".", "get_variables_by_name", "(", "\n", "'moving_variance'", ")", "[", "0", "]", "\n", "initial_loss", "=", "sess", ".", "run", "(", "model", ".", "total_loss", ")", "\n", "initial_mean", ",", "initial_variance", "=", "sess", ".", "run", "(", "[", "moving_mean", ",", "\n", "moving_variance", "]", ")", "\n", "self", ".", "assertAllClose", "(", "initial_mean", ",", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", ")", "\n", "self", ".", "assertAllClose", "(", "initial_variance", ",", "[", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", "]", ")", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "          ", "sess", ".", "run", "(", "model", ".", "train_op", ")", "\n", "", "final_loss", "=", "sess", ".", "run", "(", "model", ".", "total_loss", ")", "\n", "self", ".", "assertLess", "(", "final_loss", ",", "initial_loss", "/", "5.0", ")", "\n", "\n", "final_mean", ",", "final_variance", "=", "sess", ".", "run", "(", "[", "moving_mean", ",", "\n", "moving_variance", "]", ")", "\n", "self", ".", "assertAllClose", "(", "final_mean", ",", "[", "0.125", ",", "0.25", ",", "0.375", ",", "0.25", "]", ")", "\n", "self", ".", "assertAllClose", "(", "final_variance", ",", "[", "0.109375", ",", "0.1875", ",", "\n", "0.234375", ",", "0.1875", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeployTest.testNoSummariesOnGPU": [[526, 544], ["tensorflow.Graph().as_default", "deployment.model_deploy.DeploymentConfig", "deployment.model_deploy.deploy", "model_deploy_test.DeployTest.assertTrue", "tensorflow.constant", "tensorflow.contrib.layers.l2_regularizer", "tensorflow.contrib.layers.fully_connected", "model_deploy_test.DeployTest.assertEqual", "tensorflow.Graph", "tensorflow.train.GradientDescentOptimizer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.deploy"], ["", "", "", "def", "testNoSummariesOnGPU", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "      ", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "2", ")", "\n", "\n", "# clone function creates a fully_connected layer with a regularizer loss.", "\n", "def", "ModelFn", "(", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "constant", "(", "1.0", ",", "shape", "=", "(", "10", ",", "20", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "reg", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "0.001", ")", "\n", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "inputs", ",", "30", ",", "weights_regularizer", "=", "reg", ")", "\n", "\n", "", "model", "=", "model_deploy", ".", "deploy", "(", "\n", "deploy_config", ",", "ModelFn", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "GradientDescentOptimizer", "(", "1.0", ")", ")", "\n", "# The model summary op should have a few summary inputs and all of them", "\n", "# should be on the CPU.", "\n", "self", ".", "assertTrue", "(", "model", ".", "summary_op", ".", "op", ".", "inputs", ")", "\n", "for", "inp", "in", "model", ".", "summary_op", ".", "op", ".", "inputs", ":", "\n", "        ", "self", ".", "assertEqual", "(", "'/device:CPU:0'", ",", "inp", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.DeployTest.testNoSummariesOnGPUForEvals": [[545, 562], ["tensorflow.Graph().as_default", "deployment.model_deploy.DeploymentConfig", "deployment.model_deploy.deploy", "model_deploy_test.DeployTest.assertTrue", "tensorflow.constant", "tensorflow.contrib.layers.l2_regularizer", "tensorflow.contrib.layers.fully_connected", "model_deploy_test.DeployTest.assertEqual", "tensorflow.Graph"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.deploy"], ["", "", "", "def", "testNoSummariesOnGPUForEvals", "(", "self", ")", ":", "\n", "    ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "      ", "deploy_config", "=", "model_deploy", ".", "DeploymentConfig", "(", "num_clones", "=", "2", ")", "\n", "\n", "# clone function creates a fully_connected layer with a regularizer loss.", "\n", "def", "ModelFn", "(", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "constant", "(", "1.0", ",", "shape", "=", "(", "10", ",", "20", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "reg", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "0.001", ")", "\n", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "inputs", ",", "30", ",", "weights_regularizer", "=", "reg", ")", "\n", "\n", "# No optimizer here, it's an eval.", "\n", "", "model", "=", "model_deploy", ".", "deploy", "(", "deploy_config", ",", "ModelFn", ")", "\n", "# The model summary op should have a few summary inputs and all of them", "\n", "# should be on the CPU.", "\n", "self", ".", "assertTrue", "(", "model", ".", "summary_op", ".", "op", ".", "inputs", ")", "\n", "for", "inp", "in", "model", ".", "summary_op", ".", "op", ".", "inputs", ":", "\n", "        ", "self", ".", "assertEqual", "(", "'/device:CPU:0'", ",", "inp", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.LogisticClassifier": [[149, 156], ["tensorflow.variable_scope", "slim.fully_connected", "slim.losses.log_loss"], "function", ["None"], ["", "", "def", "LogisticClassifier", "(", "inputs", ",", "labels", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'LogisticClassifier'", ",", "[", "inputs", ",", "labels", "]", ",", "\n", "reuse", "=", "reuse", ")", ":", "\n", "    ", "predictions", "=", "slim", ".", "fully_connected", "(", "inputs", ",", "1", ",", "activation_fn", "=", "tf", ".", "sigmoid", ",", "\n", "scope", "=", "'fully_connected'", ")", "\n", "slim", ".", "losses", ".", "log_loss", "(", "predictions", ",", "labels", ")", "\n", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy_test.BatchNormClassifier": [[158, 167], ["tensorflow.variable_scope", "slim.batch_norm", "slim.fully_connected", "slim.losses.log_loss"], "function", ["None"], ["", "", "def", "BatchNormClassifier", "(", "inputs", ",", "labels", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'BatchNormClassifier'", ",", "[", "inputs", ",", "labels", "]", ",", "\n", "reuse", "=", "reuse", ")", ":", "\n", "    ", "inputs", "=", "slim", ".", "batch_norm", "(", "inputs", ",", "decay", "=", "0.1", ")", "\n", "predictions", "=", "slim", ".", "fully_connected", "(", "inputs", ",", "1", ",", "\n", "activation_fn", "=", "tf", ".", "sigmoid", ",", "\n", "scope", "=", "'fully_connected'", ")", "\n", "slim", ".", "losses", ".", "log_loss", "(", "predictions", ",", "labels", ")", "\n", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.__init__": [[482, 533], ["ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "num_clones", "=", "1", ",", "\n", "clone_on_cpu", "=", "False", ",", "\n", "replica_id", "=", "0", ",", "\n", "num_replicas", "=", "1", ",", "\n", "num_ps_tasks", "=", "0", ",", "\n", "worker_job_name", "=", "'worker'", ",", "\n", "ps_job_name", "=", "'ps'", ")", ":", "\n", "    ", "\"\"\"Create a DeploymentConfig.\n\n    The config describes how to deploy a model across multiple clones and\n    replicas.  The model will be replicated `num_clones` times in each replica.\n    If `clone_on_cpu` is True, each clone will placed on CPU.\n\n    If `num_replicas` is 1, the model is deployed via a single process.  In that\n    case `worker_device`, `num_ps_tasks`, and `ps_device` are ignored.\n\n    If `num_replicas` is greater than 1, then `worker_device` and `ps_device`\n    must specify TensorFlow devices for the `worker` and `ps` jobs and\n    `num_ps_tasks` must be positive.\n\n    Args:\n      num_clones: Number of model clones to deploy in each replica.\n      clone_on_cpu: If True clones would be placed on CPU.\n      replica_id: Integer.  Index of the replica for which the model is\n        deployed.  Usually 0 for the chief replica.\n      num_replicas: Number of replicas to use.\n      num_ps_tasks: Number of tasks for the `ps` job. 0 to not use replicas.\n      worker_job_name: A name for the worker job.\n      ps_job_name: A name for the parameter server job.\n\n    Raises:\n      ValueError: If the arguments are invalid.\n    \"\"\"", "\n", "if", "num_replicas", ">", "1", ":", "\n", "      ", "if", "num_ps_tasks", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "'When using replicas num_ps_tasks must be positive'", ")", "\n", "", "", "if", "num_replicas", ">", "1", "or", "num_ps_tasks", ">", "0", ":", "\n", "      ", "if", "not", "worker_job_name", ":", "\n", "        ", "raise", "ValueError", "(", "'Must specify worker_job_name when using replicas'", ")", "\n", "", "if", "not", "ps_job_name", ":", "\n", "        ", "raise", "ValueError", "(", "'Must specify ps_job_name when using parameter server'", ")", "\n", "", "", "if", "replica_id", ">=", "num_replicas", ":", "\n", "      ", "raise", "ValueError", "(", "'replica_id must be less than num_replicas'", ")", "\n", "", "self", ".", "_num_clones", "=", "num_clones", "\n", "self", ".", "_clone_on_cpu", "=", "clone_on_cpu", "\n", "self", ".", "_replica_id", "=", "replica_id", "\n", "self", ".", "_num_replicas", "=", "num_replicas", "\n", "self", ".", "_num_ps_tasks", "=", "num_ps_tasks", "\n", "self", ".", "_ps_device", "=", "'/job:'", "+", "ps_job_name", "if", "num_ps_tasks", ">", "0", "else", "''", "\n", "self", ".", "_worker_device", "=", "'/job:'", "+", "worker_job_name", "if", "num_ps_tasks", ">", "0", "else", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.num_clones": [[534, 537], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_clones", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_num_clones", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_on_cpu": [[538, 541], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "clone_on_cpu", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_clone_on_cpu", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.replica_id": [[542, 545], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "replica_id", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_replica_id", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.num_replicas": [[546, 549], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_replicas", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_num_replicas", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.num_ps_tasks": [[550, 553], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_ps_tasks", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_num_ps_tasks", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.ps_device": [[554, 557], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "ps_device", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_ps_device", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.worker_device": [[558, 561], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "worker_device", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_worker_device", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.caching_device": [[562, 574], ["None"], "methods", ["None"], ["", "def", "caching_device", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the device to use for caching variables.\n\n    Variables are cached on the worker CPU when using replicas.\n\n    Returns:\n      A device string or None if the variables do not need to be cached.\n    \"\"\"", "\n", "if", "self", ".", "_num_ps_tasks", ">", "0", ":", "\n", "      ", "return", "lambda", "op", ":", "op", ".", "device", "\n", "", "else", ":", "\n", "      ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device": [[575, 597], ["ValueError"], "methods", ["None"], ["", "", "def", "clone_device", "(", "self", ",", "clone_index", ")", ":", "\n", "    ", "\"\"\"Device used to create the clone and all the ops inside the clone.\n\n    Args:\n      clone_index: Int, representing the clone_index.\n\n    Returns:\n      A value suitable for `tf.device()`.\n\n    Raises:\n      ValueError: if `clone_index` is greater or equal to the number of clones\".\n    \"\"\"", "\n", "if", "clone_index", ">=", "self", ".", "_num_clones", ":", "\n", "      ", "raise", "ValueError", "(", "'clone_index must be less than num_clones'", ")", "\n", "", "device", "=", "''", "\n", "if", "self", ".", "_num_ps_tasks", ">", "0", ":", "\n", "      ", "device", "+=", "self", ".", "_worker_device", "\n", "", "if", "self", ".", "_clone_on_cpu", ":", "\n", "      ", "device", "+=", "'/device:CPU:0'", "\n", "", "else", ":", "\n", "      ", "device", "+=", "'/device:GPU:%d'", "%", "clone_index", "\n", "", "return", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope": [[598, 616], ["ValueError"], "methods", ["None"], ["", "def", "clone_scope", "(", "self", ",", "clone_index", ")", ":", "\n", "    ", "\"\"\"Name scope to create the clone.\n\n    Args:\n      clone_index: Int, representing the clone_index.\n\n    Returns:\n      A name_scope suitable for `tf.name_scope()`.\n\n    Raises:\n      ValueError: if `clone_index` is greater or equal to the number of clones\".\n    \"\"\"", "\n", "if", "clone_index", ">=", "self", ".", "_num_clones", ":", "\n", "      ", "raise", "ValueError", "(", "'clone_index must be less than num_clones'", ")", "\n", "", "scope", "=", "''", "\n", "if", "self", ".", "_num_clones", ">", "1", ":", "\n", "      ", "scope", "=", "'clone_%d'", "%", "clone_index", "\n", "", "return", "scope", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.optimizer_device": [[617, 627], ["None"], "methods", ["None"], ["", "def", "optimizer_device", "(", "self", ")", ":", "\n", "    ", "\"\"\"Device to use with the optimizer.\n\n    Returns:\n      A value suitable for `tf.device()`.\n    \"\"\"", "\n", "if", "self", ".", "_num_ps_tasks", ">", "0", "or", "self", ".", "_num_clones", ">", "0", ":", "\n", "      ", "return", "self", ".", "_worker_device", "+", "'/device:CPU:0'", "\n", "", "else", ":", "\n", "      ", "return", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.inputs_device": [[628, 639], ["None"], "methods", ["None"], ["", "", "def", "inputs_device", "(", "self", ")", ":", "\n", "    ", "\"\"\"Device to use to build the inputs.\n\n    Returns:\n      A value suitable for `tf.device()`.\n    \"\"\"", "\n", "device", "=", "''", "\n", "if", "self", ".", "_num_ps_tasks", ">", "0", ":", "\n", "      ", "device", "+=", "self", ".", "_worker_device", "\n", "", "device", "+=", "'/device:CPU:0'", "\n", "return", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.variables_device": [[640, 676], ["_PSDeviceChooser", "node_def.op.startswith", "isinstance"], "methods", ["None"], ["", "def", "variables_device", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the device to use for variables created inside the clone.\n\n    Returns:\n      A value suitable for `tf.device()`.\n    \"\"\"", "\n", "device", "=", "''", "\n", "if", "self", ".", "_num_ps_tasks", ">", "0", ":", "\n", "      ", "device", "+=", "self", ".", "_ps_device", "\n", "", "device", "+=", "'/device:CPU:0'", "\n", "\n", "class", "_PSDeviceChooser", "(", "object", ")", ":", "\n", "      ", "\"\"\"Slim device chooser for variables when using PS.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "device", ",", "tasks", ")", ":", "\n", "        ", "self", ".", "_device", "=", "device", "\n", "self", ".", "_tasks", "=", "tasks", "\n", "self", ".", "_task", "=", "0", "\n", "\n", "", "def", "choose", "(", "self", ",", "op", ")", ":", "\n", "        ", "if", "op", ".", "device", ":", "\n", "          ", "return", "op", ".", "device", "\n", "", "node_def", "=", "op", "if", "isinstance", "(", "op", ",", "tf", ".", "NodeDef", ")", "else", "op", ".", "node_def", "\n", "if", "node_def", ".", "op", ".", "startswith", "(", "'Variable'", ")", ":", "\n", "          ", "t", "=", "self", ".", "_task", "\n", "self", ".", "_task", "=", "(", "self", ".", "_task", "+", "1", ")", "%", "self", ".", "_tasks", "\n", "d", "=", "'%s/task:%d'", "%", "(", "self", ".", "_device", ",", "t", ")", "\n", "return", "d", "\n", "", "else", ":", "\n", "          ", "return", "op", ".", "device", "\n", "\n", "", "", "", "if", "not", "self", ".", "_num_ps_tasks", ":", "\n", "      ", "return", "device", "\n", "", "else", ":", "\n", "      ", "chooser", "=", "_PSDeviceChooser", "(", "device", ",", "self", ".", "_num_ps_tasks", ")", "\n", "return", "chooser", ".", "choose", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones": [[143, 196], ["slim.arg_scope", "range", "config.variables_device", "tensorflow.name_scope", "config.clone_device", "config.clone_scope", "tensorflow.device", "clones.append", "tensorflow.variable_scope", "model_fn", "Clone", "tensorflow.get_variable_scope"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.variables_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.clone_scope"], ["def", "create_clones", "(", "config", ",", "model_fn", ",", "args", "=", "None", ",", "kwargs", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates multiple clones according to config using a `model_fn`.\n\n  The returned values of `model_fn(*args, **kwargs)` are collected along with\n  the scope and device used to created it in a namedtuple\n  `Clone(outputs, scope, device)`\n\n  Note: it is assumed that any loss created by `model_fn` is collected at\n  the tf.GraphKeys.LOSSES collection.\n\n  To recover the losses, summaries or update_ops created by the clone use:\n  ```python\n    losses = tf.get_collection(tf.GraphKeys.LOSSES, clone.scope)\n    summaries = tf.get_collection(tf.GraphKeys.SUMMARIES, clone.scope)\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, clone.scope)\n  ```\n\n  The deployment options are specified by the config object and support\n  deploying one or several clones on different GPUs and one or several replicas\n  of such clones.\n\n  The argument `model_fn` is called `config.num_clones` times to create the\n  model clones as `model_fn(*args, **kwargs)`.\n\n  If `config` specifies deployment on multiple replicas then the default\n  tensorflow device is set appropriatly for each call to `model_fn` and for the\n  slim variable creation functions: model and global variables will be created\n  on the `ps` device, the clone operations will be on the `worker` device.\n\n  Args:\n    config: A DeploymentConfig object.\n    model_fn: A callable. Called as `model_fn(*args, **kwargs)`\n    args: Optional list of arguments to pass to `model_fn`.\n    kwargs: Optional list of keyword arguments to pass to `model_fn`.\n\n  Returns:\n    A list of namedtuples `Clone`.\n  \"\"\"", "\n", "clones", "=", "[", "]", "\n", "args", "=", "args", "or", "[", "]", "\n", "kwargs", "=", "kwargs", "or", "{", "}", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "\n", "device", "=", "config", ".", "variables_device", "(", ")", ")", ":", "\n", "# Create clones.", "\n", "    ", "for", "i", "in", "range", "(", "0", ",", "config", ".", "num_clones", ")", ":", "\n", "      ", "with", "tf", ".", "name_scope", "(", "config", ".", "clone_scope", "(", "i", ")", ")", "as", "clone_scope", ":", "\n", "        ", "clone_device", "=", "config", ".", "clone_device", "(", "i", ")", "\n", "with", "tf", ".", "device", "(", "clone_device", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "tf", ".", "get_variable_scope", "(", ")", ",", "\n", "reuse", "=", "True", "if", "i", ">", "0", "else", "None", ")", ":", "\n", "            ", "outputs", "=", "model_fn", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "clones", ".", "append", "(", "Clone", "(", "outputs", ",", "clone_scope", ",", "clone_device", ")", ")", "\n", "", "", "", "", "return", "clones", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy._gather_clone_loss": [[198, 237], ["tensorflow.device", "tensorflow.get_collection", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.add_n", "all_losses.append", "tensorflow.add_n", "all_losses.append", "tensorflow.add_n", "tensorflow.div"], "function", ["None"], ["", "def", "_gather_clone_loss", "(", "clone", ",", "num_clones", ",", "regularization_losses", ")", ":", "\n", "  ", "\"\"\"Gather the loss for a single clone.\n\n  Args:\n    clone: A Clone namedtuple.\n    num_clones: The number of clones being deployed.\n    regularization_losses: Possibly empty list of regularization_losses\n      to add to the clone losses.\n\n  Returns:\n    A tensor for the total loss for the clone.  Can be None.\n  \"\"\"", "\n", "# The return value.", "\n", "sum_loss", "=", "None", "\n", "# Individual components of the loss that will need summaries.", "\n", "clone_loss", "=", "None", "\n", "regularization_loss", "=", "None", "\n", "# Compute and aggregate losses on the clone device.", "\n", "with", "tf", ".", "device", "(", "clone", ".", "device", ")", ":", "\n", "    ", "all_losses", "=", "[", "]", "\n", "clone_losses", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "LOSSES", ",", "clone", ".", "scope", ")", "\n", "if", "clone_losses", ":", "\n", "      ", "clone_loss", "=", "tf", ".", "add_n", "(", "clone_losses", ",", "name", "=", "'clone_loss'", ")", "\n", "if", "num_clones", ">", "1", ":", "\n", "        ", "clone_loss", "=", "tf", ".", "div", "(", "clone_loss", ",", "1.0", "*", "num_clones", ",", "\n", "name", "=", "'scaled_clone_loss'", ")", "\n", "", "all_losses", ".", "append", "(", "clone_loss", ")", "\n", "", "if", "regularization_losses", ":", "\n", "      ", "regularization_loss", "=", "tf", ".", "add_n", "(", "regularization_losses", ",", "\n", "name", "=", "'regularization_loss'", ")", "\n", "all_losses", ".", "append", "(", "regularization_loss", ")", "\n", "", "if", "all_losses", ":", "\n", "      ", "sum_loss", "=", "tf", ".", "add_n", "(", "all_losses", ")", "\n", "# Add the summaries out of the clone device block.", "\n", "", "", "if", "clone_loss", "is", "not", "None", ":", "\n", "    ", "tf", ".", "summary", ".", "scalar", "(", "clone", ".", "scope", "+", "'/clone_loss'", ",", "clone_loss", ")", "\n", "", "if", "regularization_loss", "is", "not", "None", ":", "\n", "    ", "tf", ".", "summary", ".", "scalar", "(", "'regularization_loss'", ",", "regularization_loss", ")", "\n", "", "return", "sum_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy._optimize_clone": [[239, 263], ["model_deploy._gather_clone_loss", "tensorflow.device", "optimizer.compute_gradients"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy._gather_clone_loss"], ["", "def", "_optimize_clone", "(", "optimizer", ",", "clone", ",", "num_clones", ",", "regularization_losses", ",", "\n", "**", "kwargs", ")", ":", "\n", "  ", "\"\"\"Compute losses and gradients for a single clone.\n\n  Args:\n    optimizer: A tf.Optimizer  object.\n    clone: A Clone namedtuple.\n    num_clones: The number of clones being deployed.\n    regularization_losses: Possibly empty list of regularization_losses\n      to add to the clone losses.\n    **kwargs: Dict of kwarg to pass to compute_gradients().\n\n  Returns:\n    A tuple (clone_loss, clone_grads_and_vars).\n      - clone_loss: A tensor for the total loss for the clone.  Can be None.\n      - clone_grads_and_vars: List of (gradient, variable) for the clone.\n        Can be empty.\n  \"\"\"", "\n", "sum_loss", "=", "_gather_clone_loss", "(", "clone", ",", "num_clones", ",", "regularization_losses", ")", "\n", "clone_grad", "=", "None", "\n", "if", "sum_loss", "is", "not", "None", ":", "\n", "    ", "with", "tf", ".", "device", "(", "clone", ".", "device", ")", ":", "\n", "      ", "clone_grad", "=", "optimizer", ".", "compute_gradients", "(", "sum_loss", ",", "**", "kwargs", ")", "\n", "", "", "return", "sum_loss", ",", "clone_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.optimize_clones": [[265, 308], ["len", "tensorflow.add_n", "model_deploy._sum_clones_gradients", "tensorflow.get_collection", "tensorflow.name_scope", "model_deploy._optimize_clone", "clones_losses.append", "_sum_clones_gradients.append"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy._sum_clones_gradients", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy._optimize_clone"], ["", "def", "optimize_clones", "(", "clones", ",", "optimizer", ",", "\n", "regularization_losses", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "  ", "\"\"\"Compute clone losses and gradients for the given list of `Clones`.\n\n  Note: The regularization_losses are added to the first clone losses.\n\n  Args:\n   clones: List of `Clones` created by `create_clones()`.\n   optimizer: An `Optimizer` object.\n   regularization_losses: Optional list of regularization losses. If None it\n     will gather them from tf.GraphKeys.REGULARIZATION_LOSSES. Pass `[]` to\n     exclude them.\n   **kwargs: Optional list of keyword arguments to pass to `compute_gradients`.\n\n  Returns:\n   A tuple (total_loss, grads_and_vars).\n     - total_loss: A Tensor containing the average of the clone losses including\n       the regularization loss.\n     - grads_and_vars: A List of tuples (gradient, variable) containing the sum\n       of the gradients for each variable.\n\n  \"\"\"", "\n", "grads_and_vars", "=", "[", "]", "\n", "clones_losses", "=", "[", "]", "\n", "num_clones", "=", "len", "(", "clones", ")", "\n", "if", "regularization_losses", "is", "None", ":", "\n", "    ", "regularization_losses", "=", "tf", ".", "get_collection", "(", "\n", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "", "for", "clone", "in", "clones", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "clone", ".", "scope", ")", ":", "\n", "      ", "clone_loss", ",", "clone_grad", "=", "_optimize_clone", "(", "\n", "optimizer", ",", "clone", ",", "num_clones", ",", "regularization_losses", ",", "**", "kwargs", ")", "\n", "if", "clone_loss", "is", "not", "None", ":", "\n", "        ", "clones_losses", ".", "append", "(", "clone_loss", ")", "\n", "grads_and_vars", ".", "append", "(", "clone_grad", ")", "\n", "# Only use regularization_losses for the first clone", "\n", "", "regularization_losses", "=", "None", "\n", "# Compute the total_loss summing all the clones_losses.", "\n", "", "", "total_loss", "=", "tf", ".", "add_n", "(", "clones_losses", ",", "name", "=", "'total_loss'", ")", "\n", "# Sum the gradients across clones.", "\n", "grads_and_vars", "=", "_sum_clones_gradients", "(", "grads_and_vars", ")", "\n", "return", "total_loss", ",", "grads_and_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.deploy": [[310, 412], ["set", "model_deploy.create_clones", "tensorflow.get_collection", "DeployedModel", "tensorflow.get_collection", "tensorflow.device", "set", "config.optimizer_device", "model_deploy.optimize_clones", "tensorflow.get_collection", "tensorflow.get_collection", "set.add", "tensorflow.summary.merge", "tensorflow.device", "slim.get_or_create_global_step", "optimizer.apply_gradients", "tf.get_collection.append", "tensorflow.group", "tensorflow.add_n", "tensorflow.summary.scalar", "list", "config.variables_device", "set", "tensorflow.control_dependencies", "tensorflow.identity", "tensorflow.name_scope", "model_deploy._gather_clone_loss", "model_deploy._add_gradients_summaries", "len", "clones_losses.append"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.create_clones", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.optimizer_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.optimize_clones", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy.DeploymentConfig.variables_device", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy._gather_clone_loss", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy._add_gradients_summaries"], ["", "def", "deploy", "(", "config", ",", "\n", "model_fn", ",", "\n", "args", "=", "None", ",", "\n", "kwargs", "=", "None", ",", "\n", "optimizer", "=", "None", ",", "\n", "summarize_gradients", "=", "False", ")", ":", "\n", "  ", "\"\"\"Deploys a Slim-constructed model across multiple clones.\n\n  The deployment options are specified by the config object and support\n  deploying one or several clones on different GPUs and one or several replicas\n  of such clones.\n\n  The argument `model_fn` is called `config.num_clones` times to create the\n  model clones as `model_fn(*args, **kwargs)`.\n\n  The optional argument `optimizer` is an `Optimizer` object.  If not `None`,\n  the deployed model is configured for training with that optimizer.\n\n  If `config` specifies deployment on multiple replicas then the default\n  tensorflow device is set appropriatly for each call to `model_fn` and for the\n  slim variable creation functions: model and global variables will be created\n  on the `ps` device, the clone operations will be on the `worker` device.\n\n  Args:\n    config: A `DeploymentConfig` object.\n    model_fn: A callable. Called as `model_fn(*args, **kwargs)`\n    args: Optional list of arguments to pass to `model_fn`.\n    kwargs: Optional list of keyword arguments to pass to `model_fn`.\n    optimizer: Optional `Optimizer` object.  If passed the model is deployed\n      for training with that optimizer.\n    summarize_gradients: Whether or not add summaries to the gradients.\n\n  Returns:\n    A `DeployedModel` namedtuple.\n\n  \"\"\"", "\n", "# Gather initial summaries.", "\n", "summaries", "=", "set", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "SUMMARIES", ")", ")", "\n", "\n", "# Create Clones.", "\n", "clones", "=", "create_clones", "(", "config", ",", "model_fn", ",", "args", ",", "kwargs", ")", "\n", "first_clone", "=", "clones", "[", "0", "]", "\n", "\n", "# Gather update_ops from the first clone. These contain, for example,", "\n", "# the updates for the batch_norm variables created by model_fn.", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "first_clone", ".", "scope", ")", "\n", "\n", "train_op", "=", "None", "\n", "total_loss", "=", "None", "\n", "with", "tf", ".", "device", "(", "config", ".", "optimizer_device", "(", ")", ")", ":", "\n", "    ", "if", "optimizer", ":", "\n", "# Place the global step on the device storing the variables.", "\n", "      ", "with", "tf", ".", "device", "(", "config", ".", "variables_device", "(", ")", ")", ":", "\n", "        ", "global_step", "=", "slim", ".", "get_or_create_global_step", "(", ")", "\n", "\n", "# Compute the gradients for the clones.", "\n", "", "total_loss", ",", "clones_gradients", "=", "optimize_clones", "(", "clones", ",", "optimizer", ")", "\n", "\n", "if", "clones_gradients", ":", "\n", "        ", "if", "summarize_gradients", ":", "\n", "# Add summaries to the gradients.", "\n", "          ", "summaries", "|=", "set", "(", "_add_gradients_summaries", "(", "clones_gradients", ")", ")", "\n", "\n", "# Create gradient updates.", "\n", "", "grad_updates", "=", "optimizer", ".", "apply_gradients", "(", "clones_gradients", ",", "\n", "global_step", "=", "global_step", ")", "\n", "update_ops", ".", "append", "(", "grad_updates", ")", "\n", "\n", "update_op", "=", "tf", ".", "group", "(", "*", "update_ops", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "update_op", "]", ")", ":", "\n", "          ", "train_op", "=", "tf", ".", "identity", "(", "total_loss", ",", "name", "=", "'train_op'", ")", "\n", "", "", "", "else", ":", "\n", "      ", "clones_losses", "=", "[", "]", "\n", "regularization_losses", "=", "tf", ".", "get_collection", "(", "\n", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ")", "\n", "for", "clone", "in", "clones", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "clone", ".", "scope", ")", ":", "\n", "          ", "clone_loss", "=", "_gather_clone_loss", "(", "clone", ",", "len", "(", "clones", ")", ",", "\n", "regularization_losses", ")", "\n", "if", "clone_loss", "is", "not", "None", ":", "\n", "            ", "clones_losses", ".", "append", "(", "clone_loss", ")", "\n", "# Only use regularization_losses for the first clone", "\n", "", "regularization_losses", "=", "None", "\n", "", "", "if", "clones_losses", ":", "\n", "        ", "total_loss", "=", "tf", ".", "add_n", "(", "clones_losses", ",", "name", "=", "'total_loss'", ")", "\n", "\n", "# Add the summaries from the first clone. These contain the summaries", "\n", "# created by model_fn and either optimize_clones() or _gather_clone_loss().", "\n", "", "", "summaries", "|=", "set", "(", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "SUMMARIES", ",", "\n", "first_clone", ".", "scope", ")", ")", "\n", "\n", "if", "total_loss", "is", "not", "None", ":", "\n", "# Add total_loss to summary.", "\n", "      ", "summaries", ".", "add", "(", "tf", ".", "summary", ".", "scalar", "(", "'total_loss'", ",", "total_loss", ")", ")", "\n", "\n", "", "if", "summaries", ":", "\n", "# Merge all summaries together.", "\n", "      ", "summary_op", "=", "tf", ".", "summary", ".", "merge", "(", "list", "(", "summaries", ")", ",", "name", "=", "'summary_op'", ")", "\n", "", "else", ":", "\n", "      ", "summary_op", "=", "None", "\n", "\n", "", "", "return", "DeployedModel", "(", "train_op", ",", "summary_op", ",", "total_loss", ",", "clones", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy._sum_clones_gradients": [[414, 445], ["zip", "sum_grads.append", "grads.append", "len", "tensorflow.add_n"], "function", ["None"], ["", "def", "_sum_clones_gradients", "(", "clone_grads", ")", ":", "\n", "  ", "\"\"\"Calculate the sum gradient for each shared variable across all clones.\n\n  This function assumes that the clone_grads has been scaled appropriately by\n  1 / num_clones.\n\n  Args:\n    clone_grads: A List of List of tuples (gradient, variable), one list per\n    `Clone`.\n\n  Returns:\n     List of tuples of (gradient, variable) where the gradient has been summed\n     across all clones.\n  \"\"\"", "\n", "sum_grads", "=", "[", "]", "\n", "for", "grad_and_vars", "in", "zip", "(", "*", "clone_grads", ")", ":", "\n", "# Note that each grad_and_vars looks like the following:", "\n", "#   ((grad_var0_clone0, var0), ... (grad_varN_cloneN, varN))", "\n", "    ", "grads", "=", "[", "]", "\n", "var", "=", "grad_and_vars", "[", "0", "]", "[", "1", "]", "\n", "for", "g", ",", "v", "in", "grad_and_vars", ":", "\n", "      ", "assert", "v", "==", "var", "\n", "if", "g", "is", "not", "None", ":", "\n", "        ", "grads", ".", "append", "(", "g", ")", "\n", "", "", "if", "grads", ":", "\n", "      ", "if", "len", "(", "grads", ")", ">", "1", ":", "\n", "        ", "sum_grad", "=", "tf", ".", "add_n", "(", "grads", ",", "name", "=", "var", ".", "op", ".", "name", "+", "'/sum_grads'", ")", "\n", "", "else", ":", "\n", "        ", "sum_grad", "=", "grads", "[", "0", "]", "\n", "", "sum_grads", ".", "append", "(", "(", "sum_grad", ",", "var", ")", ")", "\n", "", "", "return", "sum_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.deployment.model_deploy._add_gradients_summaries": [[447, 472], ["isinstance", "summaries.append", "summaries.append", "tensorflow.logging.info", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.global_norm"], "function", ["None"], ["", "def", "_add_gradients_summaries", "(", "grads_and_vars", ")", ":", "\n", "  ", "\"\"\"Add histogram summaries to gradients.\n\n  Note: The summaries are also added to the SUMMARIES collection.\n\n  Args:\n    grads_and_vars: A list of gradient to variable pairs (tuples).\n\n  Returns:\n    The _list_ of the added summaries for grads_and_vars.\n  \"\"\"", "\n", "summaries", "=", "[", "]", "\n", "for", "grad", ",", "var", "in", "grads_and_vars", ":", "\n", "    ", "if", "grad", "is", "not", "None", ":", "\n", "      ", "if", "isinstance", "(", "grad", ",", "tf", ".", "IndexedSlices", ")", ":", "\n", "        ", "grad_values", "=", "grad", ".", "values", "\n", "", "else", ":", "\n", "        ", "grad_values", "=", "grad", "\n", "", "summaries", ".", "append", "(", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "':gradient'", ",", "\n", "grad_values", ")", ")", "\n", "summaries", ".", "append", "(", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "':gradient_norm'", ",", "\n", "tf", ".", "global_norm", "(", "[", "grad_values", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "'Var %s has no gradient'", ",", "var", ".", "op", ".", "name", ")", "\n", "", "", "return", "summaries", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testBuildClassificationNetwork": [[31, 44], ["tensorflow.random_uniform", "nets.inception.inception_v2", "inception_v2_test.InceptionV2Test.assertTrue", "inception_v2_test.InceptionV2Test.assertListEqual", "inception_v2_test.InceptionV2Test.assertTrue", "inception_v2_test.InceptionV2Test.assertListEqual", "logits.op.name.startswith", "logits.get_shape().as_list", "end_points[].get_shape().as_list", "logits.get_shape", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2"], ["  ", "def", "testBuildClassificationNetwork", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "inception", ".", "inception_v2", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV2/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "self", ".", "assertTrue", "(", "'Predictions'", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "'Predictions'", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testBuildBaseNetwork": [[45, 60], ["tensorflow.random_uniform", "nets.inception.inception_v2_base", "inception_v2_test.InceptionV2Test.assertTrue", "inception_v2_test.InceptionV2Test.assertListEqual", "inception_v2_test.InceptionV2Test.assertItemsEqual", "mixed_5c.op.name.startswith", "mixed_5c.get_shape().as_list", "end_points.keys", "mixed_5c.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2_base"], ["", "def", "testBuildBaseNetwork", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "mixed_5c", ",", "end_points", "=", "inception", ".", "inception_v2_base", "(", "inputs", ")", "\n", "self", ".", "assertTrue", "(", "mixed_5c", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV2/Mixed_5c'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "mixed_5c", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "7", ",", "7", ",", "1024", "]", ")", "\n", "expected_endpoints", "=", "[", "'Mixed_3b'", ",", "'Mixed_3c'", ",", "'Mixed_4a'", ",", "'Mixed_4b'", ",", "\n", "'Mixed_4c'", ",", "'Mixed_4d'", ",", "'Mixed_4e'", ",", "'Mixed_5a'", ",", "\n", "'Mixed_5b'", ",", "'Mixed_5c'", ",", "'Conv2d_1a_7x7'", ",", "\n", "'MaxPool_2a_3x3'", ",", "'Conv2d_2b_1x1'", ",", "'Conv2d_2c_3x3'", ",", "\n", "'MaxPool_3a_3x3'", "]", "\n", "self", ".", "assertItemsEqual", "(", "end_points", ".", "keys", "(", ")", ",", "expected_endpoints", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testBuildOnlyUptoFinalEndpoint": [[61, 76], ["enumerate", "tensorflow.Graph().as_default", "tensorflow.random_uniform", "nets.inception.inception_v2_base", "inception_v2_test.InceptionV2Test.assertTrue", "inception_v2_test.InceptionV2Test.assertItemsEqual", "out_tensor.op.name.startswith", "tensorflow.Graph"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2_base"], ["", "def", "testBuildOnlyUptoFinalEndpoint", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "endpoints", "=", "[", "'Conv2d_1a_7x7'", ",", "'MaxPool_2a_3x3'", ",", "'Conv2d_2b_1x1'", ",", "\n", "'Conv2d_2c_3x3'", ",", "'MaxPool_3a_3x3'", ",", "'Mixed_3b'", ",", "'Mixed_3c'", ",", "\n", "'Mixed_4a'", ",", "'Mixed_4b'", ",", "'Mixed_4c'", ",", "'Mixed_4d'", ",", "'Mixed_4e'", ",", "\n", "'Mixed_5a'", ",", "'Mixed_5b'", ",", "'Mixed_5c'", "]", "\n", "for", "index", ",", "endpoint", "in", "enumerate", "(", "endpoints", ")", ":", "\n", "      ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "out_tensor", ",", "end_points", "=", "inception", ".", "inception_v2_base", "(", "\n", "inputs", ",", "final_endpoint", "=", "endpoint", ")", "\n", "self", ".", "assertTrue", "(", "out_tensor", ".", "op", ".", "name", ".", "startswith", "(", "\n", "'InceptionV2/'", "+", "endpoint", ")", ")", "\n", "self", ".", "assertItemsEqual", "(", "endpoints", "[", ":", "index", "+", "1", "]", ",", "end_points", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testBuildAndCheckAllEndPointsUptoMixed5c": [[77, 105], ["tensorflow.random_uniform", "nets.inception.inception_v2_base", "inception_v2_test.InceptionV2Test.assertItemsEqual", "endpoints_shapes.keys", "end_points.keys", "inception_v2_test.InceptionV2Test.assertTrue", "inception_v2_test.InceptionV2Test.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2_base"], ["", "", "", "def", "testBuildAndCheckAllEndPointsUptoMixed5c", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_v2_base", "(", "inputs", ",", "\n", "final_endpoint", "=", "'Mixed_5c'", ")", "\n", "endpoints_shapes", "=", "{", "'Mixed_3b'", ":", "[", "batch_size", ",", "28", ",", "28", ",", "256", "]", ",", "\n", "'Mixed_3c'", ":", "[", "batch_size", ",", "28", ",", "28", ",", "320", "]", ",", "\n", "'Mixed_4a'", ":", "[", "batch_size", ",", "14", ",", "14", ",", "576", "]", ",", "\n", "'Mixed_4b'", ":", "[", "batch_size", ",", "14", ",", "14", ",", "576", "]", ",", "\n", "'Mixed_4c'", ":", "[", "batch_size", ",", "14", ",", "14", ",", "576", "]", ",", "\n", "'Mixed_4d'", ":", "[", "batch_size", ",", "14", ",", "14", ",", "576", "]", ",", "\n", "'Mixed_4e'", ":", "[", "batch_size", ",", "14", ",", "14", ",", "576", "]", ",", "\n", "'Mixed_5a'", ":", "[", "batch_size", ",", "7", ",", "7", ",", "1024", "]", ",", "\n", "'Mixed_5b'", ":", "[", "batch_size", ",", "7", ",", "7", ",", "1024", "]", ",", "\n", "'Mixed_5c'", ":", "[", "batch_size", ",", "7", ",", "7", ",", "1024", "]", ",", "\n", "'Conv2d_1a_7x7'", ":", "[", "batch_size", ",", "112", ",", "112", ",", "64", "]", ",", "\n", "'MaxPool_2a_3x3'", ":", "[", "batch_size", ",", "56", ",", "56", ",", "64", "]", ",", "\n", "'Conv2d_2b_1x1'", ":", "[", "batch_size", ",", "56", ",", "56", ",", "64", "]", ",", "\n", "'Conv2d_2c_3x3'", ":", "[", "batch_size", ",", "56", ",", "56", ",", "192", "]", ",", "\n", "'MaxPool_3a_3x3'", ":", "[", "batch_size", ",", "28", ",", "28", ",", "192", "]", "}", "\n", "self", ".", "assertItemsEqual", "(", "endpoints_shapes", ".", "keys", "(", ")", ",", "end_points", ".", "keys", "(", ")", ")", "\n", "for", "endpoint_name", "in", "endpoints_shapes", ":", "\n", "      ", "expected_shape", "=", "endpoints_shapes", "[", "endpoint_name", "]", "\n", "self", ".", "assertTrue", "(", "endpoint_name", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint_name", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "expected_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testModelHasExpectedNumberOfParameters": [[106, 115], ["tensorflow.random_uniform", "slim.model_analyzer.analyze_vars", "inception_v2_test.InceptionV2Test.assertAlmostEqual", "slim.arg_scope", "nets.inception.inception_v2_base", "slim.get_model_variables", "nets.inception.inception_v2_arg_scope"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2_base"], ["", "", "def", "testModelHasExpectedNumberOfParameters", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "with", "slim", ".", "arg_scope", "(", "inception", ".", "inception_v2_arg_scope", "(", ")", ")", ":", "\n", "      ", "inception", ".", "inception_v2_base", "(", "inputs", ")", "\n", "", "total_params", ",", "_", "=", "slim", ".", "model_analyzer", ".", "analyze_vars", "(", "\n", "slim", ".", "get_model_variables", "(", ")", ")", "\n", "self", ".", "assertAlmostEqual", "(", "10173112", ",", "total_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testBuildEndPointsWithDepthMultiplierLessThanOne": [[116, 135], ["tensorflow.random_uniform", "nets.inception.inception_v2", "nets.inception.inception_v2", "inception_v2_test.InceptionV2Test.assertEqual", "end_points.keys", "end_points[].get_shape().as_list", "end_points_with_multiplier[].get_shape().as_list", "key.startswith", "key.startswith", "end_points[].get_shape", "end_points_with_multiplier[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2"], ["", "def", "testBuildEndPointsWithDepthMultiplierLessThanOne", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_v2", "(", "inputs", ",", "num_classes", ")", "\n", "\n", "endpoint_keys", "=", "[", "key", "for", "key", "in", "end_points", ".", "keys", "(", ")", "\n", "if", "key", ".", "startswith", "(", "'Mixed'", ")", "or", "key", ".", "startswith", "(", "'Conv'", ")", "]", "\n", "\n", "_", ",", "end_points_with_multiplier", "=", "inception", ".", "inception_v2", "(", "\n", "inputs", ",", "num_classes", ",", "scope", "=", "'depth_multiplied_net'", ",", "\n", "depth_multiplier", "=", "0.5", ")", "\n", "\n", "for", "key", "in", "endpoint_keys", ":", "\n", "      ", "original_depth", "=", "end_points", "[", "key", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "new_depth", "=", "end_points_with_multiplier", "[", "key", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "self", ".", "assertEqual", "(", "0.5", "*", "original_depth", ",", "new_depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testBuildEndPointsWithDepthMultiplierGreaterThanOne": [[136, 155], ["tensorflow.random_uniform", "nets.inception.inception_v2", "nets.inception.inception_v2", "inception_v2_test.InceptionV2Test.assertEqual", "end_points.keys", "end_points[].get_shape().as_list", "end_points_with_multiplier[].get_shape().as_list", "key.startswith", "key.startswith", "end_points[].get_shape", "end_points_with_multiplier[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2"], ["", "", "def", "testBuildEndPointsWithDepthMultiplierGreaterThanOne", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_v2", "(", "inputs", ",", "num_classes", ")", "\n", "\n", "endpoint_keys", "=", "[", "key", "for", "key", "in", "end_points", ".", "keys", "(", ")", "\n", "if", "key", ".", "startswith", "(", "'Mixed'", ")", "or", "key", ".", "startswith", "(", "'Conv'", ")", "]", "\n", "\n", "_", ",", "end_points_with_multiplier", "=", "inception", ".", "inception_v2", "(", "\n", "inputs", ",", "num_classes", ",", "scope", "=", "'depth_multiplied_net'", ",", "\n", "depth_multiplier", "=", "2.0", ")", "\n", "\n", "for", "key", "in", "endpoint_keys", ":", "\n", "      ", "original_depth", "=", "end_points", "[", "key", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "new_depth", "=", "end_points_with_multiplier", "[", "key", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "self", ".", "assertEqual", "(", "2.0", "*", "original_depth", ",", "new_depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testRaiseValueErrorWithInvalidDepthMultiplier": [[156, 166], ["tensorflow.random_uniform", "inception_v2_test.InceptionV2Test.assertRaises", "nets.inception.inception_v2", "inception_v2_test.InceptionV2Test.assertRaises", "nets.inception.inception_v2"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2"], ["", "", "def", "testRaiseValueErrorWithInvalidDepthMultiplier", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "      ", "_", "=", "inception", ".", "inception_v2", "(", "inputs", ",", "num_classes", ",", "depth_multiplier", "=", "-", "0.1", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "      ", "_", "=", "inception", ".", "inception_v2", "(", "inputs", ",", "num_classes", ",", "depth_multiplier", "=", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testHalfSizeImages": [[167, 180], ["tensorflow.random_uniform", "nets.inception.inception_v2", "inception_v2_test.InceptionV2Test.assertTrue", "inception_v2_test.InceptionV2Test.assertListEqual", "inception_v2_test.InceptionV2Test.assertListEqual", "logits.op.name.startswith", "logits.get_shape().as_list", "pre_pool.get_shape().as_list", "logits.get_shape", "pre_pool.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2"], ["", "", "def", "testHalfSizeImages", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "112", ",", "112", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "inception", ".", "inception_v2", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV2/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "pre_pool", "=", "end_points", "[", "'Mixed_5c'", "]", "\n", "self", ".", "assertListEqual", "(", "pre_pool", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "4", ",", "4", ",", "1024", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testUnknownImageShape": [[181, 198], ["tensorflow.reset_default_graph", "numpy.random.uniform", "inception_v2_test.InceptionV2Test.test_session", "tensorflow.placeholder", "nets.inception.inception_v2", "inception_v2_test.InceptionV2Test.assertTrue", "inception_v2_test.InceptionV2Test.assertListEqual", "tensorflow.global_variables_initializer().run", "sess.run", "inception_v2_test.InceptionV2Test.assertListEqual", "logits.op.name.startswith", "logits.get_shape().as_list", "list", "tensorflow.global_variables_initializer", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "testUnknownImageShape", "(", "self", ")", ":", "\n", "    ", "tf", ".", "reset_default_graph", "(", ")", "\n", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "input_np", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "1", ",", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "batch_size", ",", "None", ",", "None", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "inception", ".", "inception_v2", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV2/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "pre_pool", "=", "end_points", "[", "'Mixed_5c'", "]", "\n", "feed_dict", "=", "{", "inputs", ":", "input_np", "}", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "pre_pool_out", "=", "sess", ".", "run", "(", "pre_pool", ",", "feed_dict", "=", "feed_dict", ")", "\n", "self", ".", "assertListEqual", "(", "list", "(", "pre_pool_out", ".", "shape", ")", ",", "[", "batch_size", ",", "7", ",", "7", ",", "1024", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testUnknowBatchSize": [[199, 215], ["tensorflow.placeholder", "nets.inception.inception_v2", "inception_v2_test.InceptionV2Test.assertTrue", "inception_v2_test.InceptionV2Test.assertListEqual", "tensorflow.random_uniform", "logits.op.name.startswith", "logits.get_shape().as_list", "inception_v2_test.InceptionV2Test.test_session", "sess.run", "sess.run", "inception_v2_test.InceptionV2Test.assertEquals", "tensorflow.global_variables_initializer", "logits.get_shape", "tensorflow.random_uniform.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testUnknowBatchSize", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v2", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV2/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "None", ",", "num_classes", "]", ")", "\n", "images", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ",", "{", "inputs", ":", "images", ".", "eval", "(", ")", "}", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "batch_size", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testEvaluation": [[216, 230], ["tensorflow.random_uniform", "nets.inception.inception_v2", "tensorflow.argmax", "inception_v2_test.InceptionV2Test.test_session", "sess.run", "sess.run", "inception_v2_test.InceptionV2Test.assertEquals", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testEvaluation", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v2", "(", "eval_inputs", ",", "num_classes", ",", "\n", "is_training", "=", "False", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "predictions", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testTrainEvalWithReuse": [[231, 247], ["tensorflow.random_uniform", "nets.inception.inception_v2", "tensorflow.random_uniform", "nets.inception.inception_v2", "tensorflow.argmax", "inception_v2_test.InceptionV2Test.test_session", "sess.run", "sess.run", "inception_v2_test.InceptionV2Test.assertEquals", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testTrainEvalWithReuse", "(", "self", ")", ":", "\n", "    ", "train_batch_size", "=", "5", "\n", "eval_batch_size", "=", "2", "\n", "height", ",", "width", "=", "150", ",", "150", "\n", "num_classes", "=", "1000", "\n", "\n", "train_inputs", "=", "tf", ".", "random_uniform", "(", "(", "train_batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "inception", ".", "inception_v2", "(", "train_inputs", ",", "num_classes", ")", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "eval_batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v2", "(", "eval_inputs", ",", "num_classes", ",", "reuse", "=", "True", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "predictions", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "eval_batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2_test.InceptionV2Test.testLogitsNotSqueezed": [[248, 259], ["tensorflow.random_uniform", "nets.inception.inception_v2", "inception_v2_test.InceptionV2Test.test_session", "tensorflow.global_variables_initializer().run", "sess.run", "inception_v2_test.InceptionV2Test.assertListEqual", "list", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testLogitsNotSqueezed", "(", "self", ")", ":", "\n", "    ", "num_classes", "=", "25", "\n", "images", "=", "tf", ".", "random_uniform", "(", "[", "1", ",", "224", ",", "224", ",", "3", "]", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v2", "(", "images", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "spatial_squeeze", "=", "False", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "logits_out", "=", "sess", ".", "run", "(", "logits", ")", "\n", "self", ".", "assertListEqual", "(", "list", "(", "logits_out", ".", "shape", ")", ",", "[", "1", ",", "1", ",", "1", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.block_inception_a": [[34, 53], ["slim.arg_scope", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d"], "function", ["None"], ["def", "block_inception_a", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds Inception-A block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'BlockInceptionA'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "        ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "96", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "        ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "96", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "        ", "branch_2", "=", "slim", ".", "conv2d", "(", "inputs", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "96", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "96", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "        ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "96", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.block_reduction_a": [[55, 73], ["slim.arg_scope", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d"], "function", ["None"], ["", "", "", "def", "block_reduction_a", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds Reduction-A block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'BlockReductionA'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "        ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "        ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "224", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "        ", "branch_2", "=", "slim", ".", "max_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.block_inception_b": [[75, 97], ["slim.arg_scope", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d"], "function", ["None"], ["", "", "", "def", "block_inception_b", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds Inception-B block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'BlockInceptionB'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "        ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "        ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "224", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "        ", "branch_2", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "192", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "224", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0c_1x7'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "224", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0d_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "256", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0e_1x7'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "        ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.block_reduction_b": [[99, 119], ["slim.arg_scope", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d"], "function", ["None"], ["", "", "", "def", "block_reduction_b", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds Reduction-B block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'BlockReductionB'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "        ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_0", "=", "slim", ".", "conv2d", "(", "branch_0", ",", "192", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "        ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "320", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "320", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "        ", "branch_2", "=", "slim", ".", "max_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.block_inception_c": [[121, 145], ["slim.arg_scope", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.concat", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d"], "function", ["None"], ["", "", "", "def", "block_inception_c", "(", "inputs", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds Inception-C block for Inception v4 network.\"\"\"", "\n", "# By default use stride=1 and SAME padding", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'BlockInceptionC'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "        ", "branch_0", "=", "slim", ".", "conv2d", "(", "inputs", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "        ", "branch_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "\n", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_1x3'", ")", ",", "\n", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_3x1'", ")", "]", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "        ", "branch_2", "=", "slim", ".", "conv2d", "(", "inputs", ",", "384", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "448", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_3x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "512", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0c_1x3'", ")", "\n", "branch_2", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "\n", "slim", ".", "conv2d", "(", "branch_2", ",", "256", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0d_1x3'", ")", ",", "\n", "slim", ".", "conv2d", "(", "branch_2", ",", "256", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0e_3x1'", ")", "]", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "        ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "inputs", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4_base": [[147, 255], ["ValueError", "tensorflow.variable_scope", "slim.arg_scope", "slim.conv2d", "inception_v4.inception_v4_base.add_and_check_final"], "function", ["None"], ["", "", "", "def", "inception_v4_base", "(", "inputs", ",", "final_endpoint", "=", "'Mixed_7d'", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Creates the Inception V4 network up to the given final endpoint.\n\n  Args:\n    inputs: a 4-D tensor of size [batch_size, height, width, 3].\n    final_endpoint: specifies the endpoint to construct the network up to.\n      It can be one of [ 'Conv2d_1a_3x3', 'Conv2d_2a_3x3', 'Conv2d_2b_3x3',\n      'Mixed_3a', 'Mixed_4a', 'Mixed_5a', 'Mixed_5b', 'Mixed_5c', 'Mixed_5d',\n      'Mixed_5e', 'Mixed_6a', 'Mixed_6b', 'Mixed_6c', 'Mixed_6d', 'Mixed_6e',\n      'Mixed_6f', 'Mixed_6g', 'Mixed_6h', 'Mixed_7a', 'Mixed_7b', 'Mixed_7c',\n      'Mixed_7d']\n    scope: Optional variable_scope.\n\n  Returns:\n    logits: the logits outputs of the model.\n    end_points: the set of end_points from the inception model.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values,\n  \"\"\"", "\n", "end_points", "=", "{", "}", "\n", "\n", "def", "add_and_check_final", "(", "name", ",", "net", ")", ":", "\n", "    ", "end_points", "[", "name", "]", "=", "net", "\n", "return", "name", "==", "final_endpoint", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV4'", ",", "[", "inputs", "]", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "# 299 x 299 x 3", "\n", "      ", "net", "=", "slim", ".", "conv2d", "(", "inputs", ",", "32", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_1a_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 149 x 149 x 32", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "[", "3", ",", "3", "]", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_2a_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_2a_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 147 x 147 x 32", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_2b_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_2b_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 147 x 147 x 64", "\n", "with", "tf", ".", "variable_scope", "(", "'Mixed_3a'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "96", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_0a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", "]", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_3a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 73 x 73 x 160", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Mixed_4a'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_0", "=", "slim", ".", "conv2d", "(", "branch_0", ",", "96", ",", "[", "3", ",", "3", "]", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "64", ",", "[", "1", ",", "7", "]", ",", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "64", ",", "[", "7", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "96", ",", "[", "3", ",", "3", "]", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", "]", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_4a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 71 x 71 x 192", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Mixed_5a'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", "]", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_5a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 35 x 35 x 384", "\n", "# 4 x Inception-A blocks", "\n", "", "for", "idx", "in", "range", "(", "4", ")", ":", "\n", "        ", "block_scope", "=", "'Mixed_5'", "+", "chr", "(", "ord", "(", "'b'", ")", "+", "idx", ")", "\n", "net", "=", "block_inception_a", "(", "net", ",", "block_scope", ")", "\n", "if", "add_and_check_final", "(", "block_scope", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 35 x 35 x 384", "\n", "# Reduction-A block", "\n", "", "net", "=", "block_reduction_a", "(", "net", ",", "'Mixed_6a'", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_6a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 17 x 17 x 1024", "\n", "# 7 x Inception-B blocks", "\n", "for", "idx", "in", "range", "(", "7", ")", ":", "\n", "        ", "block_scope", "=", "'Mixed_6'", "+", "chr", "(", "ord", "(", "'b'", ")", "+", "idx", ")", "\n", "net", "=", "block_inception_b", "(", "net", ",", "block_scope", ")", "\n", "if", "add_and_check_final", "(", "block_scope", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 17 x 17 x 1024", "\n", "# Reduction-B block", "\n", "", "net", "=", "block_reduction_b", "(", "net", ",", "'Mixed_7a'", ")", "\n", "if", "add_and_check_final", "(", "'Mixed_7a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 8 x 8 x 1536", "\n", "# 3 x Inception-C blocks", "\n", "for", "idx", "in", "range", "(", "3", ")", ":", "\n", "        ", "block_scope", "=", "'Mixed_7'", "+", "chr", "(", "ord", "(", "'b'", ")", "+", "idx", ")", "\n", "net", "=", "block_inception_c", "(", "net", ",", "block_scope", ")", "\n", "if", "add_and_check_final", "(", "block_scope", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "", "", "", "raise", "ValueError", "(", "'Unknown final endpoint %s'", "%", "final_endpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4": [[257, 320], ["tensorflow.variable_scope", "slim.arg_scope", "inception_v4.inception_v4_base", "slim.arg_scope", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.dropout", "slim.flatten", "slim.fully_connected", "tensorflow.nn.softmax", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "slim.conv2d", "slim.flatten", "slim.fully_connected", "slim.flatten.get_shape", "slim.fully_connected.get_shape"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4_base"], ["", "def", "inception_v4", "(", "inputs", ",", "num_classes", "=", "1001", ",", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.8", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'InceptionV4'", ",", "\n", "create_aux_logits", "=", "True", ")", ":", "\n", "  ", "\"\"\"Creates the Inception V4 model.\n\n  Args:\n    inputs: a 4-D tensor of size [batch_size, height, width, 3].\n    num_classes: number of predicted classes.\n    is_training: whether is training or not.\n    dropout_keep_prob: float, the fraction to keep before final layer.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    scope: Optional variable_scope.\n    create_aux_logits: Whether to include the auxiliary logits.\n\n  Returns:\n    logits: the logits outputs of the model.\n    end_points: the set of end_points from the inception model.\n  \"\"\"", "\n", "end_points", "=", "{", "}", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV4'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "\n", "is_training", "=", "is_training", ")", ":", "\n", "      ", "net", ",", "end_points", "=", "inception_v4_base", "(", "inputs", ",", "scope", "=", "scope", ")", "\n", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "# Auxiliary Head logits", "\n", "        ", "if", "create_aux_logits", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'AuxLogits'", ")", ":", "\n", "# 17 x 17 x 1024", "\n", "            ", "aux_logits", "=", "end_points", "[", "'Mixed_6h'", "]", "\n", "aux_logits", "=", "slim", ".", "avg_pool2d", "(", "aux_logits", ",", "[", "5", ",", "5", "]", ",", "stride", "=", "3", ",", "\n", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'AvgPool_1a_5x5'", ")", "\n", "aux_logits", "=", "slim", ".", "conv2d", "(", "aux_logits", ",", "128", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_1b_1x1'", ")", "\n", "aux_logits", "=", "slim", ".", "conv2d", "(", "aux_logits", ",", "768", ",", "\n", "aux_logits", ".", "get_shape", "(", ")", "[", "1", ":", "3", "]", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_2a'", ")", "\n", "aux_logits", "=", "slim", ".", "flatten", "(", "aux_logits", ")", "\n", "aux_logits", "=", "slim", ".", "fully_connected", "(", "aux_logits", ",", "num_classes", ",", "\n", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'Aux_logits'", ")", "\n", "end_points", "[", "'AuxLogits'", "]", "=", "aux_logits", "\n", "\n", "# Final pooling and prediction", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Logits'", ")", ":", "\n", "# 8 x 8 x 1536", "\n", "          ", "net", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "net", ".", "get_shape", "(", ")", "[", "1", ":", "3", "]", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'AvgPool_1a'", ")", "\n", "# 1 x 1 x 1536", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "scope", "=", "'Dropout_1b'", ")", "\n", "net", "=", "slim", ".", "flatten", "(", "net", ",", "scope", "=", "'PreLogitsFlatten'", ")", "\n", "end_points", "[", "'PreLogitsFlatten'", "]", "=", "net", "\n", "# 1536", "\n", "logits", "=", "slim", ".", "fully_connected", "(", "net", ",", "num_classes", ",", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'Logits'", ")", "\n", "end_points", "[", "'Logits'", "]", "=", "logits", "\n", "end_points", "[", "'Predictions'", "]", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ",", "name", "=", "'Predictions'", ")", "\n", "", "", "", "return", "logits", ",", "end_points", "\n", "", "", "inception_v4", ".", "default_image_size", "=", "299", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat_test.OverFeatTest.testBuild": [[29, 39], ["overfeat_test.OverFeatTest.test_session", "tensorflow.random_uniform", "nets.overfeat.overfeat", "overfeat_test.OverFeatTest.assertEquals", "overfeat_test.OverFeatTest.assertListEqual", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat.overfeat"], ["  ", "def", "testBuild", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "231", ",", "231", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "overfeat", ".", "overfeat", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertEquals", "(", "logits", ".", "op", ".", "name", ",", "'overfeat/fc8/squeezed'", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat_test.OverFeatTest.testFullyConvolutional": [[40, 50], ["overfeat_test.OverFeatTest.test_session", "tensorflow.random_uniform", "nets.overfeat.overfeat", "overfeat_test.OverFeatTest.assertEquals", "overfeat_test.OverFeatTest.assertListEqual", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat.overfeat"], ["", "", "def", "testFullyConvolutional", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "281", ",", "281", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "overfeat", ".", "overfeat", "(", "inputs", ",", "num_classes", ",", "spatial_squeeze", "=", "False", ")", "\n", "self", ".", "assertEquals", "(", "logits", ".", "op", ".", "name", ",", "'overfeat/fc8/BiasAdd'", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "2", ",", "2", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat_test.OverFeatTest.testEndPoints": [[51, 71], ["overfeat_test.OverFeatTest.test_session", "tensorflow.random_uniform", "nets.overfeat.overfeat", "overfeat_test.OverFeatTest.assertSetEqual", "set", "set", "end_points.keys"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat.overfeat"], ["", "", "def", "testEndPoints", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "231", ",", "231", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "overfeat", ".", "overfeat", "(", "inputs", ",", "num_classes", ")", "\n", "expected_names", "=", "[", "'overfeat/conv1'", ",", "\n", "'overfeat/pool1'", ",", "\n", "'overfeat/conv2'", ",", "\n", "'overfeat/pool2'", ",", "\n", "'overfeat/conv3'", ",", "\n", "'overfeat/conv4'", ",", "\n", "'overfeat/conv5'", ",", "\n", "'overfeat/pool5'", ",", "\n", "'overfeat/fc6'", ",", "\n", "'overfeat/fc7'", ",", "\n", "'overfeat/fc8'", "\n", "]", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "end_points", ".", "keys", "(", ")", ")", ",", "set", "(", "expected_names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat_test.OverFeatTest.testModelVariables": [[72, 98], ["overfeat_test.OverFeatTest.test_session", "tensorflow.random_uniform", "nets.overfeat.overfeat", "overfeat_test.OverFeatTest.assertSetEqual", "set", "set", "slim.get_model_variables"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat.overfeat"], ["", "", "def", "testModelVariables", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "231", ",", "231", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "overfeat", ".", "overfeat", "(", "inputs", ",", "num_classes", ")", "\n", "expected_names", "=", "[", "'overfeat/conv1/weights'", ",", "\n", "'overfeat/conv1/biases'", ",", "\n", "'overfeat/conv2/weights'", ",", "\n", "'overfeat/conv2/biases'", ",", "\n", "'overfeat/conv3/weights'", ",", "\n", "'overfeat/conv3/biases'", ",", "\n", "'overfeat/conv4/weights'", ",", "\n", "'overfeat/conv4/biases'", ",", "\n", "'overfeat/conv5/weights'", ",", "\n", "'overfeat/conv5/biases'", ",", "\n", "'overfeat/fc6/weights'", ",", "\n", "'overfeat/fc6/biases'", ",", "\n", "'overfeat/fc7/weights'", ",", "\n", "'overfeat/fc7/biases'", ",", "\n", "'overfeat/fc8/weights'", ",", "\n", "'overfeat/fc8/biases'", ",", "\n", "]", "\n", "model_variables", "=", "[", "v", ".", "op", ".", "name", "for", "v", "in", "slim", ".", "get_model_variables", "(", ")", "]", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "model_variables", ")", ",", "set", "(", "expected_names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat_test.OverFeatTest.testEvaluation": [[99, 110], ["overfeat_test.OverFeatTest.test_session", "tensorflow.random_uniform", "nets.overfeat.overfeat", "overfeat_test.OverFeatTest.assertListEqual", "tensorflow.argmax", "overfeat_test.OverFeatTest.assertListEqual", "logits.get_shape().as_list", "tensorflow.argmax.get_shape().as_list", "logits.get_shape", "tensorflow.argmax.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat.overfeat"], ["", "", "def", "testEvaluation", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "231", ",", "231", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "overfeat", ".", "overfeat", "(", "eval_inputs", ",", "is_training", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "predictions", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat_test.OverFeatTest.testTrainEvalWithReuse": [[111, 133], ["overfeat_test.OverFeatTest.test_session", "tensorflow.random_uniform", "nets.overfeat.overfeat", "overfeat_test.OverFeatTest.assertListEqual", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.random_uniform", "nets.overfeat.overfeat", "overfeat_test.OverFeatTest.assertListEqual", "tensorflow.reduce_mean", "tensorflow.argmax", "overfeat_test.OverFeatTest.assertEquals", "tensorflow.reduce_mean.get_shape().as_list", "tensorflow.reduce_mean.get_shape().as_list", "tensorflow.argmax.get_shape().as_list", "tensorflow.get_variable_scope", "tensorflow.reduce_mean.get_shape", "tensorflow.reduce_mean.get_shape", "tensorflow.argmax.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat.overfeat", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat.overfeat"], ["", "", "def", "testTrainEvalWithReuse", "(", "self", ")", ":", "\n", "    ", "train_batch_size", "=", "2", "\n", "eval_batch_size", "=", "1", "\n", "train_height", ",", "train_width", "=", "231", ",", "231", "\n", "eval_height", ",", "eval_width", "=", "281", ",", "281", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "train_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "(", "train_batch_size", ",", "train_height", ",", "train_width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "overfeat", ".", "overfeat", "(", "train_inputs", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "train_batch_size", ",", "num_classes", "]", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "(", "eval_batch_size", ",", "eval_height", ",", "eval_width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "overfeat", ".", "overfeat", "(", "eval_inputs", ",", "is_training", "=", "False", ",", "\n", "spatial_squeeze", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "eval_batch_size", ",", "2", ",", "2", ",", "num_classes", "]", ")", "\n", "logits", "=", "tf", ".", "reduce_mean", "(", "logits", ",", "[", "1", ",", "2", "]", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "self", ".", "assertEquals", "(", "predictions", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "eval_batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat_test.OverFeatTest.testForward": [[134, 143], ["overfeat_test.OverFeatTest.test_session", "tensorflow.random_uniform", "nets.overfeat.overfeat", "sess.run", "sess.run", "overfeat_test.OverFeatTest.assertTrue", "tensorflow.global_variables_initializer", "sess.run.any"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat.overfeat", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testForward", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "231", ",", "231", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "overfeat", ".", "overfeat", "(", "inputs", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ")", "\n", "self", ".", "assertTrue", "(", "output", ".", "any", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4_test.InceptionTest.testBuildLogits": [[27, 45], ["tensorflow.random_uniform", "nets.inception.inception_v4", "inception_v4_test.InceptionTest.assertTrue", "inception_v4_test.InceptionTest.assertListEqual", "inception_v4_test.InceptionTest.assertTrue", "inception_v4_test.InceptionTest.assertListEqual", "inception_v4_test.InceptionTest.assertTrue", "inception_v4_test.InceptionTest.assertListEqual", "auxlogits.op.name.startswith", "auxlogits.get_shape().as_list", "logits.op.name.startswith", "logits.get_shape().as_list", "predictions.op.name.startswith", "predictions.get_shape().as_list", "auxlogits.get_shape", "logits.get_shape", "predictions.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4"], ["  ", "def", "testBuildLogits", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "inception", ".", "inception_v4", "(", "inputs", ",", "num_classes", ")", "\n", "auxlogits", "=", "end_points", "[", "'AuxLogits'", "]", "\n", "predictions", "=", "end_points", "[", "'Predictions'", "]", "\n", "self", ".", "assertTrue", "(", "auxlogits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV4/AuxLogits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "auxlogits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV4/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "self", ".", "assertTrue", "(", "predictions", ".", "op", ".", "name", ".", "startswith", "(", "\n", "'InceptionV4/Logits/Predictions'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "predictions", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4_test.InceptionTest.testBuildWithoutAuxLogits": [[46, 57], ["tensorflow.random_uniform", "nets.inception.inception_v4", "inception_v4_test.InceptionTest.assertFalse", "inception_v4_test.InceptionTest.assertTrue", "inception_v4_test.InceptionTest.assertListEqual", "logits.op.name.startswith", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4"], ["", "def", "testBuildWithoutAuxLogits", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "endpoints", "=", "inception", ".", "inception_v4", "(", "inputs", ",", "num_classes", ",", "\n", "create_aux_logits", "=", "False", ")", "\n", "self", ".", "assertFalse", "(", "'AuxLogits'", "in", "endpoints", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV4/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4_test.InceptionTest.testAllEndPointsShapes": [[58, 102], ["tensorflow.random_uniform", "nets.inception.inception_v4", "inception_v4_test.InceptionTest.assertItemsEqual", "endpoints_shapes.keys", "end_points.keys", "inception_v4_test.InceptionTest.assertTrue", "inception_v4_test.InceptionTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4"], ["", "def", "testAllEndPointsShapes", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_v4", "(", "inputs", ",", "num_classes", ")", "\n", "endpoints_shapes", "=", "{", "'Conv2d_1a_3x3'", ":", "[", "batch_size", ",", "149", ",", "149", ",", "32", "]", ",", "\n", "'Conv2d_2a_3x3'", ":", "[", "batch_size", ",", "147", ",", "147", ",", "32", "]", ",", "\n", "'Conv2d_2b_3x3'", ":", "[", "batch_size", ",", "147", ",", "147", ",", "64", "]", ",", "\n", "'Mixed_3a'", ":", "[", "batch_size", ",", "73", ",", "73", ",", "160", "]", ",", "\n", "'Mixed_4a'", ":", "[", "batch_size", ",", "71", ",", "71", ",", "192", "]", ",", "\n", "'Mixed_5a'", ":", "[", "batch_size", ",", "35", ",", "35", ",", "384", "]", ",", "\n", "# 4 x Inception-A blocks", "\n", "'Mixed_5b'", ":", "[", "batch_size", ",", "35", ",", "35", ",", "384", "]", ",", "\n", "'Mixed_5c'", ":", "[", "batch_size", ",", "35", ",", "35", ",", "384", "]", ",", "\n", "'Mixed_5d'", ":", "[", "batch_size", ",", "35", ",", "35", ",", "384", "]", ",", "\n", "'Mixed_5e'", ":", "[", "batch_size", ",", "35", ",", "35", ",", "384", "]", ",", "\n", "# Reduction-A block", "\n", "'Mixed_6a'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "1024", "]", ",", "\n", "# 7 x Inception-B blocks", "\n", "'Mixed_6b'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "1024", "]", ",", "\n", "'Mixed_6c'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "1024", "]", ",", "\n", "'Mixed_6d'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "1024", "]", ",", "\n", "'Mixed_6e'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "1024", "]", ",", "\n", "'Mixed_6f'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "1024", "]", ",", "\n", "'Mixed_6g'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "1024", "]", ",", "\n", "'Mixed_6h'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "1024", "]", ",", "\n", "# Reduction-A block", "\n", "'Mixed_7a'", ":", "[", "batch_size", ",", "8", ",", "8", ",", "1536", "]", ",", "\n", "# 3 x Inception-C blocks", "\n", "'Mixed_7b'", ":", "[", "batch_size", ",", "8", ",", "8", ",", "1536", "]", ",", "\n", "'Mixed_7c'", ":", "[", "batch_size", ",", "8", ",", "8", ",", "1536", "]", ",", "\n", "'Mixed_7d'", ":", "[", "batch_size", ",", "8", ",", "8", ",", "1536", "]", ",", "\n", "# Logits and predictions", "\n", "'AuxLogits'", ":", "[", "batch_size", ",", "num_classes", "]", ",", "\n", "'PreLogitsFlatten'", ":", "[", "batch_size", ",", "1536", "]", ",", "\n", "'Logits'", ":", "[", "batch_size", ",", "num_classes", "]", ",", "\n", "'Predictions'", ":", "[", "batch_size", ",", "num_classes", "]", "}", "\n", "self", ".", "assertItemsEqual", "(", "endpoints_shapes", ".", "keys", "(", ")", ",", "end_points", ".", "keys", "(", ")", ")", "\n", "for", "endpoint_name", "in", "endpoints_shapes", ":", "\n", "      ", "expected_shape", "=", "endpoints_shapes", "[", "endpoint_name", "]", "\n", "self", ".", "assertTrue", "(", "endpoint_name", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint_name", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "expected_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4_test.InceptionTest.testBuildBaseNetwork": [[103, 120], ["tensorflow.random_uniform", "nets.inception.inception_v4_base", "inception_v4_test.InceptionTest.assertTrue", "inception_v4_test.InceptionTest.assertListEqual", "inception_v4_test.InceptionTest.assertItemsEqual", "end_points.iteritems", "net.op.name.startswith", "net.get_shape().as_list", "end_points.keys", "inception_v4_test.InceptionTest.assertTrue", "op.name.startswith", "net.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4_base"], ["", "", "def", "testBuildBaseNetwork", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "net", ",", "end_points", "=", "inception", ".", "inception_v4_base", "(", "inputs", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "op", ".", "name", ".", "startswith", "(", "\n", "'InceptionV4/Mixed_7d'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "net", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "batch_size", ",", "8", ",", "8", ",", "1536", "]", ")", "\n", "expected_endpoints", "=", "[", "\n", "'Conv2d_1a_3x3'", ",", "'Conv2d_2a_3x3'", ",", "'Conv2d_2b_3x3'", ",", "'Mixed_3a'", ",", "\n", "'Mixed_4a'", ",", "'Mixed_5a'", ",", "'Mixed_5b'", ",", "'Mixed_5c'", ",", "'Mixed_5d'", ",", "\n", "'Mixed_5e'", ",", "'Mixed_6a'", ",", "'Mixed_6b'", ",", "'Mixed_6c'", ",", "'Mixed_6d'", ",", "\n", "'Mixed_6e'", ",", "'Mixed_6f'", ",", "'Mixed_6g'", ",", "'Mixed_6h'", ",", "'Mixed_7a'", ",", "\n", "'Mixed_7b'", ",", "'Mixed_7c'", ",", "'Mixed_7d'", "]", "\n", "self", ".", "assertItemsEqual", "(", "end_points", ".", "keys", "(", ")", ",", "expected_endpoints", ")", "\n", "for", "name", ",", "op", "in", "end_points", ".", "iteritems", "(", ")", ":", "\n", "      ", "self", ".", "assertTrue", "(", "op", ".", "name", ".", "startswith", "(", "'InceptionV4/'", "+", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4_test.InceptionTest.testBuildOnlyUpToFinalEndpoint": [[121, 138], ["enumerate", "tensorflow.Graph().as_default", "tensorflow.random_uniform", "nets.inception.inception_v4_base", "inception_v4_test.InceptionTest.assertTrue", "inception_v4_test.InceptionTest.assertItemsEqual", "out_tensor.op.name.startswith", "tensorflow.Graph"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4_base"], ["", "", "def", "testBuildOnlyUpToFinalEndpoint", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "all_endpoints", "=", "[", "\n", "'Conv2d_1a_3x3'", ",", "'Conv2d_2a_3x3'", ",", "'Conv2d_2b_3x3'", ",", "'Mixed_3a'", ",", "\n", "'Mixed_4a'", ",", "'Mixed_5a'", ",", "'Mixed_5b'", ",", "'Mixed_5c'", ",", "'Mixed_5d'", ",", "\n", "'Mixed_5e'", ",", "'Mixed_6a'", ",", "'Mixed_6b'", ",", "'Mixed_6c'", ",", "'Mixed_6d'", ",", "\n", "'Mixed_6e'", ",", "'Mixed_6f'", ",", "'Mixed_6g'", ",", "'Mixed_6h'", ",", "'Mixed_7a'", ",", "\n", "'Mixed_7b'", ",", "'Mixed_7c'", ",", "'Mixed_7d'", "]", "\n", "for", "index", ",", "endpoint", "in", "enumerate", "(", "all_endpoints", ")", ":", "\n", "      ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "out_tensor", ",", "end_points", "=", "inception", ".", "inception_v4_base", "(", "\n", "inputs", ",", "final_endpoint", "=", "endpoint", ")", "\n", "self", ".", "assertTrue", "(", "out_tensor", ".", "op", ".", "name", ".", "startswith", "(", "\n", "'InceptionV4/'", "+", "endpoint", ")", ")", "\n", "self", ".", "assertItemsEqual", "(", "all_endpoints", "[", ":", "index", "+", "1", "]", ",", "end_points", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4_test.InceptionTest.testVariablesSetDevice": [[139, 153], ["tensorflow.random_uniform", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.variable_scope", "tensorflow.device", "nets.inception.inception_v4", "tensorflow.variable_scope", "tensorflow.device", "nets.inception.inception_v4", "inception_v4_test.InceptionTest.assertDeviceEqual", "inception_v4_test.InceptionTest.assertDeviceEqual"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4"], ["", "", "", "def", "testVariablesSetDevice", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "# Force all Variables to reside on the device.", "\n", "with", "tf", ".", "variable_scope", "(", "'on_cpu'", ")", ",", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "      ", "inception", ".", "inception_v4", "(", "inputs", ",", "num_classes", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'on_gpu'", ")", ",", "tf", ".", "device", "(", "'/gpu:0'", ")", ":", "\n", "      ", "inception", ".", "inception_v4", "(", "inputs", ",", "num_classes", ")", "\n", "", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "'on_cpu'", ")", ":", "\n", "      ", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'/cpu:0'", ")", "\n", "", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "'on_gpu'", ")", ":", "\n", "      ", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'/gpu:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4_test.InceptionTest.testHalfSizeImages": [[154, 166], ["tensorflow.random_uniform", "nets.inception.inception_v4", "inception_v4_test.InceptionTest.assertTrue", "inception_v4_test.InceptionTest.assertListEqual", "inception_v4_test.InceptionTest.assertListEqual", "logits.op.name.startswith", "logits.get_shape().as_list", "pre_pool.get_shape().as_list", "logits.get_shape", "pre_pool.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4"], ["", "", "def", "testHalfSizeImages", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "150", ",", "150", "\n", "num_classes", "=", "1000", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "inception", ".", "inception_v4", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV4/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "pre_pool", "=", "end_points", "[", "'Mixed_7d'", "]", "\n", "self", ".", "assertListEqual", "(", "pre_pool", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "3", ",", "3", ",", "1536", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4_test.InceptionTest.testUnknownBatchSize": [[167, 181], ["inception_v4_test.InceptionTest.test_session", "tensorflow.placeholder", "nets.inception.inception_v4", "inception_v4_test.InceptionTest.assertTrue", "inception_v4_test.InceptionTest.assertListEqual", "tensorflow.random_uniform", "sess.run", "sess.run", "inception_v4_test.InceptionTest.assertEquals", "logits.op.name.startswith", "logits.get_shape().as_list", "tensorflow.global_variables_initializer", "tensorflow.random_uniform.eval", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "testUnknownBatchSize", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v4", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV4/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "None", ",", "num_classes", "]", ")", "\n", "images", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ",", "{", "inputs", ":", "images", ".", "eval", "(", ")", "}", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "batch_size", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4_test.InceptionTest.testEvaluation": [[182, 195], ["inception_v4_test.InceptionTest.test_session", "tensorflow.random_uniform", "nets.inception.inception_v4", "tensorflow.argmax", "sess.run", "sess.run", "inception_v4_test.InceptionTest.assertEquals", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testEvaluation", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v4", "(", "eval_inputs", ",", "\n", "num_classes", ",", "\n", "is_training", "=", "False", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "predictions", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4_test.InceptionTest.testTrainEvalWithReuse": [[196, 213], ["inception_v4_test.InceptionTest.test_session", "tensorflow.random_uniform", "nets.inception.inception_v4", "tensorflow.random_uniform", "nets.inception.inception_v4", "tensorflow.argmax", "sess.run", "sess.run", "inception_v4_test.InceptionTest.assertEquals", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v4.inception_v4", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testTrainEvalWithReuse", "(", "self", ")", ":", "\n", "    ", "train_batch_size", "=", "5", "\n", "eval_batch_size", "=", "2", "\n", "height", ",", "width", "=", "150", ",", "150", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "train_inputs", "=", "tf", ".", "random_uniform", "(", "(", "train_batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "inception", ".", "inception_v4", "(", "train_inputs", ",", "num_classes", ")", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "eval_batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v4", "(", "eval_inputs", ",", "\n", "num_classes", ",", "\n", "is_training", "=", "False", ",", "\n", "reuse", "=", "True", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "predictions", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "eval_batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2_base": [[29, 414], ["ValueError", "max", "tensorflow.variable_scope", "ValueError", "int", "slim.arg_scope", "min", "slim.separable_conv2d", "slim.max_pool2d", "slim.conv2d", "slim.conv2d", "slim.max_pool2d", "int", "depth", "depth", "depth", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "trunc_normal", "trunc_normal", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal", "trunc_normal"], "function", ["None"], ["def", "inception_v2_base", "(", "inputs", ",", "\n", "final_endpoint", "=", "'Mixed_5c'", ",", "\n", "min_depth", "=", "16", ",", "\n", "depth_multiplier", "=", "1.0", ",", "\n", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Inception v2 (6a2).\n\n  Constructs an Inception v2 network from inputs to the given final endpoint.\n  This method can construct the network up to the layer inception(5b) as\n  described in http://arxiv.org/abs/1502.03167.\n\n  Args:\n    inputs: a tensor of shape [batch_size, height, width, channels].\n    final_endpoint: specifies the endpoint to construct the network up to. It\n      can be one of ['Conv2d_1a_7x7', 'MaxPool_2a_3x3', 'Conv2d_2b_1x1',\n      'Conv2d_2c_3x3', 'MaxPool_3a_3x3', 'Mixed_3b', 'Mixed_3c', 'Mixed_4a',\n      'Mixed_4b', 'Mixed_4c', 'Mixed_4d', 'Mixed_4e', 'Mixed_5a', 'Mixed_5b',\n      'Mixed_5c'].\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\n      Enforced when depth_multiplier < 1, and not an active constraint when\n      depth_multiplier >= 1.\n    depth_multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n    scope: Optional variable_scope.\n\n  Returns:\n    tensor_out: output tensor corresponding to the final_endpoint.\n    end_points: a set of activations for external use, for example summaries or\n                losses.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values,\n                or depth_multiplier <= 0\n  \"\"\"", "\n", "\n", "# end_points will collect relevant activations for external use, for example", "\n", "# summaries or losses.", "\n", "end_points", "=", "{", "}", "\n", "\n", "# Used to find thinned depths for each layer.", "\n", "if", "depth_multiplier", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "'depth_multiplier is not greater than zero.'", ")", "\n", "", "depth", "=", "lambda", "d", ":", "max", "(", "int", "(", "d", "*", "depth_multiplier", ")", ",", "min_depth", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV2'", ",", "[", "inputs", "]", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", ",", "slim", ".", "separable_conv2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "\n", "# Note that sizes in the comments below assume an input spatial size of", "\n", "# 224x224, however, the inputs can be of any size greater 32x32.", "\n", "\n", "# 224 x 224 x 3", "\n", "      ", "end_point", "=", "'Conv2d_1a_7x7'", "\n", "# depthwise_multiplier here is different from depth_multiplier.", "\n", "# depthwise_multiplier determines the output channels of the initial", "\n", "# depthwise conv (see docs for tf.nn.separable_conv2d), while", "\n", "# depth_multiplier controls the # channels of the subsequent 1x1", "\n", "# convolution. Must have", "\n", "#   in_channels * depthwise_multipler <= out_channels", "\n", "# so that the separable convolution is not overparameterized.", "\n", "depthwise_multiplier", "=", "min", "(", "int", "(", "depth", "(", "64", ")", "/", "3", ")", ",", "8", ")", "\n", "net", "=", "slim", ".", "separable_conv2d", "(", "\n", "inputs", ",", "depth", "(", "64", ")", ",", "[", "7", ",", "7", "]", ",", "depth_multiplier", "=", "depthwise_multiplier", ",", "\n", "stride", "=", "2", ",", "weights_initializer", "=", "trunc_normal", "(", "1.0", ")", ",", "\n", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 112 x 112 x 64", "\n", "end_point", "=", "'MaxPool_2a_3x3'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "end_point", ",", "stride", "=", "2", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 56 x 56 x 64", "\n", "end_point", "=", "'Conv2d_2b_1x1'", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "end_point", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.1", ")", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 56 x 56 x 64", "\n", "end_point", "=", "'Conv2d_2c_3x3'", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "192", ")", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 56 x 56 x 192", "\n", "end_point", "=", "'MaxPool_3a_3x3'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "end_point", ",", "stride", "=", "2", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 28 x 28 x 192", "\n", "# Inception module.", "\n", "end_point", "=", "'Mixed_3b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "64", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "\n", "branch_3", ",", "depth", "(", "32", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.1", ")", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 28 x 28 x 256", "\n", "", "end_point", "=", "'Mixed_3c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "\n", "branch_3", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.1", ")", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 28 x 28 x 320", "\n", "", "end_point", "=", "'Mixed_4a'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_0", "=", "slim", ".", "conv2d", "(", "branch_0", ",", "depth", "(", "160", ")", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "branch_1", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "branch_1", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "max_pool2d", "(", "\n", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", "]", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 14 x 14 x 576", "\n", "", "end_point", "=", "'Mixed_4b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "224", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "branch_1", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "96", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "128", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "128", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "\n", "branch_3", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.1", ")", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 14 x 14 x 576", "\n", "", "end_point", "=", "'Mixed_4c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "96", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "128", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "96", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "128", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "128", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "\n", "branch_3", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.1", ")", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 14 x 14 x 576", "\n", "", "end_point", "=", "'Mixed_4d'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "160", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "160", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "160", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "160", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "\n", "branch_3", ",", "depth", "(", "96", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.1", ")", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "\n", "# 14 x 14 x 576", "\n", "", "end_point", "=", "'Mixed_4e'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "96", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "192", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "160", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "192", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "192", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "\n", "branch_3", ",", "depth", "(", "96", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.1", ")", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 14 x 14 x 576", "\n", "", "end_point", "=", "'Mixed_5a'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_0", "=", "slim", ".", "conv2d", "(", "branch_0", ",", "depth", "(", "192", ")", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "256", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "256", ")", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", "]", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 7 x 7 x 1024", "\n", "", "end_point", "=", "'Mixed_5b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "352", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "320", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "160", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "224", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "224", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "\n", "branch_3", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.1", ")", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "\n", "# 7 x 7 x 1024", "\n", "", "end_point", "=", "'Mixed_5c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "352", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "320", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "\n", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.09", ")", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "224", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "224", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "\n", "branch_3", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.1", ")", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "", "", "raise", "ValueError", "(", "'Unknown final endpoint %s'", "%", "final_endpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2": [[416, 486], ["ValueError", "tensorflow.variable_scope", "slim.arg_scope", "inception_v2.inception_v2_base", "prediction_fn", "tensorflow.variable_scope", "inception_v2._reduced_kernel_size_for_small_input", "slim.avg_pool2d", "slim.dropout", "slim.conv2d", "tensorflow.squeeze"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2.inception_v2_base", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.mobilenet_v1._reduced_kernel_size_for_small_input"], ["", "", "def", "inception_v2", "(", "inputs", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.8", ",", "\n", "min_depth", "=", "16", ",", "\n", "depth_multiplier", "=", "1.0", ",", "\n", "prediction_fn", "=", "slim", ".", "softmax", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'InceptionV2'", ")", ":", "\n", "  ", "\"\"\"Inception v2 model for classification.\n\n  Constructs an Inception v2 network for classification as described in\n  http://arxiv.org/abs/1502.03167.\n\n  The default image size used to train this network is 224x224.\n\n  Args:\n    inputs: a tensor of shape [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    is_training: whether is training or not.\n    dropout_keep_prob: the percentage of activation values that are retained.\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\n      Enforced when depth_multiplier < 1, and not an active constraint when\n      depth_multiplier >= 1.\n    depth_multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n    prediction_fn: a function to get predictions out of logits.\n    spatial_squeeze: if True, logits is of shape [B, C], if false logits is\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    scope: Optional variable_scope.\n\n  Returns:\n    logits: the pre-softmax activations, a tensor of size\n      [batch_size, num_classes]\n    end_points: a dictionary from components of the network to the corresponding\n      activation.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values,\n                or depth_multiplier <= 0\n  \"\"\"", "\n", "if", "depth_multiplier", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "'depth_multiplier is not greater than zero.'", ")", "\n", "\n", "# Final pooling and prediction", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV2'", ",", "[", "inputs", ",", "num_classes", "]", ",", "\n", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "\n", "is_training", "=", "is_training", ")", ":", "\n", "      ", "net", ",", "end_points", "=", "inception_v2_base", "(", "\n", "inputs", ",", "scope", "=", "scope", ",", "min_depth", "=", "min_depth", ",", "\n", "depth_multiplier", "=", "depth_multiplier", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Logits'", ")", ":", "\n", "        ", "kernel_size", "=", "_reduced_kernel_size_for_small_input", "(", "net", ",", "[", "7", ",", "7", "]", ")", "\n", "net", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "kernel_size", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'AvgPool_1a_{}x{}'", ".", "format", "(", "*", "kernel_size", ")", ")", "\n", "# 1 x 1 x 1024", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "keep_prob", "=", "dropout_keep_prob", ",", "scope", "=", "'Dropout_1b'", ")", "\n", "logits", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "scope", "=", "'Conv2d_1c_1x1'", ")", "\n", "if", "spatial_squeeze", ":", "\n", "          ", "logits", "=", "tf", ".", "squeeze", "(", "logits", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'SpatialSqueeze'", ")", "\n", "", "", "end_points", "[", "'Logits'", "]", "=", "logits", "\n", "end_points", "[", "'Predictions'", "]", "=", "prediction_fn", "(", "logits", ",", "scope", "=", "'Predictions'", ")", "\n", "", "", "return", "logits", ",", "end_points", "\n", "", "inception_v2", ".", "default_image_size", "=", "224", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v2._reduced_kernel_size_for_small_input": [[489, 518], ["input_tensor.get_shape().as_list", "input_tensor.get_shape", "min", "min"], "function", ["None"], ["def", "_reduced_kernel_size_for_small_input", "(", "input_tensor", ",", "kernel_size", ")", ":", "\n", "  ", "\"\"\"Define kernel size which is automatically reduced for small input.\n\n  If the shape of the input images is unknown at graph construction time this\n  function assumes that the input images are is large enough.\n\n  Args:\n    input_tensor: input tensor of size [batch_size, height, width, channels].\n    kernel_size: desired kernel size of length 2: [kernel_height, kernel_width]\n\n  Returns:\n    a tensor with the kernel size.\n\n  TODO(jrru): Make this function work with unknown shapes. Theoretically, this\n  can be done with the code below. Problems are two-fold: (1) If the shape was\n  known, it will be lost. (2) inception.slim.ops._two_element_tuple cannot\n  handle tensors that define the kernel size.\n      shape = tf.shape(input_tensor)\n      return = tf.pack([tf.minimum(shape[1], kernel_size[0]),\n                        tf.minimum(shape[2], kernel_size[1])])\n\n  \"\"\"", "\n", "shape", "=", "input_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "if", "shape", "[", "1", "]", "is", "None", "or", "shape", "[", "2", "]", "is", "None", ":", "\n", "    ", "kernel_size_out", "=", "kernel_size", "\n", "", "else", ":", "\n", "    ", "kernel_size_out", "=", "[", "min", "(", "shape", "[", "1", "]", ",", "kernel_size", "[", "0", "]", ")", ",", "\n", "min", "(", "shape", "[", "2", "]", ",", "kernel_size", "[", "1", "]", ")", "]", "\n", "", "return", "kernel_size_out", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3_base": [[29, 417], ["ValueError", "max", "tensorflow.variable_scope", "ValueError", "int", "slim.arg_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.max_pool2d", "slim.conv2d", "slim.conv2d", "slim.max_pool2d", "slim.arg_scope", "depth", "depth", "depth", "depth", "depth", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.concat", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.concat", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "depth", "depth", "depth", "depth", "depth", "depth", "depth", "depth"], "function", ["None"], ["def", "inception_v3_base", "(", "inputs", ",", "\n", "final_endpoint", "=", "'Mixed_7c'", ",", "\n", "min_depth", "=", "16", ",", "\n", "depth_multiplier", "=", "1.0", ",", "\n", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Inception model from http://arxiv.org/abs/1512.00567.\n\n  Constructs an Inception v3 network from inputs to the given final endpoint.\n  This method can construct the network up to the final inception block\n  Mixed_7c.\n\n  Note that the names of the layers in the paper do not correspond to the names\n  of the endpoints registered by this function although they build the same\n  network.\n\n  Here is a mapping from the old_names to the new names:\n  Old name          | New name\n  =======================================\n  conv0             | Conv2d_1a_3x3\n  conv1             | Conv2d_2a_3x3\n  conv2             | Conv2d_2b_3x3\n  pool1             | MaxPool_3a_3x3\n  conv3             | Conv2d_3b_1x1\n  conv4             | Conv2d_4a_3x3\n  pool2             | MaxPool_5a_3x3\n  mixed_35x35x256a  | Mixed_5b\n  mixed_35x35x288a  | Mixed_5c\n  mixed_35x35x288b  | Mixed_5d\n  mixed_17x17x768a  | Mixed_6a\n  mixed_17x17x768b  | Mixed_6b\n  mixed_17x17x768c  | Mixed_6c\n  mixed_17x17x768d  | Mixed_6d\n  mixed_17x17x768e  | Mixed_6e\n  mixed_8x8x1280a   | Mixed_7a\n  mixed_8x8x2048a   | Mixed_7b\n  mixed_8x8x2048b   | Mixed_7c\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    final_endpoint: specifies the endpoint to construct the network up to. It\n      can be one of ['Conv2d_1a_3x3', 'Conv2d_2a_3x3', 'Conv2d_2b_3x3',\n      'MaxPool_3a_3x3', 'Conv2d_3b_1x1', 'Conv2d_4a_3x3', 'MaxPool_5a_3x3',\n      'Mixed_5b', 'Mixed_5c', 'Mixed_5d', 'Mixed_6a', 'Mixed_6b', 'Mixed_6c',\n      'Mixed_6d', 'Mixed_6e', 'Mixed_7a', 'Mixed_7b', 'Mixed_7c'].\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\n      Enforced when depth_multiplier < 1, and not an active constraint when\n      depth_multiplier >= 1.\n    depth_multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n    scope: Optional variable_scope.\n\n  Returns:\n    tensor_out: output tensor corresponding to the final_endpoint.\n    end_points: a set of activations for external use, for example summaries or\n                losses.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values,\n                or depth_multiplier <= 0\n  \"\"\"", "\n", "# end_points will collect relevant activations for external use, for example", "\n", "# summaries or losses.", "\n", "end_points", "=", "{", "}", "\n", "\n", "if", "depth_multiplier", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "'depth_multiplier is not greater than zero.'", ")", "\n", "", "depth", "=", "lambda", "d", ":", "max", "(", "int", "(", "d", "*", "depth_multiplier", ")", ",", "min_depth", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV3'", ",", "[", "inputs", "]", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'VALID'", ")", ":", "\n", "# 299 x 299 x 3", "\n", "      ", "end_point", "=", "'Conv2d_1a_3x3'", "\n", "net", "=", "slim", ".", "conv2d", "(", "inputs", ",", "depth", "(", "32", ")", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 149 x 149 x 32", "\n", "end_point", "=", "'Conv2d_2a_3x3'", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "32", ")", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 147 x 147 x 32", "\n", "end_point", "=", "'Conv2d_2b_3x3'", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "64", ")", ",", "[", "3", ",", "3", "]", ",", "padding", "=", "'SAME'", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 147 x 147 x 64", "\n", "end_point", "=", "'MaxPool_3a_3x3'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 73 x 73 x 64", "\n", "end_point", "=", "'Conv2d_3b_1x1'", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "80", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 73 x 73 x 80.", "\n", "end_point", "=", "'Conv2d_4a_3x3'", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "192", ")", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 71 x 71 x 192.", "\n", "end_point", "=", "'MaxPool_5a_3x3'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# 35 x 35 x 192.", "\n", "\n", "# Inception blocks", "\n", "", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "# mixed: 35 x 35 x 256.", "\n", "      ", "end_point", "=", "'Mixed_5b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "48", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "64", ")", ",", "[", "5", ",", "5", "]", ",", "\n", "scope", "=", "'Conv2d_0b_5x5'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "depth", "(", "32", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "\n", "# mixed_1: 35 x 35 x 288.", "\n", "end_point", "=", "'Mixed_5c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "48", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "64", ")", ",", "[", "5", ",", "5", "]", ",", "\n", "scope", "=", "'Conv_1_0c_5x5'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "\n", "# mixed_2: 35 x 35 x 288.", "\n", "end_point", "=", "'Mixed_5d'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "48", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "64", ")", ",", "[", "5", ",", "5", "]", ",", "\n", "scope", "=", "'Conv2d_0b_5x5'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "\n", "# mixed_3: 17 x 17 x 768.", "\n", "end_point", "=", "'Mixed_6a'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "384", ")", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "64", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "96", ")", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "\n", "# mixed4: 17 x 17 x 768.", "\n", "end_point", "=", "'Mixed_6b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "192", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "128", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0b_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0c_1x7'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "128", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0d_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0e_1x7'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "\n", "# mixed_5: 17 x 17 x 768.", "\n", "end_point", "=", "'Mixed_6c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "160", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "160", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "192", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "160", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "160", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0b_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "160", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0c_1x7'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "160", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0d_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0e_1x7'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# mixed_6: 17 x 17 x 768.", "\n", "end_point", "=", "'Mixed_6d'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "160", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "160", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "192", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "160", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "160", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0b_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "160", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0c_1x7'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "160", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0d_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0e_1x7'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "\n", "# mixed_7: 17 x 17 x 768.", "\n", "end_point", "=", "'Mixed_6e'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "192", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "192", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0b_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0c_1x7'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "192", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0d_7x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0e_1x7'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "\n", "# mixed_8: 8 x 8 x 1280.", "\n", "end_point", "=", "'Mixed_7a'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_0", "=", "slim", ".", "conv2d", "(", "branch_0", ",", "depth", "(", "320", ")", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "192", ")", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "192", ")", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "# mixed_9: 8 x 8 x 2048.", "\n", "end_point", "=", "'Mixed_7b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "320", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "384", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "\n", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "384", ")", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_1x3'", ")", ",", "\n", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "384", ")", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_3x1'", ")", "]", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "448", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "\n", "branch_2", ",", "depth", "(", "384", ")", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "\n", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "384", ")", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0c_1x3'", ")", ",", "\n", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "384", ")", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0d_3x1'", ")", "]", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "\n", "branch_3", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "\n", "# mixed_10: 8 x 8 x 2048.", "\n", "end_point", "=", "'Mixed_7c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "320", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "384", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "\n", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "384", ")", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_1x3'", ")", ",", "\n", "slim", ".", "conv2d", "(", "branch_1", ",", "depth", "(", "384", ")", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0c_3x1'", ")", "]", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "448", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "\n", "branch_2", ",", "depth", "(", "384", ")", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "branch_2", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "\n", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "384", ")", ",", "[", "1", ",", "3", "]", ",", "scope", "=", "'Conv2d_0c_1x3'", ")", ",", "\n", "slim", ".", "conv2d", "(", "branch_2", ",", "depth", "(", "384", ")", ",", "[", "3", ",", "1", "]", ",", "scope", "=", "'Conv2d_0d_3x1'", ")", "]", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "branch_3", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "\n", "branch_3", ",", "depth", "(", "192", ")", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "return", "net", ",", "end_points", "\n", "", "raise", "ValueError", "(", "'Unknown final endpoint %s'", "%", "final_endpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3": [[419, 526], ["ValueError", "max", "tensorflow.variable_scope", "int", "slim.arg_scope", "inception_v3.inception_v3_base", "prediction_fn", "slim.arg_scope", "tensorflow.variable_scope", "inception_v3._reduced_kernel_size_for_small_input", "slim.avg_pool2d", "slim.dropout", "slim.conv2d", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "inception_v3._reduced_kernel_size_for_small_input", "slim.conv2d", "slim.conv2d", "tensorflow.squeeze", "depth", "depth", "tensorflow.squeeze", "trunc_normal", "trunc_normal"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3_base", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.mobilenet_v1._reduced_kernel_size_for_small_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.mobilenet_v1._reduced_kernel_size_for_small_input"], ["", "", "def", "inception_v3", "(", "inputs", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.8", ",", "\n", "min_depth", "=", "16", ",", "\n", "depth_multiplier", "=", "1.0", ",", "\n", "prediction_fn", "=", "slim", ".", "softmax", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'InceptionV3'", ")", ":", "\n", "  ", "\"\"\"Inception model from http://arxiv.org/abs/1512.00567.\n\n  \"Rethinking the Inception Architecture for Computer Vision\"\n\n  Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens,\n  Zbigniew Wojna.\n\n  With the default arguments this method constructs the exact model defined in\n  the paper. However, one can experiment with variations of the inception_v3\n  network by changing arguments dropout_keep_prob, min_depth and\n  depth_multiplier.\n\n  The default image size used to train this network is 299x299.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    is_training: whether is training or not.\n    dropout_keep_prob: the percentage of activation values that are retained.\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\n      Enforced when depth_multiplier < 1, and not an active constraint when\n      depth_multiplier >= 1.\n    depth_multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n    prediction_fn: a function to get predictions out of logits.\n    spatial_squeeze: if True, logits is of shape [B, C], if false logits is\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    scope: Optional variable_scope.\n\n  Returns:\n    logits: the pre-softmax activations, a tensor of size\n      [batch_size, num_classes]\n    end_points: a dictionary from components of the network to the corresponding\n      activation.\n\n  Raises:\n    ValueError: if 'depth_multiplier' is less than or equal to zero.\n  \"\"\"", "\n", "if", "depth_multiplier", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "'depth_multiplier is not greater than zero.'", ")", "\n", "", "depth", "=", "lambda", "d", ":", "max", "(", "int", "(", "d", "*", "depth_multiplier", ")", ",", "min_depth", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV3'", ",", "[", "inputs", ",", "num_classes", "]", ",", "\n", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "\n", "is_training", "=", "is_training", ")", ":", "\n", "      ", "net", ",", "end_points", "=", "inception_v3_base", "(", "\n", "inputs", ",", "scope", "=", "scope", ",", "min_depth", "=", "min_depth", ",", "\n", "depth_multiplier", "=", "depth_multiplier", ")", "\n", "\n", "# Auxiliary Head logits", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "        ", "aux_logits", "=", "end_points", "[", "'Mixed_6e'", "]", "\n", "with", "tf", ".", "variable_scope", "(", "'AuxLogits'", ")", ":", "\n", "          ", "aux_logits", "=", "slim", ".", "avg_pool2d", "(", "\n", "aux_logits", ",", "[", "5", ",", "5", "]", ",", "stride", "=", "3", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'AvgPool_1a_5x5'", ")", "\n", "aux_logits", "=", "slim", ".", "conv2d", "(", "aux_logits", ",", "depth", "(", "128", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_1b_1x1'", ")", "\n", "\n", "# Shape of feature map before the final layer.", "\n", "kernel_size", "=", "_reduced_kernel_size_for_small_input", "(", "\n", "aux_logits", ",", "[", "5", ",", "5", "]", ")", "\n", "aux_logits", "=", "slim", ".", "conv2d", "(", "\n", "aux_logits", ",", "depth", "(", "768", ")", ",", "kernel_size", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.01", ")", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_2a_{}x{}'", ".", "format", "(", "*", "kernel_size", ")", ")", "\n", "aux_logits", "=", "slim", ".", "conv2d", "(", "\n", "aux_logits", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "weights_initializer", "=", "trunc_normal", "(", "0.001", ")", ",", "\n", "scope", "=", "'Conv2d_2b_1x1'", ")", "\n", "if", "spatial_squeeze", ":", "\n", "            ", "aux_logits", "=", "tf", ".", "squeeze", "(", "aux_logits", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'SpatialSqueeze'", ")", "\n", "", "end_points", "[", "'AuxLogits'", "]", "=", "aux_logits", "\n", "\n", "# Final pooling and prediction", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Logits'", ")", ":", "\n", "        ", "kernel_size", "=", "_reduced_kernel_size_for_small_input", "(", "net", ",", "[", "8", ",", "8", "]", ")", "\n", "net", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "kernel_size", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'AvgPool_1a_{}x{}'", ".", "format", "(", "*", "kernel_size", ")", ")", "\n", "# 1 x 1 x 2048", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "keep_prob", "=", "dropout_keep_prob", ",", "scope", "=", "'Dropout_1b'", ")", "\n", "end_points", "[", "'PreLogits'", "]", "=", "net", "\n", "# 2048", "\n", "logits", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "scope", "=", "'Conv2d_1c_1x1'", ")", "\n", "if", "spatial_squeeze", ":", "\n", "          ", "logits", "=", "tf", ".", "squeeze", "(", "logits", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'SpatialSqueeze'", ")", "\n", "# 1000", "\n", "", "", "end_points", "[", "'Logits'", "]", "=", "logits", "\n", "end_points", "[", "'Predictions'", "]", "=", "prediction_fn", "(", "logits", ",", "scope", "=", "'Predictions'", ")", "\n", "", "", "return", "logits", ",", "end_points", "\n", "", "inception_v3", ".", "default_image_size", "=", "299", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3._reduced_kernel_size_for_small_input": [[529, 558], ["input_tensor.get_shape().as_list", "input_tensor.get_shape", "min", "min"], "function", ["None"], ["def", "_reduced_kernel_size_for_small_input", "(", "input_tensor", ",", "kernel_size", ")", ":", "\n", "  ", "\"\"\"Define kernel size which is automatically reduced for small input.\n\n  If the shape of the input images is unknown at graph construction time this\n  function assumes that the input images are is large enough.\n\n  Args:\n    input_tensor: input tensor of size [batch_size, height, width, channels].\n    kernel_size: desired kernel size of length 2: [kernel_height, kernel_width]\n\n  Returns:\n    a tensor with the kernel size.\n\n  TODO(jrru): Make this function work with unknown shapes. Theoretically, this\n  can be done with the code below. Problems are two-fold: (1) If the shape was\n  known, it will be lost. (2) inception.slim.ops._two_element_tuple cannot\n  handle tensors that define the kernel size.\n      shape = tf.shape(input_tensor)\n      return = tf.pack([tf.minimum(shape[1], kernel_size[0]),\n                        tf.minimum(shape[2], kernel_size[1])])\n\n  \"\"\"", "\n", "shape", "=", "input_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "if", "shape", "[", "1", "]", "is", "None", "or", "shape", "[", "2", "]", "is", "None", ":", "\n", "    ", "kernel_size_out", "=", "kernel_size", "\n", "", "else", ":", "\n", "    ", "kernel_size_out", "=", "[", "min", "(", "shape", "[", "1", "]", ",", "kernel_size", "[", "0", "]", ")", ",", "\n", "min", "(", "shape", "[", "2", "]", ",", "kernel_size", "[", "1", "]", ")", "]", "\n", "", "return", "kernel_size_out", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_arg_scope": [[49, 64], ["slim.arg_scope", "slim.arg_scope", "slim.l2_regularizer", "tensorflow.zeros_initializer"], "function", ["None"], ["def", "vgg_arg_scope", "(", "weight_decay", "=", "0.0005", ")", ":", "\n", "  ", "\"\"\"Defines the VGG arg scope.\n\n  Args:\n    weight_decay: The l2 regularization coefficient.\n\n  Returns:\n    An arg_scope.\n  \"\"\"", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "padding", "=", "'SAME'", ")", "as", "arg_sc", ":", "\n", "      ", "return", "arg_sc", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_a": [[66, 128], ["tensorflow.variable_scope", "slim.arg_scope", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.conv2d", "slim.dropout", "slim.conv2d", "slim.dropout", "slim.conv2d", "slim.utils.convert_collection_to_dict", "tensorflow.squeeze"], "function", ["None"], ["", "", "", "def", "vgg_a", "(", "inputs", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.5", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "scope", "=", "'vgg_a'", ",", "\n", "fc_conv_padding", "=", "'VALID'", ")", ":", "\n", "  ", "\"\"\"Oxford Net VGG 11-Layers version A Example.\n\n  Note: All the fully_connected layers have been transformed to conv2d layers.\n        To use in classification mode, resize input to 224x224.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    is_training: whether or not the model is being trained.\n    dropout_keep_prob: the probability that activations are kept in the dropout\n      layers during training.\n    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n      outputs. Useful to remove unnecessary dimensions for classification.\n    scope: Optional scope for the variables.\n    fc_conv_padding: the type of padding to use for the fully connected layer\n      that is implemented as a convolutional layer. Use 'SAME' padding if you\n      are applying the network in a fully convolutional manner and want to\n      get a prediction map downsampled by a factor of 32 as an output. Otherwise,\n      the output prediction map will be (input / 32) - 6 in case of 'VALID' padding.\n\n  Returns:\n    the last op containing the log predictions and end_points dict.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'vgg_a'", ",", "[", "inputs", "]", ")", "as", "sc", ":", "\n", "    ", "end_points_collection", "=", "sc", ".", "name", "+", "'_end_points'", "\n", "# Collect outputs for conv2d, fully_connected and max_pool2d.", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "outputs_collections", "=", "end_points_collection", ")", ":", "\n", "      ", "net", "=", "slim", ".", "repeat", "(", "inputs", ",", "1", ",", "slim", ".", "conv2d", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv1'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool1'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "1", ",", "slim", ".", "conv2d", ",", "128", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv2'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool2'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "2", ",", "slim", ".", "conv2d", ",", "256", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv3'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool3'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "2", ",", "slim", ".", "conv2d", ",", "512", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv4'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool4'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "2", ",", "slim", ".", "conv2d", ",", "512", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv5'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool5'", ")", "\n", "# Use conv2d instead of fully_connected layers.", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "4096", ",", "[", "7", ",", "7", "]", ",", "padding", "=", "fc_conv_padding", ",", "scope", "=", "'fc6'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout6'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "4096", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'fc7'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout7'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "\n", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "\n", "scope", "=", "'fc8'", ")", "\n", "# Convert end_points_collection into a end_point dict.", "\n", "end_points", "=", "slim", ".", "utils", ".", "convert_collection_to_dict", "(", "end_points_collection", ")", "\n", "if", "spatial_squeeze", ":", "\n", "        ", "net", "=", "tf", ".", "squeeze", "(", "net", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'fc8/squeezed'", ")", "\n", "end_points", "[", "sc", ".", "name", "+", "'/fc8'", "]", "=", "net", "\n", "", "return", "net", ",", "end_points", "\n", "", "", "", "vgg_a", ".", "default_image_size", "=", "224", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_16": [[131, 193], ["tensorflow.variable_scope", "slim.arg_scope", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.conv2d", "slim.dropout", "slim.conv2d", "slim.dropout", "slim.conv2d", "slim.utils.convert_collection_to_dict", "tensorflow.squeeze"], "function", ["None"], ["def", "vgg_16", "(", "inputs", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.5", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "scope", "=", "'vgg_16'", ",", "\n", "fc_conv_padding", "=", "'VALID'", ")", ":", "\n", "  ", "\"\"\"Oxford Net VGG 16-Layers version D Example.\n\n  Note: All the fully_connected layers have been transformed to conv2d layers.\n        To use in classification mode, resize input to 224x224.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    is_training: whether or not the model is being trained.\n    dropout_keep_prob: the probability that activations are kept in the dropout\n      layers during training.\n    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n      outputs. Useful to remove unnecessary dimensions for classification.\n    scope: Optional scope for the variables.\n    fc_conv_padding: the type of padding to use for the fully connected layer\n      that is implemented as a convolutional layer. Use 'SAME' padding if you\n      are applying the network in a fully convolutional manner and want to\n      get a prediction map downsampled by a factor of 32 as an output. Otherwise,\n      the output prediction map will be (input / 32) - 6 in case of 'VALID' padding.\n\n  Returns:\n    the last op containing the log predictions and end_points dict.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'vgg_16'", ",", "[", "inputs", "]", ")", "as", "sc", ":", "\n", "    ", "end_points_collection", "=", "sc", ".", "name", "+", "'_end_points'", "\n", "# Collect outputs for conv2d, fully_connected and max_pool2d.", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "outputs_collections", "=", "end_points_collection", ")", ":", "\n", "      ", "net", "=", "slim", ".", "repeat", "(", "inputs", ",", "2", ",", "slim", ".", "conv2d", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv1'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool1'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "2", ",", "slim", ".", "conv2d", ",", "128", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv2'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool2'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "3", ",", "slim", ".", "conv2d", ",", "256", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv3'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool3'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "3", ",", "slim", ".", "conv2d", ",", "512", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv4'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool4'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "3", ",", "slim", ".", "conv2d", ",", "512", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv5'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool5'", ")", "\n", "# Use conv2d instead of fully_connected layers.", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "4096", ",", "[", "7", ",", "7", "]", ",", "padding", "=", "fc_conv_padding", ",", "scope", "=", "'fc6'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout6'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "4096", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'fc7'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout7'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "\n", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "\n", "scope", "=", "'fc8'", ")", "\n", "# Convert end_points_collection into a end_point dict.", "\n", "end_points", "=", "slim", ".", "utils", ".", "convert_collection_to_dict", "(", "end_points_collection", ")", "\n", "if", "spatial_squeeze", ":", "\n", "        ", "net", "=", "tf", ".", "squeeze", "(", "net", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'fc8/squeezed'", ")", "\n", "end_points", "[", "sc", ".", "name", "+", "'/fc8'", "]", "=", "net", "\n", "", "return", "net", ",", "end_points", "\n", "", "", "", "vgg_16", ".", "default_image_size", "=", "224", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_19": [[196, 258], ["tensorflow.variable_scope", "slim.arg_scope", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.repeat", "slim.max_pool2d", "slim.conv2d", "slim.dropout", "slim.conv2d", "slim.dropout", "slim.conv2d", "slim.utils.convert_collection_to_dict", "tensorflow.squeeze"], "function", ["None"], ["def", "vgg_19", "(", "inputs", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.5", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "scope", "=", "'vgg_19'", ",", "\n", "fc_conv_padding", "=", "'VALID'", ")", ":", "\n", "  ", "\"\"\"Oxford Net VGG 19-Layers version E Example.\n\n  Note: All the fully_connected layers have been transformed to conv2d layers.\n        To use in classification mode, resize input to 224x224.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    is_training: whether or not the model is being trained.\n    dropout_keep_prob: the probability that activations are kept in the dropout\n      layers during training.\n    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n      outputs. Useful to remove unnecessary dimensions for classification.\n    scope: Optional scope for the variables.\n    fc_conv_padding: the type of padding to use for the fully connected layer\n      that is implemented as a convolutional layer. Use 'SAME' padding if you\n      are applying the network in a fully convolutional manner and want to\n      get a prediction map downsampled by a factor of 32 as an output. Otherwise,\n      the output prediction map will be (input / 32) - 6 in case of 'VALID' padding.\n\n  Returns:\n    the last op containing the log predictions and end_points dict.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'vgg_19'", ",", "[", "inputs", "]", ")", "as", "sc", ":", "\n", "    ", "end_points_collection", "=", "sc", ".", "name", "+", "'_end_points'", "\n", "# Collect outputs for conv2d, fully_connected and max_pool2d.", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "outputs_collections", "=", "end_points_collection", ")", ":", "\n", "      ", "net", "=", "slim", ".", "repeat", "(", "inputs", ",", "2", ",", "slim", ".", "conv2d", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv1'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool1'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "2", ",", "slim", ".", "conv2d", ",", "128", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv2'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool2'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "4", ",", "slim", ".", "conv2d", ",", "256", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv3'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool3'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "4", ",", "slim", ".", "conv2d", ",", "512", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv4'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool4'", ")", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "4", ",", "slim", ".", "conv2d", ",", "512", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv5'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool5'", ")", "\n", "# Use conv2d instead of fully_connected layers.", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "4096", ",", "[", "7", ",", "7", "]", ",", "padding", "=", "fc_conv_padding", ",", "scope", "=", "'fc6'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout6'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "4096", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'fc7'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout7'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "\n", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "\n", "scope", "=", "'fc8'", ")", "\n", "# Convert end_points_collection into a end_point dict.", "\n", "end_points", "=", "slim", ".", "utils", ".", "convert_collection_to_dict", "(", "end_points_collection", ")", "\n", "if", "spatial_squeeze", ":", "\n", "        ", "net", "=", "tf", ".", "squeeze", "(", "net", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'fc8/squeezed'", ")", "\n", "end_points", "[", "sc", ".", "name", "+", "'/fc8'", "]", "=", "net", "\n", "", "return", "net", ",", "end_points", "\n", "", "", "", "vgg_19", ".", "default_image_size", "=", "224", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.nets_factory.get_network_fn": [[84, 113], ["functools.wraps", "hasattr", "ValueError", "slim.arg_scope", "func"], "function", ["None"], ["def", "get_network_fn", "(", "name", ",", "num_classes", ",", "weight_decay", "=", "0.0", ",", "is_training", "=", "False", ")", ":", "\n", "  ", "\"\"\"Returns a network_fn such as `logits, end_points = network_fn(images)`.\n\n  Args:\n    name: The name of the network.\n    num_classes: The number of classes to use for classification.\n    weight_decay: The l2 coefficient for the model weights.\n    is_training: `True` if the model is being used for training and `False`\n      otherwise.\n\n  Returns:\n    network_fn: A function that applies the model to a batch of images. It has\n      the following signature:\n        logits, end_points = network_fn(images)\n  Raises:\n    ValueError: If network `name` is not recognized.\n  \"\"\"", "\n", "if", "name", "not", "in", "networks_map", ":", "\n", "    ", "raise", "ValueError", "(", "'Name of network unknown %s'", "%", "name", ")", "\n", "", "arg_scope", "=", "arg_scopes_map", "[", "name", "]", "(", "weight_decay", "=", "weight_decay", ")", "\n", "func", "=", "networks_map", "[", "name", "]", "\n", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "network_fn", "(", "images", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "arg_scope", ")", ":", "\n", "      ", "return", "func", "(", "images", ",", "num_classes", ",", "is_training", "=", "is_training", ")", "\n", "", "", "if", "hasattr", "(", "func", ",", "'default_image_size'", ")", ":", "\n", "    ", "network_fn", ".", "default_image_size", "=", "func", ".", "default_image_size", "\n", "\n", "", "return", "network_fn", "\n", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.lenet.lenet": [[26, 76], ["prediction_fn", "tensorflow.variable_scope", "slim.conv2d", "slim.max_pool2d", "slim.conv2d", "slim.max_pool2d", "slim.flatten", "slim.fully_connected", "slim.dropout", "slim.fully_connected"], "function", ["None"], ["def", "lenet", "(", "images", ",", "num_classes", "=", "10", ",", "is_training", "=", "False", ",", "\n", "dropout_keep_prob", "=", "0.5", ",", "\n", "prediction_fn", "=", "slim", ".", "softmax", ",", "\n", "scope", "=", "'LeNet'", ")", ":", "\n", "  ", "\"\"\"Creates a variant of the LeNet model.\n\n  Note that since the output is a set of 'logits', the values fall in the\n  interval of (-infinity, infinity). Consequently, to convert the outputs to a\n  probability distribution over the characters, one will need to convert them\n  using the softmax function:\n\n        logits = lenet.lenet(images, is_training=False)\n        probabilities = tf.nn.softmax(logits)\n        predictions = tf.argmax(logits, 1)\n\n  Args:\n    images: A batch of `Tensors` of size [batch_size, height, width, channels].\n    num_classes: the number of classes in the dataset.\n    is_training: specifies whether or not we're currently training the model.\n      This variable will determine the behaviour of the dropout layer.\n    dropout_keep_prob: the percentage of activation values that are retained.\n    prediction_fn: a function to get predictions out of logits.\n    scope: Optional variable_scope.\n\n  Returns:\n    logits: the pre-softmax activations, a tensor of size\n      [batch_size, `num_classes`]\n    end_points: a dictionary from components of the network to the corresponding\n      activation.\n  \"\"\"", "\n", "end_points", "=", "{", "}", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'LeNet'", ",", "[", "images", ",", "num_classes", "]", ")", ":", "\n", "    ", "net", "=", "slim", ".", "conv2d", "(", "images", ",", "32", ",", "[", "5", ",", "5", "]", ",", "scope", "=", "'conv1'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "2", ",", "scope", "=", "'pool1'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "5", ",", "5", "]", ",", "scope", "=", "'conv2'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "2", ",", "scope", "=", "'pool2'", ")", "\n", "net", "=", "slim", ".", "flatten", "(", "net", ")", "\n", "end_points", "[", "'Flatten'", "]", "=", "net", "\n", "\n", "net", "=", "slim", ".", "fully_connected", "(", "net", ",", "1024", ",", "scope", "=", "'fc3'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout3'", ")", "\n", "logits", "=", "slim", ".", "fully_connected", "(", "net", ",", "num_classes", ",", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'fc4'", ")", "\n", "\n", "", "end_points", "[", "'Logits'", "]", "=", "logits", "\n", "end_points", "[", "'Predictions'", "]", "=", "prediction_fn", "(", "logits", ",", "scope", "=", "'Predictions'", ")", "\n", "\n", "return", "logits", ",", "end_points", "\n", "", "lenet", ".", "default_image_size", "=", "28", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.lenet.lenet_arg_scope": [[79, 94], ["slim.arg_scope", "slim.l2_regularizer", "tensorflow.truncated_normal_initializer"], "function", ["None"], ["def", "lenet_arg_scope", "(", "weight_decay", "=", "0.0", ")", ":", "\n", "  ", "\"\"\"Defines the default lenet argument scope.\n\n  Args:\n    weight_decay: The weight decay to use for regularizing the model.\n\n  Returns:\n    An `arg_scope` to use for the inception v3 model.\n  \"\"\"", "\n", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ",", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.1", ")", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "as", "sc", ":", "\n", "    ", "return", "sc", "\n", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1_test.InceptionV1Test.testBuildClassificationNetwork": [[31, 44], ["tensorflow.random_uniform", "nets.inception.inception_v1", "inception_v1_test.InceptionV1Test.assertTrue", "inception_v1_test.InceptionV1Test.assertListEqual", "inception_v1_test.InceptionV1Test.assertTrue", "inception_v1_test.InceptionV1Test.assertListEqual", "logits.op.name.startswith", "logits.get_shape().as_list", "end_points[].get_shape().as_list", "logits.get_shape", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1"], ["  ", "def", "testBuildClassificationNetwork", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "inception", ".", "inception_v1", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV1/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "self", ".", "assertTrue", "(", "'Predictions'", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "'Predictions'", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1_test.InceptionV1Test.testBuildBaseNetwork": [[45, 60], ["tensorflow.random_uniform", "nets.inception.inception_v1_base", "inception_v1_test.InceptionV1Test.assertTrue", "inception_v1_test.InceptionV1Test.assertListEqual", "inception_v1_test.InceptionV1Test.assertItemsEqual", "mixed_6c.op.name.startswith", "mixed_6c.get_shape().as_list", "end_points.keys", "mixed_6c.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1_base"], ["", "def", "testBuildBaseNetwork", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "mixed_6c", ",", "end_points", "=", "inception", ".", "inception_v1_base", "(", "inputs", ")", "\n", "self", ".", "assertTrue", "(", "mixed_6c", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV1/Mixed_5c'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "mixed_6c", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "7", ",", "7", ",", "1024", "]", ")", "\n", "expected_endpoints", "=", "[", "'Conv2d_1a_7x7'", ",", "'MaxPool_2a_3x3'", ",", "'Conv2d_2b_1x1'", ",", "\n", "'Conv2d_2c_3x3'", ",", "'MaxPool_3a_3x3'", ",", "'Mixed_3b'", ",", "\n", "'Mixed_3c'", ",", "'MaxPool_4a_3x3'", ",", "'Mixed_4b'", ",", "'Mixed_4c'", ",", "\n", "'Mixed_4d'", ",", "'Mixed_4e'", ",", "'Mixed_4f'", ",", "'MaxPool_5a_2x2'", ",", "\n", "'Mixed_5b'", ",", "'Mixed_5c'", "]", "\n", "self", ".", "assertItemsEqual", "(", "end_points", ".", "keys", "(", ")", ",", "expected_endpoints", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1_test.InceptionV1Test.testBuildOnlyUptoFinalEndpoint": [[61, 77], ["enumerate", "tensorflow.Graph().as_default", "tensorflow.random_uniform", "nets.inception.inception_v1_base", "inception_v1_test.InceptionV1Test.assertTrue", "inception_v1_test.InceptionV1Test.assertItemsEqual", "out_tensor.op.name.startswith", "tensorflow.Graph"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1_base"], ["", "def", "testBuildOnlyUptoFinalEndpoint", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "endpoints", "=", "[", "'Conv2d_1a_7x7'", ",", "'MaxPool_2a_3x3'", ",", "'Conv2d_2b_1x1'", ",", "\n", "'Conv2d_2c_3x3'", ",", "'MaxPool_3a_3x3'", ",", "'Mixed_3b'", ",", "'Mixed_3c'", ",", "\n", "'MaxPool_4a_3x3'", ",", "'Mixed_4b'", ",", "'Mixed_4c'", ",", "'Mixed_4d'", ",", "\n", "'Mixed_4e'", ",", "'Mixed_4f'", ",", "'MaxPool_5a_2x2'", ",", "'Mixed_5b'", ",", "\n", "'Mixed_5c'", "]", "\n", "for", "index", ",", "endpoint", "in", "enumerate", "(", "endpoints", ")", ":", "\n", "      ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "out_tensor", ",", "end_points", "=", "inception", ".", "inception_v1_base", "(", "\n", "inputs", ",", "final_endpoint", "=", "endpoint", ")", "\n", "self", ".", "assertTrue", "(", "out_tensor", ".", "op", ".", "name", ".", "startswith", "(", "\n", "'InceptionV1/'", "+", "endpoint", ")", ")", "\n", "self", ".", "assertItemsEqual", "(", "endpoints", "[", ":", "index", "+", "1", "]", ",", "end_points", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1_test.InceptionV1Test.testBuildAndCheckAllEndPointsUptoMixed5c": [[78, 108], ["tensorflow.random_uniform", "nets.inception.inception_v1_base", "inception_v1_test.InceptionV1Test.assertItemsEqual", "endpoints_shapes.keys", "end_points.keys", "inception_v1_test.InceptionV1Test.assertTrue", "inception_v1_test.InceptionV1Test.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1_base"], ["", "", "", "def", "testBuildAndCheckAllEndPointsUptoMixed5c", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_v1_base", "(", "inputs", ",", "\n", "final_endpoint", "=", "'Mixed_5c'", ")", "\n", "endpoints_shapes", "=", "{", "'Conv2d_1a_7x7'", ":", "[", "5", ",", "112", ",", "112", ",", "64", "]", ",", "\n", "'MaxPool_2a_3x3'", ":", "[", "5", ",", "56", ",", "56", ",", "64", "]", ",", "\n", "'Conv2d_2b_1x1'", ":", "[", "5", ",", "56", ",", "56", ",", "64", "]", ",", "\n", "'Conv2d_2c_3x3'", ":", "[", "5", ",", "56", ",", "56", ",", "192", "]", ",", "\n", "'MaxPool_3a_3x3'", ":", "[", "5", ",", "28", ",", "28", ",", "192", "]", ",", "\n", "'Mixed_3b'", ":", "[", "5", ",", "28", ",", "28", ",", "256", "]", ",", "\n", "'Mixed_3c'", ":", "[", "5", ",", "28", ",", "28", ",", "480", "]", ",", "\n", "'MaxPool_4a_3x3'", ":", "[", "5", ",", "14", ",", "14", ",", "480", "]", ",", "\n", "'Mixed_4b'", ":", "[", "5", ",", "14", ",", "14", ",", "512", "]", ",", "\n", "'Mixed_4c'", ":", "[", "5", ",", "14", ",", "14", ",", "512", "]", ",", "\n", "'Mixed_4d'", ":", "[", "5", ",", "14", ",", "14", ",", "512", "]", ",", "\n", "'Mixed_4e'", ":", "[", "5", ",", "14", ",", "14", ",", "528", "]", ",", "\n", "'Mixed_4f'", ":", "[", "5", ",", "14", ",", "14", ",", "832", "]", ",", "\n", "'MaxPool_5a_2x2'", ":", "[", "5", ",", "7", ",", "7", ",", "832", "]", ",", "\n", "'Mixed_5b'", ":", "[", "5", ",", "7", ",", "7", ",", "832", "]", ",", "\n", "'Mixed_5c'", ":", "[", "5", ",", "7", ",", "7", ",", "1024", "]", "}", "\n", "\n", "self", ".", "assertItemsEqual", "(", "endpoints_shapes", ".", "keys", "(", ")", ",", "end_points", ".", "keys", "(", ")", ")", "\n", "for", "endpoint_name", "in", "endpoints_shapes", ":", "\n", "      ", "expected_shape", "=", "endpoints_shapes", "[", "endpoint_name", "]", "\n", "self", ".", "assertTrue", "(", "endpoint_name", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint_name", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "expected_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1_test.InceptionV1Test.testModelHasExpectedNumberOfParameters": [[109, 118], ["tensorflow.random_uniform", "slim.model_analyzer.analyze_vars", "inception_v1_test.InceptionV1Test.assertAlmostEqual", "slim.arg_scope", "nets.inception.inception_v1_base", "slim.get_model_variables", "nets.inception.inception_v1_arg_scope"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1_base"], ["", "", "def", "testModelHasExpectedNumberOfParameters", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "with", "slim", ".", "arg_scope", "(", "inception", ".", "inception_v1_arg_scope", "(", ")", ")", ":", "\n", "      ", "inception", ".", "inception_v1_base", "(", "inputs", ")", "\n", "", "total_params", ",", "_", "=", "slim", ".", "model_analyzer", ".", "analyze_vars", "(", "\n", "slim", ".", "get_model_variables", "(", ")", ")", "\n", "self", ".", "assertAlmostEqual", "(", "5607184", ",", "total_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1_test.InceptionV1Test.testHalfSizeImages": [[119, 128], ["tensorflow.random_uniform", "nets.inception.inception_v1_base", "inception_v1_test.InceptionV1Test.assertTrue", "inception_v1_test.InceptionV1Test.assertListEqual", "mixed_5c.op.name.startswith", "mixed_5c.get_shape().as_list", "mixed_5c.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1_base"], ["", "def", "testHalfSizeImages", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "112", ",", "112", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "mixed_5c", ",", "_", "=", "inception", ".", "inception_v1_base", "(", "inputs", ")", "\n", "self", ".", "assertTrue", "(", "mixed_5c", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV1/Mixed_5c'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "mixed_5c", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "4", ",", "4", ",", "1024", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1_test.InceptionV1Test.testUnknownImageShape": [[129, 146], ["tensorflow.reset_default_graph", "numpy.random.uniform", "inception_v1_test.InceptionV1Test.test_session", "tensorflow.placeholder", "nets.inception.inception_v1", "inception_v1_test.InceptionV1Test.assertTrue", "inception_v1_test.InceptionV1Test.assertListEqual", "tensorflow.global_variables_initializer().run", "sess.run", "inception_v1_test.InceptionV1Test.assertListEqual", "logits.op.name.startswith", "logits.get_shape().as_list", "list", "tensorflow.global_variables_initializer", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "testUnknownImageShape", "(", "self", ")", ":", "\n", "    ", "tf", ".", "reset_default_graph", "(", ")", "\n", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "input_np", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "1", ",", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "batch_size", ",", "None", ",", "None", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "inception", ".", "inception_v1", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV1/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "pre_pool", "=", "end_points", "[", "'Mixed_5c'", "]", "\n", "feed_dict", "=", "{", "inputs", ":", "input_np", "}", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "pre_pool_out", "=", "sess", ".", "run", "(", "pre_pool", ",", "feed_dict", "=", "feed_dict", ")", "\n", "self", ".", "assertListEqual", "(", "list", "(", "pre_pool_out", ".", "shape", ")", ",", "[", "batch_size", ",", "7", ",", "7", ",", "1024", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1_test.InceptionV1Test.testUnknowBatchSize": [[147, 163], ["tensorflow.placeholder", "nets.inception.inception_v1", "inception_v1_test.InceptionV1Test.assertTrue", "inception_v1_test.InceptionV1Test.assertListEqual", "tensorflow.random_uniform", "logits.op.name.startswith", "logits.get_shape().as_list", "inception_v1_test.InceptionV1Test.test_session", "sess.run", "sess.run", "inception_v1_test.InceptionV1Test.assertEquals", "tensorflow.global_variables_initializer", "logits.get_shape", "tensorflow.random_uniform.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testUnknowBatchSize", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v1", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV1/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "None", ",", "num_classes", "]", ")", "\n", "images", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ",", "{", "inputs", ":", "images", ".", "eval", "(", ")", "}", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "batch_size", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1_test.InceptionV1Test.testEvaluation": [[164, 178], ["tensorflow.random_uniform", "nets.inception.inception_v1", "tensorflow.argmax", "inception_v1_test.InceptionV1Test.test_session", "sess.run", "sess.run", "inception_v1_test.InceptionV1Test.assertEquals", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testEvaluation", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v1", "(", "eval_inputs", ",", "num_classes", ",", "\n", "is_training", "=", "False", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "predictions", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1_test.InceptionV1Test.testTrainEvalWithReuse": [[179, 195], ["tensorflow.random_uniform", "nets.inception.inception_v1", "tensorflow.random_uniform", "nets.inception.inception_v1", "tensorflow.argmax", "inception_v1_test.InceptionV1Test.test_session", "sess.run", "sess.run", "inception_v1_test.InceptionV1Test.assertEquals", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testTrainEvalWithReuse", "(", "self", ")", ":", "\n", "    ", "train_batch_size", "=", "5", "\n", "eval_batch_size", "=", "2", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "\n", "train_inputs", "=", "tf", ".", "random_uniform", "(", "(", "train_batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "inception", ".", "inception_v1", "(", "train_inputs", ",", "num_classes", ")", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "eval_batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v1", "(", "eval_inputs", ",", "num_classes", ",", "reuse", "=", "True", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "predictions", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "eval_batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1_test.InceptionV1Test.testLogitsNotSqueezed": [[196, 207], ["tensorflow.random_uniform", "nets.inception.inception_v1", "inception_v1_test.InceptionV1Test.test_session", "tensorflow.global_variables_initializer().run", "sess.run", "inception_v1_test.InceptionV1Test.assertListEqual", "list", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testLogitsNotSqueezed", "(", "self", ")", ":", "\n", "    ", "num_classes", "=", "25", "\n", "images", "=", "tf", ".", "random_uniform", "(", "[", "1", ",", "224", ",", "224", ",", "3", "]", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v1", "(", "images", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "spatial_squeeze", "=", "False", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "logits_out", "=", "sess", ".", "run", "(", "logits", ")", "\n", "self", ".", "assertListEqual", "(", "list", "(", "logits_out", ".", "shape", ")", ",", "[", "1", ",", "1", ",", "1", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testBuildLogits": [[27, 43], ["inception_resnet_v2_test.InceptionTest.test_session", "tensorflow.random_uniform", "nets.inception.inception_resnet_v2", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertListEqual", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertListEqual", "auxlogits.op.name.startswith", "auxlogits.get_shape().as_list", "logits.op.name.startswith", "logits.get_shape().as_list", "auxlogits.get_shape", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2"], ["  ", "def", "testBuildLogits", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "endpoints", "=", "inception", ".", "inception_resnet_v2", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "'AuxLogits'", "in", "endpoints", ")", "\n", "auxlogits", "=", "endpoints", "[", "'AuxLogits'", "]", "\n", "self", ".", "assertTrue", "(", "\n", "auxlogits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionResnetV2/AuxLogits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "auxlogits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionResnetV2/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testBuildWithoutAuxLogits": [[44, 56], ["inception_resnet_v2_test.InceptionTest.test_session", "tensorflow.random_uniform", "nets.inception.inception_resnet_v2", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertListEqual", "logits.op.name.startswith", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2"], ["", "", "def", "testBuildWithoutAuxLogits", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "endpoints", "=", "inception", ".", "inception_resnet_v2", "(", "inputs", ",", "num_classes", ",", "\n", "create_aux_logits", "=", "False", ")", "\n", "self", ".", "assertTrue", "(", "'AuxLogits'", "not", "in", "endpoints", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionResnetV2/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testBuildEndPoints": [[57, 75], ["inception_resnet_v2_test.InceptionTest.test_session", "tensorflow.random_uniform", "nets.inception.inception_resnet_v2", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertListEqual", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertListEqual", "inception_resnet_v2_test.InceptionTest.assertListEqual", "logits.get_shape().as_list", "aux_logits.get_shape().as_list", "pre_pool.get_shape().as_list", "logits.get_shape", "aux_logits.get_shape", "pre_pool.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2"], ["", "", "def", "testBuildEndPoints", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_resnet_v2", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "'Logits'", "in", "end_points", ")", "\n", "logits", "=", "end_points", "[", "'Logits'", "]", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "self", ".", "assertTrue", "(", "'AuxLogits'", "in", "end_points", ")", "\n", "aux_logits", "=", "end_points", "[", "'AuxLogits'", "]", "\n", "self", ".", "assertListEqual", "(", "aux_logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "pre_pool", "=", "end_points", "[", "'Conv2d_7b_1x1'", "]", "\n", "self", ".", "assertListEqual", "(", "pre_pool", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "8", ",", "8", ",", "1536", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testBuildBaseNetwork": [[76, 90], ["tensorflow.random_uniform", "nets.inception.inception_resnet_v2_base", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertListEqual", "inception_resnet_v2_test.InceptionTest.assertItemsEqual", "net.op.name.startswith", "net.get_shape().as_list", "end_points.keys", "net.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2_base"], ["", "", "def", "testBuildBaseNetwork", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "net", ",", "end_points", "=", "inception", ".", "inception_resnet_v2_base", "(", "inputs", ")", "\n", "self", ".", "assertTrue", "(", "net", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionResnetV2/Conv2d_7b_1x1'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "net", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "8", ",", "8", ",", "1536", "]", ")", "\n", "expected_endpoints", "=", "[", "'Conv2d_1a_3x3'", ",", "'Conv2d_2a_3x3'", ",", "'Conv2d_2b_3x3'", ",", "\n", "'MaxPool_3a_3x3'", ",", "'Conv2d_3b_1x1'", ",", "'Conv2d_4a_3x3'", ",", "\n", "'MaxPool_5a_3x3'", ",", "'Mixed_5b'", ",", "'Mixed_6a'", ",", "\n", "'PreAuxLogits'", ",", "'Mixed_7a'", ",", "'Conv2d_7b_1x1'", "]", "\n", "self", ".", "assertItemsEqual", "(", "end_points", ".", "keys", "(", ")", ",", "expected_endpoints", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testBuildOnlyUptoFinalEndpoint": [[91, 107], ["enumerate", "tensorflow.Graph().as_default", "tensorflow.random_uniform", "nets.inception.inception_resnet_v2_base", "inception_resnet_v2_test.InceptionTest.assertItemsEqual", "inception_resnet_v2_test.InceptionTest.assertTrue", "tensorflow.Graph", "out_tensor.op.name.startswith"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2_base"], ["", "def", "testBuildOnlyUptoFinalEndpoint", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "endpoints", "=", "[", "'Conv2d_1a_3x3'", ",", "'Conv2d_2a_3x3'", ",", "'Conv2d_2b_3x3'", ",", "\n", "'MaxPool_3a_3x3'", ",", "'Conv2d_3b_1x1'", ",", "'Conv2d_4a_3x3'", ",", "\n", "'MaxPool_5a_3x3'", ",", "'Mixed_5b'", ",", "'Mixed_6a'", ",", "\n", "'PreAuxLogits'", ",", "'Mixed_7a'", ",", "'Conv2d_7b_1x1'", "]", "\n", "for", "index", ",", "endpoint", "in", "enumerate", "(", "endpoints", ")", ":", "\n", "      ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "out_tensor", ",", "end_points", "=", "inception", ".", "inception_resnet_v2_base", "(", "\n", "inputs", ",", "final_endpoint", "=", "endpoint", ")", "\n", "if", "endpoint", "!=", "'PreAuxLogits'", ":", "\n", "          ", "self", ".", "assertTrue", "(", "out_tensor", ".", "op", ".", "name", ".", "startswith", "(", "\n", "'InceptionResnetV2/'", "+", "endpoint", ")", ")", "\n", "", "self", ".", "assertItemsEqual", "(", "endpoints", "[", ":", "index", "+", "1", "]", ",", "end_points", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testBuildAndCheckAllEndPointsUptoPreAuxLogits": [[108, 133], ["tensorflow.random_uniform", "nets.inception.inception_resnet_v2_base", "inception_resnet_v2_test.InceptionTest.assertItemsEqual", "endpoints_shapes.keys", "end_points.keys", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2_base"], ["", "", "", "def", "testBuildAndCheckAllEndPointsUptoPreAuxLogits", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_resnet_v2_base", "(", "\n", "inputs", ",", "final_endpoint", "=", "'PreAuxLogits'", ")", "\n", "endpoints_shapes", "=", "{", "'Conv2d_1a_3x3'", ":", "[", "5", ",", "149", ",", "149", ",", "32", "]", ",", "\n", "'Conv2d_2a_3x3'", ":", "[", "5", ",", "147", ",", "147", ",", "32", "]", ",", "\n", "'Conv2d_2b_3x3'", ":", "[", "5", ",", "147", ",", "147", ",", "64", "]", ",", "\n", "'MaxPool_3a_3x3'", ":", "[", "5", ",", "73", ",", "73", ",", "64", "]", ",", "\n", "'Conv2d_3b_1x1'", ":", "[", "5", ",", "73", ",", "73", ",", "80", "]", ",", "\n", "'Conv2d_4a_3x3'", ":", "[", "5", ",", "71", ",", "71", ",", "192", "]", ",", "\n", "'MaxPool_5a_3x3'", ":", "[", "5", ",", "35", ",", "35", ",", "192", "]", ",", "\n", "'Mixed_5b'", ":", "[", "5", ",", "35", ",", "35", ",", "320", "]", ",", "\n", "'Mixed_6a'", ":", "[", "5", ",", "17", ",", "17", ",", "1088", "]", ",", "\n", "'PreAuxLogits'", ":", "[", "5", ",", "17", ",", "17", ",", "1088", "]", "\n", "}", "\n", "\n", "self", ".", "assertItemsEqual", "(", "endpoints_shapes", ".", "keys", "(", ")", ",", "end_points", ".", "keys", "(", ")", ")", "\n", "for", "endpoint_name", "in", "endpoints_shapes", ":", "\n", "      ", "expected_shape", "=", "endpoints_shapes", "[", "endpoint_name", "]", "\n", "self", ".", "assertTrue", "(", "endpoint_name", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint_name", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "expected_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testBuildAndCheckAllEndPointsUptoPreAuxLogitsWithAlignedFeatureMaps": [[134, 159], ["tensorflow.random_uniform", "nets.inception.inception_resnet_v2_base", "inception_resnet_v2_test.InceptionTest.assertItemsEqual", "endpoints_shapes.keys", "end_points.keys", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2_base"], ["", "", "def", "testBuildAndCheckAllEndPointsUptoPreAuxLogitsWithAlignedFeatureMaps", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_resnet_v2_base", "(", "\n", "inputs", ",", "final_endpoint", "=", "'PreAuxLogits'", ",", "align_feature_maps", "=", "True", ")", "\n", "endpoints_shapes", "=", "{", "'Conv2d_1a_3x3'", ":", "[", "5", ",", "150", ",", "150", ",", "32", "]", ",", "\n", "'Conv2d_2a_3x3'", ":", "[", "5", ",", "150", ",", "150", ",", "32", "]", ",", "\n", "'Conv2d_2b_3x3'", ":", "[", "5", ",", "150", ",", "150", ",", "64", "]", ",", "\n", "'MaxPool_3a_3x3'", ":", "[", "5", ",", "75", ",", "75", ",", "64", "]", ",", "\n", "'Conv2d_3b_1x1'", ":", "[", "5", ",", "75", ",", "75", ",", "80", "]", ",", "\n", "'Conv2d_4a_3x3'", ":", "[", "5", ",", "75", ",", "75", ",", "192", "]", ",", "\n", "'MaxPool_5a_3x3'", ":", "[", "5", ",", "38", ",", "38", ",", "192", "]", ",", "\n", "'Mixed_5b'", ":", "[", "5", ",", "38", ",", "38", ",", "320", "]", ",", "\n", "'Mixed_6a'", ":", "[", "5", ",", "19", ",", "19", ",", "1088", "]", ",", "\n", "'PreAuxLogits'", ":", "[", "5", ",", "19", ",", "19", ",", "1088", "]", "\n", "}", "\n", "\n", "self", ".", "assertItemsEqual", "(", "endpoints_shapes", ".", "keys", "(", ")", ",", "end_points", ".", "keys", "(", ")", ")", "\n", "for", "endpoint_name", "in", "endpoints_shapes", ":", "\n", "      ", "expected_shape", "=", "endpoints_shapes", "[", "endpoint_name", "]", "\n", "self", ".", "assertTrue", "(", "endpoint_name", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint_name", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "expected_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testBuildAndCheckAllEndPointsUptoPreAuxLogitsWithOutputStrideEight": [[160, 185], ["tensorflow.random_uniform", "nets.inception.inception_resnet_v2_base", "inception_resnet_v2_test.InceptionTest.assertItemsEqual", "endpoints_shapes.keys", "end_points.keys", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2_base"], ["", "", "def", "testBuildAndCheckAllEndPointsUptoPreAuxLogitsWithOutputStrideEight", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_resnet_v2_base", "(", "\n", "inputs", ",", "final_endpoint", "=", "'PreAuxLogits'", ",", "output_stride", "=", "8", ")", "\n", "endpoints_shapes", "=", "{", "'Conv2d_1a_3x3'", ":", "[", "5", ",", "149", ",", "149", ",", "32", "]", ",", "\n", "'Conv2d_2a_3x3'", ":", "[", "5", ",", "147", ",", "147", ",", "32", "]", ",", "\n", "'Conv2d_2b_3x3'", ":", "[", "5", ",", "147", ",", "147", ",", "64", "]", ",", "\n", "'MaxPool_3a_3x3'", ":", "[", "5", ",", "73", ",", "73", ",", "64", "]", ",", "\n", "'Conv2d_3b_1x1'", ":", "[", "5", ",", "73", ",", "73", ",", "80", "]", ",", "\n", "'Conv2d_4a_3x3'", ":", "[", "5", ",", "71", ",", "71", ",", "192", "]", ",", "\n", "'MaxPool_5a_3x3'", ":", "[", "5", ",", "35", ",", "35", ",", "192", "]", ",", "\n", "'Mixed_5b'", ":", "[", "5", ",", "35", ",", "35", ",", "320", "]", ",", "\n", "'Mixed_6a'", ":", "[", "5", ",", "33", ",", "33", ",", "1088", "]", ",", "\n", "'PreAuxLogits'", ":", "[", "5", ",", "33", ",", "33", ",", "1088", "]", "\n", "}", "\n", "\n", "self", ".", "assertItemsEqual", "(", "endpoints_shapes", ".", "keys", "(", ")", ",", "end_points", ".", "keys", "(", ")", ")", "\n", "for", "endpoint_name", "in", "endpoints_shapes", ":", "\n", "      ", "expected_shape", "=", "endpoints_shapes", "[", "endpoint_name", "]", "\n", "self", ".", "assertTrue", "(", "endpoint_name", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint_name", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "expected_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testVariablesSetDevice": [[186, 201], ["inception_resnet_v2_test.InceptionTest.test_session", "tensorflow.random_uniform", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.variable_scope", "tensorflow.device", "nets.inception.inception_resnet_v2", "tensorflow.variable_scope", "tensorflow.device", "nets.inception.inception_resnet_v2", "inception_resnet_v2_test.InceptionTest.assertDeviceEqual", "inception_resnet_v2_test.InceptionTest.assertDeviceEqual"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2"], ["", "", "def", "testVariablesSetDevice", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "# Force all Variables to reside on the device.", "\n", "with", "tf", ".", "variable_scope", "(", "'on_cpu'", ")", ",", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "        ", "inception", ".", "inception_resnet_v2", "(", "inputs", ",", "num_classes", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'on_gpu'", ")", ",", "tf", ".", "device", "(", "'/gpu:0'", ")", ":", "\n", "        ", "inception", ".", "inception_resnet_v2", "(", "inputs", ",", "num_classes", ")", "\n", "", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "'on_cpu'", ")", ":", "\n", "        ", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'/cpu:0'", ")", "\n", "", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "'on_gpu'", ")", ":", "\n", "        ", "self", ".", "assertDeviceEqual", "(", "v", ".", "device", ",", "'/gpu:0'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testHalfSizeImages": [[202, 215], ["inception_resnet_v2_test.InceptionTest.test_session", "tensorflow.random_uniform", "nets.inception.inception_resnet_v2", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertListEqual", "inception_resnet_v2_test.InceptionTest.assertListEqual", "logits.op.name.startswith", "logits.get_shape().as_list", "pre_pool.get_shape().as_list", "logits.get_shape", "pre_pool.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2"], ["", "", "", "def", "testHalfSizeImages", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "150", ",", "150", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "inception", ".", "inception_resnet_v2", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionResnetV2/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "pre_pool", "=", "end_points", "[", "'Conv2d_7b_1x1'", "]", "\n", "self", ".", "assertListEqual", "(", "pre_pool", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "3", ",", "3", ",", "1536", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testUnknownBatchSize": [[216, 230], ["inception_resnet_v2_test.InceptionTest.test_session", "tensorflow.placeholder", "nets.inception.inception_resnet_v2", "inception_resnet_v2_test.InceptionTest.assertTrue", "inception_resnet_v2_test.InceptionTest.assertListEqual", "tensorflow.random_uniform", "sess.run", "sess.run", "inception_resnet_v2_test.InceptionTest.assertEquals", "logits.op.name.startswith", "logits.get_shape().as_list", "tensorflow.global_variables_initializer", "tensorflow.random_uniform.eval", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testUnknownBatchSize", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_resnet_v2", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionResnetV2/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "None", ",", "num_classes", "]", ")", "\n", "images", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ",", "{", "inputs", ":", "images", ".", "eval", "(", ")", "}", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "batch_size", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testEvaluation": [[231, 244], ["inception_resnet_v2_test.InceptionTest.test_session", "tensorflow.random_uniform", "nets.inception.inception_resnet_v2", "tensorflow.argmax", "sess.run", "sess.run", "inception_resnet_v2_test.InceptionTest.assertEquals", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testEvaluation", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_resnet_v2", "(", "eval_inputs", ",", "\n", "num_classes", ",", "\n", "is_training", "=", "False", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "predictions", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2_test.InceptionTest.testTrainEvalWithReuse": [[245, 262], ["inception_resnet_v2_test.InceptionTest.test_session", "tensorflow.random_uniform", "nets.inception.inception_resnet_v2", "tensorflow.random_uniform", "nets.inception.inception_resnet_v2", "tensorflow.argmax", "sess.run", "sess.run", "inception_resnet_v2_test.InceptionTest.assertEquals", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testTrainEvalWithReuse", "(", "self", ")", ":", "\n", "    ", "train_batch_size", "=", "5", "\n", "eval_batch_size", "=", "2", "\n", "height", ",", "width", "=", "150", ",", "150", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "train_inputs", "=", "tf", ".", "random_uniform", "(", "(", "train_batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "inception", ".", "inception_resnet_v2", "(", "train_inputs", ",", "num_classes", ")", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "eval_batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_resnet_v2", "(", "eval_inputs", ",", "\n", "num_classes", ",", "\n", "is_training", "=", "False", ",", "\n", "reuse", "=", "True", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "predictions", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "eval_batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.cifarnet.cifarnet": [[28, 90], ["tensorflow.variable_scope", "slim.conv2d", "slim.max_pool2d", "tensorflow.nn.lrn", "slim.conv2d", "tensorflow.nn.lrn", "slim.max_pool2d", "slim.flatten", "slim.fully_connected", "slim.dropout", "slim.fully_connected", "slim.fully_connected", "prediction_fn", "tensorflow.zeros_initializer", "trunc_normal"], "function", ["None"], ["def", "cifarnet", "(", "images", ",", "num_classes", "=", "10", ",", "is_training", "=", "False", ",", "\n", "dropout_keep_prob", "=", "0.5", ",", "\n", "prediction_fn", "=", "slim", ".", "softmax", ",", "\n", "scope", "=", "'CifarNet'", ")", ":", "\n", "  ", "\"\"\"Creates a variant of the CifarNet model.\n\n  Note that since the output is a set of 'logits', the values fall in the\n  interval of (-infinity, infinity). Consequently, to convert the outputs to a\n  probability distribution over the characters, one will need to convert them\n  using the softmax function:\n\n        logits = cifarnet.cifarnet(images, is_training=False)\n        probabilities = tf.nn.softmax(logits)\n        predictions = tf.argmax(logits, 1)\n\n  Args:\n    images: A batch of `Tensors` of size [batch_size, height, width, channels].\n    num_classes: the number of classes in the dataset.\n    is_training: specifies whether or not we're currently training the model.\n      This variable will determine the behaviour of the dropout layer.\n    dropout_keep_prob: the percentage of activation values that are retained.\n    prediction_fn: a function to get predictions out of logits.\n    scope: Optional variable_scope.\n\n  Returns:\n    logits: the pre-softmax activations, a tensor of size\n      [batch_size, `num_classes`]\n    end_points: a dictionary from components of the network to the corresponding\n      activation.\n  \"\"\"", "\n", "end_points", "=", "{", "}", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'CifarNet'", ",", "[", "images", ",", "num_classes", "]", ")", ":", "\n", "    ", "net", "=", "slim", ".", "conv2d", "(", "images", ",", "64", ",", "[", "5", ",", "5", "]", ",", "scope", "=", "'conv1'", ")", "\n", "end_points", "[", "'conv1'", "]", "=", "net", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "2", ",", "scope", "=", "'pool1'", ")", "\n", "end_points", "[", "'pool1'", "]", "=", "net", "\n", "net", "=", "tf", ".", "nn", ".", "lrn", "(", "net", ",", "4", ",", "bias", "=", "1.0", ",", "alpha", "=", "0.001", "/", "9.0", ",", "beta", "=", "0.75", ",", "name", "=", "'norm1'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "5", ",", "5", "]", ",", "scope", "=", "'conv2'", ")", "\n", "end_points", "[", "'conv2'", "]", "=", "net", "\n", "net", "=", "tf", ".", "nn", ".", "lrn", "(", "net", ",", "4", ",", "bias", "=", "1.0", ",", "alpha", "=", "0.001", "/", "9.0", ",", "beta", "=", "0.75", ",", "name", "=", "'norm2'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "2", ",", "scope", "=", "'pool2'", ")", "\n", "end_points", "[", "'pool2'", "]", "=", "net", "\n", "net", "=", "slim", ".", "flatten", "(", "net", ")", "\n", "end_points", "[", "'Flatten'", "]", "=", "net", "\n", "net", "=", "slim", ".", "fully_connected", "(", "net", ",", "384", ",", "scope", "=", "'fc3'", ")", "\n", "end_points", "[", "'fc3'", "]", "=", "net", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout3'", ")", "\n", "net", "=", "slim", ".", "fully_connected", "(", "net", ",", "192", ",", "scope", "=", "'fc4'", ")", "\n", "end_points", "[", "'fc4'", "]", "=", "net", "\n", "logits", "=", "slim", ".", "fully_connected", "(", "net", ",", "num_classes", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "1", "/", "192.0", ")", ",", "\n", "weights_regularizer", "=", "None", ",", "\n", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'logits'", ")", "\n", "\n", "end_points", "[", "'Logits'", "]", "=", "logits", "\n", "end_points", "[", "'Predictions'", "]", "=", "prediction_fn", "(", "logits", ",", "scope", "=", "'Predictions'", ")", "\n", "\n", "", "return", "logits", ",", "end_points", "\n", "", "cifarnet", ".", "default_image_size", "=", "32", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.cifarnet.cifarnet_arg_scope": [[93, 113], ["slim.arg_scope", "slim.arg_scope", "tensorflow.truncated_normal_initializer", "tensorflow.constant_initializer", "trunc_normal", "slim.l2_regularizer"], "function", ["None"], ["def", "cifarnet_arg_scope", "(", "weight_decay", "=", "0.004", ")", ":", "\n", "  ", "\"\"\"Defines the default cifarnet argument scope.\n\n  Args:\n    weight_decay: The weight decay to use for regularizing the model.\n\n  Returns:\n    An `arg_scope` to use for the inception v3 model.\n  \"\"\"", "\n", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", "]", ",", "\n", "weights_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "5e-2", ")", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "fully_connected", "]", ",", "\n", "biases_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.04", ")", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "as", "sc", ":", "\n", "      ", "return", "sc", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.bottleneck": [[68, 113], ["tensorflow.variable_scope", "slim.utils.last_dimension", "slim.conv2d", "nets.resnet_utils.conv2d_same", "slim.conv2d", "tensorflow.nn.relu", "slim.utils.collect_named_outputs", "inputs.get_shape", "nets.resnet_utils.subsample", "slim.conv2d"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.conv2d_same", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample"], ["@", "slim", ".", "add_arg_scope", "\n", "def", "bottleneck", "(", "inputs", ",", "depth", ",", "depth_bottleneck", ",", "stride", ",", "rate", "=", "1", ",", "\n", "outputs_collections", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Bottleneck residual unit variant with BN after convolutions.\n\n  This is the original residual unit proposed in [1]. See Fig. 1(a) of [2] for\n  its definition. Note that we use here the bottleneck variant which has an\n  extra bottleneck layer.\n\n  When putting together two consecutive ResNet blocks that use this unit, one\n  should use stride = 2 in the last unit of the first block.\n\n  Args:\n    inputs: A tensor of size [batch, height, width, channels].\n    depth: The depth of the ResNet unit output.\n    depth_bottleneck: The depth of the bottleneck layers.\n    stride: The ResNet unit's stride. Determines the amount of downsampling of\n      the units output compared to its input.\n    rate: An integer, rate for atrous convolution.\n    outputs_collections: Collection to add the ResNet unit output.\n    scope: Optional variable_scope.\n\n  Returns:\n    The ResNet unit's output.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'bottleneck_v1'", ",", "[", "inputs", "]", ")", "as", "sc", ":", "\n", "    ", "depth_in", "=", "slim", ".", "utils", ".", "last_dimension", "(", "inputs", ".", "get_shape", "(", ")", ",", "min_rank", "=", "4", ")", "\n", "if", "depth", "==", "depth_in", ":", "\n", "      ", "shortcut", "=", "resnet_utils", ".", "subsample", "(", "inputs", ",", "stride", ",", "'shortcut'", ")", "\n", "", "else", ":", "\n", "      ", "shortcut", "=", "slim", ".", "conv2d", "(", "inputs", ",", "depth", ",", "[", "1", ",", "1", "]", ",", "stride", "=", "stride", ",", "\n", "activation_fn", "=", "None", ",", "scope", "=", "'shortcut'", ")", "\n", "\n", "", "residual", "=", "slim", ".", "conv2d", "(", "inputs", ",", "depth_bottleneck", ",", "[", "1", ",", "1", "]", ",", "stride", "=", "1", ",", "\n", "scope", "=", "'conv1'", ")", "\n", "residual", "=", "resnet_utils", ".", "conv2d_same", "(", "residual", ",", "depth_bottleneck", ",", "3", ",", "stride", ",", "\n", "rate", "=", "rate", ",", "scope", "=", "'conv2'", ")", "\n", "residual", "=", "slim", ".", "conv2d", "(", "residual", ",", "depth", ",", "[", "1", ",", "1", "]", ",", "stride", "=", "1", ",", "\n", "activation_fn", "=", "None", ",", "scope", "=", "'conv3'", ")", "\n", "\n", "output", "=", "tf", ".", "nn", ".", "relu", "(", "shortcut", "+", "residual", ")", "\n", "\n", "return", "slim", ".", "utils", ".", "collect_named_outputs", "(", "outputs_collections", ",", "\n", "sc", ".", "original_name_scope", ",", "\n", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1": [[115, 214], ["tensorflow.variable_scope", "slim.arg_scope", "slim.arg_scope", "nets.resnet_utils.stack_blocks_dense", "slim.utils.convert_collection_to_dict", "nets.resnet_utils.conv2d_same", "slim.max_pool2d", "tensorflow.reduce_mean", "slim.conv2d", "slim.softmax", "tensorflow.squeeze", "ValueError"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.stack_blocks_dense", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.conv2d_same"], ["", "", "def", "resnet_v1", "(", "inputs", ",", "\n", "blocks", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "include_root_block", "=", "True", ",", "\n", "spatial_squeeze", "=", "False", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Generator for v1 ResNet models.\n\n  This function generates a family of ResNet v1 models. See the resnet_v1_*()\n  methods for specific model instantiations, obtained by selecting different\n  block instantiations that produce ResNets of various depths.\n\n  Training for image classification on Imagenet is usually done with [224, 224]\n  inputs, resulting in [7, 7] feature maps at the output of the last ResNet\n  block for the ResNets defined in [1] that have nominal stride equal to 32.\n  However, for dense prediction tasks we advise that one uses inputs with\n  spatial dimensions that are multiples of 32 plus 1, e.g., [321, 321]. In\n  this case the feature maps at the ResNet output will have spatial shape\n  [(height - 1) / output_stride + 1, (width - 1) / output_stride + 1]\n  and corners exactly aligned with the input image corners, which greatly\n  facilitates alignment of the features to the image. Using as input [225, 225]\n  images results in [8, 8] feature maps at the output of the last ResNet block.\n\n  For dense prediction tasks, the ResNet needs to run in fully-convolutional\n  (FCN) mode and global_pool needs to be set to False. The ResNets in [1, 2] all\n  have nominal stride equal to 32 and a good choice in FCN mode is to use\n  output_stride=16 in order to increase the density of the computed features at\n  small computational and memory overhead, cf. http://arxiv.org/abs/1606.00915.\n\n  Args:\n    inputs: A tensor of size [batch, height_in, width_in, channels].\n    blocks: A list of length equal to the number of ResNet blocks. Each element\n      is a resnet_utils.Block object describing the units in the block.\n    num_classes: Number of predicted classes for classification tasks. If None\n      we return the features before the logit layer.\n    is_training: whether is training or not.\n    global_pool: If True, we perform global average pooling before computing the\n      logits. Set to True for image classification, False for dense prediction.\n    output_stride: If None, then the output will be computed at the nominal\n      network stride. If output_stride is not None, it specifies the requested\n      ratio of input to output spatial resolution.\n    include_root_block: If True, include the initial convolution followed by\n      max-pooling, if False excludes it.\n    spatial_squeeze: if True, logits is of shape [B, C], if false logits is\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n        To use this parameter, the input images must be smaller than 300x300\n        pixels, in which case the output logit layer does not contain spatial\n        information and can be removed.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    scope: Optional variable_scope.\n\n  Returns:\n    net: A rank-4 tensor of size [batch, height_out, width_out, channels_out].\n      If global_pool is False, then height_out and width_out are reduced by a\n      factor of output_stride compared to the respective height_in and width_in,\n      else both height_out and width_out equal one. If num_classes is None, then\n      net is the output of the last ResNet block, potentially after global\n      average pooling. If num_classes is not None, net contains the pre-softmax\n      activations.\n    end_points: A dictionary from components of the network to the corresponding\n      activation.\n\n  Raises:\n    ValueError: If the target output_stride is not valid.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'resnet_v1'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", "as", "sc", ":", "\n", "    ", "end_points_collection", "=", "sc", ".", "name", "+", "'_end_points'", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "bottleneck", ",", "\n", "resnet_utils", ".", "stack_blocks_dense", "]", ",", "\n", "outputs_collections", "=", "end_points_collection", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", "]", ",", "is_training", "=", "is_training", ")", ":", "\n", "        ", "net", "=", "inputs", "\n", "if", "include_root_block", ":", "\n", "          ", "if", "output_stride", "is", "not", "None", ":", "\n", "            ", "if", "output_stride", "%", "4", "!=", "0", ":", "\n", "              ", "raise", "ValueError", "(", "'The output_stride needs to be a multiple of 4.'", ")", "\n", "", "output_stride", "/=", "4", "\n", "", "net", "=", "resnet_utils", ".", "conv2d_same", "(", "net", ",", "64", ",", "7", ",", "stride", "=", "2", ",", "scope", "=", "'conv1'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "'pool1'", ")", "\n", "", "net", "=", "resnet_utils", ".", "stack_blocks_dense", "(", "net", ",", "blocks", ",", "output_stride", ")", "\n", "if", "global_pool", ":", "\n", "# Global average pooling.", "\n", "          ", "net", "=", "tf", ".", "reduce_mean", "(", "net", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'pool5'", ",", "keep_dims", "=", "True", ")", "\n", "", "if", "num_classes", "is", "not", "None", ":", "\n", "          ", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "scope", "=", "'logits'", ")", "\n", "if", "spatial_squeeze", ":", "\n", "            ", "net", "=", "tf", ".", "squeeze", "(", "net", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'SpatialSqueeze'", ")", "\n", "# Convert end_points_collection into a dictionary of end_points.", "\n", "", "", "end_points", "=", "slim", ".", "utils", ".", "convert_collection_to_dict", "(", "\n", "end_points_collection", ")", "\n", "if", "num_classes", "is", "not", "None", ":", "\n", "          ", "end_points", "[", "'predictions'", "]", "=", "slim", ".", "softmax", "(", "net", ",", "scope", "=", "'predictions'", ")", "\n", "", "return", "net", ",", "end_points", "\n", "", "", "", "", "resnet_v1", ".", "default_image_size", "=", "224", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block": [[217, 238], ["nets.resnet_utils.Block"], "function", ["None"], ["def", "resnet_v1_block", "(", "scope", ",", "base_depth", ",", "num_units", ",", "stride", ")", ":", "\n", "  ", "\"\"\"Helper function for creating a resnet_v1 bottleneck block.\n\n  Args:\n    scope: The scope of the block.\n    base_depth: The depth of the bottleneck layer for each unit.\n    num_units: The number of units in the block.\n    stride: The stride of the block, implemented as a stride in the last unit.\n      All other units have stride=1.\n\n  Returns:\n    A resnet_v1 bottleneck block.\n  \"\"\"", "\n", "return", "resnet_utils", ".", "Block", "(", "scope", ",", "bottleneck", ",", "[", "{", "\n", "'depth'", ":", "base_depth", "*", "4", ",", "\n", "'depth_bottleneck'", ":", "base_depth", ",", "\n", "'stride'", ":", "1", "\n", "}", "]", "*", "(", "num_units", "-", "1", ")", "+", "[", "{", "\n", "'depth'", ":", "base_depth", "*", "4", ",", "\n", "'depth_bottleneck'", ":", "base_depth", ",", "\n", "'stride'", ":", "stride", "\n", "}", "]", ")", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_50": [[241, 260], ["resnet_v1.resnet_v1", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block"], ["", "def", "resnet_v1_50", "(", "inputs", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'resnet_v1_50'", ")", ":", "\n", "  ", "\"\"\"ResNet-50 model of [1]. See resnet_v1() for arg and return description.\"\"\"", "\n", "blocks", "=", "[", "\n", "resnet_v1_block", "(", "'block1'", ",", "base_depth", "=", "64", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block2'", ",", "base_depth", "=", "128", ",", "num_units", "=", "4", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block3'", ",", "base_depth", "=", "256", ",", "num_units", "=", "6", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block4'", ",", "base_depth", "=", "512", ",", "num_units", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "return", "resnet_v1", "(", "inputs", ",", "blocks", ",", "num_classes", ",", "is_training", ",", "\n", "global_pool", "=", "global_pool", ",", "output_stride", "=", "output_stride", ",", "\n", "include_root_block", "=", "True", ",", "spatial_squeeze", "=", "spatial_squeeze", ",", "\n", "reuse", "=", "reuse", ",", "scope", "=", "scope", ")", "\n", "", "resnet_v1_50", ".", "default_image_size", "=", "resnet_v1", ".", "default_image_size", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_101": [[263, 282], ["resnet_v1.resnet_v1", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block"], ["def", "resnet_v1_101", "(", "inputs", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'resnet_v1_101'", ")", ":", "\n", "  ", "\"\"\"ResNet-101 model of [1]. See resnet_v1() for arg and return description.\"\"\"", "\n", "blocks", "=", "[", "\n", "resnet_v1_block", "(", "'block1'", ",", "base_depth", "=", "64", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block2'", ",", "base_depth", "=", "128", ",", "num_units", "=", "4", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block3'", ",", "base_depth", "=", "256", ",", "num_units", "=", "23", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block4'", ",", "base_depth", "=", "512", ",", "num_units", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "return", "resnet_v1", "(", "inputs", ",", "blocks", ",", "num_classes", ",", "is_training", ",", "\n", "global_pool", "=", "global_pool", ",", "output_stride", "=", "output_stride", ",", "\n", "include_root_block", "=", "True", ",", "spatial_squeeze", "=", "spatial_squeeze", ",", "\n", "reuse", "=", "reuse", ",", "scope", "=", "scope", ")", "\n", "", "resnet_v1_101", ".", "default_image_size", "=", "resnet_v1", ".", "default_image_size", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_152": [[285, 304], ["resnet_v1.resnet_v1", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block"], ["def", "resnet_v1_152", "(", "inputs", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'resnet_v1_152'", ")", ":", "\n", "  ", "\"\"\"ResNet-152 model of [1]. See resnet_v1() for arg and return description.\"\"\"", "\n", "blocks", "=", "[", "\n", "resnet_v1_block", "(", "'block1'", ",", "base_depth", "=", "64", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block2'", ",", "base_depth", "=", "128", ",", "num_units", "=", "8", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block3'", ",", "base_depth", "=", "256", ",", "num_units", "=", "36", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block4'", ",", "base_depth", "=", "512", ",", "num_units", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "return", "resnet_v1", "(", "inputs", ",", "blocks", ",", "num_classes", ",", "is_training", ",", "\n", "global_pool", "=", "global_pool", ",", "output_stride", "=", "output_stride", ",", "\n", "include_root_block", "=", "True", ",", "spatial_squeeze", "=", "spatial_squeeze", ",", "\n", "reuse", "=", "reuse", ",", "scope", "=", "scope", ")", "\n", "", "resnet_v1_152", ".", "default_image_size", "=", "resnet_v1", ".", "default_image_size", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_200": [[307, 326], ["resnet_v1.resnet_v1", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block", "resnet_v1.resnet_v1_block"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block"], ["def", "resnet_v1_200", "(", "inputs", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'resnet_v1_200'", ")", ":", "\n", "  ", "\"\"\"ResNet-200 model of [2]. See resnet_v1() for arg and return description.\"\"\"", "\n", "blocks", "=", "[", "\n", "resnet_v1_block", "(", "'block1'", ",", "base_depth", "=", "64", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block2'", ",", "base_depth", "=", "128", ",", "num_units", "=", "24", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block3'", ",", "base_depth", "=", "256", ",", "num_units", "=", "36", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1_block", "(", "'block4'", ",", "base_depth", "=", "512", ",", "num_units", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "return", "resnet_v1", "(", "inputs", ",", "blocks", ",", "num_classes", ",", "is_training", ",", "\n", "global_pool", "=", "global_pool", ",", "output_stride", "=", "output_stride", ",", "\n", "include_root_block", "=", "True", ",", "spatial_squeeze", "=", "spatial_squeeze", ",", "\n", "reuse", "=", "reuse", ",", "scope", "=", "scope", ")", "\n", "", "resnet_v1_200", ".", "default_image_size", "=", "resnet_v1", ".", "default_image_size", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetUtilsTest.testSubsampleThreeByThree": [[58, 64], ["tensorflow.reshape", "nets.resnet_utils.subsample", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.constant", "resnet_v1_test.ResnetUtilsTest.test_session", "resnet_v1_test.ResnetUtilsTest.assertAllClose", "tensorflow.range", "nets.resnet_utils.subsample.eval", "tensorflow.reshape.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample"], ["  ", "def", "testSubsampleThreeByThree", "(", "self", ")", ":", "\n", "    ", "x", "=", "tf", ".", "reshape", "(", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "9", ")", ")", ",", "[", "1", ",", "3", ",", "3", ",", "1", "]", ")", "\n", "x", "=", "resnet_utils", ".", "subsample", "(", "x", ",", "2", ")", "\n", "expected", "=", "tf", ".", "reshape", "(", "tf", ".", "constant", "(", "[", "0", ",", "2", ",", "6", ",", "8", "]", ")", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ")", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "self", ".", "assertAllClose", "(", "x", ".", "eval", "(", ")", ",", "expected", ".", "eval", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetUtilsTest.testSubsampleFourByFour": [[65, 71], ["tensorflow.reshape", "nets.resnet_utils.subsample", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.constant", "resnet_v1_test.ResnetUtilsTest.test_session", "resnet_v1_test.ResnetUtilsTest.assertAllClose", "tensorflow.range", "nets.resnet_utils.subsample.eval", "tensorflow.reshape.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample"], ["", "", "def", "testSubsampleFourByFour", "(", "self", ")", ":", "\n", "    ", "x", "=", "tf", ".", "reshape", "(", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "16", ")", ")", ",", "[", "1", ",", "4", ",", "4", ",", "1", "]", ")", "\n", "x", "=", "resnet_utils", ".", "subsample", "(", "x", ",", "2", ")", "\n", "expected", "=", "tf", ".", "reshape", "(", "tf", ".", "constant", "(", "[", "0", ",", "2", ",", "8", ",", "10", "]", ")", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ")", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "self", ".", "assertAllClose", "(", "x", ".", "eval", "(", ")", ",", "expected", ".", "eval", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetUtilsTest.testConv2DSameEven": [[72, 112], ["resnet_v1_test.create_test_input", "resnet_v1_test.create_test_input", "tensorflow.reshape", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable_scope().reuse_variables", "slim.conv2d", "tensorflow.to_float", "tensorflow.reshape", "nets.resnet_utils.subsample", "tensorflow.to_float", "tensorflow.reshape", "nets.resnet_utils.conv2d_same", "slim.conv2d", "tensorflow.to_float", "tensorflow.reshape", "resnet_v1_test.ResnetUtilsTest.test_session", "sess.run", "resnet_v1_test.ResnetUtilsTest.assertAllClose", "resnet_v1_test.ResnetUtilsTest.assertAllClose", "resnet_v1_test.ResnetUtilsTest.assertAllClose", "resnet_v1_test.ResnetUtilsTest.assertAllClose", "tensorflow.zeros", "tensorflow.get_variable_scope", "tensorflow.global_variables_initializer", "slim.conv2d.eval", "tensorflow.reshape.eval", "nets.resnet_utils.subsample.eval", "tensorflow.reshape.eval", "nets.resnet_utils.conv2d_same.eval", "y3_expected.eval", "slim.conv2d.eval", "tensorflow.reshape.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.conv2d_same", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testConv2DSameEven", "(", "self", ")", ":", "\n", "    ", "n", ",", "n2", "=", "4", ",", "2", "\n", "\n", "# Input image.", "\n", "x", "=", "create_test_input", "(", "1", ",", "n", ",", "n", ",", "1", ")", "\n", "\n", "# Convolution kernel.", "\n", "w", "=", "create_test_input", "(", "1", ",", "3", ",", "3", ",", "1", ")", "\n", "w", "=", "tf", ".", "reshape", "(", "w", ",", "[", "3", ",", "3", ",", "1", ",", "1", "]", ")", "\n", "\n", "tf", ".", "get_variable", "(", "'Conv/weights'", ",", "initializer", "=", "w", ")", "\n", "tf", ".", "get_variable", "(", "'Conv/biases'", ",", "initializer", "=", "tf", ".", "zeros", "(", "[", "1", "]", ")", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "y1", "=", "slim", ".", "conv2d", "(", "x", ",", "1", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "1", ",", "scope", "=", "'Conv'", ")", "\n", "y1_expected", "=", "tf", ".", "to_float", "(", "[", "[", "14", ",", "28", ",", "43", ",", "26", "]", ",", "\n", "[", "28", ",", "48", ",", "66", ",", "37", "]", ",", "\n", "[", "43", ",", "66", ",", "84", ",", "46", "]", ",", "\n", "[", "26", ",", "37", ",", "46", ",", "22", "]", "]", ")", "\n", "y1_expected", "=", "tf", ".", "reshape", "(", "y1_expected", ",", "[", "1", ",", "n", ",", "n", ",", "1", "]", ")", "\n", "\n", "y2", "=", "resnet_utils", ".", "subsample", "(", "y1", ",", "2", ")", "\n", "y2_expected", "=", "tf", ".", "to_float", "(", "[", "[", "14", ",", "43", "]", ",", "\n", "[", "43", ",", "84", "]", "]", ")", "\n", "y2_expected", "=", "tf", ".", "reshape", "(", "y2_expected", ",", "[", "1", ",", "n2", ",", "n2", ",", "1", "]", ")", "\n", "\n", "y3", "=", "resnet_utils", ".", "conv2d_same", "(", "x", ",", "1", ",", "3", ",", "stride", "=", "2", ",", "scope", "=", "'Conv'", ")", "\n", "y3_expected", "=", "y2_expected", "\n", "\n", "y4", "=", "slim", ".", "conv2d", "(", "x", ",", "1", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "'Conv'", ")", "\n", "y4_expected", "=", "tf", ".", "to_float", "(", "[", "[", "48", ",", "37", "]", ",", "\n", "[", "37", ",", "22", "]", "]", ")", "\n", "y4_expected", "=", "tf", ".", "reshape", "(", "y4_expected", ",", "[", "1", ",", "n2", ",", "n2", ",", "1", "]", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y1", ".", "eval", "(", ")", ",", "y1_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y2", ".", "eval", "(", ")", ",", "y2_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y3", ".", "eval", "(", ")", ",", "y3_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y4", ".", "eval", "(", ")", ",", "y4_expected", ".", "eval", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetUtilsTest.testConv2DSameOdd": [[113, 153], ["resnet_v1_test.create_test_input", "resnet_v1_test.create_test_input", "tensorflow.reshape", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable_scope().reuse_variables", "slim.conv2d", "tensorflow.to_float", "tensorflow.reshape", "nets.resnet_utils.subsample", "tensorflow.to_float", "tensorflow.reshape", "nets.resnet_utils.conv2d_same", "slim.conv2d", "resnet_v1_test.ResnetUtilsTest.test_session", "sess.run", "resnet_v1_test.ResnetUtilsTest.assertAllClose", "resnet_v1_test.ResnetUtilsTest.assertAllClose", "resnet_v1_test.ResnetUtilsTest.assertAllClose", "resnet_v1_test.ResnetUtilsTest.assertAllClose", "tensorflow.zeros", "tensorflow.get_variable_scope", "tensorflow.global_variables_initializer", "slim.conv2d.eval", "tensorflow.reshape.eval", "nets.resnet_utils.subsample.eval", "tensorflow.reshape.eval", "nets.resnet_utils.conv2d_same.eval", "y3_expected.eval", "slim.conv2d.eval", "y4_expected.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.conv2d_same", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testConv2DSameOdd", "(", "self", ")", ":", "\n", "    ", "n", ",", "n2", "=", "5", ",", "3", "\n", "\n", "# Input image.", "\n", "x", "=", "create_test_input", "(", "1", ",", "n", ",", "n", ",", "1", ")", "\n", "\n", "# Convolution kernel.", "\n", "w", "=", "create_test_input", "(", "1", ",", "3", ",", "3", ",", "1", ")", "\n", "w", "=", "tf", ".", "reshape", "(", "w", ",", "[", "3", ",", "3", ",", "1", ",", "1", "]", ")", "\n", "\n", "tf", ".", "get_variable", "(", "'Conv/weights'", ",", "initializer", "=", "w", ")", "\n", "tf", ".", "get_variable", "(", "'Conv/biases'", ",", "initializer", "=", "tf", ".", "zeros", "(", "[", "1", "]", ")", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "y1", "=", "slim", ".", "conv2d", "(", "x", ",", "1", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "1", ",", "scope", "=", "'Conv'", ")", "\n", "y1_expected", "=", "tf", ".", "to_float", "(", "[", "[", "14", ",", "28", ",", "43", ",", "58", ",", "34", "]", ",", "\n", "[", "28", ",", "48", ",", "66", ",", "84", ",", "46", "]", ",", "\n", "[", "43", ",", "66", ",", "84", ",", "102", ",", "55", "]", ",", "\n", "[", "58", ",", "84", ",", "102", ",", "120", ",", "64", "]", ",", "\n", "[", "34", ",", "46", ",", "55", ",", "64", ",", "30", "]", "]", ")", "\n", "y1_expected", "=", "tf", ".", "reshape", "(", "y1_expected", ",", "[", "1", ",", "n", ",", "n", ",", "1", "]", ")", "\n", "\n", "y2", "=", "resnet_utils", ".", "subsample", "(", "y1", ",", "2", ")", "\n", "y2_expected", "=", "tf", ".", "to_float", "(", "[", "[", "14", ",", "43", ",", "34", "]", ",", "\n", "[", "43", ",", "84", ",", "55", "]", ",", "\n", "[", "34", ",", "55", ",", "30", "]", "]", ")", "\n", "y2_expected", "=", "tf", ".", "reshape", "(", "y2_expected", ",", "[", "1", ",", "n2", ",", "n2", ",", "1", "]", ")", "\n", "\n", "y3", "=", "resnet_utils", ".", "conv2d_same", "(", "x", ",", "1", ",", "3", ",", "stride", "=", "2", ",", "scope", "=", "'Conv'", ")", "\n", "y3_expected", "=", "y2_expected", "\n", "\n", "y4", "=", "slim", ".", "conv2d", "(", "x", ",", "1", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "'Conv'", ")", "\n", "y4_expected", "=", "y2_expected", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y1", ".", "eval", "(", ")", ",", "y1_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y2", ".", "eval", "(", ")", ",", "y2_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y3", ".", "eval", "(", ")", ",", "y3_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y4", ".", "eval", "(", ")", ",", "y4_expected", ".", "eval", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetUtilsTest._resnet_plain": [[154, 161], ["tensorflow.variable_scope", "slim.arg_scope", "nets.resnet_utils.stack_blocks_dense", "slim.utils.convert_collection_to_dict"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.stack_blocks_dense"], ["", "", "def", "_resnet_plain", "(", "self", ",", "inputs", ",", "blocks", ",", "output_stride", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"A plain ResNet without extra layers before or after the ResNet blocks.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "outputs_collections", "=", "'end_points'", ")", ":", "\n", "        ", "net", "=", "resnet_utils", ".", "stack_blocks_dense", "(", "inputs", ",", "blocks", ",", "output_stride", ")", "\n", "end_points", "=", "slim", ".", "utils", ".", "convert_collection_to_dict", "(", "'end_points'", ")", "\n", "return", "net", ",", "end_points", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetUtilsTest.testEndPointsV1": [[162, 189], ["resnet_v1_test.create_test_input", "resnet_v1_test.ResnetUtilsTest.assertItemsEqual", "nets.resnet_v1.resnet_v1_block", "nets.resnet_v1.resnet_v1_block", "slim.arg_scope", "resnet_v1_test.ResnetUtilsTest._resnet_plain", "nets.resnet_utils.resnet_arg_scope"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest._resnet_plain", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "", "def", "testEndPointsV1", "(", "self", ")", ":", "\n", "    ", "\"\"\"Test the end points of a tiny v1 bottleneck network.\"\"\"", "\n", "blocks", "=", "[", "\n", "resnet_v1", ".", "resnet_v1_block", "(", "\n", "'block1'", ",", "base_depth", "=", "1", ",", "num_units", "=", "2", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v1", ".", "resnet_v1_block", "(", "\n", "'block2'", ",", "base_depth", "=", "2", ",", "num_units", "=", "2", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "32", ",", "16", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "_", ",", "end_points", "=", "self", ".", "_resnet_plain", "(", "inputs", ",", "blocks", ",", "scope", "=", "'tiny'", ")", "\n", "", "expected", "=", "[", "\n", "'tiny/block1/unit_1/bottleneck_v1/shortcut'", ",", "\n", "'tiny/block1/unit_1/bottleneck_v1/conv1'", ",", "\n", "'tiny/block1/unit_1/bottleneck_v1/conv2'", ",", "\n", "'tiny/block1/unit_1/bottleneck_v1/conv3'", ",", "\n", "'tiny/block1/unit_2/bottleneck_v1/conv1'", ",", "\n", "'tiny/block1/unit_2/bottleneck_v1/conv2'", ",", "\n", "'tiny/block1/unit_2/bottleneck_v1/conv3'", ",", "\n", "'tiny/block2/unit_1/bottleneck_v1/shortcut'", ",", "\n", "'tiny/block2/unit_1/bottleneck_v1/conv1'", ",", "\n", "'tiny/block2/unit_1/bottleneck_v1/conv2'", ",", "\n", "'tiny/block2/unit_1/bottleneck_v1/conv3'", ",", "\n", "'tiny/block2/unit_2/bottleneck_v1/conv1'", ",", "\n", "'tiny/block2/unit_2/bottleneck_v1/conv2'", ",", "\n", "'tiny/block2/unit_2/bottleneck_v1/conv3'", "]", "\n", "self", ".", "assertItemsEqual", "(", "expected", ",", "end_points", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetUtilsTest._stack_blocks_nondense": [[190, 198], ["tensorflow.variable_scope", "enumerate", "tensorflow.variable_scope", "block.unit_fn"], "methods", ["None"], ["", "def", "_stack_blocks_nondense", "(", "self", ",", "net", ",", "blocks", ")", ":", "\n", "    ", "\"\"\"A simplified ResNet Block stacker without output stride control.\"\"\"", "\n", "for", "block", "in", "blocks", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "block", ".", "scope", ",", "'block'", ",", "[", "net", "]", ")", ":", "\n", "        ", "for", "i", ",", "unit", "in", "enumerate", "(", "block", ".", "args", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'unit_%d'", "%", "(", "i", "+", "1", ")", ",", "values", "=", "[", "net", "]", ")", ":", "\n", "            ", "net", "=", "block", ".", "unit_fn", "(", "net", ",", "rate", "=", "1", ",", "**", "unit", ")", "\n", "", "", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetUtilsTest.testAtrousValuesBottleneck": [[199, 242], ["block", "block", "block", "block", "slim.arg_scope", "nets.resnet_utils.resnet_arg_scope", "slim.arg_scope", "tensorflow.Graph().as_default", "resnet_v1_test.ResnetUtilsTest.test_session", "tensorflow.set_random_seed", "resnet_v1_test.create_test_input", "nets.resnet_utils.stack_blocks_dense", "nets.resnet_utils.subsample", "tensorflow.get_variable_scope().reuse_variables", "resnet_v1_test.ResnetUtilsTest._stack_blocks_nondense", "sess.run", "sess.run", "resnet_v1_test.ResnetUtilsTest.assertAllClose", "tensorflow.Graph", "tensorflow.global_variables_initializer", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.stack_blocks_dense", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest._stack_blocks_nondense", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "testAtrousValuesBottleneck", "(", "self", ")", ":", "\n", "    ", "\"\"\"Verify the values of dense feature extraction by atrous convolution.\n\n    Make sure that dense feature extraction by stack_blocks_dense() followed by\n    subsampling gives identical results to feature extraction at the nominal\n    network output stride using the simple self._stack_blocks_nondense() above.\n    \"\"\"", "\n", "block", "=", "resnet_v1", ".", "resnet_v1_block", "\n", "blocks", "=", "[", "\n", "block", "(", "'block1'", ",", "base_depth", "=", "1", ",", "num_units", "=", "2", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block2'", ",", "base_depth", "=", "2", ",", "num_units", "=", "2", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block3'", ",", "base_depth", "=", "4", ",", "num_units", "=", "2", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block4'", ",", "base_depth", "=", "8", ",", "num_units", "=", "2", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "nominal_stride", "=", "8", "\n", "\n", "# Test both odd and even input dimensions.", "\n", "height", "=", "30", "\n", "width", "=", "31", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", "]", ",", "is_training", "=", "False", ")", ":", "\n", "        ", "for", "output_stride", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "None", "]", ":", "\n", "          ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "            ", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "              ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "inputs", "=", "create_test_input", "(", "1", ",", "height", ",", "width", ",", "3", ")", "\n", "# Dense feature extraction followed by subsampling.", "\n", "output", "=", "resnet_utils", ".", "stack_blocks_dense", "(", "inputs", ",", "\n", "blocks", ",", "\n", "output_stride", ")", "\n", "if", "output_stride", "is", "None", ":", "\n", "                ", "factor", "=", "1", "\n", "", "else", ":", "\n", "                ", "factor", "=", "nominal_stride", "//", "output_stride", "\n", "\n", "", "output", "=", "resnet_utils", ".", "subsample", "(", "output", ",", "factor", ")", "\n", "# Make the two networks use the same weights.", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# Feature extraction at the nominal network rate.", "\n", "expected", "=", "self", ".", "_stack_blocks_nondense", "(", "inputs", ",", "blocks", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", ",", "expected", "=", "sess", ".", "run", "(", "[", "output", ",", "expected", "]", ")", "\n", "self", ".", "assertAllClose", "(", "output", ",", "expected", ",", "atol", "=", "1e-4", ",", "rtol", "=", "1e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetCompleteNetworkTest._resnet_small": [[247, 271], ["nets.resnet_v1.resnet_v1", "block", "block", "block", "block"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1.resnet_v1"], ["def", "_resnet_small", "(", "self", ",", "\n", "inputs", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "include_root_block", "=", "True", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'resnet_v1_small'", ")", ":", "\n", "    ", "\"\"\"A shallow and thin ResNet v1 for faster tests.\"\"\"", "\n", "block", "=", "resnet_v1", ".", "resnet_v1_block", "\n", "blocks", "=", "[", "\n", "block", "(", "'block1'", ",", "base_depth", "=", "1", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block2'", ",", "base_depth", "=", "2", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block3'", ",", "base_depth", "=", "4", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block4'", ",", "base_depth", "=", "8", ",", "num_units", "=", "2", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "return", "resnet_v1", ".", "resnet_v1", "(", "inputs", ",", "blocks", ",", "num_classes", ",", "\n", "is_training", "=", "is_training", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "output_stride", "=", "output_stride", ",", "\n", "include_root_block", "=", "include_root_block", ",", "\n", "reuse", "=", "reuse", ",", "\n", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetCompleteNetworkTest.testClassificationEndPoints": [[272, 285], ["resnet_v1_test.create_test_input", "resnet_v1_test.ResnetCompleteNetworkTest.assertTrue", "resnet_v1_test.ResnetCompleteNetworkTest.assertListEqual", "resnet_v1_test.ResnetCompleteNetworkTest.assertTrue", "resnet_v1_test.ResnetCompleteNetworkTest.assertListEqual", "slim.arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest._resnet_small", "logits.op.name.startswith", "logits.get_shape().as_list", "end_points[].get_shape().as_list", "nets.resnet_utils.resnet_arg_scope", "logits.get_shape", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "def", "testClassificationEndPoints", "(", "self", ")", ":", "\n", "    ", "global_pool", "=", "True", "\n", "num_classes", "=", "10", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "224", ",", "224", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "logits", ",", "end_points", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'resnet/logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "2", ",", "1", ",", "1", ",", "num_classes", "]", ")", "\n", "self", ".", "assertTrue", "(", "'predictions'", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "'predictions'", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "2", ",", "1", ",", "1", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetCompleteNetworkTest.testClassificationShapes": [[286, 302], ["resnet_v1_test.create_test_input", "slim.arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest._resnet_small", "nets.resnet_utils.resnet_arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "def", "testClassificationShapes", "(", "self", ")", ":", "\n", "    ", "global_pool", "=", "True", "\n", "num_classes", "=", "10", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "224", ",", "224", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "_", ",", "end_points", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "endpoint_to_shape", "=", "{", "\n", "'resnet/block1'", ":", "[", "2", ",", "28", ",", "28", ",", "4", "]", ",", "\n", "'resnet/block2'", ":", "[", "2", ",", "14", ",", "14", ",", "8", "]", ",", "\n", "'resnet/block3'", ":", "[", "2", ",", "7", ",", "7", ",", "16", "]", ",", "\n", "'resnet/block4'", ":", "[", "2", ",", "7", ",", "7", ",", "32", "]", "}", "\n", "for", "endpoint", "in", "endpoint_to_shape", ":", "\n", "        ", "shape", "=", "endpoint_to_shape", "[", "endpoint", "]", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetCompleteNetworkTest.testFullyConvolutionalEndpointShapes": [[303, 319], ["resnet_v1_test.create_test_input", "slim.arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest._resnet_small", "nets.resnet_utils.resnet_arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "", "def", "testFullyConvolutionalEndpointShapes", "(", "self", ")", ":", "\n", "    ", "global_pool", "=", "False", "\n", "num_classes", "=", "10", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "321", ",", "321", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "_", ",", "end_points", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "endpoint_to_shape", "=", "{", "\n", "'resnet/block1'", ":", "[", "2", ",", "41", ",", "41", ",", "4", "]", ",", "\n", "'resnet/block2'", ":", "[", "2", ",", "21", ",", "21", ",", "8", "]", ",", "\n", "'resnet/block3'", ":", "[", "2", ",", "11", ",", "11", ",", "16", "]", ",", "\n", "'resnet/block4'", ":", "[", "2", ",", "11", ",", "11", ",", "32", "]", "}", "\n", "for", "endpoint", "in", "endpoint_to_shape", ":", "\n", "        ", "shape", "=", "endpoint_to_shape", "[", "endpoint", "]", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetCompleteNetworkTest.testRootlessFullyConvolutionalEndpointShapes": [[320, 337], ["resnet_v1_test.create_test_input", "slim.arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest._resnet_small", "nets.resnet_utils.resnet_arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "", "def", "testRootlessFullyConvolutionalEndpointShapes", "(", "self", ")", ":", "\n", "    ", "global_pool", "=", "False", "\n", "num_classes", "=", "10", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "128", ",", "128", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "_", ",", "end_points", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "include_root_block", "=", "False", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "endpoint_to_shape", "=", "{", "\n", "'resnet/block1'", ":", "[", "2", ",", "64", ",", "64", ",", "4", "]", ",", "\n", "'resnet/block2'", ":", "[", "2", ",", "32", ",", "32", ",", "8", "]", ",", "\n", "'resnet/block3'", ":", "[", "2", ",", "16", ",", "16", ",", "16", "]", ",", "\n", "'resnet/block4'", ":", "[", "2", ",", "16", ",", "16", ",", "32", "]", "}", "\n", "for", "endpoint", "in", "endpoint_to_shape", ":", "\n", "        ", "shape", "=", "endpoint_to_shape", "[", "endpoint", "]", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetCompleteNetworkTest.testAtrousFullyConvolutionalEndpointShapes": [[338, 357], ["resnet_v1_test.create_test_input", "slim.arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest._resnet_small", "nets.resnet_utils.resnet_arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "", "def", "testAtrousFullyConvolutionalEndpointShapes", "(", "self", ")", ":", "\n", "    ", "global_pool", "=", "False", "\n", "num_classes", "=", "10", "\n", "output_stride", "=", "8", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "321", ",", "321", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "_", ",", "end_points", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "\n", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "output_stride", "=", "output_stride", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "endpoint_to_shape", "=", "{", "\n", "'resnet/block1'", ":", "[", "2", ",", "41", ",", "41", ",", "4", "]", ",", "\n", "'resnet/block2'", ":", "[", "2", ",", "41", ",", "41", ",", "8", "]", ",", "\n", "'resnet/block3'", ":", "[", "2", ",", "41", ",", "41", ",", "16", "]", ",", "\n", "'resnet/block4'", ":", "[", "2", ",", "41", ",", "41", ",", "32", "]", "}", "\n", "for", "endpoint", "in", "endpoint_to_shape", ":", "\n", "        ", "shape", "=", "endpoint_to_shape", "[", "endpoint", "]", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetCompleteNetworkTest.testAtrousFullyConvolutionalValues": [[358, 384], ["slim.arg_scope", "nets.resnet_utils.resnet_arg_scope", "tensorflow.Graph().as_default", "resnet_v1_test.ResnetCompleteNetworkTest.test_session", "tensorflow.set_random_seed", "resnet_v1_test.create_test_input", "resnet_v1_test.ResnetCompleteNetworkTest._resnet_small", "nets.resnet_utils.subsample", "tensorflow.get_variable_scope().reuse_variables", "resnet_v1_test.ResnetCompleteNetworkTest._resnet_small", "sess.run", "resnet_v1_test.ResnetCompleteNetworkTest.assertAllClose", "tensorflow.Graph", "tensorflow.global_variables_initializer", "nets.resnet_utils.subsample.eval", "expected.eval", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "", "def", "testAtrousFullyConvolutionalValues", "(", "self", ")", ":", "\n", "    ", "\"\"\"Verify dense feature extraction with atrous convolution.\"\"\"", "\n", "nominal_stride", "=", "32", "\n", "for", "output_stride", "in", "[", "4", ",", "8", ",", "16", ",", "32", ",", "None", "]", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "        ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "          ", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "81", ",", "81", ",", "3", ")", "\n", "# Dense feature extraction followed by subsampling.", "\n", "output", ",", "_", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "None", ",", "is_training", "=", "False", ",", "\n", "global_pool", "=", "False", ",", "\n", "output_stride", "=", "output_stride", ")", "\n", "if", "output_stride", "is", "None", ":", "\n", "              ", "factor", "=", "1", "\n", "", "else", ":", "\n", "              ", "factor", "=", "nominal_stride", "//", "output_stride", "\n", "", "output", "=", "resnet_utils", ".", "subsample", "(", "output", ",", "factor", ")", "\n", "# Make the two networks use the same weights.", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# Feature extraction at the nominal network rate.", "\n", "expected", ",", "_", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "None", ",", "is_training", "=", "False", ",", "\n", "global_pool", "=", "False", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "output", ".", "eval", "(", ")", ",", "expected", ".", "eval", "(", ")", ",", "\n", "atol", "=", "1e-4", ",", "rtol", "=", "1e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetCompleteNetworkTest.testUnknownBatchSize": [[385, 403], ["resnet_v1_test.create_test_input", "resnet_v1_test.ResnetCompleteNetworkTest.assertTrue", "resnet_v1_test.ResnetCompleteNetworkTest.assertListEqual", "resnet_v1_test.create_test_input", "slim.arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest._resnet_small", "logits.op.name.startswith", "logits.get_shape().as_list", "resnet_v1_test.ResnetCompleteNetworkTest.test_session", "sess.run", "sess.run", "resnet_v1_test.ResnetCompleteNetworkTest.assertEqual", "nets.resnet_utils.resnet_arg_scope", "tensorflow.global_variables_initializer", "logits.get_shape", "create_test_input.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "", "", "", "def", "testUnknownBatchSize", "(", "self", ")", ":", "\n", "    ", "batch", "=", "2", "\n", "height", ",", "width", "=", "65", ",", "65", "\n", "global_pool", "=", "True", "\n", "num_classes", "=", "10", "\n", "inputs", "=", "create_test_input", "(", "None", ",", "height", ",", "width", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "logits", ",", "_", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'resnet/logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "None", ",", "1", ",", "1", ",", "num_classes", "]", ")", "\n", "images", "=", "create_test_input", "(", "batch", ",", "height", ",", "width", ",", "3", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ",", "{", "inputs", ":", "images", ".", "eval", "(", ")", "}", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "shape", ",", "(", "batch", ",", "1", ",", "1", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetCompleteNetworkTest.testFullyConvolutionalUnknownHeightWidth": [[404, 418], ["resnet_v1_test.create_test_input", "resnet_v1_test.ResnetCompleteNetworkTest.assertListEqual", "resnet_v1_test.create_test_input", "slim.arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest._resnet_small", "sess.run.get_shape().as_list", "resnet_v1_test.ResnetCompleteNetworkTest.test_session", "sess.run", "sess.run", "resnet_v1_test.ResnetCompleteNetworkTest.assertEqual", "nets.resnet_utils.resnet_arg_scope", "tensorflow.global_variables_initializer", "sess.run.get_shape", "create_test_input.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "def", "testFullyConvolutionalUnknownHeightWidth", "(", "self", ")", ":", "\n", "    ", "batch", "=", "2", "\n", "height", ",", "width", "=", "65", ",", "65", "\n", "global_pool", "=", "False", "\n", "inputs", "=", "create_test_input", "(", "batch", ",", "None", ",", "None", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "output", ",", "_", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "None", ",", "global_pool", "=", "global_pool", ")", "\n", "", "self", ".", "assertListEqual", "(", "output", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch", ",", "None", ",", "None", ",", "32", "]", ")", "\n", "images", "=", "create_test_input", "(", "batch", ",", "height", ",", "width", ",", "3", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "output", ",", "{", "inputs", ":", "images", ".", "eval", "(", ")", "}", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "shape", ",", "(", "batch", ",", "3", ",", "3", ",", "32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.ResnetCompleteNetworkTest.testAtrousFullyConvolutionalUnknownHeightWidth": [[419, 437], ["resnet_v1_test.create_test_input", "resnet_v1_test.ResnetCompleteNetworkTest.assertListEqual", "resnet_v1_test.create_test_input", "slim.arg_scope", "resnet_v1_test.ResnetCompleteNetworkTest._resnet_small", "sess.run.get_shape().as_list", "resnet_v1_test.ResnetCompleteNetworkTest.test_session", "sess.run", "sess.run", "resnet_v1_test.ResnetCompleteNetworkTest.assertEqual", "nets.resnet_utils.resnet_arg_scope", "tensorflow.global_variables_initializer", "sess.run.get_shape", "create_test_input.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "def", "testAtrousFullyConvolutionalUnknownHeightWidth", "(", "self", ")", ":", "\n", "    ", "batch", "=", "2", "\n", "height", ",", "width", "=", "65", ",", "65", "\n", "global_pool", "=", "False", "\n", "output_stride", "=", "8", "\n", "inputs", "=", "create_test_input", "(", "batch", ",", "None", ",", "None", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "output", ",", "_", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "\n", "None", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "output_stride", "=", "output_stride", ")", "\n", "", "self", ".", "assertListEqual", "(", "output", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch", ",", "None", ",", "None", ",", "32", "]", ")", "\n", "images", "=", "create_test_input", "(", "batch", ",", "height", ",", "width", ",", "3", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "output", ",", "{", "inputs", ":", "images", ".", "eval", "(", ")", "}", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "shape", ",", "(", "batch", ",", "9", ",", "9", ",", "32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v1_test.create_test_input": [[30, 54], ["tensorflow.placeholder", "tensorflow.to_float", "numpy.tile", "numpy.reshape", "numpy.reshape", "numpy.reshape", "numpy.arange", "numpy.arange"], "function", ["None"], ["def", "create_test_input", "(", "batch_size", ",", "height", ",", "width", ",", "channels", ")", ":", "\n", "  ", "\"\"\"Create test input tensor.\n\n  Args:\n    batch_size: The number of images per batch or `None` if unknown.\n    height: The height of each image or `None` if unknown.\n    width: The width of each image or `None` if unknown.\n    channels: The number of channels per image or `None` if unknown.\n\n  Returns:\n    Either a placeholder `Tensor` of dimension\n      [batch_size, height, width, channels] if any of the inputs are `None` or a\n    constant `Tensor` with the mesh grid values along the spatial dimensions.\n  \"\"\"", "\n", "if", "None", "in", "[", "batch_size", ",", "height", ",", "width", ",", "channels", "]", ":", "\n", "    ", "return", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "batch_size", ",", "height", ",", "width", ",", "channels", ")", ")", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "to_float", "(", "\n", "np", ".", "tile", "(", "\n", "np", ".", "reshape", "(", "\n", "np", ".", "reshape", "(", "np", ".", "arange", "(", "height", ")", ",", "[", "height", ",", "1", "]", ")", "+", "\n", "np", ".", "reshape", "(", "np", ".", "arange", "(", "width", ")", ",", "[", "1", ",", "width", "]", ")", ",", "\n", "[", "1", ",", "height", ",", "width", ",", "1", "]", ")", ",", "\n", "[", "batch_size", ",", "1", ",", "1", ",", "channels", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet_test.AlexnetV2Test.testBuild": [[29, 39], ["alexnet_test.AlexnetV2Test.test_session", "tensorflow.random_uniform", "nets.alexnet.alexnet_v2", "alexnet_test.AlexnetV2Test.assertEquals", "alexnet_test.AlexnetV2Test.assertListEqual", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet.alexnet_v2"], ["  ", "def", "testBuild", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "alexnet", ".", "alexnet_v2", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertEquals", "(", "logits", ".", "op", ".", "name", ",", "'alexnet_v2/fc8/squeezed'", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet_test.AlexnetV2Test.testFullyConvolutional": [[40, 50], ["alexnet_test.AlexnetV2Test.test_session", "tensorflow.random_uniform", "nets.alexnet.alexnet_v2", "alexnet_test.AlexnetV2Test.assertEquals", "alexnet_test.AlexnetV2Test.assertListEqual", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet.alexnet_v2"], ["", "", "def", "testFullyConvolutional", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "300", ",", "400", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "alexnet", ".", "alexnet_v2", "(", "inputs", ",", "num_classes", ",", "spatial_squeeze", "=", "False", ")", "\n", "self", ".", "assertEquals", "(", "logits", ".", "op", ".", "name", ",", "'alexnet_v2/fc8/BiasAdd'", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "4", ",", "7", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet_test.AlexnetV2Test.testEndPoints": [[51, 71], ["alexnet_test.AlexnetV2Test.test_session", "tensorflow.random_uniform", "nets.alexnet.alexnet_v2", "alexnet_test.AlexnetV2Test.assertSetEqual", "set", "set", "end_points.keys"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet.alexnet_v2"], ["", "", "def", "testEndPoints", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "alexnet", ".", "alexnet_v2", "(", "inputs", ",", "num_classes", ")", "\n", "expected_names", "=", "[", "'alexnet_v2/conv1'", ",", "\n", "'alexnet_v2/pool1'", ",", "\n", "'alexnet_v2/conv2'", ",", "\n", "'alexnet_v2/pool2'", ",", "\n", "'alexnet_v2/conv3'", ",", "\n", "'alexnet_v2/conv4'", ",", "\n", "'alexnet_v2/conv5'", ",", "\n", "'alexnet_v2/pool5'", ",", "\n", "'alexnet_v2/fc6'", ",", "\n", "'alexnet_v2/fc7'", ",", "\n", "'alexnet_v2/fc8'", "\n", "]", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "end_points", ".", "keys", "(", ")", ")", ",", "set", "(", "expected_names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet_test.AlexnetV2Test.testModelVariables": [[72, 98], ["alexnet_test.AlexnetV2Test.test_session", "tensorflow.random_uniform", "nets.alexnet.alexnet_v2", "alexnet_test.AlexnetV2Test.assertSetEqual", "set", "set", "slim.get_model_variables"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet.alexnet_v2"], ["", "", "def", "testModelVariables", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "alexnet", ".", "alexnet_v2", "(", "inputs", ",", "num_classes", ")", "\n", "expected_names", "=", "[", "'alexnet_v2/conv1/weights'", ",", "\n", "'alexnet_v2/conv1/biases'", ",", "\n", "'alexnet_v2/conv2/weights'", ",", "\n", "'alexnet_v2/conv2/biases'", ",", "\n", "'alexnet_v2/conv3/weights'", ",", "\n", "'alexnet_v2/conv3/biases'", ",", "\n", "'alexnet_v2/conv4/weights'", ",", "\n", "'alexnet_v2/conv4/biases'", ",", "\n", "'alexnet_v2/conv5/weights'", ",", "\n", "'alexnet_v2/conv5/biases'", ",", "\n", "'alexnet_v2/fc6/weights'", ",", "\n", "'alexnet_v2/fc6/biases'", ",", "\n", "'alexnet_v2/fc7/weights'", ",", "\n", "'alexnet_v2/fc7/biases'", ",", "\n", "'alexnet_v2/fc8/weights'", ",", "\n", "'alexnet_v2/fc8/biases'", ",", "\n", "]", "\n", "model_variables", "=", "[", "v", ".", "op", ".", "name", "for", "v", "in", "slim", ".", "get_model_variables", "(", ")", "]", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "model_variables", ")", ",", "set", "(", "expected_names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet_test.AlexnetV2Test.testEvaluation": [[99, 110], ["alexnet_test.AlexnetV2Test.test_session", "tensorflow.random_uniform", "nets.alexnet.alexnet_v2", "alexnet_test.AlexnetV2Test.assertListEqual", "tensorflow.argmax", "alexnet_test.AlexnetV2Test.assertListEqual", "logits.get_shape().as_list", "tensorflow.argmax.get_shape().as_list", "logits.get_shape", "tensorflow.argmax.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet.alexnet_v2"], ["", "", "def", "testEvaluation", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "alexnet", ".", "alexnet_v2", "(", "eval_inputs", ",", "is_training", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "predictions", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet_test.AlexnetV2Test.testTrainEvalWithReuse": [[111, 133], ["alexnet_test.AlexnetV2Test.test_session", "tensorflow.random_uniform", "nets.alexnet.alexnet_v2", "alexnet_test.AlexnetV2Test.assertListEqual", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.random_uniform", "nets.alexnet.alexnet_v2", "alexnet_test.AlexnetV2Test.assertListEqual", "tensorflow.reduce_mean", "tensorflow.argmax", "alexnet_test.AlexnetV2Test.assertEquals", "tensorflow.reduce_mean.get_shape().as_list", "tensorflow.reduce_mean.get_shape().as_list", "tensorflow.argmax.get_shape().as_list", "tensorflow.get_variable_scope", "tensorflow.reduce_mean.get_shape", "tensorflow.reduce_mean.get_shape", "tensorflow.argmax.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet.alexnet_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet.alexnet_v2"], ["", "", "def", "testTrainEvalWithReuse", "(", "self", ")", ":", "\n", "    ", "train_batch_size", "=", "2", "\n", "eval_batch_size", "=", "1", "\n", "train_height", ",", "train_width", "=", "224", ",", "224", "\n", "eval_height", ",", "eval_width", "=", "300", ",", "400", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "train_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "(", "train_batch_size", ",", "train_height", ",", "train_width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "alexnet", ".", "alexnet_v2", "(", "train_inputs", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "train_batch_size", ",", "num_classes", "]", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "(", "eval_batch_size", ",", "eval_height", ",", "eval_width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "alexnet", ".", "alexnet_v2", "(", "eval_inputs", ",", "is_training", "=", "False", ",", "\n", "spatial_squeeze", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "eval_batch_size", ",", "4", ",", "7", ",", "num_classes", "]", ")", "\n", "logits", "=", "tf", ".", "reduce_mean", "(", "logits", ",", "[", "1", ",", "2", "]", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "self", ".", "assertEquals", "(", "predictions", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "eval_batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet_test.AlexnetV2Test.testForward": [[134, 143], ["alexnet_test.AlexnetV2Test.test_session", "tensorflow.random_uniform", "nets.alexnet.alexnet_v2", "sess.run", "sess.run", "alexnet_test.AlexnetV2Test.assertTrue", "tensorflow.global_variables_initializer", "sess.run.any"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet.alexnet_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testForward", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "alexnet", ".", "alexnet_v2", "(", "inputs", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ")", "\n", "self", ".", "assertTrue", "(", "output", ".", "any", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat.overfeat_arg_scope": [[40, 48], ["slim.arg_scope", "slim.arg_scope", "slim.l2_regularizer", "tensorflow.zeros_initializer", "slim.arg_scope"], "function", ["None"], ["def", "overfeat_arg_scope", "(", "weight_decay", "=", "0.0005", ")", ":", "\n", "  ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "padding", "=", "'SAME'", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "max_pool2d", "]", ",", "padding", "=", "'VALID'", ")", "as", "arg_sc", ":", "\n", "        ", "return", "arg_sc", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.overfeat.overfeat": [[50, 118], ["tensorflow.variable_scope", "slim.arg_scope", "slim.conv2d", "slim.max_pool2d", "slim.conv2d", "slim.max_pool2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.max_pool2d", "slim.utils.convert_collection_to_dict", "slim.arg_scope", "slim.conv2d", "slim.dropout", "slim.conv2d", "slim.dropout", "slim.conv2d", "tensorflow.squeeze", "trunc_normal", "tensorflow.constant_initializer", "tensorflow.zeros_initializer"], "function", ["None"], ["", "", "", "", "def", "overfeat", "(", "inputs", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.5", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "scope", "=", "'overfeat'", ")", ":", "\n", "  ", "\"\"\"Contains the model definition for the OverFeat network.\n\n  The definition for the network was obtained from:\n    OverFeat: Integrated Recognition, Localization and Detection using\n    Convolutional Networks\n    Pierre Sermanet, David Eigen, Xiang Zhang, Michael Mathieu, Rob Fergus and\n    Yann LeCun, 2014\n    http://arxiv.org/abs/1312.6229\n\n  Note: All the fully_connected layers have been transformed to conv2d layers.\n        To use in classification mode, resize input to 231x231. To use in fully\n        convolutional mode, set spatial_squeeze to false.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    is_training: whether or not the model is being trained.\n    dropout_keep_prob: the probability that activations are kept in the dropout\n      layers during training.\n    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n      outputs. Useful to remove unnecessary dimensions for classification.\n    scope: Optional scope for the variables.\n\n  Returns:\n    the last op containing the log predictions and end_points dict.\n\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'overfeat'", ",", "[", "inputs", "]", ")", "as", "sc", ":", "\n", "    ", "end_points_collection", "=", "sc", ".", "name", "+", "'_end_points'", "\n", "# Collect outputs for conv2d, fully_connected and max_pool2d", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "outputs_collections", "=", "end_points_collection", ")", ":", "\n", "      ", "net", "=", "slim", ".", "conv2d", "(", "inputs", ",", "64", ",", "[", "11", ",", "11", "]", ",", "4", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'conv1'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool1'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "[", "5", ",", "5", "]", ",", "padding", "=", "'VALID'", ",", "scope", "=", "'conv2'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool2'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "512", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv3'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "1024", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv4'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "1024", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv5'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "scope", "=", "'pool5'", ")", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.005", ")", ",", "\n", "biases_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ")", ":", "\n", "# Use conv2d instead of fully_connected layers.", "\n", "        ", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "3072", ",", "[", "6", ",", "6", "]", ",", "padding", "=", "'VALID'", ",", "scope", "=", "'fc6'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout6'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "4096", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'fc7'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout7'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "\n", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "scope", "=", "'fc8'", ")", "\n", "# Convert end_points_collection into a end_point dict.", "\n", "", "end_points", "=", "slim", ".", "utils", ".", "convert_collection_to_dict", "(", "end_points_collection", ")", "\n", "if", "spatial_squeeze", ":", "\n", "        ", "net", "=", "tf", ".", "squeeze", "(", "net", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'fc8/squeezed'", ")", "\n", "end_points", "[", "sc", ".", "name", "+", "'/fc8'", "]", "=", "net", "\n", "", "return", "net", ",", "end_points", "\n", "", "", "", "overfeat", ".", "default_image_size", "=", "231", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.block35": [[33, 52], ["tensorflow.variable_scope", "tensorflow.concat", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "activation_fn", "activation_fn.get_shape"], "function", ["None"], ["def", "block35", "(", "net", ",", "scale", "=", "1.0", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds the 35x35 resnet block.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'Block35'", ",", "[", "net", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "      ", "tower_conv", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "1", ",", "scope", "=", "'Conv2d_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "      ", "tower_conv1_0", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "1", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "tower_conv1_1", "=", "slim", ".", "conv2d", "(", "tower_conv1_0", ",", "32", ",", "3", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "      ", "tower_conv2_0", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "1", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "tower_conv2_1", "=", "slim", ".", "conv2d", "(", "tower_conv2_0", ",", "48", ",", "3", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "tower_conv2_2", "=", "slim", ".", "conv2d", "(", "tower_conv2_1", ",", "64", ",", "3", ",", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "mixed", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "tower_conv", ",", "tower_conv1_1", ",", "tower_conv2_2", "]", ")", "\n", "up", "=", "slim", ".", "conv2d", "(", "mixed", ",", "net", ".", "get_shape", "(", ")", "[", "3", "]", ",", "1", ",", "normalizer_fn", "=", "None", ",", "\n", "activation_fn", "=", "None", ",", "scope", "=", "'Conv2d_1x1'", ")", "\n", "net", "+=", "scale", "*", "up", "\n", "if", "activation_fn", ":", "\n", "      ", "net", "=", "activation_fn", "(", "net", ")", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.block17": [[54, 72], ["tensorflow.variable_scope", "tensorflow.concat", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "activation_fn", "activation_fn.get_shape"], "function", ["None"], ["", "def", "block17", "(", "net", ",", "scale", "=", "1.0", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds the 17x17 resnet block.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'Block17'", ",", "[", "net", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "      ", "tower_conv", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "1", ",", "scope", "=", "'Conv2d_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "      ", "tower_conv1_0", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "1", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "tower_conv1_1", "=", "slim", ".", "conv2d", "(", "tower_conv1_0", ",", "160", ",", "[", "1", ",", "7", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x7'", ")", "\n", "tower_conv1_2", "=", "slim", ".", "conv2d", "(", "tower_conv1_1", ",", "192", ",", "[", "7", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0c_7x1'", ")", "\n", "", "mixed", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "tower_conv", ",", "tower_conv1_2", "]", ")", "\n", "up", "=", "slim", ".", "conv2d", "(", "mixed", ",", "net", ".", "get_shape", "(", ")", "[", "3", "]", ",", "1", ",", "normalizer_fn", "=", "None", ",", "\n", "activation_fn", "=", "None", ",", "scope", "=", "'Conv2d_1x1'", ")", "\n", "net", "+=", "scale", "*", "up", "\n", "if", "activation_fn", ":", "\n", "      ", "net", "=", "activation_fn", "(", "net", ")", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.block8": [[74, 92], ["tensorflow.variable_scope", "tensorflow.concat", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "slim.conv2d", "activation_fn", "activation_fn.get_shape"], "function", ["None"], ["", "def", "block8", "(", "net", ",", "scale", "=", "1.0", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "None", ",", "reuse", "=", "None", ")", ":", "\n", "  ", "\"\"\"Builds the 8x8 resnet block.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'Block8'", ",", "[", "net", "]", ",", "reuse", "=", "reuse", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "      ", "tower_conv", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "1", ",", "scope", "=", "'Conv2d_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "      ", "tower_conv1_0", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "1", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "tower_conv1_1", "=", "slim", ".", "conv2d", "(", "tower_conv1_0", ",", "224", ",", "[", "1", ",", "3", "]", ",", "\n", "scope", "=", "'Conv2d_0b_1x3'", ")", "\n", "tower_conv1_2", "=", "slim", ".", "conv2d", "(", "tower_conv1_1", ",", "256", ",", "[", "3", ",", "1", "]", ",", "\n", "scope", "=", "'Conv2d_0c_3x1'", ")", "\n", "", "mixed", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "tower_conv", ",", "tower_conv1_2", "]", ")", "\n", "up", "=", "slim", ".", "conv2d", "(", "mixed", ",", "net", ".", "get_shape", "(", ")", "[", "3", "]", ",", "1", ",", "normalizer_fn", "=", "None", ",", "\n", "activation_fn", "=", "None", ",", "scope", "=", "'Conv2d_1x1'", ")", "\n", "net", "+=", "scale", "*", "up", "\n", "if", "activation_fn", ":", "\n", "      ", "net", "=", "activation_fn", "(", "net", ")", "\n", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2_base": [[94, 268], ["ValueError", "tensorflow.variable_scope", "ValueError", "slim.arg_scope", "slim.conv2d", "inception_resnet_v2.inception_resnet_v2_base.add_and_check_final"], "function", ["None"], ["", "def", "inception_resnet_v2_base", "(", "inputs", ",", "\n", "final_endpoint", "=", "'Conv2d_7b_1x1'", ",", "\n", "output_stride", "=", "16", ",", "\n", "align_feature_maps", "=", "False", ",", "\n", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Inception model from  http://arxiv.org/abs/1602.07261.\n\n  Constructs an Inception Resnet v2 network from inputs to the given final\n  endpoint. This method can construct the network up to the final inception\n  block Conv2d_7b_1x1.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    final_endpoint: specifies the endpoint to construct the network up to. It\n      can be one of ['Conv2d_1a_3x3', 'Conv2d_2a_3x3', 'Conv2d_2b_3x3',\n      'MaxPool_3a_3x3', 'Conv2d_3b_1x1', 'Conv2d_4a_3x3', 'MaxPool_5a_3x3',\n      'Mixed_5b', 'Mixed_6a', 'PreAuxLogits', 'Mixed_7a', 'Conv2d_7b_1x1']\n    output_stride: A scalar that specifies the requested ratio of input to\n      output spatial resolution. Only supports 8 and 16.\n    align_feature_maps: When true, changes all the VALID paddings in the network\n      to SAME padding so that the feature maps are aligned.\n    scope: Optional variable_scope.\n\n  Returns:\n    tensor_out: output tensor corresponding to the final_endpoint.\n    end_points: a set of activations for external use, for example summaries or\n                losses.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values,\n      or if the output_stride is not 8 or 16, or if the output_stride is 8 and\n      we request an end point after 'PreAuxLogits'.\n  \"\"\"", "\n", "if", "output_stride", "!=", "8", "and", "output_stride", "!=", "16", ":", "\n", "    ", "raise", "ValueError", "(", "'output_stride must be 8 or 16.'", ")", "\n", "\n", "", "padding", "=", "'SAME'", "if", "align_feature_maps", "else", "'VALID'", "\n", "\n", "end_points", "=", "{", "}", "\n", "\n", "def", "add_and_check_final", "(", "name", ",", "net", ")", ":", "\n", "    ", "end_points", "[", "name", "]", "=", "net", "\n", "return", "name", "==", "final_endpoint", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionResnetV2'", ",", "[", "inputs", "]", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", ",", "slim", ".", "avg_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "# 149 x 149 x 32", "\n", "      ", "net", "=", "slim", ".", "conv2d", "(", "inputs", ",", "32", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "padding", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_1a_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 147 x 147 x 32", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "3", ",", "padding", "=", "padding", ",", "\n", "scope", "=", "'Conv2d_2a_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_2a_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 147 x 147 x 64", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "3", ",", "scope", "=", "'Conv2d_2b_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_2b_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 73 x 73 x 64", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "padding", ",", "\n", "scope", "=", "'MaxPool_3a_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'MaxPool_3a_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 73 x 73 x 80", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "80", ",", "1", ",", "padding", "=", "padding", ",", "\n", "scope", "=", "'Conv2d_3b_1x1'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_3b_1x1'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 71 x 71 x 192", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "3", ",", "padding", "=", "padding", ",", "\n", "scope", "=", "'Conv2d_4a_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_4a_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# 35 x 35 x 192", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "padding", ",", "\n", "scope", "=", "'MaxPool_5a_3x3'", ")", "\n", "if", "add_and_check_final", "(", "'MaxPool_5a_3x3'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# 35 x 35 x 320", "\n", "with", "tf", ".", "variable_scope", "(", "'Mixed_5b'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "tower_conv", "=", "slim", ".", "conv2d", "(", "net", ",", "96", ",", "1", ",", "scope", "=", "'Conv2d_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "tower_conv1_0", "=", "slim", ".", "conv2d", "(", "net", ",", "48", ",", "1", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "tower_conv1_1", "=", "slim", ".", "conv2d", "(", "tower_conv1_0", ",", "64", ",", "5", ",", "\n", "scope", "=", "'Conv2d_0b_5x5'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "tower_conv2_0", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "1", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "tower_conv2_1", "=", "slim", ".", "conv2d", "(", "tower_conv2_0", ",", "96", ",", "3", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "tower_conv2_2", "=", "slim", ".", "conv2d", "(", "tower_conv2_1", ",", "96", ",", "3", ",", "\n", "scope", "=", "'Conv2d_0c_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "tower_pool", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "'SAME'", ",", "\n", "scope", "=", "'AvgPool_0a_3x3'", ")", "\n", "tower_pool_1", "=", "slim", ".", "conv2d", "(", "tower_pool", ",", "64", ",", "1", ",", "\n", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "\n", "[", "tower_conv", ",", "tower_conv1_1", ",", "tower_conv2_2", ",", "tower_pool_1", "]", ",", "3", ")", "\n", "\n", "", "if", "add_and_check_final", "(", "'Mixed_5b'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "# TODO(alemi): Register intermediate endpoints", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "10", ",", "block35", ",", "scale", "=", "0.17", ")", "\n", "\n", "# 17 x 17 x 1088 if output_stride == 8,", "\n", "# 33 x 33 x 1088 if output_stride == 16", "\n", "use_atrous", "=", "output_stride", "==", "8", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'Mixed_6a'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "tower_conv", "=", "slim", ".", "conv2d", "(", "net", ",", "384", ",", "3", ",", "stride", "=", "1", "if", "use_atrous", "else", "2", ",", "\n", "padding", "=", "padding", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "tower_conv1_0", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "1", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "tower_conv1_1", "=", "slim", ".", "conv2d", "(", "tower_conv1_0", ",", "256", ",", "3", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "tower_conv1_2", "=", "slim", ".", "conv2d", "(", "tower_conv1_1", ",", "384", ",", "3", ",", "\n", "stride", "=", "1", "if", "use_atrous", "else", "2", ",", "\n", "padding", "=", "padding", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "tower_pool", "=", "slim", ".", "max_pool2d", "(", "net", ",", "3", ",", "stride", "=", "1", "if", "use_atrous", "else", "2", ",", "\n", "padding", "=", "padding", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "[", "tower_conv", ",", "tower_conv1_2", ",", "tower_pool", "]", ",", "3", ")", "\n", "\n", "", "if", "add_and_check_final", "(", "'Mixed_6a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# TODO(alemi): register intermediate endpoints", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "rate", "=", "2", "if", "use_atrous", "else", "1", ")", ":", "\n", "        ", "net", "=", "slim", ".", "repeat", "(", "net", ",", "20", ",", "block17", ",", "scale", "=", "0.10", ")", "\n", "", "if", "add_and_check_final", "(", "'PreAuxLogits'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "if", "output_stride", "==", "8", ":", "\n", "# TODO(gpapan): Properly support output_stride for the rest of the net.", "\n", "        ", "raise", "ValueError", "(", "'output_stride==8 is only supported up to the '", "\n", "'PreAuxlogits end_point for now.'", ")", "\n", "\n", "# 8 x 8 x 2080", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Mixed_7a'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "          ", "tower_conv", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "1", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "tower_conv_1", "=", "slim", ".", "conv2d", "(", "tower_conv", ",", "384", ",", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "padding", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "          ", "tower_conv1", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "1", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "tower_conv1_1", "=", "slim", ".", "conv2d", "(", "tower_conv1", ",", "288", ",", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "padding", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "          ", "tower_conv2", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "1", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "tower_conv2_1", "=", "slim", ".", "conv2d", "(", "tower_conv2", ",", "288", ",", "3", ",", "\n", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "tower_conv2_2", "=", "slim", ".", "conv2d", "(", "tower_conv2_1", ",", "320", ",", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "padding", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "          ", "tower_pool", "=", "slim", ".", "max_pool2d", "(", "net", ",", "3", ",", "stride", "=", "2", ",", "\n", "padding", "=", "padding", ",", "\n", "scope", "=", "'MaxPool_1a_3x3'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "\n", "[", "tower_conv_1", ",", "tower_conv1_1", ",", "tower_conv2_2", ",", "tower_pool", "]", ",", "3", ")", "\n", "\n", "", "if", "add_and_check_final", "(", "'Mixed_7a'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "# TODO(alemi): register intermediate endpoints", "\n", "net", "=", "slim", ".", "repeat", "(", "net", ",", "9", ",", "block8", ",", "scale", "=", "0.20", ")", "\n", "net", "=", "block8", "(", "net", ",", "activation_fn", "=", "None", ")", "\n", "\n", "# 8 x 8 x 1536", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "1536", ",", "1", ",", "scope", "=", "'Conv2d_7b_1x1'", ")", "\n", "if", "add_and_check_final", "(", "'Conv2d_7b_1x1'", ",", "net", ")", ":", "return", "net", ",", "end_points", "\n", "\n", "", "raise", "ValueError", "(", "'final_endpoint (%s) not recognized'", ",", "final_endpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2": [[270, 328], ["tensorflow.variable_scope", "slim.arg_scope", "inception_resnet_v2.inception_resnet_v2_base", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.flatten", "slim.dropout", "slim.fully_connected", "tensorflow.nn.softmax", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.conv2d", "slim.conv2d", "slim.flatten", "slim.fully_connected", "slim.dropout.get_shape", "slim.fully_connected.get_shape"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2_base"], ["", "", "def", "inception_resnet_v2", "(", "inputs", ",", "num_classes", "=", "1001", ",", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.8", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'InceptionResnetV2'", ",", "\n", "create_aux_logits", "=", "True", ")", ":", "\n", "  ", "\"\"\"Creates the Inception Resnet V2 model.\n\n  Args:\n    inputs: a 4-D tensor of size [batch_size, height, width, 3].\n    num_classes: number of predicted classes.\n    is_training: whether is training or not.\n    dropout_keep_prob: float, the fraction to keep before final layer.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    scope: Optional variable_scope.\n    create_aux_logits: Whether to include the auxilliary logits.\n\n  Returns:\n    logits: the logits outputs of the model.\n    end_points: the set of end_points from the inception model.\n  \"\"\"", "\n", "end_points", "=", "{", "}", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionResnetV2'", ",", "[", "inputs", ",", "num_classes", "]", ",", "\n", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "\n", "is_training", "=", "is_training", ")", ":", "\n", "\n", "      ", "net", ",", "end_points", "=", "inception_resnet_v2_base", "(", "inputs", ",", "scope", "=", "scope", ")", "\n", "\n", "if", "create_aux_logits", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'AuxLogits'", ")", ":", "\n", "          ", "aux", "=", "end_points", "[", "'PreAuxLogits'", "]", "\n", "aux", "=", "slim", ".", "avg_pool2d", "(", "aux", ",", "5", ",", "stride", "=", "3", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'Conv2d_1a_3x3'", ")", "\n", "aux", "=", "slim", ".", "conv2d", "(", "aux", ",", "128", ",", "1", ",", "scope", "=", "'Conv2d_1b_1x1'", ")", "\n", "aux", "=", "slim", ".", "conv2d", "(", "aux", ",", "768", ",", "aux", ".", "get_shape", "(", ")", "[", "1", ":", "3", "]", ",", "\n", "padding", "=", "'VALID'", ",", "scope", "=", "'Conv2d_2a_5x5'", ")", "\n", "aux", "=", "slim", ".", "flatten", "(", "aux", ")", "\n", "aux", "=", "slim", ".", "fully_connected", "(", "aux", ",", "num_classes", ",", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'Logits'", ")", "\n", "end_points", "[", "'AuxLogits'", "]", "=", "aux", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'Logits'", ")", ":", "\n", "        ", "net", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "net", ".", "get_shape", "(", ")", "[", "1", ":", "3", "]", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'AvgPool_1a_8x8'", ")", "\n", "net", "=", "slim", ".", "flatten", "(", "net", ")", "\n", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'Dropout'", ")", "\n", "\n", "end_points", "[", "'PreLogitsFlatten'", "]", "=", "net", "\n", "logits", "=", "slim", ".", "fully_connected", "(", "net", ",", "num_classes", ",", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'Logits'", ")", "\n", "end_points", "[", "'Logits'", "]", "=", "logits", "\n", "end_points", "[", "'Predictions'", "]", "=", "tf", ".", "nn", ".", "softmax", "(", "logits", ",", "name", "=", "'Predictions'", ")", "\n", "\n", "", "", "return", "logits", ",", "end_points", "\n", "", "", "inception_resnet_v2", ".", "default_image_size", "=", "299", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_resnet_v2.inception_resnet_v2_arg_scope": [[331, 358], ["slim.arg_scope", "slim.arg_scope", "slim.l2_regularizer", "slim.l2_regularizer"], "function", ["None"], ["def", "inception_resnet_v2_arg_scope", "(", "weight_decay", "=", "0.00004", ",", "\n", "batch_norm_decay", "=", "0.9997", ",", "\n", "batch_norm_epsilon", "=", "0.001", ")", ":", "\n", "  ", "\"\"\"Yields the scope with the default parameters for inception_resnet_v2.\n\n  Args:\n    weight_decay: the weight decay for weights variables.\n    batch_norm_decay: decay for the moving average of batch_norm momentums.\n    batch_norm_epsilon: small float added to variance to avoid dividing by zero.\n\n  Returns:\n    a arg_scope with the parameters needed for inception_resnet_v2.\n  \"\"\"", "\n", "# Set weight_decay for weights in conv2d and fully_connected layers.", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ",", "\n", "biases_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ")", ":", "\n", "\n", "    ", "batch_norm_params", "=", "{", "\n", "'decay'", ":", "batch_norm_decay", ",", "\n", "'epsilon'", ":", "batch_norm_epsilon", ",", "\n", "}", "\n", "# Set activation_fn and parameters for batch_norm.", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "normalizer_fn", "=", "slim", ".", "batch_norm", ",", "\n", "normalizer_params", "=", "batch_norm_params", ")", "as", "scope", ":", "\n", "      ", "return", "scope", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testBuildClassificationNetwork": [[31, 44], ["tensorflow.random_uniform", "nets.inception.inception_v3", "inception_v3_test.InceptionV3Test.assertTrue", "inception_v3_test.InceptionV3Test.assertListEqual", "inception_v3_test.InceptionV3Test.assertTrue", "inception_v3_test.InceptionV3Test.assertListEqual", "logits.op.name.startswith", "logits.get_shape().as_list", "end_points[].get_shape().as_list", "logits.get_shape", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3"], ["  ", "def", "testBuildClassificationNetwork", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "inception", ".", "inception_v3", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV3/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "self", ".", "assertTrue", "(", "'Predictions'", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "'Predictions'", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testBuildBaseNetwork": [[45, 61], ["tensorflow.random_uniform", "nets.inception.inception_v3_base", "inception_v3_test.InceptionV3Test.assertTrue", "inception_v3_test.InceptionV3Test.assertListEqual", "inception_v3_test.InceptionV3Test.assertItemsEqual", "final_endpoint.op.name.startswith", "final_endpoint.get_shape().as_list", "end_points.keys", "final_endpoint.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3_base"], ["", "def", "testBuildBaseNetwork", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "final_endpoint", ",", "end_points", "=", "inception", ".", "inception_v3_base", "(", "inputs", ")", "\n", "self", ".", "assertTrue", "(", "final_endpoint", ".", "op", ".", "name", ".", "startswith", "(", "\n", "'InceptionV3/Mixed_7c'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "final_endpoint", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "8", ",", "8", ",", "2048", "]", ")", "\n", "expected_endpoints", "=", "[", "'Conv2d_1a_3x3'", ",", "'Conv2d_2a_3x3'", ",", "'Conv2d_2b_3x3'", ",", "\n", "'MaxPool_3a_3x3'", ",", "'Conv2d_3b_1x1'", ",", "'Conv2d_4a_3x3'", ",", "\n", "'MaxPool_5a_3x3'", ",", "'Mixed_5b'", ",", "'Mixed_5c'", ",", "'Mixed_5d'", ",", "\n", "'Mixed_6a'", ",", "'Mixed_6b'", ",", "'Mixed_6c'", ",", "'Mixed_6d'", ",", "\n", "'Mixed_6e'", ",", "'Mixed_7a'", ",", "'Mixed_7b'", ",", "'Mixed_7c'", "]", "\n", "self", ".", "assertItemsEqual", "(", "end_points", ".", "keys", "(", ")", ",", "expected_endpoints", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testBuildOnlyUptoFinalEndpoint": [[62, 79], ["enumerate", "tensorflow.Graph().as_default", "tensorflow.random_uniform", "nets.inception.inception_v3_base", "inception_v3_test.InceptionV3Test.assertTrue", "inception_v3_test.InceptionV3Test.assertItemsEqual", "out_tensor.op.name.startswith", "tensorflow.Graph"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3_base"], ["", "def", "testBuildOnlyUptoFinalEndpoint", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "endpoints", "=", "[", "'Conv2d_1a_3x3'", ",", "'Conv2d_2a_3x3'", ",", "'Conv2d_2b_3x3'", ",", "\n", "'MaxPool_3a_3x3'", ",", "'Conv2d_3b_1x1'", ",", "'Conv2d_4a_3x3'", ",", "\n", "'MaxPool_5a_3x3'", ",", "'Mixed_5b'", ",", "'Mixed_5c'", ",", "'Mixed_5d'", ",", "\n", "'Mixed_6a'", ",", "'Mixed_6b'", ",", "'Mixed_6c'", ",", "'Mixed_6d'", ",", "\n", "'Mixed_6e'", ",", "'Mixed_7a'", ",", "'Mixed_7b'", ",", "'Mixed_7c'", "]", "\n", "\n", "for", "index", ",", "endpoint", "in", "enumerate", "(", "endpoints", ")", ":", "\n", "      ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "out_tensor", ",", "end_points", "=", "inception", ".", "inception_v3_base", "(", "\n", "inputs", ",", "final_endpoint", "=", "endpoint", ")", "\n", "self", ".", "assertTrue", "(", "out_tensor", ".", "op", ".", "name", ".", "startswith", "(", "\n", "'InceptionV3/'", "+", "endpoint", ")", ")", "\n", "self", ".", "assertItemsEqual", "(", "endpoints", "[", ":", "index", "+", "1", "]", ",", "end_points", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testBuildAndCheckAllEndPointsUptoMixed7c": [[80, 111], ["tensorflow.random_uniform", "nets.inception.inception_v3_base", "inception_v3_test.InceptionV3Test.assertItemsEqual", "endpoints_shapes.keys", "end_points.keys", "inception_v3_test.InceptionV3Test.assertTrue", "inception_v3_test.InceptionV3Test.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3_base"], ["", "", "", "def", "testBuildAndCheckAllEndPointsUptoMixed7c", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_v3_base", "(", "\n", "inputs", ",", "final_endpoint", "=", "'Mixed_7c'", ")", "\n", "endpoints_shapes", "=", "{", "'Conv2d_1a_3x3'", ":", "[", "batch_size", ",", "149", ",", "149", ",", "32", "]", ",", "\n", "'Conv2d_2a_3x3'", ":", "[", "batch_size", ",", "147", ",", "147", ",", "32", "]", ",", "\n", "'Conv2d_2b_3x3'", ":", "[", "batch_size", ",", "147", ",", "147", ",", "64", "]", ",", "\n", "'MaxPool_3a_3x3'", ":", "[", "batch_size", ",", "73", ",", "73", ",", "64", "]", ",", "\n", "'Conv2d_3b_1x1'", ":", "[", "batch_size", ",", "73", ",", "73", ",", "80", "]", ",", "\n", "'Conv2d_4a_3x3'", ":", "[", "batch_size", ",", "71", ",", "71", ",", "192", "]", ",", "\n", "'MaxPool_5a_3x3'", ":", "[", "batch_size", ",", "35", ",", "35", ",", "192", "]", ",", "\n", "'Mixed_5b'", ":", "[", "batch_size", ",", "35", ",", "35", ",", "256", "]", ",", "\n", "'Mixed_5c'", ":", "[", "batch_size", ",", "35", ",", "35", ",", "288", "]", ",", "\n", "'Mixed_5d'", ":", "[", "batch_size", ",", "35", ",", "35", ",", "288", "]", ",", "\n", "'Mixed_6a'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "768", "]", ",", "\n", "'Mixed_6b'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "768", "]", ",", "\n", "'Mixed_6c'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "768", "]", ",", "\n", "'Mixed_6d'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "768", "]", ",", "\n", "'Mixed_6e'", ":", "[", "batch_size", ",", "17", ",", "17", ",", "768", "]", ",", "\n", "'Mixed_7a'", ":", "[", "batch_size", ",", "8", ",", "8", ",", "1280", "]", ",", "\n", "'Mixed_7b'", ":", "[", "batch_size", ",", "8", ",", "8", ",", "2048", "]", ",", "\n", "'Mixed_7c'", ":", "[", "batch_size", ",", "8", ",", "8", ",", "2048", "]", "}", "\n", "self", ".", "assertItemsEqual", "(", "endpoints_shapes", ".", "keys", "(", ")", ",", "end_points", ".", "keys", "(", ")", ")", "\n", "for", "endpoint_name", "in", "endpoints_shapes", ":", "\n", "      ", "expected_shape", "=", "endpoints_shapes", "[", "endpoint_name", "]", "\n", "self", ".", "assertTrue", "(", "endpoint_name", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint_name", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "expected_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testModelHasExpectedNumberOfParameters": [[112, 121], ["tensorflow.random_uniform", "slim.model_analyzer.analyze_vars", "inception_v3_test.InceptionV3Test.assertAlmostEqual", "slim.arg_scope", "nets.inception.inception_v3_base", "slim.get_model_variables", "nets.inception.inception_v3_arg_scope"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3_base"], ["", "", "def", "testModelHasExpectedNumberOfParameters", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "with", "slim", ".", "arg_scope", "(", "inception", ".", "inception_v3_arg_scope", "(", ")", ")", ":", "\n", "      ", "inception", ".", "inception_v3_base", "(", "inputs", ")", "\n", "", "total_params", ",", "_", "=", "slim", ".", "model_analyzer", ".", "analyze_vars", "(", "\n", "slim", ".", "get_model_variables", "(", ")", ")", "\n", "self", ".", "assertAlmostEqual", "(", "21802784", ",", "total_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testBuildEndPoints": [[122, 145], ["tensorflow.random_uniform", "nets.inception.inception_v3", "inception_v3_test.InceptionV3Test.assertTrue", "inception_v3_test.InceptionV3Test.assertListEqual", "inception_v3_test.InceptionV3Test.assertTrue", "inception_v3_test.InceptionV3Test.assertListEqual", "inception_v3_test.InceptionV3Test.assertTrue", "inception_v3_test.InceptionV3Test.assertListEqual", "inception_v3_test.InceptionV3Test.assertTrue", "inception_v3_test.InceptionV3Test.assertListEqual", "logits.get_shape().as_list", "aux_logits.get_shape().as_list", "pre_pool.get_shape().as_list", "pre_logits.get_shape().as_list", "logits.get_shape", "aux_logits.get_shape", "pre_pool.get_shape", "pre_logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3"], ["", "def", "testBuildEndPoints", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_v3", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "'Logits'", "in", "end_points", ")", "\n", "logits", "=", "end_points", "[", "'Logits'", "]", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "self", ".", "assertTrue", "(", "'AuxLogits'", "in", "end_points", ")", "\n", "aux_logits", "=", "end_points", "[", "'AuxLogits'", "]", "\n", "self", ".", "assertListEqual", "(", "aux_logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "self", ".", "assertTrue", "(", "'Mixed_7c'", "in", "end_points", ")", "\n", "pre_pool", "=", "end_points", "[", "'Mixed_7c'", "]", "\n", "self", ".", "assertListEqual", "(", "pre_pool", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "8", ",", "8", ",", "2048", "]", ")", "\n", "self", ".", "assertTrue", "(", "'PreLogits'", "in", "end_points", ")", "\n", "pre_logits", "=", "end_points", "[", "'PreLogits'", "]", "\n", "self", ".", "assertListEqual", "(", "pre_logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "1", ",", "1", ",", "2048", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testBuildEndPointsWithDepthMultiplierLessThanOne": [[146, 165], ["tensorflow.random_uniform", "nets.inception.inception_v3", "nets.inception.inception_v3", "inception_v3_test.InceptionV3Test.assertEqual", "end_points.keys", "end_points[].get_shape().as_list", "end_points_with_multiplier[].get_shape().as_list", "key.startswith", "key.startswith", "end_points[].get_shape", "end_points_with_multiplier[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3"], ["", "def", "testBuildEndPointsWithDepthMultiplierLessThanOne", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_v3", "(", "inputs", ",", "num_classes", ")", "\n", "\n", "endpoint_keys", "=", "[", "key", "for", "key", "in", "end_points", ".", "keys", "(", ")", "\n", "if", "key", ".", "startswith", "(", "'Mixed'", ")", "or", "key", ".", "startswith", "(", "'Conv'", ")", "]", "\n", "\n", "_", ",", "end_points_with_multiplier", "=", "inception", ".", "inception_v3", "(", "\n", "inputs", ",", "num_classes", ",", "scope", "=", "'depth_multiplied_net'", ",", "\n", "depth_multiplier", "=", "0.5", ")", "\n", "\n", "for", "key", "in", "endpoint_keys", ":", "\n", "      ", "original_depth", "=", "end_points", "[", "key", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "new_depth", "=", "end_points_with_multiplier", "[", "key", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "self", ".", "assertEqual", "(", "0.5", "*", "original_depth", ",", "new_depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testBuildEndPointsWithDepthMultiplierGreaterThanOne": [[166, 185], ["tensorflow.random_uniform", "nets.inception.inception_v3", "nets.inception.inception_v3", "inception_v3_test.InceptionV3Test.assertEqual", "end_points.keys", "end_points[].get_shape().as_list", "end_points_with_multiplier[].get_shape().as_list", "key.startswith", "key.startswith", "end_points[].get_shape", "end_points_with_multiplier[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3"], ["", "", "def", "testBuildEndPointsWithDepthMultiplierGreaterThanOne", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "inception", ".", "inception_v3", "(", "inputs", ",", "num_classes", ")", "\n", "\n", "endpoint_keys", "=", "[", "key", "for", "key", "in", "end_points", ".", "keys", "(", ")", "\n", "if", "key", ".", "startswith", "(", "'Mixed'", ")", "or", "key", ".", "startswith", "(", "'Conv'", ")", "]", "\n", "\n", "_", ",", "end_points_with_multiplier", "=", "inception", ".", "inception_v3", "(", "\n", "inputs", ",", "num_classes", ",", "scope", "=", "'depth_multiplied_net'", ",", "\n", "depth_multiplier", "=", "2.0", ")", "\n", "\n", "for", "key", "in", "endpoint_keys", ":", "\n", "      ", "original_depth", "=", "end_points", "[", "key", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "new_depth", "=", "end_points_with_multiplier", "[", "key", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "self", ".", "assertEqual", "(", "2.0", "*", "original_depth", ",", "new_depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testRaiseValueErrorWithInvalidDepthMultiplier": [[186, 196], ["tensorflow.random_uniform", "inception_v3_test.InceptionV3Test.assertRaises", "nets.inception.inception_v3", "inception_v3_test.InceptionV3Test.assertRaises", "nets.inception.inception_v3"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3"], ["", "", "def", "testRaiseValueErrorWithInvalidDepthMultiplier", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "      ", "_", "=", "inception", ".", "inception_v3", "(", "inputs", ",", "num_classes", ",", "depth_multiplier", "=", "-", "0.1", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "      ", "_", "=", "inception", ".", "inception_v3", "(", "inputs", ",", "num_classes", ",", "depth_multiplier", "=", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testHalfSizeImages": [[197, 210], ["tensorflow.random_uniform", "nets.inception.inception_v3", "inception_v3_test.InceptionV3Test.assertTrue", "inception_v3_test.InceptionV3Test.assertListEqual", "inception_v3_test.InceptionV3Test.assertListEqual", "logits.op.name.startswith", "logits.get_shape().as_list", "pre_pool.get_shape().as_list", "logits.get_shape", "pre_pool.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3"], ["", "", "def", "testHalfSizeImages", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "150", ",", "150", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "inception", ".", "inception_v3", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV3/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "pre_pool", "=", "end_points", "[", "'Mixed_7c'", "]", "\n", "self", ".", "assertListEqual", "(", "pre_pool", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "3", ",", "3", ",", "2048", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testUnknownImageShape": [[211, 227], ["tensorflow.reset_default_graph", "numpy.random.uniform", "inception_v3_test.InceptionV3Test.test_session", "tensorflow.placeholder", "nets.inception.inception_v3", "inception_v3_test.InceptionV3Test.assertListEqual", "tensorflow.global_variables_initializer().run", "sess.run", "inception_v3_test.InceptionV3Test.assertListEqual", "logits.get_shape().as_list", "list", "tensorflow.global_variables_initializer", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "testUnknownImageShape", "(", "self", ")", ":", "\n", "    ", "tf", ".", "reset_default_graph", "(", ")", "\n", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "input_np", "=", "np", ".", "random", ".", "uniform", "(", "0", ",", "1", ",", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "batch_size", ",", "None", ",", "None", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "inception", ".", "inception_v3", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "pre_pool", "=", "end_points", "[", "'Mixed_7c'", "]", "\n", "feed_dict", "=", "{", "inputs", ":", "input_np", "}", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "pre_pool_out", "=", "sess", ".", "run", "(", "pre_pool", ",", "feed_dict", "=", "feed_dict", ")", "\n", "self", ".", "assertListEqual", "(", "list", "(", "pre_pool_out", ".", "shape", ")", ",", "[", "batch_size", ",", "8", ",", "8", ",", "2048", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testUnknowBatchSize": [[228, 244], ["tensorflow.placeholder", "nets.inception.inception_v3", "inception_v3_test.InceptionV3Test.assertTrue", "inception_v3_test.InceptionV3Test.assertListEqual", "tensorflow.random_uniform", "logits.op.name.startswith", "logits.get_shape().as_list", "inception_v3_test.InceptionV3Test.test_session", "sess.run", "sess.run", "inception_v3_test.InceptionV3Test.assertEquals", "tensorflow.global_variables_initializer", "logits.get_shape", "tensorflow.random_uniform.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testUnknowBatchSize", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "\n", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v3", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'InceptionV3/Logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "None", ",", "num_classes", "]", ")", "\n", "images", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ",", "{", "inputs", ":", "images", ".", "eval", "(", ")", "}", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "batch_size", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testEvaluation": [[245, 259], ["tensorflow.random_uniform", "nets.inception.inception_v3", "tensorflow.argmax", "inception_v3_test.InceptionV3Test.test_session", "sess.run", "sess.run", "inception_v3_test.InceptionV3Test.assertEquals", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testEvaluation", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "299", ",", "299", "\n", "num_classes", "=", "1000", "\n", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v3", "(", "eval_inputs", ",", "num_classes", ",", "\n", "is_training", "=", "False", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "predictions", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testTrainEvalWithReuse": [[260, 277], ["tensorflow.random_uniform", "nets.inception.inception_v3", "tensorflow.random_uniform", "nets.inception.inception_v3", "tensorflow.argmax", "inception_v3_test.InceptionV3Test.test_session", "sess.run", "sess.run", "inception_v3_test.InceptionV3Test.assertEquals", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testTrainEvalWithReuse", "(", "self", ")", ":", "\n", "    ", "train_batch_size", "=", "5", "\n", "eval_batch_size", "=", "2", "\n", "height", ",", "width", "=", "150", ",", "150", "\n", "num_classes", "=", "1000", "\n", "\n", "train_inputs", "=", "tf", ".", "random_uniform", "(", "(", "train_batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "inception", ".", "inception_v3", "(", "train_inputs", ",", "num_classes", ")", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "eval_batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v3", "(", "eval_inputs", ",", "num_classes", ",", "\n", "is_training", "=", "False", ",", "reuse", "=", "True", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "predictions", ")", "\n", "self", ".", "assertEquals", "(", "output", ".", "shape", ",", "(", "eval_batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3_test.InceptionV3Test.testLogitsNotSqueezed": [[278, 289], ["tensorflow.random_uniform", "nets.inception.inception_v3", "inception_v3_test.InceptionV3Test.test_session", "tensorflow.global_variables_initializer().run", "sess.run", "inception_v3_test.InceptionV3Test.assertListEqual", "list", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v3.inception_v3", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testLogitsNotSqueezed", "(", "self", ")", ":", "\n", "    ", "num_classes", "=", "25", "\n", "images", "=", "tf", ".", "random_uniform", "(", "[", "1", ",", "299", ",", "299", ",", "3", "]", ")", "\n", "logits", ",", "_", "=", "inception", ".", "inception_v3", "(", "images", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "spatial_squeeze", "=", "False", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", ")", "\n", "logits_out", "=", "sess", ".", "run", "(", "logits", ")", "\n", "self", ".", "assertListEqual", "(", "list", "(", "logits_out", ".", "shape", ")", ",", "[", "1", ",", "1", ",", "1", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1_base": [[29, 246], ["tensorflow.variable_scope", "ValueError", "slim.arg_scope", "slim.arg_scope", "slim.conv2d", "slim.max_pool2d", "slim.conv2d", "slim.conv2d", "slim.max_pool2d", "slim.max_pool2d", "slim.max_pool2d", "trunc_normal", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.conv2d", "slim.conv2d", "tensorflow.variable_scope", "slim.max_pool2d", "slim.conv2d"], "function", ["None"], ["def", "inception_v1_base", "(", "inputs", ",", "\n", "final_endpoint", "=", "'Mixed_5c'", ",", "\n", "scope", "=", "'InceptionV1'", ")", ":", "\n", "  ", "\"\"\"Defines the Inception V1 base architecture.\n\n  This architecture is defined in:\n    Going deeper with convolutions\n    Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,\n    Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich.\n    http://arxiv.org/pdf/1409.4842v1.pdf.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    final_endpoint: specifies the endpoint to construct and freeze the network up to. It\n      can be one of ['Conv2d_1a_7x7', 'MaxPool_2a_3x3', 'Conv2d_2b_1x1',\n      'Conv2d_2c_3x3', 'MaxPool_3a_3x3', 'Mixed_3b', 'Mixed_3c',\n      'MaxPool_4a_3x3', 'Mixed_4b', 'Mixed_4c', 'Mixed_4d', 'Mixed_4e',\n      'Mixed_4f', 'MaxPool_5a_2x2', 'Mixed_5b', 'Mixed_5c']\n    scope: Optional variable_scope.\n\n  Returns:\n    A dictionary from components of the network to the corresponding activation.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values.\n  \"\"\"", "\n", "end_points", "=", "{", "}", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV1'", ",", "[", "inputs", "]", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.01", ")", ",", "trainable", "=", "False", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "        ", "end_point", "=", "'Conv2d_1a_7x7'", "\n", "net", "=", "slim", ".", "conv2d", "(", "inputs", ",", "64", ",", "[", "7", ",", "7", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "end_point", "=", "'MaxPool_2a_3x3'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "end_point", "=", "'Conv2d_2b_1x1'", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "end_point", "=", "'Conv2d_2c_3x3'", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "end_point", "=", "'MaxPool_3a_3x3'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_3b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "96", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "128", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "16", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "32", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "32", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_3c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "192", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "96", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'MaxPool_4a_3x3'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_4b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "96", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "208", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "16", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "48", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_4c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "160", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "112", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "224", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "24", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_4d'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "256", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "24", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_4e'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "112", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "144", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "288", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "64", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "64", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_4f'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "160", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "320", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "128", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'MaxPool_5a_2x2'", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "2", ",", "2", "]", ",", "stride", "=", "2", ",", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "end_point", "=", "'Mixed_5b'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "160", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "320", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "32", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "128", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0a_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n", "branch_3", "=", "slim", ".", "conv2d", "(", "branch_3", ",", "128", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0b_1x1'", ")", "\n", "", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "\n", "# Retrain Mixed_5c layer", "\n", "", "", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.01", ")", ",", "trainable", "=", "True", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "stride", "=", "1", ",", "padding", "=", "'SAME'", ")", ":", "\n", "        ", "end_point", "=", "'Mixed_5c'", "\n", "with", "tf", ".", "variable_scope", "(", "end_point", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'Branch_0'", ")", ":", "\n", "            ", "branch_0", "=", "slim", ".", "conv2d", "(", "net", ",", "384", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_1'", ")", ":", "\n", "            ", "branch_1", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_1", "=", "slim", ".", "conv2d", "(", "branch_1", ",", "384", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_2'", ")", ":", "\n", "            ", "branch_2", "=", "slim", ".", "conv2d", "(", "net", ",", "48", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'Conv2d_0a_1x1'", ")", "\n", "branch_2", "=", "slim", ".", "conv2d", "(", "branch_2", ",", "128", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'Conv2d_0b_3x3'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Branch_3'", ")", ":", "\n", "            ", "branch_3", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'MaxPool_0a_3x3'", ")", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1": [[248, 303], ["tensorflow.variable_scope", "slim.arg_scope", "inception_v1.inception_v1_base", "tensorflow.variable_scope", "slim.avg_pool2d", "slim.dropout", "slim.conv2d", "prediction_fn", "tensorflow.squeeze"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_v1.inception_v1_base"], ["", "net", "=", "tf", ".", "concat", "(", "axis", "=", "3", ",", "values", "=", "[", "branch_0", ",", "branch_1", ",", "branch_2", ",", "branch_3", "]", ")", "\n", "", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "final_endpoint", "==", "end_point", ":", "return", "net", ",", "end_points", "\n", "", "", "raise", "ValueError", "(", "'Unknown final endpoint %s'", "%", "final_endpoint", ")", "\n", "\n", "\n", "", "", "def", "inception_v1", "(", "inputs", ",", "\n", "final_endpoint", "=", "'Mixed_5c'", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.8", ",", "\n", "prediction_fn", "=", "slim", ".", "softmax", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'InceptionV1'", ")", ":", "\n", "  ", "\"\"\"Defines the Inception V1 architecture.\n\n  This architecture is defined in:\n\n    Going deeper with convolutions\n    Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,\n    Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich.\n    http://arxiv.org/pdf/1409.4842v1.pdf.\n\n  The default image size used to train this network is 224x224.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    is_training: whether is training or not.\n    dropout_keep_prob: the percentage of activation values that are retained.\n    prediction_fn: a function to get predictions out of logits.\n    spatial_squeeze: if True, logits is of shape [B, C], if false logits is\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    scope: Optional variable_scope.\n\n  Returns:\n    logits: the pre-softmax activations, a tensor of size\n      [batch_size, num_classes]\n    end_points: a dictionary from components of the network to the corresponding\n      activation.\n  \"\"\"", "\n", "# Final pooling and prediction", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'InceptionV1'", ",", "[", "inputs", ",", "num_classes", "]", ",", "\n", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "\n", "is_training", "=", "is_training", ")", ":", "\n", "      ", "net", ",", "end_points", "=", "inception_v1_base", "(", "inputs", ",", "final_endpoint", "=", "final_endpoint", ",", "scope", "=", "scope", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Logits'", ")", ":", "\n", "        ", "net", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "[", "7", ",", "7", "]", ",", "stride", "=", "1", ",", "scope", "=", "'AvgPool_0a_7x7'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "\n", "dropout_keep_prob", ",", "scope", "=", "'Dropout_0b'", ")", "\n", "logits", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "scope", "=", "'Conv2d_0c_1x1'", ")", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.nets_factory_test.NetworksTest.testGetNetworkFn": [[31, 45], ["nets_factory_test.NetworksTest.test_session", "nets.nets_factory.get_network_fn", "getattr", "tensorflow.random_uniform", "nets.nets_factory.get_network_fn.", "nets_factory_test.NetworksTest.assertTrue", "nets_factory_test.NetworksTest.assertTrue", "nets_factory_test.NetworksTest.assertEqual", "nets_factory_test.NetworksTest.assertEqual", "isinstance", "isinstance", "logits.get_shape().as_list", "logits.get_shape().as_list", "logits.get_shape", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.nets_factory.get_network_fn"], ["  ", "def", "testGetNetworkFn", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "num_classes", "=", "1000", "\n", "for", "net", "in", "nets_factory", ".", "networks_map", ":", "\n", "      ", "with", "self", ".", "test_session", "(", ")", ":", "\n", "        ", "net_fn", "=", "nets_factory", ".", "get_network_fn", "(", "net", ",", "num_classes", ")", "\n", "# Most networks use 224 as their default_image_size", "\n", "image_size", "=", "getattr", "(", "net_fn", ",", "'default_image_size'", ",", "224", ")", "\n", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "image_size", ",", "image_size", ",", "3", ")", ")", "\n", "logits", ",", "end_points", "=", "net_fn", "(", "inputs", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "logits", ",", "tf", ".", "Tensor", ")", ")", "\n", "self", ".", "assertTrue", "(", "isinstance", "(", "end_points", ",", "dict", ")", ")", "\n", "self", ".", "assertEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", "]", ",", "batch_size", ")", "\n", "self", ".", "assertEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.nets_factory_test.NetworksTest.testGetNetworkFnArgScope": [[46, 59], ["nets_factory_test.NetworksTest.test_session", "nets.nets_factory.get_network_fn", "getattr", "nets_factory_test.NetworksTest.assertDeviceEqual", "slim.arg_scope", "tensorflow.random_uniform", "nets.nets_factory.get_network_fn.", "tensorflow.get_collection"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.nets_factory.get_network_fn"], ["", "", "", "def", "testGetNetworkFnArgScope", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "num_classes", "=", "10", "\n", "net", "=", "'cifarnet'", "\n", "with", "self", ".", "test_session", "(", "use_gpu", "=", "True", ")", ":", "\n", "      ", "net_fn", "=", "nets_factory", ".", "get_network_fn", "(", "net", ",", "num_classes", ")", "\n", "image_size", "=", "getattr", "(", "net_fn", ",", "'default_image_size'", ",", "224", ")", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "model_variable", ",", "slim", ".", "variable", "]", ",", "\n", "device", "=", "'/CPU:0'", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "image_size", ",", "image_size", ",", "3", ")", ")", "\n", "net_fn", "(", "inputs", ")", "\n", "", "weights", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "'CifarNet/conv1'", ")", "[", "0", "]", "\n", "self", ".", "assertDeviceEqual", "(", "'/CPU:0'", ",", "weights", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet.alexnet_v2_arg_scope": [[45, 53], ["slim.arg_scope", "slim.arg_scope", "tensorflow.constant_initializer", "slim.l2_regularizer", "slim.arg_scope"], "function", ["None"], ["def", "alexnet_v2_arg_scope", "(", "weight_decay", "=", "0.0005", ")", ":", "\n", "  ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "biases_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "padding", "=", "'SAME'", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "max_pool2d", "]", ",", "padding", "=", "'VALID'", ")", "as", "arg_sc", ":", "\n", "        ", "return", "arg_sc", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.alexnet.alexnet_v2": [[55, 125], ["tensorflow.variable_scope", "slim.arg_scope", "slim.conv2d", "slim.max_pool2d", "slim.conv2d", "slim.max_pool2d", "slim.conv2d", "slim.conv2d", "slim.conv2d", "slim.max_pool2d", "slim.utils.convert_collection_to_dict", "slim.arg_scope", "slim.conv2d", "slim.dropout", "slim.conv2d", "slim.dropout", "slim.conv2d", "tensorflow.squeeze", "trunc_normal", "tensorflow.constant_initializer", "tensorflow.zeros_initializer"], "function", ["None"], ["", "", "", "", "def", "alexnet_v2", "(", "inputs", ",", "\n", "num_classes", "=", "1000", ",", "\n", "is_training", "=", "True", ",", "\n", "dropout_keep_prob", "=", "0.5", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "scope", "=", "'alexnet_v2'", ")", ":", "\n", "  ", "\"\"\"AlexNet version 2.\n\n  Described in: http://arxiv.org/pdf/1404.5997v2.pdf\n  Parameters from:\n  github.com/akrizhevsky/cuda-convnet2/blob/master/layers/\n  layers-imagenet-1gpu.cfg\n\n  Note: All the fully_connected layers have been transformed to conv2d layers.\n        To use in classification mode, resize input to 224x224. To use in fully\n        convolutional mode, set spatial_squeeze to false.\n        The LRN layers have been removed and change the initializers from\n        random_normal_initializer to xavier_initializer.\n\n  Args:\n    inputs: a tensor of size [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    is_training: whether or not the model is being trained.\n    dropout_keep_prob: the probability that activations are kept in the dropout\n      layers during training.\n    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n      outputs. Useful to remove unnecessary dimensions for classification.\n    scope: Optional scope for the variables.\n\n  Returns:\n    the last op containing the log predictions and end_points dict.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'alexnet_v2'", ",", "[", "inputs", "]", ")", "as", "sc", ":", "\n", "    ", "end_points_collection", "=", "sc", ".", "name", "+", "'_end_points'", "\n", "# Collect outputs for conv2d, fully_connected and max_pool2d.", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", ",", "slim", ".", "max_pool2d", "]", ",", "\n", "outputs_collections", "=", "[", "end_points_collection", "]", ")", ":", "\n", "      ", "net", "=", "slim", ".", "conv2d", "(", "inputs", ",", "64", ",", "[", "11", ",", "11", "]", ",", "4", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'conv1'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "2", ",", "scope", "=", "'pool1'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "192", ",", "[", "5", ",", "5", "]", ",", "scope", "=", "'conv2'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "2", ",", "scope", "=", "'pool2'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "384", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv3'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "384", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv4'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "256", ",", "[", "3", ",", "3", "]", ",", "scope", "=", "'conv5'", ")", "\n", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "2", ",", "scope", "=", "'pool5'", ")", "\n", "\n", "# Use conv2d instead of fully_connected layers.", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "\n", "weights_initializer", "=", "trunc_normal", "(", "0.005", ")", ",", "\n", "biases_initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ")", ":", "\n", "        ", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "4096", ",", "[", "5", ",", "5", "]", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'fc6'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout6'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "4096", ",", "[", "1", ",", "1", "]", ",", "scope", "=", "'fc7'", ")", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "dropout_keep_prob", ",", "is_training", "=", "is_training", ",", "\n", "scope", "=", "'dropout7'", ")", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "\n", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "scope", "=", "'fc8'", ")", "\n", "\n", "# Convert end_points_collection into a end_point dict.", "\n", "", "end_points", "=", "slim", ".", "utils", ".", "convert_collection_to_dict", "(", "end_points_collection", ")", "\n", "if", "spatial_squeeze", ":", "\n", "        ", "net", "=", "tf", ".", "squeeze", "(", "net", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'fc8/squeezed'", ")", "\n", "end_points", "[", "sc", ".", "name", "+", "'/fc8'", "]", "=", "net", "\n", "", "return", "net", ",", "end_points", "\n", "", "", "", "alexnet_v2", ".", "default_image_size", "=", "224", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.bottleneck": [[61, 109], ["tensorflow.variable_scope", "slim.utils.last_dimension", "slim.batch_norm", "slim.conv2d", "nets.resnet_utils.conv2d_same", "slim.conv2d", "slim.utils.collect_named_outputs", "inputs.get_shape", "nets.resnet_utils.subsample", "slim.conv2d"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.conv2d_same", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample"], ["@", "slim", ".", "add_arg_scope", "\n", "def", "bottleneck", "(", "inputs", ",", "depth", ",", "depth_bottleneck", ",", "stride", ",", "rate", "=", "1", ",", "\n", "outputs_collections", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Bottleneck residual unit variant with BN before convolutions.\n\n  This is the full preactivation residual unit variant proposed in [2]. See\n  Fig. 1(b) of [2] for its definition. Note that we use here the bottleneck\n  variant which has an extra bottleneck layer.\n\n  When putting together two consecutive ResNet blocks that use this unit, one\n  should use stride = 2 in the last unit of the first block.\n\n  Args:\n    inputs: A tensor of size [batch, height, width, channels].\n    depth: The depth of the ResNet unit output.\n    depth_bottleneck: The depth of the bottleneck layers.\n    stride: The ResNet unit's stride. Determines the amount of downsampling of\n      the units output compared to its input.\n    rate: An integer, rate for atrous convolution.\n    outputs_collections: Collection to add the ResNet unit output.\n    scope: Optional variable_scope.\n\n  Returns:\n    The ResNet unit's output.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'bottleneck_v2'", ",", "[", "inputs", "]", ")", "as", "sc", ":", "\n", "    ", "depth_in", "=", "slim", ".", "utils", ".", "last_dimension", "(", "inputs", ".", "get_shape", "(", ")", ",", "min_rank", "=", "4", ")", "\n", "preact", "=", "slim", ".", "batch_norm", "(", "inputs", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "'preact'", ")", "\n", "if", "depth", "==", "depth_in", ":", "\n", "      ", "shortcut", "=", "resnet_utils", ".", "subsample", "(", "inputs", ",", "stride", ",", "'shortcut'", ")", "\n", "", "else", ":", "\n", "      ", "shortcut", "=", "slim", ".", "conv2d", "(", "preact", ",", "depth", ",", "[", "1", ",", "1", "]", ",", "stride", "=", "stride", ",", "\n", "normalizer_fn", "=", "None", ",", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'shortcut'", ")", "\n", "\n", "", "residual", "=", "slim", ".", "conv2d", "(", "preact", ",", "depth_bottleneck", ",", "[", "1", ",", "1", "]", ",", "stride", "=", "1", ",", "\n", "scope", "=", "'conv1'", ")", "\n", "residual", "=", "resnet_utils", ".", "conv2d_same", "(", "residual", ",", "depth_bottleneck", ",", "3", ",", "stride", ",", "\n", "rate", "=", "rate", ",", "scope", "=", "'conv2'", ")", "\n", "residual", "=", "slim", ".", "conv2d", "(", "residual", ",", "depth", ",", "[", "1", ",", "1", "]", ",", "stride", "=", "1", ",", "\n", "normalizer_fn", "=", "None", ",", "activation_fn", "=", "None", ",", "\n", "scope", "=", "'conv3'", ")", "\n", "\n", "output", "=", "shortcut", "+", "residual", "\n", "\n", "return", "slim", ".", "utils", ".", "collect_named_outputs", "(", "outputs_collections", ",", "\n", "sc", ".", "original_name_scope", ",", "\n", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2": [[111, 221], ["tensorflow.variable_scope", "slim.arg_scope", "slim.arg_scope", "nets.resnet_utils.stack_blocks_dense", "slim.batch_norm", "slim.utils.convert_collection_to_dict", "slim.max_pool2d", "tensorflow.reduce_mean", "slim.conv2d", "slim.softmax", "slim.arg_scope", "nets.resnet_utils.conv2d_same", "tensorflow.squeeze", "ValueError"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.stack_blocks_dense", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.conv2d_same"], ["", "", "def", "resnet_v2", "(", "inputs", ",", "\n", "blocks", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "include_root_block", "=", "True", ",", "\n", "spatial_squeeze", "=", "False", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Generator for v2 (preactivation) ResNet models.\n\n  This function generates a family of ResNet v2 models. See the resnet_v2_*()\n  methods for specific model instantiations, obtained by selecting different\n  block instantiations that produce ResNets of various depths.\n\n  Training for image classification on Imagenet is usually done with [224, 224]\n  inputs, resulting in [7, 7] feature maps at the output of the last ResNet\n  block for the ResNets defined in [1] that have nominal stride equal to 32.\n  However, for dense prediction tasks we advise that one uses inputs with\n  spatial dimensions that are multiples of 32 plus 1, e.g., [321, 321]. In\n  this case the feature maps at the ResNet output will have spatial shape\n  [(height - 1) / output_stride + 1, (width - 1) / output_stride + 1]\n  and corners exactly aligned with the input image corners, which greatly\n  facilitates alignment of the features to the image. Using as input [225, 225]\n  images results in [8, 8] feature maps at the output of the last ResNet block.\n\n  For dense prediction tasks, the ResNet needs to run in fully-convolutional\n  (FCN) mode and global_pool needs to be set to False. The ResNets in [1, 2] all\n  have nominal stride equal to 32 and a good choice in FCN mode is to use\n  output_stride=16 in order to increase the density of the computed features at\n  small computational and memory overhead, cf. http://arxiv.org/abs/1606.00915.\n\n  Args:\n    inputs: A tensor of size [batch, height_in, width_in, channels].\n    blocks: A list of length equal to the number of ResNet blocks. Each element\n      is a resnet_utils.Block object describing the units in the block.\n    num_classes: Number of predicted classes for classification tasks. If None\n      we return the features before the logit layer.\n    is_training: whether is training or not.\n    global_pool: If True, we perform global average pooling before computing the\n      logits. Set to True for image classification, False for dense prediction.\n    output_stride: If None, then the output will be computed at the nominal\n      network stride. If output_stride is not None, it specifies the requested\n      ratio of input to output spatial resolution.\n    include_root_block: If True, include the initial convolution followed by\n      max-pooling, if False excludes it. If excluded, `inputs` should be the\n      results of an activation-less convolution.\n    spatial_squeeze: if True, logits is of shape [B, C], if false logits is\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n        To use this parameter, the input images must be smaller than 300x300\n        pixels, in which case the output logit layer does not contain spatial\n        information and can be removed.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    scope: Optional variable_scope.\n\n\n  Returns:\n    net: A rank-4 tensor of size [batch, height_out, width_out, channels_out].\n      If global_pool is False, then height_out and width_out are reduced by a\n      factor of output_stride compared to the respective height_in and width_in,\n      else both height_out and width_out equal one. If num_classes is None, then\n      net is the output of the last ResNet block, potentially after global\n      average pooling. If num_classes is not None, net contains the pre-softmax\n      activations.\n    end_points: A dictionary from components of the network to the corresponding\n      activation.\n\n  Raises:\n    ValueError: If the target output_stride is not valid.\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'resnet_v2'", ",", "[", "inputs", "]", ",", "reuse", "=", "reuse", ")", "as", "sc", ":", "\n", "    ", "end_points_collection", "=", "sc", ".", "name", "+", "'_end_points'", "\n", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "bottleneck", ",", "\n", "resnet_utils", ".", "stack_blocks_dense", "]", ",", "\n", "outputs_collections", "=", "end_points_collection", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", "]", ",", "is_training", "=", "is_training", ")", ":", "\n", "        ", "net", "=", "inputs", "\n", "if", "include_root_block", ":", "\n", "          ", "if", "output_stride", "is", "not", "None", ":", "\n", "            ", "if", "output_stride", "%", "4", "!=", "0", ":", "\n", "              ", "raise", "ValueError", "(", "'The output_stride needs to be a multiple of 4.'", ")", "\n", "", "output_stride", "/=", "4", "\n", "# We do not include batch normalization or activation functions in", "\n", "# conv1 because the first ResNet unit will perform these. Cf.", "\n", "# Appendix of [2].", "\n", "", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "\n", "activation_fn", "=", "None", ",", "normalizer_fn", "=", "None", ")", ":", "\n", "            ", "net", "=", "resnet_utils", ".", "conv2d_same", "(", "net", ",", "64", ",", "7", ",", "stride", "=", "2", ",", "scope", "=", "'conv1'", ")", "\n", "", "net", "=", "slim", ".", "max_pool2d", "(", "net", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "'pool1'", ")", "\n", "", "net", "=", "resnet_utils", ".", "stack_blocks_dense", "(", "net", ",", "blocks", ",", "output_stride", ")", "\n", "# This is needed because the pre-activation variant does not have batch", "\n", "# normalization or activation functions in the residual unit output. See", "\n", "# Appendix of [2].", "\n", "net", "=", "slim", ".", "batch_norm", "(", "net", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "'postnorm'", ")", "\n", "if", "global_pool", ":", "\n", "# Global average pooling.", "\n", "          ", "net", "=", "tf", ".", "reduce_mean", "(", "net", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'pool5'", ",", "keep_dims", "=", "True", ")", "\n", "", "if", "num_classes", "is", "not", "None", ":", "\n", "          ", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "scope", "=", "'logits'", ")", "\n", "if", "spatial_squeeze", ":", "\n", "            ", "net", "=", "tf", ".", "squeeze", "(", "net", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'SpatialSqueeze'", ")", "\n", "# Convert end_points_collection into a dictionary of end_points.", "\n", "", "", "end_points", "=", "slim", ".", "utils", ".", "convert_collection_to_dict", "(", "\n", "end_points_collection", ")", "\n", "if", "num_classes", "is", "not", "None", ":", "\n", "          ", "end_points", "[", "'predictions'", "]", "=", "slim", ".", "softmax", "(", "net", ",", "scope", "=", "'predictions'", ")", "\n", "", "return", "net", ",", "end_points", "\n", "", "", "", "", "resnet_v2", ".", "default_image_size", "=", "224", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block": [[224, 245], ["nets.resnet_utils.Block"], "function", ["None"], ["def", "resnet_v2_block", "(", "scope", ",", "base_depth", ",", "num_units", ",", "stride", ")", ":", "\n", "  ", "\"\"\"Helper function for creating a resnet_v2 bottleneck block.\n\n  Args:\n    scope: The scope of the block.\n    base_depth: The depth of the bottleneck layer for each unit.\n    num_units: The number of units in the block.\n    stride: The stride of the block, implemented as a stride in the last unit.\n      All other units have stride=1.\n\n  Returns:\n    A resnet_v2 bottleneck block.\n  \"\"\"", "\n", "return", "resnet_utils", ".", "Block", "(", "scope", ",", "bottleneck", ",", "[", "{", "\n", "'depth'", ":", "base_depth", "*", "4", ",", "\n", "'depth_bottleneck'", ":", "base_depth", ",", "\n", "'stride'", ":", "1", "\n", "}", "]", "*", "(", "num_units", "-", "1", ")", "+", "[", "{", "\n", "'depth'", ":", "base_depth", "*", "4", ",", "\n", "'depth_bottleneck'", ":", "base_depth", ",", "\n", "'stride'", ":", "stride", "\n", "}", "]", ")", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_50": [[249, 268], ["resnet_v2.resnet_v2", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block"], ["def", "resnet_v2_50", "(", "inputs", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "spatial_squeeze", "=", "False", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'resnet_v2_50'", ")", ":", "\n", "  ", "\"\"\"ResNet-50 model of [1]. See resnet_v2() for arg and return description.\"\"\"", "\n", "blocks", "=", "[", "\n", "resnet_v2_block", "(", "'block1'", ",", "base_depth", "=", "64", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block2'", ",", "base_depth", "=", "128", ",", "num_units", "=", "4", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block3'", ",", "base_depth", "=", "256", ",", "num_units", "=", "6", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block4'", ",", "base_depth", "=", "512", ",", "num_units", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "return", "resnet_v2", "(", "inputs", ",", "blocks", ",", "num_classes", ",", "is_training", "=", "is_training", ",", "\n", "global_pool", "=", "global_pool", ",", "output_stride", "=", "output_stride", ",", "\n", "include_root_block", "=", "True", ",", "spatial_squeeze", "=", "spatial_squeeze", ",", "\n", "reuse", "=", "reuse", ",", "scope", "=", "scope", ")", "\n", "", "resnet_v2_50", ".", "default_image_size", "=", "resnet_v2", ".", "default_image_size", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_101": [[271, 290], ["resnet_v2.resnet_v2", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block"], ["def", "resnet_v2_101", "(", "inputs", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "spatial_squeeze", "=", "False", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'resnet_v2_101'", ")", ":", "\n", "  ", "\"\"\"ResNet-101 model of [1]. See resnet_v2() for arg and return description.\"\"\"", "\n", "blocks", "=", "[", "\n", "resnet_v2_block", "(", "'block1'", ",", "base_depth", "=", "64", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block2'", ",", "base_depth", "=", "128", ",", "num_units", "=", "4", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block3'", ",", "base_depth", "=", "256", ",", "num_units", "=", "23", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block4'", ",", "base_depth", "=", "512", ",", "num_units", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "return", "resnet_v2", "(", "inputs", ",", "blocks", ",", "num_classes", ",", "is_training", "=", "is_training", ",", "\n", "global_pool", "=", "global_pool", ",", "output_stride", "=", "output_stride", ",", "\n", "include_root_block", "=", "True", ",", "spatial_squeeze", "=", "spatial_squeeze", ",", "\n", "reuse", "=", "reuse", ",", "scope", "=", "scope", ")", "\n", "", "resnet_v2_101", ".", "default_image_size", "=", "resnet_v2", ".", "default_image_size", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_152": [[293, 312], ["resnet_v2.resnet_v2", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block"], ["def", "resnet_v2_152", "(", "inputs", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "spatial_squeeze", "=", "False", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'resnet_v2_152'", ")", ":", "\n", "  ", "\"\"\"ResNet-152 model of [1]. See resnet_v2() for arg and return description.\"\"\"", "\n", "blocks", "=", "[", "\n", "resnet_v2_block", "(", "'block1'", ",", "base_depth", "=", "64", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block2'", ",", "base_depth", "=", "128", ",", "num_units", "=", "8", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block3'", ",", "base_depth", "=", "256", ",", "num_units", "=", "36", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block4'", ",", "base_depth", "=", "512", ",", "num_units", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "return", "resnet_v2", "(", "inputs", ",", "blocks", ",", "num_classes", ",", "is_training", "=", "is_training", ",", "\n", "global_pool", "=", "global_pool", ",", "output_stride", "=", "output_stride", ",", "\n", "include_root_block", "=", "True", ",", "spatial_squeeze", "=", "spatial_squeeze", ",", "\n", "reuse", "=", "reuse", ",", "scope", "=", "scope", ")", "\n", "", "resnet_v2_152", ".", "default_image_size", "=", "resnet_v2", ".", "default_image_size", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_200": [[315, 334], ["resnet_v2.resnet_v2", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block", "resnet_v2.resnet_v2_block"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block"], ["def", "resnet_v2_200", "(", "inputs", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "spatial_squeeze", "=", "False", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'resnet_v2_200'", ")", ":", "\n", "  ", "\"\"\"ResNet-200 model of [2]. See resnet_v2() for arg and return description.\"\"\"", "\n", "blocks", "=", "[", "\n", "resnet_v2_block", "(", "'block1'", ",", "base_depth", "=", "64", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block2'", ",", "base_depth", "=", "128", ",", "num_units", "=", "24", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block3'", ",", "base_depth", "=", "256", ",", "num_units", "=", "36", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2_block", "(", "'block4'", ",", "base_depth", "=", "512", ",", "num_units", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "return", "resnet_v2", "(", "inputs", ",", "blocks", ",", "num_classes", ",", "is_training", "=", "is_training", ",", "\n", "global_pool", "=", "global_pool", ",", "output_stride", "=", "output_stride", ",", "\n", "include_root_block", "=", "True", ",", "spatial_squeeze", "=", "spatial_squeeze", ",", "\n", "reuse", "=", "reuse", ",", "scope", "=", "scope", ")", "\n", "", "resnet_v2_200", ".", "default_image_size", "=", "resnet_v2", ".", "default_image_size", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.inception_utils.inception_arg_scope": [[32, 72], ["slim.arg_scope", "slim.arg_scope", "slim.l2_regularizer", "slim.variance_scaling_initializer"], "function", ["None"], ["def", "inception_arg_scope", "(", "weight_decay", "=", "0.00004", ",", "\n", "use_batch_norm", "=", "True", ",", "\n", "batch_norm_decay", "=", "0.9997", ",", "\n", "batch_norm_epsilon", "=", "0.001", ")", ":", "\n", "  ", "\"\"\"Defines the default arg scope for inception models.\n\n  Args:\n    weight_decay: The weight decay to use for regularizing the model.\n    use_batch_norm: \"If `True`, batch_norm is applied after each convolution.\n    batch_norm_decay: Decay for batch norm moving average.\n    batch_norm_epsilon: Small float added to variance to avoid dividing by zero\n      in batch norm.\n\n  Returns:\n    An `arg_scope` to use for the inception models.\n  \"\"\"", "\n", "batch_norm_params", "=", "{", "\n", "# Decay for the moving averages.", "\n", "'decay'", ":", "batch_norm_decay", ",", "\n", "# epsilon to prevent 0s in variance.", "\n", "'epsilon'", ":", "batch_norm_epsilon", ",", "\n", "# collection containing update_ops.", "\n", "'updates_collections'", ":", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "\n", "}", "\n", "if", "use_batch_norm", ":", "\n", "    ", "normalizer_fn", "=", "slim", ".", "batch_norm", "\n", "normalizer_params", "=", "batch_norm_params", "\n", "", "else", ":", "\n", "    ", "normalizer_fn", "=", "None", "\n", "normalizer_params", "=", "{", "}", "\n", "# Set weight_decay for weights in Conv and FC layers.", "\n", "", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "fully_connected", "]", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", "]", ",", "\n", "weights_initializer", "=", "slim", ".", "variance_scaling_initializer", "(", ")", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "normalizer_fn", "=", "normalizer_fn", ",", "\n", "normalizer_params", "=", "normalizer_params", ")", "as", "sc", ":", "\n", "      ", "return", "sc", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.mobilenet_v1.mobilenet_v1_base": [[137, 262], ["ValueError", "max", "ValueError", "ValueError", "tensorflow.variable_scope", "int", "slim.arg_scope", "enumerate", "isinstance", "slim.conv2d", "isinstance", "depth", "slim.separable_conv2d", "slim.conv2d", "ValueError", "depth"], "function", ["None"], ["def", "mobilenet_v1_base", "(", "inputs", ",", "\n", "final_endpoint", "=", "'Conv2d_13_pointwise'", ",", "\n", "min_depth", "=", "8", ",", "\n", "depth_multiplier", "=", "1.0", ",", "\n", "conv_defs", "=", "None", ",", "\n", "output_stride", "=", "None", ",", "\n", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Mobilenet v1.\n\n  Constructs a Mobilenet v1 network from inputs to the given final endpoint.\n\n  Args:\n    inputs: a tensor of shape [batch_size, height, width, channels].\n    final_endpoint: specifies the endpoint to construct the network up to. It\n      can be one of ['Conv2d_0', 'Conv2d_1_pointwise', 'Conv2d_2_pointwise',\n      'Conv2d_3_pointwise', 'Conv2d_4_pointwise', 'Conv2d_5'_pointwise,\n      'Conv2d_6_pointwise', 'Conv2d_7_pointwise', 'Conv2d_8_pointwise',\n      'Conv2d_9_pointwise', 'Conv2d_10_pointwise', 'Conv2d_11_pointwise',\n      'Conv2d_12_pointwise', 'Conv2d_13_pointwise'].\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\n      Enforced when depth_multiplier < 1, and not an active constraint when\n      depth_multiplier >= 1.\n    depth_multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n    conv_defs: A list of ConvDef namedtuples specifying the net architecture.\n    output_stride: An integer that specifies the requested ratio of input to\n      output spatial resolution. If not None, then we invoke atrous convolution\n      if necessary to prevent the network from reducing the spatial resolution\n      of the activation maps. Allowed values are 8 (accurate fully convolutional\n      mode), 16 (fast fully convolutional mode), 32 (classification mode).\n    scope: Optional variable_scope.\n\n  Returns:\n    tensor_out: output tensor corresponding to the final_endpoint.\n    end_points: a set of activations for external use, for example summaries or\n                losses.\n\n  Raises:\n    ValueError: if final_endpoint is not set to one of the predefined values,\n                or depth_multiplier <= 0, or the target output_stride is not\n                allowed.\n  \"\"\"", "\n", "depth", "=", "lambda", "d", ":", "max", "(", "int", "(", "d", "*", "depth_multiplier", ")", ",", "min_depth", ")", "\n", "end_points", "=", "{", "}", "\n", "\n", "# Used to find thinned depths for each layer.", "\n", "if", "depth_multiplier", "<=", "0", ":", "\n", "    ", "raise", "ValueError", "(", "'depth_multiplier is not greater than zero.'", ")", "\n", "\n", "", "if", "conv_defs", "is", "None", ":", "\n", "    ", "conv_defs", "=", "_CONV_DEFS", "\n", "\n", "", "if", "output_stride", "is", "not", "None", "and", "output_stride", "not", "in", "[", "8", ",", "16", ",", "32", "]", ":", "\n", "    ", "raise", "ValueError", "(", "'Only allowed output_stride values are 8, 16, 32.'", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'MobilenetV1'", ",", "[", "inputs", "]", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "separable_conv2d", "]", ",", "padding", "=", "'SAME'", ")", ":", "\n", "# The current_stride variable keeps track of the output stride of the", "\n", "# activations, i.e., the running product of convolution strides up to the", "\n", "# current network layer. This allows us to invoke atrous convolution", "\n", "# whenever applying the next convolution would result in the activations", "\n", "# having output stride larger than the target output_stride.", "\n", "      ", "current_stride", "=", "1", "\n", "\n", "# The atrous convolution rate parameter.", "\n", "rate", "=", "1", "\n", "\n", "net", "=", "inputs", "\n", "for", "i", ",", "conv_def", "in", "enumerate", "(", "conv_defs", ")", ":", "\n", "        ", "end_point_base", "=", "'Conv2d_%d'", "%", "i", "\n", "\n", "if", "output_stride", "is", "not", "None", "and", "current_stride", "==", "output_stride", ":", "\n", "# If we have reached the target output_stride, then we need to employ", "\n", "# atrous convolution with stride=1 and multiply the atrous rate by the", "\n", "# current unit's stride for use in subsequent layers.", "\n", "          ", "layer_stride", "=", "1", "\n", "layer_rate", "=", "rate", "\n", "rate", "*=", "conv_def", ".", "stride", "\n", "", "else", ":", "\n", "          ", "layer_stride", "=", "conv_def", ".", "stride", "\n", "layer_rate", "=", "1", "\n", "current_stride", "*=", "conv_def", ".", "stride", "\n", "\n", "", "if", "isinstance", "(", "conv_def", ",", "Conv", ")", ":", "\n", "          ", "end_point", "=", "end_point_base", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "conv_def", ".", "depth", ")", ",", "conv_def", ".", "kernel", ",", "\n", "stride", "=", "conv_def", ".", "stride", ",", "\n", "normalizer_fn", "=", "slim", ".", "batch_norm", ",", "\n", "scope", "=", "end_point", ")", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "\n", "            ", "return", "net", ",", "end_points", "\n", "\n", "", "", "elif", "isinstance", "(", "conv_def", ",", "DepthSepConv", ")", ":", "\n", "          ", "end_point", "=", "end_point_base", "+", "'_depthwise'", "\n", "\n", "# By passing filters=None", "\n", "# separable_conv2d produces only a depthwise convolution layer", "\n", "net", "=", "slim", ".", "separable_conv2d", "(", "net", ",", "None", ",", "conv_def", ".", "kernel", ",", "\n", "depth_multiplier", "=", "1", ",", "\n", "stride", "=", "layer_stride", ",", "\n", "rate", "=", "layer_rate", ",", "\n", "normalizer_fn", "=", "slim", ".", "batch_norm", ",", "\n", "scope", "=", "end_point", ")", "\n", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "\n", "            ", "return", "net", ",", "end_points", "\n", "\n", "", "end_point", "=", "end_point_base", "+", "'_pointwise'", "\n", "\n", "net", "=", "slim", ".", "conv2d", "(", "net", ",", "depth", "(", "conv_def", ".", "depth", ")", ",", "[", "1", ",", "1", "]", ",", "\n", "stride", "=", "1", ",", "\n", "normalizer_fn", "=", "slim", ".", "batch_norm", ",", "\n", "scope", "=", "end_point", ")", "\n", "\n", "end_points", "[", "end_point", "]", "=", "net", "\n", "if", "end_point", "==", "final_endpoint", ":", "\n", "            ", "return", "net", ",", "end_points", "\n", "", "", "else", ":", "\n", "          ", "raise", "ValueError", "(", "'Unknown convolution type %s for layer %d'", "\n", "%", "(", "conv_def", ".", "ltype", ",", "i", ")", ")", "\n", "", "", "", "", "raise", "ValueError", "(", "'Unknown final endpoint %s'", "%", "final_endpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.mobilenet_v1.mobilenet_v1": [[264, 334], ["inputs.get_shape().as_list", "len", "ValueError", "tensorflow.variable_scope", "inputs.get_shape", "slim.arg_scope", "mobilenet_v1.mobilenet_v1_base", "len", "tensorflow.variable_scope", "mobilenet_v1._reduced_kernel_size_for_small_input", "slim.avg_pool2d", "slim.dropout", "slim.conv2d", "prediction_fn", "tensorflow.squeeze"], "function", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.mobilenet_v1.mobilenet_v1_base", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.mobilenet_v1._reduced_kernel_size_for_small_input"], ["", "def", "mobilenet_v1", "(", "inputs", ",", "\n", "num_classes", "=", "1000", ",", "\n", "dropout_keep_prob", "=", "0.999", ",", "\n", "is_training", "=", "True", ",", "\n", "min_depth", "=", "8", ",", "\n", "depth_multiplier", "=", "1.0", ",", "\n", "conv_defs", "=", "None", ",", "\n", "prediction_fn", "=", "tf", ".", "contrib", ".", "layers", ".", "softmax", ",", "\n", "spatial_squeeze", "=", "True", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'MobilenetV1'", ")", ":", "\n", "  ", "\"\"\"Mobilenet v1 model for classification.\n\n  Args:\n    inputs: a tensor of shape [batch_size, height, width, channels].\n    num_classes: number of predicted classes.\n    dropout_keep_prob: the percentage of activation values that are retained.\n    is_training: whether is training or not.\n    min_depth: Minimum depth value (number of channels) for all convolution ops.\n      Enforced when depth_multiplier < 1, and not an active constraint when\n      depth_multiplier >= 1.\n    depth_multiplier: Float multiplier for the depth (number of channels)\n      for all convolution ops. The value must be greater than zero. Typical\n      usage will be to set this value in (0, 1) to reduce the number of\n      parameters or computation cost of the model.\n    conv_defs: A list of ConvDef namedtuples specifying the net architecture.\n    prediction_fn: a function to get predictions out of logits.\n    spatial_squeeze: if True, logits is of shape is [B, C], if false logits is\n        of shape [B, 1, 1, C], where B is batch_size and C is number of classes.\n    reuse: whether or not the network and its variables should be reused. To be\n      able to reuse 'scope' must be given.\n    scope: Optional variable_scope.\n\n  Returns:\n    logits: the pre-softmax activations, a tensor of size\n      [batch_size, num_classes]\n    end_points: a dictionary from components of the network to the corresponding\n      activation.\n\n  Raises:\n    ValueError: Input rank is invalid.\n  \"\"\"", "\n", "input_shape", "=", "inputs", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "if", "len", "(", "input_shape", ")", "!=", "4", ":", "\n", "    ", "raise", "ValueError", "(", "'Invalid input tensor rank, expected 4, was: %d'", "%", "\n", "len", "(", "input_shape", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "'MobilenetV1'", ",", "[", "inputs", ",", "num_classes", "]", ",", "\n", "reuse", "=", "reuse", ")", "as", "scope", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", ",", "slim", ".", "dropout", "]", ",", "\n", "is_training", "=", "is_training", ")", ":", "\n", "      ", "net", ",", "end_points", "=", "mobilenet_v1_base", "(", "inputs", ",", "scope", "=", "scope", ",", "\n", "min_depth", "=", "min_depth", ",", "\n", "depth_multiplier", "=", "depth_multiplier", ",", "\n", "conv_defs", "=", "conv_defs", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'Logits'", ")", ":", "\n", "        ", "kernel_size", "=", "_reduced_kernel_size_for_small_input", "(", "net", ",", "[", "7", ",", "7", "]", ")", "\n", "net", "=", "slim", ".", "avg_pool2d", "(", "net", ",", "kernel_size", ",", "padding", "=", "'VALID'", ",", "\n", "scope", "=", "'AvgPool_1a'", ")", "\n", "end_points", "[", "'AvgPool_1a'", "]", "=", "net", "\n", "# 1 x 1 x 1024", "\n", "net", "=", "slim", ".", "dropout", "(", "net", ",", "keep_prob", "=", "dropout_keep_prob", ",", "scope", "=", "'Dropout_1b'", ")", "\n", "logits", "=", "slim", ".", "conv2d", "(", "net", ",", "num_classes", ",", "[", "1", ",", "1", "]", ",", "activation_fn", "=", "None", ",", "\n", "normalizer_fn", "=", "None", ",", "scope", "=", "'Conv2d_1c_1x1'", ")", "\n", "if", "spatial_squeeze", ":", "\n", "          ", "logits", "=", "tf", ".", "squeeze", "(", "logits", ",", "[", "1", ",", "2", "]", ",", "name", "=", "'SpatialSqueeze'", ")", "\n", "", "", "end_points", "[", "'Logits'", "]", "=", "logits", "\n", "if", "prediction_fn", ":", "\n", "        ", "end_points", "[", "'Predictions'", "]", "=", "prediction_fn", "(", "logits", ",", "scope", "=", "'Predictions'", ")", "\n", "", "", "", "return", "logits", ",", "end_points", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.mobilenet_v1._reduced_kernel_size_for_small_input": [[338, 358], ["input_tensor.get_shape().as_list", "input_tensor.get_shape", "min", "min"], "function", ["None"], ["def", "_reduced_kernel_size_for_small_input", "(", "input_tensor", ",", "kernel_size", ")", ":", "\n", "  ", "\"\"\"Define kernel size which is automatically reduced for small input.\n\n  If the shape of the input images is unknown at graph construction time this\n  function assumes that the input images are large enough.\n\n  Args:\n    input_tensor: input tensor of size [batch_size, height, width, channels].\n    kernel_size: desired kernel size of length 2: [kernel_height, kernel_width]\n\n  Returns:\n    a tensor with the kernel size.\n  \"\"\"", "\n", "shape", "=", "input_tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "if", "shape", "[", "1", "]", "is", "None", "or", "shape", "[", "2", "]", "is", "None", ":", "\n", "    ", "kernel_size_out", "=", "kernel_size", "\n", "", "else", ":", "\n", "    ", "kernel_size_out", "=", "[", "min", "(", "shape", "[", "1", "]", ",", "kernel_size", "[", "0", "]", ")", ",", "\n", "min", "(", "shape", "[", "2", "]", ",", "kernel_size", "[", "1", "]", ")", "]", "\n", "", "return", "kernel_size_out", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.mobilenet_v1.mobilenet_v1_arg_scope": [[360, 398], ["tensorflow.truncated_normal_initializer", "tensorflow.contrib.layers.l2_regularizer", "slim.arg_scope", "slim.arg_scope", "slim.arg_scope", "slim.arg_scope"], "function", ["None"], ["", "def", "mobilenet_v1_arg_scope", "(", "is_training", "=", "True", ",", "\n", "weight_decay", "=", "0.00004", ",", "\n", "stddev", "=", "0.09", ",", "\n", "regularize_depthwise", "=", "False", ")", ":", "\n", "  ", "\"\"\"Defines the default MobilenetV1 arg scope.\n\n  Args:\n    is_training: Whether or not we're training the model.\n    weight_decay: The weight decay to use for regularizing the model.\n    stddev: The standard deviation of the trunctated normal weight initializer.\n    regularize_depthwise: Whether or not apply regularization on depthwise.\n\n  Returns:\n    An `arg_scope` to use for the mobilenet v1 model.\n  \"\"\"", "\n", "batch_norm_params", "=", "{", "\n", "'is_training'", ":", "is_training", ",", "\n", "'center'", ":", "True", ",", "\n", "'scale'", ":", "True", ",", "\n", "'decay'", ":", "0.9997", ",", "\n", "'epsilon'", ":", "0.001", ",", "\n", "}", "\n", "\n", "# Set weight_decay for weights in Conv and DepthSepConv layers.", "\n", "weights_init", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "stddev", ")", "\n", "regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "weight_decay", ")", "\n", "if", "regularize_depthwise", ":", "\n", "    ", "depthwise_regularizer", "=", "regularizer", "\n", "", "else", ":", "\n", "    ", "depthwise_regularizer", "=", "None", "\n", "", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", ",", "slim", ".", "separable_conv2d", "]", ",", "\n", "weights_initializer", "=", "weights_init", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu6", ",", "normalizer_fn", "=", "slim", ".", "batch_norm", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", "]", ",", "**", "batch_norm_params", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "weights_regularizer", "=", "regularizer", ")", ":", "\n", "        ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "separable_conv2d", "]", ",", "\n", "weights_regularizer", "=", "depthwise_regularizer", ")", "as", "sc", ":", "\n", "          ", "return", "sc", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGGATest.testBuild": [[29, 39], ["vgg_test.VGGATest.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_a", "vgg_test.VGGATest.assertEquals", "vgg_test.VGGATest.assertListEqual", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_a"], ["  ", "def", "testBuild", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_a", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertEquals", "(", "logits", ".", "op", ".", "name", ",", "'vgg_a/fc8/squeezed'", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGGATest.testFullyConvolutional": [[40, 50], ["vgg_test.VGGATest.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_a", "vgg_test.VGGATest.assertEquals", "vgg_test.VGGATest.assertListEqual", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_a"], ["", "", "def", "testFullyConvolutional", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "256", ",", "256", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_a", "(", "inputs", ",", "num_classes", ",", "spatial_squeeze", "=", "False", ")", "\n", "self", ".", "assertEquals", "(", "logits", ".", "op", ".", "name", ",", "'vgg_a/fc8/BiasAdd'", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "2", ",", "2", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGGATest.testEndPoints": [[51, 76], ["vgg_test.VGGATest.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_a", "vgg_test.VGGATest.assertSetEqual", "set", "set", "end_points.keys"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_a"], ["", "", "def", "testEndPoints", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "vgg", ".", "vgg_a", "(", "inputs", ",", "num_classes", ")", "\n", "expected_names", "=", "[", "'vgg_a/conv1/conv1_1'", ",", "\n", "'vgg_a/pool1'", ",", "\n", "'vgg_a/conv2/conv2_1'", ",", "\n", "'vgg_a/pool2'", ",", "\n", "'vgg_a/conv3/conv3_1'", ",", "\n", "'vgg_a/conv3/conv3_2'", ",", "\n", "'vgg_a/pool3'", ",", "\n", "'vgg_a/conv4/conv4_1'", ",", "\n", "'vgg_a/conv4/conv4_2'", ",", "\n", "'vgg_a/pool4'", ",", "\n", "'vgg_a/conv5/conv5_1'", ",", "\n", "'vgg_a/conv5/conv5_2'", ",", "\n", "'vgg_a/pool5'", ",", "\n", "'vgg_a/fc6'", ",", "\n", "'vgg_a/fc7'", ",", "\n", "'vgg_a/fc8'", "\n", "]", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "end_points", ".", "keys", "(", ")", ")", ",", "set", "(", "expected_names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGGATest.testModelVariables": [[77, 109], ["vgg_test.VGGATest.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_a", "vgg_test.VGGATest.assertSetEqual", "set", "set", "slim.get_model_variables"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_a"], ["", "", "def", "testModelVariables", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "vgg", ".", "vgg_a", "(", "inputs", ",", "num_classes", ")", "\n", "expected_names", "=", "[", "'vgg_a/conv1/conv1_1/weights'", ",", "\n", "'vgg_a/conv1/conv1_1/biases'", ",", "\n", "'vgg_a/conv2/conv2_1/weights'", ",", "\n", "'vgg_a/conv2/conv2_1/biases'", ",", "\n", "'vgg_a/conv3/conv3_1/weights'", ",", "\n", "'vgg_a/conv3/conv3_1/biases'", ",", "\n", "'vgg_a/conv3/conv3_2/weights'", ",", "\n", "'vgg_a/conv3/conv3_2/biases'", ",", "\n", "'vgg_a/conv4/conv4_1/weights'", ",", "\n", "'vgg_a/conv4/conv4_1/biases'", ",", "\n", "'vgg_a/conv4/conv4_2/weights'", ",", "\n", "'vgg_a/conv4/conv4_2/biases'", ",", "\n", "'vgg_a/conv5/conv5_1/weights'", ",", "\n", "'vgg_a/conv5/conv5_1/biases'", ",", "\n", "'vgg_a/conv5/conv5_2/weights'", ",", "\n", "'vgg_a/conv5/conv5_2/biases'", ",", "\n", "'vgg_a/fc6/weights'", ",", "\n", "'vgg_a/fc6/biases'", ",", "\n", "'vgg_a/fc7/weights'", ",", "\n", "'vgg_a/fc7/biases'", ",", "\n", "'vgg_a/fc8/weights'", ",", "\n", "'vgg_a/fc8/biases'", ",", "\n", "]", "\n", "model_variables", "=", "[", "v", ".", "op", ".", "name", "for", "v", "in", "slim", ".", "get_model_variables", "(", ")", "]", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "model_variables", ")", ",", "set", "(", "expected_names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGGATest.testEvaluation": [[110, 121], ["vgg_test.VGGATest.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_a", "vgg_test.VGGATest.assertListEqual", "tensorflow.argmax", "vgg_test.VGGATest.assertListEqual", "logits.get_shape().as_list", "tensorflow.argmax.get_shape().as_list", "logits.get_shape", "tensorflow.argmax.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_a"], ["", "", "def", "testEvaluation", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_a", "(", "eval_inputs", ",", "is_training", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "predictions", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGGATest.testTrainEvalWithReuse": [[122, 144], ["vgg_test.VGGATest.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_a", "vgg_test.VGGATest.assertListEqual", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.random_uniform", "nets.vgg.vgg_a", "vgg_test.VGGATest.assertListEqual", "tensorflow.reduce_mean", "tensorflow.argmax", "vgg_test.VGGATest.assertEquals", "tensorflow.reduce_mean.get_shape().as_list", "tensorflow.reduce_mean.get_shape().as_list", "tensorflow.argmax.get_shape().as_list", "tensorflow.get_variable_scope", "tensorflow.reduce_mean.get_shape", "tensorflow.reduce_mean.get_shape", "tensorflow.argmax.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_a", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_a"], ["", "", "def", "testTrainEvalWithReuse", "(", "self", ")", ":", "\n", "    ", "train_batch_size", "=", "2", "\n", "eval_batch_size", "=", "1", "\n", "train_height", ",", "train_width", "=", "224", ",", "224", "\n", "eval_height", ",", "eval_width", "=", "256", ",", "256", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "train_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "(", "train_batch_size", ",", "train_height", ",", "train_width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_a", "(", "train_inputs", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "train_batch_size", ",", "num_classes", "]", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "(", "eval_batch_size", ",", "eval_height", ",", "eval_width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_a", "(", "eval_inputs", ",", "is_training", "=", "False", ",", "\n", "spatial_squeeze", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "eval_batch_size", ",", "2", ",", "2", ",", "num_classes", "]", ")", "\n", "logits", "=", "tf", ".", "reduce_mean", "(", "logits", ",", "[", "1", ",", "2", "]", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "self", ".", "assertEquals", "(", "predictions", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "eval_batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGGATest.testForward": [[145, 154], ["vgg_test.VGGATest.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_a", "sess.run", "sess.run", "vgg_test.VGGATest.assertTrue", "tensorflow.global_variables_initializer", "sess.run.any"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_a", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testForward", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_a", "(", "inputs", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ")", "\n", "self", ".", "assertTrue", "(", "output", ".", "any", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG16Test.testBuild": [[158, 168], ["vgg_test.VGG16Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_16", "vgg_test.VGG16Test.assertEquals", "vgg_test.VGG16Test.assertListEqual", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_16"], ["  ", "def", "testBuild", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_16", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertEquals", "(", "logits", ".", "op", ".", "name", ",", "'vgg_16/fc8/squeezed'", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG16Test.testFullyConvolutional": [[169, 179], ["vgg_test.VGG16Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_16", "vgg_test.VGG16Test.assertEquals", "vgg_test.VGG16Test.assertListEqual", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_16"], ["", "", "def", "testFullyConvolutional", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "256", ",", "256", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_16", "(", "inputs", ",", "num_classes", ",", "spatial_squeeze", "=", "False", ")", "\n", "self", ".", "assertEquals", "(", "logits", ".", "op", ".", "name", ",", "'vgg_16/fc8/BiasAdd'", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "2", ",", "2", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG16Test.testEndPoints": [[180, 210], ["vgg_test.VGG16Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_16", "vgg_test.VGG16Test.assertSetEqual", "set", "set", "end_points.keys"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_16"], ["", "", "def", "testEndPoints", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "vgg", ".", "vgg_16", "(", "inputs", ",", "num_classes", ")", "\n", "expected_names", "=", "[", "'vgg_16/conv1/conv1_1'", ",", "\n", "'vgg_16/conv1/conv1_2'", ",", "\n", "'vgg_16/pool1'", ",", "\n", "'vgg_16/conv2/conv2_1'", ",", "\n", "'vgg_16/conv2/conv2_2'", ",", "\n", "'vgg_16/pool2'", ",", "\n", "'vgg_16/conv3/conv3_1'", ",", "\n", "'vgg_16/conv3/conv3_2'", ",", "\n", "'vgg_16/conv3/conv3_3'", ",", "\n", "'vgg_16/pool3'", ",", "\n", "'vgg_16/conv4/conv4_1'", ",", "\n", "'vgg_16/conv4/conv4_2'", ",", "\n", "'vgg_16/conv4/conv4_3'", ",", "\n", "'vgg_16/pool4'", ",", "\n", "'vgg_16/conv5/conv5_1'", ",", "\n", "'vgg_16/conv5/conv5_2'", ",", "\n", "'vgg_16/conv5/conv5_3'", ",", "\n", "'vgg_16/pool5'", ",", "\n", "'vgg_16/fc6'", ",", "\n", "'vgg_16/fc7'", ",", "\n", "'vgg_16/fc8'", "\n", "]", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "end_points", ".", "keys", "(", ")", ")", ",", "set", "(", "expected_names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG16Test.testModelVariables": [[211, 253], ["vgg_test.VGG16Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_16", "vgg_test.VGG16Test.assertSetEqual", "set", "set", "slim.get_model_variables"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_16"], ["", "", "def", "testModelVariables", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "vgg", ".", "vgg_16", "(", "inputs", ",", "num_classes", ")", "\n", "expected_names", "=", "[", "'vgg_16/conv1/conv1_1/weights'", ",", "\n", "'vgg_16/conv1/conv1_1/biases'", ",", "\n", "'vgg_16/conv1/conv1_2/weights'", ",", "\n", "'vgg_16/conv1/conv1_2/biases'", ",", "\n", "'vgg_16/conv2/conv2_1/weights'", ",", "\n", "'vgg_16/conv2/conv2_1/biases'", ",", "\n", "'vgg_16/conv2/conv2_2/weights'", ",", "\n", "'vgg_16/conv2/conv2_2/biases'", ",", "\n", "'vgg_16/conv3/conv3_1/weights'", ",", "\n", "'vgg_16/conv3/conv3_1/biases'", ",", "\n", "'vgg_16/conv3/conv3_2/weights'", ",", "\n", "'vgg_16/conv3/conv3_2/biases'", ",", "\n", "'vgg_16/conv3/conv3_3/weights'", ",", "\n", "'vgg_16/conv3/conv3_3/biases'", ",", "\n", "'vgg_16/conv4/conv4_1/weights'", ",", "\n", "'vgg_16/conv4/conv4_1/biases'", ",", "\n", "'vgg_16/conv4/conv4_2/weights'", ",", "\n", "'vgg_16/conv4/conv4_2/biases'", ",", "\n", "'vgg_16/conv4/conv4_3/weights'", ",", "\n", "'vgg_16/conv4/conv4_3/biases'", ",", "\n", "'vgg_16/conv5/conv5_1/weights'", ",", "\n", "'vgg_16/conv5/conv5_1/biases'", ",", "\n", "'vgg_16/conv5/conv5_2/weights'", ",", "\n", "'vgg_16/conv5/conv5_2/biases'", ",", "\n", "'vgg_16/conv5/conv5_3/weights'", ",", "\n", "'vgg_16/conv5/conv5_3/biases'", ",", "\n", "'vgg_16/fc6/weights'", ",", "\n", "'vgg_16/fc6/biases'", ",", "\n", "'vgg_16/fc7/weights'", ",", "\n", "'vgg_16/fc7/biases'", ",", "\n", "'vgg_16/fc8/weights'", ",", "\n", "'vgg_16/fc8/biases'", ",", "\n", "]", "\n", "model_variables", "=", "[", "v", ".", "op", ".", "name", "for", "v", "in", "slim", ".", "get_model_variables", "(", ")", "]", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "model_variables", ")", ",", "set", "(", "expected_names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG16Test.testEvaluation": [[254, 265], ["vgg_test.VGG16Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_16", "vgg_test.VGG16Test.assertListEqual", "tensorflow.argmax", "vgg_test.VGG16Test.assertListEqual", "logits.get_shape().as_list", "tensorflow.argmax.get_shape().as_list", "logits.get_shape", "tensorflow.argmax.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_16"], ["", "", "def", "testEvaluation", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_16", "(", "eval_inputs", ",", "is_training", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "predictions", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG16Test.testTrainEvalWithReuse": [[266, 288], ["vgg_test.VGG16Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_16", "vgg_test.VGG16Test.assertListEqual", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.random_uniform", "nets.vgg.vgg_16", "vgg_test.VGG16Test.assertListEqual", "tensorflow.reduce_mean", "tensorflow.argmax", "vgg_test.VGG16Test.assertEquals", "tensorflow.reduce_mean.get_shape().as_list", "tensorflow.reduce_mean.get_shape().as_list", "tensorflow.argmax.get_shape().as_list", "tensorflow.get_variable_scope", "tensorflow.reduce_mean.get_shape", "tensorflow.reduce_mean.get_shape", "tensorflow.argmax.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_16", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_16"], ["", "", "def", "testTrainEvalWithReuse", "(", "self", ")", ":", "\n", "    ", "train_batch_size", "=", "2", "\n", "eval_batch_size", "=", "1", "\n", "train_height", ",", "train_width", "=", "224", ",", "224", "\n", "eval_height", ",", "eval_width", "=", "256", ",", "256", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "train_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "(", "train_batch_size", ",", "train_height", ",", "train_width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_16", "(", "train_inputs", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "train_batch_size", ",", "num_classes", "]", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "(", "eval_batch_size", ",", "eval_height", ",", "eval_width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_16", "(", "eval_inputs", ",", "is_training", "=", "False", ",", "\n", "spatial_squeeze", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "eval_batch_size", ",", "2", ",", "2", ",", "num_classes", "]", ")", "\n", "logits", "=", "tf", ".", "reduce_mean", "(", "logits", ",", "[", "1", ",", "2", "]", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "self", ".", "assertEquals", "(", "predictions", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "eval_batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG16Test.testForward": [[289, 298], ["vgg_test.VGG16Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_16", "sess.run", "sess.run", "vgg_test.VGG16Test.assertTrue", "tensorflow.global_variables_initializer", "sess.run.any"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_16", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testForward", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_16", "(", "inputs", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ")", "\n", "self", ".", "assertTrue", "(", "output", ".", "any", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG19Test.testBuild": [[302, 312], ["vgg_test.VGG19Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_19", "vgg_test.VGG19Test.assertEquals", "vgg_test.VGG19Test.assertListEqual", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_19"], ["  ", "def", "testBuild", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_19", "(", "inputs", ",", "num_classes", ")", "\n", "self", ".", "assertEquals", "(", "logits", ".", "op", ".", "name", ",", "'vgg_19/fc8/squeezed'", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG19Test.testFullyConvolutional": [[313, 323], ["vgg_test.VGG19Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_19", "vgg_test.VGG19Test.assertEquals", "vgg_test.VGG19Test.assertListEqual", "logits.get_shape().as_list", "logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_19"], ["", "", "def", "testFullyConvolutional", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "256", ",", "256", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_19", "(", "inputs", ",", "num_classes", ",", "spatial_squeeze", "=", "False", ")", "\n", "self", ".", "assertEquals", "(", "logits", ".", "op", ".", "name", ",", "'vgg_19/fc8/BiasAdd'", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "2", ",", "2", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG19Test.testEndPoints": [[324, 358], ["vgg_test.VGG19Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_19", "vgg_test.VGG19Test.assertSetEqual", "set", "set", "end_points.keys"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_19"], ["", "", "def", "testEndPoints", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "_", ",", "end_points", "=", "vgg", ".", "vgg_19", "(", "inputs", ",", "num_classes", ")", "\n", "expected_names", "=", "[", "\n", "'vgg_19/conv1/conv1_1'", ",", "\n", "'vgg_19/conv1/conv1_2'", ",", "\n", "'vgg_19/pool1'", ",", "\n", "'vgg_19/conv2/conv2_1'", ",", "\n", "'vgg_19/conv2/conv2_2'", ",", "\n", "'vgg_19/pool2'", ",", "\n", "'vgg_19/conv3/conv3_1'", ",", "\n", "'vgg_19/conv3/conv3_2'", ",", "\n", "'vgg_19/conv3/conv3_3'", ",", "\n", "'vgg_19/conv3/conv3_4'", ",", "\n", "'vgg_19/pool3'", ",", "\n", "'vgg_19/conv4/conv4_1'", ",", "\n", "'vgg_19/conv4/conv4_2'", ",", "\n", "'vgg_19/conv4/conv4_3'", ",", "\n", "'vgg_19/conv4/conv4_4'", ",", "\n", "'vgg_19/pool4'", ",", "\n", "'vgg_19/conv5/conv5_1'", ",", "\n", "'vgg_19/conv5/conv5_2'", ",", "\n", "'vgg_19/conv5/conv5_3'", ",", "\n", "'vgg_19/conv5/conv5_4'", ",", "\n", "'vgg_19/pool5'", ",", "\n", "'vgg_19/fc6'", ",", "\n", "'vgg_19/fc7'", ",", "\n", "'vgg_19/fc8'", "\n", "]", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "end_points", ".", "keys", "(", ")", ")", ",", "set", "(", "expected_names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG19Test.testModelVariables": [[359, 408], ["vgg_test.VGG19Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_19", "vgg_test.VGG19Test.assertSetEqual", "set", "set", "slim.get_model_variables"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_19"], ["", "", "def", "testModelVariables", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "5", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "vgg", ".", "vgg_19", "(", "inputs", ",", "num_classes", ")", "\n", "expected_names", "=", "[", "\n", "'vgg_19/conv1/conv1_1/weights'", ",", "\n", "'vgg_19/conv1/conv1_1/biases'", ",", "\n", "'vgg_19/conv1/conv1_2/weights'", ",", "\n", "'vgg_19/conv1/conv1_2/biases'", ",", "\n", "'vgg_19/conv2/conv2_1/weights'", ",", "\n", "'vgg_19/conv2/conv2_1/biases'", ",", "\n", "'vgg_19/conv2/conv2_2/weights'", ",", "\n", "'vgg_19/conv2/conv2_2/biases'", ",", "\n", "'vgg_19/conv3/conv3_1/weights'", ",", "\n", "'vgg_19/conv3/conv3_1/biases'", ",", "\n", "'vgg_19/conv3/conv3_2/weights'", ",", "\n", "'vgg_19/conv3/conv3_2/biases'", ",", "\n", "'vgg_19/conv3/conv3_3/weights'", ",", "\n", "'vgg_19/conv3/conv3_3/biases'", ",", "\n", "'vgg_19/conv3/conv3_4/weights'", ",", "\n", "'vgg_19/conv3/conv3_4/biases'", ",", "\n", "'vgg_19/conv4/conv4_1/weights'", ",", "\n", "'vgg_19/conv4/conv4_1/biases'", ",", "\n", "'vgg_19/conv4/conv4_2/weights'", ",", "\n", "'vgg_19/conv4/conv4_2/biases'", ",", "\n", "'vgg_19/conv4/conv4_3/weights'", ",", "\n", "'vgg_19/conv4/conv4_3/biases'", ",", "\n", "'vgg_19/conv4/conv4_4/weights'", ",", "\n", "'vgg_19/conv4/conv4_4/biases'", ",", "\n", "'vgg_19/conv5/conv5_1/weights'", ",", "\n", "'vgg_19/conv5/conv5_1/biases'", ",", "\n", "'vgg_19/conv5/conv5_2/weights'", ",", "\n", "'vgg_19/conv5/conv5_2/biases'", ",", "\n", "'vgg_19/conv5/conv5_3/weights'", ",", "\n", "'vgg_19/conv5/conv5_3/biases'", ",", "\n", "'vgg_19/conv5/conv5_4/weights'", ",", "\n", "'vgg_19/conv5/conv5_4/biases'", ",", "\n", "'vgg_19/fc6/weights'", ",", "\n", "'vgg_19/fc6/biases'", ",", "\n", "'vgg_19/fc7/weights'", ",", "\n", "'vgg_19/fc7/biases'", ",", "\n", "'vgg_19/fc8/weights'", ",", "\n", "'vgg_19/fc8/biases'", ",", "\n", "]", "\n", "model_variables", "=", "[", "v", ".", "op", ".", "name", "for", "v", "in", "slim", ".", "get_model_variables", "(", ")", "]", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "model_variables", ")", ",", "set", "(", "expected_names", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG19Test.testEvaluation": [[409, 420], ["vgg_test.VGG19Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_19", "vgg_test.VGG19Test.assertListEqual", "tensorflow.argmax", "vgg_test.VGG19Test.assertListEqual", "logits.get_shape().as_list", "tensorflow.argmax.get_shape().as_list", "logits.get_shape", "tensorflow.argmax.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_19"], ["", "", "def", "testEvaluation", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "2", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_19", "(", "eval_inputs", ",", "is_training", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch_size", ",", "num_classes", "]", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "predictions", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG19Test.testTrainEvalWithReuse": [[421, 443], ["vgg_test.VGG19Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_19", "vgg_test.VGG19Test.assertListEqual", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.random_uniform", "nets.vgg.vgg_19", "vgg_test.VGG19Test.assertListEqual", "tensorflow.reduce_mean", "tensorflow.argmax", "vgg_test.VGG19Test.assertEquals", "tensorflow.reduce_mean.get_shape().as_list", "tensorflow.reduce_mean.get_shape().as_list", "tensorflow.argmax.get_shape().as_list", "tensorflow.get_variable_scope", "tensorflow.reduce_mean.get_shape", "tensorflow.reduce_mean.get_shape", "tensorflow.argmax.get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_19", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_19"], ["", "", "def", "testTrainEvalWithReuse", "(", "self", ")", ":", "\n", "    ", "train_batch_size", "=", "2", "\n", "eval_batch_size", "=", "1", "\n", "train_height", ",", "train_width", "=", "224", ",", "224", "\n", "eval_height", ",", "eval_width", "=", "256", ",", "256", "\n", "num_classes", "=", "1000", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "train_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "(", "train_batch_size", ",", "train_height", ",", "train_width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_19", "(", "train_inputs", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "train_batch_size", ",", "num_classes", "]", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "eval_inputs", "=", "tf", ".", "random_uniform", "(", "\n", "(", "eval_batch_size", ",", "eval_height", ",", "eval_width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_19", "(", "eval_inputs", ",", "is_training", "=", "False", ",", "\n", "spatial_squeeze", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "eval_batch_size", ",", "2", ",", "2", ",", "num_classes", "]", ")", "\n", "logits", "=", "tf", ".", "reduce_mean", "(", "logits", ",", "[", "1", ",", "2", "]", ")", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "1", ")", "\n", "self", ".", "assertEquals", "(", "predictions", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "eval_batch_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg_test.VGG19Test.testForward": [[444, 453], ["vgg_test.VGG19Test.test_session", "tensorflow.random_uniform", "nets.vgg.vgg_19", "sess.run", "sess.run", "vgg_test.VGG19Test.assertTrue", "tensorflow.global_variables_initializer", "sess.run.any"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.vgg.vgg_19", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testForward", "(", "self", ")", ":", "\n", "    ", "batch_size", "=", "1", "\n", "height", ",", "width", "=", "224", ",", "224", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "inputs", "=", "tf", ".", "random_uniform", "(", "(", "batch_size", ",", "height", ",", "width", ",", "3", ")", ")", "\n", "logits", ",", "_", "=", "vgg", ".", "vgg_19", "(", "inputs", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ")", "\n", "self", ".", "assertTrue", "(", "output", ".", "any", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest.testSubsampleThreeByThree": [[58, 64], ["tensorflow.reshape", "nets.resnet_utils.subsample", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.constant", "resnet_v2_test.ResnetUtilsTest.test_session", "resnet_v2_test.ResnetUtilsTest.assertAllClose", "tensorflow.range", "nets.resnet_utils.subsample.eval", "tensorflow.reshape.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample"], ["  ", "def", "testSubsampleThreeByThree", "(", "self", ")", ":", "\n", "    ", "x", "=", "tf", ".", "reshape", "(", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "9", ")", ")", ",", "[", "1", ",", "3", ",", "3", ",", "1", "]", ")", "\n", "x", "=", "resnet_utils", ".", "subsample", "(", "x", ",", "2", ")", "\n", "expected", "=", "tf", ".", "reshape", "(", "tf", ".", "constant", "(", "[", "0", ",", "2", ",", "6", ",", "8", "]", ")", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ")", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "self", ".", "assertAllClose", "(", "x", ".", "eval", "(", ")", ",", "expected", ".", "eval", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest.testSubsampleFourByFour": [[65, 71], ["tensorflow.reshape", "nets.resnet_utils.subsample", "tensorflow.reshape", "tensorflow.to_float", "tensorflow.constant", "resnet_v2_test.ResnetUtilsTest.test_session", "resnet_v2_test.ResnetUtilsTest.assertAllClose", "tensorflow.range", "nets.resnet_utils.subsample.eval", "tensorflow.reshape.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample"], ["", "", "def", "testSubsampleFourByFour", "(", "self", ")", ":", "\n", "    ", "x", "=", "tf", ".", "reshape", "(", "tf", ".", "to_float", "(", "tf", ".", "range", "(", "16", ")", ")", ",", "[", "1", ",", "4", ",", "4", ",", "1", "]", ")", "\n", "x", "=", "resnet_utils", ".", "subsample", "(", "x", ",", "2", ")", "\n", "expected", "=", "tf", ".", "reshape", "(", "tf", ".", "constant", "(", "[", "0", ",", "2", ",", "8", ",", "10", "]", ")", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ")", "\n", "with", "self", ".", "test_session", "(", ")", ":", "\n", "      ", "self", ".", "assertAllClose", "(", "x", ".", "eval", "(", ")", ",", "expected", ".", "eval", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest.testConv2DSameEven": [[72, 112], ["resnet_v2_test.create_test_input", "resnet_v2_test.create_test_input", "tensorflow.reshape", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable_scope().reuse_variables", "slim.conv2d", "tensorflow.to_float", "tensorflow.reshape", "nets.resnet_utils.subsample", "tensorflow.to_float", "tensorflow.reshape", "nets.resnet_utils.conv2d_same", "slim.conv2d", "tensorflow.to_float", "tensorflow.reshape", "resnet_v2_test.ResnetUtilsTest.test_session", "sess.run", "resnet_v2_test.ResnetUtilsTest.assertAllClose", "resnet_v2_test.ResnetUtilsTest.assertAllClose", "resnet_v2_test.ResnetUtilsTest.assertAllClose", "resnet_v2_test.ResnetUtilsTest.assertAllClose", "tensorflow.zeros", "tensorflow.get_variable_scope", "tensorflow.global_variables_initializer", "slim.conv2d.eval", "tensorflow.reshape.eval", "nets.resnet_utils.subsample.eval", "tensorflow.reshape.eval", "nets.resnet_utils.conv2d_same.eval", "y3_expected.eval", "slim.conv2d.eval", "tensorflow.reshape.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.conv2d_same", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testConv2DSameEven", "(", "self", ")", ":", "\n", "    ", "n", ",", "n2", "=", "4", ",", "2", "\n", "\n", "# Input image.", "\n", "x", "=", "create_test_input", "(", "1", ",", "n", ",", "n", ",", "1", ")", "\n", "\n", "# Convolution kernel.", "\n", "w", "=", "create_test_input", "(", "1", ",", "3", ",", "3", ",", "1", ")", "\n", "w", "=", "tf", ".", "reshape", "(", "w", ",", "[", "3", ",", "3", ",", "1", ",", "1", "]", ")", "\n", "\n", "tf", ".", "get_variable", "(", "'Conv/weights'", ",", "initializer", "=", "w", ")", "\n", "tf", ".", "get_variable", "(", "'Conv/biases'", ",", "initializer", "=", "tf", ".", "zeros", "(", "[", "1", "]", ")", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "y1", "=", "slim", ".", "conv2d", "(", "x", ",", "1", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "1", ",", "scope", "=", "'Conv'", ")", "\n", "y1_expected", "=", "tf", ".", "to_float", "(", "[", "[", "14", ",", "28", ",", "43", ",", "26", "]", ",", "\n", "[", "28", ",", "48", ",", "66", ",", "37", "]", ",", "\n", "[", "43", ",", "66", ",", "84", ",", "46", "]", ",", "\n", "[", "26", ",", "37", ",", "46", ",", "22", "]", "]", ")", "\n", "y1_expected", "=", "tf", ".", "reshape", "(", "y1_expected", ",", "[", "1", ",", "n", ",", "n", ",", "1", "]", ")", "\n", "\n", "y2", "=", "resnet_utils", ".", "subsample", "(", "y1", ",", "2", ")", "\n", "y2_expected", "=", "tf", ".", "to_float", "(", "[", "[", "14", ",", "43", "]", ",", "\n", "[", "43", ",", "84", "]", "]", ")", "\n", "y2_expected", "=", "tf", ".", "reshape", "(", "y2_expected", ",", "[", "1", ",", "n2", ",", "n2", ",", "1", "]", ")", "\n", "\n", "y3", "=", "resnet_utils", ".", "conv2d_same", "(", "x", ",", "1", ",", "3", ",", "stride", "=", "2", ",", "scope", "=", "'Conv'", ")", "\n", "y3_expected", "=", "y2_expected", "\n", "\n", "y4", "=", "slim", ".", "conv2d", "(", "x", ",", "1", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "'Conv'", ")", "\n", "y4_expected", "=", "tf", ".", "to_float", "(", "[", "[", "48", ",", "37", "]", ",", "\n", "[", "37", ",", "22", "]", "]", ")", "\n", "y4_expected", "=", "tf", ".", "reshape", "(", "y4_expected", ",", "[", "1", ",", "n2", ",", "n2", ",", "1", "]", ")", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y1", ".", "eval", "(", ")", ",", "y1_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y2", ".", "eval", "(", ")", ",", "y2_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y3", ".", "eval", "(", ")", ",", "y3_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y4", ".", "eval", "(", ")", ",", "y4_expected", ".", "eval", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest.testConv2DSameOdd": [[113, 153], ["resnet_v2_test.create_test_input", "resnet_v2_test.create_test_input", "tensorflow.reshape", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable_scope().reuse_variables", "slim.conv2d", "tensorflow.to_float", "tensorflow.reshape", "nets.resnet_utils.subsample", "tensorflow.to_float", "tensorflow.reshape", "nets.resnet_utils.conv2d_same", "slim.conv2d", "resnet_v2_test.ResnetUtilsTest.test_session", "sess.run", "resnet_v2_test.ResnetUtilsTest.assertAllClose", "resnet_v2_test.ResnetUtilsTest.assertAllClose", "resnet_v2_test.ResnetUtilsTest.assertAllClose", "resnet_v2_test.ResnetUtilsTest.assertAllClose", "tensorflow.zeros", "tensorflow.get_variable_scope", "tensorflow.global_variables_initializer", "slim.conv2d.eval", "tensorflow.reshape.eval", "nets.resnet_utils.subsample.eval", "tensorflow.reshape.eval", "nets.resnet_utils.conv2d_same.eval", "y3_expected.eval", "slim.conv2d.eval", "y4_expected.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.conv2d_same", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "def", "testConv2DSameOdd", "(", "self", ")", ":", "\n", "    ", "n", ",", "n2", "=", "5", ",", "3", "\n", "\n", "# Input image.", "\n", "x", "=", "create_test_input", "(", "1", ",", "n", ",", "n", ",", "1", ")", "\n", "\n", "# Convolution kernel.", "\n", "w", "=", "create_test_input", "(", "1", ",", "3", ",", "3", ",", "1", ")", "\n", "w", "=", "tf", ".", "reshape", "(", "w", ",", "[", "3", ",", "3", ",", "1", ",", "1", "]", ")", "\n", "\n", "tf", ".", "get_variable", "(", "'Conv/weights'", ",", "initializer", "=", "w", ")", "\n", "tf", ".", "get_variable", "(", "'Conv/biases'", ",", "initializer", "=", "tf", ".", "zeros", "(", "[", "1", "]", ")", ")", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "y1", "=", "slim", ".", "conv2d", "(", "x", ",", "1", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "1", ",", "scope", "=", "'Conv'", ")", "\n", "y1_expected", "=", "tf", ".", "to_float", "(", "[", "[", "14", ",", "28", ",", "43", ",", "58", ",", "34", "]", ",", "\n", "[", "28", ",", "48", ",", "66", ",", "84", ",", "46", "]", ",", "\n", "[", "43", ",", "66", ",", "84", ",", "102", ",", "55", "]", ",", "\n", "[", "58", ",", "84", ",", "102", ",", "120", ",", "64", "]", ",", "\n", "[", "34", ",", "46", ",", "55", ",", "64", ",", "30", "]", "]", ")", "\n", "y1_expected", "=", "tf", ".", "reshape", "(", "y1_expected", ",", "[", "1", ",", "n", ",", "n", ",", "1", "]", ")", "\n", "\n", "y2", "=", "resnet_utils", ".", "subsample", "(", "y1", ",", "2", ")", "\n", "y2_expected", "=", "tf", ".", "to_float", "(", "[", "[", "14", ",", "43", ",", "34", "]", ",", "\n", "[", "43", ",", "84", ",", "55", "]", ",", "\n", "[", "34", ",", "55", ",", "30", "]", "]", ")", "\n", "y2_expected", "=", "tf", ".", "reshape", "(", "y2_expected", ",", "[", "1", ",", "n2", ",", "n2", ",", "1", "]", ")", "\n", "\n", "y3", "=", "resnet_utils", ".", "conv2d_same", "(", "x", ",", "1", ",", "3", ",", "stride", "=", "2", ",", "scope", "=", "'Conv'", ")", "\n", "y3_expected", "=", "y2_expected", "\n", "\n", "y4", "=", "slim", ".", "conv2d", "(", "x", ",", "1", ",", "[", "3", ",", "3", "]", ",", "stride", "=", "2", ",", "scope", "=", "'Conv'", ")", "\n", "y4_expected", "=", "y2_expected", "\n", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y1", ".", "eval", "(", ")", ",", "y1_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y2", ".", "eval", "(", ")", ",", "y2_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y3", ".", "eval", "(", ")", ",", "y3_expected", ".", "eval", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "y4", ".", "eval", "(", ")", ",", "y4_expected", ".", "eval", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest._resnet_plain": [[154, 161], ["tensorflow.variable_scope", "slim.arg_scope", "nets.resnet_utils.stack_blocks_dense", "slim.utils.convert_collection_to_dict"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.stack_blocks_dense"], ["", "", "def", "_resnet_plain", "(", "self", ",", "inputs", ",", "blocks", ",", "output_stride", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "    ", "\"\"\"A plain ResNet without extra layers before or after the ResNet blocks.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "values", "=", "[", "inputs", "]", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d", "]", ",", "outputs_collections", "=", "'end_points'", ")", ":", "\n", "        ", "net", "=", "resnet_utils", ".", "stack_blocks_dense", "(", "inputs", ",", "blocks", ",", "output_stride", ")", "\n", "end_points", "=", "slim", ".", "utils", ".", "convert_collection_to_dict", "(", "'end_points'", ")", "\n", "return", "net", ",", "end_points", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest.testEndPointsV2": [[162, 189], ["resnet_v2_test.create_test_input", "resnet_v2_test.ResnetUtilsTest.assertItemsEqual", "nets.resnet_v2.resnet_v2_block", "nets.resnet_v2.resnet_v2_block", "slim.arg_scope", "resnet_v2_test.ResnetUtilsTest._resnet_plain", "nets.resnet_utils.resnet_arg_scope"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2_block", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest._resnet_plain", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "", "def", "testEndPointsV2", "(", "self", ")", ":", "\n", "    ", "\"\"\"Test the end points of a tiny v2 bottleneck network.\"\"\"", "\n", "blocks", "=", "[", "\n", "resnet_v2", ".", "resnet_v2_block", "(", "\n", "'block1'", ",", "base_depth", "=", "1", ",", "num_units", "=", "2", ",", "stride", "=", "2", ")", ",", "\n", "resnet_v2", ".", "resnet_v2_block", "(", "\n", "'block2'", ",", "base_depth", "=", "2", ",", "num_units", "=", "2", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "32", ",", "16", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "_", ",", "end_points", "=", "self", ".", "_resnet_plain", "(", "inputs", ",", "blocks", ",", "scope", "=", "'tiny'", ")", "\n", "", "expected", "=", "[", "\n", "'tiny/block1/unit_1/bottleneck_v2/shortcut'", ",", "\n", "'tiny/block1/unit_1/bottleneck_v2/conv1'", ",", "\n", "'tiny/block1/unit_1/bottleneck_v2/conv2'", ",", "\n", "'tiny/block1/unit_1/bottleneck_v2/conv3'", ",", "\n", "'tiny/block1/unit_2/bottleneck_v2/conv1'", ",", "\n", "'tiny/block1/unit_2/bottleneck_v2/conv2'", ",", "\n", "'tiny/block1/unit_2/bottleneck_v2/conv3'", ",", "\n", "'tiny/block2/unit_1/bottleneck_v2/shortcut'", ",", "\n", "'tiny/block2/unit_1/bottleneck_v2/conv1'", ",", "\n", "'tiny/block2/unit_1/bottleneck_v2/conv2'", ",", "\n", "'tiny/block2/unit_1/bottleneck_v2/conv3'", ",", "\n", "'tiny/block2/unit_2/bottleneck_v2/conv1'", ",", "\n", "'tiny/block2/unit_2/bottleneck_v2/conv2'", ",", "\n", "'tiny/block2/unit_2/bottleneck_v2/conv3'", "]", "\n", "self", ".", "assertItemsEqual", "(", "expected", ",", "end_points", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest._stack_blocks_nondense": [[190, 198], ["tensorflow.variable_scope", "enumerate", "tensorflow.variable_scope", "block.unit_fn"], "methods", ["None"], ["", "def", "_stack_blocks_nondense", "(", "self", ",", "net", ",", "blocks", ")", ":", "\n", "    ", "\"\"\"A simplified ResNet Block stacker without output stride control.\"\"\"", "\n", "for", "block", "in", "blocks", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "block", ".", "scope", ",", "'block'", ",", "[", "net", "]", ")", ":", "\n", "        ", "for", "i", ",", "unit", "in", "enumerate", "(", "block", ".", "args", ")", ":", "\n", "          ", "with", "tf", ".", "variable_scope", "(", "'unit_%d'", "%", "(", "i", "+", "1", ")", ",", "values", "=", "[", "net", "]", ")", ":", "\n", "            ", "net", "=", "block", ".", "unit_fn", "(", "net", ",", "rate", "=", "1", ",", "**", "unit", ")", "\n", "", "", "", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest.testAtrousValuesBottleneck": [[199, 242], ["block", "block", "block", "block", "slim.arg_scope", "nets.resnet_utils.resnet_arg_scope", "slim.arg_scope", "tensorflow.Graph().as_default", "resnet_v2_test.ResnetUtilsTest.test_session", "tensorflow.set_random_seed", "resnet_v2_test.create_test_input", "nets.resnet_utils.stack_blocks_dense", "nets.resnet_utils.subsample", "tensorflow.get_variable_scope().reuse_variables", "resnet_v2_test.ResnetUtilsTest._stack_blocks_nondense", "sess.run", "sess.run", "resnet_v2_test.ResnetUtilsTest.assertAllClose", "tensorflow.Graph", "tensorflow.global_variables_initializer", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.stack_blocks_dense", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetUtilsTest._stack_blocks_nondense", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "def", "testAtrousValuesBottleneck", "(", "self", ")", ":", "\n", "    ", "\"\"\"Verify the values of dense feature extraction by atrous convolution.\n\n    Make sure that dense feature extraction by stack_blocks_dense() followed by\n    subsampling gives identical results to feature extraction at the nominal\n    network output stride using the simple self._stack_blocks_nondense() above.\n    \"\"\"", "\n", "block", "=", "resnet_v2", ".", "resnet_v2_block", "\n", "blocks", "=", "[", "\n", "block", "(", "'block1'", ",", "base_depth", "=", "1", ",", "num_units", "=", "2", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block2'", ",", "base_depth", "=", "2", ",", "num_units", "=", "2", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block3'", ",", "base_depth", "=", "4", ",", "num_units", "=", "2", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block4'", ",", "base_depth", "=", "8", ",", "num_units", "=", "2", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "nominal_stride", "=", "8", "\n", "\n", "# Test both odd and even input dimensions.", "\n", "height", "=", "30", "\n", "width", "=", "31", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", "]", ",", "is_training", "=", "False", ")", ":", "\n", "        ", "for", "output_stride", "in", "[", "1", ",", "2", ",", "4", ",", "8", ",", "None", "]", ":", "\n", "          ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "            ", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "              ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "inputs", "=", "create_test_input", "(", "1", ",", "height", ",", "width", ",", "3", ")", "\n", "# Dense feature extraction followed by subsampling.", "\n", "output", "=", "resnet_utils", ".", "stack_blocks_dense", "(", "inputs", ",", "\n", "blocks", ",", "\n", "output_stride", ")", "\n", "if", "output_stride", "is", "None", ":", "\n", "                ", "factor", "=", "1", "\n", "", "else", ":", "\n", "                ", "factor", "=", "nominal_stride", "//", "output_stride", "\n", "\n", "", "output", "=", "resnet_utils", ".", "subsample", "(", "output", ",", "factor", ")", "\n", "# Make the two networks use the same weights.", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# Feature extraction at the nominal network rate.", "\n", "expected", "=", "self", ".", "_stack_blocks_nondense", "(", "inputs", ",", "blocks", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", ",", "expected", "=", "sess", ".", "run", "(", "[", "output", ",", "expected", "]", ")", "\n", "self", ".", "assertAllClose", "(", "output", ",", "expected", ",", "atol", "=", "1e-4", ",", "rtol", "=", "1e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small": [[247, 271], ["nets.resnet_v2.resnet_v2", "block", "block", "block", "block"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2.resnet_v2"], ["def", "_resnet_small", "(", "self", ",", "\n", "inputs", ",", "\n", "num_classes", "=", "None", ",", "\n", "is_training", "=", "True", ",", "\n", "global_pool", "=", "True", ",", "\n", "output_stride", "=", "None", ",", "\n", "include_root_block", "=", "True", ",", "\n", "reuse", "=", "None", ",", "\n", "scope", "=", "'resnet_v2_small'", ")", ":", "\n", "    ", "\"\"\"A shallow and thin ResNet v2 for faster tests.\"\"\"", "\n", "block", "=", "resnet_v2", ".", "resnet_v2_block", "\n", "blocks", "=", "[", "\n", "block", "(", "'block1'", ",", "base_depth", "=", "1", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block2'", ",", "base_depth", "=", "2", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block3'", ",", "base_depth", "=", "4", ",", "num_units", "=", "3", ",", "stride", "=", "2", ")", ",", "\n", "block", "(", "'block4'", ",", "base_depth", "=", "8", ",", "num_units", "=", "2", ",", "stride", "=", "1", ")", ",", "\n", "]", "\n", "return", "resnet_v2", ".", "resnet_v2", "(", "inputs", ",", "blocks", ",", "num_classes", ",", "\n", "is_training", "=", "is_training", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "output_stride", "=", "output_stride", ",", "\n", "include_root_block", "=", "include_root_block", ",", "\n", "reuse", "=", "reuse", ",", "\n", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest.testClassificationEndPoints": [[272, 285], ["resnet_v2_test.create_test_input", "resnet_v2_test.ResnetCompleteNetworkTest.assertTrue", "resnet_v2_test.ResnetCompleteNetworkTest.assertListEqual", "resnet_v2_test.ResnetCompleteNetworkTest.assertTrue", "resnet_v2_test.ResnetCompleteNetworkTest.assertListEqual", "slim.arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "logits.op.name.startswith", "logits.get_shape().as_list", "end_points[].get_shape().as_list", "nets.resnet_utils.resnet_arg_scope", "logits.get_shape", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "def", "testClassificationEndPoints", "(", "self", ")", ":", "\n", "    ", "global_pool", "=", "True", "\n", "num_classes", "=", "10", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "224", ",", "224", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "logits", ",", "end_points", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'resnet/logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "[", "2", ",", "1", ",", "1", ",", "num_classes", "]", ")", "\n", "self", ".", "assertTrue", "(", "'predictions'", "in", "end_points", ")", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "'predictions'", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "2", ",", "1", ",", "1", ",", "num_classes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest.testClassificationShapes": [[286, 302], ["resnet_v2_test.create_test_input", "slim.arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "nets.resnet_utils.resnet_arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "def", "testClassificationShapes", "(", "self", ")", ":", "\n", "    ", "global_pool", "=", "True", "\n", "num_classes", "=", "10", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "224", ",", "224", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "_", ",", "end_points", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "endpoint_to_shape", "=", "{", "\n", "'resnet/block1'", ":", "[", "2", ",", "28", ",", "28", ",", "4", "]", ",", "\n", "'resnet/block2'", ":", "[", "2", ",", "14", ",", "14", ",", "8", "]", ",", "\n", "'resnet/block3'", ":", "[", "2", ",", "7", ",", "7", ",", "16", "]", ",", "\n", "'resnet/block4'", ":", "[", "2", ",", "7", ",", "7", ",", "32", "]", "}", "\n", "for", "endpoint", "in", "endpoint_to_shape", ":", "\n", "        ", "shape", "=", "endpoint_to_shape", "[", "endpoint", "]", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest.testFullyConvolutionalEndpointShapes": [[303, 319], ["resnet_v2_test.create_test_input", "slim.arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "nets.resnet_utils.resnet_arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "", "def", "testFullyConvolutionalEndpointShapes", "(", "self", ")", ":", "\n", "    ", "global_pool", "=", "False", "\n", "num_classes", "=", "10", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "321", ",", "321", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "_", ",", "end_points", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "endpoint_to_shape", "=", "{", "\n", "'resnet/block1'", ":", "[", "2", ",", "41", ",", "41", ",", "4", "]", ",", "\n", "'resnet/block2'", ":", "[", "2", ",", "21", ",", "21", ",", "8", "]", ",", "\n", "'resnet/block3'", ":", "[", "2", ",", "11", ",", "11", ",", "16", "]", ",", "\n", "'resnet/block4'", ":", "[", "2", ",", "11", ",", "11", ",", "32", "]", "}", "\n", "for", "endpoint", "in", "endpoint_to_shape", ":", "\n", "        ", "shape", "=", "endpoint_to_shape", "[", "endpoint", "]", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest.testRootlessFullyConvolutionalEndpointShapes": [[320, 337], ["resnet_v2_test.create_test_input", "slim.arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "nets.resnet_utils.resnet_arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "", "def", "testRootlessFullyConvolutionalEndpointShapes", "(", "self", ")", ":", "\n", "    ", "global_pool", "=", "False", "\n", "num_classes", "=", "10", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "128", ",", "128", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "_", ",", "end_points", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "include_root_block", "=", "False", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "endpoint_to_shape", "=", "{", "\n", "'resnet/block1'", ":", "[", "2", ",", "64", ",", "64", ",", "4", "]", ",", "\n", "'resnet/block2'", ":", "[", "2", ",", "32", ",", "32", ",", "8", "]", ",", "\n", "'resnet/block3'", ":", "[", "2", ",", "16", ",", "16", ",", "16", "]", ",", "\n", "'resnet/block4'", ":", "[", "2", ",", "16", ",", "16", ",", "32", "]", "}", "\n", "for", "endpoint", "in", "endpoint_to_shape", ":", "\n", "        ", "shape", "=", "endpoint_to_shape", "[", "endpoint", "]", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest.testAtrousFullyConvolutionalEndpointShapes": [[338, 357], ["resnet_v2_test.create_test_input", "slim.arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "nets.resnet_utils.resnet_arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest.assertListEqual", "end_points[].get_shape().as_list", "end_points[].get_shape"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "", "def", "testAtrousFullyConvolutionalEndpointShapes", "(", "self", ")", ":", "\n", "    ", "global_pool", "=", "False", "\n", "num_classes", "=", "10", "\n", "output_stride", "=", "8", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "321", ",", "321", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "_", ",", "end_points", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "\n", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "output_stride", "=", "output_stride", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "endpoint_to_shape", "=", "{", "\n", "'resnet/block1'", ":", "[", "2", ",", "41", ",", "41", ",", "4", "]", ",", "\n", "'resnet/block2'", ":", "[", "2", ",", "41", ",", "41", ",", "8", "]", ",", "\n", "'resnet/block3'", ":", "[", "2", ",", "41", ",", "41", ",", "16", "]", ",", "\n", "'resnet/block4'", ":", "[", "2", ",", "41", ",", "41", ",", "32", "]", "}", "\n", "for", "endpoint", "in", "endpoint_to_shape", ":", "\n", "        ", "shape", "=", "endpoint_to_shape", "[", "endpoint", "]", "\n", "self", ".", "assertListEqual", "(", "end_points", "[", "endpoint", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest.testAtrousFullyConvolutionalValues": [[358, 386], ["slim.arg_scope", "nets.resnet_utils.resnet_arg_scope", "tensorflow.Graph().as_default", "resnet_v2_test.ResnetCompleteNetworkTest.test_session", "tensorflow.set_random_seed", "resnet_v2_test.create_test_input", "resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "nets.resnet_utils.subsample", "tensorflow.get_variable_scope().reuse_variables", "resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "sess.run", "resnet_v2_test.ResnetCompleteNetworkTest.assertAllClose", "tensorflow.Graph", "tensorflow.global_variables_initializer", "nets.resnet_utils.subsample.eval", "expected.eval", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run"], ["", "", "", "def", "testAtrousFullyConvolutionalValues", "(", "self", ")", ":", "\n", "    ", "\"\"\"Verify dense feature extraction with atrous convolution.\"\"\"", "\n", "nominal_stride", "=", "32", "\n", "for", "output_stride", "in", "[", "4", ",", "8", ",", "16", ",", "32", ",", "None", "]", ":", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "        ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "          ", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "            ", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "inputs", "=", "create_test_input", "(", "2", ",", "81", ",", "81", ",", "3", ")", "\n", "# Dense feature extraction followed by subsampling.", "\n", "output", ",", "_", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "None", ",", "\n", "is_training", "=", "False", ",", "\n", "global_pool", "=", "False", ",", "\n", "output_stride", "=", "output_stride", ")", "\n", "if", "output_stride", "is", "None", ":", "\n", "              ", "factor", "=", "1", "\n", "", "else", ":", "\n", "              ", "factor", "=", "nominal_stride", "//", "output_stride", "\n", "", "output", "=", "resnet_utils", ".", "subsample", "(", "output", ",", "factor", ")", "\n", "# Make the two networks use the same weights.", "\n", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "# Feature extraction at the nominal network rate.", "\n", "expected", ",", "_", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "None", ",", "\n", "is_training", "=", "False", ",", "\n", "global_pool", "=", "False", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "assertAllClose", "(", "output", ".", "eval", "(", ")", ",", "expected", ".", "eval", "(", ")", ",", "\n", "atol", "=", "1e-4", ",", "rtol", "=", "1e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest.testUnknownBatchSize": [[387, 405], ["resnet_v2_test.create_test_input", "resnet_v2_test.ResnetCompleteNetworkTest.assertTrue", "resnet_v2_test.ResnetCompleteNetworkTest.assertListEqual", "resnet_v2_test.create_test_input", "slim.arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "logits.op.name.startswith", "logits.get_shape().as_list", "resnet_v2_test.ResnetCompleteNetworkTest.test_session", "sess.run", "sess.run", "resnet_v2_test.ResnetCompleteNetworkTest.assertEqual", "nets.resnet_utils.resnet_arg_scope", "tensorflow.global_variables_initializer", "logits.get_shape", "create_test_input.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "", "", "", "def", "testUnknownBatchSize", "(", "self", ")", ":", "\n", "    ", "batch", "=", "2", "\n", "height", ",", "width", "=", "65", ",", "65", "\n", "global_pool", "=", "True", "\n", "num_classes", "=", "10", "\n", "inputs", "=", "create_test_input", "(", "None", ",", "height", ",", "width", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "logits", ",", "_", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "num_classes", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "scope", "=", "'resnet'", ")", "\n", "", "self", ".", "assertTrue", "(", "logits", ".", "op", ".", "name", ".", "startswith", "(", "'resnet/logits'", ")", ")", "\n", "self", ".", "assertListEqual", "(", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "None", ",", "1", ",", "1", ",", "num_classes", "]", ")", "\n", "images", "=", "create_test_input", "(", "batch", ",", "height", ",", "width", ",", "3", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "logits", ",", "{", "inputs", ":", "images", ".", "eval", "(", ")", "}", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "shape", ",", "(", "batch", ",", "1", ",", "1", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest.testFullyConvolutionalUnknownHeightWidth": [[406, 421], ["resnet_v2_test.create_test_input", "resnet_v2_test.ResnetCompleteNetworkTest.assertListEqual", "resnet_v2_test.create_test_input", "slim.arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "sess.run.get_shape().as_list", "resnet_v2_test.ResnetCompleteNetworkTest.test_session", "sess.run", "sess.run", "resnet_v2_test.ResnetCompleteNetworkTest.assertEqual", "nets.resnet_utils.resnet_arg_scope", "tensorflow.global_variables_initializer", "sess.run.get_shape", "create_test_input.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "def", "testFullyConvolutionalUnknownHeightWidth", "(", "self", ")", ":", "\n", "    ", "batch", "=", "2", "\n", "height", ",", "width", "=", "65", ",", "65", "\n", "global_pool", "=", "False", "\n", "inputs", "=", "create_test_input", "(", "batch", ",", "None", ",", "None", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "output", ",", "_", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "None", ",", "\n", "global_pool", "=", "global_pool", ")", "\n", "", "self", ".", "assertListEqual", "(", "output", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch", ",", "None", ",", "None", ",", "32", "]", ")", "\n", "images", "=", "create_test_input", "(", "batch", ",", "height", ",", "width", ",", "3", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "output", ",", "{", "inputs", ":", "images", ".", "eval", "(", ")", "}", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "shape", ",", "(", "batch", ",", "3", ",", "3", ",", "32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest.testAtrousFullyConvolutionalUnknownHeightWidth": [[422, 440], ["resnet_v2_test.create_test_input", "resnet_v2_test.ResnetCompleteNetworkTest.assertListEqual", "resnet_v2_test.create_test_input", "slim.arg_scope", "resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "sess.run.get_shape().as_list", "resnet_v2_test.ResnetCompleteNetworkTest.test_session", "sess.run", "sess.run", "resnet_v2_test.ResnetCompleteNetworkTest.assertEqual", "nets.resnet_utils.resnet_arg_scope", "tensorflow.global_variables_initializer", "sess.run.get_shape", "create_test_input.eval"], "methods", ["home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.ResnetCompleteNetworkTest._resnet_small", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.datasets.download_and_convert_mnist.run", "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope"], ["", "", "def", "testAtrousFullyConvolutionalUnknownHeightWidth", "(", "self", ")", ":", "\n", "    ", "batch", "=", "2", "\n", "height", ",", "width", "=", "65", ",", "65", "\n", "global_pool", "=", "False", "\n", "output_stride", "=", "8", "\n", "inputs", "=", "create_test_input", "(", "batch", ",", "None", ",", "None", ",", "3", ")", "\n", "with", "slim", ".", "arg_scope", "(", "resnet_utils", ".", "resnet_arg_scope", "(", ")", ")", ":", "\n", "      ", "output", ",", "_", "=", "self", ".", "_resnet_small", "(", "inputs", ",", "\n", "None", ",", "\n", "global_pool", "=", "global_pool", ",", "\n", "output_stride", "=", "output_stride", ")", "\n", "", "self", ".", "assertListEqual", "(", "output", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ",", "\n", "[", "batch", ",", "None", ",", "None", ",", "32", "]", ")", "\n", "images", "=", "create_test_input", "(", "batch", ",", "height", ",", "width", ",", "3", ")", "\n", "with", "self", ".", "test_session", "(", ")", "as", "sess", ":", "\n", "      ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "output", "=", "sess", ".", "run", "(", "output", ",", "{", "inputs", ":", "images", ".", "eval", "(", ")", "}", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "shape", ",", "(", "batch", ",", "9", ",", "9", ",", "32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_v2_test.create_test_input": [[30, 54], ["tensorflow.placeholder", "tensorflow.to_float", "numpy.tile", "numpy.reshape", "numpy.reshape", "numpy.reshape", "numpy.arange", "numpy.arange"], "function", ["None"], ["def", "create_test_input", "(", "batch_size", ",", "height", ",", "width", ",", "channels", ")", ":", "\n", "  ", "\"\"\"Create test input tensor.\n\n  Args:\n    batch_size: The number of images per batch or `None` if unknown.\n    height: The height of each image or `None` if unknown.\n    width: The width of each image or `None` if unknown.\n    channels: The number of channels per image or `None` if unknown.\n\n  Returns:\n    Either a placeholder `Tensor` of dimension\n      [batch_size, height, width, channels] if any of the inputs are `None` or a\n    constant `Tensor` with the mesh grid values along the spatial dimensions.\n  \"\"\"", "\n", "if", "None", "in", "[", "batch_size", ",", "height", ",", "width", ",", "channels", "]", ":", "\n", "    ", "return", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "batch_size", ",", "height", ",", "width", ",", "channels", ")", ")", "\n", "", "else", ":", "\n", "    ", "return", "tf", ".", "to_float", "(", "\n", "np", ".", "tile", "(", "\n", "np", ".", "reshape", "(", "\n", "np", ".", "reshape", "(", "np", ".", "arange", "(", "height", ")", ",", "[", "height", ",", "1", "]", ")", "+", "\n", "np", ".", "reshape", "(", "np", ".", "arange", "(", "width", ")", ",", "[", "1", ",", "width", "]", ")", ",", "\n", "[", "1", ",", "height", ",", "width", ",", "1", "]", ")", ",", "\n", "[", "batch_size", ",", "1", ",", "1", ",", "channels", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.subsample": [[59, 75], ["slim.max_pool2d"], "function", ["None"], ["", "def", "subsample", "(", "inputs", ",", "factor", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Subsamples the input along the spatial dimensions.\n\n  Args:\n    inputs: A `Tensor` of size [batch, height_in, width_in, channels].\n    factor: The subsampling factor.\n    scope: Optional variable_scope.\n\n  Returns:\n    output: A `Tensor` of size [batch, height_out, width_out, channels] with the\n      input, either intact (if factor == 1) or subsampled (if factor > 1).\n  \"\"\"", "\n", "if", "factor", "==", "1", ":", "\n", "    ", "return", "inputs", "\n", "", "else", ":", "\n", "    ", "return", "slim", ".", "max_pool2d", "(", "inputs", ",", "[", "1", ",", "1", "]", ",", "stride", "=", "factor", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.conv2d_same": [[77, 123], ["slim.conv2d", "tensorflow.pad", "slim.conv2d"], "function", ["None"], ["", "", "def", "conv2d_same", "(", "inputs", ",", "num_outputs", ",", "kernel_size", ",", "stride", ",", "rate", "=", "1", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"Strided 2-D convolution with 'SAME' padding.\n\n  When stride > 1, then we do explicit zero-padding, followed by conv2d with\n  'VALID' padding.\n\n  Note that\n\n     net = conv2d_same(inputs, num_outputs, 3, stride=stride)\n\n  is equivalent to\n\n     net = slim.conv2d(inputs, num_outputs, 3, stride=1, padding='SAME')\n     net = subsample(net, factor=stride)\n\n  whereas\n\n     net = slim.conv2d(inputs, num_outputs, 3, stride=stride, padding='SAME')\n\n  is different when the input's height or width is even, which is why we add the\n  current function. For more details, see ResnetUtilsTest.testConv2DSameEven().\n\n  Args:\n    inputs: A 4-D tensor of size [batch, height_in, width_in, channels].\n    num_outputs: An integer, the number of output filters.\n    kernel_size: An int with the kernel_size of the filters.\n    stride: An integer, the output stride.\n    rate: An integer, rate for atrous convolution.\n    scope: Scope.\n\n  Returns:\n    output: A 4-D tensor of size [batch, height_out, width_out, channels] with\n      the convolution output.\n  \"\"\"", "\n", "if", "stride", "==", "1", ":", "\n", "    ", "return", "slim", ".", "conv2d", "(", "inputs", ",", "num_outputs", ",", "kernel_size", ",", "stride", "=", "1", ",", "rate", "=", "rate", ",", "\n", "padding", "=", "'SAME'", ",", "scope", "=", "scope", ")", "\n", "", "else", ":", "\n", "    ", "kernel_size_effective", "=", "kernel_size", "+", "(", "kernel_size", "-", "1", ")", "*", "(", "rate", "-", "1", ")", "\n", "pad_total", "=", "kernel_size_effective", "-", "1", "\n", "pad_beg", "=", "pad_total", "//", "2", "\n", "pad_end", "=", "pad_total", "-", "pad_beg", "\n", "inputs", "=", "tf", ".", "pad", "(", "inputs", ",", "\n", "[", "[", "0", ",", "0", "]", ",", "[", "pad_beg", ",", "pad_end", "]", ",", "[", "pad_beg", ",", "pad_end", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "return", "slim", ".", "conv2d", "(", "inputs", ",", "num_outputs", ",", "kernel_size", ",", "stride", "=", "stride", ",", "\n", "rate", "=", "rate", ",", "padding", "=", "'VALID'", ",", "scope", "=", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.stack_blocks_dense": [[125, 197], ["ValueError", "tensorflow.variable_scope", "enumerate", "slim.utils.collect_named_outputs", "ValueError", "tensorflow.variable_scope", "block.unit_fn", "unit.get", "block.unit_fn", "unit.get", "dict"], "function", ["None"], ["", "", "@", "slim", ".", "add_arg_scope", "\n", "def", "stack_blocks_dense", "(", "net", ",", "blocks", ",", "output_stride", "=", "None", ",", "\n", "outputs_collections", "=", "None", ")", ":", "\n", "  ", "\"\"\"Stacks ResNet `Blocks` and controls output feature density.\n\n  First, this function creates scopes for the ResNet in the form of\n  'block_name/unit_1', 'block_name/unit_2', etc.\n\n  Second, this function allows the user to explicitly control the ResNet\n  output_stride, which is the ratio of the input to output spatial resolution.\n  This is useful for dense prediction tasks such as semantic segmentation or\n  object detection.\n\n  Most ResNets consist of 4 ResNet blocks and subsample the activations by a\n  factor of 2 when transitioning between consecutive ResNet blocks. This results\n  to a nominal ResNet output_stride equal to 8. If we set the output_stride to\n  half the nominal network stride (e.g., output_stride=4), then we compute\n  responses twice.\n\n  Control of the output feature density is implemented by atrous convolution.\n\n  Args:\n    net: A `Tensor` of size [batch, height, width, channels].\n    blocks: A list of length equal to the number of ResNet `Blocks`. Each\n      element is a ResNet `Block` object describing the units in the `Block`.\n    output_stride: If `None`, then the output will be computed at the nominal\n      network stride. If output_stride is not `None`, it specifies the requested\n      ratio of input to output spatial resolution, which needs to be equal to\n      the product of unit strides from the start up to some level of the ResNet.\n      For example, if the ResNet employs units with strides 1, 2, 1, 3, 4, 1,\n      then valid values for the output_stride are 1, 2, 6, 24 or None (which\n      is equivalent to output_stride=24).\n    outputs_collections: Collection to add the ResNet block outputs.\n\n  Returns:\n    net: Output tensor with stride equal to the specified output_stride.\n\n  Raises:\n    ValueError: If the target output_stride is not valid.\n  \"\"\"", "\n", "# The current_stride variable keeps track of the effective stride of the", "\n", "# activations. This allows us to invoke atrous convolution whenever applying", "\n", "# the next residual unit would result in the activations having stride larger", "\n", "# than the target output_stride.", "\n", "current_stride", "=", "1", "\n", "\n", "# The atrous convolution rate parameter.", "\n", "rate", "=", "1", "\n", "\n", "for", "block", "in", "blocks", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "block", ".", "scope", ",", "'block'", ",", "[", "net", "]", ")", "as", "sc", ":", "\n", "      ", "for", "i", ",", "unit", "in", "enumerate", "(", "block", ".", "args", ")", ":", "\n", "        ", "if", "output_stride", "is", "not", "None", "and", "current_stride", ">", "output_stride", ":", "\n", "          ", "raise", "ValueError", "(", "'The target output_stride cannot be reached.'", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'unit_%d'", "%", "(", "i", "+", "1", ")", ",", "values", "=", "[", "net", "]", ")", ":", "\n", "# If we have reached the target output_stride, then we need to employ", "\n", "# atrous convolution with stride=1 and multiply the atrous rate by the", "\n", "# current unit's stride for use in subsequent layers.", "\n", "          ", "if", "output_stride", "is", "not", "None", "and", "current_stride", "==", "output_stride", ":", "\n", "            ", "net", "=", "block", ".", "unit_fn", "(", "net", ",", "rate", "=", "rate", ",", "**", "dict", "(", "unit", ",", "stride", "=", "1", ")", ")", "\n", "rate", "*=", "unit", ".", "get", "(", "'stride'", ",", "1", ")", "\n", "\n", "", "else", ":", "\n", "            ", "net", "=", "block", ".", "unit_fn", "(", "net", ",", "rate", "=", "1", ",", "**", "unit", ")", "\n", "current_stride", "*=", "unit", ".", "get", "(", "'stride'", ",", "1", ")", "\n", "", "", "", "net", "=", "slim", ".", "utils", ".", "collect_named_outputs", "(", "outputs_collections", ",", "sc", ".", "name", ",", "net", ")", "\n", "\n", "", "", "if", "output_stride", "is", "not", "None", "and", "current_stride", "!=", "output_stride", ":", "\n", "    ", "raise", "ValueError", "(", "'The target output_stride cannot be reached.'", ")", "\n", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.anthonyhu_tumblr-emotions.nets.resnet_utils.resnet_arg_scope": [[199, 245], ["slim.arg_scope", "slim.arg_scope", "slim.l2_regularizer", "slim.variance_scaling_initializer", "slim.arg_scope"], "function", ["None"], ["", "def", "resnet_arg_scope", "(", "weight_decay", "=", "0.0001", ",", "\n", "batch_norm_decay", "=", "0.997", ",", "\n", "batch_norm_epsilon", "=", "1e-5", ",", "\n", "batch_norm_scale", "=", "True", ")", ":", "\n", "  ", "\"\"\"Defines the default ResNet arg scope.\n\n  TODO(gpapan): The batch-normalization related default values above are\n    appropriate for use in conjunction with the reference ResNet models\n    released at https://github.com/KaimingHe/deep-residual-networks. When\n    training ResNets from scratch, they might need to be tuned.\n\n  Args:\n    weight_decay: The weight decay to use for regularizing the model.\n    batch_norm_decay: The moving average decay when estimating layer activation\n      statistics in batch normalization.\n    batch_norm_epsilon: Small constant to prevent division by zero when\n      normalizing activations by their variance in batch normalization.\n    batch_norm_scale: If True, uses an explicit `gamma` multiplier to scale the\n      activations in the batch normalization layer.\n\n  Returns:\n    An `arg_scope` to use for the resnet models.\n  \"\"\"", "\n", "batch_norm_params", "=", "{", "\n", "'decay'", ":", "batch_norm_decay", ",", "\n", "'epsilon'", ":", "batch_norm_epsilon", ",", "\n", "'scale'", ":", "batch_norm_scale", ",", "\n", "'updates_collections'", ":", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ",", "\n", "}", "\n", "\n", "with", "slim", ".", "arg_scope", "(", "\n", "[", "slim", ".", "conv2d", "]", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "weight_decay", ")", ",", "\n", "weights_initializer", "=", "slim", ".", "variance_scaling_initializer", "(", ")", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "normalizer_fn", "=", "slim", ".", "batch_norm", ",", "\n", "normalizer_params", "=", "batch_norm_params", ")", ":", "\n", "    ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "batch_norm", "]", ",", "**", "batch_norm_params", ")", ":", "\n", "# The following implies padding='SAME' for pool1, which makes feature", "\n", "# alignment easier for dense prediction tasks. This is also used in", "\n", "# https://github.com/facebook/fb.resnet.torch. However the accompanying", "\n", "# code of 'Deep Residual Learning for Image Recognition' uses", "\n", "# padding='VALID' for pool1. You can switch to that choice by setting", "\n", "# slim.arg_scope([slim.max_pool2d], padding='VALID').", "\n", "      ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "max_pool2d", "]", ",", "padding", "=", "'SAME'", ")", "as", "arg_sc", ":", "\n", "        ", "return", "arg_sc", "\n", "", "", "", "", ""]]}