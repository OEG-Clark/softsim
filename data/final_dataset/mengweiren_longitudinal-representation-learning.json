{"home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.mains.train_conseg.one_iter_run": [[107, 166], ["data[].size", "time.time", "time.time", "model.set_input", "model.optimize_parameters", "time.time", "len", "torch.cuda.synchronize", "print", "model.data_dependent_initialize", "model.setup", "model.parallelize", "model.train", "print", "model.freeze_bn", "len", "torch.cuda.synchronize", "len", "torch.cuda.empty_cache", "model.visualizer.display_current_results", "model.get_current_losses", "model.visualizer.print_current_losses", "model.visualizer.plot_current_losses", "model.visualizer.writer.add_scalar", "print", "print", "model.save_networks", "print", "data.keys", "model.get_current_visuals", "time.time"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.set_input", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.optimize_parameters", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.data_dependent_initialize", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.setup", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.parallelize", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.train", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.freeze_bn", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.Visualizer.display_current_results", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.get_current_losses", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.Visualizer.print_current_losses", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.Visualizer.plot_current_losses", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.save_networks", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.get_current_visuals"], ["def", "one_iter_run", "(", "data", ",", "i", ")", ":", "\n", "\n", "    ", "batch_size", "=", "data", "[", "\"A\"", "]", ".", "size", "(", "0", ")", "\n", "iter_start_time", "=", "time", ".", "time", "(", ")", "# timer for computation per iteration", "\n", "global", "total_iters", ",", "epoch_iter", ",", "last_eval_loss", ",", "best_evaluation_loss", ",", "iter_data_time", ",", "optimize_time", "\n", "if", "total_iters", "%", "opt", ".", "print_freq", "==", "0", ":", "\n", "        ", "t_data", "=", "iter_start_time", "-", "iter_data_time", "\n", "\n", "", "total_iters", "+=", "batch_size", "\n", "epoch_iter", "+=", "batch_size", "\n", "if", "len", "(", "opt", ".", "gpu_ids", ")", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "", "optimize_start_time", "=", "time", ".", "time", "(", ")", "\n", "if", "epoch", "==", "opt", ".", "epoch_count", "and", "i", "==", "0", ":", "\n", "        ", "print", "(", "'data dependent initialize'", ",", "data", ".", "keys", "(", ")", ")", "\n", "model", ".", "data_dependent_initialize", "(", "data", ")", "\n", "model", ".", "setup", "(", "opt", ")", "# regular setup: load and print networks; create schedulers", "\n", "model", ".", "parallelize", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "\n", "\n", "", "verbose", "=", "(", "total_iters", "%", "opt", ".", "evaluation_freq", "==", "0", ")", "# print out sample information every 1k iters", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "f'Start of iters [{total_iters}]'", ")", "\n", "\n", "", "if", "opt", ".", "freeze_bn", ":", "\n", "        ", "model", ".", "freeze_bn", "(", "verbose", ")", "\n", "\n", "", "model", ".", "set_input", "(", "data", ",", "False", ")", "# unpack data from dataset and apply preprocessing", "\n", "model", ".", "optimize_parameters", "(", "total_iters", ")", "# calculate loss functions, get gradients, update network weights", "\n", "if", "len", "(", "opt", ".", "gpu_ids", ")", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "", "del", "data", "\n", "if", "len", "(", "opt", ".", "gpu_ids", ")", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "optimize_time", "=", "(", "time", ".", "time", "(", ")", "-", "optimize_start_time", ")", "/", "batch_size", "*", "0.005", "+", "0.995", "*", "optimize_time", "\n", "if", "total_iters", "%", "opt", ".", "display_freq", "==", "0", ":", "# display images on visdom and save images to a HTML file", "\n", "        ", "model", ".", "visualizer", ".", "display_current_results", "(", "model", ".", "get_current_visuals", "(", ")", ",", "total_iters", ",", "board_name", "=", "'train'", ")", "\n", "\n", "\n", "", "if", "total_iters", "%", "opt", ".", "print_freq", "==", "0", ":", "# print training losses and save logging information to the disk", "\n", "        ", "losses", "=", "model", ".", "get_current_losses", "(", ")", "\n", "model", ".", "visualizer", ".", "print_current_losses", "(", "total_iters", ",", "epoch", ",", "epoch_iter", ",", "losses", ",", "optimize_time", ",", "t_data", ")", "\n", "model", ".", "visualizer", ".", "plot_current_losses", "(", "total_iters", ",", "losses", ")", "\n", "model", ".", "visualizer", ".", "writer", ".", "add_scalar", "(", "'learning_rate'", ",", "model", ".", "optimizers", "[", "0", "]", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "total_iters", ")", "\n", "\n", "", "if", "total_iters", "%", "opt", ".", "save_latest_freq", "==", "0", ":", "# cache our latest model every <save_latest_freq> iterations", "\n", "        ", "print", "(", "'saving the latest model (epoch %d, total_iters %d)'", "%", "(", "epoch", ",", "total_iters", ")", ")", "\n", "print", "(", "opt", ".", "name", ")", "# it's useful to occasionally show the experiment name on console", "\n", "save_suffix", "=", "'iter_%d'", "%", "total_iters", "if", "opt", ".", "save_by_iter", "else", "'latest'", "\n", "model", ".", "save_networks", "(", "save_suffix", ")", "\n", "\n", "", "iter_data_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "f'End of iters [{total_iters}]'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.Visualizer.__init__": [[32, 51], ["os.path.join", "tensorboardX.SummaryWriter", "print", "os.path.join", "open", "time.strftime", "time.strftime", "time.strftime", "time.strftime", "log_file.write", "numpy.random.randint"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "if", "opt", ".", "display_id", "is", "None", ":", "\n", "            ", "self", ".", "display_id", "=", "np", ".", "random", ".", "randint", "(", "100000", ")", "*", "10", "# just a random display id", "\n", "", "else", ":", "\n", "            ", "self", ".", "display_id", "=", "opt", ".", "display_id", "\n", "", "self", ".", "name", "=", "opt", ".", "name", "\n", "self", ".", "port", "=", "opt", ".", "display_port", "\n", "self", ".", "ncols", "=", "opt", ".", "display_ncols", "\n", "import", "tensorboardX", "\n", "self", ".", "dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "\n", "self", ".", "writer", "=", "tensorboardX", ".", "SummaryWriter", "(", "self", ".", "dir", ")", "\n", "#self.create_tensorboard_connections()", "\n", "print", "(", "f'creating tensorboard at {self.dir}'", ")", "\n", "# create a logging file to store training losses", "\n", "self", ".", "log_name", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ",", "'loss_log.txt'", ")", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "now", "=", "time", ".", "strftime", "(", "\"%c\"", ")", "\n", "log_file", ".", "write", "(", "'================ Training Loss (%s) ================\\n'", "%", "now", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.Visualizer.create_tensorboard_connections": [[52, 55], ["os.system"], "methods", ["None"], ["", "", "def", "create_tensorboard_connections", "(", "self", ")", ":", "\n", "        ", "cmd", "=", "'tensorboard --logdir {0} --port {1}'", ".", "format", "(", "self", ".", "opt", ".", "checkpoints_dir", ",", "self", ".", "port", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.Visualizer.display_current_results": [[56, 78], ["visuals.items", "visualization.tensorboard_vis", "visuals.item", "visualization.tensor2img", "images.append", "titles.append", "visualization.tensor2img", "visualization.Visualizer.writer.add_image", "data.data_utils.renormalize_img"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.tensorboard_vis", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.tensor2img", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.tensor2img", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.data_utils.renormalize_img"], ["", "def", "display_current_results", "(", "self", ",", "visuals", ",", "epoch", ",", "board_name", "=", "'images'", ")", ":", "\n", "        ", "\"\"\"Display current results on tensorboard;.\n\n        Parameters:\n            visuals (OrderedDict) - - dictionary of images to display or save\n            epoch (int) - - the current epoch\n        \"\"\"", "\n", "ncols", "=", "self", ".", "ncols", "\n", "if", "ncols", ">", "0", ":", "# show all the images in one panel", "\n", "            ", "images", "=", "[", "]", "\n", "titles", "=", "[", "]", "\n", "for", "label", ",", "image", "in", "visuals", ".", "items", "(", ")", ":", "\n", "                ", "if", "image", "is", "None", ":", "continue", "\n", "image_numpy", "=", "tensor2img", "(", "image", ",", "self", ".", "opt", ".", "display_slice", ")", "\n", "images", ".", "append", "(", "image_numpy", ")", "\n", "titles", ".", "append", "(", "label", ")", "\n", "", "tensorboard_vis", "(", "self", ".", "writer", ",", "epoch", ",", "board_name", ",", "images", ",", "self", ".", "ncols", ",", "cmaps", "=", "'gist_gray'", ",", "titles", "=", "titles", ")", "\n", "", "else", ":", "\n", "            ", "for", "label", ",", "image", "in", "visuals", ".", "item", "(", ")", ":", "\n", "                ", "image_numpy", "=", "tensor2img", "(", "image", ",", "self", ".", "opt", ".", "display_slice", ")", "\n", "self", ".", "writer", ".", "add_image", "(", "board_name", "+", "'/'", "+", "label", ",", "renormalize_img", "(", "image_numpy", ")", ",", "\n", "epoch", ",", "dataformats", "=", "'HW'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.Visualizer.plot_current_losses": [[79, 94], ["losses.items", "len", "list", "visualization.Visualizer.writer.add_scalar", "losses.keys"], "methods", ["None"], ["", "", "", "def", "plot_current_losses", "(", "self", ",", "epoch", ",", "losses", ")", ":", "\n", "        ", "\"\"\"display the current losses on tensorboard: dictionary of error labels and values\n\n        Parameters:\n            epoch (int)           -- current epoch\n            counter_ratio (float) -- progress (percentage) in the current epoch, between 0 to 1\n            losses (OrderedDict)  -- training losses stored in the format of (name, float) pairs\n        \"\"\"", "\n", "if", "len", "(", "losses", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "plot_name", "=", "'_'", ".", "join", "(", "list", "(", "losses", ".", "keys", "(", ")", ")", ")", "\n", "for", "name", ",", "loss", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "if", "loss", "==", "0", ":", "\n", "                ", "continue", "\n", "", "self", ".", "writer", ".", "add_scalar", "(", "'loss/'", "+", "name", ",", "loss", ",", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.Visualizer.print_current_losses": [[96, 113], ["losses.items", "print", "open", "log_file.write"], "methods", ["None"], ["", "", "def", "print_current_losses", "(", "self", ",", "total_iters", ",", "epoch", ",", "iters", ",", "losses", ",", "t_comp", ",", "t_data", ")", ":", "\n", "        ", "\"\"\"print current losses on console; also save the losses to the disk\n\n        Parameters:\n            epoch (int) -- current epoch\n            iters (int) -- current training iteration during this epoch (reset to 0 at the end of every epoch)\n            losses (OrderedDict) -- training losses stored in the format of (name, float) pairs\n            t_comp (float) -- computational time per data point (normalized by batch_size)\n            t_data (float) -- data loading time per data point (normalized by batch_size)\n        \"\"\"", "\n", "message", "=", "'[Total iters: %d] (epoch: %d, iters: %d, time: %.3f, data: %.3f) '", "%", "(", "total_iters", ",", "epoch", ",", "iters", ",", "t_comp", ",", "t_data", ")", "\n", "for", "k", ",", "v", "in", "losses", ".", "items", "(", ")", ":", "\n", "            ", "message", "+=", "'%s: %f '", "%", "(", "k", ",", "v", ")", "\n", "\n", "", "print", "(", "message", ")", "# print the message", "\n", "with", "open", "(", "self", ".", "log_name", ",", "\"a\"", ")", "as", "log_file", ":", "\n", "            ", "log_file", ".", "write", "(", "'%s\\n'", "%", "message", ")", "# save the message", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.get_random_color": [[12, 14], ["random.uniform"], "function", ["None"], ["def", "get_random_color", "(", "pastel_factor", "=", "0.5", ")", ":", "\n", "    ", "return", "[", "(", "x", "+", "pastel_factor", ")", "/", "(", "1.0", "+", "pastel_factor", ")", "for", "x", "in", "[", "random", ".", "uniform", "(", "0", ",", "1.0", ")", "for", "i", "in", "[", "1", ",", "2", ",", "3", "]", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.color_distance": [[15, 17], ["sum", "abs", "zip"], "function", ["None"], ["", "def", "color_distance", "(", "c1", ",", "c2", ")", ":", "\n", "    ", "return", "sum", "(", "[", "abs", "(", "x", "[", "0", "]", "-", "x", "[", "1", "]", ")", "for", "x", "in", "zip", "(", "c1", ",", "c2", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.generate_new_color": [[18, 30], ["range", "visualization.get_random_color", "min", "visualization.color_distance"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.get_random_color", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.color_distance"], ["", "def", "generate_new_color", "(", "existing_colors", ",", "pastel_factor", "=", "0.5", ")", ":", "\n", "    ", "max_distance", "=", "None", "\n", "best_color", "=", "None", "\n", "for", "i", "in", "range", "(", "0", ",", "100", ")", ":", "\n", "        ", "color", "=", "get_random_color", "(", "pastel_factor", "=", "pastel_factor", ")", "\n", "if", "not", "existing_colors", ":", "\n", "            ", "return", "color", "\n", "", "best_distance", "=", "min", "(", "[", "color_distance", "(", "color", ",", "c", ")", "for", "c", "in", "existing_colors", "]", ")", "\n", "if", "not", "max_distance", "or", "best_distance", ">", "max_distance", ":", "\n", "            ", "max_distance", "=", "best_distance", "\n", "best_color", "=", "color", "\n", "", "", "return", "best_color", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.tensorboard_vis": [[115, 147], ["len", "matplotlib.figure", "int", "print", "range", "summarywriter.add_figure", "numpy.ceil", "matplotlib.subplot", "isinstance", "tmp.min", "tmp.max", "print", "plt.subplot.imshow", "matplotlib.title", "matplotlib.axis"], "function", ["None"], ["", "", "", "def", "tensorboard_vis", "(", "summarywriter", ",", "step", ",", "board_name", ",", "img_list", ",", "num_row", ",", "cmaps", ",", "titles", ",", "resize", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    :param summarywriter: tensorboard summary writer handle\n    :param step:\n    :param board_name: display name\n    :param img_list: a list of images to show\n    :param num_row: specify the number of row\n    :param cmaps: specify color maps for each image ('gray' for MRI, i.e.)\n    :param titles: specify each image title\n    :param resize: whether resize the image to show\n    :return:\n    \"\"\"", "\n", "num_figs", "=", "len", "(", "img_list", ")", "\n", "if", "num_figs", "==", "0", ":", "\n", "        ", "return", "summarywriter", "\n", "", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "num_col", "=", "int", "(", "np", ".", "ceil", "(", "num_figs", "/", "num_row", ")", ")", "\n", "print", "(", "'Visualizing %d images in %d row %d column'", "%", "(", "num_figs", ",", "num_row", ",", "num_col", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_figs", ")", ":", "\n", "        ", "ax", "=", "plt", ".", "subplot", "(", "num_row", ",", "num_col", ",", "i", "+", "1", ")", "\n", "tmp", "=", "img_list", "[", "i", "]", "\n", "if", "isinstance", "(", "cmaps", ",", "str", ")", ":", "c", "=", "cmaps", "\n", "else", ":", "c", "=", "cmaps", "[", "i", "]", "\n", "\n", "vmin", "=", "tmp", ".", "min", "(", ")", "\n", "vmax", "=", "tmp", ".", "max", "(", ")", "\n", "print", "(", "titles", "[", "i", "]", ",", "vmin", ",", "vmax", ")", "\n", "ax", ".", "imshow", "(", "tmp", ",", "cmap", "=", "c", ",", "vmin", "=", "vmin", ",", "vmax", "=", "vmax", ")", ",", "plt", ".", "title", "(", "titles", "[", "i", "]", ")", ",", "plt", ".", "axis", "(", "'off'", ")", "\n", "\n", "", "summarywriter", ".", "add_figure", "(", "board_name", ",", "fig", ",", "step", ")", "\n", "return", "summarywriter", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.tensor2img": [[148, 162], ["torch.no_grad", "len", "tensor.size", "tensor[].detach().cpu().numpy", "len", "tensor[].detach().cpu().numpy", "int", "tensor[].detach().cpu().numpy", "tensor.size", "tensor[].detach().cpu", "tensor[].detach().cpu", "tensor.size", "tensor[].detach().cpu", "tensor[].detach", "tensor[].detach", "tensor[].detach"], "function", ["None"], ["", "def", "tensor2img", "(", "tensor", ",", "slc", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "if", "len", "(", "tensor", ".", "size", "(", ")", ")", "==", "5", ":", "# input is 3D volume, sample one slice for visualization purpose", "\n", "            ", "try", ":", "\n", "                ", "x", "=", "tensor", "[", "0", ",", "0", ",", "slc", ",", "...", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "except", ":", "\n", "                ", "slc", "=", "int", "(", "tensor", ".", "size", "(", "2", ")", "/", "2", ")", "\n", "x", "=", "tensor", "[", "0", ",", "0", ",", "slc", ",", "...", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "", "elif", "len", "(", "tensor", ".", "size", "(", ")", ")", "==", "4", ":", "\n", "            ", "x", "=", "tensor", "[", "0", ",", "0", ",", "...", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.vis_slc": [[163, 175], ["torch.no_grad", "zip", "tf_writer.add_image", "len", "x[].detach().cpu().numpy", "data.data_utils.renormalize_img", "x[].detach().cpu().numpy.size", "len", "x[].detach().cpu().numpy", "x[].detach().cpu", "x[].detach().cpu().numpy.size", "len", "x[].detach().cpu().numpy", "x[].detach().cpu", "x[].detach().cpu().numpy.size", "x[].detach", "x[].detach().cpu", "x[].detach", "x[].detach"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.data_utils.renormalize_img"], ["", "", "def", "vis_slc", "(", "tf_writer", ",", "board_name", ",", "tensor_list", ",", "tensor_names", ",", "slc", ",", "step", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "x", ",", "name", "in", "zip", "(", "tensor_list", ",", "tensor_names", ")", ":", "\n", "            ", "if", "len", "(", "x", ".", "size", "(", ")", ")", "==", "5", ":", "\n", "                ", "x", "=", "x", "[", "0", ",", "0", ",", "...", ",", "slc", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "elif", "len", "(", "x", ".", "size", "(", ")", ")", "==", "4", ":", "\n", "                ", "x", "=", "x", "[", "slc", ",", "0", ",", "...", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "elif", "len", "(", "x", ".", "size", "(", ")", ")", "==", "3", ":", "\n", "                ", "x", "=", "x", "[", "0", ",", "...", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "tf_writer", ".", "add_image", "(", "board_name", "+", "'/'", "+", "name", ",", "renormalize_img", "(", "x", ",", "name", ")", ",", "step", ",", "dataformats", "=", "'HW'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.make_axes": [[177, 180], ["None"], "function", ["None"], ["", "", "", "def", "make_axes", "(", "sx", ",", "sy", ",", "sz", ")", ":", "\n", "    ", "axes", "=", "{", "'ax'", ":", "(", "0", ",", "sz", ")", ",", "'sag'", ":", "(", "2", ",", "sx", ")", ",", "'cor'", ":", "(", "1", ",", "sy", ")", "}", "#sitk/np", "\n", "return", "axes", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.take_slice_from_vol": [[181, 194], ["visualization.make_axes", "SimpleITK.GetArrayFromImage", "print", "numpy.take", "SimpleITK.ReadImage", "print", "numpy.flip"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.make_axes"], ["", "def", "take_slice_from_vol", "(", "file_path", ",", "view", ",", "sx", ",", "sy", ",", "sz", ",", "sqrt_pad", "=", "False", ",", "psize", "=", "-", "1", ")", ":", "\n", "    ", "axes", "=", "make_axes", "(", "sx", ",", "sy", ",", "sz", ")", "\n", "transpose", "=", "False", "\n", "flip", "=", "False", "\n", "#if file_path.endswith('.nii.gz'):", "\n", "vol", "=", "sitk", ".", "GetArrayFromImage", "(", "sitk", ".", "ReadImage", "(", "file_path", ")", ")", "\n", "ax", "=", "axes", "[", "view", "]", "\n", "print", "(", "vol", ".", "shape", ")", "\n", "slice", "=", "np", ".", "take", "(", "vol", ",", "ax", "[", "1", "]", ",", "axis", "=", "ax", "[", "0", "]", ")", "\n", "if", "flip", ":", "\n", "        ", "print", "(", "'Flip image'", ")", "\n", "slice", "=", "np", ".", "flip", "(", "slice", ",", "0", ")", "\n", "", "return", "slice", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.colorbar_wrapper": [[196, 207], ["matplotlib.gca", "make_axes_locatable", "make_axes_locatable.append_axes", "fig.colorbar", "matplotlib.sca"], "function", ["None"], ["", "def", "colorbar_wrapper", "(", "mappable", ")", ":", "\n", "    ", "from", "mpl_toolkits", ".", "axes_grid1", "import", "make_axes_locatable", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "last_axes", "=", "plt", ".", "gca", "(", ")", "\n", "ax", "=", "mappable", ".", "axes", "\n", "fig", "=", "ax", ".", "figure", "\n", "divider", "=", "make_axes_locatable", "(", "ax", ")", "\n", "cax", "=", "divider", ".", "append_axes", "(", "\"right\"", ",", "size", "=", "\"5%\"", ",", "pad", "=", "0.05", ")", "\n", "cbar", "=", "fig", ".", "colorbar", "(", "mappable", ",", "cax", "=", "cax", ")", "\n", "plt", ".", "sca", "(", "last_axes", ")", "\n", "return", "cbar", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.create_group_fig": [[209, 303], ["len", "int", "matplotlib.subplots", "range", "int", "numpy.ceil", "print", "print", "matplotlib.sca", "isinstance", "matplotlib.imshow", "matplotlib.axis", "matplotlib.subplots_adjust", "fig.suptitle", "time.time", "time.time", "matplotlib.savefig", "time.time", "time.time", "numpy.sqrt", "str", "exposure.adjust_gamma", "isinstance", "print", "matplotlib.title", "visualization.colorbar_wrapper", "print", "range", "tmp.min", "tmp.max", "len", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.visualization.colorbar_wrapper"], ["", "def", "create_group_fig", "(", "img_list", ",", "cmaps", ",", "titles", "=", "None", ",", "annot", "=", "None", ",", "save_name", "=", "None", ",", "fig_size", "=", "None", ",", "num_row", "=", "None", ",", "\n", "vmin", "=", "None", ",", "vmax", "=", "None", ",", "colorbar", "=", "False", ",", "suptitle", "=", "None", ",", "\n", "dpi", "=", "100", ",", "format", "=", "'eps'", ",", "zoom", "=", "False", ",", "gamma_correction", "=", "1", ",", "verbose", "=", "True", ",", "fontsize", "=", "16", ",", "adjust", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    :param img_list: a list of images to show\n    :param cmaps: specify color maps for each image ('gray' for MRI, i.e.)\n    :param num_row: specify the number of row\n    :param titles: specify each image title\n    :return:\n    \"\"\"", "\n", "num_figs", "=", "len", "(", "img_list", ")", "\n", "if", "num_row", "is", "None", ":", "\n", "        ", "num_row", "=", "int", "(", "np", ".", "sqrt", "(", "num_figs", ")", ")", "\n", "", "num_col", "=", "int", "(", "np", ".", "ceil", "(", "num_figs", "/", "num_row", ")", ")", "\n", "\n", "if", "zoom", "and", "num_row", "==", "1", ":", "\n", "        ", "num_row", "*=", "2", "\n", "\n", "", "if", "fig_size", "is", "None", ":", "\n", "        ", "h", ",", "w", "=", "img_list", "[", "0", "]", ".", "shape", "[", ":", "2", "]", "\n", "fig_size", "=", "[", "w", "*", "num_col", "/", "50.", ",", "h", "*", "num_row", "/", "50.", "]", "\n", "\n", "", "if", "titles", "is", "None", ":", "\n", "        ", "titles", "=", "[", "str", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "img_list", ")", ")", "]", "\n", "", "plt", ".", "rcParams", "[", "'figure.figsize'", "]", "=", "fig_size", "\n", "#plt.rcParams['font.family'] = 'serif'", "\n", "#plt.rcParams['font.serif'] = ['Times New Roman'] + plt.rcParams['font.serif']", "\n", "plt", ".", "rcParams", "[", "'font.size'", "]", "=", "fontsize", "\n", "# rc('font', **{'family': 'serif', 'serif': ['Computer Modern'], 'size':14})", "\n", "# rc('text', usetex=True)", "\n", "#new_rc_params = {'text.usetex': False,", "\n", "#                 \"svg.fonttype\": 'none'", "\n", "#                 }", "\n", "#plt.rcParams.update(new_rc_params)", "\n", "#fig = plt.figure()", "\n", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "num_row", ",", "num_col", ")", "\n", "#print(axs)", "\n", "if", "num_row", "==", "1", ":", "\n", "        ", "axs", "=", "[", "axs", "]", "\n", "", "if", "num_col", "==", "1", ":", "\n", "        ", "axs", "=", "[", "[", "ax", "]", "for", "ax", "in", "axs", "]", "\n", "#gs = gridspec.GridSpec(num_row,num_col)", "\n", "#gs.update(wspace=0, hspace=0.)", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'Visualizing %d images in %d row %d column'", "%", "(", "num_figs", ",", "num_row", ",", "num_col", ")", ")", "\n", "print", "(", "'Figure size'", ",", "fig_size", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "num_figs", ")", ":", "\n", "        ", "plt", ".", "sca", "(", "axs", "[", "int", "(", "i", "/", "num_col", ")", "]", "[", "int", "(", "i", "%", "num_col", ")", "]", ")", "\n", "if", "isinstance", "(", "cmaps", ",", "str", ")", ":", "\n", "            ", "c", "=", "cmaps", "\n", "", "else", ":", "\n", "            ", "c", "=", "cmaps", "[", "i", "]", "\n", "", "if", "gamma_correction", "!=", "1", "and", "c", "==", "'gist_gray'", ":", "\n", "            ", "from", "skimage", "import", "exposure", "\n", "img_list", "[", "i", "]", "=", "exposure", ".", "adjust_gamma", "(", "img_list", "[", "i", "]", ",", "gamma_correction", ")", "\n", "vmax", "=", "None", "\n", "#plt.subplot(gs[i])#num_row, num_col, i + 1)#", "\n", "", "tmp", "=", "img_list", "[", "i", "]", "\n", "if", "vmax", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "vmax", ",", "list", ")", ":", "v_min", ",", "v_max", "=", "vmin", "[", "i", "]", ",", "vmax", "[", "i", "]", "\n", "else", ":", "v_min", ",", "v_max", "=", "vmin", ",", "vmax", "\n", "", "else", ":", "\n", "            ", "v_min", ",", "v_max", "=", "tmp", ".", "min", "(", ")", ",", "tmp", ".", "max", "(", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "titles", "[", "int", "(", "i", "%", "num_col", ")", "]", ",", "v_min", ",", "v_max", ")", "\n", "", "im", "=", "plt", ".", "imshow", "(", "tmp", ",", "cmap", "=", "c", ",", "vmin", "=", "v_min", ",", "vmax", "=", "v_max", ",", "aspect", "=", "\"equal\"", ")", "#", "\n", "#ax = plt.gca()", "\n", "# if annot[i] is not None:", "\n", "#    ax.text(0.95, 0.9, '%.2f'%annot[i],", "\n", "#            verticalalignment='bottom', horizontalalignment='right',", "\n", "#            transform=ax.transAxes,", "\n", "#            color='white', fontsize=15)", "\n", "if", "titles", "[", "i", "]", "is", "not", "None", ":", "\n", "            ", "plt", ".", "title", "(", "titles", "[", "i", "]", ")", "\n", "", "plt", ".", "axis", "(", "'off'", ")", "\n", "if", "colorbar", ":", "\n", "            ", "colorbar_wrapper", "(", "im", ")", "\n", "", "", "if", "adjust", ":", "\n", "        ", "plt", ".", "subplots_adjust", "(", "wspace", "=", "0", ",", "hspace", "=", "0", ")", "\n", "#plt.tight_layout()", "\n", "", "if", "suptitle", "is", "not", "None", ":", "\n", "        ", "fig", ".", "suptitle", "(", "suptitle", ",", "fontsize", "=", "fontsize", ")", "\n", "", "if", "save_name", ":", "\n", "        ", "s", "=", "time", ".", "time", "(", ")", "\n", "#if dpi:", "\n", "#    plt.savefig(save_name,  format=format, dpi=dpi)", "\n", "#else:", "\n", "plt", ".", "savefig", "(", "save_name", ",", "format", "=", "format", ",", "dpi", "=", "dpi", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "e", "=", "time", ".", "time", "(", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'save figure %s in %.5f seconds'", "%", "(", "save_name", ",", "(", "e", "-", "s", ")", ")", ")", "\n", "\n", "", "", "return", "fig", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.util.str2bool": [[4, 13], ["isinstance", "v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "isinstance", "(", "v", ",", "bool", ")", ":", "\n", "        ", "return", "v", "\n", "", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.util.mkdirs": [[14, 25], ["isinstance", "util.mkdir", "isinstance", "util.mkdir"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.util.mkdir", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.util.mkdir"], ["", "", "def", "mkdirs", "(", "paths", ")", ":", "\n", "    ", "\"\"\"create empty directories if they don't exist\n\n    Parameters:\n        paths (str list) -- a list of directory paths\n    \"\"\"", "\n", "if", "isinstance", "(", "paths", ",", "list", ")", "and", "not", "isinstance", "(", "paths", ",", "str", ")", ":", "\n", "        ", "for", "path", "in", "paths", ":", "\n", "            ", "mkdir", "(", "path", ")", "\n", "", "", "else", ":", "\n", "        ", "mkdir", "(", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.util.mkdir": [[26, 34], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "\"\"\"create a single empty directory if it didn't exist\n\n    Parameters:\n        path (str) -- a single directory path\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.util.save_tensor": [[36, 69], ["os.makedirs", "dict", "data_dict[].cpu().detach().numpy", "print", "print", "np.savez", "print", "data_dict[].cpu().detach", "print", "print", "sitk.WriteImage", "print", "os.path.exists", "os.path.exists", "len", "sitk.GetImageFromArray", "data_dict[].cpu", "f[].transpose", "len", "sitk.GetImageFromArray", "data_dict[].cpu().detach().numpy.transpose"], "function", ["None"], ["", "", "def", "save_tensor", "(", "format", ",", "save_path", ",", "save_name", ",", "data_dict", ",", "override", "=", "True", ")", ":", "\n", "    ", "if", "format", "==", "'npz'", ":", "\n", "        ", "save_dict", "=", "dict", "(", ")", "\n", "import", "numpy", "as", "np", "\n", "", "os", ".", "makedirs", "(", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "for", "k", "in", "data_dict", ":", "\n", "        ", "f", "=", "data_dict", "[", "k", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "if", "format", "==", "'npz'", ":", "\n", "            ", "save_dict", "[", "k", "]", "=", "f", "\n", "print", "(", "f", ".", "shape", ")", "\n", "", "if", "format", "==", "'nii'", ":", "\n", "            ", "save_suffix", "=", "'%s_%s.nii.gz'", "%", "(", "save_name", ",", "k", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path", "+", "save_suffix", ")", "or", "override", ":", "\n", "                ", "import", "SimpleITK", "as", "sitk", "\n", "if", "len", "(", "f", ".", "shape", ")", "==", "5", ":", "\n", "                    ", "img", "=", "sitk", ".", "GetImageFromArray", "(", "f", "[", "0", "]", ".", "transpose", "(", "1", ",", "2", ",", "3", ",", "0", ")", ")", "\n", "", "elif", "len", "(", "f", ".", "shape", ")", "==", "4", ":", "\n", "                    ", "img", "=", "sitk", ".", "GetImageFromArray", "(", "f", ".", "transpose", "(", "1", ",", "2", ",", "3", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "", "print", "(", "'{} Saving nifti {} - Image shape: {}, data type: {}'", ".", "format", "(", "k", ",", "save_suffix", ",", "f", ".", "shape", ",", "f", ".", "dtype", ")", ")", "\n", "print", "(", "save_path", ")", "\n", "sitk", ".", "WriteImage", "(", "img", ",", "save_path", "+", "save_suffix", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'{} exists.'", ".", "format", "(", "save_suffix", ")", ")", "\n", "\n", "\n", "", "", "", "if", "format", "==", "'npz'", ":", "\n", "        ", "print", "(", "'Saving npz...'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path", "+", "'%s.npz'", "%", "save_name", ")", "or", "override", ":", "\n", "            ", "np", ".", "savez", "(", "save_path", "+", "'%s.npz'", "%", "save_name", ",", "**", "save_dict", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'File exists, skip.'", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.ConvBlock.__init__": [[15, 60], ["torch.Module.__init__", "getattr", "getattr.", "torch.ReLU", "torch.ReLU", "torch.ReLU", "getattr", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "getattr", "torch.ELU", "torch.ELU", "torch.ELU", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.SELU", "torch.SELU", "torch.SELU", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ndims", ",", "input_dim", ",", "output_dim", ",", "kernel_size", ",", "stride", ",", "bias", ",", "\n", "padding", "=", "0", ",", "norm", "=", "'none'", ",", "activation", "=", "'relu'", ",", "pad_type", "=", "'zeros'", ")", ":", "\n", "        ", "super", "(", "ConvBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_bias", "=", "bias", "\n", "assert", "ndims", "in", "[", "1", ",", "2", ",", "3", "]", ",", "'ndims should be one of 1, 2, or 3. found: %d'", "%", "ndims", "\n", "Conv", "=", "getattr", "(", "nn", ",", "'Conv%dd'", "%", "ndims", ")", "\n", "# initialize padding", "\n", "#if pad_type == 'reflect':", "\n", "#    self.pad = getattr(nn, 'ReflectionPad%dd'%ndims)(padding)", "\n", "#elif pad_type == 'zero':", "\n", "#    self.pad = getattr(nn, 'ZeroPad%dd'%ndims)(padding)", "\n", "#else:", "\n", "#    assert 0, \"Unsupported padding type: {}\".format(pad_type)", "\n", "\n", "# initialize convolution", "\n", "self", ".", "conv", "=", "Conv", "(", "input_dim", ",", "output_dim", ",", "kernel_size", ",", "stride", ",", "bias", "=", "self", ".", "use_bias", ",", "padding", "=", "padding", ",", "padding_mode", "=", "pad_type", ")", "\n", "\n", "# initialize normalization", "\n", "norm_dim", "=", "output_dim", "\n", "if", "norm", "==", "'batch'", ":", "\n", "            ", "self", ".", "norm", "=", "getattr", "(", "nn", ",", "'BatchNorm%dd'", "%", "ndims", ")", "(", "norm_dim", ")", "\n", "", "elif", "norm", "==", "'instance'", ":", "\n", "            ", "self", ".", "norm", "=", "getattr", "(", "nn", ",", "'InstanceNorm%dd'", "%", "ndims", ")", "(", "norm_dim", ",", "track_running_stats", "=", "False", ")", "\n", "", "elif", "norm", "==", "'none'", ":", "\n", "            ", "self", ".", "norm", "=", "None", "\n", "", "else", ":", "\n", "            ", "assert", "0", ",", "\"Unsupported normalization: {}\"", ".", "format", "(", "norm", ")", "\n", "\n", "# initialize activation", "\n", "", "if", "activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'lrelu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'elu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "ELU", "(", ")", "\n", "", "elif", "activation", "==", "'prelu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "PReLU", "(", ")", "\n", "", "elif", "activation", "==", "'selu'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "SELU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'tanh'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "", "elif", "activation", "==", "'none'", ":", "\n", "            ", "self", ".", "activation", "=", "None", "\n", "", "else", ":", "\n", "            ", "assert", "0", ",", "\"Unsupported activation: {}\"", ".", "format", "(", "activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.ConvBlock.forward": [[62, 69], ["networks.ConvBlock.conv", "networks.ConvBlock.norm", "networks.ConvBlock.activation"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "if", "self", ".", "norm", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "if", "self", ".", "activation", ":", "\n", "            ", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.UnetGeneratorExpand.__init__": [[107, 251], ["torch.Module.__init__", "getattr", "getattr", "networks.get_norm_layer", "networks.get_actvn_layer", "networks.get_actvn_layer", "range", "range", "print", "print", "getattr", "torch.Sequential", "torch.Sequential", "torch.Sequential", "getattr.", "getattr.", "getattr.", "len", "get_norm_layer.", "len", "getattr.", "getattr.", "len", "get_norm_layer.", "len", "getattr.", "len", "torch.Upsample", "torch.Upsample", "torch.Upsample", "getattr.", "len", "get_norm_layer.", "len", "getattr.", "len", "len", "get_norm_layer.", "len", "len", "get_norm_layer.", "len", "getattr.", "len", "get_norm_layer.", "len", "len", "get_norm_layer.", "len"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_actvn_layer", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_actvn_layer"], ["def", "__init__", "(", "self", ",", "dimension", ",", "input_nc", ",", "output_nc", ",", "num_downs", ",", "ngf", "=", "24", ",", "norm", "=", "'batch'", ",", "\n", "final_act", "=", "'none'", ",", "activation", "=", "'relu'", ",", "pad_type", "=", "'reflect'", ",", "doubleconv", "=", "True", ",", "residual_connection", "=", "False", ",", "\n", "pooling", "=", "'Max'", ",", "interp", "=", "'nearest'", ",", "use_skip_connection", "=", "True", ")", ":", "\n", "        ", "\"\"\"Construct a Unet generator\n        Parameters:\n            input_nc (int)  -- the number of channels in input images\n            output_nc (int) -- the number of channels in output images\n            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n                                image of size 128x128 will become of size 1x1 # at the bottleneck\n            ngf (int)       -- the number of filters in the last conv layer\n            norm_layer      -- normalization layer\n            pooling         -- Max or Avg\n            interp          -- 'nearest' or 'trilinear'\n        We construct the U-Net from the innermost layer to the outermost layer.\n        It is a recursive process.\n        \"\"\"", "\n", "super", "(", "UnetGeneratorExpand", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# construct unet structure", "\n", "ndims", "=", "dimension", "\n", "assert", "ndims", "in", "[", "1", ",", "2", ",", "3", "]", ",", "'ndims should be one of 1, 2, or 3. found: %d'", "%", "ndims", "\n", "use_bias", "=", "norm", "==", "'instance'", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "\n", "Conv", "=", "getattr", "(", "nn", ",", "'Conv%dd'", "%", "ndims", ")", "\n", "Pool", "=", "getattr", "(", "nn", ",", "'%sPool%dd'", "%", "(", "pooling", ",", "ndims", ")", ")", "\n", "\n", "# initialize normalization", "\n", "Norm", "=", "get_norm_layer", "(", "ndims", ",", "norm", ")", "\n", "Activation", "=", "get_actvn_layer", "(", "activation", ")", "\n", "FinalActivation", "=", "get_actvn_layer", "(", "final_act", ")", "\n", "\n", "self", ".", "residual_connection", "=", "residual_connection", "\n", "self", ".", "res_dest", "=", "[", "]", "\n", "self", ".", "res_source", "=", "[", "]", "\n", "\n", "model", "=", "[", "Conv", "(", "input_nc", ",", "ngf", ",", "3", ",", "stride", "=", "1", ",", "bias", "=", "use_bias", ",", "padding", "=", "'same'", ",", "padding_mode", "=", "pad_type", ")", "]", "\n", "self", ".", "res_source", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "if", "Norm", "is", "not", "None", ":", "\n", "            ", "model", "+=", "[", "Norm", "(", "ngf", ")", "]", "\n", "\n", "", "if", "Activation", "is", "not", "None", ":", "\n", "            ", "model", "+=", "[", "Activation", "]", "\n", "", "self", ".", "res_dest", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "\n", "# Encoder: downsampling blocks", "\n", "self", ".", "use_skip_connection", "=", "use_skip_connection", "\n", "self", ".", "encoder_idx", "=", "[", "]", "\n", "in_ngf", "=", "ngf", "\n", "for", "i", "in", "range", "(", "num_downs", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "mult", "=", "1", "\n", "", "else", ":", "\n", "                ", "mult", "=", "2", "\n", "", "model", "+=", "[", "Conv", "(", "in_ngf", ",", "in_ngf", "*", "mult", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "bias", "=", "use_bias", ",", "padding", "=", "'same'", ",", "\n", "padding_mode", "=", "pad_type", ")", "]", "\n", "self", ".", "res_source", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "if", "Norm", "is", "not", "None", ":", "\n", "                ", "model", "+=", "[", "Norm", "(", "in_ngf", "*", "mult", ")", "]", "\n", "\n", "", "if", "Activation", "is", "not", "None", ":", "\n", "                ", "model", "+=", "[", "Activation", "]", "\n", "", "self", ".", "res_dest", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "\n", "if", "doubleconv", ":", "\n", "                ", "model", "+=", "[", "Conv", "(", "in_ngf", "*", "mult", ",", "in_ngf", "*", "mult", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "bias", "=", "use_bias", ",", "padding", "=", "'same'", ",", "\n", "padding_mode", "=", "pad_type", ")", "]", "\n", "self", ".", "res_source", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "if", "Norm", "is", "not", "None", ":", "\n", "                    ", "model", "+=", "[", "Norm", "(", "in_ngf", "*", "mult", ")", "]", "\n", "", "if", "Activation", "is", "not", "None", ":", "\n", "                    ", "model", "+=", "[", "Activation", "]", "\n", "", "self", ".", "res_dest", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "\n", "", "self", ".", "encoder_idx", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "model", "+=", "[", "Pool", "(", "2", ")", "]", "\n", "in_ngf", "=", "in_ngf", "*", "mult", "\n", "\n", "\n", "", "model", "+=", "[", "\n", "Conv", "(", "in_ngf", ",", "in_ngf", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "bias", "=", "use_bias", ",", "padding", "=", "'same'", ",", "padding_mode", "=", "pad_type", ")", "]", "\n", "self", ".", "res_source", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "if", "Norm", "is", "not", "None", ":", "\n", "            ", "model", "+=", "[", "Norm", "(", "in_ngf", "*", "2", ")", "]", "\n", "\n", "", "if", "Activation", "is", "not", "None", ":", "\n", "            ", "model", "+=", "[", "Activation", "]", "\n", "", "self", ".", "res_dest", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "\n", "if", "doubleconv", ":", "\n", "#self.conv_id += [len(model)]", "\n", "            ", "model", "+=", "[", "\n", "Conv", "(", "in_ngf", "*", "2", ",", "in_ngf", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "bias", "=", "use_bias", ",", "padding", "=", "'same'", ",", "padding_mode", "=", "pad_type", ")", "]", "\n", "self", ".", "res_source", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "if", "Norm", "is", "not", "None", ":", "\n", "                ", "model", "+=", "[", "Norm", "(", "in_ngf", "*", "2", ")", "]", "\n", "\n", "", "if", "Activation", "is", "not", "None", ":", "\n", "                ", "model", "+=", "[", "Activation", "]", "\n", "", "self", ".", "res_dest", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "\n", "# Decoder", "\n", "", "self", ".", "decoder_idx", "=", "[", "]", "\n", "mult", "=", "2", "**", "(", "num_downs", ")", "\n", "for", "i", "in", "range", "(", "num_downs", ")", ":", "\n", "            ", "self", ".", "decoder_idx", "+=", "[", "len", "(", "model", ")", "]", "\n", "model", "+=", "[", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "interp", ")", "]", "\n", "if", "self", ".", "use_skip_connection", ":", "# concate encoder/decoder feature", "\n", "                ", "m", "=", "mult", "+", "mult", "//", "2", "\n", "", "else", ":", "\n", "                ", "m", "=", "mult", "\n", "#self.conv_id += [len(model)]", "\n", "", "model", "+=", "[", "Conv", "(", "ngf", "*", "m", ",", "ngf", "*", "(", "mult", "//", "2", ")", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "bias", "=", "use_bias", ",", "\n", "padding", "=", "'same'", ",", "padding_mode", "=", "pad_type", ")", "]", "\n", "self", ".", "res_source", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "if", "Norm", "is", "not", "None", ":", "\n", "                ", "model", "+=", "[", "Norm", "(", "ngf", "*", "(", "mult", "//", "2", ")", ")", "]", "\n", "", "if", "Activation", "is", "not", "None", ":", "\n", "                ", "model", "+=", "[", "Activation", "]", "\n", "", "self", ".", "res_dest", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "\n", "if", "doubleconv", ":", "\n", "#self.conv_id += [len(model)]", "\n", "                ", "model", "+=", "[", "Conv", "(", "ngf", "*", "(", "mult", "//", "2", ")", ",", "ngf", "*", "(", "mult", "//", "2", ")", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "bias", "=", "use_bias", ",", "padding", "=", "'same'", ",", "\n", "padding_mode", "=", "pad_type", ")", "]", "\n", "self", ".", "res_source", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "if", "Norm", "is", "not", "None", ":", "\n", "                    ", "model", "+=", "[", "Norm", "(", "ngf", "*", "(", "mult", "//", "2", ")", ")", "]", "\n", "\n", "", "if", "Activation", "is", "not", "None", ":", "\n", "                    ", "model", "+=", "[", "Activation", "]", "\n", "", "self", ".", "res_dest", "+=", "[", "len", "(", "model", ")", "-", "1", "]", "\n", "\n", "", "mult", "=", "mult", "//", "2", "\n", "\n", "", "print", "(", "'Encoder skip connect id'", ",", "self", ".", "encoder_idx", ")", "\n", "print", "(", "'Decoder skip connect id'", ",", "self", ".", "decoder_idx", ")", "\n", "\n", "Conv", "=", "getattr", "(", "nn", ",", "'Conv%dd'", "%", "ndims", ")", "# no weight standardization at output layer ", "\n", "# final conv w/o normalization layer", "\n", "model", "+=", "[", "\n", "Conv", "(", "ngf", "*", "mult", ",", "output_nc", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "bias", "=", "use_bias", ",", "padding", "=", "'same'", ",", "padding_mode", "=", "pad_type", ")", "]", "\n", "if", "FinalActivation", "is", "not", "None", ":", "\n", "            ", "model", "+=", "[", "FinalActivation", "]", "\n", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.UnetGeneratorExpand.forward": [[252, 318], ["layers.append", "len", "dict", "enumerate", "enumerate", "len", "layer", "layer", "print", "feats.append", "torch.cat.size", "torch.cat.size", "torch.cat.size", "print", "dict.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "print", "enc_feats.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "print", "print", "dict.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enc_feats.append", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "enc_feats.pop", "enc_feats.pop", "torch.cat.size", "torch.cat.size", "torch.cat.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "layers", "=", "[", "]", ",", "encode_only", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "-", "1", "in", "layers", ":", "\n", "            ", "layers", ".", "append", "(", "len", "(", "self", ".", "model", ")", ")", "\n", "", "if", "len", "(", "layers", ")", ">", "0", ":", "\n", "            ", "feat", "=", "input", "\n", "feats", "=", "[", "]", "\n", "enc_feats", "=", "[", "]", "\n", "feat_tmp", "=", "dict", "(", ")", "\n", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "self", ".", "model", ")", ":", "\n", "                ", "feat", "=", "layer", "(", "feat", ")", "\n", "#print(layer_id, layer)", "\n", "\n", "if", "verbose", ":", "\n", "                    ", "print", "(", "layer_id", ",", "layer", ".", "__class__", ".", "__name__", ",", "feat", ".", "size", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "residual_connection", "and", "layer_id", "in", "self", ".", "res_source", ":", "\n", "                    ", "feat_tmp", "=", "feat", "\n", "if", "verbose", ":", "\n", "                        ", "print", "(", "'Record skip connection input from %d'", "%", "layer_id", ")", "\n", "\n", "", "", "if", "self", ".", "residual_connection", "and", "layer_id", "in", "self", ".", "res_dest", ":", "\n", "                    ", "assert", "feat_tmp", ".", "size", "(", ")", "==", "feat", ".", "size", "(", ")", "\n", "feat", "=", "feat", "+", "0.1", "*", "feat_tmp", "\n", "if", "verbose", ":", "\n", "                        ", "print", "(", "'Add skip connection input for %d'", "%", "layer_id", ")", "\n", "\n", "", "", "if", "self", ".", "use_skip_connection", ":", "# use encoder/decoder concat ", "\n", "                    ", "if", "layer_id", "in", "self", ".", "encoder_idx", ":", "\n", "                        ", "enc_feats", ".", "append", "(", "feat", ")", "\n", "", "if", "layer_id", "in", "self", ".", "decoder_idx", ":", "\n", "                        ", "feat", "=", "torch", ".", "cat", "(", "(", "enc_feats", ".", "pop", "(", ")", ",", "feat", ")", ",", "dim", "=", "1", ")", "\n", "\n", "\n", "", "", "if", "layer_id", "in", "layers", ":", "\n", "                    ", "if", "verbose", ":", "\n", "                        ", "print", "(", "\"%d: adding the output of %s %d\"", "%", "(", "layer_id", ",", "layer", ".", "__class__", ".", "__name__", ",", "feat", ".", "size", "(", "1", ")", ")", ",", "feat", ".", "size", "(", ")", ")", "\n", "", "feats", ".", "append", "(", "feat", ")", "\n", "", "else", ":", "\n", "                    ", "if", "verbose", ":", "\n", "                        ", "print", "(", "\"%d: skipping %s\"", "%", "(", "layer_id", ",", "layer", ".", "__class__", ".", "__name__", ")", ",", "feat", ".", "size", "(", ")", ")", "\n", "", "pass", "\n", "", "if", "layer_id", "==", "layers", "[", "-", "1", "]", "and", "encode_only", ":", "\n", "                    ", "if", "verbose", ":", "\n", "                        ", "print", "(", "'encoder only return features'", ")", "\n", "", "return", "feats", "# return intermediate features alone; stop in the last layers", "\n", "\n", "", "", "return", "feat", ",", "feats", "# return both output and intermediate features", "\n", "", "else", ":", "\n", "            ", "\"\"\"Standard forward\"\"\"", "\n", "enc_feats", "=", "[", "]", "\n", "feat", "=", "input", "\n", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "self", ".", "model", ")", ":", "\n", "# print(layer_id, layer.__class__.__name__)", "\n", "                ", "feat", "=", "layer", "(", "feat", ")", "\n", "if", "self", ".", "residual_connection", "and", "layer_id", "in", "self", ".", "res_source", ":", "\n", "                    ", "feat_tmp", "=", "feat", "\n", "", "if", "self", ".", "residual_connection", "and", "layer_id", "in", "self", ".", "res_dest", ":", "\n", "                    ", "assert", "feat_tmp", ".", "size", "(", ")", "==", "feat", ".", "size", "(", ")", "\n", "feat", "=", "feat", "+", "0.1", "*", "feat_tmp", "\n", "\n", "", "if", "self", ".", "use_skip_connection", ":", "\n", "                    ", "if", "layer_id", "in", "self", ".", "decoder_idx", ":", "\n", "                        ", "feat", "=", "torch", ".", "cat", "(", "(", "enc_feats", ".", "pop", "(", ")", ",", "feat", ")", ",", "dim", "=", "1", ")", "\n", "", "if", "layer_id", "in", "self", ".", "encoder_idx", ":", "\n", "                        ", "enc_feats", ".", "append", "(", "feat", ")", "\n", "", "", "", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.SingleConv.__init__": [[363, 370], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.ConvBlock"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dimension", ",", "input_nc", ",", "output_nc", ",", "ngf", "=", "24", ",", "norm", "=", "'batch'", ",", "\n", "final_act", "=", "'none'", ",", "activation", "=", "'elu'", ",", "pad_type", "=", "'reflect'", ")", ":", "\n", "        ", "super", "(", "SingleConv", ",", "self", ")", ".", "__init__", "(", ")", "\n", "use_bias", "=", "norm", "==", "'instance'", "\n", "self", ".", "model", "=", "[", "ConvBlock", "(", "dimension", ",", "input_nc", ",", "output_nc", ",", "stride", "=", "1", ",", "kernel_size", "=", "3", ",", "bias", "=", "use_bias", ",", "\n", "padding", "=", "'same'", ",", "norm", "=", "'none'", ",", "activation", "=", "final_act", ",", "pad_type", "=", "pad_type", ")", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.SingleConv.forward": [[371, 373], ["networks.SingleConv.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.Normalize.__init__": [[376, 379], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "power", "=", "2", ")", ":", "\n", "        ", "super", "(", "Normalize", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "power", "=", "power", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.Normalize.forward": [[380, 386], ["x.pow().sum().pow", "x.div", "len", "x.size", "x.size", "x.pow().sum", "x.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "#print('Input before normalization: ', x.min().item(), x.max().item())", "\n", "        ", "assert", "len", "(", "x", ".", "size", "(", ")", ")", "==", "2", ",", "'wrong shape {} for L2-Norm'", ".", "format", "(", "x", ".", "size", "(", ")", ")", "\n", "norm", "=", "x", ".", "pow", "(", "self", ".", "power", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ".", "pow", "(", "1.", "/", "self", ".", "power", ")", "\n", "out", "=", "x", ".", "div", "(", "norm", "+", "1e-7", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.PoolingF.__init__": [[389, 394], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.Normalize", "torch.AdaptiveMaxPool2d", "torch.AdaptiveMaxPool2d", "torch.AdaptiveMaxPool2d"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "PoolingF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "model", "=", "[", "nn", ".", "AdaptiveMaxPool2d", "(", "1", ")", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "self", ".", "l2norm", "=", "Normalize", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.PoolingF.forward": [[395, 397], ["networks.PoolingF.l2norm", "networks.PoolingF.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "l2norm", "(", "self", ".", "model", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.SimSiamPatchSampleF.__init__": [[400, 415], ["torch.Module.__init__", "networks.Normalize", "print"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "use_mlp", "=", "False", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "nc", "=", "256", ",", "gpu_ids", "=", "[", "]", ",", "n_mlps", "=", "2", ",", "position", "=", "False", ",", "activation", "=", "'relu'", ",", "arch", "=", "2", ")", ":", "\n", "# use the same patch_ids for multiple images in the batch", "\n", "        ", "super", "(", "SimSiamPatchSampleF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "l2norm", "=", "Normalize", "(", "2", ")", "\n", "self", ".", "use_mlp", "=", "use_mlp", "\n", "print", "(", "'Use MLP: {}'", ".", "format", "(", "use_mlp", ")", ")", "\n", "self", ".", "nc", "=", "nc", "# hard-coded", "\n", "self", ".", "mlp_init", "=", "False", "\n", "self", ".", "init_type", "=", "init_type", "\n", "self", ".", "init_gain", "=", "init_gain", "\n", "self", ".", "gpu_ids", "=", "gpu_ids", "\n", "self", ".", "n_mlps", "=", "n_mlps", "\n", "self", ".", "position", "=", "position", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "arch", "=", "arch", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.SimSiamPatchSampleF.create_mlp": [[416, 452], ["enumerate", "networks.init_net", "networks.get_norm_layer", "networks.get_actvn_layer", "setattr", "setattr", "print", "print", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential.to", "torch.Sequential.to", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "len", "torch.Sequential.cuda", "torch.Sequential.cuda", "torch.Linear", "torch.Linear", "torch.Linear", "get_norm_layer.", "torch.Linear", "torch.Linear", "torch.Linear", "get_norm_layer.", "torch.Linear", "torch.Linear", "torch.Linear", "get_norm_layer.", "torch.Linear", "torch.Linear", "torch.Linear", "get_norm_layer.", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "get_norm_layer.", "torch.Linear", "torch.Linear", "torch.Linear", "get_norm_layer.", "torch.Linear", "torch.Linear", "torch.Linear", "get_norm_layer.", "torch.Linear", "torch.Linear", "torch.Linear", "get_norm_layer.", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.init_net", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_actvn_layer"], ["", "def", "create_mlp", "(", "self", ",", "feats", ")", ":", "\n", "        ", "for", "mlp_id", ",", "feat", "in", "enumerate", "(", "feats", ")", ":", "\n", "            ", "input_nc", "=", "feat", ".", "shape", "[", "1", "]", "\n", "norm", "=", "get_norm_layer", "(", "1", ",", "'batch'", ")", "\n", "Activation", "=", "get_actvn_layer", "(", "self", ".", "activation", ")", "\n", "\n", "if", "self", ".", "arch", "==", "2", ":", "# turn off bias ", "\n", "                ", "mlp", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Linear", "(", "input_nc", ",", "self", ".", "nc", ",", "bias", "=", "False", ")", ",", "norm", "(", "self", ".", "nc", ")", ",", "Activation", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "nc", ",", "self", ".", "nc", ",", "bias", "=", "False", ")", ",", "norm", "(", "self", ".", "nc", ")", ",", "Activation", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "nc", ",", "self", ".", "nc", ",", "bias", "=", "False", ")", ",", "norm", "(", "self", ".", "nc", ",", "affine", "=", "False", ")", "]", ")", "\n", "pred", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Linear", "(", "self", ".", "nc", ",", "self", ".", "nc", "//", "4", ",", "bias", "=", "False", ")", ",", "norm", "(", "self", ".", "nc", "//", "4", ")", ",", "Activation", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "nc", "//", "4", ",", "self", ".", "nc", ")", "]", ")", "\n", "\n", "", "elif", "self", ".", "arch", "==", "1", ":", "\n", "                ", "mlp", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Linear", "(", "input_nc", ",", "self", ".", "nc", ")", ",", "norm", "(", "self", ".", "nc", ")", ",", "Activation", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "nc", ",", "self", ".", "nc", ")", ",", "norm", "(", "self", ".", "nc", ")", ",", "Activation", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "nc", ",", "self", ".", "nc", ")", ",", "norm", "(", "self", ".", "nc", ")", "]", ")", "\n", "pred", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Linear", "(", "self", ".", "nc", ",", "self", ".", "nc", "//", "4", ")", ",", "norm", "(", "self", ".", "nc", "//", "4", ")", ",", "Activation", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "nc", "//", "4", ",", "self", ".", "nc", ")", "]", ")", "\n", "\n", "\n", "", "if", "self", ".", "gpu_ids", "==", "\"tpu\"", ":", "\n", "                ", "mlp", ".", "to", "(", "\"xla:1\"", ")", "\n", "pred", ".", "to", "(", "\"xla:1\"", ")", "\n", "", "else", ":", "\n", "                ", "if", "len", "(", "self", ".", "gpu_ids", ")", ">", "0", ":", "\n", "                    ", "mlp", ".", "cuda", "(", ")", "\n", "pred", ".", "cuda", "(", ")", "\n", "", "", "setattr", "(", "self", ",", "'mlp_%d'", "%", "mlp_id", ",", "mlp", ")", "\n", "setattr", "(", "self", ",", "'pred_%d'", "%", "mlp_id", ",", "pred", ")", "\n", "\n", "print", "(", "'mlp_%d created, input nc %d'", "%", "(", "mlp_id", ",", "input_nc", ")", ")", "\n", "print", "(", "'pred_%d created, bottleneck nc %d'", "%", "(", "mlp_id", ",", "self", ".", "nc", "//", "4", ")", ")", "\n", "\n", "", "init_net", "(", "self", ",", "self", ".", "init_type", ",", "self", ".", "init_gain", ",", "self", ".", "gpu_ids", ")", "\n", "self", ".", "mlp_init", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.SimSiamPatchSampleF.sample_by_id": [[453, 515], ["len", "x_sample.view.view.size", "x_sample.view.view.permute().flatten", "getattr", "getattr", "getattr.", "getattr.", "x_sample.view.view.view", "x_pred.view.view.view", "print", "print", "print", "feat.size", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "x_sample.view.view.permute", "x_sample.view.view.min().item", "x_sample.view.view.max().item", "print", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "x_sample.view.view.size", "int", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_sample.view.view.min", "x_sample.view.view.max", "len", "x_sample.view.view.size", "min", "select_x.unsqueeze", "select_y.unsqueeze", "select_z.unsqueeze", "len", "x_sample.view.view.size", "select_x.unsqueeze", "select_y.unsqueeze"], "methods", ["None"], ["", "def", "sample_by_id", "(", "self", ",", "feat", ",", "feat_id", ",", "num_patches", ",", "patch_id", "=", "None", ",", "mask_i", "=", "None", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "ndims", "=", "len", "(", "feat", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "if", "num_patches", ">", "0", ":", "\n", "            ", "if", "patch_id", "is", "not", "None", ":", "# sample based on given index", "\n", "                ", "coords", "=", "patch_id", "\n", "# patch_id is a torch tensor (share idx across batch)", "\n", "if", "ndims", "==", "3", ":", "\n", "                    ", "x_sample", "=", "feat", "[", ":", ",", ":", ",", "patch_id", "[", ":", ",", "0", "]", ",", "patch_id", "[", ":", ",", "1", "]", ",", "patch_id", "[", ":", ",", "2", "]", "]", "\n", "", "elif", "ndims", "==", "2", ":", "\n", "                    ", "x_sample", "=", "feat", "[", ":", ",", ":", ",", "patch_id", "[", ":", ",", "0", "]", ",", "patch_id", "[", ":", ",", "1", "]", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "", "if", "verbose", ":", "\n", "                    ", "print", "(", "'Sample basd on given {} idx w/o mask: sample shape: {}'", ".", "format", "(", "len", "(", "patch_id", ")", ",", "x_sample", ".", "size", "(", ")", ")", ")", "\n", "", "", "else", ":", "# sample patch index", "\n", "                ", "fg_coords", "=", "torch", ".", "where", "(", "mask_i", ">", "0", ")", "\n", "if", "ndims", "==", "3", ":", "\n", "                    ", "(", "_", ",", "_", ",", "fg_x", ",", "fg_y", ",", "fg_z", ")", "=", "fg_coords", "\n", "#print('coords', fg_x.size(), fg_y.size(), fg_z.size())", "\n", "", "elif", "ndims", "==", "2", ":", "\n", "                    ", "(", "_", ",", "_", ",", "fg_x", ",", "fg_y", ")", "=", "fg_coords", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "\n", "", "patch_id", "=", "torch", ".", "randperm", "(", "fg_x", ".", "shape", "[", "0", "]", ",", "device", "=", "feat", ".", "device", ")", "\n", "patch_id", "=", "patch_id", "[", ":", "int", "(", "min", "(", "num_patches", ",", "patch_id", ".", "shape", "[", "0", "]", ")", ")", "]", "\n", "\n", "select_x", ",", "select_y", "=", "fg_x", "[", "patch_id", "]", ",", "fg_y", "[", "patch_id", "]", "\n", "if", "ndims", "==", "3", ":", "\n", "                    ", "select_z", "=", "fg_z", "[", "patch_id", "]", "\n", "coords", "=", "torch", ".", "cat", "(", "(", "select_x", ".", "unsqueeze", "(", "1", ")", ",", "select_y", ".", "unsqueeze", "(", "1", ")", ",", "select_z", ".", "unsqueeze", "(", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "x_sample", "=", "feat", "[", ":", ",", ":", ",", "select_x", ",", "select_y", ",", "select_z", "]", "\n", "\n", "", "elif", "ndims", "==", "2", ":", "\n", "                    ", "coords", "=", "torch", ".", "cat", "(", "(", "select_x", ".", "unsqueeze", "(", "1", ")", ",", "select_y", ".", "unsqueeze", "(", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "x_sample", "=", "feat", "[", ":", ",", ":", ",", "select_x", ",", "select_y", "]", "\n", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "\n", "", "if", "verbose", ":", "\n", "                    ", "print", "(", "'Masked sampling, patch_id: {} sample shape: {}'", ".", "format", "(", "len", "(", "patch_id", ")", ",", "x_sample", ".", "size", "(", ")", ")", ")", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "x_sample", "=", "feat", "\n", "coords", "=", "[", "]", "\n", "\n", "", "tps", ",", "nc", ",", "nsample", "=", "x_sample", ".", "size", "(", ")", "\n", "x_sample", "=", "x_sample", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "flatten", "(", "0", ",", "1", ")", "# tps*nsample, nc", "\n", "\n", "mlp", "=", "getattr", "(", "self", ",", "'mlp_%d'", "%", "feat_id", ")", "\n", "pred", "=", "getattr", "(", "self", ",", "'pred_%d'", "%", "feat_id", ")", "\n", "\n", "x_sample", "=", "mlp", "(", "x_sample", ")", "\n", "x_pred", "=", "pred", "(", "x_sample", ")", "\n", "x_sample", "=", "x_sample", ".", "view", "(", "tps", ",", "nsample", ",", "-", "1", ")", "\n", "x_pred", "=", "x_pred", ".", "view", "(", "tps", ",", "nsample", ",", "-", "1", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'MLP + reshape: {}'", ".", "format", "(", "x_sample", ".", "size", "(", ")", ")", ")", "\n", "print", "(", "'feature range '", ",", "feat_id", ",", "x_sample", ".", "min", "(", ")", ".", "item", "(", ")", ",", "x_sample", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "'\\n\\n'", ")", "\n", "", "return", "x_sample", ",", "x_pred", ",", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.SimSiamPatchSampleF.forward": [[517, 614], ["len", "enumerate", "print", "networks.SimSiamPatchSampleF.create_mlp", "x_sample.view.view.size", "x_sample.view.view.permute().flatten", "return_ids.append", "return_feats.append", "feats[].size", "print", "torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.ones().unsqueeze().unsqueeze", "torch.ones().unsqueeze().unsqueeze", "torch.ones().unsqueeze().unsqueeze", "torch.ones().unsqueeze().unsqueeze", "torch.ones().unsqueeze().unsqueeze", "torch.ones().unsqueeze().unsqueeze", "torch.ones().unsqueeze().unsqueeze", "torch.ones().unsqueeze().unsqueeze", "torch.ones().unsqueeze().unsqueeze", "print", "getattr", "getattr", "getattr.", "getattr.", "x_sample.view.view.view", "x_sample.view.view.view", "x_sample.view.view.view", "x_sample.view.view.view", "x_sample.view.view.view", "print", "print", "print", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "x_sample.view.view.permute", "x_sample.view.view.min().item", "x_sample.view.view.max().item", "print", "len", "torch.ones().unsqueeze", "torch.ones().unsqueeze", "torch.ones().unsqueeze", "torch.ones().unsqueeze", "torch.ones().unsqueeze", "torch.ones().unsqueeze", "torch.ones().unsqueeze", "torch.ones().unsqueeze", "torch.ones().unsqueeze", "feat.size", "print", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "x_sample.view.view.size", "position_enc.min", "position_enc.max", "mask.size", "f.size", "int", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_sample.view.view.min", "x_sample.view.view.max", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len", "x_sample.view.view.size", "min", "select_x.unsqueeze", "select_y.unsqueeze", "select_z.unsqueeze", "len", "x_sample.view.view.size", "select_x.unsqueeze", "select_y.unsqueeze", "f.size"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.SimSiamPatchSampleF.create_mlp"], ["", "def", "forward", "(", "self", ",", "feats", ",", "num_patches", "=", "64", ",", "patch_ids", "=", "None", ",", "mask", "=", "None", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "return_ids", "=", "[", "]", "\n", "return_feats", "=", "[", "]", "\n", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "f'Net F forward pass: # features: {len(feats)}'", ")", "\n", "\n", "", "ndims", "=", "len", "(", "feats", "[", "0", "]", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "f'Using foreground mask {mask.size()}'", ")", "\n", "", "masks", "=", "[", "F", ".", "interpolate", "(", "mask", ",", "size", "=", "f", ".", "size", "(", ")", "[", "2", ":", "]", ",", "mode", "=", "'nearest'", ")", "for", "f", "in", "feats", "]", "\n", "", "else", ":", "\n", "            ", "masks", "=", "[", "torch", ".", "ones", "(", "f", ".", "size", "(", ")", "[", "2", ":", "]", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "for", "f", "in", "feats", "]", "\n", "\n", "", "if", "self", ".", "use_mlp", "and", "not", "self", ".", "mlp_init", ":", "\n", "            ", "self", ".", "create_mlp", "(", "feats", ")", "\n", "", "for", "feat_id", ",", "feat", "in", "enumerate", "(", "feats", ")", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "feat_id", ",", "'input -> {}'", ".", "format", "(", "feat", ".", "size", "(", ")", ")", ")", "\n", "", "if", "num_patches", ">", "0", ":", "\n", "                ", "if", "patch_ids", "is", "not", "None", ":", "# sample based on given index", "\n", "                    ", "patch_id", "=", "patch_ids", "[", "feat_id", "]", "\n", "# patch_id is a torch tensor (share idx across batch)", "\n", "if", "ndims", "==", "3", ":", "\n", "                        ", "x_sample", "=", "feat", "[", ":", ",", ":", ",", "patch_id", "[", ":", ",", "0", "]", ",", "patch_id", "[", ":", ",", "1", "]", ",", "patch_id", "[", ":", ",", "2", "]", "]", "\n", "", "elif", "ndims", "==", "2", ":", "\n", "                        ", "x_sample", "=", "feat", "[", ":", ",", ":", ",", "patch_id", "[", ":", ",", "0", "]", ",", "patch_id", "[", ":", ",", "1", "]", "]", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "", "if", "verbose", ":", "\n", "                        ", "print", "(", "'Sample basd on given {} idx w/o mask: sample shape: {}'", ".", "format", "(", "len", "(", "patch_id", ")", ",", "x_sample", ".", "size", "(", ")", ")", ")", "\n", "\n", "", "", "else", ":", "# sample patch index", "\n", "                    ", "mask_i", "=", "masks", "[", "feat_id", "]", "\n", "fg_coords", "=", "torch", ".", "where", "(", "mask_i", ">", "0", ")", "\n", "if", "ndims", "==", "3", ":", "\n", "                        ", "(", "_", ",", "_", ",", "fg_x", ",", "fg_y", ",", "fg_z", ")", "=", "fg_coords", "\n", "", "elif", "ndims", "==", "2", ":", "\n", "                        ", "(", "_", ",", "_", ",", "fg_x", ",", "fg_y", ")", "=", "fg_coords", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "\n", "", "patch_id", "=", "torch", ".", "randperm", "(", "fg_x", ".", "shape", "[", "0", "]", ",", "device", "=", "feats", "[", "0", "]", ".", "device", ")", "\n", "patch_id", "=", "patch_id", "[", ":", "int", "(", "min", "(", "num_patches", ",", "patch_id", ".", "shape", "[", "0", "]", ")", ")", "]", "\n", "\n", "select_x", ",", "select_y", "=", "fg_x", "[", "patch_id", "]", ",", "fg_y", "[", "patch_id", "]", "\n", "if", "ndims", "==", "3", ":", "\n", "                        ", "select_z", "=", "fg_z", "[", "patch_id", "]", "\n", "coords", "=", "torch", ".", "cat", "(", "(", "select_x", ".", "unsqueeze", "(", "1", ")", ",", "select_y", ".", "unsqueeze", "(", "1", ")", ",", "select_z", ".", "unsqueeze", "(", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "x_sample", "=", "feat", "[", ":", ",", ":", ",", "select_x", ",", "select_y", ",", "select_z", "]", "\n", "\n", "", "elif", "ndims", "==", "2", ":", "\n", "                        ", "coords", "=", "torch", ".", "cat", "(", "(", "select_x", ".", "unsqueeze", "(", "1", ")", ",", "select_y", ".", "unsqueeze", "(", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "x_sample", "=", "feat", "[", ":", ",", ":", ",", "select_x", ",", "select_y", "]", "\n", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "\n", "", "if", "verbose", ":", "\n", "                        ", "print", "(", "'Masked sampling, patch_id: {} sample shape: {}'", ".", "format", "(", "len", "(", "patch_id", ")", ",", "x_sample", ".", "size", "(", ")", ")", ")", "\n", "\n", "", "", "", "else", ":", "\n", "                ", "x_sample", "=", "feat", "\n", "coords", "=", "[", "]", "\n", "\n", "", "tps", ",", "nc", ",", "nsample", "=", "x_sample", ".", "size", "(", ")", "\n", "x_sample", "=", "x_sample", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "flatten", "(", "0", ",", "1", ")", "# tps*nsample, nc", "\n", "#print(x_sample.size())", "\n", "return_ids", ".", "append", "(", "coords", ")", "\n", "\n", "\n", "if", "self", ".", "use_mlp", ":", "\n", "                ", "mlp", "=", "getattr", "(", "self", ",", "'mlp_%d'", "%", "feat_id", ")", "\n", "pred", "=", "getattr", "(", "self", ",", "'pred_%d'", "%", "feat_id", ")", "\n", "\n", "x_sample", "=", "mlp", "(", "x_sample", ")", "\n", "x_pred", "=", "pred", "(", "x_sample", ")", "\n", "#x_sample = self.l2norm(x_sample)  # moved l2-norm outside", "\n", "x_sample", "=", "x_sample", ".", "view", "(", "tps", ",", "nsample", ",", "-", "1", ")", "\n", "#x_pred = self.l2norm(x_pred)", "\n", "x_sample", "=", "x_sample", ".", "view", "(", "tps", ",", "nsample", ",", "-", "1", ")", "\n", "x_pred", "=", "x_pred", ".", "view", "(", "tps", ",", "nsample", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "x_sample", "=", "x_sample", ".", "view", "(", "tps", ",", "nsample", ",", "-", "1", ")", "\n", "x_pred", "=", "x_sample", ".", "view", "(", "tps", ",", "nsample", ",", "-", "1", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "                ", "print", "(", "'MLP + reshape: {}'", ".", "format", "(", "x_sample", ".", "size", "(", ")", ")", ")", "\n", "print", "(", "'feature range '", ",", "feat_id", ",", "x_sample", ".", "min", "(", ")", ".", "item", "(", ")", ",", "x_sample", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "if", "self", ".", "position", ":", "\n", "                    ", "print", "(", "'ff feature range '", ",", "position_enc", ".", "min", "(", ")", ",", "position_enc", ".", "max", "(", ")", ")", "\n", "#print('patch id check', coords[:20])", "\n", "", "print", "(", "'\\n\\n'", ")", "\n", "", "return_feats", ".", "append", "(", "(", "x_sample", ",", "x_pred", ")", ")", "\n", "\n", "", "return", "return_feats", ",", "return_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.EarlyStopping.__init__": [[653, 665], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "patience", "=", "5", ",", "min_delta", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        :param patience: how many epochs to wait before stopping when loss is\n               not improving\n        :param min_delta: minimum difference between new loss and old loss for\n               new loss to be considered as an improvement\n        \"\"\"", "\n", "self", ".", "patience", "=", "patience", "\n", "self", ".", "min_delta", "=", "min_delta", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "best_loss", "=", "None", "\n", "self", ".", "early_stop", "=", "False", "\n", "", "def", "__call__", "(", "self", ",", "val_loss", ")", ":", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.EarlyStopping.__call__": [[665, 678], ["print", "print"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "val_loss", ")", ":", "\n", "        ", "if", "self", ".", "best_loss", "==", "None", ":", "\n", "            ", "self", ".", "best_loss", "=", "val_loss", "\n", "", "elif", "self", ".", "best_loss", "-", "val_loss", ">", "self", ".", "min_delta", ":", "\n", "            ", "self", ".", "best_loss", "=", "val_loss", "\n", "# reset counter if validation loss improves", "\n", "self", ".", "counter", "=", "0", "\n", "", "elif", "self", ".", "best_loss", "-", "val_loss", "<", "self", ".", "min_delta", ":", "\n", "            ", "self", ".", "counter", "+=", "1", "\n", "print", "(", "f\"INFO: Early stopping counter {self.counter} of {self.patience}\"", ")", "\n", "if", "self", ".", "counter", ">=", "self", ".", "patience", ":", "\n", "                ", "print", "(", "'INFO: Early stopping'", ")", "\n", "self", ".", "early_stop", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks._CustomDataParallel.__init__": [[742, 744], ["torch.DataParallel.__init__"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", "_CustomDataParallel", ",", "self", ")", ".", "__init__", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks._CustomDataParallel.__getattr__": [[745, 751], ["super().__getattr__", "print", "getattr"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks._CustomDataParallel.__getattr__"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "super", "(", "_CustomDataParallel", ",", "self", ")", ".", "__getattr__", "(", "name", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "print", "(", "name", ")", "\n", "return", "getattr", "(", "self", ".", "module", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.Pairwise_Feature_Similarity.__init__": [[756, 763], ["torch.Module.__init__", "networks.Normalize", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "print"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "l2norm", "=", "Normalize", "(", "2", ")", "\n", "\n", "self", ".", "_cosine_similarity", "=", "torch", ".", "nn", ".", "CosineSimilarity", "(", "dim", "=", "1", ")", "\n", "print", "(", "'Initialized pairwise similarity loss'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.Pairwise_Feature_Similarity.pairwise_cosine_simililarity": [[764, 769], ["networks.Pairwise_Feature_Similarity._cosine_similarity", "x.size", "y.size", "x.size", "y.size"], "methods", ["None"], ["", "def", "pairwise_cosine_simililarity", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "assert", "x", ".", "size", "(", ")", "==", "y", ".", "size", "(", ")", ",", "f'wrong shape {x.size()} and {y.size()}'", "\n", "v", "=", "self", ".", "_cosine_similarity", "(", "x", ",", "y", ")", "#(x.unsqueeze(1), y.unsqueeze(2))", "\n", "\n", "return", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.Pairwise_Feature_Similarity.forward": [[770, 792], ["features.size", "features[].view", "features[].view", "networks.Pairwise_Feature_Similarity.pairwise_cosine_simililarity", "networks.Pairwise_Feature_Similarity.sum"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.Pairwise_Feature_Similarity.pairwise_cosine_simililarity"], ["", "def", "forward", "(", "self", ",", "features", ",", "labels_age", ",", "labels_subjid", ",", "labels_coords", ",", "coords_range", ",", "debug", "=", "False", ")", ":", "\n", "        ", "'''\n        :param feats:  bs*2, num_patches, nc_feature\n        :param labels_age: bs*2 -> currently not consider age\n        :param labels_subjid: bs*2\n        :return:\n        '''", "\n", "bs2", ",", "num_patches", ",", "nc", "=", "features", ".", "size", "(", ")", "\n", "#print(features.size())", "\n", "\n", "bs", "=", "bs2", "//", "2", "\n", "feat_A", "=", "features", "[", ":", "bs", ",", "...", "]", ".", "view", "(", "bs", "*", "num_patches", ",", "nc", ")", "\n", "feat_B", "=", "features", "[", "bs", ":", ",", "...", "]", ".", "view", "(", "bs", "*", "num_patches", ",", "nc", ")", "\n", "\n", "#age_A = labels_age[:bs, ...].unsqueeze(1).repeat(1, num_patches).view(-1).float()", "\n", "#age_B = labels_age[bs:, ...].unsqueeze(1).repeat(1, num_patches).view(-1).float()", "\n", "\n", "device", "=", "features", ".", "device", "\n", "#weight = torch.ones(bs*num_patches).to(device)", "\n", "sim_pos", "=", "self", ".", "pairwise_cosine_simililarity", "(", "feat_A", ",", "feat_B", ")", "\n", "loss", "=", "-", "(", "sim_pos", ")", ".", "sum", "(", ")", "/", "(", "num_patches", "*", "bs", ")", "# negative cosine similarity", "\n", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_norm_layer": [[71, 81], ["getattr", "getattr"], "function", ["None"], ["", "", "def", "get_norm_layer", "(", "ndims", ",", "norm", "=", "'batch'", ")", ":", "\n", "    ", "if", "norm", "==", "'batch'", ":", "\n", "        ", "Norm", "=", "getattr", "(", "nn", ",", "'BatchNorm%dd'", "%", "ndims", ")", "\n", "", "elif", "norm", "==", "'instance'", ":", "\n", "        ", "Norm", "=", "getattr", "(", "nn", ",", "'InstanceNorm%dd'", "%", "ndims", ")", "\n", "", "elif", "norm", "==", "'none'", ":", "\n", "        ", "Norm", "=", "None", "\n", "", "else", ":", "\n", "        ", "assert", "0", ",", "\"Unsupported normalization: {}\"", ".", "format", "(", "norm", ")", "\n", "", "return", "Norm", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_actvn_layer": [[82, 100], ["torch.ReLU", "torch.LeakyReLU", "torch.ELU", "torch.PReLU", "torch.SELU", "torch.Tanh"], "function", ["None"], ["", "def", "get_actvn_layer", "(", "activation", "=", "'relu'", ")", ":", "\n", "    ", "if", "activation", "==", "'relu'", ":", "\n", "        ", "Activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'lrelu'", ":", "\n", "        ", "Activation", "=", "nn", ".", "LeakyReLU", "(", "0.3", ",", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'elu'", ":", "\n", "        ", "Activation", "=", "nn", ".", "ELU", "(", ")", "\n", "", "elif", "activation", "==", "'prelu'", ":", "\n", "        ", "Activation", "=", "nn", ".", "PReLU", "(", ")", "\n", "", "elif", "activation", "==", "'selu'", ":", "\n", "        ", "Activation", "=", "nn", ".", "SELU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "activation", "==", "'tanh'", ":", "\n", "        ", "Activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "", "elif", "activation", "==", "'none'", ":", "\n", "        ", "Activation", "=", "None", "\n", "", "else", ":", "\n", "        ", "assert", "0", ",", "\"Unsupported activation: {}\"", ".", "format", "(", "activation", ")", "\n", "", "return", "Activation", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.define_G": [[321, 352], ["networks.init_net", "networks.UnetGeneratorExpand", "networks.SingleConv", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.init_net"], ["", "", "", "def", "define_G", "(", "dimension", ",", "input_nc", ",", "output_nc", ",", "ngf", ",", "netG", ",", "norm", "=", "'batch'", ",", "use_dropout", "=", "False", ",", "init_type", "=", "'normal'", ",", "\n", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ",", "opt", "=", "None", ",", "final_act", "=", "'none'", ",", "activation", "=", "'relu'", ",", "\n", "pooling", "=", "'Max'", ",", "interp", "=", "'nearest'", ")", ":", "\n", "    ", "\"\"\"Create a generator\n\n    Parameters:\n        input_nc (int) -- the number of channels in input images\n        output_nc (int) -- the number of channels in output images\n        ngf (int) -- the number of filters in the last conv layer\n        netG (str) -- the architecture's name: resnet_9blocks | resnet_6blocks | unet_256 | unet_128\n        norm (str) -- the name of normalization layers used in the network: batch | instance | none\n        use_dropout (bool) -- if use dropout layers.\n        init_type (str)    -- the name of our initialization method.\n        init_gain (float)  -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Returns a generator\n    The generator has been initialized by <init_net>. It uses RELU for non-linearity.\n    \"\"\"", "\n", "net", "=", "None", "\n", "\n", "if", "netG", "==", "'unet'", ":", "\n", "# UnetGeneratorExpand uses one list for all layers, which is more flexible for PatchSim index", "\n", "        ", "net", "=", "UnetGeneratorExpand", "(", "dimension", ",", "input_nc", ",", "output_nc", ",", "num_downs", "=", "4", ",", "ngf", "=", "ngf", ",", "norm", "=", "norm", ",", "activation", "=", "activation", ",", "\n", "final_act", "=", "final_act", ",", "pad_type", "=", "'reflect'", ",", "doubleconv", "=", "True", ",", "residual_connection", "=", "False", ",", "use_skip_connection", "=", "True", ",", "\n", "pooling", "=", "pooling", ",", "interp", "=", "interp", ")", "\n", "", "elif", "netG", "==", "'conv'", ":", "\n", "        ", "net", "=", "SingleConv", "(", "dimension", ",", "input_nc", ",", "output_nc", ",", "ngf", ",", "norm", "=", "norm", ",", "final_act", "=", "'none'", ",", "pad_type", "=", "'reflect'", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Generator model name [%s] is not recognized'", "%", "netG", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ",", "initialize_weights", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.define_F": [[354, 361], ["networks.init_net", "networks.SimSiamPatchSampleF", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.init_net"], ["", "def", "define_F", "(", "input_nc", ",", "netF", ",", "norm", "=", "'batch'", ",", "use_dropout", "=", "False", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "\n", "n_mlps", "=", "2", ",", "gpu_ids", "=", "[", "]", ",", "opt", "=", "None", ",", "activation", "=", "'relu'", ",", "arch", "=", "2", ",", "use_mlp", "=", "True", ")", ":", "\n", "    ", "if", "netF", "==", "'simsiam_mlp_sample'", ":", "\n", "        ", "net", "=", "SimSiamPatchSampleF", "(", "use_mlp", "=", "use_mlp", ",", "init_type", "=", "init_type", ",", "init_gain", "=", "init_gain", ",", "gpu_ids", "=", "gpu_ids", ",", "nc", "=", "opt", ".", "netF_nc", ",", "activation", "=", "activation", ",", "arch", "=", "arch", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'projection model name [%s] is not recognized'", "%", "netF", ")", "\n", "", "return", "init_net", "(", "net", ",", "init_type", ",", "init_gain", ",", "gpu_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_scheduler": [[616, 647], ["torch.optim.lr_scheduler.LambdaLR", "torch.optim.lr_scheduler.LinearLR", "torch.optim.lr_scheduler.ExponentialLR", "max", "float", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.CosineAnnealingLR", "NotImplementedError"], "function", ["None"], ["", "", "def", "get_scheduler", "(", "optimizer", ",", "opt", ")", ":", "\n", "    ", "\"\"\"Return a learning rate scheduler\n\n    Parameters:\n        optimizer          -- the optimizer of the network\n        opt (option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\uff0e\u3000\n                              opt.lr_policy is the name of learning rate policy: linear | step | plateau | cosine\n\n    For 'linear', we keep the same learning rate for the first <opt.n_epochs> epochs\n    and linearly decay the rate to zero over the next <opt.n_epochs_decay> epochs.\n    For other schedulers (step, plateau, and cosine), we use the default PyTorch schedulers.\n    See https://pytorch.org/docs/stable/optim.html for more details.\n    \"\"\"", "\n", "if", "opt", ".", "lr_policy", "==", "'const_linear'", ":", "\n", "        ", "def", "lambda_rule", "(", "epoch", ")", ":", "\n", "            ", "lr_l", "=", "1.0", "-", "max", "(", "0", ",", "epoch", "+", "opt", ".", "epoch_count", "-", "opt", ".", "n_epochs", ")", "/", "float", "(", "opt", ".", "n_epochs_decay", "+", "1", ")", "\n", "return", "lr_l", "\n", "", "scheduler", "=", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lambda_rule", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'linear'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "LinearLR", "(", "optimizer", ",", "start_factor", "=", "1.", ",", "end_factor", "=", "5e-2", ",", "total_iters", "=", "opt", ".", "n_epochs", "+", "opt", ".", "n_epochs_decay", ",", "last_epoch", "=", "-", "1", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'exponential'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "ExponentialLR", "(", "optimizer", ",", "0.99", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'step'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "opt", ".", "lr_decay_iters", ",", "gamma", "=", "0.5", ")", "# 0.1", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "factor", "=", "0.5", ",", "threshold", "=", "1e-4", ",", "patience", "=", "5", ",", "min_lr", "=", "1e-7", ")", "\n", "", "elif", "opt", ".", "lr_policy", "==", "'cosine'", ":", "\n", "        ", "scheduler", "=", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", ",", "T_max", "=", "opt", ".", "n_epochs", ",", "eta_min", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "return", "NotImplementedError", "(", "'learning rate policy [%s] is not implemented'", ",", "opt", ".", "lr_policy", ")", "\n", "", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.init_weights": [[679, 712], ["net.apply", "hasattr", "print", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_", "torch.nn.init.normal_", "torch.nn.init.constant_", "classname.find", "classname.find", "torch.nn.init.xavier_normal_", "classname.find", "classname.find", "torch.nn.init.kaiming_normal_", "torch.nn.init.orthogonal_", "NotImplementedError"], "function", ["None"], ["", "", "", "", "def", "init_weights", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "debug", "=", "False", ")", ":", "\n", "    ", "\"\"\"Initialize network weights.\n\n    Parameters:\n        net (network)   -- network to be initialized\n        init_type (str) -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        init_gain (float)    -- scaling factor for normal, xavier and orthogonal.\n\n    We use 'normal' in the original pix2pix and CycleGAN paper. But xavier and kaiming might\n    work better for some applications. Feel free to try yourself.\n    \"\"\"", "\n", "def", "init_func", "(", "m", ")", ":", "# define the initialization function", "\n", "        ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "hasattr", "(", "m", ",", "'weight'", ")", "and", "(", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ")", ":", "\n", "            ", "if", "debug", ":", "\n", "                ", "print", "(", "classname", ")", "\n", "", "if", "init_type", "==", "'normal'", ":", "\n", "                ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "0.0", ",", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'xavier'", ":", "\n", "                ", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "elif", "init_type", "==", "'kaiming'", ":", "\n", "                ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "a", "=", "0", ",", "mode", "=", "'fan_in'", ")", "\n", "", "elif", "init_type", "==", "'orthogonal'", ":", "\n", "                ", "init", ".", "orthogonal_", "(", "m", ".", "weight", ".", "data", ",", "gain", "=", "init_gain", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'initialization method [%s] is not implemented'", "%", "init_type", ")", "\n", "", "if", "hasattr", "(", "m", ",", "'bias'", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", "or", "classname", ".", "find", "(", "'BatchNorm3d'", ")", "!=", "-", "1", ":", "# BatchNorm Layer's weight is not a matrix; only normal distribution applies.", "\n", "            ", "init", ".", "normal_", "(", "m", ".", "weight", ".", "data", ",", "1.0", ",", "init_gain", ")", "\n", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0.0", ")", "\n", "\n", "", "", "net", ".", "apply", "(", "init_func", ")", "# apply the initialization function <init_func>", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.init_net": [[714, 736], ["net.to", "networks.init_weights", "len", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "net.to"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.init_weights"], ["", "def", "init_net", "(", "net", ",", "init_type", "=", "'normal'", ",", "init_gain", "=", "0.02", ",", "gpu_ids", "=", "[", "]", ",", "debug", "=", "False", ",", "initialize_weights", "=", "True", ")", ":", "\n", "    ", "\"\"\"Initialize a network: 1. register CPU/GPU device (with multi-GPU support); 2. initialize the network weights\n    Parameters:\n        net (network)      -- the network to be initialized\n        init_type (str)    -- the name of an initialization method: normal | xavier | kaiming | orthogonal\n        gain (float)       -- scaling factor for normal, xavier and orthogonal.\n        gpu_ids (int list) -- which GPUs the network runs on: e.g., 0,1,2\n\n    Return an initialized network.\n    \"\"\"", "\n", "if", "gpu_ids", "==", "\"tpu\"", ":", "\n", "        ", "net", ".", "to", "(", "\"xla:1\"", ")", "\n", "", "else", ":", "\n", "        ", "if", "len", "(", "gpu_ids", ")", ">", "0", ":", "\n", "            ", "assert", "(", "torch", ".", "cuda", ".", "is_available", "(", ")", ")", "\n", "net", ".", "to", "(", "\"cuda\"", ")", "\n", "# if not amp:", "\n", "#net = torch.nn.DataParallel(net, \"gpu_ids\")  # multi-GPUs for non-AMP training", "\n", "#    net = torch.nn.DataParallel(net, \"cuda\")", "\n", "", "", "if", "initialize_weights", ":", "\n", "        ", "init_weights", "(", "net", ",", "init_type", ",", "init_gain", "=", "init_gain", ",", "debug", "=", "debug", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.__init__.find_model_using_name": [[25, 46], ["importlib.import_module", "importlib.import_module.__dict__.items", "model_name.replace", "print", "exit", "issubclass", "name.lower", "target_model_name.lower"], "function", ["None"], ["def", "find_model_using_name", "(", "model_name", ")", ":", "\n", "    ", "\"\"\"Import the module \"models/[model_name]_model.py\".\n\n    In the file, the class called DatasetNameModel() will\n    be instantiated. It has to be a subclass of BaseModel,\n    and it is case-insensitive.\n    \"\"\"", "\n", "model_filename", "=", "\"models.\"", "+", "model_name", "+", "\"_model\"", "\n", "modellib", "=", "importlib", ".", "import_module", "(", "model_filename", ")", "\n", "model", "=", "None", "\n", "target_model_name", "=", "model_name", ".", "replace", "(", "'_'", ",", "''", ")", "+", "'model'", "\n", "for", "name", ",", "cls", "in", "modellib", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "        ", "if", "name", ".", "lower", "(", ")", "==", "target_model_name", ".", "lower", "(", ")", "and", "issubclass", "(", "cls", ",", "BaseModel", ")", ":", "\n", "            ", "model", "=", "cls", "\n", "\n", "", "", "if", "model", "is", "None", ":", "\n", "        ", "print", "(", "\"In %s.py, there should be a subclass of BaseModel with class name that matches %s in lowercase.\"", "%", "(", "model_filename", ",", "target_model_name", ")", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.__init__.get_option_setter": [[48, 52], ["__init__.find_model_using_name"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.__init__.find_model_using_name"], ["", "def", "get_option_setter", "(", "model_name", ")", ":", "\n", "    ", "\"\"\"Return the static method <modify_commandline_options> of the model class.\"\"\"", "\n", "model_class", "=", "find_model_using_name", "(", "model_name", ")", "\n", "return", "model_class", ".", "modify_commandline_options", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.__init__.create_model": [[54, 68], ["__init__.find_model_using_name", "find_model_using_name.", "print", "type"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.__init__.find_model_using_name"], ["", "def", "create_model", "(", "opt", ")", ":", "\n", "    ", "\"\"\"Create a model given the option.\n\n    This function warps the class CustomDatasetDataLoader.\n    This is the main interface between this package and 'train.py'/'test.py'\n\n    Example:\n        >>> from models import create_model\n        >>> model = create_model(opt)\n    \"\"\"", "\n", "model", "=", "find_model_using_name", "(", "opt", ".", "model", ")", "\n", "instance", "=", "model", "(", "opt", ")", "\n", "print", "(", "\"model [%s] was created\"", "%", "type", "(", "instance", ")", ".", "__name__", ")", "\n", "return", "instance", "\n", "", ""]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.__init__": [[18, 54], ["print", "os.path.join", "torch.device", "torch.device"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the BaseModel class.\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n\n        When creating your custom class, you need to implement your own initialization.\n        In this fucntion, you should first call <BaseModel.__init__(self, opt)>\n        Then, you need to define four lists:\n            -- self.loss_names (str list):          specify the training losses that you want to plot and save.\n            -- self.model_names (str list):         specify the images that you want to display and save.\n            -- self.visual_names (str list):        define networks used in our training.\n            -- self.optimizers (optimizer list):    define and initialize optimizers. You can define one optimizer for each network. If two networks are updated at the same time, you can use itertools.chain to group them. See cycle_gan_model.py for an example.\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "gpu_ids", "=", "opt", ".", "gpu_ids", "\n", "self", ".", "isTrain", "=", "opt", ".", "isTrain", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", "if", "self", ".", "gpu_ids", "else", "torch", ".", "device", "(", "'cpu'", ")", "# get device name: CPU or GPU", "\n", "\n", "print", "(", "'running on device: {}'", ".", "format", "(", "self", ".", "device", ")", ")", "\n", "self", ".", "save_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "# save all the checkpoints to save_dir", "\n", "self", ".", "loss_names", "=", "[", "]", "\n", "self", ".", "model_names", "=", "[", "]", "\n", "self", ".", "load_model_names", "=", "[", "]", "\n", "self", ".", "visual_names", "=", "[", "]", "\n", "self", ".", "feat_names", "=", "[", "]", "\n", "self", ".", "optimizers", "=", "[", "]", "\n", "self", ".", "image_paths", "=", "[", "]", "\n", "self", ".", "visualizer", "=", "None", "\n", "#self.metric = 0  # used for learning rate policy 'plateau'", "\n", "if", "self", ".", "opt", ".", "isTrain", ":", "\n", "            ", "self", ".", "old_lr", "=", "opt", ".", "lr", "\n", "", "self", ".", "unfreeze_layers", "=", "[", "]", "\n", "self", ".", "reset_params", "=", "False", "\n", "self", ".", "freeze_netF", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.dict_grad_hook_factory": [[56, 66], ["dict", "add_func"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "dict_grad_hook_factory", "(", "add_func", "=", "lambda", "x", ":", "x", ")", ":", "\n", "        ", "saved_dict", "=", "dict", "(", ")", "\n", "\n", "def", "hook_gen", "(", "name", ")", ":", "\n", "            ", "def", "grad_hook", "(", "grad", ")", ":", "\n", "                ", "saved_vals", "=", "add_func", "(", "grad", ")", "\n", "saved_dict", "[", "name", "]", "=", "saved_vals", "\n", "", "return", "grad_hook", "\n", "", "return", "hook_gen", ",", "saved_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.modify_commandline_options": [[67, 79], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new model-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.set_input": [[80, 88], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "set_input", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n\n        Parameters:\n            input (dict): includes the data itself and its metadata information.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.forward": [[89, 93], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "forward", "(", "self", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.optimize_parameters": [[94, 98], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "optimize_parameters", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Calculate losses, gradients, and update network weights; called in every training iteration\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.setup": [[99, 112], ["base_model.BaseModel.print_networks", "base_model.BaseModel.load_networks", "networks.get_scheduler"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.print_networks", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.load_networks", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_scheduler"], ["", "def", "setup", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Load and print networks; create schedulers\n\n        Parameters:\n            opt (Option class) -- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "schedulers", "=", "[", "networks", ".", "get_scheduler", "(", "optimizer", ",", "opt", ")", "for", "optimizer", "in", "self", ".", "optimizers", "]", "\n", "", "if", "not", "self", ".", "isTrain", "or", "opt", ".", "continue_train", "or", "(", "opt", ".", "pretrained_name", "is", "not", "None", "and", "opt", ".", "pretrained_name", "!=", "\"None\"", ")", ":", "\n", "            ", "load_suffix", "=", "opt", ".", "epoch", "\n", "self", ".", "load_networks", "(", "load_suffix", ")", "\n", "\n", "", "self", ".", "print_networks", "(", "opt", ".", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.parallelize": [[113, 121], ["isinstance", "getattr", "len", "isinstance", "print", "setattr", "torch.nn.DataParallel"], "methods", ["None"], ["", "def", "parallelize", "(", "self", ")", ":", "\n", "        ", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "if", "len", "(", "self", ".", "opt", ".", "gpu_ids", ")", ">", "0", "and", "self", ".", "opt", ".", "gpu_ids", "!=", "-", "1", ":", "\n", "                    ", "if", "not", "isinstance", "(", "net", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                        ", "print", "(", "'Parallelize: {}'", ".", "format", "(", "name", ")", ")", "\n", "setattr", "(", "self", ",", "'net'", "+", "name", ",", "torch", ".", "nn", ".", "DataParallel", "(", "net", ",", "self", ".", "opt", ".", "gpu_ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.data_dependent_initialize": [[122, 124], ["None"], "methods", ["None"], ["", "", "", "", "", "def", "data_dependent_initialize", "(", "self", ",", "data", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.eval": [[125, 131], ["isinstance", "getattr", "getattr.eval"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.eval"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make models eval mode during test time\"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.train": [[132, 144], ["isinstance", "getattr", "getattr.train", "networks.get_norm_layer", "enumerate", "len", "isinstance", "print", "layer.eval", "str"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.train", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.eval"], ["", "", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make models train mode during train time\"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "net", ".", "train", "(", ")", "\n", "Norm", "=", "networks", ".", "get_norm_layer", "(", "self", ".", "opt", ".", "ndims", ",", "self", ".", "opt", ".", "normG", ")", "\n", "if", "name", "==", "'G'", "and", "len", "(", "self", ".", "unfreeze_layers", ")", ">", "0", ":", "\n", "                    ", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "net", ".", "model", ")", ":", "\n", "                        ", "if", "str", "(", "layer_id", ")", "not", "in", "self", ".", "unfreeze_layers", "and", "isinstance", "(", "layer", ",", "Norm", ")", ":", "\n", "                            ", "print", "(", "'Freezing BN stats {}'", ".", "format", "(", "layer_id", ")", ")", "\n", "layer", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.test": [[145, 154], ["torch.no_grad", "base_model.BaseModel.forward", "base_model.BaseModel.compute_visuals"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.forward", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.compute_visuals"], ["", "", "", "", "", "", "def", "test", "(", "self", ")", ":", "\n", "        ", "\"\"\"Forward function used in test time.\n\n        This function wraps <forward> function in no_grad() so we don't save intermediate steps for backprop\n        It also calls <compute_visuals> to produce additional visualization results\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "forward", "(", ")", "\n", "self", ".", "compute_visuals", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.compute_visuals": [[155, 158], ["None"], "methods", ["None"], ["", "", "def", "compute_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate additional output images for visdom and HTML visualization\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.get_image_paths": [[159, 162], ["None"], "methods", ["None"], ["", "def", "get_image_paths", "(", "self", ")", ":", "\n", "        ", "\"\"\" Return image paths that are used to load current data\"\"\"", "\n", "return", "self", ".", "image_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.update_learning_rate_decay": [[163, 171], ["print"], "methods", ["None"], ["", "def", "update_learning_rate_decay", "(", "self", ",", "decay_gamma", "=", "0.5", ")", ":", "\n", "        ", "lr", "=", "self", ".", "old_lr", "*", "decay_gamma", "\n", "for", "optimizer", "in", "self", ".", "optimizers", ":", "\n", "            ", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "", "", "if", "self", ".", "opt", ".", "verbose", ":", "\n", "            ", "print", "(", "'update learning rate: %f -> %f'", "%", "(", "self", ".", "old_lr", ",", "lr", ")", ")", "\n", "", "self", ".", "old_lr", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.update_learning_rate": [[172, 182], ["print", "scheduler.step", "scheduler.step"], "methods", ["None"], ["", "def", "update_learning_rate", "(", "self", ",", "metric", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update learning rates for all the networks; called at the end of every epoch\"\"\"", "\n", "for", "scheduler", "in", "self", ".", "schedulers", ":", "\n", "            ", "if", "self", ".", "opt", ".", "lr_policy", "==", "'plateau'", ":", "\n", "                ", "scheduler", ".", "step", "(", "metric", ")", "\n", "", "else", ":", "\n", "                ", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "", "lr", "=", "self", ".", "optimizers", "[", "0", "]", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "print", "(", "'learning rate = %.7f'", "%", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.get_current_visuals": [[183, 190], ["collections.OrderedDict", "isinstance", "getattr"], "methods", ["None"], ["", "def", "get_current_visuals", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return visualization images. \"\"\"", "\n", "visual_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "visual_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "visual_ret", "[", "name", "]", "=", "getattr", "(", "self", ",", "name", ")", "\n", "", "", "return", "visual_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.get_current_losses": [[191, 198], ["collections.OrderedDict", "isinstance", "float", "getattr"], "methods", ["None"], ["", "def", "get_current_losses", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return traning losses / errors. train.py will print out these errors on console, and save them to a file\"\"\"", "\n", "errors_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "loss_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "errors_ret", "[", "name", "]", "=", "float", "(", "getattr", "(", "self", ",", "'loss_'", "+", "name", ")", ")", "# float(...) works for both scalar tensor and float number", "\n", "", "", "return", "errors_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.get_latent_features": [[199, 205], ["collections.OrderedDict", "isinstance", "getattr"], "methods", ["None"], ["", "def", "get_latent_features", "(", "self", ")", ":", "\n", "        ", "feat_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "feat_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "feat_ret", "[", "name", "]", "=", "getattr", "(", "self", ",", "name", ")", "\n", "", "", "return", "feat_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.save_networks": [[206, 227], ["isinstance", "os.path.join", "getattr", "torch.cuda.is_available", "isinstance", "getattr.cuda", "torch.save", "len", "torch.save", "torch.save", "getattr.cpu().state_dict", "getattr.module.cpu().state_dict", "getattr.cpu().state_dict", "getattr.cpu", "getattr.module.cpu", "getattr.cpu"], "methods", ["None"], ["", "def", "save_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Save all the networks to the disk.\n\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n        \"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "save_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "save_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "\n", "if", "len", "(", "self", ".", "gpu_ids", ")", ">", "0", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "if", "isinstance", "(", "net", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                        ", "torch", ".", "save", "(", "net", ".", "module", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "", "else", ":", "\n", "                        ", "torch", ".", "save", "(", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n", "", "net", ".", "cuda", "(", "self", ".", "gpu_ids", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "save", "(", "net", ".", "cpu", "(", ")", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.__patch_instance_norm_state_dict": [[228, 241], ["len", "base_model.BaseModel.__patch_instance_norm_state_dict", "module.__class__.__name__.startswith", "module.__class__.__name__.startswith", "state_dict.pop", "getattr", "getattr", "state_dict.pop"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.__patch_instance_norm_state_dict"], ["", "", "", "", "def", "__patch_instance_norm_state_dict", "(", "self", ",", "state_dict", ",", "module", ",", "keys", ",", "i", "=", "0", ")", ":", "\n", "        ", "\"\"\"Fix InstanceNorm checkpoints incompatibility (prior to 0.4)\"\"\"", "\n", "key", "=", "keys", "[", "i", "]", "\n", "if", "i", "+", "1", "==", "len", "(", "keys", ")", ":", "# at the end, pointing to a parameter/buffer", "\n", "            ", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'running_mean'", "or", "key", "==", "'running_var'", ")", ":", "\n", "                ", "if", "getattr", "(", "module", ",", "key", ")", "is", "None", ":", "\n", "                    ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "if", "module", ".", "__class__", ".", "__name__", ".", "startswith", "(", "'InstanceNorm'", ")", "and", "(", "key", "==", "'num_batches_tracked'", ")", ":", "\n", "                ", "state_dict", ".", "pop", "(", "'.'", ".", "join", "(", "keys", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "__patch_instance_norm_state_dict", "(", "state_dict", ",", "getattr", "(", "module", ",", "key", ")", ",", "keys", ",", "i", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.load_networks": [[242, 288], ["print", "len", "isinstance", "os.path.join", "getattr", "isinstance", "print", "torch.load", "print", "hasattr", "print", "os.path.join", "base_model.BaseModel.convert_dict", "getattr.load_state_dict", "str", "list", "list", "getattr.state_dict", "base_model.BaseModel.items", "getattr.load_state_dict", "print", "base_model.BaseModel.keys", "base_model.BaseModel.keys", "len", "v.size", "model_dict[].size", "print", "not_initialized.append", "v.size", "model_dict[].size"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.convert_dict"], ["", "", "def", "load_networks", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Load all the networks from the disk.\n\n        Parameters:\n            epoch (int) -- current epoch; used in the file name '%s_net_%s.pth' % (epoch, name)\n        \"\"\"", "\n", "assert", "len", "(", "self", ".", "load_model_names", ")", ">", "0", ",", "'found empty model list to load, please double check'", "\n", "print", "(", "'Loading models {}'", ".", "format", "(", "self", ".", "load_model_names", ")", ")", "\n", "for", "name", "in", "self", ".", "load_model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "load_filename", "=", "'%s_net_%s.pth'", "%", "(", "epoch", ",", "name", ")", "\n", "if", "self", ".", "opt", ".", "isTrain", "and", "(", "self", ".", "opt", ".", "pretrained_name", "is", "not", "None", "and", "self", ".", "opt", ".", "pretrained_name", "!=", "\"None\"", ")", ":", "\n", "                    ", "print", "(", "self", ".", "opt", ".", "pretrained_name", ")", "\n", "load_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "opt", ".", "checkpoints_dir", ",", "self", ".", "opt", ".", "pretrained_name", ")", "\n", "", "else", ":", "\n", "                    ", "load_dir", "=", "self", ".", "save_dir", "\n", "\n", "", "load_path", "=", "os", ".", "path", ".", "join", "(", "load_dir", ",", "load_filename", ")", "\n", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "if", "isinstance", "(", "net", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                    ", "net", "=", "net", ".", "module", "\n", "", "print", "(", "'loading the model from %s'", "%", "load_path", ")", "\n", "# if you are using PyTorch newer than 0.4 (e.g., built from", "\n", "# GitHub source), you can remove str() on self.device", "\n", "state_dict", "=", "torch", ".", "load", "(", "load_path", ",", "map_location", "=", "str", "(", "self", ".", "device", ")", ")", "\n", "print", "(", "list", "(", "state_dict", ".", "keys", "(", ")", ")", "[", "0", "]", ")", "\n", "if", "\"module\"", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", "[", "0", "]", ":", "\n", "                    ", "state_dict", "=", "self", ".", "convert_dict", "(", "state_dict", ")", "\n", "", "if", "hasattr", "(", "state_dict", ",", "'_metadata'", ")", ":", "\n", "                    ", "del", "state_dict", ".", "_metadata", "\n", "\n", "", "try", ":", "\n", "                    ", "net", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "except", ":", "\n", "                    ", "model_dict", "=", "net", ".", "state_dict", "(", ")", "\n", "not_initialized", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "                        ", "if", "v", ".", "size", "(", ")", "==", "model_dict", "[", "k", "]", ".", "size", "(", ")", ":", "\n", "                            ", "model_dict", "[", "k", "]", "=", "v", "\n", "", "else", ":", "\n", "                            ", "print", "(", "f'mismatch for {k} size: checkpoint size {v.size()}, model size {model_dict[k].size()}'", ")", "\n", "model_dict", "[", "k", "]", "\n", "not_initialized", ".", "append", "(", "k", ")", "\n", "", "", "assert", "len", "(", "not_initialized", ")", "==", "1", ",", "'only allow for last layer mismatch, found more than 1 param with mismatched shape {}'", ".", "format", "(", "not_initialized", ")", "\n", "net", ".", "load_state_dict", "(", "model_dict", ")", "\n", "print", "(", "'Partial network initialized'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.convert_dict": [[289, 294], ["collections.OrderedDict", "list", "state_dict.keys", "k.replace"], "methods", ["None"], ["", "", "", "", "def", "convert_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "new_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "new_dict", "[", "k", ".", "replace", "(", "'module.'", ",", "''", ")", "]", "=", "state_dict", "[", "k", "]", "\n", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.print_networks": [[295, 316], ["print", "print", "isinstance", "getattr", "getattr.parameters", "print", "param.numel", "print", "param.numel"], "methods", ["None"], ["", "def", "print_networks", "(", "self", ",", "verbose", ")", ":", "\n", "        ", "\"\"\"Print the total number of parameters in the network and (if verbose) network architecture\n\n        Parameters:\n            verbose (bool) -- if verbose: print the network architecture\n        \"\"\"", "\n", "print", "(", "'---------- Networks initialized -------------'", ")", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "num_params", "=", "0", "\n", "num_trainable_params", "=", "0", "\n", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "#print(param.name, param.numel())", "\n", "                    ", "num_params", "+=", "param", ".", "numel", "(", ")", "\n", "if", "param", ".", "requires_grad", ":", "\n", "                        ", "num_trainable_params", "+=", "param", ".", "numel", "(", ")", "\n", "", "", "if", "verbose", ":", "\n", "                    ", "print", "(", "net", ")", "\n", "", "print", "(", "'[Network %s] Total number of parameters : %d'", "%", "(", "name", ",", "num_params", ")", ")", "\n", "", "", "print", "(", "'-----------------------------------------------'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.set_requires_grad": [[317, 329], ["isinstance", "net.parameters"], "methods", ["None"], ["", "def", "set_requires_grad", "(", "self", ",", "nets", ",", "requires_grad", "=", "False", ")", ":", "\n", "        ", "\"\"\"Set requies_grad=Fasle for all the networks to avoid unnecessary computations\n        Parameters:\n            nets (network list)   -- a list of networks\n            requires_grad (bool)  -- whether the networks require gradients or not\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "nets", ",", "list", ")", ":", "\n", "            ", "nets", "=", "[", "nets", "]", "\n", "", "for", "net", "in", "nets", ":", "\n", "            ", "if", "net", "is", "not", "None", ":", "\n", "                ", "for", "param", "in", "net", ".", "parameters", "(", ")", ":", "\n", "                    ", "param", ".", "requires_grad", "=", "requires_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.log_gradients_in_model": [[330, 339], ["isinstance", "getattr", "getattr.named_parameters", "base_model.BaseModel.visualizer.writer.add_histogram", "base_model.BaseModel.visualizer.writer.add_scalar", "value.grad.detach().cpu", "torch.norm", "value.grad.detach().cpu", "value.grad.detach", "value.grad.detach"], "methods", ["None"], ["", "", "", "", "def", "log_gradients_in_model", "(", "self", ",", "step", ")", ":", "\n", "        ", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "for", "tag", ",", "value", "in", "net", ".", "named_parameters", "(", ")", ":", "\n", "#print(tag)", "\n", "                    ", "if", "value", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "self", ".", "visualizer", ".", "writer", ".", "add_histogram", "(", "name", "+", "\"/\"", "+", "tag", "+", "\"_grad\"", ",", "value", ".", "grad", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "step", ")", "\n", "self", ".", "visualizer", ".", "writer", ".", "add_scalar", "(", "name", "+", "\"/\"", "+", "tag", "+", "\"_grad_norm\"", ",", "torch", ".", "norm", "(", "value", ".", "grad", ".", "detach", "(", ")", ".", "cpu", "(", ")", ")", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.generate_visuals_for_evaluation": [[341, 343], ["None"], "methods", ["None"], ["", "", "", "", "", "def", "generate_visuals_for_evaluation", "(", "self", ",", "data", ",", "mode", ")", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.freeze_bn": [[344, 346], ["None"], "methods", ["None"], ["", "def", "freeze_bn", "(", "self", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.modify_commandline_options": [[23, 56], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.set_defaults", "parser.parse_known_args"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "\"\"\"  Configures options specific for PatchSim + Seg model\n        \"\"\"", "\n", "parser", ".", "add_argument", "(", "'--lambda_seg'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'weight for segmentation loss: L1(G(x) S)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_cseg'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'weight for segmentation consistency'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_sim'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'weight for Sim loss: Sim(X,Y)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--unfreeze_layers'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'specify partial layers that will be trained'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--netF'", ",", "type", "=", "str", ",", "default", "=", "'simsiam_mlp_sample'", ",", "choices", "=", "[", "'simsiam_mlp_sample'", "]", ",", "help", "=", "'how to downsample the feature map'", ")", "\n", "parser", ".", "add_argument", "(", "'--archF'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "choices", "=", "[", "1", ",", "2", "]", ",", "help", "=", "'delete later, 1 is the previous model with bias/BN affine, 2 is the same as simsiam github implementation '", ")", "\n", "parser", ".", "add_argument", "(", "'--netF_nc'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "\n", "parser", ".", "add_argument", "(", "'--num_patches'", ",", "type", "=", "int", ",", "default", "=", "768", ",", "help", "=", "'number of patches per layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_mlps'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'number of mlps, 2 or 3'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--sim_layers'", ",", "type", "=", "str", ",", "default", "=", "'3,10,17,24,27,31,38,45,52'", ",", "\n", "help", "=", "'compute Sim loss on which layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--sim_weights'", ",", "type", "=", "str", ",", "default", "=", "'1'", ",", "\n", "help", "=", "'how to sum all nce losses. If \"1\", simply use mean. Otherwise, weighted average by specified weights that must have equal length of sim_layers'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_mlp'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'whether to use MLP '", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--reg_V'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'regularization weight for batch variance'", ")", "\n", "parser", ".", "add_argument", "(", "'--reg_C'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'regularization weight for dimension covariance'", ")", "\n", "parser", ".", "add_argument", "(", "'--reg_O'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'regularization weight for orthogonal encoder decoder'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--ortho_idx'", ",", "type", "=", "str", ",", "default", "=", "'0,1,2'", ",", "\n", "help", "=", "'compute orthogonal loss on which concat pairs'", ")", "\n", "\n", "parser", ".", "set_defaults", "(", "pool_size", "=", "0", ")", "# no image pooling", "\n", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.__init__": [[57, 250], ["models.base_model.BaseModel.__init__", "print", "float", "range", "networks.define_G", "zip", "print", "print", "range", "max", "print", "print", "numpy.sum", "len", "len", "float", "float", "len", "len", "len", "print", "print", "print", "print", "print", "int", "longrep_model.LongRepModel.ortho_idx.append", "len", "len", "print", "os.path.exists", "print", "f.close", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.MSELoss", "networks.define_G", "print", "monai.losses.DiceLoss", "monai.losses.DiceCELoss", "monai.losses.DiceCELoss", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "longrep_model.LongRepModel.optimizers.append", "len", "int", "float", "numpy.asarray", "len", "longrep_model.LongRepModel.opt.reg_V.split", "longrep_model.LongRepModel.opt.reg_C.split", "print", "longrep_model.LongRepModel.sim_layers.index", "longrep_model.LongRepModel.sim_layers.index", "all_pairs.append", "longrep_model.LongRepModel.opt.ortho_idx.split", "longrep_model.LongRepModel.concat_pairs.append", "os.path.join", "open", "print", "os.path.exists", "print", "f.close", "networks.define_F", "dict", "dict.items", "longrep_model.LongRepModel.netG.parameters", "print", "itertools.chain", "longrep_model.LongRepModel.opt.sim_layers.split", "longrep_model.LongRepModel.opt.sim_weights.split", "longrep_model.LongRepModel.opt.unfreeze_layers.split", "len", "os.path.join", "os.path.join", "open", "print", "longrep_model.LongRepModel.criterionSim.append", "longrep_model.LongRepModel.netG.named_parameters", "print", "longrep_model.LongRepModel.netRec.parameters", "len", "os.path.join", "models.networks.Pairwise_Feature_Similarity().to", "print", "models.networks.Pairwise_Feature_Similarity"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.define_G", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.define_G", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.define_F"], ["", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "BaseModel", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "\n", "# specify the training losses you want to print out.", "\n", "# The training/test scripts will call <BaseModel.get_current_losses>", "\n", "self", ".", "loss_names", "=", "[", "'G'", "]", "# total loss ", "\n", "if", "self", ".", "opt", ".", "lambda_seg", ">", "0", ":", "\n", "            ", "self", ".", "loss_names", "+=", "[", "'S'", "]", "#, 'dice', 'ce']", "\n", "assert", "self", ".", "opt", ".", "lambda_Rec", "==", "0.", ",", "'segmentation and reconstruction conflicts.'", "\n", "self", ".", "visual_names", "=", "[", "'real_A'", ",", "'pred_seg'", ",", "'seg_A'", "]", "\n", "\n", "", "if", "self", ".", "opt", ".", "lambda_Rec", ">", "0", ":", "\n", "            ", "self", ".", "loss_names", "+=", "[", "'Rec'", "]", "\n", "assert", "self", ".", "opt", ".", "lambda_seg", "==", "0.", ",", "'segmentation and reconstruction conflicts.'", "\n", "self", ".", "visual_names", "=", "[", "'real_A'", ",", "'rec_A'", ",", "'rec_A_trg'", "]", "\n", "\n", "\n", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "grad_accum_iters", "=", "opt", ".", "grad_accum_iters", "\n", "\n", "if", "self", ".", "opt", ".", "lambda_cseg", ">", "0.", ":", "\n", "                ", "self", ".", "loss_names", "+=", "[", "'CS'", "]", "\n", "self", ".", "visual_names", "=", "[", "'real_A'", ",", "'pred_seg_A'", ",", "'real_B'", ",", "'pred_seg_B'", "]", "\n", "\n", "", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0", ":", "\n", "                ", "self", ".", "loss_names", "+=", "[", "'Sim'", ",", "'std'", ",", "'cov'", ",", "'ortho'", "]", "\n", "\n", "", "", "print", "(", "'Visuals: {}'", ".", "format", "(", "self", ".", "visual_names", ")", ")", "\n", "\n", "if", "not", "opt", ".", "sim_layers", "==", "''", ":", "\n", "            ", "self", ".", "sim_layers", "=", "[", "int", "(", "i", ")", "for", "i", "in", "self", ".", "opt", ".", "sim_layers", ".", "split", "(", "','", ")", "]", "\n", "self", ".", "last_layer_to_freeze", "=", "self", ".", "sim_layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "sim_layers", "=", "[", "]", "\n", "self", ".", "last_layer_to_freeze", "=", "-", "1", "\n", "\n", "", "if", "self", ".", "opt", ".", "sim_weights", "!=", "'1'", ":", "\n", "            ", "self", ".", "sim_weights", "=", "[", "float", "(", "i", ")", "for", "i", "in", "self", ".", "opt", ".", "sim_weights", ".", "split", "(", "','", ")", "]", "\n", "sum_", "=", "np", ".", "sum", "(", "np", ".", "asarray", "(", "self", ".", "sim_weights", ")", ")", "\n", "self", ".", "sim_weights", "=", "[", "i", "/", "sum_", "for", "i", "in", "self", ".", "sim_weights", "]", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "self", ".", "sim_layers", ")", ">", "0", ":", "\n", "                ", "self", ".", "sim_weights", "=", "[", "1.", "/", "len", "(", "self", ".", "sim_layers", ")", "for", "_", "in", "self", ".", "sim_layers", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "sim_weights", "=", "[", "]", "\n", "", "", "assert", "len", "(", "self", ".", "sim_weights", ")", "==", "len", "(", "self", ".", "sim_layers", ")", "\n", "\n", "self", ".", "reg_V", "=", "[", "float", "(", "i", ")", "for", "i", "in", "self", ".", "opt", ".", "reg_V", ".", "split", "(", "','", ")", "]", "\n", "self", ".", "reg_C", "=", "[", "float", "(", "i", ")", "for", "i", "in", "self", ".", "opt", ".", "reg_C", ".", "split", "(", "','", ")", "]", "\n", "self", ".", "reg_O", "=", "float", "(", "self", ".", "opt", ".", "reg_O", ")", "\n", "\n", "if", "len", "(", "self", ".", "reg_V", ")", "==", "1", ":", "\n", "            ", "self", ".", "reg_V", "=", "[", "self", ".", "reg_V", "[", "0", "]", "for", "_", "in", "self", ".", "sim_layers", "]", "\n", "", "if", "len", "(", "self", ".", "reg_C", ")", "==", "1", ":", "\n", "            ", "self", ".", "reg_C", "=", "[", "self", ".", "reg_C", "[", "0", "]", "for", "_", "in", "self", ".", "sim_layers", "]", "\n", "#if len(self.reg_O) == 1:", "\n", "#self.reg_O = [self.reg_O[0]  for _ in self.sim_layers]", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "sim_layers", ")", ")", ":", "\n", "            ", "self", ".", "reg_V", "[", "i", "]", "=", "self", ".", "reg_V", "[", "i", "]", "*", "self", ".", "sim_weights", "[", "i", "]", "# scale by the weight ", "\n", "self", ".", "reg_C", "[", "i", "]", "=", "self", ".", "reg_C", "[", "i", "]", "*", "self", ".", "sim_weights", "[", "i", "]", "\n", "#self.reg_O[i] = self.reg_O[i] * self.sim_weights[i]", "\n", "\n", "\n", "", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0", ":", "\n", "            ", "print", "(", "'--------------- Loss configuration -------------'", ")", "\n", "print", "(", "'sim Layers'", ",", "self", ".", "sim_layers", ")", "\n", "print", "(", "'sim weights'", ",", "self", ".", "sim_weights", ")", "\n", "print", "(", "'regularization (V) - std'", ",", "self", ".", "reg_V", ")", "\n", "print", "(", "'regularization (C) - cov'", ",", "self", ".", "reg_C", ")", "\n", "\n", "", "self", ".", "reset_params", "=", "False", "\n", "if", "not", "self", ".", "opt", ".", "unfreeze_layers", "==", "''", ":", "\n", "            ", "self", ".", "unfreeze_layers", "=", "[", "i", "for", "i", "in", "self", ".", "opt", ".", "unfreeze_layers", ".", "split", "(", "','", ")", "]", "\n", "self", ".", "reset_params", "=", "True", "\n", "#assert self.opt.pretrained_name is not None, 'Must have pretrained checkpoints for the freezed layers!!'", "\n", "self", ".", "load_model_names", "=", "[", "'G'", "]", "\n", "", "self", ".", "model_names", "=", "[", "'G'", "]", "\n", "# define networks (generator)", "\n", "self", ".", "netG", "=", "networks", ".", "define_G", "(", "opt", ".", "ndims", ",", "opt", ".", "input_nc", ",", "opt", ".", "output_nc", ",", "opt", ".", "ngf", ",", "opt", ".", "netG", ",", "opt", ".", "normG", ",", "not", "opt", ".", "no_dropout", ",", "\n", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ",", "opt", ",", "pooling", "=", "opt", ".", "pool_type", ",", "interp", "=", "opt", ".", "interp_type", ",", "\n", "final_act", "=", "'none'", ",", "activation", "=", "opt", ".", "actG", ")", "\n", "\n", "### Get the paired encoder and decoder features for orthogonal regularization ", "\n", "enc_idx", "=", "self", ".", "netG", ".", "encoder_idx", "\n", "dec_idx", "=", "self", ".", "netG", ".", "decoder_idx", "[", ":", ":", "-", "1", "]", "\n", "#Encoder skip connect id [8, 15, 22, 29]", "\n", "#Decoder skip connect id [37, 44, 51, 58]", "\n", "all_pairs", "=", "[", "]", "\n", "for", "eid", ",", "did", "in", "zip", "(", "enc_idx", ",", "dec_idx", ")", ":", "\n", "#if (eid) in self.sim_layers and (did+3) in self.sim_layers:  # after relu ", "\n", "            ", "if", "(", "eid", "-", "2", ")", "in", "self", ".", "sim_layers", "and", "(", "did", "+", "1", ")", "in", "self", ".", "sim_layers", ":", "# after conv", "\n", "                ", "print", "(", "eid", ",", "did", ")", "\n", "nce_e", "=", "self", ".", "sim_layers", ".", "index", "(", "eid", "-", "2", ")", "\n", "nce_d", "=", "self", ".", "sim_layers", ".", "index", "(", "did", "+", "1", ")", "\n", "all_pairs", ".", "append", "(", "(", "nce_e", ",", "nce_d", ")", ")", "# the encoder/decoder id in sim_layer ", "\n", "\n", "", "", "print", "(", "'Found all concat pairs'", ",", "all_pairs", ")", "\n", "self", ".", "ortho_idx", "=", "[", "int", "(", "i", ")", "for", "i", "in", "self", ".", "opt", ".", "ortho_idx", ".", "split", "(", "','", ")", "]", "\n", "if", "-", "1", "in", "self", ".", "ortho_idx", ":", "\n", "            ", "self", ".", "ortho_idx", ".", "append", "(", "len", "(", "all_pairs", ")", "-", "1", ")", "\n", "", "print", "(", "'using {} as orthogonal loss'", ".", "format", "(", "self", ".", "ortho_idx", ")", ")", "\n", "self", ".", "concat_pairs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "all_pairs", ")", ")", ":", "\n", "            ", "if", "i", "in", "self", ".", "ortho_idx", ":", "\n", "                ", "self", ".", "concat_pairs", ".", "append", "(", "all_pairs", "[", "i", "]", ")", "\n", "\n", "", "", "self", ".", "reg_O", "/=", "max", "(", "len", "(", "self", ".", "concat_pairs", ")", ",", "1", ")", "\n", "print", "(", "'regularization (O) - Ortho'", ",", "self", ".", "reg_O", ")", "\n", "print", "(", "'apply orthogonal loss on {}'", ".", "format", "(", "self", ".", "concat_pairs", ")", ")", "\n", "for", "e", ",", "d", "in", "self", ".", "concat_pairs", ":", "\n", "            ", "print", "(", "'ID'", ",", "self", ".", "sim_layers", "[", "e", "]", ",", "self", ".", "sim_layers", "[", "d", "]", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "'netG.txt'", ")", ")", ":", "\n", "            ", "print", "(", "'Write network configs into text'", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "'netG.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "print", "(", "self", ".", "netG", ",", "file", "=", "f", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "lambda_Rec", ">", "0", ":", "\n", "            ", "self", ".", "criterionRec", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "self", ".", "model_names", "+=", "[", "'Rec'", "]", "\n", "self", ".", "netRec", "=", "networks", ".", "define_G", "(", "opt", ".", "ndims", ",", "opt", ".", "output_nc", ",", "opt", ".", "input_nc", ",", "opt", ".", "ngf", ",", "'conv'", ",", "opt", ".", "normG", ",", "\n", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "opt", ".", "init_gain", ",", "self", ".", "gpu_ids", ",", "opt", ",", "\n", "final_act", "=", "'none'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "'netRec.txt'", ")", ")", ":", "\n", "                ", "print", "(", "'Write recon net configs into text'", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "'netRec.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                    ", "print", "(", "self", ".", "netRec", ",", "file", "=", "f", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "\n", "", "", "if", "self", ".", "isTrain", ":", "\n", "            ", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0.", ":", "\n", "                ", "self", ".", "netF", "=", "networks", ".", "define_F", "(", "opt", ".", "input_nc", ",", "opt", ".", "netF", ",", "opt", ".", "normG", ",", "not", "opt", ".", "no_dropout", ",", "opt", ".", "init_type", ",", "\n", "opt", ".", "init_gain", ",", "opt", ".", "n_mlps", ",", "self", ".", "gpu_ids", ",", "opt", ",", "activation", "=", "opt", ".", "actF", ",", "arch", "=", "opt", ".", "archF", ",", "use_mlp", "=", "opt", ".", "use_mlp", ")", "\n", "\n", "if", "self", ".", "opt", ".", "use_mlp", ":", "\n", "                    ", "self", ".", "model_names", "+=", "[", "'F'", "]", "\n", "\n", "# define loss functions", "\n", "", "self", ".", "criterionSim", "=", "[", "]", "\n", "for", "sim_layer", "in", "self", ".", "sim_layers", ":", "\n", "                    ", "self", ".", "criterionSim", ".", "append", "(", "Pairwise_Feature_Similarity", "(", "opt", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "", "", "lambda_dice", "=", "1.", "\n", "lambda_ce", "=", "1", "\n", "smooth_dr", "=", "self", ".", "opt", ".", "smooth_dr", "\n", "smooth_nr", "=", "self", ".", "opt", ".", "smooth_nr", "\n", "batch_dice", "=", "self", ".", "opt", ".", "batch_dice", "\n", "include_background", "=", "self", ".", "opt", ".", "include_background", "\n", "\n", "print", "(", "f'Dice {lambda_dice}, CE {lambda_ce}, smooth_dr {smooth_dr}, smooth_nr {smooth_nr}, batch {batch_dice}'", ")", "#, include_background {include_background}')", "\n", "\n", "self", ".", "criterionSegC", "=", "monai", ".", "losses", ".", "DiceLoss", "(", "to_onehot_y", "=", "True", ",", "softmax", "=", "True", ")", "\n", "\n", "self", ".", "criterionSeg", "=", "monai", ".", "losses", ".", "DiceCELoss", "(", "to_onehot_y", "=", "True", ",", "softmax", "=", "True", ",", "lambda_dice", "=", "lambda_dice", ",", "lambda_ce", "=", "lambda_ce", ",", "\n", "smooth_nr", "=", "smooth_nr", ",", "smooth_dr", "=", "smooth_dr", ",", "batch", "=", "batch_dice", ")", "\n", "\n", "self", ".", "criterionSeg_val", "=", "monai", ".", "losses", ".", "DiceCELoss", "(", "to_onehot_y", "=", "True", ",", "softmax", "=", "True", ",", "lambda_dice", "=", "lambda_dice", ",", "lambda_ce", "=", "lambda_ce", ",", "smooth_nr", "=", "1e-5", ",", "smooth_dr", "=", "1e-5", ")", "\n", "\n", "if", "self", ".", "reset_params", ":", "\n", "                ", "paramsG", "=", "[", "]", "\n", "params_dict_G", "=", "dict", "(", "self", ".", "netG", ".", "named_parameters", "(", ")", ")", "\n", "for", "key", ",", "value", "in", "params_dict_G", ".", "items", "(", ")", ":", "\n", "                    ", "grad", "=", "False", "\n", "for", "f", "in", "self", ".", "unfreeze_layers", ":", "\n", "                        ", "if", "f", "in", "key", ":", "\n", "                            ", "print", "(", "'Add %s to optimizer list'", "%", "key", ")", "\n", "grad", "=", "True", "\n", "paramsG", "+=", "[", "{", "'params'", ":", "[", "value", "]", "}", "]", "\n", "break", "\n", "", "", "value", ".", "requires_grad", "=", "grad", "\n", "print", "(", "key", ",", "value", ".", "requires_grad", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "paramsG", "=", "self", ".", "netG", ".", "parameters", "(", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "lambda_Rec", ">", "0", ":", "\n", "                ", "print", "(", "'Adding netRec parameters for reconstruction'", ")", "\n", "import", "itertools", "\n", "paramsG", "=", "itertools", ".", "chain", "(", "paramsG", ",", "self", ".", "netRec", ".", "parameters", "(", ")", ")", "\n", "\n", "#self.optimizer_G =  torch.optim.AdamW(paramsG, lr=opt.lr, betas=(opt.beta1, opt.beta2), eps=opt.eps, weight_decay=opt.weight_decay,", "\n", "#                                      amsgrad=opt.ams_grad)", "\n", "", "self", ".", "optimizer_G", "=", "torch", ".", "optim", ".", "Adam", "(", "paramsG", ",", "lr", "=", "opt", ".", "lr", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "opt", ".", "beta2", ")", ")", "\n", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_G", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "feat_names", "=", "[", "'feat'", ",", "'global_feat'", "]", "\n", "\n", "", "self", ".", "new_bs", "=", "-", "1", "\n", "if", "len", "(", "self", ".", "load_model_names", ")", "==", "0", ":", "\n", "            ", "self", ".", "load_model_names", "=", "self", ".", "model_names", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.data_dependent_initialize": [[252, 276], ["longrep_model.LongRepModel.set_input", "longrep_model.LongRepModel.forward", "longrep_model.LongRepModel.compute_G_loss().backward", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "torch.optim.AdamW", "longrep_model.LongRepModel.optimizers.append", "os.path.exists", "print", "f.close", "longrep_model.LongRepModel.compute_G_loss", "longrep_model.LongRepModel.netF.parameters", "os.path.join", "open", "print", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.set_input", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.forward", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.compute_G_loss"], ["", "", "def", "data_dependent_initialize", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        The feature network netF is defined in terms of the shape of the intermediate, extracted\n        features of the encoder portion of netG. Because of this, the weights of netF are\n        initialized at the first feedforward pass with some input images.\n        Please also see PatchSampleF.create_mlp(), which is called at the first forward() call.\n        \"\"\"", "\n", "if", "self", ".", "opt", ".", "isTrain", ":", "\n", "            ", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0", ":", "\n", "                ", "self", ".", "set_input", "(", "data", ",", "verbose", "=", "True", ")", "\n", "self", ".", "forward", "(", "verbose", "=", "False", ")", "# compute fake images: G(A)", "\n", "self", ".", "compute_G_loss", "(", "0", ")", ".", "backward", "(", ")", "# calculate graidents for G", "\n", "\n", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0.0", "and", "self", ".", "opt", ".", "use_mlp", "and", "not", "self", ".", "freeze_netF", ":", "\n", "                    ", "self", ".", "optimizer_F", "=", "torch", ".", "optim", ".", "AdamW", "(", "self", ".", "netF", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "opt", ".", "lr", ",", "betas", "=", "(", "self", ".", "opt", ".", "beta1", ",", "self", ".", "opt", ".", "beta2", ")", ",", "\n", "eps", "=", "self", ".", "opt", ".", "eps", ",", "weight_decay", "=", "self", ".", "opt", ".", "weight_decay", ",", "amsgrad", "=", "self", ".", "opt", ".", "ams_grad", ")", "\n", "self", ".", "optimizers", ".", "append", "(", "self", ".", "optimizer_F", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "'netF.txt'", ")", ")", ":", "\n", "                    ", "print", "(", "'Write network configs into text'", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "save_dir", ",", "'netF.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                        ", "print", "(", "self", ".", "netF", ",", "file", "=", "f", ")", "\n", "", "f", ".", "close", "(", ")", "\n", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "#self.parallelize()", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.optimize_parameters": [[278, 300], ["torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "longrep_model.LongRepModel.forward", "longrep_model.LongRepModel.compute_G_loss", "longrep_model.LongRepModel.loss_G.backward", "longrep_model.LongRepModel.optimizer_G.step", "longrep_model.LongRepModel.optimizer_G.zero_grad", "longrep_model.LongRepModel.optimizer_F.step", "longrep_model.LongRepModel.optimizer_F.zero_grad", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "longrep_model.LongRepModel.netF.parameters"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.forward", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.compute_G_loss"], ["", "", "", "def", "optimize_parameters", "(", "self", ",", "iters", ")", ":", "\n", "# forward", "\n", "        ", "accum_iter", "=", "self", ".", "grad_accum_iters", "#4", "\n", "# accumulate ", "\n", "with", "torch", ".", "set_grad_enabled", "(", "True", ")", ":", "\n", "            ", "self", ".", "forward", "(", ")", "\n", "self", ".", "loss_G", "=", "self", ".", "compute_G_loss", "(", ")", "\n", "self", ".", "loss_G", "=", "self", ".", "loss_G", "/", "accum_iter", "\n", "self", ".", "loss_G", ".", "backward", "(", ")", "\n", "\n", "# weights update", "\n", "", "if", "(", "(", "iters", ")", "%", "accum_iter", "==", "0", ")", ":", "\n", "            ", "self", ".", "optimizer_G", ".", "step", "(", ")", "\n", "\n", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0", "and", "self", ".", "opt", ".", "use_mlp", "and", "not", "self", ".", "freeze_netF", ":", "\n", "                ", "if", "self", ".", "opt", ".", "clip_grad", ":", "\n", "                    ", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "netF", ".", "parameters", "(", ")", ",", "max_norm", "=", "self", ".", "opt", ".", "max_norm", ",", "norm_type", "=", "2", ",", "error_if_nonfinite", "=", "True", ")", "\n", "", "self", ".", "optimizer_F", ".", "step", "(", ")", "\n", "# zero grad ", "\n", "", "self", ".", "optimizer_G", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0", "and", "self", ".", "opt", ".", "use_mlp", "and", "not", "self", ".", "freeze_netF", ":", "\n", "                ", "self", ".", "optimizer_F", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.set_input": [[301, 357], ["input[].to().float", "print", "input[].to().float", "input[].to().float", "input[].to().float", "input[].to().float", "input.keys", "input[].to().float", "input.keys", "input[].unsqueeze().to", "input.keys", "input[].unsqueeze().to", "longrep_model.LongRepModel.real_A.size", "input.keys", "input[].unsqueeze().to().float", "input[].to", "input[].to().float", "input[].to().float", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "torch.cat().squeeze", "input[].to().float", "longrep_model.LongRepModel.subj_A.squeeze", "longrep_model.LongRepModel.age_A.squeeze", "input[].to", "input[].to", "input[].to", "input[].to", "input[].to", "input[].unsqueeze", "input[].unsqueeze", "input[].unsqueeze().to", "input[].to", "input[].to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input[].to", "input[].unsqueeze"], "methods", ["None"], ["", "", "", "def", "set_input", "(", "self", ",", "input", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"Unpack input data from the dataloader and perform necessary pre-processing steps.\n        Parameters:\n            input (dict): include the data itself and its metadata information.\n        The option 'direction' can be used to swap domain A and domain B.\n        \"\"\"", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n", "if", "self", ".", "isTrain", ":", "\n", "            ", "self", ".", "real_A", "=", "input", "[", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0", ":", "\n", "                ", "self", ".", "age_A", "=", "input", "[", "'A_age'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "self", ".", "subj_A", "=", "input", "[", "'A_id'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "", "if", "self", ".", "opt", ".", "lambda_Rec", ">", "0", ":", "\n", "                ", "self", ".", "rec_A_trg", "=", "input", "[", "'A_trg'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "\n", "", "if", "'B'", "in", "input", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "real_B", "=", "input", "[", "'B'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0", ":", "\n", "                    ", "self", ".", "age_B", "=", "input", "[", "'B_age'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "self", ".", "subj_B", "=", "input", "[", "'B_id'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "self", ".", "label_subjid", "=", "torch", ".", "cat", "(", "(", "self", ".", "subj_A", ",", "self", ".", "subj_B", ")", ",", "dim", "=", "0", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "self", ".", "label_age", "=", "torch", ".", "cat", "(", "(", "self", ".", "age_A", ",", "self", ".", "age_B", ")", ",", "dim", "=", "0", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "self", ".", "opt", ".", "lambda_Rec", ">", "0", ":", "\n", "                    ", "self", ".", "rec_B_trg", "=", "input", "[", "'B_trg'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "real_B", "=", "None", "\n", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0", ":", "\n", "                    ", "self", ".", "label_subjid", "=", "self", ".", "subj_A", ".", "squeeze", "(", "-", "1", ")", "\n", "self", ".", "label_age", "=", "self", ".", "age_A", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "", "", "if", "'A_seg'", "in", "input", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "seg_A", "=", "input", "[", "'A_seg'", "]", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "visual_names", "=", "[", "'real_A'", ",", "'pred_seg_A'", ",", "'seg_A'", "]", "\n", "self", ".", "seg_A_gt", "=", "True", "\n", "", "else", ":", "\n", "                ", "self", ".", "seg_A", "=", "None", "\n", "self", ".", "seg_A_gt", "=", "False", "\n", "\n", "", "if", "'B_seg'", "in", "input", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "seg_B", "=", "input", "[", "'B_seg'", "]", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "visual_names", "+=", "[", "'real_B'", ",", "'pred_seg_B'", ",", "'seg_B'", "]", "\n", "self", ".", "seg_B_gt", "=", "True", "\n", "", "else", ":", "\n", "                ", "self", ".", "seg_B", "=", "None", "\n", "self", ".", "seg_B_gt", "=", "False", "\n", "", "del", "input", "\n", "print", "(", "'A'", ",", "self", ".", "real_A", ".", "size", "(", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "real_A", "=", "input", "[", "'A'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "if", "'A_seg'", "in", "input", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "seg_A", "=", "input", "[", "'A_seg'", "]", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "visual_names", "=", "[", "'real_A'", ",", "'pred_seg'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.forward": [[359, 409], ["torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "longrep_model.LongRepModel.netG", "longrep_model.LongRepModel.netG", "longrep_model.LongRepModel.netRec", "torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "longrep_model.LongRepModel.real_A.size", "longrep_model.LongRepModel.real_A.size", "longrep_model.LongRepModel.real_A.permute().view", "longrep_model.LongRepModel.netG", "torch.argmax().float().unsqueeze.size", "torch.argmax().float().unsqueeze.size", "torch.argmax().float().unsqueeze.view().permute", "torch.argmax().float().unsqueeze.view().permute", "torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "longrep_model.LongRepModel.recs.size", "longrep_model.LongRepModel.reals.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "longrep_model.LongRepModel.real_A.size", "torch.argmax().float", "torch.argmax().float", "torch.argmax().float", "torch.argmax().float", "longrep_model.LongRepModel.real_A.size", "longrep_model.LongRepModel.real_A.size", "torch.argmax().float", "torch.argmax().float", "torch.argmax().float", "torch.argmax().float", "longrep_model.LongRepModel.real_A.permute", "torch.argmax().float().unsqueeze.view", "torch.argmax().float().unsqueeze.view", "torch.argmax().float", "torch.argmax().float", "torch.argmax().float", "torch.argmax().float", "longrep_model.LongRepModel.netG", "torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "torch.argmax().float().unsqueeze", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.softmax", "torch.softmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax().float", "torch.argmax().float", "torch.argmax().float", "torch.argmax().float", "longrep_model.LongRepModel.pred_A.detach", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "longrep_model.LongRepModel.pred_B.detach", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.softmax", "torch.softmax"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"Run forward pass; called by both functions <optimize_parameters> and <test>.\"\"\"", "\n", "if", "self", ".", "isTrain", ":", "\n", "# for segmentation", "\n", "            ", "if", "self", ".", "real_B", "is", "not", "None", ":", "\n", "                ", "self", ".", "reals", "=", "torch", ".", "cat", "(", "(", "self", ".", "real_A", ",", "self", ".", "real_B", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "reals", "=", "self", ".", "real_A", "\n", "\n", "", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0", ":", "\n", "                ", "segs", ",", "self", ".", "feat_kq", "=", "self", ".", "netG", "(", "self", ".", "reals", ",", "self", ".", "sim_layers", ",", "False", ",", "verbose", "=", "verbose", ")", "\n", "", "else", ":", "\n", "                ", "segs", "=", "self", ".", "netG", "(", "self", ".", "reals", ",", "[", "]", ",", "False", ",", "verbose", "=", "verbose", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "lambda_Rec", ">", "0", ":", "\n", "                ", "self", ".", "recs", "=", "self", ".", "netRec", "(", "segs", ")", "\n", "assert", "self", ".", "recs", ".", "size", "(", ")", "==", "self", ".", "reals", ".", "size", "(", ")", "\n", "self", ".", "rec_A", "=", "self", ".", "recs", "[", ":", "self", ".", "real_A", ".", "size", "(", "0", ")", "]", "\n", "if", "self", ".", "rec_B_trg", "is", "not", "None", ":", "\n", "                    ", "self", ".", "recon_trg", "=", "torch", ".", "cat", "(", "(", "self", ".", "rec_A_trg", ",", "self", ".", "rec_B_trg", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "recon_trg", "=", "self", ".", "rec_A_trg", "\n", "", "", "self", ".", "pred_A", "=", "segs", "[", ":", "self", ".", "real_A", ".", "size", "(", "0", ")", "]", "\n", "self", ".", "pred_seg_A", "=", "torch", ".", "argmax", "(", "F", ".", "softmax", "(", "self", ".", "pred_A", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "if", "self", ".", "real_B", "is", "not", "None", ":", "\n", "                ", "self", ".", "pred_B", "=", "segs", "[", "self", ".", "real_A", ".", "size", "(", "0", ")", ":", "]", "\n", "self", ".", "pred_seg_B", "=", "torch", ".", "argmax", "(", "F", ".", "softmax", "(", "self", ".", "pred_B", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "\n", "", "", "else", ":", "\n", "# test time: single input", "\n", "            ", "crop_size", "=", "self", ".", "opt", ".", "crop_size", "\n", "if", "self", ".", "opt", ".", "ndims", "==", "2", ":", "\n", "                ", "self", ".", "pred_seg", "=", "torch", ".", "zeros_like", "(", "self", ".", "real_A", ")", "\n", "nframes", "=", "self", ".", "real_A", ".", "size", "(", "2", ")", "\n", "b", ",", "c", ",", "w", ",", "h", ",", "d", "=", "self", ".", "real_A", ".", "size", "(", ")", "\n", "patch", "=", "self", ".", "real_A", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", ".", "view", "(", "b", "*", "w", ",", "c", ",", "h", ",", "d", ")", "\n", "patch_pred_seg", "=", "self", ".", "netG", "(", "patch", ",", "[", "]", ",", "False", ")", "\n", "_", ",", "cseg", ",", "_", ",", "_", "=", "patch_pred_seg", ".", "size", "(", ")", "\n", "\n", "patch_pred_seg", "=", "patch_pred_seg", ".", "view", "(", "b", ",", "w", ",", "cseg", ",", "h", ",", "d", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", "\n", "patch_pred_seg", "=", "torch", ".", "argmax", "(", "F", ".", "softmax", "(", "patch_pred_seg", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", "\n", "self", ".", "pred_seg", "=", "patch_pred_seg", "\n", "\n", "", "elif", "self", ".", "opt", ".", "ndims", "==", "3", ":", "\n", "                ", "if", "crop_size", "==", "-", "1", ":", "\n", "                    ", "patch", "=", "self", ".", "real_A", "\n", "self", ".", "pred_seg", "=", "self", ".", "netG", "(", "patch", ",", "[", "]", ",", "False", ")", "\n", "self", ".", "pred_seg", "=", "torch", ".", "argmax", "(", "F", ".", "softmax", "(", "self", ".", "pred_seg", ",", "dim", "=", "1", ")", ",", "dim", "=", "1", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.compute_G_loss": [[411, 461], ["longrep_model.LongRepModel.criterionSeg", "longrep_model.LongRepModel.criterionSeg", "longrep_model.LongRepModel.calculate_Sim_loss", "longrep_model.LongRepModel.calculate_recon_loss", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "longrep_model.LongRepModel.criterionSeg_val.dice", "longrep_model.LongRepModel.criterionSeg_val.ce", "longrep_model.LongRepModel.criterionSegC", "longrep_model.LongRepModel.criterionSegC", "longrep_model.LongRepModel.pred_A.detach", "longrep_model.LongRepModel.seg_A.detach", "longrep_model.LongRepModel.pred_A.detach", "longrep_model.LongRepModel.seg_A.detach"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.calculate_Sim_loss", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.calculate_recon_loss"], ["", "", "", "", "def", "compute_G_loss", "(", "self", ",", "iters", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Calculate  Sim loss for the generator\"\"\"", "\n", "self", ".", "loss_G", "=", "0.", "\n", "\n", "# segmentation consistency loss", "\n", "if", "self", ".", "real_B", "is", "not", "None", "and", "self", ".", "opt", ".", "lambda_cseg", ">", "0", ":", "\n", "            ", "self", ".", "loss_CS", "=", "0.5", "*", "(", "self", ".", "criterionSegC", "(", "self", ".", "pred_A", ",", "self", ".", "pred_seg_B", ")", "+", "self", ".", "criterionSegC", "(", "self", ".", "pred_B", ",", "self", ".", "pred_seg_A", ")", ")", "\n", "self", ".", "loss_G", "+=", "(", "self", ".", "loss_CS", "*", "self", ".", "opt", ".", "lambda_cseg", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_CS", "=", "0.", "\n", "\n", "# segmentation gt dice ", "\n", "", "if", "self", ".", "seg_A_gt", ":", "\n", "            ", "self", ".", "loss_S", "=", "self", ".", "criterionSeg", "(", "self", ".", "pred_A", ",", "self", ".", "seg_A", ")", "#.long())", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "# for checking purpose only ", "\n", "                ", "self", ".", "loss_dice", "=", "self", ".", "criterionSeg_val", ".", "dice", "(", "self", ".", "pred_A", ".", "detach", "(", ")", ",", "self", ".", "seg_A", ".", "detach", "(", ")", ")", "\n", "self", ".", "loss_ce", "=", "self", ".", "criterionSeg_val", ".", "ce", "(", "self", ".", "pred_A", ".", "detach", "(", ")", ",", "self", ".", "seg_A", ".", "detach", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "loss_S", "=", "0.", "\n", "\n", "", "if", "self", ".", "seg_B_gt", ":", "\n", "            ", "self", ".", "loss_S", "+=", "self", ".", "criterionSeg", "(", "self", ".", "pred_B", ",", "self", ".", "seg_B", ")", "#.long())", "\n", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "if", "self", ".", "seg_A_gt", "or", "self", ".", "seg_B_gt", ":", "\n", "            ", "self", ".", "loss_G", "+=", "(", "self", ".", "loss_S", "*", "self", ".", "opt", ".", "lambda_seg", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0", ":", "\n", "            ", "self", ".", "loss_Sim", ",", "self", ".", "sim_dict", ",", "self", ".", "loss_std", ",", "self", ".", "std_dict", ",", "self", ".", "loss_cov", ",", "self", ".", "cov_dict", ",", "self", ".", "loss_ortho", ",", "self", ".", "ortho_dict", "=", "self", ".", "calculate_Sim_loss", "(", "self", ".", "feat_kq", ",", "None", ",", "iter", ",", "vis", "=", "False", ")", "#(step!=-1))", "\n", "\n", "self", ".", "loss_G", "+=", "self", ".", "loss_Sim", "*", "self", ".", "opt", ".", "lambda_sim", "\n", "self", ".", "loss_G", "+=", "self", ".", "loss_std", "\n", "self", ".", "loss_G", "+=", "self", ".", "loss_cov", "\n", "self", ".", "loss_G", "+=", "self", ".", "reg_O", "*", "self", ".", "loss_ortho", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_Sim", "=", "0.", "\n", "self", ".", "loss_std", ",", "self", ".", "loss_cov", ",", "self", ".", "loss_ortho", "=", "0.", ",", "0.", ",", "0.", "\n", "\n", "", "if", "self", ".", "opt", ".", "lambda_Rec", ">", "0", ":", "\n", "            ", "assert", "self", ".", "opt", ".", "lambda_seg", "==", "0", ",", "'Reconstruction and segmentation conflicts'", "\n", "self", ".", "loss_Rec", "=", "self", ".", "calculate_recon_loss", "(", ")", "#self.criterionRec(self.recs, self.reals)", "\n", "self", ".", "loss_G", "+=", "self", ".", "loss_Rec", "*", "self", ".", "opt", ".", "lambda_Rec", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_Rec", "=", "0.", "\n", "\n", "", "return", "self", ".", "loss_G", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.calculate_recon_loss": [[462, 464], ["longrep_model.LongRepModel.criterionRec"], "methods", ["None"], ["", "def", "calculate_recon_loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "criterionRec", "(", "self", ".", "recs", ",", "self", ".", "recon_trg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.calculate_Sim_loss": [[465, 529], ["longrep_model.LongRepModel.netF", "collections.OrderedDict", "longrep_model.LongRepModel.real_A.size", "zip", "[].flatten", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "loss.cpu().item", "z1.size", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "float", "float", "longrep_model.LongRepModel.netF.sample_by_id", "f_proj_E.view.view.size", "f_proj_D.view.view.view", "f_proj_E.view.view.view", "longrep_model.LongRepModel.netF.l2norm", "longrep_model.LongRepModel.netF.l2norm", "f_proj_E.view.view.view", "f_proj_D.view.view.view", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "float", "crit", "crit", "str", "loss.cpu", "z1.view().float", "z2.view().float", "x.mean", "y.mean", "std_loss.cpu().item", "off_diagonal().pow_().sum().div", "off_diagonal().pow_().sum().div", "cov_loss.cpu().item", "torch.square", "torch.square", "torch.square", "torch.square", "torch.mean.item", "torch.mean.item", "[].view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.var", "y.var", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.view", "torch.mean.view", "feat.size", "feat.size", "z1.view", "z2.view", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "str", "std_loss.cpu", "off_diagonal().pow_().sum", "off_diagonal().pow_().sum", "str", "cov_loss.cpu", "z2.detach", "z1.detach", "x.flatten", "off_diagonal().pow_", "off_diagonal().pow_", "longrep_model.LongRepModel.calculate_Sim_loss.off_diagonal"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.SimSiamPatchSampleF.sample_by_id"], ["", "def", "calculate_Sim_loss", "(", "self", ",", "feat_kq", ",", "mask", "=", "None", ",", "step", "=", "-", "1", ",", "vis", "=", "False", ")", ":", "\n", "        ", "def", "off_diagonal", "(", "x", ")", ":", "\n", "            ", "n", ",", "m", "=", "x", ".", "shape", "\n", "assert", "n", "==", "m", "\n", "return", "x", ".", "flatten", "(", ")", "[", ":", "-", "1", "]", ".", "view", "(", "n", "-", "1", ",", "n", "+", "1", ")", "[", ":", ",", "1", ":", "]", ".", "flatten", "(", ")", "\n", "\n", "", "feat_kq_pool", ",", "sample_ids", "=", "self", ".", "netF", "(", "feat_kq", ",", "self", ".", "opt", ".", "num_patches", ",", "None", ",", "mask", ",", "False", ")", "# verbose=self.verbose)", "\n", "total_nce_loss", ",", "total_std_loss", ",", "total_cov_loss", ",", "total_ortho_loss", "=", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "\n", "layer_wise_dict", "=", "OrderedDict", "(", ")", "\n", "layer_wise_std", ",", "layer_wise_cov", ",", "layer_wise_ortho", "=", "OrderedDict", "(", ")", ",", "OrderedDict", "(", ")", ",", "OrderedDict", "(", ")", "\n", "bs", "=", "self", ".", "real_A", ".", "size", "(", "0", ")", "\n", "for", "f_kq", ",", "sample_id", ",", "crit", ",", "sim_layer", ",", "nce_w", ",", "feat", ",", "lambda_std", ",", "lambda_cov", "in", "zip", "(", "feat_kq_pool", ",", "\n", "sample_ids", ",", "self", ".", "criterionSim", ",", "self", ".", "sim_layers", ",", "self", ".", "sim_weights", ",", "feat_kq", ",", "self", ".", "reg_V", ",", "self", ".", "reg_C", ")", ":", "\n", "            ", "f_proj", ",", "f_pred", "=", "f_kq", "\n", "z1", ",", "z2", "=", "f_proj", "[", ":", "bs", "]", ",", "f_proj", "[", "bs", ":", "]", "# non-normalized features", "\n", "p1", ",", "p2", "=", "f_pred", "[", ":", "bs", "]", ",", "f_pred", "[", "bs", ":", "]", "\n", "loss", "=", "0.5", "*", "crit", "(", "torch", ".", "cat", "(", "(", "p1", ",", "z2", ".", "detach", "(", ")", ")", ",", "dim", "=", "0", ")", ",", "self", ".", "label_age", ",", "self", ".", "label_subjid", ",", "sample_id", ",", "feat", ".", "size", "(", ")", "[", "2", ":", "]", ",", "debug", "=", "False", ")", "+", "0.5", "*", "crit", "(", "torch", ".", "cat", "(", "(", "p2", ",", "z1", ".", "detach", "(", ")", ")", ",", "dim", "=", "0", ")", ",", "self", ".", "label_age", ",", "self", ".", "label_subjid", ",", "sample_id", ",", "feat", ".", "size", "(", ")", "[", "2", ":", "]", ",", "debug", "=", "False", ")", "\n", "\n", "total_nce_loss", "+=", "(", "loss", "*", "nce_w", "*", "self", ".", "opt", ".", "lambda_sim", ")", "\n", "layer_wise_dict", "[", "str", "(", "sim_layer", ")", "]", "=", "loss", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "\n", "if", "lambda_std", ">", "0", "or", "lambda_cov", ">", "0", ":", "\n", "                ", "ntps", ",", "num_patches", ",", "nc", "=", "z1", ".", "size", "(", ")", "\n", "\n", "x", ",", "y", "=", "z1", ".", "view", "(", "ntps", "*", "num_patches", ",", "nc", ")", ".", "float", "(", ")", ",", "z2", ".", "view", "(", "ntps", "*", "num_patches", ",", "nc", ")", ".", "float", "(", ")", "\n", "x", "=", "x", "-", "x", ".", "mean", "(", "dim", "=", "0", ")", "\n", "y", "=", "y", "-", "y", ".", "mean", "(", "dim", "=", "0", ")", "\n", "std_x", "=", "torch", ".", "sqrt", "(", "x", ".", "var", "(", "dim", "=", "0", ")", "+", "0.0001", ")", "# variance across batch", "\n", "std_y", "=", "torch", ".", "sqrt", "(", "y", ".", "var", "(", "dim", "=", "0", ")", "+", "0.0001", ")", "\n", "std_loss", "=", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1", "-", "std_x", ")", ")", "/", "2", "+", "torch", ".", "mean", "(", "F", ".", "relu", "(", "1", "-", "std_y", ")", ")", "/", "2", "\n", "layer_wise_std", "[", "str", "(", "sim_layer", ")", "+", "'_Var'", "]", "=", "float", "(", "std_loss", ".", "cpu", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "cov_x", "=", "(", "x", ".", "T", "@", "x", ")", "/", "(", "ntps", "*", "num_patches", "-", "1", ")", "# covariance of nc dimension ", "\n", "cov_y", "=", "(", "y", ".", "T", "@", "y", ")", "/", "(", "ntps", "*", "num_patches", "-", "1", ")", "\n", "cov_loss", "=", "off_diagonal", "(", "cov_x", ")", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", ".", "div", "(", "nc", ")", "+", "off_diagonal", "(", "cov_y", ")", ".", "pow_", "(", "2", ")", ".", "sum", "(", ")", ".", "div", "(", "nc", ")", "\n", "layer_wise_cov", "[", "str", "(", "sim_layer", ")", "+", "'_Cov'", "]", "=", "float", "(", "cov_loss", ".", "cpu", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "total_std_loss", "+=", "lambda_std", "*", "std_loss", "*", "self", ".", "opt", ".", "lambda_sim", "\n", "total_cov_loss", "+=", "lambda_cov", "*", "cov_loss", "*", "self", ".", "opt", ".", "lambda_sim", "\n", "\n", "", "", "if", "self", ".", "reg_O", ">", "0", ":", "\n", "            ", "for", "(", "eid", ",", "did", ")", "in", "self", ".", "concat_pairs", ":", "\n", "                ", "f_proj_E", ",", "_", "=", "feat_kq_pool", "[", "eid", "]", "\n", "sample_id_E", "=", "sample_ids", "[", "eid", "]", "\n", "f_proj_D", ",", "_", ",", "sample_id_D", "=", "self", ".", "netF", ".", "sample_by_id", "(", "feat_kq", "[", "did", "]", ",", "did", ",", "\n", "self", ".", "opt", ".", "num_patches", ",", "sample_id_E", ")", "\n", "ntps", ",", "npatches", ",", "nc", "=", "f_proj_E", ".", "size", "(", ")", "\n", "f_proj_D", "=", "f_proj_D", ".", "view", "(", "ntps", "*", "npatches", ",", "nc", ")", "\n", "f_proj_E", "=", "f_proj_E", ".", "view", "(", "ntps", "*", "npatches", ",", "nc", ")", "#.detach()", "\n", "\n", "f_proj_D", "=", "self", ".", "netF", ".", "l2norm", "(", "f_proj_D", ")", "\n", "f_proj_E", "=", "self", ".", "netF", ".", "l2norm", "(", "f_proj_E", ")", "\n", "\n", "f_proj_E", "=", "f_proj_E", ".", "view", "(", "ntps", "*", "npatches", ",", "1", ",", "nc", ")", "\n", "f_proj_D", "=", "f_proj_D", ".", "view", "(", "ntps", "*", "npatches", ",", "nc", ",", "1", ")", "\n", "loss_ortho", "=", "torch", ".", "bmm", "(", "f_proj_E", ",", "f_proj_D", ")", "\n", "loss_ortho", "=", "torch", ".", "mean", "(", "torch", ".", "square", "(", "loss_ortho", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "total_ortho_loss", "+=", "loss_ortho", "\n", "layer_wise_ortho", "[", "'{}_{}_Ortho'", ".", "format", "(", "eid", ",", "did", ")", "]", "=", "float", "(", "loss_ortho", ".", "item", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "total_ortho_loss", "=", "0", "\n", "", "return", "total_nce_loss", ",", "layer_wise_dict", ",", "total_std_loss", ",", "layer_wise_std", ",", "total_cov_loss", ",", "layer_wise_cov", ",", "total_ortho_loss", ",", "layer_wise_ortho", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.get_current_visuals": [[534, 543], ["collections.OrderedDict", "isinstance", "getattr", "print", "getattr.size", "getattr.min().item", "getattr.max().item", "getattr.min", "getattr.max"], "methods", ["None"], ["", "def", "get_current_visuals", "(", "self", ")", ":", "\n", "        ", "visual_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "visual_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "tmp", "=", "getattr", "(", "self", ",", "name", ")", "\n", "if", "tmp", "is", "not", "None", ":", "\n", "                    ", "print", "(", "name", ",", "tmp", ".", "size", "(", ")", ",", "tmp", ".", "min", "(", ")", ".", "item", "(", ")", ",", "tmp", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "visual_ret", "[", "name", "]", "=", "tmp", "\n", "", "", "", "return", "visual_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.get_current_losses": [[544, 557], ["collections.OrderedDict", "isinstance", "collections.OrderedDict.update", "collections.OrderedDict.update", "collections.OrderedDict.update", "collections.OrderedDict.update", "float", "getattr"], "methods", ["None"], ["", "def", "get_current_losses", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return traning losses / errors. train.py will print out these errors on console, and save them to a file\"\"\"", "\n", "errors_ret", "=", "OrderedDict", "(", ")", "\n", "for", "name", "in", "self", ".", "loss_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "errors_ret", "[", "name", "]", "=", "float", "(", "getattr", "(", "self", ",", "'loss_'", "+", "name", ")", ")", "\n", "", "", "if", "self", ".", "opt", ".", "lambda_sim", ">", "0", ":", "\n", "            ", "errors_ret", ".", "update", "(", "self", ".", "sim_dict", ")", "\n", "errors_ret", ".", "update", "(", "self", ".", "std_dict", ")", "\n", "errors_ret", ".", "update", "(", "self", ".", "cov_dict", ")", "\n", "errors_ret", ".", "update", "(", "self", ".", "ortho_dict", ")", "\n", "\n", "", "return", "errors_ret", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.train": [[559, 592], ["isinstance", "getattr", "getattr.train", "networks.get_norm_layer", "enumerate", "longrep_model.LongRepModel.set_requires_grad", "networks.get_norm_layer", "enumerate", "len", "isinstance", "enumerate", "enumerate", "isinstance", "print", "layer.eval", "getattr", "getattr", "getattr", "getattr", "isinstance", "isinstance", "str", "print", "layer.eval", "print", "layer.eval"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.longrep_model.LongRepModel.train", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.set_requires_grad", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.networks.get_norm_layer", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.eval", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.eval", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.models.base_model.BaseModel.eval"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make models train mode during train time\"\"\"", "\n", "for", "name", "in", "self", ".", "model_names", ":", "\n", "            ", "if", "isinstance", "(", "name", ",", "str", ")", ":", "\n", "                ", "net", "=", "getattr", "(", "self", ",", "'net'", "+", "name", ")", "\n", "net", ".", "train", "(", ")", "\n", "Norm", "=", "networks", ".", "get_norm_layer", "(", "self", ".", "opt", ".", "ndims", ",", "self", ".", "opt", ".", "normG", ")", "\n", "if", "name", "==", "'G'", "and", "len", "(", "self", ".", "unfreeze_layers", ")", ">", "0", ":", "\n", "                    ", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "net", ".", "model", ")", ":", "\n", "                        ", "if", "str", "(", "layer_id", ")", "not", "in", "self", ".", "unfreeze_layers", "and", "isinstance", "(", "layer", ",", "Norm", ")", ":", "\n", "                            ", "print", "(", "'Freezing BN stats {}'", ".", "format", "(", "layer_id", ")", ")", "\n", "layer", ".", "eval", "(", ")", "\n", "\n", "", "", "", "if", "name", "==", "'F'", "and", "self", ".", "freeze_netF", ":", "\n", "                    ", "self", ".", "set_requires_grad", "(", "net", ",", "False", ")", "\n", "normF", "=", "networks", ".", "get_norm_layer", "(", "1", ",", "'batch'", ")", "\n", "\n", "for", "feat_id", ",", "_", "in", "enumerate", "(", "self", ".", "sim_layers", ")", ":", "\n", "                        ", "if", "isinstance", "(", "self", ".", "netF", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "                            ", "mlp", "=", "getattr", "(", "self", ".", "netF", ".", "module", ",", "'mlp_%d'", "%", "feat_id", ")", "\n", "pred", "=", "getattr", "(", "self", ".", "netF", ".", "module", ",", "'pred_%d'", "%", "feat_id", ")", "\n", "", "else", ":", "\n", "                            ", "mlp", "=", "getattr", "(", "self", ".", "netF", ",", "'mlp_%d'", "%", "feat_id", ")", "\n", "pred", "=", "getattr", "(", "self", ".", "netF", ",", "'pred_%d'", "%", "feat_id", ")", "\n", "", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "mlp", ")", ":", "\n", "                            ", "if", "isinstance", "(", "layer", ",", "normF", ")", ":", "\n", "                                ", "print", "(", "'[MLP {}] Freezing BN stats {}'", ".", "format", "(", "feat_id", ",", "layer_id", ")", ")", "\n", "layer", ".", "eval", "(", ")", "\n", "\n", "", "", "for", "layer_id", ",", "layer", "in", "enumerate", "(", "pred", ")", ":", "\n", "                            ", "if", "isinstance", "(", "layer", ",", "normF", ")", ":", "\n", "                                ", "print", "(", "'[Pred {}] Freezing BN stats {}'", ".", "format", "(", "feat_id", ",", "layer_id", ")", ")", "\n", "layer", ".", "eval", "(", ")", "", "", "", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.longitudinalh5_dataset.Longitudinalh5Dataset.__init__": [[21, 123], ["data.base_dataset.BaseDataset.__init__", "print", "print", "h5py.File", "list", "len", "print", "print", "torchio.Resize", "print", "torchio.Compose", "torchio.Compose", "print", "os.path.exists", "longitudinalh5_dataset.Longitudinalh5Dataset.hf.keys", "longitudinalh5_dataset.Longitudinalh5Dataset.hf.keys", "print", "print", "print", "longitudinalh5_dataset.Longitudinalh5Dataset.partial_train.endswith", "print", "h5py.File", "print", "h5py.File", "print", "print", "print", "print", "print", "torchio.RandomFlip", "int", "torchio.RandomBlur", "torchio.RandomNoise", "torchio.RandomBiasField", "torchio.RandomGamma", "torchio.RandomMotion", "torchio.RandomAffine", "int", "torchio.RandomAffine"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "BaseDataset", ".", "__init__", "(", "self", ",", "opt", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "folder", "=", "opt", ".", "dataroot", "\n", "self", ".", "isTrain", "=", "opt", ".", "isTrain", "\n", "key", "=", "'train'", "if", "self", ".", "isTrain", "else", "'val'", "\n", "self", ".", "dimension", "=", "opt", ".", "data_ndims", "\n", "self", ".", "h5_long", "=", "self", ".", "folder", "+", "f'/{key}_placeholder_long.hdf5'", "\n", "self", ".", "normalize", "=", "opt", ".", "normalize", "\n", "self", ".", "percentile", "=", "99.99", "\n", "self", ".", "zero_centered", "=", "False", "\n", "self", ".", "mode", "=", "opt", ".", "load_mode", "\n", "print", "(", "'----------- %dd Data Loader Initialization, load mode [%s] ----------'", "%", "(", "self", ".", "dimension", ",", "self", ".", "mode", ")", ")", "\n", "if", "self", ".", "mode", "==", "'long_pairs'", ":", "# longitudinal pairs", "\n", "            ", "print", "(", "self", ".", "h5_long", ",", "os", ".", "path", ".", "exists", "(", "self", ".", "h5_long", ")", ")", "\n", "self", ".", "hf", "=", "h5py", ".", "File", "(", "self", ".", "h5_long", ",", "'r'", ")", "\n", "self", ".", "subj_id", "=", "list", "(", "self", ".", "hf", ".", "keys", "(", ")", ")", "\n", "self", ".", "len", "=", "len", "(", "self", ".", "hf", ".", "keys", "(", ")", ")", "\n", "print", "(", "'load tp in order: {}'", ".", "format", "(", "self", ".", "opt", ".", "tp_order", ")", ")", "\n", "\n", "", "elif", "self", ".", "mode", "==", "'single_seg'", ":", "# one image with its segmentation, for training segmentation net", "\n", "            ", "self", ".", "use_numpy", "=", "False", "\n", "if", "self", ".", "isTrain", ":", "\n", "                ", "self", ".", "partial_train", "=", "opt", ".", "partial_train", "\n", "\n", "assert", "self", ".", "partial_train", ".", "endswith", "(", "'.hdf5'", ")", "\n", "self", ".", "h5_seg", "=", "self", ".", "folder", "+", "f'/{self.partial_train}'", "\n", "print", "(", "f'Using {self.h5_seg}'", ")", "\n", "self", ".", "hf", "=", "h5py", ".", "File", "(", "self", ".", "h5_seg", ",", "'r'", ")", "\n", "if", "self", ".", "dimension", "==", "3", ":", "\n", "                    ", "self", ".", "len", "=", "int", "(", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'t1'", "]", ".", "shape", "[", "0", "]", ")", "# n, 192, 160, 160", "\n", "", "elif", "self", ".", "dimension", "==", "2", ":", "\n", "                    ", "self", ".", "nframes", "=", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'t1'", "]", ".", "shape", "[", "1", "]", "# !!! this is first axis only", "\n", "self", ".", "len", "=", "int", "(", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'t1'", "]", ".", "shape", "[", "0", "]", "*", "self", ".", "nframes", ")", "# n*192, 160, 160", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "h5_seg", "=", "self", ".", "folder", "+", "f'/{key}_{opt.validation_prefix}.hdf5'", "\n", "print", "(", "self", ".", "h5_seg", ")", "\n", "self", ".", "hf", "=", "h5py", ".", "File", "(", "self", ".", "h5_seg", ",", "'r'", ")", "\n", "if", "self", ".", "dimension", "==", "3", ":", "\n", "                    ", "self", ".", "len", "=", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'t1'", "]", ".", "shape", "[", "0", "]", "# 98, 192, 160, 160", "\n", "", "elif", "self", ".", "dimension", "==", "2", ":", "\n", "                    ", "self", ".", "len", "=", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'t1'", "]", ".", "shape", "[", "0", "]", "*", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'t1'", "]", ".", "shape", "[", "1", "]", "# 98, 192, 160, 160", "\n", "self", ".", "nframes", "=", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'t1'", "]", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "self", ".", "load_seg", "=", "True", "\n", "self", ".", "crop_size", "=", "opt", ".", "crop_size", "\n", "self", ".", "load_recon", "=", "opt", ".", "lambda_Rec", ">", "0", "\n", "\n", "if", "self", ".", "opt", ".", "resize", ":", "\n", "            ", "print", "(", "'Including resizing in preprocessing: %d'", "%", "opt", ".", "crop_size", ")", "\n", "assert", "opt", ".", "crop_size", ">", "0", ",", "'Wrong size %d specified for resizing.'", "%", "(", "opt", ".", "crop_size", ")", "\n", "self", ".", "pre_resize", "=", "tio", ".", "Resize", "(", "(", "opt", ".", "crop_size", ",", "opt", ".", "crop_size", ",", "opt", ".", "crop_size", ")", ")", "\n", "\n", "", "self", ".", "apply_same_inten_augment", "=", "opt", ".", "apply_same_inten_augment", "\n", "if", "(", "opt", ".", "isTrain", "and", "opt", ".", "augment", ")", ":", "\n", "            ", "print", "(", "'Initializing augmentation ...'", ")", "\n", "\n", "augment_list_intensity", "=", "[", "]", "\n", "if", "opt", ".", "inten_augment", ":", "\n", "                ", "print", "(", "'Add in intensity augmentation '", ")", "\n", "if", "opt", ".", "blur", ":", "\n", "                    ", "print", "(", "'Random Blur'", ")", "\n", "augment_list_intensity", "+=", "[", "tio", ".", "RandomBlur", "(", "p", "=", "0.3", ")", "]", "\n", "", "if", "opt", ".", "noise", ":", "\n", "                    ", "print", "(", "'Noise'", ")", "\n", "augment_list_intensity", "+=", "[", "tio", ".", "RandomNoise", "(", "p", "=", "0.25", ")", "]", "\n", "", "if", "opt", ".", "bias", ":", "\n", "                    ", "print", "(", "'Bias Field'", ")", "\n", "augment_list_intensity", "+=", "[", "tio", ".", "RandomBiasField", "(", "p", "=", "0.2", ")", "]", "\n", "", "if", "opt", ".", "gamma", ":", "\n", "                    ", "print", "(", "'Gamma'", ")", "\n", "augment_list_intensity", "+=", "[", "tio", ".", "RandomGamma", "(", "p", "=", "0.3", ",", "log_gamma", "=", "(", "-", "0.3", ",", "0.3", ")", ")", "]", "\n", "", "if", "opt", ".", "motion", ":", "\n", "                    ", "print", "(", "'Motion'", ")", "\n", "augment_list_intensity", "+=", "[", "tio", ".", "RandomMotion", "(", "p", "=", "0.1", ")", "]", "\n", "", "", "self", ".", "augment_fn_intensity", "=", "tio", ".", "Compose", "(", "augment_list_intensity", ")", "\n", "\n", "augment_list_spatial", "=", "[", "]", "\n", "if", "opt", ".", "geo_augment", ":", "\n", "                ", "print", "(", "'Add in geometric augmentation '", ")", "\n", "augment_list_spatial", "+=", "[", "tio", ".", "RandomFlip", "(", "p", "=", "0.5", ")", "]", "\n", "self", ".", "scale", "=", "0.2", "\n", "self", ".", "degrees", "=", "10", "\n", "print", "(", "'affine configs: scale {}, degree {}'", ".", "format", "(", "self", ".", "scale", ",", "self", ".", "degrees", ")", ")", "\n", "if", "self", ".", "dimension", "==", "3", ":", "\n", "                    ", "augment_list_spatial", "+=", "[", "tio", ".", "RandomAffine", "(", "p", "=", "0.5", ",", "scales", "=", "self", ".", "scale", ",", "degrees", "=", "self", ".", "degrees", ")", "]", "\n", "", "elif", "self", ".", "dimension", "==", "2", ":", "\n", "                    ", "augment_list_spatial", "+=", "[", "tio", ".", "RandomAffine", "(", "p", "=", "0.5", ",", "scales", "=", "(", "self", ".", "scale", ",", "0", ",", "0", ")", ",", "degrees", "=", "(", "self", ".", "degrees", ",", "0", ",", "0", ")", ")", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "", "", "self", ".", "augment_fn_spatial", "=", "tio", ".", "Compose", "(", "augment_list_spatial", ")", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "'No augmentation.'", ")", "\n", "self", ".", "augment_fn_intensity", ",", "self", ".", "augment_fn_spatial", "=", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.longitudinalh5_dataset.Longitudinalh5Dataset.__getitem__": [[124, 318], ["dict", "longitudinalh5_dataset.process_age", "numpy.asarray", "longitudinalh5_dataset.process_age", "numpy.asarray", "len", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "data.data_utils.normalize_img", "[].astype", "data.data_utils.normalize_img", "[].astype", "torchio.Subject", "torchio.Subject", "longitudinalh5_dataset.Longitudinalh5Dataset.augment_fn_spatial", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "longitudinalh5_dataset.Longitudinalh5Dataset.pre_resize", "longitudinalh5_dataset.Longitudinalh5Dataset.augment_fn_intensity", "longitudinalh5_dataset.Longitudinalh5Dataset.get_composed_history", "longitudinalh5_dataset.Longitudinalh5Dataset.get_composed_history.", "longitudinalh5_dataset.Longitudinalh5Dataset.get_composed_history", "longitudinalh5_dataset.Longitudinalh5Dataset.get_composed_history.", "longitudinalh5_dataset.Longitudinalh5Dataset.augment_fn_intensity", "longitudinalh5_dataset.Longitudinalh5Dataset.augment_fn_intensity", "torchio.Subject", "longitudinalh5_dataset.Longitudinalh5Dataset.pre_resize", "longitudinalh5_dataset.Longitudinalh5Dataset.get_composed_history", "torchio.Subject", "longitudinalh5_dataset.Longitudinalh5Dataset.get_composed_history.", "longitudinalh5_dataset.process_age", "torchio.Subject", "longitudinalh5_dataset.Longitudinalh5Dataset.augment_fn_intensity", "longitudinalh5_dataset.Longitudinalh5Dataset.augment_fn_spatial", "longitudinalh5_dataset.Longitudinalh5Dataset.get_composed_history", "str", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torchio.ScalarImage", "torchio.ScalarImage", "longitudinalh5_dataset.Longitudinalh5Dataset.get_composed_history", "longitudinalh5_dataset.process_age", "list", "len", "numpy.random.randint", "numpy.random.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torchio.ScalarImage", "torchio.ScalarImage", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "data.data_utils.normalize_img", "data.data_utils.normalize_img", "torchio.ScalarImage", "torchio.LabelMap", "len", "len", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "longitudinalh5_dataset.Longitudinalh5Dataset.get_composed_history.", "numpy.asarray", "int", "int", "len", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "data.data_utils.normalize_img", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "torch.randint().numpy", "data.data_utils.normalize_img", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "numpy.sum", "int", "int", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "data.data_utils.normalize_img", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.longitudinalh5_dataset.process_age", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.longitudinalh5_dataset.process_age", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.data_utils.normalize_img", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.data_utils.normalize_img", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.longitudinalh5_dataset.process_age", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.longitudinalh5_dataset.process_age", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.data_utils.normalize_img", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.data_utils.normalize_img", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.data_utils.normalize_img", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.data_utils.normalize_img", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.data_utils.normalize_img"], ["", "", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return_dict", "=", "dict", "(", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'long_pairs'", ":", "# only support 3D", "\n", "            ", "while", "item", ">=", "len", "(", "self", ".", "subj_id", ")", ":", "\n", "                ", "item", "=", "torch", ".", "randint", "(", "0", ",", "self", ".", "len", ",", "(", ")", ")", ".", "numpy", "(", ")", "\n", "", "assert", "self", ".", "dimension", "==", "3", ",", "f'Only support 3D data loading in mode {self.mode}'", "\n", "subj", "=", "self", ".", "subj_id", "[", "item", "]", "\n", "n_tps_per_subj", "=", "self", ".", "hf", "[", "subj", "]", "[", "'t1'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "# restrict the pairs to from neighboring timepoints", "\n", "if", "self", ".", "opt", ".", "tp_order", ":", "\n", "                ", "i", "=", "torch", ".", "randint", "(", "0", ",", "n_tps_per_subj", "-", "1", ",", "(", ")", ")", ".", "numpy", "(", ")", "\n", "j", "=", "i", "+", "1", "\n", "", "else", ":", "\n", "# restrict the pairs to from random timepoints per subject", "\n", "                ", "i", "=", "torch", ".", "randint", "(", "0", ",", "n_tps_per_subj", ",", "(", ")", ")", ".", "numpy", "(", ")", "\n", "j", "=", "torch", ".", "randint", "(", "0", ",", "n_tps_per_subj", ",", "(", ")", ")", ".", "numpy", "(", ")", "\n", "while", "j", "==", "i", ":", "\n", "                    ", "j", "=", "torch", ".", "randint", "(", "0", ",", "n_tps_per_subj", ",", "(", ")", ")", ".", "numpy", "(", ")", "\n", "\n", "", "", "img_keys", "=", "[", "'A'", ",", "'B'", "]", "\n", "if", "self", ".", "load_recon", ":", "\n", "                ", "img_keys", "+=", "[", "'A_trg'", ",", "'B_trg'", "]", "\n", "\n", "", "A_orig", "=", "normalize_img", "(", "self", ".", "hf", "[", "subj", "]", "[", "'t1'", "]", "[", "i", "]", ",", "percentile", "=", "self", ".", "percentile", ",", "zero_centered", "=", "self", ".", "zero_centered", ")", "[", "None", ",", "...", "]", "\n", "return_dict", "[", "'A_age'", "]", "=", "process_age", "(", "self", ".", "hf", "[", "subj", "]", "[", "'age'", "]", "[", "i", "]", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "return_dict", "[", "'A_id'", "]", "=", "np", ".", "asarray", "(", "[", "item", "]", ")", "# dummy variable that contains the subject id", "\n", "\n", "B_orig", "=", "normalize_img", "(", "self", ".", "hf", "[", "subj", "]", "[", "'t1'", "]", "[", "j", "]", ",", "percentile", "=", "self", ".", "percentile", ",", "zero_centered", "=", "self", ".", "zero_centered", ")", "[", "None", ",", "...", "]", "\n", "return_dict", "[", "'B_age'", "]", "=", "process_age", "(", "self", ".", "hf", "[", "subj", "]", "[", "'age'", "]", "[", "j", "]", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "return_dict", "[", "'meta'", "]", "=", "'%s_%.1f_%.1f'", "%", "(", "subj", ",", "self", ".", "hf", "[", "subj", "]", "[", "'age'", "]", "[", "i", "]", ",", "self", ".", "hf", "[", "subj", "]", "[", "'age'", "]", "[", "j", "]", ")", "\n", "return_dict", "[", "'B_id'", "]", "=", "np", ".", "asarray", "(", "[", "item", "]", ")", "# dummy variable that contains the subject id", "\n", "\n", "\n", "if", "self", ".", "opt", ".", "augment", "and", "self", ".", "isTrain", ":", "\n", "                ", "A", "=", "tio", ".", "Subject", "(", "img", "=", "tio", ".", "ScalarImage", "(", "tensor", "=", "torch", ".", "from_numpy", "(", "A_orig", ")", ")", ")", "\n", "B", "=", "tio", ".", "Subject", "(", "img", "=", "tio", ".", "ScalarImage", "(", "tensor", "=", "torch", ".", "from_numpy", "(", "B_orig", ")", ")", ")", "\n", "\n", "if", "self", ".", "opt", ".", "resize", ":", "\n", "                    ", "A", "=", "self", ".", "pre_resize", "(", "A", ")", "\n", "\n", "", "A", "=", "self", ".", "augment_fn_spatial", "(", "A", ")", "\n", "if", "self", ".", "load_recon", ":", "\n", "                    ", "return_dict", "[", "'A_trg'", "]", "=", "A", "[", "'img'", "]", "[", "tio", ".", "DATA", "]", "\n", "", "if", "self", ".", "apply_same_inten_augment", ":", "\n", "                    ", "if", "self", ".", "load_recon", ":", "\n", "                        ", "geo_transform", "=", "A", ".", "get_composed_history", "(", ")", "\n", "return_dict", "[", "'B_trg'", "]", "=", "geo_transform", "(", "B", ")", "[", "'img'", "]", "[", "tio", ".", "DATA", "]", "\n", "\n", "", "A", "=", "self", ".", "augment_fn_intensity", "(", "A", ")", "\n", "all_transform", "=", "A", ".", "get_composed_history", "(", ")", "\n", "B", "=", "all_transform", "(", "B", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "geo_transform", "=", "A", ".", "get_composed_history", "(", ")", "\n", "B", "=", "geo_transform", "(", "B", ")", "\n", "if", "self", ".", "load_recon", ":", "\n", "                        ", "return_dict", "[", "'B_trg'", "]", "=", "B", "[", "'img'", "]", "[", "tio", ".", "DATA", "]", "\n", "\n", "", "A", "=", "self", ".", "augment_fn_intensity", "(", "A", ")", "\n", "B", "=", "self", ".", "augment_fn_intensity", "(", "B", ")", "\n", "\n", "", "return_dict", "[", "'A'", "]", "=", "A", "[", "'img'", "]", "[", "tio", ".", "DATA", "]", "\n", "return_dict", "[", "'B'", "]", "=", "B", "[", "'img'", "]", "[", "tio", ".", "DATA", "]", "\n", "\n", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "opt", ".", "resize", ":", "\n", "                    ", "A", "=", "tio", ".", "Subject", "(", "img", "=", "tio", ".", "ScalarImage", "(", "tensor", "=", "torch", ".", "from_numpy", "(", "A_orig", ")", ")", ")", "\n", "A", "=", "self", ".", "pre_resize", "(", "A", ")", "\n", "A_orig", "=", "A", "[", "'img'", "]", "[", "tio", ".", "DATA", "]", "\n", "reproduce_transform", "=", "A", ".", "get_composed_history", "(", ")", "\n", "B", "=", "tio", ".", "Subject", "(", "img", "=", "tio", ".", "ScalarImage", "(", "tensor", "=", "torch", ".", "from_numpy", "(", "B_orig", ")", ")", ")", "\n", "B", "=", "reproduce_transform", "(", "B", ")", "\n", "B_orig", "=", "B", "[", "'img'", "]", "[", "tio", ".", "DATA", "]", "\n", "\n", "", "return_dict", "[", "'A'", "]", "=", "A_orig", "\n", "return_dict", "[", "'B'", "]", "=", "B_orig", "\n", "if", "self", ".", "load_recon", ":", "\n", "                    ", "return_dict", "[", "'A_trg'", "]", "=", "A_orig", "\n", "return_dict", "[", "'B_trg'", "]", "=", "B_orig", "\n", "\n", "", "if", "self", ".", "load_mask", ":", "\n", "                    ", "img_keys", "=", "[", "'A'", ",", "'B'", ",", "'A_mask'", ",", "'B_mask'", "]", "\n", "return_dict", "[", "'A_mask'", "]", "=", "self", ".", "hf", "[", "subj", "]", "[", "'mask'", "]", "[", "i", "]", "[", "None", ",", "...", "]", "\n", "return_dict", "[", "'B_mask'", "]", "=", "self", ".", "hf", "[", "subj", "]", "[", "'mask'", "]", "[", "j", "]", "[", "None", ",", "...", "]", "\n", "\n", "", "", "", "elif", "self", ".", "mode", "==", "'single_seg'", ":", "# for training", "\n", "            ", "img_keys", "=", "[", "'A'", ",", "'A_seg'", "]", "\n", "\n", "if", "self", ".", "use_numpy", "is", "False", ":", "\n", "#print(item)", "\n", "                ", "if", "self", ".", "dimension", "==", "3", ":", "\n", "                    ", "while", "item", ">=", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'t1'", "]", ".", "shape", "[", "0", "]", ":", "\n", "                        ", "item", "=", "torch", ".", "randint", "(", "0", ",", "self", ".", "len", ",", "(", ")", ")", ".", "numpy", "(", ")", "\n", "", "A_orig", "=", "normalize_img", "(", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'t1'", "]", "[", "item", "]", ",", "percentile", "=", "self", ".", "percentile", ",", "zero_centered", "=", "self", ".", "zero_centered", ")", "[", "None", ",", "...", "]", "\n", "A_seg", "=", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'seg'", "]", "[", "item", "]", "\n", "label_age", "=", "process_age", "(", "np", ".", "asarray", "(", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'age'", "]", ")", "[", "item", "]", ",", "amin", "=", "42", ",", "amax", "=", "97", ")", "\n", "\n", "", "elif", "self", ".", "dimension", "==", "2", ":", "\n", "                    ", "nitem", ",", "nslc", "=", "int", "(", "item", "/", "self", ".", "nframes", ")", ",", "int", "(", "item", "%", "self", ".", "nframes", ")", "\n", "#print(nitem, nslc)", "\n", "A_orig", "=", "normalize_img", "(", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'t1'", "]", "[", "nitem", "]", "[", "nslc", "]", ",", "\n", "percentile", "=", "self", ".", "percentile", ",", "zero_centered", "=", "self", ".", "zero_centered", ")", "[", "None", ",", "...", "]", "[", "None", ",", "...", "]", "\n", "if", "self", ".", "isTrain", ":", "\n", "                        ", "it", "=", "0", "\n", "while", "np", ".", "sum", "(", "A_orig", ")", "==", "0", "and", "it", "<", "10", ":", "# avoid empty slice in training", "\n", "                            ", "item", "=", "torch", ".", "randint", "(", "0", ",", "self", ".", "len", ",", "(", ")", ")", ".", "numpy", "(", ")", "\n", "nitem", ",", "nslc", "=", "int", "(", "item", "/", "self", ".", "nframes", ")", ",", "int", "(", "item", "%", "self", ".", "nframes", ")", "\n", "A_orig", "=", "normalize_img", "(", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'t1'", "]", "[", "nitem", "]", "[", "nslc", "]", ",", "\n", "percentile", "=", "self", ".", "percentile", ",", "zero_centered", "=", "self", ".", "zero_centered", ")", "[", "None", ",", "...", "]", "[", "None", ",", "...", "]", "\n", "it", "+=", "1", "\n", "\n", "", "", "A_seg", "=", "self", ".", "hf", "[", "'img_seg_pair'", "]", "[", "'seg'", "]", "[", "nitem", "]", "[", "nslc", "]", "[", "None", ",", "...", "]", "\n", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "", "return_dict", "[", "'label_age'", "]", "=", "label_age", "\n", "\n", "", "else", ":", "\n", "                ", "return_dict", "[", "'label_age'", "]", "=", "process_age", "(", "self", ".", "data", "[", "'age'", "]", ",", "amin", "=", "42", ",", "amax", "=", "97", ")", "\n", "if", "self", ".", "dimension", "==", "3", ":", "\n", "                    ", "A_orig", "=", "normalize_img", "(", "self", ".", "data", "[", "'t1'", "]", ",", "percentile", "=", "self", ".", "percentile", ",", "zero_centered", "=", "self", ".", "zero_centered", ")", "[", "None", ",", "...", "]", "\n", "A_seg", "=", "self", ".", "data", "[", "'seg'", "]", "\n", "", "elif", "self", ".", "dimension", "==", "2", ":", "\n", "                    ", "A_orig", "=", "normalize_img", "(", "self", ".", "data", "[", "'t1'", "]", "[", "item", "]", ",", "percentile", "=", "self", ".", "percentile", ",", "zero_centered", "=", "self", ".", "zero_centered", ")", "[", "None", ",", "...", "]", "[", "None", ",", "...", "]", "\n", "A_seg", "=", "self", ".", "data", "[", "'seg'", "]", "[", "item", "]", "[", "None", ",", "...", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "\n", "\n", "", "", "if", "self", ".", "opt", ".", "augment", "and", "self", ".", "isTrain", ":", "\n", "                ", "A", "=", "tio", ".", "Subject", "(", "img", "=", "tio", ".", "ScalarImage", "(", "tensor", "=", "torch", ".", "from_numpy", "(", "A_orig", ")", ")", ",", "\n", "label", "=", "tio", ".", "LabelMap", "(", "tensor", "=", "torch", ".", "from_numpy", "(", "A_seg", ")", ".", "unsqueeze", "(", "0", ")", ")", ")", "\n", "A", "=", "self", ".", "augment_fn_intensity", "(", "A", ")", "\n", "A", "=", "self", ".", "augment_fn_spatial", "(", "A", ")", "\n", "reproduce_transform", "=", "A", ".", "get_composed_history", "(", ")", "\n", "return_dict", "[", "'transform'", "]", "=", "str", "(", "list", "(", "reproduce_transform", ")", ")", "\n", "return_dict", "[", "'A'", "]", "=", "A", "[", "'img'", "]", "[", "tio", ".", "DATA", "]", "\n", "return_dict", "[", "'A_seg'", "]", "=", "A", "[", "'label'", "]", "[", "tio", ".", "DATA", "]", "[", "0", "]", "\n", "\n", "", "else", ":", "\n", "                ", "return_dict", "[", "'A'", "]", "=", "A_orig", "\n", "return_dict", "[", "'A_seg'", "]", "=", "A_seg", "\n", "\n", "", "if", "self", ".", "dimension", "==", "2", ":", "\n", "                ", "for", "k", "in", "img_keys", ":", "\n", "                    ", "return_dict", "[", "k", "]", "=", "return_dict", "[", "k", "]", "[", "0", "]", "# remove the 1st dimension", "\n", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "return_dict", "[", "'keys'", "]", "=", "img_keys", "\n", "\n", "\n", "if", "self", ".", "crop_size", ">", "0", "and", "self", ".", "opt", ".", "isTrain", "and", "(", "not", "self", ".", "opt", ".", "resize", ")", ":", "\n", "            ", "if", "self", ".", "dimension", "==", "3", ":", "\n", "                ", "sx", ",", "sy", ",", "sz", "=", "return_dict", "[", "'A'", "]", ".", "shape", "[", "1", ":", "]", "\n", "crange", "=", "self", ".", "crop_size", "//", "2", "\n", "\n", "cx", "=", "np", ".", "random", ".", "randint", "(", "crange", ",", "sx", "-", "crange", ")", "if", "sx", ">", "2", "*", "crange", "else", "crange", "\n", "cy", "=", "np", ".", "random", ".", "randint", "(", "crange", ",", "sy", "-", "crange", ")", "if", "sy", ">", "2", "*", "crange", "else", "crange", "\n", "cz", "=", "np", ".", "random", ".", "randint", "(", "crange", ",", "sz", "-", "crange", ")", "if", "sz", ">", "2", "*", "crange", "else", "crange", "\n", "#cx, cy, cz = 80, 80, 80", "\n", "#print(sx, sy, sz, cx, cy, cz)", "\n", "for", "k", "in", "img_keys", ":", "\n", "                    ", "tmp", "=", "return_dict", "[", "k", "]", "\n", "if", "len", "(", "tmp", ".", "shape", ")", "==", "4", ":", "\n", "                        ", "return_dict", "[", "k", "]", "=", "tmp", "[", ":", ",", "cx", "-", "crange", ":", "cx", "+", "crange", ",", "cy", "-", "crange", ":", "cy", "+", "crange", ",", "cz", "-", "crange", ":", "cz", "+", "crange", "]", "\n", "", "elif", "len", "(", "tmp", ".", "shape", ")", "==", "3", ":", "\n", "                        ", "return_dict", "[", "k", "]", "=", "tmp", "[", "cx", "-", "crange", ":", "cx", "+", "crange", ",", "cy", "-", "crange", ":", "cy", "+", "crange", ",", "cz", "-", "crange", ":", "cz", "+", "crange", "]", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "", "", "del", "tmp", "\n", "", "elif", "self", ".", "dimension", "==", "2", ":", "\n", "                ", "sx", ",", "sy", "=", "return_dict", "[", "'A'", "]", ".", "shape", "[", "1", ":", "]", "\n", "crange", "=", "self", ".", "crop_size", "//", "2", "\n", "\n", "cx", "=", "np", ".", "random", ".", "randint", "(", "crange", ",", "sx", "-", "crange", ")", "if", "sx", ">", "2", "*", "crange", "else", "crange", "\n", "cy", "=", "np", ".", "random", ".", "randint", "(", "crange", ",", "sy", "-", "crange", ")", "if", "sy", ">", "2", "*", "crange", "else", "crange", "\n", "for", "k", "in", "img_keys", ":", "\n", "                    ", "tmp", "=", "return_dict", "[", "k", "]", "\n", "if", "len", "(", "tmp", ".", "shape", ")", "==", "3", ":", "\n", "                        ", "return_dict", "[", "k", "]", "=", "tmp", "[", ":", ",", "cx", "-", "crange", ":", "cx", "+", "crange", ",", "cy", "-", "crange", ":", "cy", "+", "crange", "]", "\n", "", "elif", "len", "(", "tmp", ".", "shape", ")", "==", "2", ":", "\n", "                        ", "return_dict", "[", "k", "]", "=", "tmp", "[", "cx", "-", "crange", ":", "cx", "+", "crange", ",", "cy", "-", "crange", ":", "cy", "+", "crange", "]", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "\n", "", "", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "return", "return_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.longitudinalh5_dataset.Longitudinalh5Dataset.__len__": [[319, 321], ["max"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "max", "(", "self", ".", "len", ",", "self", ".", "opt", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.longitudinalh5_dataset.process_age": [[10, 18], ["numpy.isscalar", "float", "isinstance", "age.astype"], "function", ["None"], ["def", "process_age", "(", "age", ",", "amin", "=", "42.", ",", "amax", "=", "97.", ")", ":", "\n", "    ", "age", "=", "(", "age", "-", "amin", ")", "/", "(", "amax", "-", "amin", ")", "# normalize", "\n", "if", "np", ".", "isscalar", "(", "age", ")", ":", "\n", "        ", "return", "float", "(", "age", ")", "\n", "", "elif", "isinstance", "(", "age", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "return", "age", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.data_utils.normalize_img": [[5, 19], ["numpy.min", "numpy.percentile", "print", "print", "numpy.min", "numpy.max"], "function", ["None"], ["def", "normalize_img", "(", "array", ",", "percentile", "=", "None", ",", "zero_centered", "=", "True", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "min_", "=", "np", ".", "min", "(", "array", ")", "\n", "max_", "=", "np", ".", "percentile", "(", "array", ",", "percentile", ")", "\n", "#print(max_, min_)", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'original range: {},{}'", ".", "format", "(", "min_", ",", "max_", ")", ")", "\n", "\n", "", "if", "max_", "-", "min_", ">", "0", ":", "\n", "        ", "array", "=", "(", "array", "-", "min_", ")", "/", "(", "max_", "-", "min_", ")", "# [0,1] normalized", "\n", "", "if", "zero_centered", ":", "# [-1,1] normalized", "\n", "        ", "array", "=", "array", "*", "2", "-", "1", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'normalized to range {}, {}'", ".", "format", "(", "np", ".", "min", "(", "array", ")", ",", "np", ".", "max", "(", "array", ")", ")", ")", "\n", "", "return", "array", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.data_utils.renormalize_img": [[21, 28], ["print", "img.max", "img.min", "img.min", "img.max", "img.min", "img.max", "img.min"], "function", ["None"], ["", "def", "renormalize_img", "(", "img", ",", "id_", "=", "''", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "if", "verbose", ":", "\n", "        ", "print", "(", "'{} | rescale from [{}.{}] to [0,1]'", ".", "format", "(", "id_", ",", "img", ".", "min", "(", ")", ",", "img", ".", "max", "(", ")", ")", ")", "\n", "", "if", "img", ".", "max", "(", ")", "-", "img", ".", "min", "(", ")", ">", "0", ":", "\n", "        ", "return", "(", "img", "-", "img", ".", "min", "(", ")", ")", "/", "(", "img", ".", "max", "(", ")", "-", "img", ".", "min", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "img", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.base_dataset.BaseDataset.__init__": [[23, 32], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Initialize the class; save the options in the class\n\n        Parameters:\n            opt (Option class)-- stores all the experiment flags; needs to be a subclass of BaseOptions\n        \"\"\"", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "root", "=", "opt", ".", "dataroot", "\n", "self", ".", "current_epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.base_dataset.BaseDataset.modify_commandline_options": [[33, 45], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "modify_commandline_options", "(", "parser", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Add new dataset-specific options, and rewrite default values for existing options.\n\n        Parameters:\n            parser          -- original option parser\n            is_train (bool) -- whether training phase or test phase. You can use this flag to add training-specific or test-specific options.\n\n        Returns:\n            the modified parser.\n        \"\"\"", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.base_dataset.BaseDataset.__len__": [[46, 50], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the total number of images in the dataset.\"\"\"", "\n", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.base_dataset.BaseDataset.__getitem__": [[51, 62], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Return a data point and its metadata information.\n\n        Parameters:\n            index - - a random integer for data indexing\n\n        Returns:\n            a dictionary of data with their names. It ususally contains the data itself and its metadata information.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.CustomDatasetDataLoader.__init__": [[71, 105], ["__init__.find_dataset_using_name", "find_dataset_using_name.", "print", "print", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "type", "xm.xrt_world_size", "xm.get_ordinal", "int"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.find_dataset_using_name"], []], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.CustomDatasetDataLoader.set_epoch": [[107, 109], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.CustomDatasetDataLoader.load_data": [[110, 112], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.CustomDatasetDataLoader.__len__": [[113, 116], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.CustomDatasetDataLoader.__iter__": [[117, 121], ["enumerate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.find_dataset_using_name": [[19, 40], ["importlib.import_module", "importlib.import_module.__dict__.items", "dataset_name.replace", "NotImplementedError", "issubclass", "name.lower", "target_dataset_name.lower"], "function", ["None"], ["\n", "\n", "import", "importlib", "\n", "from", "models", ".", "base_model", "import", "BaseModel", "\n", "\n", "\n", "def", "find_model_using_name", "(", "model_name", ")", ":", "\n", "    ", "\"\"\"Import the module \"models/[model_name]_model.py\".\n\n    In the file, the class called DatasetNameModel() will\n    be instantiated. It has to be a subclass of BaseModel,\n    and it is case-insensitive.\n    \"\"\"", "\n", "model_filename", "=", "\"models.\"", "+", "model_name", "+", "\"_model\"", "\n", "modellib", "=", "importlib", ".", "import_module", "(", "model_filename", ")", "\n", "model", "=", "None", "\n", "target_model_name", "=", "model_name", ".", "replace", "(", "'_'", ",", "''", ")", "+", "'model'", "\n", "for", "name", ",", "cls", "in", "modellib", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "        ", "if", "name", ".", "lower", "(", ")", "==", "target_model_name", ".", "lower", "(", ")", "and", "issubclass", "(", "cls", ",", "BaseModel", ")", ":", "\n", "            ", "model", "=", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.get_option_setter": [[42, 46], ["__init__.find_dataset_using_name"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.find_dataset_using_name"], ["        ", "print", "(", "\"In %s.py, there should be a subclass of BaseModel with class name that matches %s in lowercase.\"", "%", "(", "model_filename", ",", "target_model_name", ")", ")", "\n", "exit", "(", "0", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.create_dataset": [[48, 61], ["__init__.CustomDatasetDataLoader", "__init__.CustomDatasetDataLoader.load_data"], "function", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.CustomDatasetDataLoader.load_data"], ["", "def", "get_option_setter", "(", "model_name", ")", ":", "\n", "    ", "\"\"\"Return the static method <modify_commandline_options> of the model class.\"\"\"", "\n", "model_class", "=", "find_model_using_name", "(", "model_name", ")", "\n", "return", "model_class", ".", "modify_commandline_options", "\n", "\n", "\n", "", "def", "create_model", "(", "opt", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.seed_worker": [[63, 67], ["numpy.random.seed", "random.seed", "torch.initial_seed"], "function", ["None"], ["\n", "model", "=", "find_model_using_name", "(", "opt", ".", "model", ")", "\n", "instance", "=", "model", "(", "opt", ")", "\n", "print", "(", "\"model [%s] was created\"", "%", "type", "(", "instance", ")", ".", "__name__", ")", "\n", "return", "instance", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.test_options.TestOptions.initialize": [[11, 27], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.initialize"], ["def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "# define shared options", "\n", "parser", ".", "add_argument", "(", "'--results_dir'", ",", "type", "=", "str", ",", "default", "=", "'./results/'", ",", "help", "=", "'saves results here.'", ")", "\n", "# Dropout and Batchnorm has different behavioir during training and test.", "\n", "parser", ".", "add_argument", "(", "'--eval'", ",", "action", "=", "'store_true'", ",", "help", "=", "'use eval mode during test time.'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'test'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_test'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'maximum number of images'", ")", "\n", "parser", ".", "add_argument", "(", "'--j'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'parallel running'", ")", "\n", "parser", ".", "add_argument", "(", "'--average'", ",", "action", "=", "'store_true'", ",", "help", "=", "'only used when crop size is not -1, if True, average sliding window results'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_name'", ",", "type", "=", "str", ",", "default", "=", "'val'", ",", "help", "=", "'txt file prefix'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--evaluation_space'", ",", "type", "=", "str", ",", "default", "=", "'affine'", ",", "choices", "=", "[", "'raw'", ",", "'affine'", ",", "'affine_and_deform'", "]", ",", "help", "=", "'evaluate in which space'", ")", "\n", "parser", ".", "add_argument", "(", "'--evaluation_data'", ",", "type", "=", "str", ",", "default", "=", "'prediction'", ",", "choices", "=", "[", "'prediction'", ",", "'static'", "]", ",", "help", "=", "'evaluate on data'", ")", "\n", "\n", "self", ".", "isTrain", "=", "False", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.train_options.TrainOptions.initialize": [[11, 55], ["base_options.BaseOptions.initialize", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument", "base_options.BaseOptions.initialize.add_argument"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.initialize"], ["def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "parser", "=", "BaseOptions", ".", "initialize", "(", "self", ",", "parser", ")", "\n", "# visdom and HTML visualization parameters", "\n", "parser", ".", "add_argument", "(", "'--display_freq'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'frequency of showing training results on screen'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_ncols'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'if positive, display all images in a single visdom web panel with certain number of images per row.'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_id'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'window id of the web display. Default is random window id'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_port'", ",", "type", "=", "int", ",", "default", "=", "8097", ",", "help", "=", "'visdom port of the web display'", ")", "\n", "parser", ".", "add_argument", "(", "'--display_slice'", ",", "type", "=", "int", ",", "default", "=", "80", ",", "help", "=", "'the slice index to display if inputs are 3D volumes '", ")", "\n", "parser", ".", "add_argument", "(", "'--print_freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'frequency of showing training results on console'", ")", "\n", "# network saving and loading parameters", "\n", "parser", ".", "add_argument", "(", "'--save_latest_freq'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "help", "=", "'frequency of saving the latest results'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_freq'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'frequency of saving checkpoints at the end of iterationss'", ")", "\n", "parser", ".", "add_argument", "(", "'--evaluation_freq'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "help", "=", "'evaluation freq'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_by_iter'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether saves model by iteration'", ")", "\n", "parser", ".", "add_argument", "(", "'--continue_train'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "False", ",", "help", "=", "'continue training: load the latest model'", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch_count'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'the starting epoch count, we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>, ...'", ")", "\n", "parser", ".", "add_argument", "(", "'--phase'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "help", "=", "'train, val, test, etc'", ")", "\n", "parser", ".", "add_argument", "(", "'--pretrained_name'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'resume training from another checkpoint'", ")", "\n", "\n", "# training parameters", "\n", "parser", ".", "add_argument", "(", "'--n_epochs'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'number of epochs with the initial learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--n_epochs_decay'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'number of epochs to linearly decay learning rate to zero'", ")", "\n", "parser", ".", "add_argument", "(", "'--stop_epoch'", ",", "type", "=", "int", ",", "default", "=", "99999999", ",", "help", "=", "'number of epochs to stop training'", ")", "\n", "parser", ".", "add_argument", "(", "'--partial_train'", ",", "type", "=", "str", ",", "default", "=", "'1'", ",", "help", "=", "'only use partial training samples (0-1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_iters'", ",", "type", "=", "int", ",", "default", "=", "100000", ",", "help", "=", "'maximum iterations. Training will stop after that.'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--beta1'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'momentum term of adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--beta2'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "help", "=", "'momentum term of adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--eps'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "help", "=", "'denominator for Adam for stability'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "help", "=", "'weight decay in Adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--ams_grad'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "False", ",", "help", "=", "'whether to use amsgrad'", ")", "\n", "parser", ".", "add_argument", "(", "'--clip_grad'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "False", ",", "help", "=", "'whether to clip gradient'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_norm'", ",", "type", "=", "float", ",", "default", "=", "2", ",", "help", "=", "'gradient clip norm max'", ")", "\n", "parser", ".", "add_argument", "(", "'--grad_accum_iters'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'number of iters to accumulate gradient'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.0002", ",", "help", "=", "'initial learning rate for adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--pool_size'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'the size of image buffer that stores previously generated images'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_policy'", ",", "type", "=", "str", ",", "default", "=", "'linear'", ",", "help", "=", "'learning rate policy. [linear | step | plateau | cosine]'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_iters'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'multiply by a gamma every lr_decay_iters iterations'", ")", "\n", "parser", ".", "add_argument", "(", "'--freeze_bn'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "False", ",", "help", "=", "'freeze BN layers'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--n_val_during_train'", ",", "type", "=", "int", ",", "default", "=", "999", ",", "help", "=", "\"number of samples for validation during training\"", ")", "\n", "self", ".", "isTrain", "=", "True", "\n", "return", "parser", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.__init__": [[17, 23], ["cmd_line.split"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cmd_line", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reset the class; indicates the class hasn't been initailized\"\"\"", "\n", "self", ".", "initialized", "=", "False", "\n", "self", ".", "cmd_line", "=", "None", "\n", "if", "cmd_line", "is", "not", "None", ":", "\n", "            ", "self", ".", "cmd_line", "=", "cmd_line", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.initialize": [[24, 94], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "", "def", "initialize", "(", "self", ",", "parser", ")", ":", "\n", "        ", "\"\"\"Define the common options that are used in both training and test.\"\"\"", "\n", "# basic parameters", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "type", "=", "str", ",", "default", "=", "'experiment_name'", ",", "help", "=", "'name of the experiment. It decides where to store samples and models'", ")", "\n", "parser", ".", "add_argument", "(", "'--easy_label'", ",", "type", "=", "str", ",", "default", "=", "'experiment_name'", ",", "help", "=", "'Interpretable name'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_ids'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU, -2 for TPU'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--checkpoints_dir'", ",", "type", "=", "str", ",", "default", "=", "'../../checkpoints'", ",", "help", "=", "'models are saved here'", ")", "\n", "# model parameters", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'longcl'", ",", "help", "=", "'chooses which model to use.'", ")", "\n", "parser", ".", "add_argument", "(", "'--ndims'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'network dimension: 2|3'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_nc'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'# of input image channels: 3 for RGB and 1 for grayscale'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_nc'", ",", "type", "=", "int", ",", "default", "=", "33", ",", "help", "=", "'# of output image channels: 3 for RGB and 1 for grayscale'", ")", "\n", "parser", ".", "add_argument", "(", "'--ngf'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "'# of gen filters in the last conv layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--skip_connection'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "False", ",", "help", "=", "'whether to add skip connection'", ")", "\n", "parser", ".", "add_argument", "(", "'--netG'", ",", "type", "=", "str", ",", "default", "=", "'unet'", ",", "choices", "=", "[", "'noiseunet'", ",", "'noskipunet'", ",", "'unet'", "]", ",", "help", "=", "'specify generator architecture'", ")", "\n", "parser", ".", "add_argument", "(", "'--normG'", ",", "type", "=", "str", ",", "default", "=", "'batch'", ",", "choices", "=", "[", "'instance'", ",", "'batch'", ",", "'none'", ",", "'layer'", "]", ",", "help", "=", "'instance normalization or batch normalization for G'", ")", "\n", "parser", ".", "add_argument", "(", "'--actG'", ",", "type", "=", "str", ",", "default", "=", "'relu'", ",", "choices", "=", "[", "'relu'", ",", "'lrelu'", "]", ",", "help", "=", "'relu or lrelu'", ")", "\n", "parser", ".", "add_argument", "(", "'--actF'", ",", "type", "=", "str", ",", "default", "=", "'relu'", ",", "choices", "=", "[", "'relu'", ",", "'lrelu'", "]", ",", "help", "=", "'relu or lrelu'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_type'", ",", "type", "=", "str", ",", "default", "=", "'xavier'", ",", "choices", "=", "[", "'normal'", ",", "'xavier'", ",", "'kaiming'", ",", "'orthogonal'", "]", ",", "help", "=", "'network initialization'", ")", "\n", "parser", ".", "add_argument", "(", "'--init_gain'", ",", "type", "=", "float", ",", "default", "=", "0.02", ",", "help", "=", "'scaling factor for normal, xavier and orthogonal.'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_dropout'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "\n", "help", "=", "'no dropout for the generator'", ")", "\n", "parser", ".", "add_argument", "(", "'--pool_type'", ",", "type", "=", "str", ",", "default", "=", "'Max'", ",", "choices", "=", "[", "'Max'", ",", "'Avg'", "]", ",", "help", "=", "'pooling type for downsampling'", ")", "\n", "parser", ".", "add_argument", "(", "'--interp_type'", ",", "type", "=", "str", ",", "default", "=", "'nearest'", ",", "choices", "=", "[", "'nearest'", ",", "'trilinear'", "]", ",", "help", "=", "'interpolation type for upsampling'", ")", "\n", "parser", ".", "add_argument", "(", "'--lambda_Rec'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "help", "=", "'weight for Recon loss'", ")", "\n", "\n", "# dice loss parameters", "\n", "parser", ".", "add_argument", "(", "'--smooth_dr'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "help", "=", "'denominator smoothing of Dice'", ")", "\n", "parser", ".", "add_argument", "(", "'--smooth_nr'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "help", "=", "'numerator smoothing of Dice'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_dice'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "False", ",", "help", "=", "'Whether to use batch dice'", ")", "\n", "parser", ".", "add_argument", "(", "'--include_background'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'Whether to include background in dice'", ")", "\n", "\n", "\n", "# dataset parameters", "\n", "parser", ".", "add_argument", "(", "'--dataroot'", ",", "default", "=", "'placeholder'", ",", "help", "=", "'path to images'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_mode'", ",", "type", "=", "str", ",", "default", "=", "'longitudinalIBIS'", ",", "help", "=", "'chooses datasets'", ")", "\n", "parser", ".", "add_argument", "(", "'--validation_prefix'", ",", "type", "=", "str", ",", "default", "=", "'image_seg_3d'", ",", "help", "=", "'chooses validation file'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_ndims'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'data dimension'", ")", "\n", "parser", ".", "add_argument", "(", "'--h5_prefix'", ",", "type", "=", "str", ",", "default", "=", "'_'", ",", "choices", "=", "[", "'_mini_'", ",", "'_'", "]", ",", "help", "=", "'prefix of h5 for getting different settings'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--tp_order'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "False", ",", "help", "=", "'Whether to load tps in order'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_mode'", ",", "type", "=", "str", ",", "default", "=", "'random'", ",", "help", "=", "'load subject&tps randomly (train) or by order (test time)'", ")", "\n", "parser", ".", "add_argument", "(", "'--id_age_list'", ",", "type", "=", "str", ",", "default", "=", "'txt file placeholder'", ",", "help", "=", "'subject based text file for training'", ")", "\n", "parser", ".", "add_argument", "(", "'--normalize'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'Whether to normalize data'", ")", "\n", "\n", "# augmentation specs", "\n", "parser", ".", "add_argument", "(", "'--augment'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'Whether to augment data'", ")", "\n", "parser", ".", "add_argument", "(", "'--geo_augment'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'Whether to perform geometric augmentation'", ")", "\n", "parser", ".", "add_argument", "(", "'--inten_augment'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'Whether to perform intensity augmentation'", ")", "\n", "parser", ".", "add_argument", "(", "'--apply_same_inten_augment'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'Whether to perform the same intensity augmentation on timepoint1 & 2'", ")", "\n", "parser", ".", "add_argument", "(", "'--blur'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'Whether to add augment [blur]'", ")", "\n", "parser", ".", "add_argument", "(", "'--noise'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'Whether to add augment [noise]'", ")", "\n", "parser", ".", "add_argument", "(", "'--bias'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'Whether to add augment [bias]'", ")", "\n", "parser", ".", "add_argument", "(", "'--gamma'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'Whether to add augment [gamma]'", ")", "\n", "parser", ".", "add_argument", "(", "'--motion'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "True", ",", "help", "=", "'Whether to add augment [motion]'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--resize'", ",", "type", "=", "util", ".", "str2bool", ",", "nargs", "=", "'?'", ",", "const", "=", "True", ",", "default", "=", "False", ",", "help", "=", "'Whether to resize data, if true, no crop'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--num_threads'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'# threads for loading data'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size2'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "'input batch size for Lcs'", ")", "\n", "parser", ".", "add_argument", "(", "'--crop_size'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'crop size'", ")", "\n", "# additional parameters", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "str", ",", "default", "=", "'latest'", ",", "help", "=", "'which epoch to load? set to latest to use latest cached model'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'if specified, print more debugging information'", ")", "\n", "parser", ".", "add_argument", "(", "'--suffix'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "help", "=", "'customized suffix: opt.name = opt.name + suffix: e.g., {model}_{netG}_size{load_size}'", ")", "\n", "\n", "self", ".", "initialized", "=", "True", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.gather_options": [[95, 131], ["models.get_option_setter", "models.get_option_setter.", "data.get_option_setter", "data.get_option_setter.", "argparse.ArgumentParser", "base_options.BaseOptions.initialize", "base_options.BaseOptions.parse_known_args", "base_options.BaseOptions.parse_known_args", "base_options.BaseOptions.parse_known_args", "base_options.BaseOptions.parse_known_args", "base_options.BaseOptions.parse_args", "base_options.BaseOptions.parse_args"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.data.__init__.get_option_setter", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.initialize"], ["", "def", "gather_options", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize our parser with basic options(only once).\n        Add additional model-specific and dataset-specific options.\n        These options are defined in the <modify_commandline_options> function\n        in model and dataset classes.\n        \"\"\"", "\n", "if", "not", "self", ".", "initialized", ":", "# check if it has been initialized", "\n", "            ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", "=", "self", ".", "initialize", "(", "parser", ")", "\n", "\n", "# get the basic options", "\n", "", "if", "self", ".", "cmd_line", "is", "None", ":", "\n", "            ", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "", "else", ":", "\n", "            ", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", "self", ".", "cmd_line", ")", "\n", "\n", "# modify model-related parser options", "\n", "", "model_name", "=", "opt", ".", "model", "\n", "model_option_setter", "=", "models", ".", "get_option_setter", "(", "model_name", ")", "\n", "parser", "=", "model_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "if", "self", ".", "cmd_line", "is", "None", ":", "\n", "            ", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", ")", "# parse again with new defaults", "\n", "", "else", ":", "\n", "            ", "opt", ",", "_", "=", "parser", ".", "parse_known_args", "(", "self", ".", "cmd_line", ")", "# parse again with new defaults", "\n", "\n", "# modify dataset-related parser options", "\n", "", "dataset_name", "=", "opt", ".", "dataset_mode", "\n", "dataset_option_setter", "=", "data", ".", "get_option_setter", "(", "dataset_name", ")", "\n", "parser", "=", "dataset_option_setter", "(", "parser", ",", "self", ".", "isTrain", ")", "\n", "\n", "# save and return the parser", "\n", "self", ".", "parser", "=", "parser", "\n", "if", "self", ".", "cmd_line", "is", "None", ":", "\n", "            ", "return", "parser", ".", "parse_args", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "parser", ".", "parse_args", "(", "self", ".", "cmd_line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.print_options": [[132, 164], ["sorted", "print", "os.path.join", "util.util.util.mkdirs", "os.path.join", "os.path.exists", "vars().items", "base_options.BaseOptions.parser.get_default", "file_name.replace.replace.replace", "str", "str", "open", "opt_file.write", "opt_file.write", "print", "vars", "str", "str", "datetime.datetime.now"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.util.util.mkdirs"], ["", "", "def", "print_options", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Print and save options\n\n        It will print both current options and default values(if different).\n        It will save options into a text file / [checkpoints_dir] / opt.txt\n        \"\"\"", "\n", "message", "=", "''", "\n", "message", "+=", "'----------------- Options ---------------\\n'", "\n", "for", "k", ",", "v", "in", "sorted", "(", "vars", "(", "opt", ")", ".", "items", "(", ")", ")", ":", "\n", "            ", "comment", "=", "''", "\n", "default", "=", "self", ".", "parser", ".", "get_default", "(", "k", ")", "\n", "if", "v", "!=", "default", ":", "\n", "                ", "comment", "=", "'\\t[default: %s]'", "%", "str", "(", "default", ")", "\n", "", "message", "+=", "'{:>25}: {:<30}{}\\n'", ".", "format", "(", "str", "(", "k", ")", ",", "str", "(", "v", ")", ",", "comment", ")", "\n", "", "message", "+=", "'----------------- End -------------------'", "\n", "print", "(", "message", ")", "\n", "\n", "# save to the disk", "\n", "expr_dir", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoints_dir", ",", "opt", ".", "name", ")", "\n", "util", ".", "mkdirs", "(", "expr_dir", ")", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "expr_dir", ",", "'{}_opt.txt'", ".", "format", "(", "opt", ".", "phase", ")", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "file_name", ")", ":", "\n", "            ", "import", "datetime", "\n", "file_name", "=", "file_name", ".", "replace", "(", "'opt.txt'", ",", "'opt_{}.txt'", ".", "format", "(", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "[", ":", "10", "]", ")", ")", "\n", "", "try", ":", "\n", "            ", "with", "open", "(", "file_name", ",", "'w'", ")", "as", "opt_file", ":", "\n", "                ", "opt_file", ".", "write", "(", "message", ")", "\n", "opt_file", ".", "write", "(", "'\\n'", ")", "\n", "", "", "except", "PermissionError", "as", "error", ":", "\n", "            ", "print", "(", "\"permission error {}\"", ".", "format", "(", "error", ")", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.parse": [[165, 190], ["base_options.BaseOptions.gather_options", "base_options.BaseOptions.print_options", "base_options.BaseOptions.gpu_ids.split", "int", "len", "torch.cuda.set_device", "base_options.BaseOptions.suffix.format", "base_options.BaseOptions.gpu_ids.append", "vars"], "methods", ["home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.gather_options", "home.repos.pwc.inspect_result.mengweiren_longitudinal-representation-learning.options.base_options.BaseOptions.print_options"], ["", "", "def", "parse", "(", "self", ")", ":", "\n", "        ", "\"\"\"Parse our options, create checkpoints directory suffix, and set up gpu device.\"\"\"", "\n", "opt", "=", "self", ".", "gather_options", "(", ")", "\n", "opt", ".", "isTrain", "=", "self", ".", "isTrain", "# train or test", "\n", "\n", "# process opt.suffix", "\n", "if", "opt", ".", "suffix", ":", "\n", "            ", "suffix", "=", "(", "'_'", "+", "opt", ".", "suffix", ".", "format", "(", "**", "vars", "(", "opt", ")", ")", ")", "if", "opt", ".", "suffix", "!=", "''", "else", "''", "\n", "opt", ".", "name", "=", "opt", ".", "name", "+", "suffix", "\n", "\n", "", "self", ".", "print_options", "(", "opt", ")", "\n", "\n", "if", "opt", ".", "gpu_ids", "!=", "'tpu'", ":", "\n", "# set gpu ids", "\n", "            ", "str_ids", "=", "opt", ".", "gpu_ids", ".", "split", "(", "','", ")", "\n", "opt", ".", "gpu_ids", "=", "[", "]", "\n", "for", "str_id", "in", "str_ids", ":", "\n", "                ", "id", "=", "int", "(", "str_id", ")", "\n", "if", "id", ">=", "0", ":", "\n", "                    ", "opt", ".", "gpu_ids", ".", "append", "(", "id", ")", "\n", "", "", "if", "len", "(", "opt", ".", "gpu_ids", ")", ">", "0", ":", "\n", "                ", "torch", ".", "cuda", ".", "set_device", "(", "opt", ".", "gpu_ids", "[", "0", "]", ")", "\n", "\n", "", "", "self", ".", "opt", "=", "opt", "\n", "return", "self", ".", "opt", "\n", "", "", ""]]}