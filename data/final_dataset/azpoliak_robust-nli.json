{"home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.__init__": [[14, 24], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.ClassificationNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BLSTMEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bsize", "=", "config", "[", "'bsize'", "]", "\n", "self", ".", "word_emb_dim", "=", "config", "[", "'word_emb_dim'", "]", "\n", "self", ".", "enc_lstm_dim", "=", "config", "[", "'enc_lstm_dim'", "]", "\n", "self", ".", "pool_type", "=", "config", "[", "'pool_type'", "]", "\n", "self", ".", "dpout_model", "=", "config", "[", "'dpout_model'", "]", "\n", "\n", "self", ".", "enc_lstm", "=", "nn", ".", "LSTM", "(", "self", ".", "word_emb_dim", ",", "self", ".", "enc_lstm_dim", ",", "1", ",", "\n", "bidirectional", "=", "True", ",", "dropout", "=", "self", ".", "dpout_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.is_cuda": [[25, 28], ["str"], "methods", ["None"], ["", "def", "is_cuda", "(", "self", ")", ":", "\n", "# either all weights are on cpu or they are on gpu", "\n", "        ", "return", "'cuda'", "in", "str", "(", "self", ".", "enc_lstm", ".", "bias_hh_l0", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.forward": [[29, 64], ["numpy.argsort", "sent.index_select.index_select.index_select", "torch.utils.rnn.pack_padded_sequence", "torch.utils.rnn.pack_padded_sequence", "sent_output.index_select.index_select.index_select", "numpy.argsort", "models.BLSTMEncoder.is_cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.autograd.Variable", "torch.autograd.Variable", "models.BLSTMEncoder.enc_lstm", "torch.utils.rnn.pad_packed_sequence", "torch.utils.rnn.pad_packed_sequence", "models.BLSTMEncoder.is_cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable().unsqueeze().cuda", "torch.autograd.Variable().unsqueeze().cuda", "torch.sum().squeeze", "torch.sum().squeeze", "torch.sum().squeeze", "torch.sum().squeeze", "numpy.sort", "torch.autograd.Variable().unsqueeze().cuda.expand_as", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.autograd.Variable().unsqueeze", "torch.autograd.Variable().unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.max", "torch.max", "torch.max", "torch.max", "emb.squeeze.squeeze.ndimension", "emb.squeeze.squeeze.squeeze", "emb.squeeze.squeeze.ndimension", "torch.autograd.Variable", "torch.autograd.Variable", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.is_cuda", "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.is_cuda"], ["", "def", "forward", "(", "self", ",", "sent_tuple", ")", ":", "\n", "# sent_len: [max_len, ..., min_len] (bsize)", "\n", "# sent: Variable(seqlen x bsize x worddim)", "\n", "        ", "sent", ",", "sent_len", "=", "sent_tuple", "\n", "\n", "# Sort by length (keep idx)", "\n", "sent_len", ",", "idx_sort", "=", "np", ".", "sort", "(", "sent_len", ")", "[", ":", ":", "-", "1", "]", ",", "np", ".", "argsort", "(", "-", "sent_len", ")", "\n", "idx_unsort", "=", "np", ".", "argsort", "(", "idx_sort", ")", "\n", "\n", "idx_sort", "=", "torch", ".", "from_numpy", "(", "idx_sort", ")", ".", "cuda", "(", ")", "if", "self", ".", "is_cuda", "(", ")", "else", "torch", ".", "from_numpy", "(", "idx_sort", ")", "\n", "sent", "=", "sent", ".", "index_select", "(", "1", ",", "Variable", "(", "idx_sort", ")", ")", "\n", "\n", "# Handling padding in Recurrent Networks", "\n", "sent_packed", "=", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "sent", ",", "sent_len", ")", "\n", "sent_output", "=", "self", ".", "enc_lstm", "(", "sent_packed", ")", "[", "0", "]", "# seqlen x batch x 2*nhid", "\n", "sent_output", "=", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "sent_output", ")", "[", "0", "]", "\n", "\n", "# Un-sort by length", "\n", "idx_unsort", "=", "torch", ".", "from_numpy", "(", "idx_unsort", ")", ".", "cuda", "(", ")", "if", "self", ".", "is_cuda", "(", ")", "else", "torch", ".", "from_numpy", "(", "idx_unsort", ")", "\n", "sent_output", "=", "sent_output", ".", "index_select", "(", "1", ",", "Variable", "(", "idx_unsort", ")", ")", "\n", "\n", "# Pooling", "\n", "if", "self", ".", "pool_type", "==", "\"mean\"", ":", "\n", "            ", "sent_len", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "sent_len", ")", ")", ".", "unsqueeze", "(", "1", ")", ".", "cuda", "(", ")", "\n", "emb", "=", "torch", ".", "sum", "(", "sent_output", ",", "0", ")", ".", "squeeze", "(", "0", ")", "\n", "emb", "=", "emb", "/", "sent_len", ".", "expand_as", "(", "emb", ")", "\n", "", "elif", "self", ".", "pool_type", "==", "\"max\"", ":", "\n", "            ", "emb", "=", "torch", ".", "max", "(", "sent_output", ",", "0", ")", "[", "0", "]", "\n", "if", "emb", ".", "ndimension", "(", ")", "==", "3", ":", "\n", "                ", "emb", "=", "emb", ".", "squeeze", "(", "0", ")", "\n", "assert", "emb", ".", "ndimension", "(", ")", "==", "2", "\n", "\n", "", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.set_glove_path": [[65, 67], ["None"], "methods", ["None"], ["", "def", "set_glove_path", "(", "self", ",", "glove_path", ")", ":", "\n", "        ", "self", ".", "glove_path", "=", "glove_path", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.get_word_dict": [[68, 82], ["s.split", "word_tokenize"], "methods", ["None"], ["", "def", "get_word_dict", "(", "self", ",", "sentences", ",", "tokenize", "=", "True", ")", ":", "\n", "# create vocab of words", "\n", "        ", "word_dict", "=", "{", "}", "\n", "if", "tokenize", ":", "\n", "            ", "from", "nltk", ".", "tokenize", "import", "word_tokenize", "\n", "", "sentences", "=", "[", "s", ".", "split", "(", ")", "if", "not", "tokenize", "else", "word_tokenize", "(", "s", ")", "\n", "for", "s", "in", "sentences", "]", "\n", "for", "sent", "in", "sentences", ":", "\n", "            ", "for", "word", "in", "sent", ":", "\n", "                ", "if", "word", "not", "in", "word_dict", ":", "\n", "                    ", "word_dict", "[", "word", "]", "=", "''", "\n", "", "", "", "word_dict", "[", "'<s>'", "]", "=", "''", "\n", "word_dict", "[", "'</s>'", "]", "=", "''", "\n", "return", "word_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.get_glove": [[83, 96], ["hasattr", "print", "open", "line.split", "len", "len", "numpy.fromstring"], "methods", ["None"], ["", "def", "get_glove", "(", "self", ",", "word_dict", ")", ":", "\n", "        ", "assert", "hasattr", "(", "self", ",", "'glove_path'", ")", ",", "'warning : you need to set_glove_path(glove_path)'", "\n", "# create word_vec with glove vectors", "\n", "word_vec", "=", "{", "}", "\n", "with", "open", "(", "self", ".", "glove_path", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "word", ",", "vec", "=", "line", ".", "split", "(", "' '", ",", "1", ")", "\n", "if", "word", "in", "word_dict", ":", "\n", "                    ", "word_vec", "[", "word", "]", "=", "np", ".", "fromstring", "(", "vec", ",", "sep", "=", "' '", ")", "\n", "", "", "", "print", "(", "'Found {0}(/{1}) words with glove vectors'", ".", "format", "(", "\n", "len", "(", "word_vec", ")", ",", "len", "(", "word_dict", ")", ")", ")", "\n", "return", "word_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.get_glove_k": [[97, 116], ["hasattr", "open", "line.split", "numpy.fromstring", "all", "numpy.fromstring"], "methods", ["None"], ["", "def", "get_glove_k", "(", "self", ",", "K", ")", ":", "\n", "        ", "assert", "hasattr", "(", "self", ",", "'glove_path'", ")", ",", "'warning : you need \\\n                                             to set_glove_path(glove_path)'", "\n", "# create word_vec with k first glove vectors", "\n", "k", "=", "0", "\n", "word_vec", "=", "{", "}", "\n", "with", "open", "(", "self", ".", "glove_path", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "word", ",", "vec", "=", "line", ".", "split", "(", "' '", ",", "1", ")", "\n", "if", "k", "<=", "K", ":", "\n", "                    ", "word_vec", "[", "word", "]", "=", "np", ".", "fromstring", "(", "vec", ",", "sep", "=", "' '", ")", "\n", "k", "+=", "1", "\n", "", "if", "k", ">", "K", ":", "\n", "                    ", "if", "word", "in", "[", "'<s>'", ",", "'</s>'", "]", ":", "\n", "                        ", "word_vec", "[", "word", "]", "=", "np", ".", "fromstring", "(", "vec", ",", "sep", "=", "' '", ")", "\n", "\n", "", "", "if", "k", ">", "K", "and", "all", "(", "[", "w", "in", "word_vec", "for", "w", "in", "[", "'<s>'", ",", "'</s>'", "]", "]", ")", ":", "\n", "                    ", "break", "\n", "", "", "", "return", "word_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.build_vocab": [[117, 123], ["hasattr", "models.BLSTMEncoder.get_word_dict", "models.BLSTMEncoder.get_glove", "print", "len"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.get_word_dict", "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.get_glove"], ["", "def", "build_vocab", "(", "self", ",", "sentences", ",", "tokenize", "=", "True", ")", ":", "\n", "        ", "assert", "hasattr", "(", "self", ",", "'glove_path'", ")", ",", "'warning : you need \\\n                                             to set_glove_path(glove_path)'", "\n", "word_dict", "=", "self", ".", "get_word_dict", "(", "sentences", ",", "tokenize", ")", "\n", "self", ".", "word_vec", "=", "self", ".", "get_glove", "(", "word_dict", ")", "\n", "print", "(", "'Vocab size : {0}'", ".", "format", "(", "len", "(", "self", ".", "word_vec", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.build_vocab_k_words": [[125, 130], ["hasattr", "models.BLSTMEncoder.get_glove_k", "print"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.get_glove_k"], ["", "def", "build_vocab_k_words", "(", "self", ",", "K", ")", ":", "\n", "        ", "assert", "hasattr", "(", "self", ",", "'glove_path'", ")", ",", "'warning : you need \\\n                                             to set_glove_path(glove_path)'", "\n", "self", ".", "word_vec", "=", "self", ".", "get_glove_k", "(", "K", ")", "\n", "print", "(", "'Vocab size : {0}'", ".", "format", "(", "K", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.update_vocab": [[131, 148], ["hasattr", "hasattr", "models.BLSTMEncoder.get_word_dict", "print", "models.BLSTMEncoder.get_glove", "models.BLSTMEncoder.word_vec.update", "len", "len"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.get_word_dict", "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.get_glove"], ["", "def", "update_vocab", "(", "self", ",", "sentences", ",", "tokenize", "=", "True", ")", ":", "\n", "        ", "assert", "hasattr", "(", "self", ",", "'glove_path'", ")", ",", "'warning : you need \\\n                                             to set_glove_path(glove_path)'", "\n", "assert", "hasattr", "(", "self", ",", "'word_vec'", ")", ",", "'build_vocab before updating it'", "\n", "word_dict", "=", "self", ".", "get_word_dict", "(", "sentences", ",", "tokenize", ")", "\n", "\n", "# keep only new words", "\n", "for", "word", "in", "self", ".", "word_vec", ":", "\n", "            ", "if", "word", "in", "word_dict", ":", "\n", "                ", "del", "word_dict", "[", "word", "]", "\n", "\n", "# udpate vocabulary", "\n", "", "", "if", "word_dict", ":", "\n", "            ", "new_word_vec", "=", "self", ".", "get_glove", "(", "word_dict", ")", "\n", "self", ".", "word_vec", ".", "update", "(", "new_word_vec", ")", "\n", "", "print", "(", "'New vocab size : {0} (added {1} words)'", ".", "format", "(", "\n", "len", "(", "self", ".", "word_vec", ")", ",", "len", "(", "new_word_vec", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.get_batch": [[149, 159], ["numpy.zeros", "range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "len", "range", "len", "len", "len"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "batch", ")", ":", "\n", "# sent in batch in decreasing order of lengths", "\n", "# batch: (bsize, max_len, word_dim)", "\n", "        ", "embed", "=", "np", ".", "zeros", "(", "(", "len", "(", "batch", "[", "0", "]", ")", ",", "len", "(", "batch", ")", ",", "self", ".", "word_emb_dim", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "batch", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "batch", "[", "i", "]", ")", ")", ":", "\n", "                ", "embed", "[", "j", ",", "i", ",", ":", "]", "=", "self", ".", "word_vec", "[", "batch", "[", "i", "]", "[", "j", "]", "]", "\n", "\n", "", "", "return", "torch", ".", "FloatTensor", "(", "embed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.prepare_samples": [[160, 188], ["numpy.sum", "range", "numpy.array", "numpy.sum", "len", "print", "numpy.argsort", "numpy.array", "len", "warnings.warn", "len", "numpy.sort", "round", "s.split", "word_tokenize"], "methods", ["None"], ["", "def", "prepare_samples", "(", "self", ",", "sentences", ",", "bsize", ",", "tokenize", ",", "verbose", ")", ":", "\n", "        ", "if", "tokenize", ":", "\n", "            ", "from", "nltk", ".", "tokenize", "import", "word_tokenize", "\n", "", "sentences", "=", "[", "[", "'<s>'", "]", "+", "s", ".", "split", "(", ")", "+", "[", "'</s>'", "]", "if", "not", "tokenize", "else", "\n", "[", "'<s>'", "]", "+", "word_tokenize", "(", "s", ")", "+", "[", "'</s>'", "]", "for", "s", "in", "sentences", "]", "\n", "n_w", "=", "np", ".", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "sentences", "]", ")", "\n", "\n", "# filters words without glove vectors", "\n", "for", "i", "in", "range", "(", "len", "(", "sentences", ")", ")", ":", "\n", "            ", "s_f", "=", "[", "word", "for", "word", "in", "sentences", "[", "i", "]", "if", "word", "in", "self", ".", "word_vec", "]", "\n", "if", "not", "s_f", ":", "\n", "                ", "import", "warnings", "\n", "warnings", ".", "warn", "(", "'No words in \"{0}\" (idx={1}) have glove vectors. \\\n                               Replacing by \"</s>\"..'", ".", "format", "(", "sentences", "[", "i", "]", ",", "i", ")", ")", "\n", "s_f", "=", "[", "'</s>'", "]", "\n", "", "sentences", "[", "i", "]", "=", "s_f", "\n", "\n", "", "lengths", "=", "np", ".", "array", "(", "[", "len", "(", "s", ")", "for", "s", "in", "sentences", "]", ")", "\n", "n_wk", "=", "np", ".", "sum", "(", "lengths", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'Nb words kept : {0}/{1} ({2} %)'", ".", "format", "(", "\n", "n_wk", ",", "n_w", ",", "round", "(", "(", "100.0", "*", "n_wk", ")", "/", "n_w", ",", "2", ")", ")", ")", "\n", "\n", "# sort by decreasing length", "\n", "", "lengths", ",", "idx_sort", "=", "np", ".", "sort", "(", "lengths", ")", "[", ":", ":", "-", "1", "]", ",", "np", ".", "argsort", "(", "-", "lengths", ")", "\n", "sentences", "=", "np", ".", "array", "(", "sentences", ")", "[", "idx_sort", "]", "\n", "\n", "return", "sentences", ",", "lengths", ",", "idx_sort", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.encode": [[189, 214], ["time.time", "models.BLSTMEncoder.prepare_samples", "range", "numpy.vstack", "numpy.argsort", "len", "torch.autograd.Variable", "torch.autograd.Variable", "models.BLSTMEncoder.is_cuda", "models.BLSTMEncoder.forward().data.cpu().numpy", "numpy.vstack.append", "print", "models.BLSTMEncoder.get_batch", "batch.cuda.cuda.cuda", "models.BLSTMEncoder.forward().data.cpu", "round", "models.BLSTMEncoder.is_cuda", "len", "models.BLSTMEncoder.forward", "time.time"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.prepare_samples", "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.is_cuda", "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.get_batch", "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.is_cuda", "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.ClassificationNet.forward"], ["", "def", "encode", "(", "self", ",", "sentences", ",", "bsize", "=", "64", ",", "tokenize", "=", "True", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "tic", "=", "time", ".", "time", "(", ")", "\n", "sentences", ",", "lengths", ",", "idx_sort", "=", "self", ".", "prepare_samples", "(", "\n", "sentences", ",", "bsize", ",", "tokenize", ",", "verbose", ")", "\n", "\n", "embeddings", "=", "[", "]", "\n", "for", "stidx", "in", "range", "(", "0", ",", "len", "(", "sentences", ")", ",", "bsize", ")", ":", "\n", "            ", "batch", "=", "Variable", "(", "self", ".", "get_batch", "(", "\n", "sentences", "[", "stidx", ":", "stidx", "+", "bsize", "]", ")", ",", "volatile", "=", "True", ")", "\n", "if", "self", ".", "is_cuda", "(", ")", ":", "\n", "                ", "batch", "=", "batch", ".", "cuda", "(", ")", "\n", "", "batch", "=", "self", ".", "forward", "(", "\n", "(", "batch", ",", "lengths", "[", "stidx", ":", "stidx", "+", "bsize", "]", ")", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "embeddings", ".", "append", "(", "batch", ")", "\n", "", "embeddings", "=", "np", ".", "vstack", "(", "embeddings", ")", "\n", "\n", "# unsort", "\n", "idx_unsort", "=", "np", ".", "argsort", "(", "idx_sort", ")", "\n", "embeddings", "=", "embeddings", "[", "idx_unsort", "]", "\n", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'Speed : {0} sentences/s ({1} mode, bsize={2})'", ".", "format", "(", "\n", "round", "(", "len", "(", "embeddings", ")", "/", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ",", "2", ")", ",", "\n", "'gpu'", "if", "self", ".", "is_cuda", "(", ")", "else", "'cpu'", ",", "bsize", ")", ")", "\n", "", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.visualize": [[215, 248], ["torch.autograd.Variable", "torch.autograd.Variable", "models.BLSTMEncoder.is_cuda", "torch.max", "torch.max", "torch.max", "torch.max", "idxs.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "range", "plt.xticks", "plt.bar", "plt.ylabel", "plt.title", "plt.show", "sent.split", "word_tokenize", "warnings.warn", "models.BLSTMEncoder.get_batch", "batch.cuda.cuda.cuda", "models.BLSTMEncoder.enc_lstm", "numpy.sum", "len", "idxs.data.cpu().numpy.data.cpu().numpy.data.cpu", "range", "numpy.sum", "len"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.is_cuda", "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.get_batch"], ["", "def", "visualize", "(", "self", ",", "sent", ",", "tokenize", "=", "True", ")", ":", "\n", "        ", "if", "tokenize", ":", "\n", "            ", "from", "nltk", ".", "tokenize", "import", "word_tokenize", "\n", "\n", "", "sent", "=", "sent", ".", "split", "(", ")", "if", "not", "tokenize", "else", "word_tokenize", "(", "sent", ")", "\n", "sent", "=", "[", "[", "'<s>'", "]", "+", "[", "word", "for", "word", "in", "sent", "if", "word", "in", "self", ".", "word_vec", "]", "+", "\n", "[", "'</s>'", "]", "]", "\n", "\n", "if", "' '", ".", "join", "(", "sent", "[", "0", "]", ")", "==", "'<s> </s>'", ":", "\n", "            ", "import", "warnings", "\n", "warnings", ".", "warn", "(", "'No words in \"{0}\" have glove vectors. Replacing \\\n                           by \"<s> </s>\"..'", ".", "format", "(", "sent", ")", ")", "\n", "", "batch", "=", "Variable", "(", "self", ".", "get_batch", "(", "sent", ")", ",", "volatile", "=", "True", ")", "\n", "\n", "if", "self", ".", "is_cuda", "(", ")", ":", "\n", "            ", "batch", "=", "batch", ".", "cuda", "(", ")", "\n", "", "output", "=", "self", ".", "enc_lstm", "(", "batch", ")", "[", "0", "]", "\n", "output", ",", "idxs", "=", "torch", ".", "max", "(", "output", ",", "0", ")", "\n", "# output, idxs = output.squeeze(), idxs.squeeze()", "\n", "idxs", "=", "idxs", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "argmaxs", "=", "[", "np", ".", "sum", "(", "(", "idxs", "==", "k", ")", ")", "for", "k", "in", "range", "(", "len", "(", "sent", "[", "0", "]", ")", ")", "]", "\n", "\n", "# visualize model", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "x", "=", "range", "(", "len", "(", "sent", "[", "0", "]", ")", ")", "\n", "y", "=", "[", "100.0", "*", "n", "/", "np", ".", "sum", "(", "argmaxs", ")", "for", "n", "in", "argmaxs", "]", "\n", "plt", ".", "xticks", "(", "x", ",", "sent", "[", "0", "]", ",", "rotation", "=", "45", ")", "\n", "plt", ".", "bar", "(", "x", ",", "y", ")", "\n", "plt", ".", "ylabel", "(", "'%'", ")", "\n", "plt", ".", "title", "(", "'Visualisation of words importance'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "return", "output", ",", "idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.NLINet.__init__": [[258, 291], ["torch.Module.__init__", "eval", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.ClassificationNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "NLINet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# classifier", "\n", "self", ".", "nonlinear_fc", "=", "config", "[", "'nonlinear_fc'", "]", "\n", "self", ".", "fc_dim", "=", "config", "[", "'fc_dim'", "]", "\n", "self", ".", "n_classes", "=", "config", "[", "'n_classes'", "]", "\n", "self", ".", "enc_lstm_dim", "=", "config", "[", "'enc_lstm_dim'", "]", "\n", "self", ".", "encoder_type", "=", "config", "[", "'encoder_type'", "]", "\n", "self", ".", "dpout_fc", "=", "config", "[", "'dpout_fc'", "]", "\n", "\n", "self", ".", "encoder", "=", "eval", "(", "self", ".", "encoder_type", ")", "(", "config", ")", "\n", "self", ".", "inputdim", "=", "4", "*", "2", "*", "self", ".", "enc_lstm_dim", "\n", "self", ".", "inputdim", "=", "4", "*", "self", ".", "inputdim", "if", "self", ".", "encoder_type", "in", "[", "\"ConvNetEncoder\"", ",", "\"InnerAttentionMILAEncoder\"", "]", "else", "self", ".", "inputdim", "\n", "self", ".", "inputdim", "=", "self", ".", "inputdim", "/", "2", "if", "self", ".", "encoder_type", "==", "\"LSTMEncoder\"", "else", "self", ".", "inputdim", "\n", "if", "self", ".", "nonlinear_fc", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "n_classes", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "n_classes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.NLINet.forward": [[293, 301], ["models.NLINet.encoder", "models.NLINet.encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.NLINet.classifier", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "s1", ",", "s2", ")", ":", "\n", "# s1 : (s1, s1_len)", "\n", "        ", "u", "=", "self", ".", "encoder", "(", "s1", ")", "\n", "v", "=", "self", ".", "encoder", "(", "s2", ")", "\n", "\n", "features", "=", "torch", ".", "cat", "(", "(", "u", ",", "v", ",", "torch", ".", "abs", "(", "u", "-", "v", ")", ",", "u", "*", "v", ")", ",", "1", ")", "\n", "output", "=", "self", ".", "classifier", "(", "features", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.NLINet.encode": [[302, 305], ["models.NLINet.encoder"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "s1", ")", ":", "\n", "        ", "emb", "=", "self", ".", "encoder", "(", "s1", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.NLI_HYPOTHS_Net.__init__": [[311, 345], ["torch.Module.__init__", "eval", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.ClassificationNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "NLI_HYPOTHS_Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# classifier", "\n", "self", ".", "nonlinear_fc", "=", "config", "[", "'nonlinear_fc'", "]", "\n", "self", ".", "fc_dim", "=", "config", "[", "'fc_dim'", "]", "\n", "self", ".", "n_classes", "=", "config", "[", "'n_classes'", "]", "\n", "self", ".", "enc_lstm_dim", "=", "config", "[", "'enc_lstm_dim'", "]", "\n", "self", ".", "encoder_type", "=", "config", "[", "'encoder_type'", "]", "\n", "self", ".", "dpout_fc", "=", "config", "[", "'dpout_fc'", "]", "\n", "\n", "self", ".", "encoder", "=", "eval", "(", "self", ".", "encoder_type", ")", "(", "config", ")", "\n", "self", ".", "inputdim", "=", "2", "*", "self", ".", "enc_lstm_dim", "\n", "#self.inputdim = 4*2*self.enc_lstm_dim", "\n", "self", ".", "inputdim", "=", "4", "*", "self", ".", "inputdim", "if", "self", ".", "encoder_type", "in", "[", "\"ConvNetEncoder\"", ",", "\"InnerAttentionMILAEncoder\"", "]", "else", "self", ".", "inputdim", "\n", "self", ".", "inputdim", "=", "self", ".", "inputdim", "/", "2", "if", "self", ".", "encoder_type", "==", "\"LSTMEncoder\"", "else", "self", ".", "inputdim", "\n", "if", "self", ".", "nonlinear_fc", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "n_classes", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "n_classes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.NLI_HYPOTHS_Net.forward": [[347, 354], ["models.NLI_HYPOTHS_Net.encoder", "models.NLI_HYPOTHS_Net.classifier"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "s2", ")", ":", "\n", "# s1 : (s1, s1_len)", "\n", "        ", "v", "=", "self", ".", "encoder", "(", "s2", ")", "\n", "\n", "features", "=", "v", "\n", "output", "=", "self", ".", "classifier", "(", "features", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.NLI_HYPOTHS_Net.encode": [[355, 358], ["models.NLI_HYPOTHS_Net.encoder"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "s1", ")", ":", "\n", "        ", "emb", "=", "self", ".", "encoder", "(", "s1", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.GradReverse.__init__": [[365, 367], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "lambd", "=", "1.0", ")", ":", "\n", "        ", "self", ".", "lambd", "=", "lambd", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.GradReverse.forward": [[368, 370], ["x.view_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "view_as", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.GradReverse.backward": [[371, 373], ["None"], "methods", ["None"], ["", "def", "backward", "(", "self", ",", "grad_output", ")", ":", "\n", "        ", "return", "(", "grad_output", "*", "-", "self", ".", "lambd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.SharedHypothNet.__init__": [[383, 419], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.ClassificationNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "encoder", ")", ":", "\n", "        ", "super", "(", "SharedHypothNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# classifier", "\n", "self", ".", "nonlinear_fc", "=", "config", "[", "'nonlinear_fc'", "]", "\n", "self", ".", "fc_dim", "=", "config", "[", "'fc_dim'", "]", "\n", "self", ".", "n_classes", "=", "config", "[", "'n_classes'", "]", "\n", "self", ".", "enc_lstm_dim", "=", "config", "[", "'enc_lstm_dim'", "]", "\n", "self", ".", "encoder_type", "=", "config", "[", "'encoder_type'", "]", "\n", "self", ".", "dpout_fc", "=", "config", "[", "'dpout_fc'", "]", "\n", "self", ".", "adv_hyp_encoder_lambda", "=", "config", "[", "'adv_hyp_encoder_lambda'", "]", "\n", "\n", "#self.encoder = eval(self.encoder_type)(config)", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "inputdim", "=", "2", "*", "self", ".", "enc_lstm_dim", "\n", "#self.inputdim = 4*2*self.enc_lstm_dim", "\n", "self", ".", "inputdim", "=", "4", "*", "self", ".", "inputdim", "if", "self", ".", "encoder_type", "in", "[", "\"ConvNetEncoder\"", ",", "\"InnerAttentionMILAEncoder\"", "]", "else", "self", ".", "inputdim", "\n", "self", ".", "inputdim", "=", "self", ".", "inputdim", "/", "2", "if", "self", ".", "encoder_type", "==", "\"LSTMEncoder\"", "else", "self", ".", "inputdim", "\n", "if", "self", ".", "nonlinear_fc", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "n_classes", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "n_classes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.SharedHypothNet.forward": [[421, 430], ["models.SharedHypothNet.encoder", "models.grad_reverse", "models.SharedHypothNet.classifier"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.grad_reverse"], ["", "", "def", "forward", "(", "self", ",", "s2", ")", ":", "\n", "# s1 : (s1, s1_len)", "\n", "        ", "v", "=", "self", ".", "encoder", "(", "s2", ")", "\n", "# reverse gradients going into the encoder", "\n", "v", "=", "grad_reverse", "(", "v", ",", "self", ".", "adv_hyp_encoder_lambda", ")", "\n", "\n", "features", "=", "v", "\n", "output", "=", "self", ".", "classifier", "(", "features", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.SharedHypothNet.encode": [[431, 434], ["models.SharedHypothNet.encoder"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "s1", ")", ":", "\n", "        ", "emb", "=", "self", ".", "encoder", "(", "s1", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.SharedNLINet.__init__": [[437, 474], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.ClassificationNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "encoder_premise", ",", "encoder_hypoth", ")", ":", "\n", "# Assumes encoder_premise and encoder_hypoth are of same config['encoder_type']", "\n", "        ", "super", "(", "SharedNLINet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# classifier", "\n", "self", ".", "nonlinear_fc", "=", "config", "[", "'nonlinear_fc'", "]", "\n", "self", ".", "fc_dim", "=", "config", "[", "'fc_dim'", "]", "\n", "self", ".", "n_classes", "=", "config", "[", "'n_classes'", "]", "\n", "self", ".", "enc_lstm_dim", "=", "config", "[", "'enc_lstm_dim'", "]", "\n", "self", ".", "encoder_type", "=", "config", "[", "'encoder_type'", "]", "\n", "self", ".", "dpout_fc", "=", "config", "[", "'dpout_fc'", "]", "\n", "self", ".", "adv_hyp_encoder_lambda", "=", "config", "[", "'nli_net_adv_hyp_encoder_lambda'", "]", "\n", "\n", "#self.encoder = eval(self.encoder_type)(config)", "\n", "self", ".", "encoder_premise", "=", "encoder_premise", "\n", "self", ".", "encoder_hypoth", "=", "encoder_hypoth", "\n", "self", ".", "inputdim", "=", "4", "*", "2", "*", "self", ".", "enc_lstm_dim", "\n", "self", ".", "inputdim", "=", "4", "*", "self", ".", "inputdim", "if", "self", ".", "encoder_type", "in", "[", "\"ConvNetEncoder\"", ",", "\"InnerAttentionMILAEncoder\"", "]", "else", "self", ".", "inputdim", "\n", "self", ".", "inputdim", "=", "self", ".", "inputdim", "/", "2", "if", "self", ".", "encoder_type", "==", "\"LSTMEncoder\"", "else", "self", ".", "inputdim", "\n", "if", "self", ".", "nonlinear_fc", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dpout_fc", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "n_classes", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "fc_dim", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "fc_dim", ",", "self", ".", "n_classes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.SharedNLINet.forward": [[476, 490], ["models.SharedNLINet.encoder_premise", "models.SharedNLINet.encoder_hypoth", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.SharedNLINet.classifier", "models.grad_reverse", "models.grad_reverse", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.grad_reverse", "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.grad_reverse"], ["", "", "def", "forward", "(", "self", ",", "s1", ",", "s2", ",", "random_premise", "=", "False", ")", ":", "\n", "# s1 : (s1, s1_len)", "\n", "        ", "u", "=", "self", ".", "encoder_premise", "(", "s1", ")", "\n", "v", "=", "self", ".", "encoder_hypoth", "(", "s2", ")", "\n", "if", "random_premise", ":", "\n", "# block gradients from back-propagating to the premise encoder ", "\n", "            ", "u", "=", "grad_reverse", "(", "u", ",", "0.0", ")", "\n", "# reverse gradients when back-propagating to the hypothesis encoder", "\n", "v", "=", "grad_reverse", "(", "v", ",", "self", ".", "adv_hyp_encoder_lambda", ")", "\n", "\n", "\n", "", "features", "=", "torch", ".", "cat", "(", "(", "u", ",", "v", ",", "torch", ".", "abs", "(", "u", "-", "v", ")", ",", "u", "*", "v", ")", ",", "1", ")", "\n", "output", "=", "self", ".", "classifier", "(", "features", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.SharedNLINet.encode": [[491, 494], ["models.SharedNLINet.encoder_premise"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "s1", ")", ":", "\n", "        ", "emb", "=", "self", ".", "encoder_premise", "(", "s1", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.ClassificationNet.__init__": [[499, 517], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "eval", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.ClassificationNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ClassificationNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# classifier", "\n", "self", ".", "nonlinear_fc", "=", "config", "[", "'nonlinear_fc'", "]", "\n", "self", ".", "fc_dim", "=", "config", "[", "'fc_dim'", "]", "\n", "self", ".", "n_classes", "=", "config", "[", "'n_classes'", "]", "\n", "self", ".", "enc_lstm_dim", "=", "config", "[", "'enc_lstm_dim'", "]", "\n", "self", ".", "encoder_type", "=", "config", "[", "'encoder_type'", "]", "\n", "self", ".", "dpout_fc", "=", "config", "[", "'dpout_fc'", "]", "\n", "\n", "self", ".", "encoder", "=", "eval", "(", "self", ".", "encoder_type", ")", "(", "config", ")", "\n", "self", ".", "inputdim", "=", "2", "*", "self", ".", "enc_lstm_dim", "\n", "self", ".", "inputdim", "=", "4", "*", "self", ".", "inputdim", "if", "self", ".", "encoder_type", "==", "\"ConvNetEncoder\"", "else", "self", ".", "inputdim", "\n", "self", ".", "inputdim", "=", "self", ".", "enc_lstm_dim", "if", "self", ".", "encoder_type", "==", "\"LSTMEncoder\"", "else", "self", ".", "inputdim", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "inputdim", ",", "512", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "self", ".", "n_classes", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.ClassificationNet.forward": [[519, 525], ["models.ClassificationNet.encoder", "models.ClassificationNet.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "s1", ")", ":", "\n", "# s1 : (s1, s1_len)", "\n", "        ", "u", "=", "self", ".", "encoder", "(", "s1", ")", "\n", "\n", "output", "=", "self", ".", "classifier", "(", "u", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.ClassificationNet.encode": [[526, 529], ["models.ClassificationNet.encoder"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "s1", ")", ":", "\n", "        ", "emb", "=", "self", ".", "encoder", "(", "s1", ")", "\n", "return", "emb", "\n", "", "", ""]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.grad_reverse": [[374, 376], ["models.GradReverse"], "function", ["None"], ["", "", "def", "grad_reverse", "(", "x", ",", "lambd", "=", "1.0", ")", ":", "\n", "    ", "return", "GradReverse", "(", "lambd", ")", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.mutils.get_optimizer": [[13, 60], ["s[].split", "inspect.getargspec", "all", "Exception", "x.split", "float", "s.find", "len", "re.match", "optim_params.keys", "str", "str", "optim_params.keys", "s.find", "Exception"], "function", ["None"], ["def", "get_optimizer", "(", "s", ")", ":", "\n", "    ", "\"\"\"\n    Parse optimizer parameters.\n    Input should be of the form:\n        - \"sgd,lr=0.01\"\n        - \"adagrad,lr=0.1,lr_decay=0.05\"\n    \"\"\"", "\n", "if", "\",\"", "in", "s", ":", "\n", "        ", "method", "=", "s", "[", ":", "s", ".", "find", "(", "','", ")", "]", "\n", "optim_params", "=", "{", "}", "\n", "for", "x", "in", "s", "[", "s", ".", "find", "(", "','", ")", "+", "1", ":", "]", ".", "split", "(", "','", ")", ":", "\n", "            ", "split", "=", "x", ".", "split", "(", "'='", ")", "\n", "assert", "len", "(", "split", ")", "==", "2", "\n", "assert", "re", ".", "match", "(", "\"^[+-]?(\\d+(\\.\\d*)?|\\.\\d+)$\"", ",", "split", "[", "1", "]", ")", "is", "not", "None", "\n", "optim_params", "[", "split", "[", "0", "]", "]", "=", "float", "(", "split", "[", "1", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "method", "=", "s", "\n", "optim_params", "=", "{", "}", "\n", "\n", "", "if", "method", "==", "'adadelta'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "Adadelta", "\n", "", "elif", "method", "==", "'adagrad'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "Adagrad", "\n", "", "elif", "method", "==", "'adam'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "Adam", "\n", "", "elif", "method", "==", "'adamax'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "Adamax", "\n", "", "elif", "method", "==", "'asgd'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "ASGD", "\n", "", "elif", "method", "==", "'rmsprop'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "RMSprop", "\n", "", "elif", "method", "==", "'rprop'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "Rprop", "\n", "", "elif", "method", "==", "'sgd'", ":", "\n", "        ", "optim_fn", "=", "optim", ".", "SGD", "\n", "assert", "'lr'", "in", "optim_params", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'Unknown optimization method: \"%s\"'", "%", "method", ")", "\n", "\n", "# check that we give good parameters to the optimizer", "\n", "", "expected_args", "=", "inspect", ".", "getargspec", "(", "optim_fn", ".", "__init__", ")", "[", "0", "]", "\n", "assert", "expected_args", "[", ":", "2", "]", "==", "[", "'self'", ",", "'params'", "]", "\n", "if", "not", "all", "(", "k", "in", "expected_args", "[", "2", ":", "]", "for", "k", "in", "optim_params", ".", "keys", "(", ")", ")", ":", "\n", "        ", "raise", "Exception", "(", "'Unexpected parameters: expected \"%s\", got \"%s\"'", "%", "(", "\n", "str", "(", "expected_args", "[", "2", ":", "]", ")", ",", "str", "(", "optim_params", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n", "", "return", "optim_fn", ",", "optim_params", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.mutils.batcher": [[67, 75], ["params.infersent.encode"], "function", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.ClassificationNet.encode"], ["def", "batcher", "(", "batch", ",", "params", ")", ":", "\n", "# batch contains list of words", "\n", "    ", "batch", "=", "[", "[", "'<s>'", "]", "+", "s", "+", "[", "'</s>'", "]", "for", "s", "in", "batch", "]", "\n", "sentences", "=", "[", "' '", ".", "join", "(", "s", ")", "for", "s", "in", "batch", "]", "\n", "embeddings", "=", "params", ".", "infersent", ".", "encode", "(", "sentences", ",", "bsize", "=", "params", ".", "batch_size", ",", "\n", "tokenize", "=", "False", ")", "\n", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.src.mutils.prepare": [[77, 80], ["params.infersent.build_vocab"], "function", ["home.repos.pwc.inspect_result.azpoliak_robust-nli.src.models.BLSTMEncoder.build_vocab"], ["", "def", "prepare", "(", "params", ",", "samples", ")", ":", "\n", "    ", "params", ".", "infersent", ".", "build_vocab", "(", "[", "' '", ".", "join", "(", "s", ")", "for", "s", "in", "samples", "]", ",", "\n", "params", ".", "glove_path", ",", "tokenize", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.data.convert_recast_data.main": [[5, 74], ["glob.glob", "open", "open", "open", "open", "open", "open", "open", "open", "open", "open", "[].close", "[].close", "[].split", "line.startswith", "line.startswith", "line.startswith", "file.split", "line.startswith", "[].strip", "line.startswith", "[].strip", "line.split", "line.strip", "[].write", "[].write", "[].write", "line.split", "line.split", "line.split", "str", "[].split", "file.split"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "  ", "train_count", "=", "0", "\n", "val_count", "=", "0", "\n", "test_count", "=", "0", "\n", "input_files", "=", "glob", ".", "glob", "(", "\"./recast/*_data.txt\"", ")", "\n", "\n", "f_train_orig_data", "=", "open", "(", "\"recast/cl_train_orig_dataset_file\"", ",", "\"wb\"", ")", "\n", "f_val_orig_data", "=", "open", "(", "\"recast/cl_val_orig_dataset_file\"", ",", "\"wb\"", ")", "\n", "f_test_orig_data", "=", "open", "(", "\"recast/cl_test_orig_dataset_file\"", ",", "\"wb\"", ")", "\n", "for", "file", "in", "input_files", ":", "\n", "\n", "    ", "f_type", "=", "file", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "f_train_lbl", "=", "open", "(", "\"recast/cl_\"", "+", "f_type", "+", "\"_train_lbl_file\"", ",", "\"wb\"", ")", "\n", "f_dev_lbl", "=", "open", "(", "\"recast/cl_\"", "+", "f_type", "+", "\"_val_lbl_file\"", ",", "\"wb\"", ")", "\n", "f_test_lbl", "=", "open", "(", "\"recast/cl_\"", "+", "f_type", "+", "\"_test_lbl_file\"", ",", "\"wb\"", ")", "\n", "\n", "f_train_source", "=", "open", "(", "\"recast/cl_\"", "+", "f_type", "+", "\"_train_source_file\"", ",", "\"wb\"", ")", "\n", "f_dev_source", "=", "open", "(", "\"recast/cl_\"", "+", "f_type", "+", "\"_val_source_file\"", ",", "\"wb\"", ")", "\n", "f_test_source", "=", "open", "(", "\"recast/cl_\"", "+", "f_type", "+", "\"_test_source_file\"", ",", "\"wb\"", ")", "\n", "\n", "\n", "out_files", "=", "{", "\"train\"", ":", "[", "f_train_lbl", ",", "f_train_source", ",", "f_train_orig_data", "]", ",", "\"dev\"", ":", "[", "f_dev_lbl", ",", "f_dev_source", ",", "f_val_orig_data", "]", ",", "\"test\"", ":", "[", "f_test_lbl", ",", "f_test_source", ",", "f_test_orig_data", "]", "}", "\n", "\n", "\n", "orig_sent", ",", "hyp_sent", ",", "data_split", ",", "src", ",", "label", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "for", "line", "in", "open", "(", "file", ")", ":", "\n", "      ", "if", "line", ".", "startswith", "(", "\"entailed: \"", ")", ":", "\n", "        ", "label", "=", "\"entailed\"", "\n", "if", "\"not-entailed\"", "in", "line", ":", "\n", "          ", "label", "=", "\"not-entailed\"", "\n", "", "", "elif", "line", ".", "startswith", "(", "\"text: \"", ")", ":", "\n", "        ", "orig_sent", "=", "\" \"", ".", "join", "(", "line", ".", "split", "(", "\"text: \"", ")", "[", "1", ":", "]", ")", ".", "strip", "(", ")", "\n", "", "elif", "line", ".", "startswith", "(", "\"hypothesis: \"", ")", ":", "\n", "        ", "hyp_sent", "=", "\" \"", ".", "join", "(", "line", ".", "split", "(", "\"hypothesis: \"", ")", "[", "1", ":", "]", ")", ".", "strip", "(", ")", "\n", "", "elif", "line", ".", "startswith", "(", "\"partof: \"", ")", ":", "\n", "        ", "data_split", "=", "line", ".", "split", "(", "\"partof: \"", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "", "elif", "line", ".", "startswith", "(", "\"provenance: \"", ")", ":", "\n", "        ", "src", "=", "line", ".", "split", "(", "\"provenance: \"", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "", "elif", "not", "line", ".", "strip", "(", ")", ":", "\n", "        ", "assert", "orig_sent", "!=", "None", "\n", "assert", "hyp_sent", "!=", "None", "\n", "assert", "data_split", "!=", "None", "\n", "assert", "src", "!=", "None", "\n", "assert", "label", "!=", "None", "\n", "'''if data_split == 'train':  and train_count > 1000:\n          continue\n        elif data_split == 'train':\n          train_count += 1\n        elif data_split == 'dev' and val_count > 1000:\n          continue\n        elif data_split == 'dev':\n          val_count += 1 \n        elif data_split == 'test' and test_count > 100:\n          continue\n        elif data_split == 'test':\n          test_count += 1\n        '''", "\n", "#print orig_sent, hyp_sent, data_split, src, label", "\n", "out_files", "[", "data_split", "]", "[", "0", "]", ".", "write", "(", "str", "(", "label", ")", "+", "\"\\n\"", ")", "\n", "out_files", "[", "data_split", "]", "[", "1", "]", ".", "write", "(", "orig_sent", "+", "\"|||\"", "+", "hyp_sent", "+", "\"\\n\"", ")", "\n", "out_files", "[", "data_split", "]", "[", "2", "]", ".", "write", "(", "file", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "+", "\"\\n\"", ")", "\n", "\n", "orig_sent", ",", "hyp_sent", ",", "data_split", ",", "src", ",", "label", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n", "", "", "", "for", "data_type", "in", "out_files", ":", "\n", "    ", "out_files", "[", "data_type", "]", "[", "0", "]", ".", "close", "(", ")", "\n", "out_files", "[", "data_type", "]", "[", "1", "]", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.azpoliak_robust-nli.data.convert_mpe-concat.combine_premises": [[5, 15], ["nltk.word_tokenize", "range", "row[].split"], "function", ["None"], ["def", "combine_premises", "(", "row", ")", ":", "\n", "#import pdb; pdb.set_trace()", "\n", "    ", "'''\n    Index([u'ID', u'premise1', u'premise2', u'premise3', u'premise4',\n       u'hypothesis', u'entailment_judgments', u'neutral_judgments',\n       u'contradiction_judgments', u'gold_label'],\n      dtype='object')\n    '''", "\n", "# return \" \".join([nltk.word_tokenize(row[\"premise%d\"%(i)].split('/')[1]) for i in range(1,5)])", "\n", "return", "\" \"", ".", "join", "(", "[", "\" \"", ".", "join", "(", "nltk", ".", "word_tokenize", "(", "row", "[", "\"premise%d\"", "%", "(", "i", ")", "]", ".", "split", "(", "'/'", ")", "[", "1", "]", ")", ")", "for", "i", "in", "range", "(", "1", ",", "5", ")", "]", ")", "\n", "\n"]]}