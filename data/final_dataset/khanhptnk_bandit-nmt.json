{"home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.train.init": [[128, 131], ["model.parameters", "p.data.uniform_"], "function", ["None"], ["", "def", "init", "(", "model", ")", ":", "\n", "    ", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "p", ".", "data", ".", "uniform_", "(", "-", "opt", ".", "param_init", ",", "opt", ".", "param_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.train.create_optim": [[132, 138], ["lib.Optim", "model.parameters"], "function", ["None"], ["", "", "def", "create_optim", "(", "model", ")", ":", "\n", "    ", "optim", "=", "lib", ".", "Optim", "(", "\n", "model", ".", "parameters", "(", ")", ",", "opt", ".", "optim", ",", "opt", ".", "lr", ",", "opt", ".", "max_grad_norm", ",", "\n", "lr_decay", "=", "opt", ".", "learning_rate_decay", ",", "start_decay_at", "=", "opt", ".", "start_decay_at", "\n", ")", "\n", "return", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.train.create_model": [[139, 152], ["lib.Encoder", "lib.Decoder", "train.init", "train.create_optim", "lib.MemEfficientGenerator", "lib.BaseGenerator", "torch.Linear", "torch.Linear", "lib.NMTModel", "lib.NMTModel"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.train.init", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.train.create_optim"], ["", "def", "create_model", "(", "model_class", ",", "dicts", ",", "gen_out_size", ")", ":", "\n", "    ", "encoder", "=", "lib", ".", "Encoder", "(", "opt", ",", "dicts", "[", "\"src\"", "]", ")", "\n", "decoder", "=", "lib", ".", "Decoder", "(", "opt", ",", "dicts", "[", "\"tgt\"", "]", ")", "\n", "# Use memory efficient generator when output size is large and", "\n", "# max_generator_batches is smaller than batch_size.", "\n", "if", "opt", ".", "max_generator_batches", "<", "opt", ".", "batch_size", "and", "gen_out_size", ">", "1", ":", "\n", "        ", "generator", "=", "lib", ".", "MemEfficientGenerator", "(", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", ",", "gen_out_size", ")", ",", "opt", ")", "\n", "", "else", ":", "\n", "        ", "generator", "=", "lib", ".", "BaseGenerator", "(", "nn", ".", "Linear", "(", "opt", ".", "rnn_size", ",", "gen_out_size", ")", ",", "opt", ")", "\n", "", "model", "=", "model_class", "(", "encoder", ",", "decoder", ",", "generator", ",", "opt", ")", "\n", "init", "(", "model", ")", "\n", "optim", "=", "create_optim", "(", "model", ")", "\n", "return", "model", ",", "optim", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.train.create_critic": [[153, 162], ["train.create_model", "critic.cuda"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.train.create_model"], ["", "def", "create_critic", "(", "checkpoint", ",", "dicts", ",", "opt", ")", ":", "\n", "    ", "if", "opt", ".", "load_from", "is", "not", "None", "and", "\"critic\"", "in", "checkpoint", ":", "\n", "        ", "critic", "=", "checkpoint", "[", "\"critic\"", "]", "\n", "critic_optim", "=", "checkpoint", "[", "\"critic_optim\"", "]", "\n", "", "else", ":", "\n", "        ", "critic", ",", "critic_optim", "=", "create_model", "(", "lib", ".", "NMTModel", ",", "dicts", ",", "1", ")", "\n", "", "if", "opt", ".", "cuda", ":", "\n", "        ", "critic", ".", "cuda", "(", "opt", ".", "gpus", "[", "0", "]", ")", "\n", "", "return", "critic", ",", "critic_optim", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.train.main": [[163, 264], ["print", "torch.load", "torch.load", "lib.Dataset", "lib.Dataset", "lib.Dataset", "lib.Dataset", "print", "print", "print", "print", "print", "sum", "print", "train.create_model", "print", "torch.load", "torch.load", "model.cuda", "lib.PertFunction", "lib.Evaluator", "opt.load_from.replace", "lib.Evaluator.eval", "opt.load_from.replace", "lib.Evaluator.eval", "len", "len", "dicts[].size", "p.nelement", "train.create_critic", "lib.ReinforceTrainer", "lib.ReinforceTrainer.train", "dicts[].size", "dicts[].size", "model.parameters", "optim.set_lr", "lib.Trainer", "lib.Trainer.train", "lib.Trainer", "time.time", "lib.Trainer.train", "train.create_critic", "lib.ReinforceTrainer", "lib.ReinforceTrainer.train", "lib.Trainer.train", "lib.ReinforceTrainer", "lib.ReinforceTrainer.train"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.train.create_model", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.eval.Evaluator.Evaluator.eval", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.eval.Evaluator.Evaluator.eval", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.train.create_critic", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.set_lr", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.train.create_critic", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "print", "(", "'Loading data from \"%s\"'", "%", "opt", ".", "data", ")", "\n", "\n", "dataset", "=", "torch", ".", "load", "(", "opt", ".", "data", ")", "\n", "\n", "supervised_data", "=", "lib", ".", "Dataset", "(", "dataset", "[", "\"train_xe\"", "]", ",", "opt", ".", "batch_size", ",", "opt", ".", "cuda", ",", "eval", "=", "False", ")", "\n", "bandit_data", "=", "lib", ".", "Dataset", "(", "dataset", "[", "\"train_pg\"", "]", ",", "opt", ".", "batch_size", ",", "opt", ".", "cuda", ",", "eval", "=", "False", ")", "\n", "valid_data", "=", "lib", ".", "Dataset", "(", "dataset", "[", "\"valid\"", "]", ",", "opt", ".", "batch_size", ",", "opt", ".", "cuda", ",", "eval", "=", "True", ")", "\n", "test_data", "=", "lib", ".", "Dataset", "(", "dataset", "[", "\"test\"", "]", ",", "opt", ".", "batch_size", ",", "opt", ".", "cuda", ",", "eval", "=", "True", ")", "\n", "\n", "dicts", "=", "dataset", "[", "\"dicts\"", "]", "\n", "print", "(", "\" * vocabulary size. source = %d; target = %d\"", "%", "\n", "(", "dicts", "[", "\"src\"", "]", ".", "size", "(", ")", ",", "dicts", "[", "\"tgt\"", "]", ".", "size", "(", ")", ")", ")", "\n", "print", "(", "\" * number of XENT training sentences. %d\"", "%", "\n", "len", "(", "dataset", "[", "\"train_xe\"", "]", "[", "\"src\"", "]", ")", ")", "\n", "print", "(", "\" * number of PG training sentences. %d\"", "%", "\n", "len", "(", "dataset", "[", "\"train_pg\"", "]", "[", "\"src\"", "]", ")", ")", "\n", "print", "(", "\" * maximum batch size. %d\"", "%", "opt", ".", "batch_size", ")", "\n", "print", "(", "\"Building model...\"", ")", "\n", "\n", "use_critic", "=", "opt", ".", "start_reinforce", "is", "not", "None", "\n", "\n", "if", "opt", ".", "load_from", "is", "None", ":", "\n", "        ", "model", ",", "optim", "=", "create_model", "(", "lib", ".", "NMTModel", ",", "dicts", ",", "dicts", "[", "\"tgt\"", "]", ".", "size", "(", ")", ")", "\n", "checkpoint", "=", "None", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Loading from checkpoint at %s\"", "%", "opt", ".", "load_from", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "load_from", ")", "\n", "model", "=", "checkpoint", "[", "\"model\"", "]", "\n", "optim", "=", "checkpoint", "[", "\"optim\"", "]", "\n", "opt", ".", "start_epoch", "=", "checkpoint", "[", "\"epoch\"", "]", "+", "1", "\n", "\n", "# GPU.", "\n", "", "if", "opt", ".", "cuda", ":", "\n", "        ", "model", ".", "cuda", "(", "opt", ".", "gpus", "[", "0", "]", ")", "\n", "\n", "# Start reinforce training immediately.", "\n", "", "if", "opt", ".", "start_reinforce", "==", "-", "1", ":", "\n", "        ", "opt", ".", "start_decay_at", "=", "opt", ".", "start_epoch", "\n", "opt", ".", "start_reinforce", "=", "opt", ".", "start_epoch", "\n", "\n", "# Check if end_epoch is large enough.", "\n", "", "if", "use_critic", ":", "\n", "        ", "assert", "opt", ".", "start_epoch", "+", "opt", ".", "critic_pretrain_epochs", "-", "1", "<=", "opt", ".", "end_epoch", ",", "\"Please increase -end_epoch to perform pretraining!\"", "\n", "\n", "", "nParams", "=", "sum", "(", "[", "p", ".", "nelement", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "]", ")", "\n", "print", "(", "\"* number of parameters: %d\"", "%", "nParams", ")", "\n", "\n", "# Metrics.", "\n", "metrics", "=", "{", "}", "\n", "metrics", "[", "\"nmt_loss\"", "]", "=", "lib", ".", "Loss", ".", "weighted_xent_loss", "\n", "metrics", "[", "\"critic_loss\"", "]", "=", "lib", ".", "Loss", ".", "weighted_mse", "\n", "metrics", "[", "\"sent_reward\"", "]", "=", "lib", ".", "Reward", ".", "sentence_bleu", "\n", "metrics", "[", "\"corp_reward\"", "]", "=", "lib", ".", "Reward", ".", "corpus_bleu", "\n", "if", "opt", ".", "pert_func", "is", "not", "None", ":", "\n", "        ", "opt", ".", "pert_func", "=", "lib", ".", "PertFunction", "(", "opt", ".", "pert_func", ",", "opt", ".", "pert_param", ")", "\n", "\n", "\n", "# Evaluate model on heldout dataset.", "\n", "", "if", "opt", ".", "eval", ":", "\n", "        ", "evaluator", "=", "lib", ".", "Evaluator", "(", "model", ",", "metrics", ",", "dicts", ",", "opt", ")", "\n", "# On validation set.", "\n", "pred_file", "=", "opt", ".", "load_from", ".", "replace", "(", "\".pt\"", ",", "\".valid.pred\"", ")", "\n", "evaluator", ".", "eval", "(", "valid_data", ",", "pred_file", ")", "\n", "# On test set.", "\n", "pred_file", "=", "opt", ".", "load_from", ".", "replace", "(", "\".pt\"", ",", "\".test.pred\"", ")", "\n", "evaluator", ".", "eval", "(", "test_data", ",", "pred_file", ")", "\n", "", "elif", "opt", ".", "eval_sample", ":", "\n", "        ", "opt", ".", "no_update", "=", "True", "\n", "critic", ",", "critic_optim", "=", "create_critic", "(", "checkpoint", ",", "dicts", ",", "opt", ")", "\n", "reinforce_trainer", "=", "lib", ".", "ReinforceTrainer", "(", "model", ",", "critic", ",", "bandit_data", ",", "test_data", ",", "\n", "metrics", ",", "dicts", ",", "optim", ",", "critic_optim", ",", "opt", ")", "\n", "reinforce_trainer", ".", "train", "(", "opt", ".", "start_epoch", ",", "opt", ".", "start_epoch", ",", "False", ")", "\n", "", "elif", "opt", ".", "sup_train_on_bandit", ":", "\n", "        ", "optim", ".", "set_lr", "(", "opt", ".", "reinforce_lr", ")", "\n", "xent_trainer", "=", "lib", ".", "Trainer", "(", "model", ",", "bandit_data", ",", "test_data", ",", "metrics", ",", "dicts", ",", "optim", ",", "opt", ")", "\n", "xent_trainer", ".", "train", "(", "opt", ".", "start_epoch", ",", "opt", ".", "start_epoch", ")", "\n", "", "else", ":", "\n", "        ", "xent_trainer", "=", "lib", ".", "Trainer", "(", "model", ",", "supervised_data", ",", "valid_data", ",", "metrics", ",", "dicts", ",", "optim", ",", "opt", ")", "\n", "if", "use_critic", ":", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "# Supervised training.", "\n", "xent_trainer", ".", "train", "(", "opt", ".", "start_epoch", ",", "opt", ".", "start_reinforce", "-", "1", ",", "start_time", ")", "\n", "# Create critic here to not affect random seed.", "\n", "critic", ",", "critic_optim", "=", "create_critic", "(", "checkpoint", ",", "dicts", ",", "opt", ")", "\n", "# Pretrain critic.", "\n", "if", "opt", ".", "critic_pretrain_epochs", ">", "0", ":", "\n", "                ", "reinforce_trainer", "=", "lib", ".", "ReinforceTrainer", "(", "model", ",", "critic", ",", "supervised_data", ",", "test_data", ",", "\n", "metrics", ",", "dicts", ",", "optim", ",", "critic_optim", ",", "opt", ")", "\n", "reinforce_trainer", ".", "train", "(", "opt", ".", "start_reinforce", ",", "\n", "opt", ".", "start_reinforce", "+", "opt", ".", "critic_pretrain_epochs", "-", "1", ",", "True", ",", "start_time", ")", "\n", "# Reinforce training.", "\n", "", "reinforce_trainer", "=", "lib", ".", "ReinforceTrainer", "(", "model", ",", "critic", ",", "bandit_data", ",", "test_data", ",", "\n", "metrics", ",", "dicts", ",", "optim", ",", "critic_optim", ",", "opt", ")", "\n", "reinforce_trainer", ".", "train", "(", "opt", ".", "start_reinforce", "+", "opt", ".", "critic_pretrain_epochs", ",", "opt", ".", "end_epoch", ",", "\n", "False", ",", "start_time", ")", "\n", "# Supervised training only.", "\n", "", "else", ":", "\n", "            ", "xent_trainer", ".", "train", "(", "opt", ".", "start_epoch", ",", "opt", ".", "end_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.makeVocabulary": [[53, 68], ["lib.Dict", "vocab.prune.size", "vocab.prune.prune", "print", "open", "f.readlines", "sent.split", "vocab.prune.add", "vocab.prune.size", "word.lower"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.prune", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.add", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["def", "makeVocabulary", "(", "filename", ",", "size", ")", ":", "\n", "    ", "vocab", "=", "lib", ".", "Dict", "(", "[", "lib", ".", "Constants", ".", "PAD_WORD", ",", "lib", ".", "Constants", ".", "UNK_WORD", ",", "\n", "lib", ".", "Constants", ".", "BOS_WORD", ",", "lib", ".", "Constants", ".", "EOS_WORD", "]", ")", "\n", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "for", "sent", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "for", "word", "in", "sent", ".", "split", "(", ")", ":", "\n", "                ", "vocab", ".", "add", "(", "word", ".", "lower", "(", ")", ")", "# Lowercase all words", "\n", "\n", "", "", "", "originalSize", "=", "vocab", ".", "size", "(", ")", "\n", "vocab", "=", "vocab", ".", "prune", "(", "size", ")", "\n", "print", "(", "\"Created dictionary of size %d (pruned from %d)\"", "%", "\n", "(", "vocab", ".", "size", "(", ")", ",", "originalSize", ")", ")", "\n", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.initVocabulary": [[70, 76], ["print", "preprocess.makeVocabulary", "print", "makeVocabulary.writeFile"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.makeVocabulary", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.writeFile"], ["", "def", "initVocabulary", "(", "name", ",", "dataFile", ",", "vocabSize", ",", "saveFile", ")", ":", "\n", "    ", "print", "(", "\"Building \"", "+", "name", "+", "\" vocabulary...\"", ")", "\n", "vocab", "=", "makeVocabulary", "(", "dataFile", ",", "vocabSize", ")", "\n", "print", "(", "\"Saving \"", "+", "name", "+", "\" vocabulary to \\\"\"", "+", "saveFile", "+", "\"\\\"...\"", ")", "\n", "vocab", ".", "writeFile", "(", "saveFile", ")", "\n", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.reorderSentences": [[77, 82], ["None"], "function", ["None"], ["", "def", "reorderSentences", "(", "pos", ",", "src", ",", "tgt", ",", "perm", ")", ":", "\n", "    ", "new_pos", "=", "[", "pos", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "new_src", "=", "[", "src", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "new_tgt", "=", "[", "tgt", "[", "idx", "]", "for", "idx", "in", "perm", "]", "\n", "return", "new_pos", ",", "new_src", ",", "new_tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.makeData": [[83, 122], ["print", "open", "open", "open.close", "open.close", "print", "open.readline().split", "open.readline().split", "len", "len", "range", "print", "len", "open.readline", "open.readline", "print", "len", "len", "srcDicts.convertToIdx", "tgtDicts.convertToIdx", "len", "len"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.convertToIdx", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.convertToIdx"], ["", "def", "makeData", "(", "which", ",", "srcFile", ",", "tgtFile", ",", "srcDicts", ",", "tgtDicts", ")", ":", "\n", "    ", "src", ",", "tgt", "=", "[", "]", ",", "[", "]", "\n", "sizes", "=", "[", "]", "\n", "count", ",", "ignored", "=", "0", ",", "0", "\n", "\n", "print", "(", "\"Processing %s & %s ...\"", "%", "(", "srcFile", ",", "tgtFile", ")", ")", "\n", "srcF", "=", "open", "(", "srcFile", ")", "\n", "tgtF", "=", "open", "(", "tgtFile", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "srcWords", "=", "srcF", ".", "readline", "(", ")", ".", "split", "(", ")", "\n", "tgtWords", "=", "tgtF", ".", "readline", "(", ")", ".", "split", "(", ")", "\n", "\n", "if", "not", "srcWords", "or", "not", "tgtWords", ":", "\n", "            ", "if", "srcWords", "and", "not", "tgtWords", "or", "not", "srcWords", "and", "tgtWords", ":", "\n", "                ", "print", "(", "\"WARNING: source and target do not have the same number of sentences\"", ")", "\n", "", "break", "\n", "\n", "", "if", "len", "(", "srcWords", ")", "<=", "opt", ".", "seq_length", "and", "len", "(", "tgtWords", ")", "<=", "opt", ".", "seq_length", ":", "\n", "            ", "src", "+=", "[", "srcDicts", ".", "convertToIdx", "(", "srcWords", ",", "\n", "lib", ".", "Constants", ".", "UNK_WORD", ")", "]", "\n", "tgt", "+=", "[", "tgtDicts", ".", "convertToIdx", "(", "tgtWords", ",", "\n", "lib", ".", "Constants", ".", "UNK_WORD", ",", "\n", "eosWord", "=", "lib", ".", "Constants", ".", "EOS_WORD", ")", "]", "\n", "sizes", "+=", "[", "len", "(", "srcWords", ")", "]", "\n", "", "else", ":", "\n", "            ", "ignored", "+=", "1", "\n", "\n", "", "count", "+=", "1", "\n", "if", "count", "%", "opt", ".", "report_every", "==", "0", ":", "\n", "            ", "print", "(", "\"... %d sentences prepared\"", "%", "count", ")", "\n", "\n", "", "", "srcF", ".", "close", "(", ")", "\n", "tgtF", ".", "close", "(", ")", "\n", "\n", "assert", "len", "(", "src", ")", "==", "len", "(", "tgt", ")", "\n", "print", "(", "\"Prepared %d sentences (%d ignored due to length == 0 or > %d)\"", "%", "(", "len", "(", "src", ")", ",", "ignored", ",", "opt", ".", "seq_length", ")", ")", "\n", "\n", "return", "src", ",", "tgt", ",", "range", "(", "len", "(", "src", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.makeDataGeneral": [[124, 130], ["print", "preprocess.makeData"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.makeData"], ["", "def", "makeDataGeneral", "(", "which", ",", "src_path", ",", "tgt_path", ",", "dicts", ")", ":", "\n", "    ", "print", "(", "\"Preparing \"", "+", "which", "+", "\"...\"", ")", "\n", "res", "=", "{", "}", "\n", "res", "[", "\"src\"", "]", ",", "res", "[", "\"tgt\"", "]", ",", "res", "[", "\"pos\"", "]", "=", "makeData", "(", "which", ",", "src_path", ",", "tgt_path", ",", "\n", "dicts", "[", "\"src\"", "]", ",", "dicts", "[", "\"tgt\"", "]", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.main": [[132, 152], ["preprocess.initVocabulary", "preprocess.initVocabulary", "preprocess.makeDataGeneral", "preprocess.makeDataGeneral", "preprocess.makeDataGeneral", "preprocess.makeDataGeneral", "print", "torch.save"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.initVocabulary", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.initVocabulary", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.makeDataGeneral", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.makeDataGeneral", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.makeDataGeneral", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.None.preprocess.makeDataGeneral"], ["", "def", "main", "(", ")", ":", "\n", "    ", "dicts", "=", "{", "}", "\n", "dicts", "[", "\"src\"", "]", "=", "initVocabulary", "(", "\"source\"", ",", "opt", ".", "train_src", ",", "opt", ".", "src_vocab_size", ",", "\n", "opt", ".", "save_data", "+", "\".src.dict\"", ")", "\n", "dicts", "[", "\"tgt\"", "]", "=", "initVocabulary", "(", "\"target\"", ",", "opt", ".", "train_tgt", ",", "opt", ".", "tgt_vocab_size", ",", "\n", "opt", ".", "save_data", "+", "\".tgt.dict\"", ")", "\n", "\n", "save_data", "=", "{", "}", "\n", "save_data", "[", "\"dicts\"", "]", "=", "dicts", "\n", "save_data", "[", "\"train_xe\"", "]", "=", "makeDataGeneral", "(", "\"train_xe\"", ",", "opt", ".", "train_xe_src", ",", "\n", "opt", ".", "train_xe_tgt", ",", "dicts", ")", "\n", "save_data", "[", "\"train_pg\"", "]", "=", "makeDataGeneral", "(", "\"train_pg\"", ",", "opt", ".", "train_pg_src", ",", "\n", "opt", ".", "train_pg_tgt", ",", "dicts", ")", "\n", "save_data", "[", "\"valid\"", "]", "=", "makeDataGeneral", "(", "\"valid\"", ",", "opt", ".", "valid_src", ",", "opt", ".", "valid_tgt", ",", "\n", "dicts", ")", "\n", "save_data", "[", "\"test\"", "]", "=", "makeDataGeneral", "(", "\"test\"", ",", "opt", ".", "test_src", ",", "opt", ".", "test_tgt", ",", "\n", "dicts", ")", "\n", "\n", "print", "(", "\"Saving data to \\\"\"", "+", "opt", ".", "save_data", "+", "\"-train.pt\\\"...\"", ")", "\n", "torch", ".", "save", "(", "save_data", ",", "opt", ".", "save_data", "+", "\"-train.pt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.GlobalAttention.GlobalAttention.__init__": [[8, 15], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dim", ")", ":", "\n", "        ", "super", "(", "GlobalAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear_in", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "sm", "=", "nn", ".", "Softmax", "(", ")", "\n", "self", ".", "linear_out", "=", "nn", ".", "Linear", "(", "dim", "*", "2", ",", "dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.GlobalAttention.GlobalAttention.applyMask": [[16, 18], ["None"], "methods", ["None"], ["", "def", "applyMask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask", "=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.GlobalAttention.GlobalAttention.forward": [[19, 39], ["GlobalAttention.GlobalAttention.linear_in().unsqueeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "GlobalAttention.GlobalAttention.sm", "GlobalAttention.GlobalAttention.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "GlobalAttention.GlobalAttention.tanh", "GlobalAttention.GlobalAttention.data.masked_fill_", "GlobalAttention.GlobalAttention.size", "GlobalAttention.GlobalAttention.size", "GlobalAttention.GlobalAttention.linear_out", "GlobalAttention.GlobalAttention.linear_in", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "context", ")", ":", "\n", "        ", "\"\"\"\n        inputs: batch x dim\n        context: batch x sourceL x dim\n        \"\"\"", "\n", "targetT", "=", "self", ".", "linear_in", "(", "inputs", ")", ".", "unsqueeze", "(", "2", ")", "# batch x dim x 1", "\n", "\n", "# Get attention", "\n", "attn", "=", "torch", ".", "bmm", "(", "context", ",", "targetT", ")", ".", "squeeze", "(", "2", ")", "# batch x sourceL", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "attn", ".", "data", ".", "masked_fill_", "(", "self", ".", "mask", ",", "-", "_INF", ")", "\n", "", "attn", "=", "self", ".", "sm", "(", "attn", ")", "\n", "attn3", "=", "attn", ".", "view", "(", "attn", ".", "size", "(", "0", ")", ",", "1", ",", "attn", ".", "size", "(", "1", ")", ")", "# batch x 1 x sourceL", "\n", "\n", "weightedContext", "=", "torch", ".", "bmm", "(", "attn3", ",", "context", ")", ".", "squeeze", "(", "1", ")", "# batch x dim", "\n", "contextCombined", "=", "torch", ".", "cat", "(", "(", "weightedContext", ",", "inputs", ")", ",", "1", ")", "\n", "\n", "contextOutput", "=", "self", ".", "tanh", "(", "self", ".", "linear_out", "(", "contextCombined", ")", ")", "\n", "\n", "return", "contextOutput", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.Encoder.__init__": [[11, 21], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LSTM", "torch.LSTM", "torch.LSTM", "dicts.size"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.__init__", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "dicts", ")", ":", "\n", "        ", "self", ".", "layers", "=", "opt", ".", "layers", "\n", "self", ".", "num_directions", "=", "2", "if", "opt", ".", "brnn", "else", "1", "\n", "assert", "opt", ".", "rnn_size", "%", "self", ".", "num_directions", "==", "0", "\n", "self", ".", "hidden_size", "=", "opt", ".", "rnn_size", "//", "self", ".", "num_directions", "\n", "\n", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_lut", "=", "nn", ".", "Embedding", "(", "dicts", ".", "size", "(", ")", ",", "opt", ".", "word_vec_size", ",", "padding_idx", "=", "lib", ".", "Constants", ".", "PAD", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "opt", ".", "word_vec_size", ",", "self", ".", "hidden_size", ",", "\n", "num_layers", "=", "opt", ".", "layers", ",", "dropout", "=", "opt", ".", "dropout", ",", "bidirectional", "=", "opt", ".", "brnn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.Encoder.forward": [[22, 27], ["torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "EncoderDecoder.Encoder.rnn", "EncoderDecoder.Encoder.word_lut", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "hidden", "=", "None", ")", ":", "\n", "        ", "emb", "=", "pack", "(", "self", ".", "word_lut", "(", "inputs", "[", "0", "]", ")", ",", "inputs", "[", "1", "]", ")", "\n", "outputs", ",", "hidden_t", "=", "self", ".", "rnn", "(", "emb", ",", "hidden", ")", "\n", "outputs", "=", "unpack", "(", "outputs", ")", "[", "0", "]", "\n", "return", "hidden_t", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.StackedLSTM.__init__": [[30, 39], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "EncoderDecoder.StackedLSTM.layers.append", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_layers", ",", "input_size", ",", "rnn_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "StackedLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "nn", ".", "LSTMCell", "(", "input_size", ",", "rnn_size", ")", ")", "\n", "input_size", "=", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.StackedLSTM.forward": [[40, 55], ["enumerate", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "layer", "EncoderDecoder.StackedLSTM.dropout"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ",", "hidden", ")", ":", "\n", "        ", "h_0", ",", "c_0", "=", "hidden", "\n", "h_1", ",", "c_1", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "h_1_i", ",", "c_1_i", "=", "layer", "(", "inputs", ",", "(", "h_0", "[", "i", "]", ",", "c_0", "[", "i", "]", ")", ")", "\n", "inputs", "=", "h_1_i", "\n", "if", "i", "!=", "self", ".", "num_layers", ":", "\n", "                ", "inputs", "=", "self", ".", "dropout", "(", "inputs", ")", "\n", "", "h_1", "+=", "[", "h_1_i", "]", "\n", "c_1", "+=", "[", "c_1_i", "]", "\n", "\n", "", "h_1", "=", "torch", ".", "stack", "(", "h_1", ")", "\n", "c_1", "=", "torch", ".", "stack", "(", "c_1", ")", "\n", "\n", "return", "inputs", ",", "(", "h_1", ",", "c_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.Decoder.__init__": [[58, 71], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "EncoderDecoder.StackedLSTM", "lib.GlobalAttention", "torch.Dropout", "torch.Dropout", "torch.Dropout", "dicts.size"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.__init__", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "dicts", ")", ":", "\n", "        ", "self", ".", "layers", "=", "opt", ".", "layers", "\n", "self", ".", "input_feed", "=", "opt", ".", "input_feed", "\n", "input_size", "=", "opt", ".", "word_vec_size", "\n", "if", "self", ".", "input_feed", ":", "\n", "            ", "input_size", "+=", "opt", ".", "rnn_size", "\n", "\n", "", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_lut", "=", "nn", ".", "Embedding", "(", "dicts", ".", "size", "(", ")", ",", "opt", ".", "word_vec_size", ",", "padding_idx", "=", "lib", ".", "Constants", ".", "PAD", ")", "\n", "self", ".", "rnn", "=", "StackedLSTM", "(", "opt", ".", "layers", ",", "input_size", ",", "opt", ".", "rnn_size", ",", "opt", ".", "dropout", ")", "\n", "self", ".", "attn", "=", "lib", ".", "GlobalAttention", "(", "opt", ".", "rnn_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "opt", ".", "dropout", ")", "\n", "self", ".", "hidden_size", "=", "opt", ".", "rnn_size", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.Decoder.step": [[72, 79], ["EncoderDecoder.Decoder.rnn", "EncoderDecoder.Decoder.attn", "EncoderDecoder.Decoder.dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "emb", ",", "output", ",", "hidden", ",", "context", ")", ":", "\n", "        ", "if", "self", ".", "input_feed", ":", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "output", "]", ",", "1", ")", "\n", "", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb", ",", "hidden", ")", "\n", "output", ",", "attn", "=", "self", ".", "attn", "(", "output", ",", "context", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.Decoder.forward": [[80, 92], ["EncoderDecoder.Decoder.word_lut", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "inputs.size", "EncoderDecoder.Decoder.step", "torch.stack.append", "torch.stack.append", "torch.stack.append"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.step"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "init_states", ")", ":", "\n", "        ", "emb", ",", "output", ",", "hidden", ",", "context", "=", "init_states", "\n", "embs", "=", "self", ".", "word_lut", "(", "inputs", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "inputs", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "output", ",", "hidden", "=", "self", ".", "step", "(", "emb", ",", "output", ",", "hidden", ",", "context", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "emb", "=", "embs", "[", "i", "]", "\n", "\n", "", "outputs", "=", "torch", ".", "stack", "(", "outputs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.__init__": [[96, 102], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "generator", ",", "opt", ")", ":", "\n", "        ", "super", "(", "NMTModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "generator", "=", "generator", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.make_init_decoder_output": [[103, 107], ["context.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "context.data.new().zero_", "context.data.new"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["", "def", "make_init_decoder_output", "(", "self", ",", "context", ")", ":", "\n", "        ", "batch_size", "=", "context", ".", "size", "(", "1", ")", "\n", "h_size", "=", "(", "batch_size", ",", "self", ".", "decoder", ".", "hidden_size", ")", "\n", "return", "Variable", "(", "context", ".", "data", ".", "new", "(", "*", "h_size", ")", ".", "zero_", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel._fix_enc_hidden": [[108, 117], ["h.view().transpose().contiguous().view", "h.size", "h.view().transpose().contiguous", "h.size", "h.size", "h.view().transpose", "h.view", "h.size", "h.size", "h.size"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["", "def", "_fix_enc_hidden", "(", "self", ",", "h", ")", ":", "\n", "#  the encoder hidden is  (layers*directions) x batch x dim", "\n", "#  we need to convert it to layers x batch x (directions*dim)", "\n", "        ", "if", "self", ".", "encoder", ".", "num_directions", "==", "2", ":", "\n", "            ", "return", "h", ".", "view", "(", "h", ".", "size", "(", "0", ")", "//", "2", ",", "2", ",", "h", ".", "size", "(", "1", ")", ",", "h", ".", "size", "(", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "h", ".", "size", "(", "0", ")", "//", "2", ",", "h", ".", "size", "(", "1", ")", ",", "h", ".", "size", "(", "2", ")", "*", "2", ")", "\n", "", "else", ":", "\n", "            ", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.initialize": [[118, 131], ["EncoderDecoder.NMTModel.encoder", "EncoderDecoder.NMTModel.make_init_decoder_output", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "EncoderDecoder.NMTModel.decoder.word_lut", "EncoderDecoder.NMTModel._fix_enc_hidden", "EncoderDecoder.NMTModel._fix_enc_hidden", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "init_token.cuda.cuda.cuda", "context.transpose", "EncoderDecoder.NMTModel.size"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.make_init_decoder_output", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel._fix_enc_hidden", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel._fix_enc_hidden", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["", "", "def", "initialize", "(", "self", ",", "inputs", ",", "eval", ")", ":", "\n", "        ", "src", "=", "inputs", "[", "0", "]", "\n", "tgt", "=", "inputs", "[", "1", "]", "\n", "enc_hidden", ",", "context", "=", "self", ".", "encoder", "(", "src", ")", "\n", "init_output", "=", "self", ".", "make_init_decoder_output", "(", "context", ")", "\n", "enc_hidden", "=", "(", "self", ".", "_fix_enc_hidden", "(", "enc_hidden", "[", "0", "]", ")", ",", "\n", "self", ".", "_fix_enc_hidden", "(", "enc_hidden", "[", "1", "]", ")", ")", "\n", "init_token", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "\n", "[", "lib", ".", "Constants", ".", "BOS", "]", "*", "init_output", ".", "size", "(", "0", ")", ")", ",", "volatile", "=", "eval", ")", "\n", "if", "self", ".", "opt", ".", "cuda", ":", "\n", "            ", "init_token", "=", "init_token", ".", "cuda", "(", ")", "\n", "", "emb", "=", "self", ".", "decoder", ".", "word_lut", "(", "init_token", ")", "\n", "return", "tgt", ",", "(", "emb", ",", "init_output", ",", "enc_hidden", ",", "context", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.forward": [[132, 140], ["EncoderDecoder.NMTModel.initialize", "EncoderDecoder.NMTModel.decoder", "EncoderDecoder.NMTModel.generator", "EncoderDecoder.NMTModel.view_as"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.initialize"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "eval", ",", "regression", "=", "False", ")", ":", "\n", "        ", "targets", ",", "init_states", "=", "self", ".", "initialize", "(", "inputs", ",", "eval", ")", "\n", "outputs", "=", "self", ".", "decoder", "(", "targets", ",", "init_states", ")", "\n", "\n", "if", "regression", ":", "\n", "            ", "logits", "=", "self", ".", "generator", "(", "outputs", ")", "\n", "return", "logits", ".", "view_as", "(", "targets", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.backward": [[141, 145], ["EncoderDecoder.NMTModel.generator.backward", "outputs.backward"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.backward", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.backward"], ["", "def", "backward", "(", "self", ",", "outputs", ",", "targets", ",", "weights", ",", "normalizer", ",", "criterion", ",", "regression", "=", "False", ")", ":", "\n", "        ", "grad_output", ",", "loss", "=", "self", ".", "generator", ".", "backward", "(", "outputs", ",", "targets", ",", "weights", ",", "normalizer", ",", "criterion", ",", "regression", ")", "\n", "outputs", ".", "backward", "(", "grad_output", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.predict": [[146, 148], ["EncoderDecoder.NMTModel.generator.predict"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.predict"], ["", "def", "predict", "(", "self", ",", "outputs", ",", "targets", ",", "weights", ",", "criterion", ")", ":", "\n", "        ", "return", "self", ".", "generator", ".", "predict", "(", "outputs", ",", "targets", ",", "weights", ",", "criterion", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.translate": [[149, 171], ["EncoderDecoder.NMTModel.initialize", "targets.size", "targets[].data.byte().new().zero_", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "EncoderDecoder.NMTModel.decoder.step", "EncoderDecoder.NMTModel.generator", "torch.stack.append", "torch.stack.append", "torch.stack.append", "EncoderDecoder.NMTModel.decoder.word_lut", "targets[].data.byte().new", "[].view", "targets[].data.byte().new().zero_.sum", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "targets[].data.byte", "EncoderDecoder.NMTModel.max"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.initialize", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.step"], ["", "def", "translate", "(", "self", ",", "inputs", ",", "max_length", ")", ":", "\n", "        ", "targets", ",", "init_states", "=", "self", ".", "initialize", "(", "inputs", ",", "eval", "=", "True", ")", "\n", "emb", ",", "output", ",", "hidden", ",", "context", "=", "init_states", "\n", "\n", "preds", "=", "[", "]", "\n", "batch_size", "=", "targets", ".", "size", "(", "1", ")", "\n", "num_eos", "=", "targets", "[", "0", "]", ".", "data", ".", "byte", "(", ")", ".", "new", "(", "batch_size", ")", ".", "zero_", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "max_length", ")", ":", "\n", "            ", "output", ",", "hidden", "=", "self", ".", "decoder", ".", "step", "(", "emb", ",", "output", ",", "hidden", ",", "context", ")", "\n", "logit", "=", "self", ".", "generator", "(", "output", ")", "\n", "pred", "=", "logit", ".", "max", "(", "1", ")", "[", "1", "]", ".", "view", "(", "-", "1", ")", ".", "data", "\n", "preds", ".", "append", "(", "pred", ")", "\n", "\n", "# Stop if all sentences reach EOS.", "\n", "num_eos", "|=", "(", "pred", "==", "lib", ".", "Constants", ".", "EOS", ")", "\n", "if", "num_eos", ".", "sum", "(", ")", "==", "batch_size", ":", "break", "\n", "\n", "emb", "=", "self", ".", "decoder", ".", "word_lut", "(", "Variable", "(", "pred", ")", ")", "\n", "\n", "", "preds", "=", "torch", ".", "stack", "(", "preds", ")", "\n", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.sample": [[172, 197], ["EncoderDecoder.NMTModel.initialize", "targets.size", "targets[].data.byte().new().zero_", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "EncoderDecoder.NMTModel.decoder.step", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.softmax", "torch.softmax", "torch.softmax", "torch.stack.append", "torch.stack.append", "torch.stack.append", "EncoderDecoder.NMTModel.decoder.word_lut", "targets[].data.byte().new", "EncoderDecoder.NMTModel.generator", "torch.softmax.multinomial().view", "targets[].data.byte().new().zero_.sum", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "targets[].data.byte", "torch.softmax.multinomial"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.initialize", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.step"], ["", "def", "sample", "(", "self", ",", "inputs", ",", "max_length", ")", ":", "\n", "        ", "targets", ",", "init_states", "=", "self", ".", "initialize", "(", "inputs", ",", "eval", "=", "False", ")", "\n", "emb", ",", "output", ",", "hidden", ",", "context", "=", "init_states", "\n", "\n", "outputs", "=", "[", "]", "\n", "samples", "=", "[", "]", "\n", "batch_size", "=", "targets", ".", "size", "(", "1", ")", "\n", "num_eos", "=", "targets", "[", "0", "]", ".", "data", ".", "byte", "(", ")", ".", "new", "(", "batch_size", ")", ".", "zero_", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "max_length", ")", ":", "\n", "            ", "output", ",", "hidden", "=", "self", ".", "decoder", ".", "step", "(", "emb", ",", "output", ",", "hidden", ",", "context", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "dist", "=", "F", ".", "softmax", "(", "self", ".", "generator", "(", "output", ")", ")", "\n", "sample", "=", "dist", ".", "multinomial", "(", "1", ",", "replacement", "=", "False", ")", ".", "view", "(", "-", "1", ")", ".", "data", "\n", "samples", ".", "append", "(", "sample", ")", "\n", "\n", "# Stop if all sentences reach EOS.", "\n", "num_eos", "|=", "(", "sample", "==", "lib", ".", "Constants", ".", "EOS", ")", "\n", "if", "num_eos", ".", "sum", "(", ")", "==", "batch_size", ":", "break", "\n", "\n", "emb", "=", "self", ".", "decoder", ".", "word_lut", "(", "Variable", "(", "sample", ")", ")", "\n", "\n", "", "outputs", "=", "torch", ".", "stack", "(", "outputs", ")", "\n", "samples", "=", "torch", ".", "stack", "(", "samples", ")", "\n", "return", "samples", ",", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.BaseGenerator.__init__": [[8, 12], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "generator", ",", "opt", ")", ":", "\n", "        ", "super", "(", "BaseGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "generator", "=", "generator", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.BaseGenerator.forward": [[13, 15], ["Generator.BaseGenerator.generator", "inputs.contiguous().view", "inputs.size", "inputs.contiguous"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "self", ".", "generator", "(", "inputs", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "inputs", ".", "size", "(", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.BaseGenerator.backward": [[16, 31], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "criterion", "criterion.div().backward", "torch.autograd.Variable.contiguous().view", "torch.autograd.Variable.contiguous().view", "torch.autograd.Variable.contiguous().view", "Generator.BaseGenerator.forward", "targets.contiguous().view", "weights.contiguous().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "criterion.div", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.contiguous", "torch.autograd.Variable.contiguous", "torch.autograd.Variable.contiguous", "targets.contiguous", "weights.contiguous"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.backward", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.BaseGenerator.forward", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["", "def", "backward", "(", "self", ",", "outputs", ",", "targets", ",", "weights", ",", "normalizer", ",", "criterion", ",", "regression", "=", "False", ")", ":", "\n", "        ", "outputs", "=", "Variable", "(", "outputs", ".", "data", ",", "requires_grad", "=", "True", ")", "\n", "\n", "logits", "=", "outputs", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "if", "regression", "else", "self", ".", "forward", "(", "outputs", ")", "\n", "\n", "loss", "=", "criterion", "(", "logits", ",", "targets", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "weights", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "loss", ".", "div", "(", "normalizer", ")", ".", "backward", "(", ")", "\n", "loss", "=", "loss", ".", "data", "[", "0", "]", "\n", "\n", "if", "outputs", ".", "grad", "is", "None", ":", "\n", "            ", "grad_output", "=", "torch", ".", "zeros", "(", "outputs", ".", "size", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "grad_output", "=", "outputs", ".", "grad", ".", "data", "\n", "\n", "", "return", "grad_output", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.BaseGenerator.predict": [[32, 39], ["Generator.BaseGenerator.forward", "[].view", "outputs.size", "criterion", "Generator.BaseGenerator.data.max", "targets.contiguous().view", "weights.contiguous().view", "targets.contiguous", "weights.contiguous"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.BaseGenerator.forward", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["", "def", "predict", "(", "self", ",", "outputs", ",", "targets", ",", "weights", ",", "criterion", ")", ":", "\n", "        ", "logits", "=", "self", ".", "forward", "(", "outputs", ")", "\n", "preds", "=", "logits", ".", "data", ".", "max", "(", "1", ")", "[", "1", "]", ".", "view", "(", "outputs", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "loss", "=", "criterion", "(", "logits", ",", "targets", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "weights", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", ".", "data", "[", "0", "]", "\n", "\n", "return", "preds", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.__init__": [[42, 46], ["Generator.BaseGenerator.__init__"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "generator", ",", "opt", ",", "dim", "=", "1", ")", ":", "\n", "        ", "super", "(", "MemEfficientGenerator", ",", "self", ")", ".", "__init__", "(", "generator", ",", "opt", ")", "\n", "self", ".", "batch_size", "=", "opt", ".", "max_generator_batches", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.backward": [[47, 62], ["torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Generator.BaseGenerator.backward", "torch.cat.append", "torch.cat.append", "torch.cat.append"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.backward"], ["", "def", "backward", "(", "self", ",", "outputs", ",", "targets", ",", "weights", ",", "normalizer", ",", "criterion", ",", "regression", "=", "False", ")", ":", "\n", "        ", "outputs_split", "=", "torch", ".", "split", "(", "outputs", ",", "self", ".", "batch_size", ",", "self", ".", "dim", ")", "\n", "targets_split", "=", "torch", ".", "split", "(", "targets", ",", "self", ".", "batch_size", ",", "self", ".", "dim", ")", "\n", "weights_split", "=", "torch", ".", "split", "(", "weights", ",", "self", ".", "batch_size", ",", "self", ".", "dim", ")", "\n", "\n", "grad_output", "=", "[", "]", "\n", "loss", "=", "0", "\n", "for", "out_t", ",", "targ_t", ",", "w_t", "in", "zip", "(", "outputs_split", ",", "targets_split", ",", "weights_split", ")", ":", "\n", "            ", "grad_output_t", ",", "loss_t", "=", "super", "(", "MemEfficientGenerator", ",", "self", ")", ".", "backward", "(", "\n", "out_t", ",", "targ_t", ",", "w_t", ",", "normalizer", ",", "criterion", ",", "regression", ")", "\n", "grad_output", ".", "append", "(", "grad_output_t", ")", "\n", "loss", "+=", "loss_t", "\n", "\n", "", "grad_output", "=", "torch", ".", "cat", "(", "grad_output", ",", "self", ".", "dim", ")", "\n", "return", "grad_output", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.predict": [[63, 78], ["torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "Generator.BaseGenerator.predict", "torch.cat.append", "torch.cat.append", "torch.cat.append"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.predict"], ["", "def", "predict", "(", "self", ",", "outputs", ",", "targets", ",", "weights", ",", "criterion", ")", ":", "\n", "        ", "outputs_split", "=", "torch", ".", "split", "(", "outputs", ",", "self", ".", "batch_size", ",", "self", ".", "dim", ")", "\n", "targets_split", "=", "torch", ".", "split", "(", "targets", ",", "self", ".", "batch_size", ",", "self", ".", "dim", ")", "\n", "weights_split", "=", "torch", ".", "split", "(", "weights", ",", "self", ".", "batch_size", ",", "self", ".", "dim", ")", "\n", "\n", "preds", "=", "[", "]", "\n", "loss", "=", "0", "\n", "for", "out_t", ",", "targ_t", ",", "w_t", "in", "zip", "(", "outputs_split", ",", "targets_split", ",", "weights_split", ")", ":", "\n", "            ", "preds_t", ",", "loss_t", "=", "super", "(", "MemEfficientGenerator", ",", "self", ")", ".", "predict", "(", "\n", "out_t", ",", "targ_t", ",", "w_t", ",", "criterion", ")", "\n", "preds", ".", "append", "(", "preds_t", ")", "\n", "loss", "+=", "loss_t", "\n", "\n", "", "preds", "=", "torch", ".", "cat", "(", "preds", ",", "self", ".", "dim", ")", "\n", "return", "preds", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.eval.Evaluator.Evaluator.__init__": [[5, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "metrics", ",", "dicts", ",", "opt", ")", ":", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "loss_func", "=", "metrics", "[", "\"nmt_loss\"", "]", "\n", "self", ".", "sent_reward_func", "=", "metrics", "[", "\"sent_reward\"", "]", "\n", "self", ".", "corpus_reward_func", "=", "metrics", "[", "\"corp_reward\"", "]", "\n", "self", ".", "dicts", "=", "dicts", "\n", "self", ".", "max_length", "=", "opt", ".", "max_predict_length", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.eval.Evaluator.Evaluator.eval": [[13, 58], ["Evaluator.Evaluator.model.eval", "range", "Evaluator.Evaluator.corpus_reward_func", "len", "[].data.eq().t", "Evaluator.Evaluator.model.decoder.attn.applyMask", "Evaluator.Evaluator.model", "targets.data.t().tolist.data.t().tolist.ne().float", "targets.data.t().tolist.ne().float.data.sum", "Evaluator.Evaluator.model.predict", "Evaluator.Evaluator.model.translate", "preds.t().tolist.t().tolist.t().tolist", "targets.data.t().tolist.data.t().tolist.data.t().tolist", "Evaluator.Evaluator.sent_reward_func", "all_preds.extend", "all_targets.extend", "sum", "batch[].size", "Evaluator.Evaluator._convert_and_report", "[].data.eq", "targets.data.t().tolist.data.t().tolist.ne", "preds.t().tolist.t().tolist.t", "targets.data.t().tolist.data.t().tolist.data.t"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.eval.Evaluator.Evaluator.eval", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.GlobalAttention.GlobalAttention.applyMask", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.predict", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.translate", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.eval.Evaluator.Evaluator._convert_and_report"], ["", "def", "eval", "(", "self", ",", "data", ",", "pred_file", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "total_loss", "=", "0", "\n", "total_words", "=", "0", "\n", "total_sents", "=", "0", "\n", "total_sent_reward", "=", "0", "\n", "\n", "all_preds", "=", "[", "]", "\n", "all_targets", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "            ", "batch", "=", "data", "[", "i", "]", "\n", "targets", "=", "batch", "[", "1", "]", "\n", "\n", "attention_mask", "=", "batch", "[", "0", "]", "[", "0", "]", ".", "data", ".", "eq", "(", "lib", ".", "Constants", ".", "PAD", ")", ".", "t", "(", ")", "\n", "self", ".", "model", ".", "decoder", ".", "attn", ".", "applyMask", "(", "attention_mask", ")", "\n", "outputs", "=", "self", ".", "model", "(", "batch", ",", "True", ")", "\n", "\n", "\n", "weights", "=", "targets", ".", "ne", "(", "lib", ".", "Constants", ".", "PAD", ")", ".", "float", "(", ")", "\n", "num_words", "=", "weights", ".", "data", ".", "sum", "(", ")", "\n", "_", ",", "loss", "=", "self", ".", "model", ".", "predict", "(", "outputs", ",", "targets", ",", "weights", ",", "self", ".", "loss_func", ")", "\n", "\n", "preds", "=", "self", ".", "model", ".", "translate", "(", "batch", ",", "self", ".", "max_length", ")", "\n", "preds", "=", "preds", ".", "t", "(", ")", ".", "tolist", "(", ")", "\n", "targets", "=", "targets", ".", "data", ".", "t", "(", ")", ".", "tolist", "(", ")", "\n", "rewards", ",", "_", "=", "self", ".", "sent_reward_func", "(", "preds", ",", "targets", ")", "\n", "\n", "all_preds", ".", "extend", "(", "preds", ")", "\n", "all_targets", ".", "extend", "(", "targets", ")", "\n", "\n", "total_loss", "+=", "loss", "\n", "total_words", "+=", "num_words", "\n", "total_sent_reward", "+=", "sum", "(", "rewards", ")", "\n", "total_sents", "+=", "batch", "[", "1", "]", ".", "size", "(", "1", ")", "\n", "\n", "", "loss", "=", "total_loss", "/", "total_words", "\n", "sent_reward", "=", "total_sent_reward", "/", "total_sents", "\n", "corpus_reward", "=", "self", ".", "corpus_reward_func", "(", "all_preds", ",", "all_targets", ")", "\n", "\n", "if", "pred_file", "is", "not", "None", ":", "\n", "            ", "self", ".", "_convert_and_report", "(", "data", ",", "pred_file", ",", "all_preds", ",", "\n", "(", "loss", ",", "sent_reward", ",", "corpus_reward", ")", ")", "\n", "\n", "", "return", "loss", ",", "sent_reward", ",", "corpus_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.eval.Evaluator.Evaluator._convert_and_report": [[59, 72], ["data.restore_pos", "print", "print", "print", "print", "print", "open", "lib.Reward.clean_up_sentence", "print", "Evaluator.Evaluator.dicts[].getLabel"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.restore_pos", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Reward.clean_up_sentence", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.getLabel"], ["", "def", "_convert_and_report", "(", "self", ",", "data", ",", "pred_file", ",", "preds", ",", "metrics", ")", ":", "\n", "        ", "preds", "=", "data", ".", "restore_pos", "(", "preds", ")", "\n", "with", "open", "(", "pred_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "sent", "in", "preds", ":", "\n", "                ", "sent", "=", "lib", ".", "Reward", ".", "clean_up_sentence", "(", "sent", ",", "remove_unk", "=", "False", ",", "remove_eos", "=", "True", ")", "\n", "sent", "=", "[", "self", ".", "dicts", "[", "\"tgt\"", "]", ".", "getLabel", "(", "w", ")", "for", "w", "in", "sent", "]", "\n", "print", "(", "\" \"", ".", "join", "(", "sent", ")", ",", "file", "=", "f", ")", "\n", "", "", "loss", ",", "sent_reward", ",", "corpus_reward", "=", "metrics", "\n", "print", "(", "\"\"", ")", "\n", "print", "(", "\"Loss: %.6f\"", "%", "loss", ")", "\n", "print", "(", "\"Sentence reward: %.2f\"", "%", "(", "sent_reward", "*", "100", ")", ")", "\n", "print", "(", "\"Corpus reward: %.2f\"", "%", "(", "corpus_reward", "*", "100", ")", ")", "\n", "print", "(", "\"Predictions saved to %s\"", "%", "pred_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Loss.weighted_xent_loss": [[7, 12], ["torch.log_softmax", "losses.sum", "F.log_softmax.gather().squeeze", "F.log_softmax.gather", "targets.unsqueeze"], "function", ["None"], ["def", "weighted_xent_loss", "(", "logits", ",", "targets", ",", "weights", ")", ":", "\n", "    ", "log_dist", "=", "F", ".", "log_softmax", "(", "logits", ")", "\n", "losses", "=", "-", "log_dist", ".", "gather", "(", "1", ",", "targets", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "losses", "=", "losses", "*", "weights", "\n", "return", "losses", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Loss.weighted_mse": [[13, 17], ["losses.sum"], "function", ["None"], ["", "def", "weighted_mse", "(", "logits", ",", "targets", ",", "weights", ")", ":", "\n", "    ", "losses", "=", "(", "logits", "-", "targets", ")", "**", "2", "\n", "losses", "=", "losses", "*", "weights", "\n", "return", "losses", ".", "sum", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.PertFunction.PertFunction.__init__": [[31, 43], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "func_name", ",", "param", ")", ":", "\n", "        ", "self", ".", "param", "=", "param", "\n", "if", "func_name", "==", "\"bin\"", ":", "\n", "            ", "self", ".", "func", "=", "_bin", "\n", "", "elif", "func_name", "==", "\"skew\"", ":", "\n", "            ", "self", ".", "func", "=", "_skew", "\n", "", "elif", "func_name", "==", "\"variance\"", ":", "\n", "            ", "self", ".", "func", "=", "_variance", "\n", "", "elif", "func_name", "==", "\"random\"", ":", "\n", "            ", "self", ".", "func", "=", "_random", "\n", "", "elif", "func_name", "==", "\"adver\"", ":", "\n", "            ", "self", ".", "func", "=", "_adver", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.PertFunction.PertFunction.__call__": [[44, 46], ["PertFunction.PertFunction.func"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "r", ")", ":", "\n", "        ", "return", "self", ".", "func", "(", "r", ",", "self", ".", "param", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.PertFunction._adver": [[4, 6], ["None"], "function", ["None"], ["def", "_adver", "(", "rs", ",", "_not_use", ")", ":", "\n", "    ", "return", "[", "1", "-", "r", "for", "r", "in", "rs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.PertFunction._random": [[7, 9], ["random.random", "xrange", "len"], "function", ["None"], ["", "def", "_random", "(", "rs", ",", "_not_use", ")", ":", "\n", "    ", "return", "[", "random", ".", "random", "(", ")", "for", "i", "in", "xrange", "(", "len", "(", "rs", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.PertFunction._bin": [[10, 12], ["round"], "function", ["None"], ["", "def", "_bin", "(", "rs", ",", "b", ")", ":", "\n", "    ", "return", "[", "round", "(", "r", "*", "b", ")", "/", "b", "for", "r", "in", "rs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.PertFunction._variance": [[13, 22], ["numpy.random.normal", "max", "res.append", "min", "min"], "function", ["None"], ["", "def", "_variance", "(", "rs", ",", "scale", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "for", "r", "in", "rs", ":", "\n", "# Use 0.67 instead of 67 because scores are in [0,1] instead of [0,100] as in human eval data.", "\n", "        ", "std", "=", "min", "(", "r", "*", "0.64", ",", "-", "0.67", "*", "r", "+", "0.67", ")", "*", "scale", "\n", "r_new", "=", "np", ".", "random", ".", "normal", "(", "r", ",", "std", ")", "\n", "r_new", "=", "max", "(", "0.", ",", "min", "(", "r_new", ",", "1.", ")", ")", "\n", "res", ".", "append", "(", "r_new", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.PertFunction._curve": [[27, 29], ["None"], "function", ["None"], ["", "def", "_curve", "(", "rs", ",", "p", ")", ":", "\n", "    ", "return", "[", "r", "**", "p", "for", "r", "in", "rs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Reward.clean_up_sentence": [[3, 12], ["filter", "len", "filter.index", "lib.Constants.PAD"], "function", ["None"], ["def", "clean_up_sentence", "(", "sent", ",", "remove_unk", "=", "False", ",", "remove_eos", "=", "False", ")", ":", "\n", "    ", "if", "lib", ".", "Constants", ".", "EOS", "in", "sent", ":", "\n", "        ", "sent", "=", "sent", "[", ":", "sent", ".", "index", "(", "lib", ".", "Constants", ".", "EOS", ")", "+", "1", "]", "\n", "", "if", "remove_unk", ":", "\n", "        ", "sent", "=", "filter", "(", "lambda", "x", ":", "x", "!=", "lib", ".", "Constants", ".", "UNK", ",", "sent", ")", "\n", "", "if", "remove_eos", ":", "\n", "        ", "if", "len", "(", "sent", ")", ">", "0", "and", "sent", "[", "-", "1", "]", "==", "lib", ".", "Constants", ".", "EOS", ":", "\n", "            ", "sent", "=", "sent", "[", ":", "-", "1", "]", "\n", "", "", "return", "sent", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Reward.single_sentence_bleu": [[13, 33], ["len", "Reward.clean_up_sentence", "Reward.clean_up_sentence", "len", "lib.Bleu.score_sentence", "len", "clean_up_sentence.append"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Reward.clean_up_sentence", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Reward.clean_up_sentence", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Bleu.score_sentence"], ["", "def", "single_sentence_bleu", "(", "pair", ")", ":", "\n", "    ", "length", "=", "len", "(", "pair", "[", "0", "]", ")", "\n", "pred", ",", "gold", "=", "pair", "\n", "pred", "=", "clean_up_sentence", "(", "pred", ",", "remove_unk", "=", "False", ",", "remove_eos", "=", "False", ")", "\n", "gold", "=", "clean_up_sentence", "(", "gold", ",", "remove_unk", "=", "False", ",", "remove_eos", "=", "False", ")", "\n", "len_pred", "=", "len", "(", "pred", ")", "\n", "if", "len_pred", "==", "0", ":", "\n", "        ", "score", "=", "0.", "\n", "pred", "=", "[", "lib", ".", "Constants", ".", "PAD", "]", "*", "length", "\n", "", "else", ":", "\n", "        ", "score", "=", "lib", ".", "Bleu", ".", "score_sentence", "(", "pred", ",", "gold", ",", "4", ",", "smooth", "=", "1", ")", "[", "-", "1", "]", "\n", "while", "len", "(", "pred", ")", "<", "length", ":", "\n", "            ", "pred", ".", "append", "(", "lib", ".", "Constants", ".", "PAD", ")", "\n", "\n", "#print pred", "\n", "#print gold", "\n", "#print score", "\n", "#print", "\n", "\n", "", "", "return", "score", ",", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Reward.sentence_bleu": [[34, 38], ["map", "zip", "zip"], "function", ["None"], ["", "def", "sentence_bleu", "(", "preds", ",", "golds", ")", ":", "\n", "    ", "results", "=", "map", "(", "single_sentence_bleu", ",", "zip", "(", "preds", ",", "golds", ")", ")", "\n", "scores", ",", "preds", "=", "zip", "(", "*", "results", ")", "\n", "return", "scores", ",", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Reward.corpus_bleu": [[39, 49], ["zip", "lib.Bleu.score_corpus", "len", "len", "Reward.clean_up_sentence", "Reward.clean_up_sentence", "clean_preds.append", "clean_golds.append"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Bleu.score_corpus", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Reward.clean_up_sentence", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Reward.clean_up_sentence"], ["", "def", "corpus_bleu", "(", "preds", ",", "golds", ")", ":", "\n", "    ", "assert", "len", "(", "preds", ")", "==", "len", "(", "golds", ")", "\n", "clean_preds", "=", "[", "]", "\n", "clean_golds", "=", "[", "]", "\n", "for", "pred", ",", "gold", "in", "zip", "(", "preds", ",", "golds", ")", ":", "\n", "        ", "pred", "=", "clean_up_sentence", "(", "pred", ",", "remove_unk", "=", "False", ",", "remove_eos", "=", "True", ")", "\n", "gold", "=", "clean_up_sentence", "(", "gold", ",", "remove_unk", "=", "False", ",", "remove_eos", "=", "True", ")", "\n", "clean_preds", ".", "append", "(", "pred", ")", "\n", "clean_golds", ".", "append", "(", "gold", ")", "\n", "", "return", "lib", ".", "Bleu", ".", "score_corpus", "(", "clean_preds", ",", "clean_golds", ",", "4", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Bleu._update_ngrams_count": [[5, 11], ["len", "range", "range", "tuple"], "function", ["None"], ["def", "_update_ngrams_count", "(", "sent", ",", "ngrams", ",", "count", ")", ":", "\n", "    ", "length", "=", "len", "(", "sent", ")", "\n", "for", "n", "in", "range", "(", "1", ",", "ngrams", "+", "1", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "length", "-", "n", "+", "1", ")", ":", "\n", "            ", "ngram", "=", "tuple", "(", "sent", "[", "i", ":", "(", "i", "+", "n", ")", "]", ")", "\n", "count", "[", "ngram", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Bleu._compute_bleu": [[12, 25], ["range", "math.exp", "max", "len", "math.log"], "function", ["None"], ["", "", "", "def", "_compute_bleu", "(", "p", ",", "len_pred", ",", "len_gold", ",", "smooth", ")", ":", "\n", "# Brevity penalty.", "\n", "    ", "log_brevity", "=", "1", "-", "max", "(", "1", ",", "(", "len_gold", "+", "smooth", ")", "/", "(", "len_pred", "+", "smooth", ")", ")", "\n", "log_score", "=", "0", "\n", "ngrams", "=", "len", "(", "p", ")", "-", "1", "\n", "for", "n", "in", "range", "(", "1", ",", "ngrams", "+", "1", ")", ":", "\n", "        ", "if", "p", "[", "n", "]", "[", "1", "]", ">", "0", ":", "\n", "            ", "if", "p", "[", "n", "]", "[", "0", "]", "==", "0", ":", "\n", "                ", "p", "[", "n", "]", "[", "0", "]", "=", "1e-16", "\n", "", "log_precision", "=", "math", ".", "log", "(", "(", "p", "[", "n", "]", "[", "0", "]", "+", "smooth", ")", "/", "(", "p", "[", "n", "]", "[", "1", "]", "+", "smooth", ")", ")", "\n", "log_score", "+=", "log_precision", "\n", "", "", "log_score", "/=", "ngrams", "\n", "return", "math", ".", "exp", "(", "log_score", "+", "log_brevity", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Bleu.score_sentence": [[28, 54], ["collections.defaultdict", "Bleu._update_ngrams_count", "collections.defaultdict", "range", "range", "p.append", "len", "range", "scores.append", "tuple", "Bleu._compute_bleu", "len"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Bleu._update_ngrams_count", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Bleu._compute_bleu"], ["", "def", "score_sentence", "(", "pred", ",", "gold", ",", "ngrams", ",", "smooth", "=", "0", ")", ":", "\n", "    ", "scores", "=", "[", "]", "\n", "# Get ngrams count for gold.", "\n", "count_gold", "=", "defaultdict", "(", "int", ")", "\n", "_update_ngrams_count", "(", "gold", ",", "ngrams", ",", "count_gold", ")", "\n", "# Init ngrams count for pred to 0.", "\n", "count_pred", "=", "defaultdict", "(", "int", ")", "\n", "# p[n][0] stores the number of overlapped n-grams.", "\n", "# p[n][1] is total # of n-grams in pred.", "\n", "p", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "ngrams", "+", "1", ")", ":", "\n", "        ", "p", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "pred", ")", ")", ":", "\n", "        ", "for", "n", "in", "range", "(", "1", ",", "ngrams", "+", "1", ")", ":", "\n", "            ", "if", "i", "-", "n", "+", "1", "<", "0", ":", "\n", "                ", "continue", "\n", "# n-gram is from i - n + 1 to i.", "\n", "", "ngram", "=", "tuple", "(", "pred", "[", "(", "i", "-", "n", "+", "1", ")", ":", "(", "i", "+", "1", ")", "]", ")", "\n", "# Update n-gram count.", "\n", "count_pred", "[", "ngram", "]", "+=", "1", "\n", "# Update p[n].", "\n", "p", "[", "n", "]", "[", "1", "]", "+=", "1", "\n", "if", "count_pred", "[", "ngram", "]", "<=", "count_gold", "[", "ngram", "]", ":", "\n", "                ", "p", "[", "n", "]", "[", "0", "]", "+=", "1", "\n", "", "", "scores", ".", "append", "(", "_compute_bleu", "(", "p", ",", "i", "+", "1", ",", "len", "(", "gold", ")", ",", "smooth", ")", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Bleu.score_corpus": [[56, 77], ["range", "zip", "Bleu._compute_bleu", "len", "len", "p.append", "len", "collections.defaultdict", "Bleu._update_ngrams_count", "len", "collections.defaultdict", "Bleu._update_ngrams_count", "collections.defaultdict.items", "len", "min"], "function", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Bleu._compute_bleu", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Bleu._update_ngrams_count", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.metric.Bleu._update_ngrams_count"], ["", "def", "score_corpus", "(", "preds", ",", "golds", ",", "ngrams", ",", "smooth", "=", "0", ")", ":", "\n", "    ", "assert", "len", "(", "preds", ")", "==", "len", "(", "golds", ")", "\n", "p", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "ngrams", "+", "1", ")", ":", "\n", "        ", "p", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "", "len_pred", "=", "len_gold", "=", "0", "\n", "for", "pred", ",", "gold", "in", "zip", "(", "preds", ",", "golds", ")", ":", "\n", "        ", "len_gold", "+=", "len", "(", "gold", ")", "\n", "count_gold", "=", "defaultdict", "(", "int", ")", "\n", "_update_ngrams_count", "(", "gold", ",", "ngrams", ",", "count_gold", ")", "\n", "\n", "len_pred", "+=", "len", "(", "pred", ")", "\n", "count_pred", "=", "defaultdict", "(", "int", ")", "\n", "_update_ngrams_count", "(", "pred", ",", "ngrams", ",", "count_pred", ")", "\n", "\n", "for", "k", ",", "v", "in", "count_pred", ".", "items", "(", ")", ":", "\n", "            ", "n", "=", "len", "(", "k", ")", "\n", "p", "[", "n", "]", "[", "0", "]", "+=", "min", "(", "v", ",", "count_gold", "[", "k", "]", ")", "\n", "p", "[", "n", "]", "[", "1", "]", "+=", "v", "\n", "\n", "", "", "return", "_compute_bleu", "(", "p", ",", "len_pred", ",", "len_gold", ",", "smooth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Trainer.Trainer.__init__": [[11, 24], ["lib.Evaluator", "print"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "train_data", ",", "eval_data", ",", "metrics", ",", "dicts", ",", "\n", "optim", ",", "opt", ")", ":", "\n", "\n", "        ", "self", ".", "model", "=", "model", "\n", "self", ".", "train_data", "=", "train_data", "\n", "self", ".", "eval_data", "=", "eval_data", "\n", "self", ".", "evaluator", "=", "lib", ".", "Evaluator", "(", "model", ",", "metrics", ",", "dicts", ",", "opt", ")", "\n", "self", ".", "loss_func", "=", "metrics", "[", "\"nmt_loss\"", "]", "\n", "self", ".", "dicts", "=", "dicts", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "opt", "=", "opt", "\n", "\n", "print", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Trainer.Trainer.train": [[25, 57], ["range", "time.time", "print", "print", "print", "Trainer.Trainer.train_epoch", "print", "Trainer.Trainer.evaluator.eval", "math.exp", "print", "print", "print", "Trainer.Trainer.optim.updateLearningRate", "os.path.join", "torch.save", "print", "min", "math.exp", "min"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train_epoch", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.eval.Evaluator.Evaluator.eval", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.updateLearningRate"], ["", "def", "train", "(", "self", ",", "start_epoch", ",", "end_epoch", ",", "start_time", "=", "None", ")", ":", "\n", "        ", "if", "start_time", "is", "None", ":", "\n", "            ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "start_time", "=", "start_time", "\n", "", "for", "epoch", "in", "range", "(", "start_epoch", ",", "end_epoch", "+", "1", ")", ":", "\n", "            ", "print", "(", "''", ")", "\n", "\n", "print", "(", "\"* XENT epoch *\"", ")", "\n", "print", "(", "\"Model optim lr: %g\"", "%", "self", ".", "optim", ".", "lr", ")", "\n", "train_loss", "=", "self", ".", "train_epoch", "(", "epoch", ")", "\n", "print", "(", "'Train perplexity: %.2f'", "%", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ")", "\n", "\n", "valid_loss", ",", "valid_sent_reward", ",", "valid_corpus_reward", "=", "self", ".", "evaluator", ".", "eval", "(", "self", ".", "eval_data", ")", "\n", "valid_ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", "\n", "print", "(", "'Validation perplexity: %.2f'", "%", "valid_ppl", ")", "\n", "print", "(", "'Validation sentence reward: %.2f'", "%", "(", "valid_sent_reward", "*", "100", ")", ")", "\n", "print", "(", "'Validation corpus reward: %.2f'", "%", "\n", "(", "valid_corpus_reward", "*", "100", ")", ")", "\n", "\n", "self", ".", "optim", ".", "updateLearningRate", "(", "valid_loss", ",", "epoch", ")", "\n", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "self", ".", "model", ",", "\n", "'dicts'", ":", "self", ".", "dicts", ",", "\n", "'opt'", ":", "self", ".", "opt", ",", "\n", "'epoch'", ":", "epoch", ",", "\n", "'optim'", ":", "self", ".", "optim", ",", "\n", "}", "\n", "model_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "opt", ".", "save_dir", ",", "\"model_%d.pt\"", "%", "epoch", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "print", "(", "\"Save model as %s\"", "%", "model_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Trainer.Trainer.train_epoch": [[59, 98], ["Trainer.Trainer.model.train", "Trainer.Trainer.train_data.shuffle", "time.time", "range", "len", "Trainer.Trainer.model.zero_grad", "[].data.eq().t", "Trainer.Trainer.model.decoder.attn.applyMask", "Trainer.Trainer.model", "targets.ne().float", "targets.ne().float.data.sum", "Trainer.Trainer.model.backward", "Trainer.Trainer.optim.step", "print", "time.time", "[].data.eq", "targets.ne", "len", "math.exp", "str", "datetime.timedelta", "time.time", "int", "time.time"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.GlobalAttention.GlobalAttention.applyMask", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.backward", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.step"], ["", "", "def", "train_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "self", ".", "train_data", ".", "shuffle", "(", ")", "\n", "\n", "total_loss", ",", "report_loss", "=", "0", ",", "0", "\n", "total_words", ",", "report_words", "=", "0", ",", "0", "\n", "last_time", "=", "time", ".", "time", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "train_data", ")", ")", ":", "\n", "            ", "batch", "=", "self", ".", "train_data", "[", "i", "]", "\n", "targets", "=", "batch", "[", "1", "]", "\n", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "attention_mask", "=", "batch", "[", "0", "]", "[", "0", "]", ".", "data", ".", "eq", "(", "lib", ".", "Constants", ".", "PAD", ")", ".", "t", "(", ")", "\n", "self", ".", "model", ".", "decoder", ".", "attn", ".", "applyMask", "(", "attention_mask", ")", "\n", "outputs", "=", "self", ".", "model", "(", "batch", ",", "eval", "=", "False", ")", "\n", "\n", "weights", "=", "targets", ".", "ne", "(", "lib", ".", "Constants", ".", "PAD", ")", ".", "float", "(", ")", "\n", "num_words", "=", "weights", ".", "data", ".", "sum", "(", ")", "\n", "loss", "=", "self", ".", "model", ".", "backward", "(", "outputs", ",", "targets", ",", "weights", ",", "num_words", ",", "self", ".", "loss_func", ")", "\n", "\n", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "report_loss", "+=", "loss", "\n", "total_loss", "+=", "loss", "\n", "total_words", "+=", "num_words", "\n", "report_words", "+=", "num_words", "\n", "if", "i", "%", "self", ".", "opt", ".", "log_interval", "==", "0", "and", "i", ">", "0", ":", "\n", "                ", "print", "(", "\"\"\"Epoch %3d, %6d/%d batches;\n                      perplexity: %8.2f; %5.0f tokens/s; %s elapsed\"\"\"", "%", "\n", "(", "epoch", ",", "i", ",", "len", "(", "self", ".", "train_data", ")", ",", "\n", "math", ".", "exp", "(", "report_loss", "/", "report_words", ")", ",", "\n", "report_words", "/", "(", "time", ".", "time", "(", ")", "-", "last_time", ")", ",", "\n", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ")", ")", ")", ")", ")", "\n", "\n", "report_loss", "=", "report_words", "=", "0", "\n", "last_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "", "return", "total_loss", "/", "total_words", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.__init__": [[13, 38], ["lib.Evaluator", "print", "print", "print", "print"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "actor", ",", "critic", ",", "train_data", ",", "eval_data", ",", "metrics", ",", "dicts", ",", "optim", ",", "critic_optim", ",", "opt", ")", ":", "\n", "        ", "self", ".", "actor", "=", "actor", "\n", "self", ".", "critic", "=", "critic", "\n", "\n", "self", ".", "train_data", "=", "train_data", "\n", "self", ".", "eval_data", "=", "eval_data", "\n", "self", ".", "evaluator", "=", "lib", ".", "Evaluator", "(", "actor", ",", "metrics", ",", "dicts", ",", "opt", ")", "\n", "\n", "self", ".", "actor_loss_func", "=", "metrics", "[", "\"nmt_loss\"", "]", "\n", "self", ".", "critic_loss_func", "=", "metrics", "[", "\"critic_loss\"", "]", "\n", "self", ".", "sent_reward_func", "=", "metrics", "[", "\"sent_reward\"", "]", "\n", "\n", "self", ".", "dicts", "=", "dicts", "\n", "\n", "self", ".", "optim", "=", "optim", "\n", "self", ".", "critic_optim", "=", "critic_optim", "\n", "\n", "self", ".", "max_length", "=", "opt", ".", "max_predict_length", "\n", "self", ".", "pert_func", "=", "opt", ".", "pert_func", "\n", "self", ".", "opt", "=", "opt", "\n", "\n", "print", "(", "\"\"", ")", "\n", "print", "(", "actor", ")", "\n", "print", "(", "\"\"", ")", "\n", "print", "(", "critic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train": [[39, 102], ["ReinforceTrainer.ReinforceTrainer.optim.set_lr", "range", "time.time", "ReinforceTrainer.ReinforceTrainer.critic_optim.set_lr", "ReinforceTrainer.ReinforceTrainer.critic_optim.set_lr", "print", "print", "print", "ReinforceTrainer.ReinforceTrainer.train_epoch", "print", "print", "ReinforceTrainer.ReinforceTrainer.evaluator.eval", "math.exp", "print", "print", "print", "ReinforceTrainer.ReinforceTrainer.optim.updateLearningRate", "os.path.join", "torch.save", "print", "print", "print", "min", "ReinforceTrainer.ReinforceTrainer.critic_optim.set_lr"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.set_lr", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.set_lr", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.set_lr", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train_epoch", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.eval.Evaluator.Evaluator.eval", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.updateLearningRate", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.set_lr"], ["", "def", "train", "(", "self", ",", "start_epoch", ",", "end_epoch", ",", "pretrain_critic", ",", "start_time", "=", "None", ")", ":", "\n", "        ", "if", "start_time", "is", "None", ":", "\n", "            ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "start_time", "=", "start_time", "\n", "", "self", ".", "optim", ".", "last_loss", "=", "self", ".", "critic_optim", ".", "last_loss", "=", "None", "\n", "self", ".", "optim", ".", "set_lr", "(", "self", ".", "opt", ".", "reinforce_lr", ")", "\n", "\n", "#  Use large learning rate for critic during pre-training.", "\n", "if", "pretrain_critic", ":", "\n", "            ", "self", ".", "critic_optim", ".", "set_lr", "(", "1e-3", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "critic_optim", ".", "set_lr", "(", "self", ".", "opt", ".", "reinforce_lr", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "start_epoch", ",", "end_epoch", "+", "1", ")", ":", "\n", "            ", "print", "(", "\"\"", ")", "\n", "\n", "print", "(", "\"* REINFORCE epoch *\"", ")", "\n", "print", "(", "\"Actor optim lr: %g; Critic optim lr: %g\"", "%", "\n", "(", "self", ".", "optim", ".", "lr", ",", "self", ".", "critic_optim", ".", "lr", ")", ")", "\n", "if", "pretrain_critic", ":", "\n", "                ", "print", "(", "\"Pretrain critic...\"", ")", "\n", "", "no_update", "=", "self", ".", "opt", ".", "no_update", "and", "(", "not", "pretrain_critic", ")", "and", "(", "epoch", "==", "start_epoch", ")", "\n", "\n", "if", "no_update", ":", "print", "(", "\"No update...\"", ")", "\n", "\n", "train_reward", ",", "critic_loss", "=", "self", ".", "train_epoch", "(", "epoch", ",", "pretrain_critic", ",", "no_update", ")", "\n", "print", "(", "\"Train sentence reward: %.2f\"", "%", "(", "train_reward", "*", "100", ")", ")", "\n", "print", "(", "\"Critic loss: %g\"", "%", "critic_loss", ")", "\n", "\n", "valid_loss", ",", "valid_sent_reward", ",", "valid_corpus_reward", "=", "self", ".", "evaluator", ".", "eval", "(", "self", ".", "eval_data", ")", "\n", "valid_ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", "\n", "print", "(", "\"Validation perplexity: %.2f\"", "%", "valid_ppl", ")", "\n", "print", "(", "\"Validation sentence reward: %.2f\"", "%", "(", "valid_sent_reward", "*", "100", ")", ")", "\n", "print", "(", "\"Validation corpus reward: %.2f\"", "%", "\n", "(", "valid_corpus_reward", "*", "100", ")", ")", "\n", "\n", "if", "no_update", ":", "break", "\n", "\n", "self", ".", "optim", ".", "updateLearningRate", "(", "-", "valid_sent_reward", ",", "epoch", ")", "\n", "# Actor and critic use the same lr when jointly trained.", "\n", "# TODO: using small lr for critic is better?", "\n", "if", "not", "pretrain_critic", ":", "\n", "                ", "self", ".", "critic_optim", ".", "set_lr", "(", "self", ".", "optim", ".", "lr", ")", "\n", "\n", "", "checkpoint", "=", "{", "\n", "\"model\"", ":", "self", ".", "actor", ",", "\n", "\"critic\"", ":", "self", ".", "critic", ",", "\n", "\"dicts\"", ":", "self", ".", "dicts", ",", "\n", "\"opt\"", ":", "self", ".", "opt", ",", "\n", "\"epoch\"", ":", "epoch", ",", "\n", "\"optim\"", ":", "self", ".", "optim", ",", "\n", "\"critic_optim\"", ":", "self", ".", "critic_optim", "\n", "}", "\n", "model_name", "=", "os", ".", "path", ".", "join", "(", "self", ".", "opt", ".", "save_dir", ",", "\"model_%d\"", "%", "epoch", ")", "\n", "if", "pretrain_critic", ":", "\n", "                ", "model_name", "+=", "\"_pretrain\"", "\n", "", "else", ":", "\n", "                ", "model_name", "+=", "\"_reinforce\"", "\n", "", "model_name", "+=", "\".pt\"", "\n", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "print", "(", "\"Save model as %s\"", "%", "model_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train_epoch": [[103, 183], ["ReinforceTrainer.ReinforceTrainer.actor.train", "time.time", "range", "len", "targets.size", "ReinforceTrainer.ReinforceTrainer.actor.zero_grad", "ReinforceTrainer.ReinforceTrainer.critic.zero_grad", "sources[].data.eq().t", "ReinforceTrainer.ReinforceTrainer.actor.decoder.attn.applyMask", "ReinforceTrainer.ReinforceTrainer.actor.sample", "ReinforceTrainer.ReinforceTrainer.sent_reward_func", "sum", "torch.autograd.Variable", "torch.autograd.Variable", "samples.cuda.cuda.ne().float", "samples.cuda.ne().float.data.sum", "samples.cuda.cuda.t().tolist", "targets.data.t().tolist", "ReinforceTrainer.ReinforceTrainer.pert_func", "torch.LongTensor().t().contiguous", "torch.FloatTensor().contiguous", "samples.cuda.cuda.cuda", "rewards.cuda.cuda.cuda", "ReinforceTrainer.ReinforceTrainer.critic", "ReinforceTrainer.ReinforceTrainer.critic.backward", "ReinforceTrainer.ReinforceTrainer.critic_optim.step", "torch.autograd.Variable", "ReinforceTrainer.ReinforceTrainer.actor.backward", "ReinforceTrainer.ReinforceTrainer.optim.step", "print", "time.time", "sources[].data.eq", "samples.cuda.cuda.ne", "samples.cuda.cuda.t", "targets.data.t", "torch.LongTensor().t", "torch.FloatTensor", "len", "str", "torch.LongTensor", "samples.cuda.cuda.size", "datetime.timedelta", "time.time", "int", "time.time"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.ReinforceTrainer.ReinforceTrainer.train", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.GlobalAttention.GlobalAttention.applyMask", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.EncoderDecoder.NMTModel.sample", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.backward", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.step", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.model.Generator.MemEfficientGenerator.backward", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.step", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["", "", "def", "train_epoch", "(", "self", ",", "epoch", ",", "pretrain_critic", ",", "no_update", ")", ":", "\n", "        ", "self", ".", "actor", ".", "train", "(", ")", "\n", "\n", "total_reward", ",", "report_reward", "=", "0", ",", "0", "\n", "total_critic_loss", ",", "report_critic_loss", "=", "0", ",", "0", "\n", "total_sents", ",", "report_sents", "=", "0", ",", "0", "\n", "total_words", ",", "report_words", "=", "0", ",", "0", "\n", "last_time", "=", "time", ".", "time", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "train_data", ")", ")", ":", "\n", "            ", "batch", "=", "self", ".", "train_data", "[", "i", "]", "\n", "sources", "=", "batch", "[", "0", "]", "\n", "targets", "=", "batch", "[", "1", "]", "\n", "batch_size", "=", "targets", ".", "size", "(", "1", ")", "\n", "\n", "self", ".", "actor", ".", "zero_grad", "(", ")", "\n", "self", ".", "critic", ".", "zero_grad", "(", ")", "\n", "\n", "# Sample translations", "\n", "attention_mask", "=", "sources", "[", "0", "]", ".", "data", ".", "eq", "(", "lib", ".", "Constants", ".", "PAD", ")", ".", "t", "(", ")", "\n", "self", ".", "actor", ".", "decoder", ".", "attn", ".", "applyMask", "(", "attention_mask", ")", "\n", "samples", ",", "outputs", "=", "self", ".", "actor", ".", "sample", "(", "batch", ",", "self", ".", "max_length", ")", "\n", "\n", "# Calculate rewards", "\n", "rewards", ",", "samples", "=", "self", ".", "sent_reward_func", "(", "samples", ".", "t", "(", ")", ".", "tolist", "(", ")", ",", "targets", ".", "data", ".", "t", "(", ")", ".", "tolist", "(", ")", ")", "\n", "reward", "=", "sum", "(", "rewards", ")", "\n", "\n", "# Perturb rewards (if specified).", "\n", "if", "self", ".", "pert_func", "is", "not", "None", ":", "\n", "                ", "rewards", "=", "self", ".", "pert_func", "(", "rewards", ")", "\n", "\n", "", "samples", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "samples", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ")", "\n", "rewards", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "[", "rewards", "]", "*", "samples", ".", "size", "(", "0", ")", ")", ".", "contiguous", "(", ")", ")", "\n", "if", "self", ".", "opt", ".", "cuda", ":", "\n", "                ", "samples", "=", "samples", ".", "cuda", "(", ")", "\n", "rewards", "=", "rewards", ".", "cuda", "(", ")", "\n", "\n", "# Update critic.", "\n", "", "critic_weights", "=", "samples", ".", "ne", "(", "lib", ".", "Constants", ".", "PAD", ")", ".", "float", "(", ")", "\n", "num_words", "=", "critic_weights", ".", "data", ".", "sum", "(", ")", "\n", "if", "not", "no_update", ":", "\n", "                ", "baselines", "=", "self", ".", "critic", "(", "(", "sources", ",", "samples", ")", ",", "eval", "=", "False", ",", "regression", "=", "True", ")", "\n", "critic_loss", "=", "self", ".", "critic", ".", "backward", "(", "\n", "baselines", ",", "rewards", ",", "critic_weights", ",", "num_words", ",", "self", ".", "critic_loss_func", ",", "regression", "=", "True", ")", "\n", "self", ".", "critic_optim", ".", "step", "(", ")", "\n", "", "else", ":", "\n", "                ", "critic_loss", "=", "0", "\n", "\n", "# Update actor", "\n", "", "if", "not", "pretrain_critic", "and", "not", "no_update", ":", "\n", "# Subtract baseline from reward", "\n", "                ", "norm_rewards", "=", "Variable", "(", "(", "rewards", "-", "baselines", ")", ".", "data", ")", "\n", "actor_weights", "=", "norm_rewards", "*", "critic_weights", "\n", "# TODO: can use PyTorch reinforce() here but that function is a black box.", "\n", "# This is an alternative way where you specify an objective that gives the same gradient", "\n", "# as the policy gradient's objective, which looks much like weighted log-likelihood.", "\n", "actor_loss", "=", "self", ".", "actor", ".", "backward", "(", "outputs", ",", "samples", ",", "actor_weights", ",", "1", ",", "self", ".", "actor_loss_func", ")", "\n", "self", ".", "optim", ".", "step", "(", ")", "\n", "\n", "# Gather stats", "\n", "", "total_reward", "+=", "reward", "\n", "report_reward", "+=", "reward", "\n", "total_sents", "+=", "batch_size", "\n", "report_sents", "+=", "batch_size", "\n", "total_critic_loss", "+=", "critic_loss", "\n", "report_critic_loss", "+=", "critic_loss", "\n", "total_words", "+=", "num_words", "\n", "report_words", "+=", "num_words", "\n", "if", "i", "%", "self", ".", "opt", ".", "log_interval", "==", "0", "and", "i", ">", "0", ":", "\n", "                ", "print", "(", "\"\"\"Epoch %3d, %6d/%d batches;\n                      actor reward: %.4f; critic loss: %f; %5.0f tokens/s; %s elapsed\"\"\"", "%", "\n", "(", "epoch", ",", "i", ",", "len", "(", "self", ".", "train_data", ")", ",", "\n", "(", "report_reward", "/", "report_sents", ")", "*", "100", ",", "\n", "report_critic_loss", "/", "report_words", ",", "\n", "report_words", "/", "(", "time", ".", "time", "(", ")", "-", "last_time", ")", ",", "\n", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ")", ")", ")", ")", ")", "\n", "\n", "report_reward", "=", "report_sents", "=", "report_critic_loss", "=", "report_words", "=", "0", "\n", "last_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "", "return", "total_reward", "/", "total_sents", ",", "total_critic_loss", "/", "total_words", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim._makeOptimizer": [[6, 17], ["torch.SGD", "torch.Adagrad", "torch.Adadelta", "torch.Adam", "RuntimeError"], "methods", ["None"], ["    ", "def", "_makeOptimizer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "method", "==", "'sgd'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adagrad'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adagrad", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adadelta'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adadelta", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "elif", "self", ".", "method", "==", "'adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "params", ",", "lr", "=", "self", ".", "lr", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Invalid optim method: \"", "+", "self", ".", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.__init__": [[18, 28], ["list", "Optim.Optim._makeOptimizer"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim._makeOptimizer"], ["", "", "def", "__init__", "(", "self", ",", "params", ",", "method", ",", "lr", ",", "max_grad_norm", ",", "lr_decay", "=", "1", ",", "start_decay_at", "=", "None", ")", ":", "\n", "        ", "self", ".", "params", "=", "list", "(", "params", ")", "# careful: params may be a generator", "\n", "self", ".", "last_loss", "=", "None", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "method", "=", "method", "\n", "self", ".", "lr_decay", "=", "lr_decay", "\n", "self", ".", "start_decay_at", "=", "start_decay_at", "\n", "\n", "self", ".", "_makeOptimizer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.step": [[29, 44], ["math.sqrt", "Optim.Optim.optimizer.step", "math.pow", "param.grad.data.norm", "param.grad.data.mul_"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "# Compute gradients norm.", "\n", "        ", "grad_norm", "=", "0", "\n", "for", "param", "in", "self", ".", "params", ":", "\n", "            ", "grad_norm", "+=", "math", ".", "pow", "(", "param", ".", "grad", ".", "data", ".", "norm", "(", ")", ",", "2", ")", "\n", "\n", "", "grad_norm", "=", "math", ".", "sqrt", "(", "grad_norm", ")", "\n", "shrinkage", "=", "self", ".", "max_grad_norm", "/", "grad_norm", "\n", "\n", "for", "param", "in", "self", ".", "params", ":", "\n", "            ", "if", "shrinkage", "<", "1", ":", "\n", "                ", "param", ".", "grad", ".", "data", ".", "mul_", "(", "shrinkage", ")", "\n", "\n", "", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "return", "grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.set_lr": [[45, 48], ["None"], "methods", ["None"], ["", "def", "set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "self", ".", "lr", "=", "lr", "\n", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.updateLearningRate": [[49, 54], ["Optim.Optim.set_lr"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.train.Optim.Optim.set_lr"], ["", "def", "updateLearningRate", "(", "self", ",", "loss", ",", "epoch", ")", ":", "\n", "        ", "if", "self", ".", "start_decay_at", "is", "not", "None", "and", "epoch", ">=", "self", ".", "start_decay_at", ":", "\n", "            ", "if", "self", ".", "last_loss", "is", "not", "None", "and", "loss", ">", "self", ".", "last_loss", ":", "\n", "                ", "self", ".", "set_lr", "(", "self", ".", "lr", "*", "self", ".", "lr_decay", ")", "\n", "", "", "self", ".", "last_loss", "=", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.__init__": [[5, 18], ["type", "Dict.Dict.loadFile", "Dict.Dict.addSpecials"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.loadFile", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.addSpecials"], ["    ", "def", "__init__", "(", "self", ",", "data", "=", "None", ")", ":", "\n", "        ", "self", ".", "idxToLabel", "=", "{", "}", "\n", "self", ".", "labelToIdx", "=", "{", "}", "\n", "self", ".", "frequencies", "=", "{", "}", "\n", "\n", "# Special entries will not be pruned.", "\n", "self", ".", "special", "=", "[", "]", "\n", "\n", "if", "data", "is", "not", "None", ":", "\n", "            ", "if", "type", "(", "data", ")", "==", "str", ":", "\n", "                ", "self", ".", "loadFile", "(", "data", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "addSpecials", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size": [[19, 21], ["len"], "methods", ["None"], ["", "", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idxToLabel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.loadFile": [[23, 29], ["open", "line.split", "int", "Dict.Dict.add"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.add"], ["", "def", "loadFile", "(", "self", ",", "filename", ")", ":", "\n", "        ", "for", "line", "in", "open", "(", "filename", ")", ":", "\n", "            ", "fields", "=", "line", ".", "split", "(", ")", "\n", "label", "=", "fields", "[", "0", "]", "\n", "idx", "=", "int", "(", "fields", "[", "1", "]", ")", "\n", "self", ".", "add", "(", "label", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.writeFile": [[31, 38], ["file.close", "open", "range", "Dict.Dict.size", "file.write"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["", "", "def", "writeFile", "(", "self", ",", "filename", ")", ":", "\n", "        ", "with", "open", "(", "filename", ",", "'w'", ")", "as", "file", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "size", "(", ")", ")", ":", "\n", "                ", "label", "=", "self", ".", "idxToLabel", "[", "i", "]", "\n", "file", ".", "write", "(", "'%s %d\\n'", "%", "(", "label", ",", "i", ")", ")", "\n", "\n", "", "", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.lookup": [[39, 44], ["None"], "methods", ["None"], ["", "def", "lookup", "(", "self", ",", "key", ",", "default", "=", "None", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "labelToIdx", "[", "key", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.getLabel": [[45, 50], ["None"], "methods", ["None"], ["", "", "def", "getLabel", "(", "self", ",", "idx", ",", "default", "=", "None", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "idxToLabel", "[", "idx", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.addSpecial": [[52, 55], ["Dict.Dict.add"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.add"], ["", "", "def", "addSpecial", "(", "self", ",", "label", ",", "idx", "=", "None", ")", ":", "\n", "        ", "idx", "=", "self", ".", "add", "(", "label", ",", "idx", ")", "\n", "self", ".", "special", "+=", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.addSpecials": [[57, 60], ["Dict.Dict.addSpecial"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.addSpecial"], ["", "def", "addSpecials", "(", "self", ",", "labels", ")", ":", "\n", "        ", "for", "label", "in", "labels", ":", "\n", "            ", "self", ".", "addSpecial", "(", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.add": [[62, 80], ["len"], "methods", ["None"], ["", "", "def", "add", "(", "self", ",", "label", ",", "idx", "=", "None", ")", ":", "\n", "        ", "if", "idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "idxToLabel", "[", "idx", "]", "=", "label", "\n", "self", ".", "labelToIdx", "[", "label", "]", "=", "idx", "\n", "", "else", ":", "\n", "            ", "if", "label", "in", "self", ".", "labelToIdx", ":", "\n", "                ", "idx", "=", "self", ".", "labelToIdx", "[", "label", "]", "\n", "", "else", ":", "\n", "                ", "idx", "=", "len", "(", "self", ".", "idxToLabel", ")", "\n", "self", ".", "idxToLabel", "[", "idx", "]", "=", "label", "\n", "self", ".", "labelToIdx", "[", "label", "]", "=", "idx", "\n", "\n", "", "", "if", "idx", "not", "in", "self", ".", "frequencies", ":", "\n", "            ", "self", ".", "frequencies", "[", "idx", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "frequencies", "[", "idx", "]", "+=", "1", "\n", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.prune": [[82, 101], ["torch.Tensor", "torch.sort", "Dict.Dict", "Dict.Dict.size", "Dict.addSpecial", "Dict.add", "range", "len"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.addSpecial", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.add"], ["", "def", "prune", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "size", ">=", "self", ".", "size", "(", ")", ":", "\n", "            ", "return", "self", "\n", "\n", "# Only keep the `size` most frequent entries.", "\n", "", "freq", "=", "torch", ".", "Tensor", "(", "\n", "[", "self", ".", "frequencies", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "frequencies", ")", ")", "]", ")", "\n", "_", ",", "idx", "=", "torch", ".", "sort", "(", "freq", ",", "0", ",", "True", ")", "\n", "\n", "newDict", "=", "Dict", "(", ")", "\n", "\n", "# Add special entries in all cases.", "\n", "for", "i", "in", "self", ".", "special", ":", "\n", "            ", "newDict", ".", "addSpecial", "(", "self", ".", "idxToLabel", "[", "i", "]", ")", "\n", "\n", "", "for", "i", "in", "idx", "[", ":", "size", "]", ":", "\n", "            ", "newDict", ".", "add", "(", "self", ".", "idxToLabel", "[", "i", "]", ")", "\n", "\n", "", "return", "newDict", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.convertToIdx": [[104, 117], ["Dict.Dict.lookup", "torch.LongTensor", "Dict.Dict.lookup", "Dict.Dict.lookup", "label.lower", "Dict.Dict.lookup"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.lookup", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.lookup", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.lookup", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.lookup"], ["", "def", "convertToIdx", "(", "self", ",", "labels", ",", "unkWord", ",", "bosWord", "=", "None", ",", "eosWord", "=", "None", ")", ":", "\n", "        ", "vec", "=", "[", "]", "\n", "\n", "if", "bosWord", "is", "not", "None", ":", "\n", "            ", "vec", "+=", "[", "self", ".", "lookup", "(", "bosWord", ")", "]", "\n", "\n", "", "unk", "=", "self", ".", "lookup", "(", "unkWord", ")", "\n", "vec", "+=", "[", "self", ".", "lookup", "(", "label", ".", "lower", "(", ")", ",", "default", "=", "unk", ")", "for", "label", "in", "labels", "]", "\n", "\n", "if", "eosWord", "is", "not", "None", ":", "\n", "            ", "vec", "+=", "[", "self", ".", "lookup", "(", "eosWord", ")", "]", "\n", "\n", "", "return", "torch", ".", "LongTensor", "(", "vec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.convertToLabels": [[119, 128], ["Dict.Dict.getLabel"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.getLabel"], ["", "def", "convertToLabels", "(", "self", ",", "idx", ",", "stop", ")", ":", "\n", "        ", "labels", "=", "[", "]", "\n", "\n", "for", "i", "in", "idx", ":", "\n", "            ", "labels", "+=", "[", "self", ".", "getLabel", "(", "i", ")", "]", "\n", "if", "i", "==", "stop", ":", "\n", "                ", "break", "\n", "\n", "", "", "return", "labels", "\n", "", "", ""]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.__init__": [[13, 23], ["math.ceil", "len", "len", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "batchSize", ",", "cuda", ",", "eval", "=", "False", ")", ":", "\n", "        ", "self", ".", "src", "=", "data", "[", "\"src\"", "]", "\n", "self", ".", "tgt", "=", "data", "[", "\"tgt\"", "]", "\n", "self", ".", "pos", "=", "data", "[", "\"pos\"", "]", "\n", "assert", "(", "len", "(", "self", ".", "src", ")", "==", "len", "(", "self", ".", "tgt", ")", ")", "\n", "self", ".", "cuda", "=", "cuda", "\n", "\n", "self", ".", "batchSize", "=", "batchSize", "\n", "self", ".", "numBatches", "=", "math", ".", "ceil", "(", "len", "(", "self", ".", "src", ")", "/", "batchSize", ")", "\n", "self", ".", "eval", "=", "eval", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset._batchify": [[24, 37], ["max", "data[].new().fill_", "range", "x.size", "len", "data[].size", "out[].narrow().copy_", "data[].new", "len", "out[].narrow"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dict.Dict.size"], ["", "def", "_batchify", "(", "self", ",", "data", ",", "align_right", "=", "False", ",", "include_lengths", "=", "False", ")", ":", "\n", "        ", "lengths", "=", "[", "x", ".", "size", "(", "0", ")", "for", "x", "in", "data", "]", "\n", "max_length", "=", "max", "(", "lengths", ")", "\n", "out", "=", "data", "[", "0", "]", ".", "new", "(", "len", "(", "data", ")", ",", "max_length", ")", ".", "fill_", "(", "lib", ".", "Constants", ".", "PAD", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "            ", "data_length", "=", "data", "[", "i", "]", ".", "size", "(", "0", ")", "\n", "offset", "=", "max_length", "-", "data_length", "if", "align_right", "else", "0", "\n", "out", "[", "i", "]", ".", "narrow", "(", "0", ",", "offset", ",", "data_length", ")", ".", "copy_", "(", "data", "[", "i", "]", ")", "\n", "\n", "", "if", "include_lengths", ":", "\n", "            ", "return", "out", ",", "lengths", "\n", "", "else", ":", "\n", "            ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.__getitem__": [[38, 59], ["Dataset.Dataset._batchify", "Dataset.Dataset._batchify", "range", "zip", "zip", "zip", "len", "torch.stack().t().contiguous", "torch.autograd.Variable", "Dataset.Dataset.__getitem__.wrap"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset._batchify", "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset._batchify"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "assert", "index", "<", "self", ".", "numBatches", ",", "\"%d > %d\"", "%", "(", "index", ",", "self", ".", "numBatches", ")", "\n", "srcBatch", ",", "lengths", "=", "self", ".", "_batchify", "(", "self", ".", "src", "[", "index", "*", "self", ".", "batchSize", ":", "(", "index", "+", "1", ")", "*", "self", ".", "batchSize", "]", ",", "\n", "include_lengths", "=", "True", ")", "\n", "\n", "tgtBatch", "=", "self", ".", "_batchify", "(", "self", ".", "tgt", "[", "index", "*", "self", ".", "batchSize", ":", "(", "index", "+", "1", ")", "*", "self", ".", "batchSize", "]", ")", "\n", "\n", "# within batch sort by decreasing length.", "\n", "indices", "=", "range", "(", "len", "(", "srcBatch", ")", ")", "\n", "batch", "=", "zip", "(", "indices", ",", "srcBatch", ",", "tgtBatch", ")", "\n", "batch", ",", "lengths", "=", "zip", "(", "*", "sorted", "(", "zip", "(", "batch", ",", "lengths", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", ")", "\n", "indices", ",", "srcBatch", ",", "tgtBatch", "=", "zip", "(", "*", "batch", ")", "\n", "\n", "def", "wrap", "(", "b", ")", ":", "\n", "            ", "b", "=", "torch", ".", "stack", "(", "b", ",", "0", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "if", "self", ".", "cuda", ":", "\n", "                ", "b", "=", "b", ".", "cuda", "(", ")", "\n", "", "b", "=", "Variable", "(", "b", ",", "volatile", "=", "self", ".", "eval", ")", "\n", "return", "b", "\n", "\n", "", "return", "(", "wrap", "(", "srcBatch", ")", ",", "lengths", ")", ",", "wrap", "(", "tgtBatch", ")", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.__len__": [[60, 62], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "numBatches", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.shuffle": [[63, 67], ["list", "random.shuffle", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.shuffle"], ["", "def", "shuffle", "(", "self", ")", ":", "\n", "        ", "data", "=", "list", "(", "zip", "(", "self", ".", "src", ",", "self", ".", "tgt", ",", "self", ".", "pos", ")", ")", "\n", "random", ".", "shuffle", "(", "data", ")", "\n", "self", ".", "src", ",", "self", ".", "tgt", ",", "self", ".", "pos", "=", "zip", "(", "*", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.khanhptnk_bandit-nmt.data.Dataset.Dataset.restore_pos": [[68, 73], ["zip", "len"], "methods", ["None"], ["", "def", "restore_pos", "(", "self", ",", "sents", ")", ":", "\n", "        ", "sorted_sents", "=", "[", "None", "]", "*", "len", "(", "self", ".", "pos", ")", "\n", "for", "sent", ",", "idx", "in", "zip", "(", "sents", ",", "self", ".", "pos", ")", ":", "\n", "          ", "sorted_sents", "[", "idx", "]", "=", "sent", "\n", "", "return", "sorted_sents", "\n", "", "", ""]]}