{"home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.main.my_main": [[26, 36], ["main.config_copy", "numpy.random.seed", "torch.manual_seed", "run.run"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.main.config_copy", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.seed", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.run"], ["@", "ex", ".", "main", "\n", "def", "my_main", "(", "_run", ",", "_config", ",", "_log", ")", ":", "\n", "# Setting the random seed throughout the modules", "\n", "    ", "config", "=", "config_copy", "(", "_config", ")", "\n", "np", ".", "random", ".", "seed", "(", "config", "[", "\"seed\"", "]", ")", "\n", "th", ".", "manual_seed", "(", "config", "[", "\"seed\"", "]", ")", "\n", "config", "[", "'env_args'", "]", "[", "'seed'", "]", "=", "config", "[", "\"seed\"", "]", "\n", "\n", "# run the framework", "\n", "run", "(", "_run", ",", "config", ",", "_log", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.main._get_config": [[38, 53], ["enumerate", "open", "_v.split", "_v.split", "os.path.join", "yaml.load", "os.path.dirname"], "function", ["None"], ["", "def", "_get_config", "(", "params", ",", "arg_name", ",", "subfolder", ")", ":", "\n", "    ", "config_name", "=", "None", "\n", "for", "_i", ",", "_v", "in", "enumerate", "(", "params", ")", ":", "\n", "        ", "if", "_v", ".", "split", "(", "\"=\"", ")", "[", "0", "]", "==", "arg_name", ":", "\n", "            ", "config_name", "=", "_v", ".", "split", "(", "\"=\"", ")", "[", "1", "]", "\n", "del", "params", "[", "_i", "]", "\n", "break", "\n", "\n", "", "", "if", "config_name", "is", "not", "None", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "\"config\"", ",", "subfolder", ",", "\"{}.yaml\"", ".", "format", "(", "config_name", ")", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "try", ":", "\n", "                ", "config_dict", "=", "yaml", ".", "load", "(", "f", ")", "\n", "", "except", "yaml", ".", "YAMLError", "as", "exc", ":", "\n", "                ", "assert", "False", ",", "\"{}.yaml error: {}\"", ".", "format", "(", "config_name", ",", "exc", ")", "\n", "", "", "return", "config_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.main.recursive_dict_update": [[55, 62], ["u.items", "isinstance", "main.recursive_dict_update", "d.get"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.main.recursive_dict_update"], ["", "", "def", "recursive_dict_update", "(", "d", ",", "u", ")", ":", "\n", "    ", "for", "k", ",", "v", "in", "u", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "v", ",", "collections", ".", "Mapping", ")", ":", "\n", "            ", "d", "[", "k", "]", "=", "recursive_dict_update", "(", "d", ".", "get", "(", "k", ",", "{", "}", ")", ",", "v", ")", "\n", "", "else", ":", "\n", "            ", "d", "[", "k", "]", "=", "v", "\n", "", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.main.config_copy": [[64, 71], ["isinstance", "isinstance", "main.config_copy", "copy.deepcopy", "config.items", "main.config_copy"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.main.config_copy", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.main.config_copy"], ["", "def", "config_copy", "(", "config", ")", ":", "\n", "    ", "if", "isinstance", "(", "config", ",", "dict", ")", ":", "\n", "        ", "return", "{", "k", ":", "config_copy", "(", "v", ")", "for", "k", ",", "v", "in", "config", ".", "items", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "config", ",", "list", ")", ":", "\n", "        ", "return", "[", "config_copy", "(", "v", ")", "for", "v", "in", "config", "]", "\n", "", "else", ":", "\n", "        ", "return", "deepcopy", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.heurist_run.heuristic_run": [[8, 37], ["pprint.pprint", "smac.env.StarCraft2Env", "print", "print", "tqdm.trange", "smac.env.StarCraft2Env.close", "smac.env.StarCraft2Env.reset", "t.set_postfix", "range", "smac.env.StarCraft2Env.step", "float", "float", "smac.env.StarCraft2Env.get_avail_agent_actions", "numpy.random.choice", "actions.append", "numpy.nonzero"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.close", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.reset", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_avail_agent_actions"], ["def", "heuristic_run", "(", "n_episodes", ",", "map_name", ",", "env_args", ")", ":", "\n", "    ", "env_args", "[", "'map_name'", "]", "=", "map_name", "\n", "pprint", ".", "pprint", "(", "env_args", ")", "\n", "env", "=", "StarCraft2Env", "(", "**", "env_args", ")", "\n", "wins", "=", "0", "\n", "with", "trange", "(", "n_episodes", ")", "as", "t", ":", "\n", "        ", "for", "i", "in", "t", ":", "\n", "            ", "env", ".", "reset", "(", ")", "\n", "terminated", "=", "False", "\n", "episode_reward", "=", "0", "\n", "\n", "while", "not", "terminated", ":", "\n", "                ", "actions", "=", "[", "]", "\n", "for", "agent_id", "in", "range", "(", "env", ".", "n_agents", ")", ":", "\n", "                    ", "avail_actions", "=", "env", ".", "get_avail_agent_actions", "(", "agent_id", ")", "\n", "avail_actions_ind", "=", "np", ".", "nonzero", "(", "avail_actions", ")", "[", "0", "]", "\n", "action", "=", "np", ".", "random", ".", "choice", "(", "avail_actions_ind", ")", "\n", "# _, haction_num = env.get_agent_action_heuristic(agent_id, action)", "\n", "actions", ".", "append", "(", "action", ")", "\n", "\n", "", "reward", ",", "terminated", ",", "info", "=", "env", ".", "step", "(", "actions", ")", "\n", "", "try", ":", "\n", "                ", "wins", "+=", "info", "[", "'battle_won'", "]", "\n", "", "except", ":", "\n", "                ", "continue", "\n", "", "t", ".", "set_postfix", "(", "win_rate", "=", "wins", "/", "(", "i", "+", "1.", ")", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "", "print", "(", "\"\\n\"", ")", "\n", "print", "(", "\"In {} episodes games, heuristic ai wins {}; win rate is {}\"", ".", "format", "(", "n_episodes", ",", "wins", ",", "float", "(", "wins", ")", "/", "float", "(", "n_episodes", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.run.run": [[19, 64], ["run.args_sanity_check", "types.SimpleNamespace", "utils.logging.Logger", "_log.info", "pprint.pformat", "_log.info", "utils.logging.Logger.setup_sacred", "run.run_sequential", "print", "print", "threading.enumerate", "print", "os._exit", "datetime.datetime.now().strftime", "os.path.join", "os.path.join().format", "utils.logging.Logger.setup_tb", "os.path.dirname", "print", "t.join", "print", "datetime.datetime.now", "os.path.dirname", "os.path.join", "os.path.abspath"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.run.args_sanity_check", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.setup_sacred", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.run.run_sequential", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.setup_tb"], ["def", "run", "(", "_run", ",", "_config", ",", "_log", ")", ":", "\n", "\n", "# check args sanity", "\n", "    ", "_config", "=", "args_sanity_check", "(", "_config", ",", "_log", ")", "\n", "\n", "args", "=", "SN", "(", "**", "_config", ")", "\n", "args", ".", "device", "=", "\"cuda\"", "if", "args", ".", "use_cuda", "else", "\"cpu\"", "\n", "\n", "# setup loggers", "\n", "logger", "=", "Logger", "(", "_log", ")", "\n", "\n", "_log", ".", "info", "(", "\"Experiment Parameters:\"", ")", "\n", "experiment_params", "=", "pprint", ".", "pformat", "(", "_config", ",", "\n", "indent", "=", "4", ",", "\n", "width", "=", "1", ")", "\n", "_log", ".", "info", "(", "\"\\n\\n\"", "+", "experiment_params", "+", "\"\\n\"", ")", "\n", "\n", "# configure tensorboard logger", "\n", "unique_token", "=", "\"{}__{}\"", ".", "format", "(", "args", ".", "name", ",", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d_%H-%M-%S\"", ")", ")", "\n", "args", ".", "unique_token", "=", "unique_token", "\n", "if", "args", ".", "use_tensorboard", ":", "\n", "        ", "tb_logs_direc", "=", "os", ".", "path", ".", "join", "(", "dirname", "(", "dirname", "(", "abspath", "(", "__file__", ")", ")", ")", ",", "\"results\"", ",", "\"tb_logs\"", ")", "\n", "tb_exp_direc", "=", "os", ".", "path", ".", "join", "(", "tb_logs_direc", ",", "\"{}\"", ")", ".", "format", "(", "unique_token", ")", "\n", "logger", ".", "setup_tb", "(", "tb_exp_direc", ")", "\n", "\n", "# sacred is on by default", "\n", "", "logger", ".", "setup_sacred", "(", "_run", ")", "\n", "\n", "# Run and train", "\n", "run_sequential", "(", "args", "=", "args", ",", "logger", "=", "logger", ")", "\n", "\n", "# Clean up after finishing", "\n", "print", "(", "\"Exiting Main\"", ")", "\n", "\n", "print", "(", "\"Stopping all threads\"", ")", "\n", "for", "t", "in", "threading", ".", "enumerate", "(", ")", ":", "\n", "        ", "if", "t", ".", "name", "!=", "\"MainThread\"", ":", "\n", "            ", "print", "(", "\"Thread {} is alive! Is daemon: {}\"", ".", "format", "(", "t", ".", "name", ",", "t", ".", "daemon", ")", ")", "\n", "t", ".", "join", "(", "timeout", "=", "1", ")", "\n", "print", "(", "\"Thread joined\"", ")", "\n", "\n", "", "", "print", "(", "\"Exiting script\"", ")", "\n", "\n", "# Making sure framework really exits", "\n", "os", ".", "_exit", "(", "os", ".", "EX_OK", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.run.evaluate_sequential": [[66, 75], ["range", "runner.close_env", "runner.run", "runner.save_replay"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.close_env", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.run", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.save_replay"], ["", "def", "evaluate_sequential", "(", "args", ",", "runner", ")", ":", "\n", "\n", "    ", "for", "_", "in", "range", "(", "args", ".", "test_nepisode", ")", ":", "\n", "        ", "runner", ".", "run", "(", "test_mode", "=", "True", ")", "\n", "\n", "", "if", "args", ".", "save_replay", ":", "\n", "        ", "runner", ".", "save_replay", "(", ")", "\n", "\n", "", "runner", ".", "close_env", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.run.run_sequential": [[76, 229], ["runner.get_env_info", "components.episode_buffer.ReplayBuffer", "runner.setup", "time.time", "logger.console_logger.info", "runner.close_env", "logger.console_logger.info", "learner.cuda", "os.listdir", "os.path.join", "logger.console_logger.info", "learner.load_models", "runner.run", "components.episode_buffer.ReplayBuffer.insert_episode_batch", "components.episode_buffer.ReplayBuffer.can_sample", "max", "os.path.isdir", "logger.console_logger.info", "os.path.join", "max", "min", "str", "run.evaluate_sequential", "components.episode_buffer.ReplayBuffer.sample", "buffer.sample.max_t_filled", "learner.train", "logger.console_logger.info", "logger.console_logger.info", "time.time", "range", "os.path.join", "os.makedirs", "logger.console_logger.info", "learner.save_models", "os.path.join", "os.makedirs", "logger.console_logger.info", "learner.save_models", "logger.log_stat", "logger.print_recent_stats", "components.transforms.OneHot", "os.path.isdir", "name.isdigit", "timesteps.append", "buffer.sample.to", "runner.run", "str", "str", "int", "utils.timehelper.time_left", "utils.timehelper.time_str", "abs", "time.time"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.get_env_info", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.setup", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.close_env", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_models", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.run", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.insert_episode_batch", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.can_sample", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.run.evaluate_sequential", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.max_t_filled", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner.train", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.save_models", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.save_models", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.print_recent_stats", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.to", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.run", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.timehelper.time_left", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.timehelper.time_str"], ["", "def", "run_sequential", "(", "args", ",", "logger", ")", ":", "\n", "\n", "# Init runner so we can get env info", "\n", "    ", "runner", "=", "r_REGISTRY", "[", "args", ".", "runner", "]", "(", "args", "=", "args", ",", "logger", "=", "logger", ")", "\n", "\n", "# Set up schemes and groups here", "\n", "env_info", "=", "runner", ".", "get_env_info", "(", ")", "\n", "args", ".", "n_agents", "=", "env_info", "[", "\"n_agents\"", "]", "\n", "args", ".", "n_actions", "=", "env_info", "[", "\"n_actions\"", "]", "\n", "args", ".", "state_shape", "=", "env_info", "[", "\"state_shape\"", "]", "\n", "\n", "# Default/Base scheme", "\n", "scheme", "=", "{", "\n", "\"state\"", ":", "{", "\"vshape\"", ":", "env_info", "[", "\"state_shape\"", "]", "}", ",", "\n", "\"obs\"", ":", "{", "\"vshape\"", ":", "env_info", "[", "\"obs_shape\"", "]", ",", "\"group\"", ":", "\"agents\"", "}", ",", "\n", "\"actions\"", ":", "{", "\"vshape\"", ":", "(", "1", ",", ")", ",", "\"group\"", ":", "\"agents\"", ",", "\"dtype\"", ":", "th", ".", "long", "}", ",", "\n", "\"avail_actions\"", ":", "{", "\"vshape\"", ":", "(", "env_info", "[", "\"n_actions\"", "]", ",", ")", ",", "\"group\"", ":", "\"agents\"", ",", "\"dtype\"", ":", "th", ".", "int", "}", ",", "\n", "\"reward\"", ":", "{", "\"vshape\"", ":", "(", "1", ",", ")", "}", ",", "\n", "\"terminated\"", ":", "{", "\"vshape\"", ":", "(", "1", ",", ")", ",", "\"dtype\"", ":", "th", ".", "uint8", "}", ",", "\n", "}", "\n", "groups", "=", "{", "\n", "\"agents\"", ":", "args", ".", "n_agents", "\n", "}", "\n", "preprocess", "=", "{", "\n", "\"actions\"", ":", "(", "\"actions_onehot\"", ",", "[", "OneHot", "(", "out_dim", "=", "args", ".", "n_actions", ")", "]", ")", "\n", "}", "\n", "\n", "buffer", "=", "ReplayBuffer", "(", "scheme", ",", "groups", ",", "args", ".", "buffer_size", ",", "env_info", "[", "\"episode_limit\"", "]", "+", "1", ",", "\n", "preprocess", "=", "preprocess", ",", "\n", "device", "=", "\"cpu\"", "if", "args", ".", "buffer_cpu_only", "else", "args", ".", "device", ")", "\n", "\n", "# Setup multiagent controller here", "\n", "mac", "=", "mac_REGISTRY", "[", "args", ".", "mac", "]", "(", "buffer", ".", "scheme", ",", "groups", ",", "args", ")", "\n", "\n", "# Give runner the scheme", "\n", "runner", ".", "setup", "(", "scheme", "=", "scheme", ",", "groups", "=", "groups", ",", "preprocess", "=", "preprocess", ",", "mac", "=", "mac", ")", "\n", "\n", "# Learner", "\n", "learner", "=", "le_REGISTRY", "[", "args", ".", "learner", "]", "(", "mac", ",", "buffer", ".", "scheme", ",", "logger", ",", "args", ")", "\n", "\n", "if", "args", ".", "use_cuda", ":", "\n", "        ", "learner", ".", "cuda", "(", ")", "\n", "\n", "", "if", "args", ".", "checkpoint_path", "!=", "\"\"", ":", "\n", "\n", "        ", "timesteps", "=", "[", "]", "\n", "timestep_to_load", "=", "0", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "checkpoint_path", ")", ":", "\n", "            ", "logger", ".", "console_logger", ".", "info", "(", "\"Checkpoint directiory {} doesn't exist\"", ".", "format", "(", "args", ".", "checkpoint_path", ")", ")", "\n", "return", "\n", "\n", "# Go through all files in args.checkpoint_path", "\n", "", "for", "name", "in", "os", ".", "listdir", "(", "args", ".", "checkpoint_path", ")", ":", "\n", "            ", "full_name", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_path", ",", "name", ")", "\n", "# Check if they are dirs the names of which are numbers", "\n", "if", "os", ".", "path", ".", "isdir", "(", "full_name", ")", "and", "name", ".", "isdigit", "(", ")", ":", "\n", "                ", "timesteps", ".", "append", "(", "int", "(", "name", ")", ")", "\n", "\n", "", "", "if", "args", ".", "load_step", "==", "0", ":", "\n", "# choose the max timestep", "\n", "            ", "timestep_to_load", "=", "max", "(", "timesteps", ")", "\n", "", "else", ":", "\n", "# choose the timestep closest to load_step", "\n", "            ", "timestep_to_load", "=", "min", "(", "timesteps", ",", "key", "=", "lambda", "x", ":", "abs", "(", "x", "-", "args", ".", "load_step", ")", ")", "\n", "\n", "", "model_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_path", ",", "str", "(", "timestep_to_load", ")", ")", "\n", "\n", "logger", ".", "console_logger", ".", "info", "(", "\"Loading model from {}\"", ".", "format", "(", "model_path", ")", ")", "\n", "learner", ".", "load_models", "(", "model_path", ")", "\n", "runner", ".", "t_env", "=", "timestep_to_load", "\n", "\n", "if", "args", ".", "evaluate", "or", "args", ".", "save_replay", ":", "\n", "            ", "evaluate_sequential", "(", "args", ",", "runner", ")", "\n", "return", "\n", "\n", "# start training", "\n", "", "", "episode", "=", "0", "\n", "last_test_T", "=", "-", "args", ".", "test_interval", "-", "1", "\n", "last_log_T", "=", "0", "\n", "model_save_time", "=", "0", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "last_time", "=", "start_time", "\n", "\n", "logger", ".", "console_logger", ".", "info", "(", "\"Beginning training for {} timesteps\"", ".", "format", "(", "args", ".", "t_max", ")", ")", "\n", "\n", "while", "runner", ".", "t_env", "<=", "args", ".", "t_max", ":", "\n", "\n", "# Run for a whole episode at a time", "\n", "        ", "episode_batch", "=", "runner", ".", "run", "(", "test_mode", "=", "False", ")", "\n", "buffer", ".", "insert_episode_batch", "(", "episode_batch", ")", "\n", "\n", "if", "buffer", ".", "can_sample", "(", "args", ".", "batch_size", ")", ":", "\n", "            ", "episode_sample", "=", "buffer", ".", "sample", "(", "args", ".", "batch_size", ")", "\n", "\n", "# Truncate batch to only filled timesteps", "\n", "max_ep_t", "=", "episode_sample", ".", "max_t_filled", "(", ")", "\n", "episode_sample", "=", "episode_sample", "[", ":", ",", ":", "max_ep_t", "]", "\n", "\n", "if", "episode_sample", ".", "device", "!=", "args", ".", "device", ":", "\n", "                ", "episode_sample", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "", "learner", ".", "train", "(", "episode_sample", ",", "runner", ".", "t_env", ",", "episode", ")", "\n", "\n", "# Execute test runs once in a while", "\n", "", "n_test_runs", "=", "max", "(", "1", ",", "args", ".", "test_nepisode", "//", "runner", ".", "batch_size", ")", "\n", "if", "(", "runner", ".", "t_env", "-", "last_test_T", ")", "/", "args", ".", "test_interval", ">=", "1.0", ":", "\n", "\n", "            ", "logger", ".", "console_logger", ".", "info", "(", "\"t_env: {} / {}\"", ".", "format", "(", "runner", ".", "t_env", ",", "args", ".", "t_max", ")", ")", "\n", "logger", ".", "console_logger", ".", "info", "(", "\"Estimated time left: {}. Time passed: {}\"", ".", "format", "(", "\n", "time_left", "(", "last_time", ",", "last_test_T", ",", "runner", ".", "t_env", ",", "args", ".", "t_max", ")", ",", "time_str", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ")", ")", "\n", "last_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "last_test_T", "=", "runner", ".", "t_env", "\n", "for", "_", "in", "range", "(", "n_test_runs", ")", ":", "\n", "                ", "runner", ".", "run", "(", "test_mode", "=", "True", ")", "\n", "\n", "", "", "if", "args", ".", "save_model", "and", "(", "runner", ".", "t_env", "-", "model_save_time", ">=", "args", ".", "save_model_interval", "or", "model_save_time", "==", "0", ")", ":", "\n", "            ", "model_save_time", "=", "runner", ".", "t_env", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "local_results_path", ",", "\"models\"", ",", "args", ".", "unique_token", ",", "str", "(", "runner", ".", "t_env", ")", ")", "\n", "#\"results/models/{}\".format(unique_token)", "\n", "os", ".", "makedirs", "(", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "logger", ".", "console_logger", ".", "info", "(", "\"Saving models to {}\"", ".", "format", "(", "save_path", ")", ")", "\n", "\n", "# learner should handle saving/loading -- delegate actor save/load to mac,", "\n", "# use appropriate filenames to do critics, optimizer states", "\n", "learner", ".", "save_models", "(", "save_path", ")", "\n", "\n", "", "\"\"\"\n        This block is used to save model whenever the model reaches good test performance\n        \"\"\"", "\n", "if", "args", ".", "save_model", "and", "runner", ".", "save_model", ":", "\n", "            ", "save_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "local_results_path", ",", "\"models\"", ",", "args", ".", "unique_token", ",", "str", "(", "runner", ".", "t_env", ")", ")", "\n", "#\"results/models/{}\".format(unique_token)", "\n", "os", ".", "makedirs", "(", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "logger", ".", "console_logger", ".", "info", "(", "\"Saving models to {} at the profit of {}\"", ".", "format", "(", "save_path", ",", "runner", ".", "best_performance", ")", ")", "\n", "\n", "# learner should handle saving/loading -- delegate actor save/load to mac,", "\n", "# use appropriate filenames to do critics, optimizer states", "\n", "learner", ".", "save_models", "(", "save_path", ")", "\n", "runner", ".", "save_model", "=", "False", "\n", "\n", "\n", "", "episode", "+=", "args", ".", "batch_size_run", "\n", "\n", "if", "(", "runner", ".", "t_env", "-", "last_log_T", ")", ">=", "args", ".", "log_interval", ":", "\n", "            ", "logger", ".", "log_stat", "(", "\"episode\"", ",", "episode", ",", "runner", ".", "t_env", ")", "\n", "logger", ".", "print_recent_stats", "(", ")", "\n", "last_log_T", "=", "runner", ".", "t_env", "\n", "\n", "", "", "runner", ".", "close_env", "(", ")", "\n", "logger", ".", "console_logger", ".", "info", "(", "\"Finished Training\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.src.run.args_sanity_check": [[231, 245], ["_log.warning", "torch.cuda.is_available"], "function", ["None"], ["", "def", "args_sanity_check", "(", "config", ",", "_log", ")", ":", "\n", "\n", "# set CUDA flags", "\n", "# config[\"use_cuda\"] = True # Use cuda whenever possible!", "\n", "    ", "if", "config", "[", "\"use_cuda\"", "]", "and", "not", "th", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "config", "[", "\"use_cuda\"", "]", "=", "False", "\n", "_log", ".", "warning", "(", "\"CUDA flag use_cuda was switched OFF automatically because no CUDA devices are available!\"", ")", "\n", "\n", "", "if", "config", "[", "\"test_nepisode\"", "]", "<", "config", "[", "\"batch_size_run\"", "]", ":", "\n", "        ", "config", "[", "\"test_nepisode\"", "]", "=", "config", "[", "\"batch_size_run\"", "]", "\n", "", "else", ":", "\n", "        ", "config", "[", "\"test_nepisode\"", "]", "=", "(", "config", "[", "\"test_nepisode\"", "]", "//", "config", "[", "\"batch_size_run\"", "]", ")", "*", "config", "[", "\"batch_size_run\"", "]", "\n", "\n", "", "return", "config", "\n", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.RunningMeanStd.__init__": [[80, 84], ["numpy.zeros", "numpy.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "epsilon", "=", "1e-4", ",", "shape", "=", "(", ")", ")", ":", "\n", "        ", "self", ".", "mean", "=", "np", ".", "zeros", "(", "shape", ",", "'float64'", ")", "\n", "self", ".", "var", "=", "np", ".", "ones", "(", "shape", ",", "'float64'", ")", "\n", "self", ".", "count", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.RunningMeanStd.update": [[85, 90], ["numpy.mean", "numpy.var", "rl_utils.RunningMeanStd.update_from_moments"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.RunningMeanStd.update_from_moments"], ["", "def", "update", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_mean", "=", "np", ".", "mean", "(", "x", ",", "axis", "=", "0", ")", "\n", "batch_var", "=", "np", ".", "var", "(", "x", ",", "axis", "=", "0", ")", "\n", "batch_count", "=", "x", ".", "shape", "[", "0", "]", "\n", "self", ".", "update_from_moments", "(", "batch_mean", ",", "batch_var", ",", "batch_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.RunningMeanStd.update_from_moments": [[91, 94], ["rl_utils.update_mean_var_count_from_moments"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.update_mean_var_count_from_moments"], ["", "def", "update_from_moments", "(", "self", ",", "batch_mean", ",", "batch_var", ",", "batch_count", ")", ":", "\n", "        ", "self", ".", "mean", ",", "self", ".", "var", ",", "self", ".", "count", "=", "update_mean_var_count_from_moments", "(", "\n", "self", ".", "mean", ",", "self", ".", "var", ",", "self", ".", "count", ",", "batch_mean", ",", "batch_var", ",", "batch_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.build_td_lambda_targets": [[5, 16], ["target_qs.new_zeros", "range", "torch.sum"], "function", ["None"], ["def", "build_td_lambda_targets", "(", "rewards", ",", "terminated", ",", "mask", ",", "target_qs", ",", "n_agents", ",", "gamma", ",", "td_lambda", ")", ":", "\n", "# Assumes  <target_qs > in B*T*A and <reward >, <terminated >, <mask > in (at least) B*T-1*1", "\n", "# Initialise  last  lambda -return  for  not  terminated  episodes", "\n", "    ", "ret", "=", "target_qs", ".", "new_zeros", "(", "*", "target_qs", ".", "shape", ")", "\n", "ret", "[", ":", ",", "-", "1", "]", "=", "target_qs", "[", ":", ",", "-", "1", "]", "*", "(", "1", "-", "th", ".", "sum", "(", "terminated", ",", "dim", "=", "1", ")", ")", "\n", "# Backwards  recursive  update  of the \"forward  view\"", "\n", "for", "t", "in", "range", "(", "ret", ".", "shape", "[", "1", "]", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "        ", "ret", "[", ":", ",", "t", "]", "=", "td_lambda", "*", "gamma", "*", "ret", "[", ":", ",", "t", "+", "1", "]", "+", "mask", "[", ":", ",", "t", "]", "*", "(", "rewards", "[", ":", ",", "t", "]", "+", "(", "1", "-", "td_lambda", ")", "*", "gamma", "*", "target_qs", "[", ":", ",", "t", "+", "1", "]", "*", "(", "1", "-", "terminated", "[", ":", ",", "t", "]", ")", ")", "\n", "# Returns lambda-return from t=0 to t=T-1, i.e. in B*T-1*A", "\n", "", "return", "ret", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.build_bootstrap_targets": [[17, 24], ["target_qs.new_zeros", "range", "torch.sum"], "function", ["None"], ["", "def", "build_bootstrap_targets", "(", "rewards", ",", "terminated", ",", "mask", ",", "target_qs", ",", "n_agents", ",", "gamma", ")", ":", "\n", "    ", "ret", "=", "target_qs", ".", "new_zeros", "(", "*", "target_qs", ".", "shape", ")", "\n", "ret", "[", ":", ",", "-", "1", "]", "=", "target_qs", "[", ":", ",", "-", "1", "]", "*", "(", "1", "-", "th", ".", "sum", "(", "terminated", ",", "dim", "=", "1", ")", ")", "\n", "for", "t", "in", "range", "(", "ret", ".", "shape", "[", "1", "]", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "        ", "ret", "[", ":", ",", "t", "]", "=", "(", "gamma", "*", "ret", "[", ":", ",", "t", "+", "1", "]", "*", "(", "1", "-", "terminated", "[", ":", ",", "t", "]", ")", ")", "+", "rewards", "[", ":", ",", "t", "]", "*", "mask", "[", ":", ",", "t", "]", "\n", "# Returns bootstrap-return from t=0 to t=T-1", "\n", "", "return", "ret", "[", ":", ",", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.categorical_entropy": [[25, 31], ["torch.exp", "torch.sum", "torch.sum", "torch.max", "torch.log"], "function", ["None"], ["", "def", "categorical_entropy", "(", "logits", ")", ":", "\n", "    ", "a0", "=", "logits", "-", "th", ".", "max", "(", "logits", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", "\n", "ea0", "=", "th", ".", "exp", "(", "a0", ")", "\n", "z0", "=", "th", ".", "sum", "(", "ea0", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "p0", "=", "ea0", "/", "z0", "\n", "return", "th", ".", "sum", "(", "p0", "*", "(", "th", ".", "log", "(", "z0", ")", "-", "a0", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.discount_with_dones": [[33, 41], ["zip", "discounted.append"], "function", ["None"], ["", "def", "discount_with_dones", "(", "rewards", ",", "dones", ",", "gamma", ")", ":", "\n", "    ", "discounted", "=", "[", "]", "\n", "r", "=", "0", "\n", "for", "reward", ",", "done", "in", "zip", "(", "rewards", "[", ":", ":", "-", "1", "]", ",", "dones", "[", ":", ":", "-", "1", "]", ")", ":", "\n", "        ", "r", "=", "reward", "+", "gamma", "*", "r", "\n", "r", "=", "r", "*", "(", "1.", "-", "done", ")", "\n", "discounted", ".", "append", "(", "r", ")", "\n", "", "return", "discounted", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.soft_update": [[43, 47], ["zip", "target.parameters", "source.parameters", "target_param.data.copy_"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters"], ["", "def", "soft_update", "(", "target", ",", "source", ",", "tau", ")", ":", "\n", "    ", "for", "target_param", ",", "param", "in", "zip", "(", "target", ".", "parameters", "(", ")", ",", "source", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "target_param", ".", "data", ".", "copy_", "(", "\n", "target_param", ".", "data", "*", "(", "1.0", "-", "tau", ")", "+", "param", ".", "data", "*", "tau", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.denormalize": [[72, 76], ["None"], "function", ["None"], ["", "", "def", "denormalize", "(", "x", ",", "stats", ")", ":", "\n", "    ", "if", "stats", "is", "None", ":", "\n", "        ", "return", "x", "\n", "", "return", "x", "*", "stats", ".", "std", "+", "stats", ".", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.update_mean_var_count_from_moments": [[95, 107], ["numpy.square"], "function", ["None"], ["", "", "def", "update_mean_var_count_from_moments", "(", "mean", ",", "var", ",", "count", ",", "batch_mean", ",", "batch_var", ",", "batch_count", ")", ":", "\n", "    ", "delta", "=", "batch_mean", "-", "mean", "\n", "tot_count", "=", "count", "+", "batch_count", "\n", "\n", "new_mean", "=", "mean", "+", "delta", "*", "batch_count", "/", "tot_count", "\n", "m_a", "=", "var", "*", "count", "\n", "m_b", "=", "batch_var", "*", "batch_count", "\n", "M2", "=", "m_a", "+", "m_b", "+", "np", ".", "square", "(", "delta", ")", "*", "count", "*", "batch_count", "/", "tot_count", "\n", "new_var", "=", "M2", "/", "tot_count", "\n", "new_count", "=", "tot_count", "\n", "\n", "return", "new_mean", ",", "new_var", ",", "new_count", "\n", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.__init__": [[6, 14], ["collections.defaultdict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "console_logger", ")", ":", "\n", "        ", "self", ".", "console_logger", "=", "console_logger", "\n", "\n", "self", ".", "use_tb", "=", "False", "\n", "self", ".", "use_sacred", "=", "False", "\n", "self", ".", "use_hdf", "=", "False", "\n", "\n", "self", ".", "stats", "=", "defaultdict", "(", "lambda", ":", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.setup_tb": [[15, 21], ["configure"], "methods", ["None"], ["", "def", "setup_tb", "(", "self", ",", "directory_name", ")", ":", "\n", "# Import here so it doesn't have to be installed if you don't use it", "\n", "        ", "from", "tensorboard_logger", "import", "configure", ",", "log_value", "\n", "configure", "(", "directory_name", ")", "\n", "self", ".", "tb_logger", "=", "log_value", "\n", "self", ".", "use_tb", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.setup_sacred": [[22, 25], ["None"], "methods", ["None"], ["", "def", "setup_sacred", "(", "self", ",", "sacred_run_dict", ")", ":", "\n", "        ", "self", ".", "sacred_info", "=", "sacred_run_dict", ".", "info", "\n", "self", ".", "use_sacred", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat": [[26, 39], ["logging.Logger.stats[].append", "logging.Logger.tb_logger", "logging.Logger.sacred_info[].append", "logging.Logger.sacred_info[].append"], "methods", ["None"], ["", "def", "log_stat", "(", "self", ",", "key", ",", "value", ",", "t", ",", "to_sacred", "=", "True", ")", ":", "\n", "        ", "self", ".", "stats", "[", "key", "]", ".", "append", "(", "(", "t", ",", "value", ")", ")", "\n", "\n", "if", "self", ".", "use_tb", ":", "\n", "            ", "self", ".", "tb_logger", "(", "key", ",", "value", ",", "t", ")", "\n", "\n", "", "if", "self", ".", "use_sacred", "and", "to_sacred", ":", "\n", "            ", "if", "key", "in", "self", ".", "sacred_info", ":", "\n", "                ", "self", ".", "sacred_info", "[", "\"{}_T\"", ".", "format", "(", "key", ")", "]", ".", "append", "(", "t", ")", "\n", "self", ".", "sacred_info", "[", "key", "]", ".", "append", "(", "value", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "sacred_info", "[", "\"{}_T\"", ".", "format", "(", "key", ")", "]", "=", "[", "t", "]", "\n", "self", ".", "sacred_info", "[", "key", "]", "=", "[", "value", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.print_recent_stats": [[40, 52], ["sorted", "logging.Logger.console_logger.info", "logging.Logger.stats.items", "numpy.mean"], "methods", ["None"], ["", "", "", "def", "print_recent_stats", "(", "self", ")", ":", "\n", "        ", "log_str", "=", "\"Recent Stats | t_env: {:>10} | Episode: {:>8}\\n\"", ".", "format", "(", "*", "self", ".", "stats", "[", "\"episode\"", "]", "[", "-", "1", "]", ")", "\n", "i", "=", "0", "\n", "for", "(", "k", ",", "v", ")", "in", "sorted", "(", "self", ".", "stats", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "k", "==", "\"episode\"", ":", "\n", "                ", "continue", "\n", "", "i", "+=", "1", "\n", "window", "=", "5", "if", "k", "!=", "\"epsilon\"", "else", "1", "\n", "item", "=", "\"{:.4f}\"", ".", "format", "(", "np", ".", "mean", "(", "[", "x", "[", "1", "]", "for", "x", "in", "self", ".", "stats", "[", "k", "]", "[", "-", "window", ":", "]", "]", ")", ")", "\n", "log_str", "+=", "\"{:<25}{:>8}\"", ".", "format", "(", "k", "+", "\":\"", ",", "item", ")", "\n", "log_str", "+=", "\"\\n\"", "if", "i", "%", "4", "==", "0", "else", "\"\\t\"", "\n", "", "self", ".", "console_logger", ".", "info", "(", "log_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.get_logger": [[55, 65], ["logging.getLogger", "logging.StreamHandler", "logging.Formatter", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.setLevel"], "function", ["None"], ["", "", "def", "get_logger", "(", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "handlers", "=", "[", "]", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'[%(levelname)s %(asctime)s] %(name)s %(message)s'", ",", "'%H:%M:%S'", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "logger", ".", "setLevel", "(", "'DEBUG'", ")", "\n", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.dict2namedtuple.convert": [[4, 6], ["collections.namedtuple", "dictionary.keys"], "function", ["None"], ["def", "convert", "(", "dictionary", ")", ":", "\n", "    ", "return", "namedtuple", "(", "'GenericDict'", ",", "dictionary", ".", "keys", "(", ")", ")", "(", "**", "dictionary", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.timehelper.print_time": [[5, 15], ["max", "min", "print", "time.time", "len", "numpy.mean", "timehelper.time_str", "timehelper.time_str"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.timehelper.time_str", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.timehelper.time_str"], ["def", "print_time", "(", "start_time", ",", "T", ",", "t_max", ",", "episode", ",", "episode_rewards", ")", ":", "\n", "    ", "time_elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "T", "=", "max", "(", "1", ",", "T", ")", "\n", "time_left", "=", "time_elapsed", "*", "(", "t_max", "-", "T", ")", "/", "T", "\n", "# Just in case its over 100 days", "\n", "time_left", "=", "min", "(", "time_left", ",", "60", "*", "60", "*", "24", "*", "100", ")", "\n", "last_reward", "=", "\"N\\A\"", "\n", "if", "len", "(", "episode_rewards", ")", ">", "5", ":", "\n", "        ", "last_reward", "=", "\"{:.2f}\"", ".", "format", "(", "np", ".", "mean", "(", "episode_rewards", "[", "-", "50", ":", "]", ")", ")", "\n", "", "print", "(", "\"\\033[F\\033[F\\x1b[KEp: {:,}, T: {:,}/{:,}, Reward: {}, \\n\\x1b[KElapsed: {}, Left: {}\\n\"", ".", "format", "(", "episode", ",", "T", ",", "t_max", ",", "last_reward", ",", "time_str", "(", "time_elapsed", ")", ",", "time_str", "(", "time_left", ")", ")", ",", "\" \"", "*", "10", ",", "end", "=", "\"\\r\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.timehelper.time_left": [[17, 26], ["max", "min", "timehelper.time_str", "time.time"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.timehelper.time_str"], ["", "def", "time_left", "(", "start_time", ",", "t_start", ",", "t_current", ",", "t_max", ")", ":", "\n", "    ", "if", "t_current", ">=", "t_max", ":", "\n", "        ", "return", "\"-\"", "\n", "", "time_elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "t_current", "=", "max", "(", "1", ",", "t_current", ")", "\n", "time_left", "=", "time_elapsed", "*", "(", "t_max", "-", "t_current", ")", "/", "(", "t_current", "-", "t_start", ")", "\n", "# Just in case its over 100 days", "\n", "time_left", "=", "min", "(", "time_left", ",", "60", "*", "60", "*", "24", "*", "100", ")", "\n", "return", "time_str", "(", "time_left", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.timehelper.time_str": [[28, 44], ["divmod", "divmod", "divmod", "int", "int", "int", "int", "timehelper.time_left", "timehelper.time_left"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.timehelper.time_left", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.timehelper.time_left"], ["", "def", "time_str", "(", "s", ")", ":", "\n", "    ", "\"\"\"\n    Convert seconds to a nicer string showing days, hours, minutes and seconds\n    \"\"\"", "\n", "days", ",", "remainder", "=", "divmod", "(", "s", ",", "60", "*", "60", "*", "24", ")", "\n", "hours", ",", "remainder", "=", "divmod", "(", "remainder", ",", "60", "*", "60", ")", "\n", "minutes", ",", "seconds", "=", "divmod", "(", "remainder", ",", "60", ")", "\n", "string", "=", "\"\"", "\n", "if", "days", ">", "0", ":", "\n", "        ", "string", "+=", "\"{:d} days, \"", ".", "format", "(", "int", "(", "days", ")", ")", "\n", "", "if", "hours", ">", "0", ":", "\n", "        ", "string", "+=", "\"{:d} hours, \"", ".", "format", "(", "int", "(", "hours", ")", ")", "\n", "", "if", "minutes", ">", "0", ":", "\n", "        ", "string", "+=", "\"{:d} minutes, \"", ".", "format", "(", "int", "(", "minutes", ")", ")", "\n", "", "string", "+=", "\"{:d} seconds\"", ".", "format", "(", "int", "(", "seconds", ")", ")", "\n", "return", "string", "\n", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.transforms.Transform.transform": [[5, 7], ["None"], "methods", ["None"], ["    ", "def", "transform", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.transforms.Transform.infer_output_info": [[8, 10], ["None"], "methods", ["None"], ["", "def", "infer_output_info", "(", "self", ",", "vshape_in", ",", "dtype_in", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.transforms.OneHot.__init__": [[13, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "out_dim", ")", ":", "\n", "        ", "self", ".", "out_dim", "=", "out_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.transforms.OneHot.transform": [[16, 20], ["tensor.new().zero_", "tensor.new().zero_.scatter_", "tensor.new().zero_.float", "tensor.long", "tensor.new"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "y_onehot", "=", "tensor", ".", "new", "(", "*", "tensor", ".", "shape", "[", ":", "-", "1", "]", ",", "self", ".", "out_dim", ")", ".", "zero_", "(", ")", "\n", "y_onehot", ".", "scatter_", "(", "-", "1", ",", "tensor", ".", "long", "(", ")", ",", "1", ")", "\n", "return", "y_onehot", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.transforms.OneHot.infer_output_info": [[21, 23], ["None"], "methods", ["None"], ["", "def", "infer_output_info", "(", "self", ",", "vshape_in", ",", "dtype_in", ")", ":", "\n", "        ", "return", "(", "self", ".", "out_dim", ",", ")", ",", "th", ".", "float32", "", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.action_selectors.MultinomialActionSelector.__init__": [[10, 17], ["epsilon_schedules.DecayThenFlatSchedule", "action_selectors.MultinomialActionSelector.schedule.eval", "getattr"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.epsilon_schedules.DecayThenFlatSchedule.eval"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "schedule", "=", "DecayThenFlatSchedule", "(", "args", ".", "epsilon_start", ",", "args", ".", "epsilon_finish", ",", "args", ".", "epsilon_anneal_time", ",", "\n", "decay", "=", "\"linear\"", ")", "\n", "self", ".", "epsilon", "=", "self", ".", "schedule", ".", "eval", "(", "0", ")", "\n", "self", ".", "test_greedy", "=", "getattr", "(", "args", ",", "\"test_greedy\"", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.action_selectors.MultinomialActionSelector.select_action": [[18, 30], ["agent_inputs.clone", "action_selectors.MultinomialActionSelector.schedule.eval", "torch.distributions.Categorical().sample().long", "agent_inputs.clone.max", "torch.distributions.Categorical().sample", "torch.distributions.Categorical"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.epsilon_schedules.DecayThenFlatSchedule.eval", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.sample"], ["", "def", "select_action", "(", "self", ",", "agent_inputs", ",", "avail_actions", ",", "t_env", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "masked_policies", "=", "agent_inputs", ".", "clone", "(", ")", "\n", "masked_policies", "[", "avail_actions", "==", "0.0", "]", "=", "0.0", "\n", "\n", "self", ".", "epsilon", "=", "self", ".", "schedule", ".", "eval", "(", "t_env", ")", "\n", "\n", "if", "test_mode", "and", "self", ".", "test_greedy", ":", "\n", "            ", "picked_actions", "=", "masked_policies", ".", "max", "(", "dim", "=", "2", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "picked_actions", "=", "Categorical", "(", "masked_policies", ")", ".", "sample", "(", ")", ".", "long", "(", ")", "\n", "\n", "", "return", "picked_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.action_selectors.EpsilonGreedyActionSelector.__init__": [[37, 43], ["epsilon_schedules.DecayThenFlatSchedule", "action_selectors.EpsilonGreedyActionSelector.schedule.eval"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.epsilon_schedules.DecayThenFlatSchedule.eval"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "schedule", "=", "DecayThenFlatSchedule", "(", "args", ".", "epsilon_start", ",", "args", ".", "epsilon_finish", ",", "args", ".", "epsilon_anneal_time", ",", "\n", "decay", "=", "\"linear\"", ")", "\n", "self", ".", "epsilon", "=", "self", ".", "schedule", ".", "eval", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.action_selectors.EpsilonGreedyActionSelector.select_action": [[44, 63], ["action_selectors.EpsilonGreedyActionSelector.schedule.eval", "agent_inputs.clone", "torch.rand_like", "torch.distributions.Categorical().sample().long", "float", "torch.distributions.Categorical().sample", "agent_inputs.clone.max", "torch.distributions.Categorical", "avail_actions.float"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.epsilon_schedules.DecayThenFlatSchedule.eval", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.sample"], ["", "def", "select_action", "(", "self", ",", "agent_inputs", ",", "avail_actions", ",", "t_env", ",", "test_mode", "=", "False", ")", ":", "\n", "\n", "# Assuming agent_inputs is a batch of Q-Values for each agent bav", "\n", "        ", "self", ".", "epsilon", "=", "self", ".", "schedule", ".", "eval", "(", "t_env", ")", "\n", "\n", "if", "test_mode", ":", "\n", "# Greedy action selection only", "\n", "            ", "self", ".", "epsilon", "=", "0.0", "\n", "\n", "# mask actions that are excluded from selection", "\n", "", "masked_q_values", "=", "agent_inputs", ".", "clone", "(", ")", "\n", "masked_q_values", "[", "avail_actions", "==", "0.0", "]", "=", "-", "float", "(", "\"inf\"", ")", "# should never be selected!", "\n", "\n", "random_numbers", "=", "th", ".", "rand_like", "(", "agent_inputs", "[", ":", ",", ":", ",", "0", "]", ")", "\n", "pick_random", "=", "(", "random_numbers", "<", "self", ".", "epsilon", ")", ".", "long", "(", ")", "\n", "random_actions", "=", "Categorical", "(", "avail_actions", ".", "float", "(", ")", ")", ".", "sample", "(", ")", ".", "long", "(", ")", "\n", "\n", "picked_actions", "=", "pick_random", "*", "random_actions", "+", "(", "1", "-", "pick_random", ")", "*", "masked_q_values", ".", "max", "(", "dim", "=", "2", ")", "[", "1", "]", "\n", "return", "picked_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.epsilon_schedules.DecayThenFlatSchedule.__init__": [[6, 20], ["numpy.log"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "start", ",", "\n", "finish", ",", "\n", "time_length", ",", "\n", "decay", "=", "\"exp\"", ")", ":", "\n", "\n", "        ", "self", ".", "start", "=", "start", "\n", "self", ".", "finish", "=", "finish", "\n", "self", ".", "time_length", "=", "time_length", "\n", "self", ".", "delta", "=", "(", "self", ".", "start", "-", "self", ".", "finish", ")", "/", "self", ".", "time_length", "\n", "self", ".", "decay", "=", "decay", "\n", "\n", "if", "self", ".", "decay", "in", "[", "\"exp\"", "]", ":", "\n", "            ", "self", ".", "exp_scaling", "=", "(", "-", "1", ")", "*", "self", ".", "time_length", "/", "np", ".", "log", "(", "self", ".", "finish", ")", "if", "self", ".", "finish", ">", "0", "else", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.epsilon_schedules.DecayThenFlatSchedule.eval": [[21, 26], ["max", "min", "max", "numpy.exp"], "methods", ["None"], ["", "", "def", "eval", "(", "self", ",", "T", ")", ":", "\n", "        ", "if", "self", ".", "decay", "in", "[", "\"linear\"", "]", ":", "\n", "            ", "return", "max", "(", "self", ".", "finish", ",", "self", ".", "start", "-", "self", ".", "delta", "*", "T", ")", "\n", "", "elif", "self", ".", "decay", "in", "[", "\"exp\"", "]", ":", "\n", "            ", "return", "min", "(", "self", ".", "start", ",", "max", "(", "self", ".", "finish", ",", "np", ".", "exp", "(", "-", "T", "/", "self", ".", "exp_scaling", ")", ")", ")", "\n", "", "", "pass", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.__init__": [[7, 29], ["scheme.copy", "types.SimpleNamespace", "episode_buffer.EpisodeBatch._setup_data"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._setup_data"], ["    ", "def", "__init__", "(", "self", ",", "\n", "scheme", ",", "\n", "groups", ",", "\n", "batch_size", ",", "\n", "max_seq_length", ",", "\n", "data", "=", "None", ",", "\n", "preprocess", "=", "None", ",", "\n", "device", "=", "\"cpu\"", ")", ":", "\n", "        ", "self", ".", "scheme", "=", "scheme", ".", "copy", "(", ")", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "max_seq_length", "=", "max_seq_length", "\n", "self", ".", "preprocess", "=", "{", "}", "if", "preprocess", "is", "None", "else", "preprocess", "\n", "self", ".", "device", "=", "device", "\n", "\n", "if", "data", "is", "not", "None", ":", "\n", "            ", "self", ".", "data", "=", "data", "\n", "", "else", ":", "\n", "            ", "self", ".", "data", "=", "SN", "(", ")", "\n", "self", ".", "data", ".", "transition_data", "=", "{", "}", "\n", "self", ".", "data", ".", "episode_data", "=", "{", "}", "\n", "self", ".", "_setup_data", "(", "self", ".", "scheme", ",", "self", ".", "groups", ",", "batch_size", ",", "max_seq_length", ",", "self", ".", "preprocess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._setup_data": [[30, 76], ["scheme.update", "scheme.items", "field_info.get", "field_info.get", "field_info.get", "isinstance", "torch.zeros", "torch.zeros", "transform.infer_output_info"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.transforms.OneHot.infer_output_info"], ["", "", "def", "_setup_data", "(", "self", ",", "scheme", ",", "groups", ",", "batch_size", ",", "max_seq_length", ",", "preprocess", ")", ":", "\n", "        ", "if", "preprocess", "is", "not", "None", ":", "\n", "            ", "for", "k", "in", "preprocess", ":", "\n", "                ", "assert", "k", "in", "scheme", "\n", "new_k", "=", "preprocess", "[", "k", "]", "[", "0", "]", "\n", "transforms", "=", "preprocess", "[", "k", "]", "[", "1", "]", "\n", "\n", "vshape", "=", "self", ".", "scheme", "[", "k", "]", "[", "\"vshape\"", "]", "\n", "dtype", "=", "self", ".", "scheme", "[", "k", "]", "[", "\"dtype\"", "]", "\n", "for", "transform", "in", "transforms", ":", "\n", "                    ", "vshape", ",", "dtype", "=", "transform", ".", "infer_output_info", "(", "vshape", ",", "dtype", ")", "\n", "\n", "", "self", ".", "scheme", "[", "new_k", "]", "=", "{", "\n", "\"vshape\"", ":", "vshape", ",", "\n", "\"dtype\"", ":", "dtype", "\n", "}", "\n", "if", "\"group\"", "in", "self", ".", "scheme", "[", "k", "]", ":", "\n", "                    ", "self", ".", "scheme", "[", "new_k", "]", "[", "\"group\"", "]", "=", "self", ".", "scheme", "[", "k", "]", "[", "\"group\"", "]", "\n", "", "if", "\"episode_const\"", "in", "self", ".", "scheme", "[", "k", "]", ":", "\n", "                    ", "self", ".", "scheme", "[", "new_k", "]", "[", "\"episode_const\"", "]", "=", "self", ".", "scheme", "[", "k", "]", "[", "\"episode_const\"", "]", "\n", "\n", "", "", "", "assert", "\"filled\"", "not", "in", "scheme", ",", "'\"filled\" is a reserved key for masking.'", "\n", "scheme", ".", "update", "(", "{", "\n", "\"filled\"", ":", "{", "\"vshape\"", ":", "(", "1", ",", ")", ",", "\"dtype\"", ":", "th", ".", "long", "}", ",", "\n", "}", ")", "\n", "\n", "for", "field_key", ",", "field_info", "in", "scheme", ".", "items", "(", ")", ":", "\n", "            ", "assert", "\"vshape\"", "in", "field_info", ",", "\"Scheme must define vshape for {}\"", ".", "format", "(", "field_key", ")", "\n", "vshape", "=", "field_info", "[", "\"vshape\"", "]", "\n", "episode_const", "=", "field_info", ".", "get", "(", "\"episode_const\"", ",", "False", ")", "\n", "group", "=", "field_info", ".", "get", "(", "\"group\"", ",", "None", ")", "\n", "dtype", "=", "field_info", ".", "get", "(", "\"dtype\"", ",", "th", ".", "float32", ")", "\n", "\n", "if", "isinstance", "(", "vshape", ",", "int", ")", ":", "\n", "                ", "vshape", "=", "(", "vshape", ",", ")", "\n", "\n", "", "if", "group", ":", "\n", "                ", "assert", "group", "in", "groups", ",", "\"Group {} must have its number of members defined in _groups_\"", ".", "format", "(", "group", ")", "\n", "shape", "=", "(", "groups", "[", "group", "]", ",", "*", "vshape", ")", "\n", "", "else", ":", "\n", "                ", "shape", "=", "vshape", "\n", "\n", "", "if", "episode_const", ":", "\n", "                ", "self", ".", "data", ".", "episode_data", "[", "field_key", "]", "=", "th", ".", "zeros", "(", "(", "batch_size", ",", "*", "shape", ")", ",", "dtype", "=", "dtype", ",", "device", "=", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "data", ".", "transition_data", "[", "field_key", "]", "=", "th", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_length", ",", "*", "shape", ")", ",", "dtype", "=", "dtype", ",", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.extend": [[77, 79], ["episode_buffer.EpisodeBatch._setup_data"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._setup_data"], ["", "", "", "def", "extend", "(", "self", ",", "scheme", ",", "groups", "=", "None", ")", ":", "\n", "        ", "self", ".", "_setup_data", "(", "scheme", ",", "self", ".", "groups", "if", "groups", "is", "None", "else", "groups", ",", "self", ".", "batch_size", ",", "self", ".", "max_seq_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.to": [[80, 86], ["episode_buffer.EpisodeBatch.data.transition_data.items", "episode_buffer.EpisodeBatch.data.episode_data.items", "v.to", "v.to"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.to", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "self", ".", "data", ".", "transition_data", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "data", ".", "transition_data", "[", "k", "]", "=", "v", ".", "to", "(", "device", ")", "\n", "", "for", "k", ",", "v", "in", "self", ".", "data", ".", "episode_data", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "data", ".", "episode_data", "[", "k", "]", "=", "v", ".", "to", "(", "device", ")", "\n", "", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update": [[87, 114], ["slice", "slice", "episode_buffer.EpisodeBatch._parse_slices", "data.items", "episode_buffer.EpisodeBatch.scheme[].get", "episode_buffer.EpisodeBatch._check_safe_view", "transform.transform.view_as", "type", "torch.tensor", "transform.transform.view_as", "KeyError", "transform.transform"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._parse_slices", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._check_safe_view", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.transforms.OneHot.transform"], ["", "def", "update", "(", "self", ",", "data", ",", "bs", "=", "slice", "(", "None", ")", ",", "ts", "=", "slice", "(", "None", ")", ",", "mark_filled", "=", "True", ")", ":", "\n", "        ", "slices", "=", "self", ".", "_parse_slices", "(", "(", "bs", ",", "ts", ")", ")", "\n", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "self", ".", "data", ".", "transition_data", ":", "\n", "                ", "target", "=", "self", ".", "data", ".", "transition_data", "\n", "if", "mark_filled", ":", "\n", "                    ", "target", "[", "\"filled\"", "]", "[", "slices", "]", "=", "1", "\n", "mark_filled", "=", "False", "\n", "", "_slices", "=", "slices", "\n", "", "elif", "k", "in", "self", ".", "data", ".", "episode_data", ":", "\n", "                ", "target", "=", "self", ".", "data", ".", "episode_data", "\n", "_slices", "=", "slices", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "raise", "KeyError", "(", "\"{} not found in transition or episode data\"", ".", "format", "(", "k", ")", ")", "\n", "\n", "", "dtype", "=", "self", ".", "scheme", "[", "k", "]", ".", "get", "(", "\"dtype\"", ",", "th", ".", "float32", ")", "\n", "if", "type", "(", "v", ")", "==", "list", ":", "\n", "                ", "v", "=", "th", ".", "tensor", "(", "v", ",", "dtype", "=", "dtype", ",", "device", "=", "self", ".", "device", ")", "\n", "", "self", ".", "_check_safe_view", "(", "v", ",", "target", "[", "k", "]", "[", "_slices", "]", ")", "\n", "target", "[", "k", "]", "[", "_slices", "]", "=", "v", ".", "view_as", "(", "target", "[", "k", "]", "[", "_slices", "]", ")", "\n", "\n", "if", "k", "in", "self", ".", "preprocess", ":", "\n", "                ", "new_k", "=", "self", ".", "preprocess", "[", "k", "]", "[", "0", "]", "\n", "v", "=", "target", "[", "k", "]", "[", "_slices", "]", "\n", "for", "transform", "in", "self", ".", "preprocess", "[", "k", "]", "[", "1", "]", ":", "\n", "                    ", "v", "=", "transform", ".", "transform", "(", "v", ")", "\n", "", "target", "[", "new_k", "]", "[", "_slices", "]", "=", "v", ".", "view_as", "(", "target", "[", "new_k", "]", "[", "_slices", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._check_safe_view": [[115, 123], ["len", "ValueError"], "methods", ["None"], ["", "", "", "def", "_check_safe_view", "(", "self", ",", "v", ",", "dest", ")", ":", "\n", "        ", "idx", "=", "len", "(", "v", ".", "shape", ")", "-", "1", "\n", "for", "s", "in", "dest", ".", "shape", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "if", "v", ".", "shape", "[", "idx", "]", "!=", "s", ":", "\n", "                ", "if", "s", "!=", "1", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Unsafe reshape of {} to {}\"", ".", "format", "(", "v", ".", "shape", ",", "dest", ".", "shape", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "idx", "-=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.__getitem__": [[124, 161], ["isinstance", "isinstance", "all", "episode_buffer.EpisodeBatch._new_data_sn", "episode_buffer.EpisodeBatch", "episode_buffer.EpisodeBatch._parse_slices", "episode_buffer.EpisodeBatch._new_data_sn", "episode_buffer.EpisodeBatch.data.transition_data.items", "episode_buffer.EpisodeBatch.data.episode_data.items", "episode_buffer.EpisodeBatch._get_num_items", "episode_buffer.EpisodeBatch._get_num_items", "episode_buffer.EpisodeBatch", "isinstance", "KeyError"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._new_data_sn", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._parse_slices", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._new_data_sn", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._get_num_items", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._get_num_items"], ["", "", "", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "if", "isinstance", "(", "item", ",", "str", ")", ":", "\n", "            ", "if", "item", "in", "self", ".", "data", ".", "episode_data", ":", "\n", "                ", "return", "self", ".", "data", ".", "episode_data", "[", "item", "]", "\n", "", "elif", "item", "in", "self", ".", "data", ".", "transition_data", ":", "\n", "                ", "return", "self", ".", "data", ".", "transition_data", "[", "item", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "\n", "", "", "elif", "isinstance", "(", "item", ",", "tuple", ")", "and", "all", "(", "[", "isinstance", "(", "it", ",", "str", ")", "for", "it", "in", "item", "]", ")", ":", "\n", "            ", "new_data", "=", "self", ".", "_new_data_sn", "(", ")", "\n", "for", "key", "in", "item", ":", "\n", "                ", "if", "key", "in", "self", ".", "data", ".", "transition_data", ":", "\n", "                    ", "new_data", ".", "transition_data", "[", "key", "]", "=", "self", ".", "data", ".", "transition_data", "[", "key", "]", "\n", "", "elif", "key", "in", "self", ".", "data", ".", "episode_data", ":", "\n", "                    ", "new_data", ".", "episode_data", "[", "key", "]", "=", "self", ".", "data", ".", "episode_data", "[", "key", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "KeyError", "(", "\"Unrecognised key {}\"", ".", "format", "(", "key", ")", ")", "\n", "\n", "# Update the scheme to only have the requested keys", "\n", "", "", "new_scheme", "=", "{", "key", ":", "self", ".", "scheme", "[", "key", "]", "for", "key", "in", "item", "}", "\n", "new_groups", "=", "{", "self", ".", "scheme", "[", "key", "]", "[", "\"group\"", "]", ":", "self", ".", "groups", "[", "self", ".", "scheme", "[", "key", "]", "[", "\"group\"", "]", "]", "\n", "for", "key", "in", "item", "if", "\"group\"", "in", "self", ".", "scheme", "[", "key", "]", "}", "\n", "ret", "=", "EpisodeBatch", "(", "new_scheme", ",", "new_groups", ",", "self", ".", "batch_size", ",", "self", ".", "max_seq_length", ",", "data", "=", "new_data", ",", "device", "=", "self", ".", "device", ")", "\n", "return", "ret", "\n", "", "else", ":", "\n", "            ", "item", "=", "self", ".", "_parse_slices", "(", "item", ")", "\n", "new_data", "=", "self", ".", "_new_data_sn", "(", ")", "\n", "for", "k", ",", "v", "in", "self", ".", "data", ".", "transition_data", ".", "items", "(", ")", ":", "\n", "                ", "new_data", ".", "transition_data", "[", "k", "]", "=", "v", "[", "item", "]", "\n", "", "for", "k", ",", "v", "in", "self", ".", "data", ".", "episode_data", ".", "items", "(", ")", ":", "\n", "                ", "new_data", ".", "episode_data", "[", "k", "]", "=", "v", "[", "item", "[", "0", "]", "]", "\n", "\n", "", "ret_bs", "=", "self", ".", "_get_num_items", "(", "item", "[", "0", "]", ",", "self", ".", "batch_size", ")", "\n", "ret_max_t", "=", "self", ".", "_get_num_items", "(", "item", "[", "1", "]", ",", "self", ".", "max_seq_length", ")", "\n", "\n", "ret", "=", "EpisodeBatch", "(", "self", ".", "scheme", ",", "self", ".", "groups", ",", "ret_bs", ",", "ret_max_t", ",", "data", "=", "new_data", ",", "device", "=", "self", ".", "device", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._get_num_items": [[162, 168], ["isinstance", "isinstance", "len", "isinstance", "indexing_item.indices"], "methods", ["None"], ["", "", "def", "_get_num_items", "(", "self", ",", "indexing_item", ",", "max_size", ")", ":", "\n", "        ", "if", "isinstance", "(", "indexing_item", ",", "list", ")", "or", "isinstance", "(", "indexing_item", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "return", "len", "(", "indexing_item", ")", "\n", "", "elif", "isinstance", "(", "indexing_item", ",", "slice", ")", ":", "\n", "            ", "_range", "=", "indexing_item", ".", "indices", "(", "max_size", ")", "\n", "return", "1", "+", "(", "_range", "[", "1", "]", "-", "_range", "[", "0", "]", "-", "1", ")", "//", "_range", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._new_data_sn": [[169, 174], ["types.SimpleNamespace"], "methods", ["None"], ["", "", "def", "_new_data_sn", "(", "self", ")", ":", "\n", "        ", "new_data", "=", "SN", "(", ")", "\n", "new_data", ".", "transition_data", "=", "{", "}", "\n", "new_data", ".", "episode_data", "=", "{", "}", "\n", "return", "new_data", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch._parse_slices": [[175, 197], ["isinstance", "isinstance", "isinstance", "isinstance", "IndexError", "isinstance", "slice", "parsed.append", "parsed.append", "slice"], "methods", ["None"], ["", "def", "_parse_slices", "(", "self", ",", "items", ")", ":", "\n", "        ", "parsed", "=", "[", "]", "\n", "# Only batch slice given, add full time slice", "\n", "if", "(", "isinstance", "(", "items", ",", "slice", ")", "# slice a:b", "\n", "or", "isinstance", "(", "items", ",", "int", ")", "# int i", "\n", "or", "(", "isinstance", "(", "items", ",", "(", "list", ",", "np", ".", "ndarray", ",", "th", ".", "LongTensor", ",", "th", ".", "cuda", ".", "LongTensor", ")", ")", ")", "# [a,b,c]", "\n", ")", ":", "\n", "            ", "items", "=", "(", "items", ",", "slice", "(", "None", ")", ")", "\n", "\n", "# Need the time indexing to be contiguous", "\n", "", "if", "isinstance", "(", "items", "[", "1", "]", ",", "list", ")", ":", "\n", "            ", "raise", "IndexError", "(", "\"Indexing across Time must be contiguous\"", ")", "\n", "\n", "", "for", "item", "in", "items", ":", "\n", "#TODO: stronger checks to ensure only supported options get through", "\n", "            ", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "# Convert single indices to slices", "\n", "                ", "parsed", ".", "append", "(", "slice", "(", "item", ",", "item", "+", "1", ")", ")", "\n", "", "else", ":", "\n", "# Leave slices and lists as is", "\n", "                ", "parsed", ".", "append", "(", "item", ")", "\n", "", "", "return", "parsed", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.max_t_filled": [[198, 200], ["torch.sum().max", "torch.sum"], "methods", ["None"], ["", "def", "max_t_filled", "(", "self", ")", ":", "\n", "        ", "return", "th", ".", "sum", "(", "self", ".", "data", ".", "transition_data", "[", "\"filled\"", "]", ",", "1", ")", ".", "max", "(", "0", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.__repr__": [[201, 206], ["episode_buffer.EpisodeBatch.scheme.keys", "episode_buffer.EpisodeBatch.groups.keys"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"EpisodeBatch. Batch Size:{} Max_seq_len:{} Keys:{} Groups:{}\"", ".", "format", "(", "self", ".", "batch_size", ",", "\n", "self", ".", "max_seq_length", ",", "\n", "self", ".", "scheme", ".", "keys", "(", ")", ",", "\n", "self", ".", "groups", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.__init__": [[209, 214], ["episode_buffer.EpisodeBatch.__init__"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["    ", "def", "__init__", "(", "self", ",", "scheme", ",", "groups", ",", "buffer_size", ",", "max_seq_length", ",", "preprocess", "=", "None", ",", "device", "=", "\"cpu\"", ")", ":", "\n", "        ", "super", "(", "ReplayBuffer", ",", "self", ")", ".", "__init__", "(", "scheme", ",", "groups", ",", "buffer_size", ",", "max_seq_length", ",", "preprocess", "=", "preprocess", ",", "device", "=", "device", ")", "\n", "self", ".", "buffer_size", "=", "buffer_size", "# same as self.batch_size but more explicit", "\n", "self", ".", "buffer_index", "=", "0", "\n", "self", ".", "episodes_in_buffer", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.insert_episode_batch": [[215, 231], ["episode_buffer.ReplayBuffer.update", "episode_buffer.ReplayBuffer.update", "max", "episode_buffer.ReplayBuffer.insert_episode_batch", "episode_buffer.ReplayBuffer.insert_episode_batch", "slice", "slice", "slice"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.insert_episode_batch", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.insert_episode_batch"], ["", "def", "insert_episode_batch", "(", "self", ",", "ep_batch", ")", ":", "\n", "        ", "if", "self", ".", "buffer_index", "+", "ep_batch", ".", "batch_size", "<=", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "update", "(", "ep_batch", ".", "data", ".", "transition_data", ",", "\n", "slice", "(", "self", ".", "buffer_index", ",", "self", ".", "buffer_index", "+", "ep_batch", ".", "batch_size", ")", ",", "\n", "slice", "(", "0", ",", "ep_batch", ".", "max_seq_length", ")", ",", "\n", "mark_filled", "=", "False", ")", "\n", "self", ".", "update", "(", "ep_batch", ".", "data", ".", "episode_data", ",", "\n", "slice", "(", "self", ".", "buffer_index", ",", "self", ".", "buffer_index", "+", "ep_batch", ".", "batch_size", ")", ")", "\n", "self", ".", "buffer_index", "=", "(", "self", ".", "buffer_index", "+", "ep_batch", ".", "batch_size", ")", "\n", "self", ".", "episodes_in_buffer", "=", "max", "(", "self", ".", "episodes_in_buffer", ",", "self", ".", "buffer_index", ")", "\n", "self", ".", "buffer_index", "=", "self", ".", "buffer_index", "%", "self", ".", "buffer_size", "\n", "assert", "self", ".", "buffer_index", "<", "self", ".", "buffer_size", "\n", "", "else", ":", "\n", "            ", "buffer_left", "=", "self", ".", "buffer_size", "-", "self", ".", "buffer_index", "\n", "self", ".", "insert_episode_batch", "(", "ep_batch", "[", "0", ":", "buffer_left", ",", ":", "]", ")", "\n", "self", ".", "insert_episode_batch", "(", "ep_batch", "[", "buffer_left", ":", ",", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.can_sample": [[232, 234], ["None"], "methods", ["None"], ["", "", "def", "can_sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "return", "self", ".", "episodes_in_buffer", ">=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.sample": [[235, 243], ["episode_buffer.ReplayBuffer.can_sample", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.can_sample"], ["", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "assert", "self", ".", "can_sample", "(", "batch_size", ")", "\n", "if", "self", ".", "episodes_in_buffer", "==", "batch_size", ":", "\n", "            ", "return", "self", "[", ":", "batch_size", "]", "\n", "", "else", ":", "\n", "# Uniform sampling only atm", "\n", "            ", "ep_ids", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "episodes_in_buffer", ",", "batch_size", ",", "replace", "=", "False", ")", "\n", "return", "self", "[", "ep_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.ReplayBuffer.__repr__": [[244, 249], ["episode_buffer.ReplayBuffer.scheme.keys", "episode_buffer.ReplayBuffer.groups.keys"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"ReplayBuffer. {}/{} episodes. Keys:{} Groups:{}\"", ".", "format", "(", "self", ".", "episodes_in_buffer", ",", "\n", "self", ".", "buffer_size", ",", "\n", "self", ".", "scheme", ".", "keys", "(", ")", ",", "\n", "self", ".", "groups", ".", "keys", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v2.PGLearner_v2.__init__": [[14, 39], ["copy.deepcopy", "list", "torch.optim.RMSprop", "policy_gradient_v2.PGLearner_v2.mac.parameters", "list", "modules.mixers.vdn.VDNMixer", "policy_gradient_v2.PGLearner_v2.mixer.parameters", "modules.mixers.qmix.QMixer", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters"], ["    ", "def", "__init__", "(", "self", ",", "mac", ",", "scheme", ",", "logger", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "self", ".", "n_actions", "=", "args", ".", "n_actions", "\n", "self", ".", "mac", "=", "mac", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "self", ".", "last_target_update_step", "=", "0", "\n", "self", ".", "critic_training_steps", "=", "0", "\n", "\n", "self", ".", "log_stats_t", "=", "-", "self", ".", "args", ".", "learner_log_interval", "-", "1", "\n", "\n", "self", ".", "target_mac", "=", "copy", ".", "deepcopy", "(", "mac", ")", "\n", "self", ".", "params", "=", "list", "(", "self", ".", "mac", ".", "parameters", "(", ")", ")", "\n", "\n", "if", "args", ".", "mixer", "is", "not", "None", ":", "\n", "            ", "if", "args", ".", "mixer", "==", "\"vdn\"", ":", "\n", "                ", "self", ".", "mixer", "=", "VDNMixer", "(", ")", "\n", "", "elif", "args", ".", "mixer", "==", "\"qmix\"", ":", "\n", "                ", "self", ".", "mixer", "=", "QMixer", "(", "args", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Mixer {} not recognised.\"", ".", "format", "(", "args", ".", "mixer", ")", ")", "\n", "", "self", ".", "params", "+=", "list", "(", "self", ".", "mixer", ".", "parameters", "(", ")", ")", "\n", "\n", "", "self", ".", "optimiser", "=", "RMSprop", "(", "params", "=", "self", ".", "params", ",", "lr", "=", "args", ".", "lr", ",", "alpha", "=", "args", ".", "optim_alpha", ",", "eps", "=", "args", ".", "optim_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v2.PGLearner_v2.train": [[40, 83], ["[].float", "[].float", "mask.repeat().view.repeat().view.clone", "mask.repeat().view.repeat().view.repeat().view", "policy_gradient_v2.PGLearner_v2._calculate_advs", "policy_gradient_v2.PGLearner_v2.optimiser.zero_grad", "coma_loss.backward", "torch.nn.utils.clip_grad_norm_", "policy_gradient_v2.PGLearner_v2.optimiser.step", "mask.repeat().view.repeat().view.sum", "mask.repeat().view.repeat().view.sum", "mask.repeat().view.repeat().view.sum", "policy_gradient_v2.PGLearner_v2.logger.log_stat", "policy_gradient_v2.PGLearner_v2.logger.log_stat", "policy_gradient_v2.PGLearner_v2.logger.log_stat", "policy_gradient_v2.PGLearner_v2.logger.log_stat", "policy_gradient_v2.PGLearner_v2.logger.log_stat", "policy_gradient_v2.PGLearner_v2.logger.log_stat", "policy_gradient_v2.PGLearner_v2.logger.log_stat", "policy_gradient_v2.PGLearner_v2.logger.log_stat", "mask.repeat().view.repeat().view.repeat", "coma_loss.item", "mask.repeat().view.repeat().view.sum().item", "mask.repeat().view.repeat().view.sum().item", "mask.repeat().view.repeat().view.sum().item", "mask.repeat().view.repeat().view.sum().item", "mask.repeat().view.repeat().view.sum().item", "mask.repeat().view.repeat().view.sum().item", "mask.repeat().view.repeat().view.sum", "mask.repeat().view.repeat().view.sum", "mask.repeat().view.repeat().view.sum", "mask.repeat().view.repeat().view.sum", "mask.repeat().view.repeat().view.sum", "mask.repeat().view.repeat().view.sum", "advantages.detach", "td_error.abs", "advantages.detach"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v2.PGLearner_v2._calculate_advs", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat"], ["", "def", "train", "(", "self", ",", "batch", ":", "EpisodeBatch", ",", "t_env", ":", "int", ",", "episode_num", ":", "int", ")", ":", "\n", "# Get the relevant quantities", "\n", "        ", "bs", "=", "batch", ".", "batch_size", "\n", "max_t", "=", "batch", ".", "max_seq_length", "\n", "rewards", "=", "batch", "[", "\"reward\"", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "actions", "=", "batch", "[", "\"actions\"", "]", "[", ":", ",", ":", "]", "\n", "terminated", "=", "batch", "[", "\"terminated\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "=", "batch", "[", "\"filled\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "[", ":", ",", "1", ":", "]", "=", "mask", "[", ":", ",", "1", ":", "]", "*", "(", "1", "-", "terminated", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "avail_actions", "=", "batch", "[", "\"avail_actions\"", "]", "[", ":", ",", ":", "]", "\n", "\n", "critic_mask", "=", "mask", ".", "clone", "(", ")", "\n", "mask", "=", "mask", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "advantages", ",", "td_error", ",", "targets_taken", ",", "log_pi_taken", ",", "entropy", "=", "self", ".", "_calculate_advs", "(", "batch", ",", "rewards", ",", "terminated", ",", "actions", ",", "avail_actions", ",", "\n", "critic_mask", ",", "bs", ",", "max_t", ")", "\n", "\n", "pg_loss", "=", "-", "(", "(", "advantages", ".", "detach", "(", ")", "*", "log_pi_taken", ")", "*", "mask", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "vf_loss", "=", "(", "(", "td_error", "**", "2", ")", "*", "mask", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "entropy_loss", "=", "(", "entropy", "*", "mask", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "\n", "coma_loss", "=", "pg_loss", "+", "self", ".", "args", ".", "vf_coef", "*", "vf_loss", "\n", "if", "self", ".", "args", ".", "ent_coef", ":", "\n", "            ", "coma_loss", "-=", "self", ".", "args", ".", "ent_coef", "*", "entropy_loss", "\n", "\n", "# Optimise agents", "\n", "", "self", ".", "optimiser", ".", "zero_grad", "(", ")", "\n", "coma_loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "th", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "params", ",", "self", ".", "args", ".", "grad_norm_clip", ")", "\n", "self", ".", "optimiser", ".", "step", "(", ")", "\n", "\n", "\n", "if", "t_env", "-", "self", ".", "log_stats_t", ">=", "self", ".", "args", ".", "learner_log_interval", ":", "\n", "            ", "self", ".", "logger", ".", "log_stat", "(", "\"critic_loss\"", ",", "(", "(", "td_error", "**", "2", ")", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"td_error_abs\"", ",", "(", "td_error", ".", "abs", "(", ")", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"q_taken_mean\"", ",", "(", "targets_taken", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"target_mean\"", ",", "(", "(", "targets_taken", "+", "advantages", ")", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"pg_loss\"", ",", "-", "(", "(", "advantages", ".", "detach", "(", ")", "*", "log_pi_taken", ")", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"advantage_mean\"", ",", "(", "advantages", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"coma_loss\"", ",", "coma_loss", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"agent_grad_norm\"", ",", "grad_norm", ",", "t_env", ")", "\n", "# self.logger.log_stat(\"pi_max\", (pi.max(dim=1)[0] * mask).sum().item() / mask.sum().item(), t_env)", "\n", "self", ".", "log_stats_t", "=", "t_env", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v2.PGLearner_v2._calculate_advs": [[84, 127], ["policy_gradient_v2.PGLearner_v2.mac.init_hidden", "range", "torch.stack", "torch.stack", "torch.gather().squeeze", "mask.repeat", "torch.log().reshape", "categorical_entropy().reshape", "torch.stack.squeeze", "build_td_lambda_targets", "advantages.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape", "td_error.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape", "policy_gradient_v2.PGLearner_v2.mac.forward", "torch.stack.append", "torch.stack.append", "torch.stack.sum", "policy_gradient_v2.PGLearner_v2.mixer", "build_td_lambda_targets.detach", "targets_taken[].unsqueeze().repeat().reshape", "torch.gather", "torch.log", "categorical_entropy", "advantages.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat", "td_error.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze().repeat", "targets_taken[].unsqueeze().repeat", "advantages.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze", "td_error.unsqueeze().repeat().reshape.unsqueeze().repeat().reshape.unsqueeze", "targets_taken[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.build_td_lambda_targets", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.forward", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.categorical_entropy"], ["", "", "def", "_calculate_advs", "(", "self", ",", "batch", ",", "rewards", ",", "terminated", ",", "actions", ",", "avail_actions", ",", "mask", ",", "bs", ",", "max_t", ")", ":", "\n", "        ", "mac_out", "=", "[", "]", "\n", "q_outs", "=", "[", "]", "\n", "# Roll out experiences", "\n", "self", ".", "mac", ".", "init_hidden", "(", "batch", ".", "batch_size", ")", "\n", "for", "t", "in", "range", "(", "batch", ".", "max_seq_length", ")", ":", "\n", "            ", "agent_out", ",", "q_out", "=", "self", ".", "mac", ".", "forward", "(", "batch", ",", "t", "=", "t", ")", "\n", "mac_out", ".", "append", "(", "agent_out", ")", "\n", "q_outs", ".", "append", "(", "q_out", ")", "\n", "", "mac_out", "=", "th", ".", "stack", "(", "mac_out", ",", "dim", "=", "1", ")", "# Concat over time", "\n", "q_outs", "=", "th", ".", "stack", "(", "q_outs", ",", "dim", "=", "1", ")", "# Concat over time", "\n", "\n", "# Mask out unavailable actions, renormalise (as in action selection)", "\n", "mac_out", "[", "avail_actions", "==", "0", "]", "=", "0", "\n", "mac_out", "=", "mac_out", "/", "mac_out", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "mac_out", "[", "avail_actions", "==", "0", "]", "=", "0", "\n", "\n", "# Calculated baseline", "\n", "pi", "=", "mac_out", "[", ":", ",", ":", "-", "1", "]", "#[bs, t, n_agents, n_actions]", "\n", "pi_taken", "=", "th", ".", "gather", "(", "pi", ",", "dim", "=", "-", "1", ",", "index", "=", "actions", "[", ":", ",", ":", "-", "1", "]", ")", ".", "squeeze", "(", "-", "1", ")", "#[bs, t, n_agents]", "\n", "action_mask", "=", "mask", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ")", "\n", "pi_taken", "[", "action_mask", "==", "0", "]", "=", "1.0", "\n", "log_pi_taken", "=", "th", ".", "log", "(", "pi_taken", ")", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "# Calculate entropy", "\n", "entropy", "=", "categorical_entropy", "(", "pi", ")", ".", "reshape", "(", "-", "1", ")", "#[bs, t, n_agents, 1]", "\n", "\n", "# Calculate q targets", "\n", "targets_taken", "=", "q_outs", ".", "squeeze", "(", "-", "1", ")", "#[bs, t, n_agents]", "\n", "if", "self", ".", "args", ".", "mixer", ":", "\n", "            ", "targets_taken", "=", "self", ".", "mixer", "(", "targets_taken", ",", "batch", "[", "\"state\"", "]", "[", ":", ",", ":", "]", ")", "#[bs, t, 1]", "\n", "\n", "# Calculate td-lambda targets", "\n", "", "targets", "=", "build_td_lambda_targets", "(", "rewards", ",", "terminated", ",", "mask", ",", "targets_taken", ",", "self", ".", "n_agents", ",", "self", ".", "args", ".", "gamma", ",", "self", ".", "args", ".", "td_lambda", ")", "\n", "\n", "advantages", "=", "targets", "-", "targets_taken", "[", ":", ",", ":", "-", "1", "]", "\n", "advantages", "=", "advantages", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "td_error", "=", "targets_taken", "[", ":", ",", ":", "-", "1", "]", "-", "targets", ".", "detach", "(", ")", "\n", "td_error", "=", "td_error", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "\n", "return", "advantages", ",", "td_error", ",", "targets_taken", "[", ":", ",", ":", "-", "1", "]", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", ".", "reshape", "(", "-", "1", ")", ",", "log_pi_taken", ",", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v2.PGLearner_v2.cuda": [[129, 133], ["policy_gradient_v2.PGLearner_v2.mac.cuda", "policy_gradient_v2.PGLearner_v2.mixer.cuda"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "mac", ".", "cuda", "(", ")", "\n", "if", "self", ".", "args", ".", "mixer", ":", "\n", "            ", "self", ".", "mixer", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v2.PGLearner_v2.save_models": [[134, 139], ["policy_gradient_v2.PGLearner_v2.mac.save_models", "torch.save", "torch.save", "policy_gradient_v2.PGLearner_v2.optimiser.state_dict", "policy_gradient_v2.PGLearner_v2.mixer.state_dict"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.save_models"], ["", "", "def", "save_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "save_models", "(", "path", ")", "\n", "if", "self", ".", "args", ".", "mixer", ":", "\n", "            ", "th", ".", "save", "(", "self", ".", "mixer", ".", "state_dict", "(", ")", ",", "\"{}/mixer.th\"", ".", "format", "(", "path", ")", ")", "\n", "", "th", ".", "save", "(", "self", ".", "optimiser", ".", "state_dict", "(", ")", ",", "\"{}/opt.th\"", ".", "format", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v2.PGLearner_v2.load_models": [[140, 145], ["policy_gradient_v2.PGLearner_v2.mac.load_models", "policy_gradient_v2.PGLearner_v2.optimiser.load_state_dict", "policy_gradient_v2.PGLearner_v2.mixer.load_state_dict", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_models"], ["", "def", "load_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "load_models", "(", "path", ")", "\n", "if", "self", ".", "args", ".", "mixer", ":", "\n", "            ", "self", ".", "mixer", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/mixer.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "", "self", ".", "optimiser", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/opt.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.coma_learner.COMALearner.__init__": [[10, 31], ["modules.critics.coma.COMACritic", "copy.deepcopy", "list", "list", "torch.optim.RMSprop", "torch.optim.RMSprop", "mac.parameters", "coma_learner.COMALearner.critic.parameters"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters"], ["    ", "def", "__init__", "(", "self", ",", "mac", ",", "scheme", ",", "logger", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "self", ".", "n_actions", "=", "args", ".", "n_actions", "\n", "self", ".", "mac", "=", "mac", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "self", ".", "last_target_update_step", "=", "0", "\n", "self", ".", "critic_training_steps", "=", "0", "\n", "\n", "self", ".", "log_stats_t", "=", "-", "self", ".", "args", ".", "learner_log_interval", "-", "1", "\n", "\n", "self", ".", "critic", "=", "COMACritic", "(", "scheme", ",", "args", ")", "\n", "self", ".", "target_critic", "=", "copy", ".", "deepcopy", "(", "self", ".", "critic", ")", "\n", "\n", "self", ".", "agent_params", "=", "list", "(", "mac", ".", "parameters", "(", ")", ")", "\n", "self", ".", "critic_params", "=", "list", "(", "self", ".", "critic", ".", "parameters", "(", ")", ")", "\n", "self", ".", "params", "=", "self", ".", "agent_params", "+", "self", ".", "critic_params", "\n", "\n", "self", ".", "agent_optimiser", "=", "RMSprop", "(", "params", "=", "self", ".", "agent_params", ",", "lr", "=", "args", ".", "lr", ",", "alpha", "=", "args", ".", "optim_alpha", ",", "eps", "=", "args", ".", "optim_eps", ")", "\n", "self", ".", "critic_optimiser", "=", "RMSprop", "(", "params", "=", "self", ".", "critic_params", ",", "lr", "=", "args", ".", "critic_lr", ",", "alpha", "=", "args", ".", "optim_alpha", ",", "eps", "=", "args", ".", "optim_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.coma_learner.COMALearner.train": [[32, 99], ["[].float", "[].float", "mask.repeat().view.repeat().view.clone", "mask.repeat().view.repeat().view.repeat().view", "coma_learner.COMALearner._train_critic", "coma_learner.COMALearner.mac.init_hidden", "range", "torch.stack", "q_vals.reshape.reshape.reshape", "torch.stack.view", "torch.gather().squeeze", "torch.gather().squeeze", "torch.log", "coma_learner.COMALearner.agent_optimiser.zero_grad", "coma_loss.backward", "torch.nn.utils.clip_grad_norm_", "coma_learner.COMALearner.agent_optimiser.step", "coma_learner.COMALearner.mac.forward", "torch.stack.append", "torch.stack.sum", "mask.repeat().view.repeat().view.sum", "coma_learner.COMALearner._update_targets", "len", "coma_learner.COMALearner.logger.log_stat", "coma_learner.COMALearner.logger.log_stat", "coma_learner.COMALearner.logger.log_stat", "coma_learner.COMALearner.logger.log_stat", "mask.repeat().view.repeat().view.repeat", "torch.gather", "torch.gather", "coma_learner.COMALearner.logger.log_stat", "coma_loss.item", "mask.repeat().view.repeat().view.sum().item", "mask.repeat().view.repeat().view.sum().item", "actions.reshape", "actions.reshape", "sum", "mask.repeat().view.repeat().view.sum", "mask.repeat().view.repeat().view.sum", "th.stack.view.max"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v3.PGLearner_v3._train_critic", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.forward", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner._update_targets", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat"], ["", "def", "train", "(", "self", ",", "batch", ":", "EpisodeBatch", ",", "t_env", ":", "int", ",", "episode_num", ":", "int", ")", ":", "\n", "# Get the relevant quantities", "\n", "        ", "bs", "=", "batch", ".", "batch_size", "\n", "max_t", "=", "batch", ".", "max_seq_length", "\n", "rewards", "=", "batch", "[", "\"reward\"", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "actions", "=", "batch", "[", "\"actions\"", "]", "[", ":", ",", ":", "]", "\n", "terminated", "=", "batch", "[", "\"terminated\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "=", "batch", "[", "\"filled\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "[", ":", ",", "1", ":", "]", "=", "mask", "[", ":", ",", "1", ":", "]", "*", "(", "1", "-", "terminated", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "avail_actions", "=", "batch", "[", "\"avail_actions\"", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "critic_mask", "=", "mask", ".", "clone", "(", ")", "\n", "\n", "mask", "=", "mask", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "q_vals", ",", "critic_train_stats", "=", "self", ".", "_train_critic", "(", "batch", ",", "rewards", ",", "terminated", ",", "actions", ",", "avail_actions", ",", "\n", "critic_mask", ",", "bs", ",", "max_t", ")", "\n", "\n", "actions", "=", "actions", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "mac_out", "=", "[", "]", "\n", "self", ".", "mac", ".", "init_hidden", "(", "batch", ".", "batch_size", ")", "\n", "for", "t", "in", "range", "(", "batch", ".", "max_seq_length", "-", "1", ")", ":", "\n", "            ", "agent_outs", "=", "self", ".", "mac", ".", "forward", "(", "batch", ",", "t", "=", "t", ")", "\n", "mac_out", ".", "append", "(", "agent_outs", ")", "\n", "", "mac_out", "=", "th", ".", "stack", "(", "mac_out", ",", "dim", "=", "1", ")", "# Concat over time", "\n", "\n", "# Mask out unavailable actions, renormalise (as in action selection)", "\n", "mac_out", "[", "avail_actions", "==", "0", "]", "=", "0", "\n", "mac_out", "=", "mac_out", "/", "mac_out", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "mac_out", "[", "avail_actions", "==", "0", "]", "=", "0", "\n", "\n", "# Calculated baseline", "\n", "q_vals", "=", "q_vals", ".", "reshape", "(", "-", "1", ",", "self", ".", "n_actions", ")", "\n", "pi", "=", "mac_out", ".", "view", "(", "-", "1", ",", "self", ".", "n_actions", ")", "\n", "baseline", "=", "(", "pi", "*", "q_vals", ")", ".", "sum", "(", "-", "1", ")", ".", "detach", "(", ")", "\n", "\n", "# Calculate policy grad with mask", "\n", "q_taken", "=", "th", ".", "gather", "(", "q_vals", ",", "dim", "=", "1", ",", "index", "=", "actions", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "pi_taken", "=", "th", ".", "gather", "(", "pi", ",", "dim", "=", "1", ",", "index", "=", "actions", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "pi_taken", "[", "mask", "==", "0", "]", "=", "1.0", "\n", "log_pi_taken", "=", "th", ".", "log", "(", "pi_taken", ")", "\n", "\n", "advantages", "=", "(", "q_taken", "-", "baseline", ")", ".", "detach", "(", ")", "\n", "\n", "coma_loss", "=", "-", "(", "(", "advantages", "*", "log_pi_taken", ")", "*", "mask", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "\n", "# Optimise agents", "\n", "self", ".", "agent_optimiser", ".", "zero_grad", "(", ")", "\n", "coma_loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "th", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "agent_params", ",", "self", ".", "args", ".", "grad_norm_clip", ")", "\n", "self", ".", "agent_optimiser", ".", "step", "(", ")", "\n", "\n", "if", "(", "self", ".", "critic_training_steps", "-", "self", ".", "last_target_update_step", ")", "/", "self", ".", "args", ".", "target_update_interval", ">=", "1.0", ":", "\n", "            ", "self", ".", "_update_targets", "(", ")", "\n", "self", ".", "last_target_update_step", "=", "self", ".", "critic_training_steps", "\n", "\n", "", "if", "t_env", "-", "self", ".", "log_stats_t", ">=", "self", ".", "args", ".", "learner_log_interval", ":", "\n", "            ", "ts_logged", "=", "len", "(", "critic_train_stats", "[", "\"critic_loss\"", "]", ")", "\n", "for", "key", "in", "[", "\"critic_loss\"", ",", "\"critic_grad_norm\"", ",", "\"td_error_abs\"", ",", "\"q_taken_mean\"", ",", "\"target_mean\"", "]", ":", "\n", "                ", "self", ".", "logger", ".", "log_stat", "(", "key", ",", "sum", "(", "critic_train_stats", "[", "key", "]", ")", "/", "ts_logged", ",", "t_env", ")", "\n", "\n", "", "self", ".", "logger", ".", "log_stat", "(", "\"advantage_mean\"", ",", "(", "advantages", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"coma_loss\"", ",", "coma_loss", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"agent_grad_norm\"", ",", "grad_norm", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"pi_max\"", ",", "(", "pi", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "log_stats_t", "=", "t_env", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.coma_learner.COMALearner._train_critic": [[100, 148], ["torch.gather().squeeze", "utils.rl_utils.build_td_lambda_targets", "reversed", "coma_learner.COMALearner.target_critic", "torch.zeros_like", "range", "mask[].expand", "coma_learner.COMALearner.critic", "coma_learner.COMALearner.view", "torch.gather().squeeze().squeeze", "coma_learner.COMALearner.critic_optimiser.zero_grad", "loss.backward", "torch.nn.utils.clip_grad_norm_", "coma_learner.COMALearner.critic_optimiser.step", "running_log[].append", "running_log[].append", "mask[].expand.sum().item", "running_log[].append", "running_log[].append", "running_log[].append", "torch.gather", "rewards.size", "mask[].expand.sum", "targets_t.detach", "mask[].expand.sum", "loss.item", "torch.gather().squeeze", "mask[].expand.sum", "masked_td_error.abs().sum().item", "torch.gather", "masked_td_error.abs().sum", "masked_td_error.abs"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.build_td_lambda_targets", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step"], ["", "", "def", "_train_critic", "(", "self", ",", "batch", ",", "rewards", ",", "terminated", ",", "actions", ",", "avail_actions", ",", "mask", ",", "bs", ",", "max_t", ")", ":", "\n", "# Optimise critic", "\n", "        ", "target_q_vals", "=", "self", ".", "target_critic", "(", "batch", ")", "[", ":", ",", ":", "]", "\n", "targets_taken", "=", "th", ".", "gather", "(", "target_q_vals", ",", "dim", "=", "3", ",", "index", "=", "actions", ")", ".", "squeeze", "(", "3", ")", "\n", "\n", "# Calculate td-lambda targets", "\n", "targets", "=", "build_td_lambda_targets", "(", "rewards", ",", "terminated", ",", "mask", ",", "targets_taken", ",", "self", ".", "n_agents", ",", "self", ".", "args", ".", "gamma", ",", "self", ".", "args", ".", "td_lambda", ")", "\n", "\n", "q_vals", "=", "th", ".", "zeros_like", "(", "target_q_vals", ")", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "running_log", "=", "{", "\n", "\"critic_loss\"", ":", "[", "]", ",", "\n", "\"critic_grad_norm\"", ":", "[", "]", ",", "\n", "\"td_error_abs\"", ":", "[", "]", ",", "\n", "\"target_mean\"", ":", "[", "]", ",", "\n", "\"q_taken_mean\"", ":", "[", "]", ",", "\n", "}", "\n", "\n", "for", "t", "in", "reversed", "(", "range", "(", "rewards", ".", "size", "(", "1", ")", ")", ")", ":", "\n", "            ", "mask_t", "=", "mask", "[", ":", ",", "t", "]", ".", "expand", "(", "-", "1", ",", "self", ".", "n_agents", ")", "\n", "if", "mask_t", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "q_t", "=", "self", ".", "critic", "(", "batch", ",", "t", ")", "\n", "q_vals", "[", ":", ",", "t", "]", "=", "q_t", ".", "view", "(", "bs", ",", "self", ".", "n_agents", ",", "self", ".", "n_actions", ")", "\n", "q_taken", "=", "th", ".", "gather", "(", "q_t", ",", "dim", "=", "3", ",", "index", "=", "actions", "[", ":", ",", "t", ":", "t", "+", "1", "]", ")", ".", "squeeze", "(", "3", ")", ".", "squeeze", "(", "1", ")", "\n", "targets_t", "=", "targets", "[", ":", ",", "t", "]", "\n", "td_error", "=", "(", "q_taken", "-", "targets_t", ".", "detach", "(", ")", ")", "\n", "\n", "# 0-out the targets that came from padded data", "\n", "masked_td_error", "=", "td_error", "*", "mask_t", "\n", "\n", "# Normal L2 loss, take mean over actual data", "\n", "loss", "=", "(", "masked_td_error", "**", "2", ")", ".", "sum", "(", ")", "/", "mask_t", ".", "sum", "(", ")", "\n", "self", ".", "critic_optimiser", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "th", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "critic_params", ",", "self", ".", "args", ".", "grad_norm_clip", ")", "\n", "self", ".", "critic_optimiser", ".", "step", "(", ")", "\n", "self", ".", "critic_training_steps", "+=", "1", "\n", "\n", "running_log", "[", "\"critic_loss\"", "]", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "running_log", "[", "\"critic_grad_norm\"", "]", ".", "append", "(", "grad_norm", ")", "\n", "mask_elems", "=", "mask_t", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "running_log", "[", "\"td_error_abs\"", "]", ".", "append", "(", "(", "masked_td_error", ".", "abs", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", ")", "\n", "running_log", "[", "\"q_taken_mean\"", "]", ".", "append", "(", "(", "q_taken", "*", "mask_t", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", "\n", "running_log", "[", "\"target_mean\"", "]", ".", "append", "(", "(", "targets_t", "*", "mask_t", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", "\n", "\n", "", "return", "q_vals", ",", "running_log", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.coma_learner.COMALearner._update_targets": [[149, 152], ["coma_learner.COMALearner.target_critic.load_state_dict", "coma_learner.COMALearner.logger.console_logger.info", "coma_learner.COMALearner.critic.state_dict"], "methods", ["None"], ["", "def", "_update_targets", "(", "self", ")", ":", "\n", "        ", "self", ".", "target_critic", ".", "load_state_dict", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "logger", ".", "console_logger", ".", "info", "(", "\"Updated target network\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.coma_learner.COMALearner.cuda": [[153, 157], ["coma_learner.COMALearner.mac.cuda", "coma_learner.COMALearner.critic.cuda", "coma_learner.COMALearner.target_critic.cuda"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "mac", ".", "cuda", "(", ")", "\n", "self", ".", "critic", ".", "cuda", "(", ")", "\n", "self", ".", "target_critic", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.coma_learner.COMALearner.save_models": [[158, 163], ["coma_learner.COMALearner.mac.save_models", "torch.save", "torch.save", "torch.save", "coma_learner.COMALearner.critic.state_dict", "coma_learner.COMALearner.agent_optimiser.state_dict", "coma_learner.COMALearner.critic_optimiser.state_dict"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.save_models"], ["", "def", "save_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "save_models", "(", "path", ")", "\n", "th", ".", "save", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ",", "\"{}/critic.th\"", ".", "format", "(", "path", ")", ")", "\n", "th", ".", "save", "(", "self", ".", "agent_optimiser", ".", "state_dict", "(", ")", ",", "\"{}/agent_opt.th\"", ".", "format", "(", "path", ")", ")", "\n", "th", ".", "save", "(", "self", ".", "critic_optimiser", ".", "state_dict", "(", ")", ",", "\"{}/critic_opt.th\"", ".", "format", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.coma_learner.COMALearner.load_models": [[164, 171], ["coma_learner.COMALearner.mac.load_models", "coma_learner.COMALearner.critic.load_state_dict", "coma_learner.COMALearner.target_critic.load_state_dict", "coma_learner.COMALearner.agent_optimiser.load_state_dict", "coma_learner.COMALearner.critic_optimiser.load_state_dict", "torch.load", "coma_learner.COMALearner.critic.state_dict", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_models"], ["", "def", "load_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "load_models", "(", "path", ")", "\n", "self", ".", "critic", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/critic.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "# Not quite right but I don't want to save target networks", "\n", "self", ".", "target_critic", ".", "load_state_dict", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "agent_optimiser", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/agent_opt.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "self", ".", "critic_optimiser", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/critic_opt.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.qtran_learner.QLearner.__init__": [[9, 33], ["list", "list", "copy.deepcopy", "torch.optim.RMSprop", "copy.deepcopy", "mac.parameters", "modules.mixers.qtran.QTranBase", "qtran_learner.QLearner.mixer.parameters", "Exception"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters"], ["    ", "def", "__init__", "(", "self", ",", "mac", ",", "scheme", ",", "logger", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "mac", "=", "mac", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "self", ".", "params", "=", "list", "(", "mac", ".", "parameters", "(", ")", ")", "\n", "\n", "self", ".", "last_target_update_episode", "=", "0", "\n", "\n", "self", ".", "mixer", "=", "None", "\n", "if", "args", ".", "mixer", "==", "\"qtran_base\"", ":", "\n", "            ", "self", ".", "mixer", "=", "QTranBase", "(", "args", ")", "\n", "", "elif", "args", ".", "mixer", "==", "\"qtran_alt\"", ":", "\n", "            ", "raise", "Exception", "(", "\"Not implemented here!\"", ")", "\n", "\n", "", "self", ".", "params", "+=", "list", "(", "self", ".", "mixer", ".", "parameters", "(", ")", ")", "\n", "self", ".", "target_mixer", "=", "copy", ".", "deepcopy", "(", "self", ".", "mixer", ")", "\n", "\n", "self", ".", "optimiser", "=", "RMSprop", "(", "params", "=", "self", ".", "params", ",", "lr", "=", "args", ".", "lr", ",", "alpha", "=", "args", ".", "optim_alpha", ",", "eps", "=", "args", ".", "optim_eps", ")", "\n", "\n", "# a little wasteful to deepcopy (e.g. duplicates action selector), but should work for any MAC", "\n", "self", ".", "target_mac", "=", "copy", ".", "deepcopy", "(", "mac", ")", "\n", "\n", "self", ".", "log_stats_t", "=", "-", "self", ".", "args", ".", "learner_log_interval", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.qtran_learner.QLearner.train": [[34, 154], ["[].float", "[].float", "qtran_learner.QLearner.mac.init_hidden", "range", "torch.stack", "torch.stack", "mac_hidden_states.reshape().transpose.reshape().transpose.reshape().transpose", "torch.gather().squeeze", "qtran_learner.QLearner.target_mac.init_hidden", "range", "torch.stack", "torch.stack", "target_mac_hidden_states.reshape().transpose.reshape().transpose.reshape().transpose", "torch.stack.clone", "mac_out_maxs[].max", "qtran_learner.QLearner.optimiser.zero_grad", "loss.backward", "torch.nn.utils.clip_grad_norm_", "qtran_learner.QLearner.optimiser.step", "qtran_learner.QLearner.mac.forward", "torch.stack.append", "mac_hidden_states.reshape().transpose.reshape().transpose.append", "qtran_learner.QLearner.target_mac.forward", "torch.stack.append", "target_mac_hidden_states.reshape().transpose.reshape().transpose.append", "torch.stack.max", "qtran_learner.QLearner.mixer", "qtran_learner.QLearner.target_mixer", "qtran_learner.QLearner.mixer", "nopt_values.clamp", "qtran_learner.QLearner._update_targets", "qtran_learner.QLearner.logger.log_stat", "qtran_learner.QLearner.logger.log_stat", "qtran_learner.QLearner.logger.log_stat", "qtran_learner.QLearner.logger.log_stat", "qtran_learner.QLearner.logger.log_stat", "mac_hidden_states.reshape().transpose.reshape().transpose.reshape", "torch.gather", "target_mac_hidden_states.reshape().transpose.reshape().transpose.reshape", "torch.zeros", "torch.zeros.scatter", "torch.zeros", "torch.zeros.scatter", "rewards.reshape", "td_targets.detach", "[].float.reshape", "[].float.sum", "torch.zeros", "torch.zeros.scatter", "[].float.reshape", "[].float.sum", "[].float.reshape", "[].float.sum", "Exception", "loss.item", "td_loss.item", "opt_loss.item", "nopt_loss.item", "[].float.sum().item", "qtran_learner.QLearner.logger.log_stat", "qtran_learner.QLearner.logger.log_stat", "qtran_learner.QLearner.logger.log_stat", "qtran_learner.QLearner.logger.log_stat", "qtran_learner.QLearner.logger.log_stat", "max_actions_qvals[].sum().reshape", "max_joint_qs.detach", "torch.gather().squeeze.sum().reshape", "joint_qs.detach", "[].float.sum", "masked_td_error.abs().sum().item", "masked_td_error.sum().item", "joint_qs.sum().item", "vs.sum().item", "[].float.reshape", "max_actions_qvals[].sum", "torch.gather().squeeze.sum", "masked_td_error.abs().sum", "masked_td_error.sum", "joint_qs.sum", "vs.sum", "masked_td_error.abs"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.forward", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.forward", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner._update_targets", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat"], ["", "def", "train", "(", "self", ",", "batch", ":", "EpisodeBatch", ",", "t_env", ":", "int", ",", "episode_num", ":", "int", ")", ":", "\n", "# Get the relevant quantities", "\n", "        ", "rewards", "=", "batch", "[", "\"reward\"", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "actions", "=", "batch", "[", "\"actions\"", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "terminated", "=", "batch", "[", "\"terminated\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "=", "batch", "[", "\"filled\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "[", ":", ",", "1", ":", "]", "=", "mask", "[", ":", ",", "1", ":", "]", "*", "(", "1", "-", "terminated", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "avail_actions", "=", "batch", "[", "\"avail_actions\"", "]", "\n", "\n", "# Calculate estimated Q-Values", "\n", "mac_out", "=", "[", "]", "\n", "mac_hidden_states", "=", "[", "]", "\n", "self", ".", "mac", ".", "init_hidden", "(", "batch", ".", "batch_size", ")", "\n", "for", "t", "in", "range", "(", "batch", ".", "max_seq_length", ")", ":", "\n", "            ", "agent_outs", "=", "self", ".", "mac", ".", "forward", "(", "batch", ",", "t", "=", "t", ")", "\n", "mac_out", ".", "append", "(", "agent_outs", ")", "\n", "mac_hidden_states", ".", "append", "(", "self", ".", "mac", ".", "hidden_states", ")", "\n", "", "mac_out", "=", "th", ".", "stack", "(", "mac_out", ",", "dim", "=", "1", ")", "# Concat over time", "\n", "mac_hidden_states", "=", "th", ".", "stack", "(", "mac_hidden_states", ",", "dim", "=", "1", ")", "\n", "mac_hidden_states", "=", "mac_hidden_states", ".", "reshape", "(", "batch", ".", "batch_size", ",", "self", ".", "args", ".", "n_agents", ",", "batch", ".", "max_seq_length", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "#btav", "\n", "\n", "# Pick the Q-Values for the actions taken by each agent", "\n", "chosen_action_qvals", "=", "th", ".", "gather", "(", "mac_out", "[", ":", ",", ":", "-", "1", "]", ",", "dim", "=", "3", ",", "index", "=", "actions", ")", ".", "squeeze", "(", "3", ")", "# Remove the last dim", "\n", "\n", "# Calculate the Q-Values necessary for the target", "\n", "target_mac_out", "=", "[", "]", "\n", "target_mac_hidden_states", "=", "[", "]", "\n", "self", ".", "target_mac", ".", "init_hidden", "(", "batch", ".", "batch_size", ")", "\n", "for", "t", "in", "range", "(", "batch", ".", "max_seq_length", ")", ":", "\n", "            ", "target_agent_outs", "=", "self", ".", "target_mac", ".", "forward", "(", "batch", ",", "t", "=", "t", ")", "\n", "target_mac_out", ".", "append", "(", "target_agent_outs", ")", "\n", "target_mac_hidden_states", ".", "append", "(", "self", ".", "target_mac", ".", "hidden_states", ")", "\n", "\n", "# We don't need the first timesteps Q-Value estimate for calculating targets", "\n", "", "target_mac_out", "=", "th", ".", "stack", "(", "target_mac_out", "[", ":", "]", ",", "dim", "=", "1", ")", "# Concat across time", "\n", "target_mac_hidden_states", "=", "th", ".", "stack", "(", "target_mac_hidden_states", ",", "dim", "=", "1", ")", "\n", "target_mac_hidden_states", "=", "target_mac_hidden_states", ".", "reshape", "(", "batch", ".", "batch_size", ",", "self", ".", "args", ".", "n_agents", ",", "batch", ".", "max_seq_length", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "#btav", "\n", "\n", "# Mask out unavailable actions", "\n", "target_mac_out", "[", "avail_actions", "[", ":", ",", ":", "]", "==", "0", "]", "=", "-", "9999999", "# From OG deepmarl", "\n", "mac_out_maxs", "=", "mac_out", ".", "clone", "(", ")", "\n", "mac_out_maxs", "[", "avail_actions", "==", "0", "]", "=", "-", "9999999", "\n", "\n", "# Best joint action computed by target agents", "\n", "target_max_actions", "=", "target_mac_out", ".", "max", "(", "dim", "=", "3", ",", "keepdim", "=", "True", ")", "[", "1", "]", "\n", "# Best joint-action computed by regular agents", "\n", "max_actions_qvals", ",", "max_actions_current", "=", "mac_out_maxs", "[", ":", ",", ":", "]", ".", "max", "(", "dim", "=", "3", ",", "keepdim", "=", "True", ")", "\n", "\n", "if", "self", ".", "args", ".", "mixer", "==", "\"qtran_base\"", ":", "\n", "# -- TD Loss --", "\n", "# Joint-action Q-Value estimates", "\n", "            ", "joint_qs", ",", "vs", "=", "self", ".", "mixer", "(", "batch", "[", ":", ",", ":", "-", "1", "]", ",", "mac_hidden_states", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "\n", "# Need to argmax across the target agents' actions to compute target joint-action Q-Values", "\n", "if", "self", ".", "args", ".", "double_q", ":", "\n", "                ", "max_actions_current_", "=", "th", ".", "zeros", "(", "size", "=", "(", "batch", ".", "batch_size", ",", "batch", ".", "max_seq_length", ",", "self", ".", "args", ".", "n_agents", ",", "self", ".", "args", ".", "n_actions", ")", ",", "device", "=", "batch", ".", "device", ")", "\n", "max_actions_current_onehot", "=", "max_actions_current_", ".", "scatter", "(", "3", ",", "max_actions_current", "[", ":", ",", ":", "]", ",", "1", ")", "\n", "max_actions_onehot", "=", "max_actions_current_onehot", "\n", "", "else", ":", "\n", "                ", "max_actions", "=", "th", ".", "zeros", "(", "size", "=", "(", "batch", ".", "batch_size", ",", "batch", ".", "max_seq_length", ",", "self", ".", "args", ".", "n_agents", ",", "self", ".", "args", ".", "n_actions", ")", ",", "device", "=", "batch", ".", "device", ")", "\n", "max_actions_onehot", "=", "max_actions", ".", "scatter", "(", "3", ",", "target_max_actions", "[", ":", ",", ":", "]", ",", "1", ")", "\n", "", "target_joint_qs", ",", "target_vs", "=", "self", ".", "target_mixer", "(", "batch", "[", ":", ",", "1", ":", "]", ",", "hidden_states", "=", "target_mac_hidden_states", "[", ":", ",", "1", ":", "]", ",", "actions", "=", "max_actions_onehot", "[", ":", ",", "1", ":", "]", ")", "\n", "\n", "# Td loss targets", "\n", "td_targets", "=", "rewards", ".", "reshape", "(", "-", "1", ",", "1", ")", "+", "self", ".", "args", ".", "gamma", "*", "(", "1", "-", "terminated", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", "*", "target_joint_qs", "\n", "td_error", "=", "(", "joint_qs", "-", "td_targets", ".", "detach", "(", ")", ")", "\n", "masked_td_error", "=", "td_error", "*", "mask", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "td_loss", "=", "(", "masked_td_error", "**", "2", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "# -- TD Loss --", "\n", "\n", "# -- Opt Loss --", "\n", "# Argmax across the current agents' actions", "\n", "if", "not", "self", ".", "args", ".", "double_q", ":", "# Already computed if we're doing double Q-Learning", "\n", "                ", "max_actions_current_", "=", "th", ".", "zeros", "(", "size", "=", "(", "batch", ".", "batch_size", ",", "batch", ".", "max_seq_length", ",", "self", ".", "args", ".", "n_agents", ",", "self", ".", "args", ".", "n_actions", ")", ",", "device", "=", "batch", ".", "device", ")", "\n", "max_actions_current_onehot", "=", "max_actions_current_", ".", "scatter", "(", "3", ",", "max_actions_current", "[", ":", ",", ":", "]", ",", "1", ")", "\n", "", "max_joint_qs", ",", "_", "=", "self", ".", "mixer", "(", "batch", "[", ":", ",", ":", "-", "1", "]", ",", "mac_hidden_states", "[", ":", ",", ":", "-", "1", "]", ",", "actions", "=", "max_actions_current_onehot", "[", ":", ",", ":", "-", "1", "]", ")", "# Don't use the target network and target agent max actions as per author's email", "\n", "\n", "# max_actions_qvals = th.gather(mac_out[:, :-1], dim=3, index=max_actions_current[:,:-1])", "\n", "opt_error", "=", "max_actions_qvals", "[", ":", ",", ":", "-", "1", "]", ".", "sum", "(", "dim", "=", "2", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "-", "max_joint_qs", ".", "detach", "(", ")", "+", "vs", "\n", "masked_opt_error", "=", "opt_error", "*", "mask", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "opt_loss", "=", "(", "masked_opt_error", "**", "2", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "# -- Opt Loss --", "\n", "\n", "# -- Nopt Loss --", "\n", "# target_joint_qs, _ = self.target_mixer(batch[:, :-1])", "\n", "nopt_values", "=", "chosen_action_qvals", ".", "sum", "(", "dim", "=", "2", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "-", "joint_qs", ".", "detach", "(", ")", "+", "vs", "# Don't use target networks here either", "\n", "nopt_error", "=", "nopt_values", ".", "clamp", "(", "max", "=", "0", ")", "\n", "masked_nopt_error", "=", "nopt_error", "*", "mask", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "nopt_loss", "=", "(", "masked_nopt_error", "**", "2", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "# -- Nopt loss --", "\n", "\n", "", "elif", "self", ".", "args", ".", "mixer", "==", "\"qtran_alt\"", ":", "\n", "            ", "raise", "Exception", "(", "\"Not supported yet.\"", ")", "\n", "\n", "", "loss", "=", "td_loss", "+", "self", ".", "args", ".", "opt_loss", "*", "opt_loss", "+", "self", ".", "args", ".", "nopt_min_loss", "*", "nopt_loss", "\n", "\n", "# Optimise", "\n", "self", ".", "optimiser", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "th", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "params", ",", "self", ".", "args", ".", "grad_norm_clip", ")", "\n", "self", ".", "optimiser", ".", "step", "(", ")", "\n", "\n", "if", "(", "episode_num", "-", "self", ".", "last_target_update_episode", ")", "/", "self", ".", "args", ".", "target_update_interval", ">=", "1.0", ":", "\n", "            ", "self", ".", "_update_targets", "(", ")", "\n", "self", ".", "last_target_update_episode", "=", "episode_num", "\n", "\n", "", "if", "t_env", "-", "self", ".", "log_stats_t", ">=", "self", ".", "args", ".", "learner_log_interval", ":", "\n", "            ", "self", ".", "logger", ".", "log_stat", "(", "\"loss\"", ",", "loss", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"td_loss\"", ",", "td_loss", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"opt_loss\"", ",", "opt_loss", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"nopt_loss\"", ",", "nopt_loss", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"grad_norm\"", ",", "grad_norm", ",", "t_env", ")", "\n", "if", "self", ".", "args", ".", "mixer", "==", "\"qtran_base\"", ":", "\n", "                ", "mask_elems", "=", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"td_error_abs\"", ",", "(", "masked_td_error", ".", "abs", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"td_targets\"", ",", "(", "(", "masked_td_error", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"td_chosen_qs\"", ",", "(", "joint_qs", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"v_mean\"", ",", "(", "vs", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"agent_indiv_qs\"", ",", "(", "(", "chosen_action_qvals", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "(", "mask_elems", "*", "self", ".", "args", ".", "n_agents", ")", ")", ",", "t_env", ")", "\n", "", "self", ".", "log_stats_t", "=", "t_env", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.qtran_learner.QLearner._update_targets": [[155, 160], ["qtran_learner.QLearner.target_mac.load_state", "qtran_learner.QLearner.logger.console_logger.info", "qtran_learner.QLearner.target_mixer.load_state_dict", "qtran_learner.QLearner.mixer.state_dict"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_state"], ["", "", "def", "_update_targets", "(", "self", ")", ":", "\n", "        ", "self", ".", "target_mac", ".", "load_state", "(", "self", ".", "mac", ")", "\n", "if", "self", ".", "mixer", "is", "not", "None", ":", "\n", "            ", "self", ".", "target_mixer", ".", "load_state_dict", "(", "self", ".", "mixer", ".", "state_dict", "(", ")", ")", "\n", "", "self", ".", "logger", ".", "console_logger", ".", "info", "(", "\"Updated target network\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.qtran_learner.QLearner.cuda": [[161, 167], ["qtran_learner.QLearner.mac.cuda", "qtran_learner.QLearner.target_mac.cuda", "qtran_learner.QLearner.mixer.cuda", "qtran_learner.QLearner.target_mixer.cuda"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "mac", ".", "cuda", "(", ")", "\n", "self", ".", "target_mac", ".", "cuda", "(", ")", "\n", "if", "self", ".", "mixer", "is", "not", "None", ":", "\n", "            ", "self", ".", "mixer", ".", "cuda", "(", ")", "\n", "self", ".", "target_mixer", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.qtran_learner.QLearner.save_models": [[168, 173], ["qtran_learner.QLearner.mac.save_models", "torch.save", "torch.save", "qtran_learner.QLearner.optimiser.state_dict", "qtran_learner.QLearner.mixer.state_dict"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.save_models"], ["", "", "def", "save_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "save_models", "(", "path", ")", "\n", "if", "self", ".", "mixer", "is", "not", "None", ":", "\n", "            ", "th", ".", "save", "(", "self", ".", "mixer", ".", "state_dict", "(", ")", ",", "\"{}/mixer.th\"", ".", "format", "(", "path", ")", ")", "\n", "", "th", ".", "save", "(", "self", ".", "optimiser", ".", "state_dict", "(", ")", ",", "\"{}/opt.th\"", ".", "format", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.qtran_learner.QLearner.load_models": [[174, 181], ["qtran_learner.QLearner.mac.load_models", "qtran_learner.QLearner.target_mac.load_models", "qtran_learner.QLearner.optimiser.load_state_dict", "qtran_learner.QLearner.mixer.load_state_dict", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_models", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_models"], ["", "def", "load_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "load_models", "(", "path", ")", "\n", "# Not quite right but I don't want to save target networks", "\n", "self", ".", "target_mac", ".", "load_models", "(", "path", ")", "\n", "if", "self", ".", "mixer", "is", "not", "None", ":", "\n", "            ", "self", ".", "mixer", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/mixer.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "", "self", ".", "optimiser", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/opt.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v1.PGLearner_v1.__init__": [[14, 40], ["copy.deepcopy", "list", "list", "torch.optim.RMSprop", "torch.optim.RMSprop", "modules.critics.coma.COMACritic", "mac.parameters", "policy_gradient_v1.PGLearner_v1.critic.parameters", "modules.critics.iac_critic.IACritic", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters"], ["    ", "def", "__init__", "(", "self", ",", "mac", ",", "scheme", ",", "logger", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "self", ".", "n_actions", "=", "args", ".", "n_actions", "\n", "self", ".", "mac", "=", "mac", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "self", ".", "last_target_update_step", "=", "0", "\n", "self", ".", "critic_training_steps", "=", "0", "\n", "\n", "self", ".", "log_stats_t", "=", "-", "self", ".", "args", ".", "learner_log_interval", "-", "1", "\n", "\n", "if", "self", ".", "args", ".", "critic", "==", "'coma'", ":", "\n", "            ", "self", ".", "critic", "=", "COMACritic", "(", "scheme", ",", "args", ")", "\n", "", "elif", "self", ".", "args", ".", "critic", "==", "'iac_critic'", ":", "\n", "            ", "self", ".", "critic", "=", "IACritic", "(", "scheme", ",", "args", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"{} is not implemented\"", ".", "format", "(", "self", ".", "args", ".", "critic", ")", ")", "\n", "", "self", ".", "target_critic", "=", "copy", ".", "deepcopy", "(", "self", ".", "critic", ")", "\n", "\n", "self", ".", "agent_params", "=", "list", "(", "mac", ".", "parameters", "(", ")", ")", "\n", "self", ".", "critic_params", "=", "list", "(", "self", ".", "critic", ".", "parameters", "(", ")", ")", "\n", "self", ".", "params", "=", "self", ".", "agent_params", "+", "self", ".", "critic_params", "\n", "\n", "self", ".", "agent_optimiser", "=", "RMSprop", "(", "params", "=", "self", ".", "agent_params", ",", "lr", "=", "args", ".", "lr", ",", "alpha", "=", "args", ".", "optim_alpha", ",", "eps", "=", "args", ".", "optim_eps", ")", "\n", "self", ".", "critic_optimiser", "=", "RMSprop", "(", "params", "=", "self", ".", "critic_params", ",", "lr", "=", "args", ".", "critic_lr", ",", "alpha", "=", "args", ".", "optim_alpha", ",", "eps", "=", "args", ".", "optim_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v1.PGLearner_v1.train": [[41, 116], ["[].float", "[].float", "mask.repeat().view.repeat().view.clone", "mask.repeat().view.repeat().view.repeat().view", "policy_gradient_v1.PGLearner_v1._train_critic", "policy_gradient_v1.PGLearner_v1.mac.init_hidden", "range", "torch.stack", "policy_gradient_v1.PGLearner_v1.agent_optimiser.zero_grad", "coma_loss.backward", "torch.nn.utils.clip_grad_norm_", "policy_gradient_v1.PGLearner_v1.agent_optimiser.step", "policy_gradient_v1.PGLearner_v1.mac.forward", "torch.stack.append", "torch.stack.sum", "q_vals.reshape.reshape.reshape", "torch.stack.view", "torch.gather().squeeze", "torch.gather().squeeze", "torch.log", "torch.stack.view", "torch.gather().squeeze", "torch.log", "q_vals.reshape.reshape.reshape", "q_vals.reshape.reshape.detach", "mask.repeat().view.repeat().view.sum", "policy_gradient_v1.PGLearner_v1._update_targets", "len", "policy_gradient_v1.PGLearner_v1.logger.log_stat", "policy_gradient_v1.PGLearner_v1.logger.log_stat", "policy_gradient_v1.PGLearner_v1.logger.log_stat", "policy_gradient_v1.PGLearner_v1.logger.log_stat", "mask.repeat().view.repeat().view.repeat", "policy_gradient_v1.PGLearner_v1.logger.log_stat", "coma_loss.item", "torch.gather", "torch.gather", "torch.gather", "mask.repeat().view.repeat().view.sum().item", "mask.repeat().view.repeat().view.sum().item", "sum", "actions.reshape", "actions.reshape", "actions.reshape", "mask.repeat().view.repeat().view.sum", "mask.repeat().view.repeat().view.sum", "th.stack.view.max"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v3.PGLearner_v3._train_critic", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.forward", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner._update_targets", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat"], ["", "def", "train", "(", "self", ",", "batch", ":", "EpisodeBatch", ",", "t_env", ":", "int", ",", "episode_num", ":", "int", ")", ":", "\n", "# Get the relevant quantities", "\n", "        ", "bs", "=", "batch", ".", "batch_size", "\n", "max_t", "=", "batch", ".", "max_seq_length", "\n", "rewards", "=", "batch", "[", "\"reward\"", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "actions", "=", "batch", "[", "\"actions\"", "]", "[", ":", ",", ":", "]", "\n", "terminated", "=", "batch", "[", "\"terminated\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "=", "batch", "[", "\"filled\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "[", ":", ",", "1", ":", "]", "=", "mask", "[", ":", ",", "1", ":", "]", "*", "(", "1", "-", "terminated", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "avail_actions", "=", "batch", "[", "\"avail_actions\"", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "critic_mask", "=", "mask", ".", "clone", "(", ")", "\n", "\n", "mask", "=", "mask", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "q_vals", ",", "critic_train_stats", "=", "self", ".", "_train_critic", "(", "batch", ",", "rewards", ",", "terminated", ",", "actions", ",", "avail_actions", ",", "\n", "critic_mask", ",", "bs", ",", "max_t", ")", "\n", "\n", "actions", "=", "actions", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "mac_out", "=", "[", "]", "\n", "self", ".", "mac", ".", "init_hidden", "(", "batch", ".", "batch_size", ")", "\n", "for", "t", "in", "range", "(", "batch", ".", "max_seq_length", "-", "1", ")", ":", "\n", "            ", "agent_outs", "=", "self", ".", "mac", ".", "forward", "(", "batch", ",", "t", "=", "t", ")", "\n", "mac_out", ".", "append", "(", "agent_outs", ")", "\n", "", "mac_out", "=", "th", ".", "stack", "(", "mac_out", ",", "dim", "=", "1", ")", "# Concat over time", "\n", "\n", "# Mask out unavailable actions, renormalise (as in action selection)", "\n", "mac_out", "[", "avail_actions", "==", "0", "]", "=", "0", "\n", "mac_out", "=", "mac_out", "/", "mac_out", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "mac_out", "[", "avail_actions", "==", "0", "]", "=", "0", "\n", "\n", "if", "self", ".", "args", ".", "critic", "==", "'coma'", ":", "\n", "# Calculated baseline", "\n", "            ", "q_vals", "=", "q_vals", ".", "reshape", "(", "-", "1", ",", "self", ".", "n_actions", ")", "\n", "pi", "=", "mac_out", ".", "view", "(", "-", "1", ",", "self", ".", "n_actions", ")", "\n", "baseline", "=", "(", "pi", "*", "q_vals", ")", ".", "sum", "(", "-", "1", ")", ".", "detach", "(", ")", "\n", "\n", "# Calculate policy grad with mask", "\n", "q_taken", "=", "th", ".", "gather", "(", "q_vals", ",", "dim", "=", "1", ",", "index", "=", "actions", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "pi_taken", "=", "th", ".", "gather", "(", "pi", ",", "dim", "=", "1", ",", "index", "=", "actions", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "pi_taken", "[", "mask", "==", "0", "]", "=", "1.0", "\n", "log_pi_taken", "=", "th", ".", "log", "(", "pi_taken", ")", "\n", "\n", "advantages", "=", "(", "q_taken", "-", "baseline", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "pi", "=", "mac_out", ".", "view", "(", "-", "1", ",", "self", ".", "n_actions", ")", "\n", "pi_taken", "=", "th", ".", "gather", "(", "pi", ",", "dim", "=", "1", ",", "index", "=", "actions", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "pi_taken", "[", "mask", "==", "0", "]", "=", "1.0", "\n", "log_pi_taken", "=", "th", ".", "log", "(", "pi_taken", ")", "\n", "q_taken", "=", "q_vals", ".", "reshape", "(", "-", "1", ")", "\n", "advantages", "=", "q_taken", ".", "detach", "(", ")", "\n", "\n", "", "coma_loss", "=", "-", "(", "(", "advantages", "*", "log_pi_taken", ")", "*", "mask", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "\n", "# Optimise agents", "\n", "self", ".", "agent_optimiser", ".", "zero_grad", "(", ")", "\n", "coma_loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "th", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "agent_params", ",", "self", ".", "args", ".", "grad_norm_clip", ")", "\n", "self", ".", "agent_optimiser", ".", "step", "(", ")", "\n", "\n", "if", "(", "self", ".", "critic_training_steps", "-", "self", ".", "last_target_update_step", ")", "/", "self", ".", "args", ".", "target_update_interval", ">=", "1.0", ":", "\n", "            ", "self", ".", "_update_targets", "(", ")", "\n", "self", ".", "last_target_update_step", "=", "self", ".", "critic_training_steps", "\n", "\n", "", "if", "t_env", "-", "self", ".", "log_stats_t", ">=", "self", ".", "args", ".", "learner_log_interval", ":", "\n", "            ", "ts_logged", "=", "len", "(", "critic_train_stats", "[", "\"critic_loss\"", "]", ")", "\n", "for", "key", "in", "[", "\"critic_loss\"", ",", "\"critic_grad_norm\"", ",", "\"td_error_abs\"", ",", "\"q_taken_mean\"", ",", "\"target_mean\"", "]", ":", "\n", "                ", "self", ".", "logger", ".", "log_stat", "(", "key", ",", "sum", "(", "critic_train_stats", "[", "key", "]", ")", "/", "ts_logged", ",", "t_env", ")", "\n", "\n", "", "self", ".", "logger", ".", "log_stat", "(", "\"advantage_mean\"", ",", "(", "advantages", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"coma_loss\"", ",", "coma_loss", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"agent_grad_norm\"", ",", "grad_norm", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"pi_max\"", ",", "(", "pi", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "log_stats_t", "=", "t_env", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v1.PGLearner_v1._train_critic": [[117, 178], ["build_td_lambda_targets", "reversed", "policy_gradient_v1.PGLearner_v1.target_critic", "torch.gather().squeeze", "target_q_vals.squeeze", "torch.zeros_like", "range", "mask[].expand", "policy_gradient_v1.PGLearner_v1.critic", "policy_gradient_v1.PGLearner_v1.critic_optimiser.zero_grad", "loss.backward", "torch.nn.utils.clip_grad_norm_", "policy_gradient_v1.PGLearner_v1.critic_optimiser.step", "running_log[].append", "running_log[].append", "mask[].expand.sum().item", "running_log[].append", "running_log[].append", "running_log[].append", "rewards.size", "mask[].expand.sum", "policy_gradient_v1.PGLearner_v1.view", "torch.gather().squeeze().squeeze", "targets_t.detach", "mask[].expand.sum", "loss.item", "torch.gather", "policy_gradient_v1.PGLearner_v1.view", "policy_gradient_v1.PGLearner_v1.squeeze().squeeze", "ValueError", "mask[].expand.sum", "masked_td_error.abs().sum().item", "torch.gather().squeeze", "policy_gradient_v1.PGLearner_v1.squeeze", "masked_td_error.abs().sum", "torch.gather", "masked_td_error.abs"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.build_td_lambda_targets", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step"], ["", "", "def", "_train_critic", "(", "self", ",", "batch", ",", "rewards", ",", "terminated", ",", "actions", ",", "avail_actions", ",", "mask", ",", "bs", ",", "max_t", ")", ":", "\n", "# Optimise critic", "\n", "        ", "target_q_vals", "=", "self", ".", "target_critic", "(", "batch", ")", "[", ":", ",", ":", "]", "\n", "if", "self", ".", "args", ".", "critic", "==", "'coma'", ":", "\n", "            ", "targets_taken", "=", "th", ".", "gather", "(", "target_q_vals", ",", "dim", "=", "3", ",", "index", "=", "actions", ")", ".", "squeeze", "(", "3", ")", "\n", "", "else", ":", "\n", "            ", "targets_taken", "=", "target_q_vals", ".", "squeeze", "(", "3", ")", "\n", "\n", "# Calculate td-lambda targets", "\n", "", "targets", "=", "build_td_lambda_targets", "(", "rewards", ",", "terminated", ",", "mask", ",", "targets_taken", ",", "self", ".", "n_agents", ",", "self", ".", "args", ".", "gamma", ",", "self", ".", "args", ".", "td_lambda", ")", "\n", "\n", "q_vals", "=", "th", ".", "zeros_like", "(", "target_q_vals", ")", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "running_log", "=", "{", "\n", "\"critic_loss\"", ":", "[", "]", ",", "\n", "\"critic_grad_norm\"", ":", "[", "]", ",", "\n", "\"td_error_abs\"", ":", "[", "]", ",", "\n", "\"target_mean\"", ":", "[", "]", ",", "\n", "\"q_taken_mean\"", ":", "[", "]", ",", "\n", "}", "\n", "\n", "for", "t", "in", "reversed", "(", "range", "(", "rewards", ".", "size", "(", "1", ")", ")", ")", ":", "\n", "            ", "mask_t", "=", "mask", "[", ":", ",", "t", "]", ".", "expand", "(", "-", "1", ",", "self", ".", "n_agents", ")", "\n", "if", "mask_t", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "q_t", "=", "self", ".", "critic", "(", "batch", ",", "t", ")", "\n", "if", "self", ".", "args", ".", "critic", "==", "'coma'", ":", "\n", "# coma critic output [bs, 1, n_agents, n_actions]", "\n", "                ", "q_vals", "[", ":", ",", "t", "]", "=", "q_t", ".", "view", "(", "bs", ",", "self", ".", "n_agents", ",", "self", ".", "n_actions", ")", "\n", "q_taken", "=", "th", ".", "gather", "(", "q_t", ",", "dim", "=", "3", ",", "index", "=", "actions", "[", ":", ",", "t", ":", "t", "+", "1", "]", ")", ".", "squeeze", "(", "3", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "", "elif", "self", ".", "args", ".", "critic", "==", "'iac_critic'", ":", "\n", "# iac_critic output [bs, 1, n_agents, 1]", "\n", "                ", "q_vals", "[", ":", ",", "t", "]", "=", "q_t", ".", "view", "(", "bs", ",", "self", ".", "n_agents", ",", "1", ")", "\n", "q_taken", "=", "q_t", ".", "squeeze", "(", "3", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"{} is not implemented\"", ".", "format", "(", "self", ".", "args", ".", "critic", ")", ")", "\n", "\n", "", "targets_t", "=", "targets", "[", ":", ",", "t", "]", "\n", "td_error", "=", "(", "q_taken", "-", "targets_t", ".", "detach", "(", ")", ")", "\n", "\n", "# 0-out the targets that came from padded data", "\n", "masked_td_error", "=", "td_error", "*", "mask_t", "\n", "\n", "# Normal L2 loss, take mean over actual data", "\n", "loss", "=", "(", "masked_td_error", "**", "2", ")", ".", "sum", "(", ")", "/", "mask_t", ".", "sum", "(", ")", "\n", "self", ".", "critic_optimiser", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "th", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "critic_params", ",", "self", ".", "args", ".", "grad_norm_clip", ")", "\n", "self", ".", "critic_optimiser", ".", "step", "(", ")", "\n", "self", ".", "critic_training_steps", "+=", "1", "\n", "\n", "running_log", "[", "\"critic_loss\"", "]", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "running_log", "[", "\"critic_grad_norm\"", "]", ".", "append", "(", "grad_norm", ")", "\n", "mask_elems", "=", "mask_t", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "running_log", "[", "\"td_error_abs\"", "]", ".", "append", "(", "(", "masked_td_error", ".", "abs", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", ")", "\n", "running_log", "[", "\"q_taken_mean\"", "]", ".", "append", "(", "(", "q_taken", "*", "mask_t", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", "\n", "running_log", "[", "\"target_mean\"", "]", ".", "append", "(", "(", "targets_t", "*", "mask_t", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", "\n", "\n", "", "return", "q_vals", ",", "running_log", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v1.PGLearner_v1._update_targets": [[179, 182], ["policy_gradient_v1.PGLearner_v1.target_critic.load_state_dict", "policy_gradient_v1.PGLearner_v1.logger.console_logger.info", "policy_gradient_v1.PGLearner_v1.critic.state_dict"], "methods", ["None"], ["", "def", "_update_targets", "(", "self", ")", ":", "\n", "        ", "self", ".", "target_critic", ".", "load_state_dict", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "logger", ".", "console_logger", ".", "info", "(", "\"Updated target network\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v1.PGLearner_v1.cuda": [[183, 187], ["policy_gradient_v1.PGLearner_v1.mac.cuda", "policy_gradient_v1.PGLearner_v1.critic.cuda", "policy_gradient_v1.PGLearner_v1.target_critic.cuda"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "mac", ".", "cuda", "(", ")", "\n", "self", ".", "critic", ".", "cuda", "(", ")", "\n", "self", ".", "target_critic", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v1.PGLearner_v1.save_models": [[188, 193], ["policy_gradient_v1.PGLearner_v1.mac.save_models", "torch.save", "torch.save", "torch.save", "policy_gradient_v1.PGLearner_v1.critic.state_dict", "policy_gradient_v1.PGLearner_v1.agent_optimiser.state_dict", "policy_gradient_v1.PGLearner_v1.critic_optimiser.state_dict"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.save_models"], ["", "def", "save_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "save_models", "(", "path", ")", "\n", "th", ".", "save", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ",", "\"{}/critic.th\"", ".", "format", "(", "path", ")", ")", "\n", "th", ".", "save", "(", "self", ".", "agent_optimiser", ".", "state_dict", "(", ")", ",", "\"{}/agent_opt.th\"", ".", "format", "(", "path", ")", ")", "\n", "th", ".", "save", "(", "self", ".", "critic_optimiser", ".", "state_dict", "(", ")", ",", "\"{}/critic_opt.th\"", ".", "format", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v1.PGLearner_v1.load_models": [[194, 201], ["policy_gradient_v1.PGLearner_v1.mac.load_models", "policy_gradient_v1.PGLearner_v1.critic.load_state_dict", "policy_gradient_v1.PGLearner_v1.target_critic.load_state_dict", "policy_gradient_v1.PGLearner_v1.agent_optimiser.load_state_dict", "policy_gradient_v1.PGLearner_v1.critic_optimiser.load_state_dict", "torch.load", "policy_gradient_v1.PGLearner_v1.critic.state_dict", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_models"], ["", "def", "load_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "load_models", "(", "path", ")", "\n", "self", ".", "critic", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/critic.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "# Not quite right but I don't want to save target networks", "\n", "self", ".", "target_critic", ".", "load_state_dict", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "agent_optimiser", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/agent_opt.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "self", ".", "critic_optimiser", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/critic_opt.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v3.PGLearner_v3.__init__": [[14, 40], ["copy.deepcopy", "list", "list", "torch.optim.RMSprop", "torch.optim.RMSprop", "modules.critics.coma.COMACritic", "mac.parameters", "policy_gradient_v3.PGLearner_v3.critic.parameters", "modules.critics.ctl_critic.CTLCritic", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters"], ["    ", "def", "__init__", "(", "self", ",", "mac", ",", "scheme", ",", "logger", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "self", ".", "n_actions", "=", "args", ".", "n_actions", "\n", "self", ".", "mac", "=", "mac", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "self", ".", "last_target_update_step", "=", "0", "\n", "self", ".", "critic_training_steps", "=", "0", "\n", "\n", "self", ".", "log_stats_t", "=", "-", "self", ".", "args", ".", "learner_log_interval", "-", "1", "\n", "\n", "if", "args", ".", "critic", "==", "'coma'", ":", "\n", "            ", "self", ".", "critic", "=", "COMACritic", "(", "scheme", ",", "args", ")", "\n", "", "elif", "args", ".", "critic", "==", "'central_critic'", ":", "\n", "            ", "self", ".", "critic", "=", "CTLCritic", "(", "scheme", ",", "args", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Critic {} is not implemented\"", ".", "format", "(", "args", ".", "critic", ")", ")", "\n", "", "self", ".", "target_critic", "=", "copy", ".", "deepcopy", "(", "self", ".", "critic", ")", "\n", "\n", "self", ".", "agent_params", "=", "list", "(", "mac", ".", "parameters", "(", ")", ")", "\n", "self", ".", "critic_params", "=", "list", "(", "self", ".", "critic", ".", "parameters", "(", ")", ")", "\n", "self", ".", "params", "=", "self", ".", "agent_params", "+", "self", ".", "critic_params", "\n", "\n", "self", ".", "agent_optimiser", "=", "RMSprop", "(", "params", "=", "self", ".", "agent_params", ",", "lr", "=", "args", ".", "lr", ",", "alpha", "=", "args", ".", "optim_alpha", ",", "eps", "=", "args", ".", "optim_eps", ")", "\n", "self", ".", "critic_optimiser", "=", "RMSprop", "(", "params", "=", "self", ".", "critic_params", ",", "lr", "=", "args", ".", "critic_lr", ",", "alpha", "=", "args", ".", "optim_alpha", ",", "eps", "=", "args", ".", "optim_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v3.PGLearner_v3.train": [[41, 128], ["[].float", "[].float", "mask.repeat().view.repeat().view.clone", "mask.repeat().view.repeat().view.repeat().view", "policy_gradient_v3.PGLearner_v3.mac.init_hidden", "range", "torch.stack", "policy_gradient_v3.PGLearner_v3.agent_optimiser.zero_grad", "coma_loss.backward", "torch.nn.utils.clip_grad_norm_", "policy_gradient_v3.PGLearner_v3.agent_optimiser.step", "policy_gradient_v3.PGLearner_v3._train_critic", "policy_gradient_v3.PGLearner_v3.mac.forward", "torch.stack.append", "torch.stack.sum", "q_vals.reshape.reshape.reshape", "torch.stack.view", "torch.gather().squeeze", "torch.gather().squeeze", "torch.log", "torch.gather().squeeze.detach", "mask.repeat().view.repeat().view.sum", "categorical_entropy", "policy_gradient_v3.PGLearner_v3._update_targets", "len", "policy_gradient_v3.PGLearner_v3.logger.log_stat", "policy_gradient_v3.PGLearner_v3.logger.log_stat", "policy_gradient_v3.PGLearner_v3.logger.log_stat", "policy_gradient_v3.PGLearner_v3.logger.log_stat", "mask.repeat().view.repeat().view.repeat", "policy_gradient_v3.PGLearner_v3._train_critic", "ValueError", "advs.reshape.reshape.reshape", "torch.stack.view", "torch.gather().squeeze", "torch.log", "advs.reshape.reshape.detach", "policy_gradient_v3.PGLearner_v3.logger.log_stat", "coma_loss.item", "torch.gather", "torch.gather", "mask.repeat().view.repeat().view.sum().item", "mask.repeat().view.repeat().view.sum().item", "torch.gather", "sum", "actions.reshape", "actions.reshape", "mask.repeat().view.repeat().view.sum", "mask.repeat().view.repeat().view.sum", "actions.reshape", "th.stack.view.max"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v3.PGLearner_v3._train_critic", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.forward", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.categorical_entropy", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner._update_targets", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v3.PGLearner_v3._train_critic", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat"], ["", "def", "train", "(", "self", ",", "batch", ":", "EpisodeBatch", ",", "t_env", ":", "int", ",", "episode_num", ":", "int", ")", ":", "\n", "# Get the relevant quantities", "\n", "        ", "bs", "=", "batch", ".", "batch_size", "\n", "max_t", "=", "batch", ".", "max_seq_length", "\n", "rewards", "=", "batch", "[", "\"reward\"", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "actions", "=", "batch", "[", "\"actions\"", "]", "[", ":", ",", ":", "]", "\n", "terminated", "=", "batch", "[", "\"terminated\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "=", "batch", "[", "\"filled\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "[", ":", ",", "1", ":", "]", "=", "mask", "[", ":", ",", "1", ":", "]", "*", "(", "1", "-", "terminated", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "avail_actions", "=", "batch", "[", "\"avail_actions\"", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "critic_mask", "=", "mask", ".", "clone", "(", ")", "\n", "\n", "mask", "=", "mask", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "if", "self", ".", "args", ".", "critic", "==", "'coma'", ":", "\n", "            ", "q_vals", ",", "critic_train_stats", "=", "self", ".", "_train_critic", "(", "batch", ",", "rewards", ",", "terminated", ",", "actions", ",", "avail_actions", ",", "\n", "critic_mask", ",", "bs", ",", "max_t", ")", "\n", "", "elif", "self", ".", "args", ".", "critic", "==", "'central_critic'", ":", "\n", "            ", "advs", ",", "critic_train_stats", "=", "self", ".", "_train_critic", "(", "batch", ",", "rewards", ",", "terminated", ",", "actions", ",", "avail_actions", ",", "\n", "critic_mask", ",", "bs", ",", "max_t", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Critic {} is not implemented\"", ".", "format", "(", "self", ".", "args", ".", "critic", ")", ")", "\n", "\n", "", "actions", "=", "actions", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "mac_out", "=", "[", "]", "\n", "self", ".", "mac", ".", "init_hidden", "(", "batch", ".", "batch_size", ")", "\n", "for", "t", "in", "range", "(", "batch", ".", "max_seq_length", "-", "1", ")", ":", "\n", "            ", "agent_outs", "=", "self", ".", "mac", ".", "forward", "(", "batch", ",", "t", "=", "t", ")", "\n", "mac_out", ".", "append", "(", "agent_outs", ")", "\n", "", "mac_out", "=", "th", ".", "stack", "(", "mac_out", ",", "dim", "=", "1", ")", "# Concat over time", "\n", "\n", "# Mask out unavailable actions, renormalise (as in action selection)", "\n", "mac_out", "[", "avail_actions", "==", "0", "]", "=", "0", "\n", "mac_out", "=", "mac_out", "/", "mac_out", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "mac_out", "[", "avail_actions", "==", "0", "]", "=", "0", "\n", "\n", "if", "self", ".", "args", ".", "critic", "==", "'coma'", ":", "\n", "            ", "q_vals", "=", "q_vals", ".", "reshape", "(", "-", "1", ",", "self", ".", "n_actions", ")", "\n", "pi", "=", "mac_out", ".", "view", "(", "-", "1", ",", "self", ".", "n_actions", ")", "\n", "\n", "# Calculate policy grad with mask", "\n", "q_taken", "=", "th", ".", "gather", "(", "q_vals", ",", "dim", "=", "1", ",", "index", "=", "actions", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "pi_taken", "=", "th", ".", "gather", "(", "pi", ",", "dim", "=", "1", ",", "index", "=", "actions", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "pi_taken", "[", "mask", "==", "0", "]", "=", "1.0", "\n", "log_pi_taken", "=", "th", ".", "log", "(", "pi_taken", ")", "\n", "\n", "advantages", "=", "q_taken", ".", "detach", "(", ")", "\n", "\n", "", "elif", "self", ".", "args", ".", "critic", "==", "'central_critic'", ":", "\n", "            ", "advs", "=", "advs", ".", "reshape", "(", "-", "1", ")", "\n", "pi", "=", "mac_out", ".", "view", "(", "-", "1", ",", "self", ".", "n_actions", ")", "\n", "\n", "# Calculate policy grad with mask", "\n", "pi_taken", "=", "th", ".", "gather", "(", "pi", ",", "dim", "=", "1", ",", "index", "=", "actions", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "pi_taken", "[", "mask", "==", "0", "]", "=", "1.0", "\n", "log_pi_taken", "=", "th", ".", "log", "(", "pi_taken", ")", "\n", "\n", "advantages", "=", "advs", ".", "detach", "(", ")", "\n", "\n", "", "coma_loss", "=", "-", "(", "(", "advantages", "*", "log_pi_taken", ")", "*", "mask", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "\n", "if", "self", ".", "args", ".", "ent_coef", ":", "\n", "            ", "entropy", "=", "categorical_entropy", "(", "pi", ")", "\n", "coma_loss", "-=", "self", ".", "args", ".", "ent_coef", "*", "entropy", "\n", "\n", "# Optimise agents", "\n", "", "self", ".", "agent_optimiser", ".", "zero_grad", "(", ")", "\n", "coma_loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "th", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "agent_params", ",", "self", ".", "args", ".", "grad_norm_clip", ")", "\n", "self", ".", "agent_optimiser", ".", "step", "(", ")", "\n", "\n", "if", "(", "self", ".", "critic_training_steps", "-", "self", ".", "last_target_update_step", ")", "/", "self", ".", "args", ".", "target_update_interval", ">=", "1.0", ":", "\n", "            ", "self", ".", "_update_targets", "(", ")", "\n", "self", ".", "last_target_update_step", "=", "self", ".", "critic_training_steps", "\n", "\n", "", "if", "t_env", "-", "self", ".", "log_stats_t", ">=", "self", ".", "args", ".", "learner_log_interval", ":", "\n", "            ", "ts_logged", "=", "len", "(", "critic_train_stats", "[", "\"critic_loss\"", "]", ")", "\n", "for", "key", "in", "[", "\"critic_loss\"", ",", "\"critic_grad_norm\"", ",", "\"td_error_abs\"", ",", "\"q_taken_mean\"", ",", "\"target_mean\"", "]", ":", "\n", "                ", "self", ".", "logger", ".", "log_stat", "(", "key", ",", "sum", "(", "critic_train_stats", "[", "key", "]", ")", "/", "ts_logged", ",", "t_env", ")", "\n", "\n", "", "self", ".", "logger", ".", "log_stat", "(", "\"advantage_mean\"", ",", "(", "advantages", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"coma_loss\"", ",", "coma_loss", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"agent_grad_norm\"", ",", "grad_norm", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"pi_max\"", ",", "(", "pi", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "log_stats_t", "=", "t_env", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v3.PGLearner_v3._train_critic": [[129, 211], ["reversed", "target_q_vals.squeeze", "build_bootstrap_targets", "pred_q_vals.squeeze", "build_bootstrap_targets", "range", "mask[].expand", "policy_gradient_v3.PGLearner_v3.critic", "policy_gradient_v3.PGLearner_v3.critic_optimiser.zero_grad", "loss.backward", "torch.nn.utils.clip_grad_norm_", "policy_gradient_v3.PGLearner_v3.critic_optimiser.step", "running_log[].append", "running_log[].append", "mask[].expand.sum().item", "running_log[].append", "running_log[].append", "running_log[].append", "policy_gradient_v3.PGLearner_v3.target_critic", "torch.zeros_like", "torch.zeros_like", "policy_gradient_v3.PGLearner_v3.critic", "pred_targets[].unsqueeze", "torch.gather().squeeze", "build_td_lambda_targets", "ValueError", "rewards.size", "mask[].expand.sum", "policy_gradient_v3.PGLearner_v3.squeeze().squeeze", "targets_t.detach", "mask[].expand.sum", "loss.item", "policy_gradient_v3.PGLearner_v3.target_critic", "torch.zeros_like", "policy_gradient_v3.PGLearner_v3.view", "torch.gather().squeeze().squeeze", "ValueError", "mask[].expand.sum", "masked_td_error.abs().sum().item", "torch.gather", "policy_gradient_v3.PGLearner_v3.squeeze", "torch.gather().squeeze", "masked_td_error.abs().sum", "torch.gather", "masked_td_error.abs"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.build_bootstrap_targets", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.build_bootstrap_targets", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.rl_utils.build_td_lambda_targets"], ["", "", "def", "_train_critic", "(", "self", ",", "batch", ",", "rewards", ",", "terminated", ",", "actions", ",", "avail_actions", ",", "mask", ",", "bs", ",", "max_t", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "critic", "==", "'central_critic'", ":", "\n", "# Optimise critic", "\n", "            ", "target_q_vals", "=", "self", ".", "target_critic", "(", "batch", ")", "[", ":", ",", ":", "]", "#[bs, t, n_agents, 1]", "\n", "targets_taken", "=", "target_q_vals", ".", "squeeze", "(", "3", ")", "\n", "\n", "# Calculate td-lambda targets", "\n", "targets", "=", "build_bootstrap_targets", "(", "rewards", ",", "terminated", ",", "mask", ",", "targets_taken", ",", "self", ".", "n_agents", ",", "self", ".", "args", ".", "gamma", ")", "#[bs, t, n_agents]", "\n", "\n", "\n", "q_vals", "=", "th", ".", "zeros_like", "(", "target_q_vals", ")", "[", ":", ",", ":", "-", "1", "]", "\n", "advs", "=", "th", ".", "zeros_like", "(", "target_q_vals", ")", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "pred_q_vals", "=", "self", ".", "critic", "(", "batch", ")", "[", ":", ",", ":", "]", "\n", "pred_taken", "=", "pred_q_vals", ".", "squeeze", "(", "3", ")", "\n", "\n", "# Calculate td-lambda targets", "\n", "pred_targets", "=", "build_bootstrap_targets", "(", "rewards", ",", "terminated", ",", "mask", ",", "pred_taken", ",", "self", ".", "n_agents", ",", "self", ".", "args", ".", "gamma", ")", "#[bs, t, n_agents]", "\n", "advs", "[", ":", ",", ":", "]", "=", "pred_targets", "[", ":", ",", ":", "]", ".", "unsqueeze", "(", "-", "1", ")", "-", "pred_q_vals", "[", ":", ",", ":", "-", "1", "]", "\n", "q_vals", "[", ":", ",", ":", "]", "=", "pred_q_vals", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "", "elif", "self", ".", "args", ".", "critic", "==", "'coma'", ":", "\n", "# Optimise critic", "\n", "            ", "target_q_vals", "=", "self", ".", "target_critic", "(", "batch", ")", "[", ":", ",", ":", "]", "\n", "targets_taken", "=", "th", ".", "gather", "(", "target_q_vals", ",", "dim", "=", "3", ",", "index", "=", "actions", ")", ".", "squeeze", "(", "3", ")", "\n", "\n", "# Calculate td-lambda targets", "\n", "targets", "=", "build_td_lambda_targets", "(", "rewards", ",", "terminated", ",", "mask", ",", "targets_taken", ",", "self", ".", "n_agents", ",", "self", ".", "args", ".", "gamma", ",", "self", ".", "args", ".", "td_lambda", ")", "\n", "\n", "q_vals", "=", "th", ".", "zeros_like", "(", "target_q_vals", ")", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Critic {} is not implemented\"", ".", "format", "(", "self", ".", "args", ".", "critic", ")", ")", "\n", "\n", "", "running_log", "=", "{", "\n", "\"critic_loss\"", ":", "[", "]", ",", "\n", "\"critic_grad_norm\"", ":", "[", "]", ",", "\n", "\"td_error_abs\"", ":", "[", "]", ",", "\n", "\"target_mean\"", ":", "[", "]", ",", "\n", "\"q_taken_mean\"", ":", "[", "]", ",", "\n", "}", "\n", "\n", "for", "t", "in", "reversed", "(", "range", "(", "rewards", ".", "size", "(", "1", ")", ")", ")", ":", "\n", "            ", "mask_t", "=", "mask", "[", ":", ",", "t", "]", ".", "expand", "(", "-", "1", ",", "self", ".", "n_agents", ")", "\n", "if", "mask_t", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "q_t", "=", "self", ".", "critic", "(", "batch", ",", "t", ")", "\n", "if", "self", ".", "args", ".", "critic", "==", "'central_critic'", ":", "\n", "                ", "q_taken", "=", "q_t", ".", "squeeze", "(", "3", ")", ".", "squeeze", "(", "1", ")", "\n", "", "elif", "self", ".", "args", ".", "critic", "==", "'coma'", ":", "\n", "                ", "q_vals", "[", ":", ",", "t", "]", "=", "q_t", ".", "view", "(", "bs", ",", "self", ".", "n_agents", ",", "self", ".", "n_actions", ")", "\n", "q_taken", "=", "th", ".", "gather", "(", "q_t", ",", "dim", "=", "3", ",", "index", "=", "actions", "[", ":", ",", "t", ":", "t", "+", "1", "]", ")", ".", "squeeze", "(", "3", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Critic {} is not implemented\"", ".", "format", "(", "self", ".", "args", ".", "critic", ")", ")", "\n", "\n", "", "targets_t", "=", "targets", "[", ":", ",", "t", "]", "\n", "td_error", "=", "(", "q_taken", "-", "targets_t", ".", "detach", "(", ")", ")", "\n", "# 0-out the targets that came from padded data", "\n", "masked_td_error", "=", "td_error", "*", "mask_t", "\n", "\n", "# Normal L2 loss, take mean over actual data", "\n", "loss", "=", "(", "masked_td_error", "**", "2", ")", ".", "sum", "(", ")", "/", "mask_t", ".", "sum", "(", ")", "\n", "self", ".", "critic_optimiser", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "th", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "critic_params", ",", "self", ".", "args", ".", "grad_norm_clip", ")", "\n", "self", ".", "critic_optimiser", ".", "step", "(", ")", "\n", "self", ".", "critic_training_steps", "+=", "1", "\n", "\n", "running_log", "[", "\"critic_loss\"", "]", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "running_log", "[", "\"critic_grad_norm\"", "]", ".", "append", "(", "grad_norm", ")", "\n", "mask_elems", "=", "mask_t", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "running_log", "[", "\"td_error_abs\"", "]", ".", "append", "(", "(", "masked_td_error", ".", "abs", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", ")", "\n", "running_log", "[", "\"q_taken_mean\"", "]", ".", "append", "(", "(", "q_taken", "*", "mask_t", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", "\n", "running_log", "[", "\"target_mean\"", "]", ".", "append", "(", "(", "targets_t", "*", "mask_t", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "critic", "==", "'central_critic'", ":", "\n", "            ", "return", "advs", ",", "running_log", "\n", "", "elif", "self", ".", "args", ".", "critic", "==", "'coma'", ":", "\n", "            ", "return", "q_vals", ",", "running_log", "\n", "", "else", ":", "\n", "            ", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v3.PGLearner_v3._update_targets": [[212, 215], ["policy_gradient_v3.PGLearner_v3.target_critic.load_state_dict", "policy_gradient_v3.PGLearner_v3.logger.console_logger.info", "policy_gradient_v3.PGLearner_v3.critic.state_dict"], "methods", ["None"], ["", "", "def", "_update_targets", "(", "self", ")", ":", "\n", "        ", "self", ".", "target_critic", ".", "load_state_dict", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "logger", ".", "console_logger", ".", "info", "(", "\"Updated target network\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v3.PGLearner_v3.cuda": [[216, 220], ["policy_gradient_v3.PGLearner_v3.mac.cuda", "policy_gradient_v3.PGLearner_v3.critic.cuda", "policy_gradient_v3.PGLearner_v3.target_critic.cuda"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "mac", ".", "cuda", "(", ")", "\n", "self", ".", "critic", ".", "cuda", "(", ")", "\n", "self", ".", "target_critic", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v3.PGLearner_v3.save_models": [[221, 226], ["policy_gradient_v3.PGLearner_v3.mac.save_models", "torch.save", "torch.save", "torch.save", "policy_gradient_v3.PGLearner_v3.critic.state_dict", "policy_gradient_v3.PGLearner_v3.agent_optimiser.state_dict", "policy_gradient_v3.PGLearner_v3.critic_optimiser.state_dict"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.save_models"], ["", "def", "save_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "save_models", "(", "path", ")", "\n", "th", ".", "save", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ",", "\"{}/critic.th\"", ".", "format", "(", "path", ")", ")", "\n", "th", ".", "save", "(", "self", ".", "agent_optimiser", ".", "state_dict", "(", ")", ",", "\"{}/agent_opt.th\"", ".", "format", "(", "path", ")", ")", "\n", "th", ".", "save", "(", "self", ".", "critic_optimiser", ".", "state_dict", "(", ")", ",", "\"{}/critic_opt.th\"", ".", "format", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.policy_gradient_v3.PGLearner_v3.load_models": [[227, 234], ["policy_gradient_v3.PGLearner_v3.mac.load_models", "policy_gradient_v3.PGLearner_v3.critic.load_state_dict", "policy_gradient_v3.PGLearner_v3.target_critic.load_state_dict", "policy_gradient_v3.PGLearner_v3.agent_optimiser.load_state_dict", "policy_gradient_v3.PGLearner_v3.critic_optimiser.load_state_dict", "torch.load", "policy_gradient_v3.PGLearner_v3.critic.state_dict", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_models"], ["", "def", "load_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "load_models", "(", "path", ")", "\n", "self", ".", "critic", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/critic.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "# Not quite right but I don't want to save target networks", "\n", "self", ".", "target_critic", ".", "load_state_dict", "(", "self", ".", "critic", ".", "state_dict", "(", ")", ")", "\n", "self", ".", "agent_optimiser", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/agent_opt.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "self", ".", "critic_optimiser", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/critic_opt.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner.__init__": [[10, 36], ["list", "torch.optim.RMSprop", "copy.deepcopy", "mac.parameters", "list", "copy.deepcopy", "modules.mixers.vdn.VDNMixer", "q_learner.QLearner.mixer.parameters", "modules.mixers.qmix.QMixer", "ValueError"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters"], ["    ", "def", "__init__", "(", "self", ",", "mac", ",", "scheme", ",", "logger", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "mac", "=", "mac", "\n", "self", ".", "logger", "=", "logger", "\n", "\n", "self", ".", "params", "=", "list", "(", "mac", ".", "parameters", "(", ")", ")", "\n", "\n", "self", ".", "last_target_update_episode", "=", "0", "\n", "\n", "self", ".", "mixer", "=", "None", "\n", "if", "args", ".", "mixer", "is", "not", "None", ":", "\n", "            ", "if", "args", ".", "mixer", "==", "\"vdn\"", ":", "\n", "                ", "self", ".", "mixer", "=", "VDNMixer", "(", ")", "\n", "", "elif", "args", ".", "mixer", "==", "\"qmix\"", ":", "\n", "                ", "self", ".", "mixer", "=", "QMixer", "(", "args", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Mixer {} not recognised.\"", ".", "format", "(", "args", ".", "mixer", ")", ")", "\n", "", "self", ".", "params", "+=", "list", "(", "self", ".", "mixer", ".", "parameters", "(", ")", ")", "\n", "self", ".", "target_mixer", "=", "copy", ".", "deepcopy", "(", "self", ".", "mixer", ")", "\n", "\n", "", "self", ".", "optimiser", "=", "RMSprop", "(", "params", "=", "self", ".", "params", ",", "lr", "=", "args", ".", "lr", ",", "alpha", "=", "args", ".", "optim_alpha", ",", "eps", "=", "args", ".", "optim_eps", ")", "\n", "\n", "# a little wasteful to deepcopy (e.g. duplicates action selector), but should work for any MAC", "\n", "self", ".", "target_mac", "=", "copy", ".", "deepcopy", "(", "mac", ")", "\n", "\n", "self", ".", "log_stats_t", "=", "-", "self", ".", "args", ".", "learner_log_interval", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner.train": [[37, 117], ["[].float", "[].float", "q_learner.QLearner.mac.init_hidden", "range", "torch.stack", "torch.gather().squeeze", "q_learner.QLearner.target_mac.init_hidden", "range", "torch.stack", "mask.expand_as.expand_as.expand_as", "q_learner.QLearner.optimiser.zero_grad", "loss.backward", "torch.nn.utils.clip_grad_norm_", "q_learner.QLearner.optimiser.step", "q_learner.QLearner.mac.forward", "torch.stack.append", "q_learner.QLearner.target_mac.forward", "torch.stack.append", "torch.stack.clone().detach", "torch.gather().squeeze", "q_learner.QLearner.mixer", "q_learner.QLearner.target_mixer", "targets.detach", "mask.expand_as.expand_as.sum", "q_learner.QLearner._update_targets", "q_learner.QLearner.logger.log_stat", "q_learner.QLearner.logger.log_stat", "mask.expand_as.expand_as.sum().item", "q_learner.QLearner.logger.log_stat", "q_learner.QLearner.logger.log_stat", "q_learner.QLearner.logger.log_stat", "torch.gather", "mac_out_detach[].max", "torch.stack.max", "loss.item", "torch.stack.clone", "torch.gather", "mask.expand_as.expand_as.sum", "masked_td_error.abs().sum().item", "masked_td_error.abs().sum", "masked_td_error.abs"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.forward", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.forward", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner._update_targets", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat"], ["", "def", "train", "(", "self", ",", "batch", ":", "EpisodeBatch", ",", "t_env", ":", "int", ",", "episode_num", ":", "int", ")", ":", "\n", "# Get the relevant quantities", "\n", "        ", "rewards", "=", "batch", "[", "\"reward\"", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "actions", "=", "batch", "[", "\"actions\"", "]", "[", ":", ",", ":", "-", "1", "]", "\n", "terminated", "=", "batch", "[", "\"terminated\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "=", "batch", "[", "\"filled\"", "]", "[", ":", ",", ":", "-", "1", "]", ".", "float", "(", ")", "\n", "mask", "[", ":", ",", "1", ":", "]", "=", "mask", "[", ":", ",", "1", ":", "]", "*", "(", "1", "-", "terminated", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "avail_actions", "=", "batch", "[", "\"avail_actions\"", "]", "\n", "\n", "# Calculate estimated Q-Values", "\n", "mac_out", "=", "[", "]", "\n", "self", ".", "mac", ".", "init_hidden", "(", "batch", ".", "batch_size", ")", "\n", "for", "t", "in", "range", "(", "batch", ".", "max_seq_length", ")", ":", "\n", "            ", "agent_outs", "=", "self", ".", "mac", ".", "forward", "(", "batch", ",", "t", "=", "t", ")", "\n", "mac_out", ".", "append", "(", "agent_outs", ")", "\n", "", "mac_out", "=", "th", ".", "stack", "(", "mac_out", ",", "dim", "=", "1", ")", "# Concat over time", "\n", "\n", "# Pick the Q-Values for the actions taken by each agent", "\n", "chosen_action_qvals", "=", "th", ".", "gather", "(", "mac_out", "[", ":", ",", ":", "-", "1", "]", ",", "dim", "=", "3", ",", "index", "=", "actions", ")", ".", "squeeze", "(", "3", ")", "# Remove the last dim", "\n", "\n", "# Calculate the Q-Values necessary for the target", "\n", "target_mac_out", "=", "[", "]", "\n", "self", ".", "target_mac", ".", "init_hidden", "(", "batch", ".", "batch_size", ")", "\n", "for", "t", "in", "range", "(", "batch", ".", "max_seq_length", ")", ":", "\n", "            ", "target_agent_outs", "=", "self", ".", "target_mac", ".", "forward", "(", "batch", ",", "t", "=", "t", ")", "\n", "target_mac_out", ".", "append", "(", "target_agent_outs", ")", "\n", "\n", "# We don't need the first timesteps Q-Value estimate for calculating targets", "\n", "", "target_mac_out", "=", "th", ".", "stack", "(", "target_mac_out", "[", "1", ":", "]", ",", "dim", "=", "1", ")", "# Concat across time", "\n", "\n", "# Mask out unavailable actions", "\n", "target_mac_out", "[", "avail_actions", "[", ":", ",", "1", ":", "]", "==", "0", "]", "=", "-", "9999999", "\n", "\n", "# Max over target Q-Values", "\n", "if", "self", ".", "args", ".", "double_q", ":", "\n", "# Get actions that maximise live Q (for double q-learning)", "\n", "            ", "mac_out_detach", "=", "mac_out", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "mac_out_detach", "[", "avail_actions", "==", "0", "]", "=", "-", "9999999", "\n", "cur_max_actions", "=", "mac_out_detach", "[", ":", ",", "1", ":", "]", ".", "max", "(", "dim", "=", "3", ",", "keepdim", "=", "True", ")", "[", "1", "]", "\n", "target_max_qvals", "=", "th", ".", "gather", "(", "target_mac_out", ",", "3", ",", "cur_max_actions", ")", ".", "squeeze", "(", "3", ")", "\n", "", "else", ":", "\n", "            ", "target_max_qvals", "=", "target_mac_out", ".", "max", "(", "dim", "=", "3", ")", "[", "0", "]", "\n", "\n", "# Mix", "\n", "", "if", "self", ".", "mixer", "is", "not", "None", ":", "\n", "            ", "chosen_action_qvals", "=", "self", ".", "mixer", "(", "chosen_action_qvals", ",", "batch", "[", "\"state\"", "]", "[", ":", ",", ":", "-", "1", "]", ")", "\n", "target_max_qvals", "=", "self", ".", "target_mixer", "(", "target_max_qvals", ",", "batch", "[", "\"state\"", "]", "[", ":", ",", "1", ":", "]", ")", "\n", "\n", "# Calculate 1-step Q-Learning targets", "\n", "", "targets", "=", "rewards", "+", "self", ".", "args", ".", "gamma", "*", "(", "1", "-", "terminated", ")", "*", "target_max_qvals", "\n", "\n", "# Td-error", "\n", "td_error", "=", "(", "chosen_action_qvals", "-", "targets", ".", "detach", "(", ")", ")", "\n", "\n", "mask", "=", "mask", ".", "expand_as", "(", "td_error", ")", "\n", "\n", "# 0-out the targets that came from padded data", "\n", "masked_td_error", "=", "td_error", "*", "mask", "\n", "\n", "# Normal L2 loss, take mean over actual data", "\n", "loss", "=", "(", "masked_td_error", "**", "2", ")", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "\n", "# Optimise", "\n", "self", ".", "optimiser", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "grad_norm", "=", "th", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "params", ",", "self", ".", "args", ".", "grad_norm_clip", ")", "\n", "self", ".", "optimiser", ".", "step", "(", ")", "\n", "\n", "if", "(", "episode_num", "-", "self", ".", "last_target_update_episode", ")", "/", "self", ".", "args", ".", "target_update_interval", ">=", "1.0", ":", "\n", "            ", "self", ".", "_update_targets", "(", ")", "\n", "self", ".", "last_target_update_episode", "=", "episode_num", "\n", "\n", "", "if", "t_env", "-", "self", ".", "log_stats_t", ">=", "self", ".", "args", ".", "learner_log_interval", ":", "\n", "            ", "self", ".", "logger", ".", "log_stat", "(", "\"loss\"", ",", "loss", ".", "item", "(", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"grad_norm\"", ",", "grad_norm", ",", "t_env", ")", "\n", "mask_elems", "=", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"td_error_abs\"", ",", "(", "masked_td_error", ".", "abs", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "mask_elems", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"q_taken_mean\"", ",", "(", "chosen_action_qvals", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "(", "mask_elems", "*", "self", ".", "args", ".", "n_agents", ")", ",", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "\"target_mean\"", ",", "(", "targets", "*", "mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "(", "mask_elems", "*", "self", ".", "args", ".", "n_agents", ")", ",", "t_env", ")", "\n", "self", ".", "log_stats_t", "=", "t_env", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner._update_targets": [[118, 123], ["q_learner.QLearner.target_mac.load_state", "q_learner.QLearner.logger.console_logger.info", "q_learner.QLearner.target_mixer.load_state_dict", "q_learner.QLearner.mixer.state_dict"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_state"], ["", "", "def", "_update_targets", "(", "self", ")", ":", "\n", "        ", "self", ".", "target_mac", ".", "load_state", "(", "self", ".", "mac", ")", "\n", "if", "self", ".", "mixer", "is", "not", "None", ":", "\n", "            ", "self", ".", "target_mixer", ".", "load_state_dict", "(", "self", ".", "mixer", ".", "state_dict", "(", ")", ")", "\n", "", "self", ".", "logger", ".", "console_logger", ".", "info", "(", "\"Updated target network\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner.cuda": [[124, 130], ["q_learner.QLearner.mac.cuda", "q_learner.QLearner.target_mac.cuda", "q_learner.QLearner.mixer.cuda", "q_learner.QLearner.target_mixer.cuda"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "mac", ".", "cuda", "(", ")", "\n", "self", ".", "target_mac", ".", "cuda", "(", ")", "\n", "if", "self", ".", "mixer", "is", "not", "None", ":", "\n", "            ", "self", ".", "mixer", ".", "cuda", "(", ")", "\n", "self", ".", "target_mixer", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner.save_models": [[131, 136], ["q_learner.QLearner.mac.save_models", "torch.save", "torch.save", "q_learner.QLearner.optimiser.state_dict", "q_learner.QLearner.mixer.state_dict"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.save_models"], ["", "", "def", "save_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "save_models", "(", "path", ")", "\n", "if", "self", ".", "mixer", "is", "not", "None", ":", "\n", "            ", "th", ".", "save", "(", "self", ".", "mixer", ".", "state_dict", "(", ")", ",", "\"{}/mixer.th\"", ".", "format", "(", "path", ")", ")", "\n", "", "th", ".", "save", "(", "self", ".", "optimiser", ".", "state_dict", "(", ")", ",", "\"{}/opt.th\"", ".", "format", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.learners.q_learner.QLearner.load_models": [[137, 144], ["q_learner.QLearner.mac.load_models", "q_learner.QLearner.target_mac.load_models", "q_learner.QLearner.optimiser.load_state_dict", "q_learner.QLearner.mixer.load_state_dict", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_models", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_models"], ["", "def", "load_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "mac", ".", "load_models", "(", "path", ")", "\n", "# Not quite right but I don't want to save target networks", "\n", "self", ".", "target_mac", ".", "load_models", "(", "path", ")", "\n", "if", "self", ".", "mixer", "is", "not", "None", ":", "\n", "            ", "self", ".", "mixer", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/mixer.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "", "self", ".", "optimiser", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/opt.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC.__init__": [[8, 18], ["ppo_controller.PPOMAC._get_input_shape", "ppo_controller.PPOMAC._build_agents"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._get_input_shape", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC._build_agents"], ["    ", "def", "__init__", "(", "self", ",", "scheme", ",", "groups", ",", "args", ")", ":", "\n", "        ", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "self", ".", "args", "=", "args", "\n", "input_shape", "=", "self", ".", "_get_input_shape", "(", "scheme", ")", "\n", "self", ".", "_build_agents", "(", "input_shape", ")", "\n", "self", ".", "agent_output_type", "=", "args", ".", "agent_output_type", "\n", "\n", "self", ".", "action_selector", "=", "action_REGISTRY", "[", "args", ".", "action_selector", "]", "(", "args", ")", "\n", "\n", "self", ".", "hidden_states", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC.select_actions": [[19, 25], ["slice", "ppo_controller.PPOMAC.forward", "ppo_controller.PPOMAC.action_selector.select_action"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.forward", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.action_selectors.EpsilonGreedyActionSelector.select_action"], ["", "def", "select_actions", "(", "self", ",", "ep_batch", ",", "t_ep", ",", "t_env", ",", "bs", "=", "slice", "(", "None", ")", ",", "test_mode", "=", "False", ")", ":", "\n", "# Only select actions for the selected batch elements in bs", "\n", "        ", "avail_actions", "=", "ep_batch", "[", "\"avail_actions\"", "]", "[", ":", ",", "t_ep", "]", "\n", "agent_outputs", ",", "qs", "=", "self", ".", "forward", "(", "ep_batch", ",", "t_ep", ",", "test_mode", "=", "test_mode", ")", "\n", "chosen_actions", "=", "self", ".", "action_selector", ".", "select_action", "(", "agent_outputs", "[", "bs", "]", ",", "avail_actions", "[", "bs", "]", ",", "t_env", ",", "test_mode", "=", "test_mode", ")", "\n", "return", "chosen_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC.forward": [[26, 55], ["ppo_controller.PPOMAC._build_inputs", "ppo_controller.PPOMAC.agent", "getattr", "torch.nn.functional.softmax", "avail_actions.reshape", "torch.nn.functional.softmax.size", "getattr", "getattr", "torch.nn.functional.softmax.view", "agent_outs1.view", "avail_actions.reshape.sum().float", "avail_actions.reshape.sum", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._build_inputs"], ["", "def", "forward", "(", "self", ",", "ep_batch", ",", "t", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "agent_inputs", "=", "self", ".", "_build_inputs", "(", "ep_batch", ",", "t", ")", "\n", "avail_actions", "=", "ep_batch", "[", "\"avail_actions\"", "]", "[", ":", ",", "t", "]", "\n", "agent_outs", ",", "agent_outs1", ",", "self", ".", "hidden_states", "=", "self", ".", "agent", "(", "agent_inputs", ",", "self", ".", "hidden_states", ")", "\n", "\n", "# Softmax the agent outputs if they're policy logits", "\n", "assert", "self", ".", "agent_output_type", "==", "'pi_logits'", "\n", "\n", "if", "getattr", "(", "self", ".", "args", ",", "\"mask_before_softmax\"", ",", "True", ")", ":", "\n", "# Make the logits for unavailable actions very negative to minimise their affect on the softmax", "\n", "            ", "reshaped_avail_actions", "=", "avail_actions", ".", "reshape", "(", "ep_batch", ".", "batch_size", "*", "self", ".", "n_agents", ",", "-", "1", ")", "\n", "agent_outs", "[", "reshaped_avail_actions", "==", "0", "]", "=", "-", "1e10", "\n", "\n", "", "agent_outs", "=", "th", ".", "nn", ".", "functional", ".", "softmax", "(", "agent_outs", ",", "dim", "=", "-", "1", ")", "\n", "if", "not", "test_mode", ":", "\n", "# Epsilon floor", "\n", "            ", "epsilon_action_num", "=", "agent_outs", ".", "size", "(", "-", "1", ")", "\n", "if", "getattr", "(", "self", ".", "args", ",", "\"mask_before_softmax\"", ",", "True", ")", ":", "\n", "# With probability epsilon, we will pick an available action uniformly", "\n", "                ", "epsilon_action_num", "=", "reshaped_avail_actions", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "float", "(", ")", "\n", "\n", "", "agent_outs", "=", "(", "(", "1", "-", "self", ".", "action_selector", ".", "epsilon", ")", "*", "agent_outs", "\n", "+", "th", ".", "ones_like", "(", "agent_outs", ")", "*", "self", ".", "action_selector", ".", "epsilon", "/", "epsilon_action_num", ")", "\n", "\n", "if", "getattr", "(", "self", ".", "args", ",", "\"mask_before_softmax\"", ",", "True", ")", ":", "\n", "# Zero out the unavailable actions", "\n", "                ", "agent_outs", "[", "reshaped_avail_actions", "==", "0", "]", "=", "0.0", "\n", "\n", "", "", "return", "agent_outs", ".", "view", "(", "ep_batch", ".", "batch_size", ",", "self", ".", "n_agents", ",", "-", "1", ")", ",", "agent_outs1", ".", "view", "(", "ep_batch", ".", "batch_size", ",", "self", ".", "n_agents", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC.init_hidden": [[56, 58], ["ppo_controller.PPOMAC.agent.init_hidden().unsqueeze().expand", "ppo_controller.PPOMAC.agent.init_hidden().unsqueeze", "ppo_controller.PPOMAC.agent.init_hidden"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden"], ["", "def", "init_hidden", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "hidden_states", "=", "self", ".", "agent", ".", "init_hidden", "(", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "self", ".", "n_agents", ",", "-", "1", ")", "# bav", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC.parameters": [[59, 61], ["ppo_controller.PPOMAC.agent.parameters"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "agent", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC.load_state": [[62, 64], ["ppo_controller.PPOMAC.agent.load_state_dict", "other_mac.agent.state_dict"], "methods", ["None"], ["", "def", "load_state", "(", "self", ",", "other_mac", ")", ":", "\n", "        ", "self", ".", "agent", ".", "load_state_dict", "(", "other_mac", ".", "agent", ".", "state_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC.cuda": [[65, 67], ["ppo_controller.PPOMAC.agent.cuda"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC.save_models": [[68, 70], ["torch.save", "ppo_controller.PPOMAC.agent.state_dict"], "methods", ["None"], ["", "def", "save_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "th", ".", "save", "(", "self", ".", "agent", ".", "state_dict", "(", ")", ",", "\"{}/agent.th\"", ".", "format", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC.load_models": [[71, 73], ["ppo_controller.PPOMAC.agent.load_state_dict", "torch.load"], "methods", ["None"], ["", "def", "load_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "agent", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/agent.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC._build_agents": [[74, 76], ["None"], "methods", ["None"], ["", "def", "_build_agents", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "agent", "=", "agent_REGISTRY", "[", "self", ".", "args", ".", "agent", "]", "(", "input_shape", ",", "self", ".", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC._build_inputs": [[77, 93], ["torch.cat.append", "torch.cat", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.eye().unsqueeze().expand", "x.reshape", "torch.zeros_like", "torch.eye().unsqueeze", "torch.eye"], "methods", ["None"], ["", "def", "_build_inputs", "(", "self", ",", "batch", ",", "t", ")", ":", "\n", "# Assumes homogenous agents with flat observations.", "\n", "# Other MACs might want to e.g. delegate building inputs to each agent", "\n", "        ", "bs", "=", "batch", ".", "batch_size", "\n", "inputs", "=", "[", "]", "\n", "inputs", ".", "append", "(", "batch", "[", "\"obs\"", "]", "[", ":", ",", "t", "]", ")", "# b1av", "\n", "if", "self", ".", "args", ".", "obs_last_action", ":", "\n", "            ", "if", "t", "==", "0", ":", "\n", "                ", "inputs", ".", "append", "(", "th", ".", "zeros_like", "(", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "t", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "inputs", ".", "append", "(", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "t", "-", "1", "]", ")", "\n", "", "", "if", "self", ".", "args", ".", "obs_agent_id", ":", "\n", "            ", "inputs", ".", "append", "(", "th", ".", "eye", "(", "self", ".", "n_agents", ",", "device", "=", "batch", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "bs", ",", "-", "1", ",", "-", "1", ")", ")", "\n", "\n", "", "inputs", "=", "th", ".", "cat", "(", "[", "x", ".", "reshape", "(", "bs", "*", "self", ".", "n_agents", ",", "-", "1", ")", "for", "x", "in", "inputs", "]", ",", "dim", "=", "1", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.ppo_controller.PPOMAC._get_input_shape": [[94, 102], ["None"], "methods", ["None"], ["", "def", "_get_input_shape", "(", "self", ",", "scheme", ")", ":", "\n", "        ", "input_shape", "=", "scheme", "[", "\"obs\"", "]", "[", "\"vshape\"", "]", "\n", "if", "self", ".", "args", ".", "obs_last_action", ":", "\n", "            ", "input_shape", "+=", "scheme", "[", "\"actions_onehot\"", "]", "[", "\"vshape\"", "]", "[", "0", "]", "\n", "", "if", "self", ".", "args", ".", "obs_agent_id", ":", "\n", "            ", "input_shape", "+=", "self", ".", "n_agents", "\n", "\n", "", "return", "input_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.__init__": [[8, 18], ["basic_controller.BasicMAC._get_input_shape", "basic_controller.BasicMAC._build_agents"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._get_input_shape", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC._build_agents"], ["    ", "def", "__init__", "(", "self", ",", "scheme", ",", "groups", ",", "args", ")", ":", "\n", "        ", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "self", ".", "args", "=", "args", "\n", "input_shape", "=", "self", ".", "_get_input_shape", "(", "scheme", ")", "\n", "self", ".", "_build_agents", "(", "input_shape", ")", "\n", "self", ".", "agent_output_type", "=", "args", ".", "agent_output_type", "\n", "\n", "self", ".", "action_selector", "=", "action_REGISTRY", "[", "args", ".", "action_selector", "]", "(", "args", ")", "\n", "\n", "self", ".", "hidden_states", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.select_actions": [[19, 25], ["slice", "basic_controller.BasicMAC.forward", "basic_controller.BasicMAC.action_selector.select_action"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.forward", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.action_selectors.EpsilonGreedyActionSelector.select_action"], ["", "def", "select_actions", "(", "self", ",", "ep_batch", ",", "t_ep", ",", "t_env", ",", "bs", "=", "slice", "(", "None", ")", ",", "test_mode", "=", "False", ")", ":", "\n", "# Only select actions for the selected batch elements in bs", "\n", "        ", "avail_actions", "=", "ep_batch", "[", "\"avail_actions\"", "]", "[", ":", ",", "t_ep", "]", "\n", "agent_outputs", "=", "self", ".", "forward", "(", "ep_batch", ",", "t_ep", ",", "test_mode", "=", "test_mode", ")", "\n", "chosen_actions", "=", "self", ".", "action_selector", ".", "select_action", "(", "agent_outputs", "[", "bs", "]", ",", "avail_actions", "[", "bs", "]", ",", "t_env", ",", "test_mode", "=", "test_mode", ")", "\n", "return", "chosen_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.forward": [[26, 55], ["basic_controller.BasicMAC._build_inputs", "basic_controller.BasicMAC.agent", "torch.nn.functional.softmax.view", "getattr", "torch.nn.functional.softmax", "avail_actions.reshape", "torch.nn.functional.softmax.size", "getattr", "getattr", "avail_actions.reshape.sum().float", "avail_actions.reshape.sum", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._build_inputs"], ["", "def", "forward", "(", "self", ",", "ep_batch", ",", "t", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "agent_inputs", "=", "self", ".", "_build_inputs", "(", "ep_batch", ",", "t", ")", "\n", "avail_actions", "=", "ep_batch", "[", "\"avail_actions\"", "]", "[", ":", ",", "t", "]", "\n", "agent_outs", ",", "self", ".", "hidden_states", "=", "self", ".", "agent", "(", "agent_inputs", ",", "self", ".", "hidden_states", ")", "\n", "\n", "# Softmax the agent outputs if they're policy logits", "\n", "if", "self", ".", "agent_output_type", "==", "\"pi_logits\"", ":", "\n", "\n", "            ", "if", "getattr", "(", "self", ".", "args", ",", "\"mask_before_softmax\"", ",", "True", ")", ":", "\n", "# Make the logits for unavailable actions very negative to minimise their affect on the softmax", "\n", "                ", "reshaped_avail_actions", "=", "avail_actions", ".", "reshape", "(", "ep_batch", ".", "batch_size", "*", "self", ".", "n_agents", ",", "-", "1", ")", "\n", "agent_outs", "[", "reshaped_avail_actions", "==", "0", "]", "=", "-", "1e10", "\n", "\n", "", "agent_outs", "=", "th", ".", "nn", ".", "functional", ".", "softmax", "(", "agent_outs", ",", "dim", "=", "-", "1", ")", "\n", "if", "not", "test_mode", ":", "\n", "# Epsilon floor", "\n", "                ", "epsilon_action_num", "=", "agent_outs", ".", "size", "(", "-", "1", ")", "\n", "if", "getattr", "(", "self", ".", "args", ",", "\"mask_before_softmax\"", ",", "True", ")", ":", "\n", "# With probability epsilon, we will pick an available action uniformly", "\n", "                    ", "epsilon_action_num", "=", "reshaped_avail_actions", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "float", "(", ")", "\n", "\n", "", "agent_outs", "=", "(", "(", "1", "-", "self", ".", "action_selector", ".", "epsilon", ")", "*", "agent_outs", "\n", "+", "th", ".", "ones_like", "(", "agent_outs", ")", "*", "self", ".", "action_selector", ".", "epsilon", "/", "epsilon_action_num", ")", "\n", "\n", "if", "getattr", "(", "self", ".", "args", ",", "\"mask_before_softmax\"", ",", "True", ")", ":", "\n", "# Zero out the unavailable actions", "\n", "                    ", "agent_outs", "[", "reshaped_avail_actions", "==", "0", "]", "=", "0.0", "\n", "\n", "", "", "", "return", "agent_outs", ".", "view", "(", "ep_batch", ".", "batch_size", ",", "self", ".", "n_agents", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.init_hidden": [[56, 58], ["basic_controller.BasicMAC.agent.init_hidden().unsqueeze().expand", "basic_controller.BasicMAC.agent.init_hidden().unsqueeze", "basic_controller.BasicMAC.agent.init_hidden"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden"], ["", "def", "init_hidden", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "hidden_states", "=", "self", ".", "agent", ".", "init_hidden", "(", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "self", ".", "n_agents", ",", "-", "1", ")", "# bav", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters": [[59, 61], ["basic_controller.BasicMAC.agent.parameters"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.parameters"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "agent", ".", "parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_state": [[62, 64], ["basic_controller.BasicMAC.agent.load_state_dict", "other_mac.agent.state_dict"], "methods", ["None"], ["", "def", "load_state", "(", "self", ",", "other_mac", ")", ":", "\n", "        ", "self", ".", "agent", ".", "load_state_dict", "(", "other_mac", ".", "agent", ".", "state_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda": [[65, 67], ["basic_controller.BasicMAC.agent.cuda"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda"], ["", "def", "cuda", "(", "self", ")", ":", "\n", "        ", "self", ".", "agent", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.save_models": [[68, 70], ["torch.save", "basic_controller.BasicMAC.agent.state_dict"], "methods", ["None"], ["", "def", "save_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "th", ".", "save", "(", "self", ".", "agent", ".", "state_dict", "(", ")", ",", "\"{}/agent.th\"", ".", "format", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.load_models": [[71, 73], ["basic_controller.BasicMAC.agent.load_state_dict", "torch.load"], "methods", ["None"], ["", "def", "load_models", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "agent", ".", "load_state_dict", "(", "th", ".", "load", "(", "\"{}/agent.th\"", ".", "format", "(", "path", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC._build_agents": [[74, 76], ["None"], "methods", ["None"], ["", "def", "_build_agents", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "agent", "=", "agent_REGISTRY", "[", "self", ".", "args", ".", "agent", "]", "(", "input_shape", ",", "self", ".", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC._build_inputs": [[77, 93], ["torch.cat.append", "torch.cat", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.eye().unsqueeze().expand", "x.reshape", "torch.zeros_like", "torch.eye().unsqueeze", "torch.eye"], "methods", ["None"], ["", "def", "_build_inputs", "(", "self", ",", "batch", ",", "t", ")", ":", "\n", "# Assumes homogenous agents with flat observations.", "\n", "# Other MACs might want to e.g. delegate building inputs to each agent", "\n", "        ", "bs", "=", "batch", ".", "batch_size", "\n", "inputs", "=", "[", "]", "\n", "inputs", ".", "append", "(", "batch", "[", "\"obs\"", "]", "[", ":", ",", "t", "]", ")", "# b1av", "\n", "if", "self", ".", "args", ".", "obs_last_action", ":", "\n", "            ", "if", "t", "==", "0", ":", "\n", "                ", "inputs", ".", "append", "(", "th", ".", "zeros_like", "(", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "t", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "inputs", ".", "append", "(", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "t", "-", "1", "]", ")", "\n", "", "", "if", "self", ".", "args", ".", "obs_agent_id", ":", "\n", "            ", "inputs", ".", "append", "(", "th", ".", "eye", "(", "self", ".", "n_agents", ",", "device", "=", "batch", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "bs", ",", "-", "1", ",", "-", "1", ")", ")", "\n", "\n", "", "inputs", "=", "th", ".", "cat", "(", "[", "x", ".", "reshape", "(", "bs", "*", "self", ".", "n_agents", ",", "-", "1", ")", "for", "x", "in", "inputs", "]", ",", "dim", "=", "1", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC._get_input_shape": [[94, 102], ["None"], "methods", ["None"], ["", "def", "_get_input_shape", "(", "self", ",", "scheme", ")", ":", "\n", "        ", "input_shape", "=", "scheme", "[", "\"obs\"", "]", "[", "\"vshape\"", "]", "\n", "if", "self", ".", "args", ".", "obs_last_action", ":", "\n", "            ", "input_shape", "+=", "scheme", "[", "\"actions_onehot\"", "]", "[", "\"vshape\"", "]", "[", "0", "]", "\n", "", "if", "self", ".", "args", ".", "obs_agent_id", ":", "\n", "            ", "input_shape", "+=", "self", ".", "n_agents", "\n", "\n", "", "return", "input_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.rnn_agent.RNNAgent.__init__": [[6, 13], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.GRUCell", "torch.GRUCell", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_shape", ",", "args", ")", ":", "\n", "        ", "super", "(", "RNNAgent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_shape", ",", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "GRUCell", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "n_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.rnn_agent.RNNAgent.init_hidden": [[14, 17], ["rnn_agent.RNNAgent.fc1.weight.new().zero_", "rnn_agent.RNNAgent.fc1.weight.new"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ")", ":", "\n", "# make hidden states on same device as model", "\n", "        ", "return", "self", ".", "fc1", ".", "weight", ".", "new", "(", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ")", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.rnn_agent.RNNAgent.forward": [[18, 24], ["torch.relu", "torch.relu", "hidden_state.reshape", "rnn_agent.RNNAgent.rnn", "rnn_agent.RNNAgent.fc2", "rnn_agent.RNNAgent.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "hidden_state", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "inputs", ")", ")", "\n", "h_in", "=", "hidden_state", ".", "reshape", "(", "-", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ")", "\n", "h", "=", "self", ".", "rnn", "(", "x", ",", "h_in", ")", "\n", "q", "=", "self", ".", "fc2", "(", "h", ")", "\n", "return", "q", ",", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.rnn_agent.RNNPPOAgent.__init__": [[27, 35], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.GRUCell", "torch.GRUCell", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_shape", ",", "args", ")", ":", "\n", "        ", "super", "(", "RNNPPOAgent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_shape", ",", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "GRUCell", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "n_actions", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "args", ".", "rnn_hidden_dim", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.rnn_agent.RNNPPOAgent.init_hidden": [[36, 39], ["rnn_agent.RNNPPOAgent.fc1.weight.new().zero_", "rnn_agent.RNNPPOAgent.fc1.weight.new"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ")", ":", "\n", "# make hidden states on same device as model", "\n", "        ", "return", "self", ".", "fc1", ".", "weight", ".", "new", "(", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ")", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.rnn_agent.RNNPPOAgent.forward": [[40, 47], ["torch.relu", "torch.relu", "hidden_state.reshape", "rnn_agent.RNNPPOAgent.rnn", "rnn_agent.RNNPPOAgent.fc2", "rnn_agent.RNNPPOAgent.fc3", "rnn_agent.RNNPPOAgent.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "hidden_state", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "inputs", ")", ")", "\n", "h_in", "=", "hidden_state", ".", "reshape", "(", "-", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ")", "\n", "h", "=", "self", ".", "rnn", "(", "x", ",", "h_in", ")", "\n", "pi", "=", "self", ".", "fc2", "(", "h", ")", "\n", "q", "=", "self", ".", "fc3", "(", "h", ")", "\n", "return", "pi", ",", "q", ",", "h", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.LayerNorm.__init__": [[20, 25], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["def", "__init__", "(", "self", ",", "n_state", ",", "e", "=", "1e-5", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "g", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "n_state", ")", ")", "\n", "self", ".", "b", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "n_state", ")", ")", "\n", "self", ".", "e", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "e", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.LayerNorm.forward": [[26, 31], ["x.mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "u", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "s", "=", "(", "x", "-", "u", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "(", "x", "-", "u", ")", "/", "torch", ".", "sqrt", "(", "s", "+", "self", ".", "e", ")", "\n", "return", "self", ".", "g", "*", "x", "+", "self", ".", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Conv1D.__init__": [[34, 45], ["torch.Module.__init__", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "rf", ",", "nx", ")", ":", "\n", "        ", "super", "(", "Conv1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rf", "=", "rf", "\n", "self", ".", "nf", "=", "nf", "\n", "if", "rf", "==", "1", ":", "# faster 1x1 conv", "\n", "            ", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "w", "=", "Parameter", "(", "w", ")", "\n", "self", ".", "b", "=", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "", "else", ":", "# was used to train LM", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Conv1D.forward": [[46, 54], ["torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "rf", "==", "1", ":", "\n", "            ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "b", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "w", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.GCN.__init__": [[56, 65], ["torch.Module.__init__", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "nx", ",", "adj", ")", ":", "\n", "        ", "super", "(", "GCN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nf", "=", "nf", "\n", "self", ".", "nx", "=", "nx", "\n", "self", ".", "adj", "=", "adj", "\n", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "w", "=", "Parameter", "(", "w", ")", "\n", "self", ".", "b", "=", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.GCN.forward": [[66, 70], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "pre", "=", "torch", ".", "matmul", "(", "x", ",", "self", ".", "w", ")", "\n", "x", "=", "torch", ".", "matmul", "(", "adj", ",", "pre", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Attention.__init__": [[73, 86], ["torch.Module.__init__", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "gcn_agent.Conv1D", "gcn_agent.Conv1D", "gcn_agent.Conv1D"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_head", ",", "cfg", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "n_head", "==", "0", "\n", "self", ".", "b", "=", "torch", ".", "tensor", "(", "cfg", ".", "adj", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "cfg", ".", "device", ")", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "1", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "1", ",", "nx", ")", "\n", "self", ".", "residue", "=", "cfg", ".", "residue", "\n", "self", ".", "c_proj_1", "=", "Conv1D", "(", "n_state", ",", "1", ",", "nx", ")", "\n", "# self.attn_dropout = nn.Dropout(cfg.attn_pdrop)", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Attention._attn": [[89, 101], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "numpy.prod", "torch.Softmax", "torch.Softmax", "torch.Softmax", "math.sqrt", "b.size", "v.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "# w = w * self.b + -1e9 * (1 - self.b)  # TF implem method: mask_attn_weights", "\n", "", "b", "=", "self", ".", "b", "\n", "if", "torch", ".", "sum", "(", "b", ")", "!=", "np", ".", "prod", "(", "b", ".", "size", "(", ")", ")", ":", "\n", "            ", "w", "=", "w", "*", "b", "+", "-", "1e9", "*", "(", "1", "-", "b", ")", "\n", "\n", "", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "# w = self.attn_dropout(w)", "\n", "return", "torch", ".", "matmul", "(", "w", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Attention.merge_heads": [[102, 106], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Attention.split_heads": [[107, 114], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Attention.forward": [[115, 131], ["gcn_agent.Attention.c_attn", "gcn_agent.Attention.split", "gcn_agent.Attention.split_heads", "gcn_agent.Attention.split_heads", "gcn_agent.Attention.split_heads", "gcn_agent.Attention._attn", "gcn_agent.Attention.merge_heads", "gcn_agent.Attention.c_proj", "gcn_agent.Attention.clone", "gcn_agent.Attention.merge_heads", "gcn_agent.Attention.c_proj_1"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Attention.split_heads", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Attention.split_heads", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Attention.split_heads", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Attention._attn", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Attention.merge_heads", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "a", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ")", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "if", "self", ".", "residue", ":", "\n", "            ", "residue", "=", "query", ".", "clone", "(", ")", "\n", "residue", "=", "self", ".", "merge_heads", "(", "residue", ")", "\n", "re", "=", "self", ".", "c_proj_1", "(", "residue", ")", "\n", "a", "+=", "re", "\n", "# a = self.resid_dropout(a)", "\n", "", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.GATAgent.__init__": [[137, 149], ["torch.Module.__init__", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "gcn_agent.Conv1D", "gcn_agent.Conv1D", "gcn_agent.Conv1D", "torch.GRUCell", "torch.GRUCell", "torch.GRUCell", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["def", "__init__", "(", "self", ",", "input_shape", ",", "args", ")", ":", "\n", "        ", "super", "(", "GATAgent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "adj", "=", "torch", ".", "tensor", "(", "args", ".", "adj", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "args", ".", "device", ")", "\n", "self", ".", "bias", "=", "-", "1e9", "*", "(", "1.0", "-", "self", ".", "adj", ")", "\n", "self", ".", "residue", "=", "args", ".", "residue", "\n", "\n", "self", ".", "conv1", "=", "Conv1D", "(", "args", ".", "rnn_hidden_dim", ",", "1", ",", "input_shape", ")", "\n", "self", ".", "conv2", "=", "Conv1D", "(", "1", ",", "1", ",", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "conv3", "=", "Conv1D", "(", "1", ",", "1", ",", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "GRUCell", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "n_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.GATAgent.init_hidden": [[150, 153], ["torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ")", ":", "\n", "# make hidden states on same device as model", "\n", "        ", "return", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ",", "device", "=", "self", ".", "args", ".", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.GATAgent.forward": [[154, 176], ["inputs.view.view.view", "torch.relu", "torch.relu", "torch.relu", "gcn_agent.GATAgent.conv2", "gcn_agent.GATAgent.conv3", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "att.view.view.view", "hidden_state.reshape", "gcn_agent.GATAgent.rnn", "gcn_agent.GATAgent.fc1", "gcn_agent.GATAgent.conv1", "gcn_agent.GATAgent.transpose", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "hidden_state", ")", ":", "\n", "# x shape is [batch_size * n_agents, input_shape]", "\n", "# encode raw data into feature tensors", "\n", "        ", "inputs", "=", "inputs", ".", "view", "(", "self", ".", "args", ".", "batch_size", ",", "self", ".", "args", ".", "n_agents", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "inputs", ")", ")", "\n", "# calculate attention weights", "\n", "f2", "=", "self", ".", "conv2", "(", "x", ")", "\n", "f3", "=", "self", ".", "conv3", "(", "x", ")", "\n", "logits", "=", "f2", "+", "f3", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "logits", "*=", "self", ".", "adj", "\n", "# add bias to make the weights for non-connected nodes very small", "\n", "att_weights", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "nn", ".", "LeakyReLU", "(", ")", "(", "logits", ")", "+", "self", ".", "bias", ")", "\n", "att", "=", "torch", ".", "matmul", "(", "att_weights", ",", "x", ")", "\n", "if", "self", ".", "residue", ":", "\n", "            ", "att", "+=", "x", "\n", "# reshape att from [batch_size, n_agents, rnn_hidden_dim] to [batch_size * n_agents, rnn_hidden_dim]", "\n", "", "att", "=", "att", ".", "view", "(", "-", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ")", "\n", "# rnn learns the changes of node embeddings over time", "\n", "h_in", "=", "hidden_state", ".", "reshape", "(", "-", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ")", "\n", "h", "=", "self", ".", "rnn", "(", "att", ",", "h_in", ")", "\n", "q", "=", "self", ".", "fc1", "(", "h", ")", "\n", "return", "q", ",", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.GCNAgent.__init__": [[182, 192], ["torch.Module.__init__", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "gcn_agent.GCN", "gcn_agent.GCN", "torch.GRUCell", "torch.GRUCell", "torch.GRUCell", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["def", "__init__", "(", "self", ",", "input_shape", ",", "args", ")", ":", "\n", "        ", "super", "(", "GCNAgent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "adj", "=", "torch", ".", "tensor", "(", "args", ".", "adj", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "args", ".", "device", ")", "\n", "# self.bias = -1e9 * (1.0 - self.adj)", "\n", "\n", "self", ".", "gcn1", "=", "GCN", "(", "args", ".", "rnn_hidden_dim", ",", "input_shape", ",", "self", ".", "adj", ")", "\n", "self", ".", "gcn2", "=", "GCN", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "rnn_hidden_dim", ",", "self", ".", "adj", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "GRUCell", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "n_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.GCNAgent.init_hidden": [[193, 196], ["torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ")", ":", "\n", "# make hidden states on same device as model", "\n", "        ", "return", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ",", "device", "=", "self", ".", "args", ".", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.GCNAgent.forward": [[197, 212], ["inputs.view.view.view", "gcn_agent.GCNAgent.conv1", "torch.relu", "torch.relu", "torch.relu", "gcn_agent.GCNAgent.gcn2", "x.view.view.view", "hidden_state.reshape", "gcn_agent.GCNAgent.rnn", "gcn_agent.GCNAgent.fc1", "gcn_agent.GCNAgent.gcn1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "hidden_state", ")", ":", "\n", "# x shape is [batch_size * n_agents, input_shape]", "\n", "# encode raw data into feature tensors", "\n", "        ", "inputs", "=", "inputs", ".", "view", "(", "self", ".", "args", ".", "batch_size", ",", "self", ".", "args", ".", "n_agents", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "conv1", "(", "inputs", ")", "\n", "# calculate attention weights", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "gcn1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "gcn2", "(", "x", ")", "\n", "# reshape att from [batch_size, n_agents, rnn_hidden_dim] to [batch_size * n_agents, rnn_hidden_dim]", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ")", "\n", "# rnn learns the changes of node embeddings over time", "\n", "h_in", "=", "hidden_state", ".", "reshape", "(", "-", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ")", "\n", "h", "=", "self", ".", "rnn", "(", "x", ",", "h_in", ")", "\n", "q", "=", "self", ".", "fc1", "(", "h", ")", "\n", "return", "q", ",", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.__init__": [[218, 237], ["torch.Module.__init__", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.Linear", "torch.Linear", "torch.Linear", "range", "gcn_agent.LayerNorm", "torch.GRUCell", "torch.GRUCell", "torch.GRUCell", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "gcn_agent.TRANSAgent.blocks.append", "gcn_agent.TRANSAgent.blocks.append", "Attention().cuda", "gcn_agent.Attention", "gcn_agent.Attention"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.cuda"], ["def", "__init__", "(", "self", ",", "input_shape", ",", "args", ")", ":", "\n", "        ", "super", "(", "TRANSAgent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "adj", "=", "torch", ".", "tensor", "(", "args", ".", "adj", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "args", ".", "device", ")", "\n", "num_blocks", "=", "args", ".", "num_blocks", "\n", "self", ".", "bias", "=", "-", "1e9", "*", "(", "1.0", "-", "self", ".", "adj", ")", "\n", "self", ".", "residue", "=", "args", ".", "residue", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_shape", ",", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "blocks", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "            ", "if", "args", ".", "device", "==", "'cuda'", ":", "\n", "                ", "self", ".", "blocks", ".", "append", "(", "Attention", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "n_head", ",", "args", ")", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "blocks", ".", "append", "(", "Attention", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "n_head", ",", "args", ")", ")", "\n", "", "", "self", ".", "ln", "=", "LayerNorm", "(", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "GRUCell", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "2", "*", "args", ".", "rnn_hidden_dim", ",", "args", ".", "rnn_hidden_dim", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "args", ".", "rnn_hidden_dim", ",", "args", ".", "n_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden": [[238, 241], ["torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ")", ":", "\n", "# make hidden states on same device as model", "\n", "        ", "return", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ",", "device", "=", "self", ".", "args", ".", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.forward": [[242, 265], ["inputs.view.view.view", "torch.relu", "torch.relu", "torch.relu", "gcn_agent.TRANSAgent.ln", "torch.relu.clone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gcn_agent.TRANSAgent.fc2", "hidden_state.reshape", "embed_x.view.view.view", "gcn_agent.TRANSAgent.rnn", "gcn_agent.TRANSAgent.fc3", "gcn_agent.TRANSAgent.fc1", "att"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "hidden_state", ")", ":", "\n", "# x shape is [batch_size * n_agents, input_shape]", "\n", "# encode raw data into feature tensors", "\n", "        ", "inputs", "=", "inputs", ".", "view", "(", "self", ".", "args", ".", "batch_size", ",", "self", ".", "args", ".", "n_agents", ",", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "inputs", ")", ")", "\n", "# x = self.fc1(inputs)", "\n", "embed", "=", "x", "\n", "# x size is [batch_size, n_agents, rnn_hidden_dim]", "\n", "for", "att", "in", "self", ".", "blocks", ":", "\n", "            ", "embed", "=", "att", "(", "embed", ")", "\n", "# embed = self.ln(embed)", "\n", "# message_x = embed", "\n", "", "message_x", "=", "self", ".", "ln", "(", "embed", ")", "#layernorm is good at the end of blocks", "\n", "new_x", "=", "x", ".", "clone", "(", ")", "\n", "biased_x", "=", "torch", ".", "cat", "(", "(", "new_x", ",", "message_x", ")", ",", "dim", "=", "-", "1", ")", "\n", "embed_x", "=", "self", ".", "fc2", "(", "biased_x", ")", "\n", "embed_x", "=", "message_x", "\n", "h_in", "=", "hidden_state", ".", "reshape", "(", "-", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ")", "\n", "# reshape att from [batch_size, n_agents, rnn_hidden_dim] to [batch_size * n_agents, rnn_hidden_dim]", "\n", "embed_x", "=", "embed_x", ".", "view", "(", "-", "1", ",", "self", ".", "args", ".", "rnn_hidden_dim", ")", "\n", "h", "=", "self", ".", "rnn", "(", "embed_x", ",", "h_in", ")", "\n", "q", "=", "self", ".", "fc3", "(", "h", ")", "\n", "return", "q", ",", "h", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.maddpg_critic.MADDPGCritic.__init__": [[13, 27], ["torch.Module.__init__", "maddpg_critic.MADDPGCritic._get_input_shape", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._get_input_shape"], ["    ", "def", "__init__", "(", "self", ",", "scheme", ",", "args", ")", ":", "\n", "        ", "super", "(", "MADDPGCritic", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "n_actions", "=", "args", ".", "n_actions", "\n", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "\n", "input_shape", "=", "self", ".", "_get_input_shape", "(", "scheme", ")", "\n", "self", ".", "output_type", "=", "\"q\"", "\n", "\n", "# Set up network layers", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_shape", ",", "128", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "128", ",", "128", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "128", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.maddpg_critic.MADDPGCritic.forward": [[28, 34], ["maddpg_critic.MADDPGCritic._build_inputs", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "maddpg_critic.MADDPGCritic.fc3", "maddpg_critic.MADDPGCritic.fc1", "maddpg_critic.MADDPGCritic.fc2"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._build_inputs"], ["", "def", "forward", "(", "self", ",", "batch", ",", "action", "=", "None", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "_build_inputs", "(", "batch", ",", "actions", "=", "action", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "inputs", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "q", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "q", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.maddpg_critic.MADDPGCritic._build_inputs": [[35, 72], ["torch.cat.append", "overall_actions[].view().repeat", "overall_mask.view().repeat().view.view().repeat().view.view().repeat().view", "actions[].view().repeat", "agent_mask.view().repeat().view.view().repeat().view.view().repeat().view", "torch.cat.append", "torch.cat.append", "torch.cat", "torch.cat", "torch.cat", "[].unsqueeze().repeat().view", "onehot_encode.clone().detach", "torch.eye", "torch.eye", "torch.eye", "overall_mask.view().repeat().view.view().repeat().view.unsqueeze().unsqueeze", "torch.eye", "torch.eye", "torch.eye", "agent_mask.view().repeat().view.view().repeat().view.unsqueeze().unsqueeze", "torch.eye().unsqueeze().unsqueeze().expand", "torch.eye().unsqueeze().unsqueeze().expand", "torch.eye().unsqueeze().unsqueeze().expand", "maddpg_critic.onehot_encode", "onehot_encode.clone().detach", "overall_actions[].view", "overall_mask.view().repeat().view.view().repeat().view.view().repeat", "actions[].view", "agent_mask.view().repeat().view.view().repeat().view.view().repeat", "x.reshape", "[].unsqueeze().repeat", "onehot_encode.clone", "onehot_encode.size", "overall_mask.view().repeat().view.view().repeat().view.unsqueeze", "agent_mask.view().repeat().view.view().repeat().view.unsqueeze", "torch.eye().unsqueeze().unsqueeze", "torch.eye().unsqueeze().unsqueeze", "torch.eye().unsqueeze().unsqueeze", "onehot_encode.clone", "overall_mask.view().repeat().view.view().repeat().view.view", "agent_mask.view().repeat().view.view().repeat().view.view", "[].unsqueeze", "torch.eye().unsqueeze", "torch.eye().unsqueeze", "torch.eye().unsqueeze", "torch.eye", "torch.eye", "torch.eye"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.iac_critic.onehot_encode"], ["", "def", "_build_inputs", "(", "self", ",", "batch", ",", "actions", "=", "None", ")", ":", "\n", "        ", "bs", "=", "batch", ".", "batch_size", "\n", "max_t", "=", "batch", ".", "max_seq_length", "\n", "inputs", "=", "[", "]", "\n", "\n", "# states repeated for all agents", "\n", "inputs", ".", "append", "(", "batch", "[", "\"state\"", "]", "[", ":", ",", ":", "]", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", ".", "view", "(", "bs", ",", "max_t", ",", "self", ".", "n_agents", ",", "-", "1", ")", ")", "\n", "\n", "# last actions", "\n", "if", "actions", "==", "None", ":", "\n", "            ", "actions", "=", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", ":", "]", "#[batch, time, agent, actions]", "\n", "overall_actions", "=", "actions", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "# actions are of shape [batch, time, agent, 1], first we need to onehot code it", "\n", "            ", "if", "actions", ".", "size", "(", ")", "[", "-", "1", "]", "==", "1", ":", "\n", "                ", "actions", "=", "onehot_encode", "(", "actions", ",", "self", ".", "n_actions", ")", "\n", "overall_actions", "=", "actions", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n", "", "", "overall_actions", "=", "overall_actions", "[", ":", ",", ":", "]", ".", "view", "(", "bs", ",", "max_t", ",", "1", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", "\n", "overall_mask", "=", "(", "1", "-", "th", ".", "eye", "(", "self", ".", "n_agents", ",", "device", "=", "batch", ".", "device", ")", ")", "\n", "overall_mask", "=", "overall_mask", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "n_actions", ")", ".", "view", "(", "self", ".", "n_agents", ",", "-", "1", ")", "\n", "overall_actions", "=", "overall_actions", "*", "overall_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "# inputs.append(overall_actions * agent_mask.unsqueeze(0).unsqueeze(0))", "\n", "\n", "agent_actions", "=", "actions", "[", ":", ",", ":", "]", ".", "view", "(", "bs", ",", "max_t", ",", "1", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", "\n", "agent_mask", "=", "(", "1", "-", "th", ".", "eye", "(", "self", ".", "n_agents", ",", "device", "=", "batch", ".", "device", ")", ")", "\n", "agent_mask", "=", "agent_mask", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "n_actions", ")", ".", "view", "(", "self", ".", "n_agents", ",", "-", "1", ")", "\n", "agent_actions", "=", "agent_actions", "*", "agent_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "tot_actions", "=", "overall_actions", "+", "agent_actions", "\n", "\n", "inputs", ".", "append", "(", "tot_actions", ")", "\n", "\n", "inputs", ".", "append", "(", "th", ".", "eye", "(", "self", ".", "n_agents", ",", "device", "=", "batch", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "bs", ",", "max_t", ",", "-", "1", ",", "-", "1", ")", ")", "\n", "\n", "inputs", "=", "th", ".", "cat", "(", "[", "x", ".", "reshape", "(", "bs", ",", "max_t", ",", "self", ".", "n_agents", ",", "-", "1", ")", "for", "x", "in", "inputs", "]", ",", "dim", "=", "-", "1", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.maddpg_critic.MADDPGCritic._get_input_shape": [[73, 83], ["None"], "methods", ["None"], ["", "def", "_get_input_shape", "(", "self", ",", "scheme", ")", ":", "\n", "# state", "\n", "        ", "input_shape", "=", "scheme", "[", "\"state\"", "]", "[", "\"vshape\"", "]", "\n", "# actions masked out one agent", "\n", "input_shape", "+=", "scheme", "[", "\"actions_onehot\"", "]", "[", "\"vshape\"", "]", "[", "0", "]", "*", "self", ".", "n_agents", "\n", "# actions of the agent", "\n", "# input_shape += scheme[\"actions_onehot\"][\"vshape\"][0]", "\n", "# agent id", "\n", "input_shape", "+=", "self", ".", "n_agents", "\n", "return", "input_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.maddpg_critic.onehot_encode": [[7, 11], ["tensor.new().zero_", "tensor.new().zero_.scatter_", "tensor.new().zero_.float", "tensor.long", "tensor.new"], "function", ["None"], ["def", "onehot_encode", "(", "tensor", ",", "target_dim", ")", ":", "\n", "    ", "y_onehot", "=", "tensor", ".", "new", "(", "*", "tensor", ".", "shape", "[", ":", "-", "1", "]", ",", "target_dim", ")", ".", "zero_", "(", ")", "\n", "y_onehot", ".", "scatter_", "(", "-", "1", ",", "tensor", ".", "long", "(", ")", ",", "1", ")", "\n", "return", "y_onehot", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.iac_critic.IACritic.__init__": [[11, 25], ["torch.Module.__init__", "iac_critic.IACritic._get_input_shape", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._get_input_shape"], ["    ", "def", "__init__", "(", "self", ",", "scheme", ",", "args", ")", ":", "\n", "        ", "super", "(", "IACritic", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "n_actions", "=", "args", ".", "n_actions", "\n", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "\n", "input_shape", "=", "self", ".", "_get_input_shape", "(", "scheme", ")", "\n", "self", ".", "output_type", "=", "\"q\"", "\n", "\n", "# Set up network layers", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_shape", ",", "128", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "128", ",", "128", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "128", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.iac_critic.IACritic.forward": [[26, 32], ["iac_critic.IACritic._build_inputs", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "iac_critic.IACritic.fc3", "iac_critic.IACritic.fc1", "iac_critic.IACritic.fc2"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._build_inputs"], ["", "def", "forward", "(", "self", ",", "batch", ",", "t", "=", "None", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "_build_inputs", "(", "batch", ",", "t", "=", "t", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "inputs", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "q", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "q", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.iac_critic.IACritic._build_inputs": [[33, 51], ["torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat", "torch.cat", "torch.cat", "slice", "slice", "torch.eye().unsqueeze().unsqueeze().expand", "torch.eye().unsqueeze().unsqueeze().expand", "torch.eye().unsqueeze().unsqueeze().expand", "x.reshape", "torch.eye().unsqueeze().unsqueeze", "torch.eye().unsqueeze().unsqueeze", "torch.eye().unsqueeze().unsqueeze", "torch.eye().unsqueeze", "torch.eye().unsqueeze", "torch.eye().unsqueeze", "torch.eye", "torch.eye", "torch.eye"], "methods", ["None"], ["", "def", "_build_inputs", "(", "self", ",", "batch", ",", "t", "=", "None", ")", ":", "\n", "        ", "bs", "=", "batch", ".", "batch_size", "\n", "max_t", "=", "batch", ".", "max_seq_length", "if", "t", "is", "None", "else", "1", "\n", "ts", "=", "slice", "(", "None", ")", "if", "t", "is", "None", "else", "slice", "(", "t", ",", "t", "+", "1", ")", "\n", "inputs", "=", "[", "]", "\n", "\n", "# observations", "\n", "obs", "=", "batch", "[", "\"obs\"", "]", "[", ":", ",", "ts", "]", "\n", "inputs", ".", "append", "(", "obs", ")", "\n", "\n", "# actions", "\n", "actions", "=", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "ts", "]", "\n", "inputs", ".", "append", "(", "actions", ")", "\n", "\n", "inputs", ".", "append", "(", "th", ".", "eye", "(", "self", ".", "n_agents", ",", "device", "=", "batch", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "bs", ",", "max_t", ",", "-", "1", ",", "-", "1", ")", ")", "\n", "\n", "inputs", "=", "th", ".", "cat", "(", "[", "x", ".", "reshape", "(", "bs", ",", "max_t", ",", "self", ".", "n_agents", ",", "-", "1", ")", "for", "x", "in", "inputs", "]", ",", "dim", "=", "-", "1", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.iac_critic.IACritic._get_input_shape": [[52, 60], ["None"], "methods", ["None"], ["", "def", "_get_input_shape", "(", "self", ",", "scheme", ")", ":", "\n", "# observation", "\n", "        ", "input_shape", "=", "scheme", "[", "\"obs\"", "]", "[", "\"vshape\"", "]", "\n", "# actions", "\n", "input_shape", "+=", "scheme", "[", "\"actions_onehot\"", "]", "[", "\"vshape\"", "]", "[", "0", "]", "\n", "# agent id", "\n", "input_shape", "+=", "self", ".", "n_agents", "\n", "return", "input_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.iac_critic.onehot_encode": [[5, 9], ["tensor.new().zero_", "tensor.new().zero_.scatter_", "tensor.new().zero_.float", "tensor.long", "tensor.new"], "function", ["None"], ["def", "onehot_encode", "(", "tensor", ",", "target_dim", ")", ":", "\n", "    ", "y_onehot", "=", "tensor", ".", "new", "(", "*", "tensor", ".", "shape", "[", ":", "-", "1", "]", ",", "target_dim", ")", ".", "zero_", "(", ")", "\n", "y_onehot", ".", "scatter_", "(", "-", "1", ",", "tensor", ".", "long", "(", ")", ",", "1", ")", "\n", "return", "y_onehot", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.coma.COMACritic.__init__": [[7, 21], ["torch.Module.__init__", "coma.COMACritic._get_input_shape", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._get_input_shape"], ["    ", "def", "__init__", "(", "self", ",", "scheme", ",", "args", ")", ":", "\n", "        ", "super", "(", "COMACritic", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "n_actions", "=", "args", ".", "n_actions", "\n", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "\n", "input_shape", "=", "self", ".", "_get_input_shape", "(", "scheme", ")", "\n", "self", ".", "output_type", "=", "\"q\"", "\n", "\n", "# Set up network layers", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_shape", ",", "128", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "128", ",", "128", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "128", ",", "self", ".", "n_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.coma.COMACritic.forward": [[22, 28], ["coma.COMACritic._build_inputs", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "coma.COMACritic.fc3", "coma.COMACritic.fc1", "coma.COMACritic.fc2"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._build_inputs"], ["", "def", "forward", "(", "self", ",", "batch", ",", "t", "=", "None", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "_build_inputs", "(", "batch", ",", "t", "=", "t", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "inputs", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "q", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "q", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.coma.COMACritic._build_inputs": [[29, 60], ["torch.cat.append", "torch.cat.append", "[].view().repeat", "agent_mask.view().repeat().view.view().repeat().view.view().repeat().view", "torch.cat.append", "torch.cat.append", "torch.cat", "torch.cat", "torch.cat", "slice", "slice", "[].unsqueeze().repeat", "torch.eye", "torch.eye", "torch.eye", "torch.cat.append", "isinstance", "torch.eye().unsqueeze().unsqueeze().expand", "torch.eye().unsqueeze().unsqueeze().expand", "torch.eye().unsqueeze().unsqueeze().expand", "[].view", "agent_mask.view().repeat().view.view().repeat().view.view().repeat", "agent_mask.view().repeat().view.view().repeat().view.unsqueeze().unsqueeze", "torch.zeros_like().view().repeat", "torch.zeros_like().view().repeat", "torch.zeros_like().view().repeat", "torch.cat.append", "torch.cat", "torch.cat", "torch.cat", "last_actions.view().repeat.view().repeat.view().repeat", "torch.cat.append", "x.reshape", "[].unsqueeze", "[].view().repeat", "torch.eye().unsqueeze().unsqueeze", "torch.eye().unsqueeze().unsqueeze", "torch.eye().unsqueeze().unsqueeze", "agent_mask.view().repeat().view.view().repeat().view.view", "agent_mask.view().repeat().view.view().repeat().view.unsqueeze", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "last_actions.view().repeat.view().repeat.view", "[].view", "torch.eye().unsqueeze", "torch.eye().unsqueeze", "torch.eye().unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.eye", "torch.eye", "torch.eye", "slice"], "methods", ["None"], ["", "def", "_build_inputs", "(", "self", ",", "batch", ",", "t", "=", "None", ")", ":", "\n", "        ", "bs", "=", "batch", ".", "batch_size", "\n", "max_t", "=", "batch", ".", "max_seq_length", "if", "t", "is", "None", "else", "1", "\n", "ts", "=", "slice", "(", "None", ")", "if", "t", "is", "None", "else", "slice", "(", "t", ",", "t", "+", "1", ")", "\n", "inputs", "=", "[", "]", "\n", "# state", "\n", "inputs", ".", "append", "(", "batch", "[", "\"state\"", "]", "[", ":", ",", "ts", "]", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", ")", "\n", "\n", "# observation", "\n", "inputs", ".", "append", "(", "batch", "[", "\"obs\"", "]", "[", ":", ",", "ts", "]", ")", "\n", "\n", "# actions (masked out by agent)", "\n", "actions", "=", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "ts", "]", ".", "view", "(", "bs", ",", "max_t", ",", "1", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", "\n", "agent_mask", "=", "(", "1", "-", "th", ".", "eye", "(", "self", ".", "n_agents", ",", "device", "=", "batch", ".", "device", ")", ")", "\n", "agent_mask", "=", "agent_mask", ".", "view", "(", "-", "1", ",", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "n_actions", ")", ".", "view", "(", "self", ".", "n_agents", ",", "-", "1", ")", "\n", "inputs", ".", "append", "(", "actions", "*", "agent_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "# last actions", "\n", "if", "t", "==", "0", ":", "\n", "            ", "inputs", ".", "append", "(", "th", ".", "zeros_like", "(", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "0", ":", "1", "]", ")", ".", "view", "(", "bs", ",", "max_t", ",", "1", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", ")", "\n", "", "elif", "isinstance", "(", "t", ",", "int", ")", ":", "\n", "            ", "inputs", ".", "append", "(", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "slice", "(", "t", "-", "1", ",", "t", ")", "]", ".", "view", "(", "bs", ",", "max_t", ",", "1", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "last_actions", "=", "th", ".", "cat", "(", "[", "th", ".", "zeros_like", "(", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "0", ":", "1", "]", ")", ",", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", ":", "-", "1", "]", "]", ",", "dim", "=", "1", ")", "\n", "last_actions", "=", "last_actions", ".", "view", "(", "bs", ",", "max_t", ",", "1", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", "\n", "inputs", ".", "append", "(", "last_actions", ")", "\n", "\n", "", "inputs", ".", "append", "(", "th", ".", "eye", "(", "self", ".", "n_agents", ",", "device", "=", "batch", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "bs", ",", "max_t", ",", "-", "1", ",", "-", "1", ")", ")", "\n", "\n", "inputs", "=", "th", ".", "cat", "(", "[", "x", ".", "reshape", "(", "bs", ",", "max_t", ",", "self", ".", "n_agents", ",", "-", "1", ")", "for", "x", "in", "inputs", "]", ",", "dim", "=", "-", "1", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.coma.COMACritic._get_input_shape": [[61, 71], ["None"], "methods", ["None"], ["", "def", "_get_input_shape", "(", "self", ",", "scheme", ")", ":", "\n", "# state", "\n", "        ", "input_shape", "=", "scheme", "[", "\"state\"", "]", "[", "\"vshape\"", "]", "\n", "# observation", "\n", "input_shape", "+=", "scheme", "[", "\"obs\"", "]", "[", "\"vshape\"", "]", "\n", "# actions and last actions", "\n", "input_shape", "+=", "scheme", "[", "\"actions_onehot\"", "]", "[", "\"vshape\"", "]", "[", "0", "]", "*", "self", ".", "n_agents", "*", "2", "\n", "# agent id", "\n", "input_shape", "+=", "self", ".", "n_agents", "\n", "return", "input_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic.__init__": [[7, 21], ["torch.Module.__init__", "ctl_critic.CTLCritic._get_input_shape", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._get_input_shape"], ["    ", "def", "__init__", "(", "self", ",", "scheme", ",", "args", ")", ":", "\n", "        ", "super", "(", "CTLCritic", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "n_actions", "=", "args", ".", "n_actions", "\n", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "\n", "input_shape", "=", "self", ".", "_get_input_shape", "(", "scheme", ")", "\n", "self", ".", "output_type", "=", "\"q\"", "\n", "\n", "# Set up network layers", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_shape", ",", "128", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "128", ",", "128", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "128", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic.forward": [[22, 28], ["ctl_critic.CTLCritic._build_inputs", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "ctl_critic.CTLCritic.fc3", "ctl_critic.CTLCritic.fc1", "ctl_critic.CTLCritic.fc2"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._build_inputs"], ["", "def", "forward", "(", "self", ",", "batch", ",", "t", "=", "None", ")", ":", "\n", "        ", "inputs", "=", "self", ".", "_build_inputs", "(", "batch", ",", "t", "=", "t", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "inputs", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "q", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "q", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._build_inputs": [[29, 54], ["torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat", "torch.cat", "torch.cat", "slice", "slice", "[].unsqueeze().repeat", "torch.cat.append", "isinstance", "torch.eye().unsqueeze().unsqueeze().expand", "torch.eye().unsqueeze().unsqueeze().expand", "torch.eye().unsqueeze().unsqueeze().expand", "torch.zeros_like().view().repeat", "torch.zeros_like().view().repeat", "torch.zeros_like().view().repeat", "torch.cat.append", "torch.cat", "torch.cat", "torch.cat", "last_actions.view().repeat.view().repeat.view().repeat", "torch.cat.append", "x.reshape", "[].unsqueeze", "[].view().repeat", "torch.eye().unsqueeze().unsqueeze", "torch.eye().unsqueeze().unsqueeze", "torch.eye().unsqueeze().unsqueeze", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like().view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "last_actions.view().repeat.view().repeat.view", "[].view", "torch.eye().unsqueeze", "torch.eye().unsqueeze", "torch.eye().unsqueeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.eye", "torch.eye", "torch.eye", "slice"], "methods", ["None"], ["", "def", "_build_inputs", "(", "self", ",", "batch", ",", "t", "=", "None", ")", ":", "\n", "        ", "bs", "=", "batch", ".", "batch_size", "\n", "max_t", "=", "batch", ".", "max_seq_length", "if", "t", "is", "None", "else", "1", "\n", "ts", "=", "slice", "(", "None", ")", "if", "t", "is", "None", "else", "slice", "(", "t", ",", "t", "+", "1", ")", "\n", "inputs", "=", "[", "]", "\n", "# state", "\n", "inputs", ".", "append", "(", "batch", "[", "\"state\"", "]", "[", ":", ",", "ts", "]", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", ")", "\n", "\n", "# observation", "\n", "inputs", ".", "append", "(", "batch", "[", "\"obs\"", "]", "[", ":", ",", "ts", "]", ")", "\n", "\n", "# last actions", "\n", "if", "t", "==", "0", ":", "\n", "            ", "inputs", ".", "append", "(", "th", ".", "zeros_like", "(", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "0", ":", "1", "]", ")", ".", "view", "(", "bs", ",", "max_t", ",", "1", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", ")", "\n", "", "elif", "isinstance", "(", "t", ",", "int", ")", ":", "\n", "            ", "inputs", ".", "append", "(", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "slice", "(", "t", "-", "1", ",", "t", ")", "]", ".", "view", "(", "bs", ",", "max_t", ",", "1", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "last_actions", "=", "th", ".", "cat", "(", "[", "th", ".", "zeros_like", "(", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", "0", ":", "1", "]", ")", ",", "batch", "[", "\"actions_onehot\"", "]", "[", ":", ",", ":", "-", "1", "]", "]", ",", "dim", "=", "1", ")", "\n", "last_actions", "=", "last_actions", ".", "view", "(", "bs", ",", "max_t", ",", "1", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_agents", ",", "1", ")", "\n", "inputs", ".", "append", "(", "last_actions", ")", "\n", "\n", "", "inputs", ".", "append", "(", "th", ".", "eye", "(", "self", ".", "n_agents", ",", "device", "=", "batch", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "bs", ",", "max_t", ",", "-", "1", ",", "-", "1", ")", ")", "\n", "\n", "inputs", "=", "th", ".", "cat", "(", "[", "x", ".", "reshape", "(", "bs", ",", "max_t", ",", "self", ".", "n_agents", ",", "-", "1", ")", "for", "x", "in", "inputs", "]", ",", "dim", "=", "-", "1", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.critics.ctl_critic.CTLCritic._get_input_shape": [[55, 65], ["None"], "methods", ["None"], ["", "def", "_get_input_shape", "(", "self", ",", "scheme", ")", ":", "\n", "# state", "\n", "        ", "input_shape", "=", "scheme", "[", "\"state\"", "]", "[", "\"vshape\"", "]", "\n", "# observation", "\n", "input_shape", "+=", "scheme", "[", "\"obs\"", "]", "[", "\"vshape\"", "]", "\n", "# last actions", "\n", "input_shape", "+=", "scheme", "[", "\"actions_onehot\"", "]", "[", "\"vshape\"", "]", "[", "0", "]", "*", "self", ".", "n_agents", "\n", "# agent id", "\n", "input_shape", "+=", "self", ".", "n_agents", "\n", "return", "input_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.qtran.QTranBase.__init__": [[8, 69], ["torch.Module.__init__", "int", "numpy.prod", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "Exception", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "QTranBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "self", ".", "n_actions", "=", "args", ".", "n_actions", "\n", "self", ".", "state_dim", "=", "int", "(", "np", ".", "prod", "(", "args", ".", "state_shape", ")", ")", "\n", "self", ".", "arch", "=", "self", ".", "args", ".", "qtran_arch", "# QTran architecture", "\n", "\n", "self", ".", "embed_dim", "=", "args", ".", "mixing_embed_dim", "\n", "\n", "# Q(s,u)", "\n", "if", "self", ".", "arch", "==", "\"coma_critic\"", ":", "\n", "# Q takes [state, u] as input", "\n", "            ", "q_input_size", "=", "self", ".", "state_dim", "+", "(", "self", ".", "n_agents", "*", "self", ".", "n_actions", ")", "\n", "", "elif", "self", ".", "arch", "==", "\"qtran_paper\"", ":", "\n", "# Q takes [state, agent_action_observation_encodings]", "\n", "            ", "q_input_size", "=", "self", ".", "state_dim", "+", "self", ".", "args", ".", "rnn_hidden_dim", "+", "self", ".", "n_actions", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"{} is not a valid QTran architecture\"", ".", "format", "(", "self", ".", "arch", ")", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "network_size", "==", "\"small\"", ":", "\n", "            ", "self", ".", "Q", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "q_input_size", ",", "self", ".", "embed_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "1", ")", ")", "\n", "\n", "# V(s)", "\n", "self", ".", "V", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "state_dim", ",", "self", ".", "embed_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "1", ")", ")", "\n", "ae_input", "=", "self", ".", "args", ".", "rnn_hidden_dim", "+", "self", ".", "n_actions", "\n", "self", ".", "action_encoding", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "ae_input", ",", "ae_input", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "ae_input", ",", "ae_input", ")", ")", "\n", "", "elif", "self", ".", "args", ".", "network_size", "==", "\"big\"", ":", "\n", "            ", "self", ".", "Q", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "q_input_size", ",", "self", ".", "embed_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "1", ")", ")", "\n", "# V(s)", "\n", "self", ".", "V", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "state_dim", ",", "self", ".", "embed_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "1", ")", ")", "\n", "ae_input", "=", "self", ".", "args", ".", "rnn_hidden_dim", "+", "self", ".", "n_actions", "\n", "self", ".", "action_encoding", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "ae_input", ",", "ae_input", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "ae_input", ",", "ae_input", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.qtran.QTranBase.forward": [[70, 105], ["batch[].reshape", "qtran.QTranBase.Q", "batch[].reshape", "qtran.QTranBase.V", "torch.cat", "torch.cat", "torch.cat", "batch[].reshape", "actions.reshape.reshape.reshape", "hidden_states.reshape.reshape.reshape", "torch.cat", "torch.cat", "torch.cat", "qtran.QTranBase.action_encoding().reshape", "agent_state_action_encoding.sum.sum.sum", "torch.cat", "torch.cat", "torch.cat", "batch[].reshape", "actions.reshape.reshape.reshape", "qtran.QTranBase.action_encoding", "torch.cat.reshape"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "batch", ",", "hidden_states", ",", "actions", "=", "None", ")", ":", "\n", "        ", "bs", "=", "batch", ".", "batch_size", "\n", "ts", "=", "batch", ".", "max_seq_length", "\n", "\n", "states", "=", "batch", "[", "\"state\"", "]", ".", "reshape", "(", "bs", "*", "ts", ",", "self", ".", "state_dim", ")", "\n", "\n", "if", "self", ".", "arch", "==", "\"coma_critic\"", ":", "\n", "            ", "if", "actions", "is", "None", ":", "\n", "# Use the actions taken by the agents", "\n", "                ", "actions", "=", "batch", "[", "\"actions_onehot\"", "]", ".", "reshape", "(", "bs", "*", "ts", ",", "self", ".", "n_agents", "*", "self", ".", "n_actions", ")", "\n", "", "else", ":", "\n", "# It will arrive as (bs, ts, agents, actions), we need to reshape it", "\n", "                ", "actions", "=", "actions", ".", "reshape", "(", "bs", "*", "ts", ",", "self", ".", "n_agents", "*", "self", ".", "n_actions", ")", "\n", "", "inputs", "=", "th", ".", "cat", "(", "[", "states", ",", "actions", "]", ",", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "arch", "==", "\"qtran_paper\"", ":", "\n", "            ", "if", "actions", "is", "None", ":", "\n", "# Use the actions taken by the agents", "\n", "                ", "actions", "=", "batch", "[", "\"actions_onehot\"", "]", ".", "reshape", "(", "bs", "*", "ts", ",", "self", ".", "n_agents", ",", "self", ".", "n_actions", ")", "\n", "", "else", ":", "\n", "# It will arrive as (bs, ts, agents, actions), we need to reshape it", "\n", "                ", "actions", "=", "actions", ".", "reshape", "(", "bs", "*", "ts", ",", "self", ".", "n_agents", ",", "self", ".", "n_actions", ")", "\n", "\n", "", "hidden_states", "=", "hidden_states", ".", "reshape", "(", "bs", "*", "ts", ",", "self", ".", "n_agents", ",", "-", "1", ")", "\n", "agent_state_action_input", "=", "th", ".", "cat", "(", "[", "hidden_states", ",", "actions", "]", ",", "dim", "=", "2", ")", "\n", "agent_state_action_encoding", "=", "self", ".", "action_encoding", "(", "agent_state_action_input", ".", "reshape", "(", "bs", "*", "ts", "*", "self", ".", "n_agents", ",", "-", "1", ")", ")", ".", "reshape", "(", "bs", "*", "ts", ",", "self", ".", "n_agents", ",", "-", "1", ")", "\n", "agent_state_action_encoding", "=", "agent_state_action_encoding", ".", "sum", "(", "dim", "=", "1", ")", "# Sum across agents", "\n", "\n", "inputs", "=", "th", ".", "cat", "(", "[", "states", ",", "agent_state_action_encoding", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "q_outputs", "=", "self", ".", "Q", "(", "inputs", ")", "\n", "\n", "states", "=", "batch", "[", "\"state\"", "]", ".", "reshape", "(", "bs", "*", "ts", ",", "self", ".", "state_dim", ")", "\n", "v_outputs", "=", "self", ".", "V", "(", "states", ")", "\n", "\n", "return", "q_outputs", ",", "v_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.qmix.QMixer.__init__": [[8, 40], ["torch.Module.__init__", "int", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "numpy.prod", "getattr", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "getattr", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "getattr", "Exception", "Exception"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "QMixer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "n_agents", "=", "args", ".", "n_agents", "\n", "self", ".", "state_dim", "=", "int", "(", "np", ".", "prod", "(", "args", ".", "state_shape", ")", ")", "\n", "\n", "self", ".", "embed_dim", "=", "args", ".", "mixing_embed_dim", "\n", "\n", "if", "getattr", "(", "args", ",", "\"hypernet_layers\"", ",", "1", ")", "==", "1", ":", "\n", "            ", "self", ".", "hyper_w_1", "=", "nn", ".", "Linear", "(", "self", ".", "state_dim", ",", "self", ".", "embed_dim", "*", "self", ".", "n_agents", ")", "\n", "self", ".", "hyper_w_final", "=", "nn", ".", "Linear", "(", "self", ".", "state_dim", ",", "self", ".", "embed_dim", ")", "\n", "", "elif", "getattr", "(", "args", ",", "\"hypernet_layers\"", ",", "1", ")", "==", "2", ":", "\n", "            ", "hypernet_embed", "=", "self", ".", "args", ".", "hypernet_embed", "\n", "self", ".", "hyper_w_1", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "state_dim", ",", "hypernet_embed", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hypernet_embed", ",", "self", ".", "embed_dim", "*", "self", ".", "n_agents", ")", ")", "\n", "self", ".", "hyper_w_final", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "state_dim", ",", "hypernet_embed", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "hypernet_embed", ",", "self", ".", "embed_dim", ")", ")", "\n", "", "elif", "getattr", "(", "args", ",", "\"hypernet_layers\"", ",", "1", ")", ">", "2", ":", "\n", "            ", "raise", "Exception", "(", "\"Sorry >2 hypernet layers is not implemented!\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Error setting number of hypernet layers.\"", ")", "\n", "\n", "# State dependent bias for hidden layer", "\n", "", "self", ".", "hyper_b_1", "=", "nn", ".", "Linear", "(", "self", ".", "state_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "# V(s) instead of a bias for the last layers", "\n", "self", ".", "V", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "state_dim", ",", "self", ".", "embed_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.qmix.QMixer.forward": [[41, 61], ["agent_qs.view.view.size", "states.reshape.reshape.reshape", "agent_qs.view.view.view", "torch.abs", "torch.abs", "torch.abs", "qmix.QMixer.hyper_b_1", "w1.view.view.view", "b1.view.view.view", "torch.elu", "torch.elu", "torch.elu", "torch.abs", "torch.abs", "torch.abs", "w_final.view.view.view", "qmix.QMixer.V().view", "y.view", "qmix.QMixer.hyper_w_1", "qmix.QMixer.hyper_w_final", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "qmix.QMixer.V"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "agent_qs", ",", "states", ")", ":", "\n", "        ", "bs", "=", "agent_qs", ".", "size", "(", "0", ")", "\n", "states", "=", "states", ".", "reshape", "(", "-", "1", ",", "self", ".", "state_dim", ")", "\n", "agent_qs", "=", "agent_qs", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "n_agents", ")", "\n", "# First layer", "\n", "w1", "=", "th", ".", "abs", "(", "self", ".", "hyper_w_1", "(", "states", ")", ")", "\n", "b1", "=", "self", ".", "hyper_b_1", "(", "states", ")", "\n", "w1", "=", "w1", ".", "view", "(", "-", "1", ",", "self", ".", "n_agents", ",", "self", ".", "embed_dim", ")", "\n", "b1", "=", "b1", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "embed_dim", ")", "\n", "hidden", "=", "F", ".", "elu", "(", "th", ".", "bmm", "(", "agent_qs", ",", "w1", ")", "+", "b1", ")", "\n", "# Second layer", "\n", "w_final", "=", "th", ".", "abs", "(", "self", ".", "hyper_w_final", "(", "states", ")", ")", "\n", "w_final", "=", "w_final", ".", "view", "(", "-", "1", ",", "self", ".", "embed_dim", ",", "1", ")", "\n", "# State-dependent bias", "\n", "v", "=", "self", ".", "V", "(", "states", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "\n", "# Compute final output", "\n", "y", "=", "th", ".", "bmm", "(", "hidden", ",", "w_final", ")", "+", "v", "\n", "# Reshape and return", "\n", "q_tot", "=", "y", ".", "view", "(", "bs", ",", "-", "1", ",", "1", ")", "\n", "return", "q_tot", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.__init__": [[6, 8], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "VDNMixer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.mixers.vdn.VDNMixer.forward": [[9, 11], ["torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "agent_qs", ",", "batch", ")", ":", "\n", "        ", "return", "th", ".", "sum", "(", "agent_qs", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step": [[3, 6], ["None"], "methods", ["None"], ["    ", "def", "step", "(", "self", ",", "actions", ")", ":", "\n", "        ", "\"\"\" Returns reward, terminated, info \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_obs": [[7, 10], ["None"], "methods", ["None"], ["", "def", "get_obs", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns all agent observations in a list \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_obs_agent": [[11, 14], ["None"], "methods", ["None"], ["", "def", "get_obs_agent", "(", "self", ",", "agent_id", ")", ":", "\n", "        ", "\"\"\" Returns observation for agent_id \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_obs_size": [[15, 18], ["None"], "methods", ["None"], ["", "def", "get_obs_size", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the shape of the observation \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_state": [[19, 21], ["None"], "methods", ["None"], ["", "def", "get_state", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_state_size": [[22, 25], ["None"], "methods", ["None"], ["", "def", "get_state_size", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the shape of the state\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_avail_actions": [[26, 28], ["None"], "methods", ["None"], ["", "def", "get_avail_actions", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_avail_agent_actions": [[29, 32], ["None"], "methods", ["None"], ["", "def", "get_avail_agent_actions", "(", "self", ",", "agent_id", ")", ":", "\n", "        ", "\"\"\" Returns the available actions for agent_id \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_total_actions": [[33, 37], ["None"], "methods", ["None"], ["", "def", "get_total_actions", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns the total number of actions an agent could ever take \"\"\"", "\n", "# TODO: This is only suitable for a discrete 1 dimensional action space for each agent", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.reset": [[38, 41], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns initial observations and states\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.render": [[42, 44], ["None"], "methods", ["None"], ["", "def", "render", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.close": [[45, 47], ["None"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.seed": [[48, 50], ["None"], "methods", ["None"], ["", "def", "seed", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.save_replay": [[51, 53], ["None"], "methods", ["None"], ["", "def", "save_replay", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_env_info": [[54, 61], ["multiagentenv.MultiAgentEnv.get_state_size", "multiagentenv.MultiAgentEnv.get_obs_size", "multiagentenv.MultiAgentEnv.get_total_actions"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_state_size", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_obs_size", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_total_actions"], ["", "def", "get_env_info", "(", "self", ")", ":", "\n", "        ", "env_info", "=", "{", "\"state_shape\"", ":", "self", ".", "get_state_size", "(", ")", ",", "\n", "\"obs_shape\"", ":", "self", ".", "get_obs_size", "(", ")", ",", "\n", "\"n_actions\"", ":", "self", ".", "get_total_actions", "(", ")", ",", "\n", "\"n_agents\"", ":", "self", ".", "n_agents", ",", "\n", "\"episode_limit\"", ":", "self", ".", "episode_limit", "}", "\n", "return", "env_info", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.__init__.env_fn": [[9, 11], ["env"], "function", ["None"], []], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.ParallelRunner.__init__": [[13, 44], ["zip", "parallel_runner.ParallelRunner.parent_conns[].send", "parallel_runner.ParallelRunner.parent_conns[].recv", "multiprocessing.Process", "p.start", "multiprocessing.Pipe", "range", "parallel_runner.CloudpickleWrapper", "functools.partial"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "logger", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "batch_size", "=", "self", ".", "args", ".", "batch_size_run", "\n", "self", ".", "best_performance", "=", "0.", "\n", "self", ".", "save_model", "=", "False", "\n", "\n", "# Make subprocesses for the envs", "\n", "self", ".", "parent_conns", ",", "self", ".", "worker_conns", "=", "zip", "(", "*", "[", "Pipe", "(", ")", "for", "_", "in", "range", "(", "self", ".", "batch_size", ")", "]", ")", "\n", "env_fn", "=", "env_REGISTRY", "[", "self", ".", "args", ".", "env", "]", "\n", "self", ".", "ps", "=", "[", "Process", "(", "target", "=", "env_worker", ",", "args", "=", "(", "worker_conn", ",", "CloudpickleWrapper", "(", "partial", "(", "env_fn", ",", "**", "self", ".", "args", ".", "env_args", ")", ")", ")", ")", "\n", "for", "worker_conn", "in", "self", ".", "worker_conns", "]", "\n", "\n", "for", "p", "in", "self", ".", "ps", ":", "\n", "            ", "p", ".", "daemon", "=", "True", "\n", "p", ".", "start", "(", ")", "\n", "\n", "", "self", ".", "parent_conns", "[", "0", "]", ".", "send", "(", "(", "\"get_env_info\"", ",", "None", ")", ")", "\n", "self", ".", "env_info", "=", "self", ".", "parent_conns", "[", "0", "]", ".", "recv", "(", ")", "\n", "self", ".", "episode_limit", "=", "self", ".", "env_info", "[", "\"episode_limit\"", "]", "\n", "\n", "self", ".", "t", "=", "0", "\n", "\n", "self", ".", "t_env", "=", "0", "\n", "\n", "self", ".", "train_returns", "=", "[", "]", "\n", "self", ".", "test_returns", "=", "[", "]", "\n", "self", ".", "train_stats", "=", "{", "}", "\n", "self", ".", "test_stats", "=", "{", "}", "\n", "\n", "self", ".", "log_train_stats_t", "=", "-", "100000", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.ParallelRunner.setup": [[45, 52], ["functools.partial"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "scheme", ",", "groups", ",", "preprocess", ",", "mac", ")", ":", "\n", "        ", "self", ".", "new_batch", "=", "partial", "(", "EpisodeBatch", ",", "scheme", ",", "groups", ",", "self", ".", "batch_size", ",", "self", ".", "episode_limit", "+", "1", ",", "\n", "preprocess", "=", "preprocess", ",", "device", "=", "self", ".", "args", ".", "device", ")", "\n", "self", ".", "mac", "=", "mac", "\n", "self", ".", "scheme", "=", "scheme", "\n", "self", ".", "groups", "=", "groups", "\n", "self", ".", "preprocess", "=", "preprocess", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.ParallelRunner.get_env_info": [[53, 55], ["None"], "methods", ["None"], ["", "def", "get_env_info", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "env_info", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.ParallelRunner.save_replay": [[56, 58], ["None"], "methods", ["None"], ["", "def", "save_replay", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.ParallelRunner.close_env": [[59, 62], ["parent_conn.send"], "methods", ["None"], ["", "def", "close_env", "(", "self", ")", ":", "\n", "        ", "for", "parent_conn", "in", "self", ".", "parent_conns", ":", "\n", "            ", "parent_conn", ".", "send", "(", "(", "\"close\"", ",", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.ParallelRunner.reset": [[63, 86], ["parallel_runner.ParallelRunner.new_batch", "parallel_runner.ParallelRunner.batch.update", "parent_conn.send", "parent_conn.recv", "pre_transition_data[].append", "pre_transition_data[].append", "pre_transition_data[].append"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "batch", "=", "self", ".", "new_batch", "(", ")", "\n", "\n", "# Reset the envs", "\n", "for", "parent_conn", "in", "self", ".", "parent_conns", ":", "\n", "            ", "parent_conn", ".", "send", "(", "(", "\"reset\"", ",", "None", ")", ")", "\n", "\n", "", "pre_transition_data", "=", "{", "\n", "\"state\"", ":", "[", "]", ",", "\n", "\"avail_actions\"", ":", "[", "]", ",", "\n", "\"obs\"", ":", "[", "]", "\n", "}", "\n", "# Get the obs, state and avail_actions back", "\n", "for", "parent_conn", "in", "self", ".", "parent_conns", ":", "\n", "            ", "data", "=", "parent_conn", ".", "recv", "(", ")", "\n", "pre_transition_data", "[", "\"state\"", "]", ".", "append", "(", "data", "[", "\"state\"", "]", ")", "\n", "pre_transition_data", "[", "\"avail_actions\"", "]", ".", "append", "(", "data", "[", "\"avail_actions\"", "]", ")", "\n", "pre_transition_data", "[", "\"obs\"", "]", ".", "append", "(", "data", "[", "\"obs\"", "]", ")", "\n", "\n", "", "self", ".", "batch", ".", "update", "(", "pre_transition_data", ",", "ts", "=", "0", ")", "\n", "\n", "self", ".", "t", "=", "0", "\n", "self", ".", "env_steps_this_run", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.ParallelRunner.run": [[87, 210], ["parallel_runner.ParallelRunner.reset", "parallel_runner.ParallelRunner.mac.init_hidden", "cur_stats.update", "cur_returns.extend", "parallel_runner.ParallelRunner.mac.select_actions", "parallel_runner.ParallelRunner.to().numpy", "parallel_runner.ParallelRunner.batch.update", "enumerate", "all", "enumerate", "parallel_runner.ParallelRunner.batch.update", "parallel_runner.ParallelRunner.batch.update", "parent_conn.send", "parent_conn.recv", "env_stats.append", "cur_stats.get", "sum", "cur_stats.get", "max", "parallel_runner.ParallelRunner._log", "range", "range", "range", "enumerate", "parallel_runner.ParallelRunner.unsqueeze", "sum", "len", "parallel_runner.ParallelRunner._log", "hasattr", "parallel_runner.ParallelRunner.to", "enumerate", "parent_conn.recv", "post_transition_data[].append", "post_transition_data[].append", "pre_transition_data[].append", "pre_transition_data[].append", "pre_transition_data[].append", "set.union", "parallel_runner.ParallelRunner.logger.log_stat", "parent_conn.send", "final_env_infos.append", "d.get", "data[].get", "set"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.reset", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.extend", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.select_actions", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner._log", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner._log", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.to", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat"], ["", "def", "run", "(", "self", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n", "all_terminated", "=", "False", "\n", "episode_returns", "=", "[", "0", "for", "_", "in", "range", "(", "self", ".", "batch_size", ")", "]", "\n", "episode_lengths", "=", "[", "0", "for", "_", "in", "range", "(", "self", ".", "batch_size", ")", "]", "\n", "self", ".", "mac", ".", "init_hidden", "(", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "terminated", "=", "[", "False", "for", "_", "in", "range", "(", "self", ".", "batch_size", ")", "]", "\n", "envs_not_terminated", "=", "[", "b_idx", "for", "b_idx", ",", "termed", "in", "enumerate", "(", "terminated", ")", "if", "not", "termed", "]", "\n", "final_env_infos", "=", "[", "]", "# may store extra stats like battle won. this is filled in ORDER OF TERMINATION", "\n", "\n", "while", "True", ":", "\n", "\n", "# Pass the entire batch of experiences up till now to the agents", "\n", "# Receive the actions for each agent at this timestep in a batch for each un-terminated env", "\n", "            ", "actions", "=", "self", ".", "mac", ".", "select_actions", "(", "self", ".", "batch", ",", "t_ep", "=", "self", ".", "t", ",", "t_env", "=", "self", ".", "t_env", ",", "bs", "=", "envs_not_terminated", ",", "test_mode", "=", "test_mode", ")", "\n", "cpu_actions", "=", "actions", ".", "to", "(", "\"cpu\"", ")", ".", "numpy", "(", ")", "\n", "\n", "# Update the actions taken", "\n", "actions_chosen", "=", "{", "\n", "\"actions\"", ":", "actions", ".", "unsqueeze", "(", "1", ")", "\n", "}", "\n", "self", ".", "batch", ".", "update", "(", "actions_chosen", ",", "bs", "=", "envs_not_terminated", ",", "ts", "=", "self", ".", "t", ",", "mark_filled", "=", "False", ")", "\n", "\n", "# Send actions to each env", "\n", "action_idx", "=", "0", "\n", "for", "idx", ",", "parent_conn", "in", "enumerate", "(", "self", ".", "parent_conns", ")", ":", "\n", "                ", "if", "idx", "in", "envs_not_terminated", ":", "# We produced actions for this env", "\n", "                    ", "if", "not", "terminated", "[", "idx", "]", ":", "# Only send the actions to the env if it hasn't terminated", "\n", "                        ", "parent_conn", ".", "send", "(", "(", "\"step\"", ",", "cpu_actions", "[", "action_idx", "]", ")", ")", "\n", "", "action_idx", "+=", "1", "# actions is not a list over every env", "\n", "\n", "# Update envs_not_terminated", "\n", "", "", "envs_not_terminated", "=", "[", "b_idx", "for", "b_idx", ",", "termed", "in", "enumerate", "(", "terminated", ")", "if", "not", "termed", "]", "\n", "all_terminated", "=", "all", "(", "terminated", ")", "\n", "if", "all_terminated", ":", "\n", "                ", "break", "\n", "\n", "# Post step data we will insert for the current timestep", "\n", "", "post_transition_data", "=", "{", "\n", "\"reward\"", ":", "[", "]", ",", "\n", "\"terminated\"", ":", "[", "]", "\n", "}", "\n", "# Data for the next step we will insert in order to select an action", "\n", "pre_transition_data", "=", "{", "\n", "\"state\"", ":", "[", "]", ",", "\n", "\"avail_actions\"", ":", "[", "]", ",", "\n", "\"obs\"", ":", "[", "]", ",", "\n", "}", "\n", "\n", "# Receive data back for each unterminated env", "\n", "for", "idx", ",", "parent_conn", "in", "enumerate", "(", "self", ".", "parent_conns", ")", ":", "\n", "                ", "if", "not", "terminated", "[", "idx", "]", ":", "\n", "                    ", "data", "=", "parent_conn", ".", "recv", "(", ")", "\n", "# Remaining data for this current timestep", "\n", "post_transition_data", "[", "\"reward\"", "]", ".", "append", "(", "(", "data", "[", "\"reward\"", "]", ",", ")", ")", "\n", "\n", "episode_returns", "[", "idx", "]", "+=", "data", "[", "\"reward\"", "]", "\n", "episode_lengths", "[", "idx", "]", "+=", "1", "\n", "if", "not", "test_mode", ":", "\n", "                        ", "self", ".", "env_steps_this_run", "+=", "1", "\n", "\n", "", "env_terminated", "=", "False", "\n", "if", "data", "[", "\"terminated\"", "]", ":", "\n", "                        ", "final_env_infos", ".", "append", "(", "data", "[", "\"info\"", "]", ")", "\n", "", "if", "data", "[", "\"terminated\"", "]", "and", "not", "data", "[", "\"info\"", "]", ".", "get", "(", "\"episode_limit\"", ",", "False", ")", ":", "\n", "                        ", "env_terminated", "=", "True", "\n", "", "terminated", "[", "idx", "]", "=", "data", "[", "\"terminated\"", "]", "\n", "post_transition_data", "[", "\"terminated\"", "]", ".", "append", "(", "(", "env_terminated", ",", ")", ")", "\n", "\n", "# Data for the next timestep needed to select an action", "\n", "pre_transition_data", "[", "\"state\"", "]", ".", "append", "(", "data", "[", "\"state\"", "]", ")", "\n", "pre_transition_data", "[", "\"avail_actions\"", "]", ".", "append", "(", "data", "[", "\"avail_actions\"", "]", ")", "\n", "pre_transition_data", "[", "\"obs\"", "]", ".", "append", "(", "data", "[", "\"obs\"", "]", ")", "\n", "# pre_transition_data[\"adj\"].append(data[\"adj\"])", "\n", "\n", "# Add post_transiton data into the batch", "\n", "", "", "self", ".", "batch", ".", "update", "(", "post_transition_data", ",", "bs", "=", "envs_not_terminated", ",", "ts", "=", "self", ".", "t", ",", "mark_filled", "=", "False", ")", "\n", "\n", "# Move onto the next timestep", "\n", "self", ".", "t", "+=", "1", "\n", "\n", "# Add the pre-transition data", "\n", "self", ".", "batch", ".", "update", "(", "pre_transition_data", ",", "bs", "=", "envs_not_terminated", ",", "ts", "=", "self", ".", "t", ",", "mark_filled", "=", "True", ")", "\n", "\n", "", "if", "not", "test_mode", ":", "\n", "            ", "self", ".", "t_env", "+=", "self", ".", "env_steps_this_run", "\n", "\n", "# Get stats back for each env", "\n", "", "for", "parent_conn", "in", "self", ".", "parent_conns", ":", "\n", "            ", "parent_conn", ".", "send", "(", "(", "\"get_stats\"", ",", "None", ")", ")", "\n", "\n", "", "env_stats", "=", "[", "]", "\n", "for", "parent_conn", "in", "self", ".", "parent_conns", ":", "\n", "            ", "env_stat", "=", "parent_conn", ".", "recv", "(", ")", "\n", "env_stats", ".", "append", "(", "env_stat", ")", "\n", "\n", "", "cur_stats", "=", "self", ".", "test_stats", "if", "test_mode", "else", "self", ".", "train_stats", "\n", "cur_returns", "=", "self", ".", "test_returns", "if", "test_mode", "else", "self", ".", "train_returns", "\n", "log_prefix", "=", "\"test_\"", "if", "test_mode", "else", "\"\"", "\n", "infos", "=", "[", "cur_stats", "]", "+", "final_env_infos", "\n", "cur_stats", ".", "update", "(", "{", "k", ":", "sum", "(", "d", ".", "get", "(", "k", ",", "0", ")", "for", "d", "in", "infos", ")", "for", "k", "in", "set", ".", "union", "(", "*", "[", "set", "(", "d", ")", "for", "d", "in", "infos", "]", ")", "}", ")", "\n", "cur_stats", "[", "\"n_episodes\"", "]", "=", "self", ".", "batch_size", "+", "cur_stats", ".", "get", "(", "\"n_episodes\"", ",", "0", ")", "\n", "cur_stats", "[", "\"ep_length\"", "]", "=", "sum", "(", "episode_lengths", ")", "+", "cur_stats", ".", "get", "(", "\"ep_length\"", ",", "0", ")", "\n", "\n", "cur_returns", ".", "extend", "(", "episode_returns", ")", "\n", "\n", "n_test_runs", "=", "max", "(", "1", ",", "self", ".", "args", ".", "test_nepisode", "//", "self", ".", "batch_size", ")", "*", "self", ".", "batch_size", "\n", "if", "test_mode", "and", "(", "len", "(", "self", ".", "test_returns", ")", "==", "n_test_runs", ")", ":", "\n", "# if self.t_env > 980000:", "\n", "#     cur_won_rate = cur_stats['sim_won'] / cur_stats['n_episodes']", "\n", "#     if cur_won_rate > self.best_performance:", "\n", "#         self.save_model = True", "\n", "#         self.best_performance = cur_won_rate", "\n", "            ", "self", ".", "_log", "(", "cur_returns", ",", "cur_stats", ",", "log_prefix", ")", "\n", "\n", "", "elif", "self", ".", "t_env", "-", "self", ".", "log_train_stats_t", ">=", "self", ".", "args", ".", "runner_log_interval", ":", "\n", "            ", "self", ".", "_log", "(", "cur_returns", ",", "cur_stats", ",", "log_prefix", ")", "\n", "if", "hasattr", "(", "self", ".", "mac", ".", "action_selector", ",", "\"epsilon\"", ")", ":", "\n", "                ", "self", ".", "logger", ".", "log_stat", "(", "\"epsilon\"", ",", "self", ".", "mac", ".", "action_selector", ".", "epsilon", ",", "self", ".", "t_env", ")", "\n", "", "self", ".", "log_train_stats_t", "=", "self", ".", "t_env", "\n", "\n", "", "return", "self", ".", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.ParallelRunner._log": [[211, 220], ["parallel_runner.ParallelRunner.logger.log_stat", "parallel_runner.ParallelRunner.logger.log_stat", "returns.clear", "stats.items", "stats.clear", "numpy.mean", "numpy.std", "parallel_runner.ParallelRunner.logger.log_stat"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat"], ["", "def", "_log", "(", "self", ",", "returns", ",", "stats", ",", "prefix", ")", ":", "\n", "        ", "self", ".", "logger", ".", "log_stat", "(", "prefix", "+", "\"return_mean\"", ",", "np", ".", "mean", "(", "returns", ")", ",", "self", ".", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "prefix", "+", "\"return_std\"", ",", "np", ".", "std", "(", "returns", ")", ",", "self", ".", "t_env", ")", "\n", "returns", ".", "clear", "(", ")", "\n", "\n", "for", "k", ",", "v", "in", "stats", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "!=", "\"n_episodes\"", ":", "\n", "                ", "self", ".", "logger", ".", "log_stat", "(", "prefix", "+", "k", "+", "\"_mean\"", ",", "v", "/", "stats", "[", "\"n_episodes\"", "]", ",", "self", ".", "t_env", ")", "\n", "", "", "stats", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.CloudpickleWrapper.__init__": [[271, 273], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "x", "=", "x", "\n", "", "def", "__getstate__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.CloudpickleWrapper.__getstate__": [[273, 276], ["cloudpickle.dumps"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "import", "cloudpickle", "\n", "return", "cloudpickle", ".", "dumps", "(", "self", ".", "x", ")", "\n", "", "def", "__setstate__", "(", "self", ",", "ob", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.CloudpickleWrapper.__setstate__": [[276, 279], ["pickle.loads"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "ob", ")", ":", "\n", "        ", "import", "pickle", "\n", "self", ".", "x", "=", "pickle", ".", "loads", "(", "ob", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.parallel_runner.env_worker": [[222, 265], ["env_fn.x", "remote.recv", "env_fn.x.step", "env_fn.x.get_state", "env_fn.x.get_avail_actions", "env_fn.x.get_obs", "remote.send", "env_fn.x.reset", "remote.send", "env_fn.x.close", "remote.close", "env_fn.x.get_state", "env_fn.x.get_avail_actions", "env_fn.x.get_obs", "remote.send", "env_fn.x.get_env_info", "remote.send", "env_fn.x.get_stats"], "function", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_state", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_avail_actions", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_obs", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.reset", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.close", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.close", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_state", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_avail_actions", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_obs", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.get_env_info"], ["", "", "def", "env_worker", "(", "remote", ",", "env_fn", ")", ":", "\n", "# Make environment", "\n", "    ", "env", "=", "env_fn", ".", "x", "(", ")", "\n", "while", "True", ":", "\n", "        ", "cmd", ",", "data", "=", "remote", ".", "recv", "(", ")", "\n", "if", "cmd", "==", "\"step\"", ":", "\n", "            ", "actions", "=", "data", "\n", "# Take a step in the environment", "\n", "reward", ",", "terminated", ",", "env_info", "=", "env", ".", "step", "(", "actions", ")", "\n", "# Return the observations, avail_actions and state to make the next action", "\n", "state", "=", "env", ".", "get_state", "(", ")", "\n", "avail_actions", "=", "env", ".", "get_avail_actions", "(", ")", "\n", "obs", "=", "env", ".", "get_obs", "(", ")", "\n", "# adj = env.get_adj()", "\n", "remote", ".", "send", "(", "{", "\n", "# Data for the next timestep needed to pick an action", "\n", "\"state\"", ":", "state", ",", "\n", "\"avail_actions\"", ":", "avail_actions", ",", "\n", "\"obs\"", ":", "obs", ",", "\n", "# \"adj\": adj,", "\n", "# Rest of the data for the current timestep", "\n", "\"reward\"", ":", "reward", ",", "\n", "\"terminated\"", ":", "terminated", ",", "\n", "\"info\"", ":", "env_info", "\n", "}", ")", "\n", "", "elif", "cmd", "==", "\"reset\"", ":", "\n", "            ", "env", ".", "reset", "(", ")", "\n", "remote", ".", "send", "(", "{", "\n", "\"state\"", ":", "env", ".", "get_state", "(", ")", ",", "\n", "\"avail_actions\"", ":", "env", ".", "get_avail_actions", "(", ")", ",", "\n", "\"obs\"", ":", "env", ".", "get_obs", "(", ")", "\n", "# \"adj\": env.get_adj()", "\n", "}", ")", "\n", "", "elif", "cmd", "==", "\"close\"", ":", "\n", "            ", "env", ".", "close", "(", ")", "\n", "remote", ".", "close", "(", ")", "\n", "break", "\n", "", "elif", "cmd", "==", "\"get_env_info\"", ":", "\n", "            ", "remote", ".", "send", "(", "env", ".", "get_env_info", "(", ")", ")", "\n", "", "elif", "cmd", "==", "\"get_stats\"", ":", "\n", "            ", "remote", ".", "send", "(", "env", ".", "get_stats", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.__init__": [[9, 28], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "logger", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "logger", "=", "logger", "\n", "self", ".", "batch_size", "=", "self", ".", "args", ".", "batch_size_run", "\n", "assert", "self", ".", "batch_size", "==", "1", "\n", "\n", "self", ".", "env", "=", "env_REGISTRY", "[", "self", ".", "args", ".", "env", "]", "(", "**", "self", ".", "args", ".", "env_args", ")", "\n", "self", ".", "episode_limit", "=", "self", ".", "env", ".", "episode_limit", "\n", "self", ".", "t", "=", "0", "\n", "\n", "self", ".", "t_env", "=", "0", "\n", "\n", "self", ".", "train_returns", "=", "[", "]", "\n", "self", ".", "test_returns", "=", "[", "]", "\n", "self", ".", "train_stats", "=", "{", "}", "\n", "self", ".", "test_stats", "=", "{", "}", "\n", "\n", "# Log the first run", "\n", "self", ".", "log_train_stats_t", "=", "-", "1000000", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.setup": [[29, 33], ["functools.partial"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "scheme", ",", "groups", ",", "preprocess", ",", "mac", ")", ":", "\n", "        ", "self", ".", "new_batch", "=", "partial", "(", "EpisodeBatch", ",", "scheme", ",", "groups", ",", "self", ".", "batch_size", ",", "self", ".", "episode_limit", "+", "1", ",", "\n", "preprocess", "=", "preprocess", ",", "device", "=", "self", ".", "args", ".", "device", ")", "\n", "self", ".", "mac", "=", "mac", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.get_env_info": [[34, 36], ["episode_runner.EpisodeRunner.env.get_env_info"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.get_env_info"], ["", "def", "get_env_info", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "env", ".", "get_env_info", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.save_replay": [[37, 39], ["episode_runner.EpisodeRunner.env.save_replay"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.save_replay"], ["", "def", "save_replay", "(", "self", ")", ":", "\n", "        ", "self", ".", "env", ".", "save_replay", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.close_env": [[40, 42], ["episode_runner.EpisodeRunner.env.close"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.close"], ["", "def", "close_env", "(", "self", ")", ":", "\n", "        ", "self", ".", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.reset": [[43, 47], ["episode_runner.EpisodeRunner.new_batch", "episode_runner.EpisodeRunner.env.reset"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "batch", "=", "self", ".", "new_batch", "(", ")", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "self", ".", "t", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.run": [[48, 116], ["episode_runner.EpisodeRunner.reset", "episode_runner.EpisodeRunner.mac.init_hidden", "episode_runner.EpisodeRunner.batch.update", "episode_runner.EpisodeRunner.mac.select_actions", "episode_runner.EpisodeRunner.batch.update", "cur_stats.update", "cur_returns.append", "episode_runner.EpisodeRunner.batch.update", "episode_runner.EpisodeRunner.mac.select_actions", "episode_runner.EpisodeRunner.env.step", "episode_runner.EpisodeRunner.batch.update", "cur_stats.get", "cur_stats.get", "episode_runner.EpisodeRunner._log", "episode_runner.EpisodeRunner.env.get_state", "episode_runner.EpisodeRunner.env.get_avail_actions", "episode_runner.EpisodeRunner.env.get_obs", "len", "episode_runner.EpisodeRunner._log", "hasattr", "episode_runner.EpisodeRunner.env.get_state", "episode_runner.EpisodeRunner.env.get_avail_actions", "episode_runner.EpisodeRunner.env.get_obs", "cur_stats.get", "env_info.get", "episode_runner.EpisodeRunner.logger.log_stat", "set", "set", "env_info.get"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner.reset", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.agents.gcn_agent.TRANSAgent.init_hidden", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.select_actions", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.controllers.basic_controller.BasicMAC.select_actions", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.step", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.components.episode_buffer.EpisodeBatch.update", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner._log", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_state", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_avail_actions", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_obs", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner._log", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_state", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_avail_actions", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.envs.multiagentenv.MultiAgentEnv.get_obs", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat"], ["", "def", "run", "(", "self", ",", "test_mode", "=", "False", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n", "terminated", "=", "False", "\n", "episode_return", "=", "0", "\n", "self", ".", "mac", ".", "init_hidden", "(", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "\n", "while", "not", "terminated", ":", "\n", "\n", "            ", "pre_transition_data", "=", "{", "\n", "\"state\"", ":", "[", "self", ".", "env", ".", "get_state", "(", ")", "]", ",", "\n", "\"avail_actions\"", ":", "[", "self", ".", "env", ".", "get_avail_actions", "(", ")", "]", ",", "\n", "\"obs\"", ":", "[", "self", ".", "env", ".", "get_obs", "(", ")", "]", "\n", "}", "\n", "\n", "self", ".", "batch", ".", "update", "(", "pre_transition_data", ",", "ts", "=", "self", ".", "t", ")", "\n", "\n", "# Pass the entire batch of experiences up till now to the agents", "\n", "# Receive the actions for each agent at this timestep in a batch of size 1", "\n", "actions", "=", "self", ".", "mac", ".", "select_actions", "(", "self", ".", "batch", ",", "t_ep", "=", "self", ".", "t", ",", "t_env", "=", "self", ".", "t_env", ",", "test_mode", "=", "test_mode", ")", "\n", "\n", "reward", ",", "terminated", ",", "env_info", "=", "self", ".", "env", ".", "step", "(", "actions", "[", "0", "]", ")", "\n", "episode_return", "+=", "reward", "\n", "\n", "post_transition_data", "=", "{", "\n", "\"actions\"", ":", "actions", ",", "\n", "\"reward\"", ":", "[", "(", "reward", ",", ")", "]", ",", "\n", "\"terminated\"", ":", "[", "(", "terminated", "!=", "env_info", ".", "get", "(", "\"episode_limit\"", ",", "False", ")", ",", ")", "]", ",", "\n", "}", "\n", "\n", "self", ".", "batch", ".", "update", "(", "post_transition_data", ",", "ts", "=", "self", ".", "t", ")", "\n", "\n", "self", ".", "t", "+=", "1", "\n", "\n", "", "last_data", "=", "{", "\n", "\"state\"", ":", "[", "self", ".", "env", ".", "get_state", "(", ")", "]", ",", "\n", "\"avail_actions\"", ":", "[", "self", ".", "env", ".", "get_avail_actions", "(", ")", "]", ",", "\n", "\"obs\"", ":", "[", "self", ".", "env", ".", "get_obs", "(", ")", "]", "\n", "}", "\n", "self", ".", "batch", ".", "update", "(", "last_data", ",", "ts", "=", "self", ".", "t", ")", "\n", "\n", "# Select actions in the last stored state", "\n", "actions", "=", "self", ".", "mac", ".", "select_actions", "(", "self", ".", "batch", ",", "t_ep", "=", "self", ".", "t", ",", "t_env", "=", "self", ".", "t_env", ",", "test_mode", "=", "test_mode", ")", "\n", "self", ".", "batch", ".", "update", "(", "{", "\"actions\"", ":", "actions", "}", ",", "ts", "=", "self", ".", "t", ")", "\n", "\n", "cur_stats", "=", "self", ".", "test_stats", "if", "test_mode", "else", "self", ".", "train_stats", "\n", "cur_returns", "=", "self", ".", "test_returns", "if", "test_mode", "else", "self", ".", "train_returns", "\n", "log_prefix", "=", "\"test_\"", "if", "test_mode", "else", "\"\"", "\n", "cur_stats", ".", "update", "(", "{", "k", ":", "cur_stats", ".", "get", "(", "k", ",", "0", ")", "+", "env_info", ".", "get", "(", "k", ",", "0", ")", "for", "k", "in", "set", "(", "cur_stats", ")", "|", "set", "(", "env_info", ")", "}", ")", "\n", "cur_stats", "[", "\"n_episodes\"", "]", "=", "1", "+", "cur_stats", ".", "get", "(", "\"n_episodes\"", ",", "0", ")", "\n", "cur_stats", "[", "\"ep_length\"", "]", "=", "self", ".", "t", "+", "cur_stats", ".", "get", "(", "\"ep_length\"", ",", "0", ")", "\n", "\n", "if", "not", "test_mode", ":", "\n", "            ", "self", ".", "t_env", "+=", "self", ".", "t", "\n", "\n", "", "cur_returns", ".", "append", "(", "episode_return", ")", "\n", "\n", "if", "test_mode", "and", "(", "len", "(", "self", ".", "test_returns", ")", "==", "self", ".", "args", ".", "test_nepisode", ")", ":", "\n", "# cur_profit = cur_stats['profit'] / cur_stats['n_episodes']", "\n", "# print(cur_profit)", "\n", "            ", "self", ".", "_log", "(", "cur_returns", ",", "cur_stats", ",", "log_prefix", ")", "\n", "", "elif", "self", ".", "t_env", "-", "self", ".", "log_train_stats_t", ">=", "self", ".", "args", ".", "runner_log_interval", ":", "\n", "            ", "self", ".", "_log", "(", "cur_returns", ",", "cur_stats", ",", "log_prefix", ")", "\n", "if", "hasattr", "(", "self", ".", "mac", ".", "action_selector", ",", "\"epsilon\"", ")", ":", "\n", "                ", "self", ".", "logger", ".", "log_stat", "(", "\"epsilon\"", ",", "self", ".", "mac", ".", "action_selector", ".", "epsilon", ",", "self", ".", "t_env", ")", "\n", "", "self", ".", "log_train_stats_t", "=", "self", ".", "t_env", "\n", "\n", "", "return", "self", ".", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.hahayonghuming_VDACs.runners.episode_runner.EpisodeRunner._log": [[117, 126], ["episode_runner.EpisodeRunner.logger.log_stat", "episode_runner.EpisodeRunner.logger.log_stat", "returns.clear", "stats.items", "stats.clear", "numpy.mean", "numpy.std", "episode_runner.EpisodeRunner.logger.log_stat"], "methods", ["home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat", "home.repos.pwc.inspect_result.hahayonghuming_VDACs.utils.logging.Logger.log_stat"], ["", "def", "_log", "(", "self", ",", "returns", ",", "stats", ",", "prefix", ")", ":", "\n", "        ", "self", ".", "logger", ".", "log_stat", "(", "prefix", "+", "\"return_mean\"", ",", "np", ".", "mean", "(", "returns", ")", ",", "self", ".", "t_env", ")", "\n", "self", ".", "logger", ".", "log_stat", "(", "prefix", "+", "\"return_std\"", ",", "np", ".", "std", "(", "returns", ")", ",", "self", ".", "t_env", ")", "\n", "returns", ".", "clear", "(", ")", "\n", "\n", "for", "k", ",", "v", "in", "stats", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "!=", "\"n_episodes\"", ":", "\n", "                ", "self", ".", "logger", ".", "log_stat", "(", "prefix", "+", "k", "+", "\"_mean\"", ",", "v", "/", "stats", "[", "\"n_episodes\"", "]", ",", "self", ".", "t_env", ")", "\n", "", "", "stats", ".", "clear", "(", ")", "\n", "", "", ""]]}