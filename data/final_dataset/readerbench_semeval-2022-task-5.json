{"home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.create_graph.corpus_freq": [[20, 167], ["print", "len", "print", "print", "range", "collections.defaultdict", "map", "dict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "print", "tqdm.tqdm", "range", "dict.keys", "print", "zip", "collections.defaultdict.values", "zip", "print", "dict", "tqdm.tqdm", "print", "scipy.csr_matrix", "sp.csr_matrix.setdiag", "print", "sklearn.preprocessing.normalize", "sklearn.preprocessing.normalize.dot", "utils.gcn.clean_text", "create_graph.corpus_freq.tokenize"], "function", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.gcn.clean_text"], ["def", "corpus_freq", "(", "corpus", ",", "objects", ",", "tokenizer", ",", "min_word_freq", ",", "text_window_size", ",", "text_window_stride", ",", "\n", "remove_stop_words", ",", "remove_numeric", ",", "no_idf", ",", "use_multiprocessing", ",", "num_workers", ")", ":", "\n", "\n", "    ", "def", "clean_corpus", "(", "text", ")", ":", "\n", "        ", "return", "clean_text", "(", "text", ",", "remove_stop_words", ",", "remove_numeric", ")", "\n", "", "def", "tokenize", "(", "texts", ")", ":", "\n", "        ", "return", "tokenizer", ".", "batch_encode_plus", "(", "texts", ")", "[", "'input_ids'", "]", "\n", "\n", "", "print", "(", "\"Tokenize and Encode Corpus .... \"", ")", "\n", "if", "use_multiprocessing", ":", "\n", "        ", "with", "Parallel", "(", "n_jobs", "=", "num_workers", ",", "backend", "=", "\"threading\"", ")", "as", "paralell", ":", "\n", "            ", "corpus", "=", "paralell", "(", "\n", "delayed", "(", "clean_corpus", ")", "(", "x", ")", "for", "x", "in", "corpus", "\n", ")", "\n", "\n", "", "with", "Parallel", "(", "n_jobs", "=", "num_workers", ",", "backend", "=", "\"threading\"", ")", "as", "paralell", ":", "\n", "            ", "encoded", "=", "paralell", "(", "\n", "delayed", "(", "tokenize", ")", "(", "corpus", "[", "x", "*", "100", ":", "x", "*", "100", "+", "100", "]", ")", "for", "x", "in", "range", "(", "len", "(", "corpus", ")", "//", "100", "+", "1", ")", "\n", ")", "\n", "encoded", "=", "list", "(", "itertools", ".", "chain", "(", "*", "encoded", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "corpus", "=", "[", "clean_corpus", "(", "y", ")", "for", "x", "in", "corpus", "for", "y", "in", "x", ".", "split", "(", "\"\\n\"", ")", "if", "len", "(", "y", ")", ">", "2", "]", "# split in  Paragraphs", "\n", "encoded", "=", "tokenize", "(", "corpus", ")", "\n", "", "num_docs", "=", "len", "(", "corpus", ")", "\n", "\n", "print", "(", "\"Done! \"", ")", "\n", "print", "(", "f\"Got {num_docs} lines with {sum([len(x) for x in encoded])} elements\"", ")", "\n", "\n", "objects", "=", "[", "[", "int", "(", "x", ")", "+", "tokenizer", ".", "vocab_size", "for", "x", "in", "inner", "if", "len", "(", "x", ")", ">", "0", "]", "for", "inner", "in", "objects", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "encoded", ")", ")", ":", "\n", "        ", "del", "(", "encoded", "[", "i", "]", "[", "0", "]", ")", "# remove [CLS] and [SEP] token", "\n", "del", "(", "encoded", "[", "i", "]", "[", "-", "1", "]", ")", "\n", "encoded", "[", "i", "]", ".", "extend", "(", "objects", "[", "i", "]", ")", "\n", "\n", "", "if", "min_word_freq", ">", "1", ":", "\n", "        ", "word_list_global", "=", "[", "item", "for", "sublist", "in", "encoded", "for", "item", "in", "sublist", "]", "\n", "word_global_count", "=", "defaultdict", "(", "lambda", ":", "0", ",", "Counter", "(", "word_list_global", ")", ")", "# in how many docs each word appears", "\n", "\n", "encoded", "=", "[", "[", "item", "for", "item", "in", "sublist", "if", "word_global_count", "[", "item", "]", ">", "min_word_freq", "]", "for", "sublist", "in", "\n", "encoded", "]", "# remove with lower frequency", "\n", "\n", "", "word_list_per_doc", "=", "[", "item", "for", "sublist", "in", "encoded", "for", "item", "in", "Counter", "(", "sublist", ")", "]", "\n", "\n", "word_doc_count", "=", "defaultdict", "(", "lambda", ":", "0", ",", "Counter", "(", "word_list_per_doc", ")", ")", "# in how many docs each word appears", "\n", "\n", "mixt_token_list", "=", "list", "(", "tokenizer", ".", "ids_to_tokens", ".", "keys", "(", ")", ")", "+", "list", "(", "range", "(", "tokenizer", ".", "vocab_size", ",", "tokenizer", ".", "vocab_size", "+", "OBJECT_VOCAB_SIZE", ")", ")", "\n", "\n", "idf", "=", "map", "(", "lambda", "word", ":", "log", "(", "(", "1.0", "+", "num_docs", ")", "/", "(", "1.0", "+", "word_doc_count", "[", "word", "]", ")", ")", "+", "1.0", ",", "mixt_token_list", ")", "\n", "idf", "=", "dict", "(", "zip", "(", "mixt_token_list", ",", "idf", ")", ")", "\n", "del", "(", "word_doc_count", "[", "tokenizer", ".", "sep_token_id", "]", ")", "# remove counters for special tokens", "\n", "del", "(", "word_doc_count", "[", "tokenizer", ".", "cls_token_id", "]", ")", "\n", "\n", "word_window_count", "=", "defaultdict", "(", "lambda", ":", "0", ")", "# In how many windows word x appears", "\n", "word_pairs_window_count", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "doc_word_count", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "num_windows", "=", "0", "\n", "\n", "print", "(", "\"starting text window parsing\"", ")", "\n", "\n", "def", "generate_window_matrix", "(", "array", ",", "window_size", ",", "stride", "=", "1", ")", ":", "\n", "        ", "if", "len", "(", "array", ")", "<", "window_size", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "array", "]", ")", "\n", "\n", "", "if", "stride", ">", "1", ":", "\n", "            ", "result", "=", "(", "np", ".", "lib", ".", "stride_tricks", ".", "sliding_window_view", "(", "np", ".", "array", "(", "array", ")", ",", "window_size", ")", ")", "[", ":", ":", "stride", ",", ":", "]", "\n", "", "else", ":", "\n", "            ", "result", "=", "np", ".", "lib", ".", "stride_tricks", ".", "sliding_window_view", "(", "np", ".", "array", "(", "array", ")", ",", "window_size", ")", "\n", "\n", "", "return", "result", "\n", "\n", "", "def", "inc", "(", "d", ",", "x", ",", "val", "=", "1", ")", ":", "\n", "        ", "d", "[", "x", "]", "+=", "val", "\n", "\n", "", "for", "index", ",", "line", "in", "tqdm", "(", "enumerate", "(", "encoded", ")", ",", "total", "=", "num_docs", ")", ":", "\n", "# text window information", "\n", "\n", "        ", "window_matrix", "=", "generate_window_matrix", "(", "line", ",", "text_window_size", ",", "stride", "=", "text_window_stride", ")", "# get a matrix of sliding windows", "\n", "\n", "# Increment Word count in document for each word --> used in TF", "\n", "_", "=", "list", "(", "map", "(", "lambda", "word", ":", "inc", "(", "doc_word_count", ",", "(", "index", ",", "word", ")", ")", ",", "line", ")", ")", "\n", "\n", "num_windows", "+=", "window_matrix", ".", "shape", "[", "0", "]", "# Increment number of windows", "\n", "unique_in_windows", "=", "[", "np", ".", "unique", "(", "x", ")", "for", "x", "in", "window_matrix", "]", "\n", "unique_in_windows_flat", "=", "np", ".", "concatenate", "(", "unique_in_windows", ")", "\n", "\n", "_", "=", "list", "(", "map", "(", "lambda", "word", ":", "inc", "(", "word_window_count", ",", "word", ")", ",", "\n", "unique_in_windows_flat", ")", ")", "# Increment Word count in window for each unique word", "\n", "count_word_pairs", "=", "Counter", "(", "itertools", ".", "product", "(", "unique_in_windows_flat", ",", "unique_in_windows_flat", ")", ")", "\n", "\n", "_", "=", "list", "(", "map", "(", "lambda", "word_pair", ":", "inc", "(", "word_pairs_window_count", ",", "word_pair", ",", "val", "=", "count_word_pairs", "[", "word_pair", "]", ")", ",", "\n", "count_word_pairs", ".", "keys", "(", ")", ")", ")", "# Increment Word pair count in window for each unique word pair", "\n", "# Compute TF-IDF", "\n", "", "row_tf", "=", "range", "(", "num_docs", ")", "\n", "col_tf", "=", "idf", ".", "keys", "(", ")", "\n", "print", "(", "f\"Compute TF/IDF for {len(row_tf)} x {len(col_tf)}\"", ")", "\n", "\n", "row_tf", ",", "col_tf", "=", "zip", "(", "*", "doc_word_count", ".", "keys", "(", ")", ")", "# unpack the (document, token_id) keys", "\n", "weight_tf", "=", "doc_word_count", ".", "values", "(", ")", "\n", "weight_tf_idf", "=", "[", "doc_word_count", "[", "pair", "]", "*", "idf", "[", "pair", "[", "1", "]", "]", "for", "pair", "in", "doc_word_count", "]", "\n", "\n", "# compute pmi and npmi matrices", "\n", "\n", "row", ",", "col", "=", "zip", "(", "*", "word_pairs_window_count", ".", "keys", "(", ")", ")", "\n", "\n", "weight_pmi", "=", "[", "]", "\n", "weight_npmi", "=", "[", "]", "\n", "print", "(", "\"Compute PMI  and TF\"", ")", "\n", "\n", "# Normalize word_pair_count", "\n", "word_pairs_window_count_norm", "=", "np", ".", "array", "(", "list", "(", "word_pairs_window_count", ".", "values", "(", ")", ")", ",", "dtype", "=", "float", ")", "/", "num_windows", "\n", "\n", "# normalize Word_window_count", "\n", "word_window_count_norm", "=", "np", ".", "array", "(", "list", "(", "word_window_count", ".", "values", "(", ")", ")", ",", "dtype", "=", "float", ")", "/", "num_windows", "\n", "word_window_count_norm", "=", "dict", "(", "zip", "(", "word_window_count", ".", "keys", "(", ")", ",", "word_window_count_norm", ")", ")", "\n", "\n", "for", "(", "word_i", ",", "word_j", ",", "p_ij", ")", "in", "tqdm", "(", "zip", "(", "row", ",", "col", ",", "word_pairs_window_count_norm", ")", ",", "total", "=", "len", "(", "row", ")", ")", ":", "\n", "        ", "p_i", "=", "word_window_count_norm", "[", "word_i", "]", "\n", "p_j", "=", "word_window_count_norm", "[", "word_j", "]", "\n", "\n", "pmi", "=", "log", "(", "p_ij", "/", "(", "p_i", "*", "p_j", "+", "sys", ".", "float_info", ".", "epsilon", ")", ")", "# Pointwise mutual information", "\n", "npmi", "=", "-", "pmi", "/", "(", "log", "(", "p_ij", ")", "+", "sys", ".", "float_info", ".", "epsilon", ")", "# Normalized pmi", "\n", "\n", "weight_pmi", ".", "append", "(", "pmi", ")", "\n", "weight_npmi", ".", "append", "(", "npmi", ")", "\n", "\n", "# In paper foloseste doar pmi >0 si npmi > 0 - de ce?", "\n", "# to check", "\n", "", "print", "(", "\"Compute Adjecancy \"", ")", "\n", "vocab_adj", "=", "sp", ".", "csr_matrix", "(", "(", "weight_npmi", ",", "(", "row", ",", "col", ")", ")", ",", "shape", "=", "(", "tokenizer", ".", "vocab_size", "+", "OBJECT_VOCAB_SIZE", ",", "tokenizer", ".", "vocab_size", "+", "OBJECT_VOCAB_SIZE", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "vocab_adj", ".", "setdiag", "(", "1.0", ")", "\n", "\n", "# Calculate isomorphic vocab adjacency matrix using doc\\'s tf-idf", "\n", "if", "no_idf", ":", "\n", "        ", "tfidf_all", "=", "sp", ".", "csr_matrix", "(", "(", "np", ".", "array", "(", "weight_tf", ")", ",", "(", "row_tf", ",", "col_tf", ")", ")", ",", "shape", "=", "(", "num_docs", ",", "tokenizer", ".", "vocab_size", "+", "OBJECT_VOCAB_SIZE", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "tfidf_all", "=", "sp", ".", "csr_matrix", "(", "(", "np", ".", "array", "(", "weight_tf_idf", ")", ",", "(", "row_tf", ",", "col_tf", ")", ")", ",", "shape", "=", "(", "num_docs", ",", "tokenizer", ".", "vocab_size", "+", "OBJECT_VOCAB_SIZE", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "print", "(", "\"Normalize tfidf\"", ")", "\n", "# vocab_tfidf = tfidf_all.T.tolil()", "\n", "vocab_tfidf", "=", "tfidf_all", ".", "T", "\n", "vocab_tfidf", "=", "sklearn", ".", "preprocessing", ".", "normalize", "(", "vocab_tfidf", ",", "norm", "=", "'l2'", ",", "axis", "=", "1", ")", "\n", "vocab_adj_tf", "=", "vocab_tfidf", ".", "dot", "(", "vocab_tfidf", ".", "T", ")", "\n", "\n", "return", "vocab_adj", ",", "vocab_adj_tf", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.create_graph.main": [[168, 194], ["print", "transformers.BertTokenizer.from_pretrained", "print", "pandas.read_csv", "df[].tolist", "df[].apply().tolist", "create_graph.corpus_freq", "pickle.dump", "pathlib.Path", "pathlib.Path", "open", "df[].apply", "x.strip().split", "x.strip"], "function", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.create_graph.corpus_freq"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "print", "(", "\"Load Bert Tokenizer (%s) .... \"", "%", "args", ".", "bert_model", ")", "\n", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "args", ".", "bert_model", ")", "\n", "\n", "print", "(", "\"Got %d tokens. good..\"", "%", "tokenizer", ".", "vocab_size", ")", "\n", "\n", "datafile", "=", "Path", "(", "args", ".", "data_folder", ")", "/", "args", ".", "dataset", "\n", "\n", "df", "=", "pd", ".", "read_csv", "(", "datafile", ")", "\n", "data", "=", "df", "[", "'text'", "]", ".", "tolist", "(", ")", "\n", "\n", "objects", "=", "df", "[", "'object_ids'", "]", ".", "apply", "(", "lambda", "x", ":", "x", ".", "strip", "(", "'[]'", ")", ".", "split", "(", "','", ")", ")", ".", "tolist", "(", ")", "\n", "\n", "\n", "\n", "a1", ",", "a2", "=", "corpus_freq", "(", "data", ",", "objects", ",", "tokenizer", ",", "args", ".", "min_word_frequency", ",", "\n", "args", ".", "text_window_size", ",", "args", ".", "text_window_stride", ",", "\n", "args", ".", "remove_stop_words", ",", "args", ".", "remove_numeric", ",", "\n", "args", ".", "no_idf", ",", "args", ".", "multithread", ",", "args", ".", "num_workers", ")", "\n", "\n", "outfile", "=", "Path", "(", "args", ".", "data_folder", ")", "/", "args", ".", "output_file", "\n", "pk", ".", "dump", "(", "[", "a1", ",", "a2", ",", "{", "\n", "\"bert_model\"", ":", "args", ".", "bert_model", ",", "\n", "\"remove_stop_words\"", ":", "args", ".", "remove_stop_words", ",", "\n", "\n", "}", "]", ",", "open", "(", "outfile", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.main.main": [[15, 156], ["trainer.Trainer.check_config", "datautils.dataloader.prepare_loaders", "rich.progress.Progress", "rich.progress.BarColumn", "rich.progress.TimeRemainingColumn", "trainer.Trainer", "trainer.Trainer.load_model", "trainer.Trainer.do_train", "datetime.datetime.now().strftime", "utils.logger.add_log_to_file", "utils.logger.LOGGER.info", "trainer.Trainer.print_config", "trainer.Trainer.eval_model", "trainer.Trainer.export_test_predictions", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "datetime.datetime.now().strftime", "utils.logger.add_log_to_file", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "trainer.Trainer.predict_model", "pandas.DataFrame", "df_raw[].apply", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "df_submit.to_csv", "pd.concat.to_csv", "output_file.with_suffix", "pathlib.Path", "pathlib.Path", "numpy.argmax", "numpy.argmax", "trainer.Metrics", "trainer.Metrics", "numpy.max", "df_raw[].astype", "df_raw[].max", "df_raw[].astype", "df_raw[].astype", "df_raw[].astype", "df_raw[].astype", "df_raw[].astype", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "numpy.argmax", "df_raw[].astype", "pandas.concat", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "zipfile.ZipFile", "zip.write", "datetime.datetime.now", "len", "len", "datetime.datetime.now", "pathlib.Path", "pathlib.Path", "pandas.concat", "pandas.concat", "pandas.concat", "pandas.concat", "df_submit.misogynous.value_counts", "df_submit.shaming.value_counts", "df_submit.stereotype.value_counts", "df_submit.objectification.value_counts", "df_submit.violence.value_counts", "df_submit.misogynous.value_counts", "pathlib.Path", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.accuracy_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "pathlib.Path", "str", "len", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame"], "function", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.check_config", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.prepare_loaders", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.load_model", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.do_train", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.print_config", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.eval_model", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.export_test_predictions", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.predict_model"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "config", "=", "args", ".", "__dict__", "\n", "config", "=", "Trainer", ".", "check_config", "(", "config", ")", "\n", "\n", "prepare_loaders", "(", "config", ")", "\n", "\n", "progress", "=", "Progress", "(", "\n", "\"[progress.description]{task.description}\"", ",", "\n", "BarColumn", "(", ")", ",", "\n", "\"[progress.percentage]{task.percentage:>3.0f}% [progress.completed]{task.completed}\"", ",", "\n", "TimeRemainingColumn", "(", ")", ",", "\n", ")", "\n", "\n", "with", "progress", ":", "\n", "        ", "trainer", "=", "Trainer", "(", "config", ",", "progress", ")", "\n", "\n", "trainer", ".", "load_model", "(", ")", "\n", "if", "args", ".", "task", "==", "'train'", ":", "\n", "            ", "assert", "config", "[", "'train_loader'", "]", ",", "\"Train dataset must exist!\"", "\n", "trainer", ".", "do_train", "(", ")", "\n", "\n", "", "if", "args", ".", "task", "==", "'eval'", ":", "\n", "            ", "assert", "config", "[", "'test_loader'", "]", ",", "\"Test dataset must exist!\"", "\n", "\n", "formatted_date", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y%m%d_%H%M%S\"", ")", "\n", "\n", "add_log_to_file", "(", "Path", "(", "config", "[", "'model_file'", "]", ")", ".", "parent", "/", "f\"eval_{formatted_date}.log\"", ")", "\n", "\n", "LOGGER", ".", "info", "(", "\"\\n\\n\"", "+", "\"=\"", "*", "100", "+", "\"\\n\\t\\t\\t\\t\\t Evaluating Network\\n\"", "+", "\"=\"", "*", "100", ")", "\n", "\n", "trainer", ".", "print_config", "(", ")", "\n", "labels", ",", "preds", ",", "loss", ",", "probs", "=", "trainer", ".", "eval_model", "(", "'test_loader'", ")", "\n", "trainer", ".", "config", "[", "'model_path'", "]", "=", "Path", "(", "config", "[", "'model_file'", "]", ")", ".", "parent", "\n", "trainer", ".", "checkpoint_file", "=", "Path", "(", "config", "[", "'model_file'", "]", ")", ".", "name", "\n", "\n", "trainer", ".", "export_test_predictions", "(", "preds", ",", "probs", ")", "\n", "\n", "\n", "labels", "=", "np", ".", "argmax", "(", "labels", ",", "axis", "=", "1", ")", "if", "len", "(", "labels", "[", "-", "1", "]", ")", ">", "1", "else", "labels", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "if", "len", "(", "preds", "[", "-", "1", "]", ")", ">", "1", "else", "preds", "\n", "if", "config", "[", "'nr_classes'", "]", "<=", "2", ":", "\n", "                ", "metric", "=", "Metrics", "(", "\n", "train_loss", "=", "None", ",", "\n", "train_acc", "=", "None", ",", "\n", "train_prec", "=", "None", ",", "\n", "train_recall", "=", "None", ",", "\n", "train_f1", "=", "None", ",", "\n", "valid_loss", "=", "loss", ",", "\n", "valid_acc", "=", "accuracy_score", "(", "labels", ",", "preds", ")", ",", "\n", "valid_prec", "=", "precision_score", "(", "labels", ",", "preds", ")", ",", "\n", "valid_recall", "=", "recall_score", "(", "labels", ",", "preds", ")", ",", "\n", "valid_f1", "=", "f1_score", "(", "labels", ",", "preds", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "metric", "=", "Metrics", "(", "\n", "train_loss", "=", "None", ",", "\n", "train_acc", "=", "None", ",", "\n", "train_prec", "=", "None", ",", "\n", "train_recall", "=", "None", ",", "\n", "train_f1", "=", "None", ",", "\n", "valid_loss", "=", "loss", ",", "\n", "valid_acc", "=", "accuracy_score", "(", "labels", ",", "preds", ")", ",", "\n", "valid_prec", "=", "precision_score", "(", "labels", ",", "preds", ",", "average", "=", "'weighted'", ")", ",", "\n", "valid_recall", "=", "recall_score", "(", "labels", ",", "preds", ",", "average", "=", "'weighted'", ")", ",", "\n", "valid_f1", "=", "f1_score", "(", "labels", ",", "preds", ",", "average", "=", "'weighted'", ")", ",", "\n", ")", "\n", "\n", "", "LOGGER", ".", "info", "(", "\"-\"", "*", "30", ")", "\n", "LOGGER", ".", "info", "(", "\"Report\"", ")", "\n", "LOGGER", ".", "info", "(", "\"=\"", "*", "30", ")", "\n", "LOGGER", ".", "info", "(", "metric", ")", "\n", "LOGGER", ".", "info", "(", "\"\\n\\n\"", ")", "\n", "\n", "", "if", "args", ".", "task", "==", "'predict'", ":", "\n", "            ", "assert", "config", "[", "'test_loader'", "]", ",", "\"Test dataset must exist!\"", "\n", "formatted_date", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y%m%d_%H%M%S\"", ")", "\n", "\n", "add_log_to_file", "(", "Path", "(", "config", "[", "'model_file'", "]", ")", ".", "parent", "/", "f\"predict_{formatted_date}.log\"", ")", "\n", "\n", "LOGGER", ".", "info", "(", "\"\\n\\n\"", "+", "\"=\"", "*", "100", "+", "\"\\n\\t\\t\\t\\t\\t Predicting Network\\n\"", "+", "\"=\"", "*", "100", ")", "\n", "\n", "output_file", "=", "Path", "(", "config", "[", "'model_file'", "]", ")", ".", "parent", "/", "f\"prediction_{formatted_date}.csv\"", "\n", "raw_output_file", "=", "Path", "(", "config", "[", "'model_file'", "]", ")", ".", "parent", "/", "f\"raw_prediction_{formatted_date}.csv\"", "\n", "LOGGER", ".", "info", "(", "f\"\\t\\t Output file = {output_file}\"", ")", "\n", "LOGGER", ".", "info", "(", "f\"\\t\\t Raw Output file = {raw_output_file}\"", ")", "\n", "\n", "file_ids", ",", "preds", ",", "probs", "=", "trainer", ".", "predict_model", "(", ")", "\n", "\n", "df_raw", "=", "pd", ".", "DataFrame", "(", "file_ids", ",", "columns", "=", "[", "\"filename\"", "]", ")", "\n", "df_raw", "[", "\"filename\"", "]", "=", "df_raw", "[", "\"filename\"", "]", ".", "apply", "(", "lambda", "x", ":", "str", "(", "x", ")", "+", "'.jpg'", ")", "\n", "\n", "LOGGER", ".", "info", "(", "\"\\n\\n\"", "+", "\"-\"", "*", "30", "+", "\"\\n\\t\\t\\t\\t\\t Statistics \\n\"", "+", "\"-\"", "*", "30", ")", "\n", "LOGGER", ".", "info", "(", "f\"Total Records {len(df_raw)}\"", ")", "\n", "if", "config", "[", "'nr_classes'", "]", ">", "2", ":", "\n", "# multiclass (Task B)", "\n", "                ", "df_raw", "[", "'misogynous'", "]", "=", "np", ".", "max", "(", "preds", ",", "axis", "=", "1", ")", "\n", "df_raw", "[", "'misogynous'", "]", "=", "df_raw", "[", "'misogynous'", "]", ".", "astype", "(", "int", ")", "\n", "if", "config", "[", "'nr_classes'", "]", "==", "4", ":", "\n", "                    ", "df_raw", "=", "pd", ".", "concat", "(", "[", "df_raw", ",", "pd", ".", "DataFrame", "(", "preds", ",", "columns", "=", "[", "\"shaming\"", ",", "\"stereotype\"", ",", "\"objectification\"", ",", "\"violence\"", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "df_raw", "=", "pd", ".", "concat", "(", "[", "df_raw", ",", "pd", ".", "DataFrame", "(", "probs", ",", "columns", "=", "[", "\"shaming_prob\"", ",", "\"stereotype_prob\"", ",", "\n", "\"objectification_prob\"", ",", "\"violence_prob\"", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                    ", "df_raw", "=", "pd", ".", "concat", "(", "[", "df_raw", ",", "pd", ".", "DataFrame", "(", "preds", ",", "columns", "=", "[", "\"non_misogynous\"", ",", "\"shaming\"", ",", "\"stereotype\"", ",", "\"objectification\"", ",", "\"violence\"", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "df_raw", "=", "pd", ".", "concat", "(", "[", "df_raw", ",", "pd", ".", "DataFrame", "(", "probs", ",", "columns", "=", "[", "\"non_misogynous_prob\"", ",", "\"shaming_prob\"", ",", "\"stereotype_prob\"", ",", "\n", "\"objectification_prob\"", ",", "\"violence_prob\"", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "", "df_raw", "[", "'misogynous'", "]", "=", "df_raw", "[", "[", "\"shaming\"", ",", "\"stereotype\"", ",", "\"objectification\"", ",", "\"violence\"", "]", "]", ".", "max", "(", "axis", "=", "1", ")", "\n", "\n", "df_raw", "[", "'misogynous'", "]", "=", "df_raw", "[", "'misogynous'", "]", ".", "astype", "(", "int", ")", "\n", "df_raw", "[", "'shaming'", "]", "=", "df_raw", "[", "'shaming'", "]", ".", "astype", "(", "int", ")", "\n", "df_raw", "[", "'stereotype'", "]", "=", "df_raw", "[", "'stereotype'", "]", ".", "astype", "(", "int", ")", "\n", "df_raw", "[", "'objectification'", "]", "=", "df_raw", "[", "'objectification'", "]", ".", "astype", "(", "int", ")", "\n", "df_raw", "[", "'violence'", "]", "=", "df_raw", "[", "'violence'", "]", ".", "astype", "(", "int", ")", "\n", "\n", "df_submit", "=", "df_raw", "[", "[", "\"filename\"", ",", "\"misogynous\"", ",", "\"shaming\"", ",", "\"stereotype\"", ",", "\"objectification\"", ",", "\"violence\"", "]", "]", "\n", "\n", "LOGGER", ".", "info", "(", "\"\\nMisogynous:\"", ")", "\n", "LOGGER", ".", "info", "(", "df_submit", ".", "misogynous", ".", "value_counts", "(", ")", ")", "\n", "LOGGER", ".", "info", "(", "\"\\nShaming:\"", ")", "\n", "LOGGER", ".", "info", "(", "df_submit", ".", "shaming", ".", "value_counts", "(", ")", ")", "\n", "LOGGER", ".", "info", "(", "\"\\nStereotype:\"", ")", "\n", "LOGGER", ".", "info", "(", "df_submit", ".", "stereotype", ".", "value_counts", "(", ")", ")", "\n", "LOGGER", ".", "info", "(", "\"\\nObjectification:\"", ")", "\n", "LOGGER", ".", "info", "(", "df_submit", ".", "objectification", ".", "value_counts", "(", ")", ")", "\n", "LOGGER", ".", "info", "(", "\"\\nViolence:\"", ")", "\n", "LOGGER", ".", "info", "(", "df_submit", ".", "violence", ".", "value_counts", "(", ")", ")", "\n", "\n", "", "else", ":", "\n", "# binary (Task A)", "\n", "                ", "df_raw", "[", "'misogynous'", "]", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "df_raw", "[", "'misogynous'", "]", "=", "df_raw", "[", "'misogynous'", "]", ".", "astype", "(", "int", ")", "\n", "df_raw", "=", "pd", ".", "concat", "(", "[", "df_raw", ",", "pd", ".", "DataFrame", "(", "probs", ",", "columns", "=", "[", "\"misogynous_prob_0\"", ",", "\"misogynous_prob_1\"", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "df_submit", "=", "df_raw", "[", "[", "\"filename\"", ",", "\"misogynous\"", "]", "]", "\n", "LOGGER", ".", "info", "(", "\"\\nMisogynous:\"", ")", "\n", "LOGGER", ".", "info", "(", "df_submit", ".", "misogynous", ".", "value_counts", "(", ")", ")", "\n", "\n", "", "df_submit", ".", "to_csv", "(", "output_file", ",", "sep", "=", "\"\\t\"", ",", "index", "=", "None", ",", "header", "=", "None", ")", "\n", "df_raw", ".", "to_csv", "(", "raw_output_file", ",", "sep", "=", "\"\\t\"", ",", "index", "=", "None", ")", "\n", "\n", "zip_name", "=", "output_file", ".", "with_suffix", "(", "\".zip\"", ")", "\n", "with", "ZipFile", "(", "zip_name", ",", "'w'", ")", "as", "zip", ":", "\n", "                ", "zip", ".", "write", "(", "output_file", ",", "\"answer.txt\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Metrics.__getitem__": [[39, 41], ["super().__getattribute__"], "methods", ["None"], ["def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "__getattribute__", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Metrics.__repr__": [[42, 52], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "res", "=", "\"\"", "\n", "if", "self", ".", "train_loss", "is", "not", "None", "or", "self", ".", "train_f1", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "train_loss", "if", "self", ".", "train_loss", "is", "not", "None", "else", "0.0", "\n", "res", "+=", "f\"Train: Loss={loss:.4f}, Acc = {self.train_acc:.4f}, Precision = {self.train_prec:.4f}, F1 = {self.train_f1:.4f}\\n\"", "\n", "", "if", "self", ".", "valid_loss", "is", "not", "None", "or", "self", ".", "valid_f1", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "valid_loss", "if", "self", ".", "valid_loss", "is", "not", "None", "else", "0.0", "\n", "res", "+=", "f\"Valid: Loss={self.valid_loss:.4f}, Acc = {self.valid_acc:.4f}, Precision = {self.valid_prec:.4f}, F1 = {self.valid_f1:.4f}\"", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.__init__": [[61, 78], ["torch.device", "torch.cuda.is_available"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "progress", "=", "None", ")", ":", "\n", "        ", "self", ".", "config", "=", "config", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "self", ".", "start_epoch", "=", "1", "\n", "self", ".", "total_iters", "=", "0", "\n", "self", ".", "not_improved", "=", "0", "\n", "self", ".", "best_epoch_info", "=", "None", "\n", "self", ".", "current_best_value", "=", "None", "\n", "self", ".", "checkpoint_file", "=", "None", "\n", "self", ".", "metrics_history", "=", "[", "]", "\n", "self", ".", "labels_list", "=", "[", "]", "\n", "self", ".", "probs_list", "=", "[", "]", "\n", "self", ".", "preds_list", "=", "[", "]", "\n", "self", ".", "loss_list", "=", "[", "]", "\n", "self", ".", "lr_history", "=", "[", "]", "\n", "self", ".", "progress", "=", "progress", "\n", "self", ".", "writer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.report_epoch": [[79, 85], ["utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info"], "methods", ["None"], ["", "def", "report_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "LOGGER", ".", "info", "(", "\"-\"", "*", "30", ")", "\n", "LOGGER", ".", "info", "(", "f\"Epoch {epoch} Report\"", ")", "\n", "LOGGER", ".", "info", "(", "\"=\"", "*", "30", ")", "\n", "LOGGER", ".", "info", "(", "self", ".", "metrics_history", "[", "-", "1", "]", ")", "\n", "LOGGER", ".", "info", "(", "\"\\n\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.print_config": [[87, 93], ["utils.logger.LOGGER.info", "trainer.Trainer.config.items", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info"], "methods", ["None"], ["", "def", "print_config", "(", "self", ")", ":", "\n", "# Print args", "\n", "        ", "LOGGER", ".", "info", "(", "\"\\n\"", "+", "\"x\"", "*", "50", "+", "\"\\n\\nRunning training with the following parameters: \\n\"", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "config", ".", "items", "(", ")", ":", "\n", "            ", "LOGGER", ".", "info", "(", "f\"\\t\\t\\t {key} : {value}\"", ")", "\n", "", "LOGGER", ".", "info", "(", "\"\\n\"", "+", "\"x\"", "*", "50", "+", "\"\\n\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.epoch_end": [[94, 138], ["trainer.Trainer.scheduler.get_last_lr", "trainer.Trainer.lr_history.extend", "trainer.Trainer.eval_model", "trainer.Metrics", "utils.logger.log_tensorboard", "trainer.Trainer.metrics_history.append", "trainer.Trainer.report_epoch", "sum", "len", "trainer.Trainer.compute_metrics", "trainer.Trainer.compute_metrics", "len"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.eval_model", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.logger.log_tensorboard", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.report_epoch", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.compute_metrics", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.compute_metrics"], ["", "def", "epoch_end", "(", "self", ")", ":", "\n", "\n", "        ", "lr", "=", "self", ".", "scheduler", ".", "get_last_lr", "(", ")", "\n", "self", ".", "lr_history", ".", "extend", "(", "lr", ")", "\n", "\n", "self", ".", "train_loss", "=", "sum", "(", "self", ".", "loss_list", ")", "/", "len", "(", "self", ".", "loss_list", ")", "\n", "\n", "self", ".", "total_iters", "+=", "self", ".", "iters", "+", "1", "\n", "\n", "# Evaluate on dev set", "\n", "\n", "val_labels", ",", "val_preds", ",", "val_loss", ",", "_", "=", "self", ".", "eval_model", "(", ")", "\n", "\n", "# acc, prec, recall, f1 ", "\n", "metrics", "=", "(", "\n", "self", ".", "compute_metrics", "(", "self", ".", "labels_list", ",", "self", ".", "preds_list", ")", ",", "\n", "self", ".", "compute_metrics", "(", "val_labels", ",", "val_preds", ")", ",", "\n", ")", "\n", "\n", "epoch_metric", "=", "Metrics", "(", "\n", "train_loss", "=", "self", ".", "train_loss", ",", "\n", "train_acc", "=", "metrics", "[", "0", "]", "[", "0", "]", ",", "\n", "train_prec", "=", "metrics", "[", "0", "]", "[", "1", "]", ",", "\n", "train_recall", "=", "metrics", "[", "0", "]", "[", "2", "]", ",", "\n", "train_f1", "=", "metrics", "[", "0", "]", "[", "3", "]", ",", "\n", "valid_loss", "=", "val_loss", ",", "\n", "valid_acc", "=", "metrics", "[", "1", "]", "[", "0", "]", ",", "\n", "valid_prec", "=", "metrics", "[", "1", "]", "[", "1", "]", ",", "\n", "valid_recall", "=", "metrics", "[", "1", "]", "[", "2", "]", ",", "\n", "valid_f1", "=", "metrics", "[", "1", "]", "[", "3", "]", ",", "\n", ")", "\n", "\n", "log_tensorboard", "(", "self", ".", "writer", ",", "epoch_metric", ",", "self", ".", "epoch", ",", "self", ".", "iters", ",", "len", "(", "self", ".", "config", "[", "'train_loader'", "]", ")", ",", "skip_validation", "=", "False", ")", "\n", "self", ".", "epoch_metric", "=", "epoch_metric", "\n", "self", ".", "metrics_history", ".", "append", "(", "epoch_metric", ")", "\n", "\n", "# print stats", "\n", "self", ".", "report_epoch", "(", "self", ".", "epoch", ")", "\n", "\n", "self", ".", "probs_list", "=", "[", "]", "\n", "self", ".", "preds_list", "=", "[", "]", "\n", "self", ".", "labels_list", "=", "[", "]", "\n", "self", ".", "loss_list", "=", "[", "]", "\n", "self", ".", "id_list", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.avg_gradients": [[139, 143], ["trainer.Trainer.model.parameters"], "methods", ["None"], ["", "def", "avg_gradients", "(", "self", ",", "steps", ")", ":", "\n", "        ", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", "and", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "param", ".", "grad", "=", "param", ".", "grad", "/", "steps", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.init_scheduler": [[144, 155], ["torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.MultiStepLR", "transformers.get_linear_schedule_with_warmup", "transformers.get_cosine_schedule_with_warmup", "len", "len"], "methods", ["None"], ["", "", "", "def", "init_scheduler", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "config", "[", "'scheduler'", "]", "==", "'step'", ":", "\n", "            ", "self", ".", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "self", ".", "optimizer", ",", "step_size", "=", "self", ".", "config", "[", "'lr_decay_step'", "]", ",", "gamma", "=", "self", ".", "config", "[", "'lr_decay_factor'", "]", ")", "\n", "", "elif", "self", ".", "config", "[", "'scheduler'", "]", "==", "'multi_step'", ":", "\n", "            ", "self", ".", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "self", ".", "optimizer", ",", "milestones", "=", "[", "5", ",", "10", ",", "15", ",", "25", ",", "40", "]", ",", "gamma", "=", "self", ".", "config", "[", "'lr_decay_factor'", "]", ")", "\n", "", "elif", "self", ".", "config", "[", "'scheduler'", "]", "==", "'warmup'", ":", "\n", "            ", "self", ".", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "config", "[", "'warmup_steps'", "]", ",", "\n", "num_training_steps", "=", "len", "(", "self", ".", "config", "[", "'train_loader'", "]", ")", "*", "self", ".", "config", "[", "'max_epoch'", "]", ")", "\n", "", "elif", "self", ".", "config", "[", "'scheduler'", "]", "==", "'warmup_cosine'", ":", "\n", "            ", "self", ".", "scheduler", "=", "get_cosine_schedule_with_warmup", "(", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "config", "[", "'warmup_steps'", "]", ",", "\n", "num_training_steps", "=", "len", "(", "self", ".", "config", "[", "'train_loader'", "]", ")", "*", "self", ".", "config", "[", "'max_epoch'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.init_optimizer": [[157, 169], ["OptimCls", "trainer.Trainer.model.parameters"], "methods", ["None"], ["", "", "def", "init_optimizer", "(", "self", ")", ":", "\n", "        ", "OptimCls", "=", "{", "\n", "'adam'", ":", "Adam", ",", "\n", "'adamax'", ":", "Adamax", ",", "\n", "'adamw'", ":", "AdamW", ",", "\n", "'sgd'", ":", "SGD", ",", "\n", "}", "[", "self", ".", "config", "[", "'optimizer'", "]", "]", "\n", "\n", "self", ".", "optimizer", "=", "OptimCls", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "config", "[", "'lr'", "]", ",", "\n", "weight_decay", "=", "self", ".", "config", "[", "'weight_decay'", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.load_model": [[171, 266], ["utils.logger.LOGGER.info", "trainer.Trainer.model.to", "pyexpat.model.uniter.UniterConfig.from_json_file", "pyexpat.model.uniter.UniterModel", "utils.logger.LOGGER.info", "torch.load", "pyexpat.model.uniter.UniterForPretraining.from_pretrained", "pyexpat.model.semeval.SemevalUniter", "utils.logger.LOGGER.info", "trainer.Trainer.model.load", "utils.logger.LOGGER.info", "trainer.Trainer.init_optimizer", "trainer.Trainer.init_scheduler", "torch.nn.BCEWithLogitsLoss", "pyexpat.model.semeval.SemevalUniterVGG19Sentiment", "torch.nn.BCELoss", "torch.nn.CrossEntropyLoss", "utils.gcn.GCNConfig", "pickle.load", "utils.gcn.get_torch_gcn", "range", "pyexpat.model.semeval.VGCN_Bert", "torch.tensor().to", "open", "len", "gcn_adj_list[].to", "utils.gcn.GCNConfig", "pickle.load", "utils.gcn.get_torch_gcn", "range", "pyexpat.model.semeval.VGCN_Bert_and_VGG", "Exception", "len", "open", "len", "gcn_adj_list[].to", "torch.tensor", "len"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterConfig.from_json_file", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.init_optimizer", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.init_scheduler", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.gcn.get_torch_gcn", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.gcn.get_torch_gcn"], ["", "def", "load_model", "(", "self", ")", ":", "\n", "\n", "        ", "LOGGER", ".", "info", "(", "\"Loading model..\"", ")", "\n", "if", "self", ".", "config", "[", "'model_file'", "]", "or", "not", "self", ".", "config", "[", "'pretrained_model_file'", "]", ":", "\n", "            ", "uniter_config", "=", "UniterConfig", ".", "from_json_file", "(", "self", ".", "config", "[", "'config'", "]", ")", "\n", "uniter_model", "=", "UniterModel", "(", "uniter_config", ",", "img_dim", "=", "IMG_DIM", ")", "\n", "\n", "\n", "", "else", ":", "\n", "# Pretrained model ", "\n", "            ", "LOGGER", ".", "info", "(", "f\"Starting with vanilla pretrained UNITER model\"", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "self", ".", "config", "[", "'pretrained_model_file'", "]", ")", "\n", "base_model", "=", "UniterForPretraining", ".", "from_pretrained", "(", "self", ".", "config", "[", "'config'", "]", ",", "\n", "state_dict", "=", "checkpoint", ",", "\n", "img_dim", "=", "IMG_DIM", ",", "\n", "img_label_dim", "=", "IMG_LABEL_DIM", ")", "\n", "uniter_model", "=", "base_model", ".", "uniter", "\n", "\n", "", "if", "self", ".", "config", "[", "'model_type'", "]", "==", "'uniter'", ":", "\n", "            ", "self", ".", "model", "=", "SemevalUniter", "(", "uniter_model", "=", "uniter_model", ",", "\n", "n_classes", "=", "self", ".", "config", "[", "'nr_classes'", "]", ")", "\n", "\n", "", "elif", "self", ".", "config", "[", "'model_type'", "]", "==", "'uniter-sentiment'", ":", "\n", "            ", "self", ".", "model", "=", "SemevalUniterVGG19Sentiment", "(", "uniter_model", "=", "uniter_model", ",", "\n", "dropout", "=", "self", ".", "config", "[", "'dropout'", "]", ",", "\n", "n_classes", "=", "self", ".", "config", "[", "'nr_classes'", "]", ")", "\n", "\n", "", "elif", "self", ".", "config", "[", "'model_type'", "]", "==", "'uniter-gnn'", ":", "\n", "            ", "datautils", ".", "dataloader", ".", "gcn_conf", "=", "GCNConfig", "(", "\n", "vocab_size", "=", "base_model", ".", "config", ".", "vocab_size", "+", "OBJECT_VOCAB_SIZE", ",", "\n", "npmi_threshold", "=", "self", ".", "config", "[", "'adj_npmi_threshold'", "]", ",", "\n", "tf_threshold", "=", "self", ".", "config", "[", "'adj_tf_threshold'", "]", ",", "\n", "vocab_adj", "=", "self", ".", "config", "[", "'adj_vocab_type'", "]", ",", "\n", ")", "\n", "\n", "\n", "gcn_vocab_adj_tf", ",", "gcn_vocab_adj", ",", "adj_config", "=", "pkl", ".", "load", "(", "open", "(", "self", ".", "config", "[", "'matrix_file'", "]", ",", "'rb'", ")", ")", "\n", "\n", "gcn_adj_list", "=", "get_torch_gcn", "(", "gcn_vocab_adj_tf", ",", "gcn_vocab_adj", ",", "datautils", ".", "dataloader", ".", "gcn_conf", ")", "# Scipy sparse matrix to Torch", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "gcn_adj_list", ")", ")", ":", "gcn_adj_list", "[", "i", "]", "=", "gcn_adj_list", "[", "i", "]", ".", "to", "(", "self", ".", "device", ")", "# Send to device", "\n", "\n", "self", ".", "model", "=", "VGCN_Bert", "(", "uniter_model", ",", "\n", "gcn_adj_matrix", "=", "gcn_adj_list", ",", "\n", "gcn_adj_dim", "=", "datautils", ".", "dataloader", ".", "gcn_conf", ".", "vocab_size", ",", "\n", "gcn_adj_num", "=", "len", "(", "gcn_adj_list", ")", ",", "\n", "gcn_embedding_dim", "=", "self", ".", "config", "[", "'gcn_embedding_dim'", "]", ",", "\n", "num_labels", "=", "self", ".", "config", "[", "'nr_classes'", "]", ")", "\n", "\n", "", "elif", "self", ".", "config", "[", "'model_type'", "]", "==", "'uniter-gnn2'", ":", "\n", "            ", "datautils", ".", "dataloader", ".", "gcn_conf", "=", "GCNConfig", "(", "\n", "vocab_size", "=", "base_model", ".", "config", ".", "vocab_size", "+", "OBJECT_VOCAB_SIZE", ",", "\n", "npmi_threshold", "=", "self", ".", "config", "[", "'adj_npmi_threshold'", "]", ",", "\n", "tf_threshold", "=", "self", ".", "config", "[", "'adj_tf_threshold'", "]", ",", "\n", "vocab_adj", "=", "self", ".", "config", "[", "'adj_vocab_type'", "]", ",", "\n", ")", "\n", "\n", "\n", "gcn_vocab_adj_tf", ",", "gcn_vocab_adj", ",", "adj_config", "=", "pkl", ".", "load", "(", "open", "(", "self", ".", "config", "[", "'matrix_file'", "]", ",", "'rb'", ")", ")", "\n", "\n", "gcn_adj_list", "=", "get_torch_gcn", "(", "gcn_vocab_adj_tf", ",", "gcn_vocab_adj", ",", "datautils", ".", "dataloader", ".", "gcn_conf", ")", "# Scipy sparse matrix to Torch", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "gcn_adj_list", ")", ")", ":", "gcn_adj_list", "[", "i", "]", "=", "gcn_adj_list", "[", "i", "]", ".", "to", "(", "self", ".", "device", ")", "# Send to device", "\n", "\n", "self", ".", "model", "=", "VGCN_Bert_and_VGG", "(", "uniter_model", ",", "\n", "gcn_adj_matrix", "=", "gcn_adj_list", ",", "\n", "gcn_adj_dim", "=", "datautils", ".", "dataloader", ".", "gcn_conf", ".", "vocab_size", ",", "\n", "gcn_adj_num", "=", "len", "(", "gcn_adj_list", ")", ",", "\n", "gcn_embedding_dim", "=", "self", ".", "config", "[", "'gcn_embedding_dim'", "]", ",", "\n", "num_labels", "=", "self", ".", "config", "[", "'nr_classes'", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Model Type must be defined!'", ")", "\n", "\n", "\n", "", "if", "self", ".", "config", "[", "'model_file'", "]", ":", "\n", "# previously saved model file ", "\n", "            ", "LOGGER", ".", "info", "(", "f\"Loading previously saved model {self.config['model_file']}\"", ")", "\n", "self", ".", "model", ".", "load", "(", "self", ".", "config", "[", "'model_file'", "]", ")", "\n", "", "else", ":", "\n", "            ", "LOGGER", ".", "info", "(", "f\"Starting with fresh UNITER instance\"", ")", "\n", "\n", "", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "if", "self", ".", "config", "[", "'task'", "]", "==", "'train'", ":", "\n", "            ", "self", ".", "init_optimizer", "(", ")", "\n", "self", ".", "init_scheduler", "(", ")", "\n", "\n", "", "if", "self", ".", "config", "[", "'loss_func'", "]", "==", "'bce_logits'", ":", "\n", "            ", "self", ".", "criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", "pos_weight", "=", "torch", ".", "tensor", "(", "[", "self", ".", "config", "[", "'pos_wt'", "]", "]", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "", "elif", "self", ".", "config", "[", "'loss_func'", "]", "==", "'bce'", ":", "\n", "            ", "self", ".", "criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.average_gradients": [[267, 271], ["trainer.Trainer.model.parameters"], "methods", ["None"], ["", "", "def", "average_gradients", "(", "self", ",", "steps", ")", ":", "\n", "        ", "for", "param", "in", "self", ".", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", "and", "param", ".", "grad", "is", "not", "None", ":", "\n", "                ", "param", ".", "grad", "=", "param", ".", "grad", "/", "steps", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.logits_to_prediction": [[272, 293], ["torch.argmax", "torch.eye().to().index_select", "torch.nn.functional.softmax", "torch.nonzero", "torch.nn.functional.one_hot().type", "torch.sigmoid", "torch.eye().to", "torch.nn.functional.one_hot", "torch.eye", "torch.eye().to().index_select.max", "probs[].max", "preds[].max"], "methods", ["None"], ["", "", "", "def", "logits_to_prediction", "(", "self", ",", "logits", ",", "margin", "=", "0.5", ")", ":", "\n", "        ", "if", "self", ".", "config", "[", "'loss_func'", "]", "==", "'bce'", ":", "\n", "            ", "probs", "=", "logits", "\n", "", "elif", "self", ".", "config", "[", "'loss_func'", "]", "==", "'ce'", ":", "\n", "            ", "probs", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "probs", "=", "logits", "\n", "", "elif", "self", ".", "config", "[", "'loss_func'", "]", "==", "'bce_logits'", ":", "\n", "            ", "probs", "=", "torch", ".", "sigmoid", "(", "logits", ")", "\n", "\n", "", "if", "self", ".", "config", "[", "'nr_classes'", "]", ">", "2", ":", "\n", "            ", "preds", "=", "(", "probs", ">", "margin", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "if", "self", ".", "config", "[", "'nr_classes'", "]", "==", "5", ":", "# daca e pred[0]=1 si restul not 0 --> de luat cel mai probabil", "\n", "                ", "indices", "=", "torch", ".", "nonzero", "(", "(", "(", "preds", "[", ":", ",", "0", "]", "==", "1", ")", "&", "(", "preds", "[", ":", ",", "1", ":", "]", ".", "max", "(", "dim", "=", "1", ")", ".", "values", "==", "1", ")", ")", "|", "(", "preds", ".", "max", "(", "dim", "=", "1", ")", ".", "values", "==", "0", ")", ",", "as_tuple", "=", "True", ")", "\n", "preds", "[", "indices", "]", "=", "torch", ".", "nn", ".", "functional", ".", "one_hot", "(", "probs", "[", "indices", "]", ".", "max", "(", "dim", "=", "1", ")", ".", "indices", ",", "5", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "preds", "=", "torch", ".", "argmax", "(", "probs", ",", "dim", "=", "1", ")", "\n", "preds", "=", "torch", ".", "eye", "(", "2", ")", ".", "to", "(", "preds", ".", "device", ")", ".", "index_select", "(", "dim", "=", "0", ",", "index", "=", "preds", ")", "\n", "\n", "\n", "", "return", "preds", ",", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.calculate_loss": [[295, 330], ["trainer.Trainer.criterion", "trainer.Trainer.detach().item", "torch.sigmoid", "torch.softmax", "torch.softmax.to", "batch_label.cpu().detach().tolist.cpu().detach().tolist.type().to", "trainer.Trainer.backward", "trainer.Trainer.logits_to_prediction", "preds.cpu().detach().tolist.cpu().detach().tolist.cpu().detach().tolist", "probs.cpu().detach().tolist.cpu().detach().tolist.cpu().detach().tolist", "batch_label.cpu().detach().tolist.cpu().detach().tolist.cpu().detach().tolist", "trainer.Trainer.preds_list.extend", "trainer.Trainer.probs_list.extend", "trainer.Trainer.labels_list.extend", "trainer.Trainer.loss_list.append", "trainer.Trainer.average_gradients", "torch.nn.utils.clip_grad_norm_", "trainer.Trainer.optimizer.step", "trainer.Trainer.scheduler.step", "trainer.Trainer.optimizer.zero_grad", "trainer.Trainer.detach().item", "trainer.Trainer.detach", "batch_label.cpu().detach().tolist.cpu().detach().tolist.type", "trainer.Trainer.model.parameters", "preds.cpu().detach().tolist.cpu().detach().tolist.cpu().detach", "probs.cpu().detach().tolist.cpu().detach().tolist.cpu().detach", "batch_label.cpu().detach().tolist.cpu().detach().tolist.cpu().detach", "trainer.Trainer.detach", "preds.cpu().detach().tolist.cpu().detach().tolist.cpu", "probs.cpu().detach().tolist.cpu().detach().tolist.cpu", "batch_label.cpu().detach().tolist.cpu().detach().tolist.cpu"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.logits_to_prediction", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.average_gradients"], ["", "def", "calculate_loss", "(", "self", ",", "logits", ",", "batch_label", ",", "is_train", ")", ":", "\n", "\n", "        ", "if", "self", ".", "config", "[", "'loss_func'", "]", "==", "'bce'", ":", "\n", "            ", "logits", "=", "torch", ".", "sigmoid", "(", "logits", ")", "\n", "", "if", "self", ".", "config", "[", "'loss_func'", "]", "==", "'ce'", ":", "\n", "            ", "logits", "=", "torch", ".", "softmax", "(", "logits", ")", "\n", "\n", "# logits = logits.squeeze(1).to(self.device) if self.config['loss_func'] == 'bce_logits' else logits.to(self.device)", "\n", "\n", "# loss = self.criterion(logits, batch_label.type(torch.FloatTensor).to(self.device) if self.config['loss_func']=='ce' else batch_label.float().to(self.device))", "\n", "\n", "", "loss", "=", "self", ".", "criterion", "(", "logits", ".", "to", "(", "self", ".", "device", ")", ",", "batch_label", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "to", "(", "self", ".", "device", ")", ")", "\n", "\n", "if", "is_train", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "iters", "%", "self", ".", "config", "[", "'gradient_accumulation'", "]", "==", "0", ":", "\n", "                ", "self", ".", "average_gradients", "(", "steps", "=", "self", ".", "config", "[", "'gradient_accumulation'", "]", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "config", "[", "'max_grad_norm'", "]", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "self", ".", "scheduler", ".", "step", "(", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "preds", ",", "probs", "=", "self", ".", "logits_to_prediction", "(", "logits", ")", "\n", "\n", "\n", "preds", "=", "preds", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", "\n", "probs", "=", "probs", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", "\n", "batch_label", "=", "batch_label", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "self", ".", "preds_list", ".", "extend", "(", "preds", ")", "\n", "self", ".", "probs_list", ".", "extend", "(", "probs", ")", "\n", "self", ".", "labels_list", ".", "extend", "(", "batch_label", ")", "\n", "self", ".", "loss_list", ".", "append", "(", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "", "return", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.check_early_stopping": [[331, 359], ["utils.logger.LOGGER.info", "abs", "utils.logger.LOGGER.info", "trainer.Trainer.model.save", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save"], ["", "def", "check_early_stopping", "(", "self", ")", ":", "\n", "\n", "        ", "this_metric", "=", "self", ".", "epoch_metric", "[", "\"valid_\"", "+", "self", ".", "config", "[", "'optimize_for'", "]", "]", "\n", "diff", "=", "999", "if", "self", ".", "current_best_value", "is", "None", "else", "abs", "(", "self", ".", "current_best_value", "-", "this_metric", ")", "\n", "\n", "self", ".", "not_improved", "+=", "1", "\n", "\n", "if", "(", "self", ".", "current_best_value", "is", "None", ")", "or", "(", "\n", "this_metric", "<", "self", ".", "current_best_value", "if", "self", ".", "config", "[", "'optimize_for'", "]", "==", "'loss'", "else", "this_metric", ">", "self", ".", "current_best_value", "\n", ")", ":", "\n", "            ", "LOGGER", ".", "info", "(", "\"New High Score! Saving model...\"", ")", "\n", "\n", "self", ".", "current_best_value", "=", "this_metric", "\n", "self", ".", "best_epoch_info", "=", "{", "\n", "'metrics'", ":", "this_metric", ",", "\n", "'epoch'", ":", "self", ".", "epoch", ",", "\n", "\n", "}", "\n", "\n", "\n", "if", "not", "self", ".", "config", "[", "\"no_model_checkpoints\"", "]", ":", "\n", "                ", "self", ".", "model", ".", "save", "(", "Path", "(", "self", ".", "config", "[", "'model_path'", "]", ")", "/", "self", ".", "checkpoint_file", ")", "\n", "\n", "", "if", "diff", ">=", "self", ".", "config", "[", "'early_stop_thresh'", "]", ":", "\n", "                ", "self", ".", "not_improved", "=", "0", "\n", "\n", "", "", "LOGGER", ".", "info", "(", "f\"current patience: {self.not_improved}\"", ")", "\n", "return", "self", ".", "not_improved", ">=", "self", ".", "config", "[", "'patience'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.log_training": [[361, 365], ["utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info"], "methods", ["None"], ["", "def", "log_training", "(", "self", ")", ":", "\n", "        ", "LOGGER", ".", "info", "(", "\"-----------====== Training ended ======-----------\"", ")", "\n", "LOGGER", ".", "info", "(", "f\"Best Metrics on epoch {self.best_epoch_info['epoch']}:\"", ")", "\n", "LOGGER", ".", "info", "(", "self", ".", "best_epoch_info", "[", "'metrics'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.export_test_predictions": [[367, 402], ["output_file.with_suffix.with_suffix.with_suffix", "pandas.concat.to_csv", "pathlib.Path", "df_raw[].max", "df_raw[].astype", "df_raw[].astype", "df_raw[].astype", "df_raw[].astype", "df_raw[].astype", "numpy.argmax", "df_raw[].astype", "pandas.concat", "pandas.concat", "pandas.concat", "pandas.concat", "pandas.concat", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["", "def", "export_test_predictions", "(", "self", ",", "preds", ",", "probs", ")", ":", "\n", "        ", "output_file", "=", "Path", "(", "self", ".", "config", "[", "'model_path'", "]", ")", "/", "self", ".", "checkpoint_file", "\n", "output_file", "=", "output_file", ".", "parent", "/", "(", "\"eval_\"", "+", "output_file", ".", "name", ")", "\n", "output_file", "=", "output_file", ".", "with_suffix", "(", "\".csv\"", ")", "\n", "\n", "df_raw", "=", "self", ".", "config", "[", "'test_loader'", "]", ".", "dataset", ".", "df", "\n", "\n", "\n", "if", "self", ".", "config", "[", "'nr_classes'", "]", ">", "2", ":", "\n", "# multiclass (Task B)", "\n", "            ", "if", "self", ".", "config", "[", "'nr_classes'", "]", "==", "4", ":", "\n", "                ", "df_raw", "=", "pd", ".", "concat", "(", "[", "df_raw", ",", "pd", ".", "DataFrame", "(", "preds", ",", "columns", "=", "[", "\"pred_shaming\"", ",", "\n", "\"pred_stereotype\"", ",", "\"pred_objectification\"", ",", "\"pred_violence\"", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "df_raw", "=", "pd", ".", "concat", "(", "[", "df_raw", ",", "pd", ".", "DataFrame", "(", "probs", ",", "columns", "=", "[", "\"shaming_prob\"", ",", "\"stereotype_prob\"", ",", "\n", "\"objectification_prob\"", ",", "\"violence_prob\"", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "df_raw", "=", "pd", ".", "concat", "(", "[", "df_raw", ",", "pd", ".", "DataFrame", "(", "preds", ",", "columns", "=", "[", "\"pred_non_misogynous\"", ",", "\"pred_shaming\"", ",", "\n", "\"pred_stereotype\"", ",", "\"pred_objectification\"", ",", "\"pred_violence\"", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "df_raw", "=", "pd", ".", "concat", "(", "[", "df_raw", ",", "pd", ".", "DataFrame", "(", "probs", ",", "columns", "=", "[", "\"non_misogynous_prob\"", ",", "\"shaming_prob\"", ",", "\"stereotype_prob\"", ",", "\n", "\"objectification_prob\"", ",", "\"violence_prob\"", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "df_raw", "[", "'pred_misogynous'", "]", "=", "df_raw", "[", "[", "\"pred_shaming\"", ",", "\"pred_stereotype\"", ",", "\"pred_objectification\"", ",", "\"pred_violence\"", "]", "]", ".", "max", "(", "axis", "=", "1", ")", "\n", "df_raw", "[", "'pred_misogynous'", "]", "=", "df_raw", "[", "'pred_misogynous'", "]", ".", "astype", "(", "int", ")", "\n", "df_raw", "[", "'pred_shaming'", "]", "=", "df_raw", "[", "'pred_shaming'", "]", ".", "astype", "(", "int", ")", "\n", "df_raw", "[", "'pred_stereotype'", "]", "=", "df_raw", "[", "'pred_stereotype'", "]", ".", "astype", "(", "int", ")", "\n", "df_raw", "[", "'pred_objectification'", "]", "=", "df_raw", "[", "'pred_objectification'", "]", ".", "astype", "(", "int", ")", "\n", "df_raw", "[", "'pred_violence'", "]", "=", "df_raw", "[", "'pred_violence'", "]", ".", "astype", "(", "int", ")", "\n", "\n", "", "else", ":", "\n", "# binary (Task A)", "\n", "            ", "df_raw", "[", "'pred_misogynous'", "]", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "df_raw", "[", "'pred_misogynous'", "]", "=", "df_raw", "[", "'pred_misogynous'", "]", ".", "astype", "(", "int", ")", "\n", "df_raw", "=", "pd", ".", "concat", "(", "[", "df_raw", ",", "pd", ".", "DataFrame", "(", "probs", ",", "columns", "=", "[", "\"misogynous_prob_0\"", ",", "\"misogynous_prob_1\"", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "df_raw", ".", "to_csv", "(", "output_file", ",", "sep", "=", "\"\\t\"", ",", "index", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.compute_metrics": [[403, 422], ["range", "sklearn.metrics.accuracy_score", "len", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "utils.metrics.compute_scoreA", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "utils.metrics.compute_scoreB", "numpy.argmax", "numpy.argmax", "dict", "dict", "dict", "dict", "len", "len", "zip", "zip", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.compute_scoreA", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.compute_scoreB"], ["", "def", "compute_metrics", "(", "self", ",", "labels", ",", "preds", ")", ":", "\n", "        ", "r_labels", "=", "range", "(", "len", "(", "labels", ")", ")", "\n", "if", "self", ".", "config", "[", "'nr_classes'", "]", "<=", "2", ":", "\n", "            ", "labels", "=", "np", ".", "argmax", "(", "labels", ",", "axis", "=", "1", ")", "if", "len", "(", "labels", "[", "-", "1", "]", ")", ">", "1", "else", "labels", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "if", "len", "(", "preds", "[", "-", "1", "]", ")", ">", "1", "else", "preds", "\n", "\n", "prec", "=", "precision_score", "(", "labels", ",", "preds", ",", "zero_division", "=", "0", ")", "\n", "recall", "=", "recall_score", "(", "labels", ",", "preds", ",", "zero_division", "=", "0", ")", "\n", "# f1=f1_score(labels, preds, average='weighted', zero_division=0)", "\n", "f1", "=", "compute_scoreA", "(", "dict", "(", "zip", "(", "r_labels", ",", "labels", ")", ")", ",", "dict", "(", "zip", "(", "r_labels", ",", "preds", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "prec", "=", "precision_score", "(", "labels", ",", "preds", ",", "average", "=", "'weighted'", ",", "zero_division", "=", "0", ")", "\n", "recall", "=", "recall_score", "(", "labels", ",", "preds", ",", "average", "=", "'weighted'", ",", "zero_division", "=", "0", ")", "\n", "# f1=f1_score(labels, preds, average='weighted', zero_division=0) # Weighted pt Multiclass!!", "\n", "f1", "=", "compute_scoreB", "(", "dict", "(", "zip", "(", "r_labels", ",", "labels", ")", ")", ",", "dict", "(", "zip", "(", "r_labels", ",", "preds", ")", ")", ")", "\n", "\n", "", "acc", "=", "accuracy_score", "(", "labels", ",", "preds", ")", "\n", "\n", "return", "acc", ",", "prec", ",", "recall", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.end_training": [[423, 458], ["utils.logger.LOGGER.info", "trainer.Trainer.log_training", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "len", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "utils.logger.LOGGER.info", "trainer.Trainer.eval_model", "trainer.Trainer.compute_metrics", "utils.logger.LOGGER.info", "trainer.Trainer.export_test_predictions", "trainer.Trainer.writer.close", "trainer.Trainer.model.load", "trainer.Trainer.model.to", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.log_training", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.eval_model", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.compute_metrics", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.export_test_predictions", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load"], ["", "def", "end_training", "(", "self", ")", ":", "\n", "# Termination message", "\n", "        ", "LOGGER", ".", "info", "(", "\"\\n\"", "+", "\"-\"", "*", "100", ")", "\n", "if", "self", ".", "epoch", "<", "self", ".", "config", "[", "'max_epoch'", "]", ":", "\n", "            ", "LOGGER", ".", "info", "(", "\"Training terminated on epoch {} because the Validation {} did not improve for {} epochs\"", ".", "format", "(", "self", ".", "epoch", ",", "self", ".", "config", "[", "'optimize_for'", "]", ",", "self", ".", "config", "[", "'patience'", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "LOGGER", ".", "info", "(", "\"Maximum epochs of {} reached. Finished training !!\"", ".", "format", "(", "self", ".", "config", "[", "'max_epoch'", "]", ")", ")", "\n", "\n", "", "if", "len", "(", "self", ".", "config", "[", "'test_loader'", "]", ")", "and", "'misogynous'", "in", "self", ".", "config", "[", "'test_loader'", "]", ".", "dataset", ".", "df", ":", "\n", "            ", "LOGGER", ".", "info", "(", "\"-\"", "*", "30", ")", "\n", "LOGGER", ".", "info", "(", "\"\\t\\tEvaluating on test set\"", ")", "\n", "LOGGER", ".", "info", "(", "\"-\"", "*", "30", ")", "\n", "\n", "if", "(", "Path", "(", "self", ".", "config", "[", "'model_path'", "]", ")", "/", "self", ".", "checkpoint_file", ")", ".", "exists", "(", ")", ":", "\n", "                ", "self", ".", "model", ".", "load", "(", "Path", "(", "self", ".", "config", "[", "'model_path'", "]", ")", "/", "self", ".", "checkpoint_file", ")", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "\n", "", "labels", ",", "preds", ",", "loss", ",", "probs", "=", "self", ".", "eval_model", "(", "dataset", "=", "'test_loader'", ")", "\n", "acc", ",", "prec", ",", "recall", ",", "f1", "=", "self", ".", "compute_metrics", "(", "labels", ",", "preds", ")", "\n", "LOGGER", ".", "info", "(", "f\"\\tLoss={loss:.4f} , Acc =  {acc:.4f} , Prec = {prec:.4f} , Recall = {recall:.4f} , F1 = {f1:.4f} \"", ")", "\n", "self", ".", "export_test_predictions", "(", "preds", ",", "probs", ")", "\n", "\n", "##  if test data has label ---> compute metrics ", "\n", "##", "\n", "##", "\n", "", "else", ":", "\n", "            ", "acc", ",", "prec", ",", "recall", ",", "f1", ",", "loss", "=", "[", "0", "]", "*", "5", "\n", "\n", "", "self", ".", "log_training", "(", ")", "\n", "\n", "if", "self", ".", "writer", ":", "\n", "            ", "self", ".", "writer", ".", "close", "(", ")", "\n", "\n", "", "return", "acc", ",", "prec", ",", "recall", ",", "f1", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.metric_reporting": [[459, 478], ["trainer.Trainer.compute_metrics", "trainer.Metrics", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.compute_metrics"], ["", "def", "metric_reporting", "(", "self", ")", ":", "\n", "        ", "loss", "=", "sum", "(", "self", ".", "loss_list", ")", "/", "len", "(", "self", ".", "loss_list", ")", "\n", "\n", "acc", ",", "prec", ",", "recall", ",", "f1", "=", "self", ".", "compute_metrics", "(", "self", ".", "labels_list", ",", "self", ".", "preds_list", ")", "\n", "\n", "metric", "=", "Metrics", "(", "\n", "train_loss", "=", "loss", ",", "\n", "train_acc", "=", "acc", ",", "\n", "train_prec", "=", "prec", ",", "\n", "train_recall", "=", "recall", ",", "\n", "train_f1", "=", "f1", ",", "\n", "valid_loss", "=", "None", ",", "\n", "valid_acc", "=", "None", ",", "\n", "valid_prec", "=", "None", ",", "\n", "valid_recall", "=", "None", ",", "\n", "valid_f1", "=", "None", ",", "\n", ")", "\n", "\n", "return", "metric", "\n", "", "def", "call_model", "(", "self", ",", "batch", ")", ":", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.call_model": [[478, 520], ["trainer.Trainer.model", "trainer.Trainer.model", "trainer.Trainer.model", "trainer.Trainer.model", "Exception"], "methods", ["None"], ["", "def", "call_model", "(", "self", ",", "batch", ")", ":", "\n", "        ", "if", "self", ".", "config", "[", "'model_type'", "]", "==", "'uniter'", ":", "\n", "            ", "preds", "=", "self", ".", "model", "(", "img_feat", "=", "batch", "[", "'image_features'", "]", ",", "\n", "img_pos_feat", "=", "batch", "[", "'image_pos_features'", "]", ",", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ",", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", ",", "\n", "attention_mask", "=", "batch", "[", "'attn_masks'", "]", ",", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "", "elif", "self", ".", "config", "[", "'model_type'", "]", "==", "'uniter-sentiment'", ":", "\n", "            ", "preds", "=", "self", ".", "model", "(", "img_feat", "=", "batch", "[", "'image_features'", "]", ",", "\n", "img_pos_feat", "=", "batch", "[", "'image_pos_features'", "]", ",", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ",", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", ",", "\n", "attention_mask", "=", "batch", "[", "'attn_masks'", "]", ",", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "vgg_pool", "=", "batch", "[", "'sent_features'", "]", ")", "\n", "", "elif", "self", ".", "config", "[", "'model_type'", "]", "==", "'uniter-gnn'", ":", "\n", "            ", "preds", "=", "self", ".", "model", "(", "img_feat", "=", "batch", "[", "'image_features'", "]", ",", "\n", "img_pos_feat", "=", "batch", "[", "'image_pos_features'", "]", ",", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ",", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", ",", "\n", "attention_mask", "=", "batch", "[", "'attn_masks'", "]", ",", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "gcn_swop_eye", "=", "batch", "[", "'gcn'", "]", ")", "\n", "", "elif", "self", ".", "config", "[", "'model_type'", "]", "==", "'uniter-gnn2'", ":", "\n", "            ", "preds", "=", "self", ".", "model", "(", "img_feat", "=", "batch", "[", "'image_features'", "]", ",", "\n", "img_pos_feat", "=", "batch", "[", "'image_pos_features'", "]", ",", "\n", "input_ids", "=", "batch", "[", "'input_ids'", "]", ",", "\n", "position_ids", "=", "batch", "[", "'position_ids'", "]", ",", "\n", "attention_mask", "=", "batch", "[", "'attn_masks'", "]", ",", "\n", "gather_index", "=", "batch", "[", "'gather_index'", "]", ",", "\n", "output_all_encoded_layers", "=", "False", ",", "\n", "gcn_swop_eye", "=", "batch", "[", "'gcn'", "]", ",", "\n", "vgg_pool", "=", "batch", "[", "'sent_features'", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Model Type must be defined!'", ")", "\n", "\n", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.do_train": [[521, 578], ["datetime.datetime.datetime.now().strftime", "utils.logger.add_log_to_file", "utils.logger.LOGGER.info", "trainer.Trainer.print_config", "time.time", "utils.logger.LOGGER.info", "trainer.Trainer.progress.add_task", "range", "trainer.Trainer.end_training", "torch.utils.tensorboard.SummaryWriter", "trainer.Trainer.progress.update", "trainer.Trainer.progress.add_task", "enumerate", "trainer.Trainer.progress.remove_task", "trainer.Trainer.epoch_end", "trainer.Trainer.progress.update", "trainer.Trainer.check_early_stopping", "datetime.datetime.datetime.now", "pathlib.Path", "str", "pathlib.Path", "datetime.datetime.datetime.now", "trainer.Trainer.model.train", "trainer.Trainer.progress.update", "trainer.batch_to_device", "trainer.Trainer.call_model", "trainer.Trainer.calculate_loss", "utils.logger.LOGGER.info", "len", "trainer.Trainer.metric_reporting", "trainer.Trainer.progress.update", "utils.logger.log_tensorboard", "len"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.logger.add_log_to_file", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.print_config", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.end_training", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.epoch_end", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.check_early_stopping", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.batch_to_device", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.call_model", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.calculate_loss", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.metric_reporting", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.logger.log_tensorboard"], ["", "def", "do_train", "(", "self", ")", ":", "\n", "\n", "        ", "formatted_date", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y%m%d_%H%M%S\"", ")", "\n", "self", ".", "checkpoint_file", "=", "f\"{formatted_date}/{self.config['model_save_name']}_{formatted_date}.pt\"", "\n", "if", "self", ".", "config", "[", "'with_tensorboard'", "]", ":", "\n", "            ", "tensor_path", "=", "Path", "(", "self", ".", "config", "[", "'tensorboard_path'", "]", ")", "/", "formatted_date", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "str", "(", "tensor_path", ")", ")", "\n", "\n", "", "add_log_to_file", "(", "Path", "(", "self", ".", "config", "[", "'model_path'", "]", ")", "/", "f\"{formatted_date}/training_{formatted_date}.log\"", ")", "\n", "\n", "LOGGER", ".", "info", "(", "\"\\n\\n\"", "+", "\"=\"", "*", "100", "+", "\"\\n\\t\\t\\t\\t\\t Training Network\\n\"", "+", "\"=\"", "*", "100", ")", "\n", "\n", "self", ".", "print_config", "(", ")", "\n", "\n", "self", ".", "start", "=", "time", ".", "time", "(", ")", "\n", "LOGGER", ".", "info", "(", "\"\\nBeginning training at:  {} \\n\"", ".", "format", "(", "datetime", ".", "now", "(", ")", ")", ")", "\n", "\n", "epoch_prog", "=", "self", ".", "progress", ".", "add_task", "(", "\"[green]Epoch...\"", ",", "total", "=", "self", ".", "config", "[", "'max_epoch'", "]", ")", "\n", "\n", "for", "self", ".", "epoch", "in", "range", "(", "self", ".", "start_epoch", ",", "self", ".", "config", "[", "'max_epoch'", "]", "+", "1", ")", ":", "\n", "            ", "self", ".", "progress", ".", "update", "(", "epoch_prog", ",", "advance", "=", "1", ")", "\n", "\n", "step_prog", "=", "self", ".", "progress", ".", "add_task", "(", "\"[yellow]Batch nr ...\"", ",", "total", "=", "len", "(", "self", ".", "config", "[", "'train_loader'", "]", ")", ")", "\n", "for", "self", ".", "iters", ",", "batch", "in", "enumerate", "(", "self", ".", "config", "[", "'train_loader'", "]", ")", ":", "\n", "\n", "                ", "if", "self", ".", "config", "[", "'debug'", "]", "and", "self", ".", "iters", ">", "10", ":", "\n", "                    ", "break", "\n", "\n", "", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "progress", ".", "update", "(", "step_prog", ",", "advance", "=", "1", ")", "\n", "\n", "batch_to_device", "(", "batch", ",", "self", ".", "device", ")", "\n", "\n", "preds", "=", "self", ".", "call_model", "(", "batch", ")", "\n", "\n", "self", ".", "calculate_loss", "(", "preds", ",", "batch", "[", "'labels'", "]", ",", "is_train", "=", "True", ")", "\n", "\n", "if", "self", ".", "iters", "%", "10", "==", "0", ":", "\n", "                    ", "metric", "=", "self", ".", "metric_reporting", "(", ")", "\n", "self", ".", "progress", ".", "update", "(", "step_prog", ",", "description", "=", "f\"[yellow]Batch nr {self.iters}... loss={metric.train_loss:.2f}, acc={metric.train_acc:.2f}, f1={metric.train_f1:.2f}\"", ")", "\n", "log_tensorboard", "(", "self", ".", "writer", ",", "metric", ",", "self", ".", "epoch", ",", "self", ".", "iters", ",", "len", "(", "self", ".", "config", "[", "'train_loader'", "]", ")", ",", "skip_validation", "=", "True", ")", "\n", "\n", "", "", "self", ".", "progress", ".", "remove_task", "(", "step_prog", ")", "\n", "\n", "self", ".", "epoch_end", "(", ")", "\n", "self", ".", "progress", ".", "update", "(", "epoch_prog", ",", "\n", "description", "=", "f\"[green]Epoch {self.epoch} ... loss={self.epoch_metric.train_loss:.2f}, \"", "\n", "f\"f1={self.epoch_metric.train_f1:.2f}, \"", "\n", "f\"val_loss={self.epoch_metric.valid_loss:.2f}, \"", "\n", "f\"val_f1={self.epoch_metric.valid_f1:.2f}\"", ")", "\n", "\n", "if", "self", ".", "check_early_stopping", "(", ")", ":", "\n", "                ", "LOGGER", ".", "info", "(", "f\"Early stopping on epoch {self.epoch}\"", ")", "\n", "break", "\n", "\n", "", "", "metric", "=", "self", ".", "end_training", "(", ")", "\n", "return", "self", ".", "best_epoch_info", ",", "metric", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.eval_model": [[579, 609], ["torch.no_grad", "trainer.Trainer.progress.add_task", "trainer.Trainer.model.eval", "enumerate", "trainer.Trainer.progress.remove_task", "hasattr", "trainer.batch_to_device", "trainer.Trainer.progress.update", "trainer.Trainer.call_model", "trainer.Trainer.logits_to_prediction", "trainer.Trainer.calculate_loss", "loss_list.append", "label_list.extend", "pred_list.extend", "prob_list.extend", "sum", "len", "len", "batch[].cpu().detach().tolist", "pred.cpu().detach().tolist", "probs.cpu().detach().tolist", "batch[].cpu().detach", "pred.cpu().detach", "probs.cpu().detach", "batch[].cpu", "pred.cpu", "probs.cpu"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.batch_to_device", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.call_model", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.logits_to_prediction", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.calculate_loss"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "eval_model", "(", "self", ",", "dataset", "=", "'validate_loader'", ",", "prob_margin", "=", "0.5", ")", ":", "\n", "        ", "label_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "prob_list", "=", "[", "]", "\n", "loss_list", "=", "[", "]", "\n", "\n", "epoch", "=", "self", ".", "epoch", "if", "hasattr", "(", "self", ",", "'epoch'", ")", "else", "'=None='", "\n", "eval_prog", "=", "self", ".", "progress", ".", "add_task", "(", "f\"[green]Evaluation Epoch {epoch}...\"", ",", "total", "=", "len", "(", "self", ".", "config", "[", "dataset", "]", ")", ")", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "self", ".", "config", "[", "dataset", "]", ")", ":", "\n", "            ", "batch_to_device", "(", "batch", ",", "self", ".", "device", ")", "\n", "self", ".", "progress", ".", "update", "(", "eval_prog", ",", "advance", "=", "1", ")", "\n", "\n", "if", "self", ".", "config", "[", "'debug'", "]", "and", "step", ">", "10", ":", "\n", "                ", "break", "\n", "\n", "", "logits", "=", "self", ".", "call_model", "(", "batch", ")", "\n", "\n", "pred", ",", "probs", "=", "self", ".", "logits_to_prediction", "(", "logits", ",", "self", ".", "config", "[", "'prob_margin'", "]", ")", "\n", "loss", "=", "self", ".", "calculate_loss", "(", "logits", ",", "batch", "[", "'labels'", "]", ",", "is_train", "=", "False", ")", "\n", "\n", "loss_list", ".", "append", "(", "loss", ")", "\n", "label_list", ".", "extend", "(", "batch", "[", "'labels'", "]", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", ")", "\n", "pred_list", ".", "extend", "(", "pred", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", ")", "\n", "prob_list", ".", "extend", "(", "probs", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "self", ".", "progress", ".", "remove_task", "(", "eval_prog", ")", "\n", "eval_loss", "=", "sum", "(", "loss_list", ")", "/", "len", "(", "loss_list", ")", "\n", "return", "label_list", ",", "pred_list", ",", "eval_loss", ",", "prob_list", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.predict_model": [[610, 630], ["torch.no_grad", "trainer.Trainer.progress.add_task", "trainer.Trainer.model.eval", "enumerate", "trainer.batch_to_device", "trainer.Trainer.progress.update", "trainer.Trainer.call_model", "trainer.Trainer.logits_to_prediction", "prob_list.extend", "pred_list.extend", "file_ids.extend", "len", "probs.cpu().detach().tolist", "pred.cpu().detach().tolist", "probs.cpu().detach", "pred.cpu().detach", "probs.cpu", "pred.cpu"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.batch_to_device", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.call_model", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.logits_to_prediction"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "predict_model", "(", "self", ",", "dataset", "=", "'test_loader'", ")", ":", "\n", "        ", "pred_list", "=", "[", "]", "\n", "prob_list", "=", "[", "]", "\n", "file_ids", "=", "[", "]", "\n", "\n", "predict_prog", "=", "self", ".", "progress", ".", "add_task", "(", "\"[green]Predicting ...\"", ",", "total", "=", "len", "(", "self", ".", "config", "[", "dataset", "]", ")", ")", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "self", ".", "config", "[", "dataset", "]", ")", ":", "\n", "            ", "batch_to_device", "(", "batch", ",", "self", ".", "device", ")", "\n", "self", ".", "progress", ".", "update", "(", "predict_prog", ",", "advance", "=", "1", ")", "\n", "\n", "logits", "=", "self", ".", "call_model", "(", "batch", ")", "\n", "\n", "pred", ",", "probs", "=", "self", ".", "logits_to_prediction", "(", "logits", ",", "self", ".", "config", "[", "'prob_margin'", "]", ")", "\n", "prob_list", ".", "extend", "(", "probs", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", ")", "\n", "pred_list", ".", "extend", "(", "pred", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "tolist", "(", ")", ")", "\n", "file_ids", ".", "extend", "(", "batch", "[", "'file_ids'", "]", ")", "\n", "\n", "", "return", "file_ids", ",", "pred_list", ",", "prob_list", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.set_seed": [[631, 640], ["torch.manual_seed", "torch.cuda.manual_seed", "numpy.random.seed", "random.seed"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "set_seed", "(", "seed", ")", ":", "\n", "# Seeds for reproduceable runs", "\n", "        ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.prepare_args": [[641, 756], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "prepare_args", "(", "parser", ")", ":", "\n", "# Named parameters", "\n", "        ", "parser", ".", "add_argument", "(", "'--task'", ",", "choices", "=", "[", "'train'", ",", "'eval'", ",", "'predict'", "]", ",", "default", "=", "'train'", ",", "\n", "help", "=", "'Task to perform'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "type", "=", "str", ",", "choices", "=", "[", "'uniter'", ",", "'uniter-sentiment'", ",", "'uniter-gnn'", ",", "'uniter-gnn2'", "]", ",", "default", "=", "'uniter'", ",", "\n", "help", "=", "'Moodel type'", ")", "\n", "# Required Paths", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "type", "=", "str", ",", "default", "=", "'./dataset'", ",", "required", "=", "True", ",", "\n", "help", "=", "'path to dataset folder that contains the processed data files'", ")", "\n", "parser", ".", "add_argument", "(", "'--nr_classes'", ",", "type", "=", "int", ",", "choices", "=", "[", "2", ",", "4", ",", "5", "]", ",", "default", "=", "2", ",", "\n", "help", "=", "'Number of classes for the classifier (2,4,5)'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--model_path'", ",", "type", "=", "str", ",", "default", "=", "'./model_checkpoints'", ",", "\n", "help", "=", "'Directory for saving trained model checkpoints'", ")", "\n", "parser", ".", "add_argument", "(", "'--tensorboard_path'", ",", "type", "=", "str", ",", "default", "=", "'./tensorboard'", ",", "\n", "help", "=", "'Directory for saving tensorboard checkpoints'", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_save_name\"", ",", "type", "=", "str", ",", "default", "=", "'best_model'", ",", "\n", "help", "=", "'saved model name'", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'This option is intended for tests on local machines, and more output.'", ")", "\n", "parser", ".", "add_argument", "(", "'--with_cleanup'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Enable text Cleanup'", ")", "\n", "parser", ".", "add_argument", "(", "'--lowercase'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Convert all in lowercase'", ")", "\n", "parser", ".", "add_argument", "(", "'--remove_non_ascii'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Remove all non ascii chars'", ")", "\n", "parser", ".", "add_argument", "(", "'--spellcheck'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'apply spellcheck'", ")", "\n", "parser", ".", "add_argument", "(", "'--with_tensorboard'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Enable Tensorboard logging'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--prob_margin'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "\n", "help", "=", "'Probability cutoff for classes'", ")", "\n", "\n", "# Load pretrained model", "\n", "parser", ".", "add_argument", "(", "'--pretrained_model_file'", ",", "type", "=", "str", ",", "help", "=", "'Filename for the pretrained model'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_file'", ",", "type", "=", "str", ",", "help", "=", "'Full path to File of with the previously saved model'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_model_checkpoints'", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'Do not save model'", ")", "\n", "parser", ".", "add_argument", "(", "\"--matrix_file\"", ",", "type", "=", "str", ",", "help", "=", "\"Sparse Array files (pickled)\"", ")", "\n", "\n", "# Required Paths", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "type", "=", "str", ",", "default", "=", "'./config/uniter-base.json'", ",", "\n", "help", "=", "'JSON config file'", ")", "\n", "parser", ".", "add_argument", "(", "'--feature_path'", ",", "type", "=", "str", ",", "default", "=", "'./dataset/img_feats'", ",", "\n", "help", "=", "'Path to image features'", ")", "\n", "parser", ".", "add_argument", "(", "'--sentiment_feature_path'", ",", "type", "=", "str", ",", "\n", "help", "=", "'Path to image sentiment features'", ")", "\n", "\n", "#### Pre-processing Params ####", "\n", "parser", ".", "add_argument", "(", "'--max_txt_len'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "'max number of tokens in text (BERT BPE)'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_object_conf'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "\n", "help", "=", "'Confidence threshold for dynamic bounding boxes (object detection)'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_bb'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'max number of bounding boxes'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_bb'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'min number of bounding boxes'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_bb'", ",", "type", "=", "int", ",", "default", "=", "36", ",", "\n", "help", "=", "'static number of bounding boxes'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_nms'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "'Select bounding boxes using Non-Maximum Suppression'", ")", "\n", "parser", ".", "add_argument", "(", "'--nms_threshold'", ",", "type", "=", "float", ",", "default", "=", "0.6", ",", "\n", "help", "=", "'Intersection-over-union threshold for NMS'", ")", "\n", "\n", "#### Training Params ####", "\n", "\n", "# Numerical params", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "\n", "help", "=", "'Standard dropout regularization'", ")", "\n", "parser", ".", "add_argument", "(", "\"--gcn_embedding_dim\"", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "\"GCN Embedding size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adj_npmi_threshold\"", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "\"Minimum NPMI in the Adjacency matrix\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adj_tf_threshold\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "\"Minimum Term Frequency (TF) in the Adjacency matrix\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adj_vocab_type\"", ",", "choices", "=", "[", "'all'", ",", "'pmi'", ",", "'tf'", "]", ",", "default", "=", "'all'", ",", "help", "=", "\"Build graph based on PMI, TF or both\"", ")", "\n", "\n", "# Named parameters", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "choices", "=", "[", "'adam'", ",", "'adamax'", ",", "'adamw'", "]", ",", "default", "=", "'adam'", ",", "\n", "help", "=", "'Optimizer to use for training: adam / adamax / adamw'", ")", "\n", "parser", ".", "add_argument", "(", "'--optimize_for'", ",", "choices", "=", "[", "'loss'", ",", "'acc'", ",", "'prec'", ",", "'recall'", ",", "'f1'", "]", ",", "default", "=", "'f1'", ",", "\n", "help", "=", "'Early stopping based on this metric'", ")", "\n", "\n", "## Not sure whether we should have this here. For a multi-task setup, we need our own loss functions", "\n", "parser", ".", "add_argument", "(", "'--loss_func'", ",", "type", "=", "str", ",", "default", "=", "'bce_logits'", ",", "\n", "help", "=", "'Loss function to use for optimization: bce / bce_logits / ce'", ")", "\n", "parser", ".", "add_argument", "(", "'--pos_wt'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "nargs", "=", "'+'", ",", "\n", "help", "=", "'Loss reweighting for the positive class to deal with class imbalance'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduler'", ",", "type", "=", "str", ",", "default", "=", "'warmup_cosine'", ",", "\n", "help", "=", "'The type of lr scheduler to use anneal learning rate: step/multi_step/warmup/warmp_cosine'", ")", "\n", "\n", "# Numerical parameters", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'batch size for training'", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'No. of update steps to accumulate before performing backward pass'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_grad_norm'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'max gradient norm for gradient clipping'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "1e-4", ",", "\n", "help", "=", "'Learning rate for training'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "'No. of steps to perform linear lr warmup for'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "1e-3", ",", "\n", "help", "=", "'weight decay for optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_epoch'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "\n", "help", "=", "'Max epochs to train for'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_step'", ",", "type", "=", "float", ",", "default", "=", "3", ",", "\n", "help", "=", "'No. of epochs after which learning rate should be decreased'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_factor'", ",", "type", "=", "float", ",", "default", "=", "0.8", ",", "\n", "help", "=", "'Decay the learning rate of the optimizer by this multiplicative amount'", ")", "\n", "parser", ".", "add_argument", "(", "'--patience'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "\n", "help", "=", "'Patience no. of epochs for early stopping'", ")", "\n", "parser", ".", "add_argument", "(", "'--early_stop_thresh'", ",", "type", "=", "float", ",", "default", "=", "1e-3", ",", "\n", "help", "=", "'Patience no. of epochs for early stopping'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "'set seed for reproducability'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.check_config": [[757, 785], ["pathlib.Path().exists", "utils.logger.LOGGER.info", "pathlib.Path().mkdir", "utils.logger.LOGGER.info", "config.get", "config.get", "config.get", "trainer.Trainer.set_seed", "pathlib.Path().exists", "pathlib.Path().exists", "pathlib.Path().mkdir", "config.get", "config.get", "pathlib.Path", "pathlib.Path", "config.get", "pathlib.Path().exists", "config.get", "pathlib.Path().exists", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.Trainer.set_seed"], ["", "@", "staticmethod", "\n", "def", "check_config", "(", "config", ")", ":", "\n", "# Check all provided paths:", "\n", "        ", "assert", "Path", "(", "config", "[", "'data_path'", "]", ")", ".", "exists", "(", ")", ",", "\"[!] ERROR: Dataset path does not exist\"", "\n", "LOGGER", ".", "info", "(", "\"Data path checked..\"", ")", "\n", "\n", "Path", "(", "config", "[", "'model_path'", "]", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "LOGGER", ".", "info", "(", "\"Creating checkpoint path for saved models at:  {}\\n\"", ".", "format", "(", "config", "[", "'model_path'", "]", ")", ")", "\n", "\n", "if", "config", ".", "get", "(", "'config'", ")", ":", "\n", "            ", "assert", "Path", "(", "config", "[", "'config'", "]", ")", ".", "exists", "(", ")", ",", "\"[!] ERROR: config JSON path does not exist\"", "\n", "\n", "", "if", "config", ".", "get", "(", "'model_file'", ")", ":", "\n", "            ", "assert", "Path", "(", "config", "[", "'model_file'", "]", ")", ".", "exists", "(", ")", ",", "f\"Model file {config['model_file']} must exist\"", "\n", "\n", "", "if", "config", ".", "get", "(", "'with_tensorboard'", ")", ":", "\n", "            ", "Path", "(", "config", "[", "'tensorboard_path'", "]", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "if", "config", ".", "get", "(", "'model_type'", ")", "==", "'uniter-sentiment'", ":", "\n", "            ", "assert", "config", ".", "get", "(", "'sentiment_feature_path'", ")", "and", "Path", "(", "config", "[", "'sentiment_feature_path'", "]", ")", ".", "exists", "(", ")", ",", "\"[!] ERROR: Sentiment Feature path does not exist\"", "\n", "\n", "", "if", "config", ".", "get", "(", "'model_type'", ")", "in", "[", "'uniter-gnn'", ",", "'uniter-gnn2'", "]", ":", "\n", "            ", "assert", "config", ".", "get", "(", "'matrix_file'", ")", "and", "Path", "(", "config", "[", "'matrix_file'", "]", ")", ".", "exists", "(", ")", ",", "\"[!] ERROR: Matrix File does not exist\"", "\n", "\n", "\n", "\n", "", "Trainer", ".", "set_seed", "(", "config", "[", "'seed'", "]", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.None.trainer.batch_to_device": [[53, 57], ["torch.is_tensor", "batches[].to"], "function", ["None"], ["", "", "def", "batch_to_device", "(", "batches", ",", "device", ")", ":", "\n", "    ", "for", "k", "in", "batches", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "batches", "[", "k", "]", ")", ":", "\n", "            ", "batches", "[", "k", "]", "=", "batches", "[", "k", "]", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.check_matrix": [[6, 22], ["numpy.zeros"], "function", ["None"], ["def", "check_matrix", "(", "matrix", ",", "gold", ",", "pred", ")", ":", "\n", "  ", "\"\"\"Check matrix dimension.\"\"\"", "\n", "if", "matrix", ".", "size", "==", "1", ":", "\n", "    ", "tmp", "=", "matrix", "[", "0", "]", "[", "0", "]", "\n", "matrix", "=", "np", ".", "zeros", "(", "(", "2", ",", "2", ")", ")", "\n", "if", "(", "pred", "[", "1", "]", "==", "0", ")", ":", "\n", "      ", "if", "gold", "[", "1", "]", "==", "0", ":", "#true negative", "\n", "        ", "matrix", "[", "0", "]", "[", "0", "]", "=", "tmp", "\n", "", "else", ":", "#falsi negativi", "\n", "        ", "matrix", "[", "1", "]", "[", "0", "]", "=", "tmp", "\n", "", "", "else", ":", "\n", "      ", "if", "gold", "[", "1", "]", "==", "0", ":", "#false positive", "\n", "        ", "matrix", "[", "0", "]", "[", "1", "]", "=", "tmp", "\n", "", "else", ":", "#true positive", "\n", "        ", "matrix", "[", "1", "]", "[", "1", "]", "=", "tmp", "\n", "", "", "", "return", "matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.compute_f1": [[24, 58], ["sklearn.metrics.confusion_matrix", "metrics.check_matrix"], "function", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.check_matrix"], ["", "def", "compute_f1", "(", "pred_values", ",", "gold_values", ")", ":", "\n", "  ", "matrix", "=", "metrics", ".", "confusion_matrix", "(", "gold_values", ",", "pred_values", ")", "\n", "matrix", "=", "check_matrix", "(", "matrix", ",", "gold_values", ",", "pred_values", ")", "\n", "\n", "#positive label", "\n", "if", "matrix", "[", "0", "]", "[", "0", "]", "==", "0", ":", "\n", "    ", "pos_precision", "=", "0.0", "\n", "pos_recall", "=", "0.0", "\n", "", "else", ":", "\n", "    ", "pos_precision", "=", "matrix", "[", "0", "]", "[", "0", "]", "/", "(", "matrix", "[", "0", "]", "[", "0", "]", "+", "matrix", "[", "0", "]", "[", "1", "]", ")", "\n", "pos_recall", "=", "matrix", "[", "0", "]", "[", "0", "]", "/", "(", "matrix", "[", "0", "]", "[", "0", "]", "+", "matrix", "[", "1", "]", "[", "0", "]", ")", "\n", "\n", "", "if", "(", "pos_precision", "+", "pos_recall", ")", "!=", "0", ":", "\n", "    ", "pos_F1", "=", "2", "*", "(", "pos_precision", "*", "pos_recall", ")", "/", "(", "pos_precision", "+", "pos_recall", ")", "\n", "", "else", ":", "\n", "    ", "pos_F1", "=", "0.0", "\n", "\n", "#negative label", "\n", "", "neg_matrix", "=", "[", "[", "matrix", "[", "1", "]", "[", "1", "]", ",", "matrix", "[", "1", "]", "[", "0", "]", "]", ",", "[", "matrix", "[", "0", "]", "[", "1", "]", ",", "matrix", "[", "0", "]", "[", "0", "]", "]", "]", "\n", "\n", "if", "neg_matrix", "[", "0", "]", "[", "0", "]", "==", "0", ":", "\n", "    ", "neg_precision", "=", "0.0", "\n", "neg_recall", "=", "0.0", "\n", "", "else", ":", "\n", "    ", "neg_precision", "=", "neg_matrix", "[", "0", "]", "[", "0", "]", "/", "(", "neg_matrix", "[", "0", "]", "[", "0", "]", "+", "neg_matrix", "[", "0", "]", "[", "1", "]", ")", "\n", "neg_recall", "=", "neg_matrix", "[", "0", "]", "[", "0", "]", "/", "(", "neg_matrix", "[", "0", "]", "[", "0", "]", "+", "neg_matrix", "[", "1", "]", "[", "0", "]", ")", "\n", "\n", "", "if", "(", "neg_precision", "+", "neg_recall", ")", "!=", "0", ":", "\n", "    ", "neg_F1", "=", "2", "*", "(", "neg_precision", "*", "neg_recall", ")", "/", "(", "neg_precision", "+", "neg_recall", ")", "\n", "", "else", ":", "\n", "    ", "neg_F1", "=", "0.0", "\n", "\n", "", "f1", "=", "(", "pos_F1", "+", "neg_F1", ")", "/", "2", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.extract_field": [[60, 67], ["truth.items", "gold.append", "guess.append"], "function", ["None"], ["", "def", "extract_field", "(", "truth", ",", "submission", ",", "index", ")", ":", "\n", "  ", "gold", "=", "[", "]", "\n", "guess", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "truth", ".", "items", "(", ")", ":", "\n", "    ", "gold", ".", "append", "(", "value", "[", "index", "]", ")", "\n", "guess", ".", "append", "(", "submission", "[", "key", "]", "[", "index", "]", ")", "\n", "", "return", "gold", ",", "guess", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.compute_scoreA": [[69, 73], ["metrics.extract_field", "metrics.compute_f1"], "function", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.extract_field", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.compute_f1"], ["", "def", "compute_scoreA", "(", "truth", ",", "submission", ")", ":", "\n", "  ", "gold", ",", "guess", "=", "extract_field", "(", "truth", ",", "submission", ",", "0", ")", "\n", "score", "=", "compute_f1", "(", "guess", ",", "gold", ")", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.compute_scoreB": [[75, 85], ["range", "metrics.extract_field", "metrics.compute_f1", "gold.count", "results.append", "sum"], "function", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.extract_field", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.compute_f1"], ["", "def", "compute_scoreB", "(", "truth", ",", "submission", ")", ":", "\n", "  ", "results", "=", "[", "]", "\n", "total_occurences", "=", "0", "\n", "for", "index", "in", "range", "(", "1", ",", "5", ")", ":", "\n", "    ", "gold", ",", "guess", "=", "extract_field", "(", "truth", ",", "submission", ",", "index", ")", "\n", "f1_score", "=", "compute_f1", "(", "guess", ",", "gold", ")", "\n", "weight", "=", "gold", ".", "count", "(", "True", ")", "\n", "total_occurences", "+=", "weight", "\n", "results", ".", "append", "(", "f1_score", "*", "weight", ")", "\n", "", "return", "sum", "(", "results", ")", "/", "total_occurences", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.from_eval": [[86, 95], ["pandas.read_csv", "dict", "dict", "list", "list", "metrics.compute_scoreA", "metrics.compute_scoreB", "pd.read_csv.apply", "pd.read_csv.apply"], "function", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.compute_scoreA", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.metrics.compute_scoreB"], ["", "def", "from_eval", "(", "filename", ")", ":", "\n", "  ", "truth", "=", "[", "]", "\n", "pred", "=", "[", "]", "\n", "df", "=", "pd", ".", "read_csv", "(", "filename", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "truth", "=", "dict", "(", "list", "(", "df", ".", "apply", "(", "lambda", "x", ":", "(", "x", ".", "file_name", ",", "[", "x", ".", "misogynous", ",", "x", ".", "shaming", ",", "x", ".", "stereotype", ",", "x", ".", "objectification", ",", "x", ".", "violence", "]", ")", ",", "axis", "=", "1", ")", ")", ")", "\n", "pred", "=", "dict", "(", "list", "(", "df", ".", "apply", "(", "lambda", "x", ":", "(", "x", ".", "file_name", ",", "[", "x", ".", "pred_misogynous", ",", "x", ".", "pred_shaming", ",", "x", ".", "pred_stereotype", ",", "x", ".", "pred_objectification", ",", "x", ".", "pred_violence", "]", ")", ",", "axis", "=", "1", ")", ")", ")", "\n", "\n", "return", "compute_scoreA", "(", "truth", ",", "pred", ")", ",", "compute_scoreB", "(", "truth", ",", "pred", ")", "", "", ""]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.logger.add_log_to_file": [[18, 24], ["pathlib.Path().parent.mkdir", "logging.FileHandler", "logging.Formatter", "logging.FileHandler.setFormatter", "LOGGER.addHandler", "pathlib.Path"], "function", ["None"], ["def", "add_log_to_file", "(", "log_path", ")", ":", "\n", "    ", "Path", "(", "log_path", ")", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "log_path", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "_LOG_FMT", ",", "datefmt", "=", "_DATE_FMT", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "LOGGER", ".", "addHandler", "(", "fh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.logger.log_tensorboard": [[26, 53], ["writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "isinstance", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar"], "function", ["None"], ["", "def", "log_tensorboard", "(", "writer", ",", "metric", ",", "epoch", ",", "step", ",", "total_steps", ",", "skip_validation", "=", "False", ")", ":", "\n", "# train_loss: float", "\n", "# train_acc: float", "\n", "# train_prec: float", "\n", "# train_recall: float", "\n", "# train_f1: float", "\n", "# valid_loss: float", "\n", "# valid_acc: float", "\n", "# valid_prec: float", "\n", "# valid_recall: float", "\n", "# valid_f1: float", "\n", "    ", "if", "not", "isinstance", "(", "writer", ",", "SummaryWriter", ")", ":", "\n", "        ", "return", "\n", "\n", "\n", "", "writer", ".", "add_scalar", "(", "'Train/Epoch_Loss'", ",", "metric", ".", "train_loss", ",", "step", ",", "(", "epoch", "-", "1", ")", "*", "total_steps", "+", "step", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/F1'", ",", "metric", "[", "'train_f1'", "]", ",", "step", ",", "(", "epoch", "-", "1", ")", "*", "total_steps", "+", "step", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/Precision'", ",", "metric", "[", "'train_prec'", "]", ",", "step", ",", "(", "epoch", "-", "1", ")", "*", "total_steps", "+", "step", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/Recall'", ",", "metric", "[", "'train_recall'", "]", ",", "step", ",", "(", "epoch", "-", "1", ")", "*", "total_steps", "+", "step", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/Accuracy'", ",", "metric", "[", "'train_acc'", "]", ",", "step", ",", "(", "epoch", "-", "1", ")", "*", "total_steps", "+", "step", ")", "\n", "\n", "if", "not", "skip_validation", ":", "\n", "        ", "writer", ".", "add_scalar", "(", "'Validation/Loss'", ",", "metric", ".", "valid_loss", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Validation/F1'", ",", "metric", "[", "'valid_f1'", "]", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Validation/Recall'", ",", "metric", "[", "'valid_recall'", "]", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Validation/Precision'", ",", "metric", "[", "'valid_prec'", "]", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Validation/Accuracy'", ",", "metric", "[", "'valid_acc'", "]", ",", "epoch", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.gcn.clean_text": [[36, 45], ["re.sub", "str", "stopwords_pattern.sub", "re.sub"], "function", ["None"], ["", "def", "clean_text", "(", "text", ",", "remove_stop_words", "=", "False", ",", "remove_numeric", "=", "False", ")", ":", "\n", "# delete [ \\t\\n\\r\\f\\v]", "\n", "    ", "space_pattern", "=", "r'[\\s+\\xa0]'", "\n", "text", "=", "re", ".", "sub", "(", "space_pattern", ",", "' '", ",", "str", "(", "text", ")", ")", "\n", "if", "remove_stop_words", ":", "\n", "        ", "text", "=", "stopwords_pattern", ".", "sub", "(", "''", ",", "text", ")", "\n", "", "if", "remove_numeric", ":", "\n", "        ", "text", "=", "re", ".", "sub", "(", "\"\\w*\\d\\w*\"", ",", "\" \"", ",", "text", ")", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.gcn.normalize_adj": [[46, 57], ["numpy.array", "numpy.power().flatten", "scipy.diags", "adj.dot().transpose().dot", "adj.sum", "numpy.power", "numpy.isinf", "adj.dot().transpose", "adj.dot"], "function", ["None"], ["", "def", "normalize_adj", "(", "adj", ")", ":", "\n", "    ", "\"\"\"\n        Symmetrically normalize adjacency matrix.\n\n    \"\"\"", "\n", "\n", "D_matrix", "=", "np", ".", "array", "(", "adj", ".", "sum", "(", "axis", "=", "1", ")", ")", "# D-degree matrix as array (Diagonal, rest is 0.)", "\n", "D_inv_sqrt", "=", "np", ".", "power", "(", "D_matrix", ",", "-", "0.5", ")", ".", "flatten", "(", ")", "\n", "D_inv_sqrt", "[", "np", ".", "isinf", "(", "D_inv_sqrt", ")", "]", "=", "0.", "\n", "d_mat_inv_sqrt", "=", "sp", ".", "diags", "(", "D_inv_sqrt", ")", "# array to matrix", "\n", "return", "adj", ".", "dot", "(", "d_mat_inv_sqrt", ")", ".", "transpose", "(", ")", ".", "dot", "(", "d_mat_inv_sqrt", ")", "# D^(-1/2) . A . D^(-1/2)", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.gcn.sparse_scipy2torch": [[60, 65], ["torch.LongTensor", "torch.from_numpy", "torch.sparse.FloatTensor", "numpy.vstack", "torch.Size"], "function", ["None"], ["", "def", "sparse_scipy2torch", "(", "coo_sparse", ")", ":", "\n", "# coo_sparse=coo_sparse.tocoo()", "\n", "    ", "i", "=", "torch", ".", "LongTensor", "(", "np", ".", "vstack", "(", "(", "coo_sparse", ".", "row", ",", "coo_sparse", ".", "col", ")", ")", ")", "\n", "v", "=", "torch", ".", "from_numpy", "(", "coo_sparse", ".", "data", ")", "\n", "return", "torch", ".", "sparse", ".", "FloatTensor", "(", "i", ",", "v", ",", "torch", ".", "Size", "(", "coo_sparse", ".", "shape", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.gcn.get_torch_gcn": [[67, 91], ["gcn_vocab_adj_tf.eliminate_zeros", "gcn_vocab_adj.eliminate_zeros", "range", "len", "gcn.normalize_adj", "norm_gcn_vocab_adj_list.append", "gcn.sparse_scipy2torch", "normalize_adj.tocoo"], "function", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.gcn.normalize_adj", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.utils.gcn.sparse_scipy2torch"], ["", "def", "get_torch_gcn", "(", "gcn_vocab_adj_tf", ",", "gcn_vocab_adj", ",", "gcn_config", ":", "GCNConfig", ")", ":", "\n", "\n", "    ", "gcn_vocab_adj_tf", ".", "data", "*=", "(", "gcn_vocab_adj_tf", ".", "data", ">", "gcn_config", ".", "tf_threshold", ")", "\n", "gcn_vocab_adj_tf", ".", "eliminate_zeros", "(", ")", "\n", "\n", "gcn_vocab_adj", ".", "data", "*=", "(", "gcn_vocab_adj", ".", "data", ">", "gcn_config", ".", "npmi_threshold", ")", "\n", "gcn_vocab_adj", ".", "eliminate_zeros", "(", ")", "\n", "\n", "if", "gcn_config", ".", "vocab_adj", "==", "'pmi'", ":", "\n", "        ", "gcn_vocab_adj_list", "=", "[", "gcn_vocab_adj", "]", "\n", "", "elif", "gcn_config", ".", "vocab_adj", "==", "'tf'", ":", "\n", "        ", "gcn_vocab_adj_list", "=", "[", "gcn_vocab_adj_tf", "]", "\n", "", "elif", "gcn_config", ".", "vocab_adj", "==", "'all'", ":", "\n", "        ", "gcn_vocab_adj_list", "=", "[", "gcn_vocab_adj_tf", ",", "gcn_vocab_adj", "]", "\n", "\n", "", "norm_gcn_vocab_adj_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "gcn_vocab_adj_list", ")", ")", ":", "\n", "        ", "adj", "=", "gcn_vocab_adj_list", "[", "i", "]", "\n", "adj", "=", "normalize_adj", "(", "adj", ")", "\n", "norm_gcn_vocab_adj_list", ".", "append", "(", "sparse_scipy2torch", "(", "adj", ".", "tocoo", "(", ")", ")", ")", "\n", "\n", "", "del", "gcn_vocab_adj_list", "\n", "\n", "return", "norm_gcn_vocab_adj_list", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.visual_sentiment.save_embeddings.ImageListDataset.__init__": [[20, 26], ["torch.utils.data.Dataset.__init__", "list", "pathlib.Path().glob", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], ["    ", "def", "__init__", "(", "self", ",", "image_folder", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "ImageListDataset", ")", ".", "__init__", "(", ")", "\n", "\n", "\n", "self", ".", "list", "=", "list", "(", "Path", "(", "image_folder", ")", ".", "glob", "(", "'*'", ")", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.visual_sentiment.save_embeddings.ImageListDataset.__getitem__": [[27, 35], ["torchvision.datasets.folder.default_loader", "save_embeddings.ImageListDataset.transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "path", "=", "self", ".", "list", "[", "index", "]", "\n", "\n", "x", "=", "default_loader", "(", "path", ")", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "x", "=", "self", ".", "transform", "(", "x", ")", "\n", "\n", "", "return", "x", ",", "path", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.visual_sentiment.save_embeddings.ImageListDataset.__len__": [[36, 38], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.visual_sentiment.save_embeddings.main": [[40, 94], ["pathlib.Path().exists", "pathlib.Path", "pathlib.Path.mkdir", "torchvision.Compose", "save_embeddings.ImageListDataset", "torch.utils.data.DataLoader", "model().to.to", "model().to.fc7_1.register_forward_hook", "model().to.eval", "save_embeddings.main.get_activation"], "function", ["None"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "assert", "Path", "(", "args", ".", "model_file", ")", ".", "exists", "(", ")", ",", "f\"Model file {args.model_file} does not exist\"", "\n", "out_dir", "=", "Path", "(", "args", ".", "output_folder", ")", "\n", "out_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "activation", "=", "{", "}", "\n", "def", "get_activation", "(", "name", ")", ":", "\n", "        ", "def", "hook", "(", "model", ",", "input", ",", "output", ")", ":", "\n", "            ", "activation", "[", "name", "]", "=", "output", ".", "detach", "(", ")", "\n", "", "return", "hook", "\n", "\n", "", "transform", "=", "t", ".", "Compose", "(", "[", "\n", "t", ".", "Resize", "(", "(", "224", ",", "224", ")", ")", ",", "\n", "t", ".", "ToTensor", "(", ")", ",", "\n", "t", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "[", "2", ",", "1", ",", "0", "]", ",", "...", "]", "*", "255", ")", ",", "# RGB -> BGR and [0,1] -> [0,255]", "\n", "t", ".", "Normalize", "(", "mean", "=", "[", "116.8007", ",", "121.2751", ",", "130.4602", "]", ",", "std", "=", "[", "1", ",", "1", ",", "1", "]", ")", ",", "# mean subtraction", "\n", "]", ")", "\n", "\n", "data", "=", "ImageListDataset", "(", "args", ".", "image_folder", ",", "transform", "=", "transform", ")", "\n", "dataloader", "=", "DataLoader", "(", "data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ",", "pin_memory", "=", "True", ")", "\n", "\n", "model", "=", "AlexNet", "if", "'hybrid'", "in", "args", ".", "model_file", "else", "VGG19", "\n", "model", "=", "model", "(", "args", ".", "model_file", ")", ".", "to", "(", "'cuda'", ")", "\n", "# if getattr(model, 'conv5_4'):", "\n", "#     model.conv5_4.register_forward_hook(get_activation('conv5_4'))", "\n", "# else:", "\n", "#     model.conv5.register_forward_hook(get_activation('conv5'))", "\n", "\n", "model", ".", "fc7_1", ".", "register_forward_hook", "(", "get_activation", "(", "'fc7_1'", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "x", ",", "filenames", "in", "tqdm", "(", "dataloader", ")", ":", "\n", "            ", "activation", "=", "{", "}", "\n", "p", "=", "model", "(", "x", ".", "to", "(", "'cuda'", ")", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# order is (NEG, NEU, POS)", "\n", "# features = activation['conv5_4']", "\n", "\n", "# if getattr(model, 'conv5_4'):", "\n", "#     relu5_4         = F.relu(features)", "\n", "#     pool5_pad       = F.pad(relu5_4, (0, 1, 0, 1), value=float('-inf'))", "\n", "#     pool5           = F.max_pool2d(pool5_pad, kernel_size=(2, 2), stride=(2, 2), padding=0, ceil_mode=False)", "\n", "# else:", "\n", "#     relu5           = F.relu(features)", "\n", "#     pool5_pad       = F.pad(relu5, (0, 1, 0, 1), value=float('-inf'))", "\n", "#     pool5           = F.max_pool2d(pool5_pad, kernel_size=(3, 3), stride=(2, 2), padding=0, ceil_mode=False)", "\n", "\n", "features", "=", "activation", "[", "'fc7_1'", "]", "\n", "\n", "features", "=", "F", ".", "relu", "(", "features", ")", "\n", "\n", "\n", "for", "idx", ",", "file", "in", "enumerate", "(", "filenames", ")", ":", "\n", "                ", "np", ".", "save", "(", "open", "(", "out_dir", "/", "Path", "(", "file", ")", ".", "with_suffix", "(", "'.npy'", ")", ",", "\"wb\"", ")", ",", "features", "[", "idx", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.SemevalDataset.__init__": [[58, 97], ["pathlib.Path", "pathlib.Path", "pandas.read_csv", "dataloader.SemevalDataset.df.sample", "jamspell.TSpellCorrector", "jamspell.TSpellCorrector.LoadLangModel", "dataloader.SemevalDataset.df[].apply", "sutime.SUTime"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "csv_file", ",", "image_folder", ",", "features_folder", ",", "tokenizer", ",", "max_length", ",", "*", ",", "shuffle", "=", "True", ",", "nr_classes", "=", "2", ",", "\n", "obj_vocab", "=", "None", ",", "use_nms", "=", "False", ",", "nms_threshold", "=", "0.7", ",", "min_obj_confidence", "=", "0.0", ",", "ignore_objects", "=", "None", ",", "text_cleanup", "=", "False", ",", "\n", "sentiment_path", "=", "None", ",", "use_gcn", "=", "False", ",", "gcn_embedding_dim", "=", "0", ",", "lowercase", "=", "False", ",", "remove_non_ascii", "=", "True", ",", "\n", "spellcheck", "=", "False", ")", ":", "\n", "        ", "self", ".", "csv_file", "=", "csv_file", "\n", "self", ".", "image_folder", "=", "Path", "(", "image_folder", ")", "\n", "self", ".", "features_folder", "=", "Path", "(", "features_folder", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "obj_vocab", "=", "obj_vocab", "\n", "self", ".", "min_obj_confidence", "=", "min_obj_confidence", "\n", "self", ".", "ignore_objects", "=", "ignore_objects", "\n", "self", ".", "use_nms", "=", "use_nms", "\n", "self", ".", "use_gcn", "=", "use_gcn", "\n", "self", ".", "nms_threshold", "=", "nms_threshold", "\n", "self", ".", "nr_classes", "=", "nr_classes", "\n", "\n", "self", ".", "df", "=", "pd", ".", "read_csv", "(", "self", ".", "csv_file", ",", "sep", "=", "\"\\t\"", ")", "\n", "\n", "# if self.nr_classes==4:", "\n", "#     # Classifying only positive records", "\n", "#     self.df = self.df[self.df['misogynous']==1]", "\n", "\n", "if", "shuffle", ":", "\n", "            ", "self", ".", "df", "=", "self", ".", "df", ".", "sample", "(", "frac", "=", "1.0", ")", "\n", "\n", "", "if", "spellcheck", ":", "\n", "            ", "import", "jamspell", "\n", "corrector", "=", "jamspell", ".", "TSpellCorrector", "(", ")", "\n", "corrector", ".", "LoadLangModel", "(", "'en.bin'", ")", "\n", "self", ".", "df", "[", "'Text Transcription'", "]", "=", "self", ".", "df", "[", "'Text Transcription'", "]", ".", "apply", "(", "corrector", ".", "FixFragment", ")", "\n", "\n", "", "self", ".", "text_cleanup", "=", "text_cleanup", "\n", "if", "self", ".", "text_cleanup", ":", "\n", "            ", "self", ".", "sutime", "=", "SUTime", "(", "mark_time_ranges", "=", "True", ",", "include_range", "=", "True", ")", "\n", "", "self", ".", "sentiment_path", "=", "sentiment_path", "\n", "self", ".", "gcn_embedding_dim", "=", "gcn_embedding_dim", "\n", "self", ".", "lowercase", "=", "lowercase", "\n", "self", ".", "remove_non_ascii", "=", "remove_non_ascii", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.SemevalDataset.__len__": [[99, 101], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.SemevalDataset.cleanup_text": [[102, 132], ["dataloader.SemevalDataset.cleanup_text.remove_timestamps"], "methods", ["None"], ["", "def", "cleanup_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "def", "remove_strings", "(", "text", ")", ":", "\n", "            ", "garbage_strings", "=", "[", "\"Twitter for iPhone\"", ",", "\"VERY DEMOTIVATIONAL.com\"", ",", "\"made with mematic\"", ",", "\"Meme Center\"", ",", "\"MemeCenter\"", "]", "\n", "\n", "text", "=", "re", ".", "sub", "(", "\"@(\\w){1,15}\"", ",", "\"\"", ",", "text", ")", "# Twitter Usernames", "\n", "\n", "rep", "=", "[", "re", ".", "escape", "(", "x", ")", "for", "x", "in", "garbage_strings", "]", "\n", "\n", "text", "=", "re", ".", "sub", "(", "\"([A-Za-z0-9]\\.|[A-Za-z0-9][A-Za-z0-9-]{0,61}[A-Za-z0-9]\\.){1,3}(com|net|org|co\\.uk|co|ru|eu)\"", ",", "\"\"", ",", "text", ",", "flags", "=", "re", ".", "IGNORECASE", ")", "\n", "\n", "pattern", "=", "re", ".", "compile", "(", "\"|\"", ".", "join", "(", "rep", ")", ",", "flags", "=", "re", ".", "IGNORECASE", ")", "\n", "text", "=", "pattern", ".", "sub", "(", "\"\"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "\"\\s\\s+\"", ",", "\" \"", ",", "text", ")", "# Multiple spaces", "\n", "return", "text", "\n", "\n", "\n", "", "def", "remove_timestamps", "(", "sutime", ",", "text", ")", ":", "\n", "            ", "date_seq", "=", "sutime", ".", "parse", "(", "text", ")", "\n", "res", "=", "text", "\n", "for", "seq", "in", "date_seq", ":", "\n", "                ", "if", "seq", "[", "'type'", "]", "in", "[", "'DATE'", ",", "'TIME'", ",", "'DURATION'", "]", ":", "\n", "                    ", "res", "=", "text", "[", ":", "seq", "[", "'start'", "]", "]", "+", "\" \"", "*", "(", "seq", "[", "'end'", "]", "-", "seq", "[", "'start'", "]", ")", "+", "text", "[", "seq", "[", "'end'", "]", ":", "]", "\n", "", "", "if", "len", "(", "date_seq", ")", ":", "\n", "                ", "res", "=", "\" \"", ".", "join", "(", "res", ".", "split", "(", ")", ")", "\n", "", "return", "res", "\n", "\n", "", "text", "=", "remove_timestamps", "(", "self", ".", "sutime", ",", "text", ")", "\n", "# text = remove_strings(text)", "\n", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.SemevalDataset.__getitem__": [[133, 198], ["record.file_name.lower().replace", "dataloader.SemevalDataset.tokenizer.encode().squeeze", "dataloader.SemevalDataset._load_img_feature", "torch.ones", "dict", "dataloader.SemevalDataset.lower", "dataloader.SemevalDataset.encode().decode", "dataloader.SemevalDataset.cleanup_text", "gcn_ids.extend", "numpy.load", "torch.Tensor", "dict.update", "dict.update", "record.file_name.lower", "dataloader.SemevalDataset.tokenizer.encode", "torch.tensor", "torch.nn.functional.one_hot", "len", "pathlib.Path", "str", "dataloader.SemevalDataset.encode", "torch.tensor", "torch.tensor", "dataloader.SemevalDataset.tolist", "int"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.SemevalDataset._load_img_feature", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.SemevalDataset.cleanup_text", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "record", "=", "self", ".", "df", ".", "iloc", "[", "item", "]", "\n", "data_id", "=", "record", ".", "file_name", ".", "lower", "(", ")", ".", "replace", "(", "'.jpg'", ",", "''", ")", "\n", "\n", "text", "=", "record", "[", "'Text Transcription'", "]", "\n", "if", "self", ".", "lowercase", ":", "\n", "            ", "text", "=", "text", ".", "lower", "(", ")", "\n", "", "if", "self", ".", "remove_non_ascii", ":", "\n", "            ", "text", "=", "(", "text", ".", "encode", "(", "\"ascii\"", ",", "\"ignore\"", ")", ")", ".", "decode", "(", ")", "\n", "\n", "", "if", "self", ".", "text_cleanup", ":", "\n", "            ", "text", "=", "self", ".", "cleanup_text", "(", "text", ")", "\n", "\n", "", "tokens", "=", "self", ".", "tokenizer", ".", "encode", "(", "text", ",", "max_length", "=", "self", ".", "max_length", ",", "truncation", "=", "True", ",", "padding", "=", "'do_not_pad'", ",", "return_tensors", "=", "'pt'", ")", ".", "squeeze", "(", ")", "\n", "\n", "features", ",", "pos_features", ",", "objects", ",", "_", "=", "self", ".", "_load_img_feature", "(", "data_id", ")", "\n", "nr_bboxes", "=", "features", ".", "shape", "[", "0", "]", "\n", "if", "'misogynous'", "in", "record", ":", "\n", "# Training or Validation", "\n", "            ", "if", "self", ".", "nr_classes", "==", "2", ":", "\n", "                ", "label", "=", "torch", ".", "tensor", "(", "record", ".", "misogynous", ")", "\n", "label", "=", "torch", ".", "nn", ".", "functional", ".", "one_hot", "(", "label", ",", "num_classes", "=", "2", ")", "\n", "", "elif", "self", ".", "nr_classes", "==", "4", ":", "\n", "                ", "label", "=", "torch", ".", "tensor", "(", "[", "\n", "record", ".", "shaming", ",", "\n", "record", ".", "stereotype", ",", "\n", "record", ".", "objectification", ",", "\n", "record", ".", "violence", "]", ")", "\n", "", "else", ":", "\n", "                ", "label", "=", "torch", ".", "tensor", "(", "[", "\n", "1", "-", "record", ".", "misogynous", ",", "\n", "record", ".", "shaming", ",", "\n", "record", ".", "stereotype", ",", "\n", "record", ".", "objectification", ",", "\n", "record", ".", "violence", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "label", "=", "None", "\n", "\n", "", "if", "self", ".", "use_gcn", ":", "\n", "            ", "gcn_ids", "=", "[", "-", "1", "]", "+", "tokens", ".", "tolist", "(", ")", "[", "1", ":", "-", "1", "]", "+", "[", "-", "1", "]", "\n", "gcn_ids", ".", "extend", "(", "[", "int", "(", "x", ")", "+", "self", ".", "tokenizer", ".", "vocab_size", "for", "x", "in", "objects", "]", ")", "\n", "# gcn_ids = gcn_ids[:self.gcn_embedding_dim]", "\n", "\n", "", "attn_mask", "=", "torch", ".", "ones", "(", "len", "(", "tokens", ")", "+", "nr_bboxes", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "\n", "res", "=", "dict", "(", "\n", "id", "=", "data_id", ",", "\n", "tokens", "=", "tokens", ",", "\n", "image_features", "=", "features", ",", "\n", "image_pos_features", "=", "pos_features", ",", "\n", "attn_mask", "=", "attn_mask", ",", "\n", "text", "=", "text", ",", "\n", "label", "=", "label", ",", "\n", ")", "\n", "if", "self", ".", "sentiment_path", ":", "\n", "            ", "feature_file_name", "=", "Path", "(", "self", ".", "sentiment_path", ")", "/", "f\"{data_id}.npy\"", "\n", "sent_feature", "=", "np", ".", "load", "(", "str", "(", "feature_file_name", ")", ")", "\n", "sent_feature", "=", "torch", ".", "Tensor", "(", "sent_feature", ")", "\n", "\n", "res", ".", "update", "(", "{", "'sent_features'", ":", "sent_feature", "}", ")", "\n", "", "if", "self", ".", "use_gcn", ":", "\n", "            ", "res", ".", "update", "(", "{", "'gcn_tokens'", ":", "gcn_ids", "}", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.SemevalDataset._load_img_feature": [[199, 258], ["numpy.load", "data[].item", "numpy.column_stack", "torch.tensor", "torch.tensor", "str", "len", "enumerate", "numpy.concatenate", "numpy.array", "torch.column_stack", "torch.tensor", "torchvision.ops.nms", "numpy.take", "list", "obj_map[].append", "obj_map.values"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load"], ["", "def", "_load_img_feature", "(", "self", ",", "image_id", ",", "normalize", "=", "False", ")", ":", "\n", "        ", "feature_file_name", "=", "self", ".", "features_folder", "/", "f\"{image_id}.npz\"", "\n", "data", "=", "np", ".", "load", "(", "str", "(", "feature_file_name", ")", ",", "allow_pickle", "=", "True", ")", "\n", "data_info", "=", "data", "[", "'info'", "]", ".", "item", "(", ")", "\n", "\n", "img_width", "=", "data_info", "[", "'image_w'", "]", "\n", "img_height", "=", "data_info", "[", "'image_h'", "]", "\n", "\n", "w", ",", "h", "=", "data", "[", "'bbox'", "]", "[", ":", ",", "2", "]", "-", "data", "[", "'bbox'", "]", "[", ":", ",", "0", "]", ",", "data", "[", "'bbox'", "]", "[", ":", ",", "3", "]", "-", "data", "[", "'bbox'", "]", "[", ":", ",", "1", "]", "\n", "\n", "objects", "=", "data_info", "[", "'objects_id'", "]", "\n", "objects_conf", "=", "data_info", "[", "'objects_conf'", "]", "\n", "\n", "if", "normalize", ":", "\n", "            ", "data", "[", "'bbox'", "]", "=", "data", "[", "'bbox'", "]", "/", "np", ".", "array", "(", "[", "img_width", ",", "img_height", ",", "img_width", ",", "img_height", "]", ")", "\n", "", "img_pos_feat", "=", "np", ".", "column_stack", "(", "(", "data", "[", "'bbox'", "]", ",", "w", ",", "h", ",", "w", "*", "h", ")", ")", "\n", "img_pos_feat", "=", "torch", ".", "tensor", "(", "img_pos_feat", ")", "\n", "img_feat", "=", "torch", ".", "tensor", "(", "data", "[", "'x'", "]", ")", "\n", "\n", "valid_boxes", "=", "(", "objects_conf", ">", "self", ".", "min_obj_confidence", ")", "\n", "\n", "img_feat", "=", "img_feat", "[", "valid_boxes", "]", "\n", "img_pos_feat", "=", "img_pos_feat", "[", "valid_boxes", "]", "\n", "objects", "=", "objects", "[", "valid_boxes", "]", "\n", "objects_conf", "=", "objects_conf", "[", "valid_boxes", "]", "\n", "\n", "if", "self", ".", "use_nms", "and", "len", "(", "objects", ")", ":", "\n", "            ", "obj_map", "=", "{", "}", "\n", "\n", "for", "i", ",", "obj_id", "in", "enumerate", "(", "objects", ")", ":", "\n", "                ", "if", "obj_id", "in", "obj_map", ":", "\n", "                    ", "obj_map", "[", "obj_id", "]", ".", "append", "(", "i", ")", "\n", "", "else", ":", "\n", "                    ", "obj_map", "[", "obj_id", "]", "=", "[", "i", "]", "\n", "\n", "", "", "for", "obj_id", "in", "obj_map", ":", "\n", "                ", "boxes", "=", "img_pos_feat", "[", "obj_map", "[", "obj_id", "]", "]", "\n", "boxes", "=", "torch", ".", "column_stack", "(", "\n", "[", "\n", "boxes", "[", ":", ",", "0", "]", ",", "\n", "boxes", "[", ":", ",", "1", "]", ",", "\n", "boxes", "[", ":", ",", "0", "]", "+", "boxes", "[", ":", ",", "2", "]", ",", "\n", "boxes", "[", ":", ",", "1", "]", "+", "boxes", "[", ":", ",", "3", "]", "\n", "]", ")", "\n", "\n", "confidences", "=", "torch", ".", "tensor", "(", "objects_conf", "[", "obj_map", "[", "obj_id", "]", "]", ")", "\n", "\n", "keep", "=", "torchvision", ".", "ops", ".", "nms", "(", "boxes", ",", "confidences", ",", "self", ".", "nms_threshold", ")", "\n", "obj_map", "[", "obj_id", "]", "=", "np", ".", "take", "(", "obj_map", "[", "obj_id", "]", ",", "keep", ")", "\n", "\n", "", "indices", "=", "np", ".", "concatenate", "(", "list", "(", "obj_map", ".", "values", "(", ")", ")", ")", "\n", "img_feat", "=", "img_feat", "[", "indices", "]", "\n", "img_pos_feat", "=", "img_pos_feat", "[", "indices", "]", "\n", "objects", "=", "objects", "[", "indices", "]", "\n", "objects_conf", "=", "objects_conf", "[", "indices", "]", "\n", "\n", "\n", "\n", "", "return", "img_feat", ",", "img_pos_feat", ",", "objects", ",", "objects_conf", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.SemevalDataset.show_image": [[259, 306], ["matplotlib.pyplot.subplots", "ax.axis", "ax.imshow", "record.file_name.lower().replace", "dataloader.SemevalDataset._load_img_feature", "enumerate", "matplotlib.pyplot.title", "open", "PIL.Image.open().convert", "record.file_name.lower", "open", "ax.add_patch", "ax.text", "PIL.Image.open", "[].strip", "matplotlib.patches.Rectangle", "ax.text", "enumerate", "f.readlines", "name.split"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.SemevalDataset._load_img_feature"], ["", "def", "show_image", "(", "self", ",", "idx", "=", "None", ",", "data_id", "=", "None", ",", "img", "=", "None", ",", "with_features", "=", "False", ",", "min_confidence", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"\n        Displays an image of the dataset. At least one of the following input arguments needs to be given:\n            idx - Index of the image in the dataset\n            data_id - ID of the data point with the image (stated in the original .jsonl file)\n            img - PIL image to display\n        \"\"\"", "\n", "assert", "idx", "is", "not", "None", "or", "data_id", "or", "img", ",", "\"Must specify at least one image identifier\"", "\n", "\n", "label", "=", "None", "\n", "rects", "=", "[", "]", "\n", "\n", "if", "idx", "is", "not", "None", ":", "# idx==0 is legit", "\n", "            ", "record", "=", "self", ".", "df", ".", "iloc", "[", "idx", "]", "\n", "data_id", "=", "record", ".", "file_name", ".", "lower", "(", ")", ".", "replace", "(", "'.jpg'", ",", "''", ")", "\n", "label", "=", "record", ".", "misogynous", "\n", "\n", "", "if", "data_id", ":", "\n", "            ", "with", "open", "(", "self", ".", "image_folder", "/", "f\"{data_id}.jpg\"", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "img", "=", "Image", ".", "open", "(", "f", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "", "label", "=", "self", ".", "df", "[", "self", ".", "df", "[", "'file_name'", "]", "==", "f\"{data_id}.jpg\"", "]", ".", "misogynous", "if", "label", "is", "None", "else", "label", "\n", "\n", "\n", "\n", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "ax", ".", "axis", "(", "'off'", ")", "\n", "ax", ".", "imshow", "(", "img", ")", "\n", "\n", "if", "with_features", ":", "\n", "            ", "obj_names", "=", "{", "}", "\n", "if", "self", ".", "obj_vocab", ":", "\n", "                ", "with", "open", "(", "self", ".", "obj_vocab", ",", "\"r\"", ")", "as", "f", ":", "\n", "                        ", "obj_names", "=", "{", "i", ":", "name", ".", "split", "(", "','", ")", "[", "0", "]", ".", "strip", "(", ")", "for", "i", ",", "name", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", "}", "\n", "", "", "feat", ",", "feat_pos", ",", "obj", ",", "obj_c", "=", "self", ".", "_load_img_feature", "(", "image_id", "=", "data_id", ")", "\n", "for", "i", ",", "rect", "in", "enumerate", "(", "feat_pos", ")", ":", "\n", "                ", "if", "obj_c", "[", "i", "]", ">=", "min_confidence", ":", "\n", "                    ", "obj_id", "=", "obj", "[", "i", "]", "\n", "x", ",", "y", ",", "_", ",", "_", ",", "w", ",", "h", ",", "_", "=", "rect", "\n", "ax", ".", "add_patch", "(", "patches", ".", "Rectangle", "(", "(", "x", ",", "y", ")", ",", "w", ",", "h", ",", "fill", "=", "False", ",", "edgecolor", "=", "'red'", ",", "lw", "=", "2", ")", ")", "\n", "ax", ".", "text", "(", "x", ",", "(", "y", "-", "5", ")", ",", "f\"{obj_c[i]:.2f}\"", ",", "verticalalignment", "=", "'top'", ",", "color", "=", "'white'", ",", "fontsize", "=", "15", ",", "weight", "=", "'bold'", ")", "\n", "if", "obj_id", "in", "obj_names", ":", "\n", "                        ", "ax", ".", "text", "(", "x", "+", "w", "-", "40", ",", "(", "y", "-", "5", ")", ",", "obj_names", "[", "obj_id", "]", ",", "verticalalignment", "=", "'top'", ",", "color", "=", "'magenta'", ",", "fontsize", "=", "15", ",", "weight", "=", "'bold'", ")", "\n", "\n", "\n", "", "", "", "", "if", "label", "is", "not", "None", ":", "\n", "            ", "plt", ".", "title", "(", "\n", "\"Label: %s (%i)\"", "%", "(", "\"Positive\"", "if", "label", "==", "1", "else", "\"Negative\"", ",", "label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.prepare_loaders": [[18, 29], ["transformers.BertTokenizer.from_pretrained", "functools.partial", "functools.partial.", "functools.partial.", "functools.partial.", "dataloader.semeval_data_loader", "dataloader.semeval_data_loader", "dataloader.semeval_data_loader"], "function", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterPreTrainedModel.from_pretrained", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.semeval_data_loader", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.semeval_data_loader", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.semeval_data_loader"], ["def", "prepare_loaders", "(", "config", ")", ":", "\n", "    ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "'bert-base-cased'", ")", "\n", "\n", "dloader", "=", "partial", "(", "DataLoader", ",", "batch_size", "=", "config", "[", "'batch_size'", "]", ",", "collate_fn", "=", "semeval_collate_fn", ")", "\n", "\n", "config", "[", "'tokenizer'", "]", "=", "tokenizer", "\n", "config", "[", "'train_loader'", "]", "=", "dloader", "(", "semeval_data_loader", "(", "'train'", ",", "config", ",", "tokenizer", ")", ")", "\n", "config", "[", "'validate_loader'", "]", "=", "dloader", "(", "semeval_data_loader", "(", "'validate'", ",", "config", ",", "tokenizer", ")", ")", "\n", "config", "[", "'test_loader'", "]", "=", "dloader", "(", "semeval_data_loader", "(", "'test'", ",", "config", ",", "tokenizer", ")", ")", "\n", "\n", "return", "config", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.semeval_data_loader": [[30, 55], ["dataloader.SemevalDataset", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "function", ["None"], ["", "def", "semeval_data_loader", "(", "dataset", ":", "str", "=", "'train'", ",", "config", "=", "None", ",", "tokenizer", "=", "None", ")", ":", "\n", "    ", "assert", "dataset", "in", "[", "'train'", ",", "'validate'", ",", "'test'", "]", ",", "'Allowed values for dataset: train, validate, test'", "\n", "\n", "if", "(", "Path", "(", "config", "[", "'data_path'", "]", ")", "/", "(", "dataset", "+", "\".csv\"", ")", ")", ".", "exists", "(", ")", ":", "\n", "        ", "return", "SemevalDataset", "(", "\n", "Path", "(", "config", "[", "'data_path'", "]", ")", "/", "(", "dataset", "+", "\".csv\"", ")", ",", "\n", "Path", "(", "config", "[", "'data_path'", "]", ")", "/", "\"img\"", ",", "\n", "config", "[", "'feature_path'", "]", ",", "\n", "tokenizer", ",", "\n", "config", "[", "'max_txt_len'", "]", ",", "\n", "shuffle", "=", "(", "dataset", "==", "'train'", ")", ",", "\n", "min_obj_confidence", "=", "config", "[", "'min_object_conf'", "]", ",", "\n", "use_nms", "=", "config", "[", "'use_nms'", "]", ",", "\n", "nms_threshold", "=", "config", "[", "'nms_threshold'", "]", ",", "\n", "nr_classes", "=", "config", "[", "'nr_classes'", "]", ",", "\n", "text_cleanup", "=", "config", "[", "'with_cleanup'", "]", ",", "\n", "sentiment_path", "=", "config", "[", "'sentiment_feature_path'", "]", ",", "\n", "use_gcn", "=", "(", "config", "[", "'model_type'", "]", "in", "[", "'uniter-gnn'", ",", "'uniter-gnn2'", "]", ")", ",", "\n", "gcn_embedding_dim", "=", "config", "[", "'gcn_embedding_dim'", "]", ",", "\n", "lowercase", "=", "config", "[", "'lowercase'", "]", ",", "\n", "remove_non_ascii", "=", "config", "[", "'remove_non_ascii'", "]", ",", "\n", "spellcheck", "=", "config", "[", "'spellcheck'", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.datautils.dataloader.semeval_collate_fn": [[307, 379], ["torch.nn.utils.rnn.pad_sequence", "torch.arange().unsqueeze", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "torch.nn.utils.rnn.pad_sequence.size", "torch.arange().unsqueeze().repeat", "enumerate", "list", "list", "zip", "torch.stack", "torch.stack", "batch.update", "torch.arange().unsqueeze().repeat.size", "numpy.array().reshape", "batch_gcn_swop_eye.view().transpose.view().transpose", "batch.update", "list", "list", "list", "list", "map", "map", "torch.arange", "torch.arange().unsqueeze", "torch.arange", "torch.eye", "zip", "zip", "zip", "zip", "torch.nn.utils.rnn.pad_sequence.size", "numpy.array", "batch_gcn_swop_eye.view().transpose.view", "torch.arange", "gcn_pad_func", "d.values", "d.values", "d.values", "d.values", "len"], "function", ["None"], ["", "", "", "def", "semeval_collate_fn", "(", "inputs", ")", ":", "\n", "\n", "    ", "gcn_tokens", "=", "None", "\n", "sent_features", "=", "None", "\n", "\n", "if", "'gcn_tokens'", "in", "inputs", "[", "0", "]", ":", "\n", "        ", "if", "'sent_features'", "in", "inputs", "[", "0", "]", ":", "\n", "            ", "(", "file_ids", ",", "token_ids", ",", "img_feats", ",", "img_pos_feats", ",", "\n", "attn_masks", ",", "texts", ",", "labels", ",", "sent_features", ",", "gcn_tokens", ")", "=", "list", "(", "zip", "(", "*", "[", "d", ".", "values", "(", ")", "for", "d", "in", "inputs", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "(", "file_ids", ",", "token_ids", ",", "img_feats", ",", "img_pos_feats", ",", "\n", "attn_masks", ",", "texts", ",", "labels", ",", "gcn_tokens", ")", "=", "list", "(", "zip", "(", "*", "[", "d", ".", "values", "(", ")", "for", "d", "in", "inputs", "]", ")", ")", "\n", "", "", "elif", "'sent_features'", "in", "inputs", "[", "0", "]", ":", "\n", "        ", "(", "file_ids", ",", "token_ids", ",", "img_feats", ",", "img_pos_feats", ",", "\n", "attn_masks", ",", "texts", ",", "labels", ",", "sent_features", ")", "=", "list", "(", "zip", "(", "*", "[", "d", ".", "values", "(", ")", "for", "d", "in", "inputs", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "(", "file_ids", ",", "token_ids", ",", "img_feats", ",", "img_pos_feats", ",", "\n", "attn_masks", ",", "texts", ",", "labels", ")", "=", "list", "(", "zip", "(", "*", "[", "d", ".", "values", "(", ")", "for", "d", "in", "inputs", "]", ")", ")", "\n", "\n", "", "txt_lens", ",", "num_bbs", "=", "list", "(", "map", "(", "len", ",", "token_ids", ")", ")", ",", "list", "(", "map", "(", "len", ",", "img_feats", ")", ")", "\n", "\n", "input_ids", "=", "pad_sequence", "(", "token_ids", ",", "batch_first", "=", "True", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "0", ",", "input_ids", ".", "size", "(", "1", ")", ",", "dtype", "=", "torch", ".", "long", "\n", ")", ".", "unsqueeze", "(", "0", ")", "\n", "img_feats", "=", "pad_sequence", "(", "img_feats", ",", "batch_first", "=", "True", ")", "\n", "img_pos_feats", "=", "pad_sequence", "(", "img_pos_feats", ",", "batch_first", "=", "True", ")", "\n", "attn_masks", "=", "pad_sequence", "(", "attn_masks", ",", "batch_first", "=", "True", ")", "\n", "\n", "out_size", "=", "attn_masks", ".", "size", "(", "1", ")", "# Max joint input size (features+texttokens)", "\n", "batch_size", "=", "attn_masks", ".", "size", "(", "0", ")", "# Batch size", "\n", "max_len", "=", "input_ids", ".", "size", "(", "1", ")", "# Max Text Tokens length", "\n", "\n", "# Gather Index - where to get the corresponding embeddings for each Text token/Image feature ", "\n", "gather_index", "=", "torch", ".", "arange", "(", "0", ",", "out_size", ",", "dtype", "=", "torch", ".", "long", ",", "\n", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "batch_size", ",", "1", ")", "# First Tokens are Text tokens", "\n", "\n", "for", "i", ",", "(", "tl", ",", "nbb", ")", "in", "enumerate", "(", "zip", "(", "txt_lens", ",", "num_bbs", ")", ")", ":", "\n", "        ", "gather_index", ".", "data", "[", "i", ",", "tl", ":", "tl", "+", "nbb", "]", "=", "torch", ".", "arange", "(", "max_len", ",", "max_len", "+", "nbb", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "data", "\n", "", "if", "labels", "[", "0", "]", "is", "not", "None", ":", "\n", "        ", "labels", "=", "torch", ".", "stack", "(", "labels", ",", "dim", "=", "0", ")", "\n", "\n", "", "batch", "=", "{", "\n", "'file_ids'", ":", "file_ids", ",", "\n", "'input_ids'", ":", "input_ids", ",", "\n", "'image_features'", ":", "img_feats", ",", "\n", "'image_pos_features'", ":", "img_pos_feats", ",", "\n", "'position_ids'", ":", "position_ids", ",", "\n", "'attn_masks'", ":", "attn_masks", ",", "\n", "'gather_index'", ":", "gather_index", ",", "\n", "'labels'", ":", "labels", ",", "\n", "}", "\n", "\n", "if", "sent_features", "is", "not", "None", ":", "\n", "        ", "sent_features", "=", "torch", ".", "stack", "(", "sent_features", ",", "dim", "=", "0", ")", "\n", "batch", ".", "update", "(", "{", "'sent_features'", ":", "sent_features", "}", ")", "\n", "\n", "", "if", "gcn_tokens", "is", "not", "None", ":", "\n", "        ", "max_len", "=", "gather_index", ".", "size", "(", "1", ")", "\n", "gcn_pad_func", "=", "lambda", "arr", ":", "[", "x", "+", "[", "-", "1", "]", "*", "(", "max_len", "-", "len", "(", "x", ")", ")", "for", "x", "in", "arr", "]", "\n", "\n", "batch_gcn_vocab_ids_paded", "=", "np", ".", "array", "(", "gcn_pad_func", "(", "gcn_tokens", ")", ")", ".", "reshape", "(", "-", "1", ")", "\n", "# generate eye matrix according to gcn_vocab_size+1, the 1 is for gcn_pad_func prefix -1, then change to the row with all 0 value.", "\n", "# batch_gcn_swop_eye=torch.eye(gcn_conf.vocab_size+1)[batch_gcn_vocab_ids_paded][:,:-1]", "\n", "batch_gcn_swop_eye", "=", "torch", ".", "eye", "(", "gcn_conf", ".", "vocab_size", ")", "[", "batch_gcn_vocab_ids_paded", "]", "\n", "# This tensor is for transform batch_embedding_tensor to gcn_vocab order", "\n", "# -1 is seq_len. usage: batch_gcn_swop_eye.matmul(batch_seq_embedding)", "\n", "batch_gcn_swop_eye", "=", "batch_gcn_swop_eye", ".", "view", "(", "batch_size", ",", "-", "1", ",", "gcn_conf", ".", "vocab_size", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "batch", ".", "update", "(", "{", "'gcn'", ":", "batch_gcn_swop_eye", "}", ")", "\n", "\n", "\n", "", "return", "batch", "", "", ""]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.ot.cost_matrix_cosine": [[11, 22], ["torch.nn.functional.normalize", "torch.nn.functional.normalize", "F.normalize.matmul", "x.dim", "y.dim", "x.size", "y.size", "x.size", "y.size", "F.normalize.transpose"], "function", ["None"], ["def", "cost_matrix_cosine", "(", "x", ",", "y", ",", "eps", "=", "1e-5", ")", ":", "\n", "    ", "\"\"\" Compute cosine distnace across every pairs of x, y (batched)\n    [B, L_x, D] [B, L_y, D] -> [B, Lx, Ly]\"\"\"", "\n", "assert", "x", ".", "dim", "(", ")", "==", "y", ".", "dim", "(", ")", "\n", "assert", "x", ".", "size", "(", "0", ")", "==", "y", ".", "size", "(", "0", ")", "\n", "assert", "x", ".", "size", "(", "2", ")", "==", "y", ".", "size", "(", "2", ")", "\n", "x_norm", "=", "F", ".", "normalize", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "eps", "=", "eps", ")", "\n", "y_norm", "=", "F", ".", "normalize", "(", "y", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "eps", "=", "eps", ")", "\n", "cosine_sim", "=", "x_norm", ".", "matmul", "(", "y_norm", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "cosine_dist", "=", "1", "-", "cosine_sim", "\n", "return", "cosine_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.ot.trace": [[24, 33], ["x.size", "torch.eye().unsqueeze().expand_as", "x.masked_select().contiguous().view().sum", "torch.eye().unsqueeze", "x.masked_select().contiguous().view", "torch.eye", "x.masked_select().contiguous", "x.masked_select"], "function", ["None"], ["", "def", "trace", "(", "x", ")", ":", "\n", "    ", "\"\"\" compute trace of input tensor (batched) \"\"\"", "\n", "b", ",", "m", ",", "n", "=", "x", ".", "size", "(", ")", "\n", "assert", "m", "==", "n", "\n", "mask", "=", "torch", ".", "eye", "(", "n", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "x", ".", "device", "\n", ")", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "x", ")", "\n", "trace", "=", "x", ".", "masked_select", "(", "mask", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "b", ",", "n", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "False", ")", "\n", "return", "trace", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.ot.ipot": [[35, 67], ["torch.no_grad", "C.size", "torch.ones", "torch.exp", "sigma.view.masked_fill_", "joint_pad.transpose.transpose", "torch.ones.masked_fill_", "torch.exp.masked_fill_", "x_len.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "y_len.unsqueeze().unsqueeze.unsqueeze().unsqueeze", "range", "torch.ones.masked_fill_", "torch.ones", "x_len.unsqueeze().unsqueeze.unsqueeze", "sigma.view.view", "range", "x_len.unsqueeze().unsqueeze.unsqueeze", "y_len.unsqueeze().unsqueeze.unsqueeze", "C.transpose", "x_pad.to", "y_pad.to", "delta.view", "Q.matmul().view", "delta.matmul", "Q.matmul"], "function", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "ipot", "(", "C", ",", "x_len", ",", "x_pad", ",", "y_len", ",", "y_pad", ",", "joint_pad", ",", "beta", ",", "iteration", ",", "k", ")", ":", "\n", "    ", "\"\"\" [B, M, N], [B], [B, M], [B], [B, N], [B, M, N]\"\"\"", "\n", "b", ",", "m", ",", "n", "=", "C", ".", "size", "(", ")", "\n", "sigma", "=", "torch", ".", "ones", "(", "b", ",", "m", ",", "dtype", "=", "C", ".", "dtype", ",", "device", "=", "C", ".", "device", "\n", ")", "/", "x_len", ".", "unsqueeze", "(", "1", ")", "\n", "T", "=", "torch", ".", "ones", "(", "b", ",", "n", ",", "m", ",", "dtype", "=", "C", ".", "dtype", ",", "device", "=", "C", ".", "device", ")", "\n", "A", "=", "torch", ".", "exp", "(", "-", "C", ".", "transpose", "(", "1", ",", "2", ")", "/", "beta", ")", "\n", "\n", "# mask padded positions", "\n", "sigma", ".", "masked_fill_", "(", "x_pad", ",", "0", ")", "\n", "joint_pad", "=", "joint_pad", ".", "transpose", "(", "1", ",", "2", ")", "\n", "T", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "A", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "\n", "# broadcastable lengths", "\n", "x_len", "=", "x_len", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "y_len", "=", "y_len", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# mask to zero out padding in delta and sigma", "\n", "x_mask", "=", "(", "x_pad", ".", "to", "(", "C", ".", "dtype", ")", "*", "1e4", ")", ".", "unsqueeze", "(", "1", ")", "\n", "y_mask", "=", "(", "y_pad", ".", "to", "(", "C", ".", "dtype", ")", "*", "1e4", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "for", "_", "in", "range", "(", "iteration", ")", ":", "\n", "        ", "Q", "=", "A", "*", "T", "# bs * n * m", "\n", "sigma", "=", "sigma", ".", "view", "(", "b", ",", "m", ",", "1", ")", "\n", "for", "_", "in", "range", "(", "k", ")", ":", "\n", "            ", "delta", "=", "1", "/", "(", "y_len", "*", "Q", ".", "matmul", "(", "sigma", ")", ".", "view", "(", "b", ",", "1", ",", "n", ")", "+", "y_mask", ")", "\n", "sigma", "=", "1", "/", "(", "x_len", "*", "delta", ".", "matmul", "(", "Q", ")", "+", "x_mask", ")", "\n", "", "T", "=", "delta", ".", "view", "(", "b", ",", "n", ",", "1", ")", "*", "Q", "*", "sigma", "\n", "", "T", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "return", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.ot.optimal_transport_dist": [[69, 86], ["ot.cost_matrix_cosine", "cost_matrix_cosine.masked_fill_", "ot.ipot", "ot.trace", "txt_pad.unsqueeze", "img_pad.unsqueeze", "cost_matrix_cosine.detach", "cost_matrix_cosine.matmul", "ipot.detach", "txt_pad.size", "txt_pad.sum", "img_pad.size", "img_pad.sum"], "function", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.ot.cost_matrix_cosine", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.ot.ipot", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.ot.trace"], ["", "def", "optimal_transport_dist", "(", "txt_emb", ",", "img_emb", ",", "txt_pad", ",", "img_pad", ",", "\n", "beta", "=", "0.5", ",", "iteration", "=", "50", ",", "k", "=", "1", ")", ":", "\n", "    ", "\"\"\" [B, M, D], [B, N, D], [B, M], [B, N]\"\"\"", "\n", "cost", "=", "cost_matrix_cosine", "(", "txt_emb", ",", "img_emb", ")", "\n", "# mask the padded inputs", "\n", "joint_pad", "=", "txt_pad", ".", "unsqueeze", "(", "-", "1", ")", "|", "img_pad", ".", "unsqueeze", "(", "-", "2", ")", "\n", "cost", ".", "masked_fill_", "(", "joint_pad", ",", "0", ")", "\n", "\n", "txt_len", "=", "(", "txt_pad", ".", "size", "(", "1", ")", "-", "txt_pad", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", ")", ".", "to", "(", "dtype", "=", "cost", ".", "dtype", ")", "\n", "img_len", "=", "(", "img_pad", ".", "size", "(", "1", ")", "-", "img_pad", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", ")", ".", "to", "(", "dtype", "=", "cost", ".", "dtype", ")", "\n", "\n", "T", "=", "ipot", "(", "cost", ".", "detach", "(", ")", ",", "txt_len", ",", "txt_pad", ",", "img_len", ",", "img_pad", ",", "joint_pad", ",", "\n", "beta", ",", "iteration", ",", "k", ")", "\n", "distance", "=", "trace", "(", "cost", ".", "matmul", "(", "T", ".", "detach", "(", ")", ")", ")", "\n", "return", "distance", "\n", "", ""]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniter.__init__": [[9, 17], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "uniter_model", ":", "UniterModel", ",", "\n", "n_classes", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "uniter_model", "=", "uniter_model", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "hidden_size", "=", "uniter_model", ".", "config", ".", "hidden_size", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "n_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniter.forward": [[18, 23], ["semeval.SemevalUniter.uniter_model", "semeval.SemevalUniter.uniter_model.pooler", "semeval.SemevalUniter.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "out", "=", "self", ".", "uniter_model", "(", "**", "kwargs", ")", "\n", "out", "=", "self", ".", "uniter_model", ".", "pooler", "(", "out", ")", "\n", "out", "=", "self", ".", "linear", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniter.save": [[24, 26], ["torch.save", "torch.save", "torch.save", "torch.save", "semeval.SemevalUniter.state_dict"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save"], ["", "def", "save", "(", "self", ",", "checkpoint_file", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "checkpoint_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniter.load": [[27, 29], ["semeval.SemevalUniter.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load"], ["", "def", "load", "(", "self", ",", "checkpoint_file", ")", ":", "\n", "        ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniterVGG19Sentiment.__init__": [[34, 52], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "uniter_model", ":", "UniterModel", ",", "\n", "dropout", ":", "float", ",", "\n", "n_classes", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "uniter_model", "=", "uniter_model", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "hidden_size", "=", "uniter_model", ".", "config", ".", "hidden_size", "\n", "# self.sent_linear = nn.Sequential(", "\n", "#     nn.Linear(512 * 7 * 7, 4096),", "\n", "#     nn.ReLU(True),", "\n", "#     nn.Dropout(p=dropout),", "\n", "#     nn.Linear(4096, 4096),", "\n", "#     nn.ReLU(True),", "\n", "#     nn.Dropout(p=dropout),", "\n", "# )", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "4096", ",", "n_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniterVGG19Sentiment.forward": [[53, 65], ["semeval.SemevalUniterVGG19Sentiment.uniter_model", "semeval.SemevalUniterVGG19Sentiment.uniter_model.pooler", "semeval.SemevalUniterVGG19Sentiment.drop", "vgg_pool.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "semeval.SemevalUniterVGG19Sentiment.linear", "vgg_pool.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "vgg_pool", ",", "**", "kwargs", ")", ":", "\n", "        ", "out", "=", "self", ".", "uniter_model", "(", "**", "kwargs", ")", "\n", "out", "=", "self", ".", "uniter_model", ".", "pooler", "(", "out", ")", "\n", "\n", "# vgg_pool_ = vgg_pool.view(vgg_pool.size(0), -1)        ", "\n", "# sent_out = self.sent_linear(vgg_pool_)", "\n", "sent_out", "=", "self", ".", "drop", "(", "vgg_pool", ")", "\n", "sent_out", "=", "vgg_pool", ".", "view", "(", "vgg_pool", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "out", "=", "torch", ".", "cat", "(", "(", "out", ",", "sent_out", ")", ",", "dim", "=", "1", ")", "\n", "out", "=", "self", ".", "linear", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniterVGG19Sentiment.save": [[66, 68], ["torch.save", "torch.save", "torch.save", "torch.save", "semeval.SemevalUniterVGG19Sentiment.state_dict"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save"], ["", "def", "save", "(", "self", ",", "checkpoint_file", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "checkpoint_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniterVGG19Sentiment.load": [[69, 71], ["semeval.SemevalUniterVGG19Sentiment.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load"], ["", "def", "load", "(", "self", ",", "checkpoint_file", ")", ":", "\n", "        ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniterVGG19Sentiment2.__init__": [[75, 97], ["torch.nn.Module.__init__", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "uniter_model", ":", "UniterModel", ",", "\n", "dropout", ":", "float", ",", "\n", "n_classes", ":", "int", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "uniter_model", "=", "uniter_model", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "hidden_size", "=", "uniter_model", ".", "config", ".", "hidden_size", "\n", "self", ".", "lstm_size", "=", "128", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "hidden_size", ",", "\n", "hidden_size", "=", "self", ".", "lstm_size", ",", "\n", "num_layers", "=", "1", ",", "\n", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "True", "\n", ")", "\n", "\n", "self", ".", "sent_linear", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2", "*", "self", ".", "lstm_size", "+", "4096", ",", "1024", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "n_classes", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniterVGG19Sentiment2.forward": [[100, 113], ["semeval.SemevalUniterVGG19Sentiment2.uniter_model", "semeval.SemevalUniterVGG19Sentiment2.lstm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "vgg_pool.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "semeval.SemevalUniterVGG19Sentiment2.sent_linear", "vgg_pool.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "vgg_pool", ",", "**", "kwargs", ")", ":", "\n", "        ", "out", "=", "self", ".", "uniter_model", "(", "**", "kwargs", ")", "\n", "# out = self.uniter_model.pooler(out)", "\n", "out", ",", "(", "h", ",", "c", ")", "=", "self", ".", "lstm", "(", "out", ")", "\n", "out", "=", "torch", ".", "cat", "(", "(", "out", "[", ":", ",", "-", "1", ",", ":", "self", ".", "lstm_size", "]", ",", "out", "[", ":", ",", "0", ",", "self", ".", "lstm_size", ":", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "# out = torch.cat((h[0],h[1]),dim=-1)", "\n", "# vgg_pool_ = vgg_pool.view(vgg_pool.size(0), -1)        ", "\n", "# sent_out = self.sent_linear(vgg_pool_)", "\n", "sent_out", "=", "vgg_pool", ".", "view", "(", "vgg_pool", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "out", "=", "torch", ".", "cat", "(", "(", "out", ",", "sent_out", ")", ",", "dim", "=", "1", ")", "\n", "out", "=", "self", ".", "sent_linear", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniterVGG19Sentiment2.save": [[114, 116], ["torch.save", "torch.save", "torch.save", "torch.save", "semeval.SemevalUniterVGG19Sentiment2.state_dict"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save"], ["", "def", "save", "(", "self", ",", "checkpoint_file", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "checkpoint_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.SemevalUniterVGG19Sentiment2.load": [[117, 119], ["semeval.SemevalUniterVGG19Sentiment2.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load"], ["", "def", "load", "(", "self", ",", "checkpoint_file", ")", ":", "\n", "        ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VocabGraphConvolution.__init__": [[142, 158], ["torch.nn.Module.__init__", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Dropout", "semeval.VocabGraphConvolution.reset_parameters", "setattr", "torch.nn.Parameter", "torch.nn.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VocabGraphConvolution.reset_parameters"], ["def", "__init__", "(", "self", ",", "adj_matrix", ",", "voc_dim", ",", "num_adj", ",", "hid_dim", ",", "out_dim", ",", "dropout_rate", "=", "0.2", ")", ":", "\n", "        ", "super", "(", "VocabGraphConvolution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "adj_matrix", "=", "adj_matrix", "\n", "self", ".", "voc_dim", "=", "voc_dim", "\n", "self", ".", "num_adj", "=", "num_adj", "\n", "self", ".", "hid_dim", "=", "hid_dim", "\n", "self", ".", "out_dim", "=", "out_dim", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_adj", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "'W%d_vh'", "%", "i", ",", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "voc_dim", ",", "hid_dim", ")", ")", ")", "\n", "\n", "", "self", ".", "fc_hc", "=", "nn", ".", "Linear", "(", "hid_dim", ",", "out_dim", ")", "\n", "self", ".", "act_func", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_rate", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VocabGraphConvolution.reset_parameters": [[159, 163], ["semeval.VocabGraphConvolution.named_parameters", "n.startswith", "n.startswith", "torch.kaiming_uniform_", "torch.kaiming_uniform_", "math.sqrt"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "n", ".", "startswith", "(", "'W'", ")", "or", "n", ".", "startswith", "(", "'a'", ")", "or", "n", "in", "(", "'W'", ",", "'a'", ",", "'dense'", ")", ":", "\n", "                ", "init", ".", "kaiming_uniform_", "(", "p", ",", "a", "=", "math", ".", "sqrt", "(", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VocabGraphConvolution.forward": [[164, 183], ["range", "semeval.VocabGraphConvolution.fc_hc", "semeval.VocabGraphConvolution.adj_matrix[].mm", "semeval.VocabGraphConvolution.dropout", "X_dv.matmul", "getattr", "X_dv.matmul", "semeval.VocabGraphConvolution.dropout", "getattr"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "X_dv", ",", "add_linear_mapping_term", "=", "False", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "num_adj", ")", ":", "\n", "            ", "H_vh", "=", "self", ".", "adj_matrix", "[", "i", "]", ".", "mm", "(", "getattr", "(", "self", ",", "'W%d_vh'", "%", "i", ")", ")", "\n", "# H_vh=self.dropout(F.elu(H_vh))", "\n", "H_vh", "=", "self", ".", "dropout", "(", "H_vh", ")", "\n", "H_dh", "=", "X_dv", ".", "matmul", "(", "H_vh", ")", "\n", "\n", "if", "add_linear_mapping_term", ":", "\n", "                ", "H_linear", "=", "X_dv", ".", "matmul", "(", "getattr", "(", "self", ",", "'W%d_vh'", "%", "i", ")", ")", "\n", "H_linear", "=", "self", ".", "dropout", "(", "H_linear", ")", "\n", "H_dh", "+=", "H_linear", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                ", "fused_H", "=", "H_dh", "\n", "", "else", ":", "\n", "                ", "fused_H", "+=", "H_dh", "\n", "\n", "", "", "out", "=", "self", ".", "fc_hc", "(", "fused_H", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert.__init__": [[221, 236], ["torch.nn.Module.__init__", "semeval.VocabGraphConvolution", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], ["def", "__init__", "(", "self", ",", "uniter_model", ":", "UniterModel", ",", "gcn_adj_matrix", ",", "gcn_adj_dim", ",", "gcn_adj_num", ",", "\n", "gcn_embedding_dim", ",", "num_labels", ",", "output_attentions", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_gcn", "=", "VocabGraphConvolution", "(", "gcn_adj_matrix", ",", "gcn_adj_dim", ",", "gcn_adj_num", ",", "128", ",", "gcn_embedding_dim", ")", "#192/256", "\n", "self", ".", "uniter_model", "=", "uniter_model", "\n", "self", ".", "gcn_adj_matrix", "=", "gcn_adj_matrix", "\n", "self", ".", "gcn_adj_dim", "=", "gcn_adj_dim", "\n", "self", ".", "gcn_adj_num", "=", "gcn_adj_num", "\n", "self", ".", "gcn_embedding_dim", "=", "gcn_embedding_dim", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "uniter_model", ".", "config", ".", "hidden_size", ",", "eps", "=", "uniter_model", ".", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "uniter_model", ".", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "uniter_model", ".", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "will_collect_cls_states", "=", "False", "\n", "self", ".", "all_cls_states", "=", "[", "]", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "# self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert.uniter_embeddings2": [[239, 258], ["semeval.VGCN_Bert.uniter_model._compute_img_embeddings", "semeval.VGCN_Bert.uniter_model._compute_txt_embeddings", "semeval.VGCN_Bert.uniter_model._compute_img_txt_embeddings"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_img_embeddings", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_txt_embeddings", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_img_txt_embeddings"], ["", "def", "uniter_embeddings2", "(", "self", ",", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "gather_index", "=", "None", ",", "img_masks", "=", "None", ",", "\n", "txt_type_ids", "=", "None", ",", "img_type_ids", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# embedding layer", "\n", "        ", "if", "input_ids", "is", "None", ":", "\n", "# image only", "\n", "            ", "embedding_output", "=", "self", ".", "uniter_model", ".", "_compute_img_embeddings", "(", "\n", "img_feat", ",", "img_pos_feat", ",", "img_masks", ",", "img_type_ids", ")", "\n", "", "elif", "img_feat", "is", "None", ":", "\n", "# text only", "\n", "            ", "embedding_output", "=", "self", ".", "uniter_model", ".", "_compute_txt_embeddings", "(", "\n", "input_ids", ",", "position_ids", ",", "txt_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "embedding_output", "=", "self", ".", "uniter_model", ".", "_compute_img_txt_embeddings", "(", "\n", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "gather_index", ",", "img_masks", ",", "txt_type_ids", ",", "img_type_ids", ")", "\n", "", "return", "embedding_output", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert.uniter_embeddings": [[259, 277], ["semeval.VGCN_Bert.uniter_model.embeddings.word_embeddings", "semeval.VGCN_Bert.uniter_model.embeddings.position_embeddings", "semeval.VGCN_Bert.uniter_model.embeddings.token_type_embeddings", "semeval.VGCN_Bert.uniter_model.embeddings.token_type_embeddings", "semeval.VGCN_Bert.uniter_model.img_embeddings.img_layer_norm", "semeval.VGCN_Bert.uniter_model.img_embeddings.pos_layer_norm", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "semeval.VGCN_Bert.uniter_model.img_embeddings.img_linear", "semeval.VGCN_Bert.uniter_model.img_embeddings.pos_linear", "img_feat[].long"], "methods", ["None"], ["", "def", "uniter_embeddings", "(", "self", ",", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "txt_type_ids", "=", "None", ",", "img_type_ids", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "txt_type_ids", "is", "None", ":", "\n", "            ", "txt_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "", "if", "img_type_ids", "is", "None", ":", "\n", "            ", "img_type_ids", "=", "torch", ".", "ones_like", "(", "img_feat", "[", ":", ",", ":", ",", "0", "]", ".", "long", "(", ")", ")", "\n", "\n", "\n", "", "words_embeddings", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings_txt", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "token_type_embeddings", "(", "txt_type_ids", ")", "\n", "token_type_embeddings_img", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "token_type_embeddings", "(", "img_type_ids", ")", "\n", "\n", "transformed_im", "=", "self", ".", "uniter_model", ".", "img_embeddings", ".", "img_layer_norm", "(", "self", ".", "uniter_model", ".", "img_embeddings", ".", "img_linear", "(", "img_feat", ")", ")", "\n", "transformed_pos", "=", "self", ".", "uniter_model", ".", "img_embeddings", ".", "pos_layer_norm", "(", "self", ".", "uniter_model", ".", "img_embeddings", ".", "pos_linear", "(", "img_pos_feat", ")", ")", "\n", "\n", "return", "words_embeddings", ",", "position_embeddings", ",", "token_type_embeddings_txt", ",", "transformed_im", ",", "transformed_pos", ",", "token_type_embeddings_img", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert.forward": [[278, 376], ["semeval.VGCN_Bert.uniter_embeddings", "gather_index.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "gcn_swop_eye.matmul().transpose", "semeval.VGCN_Bert.uniter_model.img_embeddings.LayerNorm", "semeval.VGCN_Bert.uniter_model.img_embeddings.dropout", "semeval.VGCN_Bert.uniter_model.embeddings.LayerNorm", "semeval.VGCN_Bert.uniter_model.embeddings.dropout", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "semeval.VGCN_Bert.vocab_gcn", "torch.ones_like.sum", "torch.ones_like.sum", "gcn_vocab_out.transpose.transpose.transpose", "enumerate", "semeval.VGCN_Bert.LayerNorm", "semeval.VGCN_Bert.dropout", "torch.ones_like.unsqueeze().unsqueeze", "torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "semeval.VGCN_Bert.uniter_model.encoder", "semeval.VGCN_Bert.uniter_model.pooler", "semeval.VGCN_Bert.dropout", "semeval.VGCN_Bert.classifier", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.ConstantPad3d", "torch.nn.ConstantPad3d", "torch.ones_like.sum.tolist", "[].to", "gather_index.unsqueeze().expand.unsqueeze().expand.unsqueeze", "gcn_swop_eye.matmul", "torch.ones_like.unsqueeze", "torch.ones_like.unsqueeze", "gcn_vocab_out.transpose.transpose.size", "next", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "semeval.VGCN_Bert.parameters", "gcn_words_embeddings.size"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.uniter_embeddings"], ["", "def", "forward", "(", "self", ",", "gcn_swop_eye", ",", "gather_index", ",", "attention_mask", ",", "**", "kwargs", ")", ":", "\n", "        ", "input_ids", "=", "kwargs", "[", "'input_ids'", "]", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "(", "words_embeddings", ",", "position_embeddings_txt", ",", "token_type_embeddings_txt", ",", "\n", "image_embeddings", ",", "position_embeddings_img", ",", "token_type_embeddings_img", "\n", ")", "=", "self", ".", "uniter_embeddings", "(", "**", "kwargs", ")", "\n", "gather_index", "=", "gather_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "\n", "-", "1", ",", "-", "1", ",", "self", ".", "uniter_model", ".", "config", ".", "hidden_size", ")", "\n", "joint_embeddings", "=", "torch", ".", "gather", "(", "torch", ".", "cat", "(", "[", "words_embeddings", ",", "image_embeddings", "]", ",", "dim", "=", "1", ")", ",", "\n", "dim", "=", "1", ",", "index", "=", "gather_index", ")", "\n", "vocab_input", "=", "gcn_swop_eye", ".", "matmul", "(", "joint_embeddings", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "embeddings_img", "=", "image_embeddings", "+", "position_embeddings_img", "+", "token_type_embeddings_img", "\n", "embeddings_img", "=", "self", ".", "uniter_model", ".", "img_embeddings", ".", "LayerNorm", "(", "embeddings_img", ")", "\n", "embeddings_img", "=", "self", ".", "uniter_model", ".", "img_embeddings", ".", "dropout", "(", "embeddings_img", ")", "\n", "\n", "embeddings_txt", "=", "words_embeddings", "+", "position_embeddings_txt", "+", "token_type_embeddings_txt", "\n", "embeddings_txt", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "LayerNorm", "(", "embeddings_txt", ")", "\n", "embeddings_txt", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "dropout", "(", "embeddings_txt", ")", "\n", "\n", "embedding_output", "=", "torch", ".", "gather", "(", "torch", ".", "cat", "(", "[", "embeddings_txt", ",", "embeddings_img", "]", ",", "dim", "=", "1", ")", ",", "\n", "dim", "=", "1", ",", "index", "=", "gather_index", ")", "\n", "\n", "\n", "gcn_vocab_out", "=", "self", ".", "vocab_gcn", "(", "vocab_input", ")", "\n", "input_lens", "=", "attention_mask", ".", "sum", "(", "-", "1", ")", "\n", "gcn_vocab_out", "=", "gcn_vocab_out", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "gcn_words_embeddings", "=", "nn", ".", "ConstantPad3d", "(", "(", "0", ",", "0", ",", "0", ",", "gcn_vocab_out", ".", "size", "(", "1", ")", ",", "0", ",", "0", ")", ",", "0", ")", "(", "embedding_output", ")", "\n", "\n", "# gcn_words_embeddings=joint_embeddings.clone()", "\n", "# for i in range(self.gcn_embedding_dim):", "\n", "#     tmp_pos=(attention_mask.sum(-1)-2-self.gcn_embedding_dim+1+i)+torch.arange(0,input_ids.shape[0]).to(self.device)*input_ids.shape[1]", "\n", "#     gcn_words_embeddings.flatten(start_dim=0, end_dim=1)[tmp_pos,:]=gcn_vocab_out[:,:,i]", "\n", "\n", "# De incercat si un LayerNorm pe GCN", "\n", "\n", "for", "i", ",", "seq_len", "in", "enumerate", "(", "input_lens", ".", "tolist", "(", ")", ")", ":", "\n", "            ", "gcn_words_embeddings", "[", "i", ",", "seq_len", ":", "seq_len", "+", "self", ".", "gcn_embedding_dim", ",", ":", "]", "=", "gcn_vocab_out", "[", "i", ",", ":", ",", ":", "]", "\n", "\n", "# Add the GCN embeddings to the mask ", "\n", "", "attention_mask", "=", "(", "torch", ".", "arange", "(", "gcn_words_embeddings", ".", "size", "(", "1", ")", ")", "[", "None", ",", ":", "]", ".", "to", "(", "input_lens", ".", "device", ")", "\n", "<", "(", "input_lens", "+", "self", ".", "gcn_embedding_dim", ")", "[", ":", ",", "None", "]", ")", "\n", "# Poate trebuie modificat sa adunam positional si la GCN...", "\n", "\n", "# seq_length = input_ids.size(1)", "\n", "# position_ids = torch.arange(seq_length, dtype=torch.long, device=input_ids.device)", "\n", "# position_ids = position_ids.unsqueeze(0).expand_as(input_ids)", "\n", "# if token_type_ids is None:", "\n", "#     token_type_ids = torch.zeros_like(input_ids)", "\n", "\n", "# position_embeddings = self.position_embeddings(position_ids)", "\n", "# token_type_embeddings = self.token_type_embeddings(token_type_ids)", "\n", "\n", "# if self.gcn_embedding_dim>0:", "\n", "#     embeddings = gcn_words_embeddings + position_embeddings + token_type_embeddings", "\n", "# else:", "\n", "#     embeddings = words_embeddings + position_embeddings + token_type_embeddings", "\n", "\n", "embeddings", "=", "gcn_words_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embedding_output", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask. ", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "output_all_encoded_layers", "=", "self", ".", "output_attentions", "\n", "encoded_layers", "=", "self", ".", "uniter_model", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ",", "\n", ")", "\n", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "\n", "", "pooled_output", "=", "self", ".", "uniter_model", ".", "pooler", "(", "encoded_layers", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "if", "output_all_encoded_layers", ":", "\n", "            ", "return", "encoded_layers", ",", "logits", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert.save": [[378, 380], ["torch.save", "torch.save", "torch.save", "torch.save", "semeval.VGCN_Bert.state_dict"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save"], ["", "def", "save", "(", "self", ",", "checkpoint_file", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "checkpoint_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert.load": [[381, 383], ["semeval.VGCN_Bert.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load"], ["", "def", "load", "(", "self", ",", "checkpoint_file", ")", ":", "\n", "        ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.__init__": [[422, 437], ["torch.nn.Module.__init__", "semeval.VocabGraphConvolution", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], ["def", "__init__", "(", "self", ",", "uniter_model", ":", "UniterModel", ",", "gcn_adj_matrix", ",", "gcn_adj_dim", ",", "gcn_adj_num", ",", "\n", "gcn_embedding_dim", ",", "num_labels", ",", "output_attentions", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_gcn", "=", "VocabGraphConvolution", "(", "gcn_adj_matrix", ",", "gcn_adj_dim", ",", "gcn_adj_num", ",", "128", ",", "gcn_embedding_dim", ")", "#192/256", "\n", "self", ".", "uniter_model", "=", "uniter_model", "\n", "self", ".", "gcn_adj_matrix", "=", "gcn_adj_matrix", "\n", "self", ".", "gcn_adj_dim", "=", "gcn_adj_dim", "\n", "self", ".", "gcn_adj_num", "=", "gcn_adj_num", "\n", "self", ".", "gcn_embedding_dim", "=", "gcn_embedding_dim", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "uniter_model", ".", "config", ".", "hidden_size", ",", "eps", "=", "uniter_model", ".", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "uniter_model", ".", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "uniter_model", ".", "config", ".", "hidden_size", "+", "4096", ",", "num_labels", ")", "\n", "self", ".", "will_collect_cls_states", "=", "False", "\n", "self", ".", "all_cls_states", "=", "[", "]", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "# self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.uniter_embeddings2": [[440, 459], ["semeval.VGCN_Bert_and_VGG.uniter_model._compute_img_embeddings", "semeval.VGCN_Bert_and_VGG.uniter_model._compute_txt_embeddings", "semeval.VGCN_Bert_and_VGG.uniter_model._compute_img_txt_embeddings"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_img_embeddings", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_txt_embeddings", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_img_txt_embeddings"], ["", "def", "uniter_embeddings2", "(", "self", ",", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "gather_index", "=", "None", ",", "img_masks", "=", "None", ",", "\n", "txt_type_ids", "=", "None", ",", "img_type_ids", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "# embedding layer", "\n", "        ", "if", "input_ids", "is", "None", ":", "\n", "# image only", "\n", "            ", "embedding_output", "=", "self", ".", "uniter_model", ".", "_compute_img_embeddings", "(", "\n", "img_feat", ",", "img_pos_feat", ",", "img_masks", ",", "img_type_ids", ")", "\n", "", "elif", "img_feat", "is", "None", ":", "\n", "# text only", "\n", "            ", "embedding_output", "=", "self", ".", "uniter_model", ".", "_compute_txt_embeddings", "(", "\n", "input_ids", ",", "position_ids", ",", "txt_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "embedding_output", "=", "self", ".", "uniter_model", ".", "_compute_img_txt_embeddings", "(", "\n", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "gather_index", ",", "img_masks", ",", "txt_type_ids", ",", "img_type_ids", ")", "\n", "", "return", "embedding_output", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.uniter_embeddings": [[460, 478], ["semeval.VGCN_Bert_and_VGG.uniter_model.embeddings.word_embeddings", "semeval.VGCN_Bert_and_VGG.uniter_model.embeddings.position_embeddings", "semeval.VGCN_Bert_and_VGG.uniter_model.embeddings.token_type_embeddings", "semeval.VGCN_Bert_and_VGG.uniter_model.embeddings.token_type_embeddings", "semeval.VGCN_Bert_and_VGG.uniter_model.img_embeddings.img_layer_norm", "semeval.VGCN_Bert_and_VGG.uniter_model.img_embeddings.pos_layer_norm", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "semeval.VGCN_Bert_and_VGG.uniter_model.img_embeddings.img_linear", "semeval.VGCN_Bert_and_VGG.uniter_model.img_embeddings.pos_linear", "img_feat[].long"], "methods", ["None"], ["", "def", "uniter_embeddings", "(", "self", ",", "input_ids", ",", "position_ids", ",", "\n", "img_feat", ",", "img_pos_feat", ",", "\n", "txt_type_ids", "=", "None", ",", "img_type_ids", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "txt_type_ids", "is", "None", ":", "\n", "            ", "txt_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "", "if", "img_type_ids", "is", "None", ":", "\n", "            ", "img_type_ids", "=", "torch", ".", "ones_like", "(", "img_feat", "[", ":", ",", ":", ",", "0", "]", ".", "long", "(", ")", ")", "\n", "\n", "\n", "", "words_embeddings", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings_txt", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "token_type_embeddings", "(", "txt_type_ids", ")", "\n", "token_type_embeddings_img", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "token_type_embeddings", "(", "img_type_ids", ")", "\n", "\n", "transformed_im", "=", "self", ".", "uniter_model", ".", "img_embeddings", ".", "img_layer_norm", "(", "self", ".", "uniter_model", ".", "img_embeddings", ".", "img_linear", "(", "img_feat", ")", ")", "\n", "transformed_pos", "=", "self", ".", "uniter_model", ".", "img_embeddings", ".", "pos_layer_norm", "(", "self", ".", "uniter_model", ".", "img_embeddings", ".", "pos_linear", "(", "img_pos_feat", ")", ")", "\n", "\n", "return", "words_embeddings", ",", "position_embeddings", ",", "token_type_embeddings_txt", ",", "transformed_im", ",", "transformed_pos", ",", "token_type_embeddings_img", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.forward": [[479, 551], ["semeval.VGCN_Bert_and_VGG.uniter_embeddings", "gather_index.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "gcn_swop_eye.matmul().transpose", "semeval.VGCN_Bert_and_VGG.uniter_model.img_embeddings.LayerNorm", "semeval.VGCN_Bert_and_VGG.uniter_model.img_embeddings.dropout", "semeval.VGCN_Bert_and_VGG.uniter_model.embeddings.LayerNorm", "semeval.VGCN_Bert_and_VGG.uniter_model.embeddings.dropout", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "semeval.VGCN_Bert_and_VGG.vocab_gcn", "gcn_vocab_out.transpose.transpose.transpose", "semeval.VGCN_Bert_and_VGG.LayerNorm", "semeval.VGCN_Bert_and_VGG.dropout", "torch.ones_like.unsqueeze().unsqueeze", "torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "semeval.VGCN_Bert_and_VGG.uniter_model.encoder", "semeval.VGCN_Bert_and_VGG.uniter_model.pooler", "vgg_pool.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "semeval.VGCN_Bert_and_VGG.dropout", "semeval.VGCN_Bert_and_VGG.classifier", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "vgg_pool.size", "gather_index.unsqueeze().expand.unsqueeze().expand.unsqueeze", "gcn_swop_eye.matmul", "torch.ones_like.unsqueeze", "torch.ones_like.unsqueeze", "next", "semeval.VGCN_Bert_and_VGG.parameters"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.uniter_embeddings"], ["", "def", "forward", "(", "self", ",", "vgg_pool", ",", "gcn_swop_eye", ",", "gather_index", ",", "attention_mask", ",", "**", "kwargs", ")", ":", "\n", "        ", "input_ids", "=", "kwargs", "[", "'input_ids'", "]", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "(", "words_embeddings", ",", "position_embeddings_txt", ",", "token_type_embeddings_txt", ",", "\n", "image_embeddings", ",", "position_embeddings_img", ",", "token_type_embeddings_img", "\n", ")", "=", "self", ".", "uniter_embeddings", "(", "**", "kwargs", ")", "\n", "gather_index", "=", "gather_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "\n", "-", "1", ",", "-", "1", ",", "self", ".", "uniter_model", ".", "config", ".", "hidden_size", ")", "\n", "joint_embeddings", "=", "torch", ".", "gather", "(", "torch", ".", "cat", "(", "[", "words_embeddings", ",", "image_embeddings", "]", ",", "dim", "=", "1", ")", ",", "\n", "dim", "=", "1", ",", "index", "=", "gather_index", ")", "\n", "vocab_input", "=", "gcn_swop_eye", ".", "matmul", "(", "joint_embeddings", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "embeddings_img", "=", "image_embeddings", "+", "position_embeddings_img", "+", "token_type_embeddings_img", "\n", "embeddings_img", "=", "self", ".", "uniter_model", ".", "img_embeddings", ".", "LayerNorm", "(", "embeddings_img", ")", "\n", "embeddings_img", "=", "self", ".", "uniter_model", ".", "img_embeddings", ".", "dropout", "(", "embeddings_img", ")", "\n", "\n", "embeddings_txt", "=", "words_embeddings", "+", "position_embeddings_txt", "+", "token_type_embeddings_txt", "\n", "embeddings_txt", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "LayerNorm", "(", "embeddings_txt", ")", "\n", "embeddings_txt", "=", "self", ".", "uniter_model", ".", "embeddings", ".", "dropout", "(", "embeddings_txt", ")", "\n", "\n", "embedding_output", "=", "torch", ".", "gather", "(", "torch", ".", "cat", "(", "[", "embeddings_txt", ",", "embeddings_img", "]", ",", "dim", "=", "1", ")", ",", "\n", "dim", "=", "1", ",", "index", "=", "gather_index", ")", "\n", "\n", "\n", "gcn_vocab_out", "=", "self", ".", "vocab_gcn", "(", "vocab_input", ")", "\n", "gcn_vocab_out", "=", "gcn_vocab_out", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "embeddings", "=", "embedding_output", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embedding_output", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask. ", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "output_all_encoded_layers", "=", "self", ".", "output_attentions", "\n", "encoded_layers", "=", "self", ".", "uniter_model", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ",", "\n", ")", "\n", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "\n", "", "pooled_output", "=", "self", ".", "uniter_model", ".", "pooler", "(", "encoded_layers", ")", "\n", "\n", "sent_out", "=", "vgg_pool", ".", "view", "(", "vgg_pool", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "out", "=", "torch", ".", "cat", "(", "(", "pooled_output", ",", "sent_out", ")", ",", "dim", "=", "1", ")", "\n", "\n", "sent_out", "=", "self", ".", "dropout", "(", "vgg_pool", ")", "\n", "\n", "logits", "=", "self", ".", "classifier", "(", "out", ")", "\n", "\n", "if", "output_all_encoded_layers", ":", "\n", "            ", "return", "encoded_layers", ",", "logits", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save": [[553, 555], ["torch.save", "torch.save", "torch.save", "torch.save", "semeval.VGCN_Bert_and_VGG.state_dict"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.save"], ["", "def", "save", "(", "self", ",", "checkpoint_file", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "checkpoint_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load": [[556, 558], ["semeval.VGCN_Bert_and_VGG.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load"], ["", "def", "load", "(", "self", ",", "checkpoint_file", ")", ":", "\n", "        ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterConfig.__init__": [[30, 88], ["isinstance", "json.loads.items", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterConfig.from_dict": [[91, 99], ["uniter.UniterConfig", "json_object.items"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterConfig.from_json_file": [[100, 106], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterConfig.from_dict"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterConfig.__repr__": [[107, 109], ["str", "uniter.UniterConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterConfig.to_json_string"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterConfig.to_dict": [[110, 114], ["copy.deepcopy"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterConfig.to_json_string": [[115, 118], ["json.dumps", "uniter.UniterConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterConfig.to_dict"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterPreTrainedModel.__init__": [[124, 135], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterPreTrainedModel.init_weights": [[136, 150], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterPreTrainedModel.from_pretrained": [[151, 218], ["uniter.UniterConfig.from_json_file", "logger.info", "cls", "state_dict.copy.copy.keys", "zip", "getattr", "state_dict.copy.copy.copy", "uniter.UniterPreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterConfig.from_json_file", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.semeval.VGCN_Bert_and_VGG.load"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterTextEmbeddings.__init__": [[221, 234], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterTextEmbeddings.forward": [[235, 249], ["uniter.UniterTextEmbeddings.word_embeddings", "uniter.UniterTextEmbeddings.position_embeddings", "uniter.UniterTextEmbeddings.token_type_embeddings", "uniter.UniterTextEmbeddings.LayerNorm", "uniter.UniterTextEmbeddings.dropout", "torch.zeros_like"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterImageEmbeddings.__init__": [[252, 263], ["torch.nn.Module.__init__", "torch.nn.Linear", "apex.normalization.fused_layer_norm.FusedLayerNorm", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Linear", "torch.nn.Embedding", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterImageEmbeddings.forward": [[264, 276], ["uniter.UniterImageEmbeddings.img_layer_norm", "uniter.UniterImageEmbeddings.pos_layer_norm", "uniter.UniterImageEmbeddings.LayerNorm", "uniter.UniterImageEmbeddings.dropout", "uniter.UniterImageEmbeddings.mask_embedding.weight.data[].fill_", "uniter.UniterImageEmbeddings.mask_embedding", "uniter.UniterImageEmbeddings.img_linear", "uniter.UniterImageEmbeddings.pos_linear", "img_masks.long"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterEncoder.__init__": [[279, 284], ["torch.nn.Module.__init__", "transformers.models.bert.modeling_bert.BertLayer", "torch.nn.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterEncoder.forward": [[285, 297], ["layer_module", "all_encoder_layers.append", "all_encoder_layers.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel.__init__": [[302, 309], ["uniter.UniterPreTrainedModel.__init__", "uniter.UniterTextEmbeddings", "uniter.UniterImageEmbeddings", "uniter.UniterEncoder", "transformers.models.bert.modeling_bert.BertPooler", "uniter.UniterModel.apply"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_txt_embeddings": [[310, 314], ["uniter.UniterModel.embeddings"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_img_embeddings": [[315, 324], ["uniter.UniterModel.embeddings.token_type_embeddings", "uniter.UniterModel.img_embeddings", "torch.ones_like", "img_feat[].long"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_img_txt_embeddings": [[325, 339], ["uniter.UniterModel._compute_txt_embeddings", "uniter.UniterModel._compute_img_embeddings", "gather_index.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.gather", "torch.cat", "gather_index.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_txt_embeddings", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_img_embeddings"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel.forward": [[340, 372], ["attention_mask.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "uniter.UniterModel.encoder", "uniter.UniterModel._compute_img_embeddings", "attention_mask.unsqueeze", "uniter.UniterModel._compute_txt_embeddings", "uniter.UniterModel._compute_img_txt_embeddings", "next", "uniter.UniterModel.parameters"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_img_embeddings", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_txt_embeddings", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterModel._compute_img_txt_embeddings"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.RegionFeatureRegression.__init__": [[377, 385], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.GELU", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.RegionFeatureRegression.forward": [[386, 390], ["uniter.RegionFeatureRegression.net", "torch.nn.functional.linear", "uniter.RegionFeatureRegression.weight.t"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.RegionClassification.__init__": [[394, 400], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.GELU", "apex.normalization.fused_layer_norm.FusedLayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.RegionClassification.forward": [[401, 404], ["uniter.RegionClassification.net"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.BertOnlyMLMHead.__init__": [[407, 411], ["torch.nn.Module.__init__", "transformers.models.bert.modeling_bert.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.BertOnlyMLMHead.forward": [[412, 415], ["uniter.BertOnlyMLMHead.predictions"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__": [[418, 430], ["uniter.UniterPreTrainedModel.__init__", "uniter.UniterModel", "uniter.BertOnlyMLMHead", "uniter.RegionFeatureRegression", "uniter.RegionClassification", "torch.nn.Linear", "uniter.UniterForPretraining.apply"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.__init__"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.forward": [[431, 472], ["collections.defaultdict", "uniter.UniterForPretraining.forward_mlm", "uniter.UniterForPretraining.forward_mrfr", "uniter.UniterForPretraining.forward_itm", "task.startswith", "uniter.UniterForPretraining.forward_mrc", "ValueError"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.forward_mlm", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.forward_mrfr", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.forward_itm", "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.forward_mrc"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.forward_mlm": [[473, 494], ["uniter.UniterForPretraining.uniter", "uniter.UniterForPretraining._compute_masked_hidden", "uniter.UniterForPretraining.cls", "torch.nn.functional.cross_entropy", "input_ids.size"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining._compute_masked_hidden"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining._compute_masked_hidden": [[495, 500], ["mask.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "hidden[].contiguous().view", "hidden.size", "mask.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "hidden[].contiguous"], "methods", ["None"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.forward_mrfr": [[501, 521], ["uniter.UniterForPretraining.uniter", "uniter.UniterForPretraining._compute_masked_hidden", "uniter.UniterForPretraining.feat_regress", "torch.nn.functional.mse_loss"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining._compute_masked_hidden"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.forward_itm": [[522, 566], ["uniter.UniterForPretraining.uniter", "uniter.UniterForPretraining.uniter.pooler", "uniter.UniterForPretraining.itm_output", "uniter.UniterForPretraining.size", "input_ids.size", "img_feat.size", "max", "ot_scatter.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.zeros().scatter_", "ot.optimal_transport_dist().to", "ot.optimal_transport_dist().to.masked_select", "ot.optimal_transport_dist().to.masked_select", "torch.nn.functional.cross_entropy", "ot_scatter.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "torch.zeros", "ot.optimal_transport_dist", "txt_emb.float", "img_emb.float"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.ot.optimal_transport_dist"], []], "home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining.forward_mrc": [[567, 596], ["uniter.UniterForPretraining.uniter", "uniter.UniterForPretraining._compute_masked_hidden", "uniter.UniterForPretraining.region_classifier", "torch.nn.functional.log_softmax", "torch.nn.functional.kl_div", "torch.nn.functional.cross_entropy", "torch.max"], "methods", ["home.repos.pwc.inspect_result.readerbench_semeval-2022-task-5.model.uniter.UniterForPretraining._compute_masked_hidden"], []]}