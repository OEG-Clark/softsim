{"home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_wavs_transforms.rename_files": [[13, 22], ["os.listdir", "tqdm.tqdm", "os.rename", "audio_file.lower"], "function", ["None"], ["def", "rename_files", "(", "initial_folder", ":", "Path", ")", ":", "\n", "    ", "\"\"\"\n    This function makes sure all files use consistent lowercase names.\n    Inputs:\n        initial_folder: Location where the file to be renamed is found\n    \"\"\"", "\n", "audio_files", "=", "os", ".", "listdir", "(", "initial_folder", "/", "'audios'", ")", "\n", "for", "audio_file", "in", "tqdm", ".", "tqdm", "(", "audio_files", ")", ":", "\n", "        ", "os", ".", "rename", "(", "initial_folder", "/", "'audios'", "/", "audio_file", ",", "initial_folder", "/", "'audios'", "/", "audio_file", ".", "lower", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_wavs_transforms.audio_to_new_sampling": [[24, 35], ["print", "subprocess.call", "str", "str"], "function", ["None"], ["", "", "def", "audio_to_new_sampling", "(", "audio_path", ":", "Path", ",", "dest_audio_path", ":", "Path", ")", ":", "\n", "    ", "\"\"\"\n    This function resamples the initial audio file found at path \\{audio_path\\}\n    and generates a new one with 16kHz sampling rate at \\{dest_audio_path\\}\n    Inputs:\n        audio_path: Location of file to be resampled\n        dest_audio_path: Location of resampled file\n    \"\"\"", "\n", "cmd", "=", "[", "'ffmpeg'", ",", "'-i'", ",", "str", "(", "audio_path", ")", ",", "'-ar'", ",", "'16000'", ",", "'-ac'", ",", "'1'", ",", "str", "(", "dest_audio_path", ")", "]", "\n", "print", "(", "f'Running this command {cmd}'", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_wavs_transforms.resample_wavs": [[37, 77], ["dest_folder.mkdir", "os.listdir", "tqdm.tqdm", "enumerate", "os.listdir", "audio_file.lower", "os.path.exists", "kwarg_list.append", "logging.info", "multiprocessing.Pool", "zsvision.zs_multiproc.starmap_with_kwargs", "logging.info", "pool_func", "len"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir"], ["", "def", "resample_wavs", "(", "dest_folder", ":", "Path", ",", "initial_folder", ":", "Path", ",", "\n", "processes", ":", "int", ",", "logging", ")", ":", "\n", "    ", "\"\"\"\n    This function generates a list of initial paths of files to be\n    resampled and the names of the new resampled files. Then the\n    audio_to_new_sampling function is called for each file in the list.\n    Inputs:\n        dest_folder: Location where new resampled files will be saved\n        initial_folder: Location of files to be resampled\n        processes: How many files are resampled at the same time\n        logging: Logging module containing information about the script\n    \"\"\"", "\n", "(", "dest_folder", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "audio_folders", "=", "os", ".", "listdir", "(", "initial_folder", "/", "'audios'", ")", "\n", "\n", "kwarg_list", "=", "[", "]", "\n", "\n", "for", "audio_folder", "in", "tqdm", ".", "tqdm", "(", "audio_folders", ")", ":", "\n", "        ", "audio_file", "=", "os", ".", "listdir", "(", "initial_folder", "/", "'audios'", "/", "audio_folder", ")", "[", "0", "]", "\n", "audio_path", "=", "initial_folder", "/", "'audios'", "/", "audio_folder", "/", "audio_file", "\n", "dest_audio_path", "=", "dest_folder", "/", "audio_file", ".", "lower", "(", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "dest_audio_path", ")", "is", "False", ":", "\n", "            ", "kwarg_list", ".", "append", "(", "{", "'audio_path'", ":", "audio_path", ",", "\n", "'dest_audio_path'", ":", "dest_audio_path", "\n", "}", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "f'File {audio_path} already transformed'", ")", "\n", "\n", "", "", "pool_func", "=", "audio_to_new_sampling", "\n", "\n", "if", "processes", ">", "1", ":", "\n", "# The definition of the pool func must precede the creation of the pool", "\n", "# to ensure its pickleable.  We force the definition to occur by reassigning", "\n", "# the function.", "\n", "        ", "with", "mp", ".", "Pool", "(", "processes", "=", "processes", ")", "as", "pool", ":", "\n", "            ", "starmap_with_kwargs", "(", "pool", "=", "pool", ",", "func", "=", "pool_func", ",", "kwargs_iter", "=", "kwarg_list", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "idx", ",", "kwarg", "in", "enumerate", "(", "kwarg_list", ")", ":", "\n", "            ", "logging", ".", "info", "(", "f'{idx}/{len(kwarg_list)} processing kwargs '", ")", "\n", "pool_func", "(", "**", "kwarg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_wavs_transforms.main": [[79, 100], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.makedirs", "logging.basicConfig", "logging.getLogger().addHandler", "logging.StreamHandler", "sounddescs_wavs_transforms.rename_files", "logging.getLogger", "sounddescs_wavs_transforms.resample_wavs", "Exception", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_wavs_transforms.rename_files", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_wavs_transforms.resample_wavs"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--dest_folder'", ",", "type", "=", "Path", ",", "\n", "help", "=", "'Location where resampled files are saved'", ")", "\n", "parser", ".", "add_argument", "(", "'--initial_folder'", ",", "type", "=", "Path", ",", "required", "=", "True", ",", "\n", "help", "=", "'Location where files to be resampled are found'", ")", "\n", "parser", ".", "add_argument", "(", "'--exp'", ",", "default", "=", "'rename'", ",", "choices", "=", "[", "'rename'", ",", "'resample'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--processes'", ",", "type", "=", "int", ",", "default", "=", "60", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "os", ".", "makedirs", "(", "'logs'", ",", "exist_ok", "=", "True", ")", "\n", "logging", ".", "basicConfig", "(", "filename", "=", "f\"logs/{datetime.now().strftime(r'%m%d_%H%M%S')}.log\"", ",", "\n", "level", "=", "logging", ".", "INFO", ")", "\n", "logging", ".", "getLogger", "(", ")", ".", "addHandler", "(", "logging", ".", "StreamHandler", "(", ")", ")", "\n", "if", "args", ".", "exp", "==", "'rename'", ":", "\n", "        ", "rename_files", "(", "args", ".", "initial_folder", ")", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "dest_folder", "is", "not", "None", ":", "\n", "            ", "resample_wavs", "(", "args", ".", "dest_folder", ",", "args", ".", "initial_folder", ",", "\n", "args", ".", "processes", ",", "logging", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"Need to add flag --dest_folder with folder location where resampled files should be saved\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_download_audios.download_audio": [[15, 35], ["[].lower", "print", "wget.download", "print", "str", "print", "[].split", "open", "f.write", "pathlib.Path", "entry.split"], "function", ["None"], ["def", "download_audio", "(", "download_folder", ":", "Path", ",", "\n", "main_link", ":", "str", ",", "\n", "entry", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Downloading one audio file.\n    Inputs:\n        download_folder: Location where audio file is downloaded\n        main_link: Address from where audio content is downloaded\n        entry: Full link address for the specific audio file being downloaded\n    \"\"\"", "\n", "audio_id", "=", "entry", ".", "split", "(", "f\"{main_link}/\"", ")", "[", "1", "]", ".", "split", "(", "\".wav.zip\"", ")", "[", "0", "]", ".", "lower", "(", ")", "\n", "print", "(", "f'Downloading file {audio_id}.wav'", ")", "\n", "(", "download_folder", "/", "'zip_audios'", "/", "audio_id", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "try", ":", "\n", "        ", "wget", ".", "download", "(", "entry", ",", "str", "(", "download_folder", "/", "'zip_audios'", "/", "audio_id", ")", ")", "\n", "print", "(", "f'Successfully downloaded file {audio_id}.wav'", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "f'File {audio_id} could not be downloaded because of error {e}'", ")", "\n", "with", "open", "(", "Path", "(", "'error_files'", ")", "/", "f'{audio_id}.txt'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_download_audios.download_audios": [[37, 80], ["logging.info", "pathlib.Path().mkdir", "tqdm.tqdm", "open", "f.read().splitlines", "kwarg_list.append", "enumerate", "pathlib.Path", "multiprocessing.Pool", "zsvision.zs_multiproc.starmap_with_kwargs", "print", "pool_func", "pathlib.Path", "f.read", "len"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir"], ["", "", "", "def", "download_audios", "(", "download_folder", ":", "Path", ",", "main_link", ":", "str", ",", "\n", "logging", ",", "download_file", ",", "processes", ":", "int", ",", "\n", "limit", ":", "int", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Downloading all audio files from given list of links.\n    Inputs:\n        download_folder: Location where audio file is downloaded\n        main_link: Address from where audio content is downloaded\n        logging: Logging module containing information about the\n            progress of the code\n        download_file: Path of txt file containing links for audio files\n        processes: Number of processes downloading audio content at\n            the same time\n        limit: If not 0, downloading only the first \\{limit\\} adio\n            files from the list\n    \"\"\"", "\n", "logging", ".", "info", "(", "f'Creating folder {download_folder}/zip_audios'", ")", "\n", "(", "download_folder", "/", "'zip_audios'", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "(", "Path", "(", "'error_files'", ")", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "with", "open", "(", "Path", "(", "'sounddescs_data'", ")", "/", "download_file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "entries", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "if", "limit", "!=", "0", ":", "\n", "        ", "entries", "=", "entries", "[", ":", "limit", "]", "\n", "\n", "", "kwarg_list", "=", "[", "]", "\n", "for", "entry", "in", "tqdm", ".", "tqdm", "(", "entries", ")", ":", "\n", "        ", "kwarg_list", ".", "append", "(", "{", "\n", "\"download_folder\"", ":", "download_folder", ",", "\n", "\"main_link\"", ":", "main_link", ",", "\n", "\"entry\"", ":", "entry", ",", "\n", "}", ")", "\n", "\n", "", "pool_func", "=", "download_audio", "\n", "if", "processes", ">", "1", ":", "\n", "# The definition of the pool func must precede the creation of the pool", "\n", "# to ensure its pickleable.  We force the definition to occur by reassigning", "\n", "# the function.", "\n", "        ", "with", "mp", ".", "Pool", "(", "processes", "=", "processes", ")", "as", "pool", ":", "\n", "            ", "starmap_with_kwargs", "(", "pool", "=", "pool", ",", "func", "=", "pool_func", ",", "kwargs_iter", "=", "kwarg_list", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "idx", ",", "kwarg", "in", "enumerate", "(", "kwarg_list", ")", ":", "\n", "            ", "print", "(", "f\"{idx}/{len(kwarg_list)} processing kwargs \"", ")", "\n", "pool_func", "(", "**", "kwarg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_download_audios.unzip_one_file": [[82, 105], ["os.listdir", "os.path.exists", "print", "zipfile.ZipFile", "print", "zip_ref.extractall", "os.rename", "print", "os.listdir", "open", "f.write", "audio_file.lower", "pathlib.Path"], "function", ["None"], ["", "", "", "def", "unzip_one_file", "(", "download_folder", ":", "Path", ",", "audio_id", ":", "str", ",", "zip_audios", ":", "Path", ")", ":", "\n", "    ", "\"\"\"\n    Unzipping one zip file from 'zip_audios' and moving it to the 'audios' folder.\n    Inputs:\n        download_folder: Location where audio file is downloaded\n        audio_id: Name of the audio file being extracted\n        zip_audios: Location where the zip files are found\n    \"\"\"", "\n", "audio_zip", "=", "os", ".", "listdir", "(", "zip_audios", "/", "audio_id", ")", "[", "0", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "download_folder", "/", "\"audios\"", "/", "audio_id", ")", "is", "False", ":", "\n", "        ", "try", ":", "\n", "            ", "with", "zipfile", ".", "ZipFile", "(", "zip_audios", "/", "audio_id", "/", "audio_zip", ",", "'r'", ")", "as", "zip_ref", ":", "\n", "                ", "print", "(", "f\"Extracting audio file {audio_id}\"", ")", "\n", "zip_ref", ".", "extractall", "(", "download_folder", "/", "\"audios\"", "/", "audio_id", ")", "\n", "audio_file", "=", "os", ".", "listdir", "(", "download_folder", "/", "\"audios\"", "/", "audio_id", ")", "[", "0", "]", "\n", "os", ".", "rename", "(", "download_folder", "/", "\"audios\"", "/", "audio_id", "/", "audio_file", ",", "\n", "download_folder", "/", "\"audios\"", "/", "audio_id", "/", "audio_file", ".", "lower", "(", ")", ")", "\n", "", "", "except", "BadZipFile", ":", "\n", "            ", "print", "(", "f\"File {audio_id} could not be unzipped because of error BadZipFile\"", ")", "\n", "with", "open", "(", "Path", "(", "\"zip_error_files\"", ")", "/", "f\"{audio_id}.txt\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "'\\n'", ")", "\n", "", "", "", "else", ":", "\n", "        ", "print", "(", "f\"Audio file {audio_id} already extracted\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_download_audios.unzip_files": [[107, 139], ["os.listdir", "pathlib.Path().mkdir", "tqdm.tqdm", "logging.info", "kwarg_list.append", "enumerate", "pathlib.Path", "multiprocessing.Pool", "zsvision.zs_multiproc.starmap_with_kwargs", "print", "pool_func", "len"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir"], ["", "", "def", "unzip_files", "(", "download_folder", ":", "Path", ",", "processes", ":", "int", ",", "logging", ")", ":", "\n", "    ", "\"\"\"\n    Unzipping all zip files and moving them to the audios folder.\n    Inputs:\n        download_folder: Location where audio file is downloaded\n        logging: Logging module containing information about the\n            progress of the code\n    \"\"\"", "\n", "zip_audios", "=", "download_folder", "/", "'zip_audios'", "\n", "existent_audio_ids", "=", "os", ".", "listdir", "(", "zip_audios", ")", "\n", "(", "download_folder", "/", "\"audios\"", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "(", "Path", "(", "'zip_error_files'", ")", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "kwarg_list", "=", "[", "]", "\n", "for", "audio_id", "in", "tqdm", ".", "tqdm", "(", "existent_audio_ids", ")", ":", "\n", "        ", "kwarg_list", ".", "append", "(", "{", "\n", "\"download_folder\"", ":", "download_folder", ",", "\n", "\"audio_id\"", ":", "audio_id", ",", "\n", "\"zip_audios\"", ":", "zip_audios", ",", "\n", "}", ")", "\n", "", "logging", ".", "info", "(", "\"Starting unzipping files\"", ")", "\n", "\n", "pool_func", "=", "unzip_one_file", "\n", "if", "processes", ">", "1", ":", "\n", "# The definition of the pool func must precede the creation of the pool", "\n", "# to ensure its pickleable.  We force the definition to occur by reassigning", "\n", "# the function.", "\n", "        ", "with", "mp", ".", "Pool", "(", "processes", "=", "processes", ")", "as", "pool", ":", "\n", "            ", "starmap_with_kwargs", "(", "pool", "=", "pool", ",", "func", "=", "pool_func", ",", "kwargs_iter", "=", "kwarg_list", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "idx", ",", "kwarg", "in", "enumerate", "(", "kwarg_list", ")", ":", "\n", "            ", "print", "(", "f\"{idx}/{len(kwarg_list)} processing kwargs \"", ")", "\n", "pool_func", "(", "**", "kwarg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_download_audios.main": [[141, 164], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.makedirs", "logging.basicConfig", "logging.getLogger().addHandler", "logging.StreamHandler", "sounddescs_download_audios.download_audios", "sounddescs_download_audios.unzip_files", "logging.getLogger", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_download_audios.download_audios", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.sounddescs_download_audios.unzip_files"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--download_folder\"", ",", "type", "=", "Path", ",", "\n", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\"--download_file\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"download_links.txt\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--action\"", ",", "type", "=", "str", ",", "default", "=", "'download'", ",", "\n", "choices", "=", "[", "'download'", ",", "'unzipping'", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--limit\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--processes\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--main_link\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"https://sound-effects-media.bbcrewind.co.uk/zip\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "os", ".", "makedirs", "(", "'logs'", ",", "exist_ok", "=", "True", ")", "\n", "logging", ".", "basicConfig", "(", "filename", "=", "f\"logs/{datetime.now().strftime(r'%m%d_%H%M%S')}.log\"", ",", "\n", "level", "=", "logging", ".", "INFO", ")", "\n", "logging", ".", "getLogger", "(", ")", ".", "addHandler", "(", "logging", ".", "StreamHandler", "(", ")", ")", "\n", "if", "args", ".", "action", "==", "'download'", ":", "\n", "        ", "download_audios", "(", "args", ".", "download_folder", ",", "args", ".", "main_link", ",", "\n", "logging", ",", "args", ".", "download_file", ",", "args", ".", "processes", ",", "\n", "args", ".", "limit", ")", "\n", "", "else", ":", "\n", "        ", "unzip_files", "(", "args", ".", "download_folder", ",", "args", ".", "processes", ",", "logging", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.eval.extracting_log_info": [[16, 41], ["collections.defaultdict", "collections.defaultdict", "logging.info", "list", "open", "f.write", "open", "f.read().splitlines", "collections.defaultdict.keys", "metrics_t2v[].append", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "pathlib.Path", "pathlib.Path", "f.read", "[].split", "float", "metrics_v2t[].append", "[].split", "float", "[].split", "line.split", "[].split", "line.split", "line.split", "line.split"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["def", "extracting_log_info", "(", "log_files", ",", "experiment", ",", "logging", ")", ":", "\n", "    ", "metrics_t2v", "=", "defaultdict", "(", "list", ")", "\n", "metrics_v2t", "=", "defaultdict", "(", "list", ")", "\n", "\n", "for", "file_name", "in", "log_files", ":", "\n", "        ", "output_string", "=", "f\"{experiment}:\\n\"", "\n", "with", "open", "(", "Path", "(", "\"./logs_eval\"", ")", "/", "file_name", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "content_lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "content_lines", "=", "content_lines", "[", "-", "14", ":", "]", "\n", "for", "line", "in", "content_lines", ":", "\n", "            ", "if", "'t2v'", "in", "line", ":", "\n", "                ", "metric_entry", "=", "line", ".", "split", "(", "'test_t2v_metrics_'", ")", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "0", "]", "\n", "metrics_t2v", "[", "metric_entry", "]", ".", "append", "(", "float", "(", "line", ".", "split", "(", "'test_t2v_metrics_'", ")", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "1", "]", ")", ")", "\n", "", "elif", "'v2t'", "in", "line", ":", "\n", "                ", "metric_entry", "=", "line", ".", "split", "(", "'test_v2t_metrics_'", ")", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "0", "]", "\n", "metrics_v2t", "[", "metric_entry", "]", ".", "append", "(", "float", "(", "line", ".", "split", "(", "'test_v2t_metrics_'", ")", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "1", "]", ")", ")", "\n", "", "", "keys", "=", "list", "(", "metrics_t2v", ".", "keys", "(", ")", ")", "\n", "\n", "", "for", "key", "in", "keys", ":", "\n", "        ", "output_string", "+=", "f\"{key}_t2v: {np.mean(metrics_t2v[key]):.1f}, {np.std(metrics_t2v[key], ddof=1):.1f}\\n\"", "\n", "", "for", "key", "in", "keys", ":", "\n", "        ", "output_string", "+=", "f\"{key}_v2t: {np.mean(metrics_v2t[key]):.1f}, {np.std(metrics_v2t[key], ddof=1):.1f}\\n\"", "\n", "", "logging", ".", "info", "(", "output_string", ")", "\n", "with", "open", "(", "Path", "(", "\"logs_eval\"", ")", "/", "f\"{experiment}_summary.txt\"", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "output_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.eval.run_exp": [[42, 46], ["logging.info", "eval.run_one_exp"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.eval.run_one_exp"], ["", "", "def", "run_exp", "(", "experiments", ",", "logging", ")", ":", "\n", "    ", "for", "experiment", "in", "experiments", ":", "\n", "        ", "logging", ".", "info", "(", "f\"Now running {experiment}\"", ")", "\n", "run_one_exp", "(", "experiment", ",", "experiments", ",", "logging", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.eval.download_configs": [[48, 58], ["wget.download", "int", "pathlib.Path", "open", "json.load", "open", "json.dump", "str"], "function", ["None"], ["", "", "def", "download_configs", "(", "experiment", ",", "trained_model_path", ",", "group_id", ",", "seed", ",", "timestamp", ")", ":", "\n", "    ", "new_folder", "=", "trained_model_path", ".", "parent", "\n", "url_config", "=", "f\"http://www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/{experiment}/{group_id}/{seed}/{timestamp}/config.json\"", "\n", "config_path", "=", "Path", "(", "new_folder", ")", "/", "'config.json'", "\n", "wget", ".", "download", "(", "url_config", ",", "out", "=", "str", "(", "config_path", ")", ")", "\n", "with", "open", "(", "config_path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "config_content", "=", "json", ".", "load", "(", "f", ")", "\n", "", "config_content", "[", "'seed'", "]", "=", "int", "(", "seed", "[", "-", "1", "]", ")", "\n", "with", "open", "(", "config_path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "config_content", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.eval.download_models": [[60, 75], ["os.path.exists", "logging.info", "new_folder.mkdir", "wget.download", "logging.info", "os.path.exists", "eval.download_configs", "logging.info", "str"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.eval.download_configs"], ["", "", "def", "download_models", "(", "experiment", ",", "logging", ",", "trained_model_path", ",", "\n", "group_id", ",", "seed", ",", "timestamp", ")", ":", "\n", "    ", "new_folder", "=", "trained_model_path", ".", "parent", "\n", "if", "os", ".", "path", ".", "exists", "(", "trained_model_path", ")", "is", "False", ":", "\n", "        ", "logging", ".", "info", "(", "f\"Downloading model for {seed} since it does not exist on the local machine\"", ")", "\n", "url", "=", "f\"http://www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data/models/{experiment}/{group_id}/{seed}/{timestamp}/trained_model.pth\"", "\n", "# import pdb; pdb.set_trace()", "\n", "new_folder", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "wget", ".", "download", "(", "url", ",", "out", "=", "str", "(", "trained_model_path", ")", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "f\"Model already downloaded for {experiment} seed {seed}\"", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "new_folder", "/", "'config.json'", ")", "is", "False", ":", "\n", "        ", "download_configs", "(", "experiment", ",", "trained_model_path", ",", "group_id", ",", "seed", ",", "timestamp", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "f\"Config already downloaded for {experiment} seed {seed}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.eval.run_one_exp": [[76, 112], ["subprocess.call", "logging.info", "eval.extracting_log_info", "open", "json.load", "logging.info", "pathlib.Path().mkdir", "eval.download_models", "log_files.append", "logging.info", "subprocess.call", "pathlib.Path", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.eval.extracting_log_info", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.train.download_models"], ["", "", "def", "run_one_exp", "(", "experiment", ",", "experiments", ",", "logging", ")", ":", "\n", "    ", "if", "'mmt'", "in", "experiment", ":", "\n", "        ", "if", "'clotho'", "in", "experiment", ":", "\n", "            ", "ds", "=", "'Clotho'", "\n", "", "elif", "'audiocaps'", "in", "experiment", ":", "\n", "            ", "ds", "=", "'AudioCaps'", "\n", "", "elif", "'sounddescs'", "in", "experiment", ":", "\n", "            ", "ds", "=", "'SoundDescs'", "\n", "", "cmd", "=", "f\"python mmt/train.py --only_eval --config mmt/configs/%s_mmt.json --experiment %s\"", "%", "(", "ds", ",", "experiment", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "group_id", "=", "experiments", "[", "experiment", "]", "[", "0", "]", "\n", "\n", "with", "open", "(", "'exp_to_seed_time.json'", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "json_dict", "=", "json", ".", "load", "(", "f", ")", "\n", "", "log_files", "=", "[", "]", "\n", "for", "(", "group_id", ",", "seed", ",", "timestamp", ")", "in", "json_dict", "[", "experiment", "]", ":", "\n", "\n", "            ", "group_id_path", "=", "Path", "(", "\"data/saved/models\"", ")", "/", "experiment", "/", "group_id", "\n", "logging", ".", "info", "(", "\"Running evaluation on existent seeds\"", ")", "\n", "(", "Path", "(", "\"logs_eval\"", ")", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "trained_model_path", "=", "group_id_path", "/", "seed", "/", "timestamp", "/", "'trained_model.pth'", "\n", "download_models", "(", "experiment", ",", "logging", ",", "trained_model_path", ",", "\n", "group_id", ",", "seed", ",", "timestamp", ")", "\n", "config_path", "=", "group_id_path", "/", "seed", "/", "timestamp", "/", "'config.json'", "\n", "\n", "cmd", "=", "f\"python test.py --config {config_path} --resume {trained_model_path} --device 0 --eval_from_training_config 2>&1 | tee logs_eval/log_{group_id}_{seed}.txt\"", "\n", "# if using windows, comment the line above and uncomment the line below", "\n", "# cmd = f\"python test.py --config {config_path} --resume {trained_model_path} --device 0 --eval_from_training_config 2>&1 | wtee logs_eval/log_{group_id}_{seed}.txt\"", "\n", "\n", "log_files", ".", "append", "(", "f\"log_{group_id}_{seed}.txt\"", ")", "\n", "logging", ".", "info", "(", "cmd", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ")", "\n", "", "logging", ".", "info", "(", "\"Now averaging results\"", ")", "\n", "\n", "extracting_log_info", "(", "log_files", ",", "experiment", ",", "logging", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.eval.main": [[114, 146], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.makedirs", "logging.basicConfig", "logging.getLogger().addHandler", "logging.info", "logging.StreamHandler", "open", "json.load", "eval.run_exp", "eval.run_one_exp", "logging.getLogger", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.train.run_exp", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.eval.run_one_exp"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--experiments_path\"", ",", "default", "=", "\"misc/experiments-audiocaps.json\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--experiment\"", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "type", "=", "Path", ",", "\n", "default", "=", "\"data\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"data\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--refresh\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "os", ".", "makedirs", "(", "'logs'", ",", "exist_ok", "=", "True", ")", "\n", "logging", ".", "basicConfig", "(", "filename", "=", "f\"logs/{datetime.now().strftime(r'%m%d_%H%M%S')}.log\"", ",", "\n", "level", "=", "logging", ".", "INFO", ")", "\n", "logging", ".", "getLogger", "(", ")", ".", "addHandler", "(", "logging", ".", "StreamHandler", "(", ")", ")", "\n", "logging", ".", "info", "(", "args", ")", "\n", "\n", "with", "open", "(", "args", ".", "experiments_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "experiments", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "args", ".", "experiment", "is", "None", ":", "\n", "        ", "run_exp", "(", "experiments", ",", "logging", ")", "\n", "", "else", ":", "\n", "        ", "run_one_exp", "(", "args", ".", "experiment", ",", "experiments", ",", "logging", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.train.run_exp": [[33, 177], ["warnings.filterwarnings", "config.get_logger", "pathlib.Path().parent.mkdir", "utils.util.compute_dims", "utils.util.compute_trn_config", "socket.gethostname().endswith", "enumerate", "print", "print", "open", "print", "os.system", "time.time", "config.get_logger.info", "utils.set_seeds", "config.init", "config.get_logger.info", "config.init", "config.get", "config.init", "filter", "utils.util.update_src_web_video_dir", "config.init", "trainer.Trainer", "trainer.Trainer.train", "time.strftime", "config.get_logger.info", "config._config.get", "len", "logger.log_parser.log_summary", "int", "int", "socket.gethostname", "str", "config.get_logger.info", "config.init.apply", "getattr", "config.init.parameters", "config.init", "config.init", "config.init", "time.gmtime", "copy.deepcopy", "mergedeep.merge", "test.evaluation", "pathlib.Path", "config._args.seeds.split", "[].get", "config.get", "config[].get", "[].get", "config.get", "config[].get", "config.get", "config.get", "config.get", "config.get", "config.get", "config[].get", "isinstance", "config.init", "config[].get", "config.get", "config.get", "config.get", "config[].get", "config[].get", "set", "str", "pathlib.Path.home", "len", "torch.nn.init.xavier_uniform", "torch.nn.init.xavier_uniform", "m.bias.data.fill_", "config.init", "config.init", "config.get", "time.time"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.get_logger", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.compute_dims", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.compute_trn_config", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.set_seeds", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.update_src_web_video_dir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer.train", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.logger.log_parser.log_summary", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.test.evaluation", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["def", "run_exp", "(", "config", ")", ":", "\n", "    ", "warnings", ".", "filterwarnings", "(", "'ignore'", ")", "\n", "logger", "=", "config", ".", "get_logger", "(", "'train'", ")", "\n", "\n", "leaderboard_path", "=", "config", ".", "_args", ".", "leaderboard", "\n", "Path", "(", "leaderboard_path", ")", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "with", "open", "(", "leaderboard_path", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "txt_path", "=", "f\"{config._log_dir}/preds.txt\"", "\n", "print", "(", "txt_path", ",", "file", "=", "f", ",", "flush", "=", "True", ")", "\n", "\n", "", "expert_dims", ",", "raw_input_dims", ",", "text_dim", "=", "compute_dims", "(", "config", ",", "logger", ")", "\n", "trn_config", "=", "compute_trn_config", "(", "config", ")", "\n", "\n", "if", "config", ".", "_args", ".", "group_seed", ":", "\n", "        ", "seeds", "=", "[", "int", "(", "config", ".", "_args", ".", "group_seed", ")", "]", "\n", "", "else", ":", "\n", "        ", "seeds", "=", "[", "int", "(", "x", ")", "for", "x", "in", "config", ".", "_args", ".", "seeds", ".", "split", "(", "\",\"", ")", "]", "\n", "\n", "# set up local filesystem on the cluster", "\n", "", "if", "socket", ".", "gethostname", "(", ")", ".", "endswith", "(", "\"cluster\"", ")", ":", "\n", "        ", "os", ".", "system", "(", "str", "(", "Path", ".", "home", "(", ")", "/", "\"configure_tmp_data.sh\"", ")", ")", "\n", "\n", "", "for", "ii", ",", "seed", "in", "enumerate", "(", "seeds", ")", ":", "\n", "        ", "tic", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "f\"{ii + 1}/{len(seeds)} Setting experiment random seed to {seed}\"", ")", "\n", "set_seeds", "(", "seed", ")", "\n", "config", "[", "\"seed\"", "]", "=", "seed", "\n", "\n", "model", "=", "config", ".", "init", "(", "\n", "name", "=", "'arch'", ",", "\n", "module", "=", "module_arch", ",", "\n", "expert_dims", "=", "expert_dims", ",", "\n", "text_dim", "=", "text_dim", ",", "\n", "disable_nan_checks", "=", "config", "[", "\"disable_nan_checks\"", "]", ",", "\n", "spatial_feats", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", ".", "get", "(", "\"spatial_feats\"", ",", "False", ")", ",", "\n", "task", "=", "config", ".", "get", "(", "\"task\"", ",", "\"retrieval\"", ")", ",", "\n", "ce_shared_dim", "=", "config", "[", "\"experts\"", "]", ".", "get", "(", "\"ce_shared_dim\"", ",", "None", ")", ",", "\n", "feat_aggregation", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"feat_aggregation\"", "]", ",", "\n", "trn_config", "=", "trn_config", ",", "\n", "trn_cat", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", ".", "get", "(", "\"trn_cat\"", ",", "0", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "model", ")", "\n", "\n", "data_loaders", "=", "config", ".", "init", "(", "\n", "name", "=", "'data_loader'", ",", "\n", "module", "=", "module_data", ",", "\n", "logger", "=", "logger", ",", "\n", "raw_input_dims", "=", "raw_input_dims", ",", "\n", "challenge_mode", "=", "config", ".", "get", "(", "\"challenge_mode\"", ",", "False", ")", ",", "\n", "text_dim", "=", "text_dim", ",", "\n", "text_feat", "=", "config", "[", "\"experts\"", "]", "[", "\"text_feat\"", "]", ",", "\n", "text_agg", "=", "config", "[", "\"experts\"", "]", "[", "\"text_agg\"", "]", ",", "\n", "use_zeros_for_missing", "=", "config", "[", "\"experts\"", "]", ".", "get", "(", "\"use_zeros_for_missing\"", ",", "False", ")", ",", "\n", "task", "=", "config", ".", "get", "(", "\"task\"", ",", "\"retrieval\"", ")", ",", "\n", "eval_only", "=", "False", ",", "\n", "distil_params", "=", "config", ".", "get", "(", "\"distil_params\"", ",", "None", ")", ",", "\n", "training_file", "=", "config", ".", "get", "(", "\"training_file\"", ",", "None", ")", ",", "\n", "testing_file", "=", "config", ".", "get", "(", "\"testing_file\"", ",", "None", ")", ",", "\n", "caption_masks", "=", "config", ".", "get", "(", "\"caption_masks\"", ",", "None", ")", ",", "\n", "ce_shared_dim", "=", "config", "[", "\"experts\"", "]", ".", "get", "(", "\"ce_shared_dim\"", ",", "None", ")", ",", "\n", ")", "\n", "\n", "if", "config", ".", "get", "(", "\"manual_linear_init\"", ",", "False", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"manually setting init for linear layers\"", ")", "\n", "\n", "def", "init_weights", "(", "m", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "xavier_uniform", "(", "m", ".", "weight", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0.01", ")", "\n", "", "", "model", ".", "apply", "(", "init_weights", ")", "\n", "\n", "", "loss", "=", "config", ".", "init", "(", "name", "=", "\"loss\"", ",", "module", "=", "module_loss", ")", "\n", "metrics", "=", "[", "getattr", "(", "module_metric", ",", "met", ")", "for", "met", "in", "config", "[", "'metrics'", "]", "]", "\n", "trainable_params", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "if", "config", "[", "\"optimizer\"", "]", "[", "\"type\"", "]", "==", "\"RAdam\"", ":", "\n", "            ", "optimizer", "=", "config", ".", "init", "(", "'optimizer'", ",", "radam", ",", "trainable_params", ")", "\n", "", "elif", "config", "[", "\"optimizer\"", "]", "[", "\"type\"", "]", "==", "\"Ranger\"", ":", "\n", "            ", "optimizer", "=", "config", ".", "init", "(", "'optimizer'", ",", "ranger", ",", "trainable_params", ")", "\n", "", "elif", "config", "[", "\"optimizer\"", "]", "[", "\"type\"", "]", "==", "\"SWATS\"", ":", "\n", "            ", "optimizer", "=", "config", ".", "init", "(", "'optimizer'", ",", "swats", ",", "trainable_params", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "config", ".", "init", "(", "'optimizer'", ",", "torch", ".", "optim", ",", "trainable_params", ")", "\n", "\n", "", "if", "config", "[", "\"lr_scheduler\"", "]", "[", "\"type\"", "]", "==", "\"StepLR\"", ":", "\n", "            ", "lr_scheduler", "=", "config", ".", "init", "(", "'lr_scheduler'", ",", "torch", ".", "optim", ".", "lr_scheduler", ",", "\n", "optimizer", ")", "\n", "", "else", ":", "\n", "            ", "lr_scheduler", "=", "config", ".", "init", "(", "'lr_scheduler'", ",", "cos_restart", ",", "optimizer", ")", "\n", "\n", "", "update_src_web_video_dir", "(", "config", ")", "\n", "visualizer", "=", "config", ".", "init", "(", "\n", "name", "=", "'visualizer'", ",", "\n", "module", "=", "module_vis", ",", "\n", "exp_name", "=", "config", ".", "_exper_name", ",", "\n", "web_dir", "=", "config", ".", "_web_log_dir", ",", "\n", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "\n", "model", ",", "\n", "loss", ",", "\n", "metrics", ",", "\n", "optimizer", ",", "\n", "config", "=", "config", ",", "\n", "data_loaders", "=", "data_loaders", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "mini_train", "=", "config", ".", "_args", ".", "mini_train", ",", "\n", "disable_nan_checks", "=", "config", "[", "\"disable_nan_checks\"", "]", ",", "\n", "visualizer", "=", "visualizer", ",", "\n", "val_freq", "=", "config", "[", "\"trainer\"", "]", ".", "get", "(", "\"val_freq\"", ",", "1", ")", ",", "\n", "distil_loss", "=", "config", ".", "get", "(", "\"distil_loss\"", ",", "False", ")", ",", "\n", "distil_params", "=", "config", ".", "get", "(", "\"distil_params\"", ",", "None", ")", ",", "\n", "force_cpu_val", "=", "config", ".", "get", "(", "\"force_cpu_val\"", ",", "False", ")", ",", "\n", "skip_first_n_saves", "=", "config", "[", "\"trainer\"", "]", ".", "get", "(", "\"skip_first_n_saves\"", ",", "0", ")", ",", "\n", "include_optim_in_ckpts", "=", "config", "[", "\"trainer\"", "]", ".", "get", "(", "\"include_optim_in_ckpts\"", ",", "1", ")", ",", "\n", "cache_targets", "=", "set", "(", "config", ".", "get", "(", "\"cache_targets\"", ",", "[", "]", ")", ")", ",", "\n", ")", "\n", "trainer", ".", "train", "(", ")", "\n", "best_ckpt_path", "=", "config", ".", "save_dir", "/", "\"trained_model.pth\"", "\n", "duration", "=", "time", ".", "strftime", "(", "'%Hh%Mm%Ss'", ",", "time", ".", "gmtime", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "logger", ".", "info", "(", "f\"Training took {duration}\"", ")", "\n", "\n", "if", "config", ".", "_config", ".", "get", "(", "\"eval_settings\"", ",", "False", ")", ":", "\n", "# import pdb; pdb.set_trace()", "\n", "            ", "eval_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "merge", "(", "eval_config", ".", "_config", ",", "config", "[", "\"eval_settings\"", "]", ",", "strategy", "=", "Strategy", ".", "REPLACE", ")", "\n", "eval_config", ".", "_args", ".", "resume", "=", "best_ckpt_path", "\n", "evaluation", "(", "eval_config", ",", "logger", "=", "logger", ",", "trainer", "=", "trainer", ")", "\n", "\n", "# If multiple runs were conducted, report relevant statistics", "\n", "", "", "if", "len", "(", "seeds", ")", ">", "1", ":", "\n", "        ", "log_summary", "(", "\n", "logger", "=", "logger", ",", "\n", "log_path", "=", "config", ".", "log_path", ",", "\n", "eval_mode", "=", "config", "[", "\"eval_mode\"", "]", ",", "\n", "fixed_num_epochs", "=", "config", "[", "\"trainer\"", "]", "[", "\"epochs\"", "]", ",", "\n", ")", "\n", "", "print", "(", "f\"Log file stored at {config.log_path}\"", ")", "\n", "\n", "# Report the location of the \"best\" checkpoint of the final seeded run (here", "\n", "# \"best\" corresponds to the model with the highest geometric mean over the", "\n", "# R@1, R@5 and R@10 metrics when a validation set is used, or simply the final", "\n", "# epoch of training for fixed-length schedules).", "\n", "print", "(", "f\"The best performing ckpt can be found at {str(best_ckpt_path)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.train.main": [[178, 213], ["argparse.ArgumentParser", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_argument", "parse_config.ConfigParser.add_mutually_exclusive_group", "args.add_mutually_exclusive_group.add_argument", "args.add_mutually_exclusive_group.add_argument", "parse_config.ConfigParser", "print", "print", "train.run_exp"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.train.run_exp"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Main entry point for training'", ")", "\n", "args", ".", "add_argument", "(", "'--config'", ",", "help", "=", "'config file path'", ")", "\n", "args", ".", "add_argument", "(", "'--resume'", ",", "help", "=", "'path to latest checkpoint (default: None)'", ")", "\n", "args", ".", "add_argument", "(", "'--finetune'", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'set to true if finetuning (default: None)'", ")", "\n", "args", ".", "add_argument", "(", "'--leaderboard'", ",", "default", "=", "\"data/leaderboards/exp.txt\"", ",", "\n", "help", "=", "'path we want to draw on leadboard'", ")", "\n", "args", ".", "add_argument", "(", "'--device'", ",", "help", "=", "\"indices of GPUs to enable\"", ")", "\n", "args", ".", "add_argument", "(", "'--mini_train'", ",", "action", "=", "\"store_true\"", ")", "\n", "args", ".", "add_argument", "(", "'--group_id'", ",", "help", "=", "\"if supplied, group these experiments\"", ")", "\n", "args", ".", "add_argument", "(", "'--disable_workers'", ",", "action", "=", "\"store_true\"", ")", "\n", "args", ".", "add_argument", "(", "'--refresh_lru_cache'", ",", "action", "=", "\"store_true\"", ")", "\n", "args", ".", "add_argument", "(", "'--train_single_epoch'", ",", "action", "=", "\"store_true\"", ")", "\n", "args", ".", "add_argument", "(", "'--purge_exp_dir'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"remove all previous experiments with the given config\"", ")", "\n", "args", ".", "add_argument", "(", "\"--dbg\"", ",", "default", "=", "\"ipdb.set_trace\"", ")", "\n", "args", ".", "add_argument", "(", "\"--custom_args\"", ",", "help", "=", "\"qualified key,val pairs\"", ")", "\n", "\n", "# Seeds can either be passed directly as a comma separated list at the command line,", "\n", "# or individually for separate experiments as a group (used for slurm experiments)", "\n", "seed_args", "=", "args", ".", "add_mutually_exclusive_group", "(", ")", "\n", "seed_args", ".", "add_argument", "(", "'--seeds'", ",", "default", "=", "\"0\"", ",", "help", "=", "\"comma separated list of seeds\"", ")", "\n", "seed_args", ".", "add_argument", "(", "'--group_seed'", ",", "help", "=", "\"seed for group member\"", ")", "\n", "\n", "args", "=", "ConfigParser", "(", "args", ")", "\n", "\n", "os", ".", "environ", "[", "\"PYTHONBREAKPOINT\"", "]", "=", "args", ".", "_args", ".", "dbg", "\n", "args", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"refresh_lru_cache\"", "]", "=", "args", ".", "_args", ".", "refresh_lru_cache", "\n", "msg", "=", "(", "f\"Expected the number of training epochs ({args['trainer']['epochs']})\"", "\n", "f\"to exceed the save period ({args['trainer']['save_period']}), otherwise\"", "\n", "\" no checkpoints will be saved.\"", ")", "\n", "assert", "args", "[", "\"trainer\"", "]", "[", "\"epochs\"", "]", ">=", "args", "[", "\"trainer\"", "]", "[", "\"save_period\"", "]", ",", "msg", "\n", "print", "(", "\"Launching experiment with config:\"", ")", "\n", "print", "(", "args", ")", "\n", "run_exp", "(", "config", "=", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.test.compress_predictions": [[29, 54], ["numpy.argsort", "query_masks.flatten().astype", "query_masks.flatten"], "function", ["None"], ["@", "typechecked", "\n", "def", "compress_predictions", "(", "query_masks", ":", "np", ".", "ndarray", ",", "sims", ":", "np", ".", "ndarray", ",", "topk", ":", "int", "=", "10", ")", ":", "\n", "    ", "\"\"\"We store the indices of the top-k predictions, rather than the full similarity\n    matrix, to reduce storage requirements.\n\n    NOTE: The similarity matrix contains `num_queries x num_videos` elements, where\n    `num_queries = num_videos x max_num_queries_per_video`.  We first mask out\n    locations in the similarity matrix that correspond to invalid queries (these are\n    produced by videos with fewer than `max_num_queries_per_video` descriptions).\n    \"\"\"", "\n", "\n", "# validate the input shapes", "\n", "assert", "query_masks", ".", "ndim", "==", "2", ",", "\"Expected query_masks to be a matrix\"", "\n", "query_num_videos", ",", "query_max_per_video", "=", "query_masks", ".", "shape", "\n", "sims_queries", ",", "sims_num_videos", "=", "sims", ".", "shape", "\n", "msg", "=", "(", "f\"Expected sims and query masks to represent the same number of videos \"", "\n", "f\"(found {sims_num_videos} v {query_num_videos}\"", ")", "\n", "assert", "query_num_videos", "==", "sims_num_videos", ",", "msg", "\n", "msg", "=", "(", "f\"Expected sims and query masks to represent the same number of queries \"", "\n", "f\"(found {sims_queries} v {query_num_videos * query_max_per_video}\"", ")", "\n", "assert", "query_max_per_video", "*", "query_num_videos", "==", "sims_queries", ",", "msg", "\n", "\n", "valid_sims", "=", "sims", "[", "query_masks", ".", "flatten", "(", ")", ".", "astype", "(", "np", ".", "bool", ")", "]", "\n", "ranks", "=", "np", ".", "argsort", "(", "-", "valid_sims", ",", "axis", "=", "1", ")", "\n", "return", "ranks", "[", ":", ",", ":", "topk", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.test.get_model_and_data_loaders": [[56, 114], ["utils.util.compute_dims", "config.init", "utils.util.compute_trn_config", "config.init", "logger.info", "torch.load", "torch.nn.DataParallel.load_state_dict", "torch.nn.DataParallel", "config.get", "config[].get", "config.get", "config.get", "config.get", "config.get", "config.get", "config[].get", "config.get", "config[].get", "[].get", "print", "state_dict.pop"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.compute_dims", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.compute_trn_config", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["", "@", "typechecked", "\n", "def", "get_model_and_data_loaders", "(", "\n", "config", ":", "ConfigParser", ",", "\n", "logger", ":", "logging", ".", "Logger", ",", "\n", "ckpt_path", ":", "Path", ",", "\n", "device", ":", "str", "\n", ")", "->", "Tuple", "[", "torch", ".", "nn", ".", "Module", ",", "module_data", ".", "ExpertDataLoader", "]", ":", "\n", "    ", "expert_dims", ",", "raw_input_dims", ",", "text_dim", "=", "compute_dims", "(", "config", ")", "\n", "\n", "data_loaders", "=", "config", ".", "init", "(", "\n", "name", "=", "'data_loader'", ",", "\n", "module", "=", "module_data", ",", "\n", "logger", "=", "logger", ",", "\n", "raw_input_dims", "=", "raw_input_dims", ",", "\n", "challenge_mode", "=", "config", ".", "get", "(", "\"challenge_mode\"", ",", "False", ")", ",", "\n", "text_dim", "=", "text_dim", ",", "\n", "text_feat", "=", "config", "[", "\"experts\"", "]", "[", "\"text_feat\"", "]", ",", "\n", "text_agg", "=", "config", "[", "\"experts\"", "]", "[", "\"text_agg\"", "]", ",", "\n", "use_zeros_for_missing", "=", "config", "[", "\"experts\"", "]", ".", "get", "(", "\"use_zeros_for_missing\"", ",", "False", ")", ",", "\n", "task", "=", "config", ".", "get", "(", "\"task\"", ",", "\"retrieval\"", ")", ",", "\n", "eval_only", "=", "True", ",", "\n", "distil_params", "=", "config", ".", "get", "(", "\"distil_params\"", ",", "None", ")", ",", "\n", "training_file", "=", "config", ".", "get", "(", "\"training_file\"", ",", "None", ")", ",", "\n", "testing_file", "=", "config", ".", "get", "(", "\"testing_file\"", ",", "None", ")", ",", "\n", "caption_masks", "=", "config", ".", "get", "(", "\"caption_masks\"", ",", "None", ")", ",", "\n", "ce_shared_dim", "=", "config", "[", "\"experts\"", "]", ".", "get", "(", "\"ce_shared_dim\"", ",", "None", ")", ",", "\n", ")", "\n", "\n", "trn_config", "=", "compute_trn_config", "(", "config", ")", "\n", "model", "=", "config", ".", "init", "(", "\n", "name", "=", "'arch'", ",", "\n", "module", "=", "module_arch", ",", "\n", "trn_config", "=", "trn_config", ",", "\n", "expert_dims", "=", "expert_dims", ",", "\n", "text_dim", "=", "text_dim", ",", "\n", "disable_nan_checks", "=", "config", "[", "\"disable_nan_checks\"", "]", ",", "\n", "task", "=", "config", ".", "get", "(", "\"task\"", ",", "\"retrieval\"", ")", ",", "\n", "ce_shared_dim", "=", "config", "[", "\"experts\"", "]", ".", "get", "(", "\"ce_shared_dim\"", ",", "None", ")", ",", "\n", "feat_aggregation", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"feat_aggregation\"", "]", ",", "\n", "trn_cat", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", ".", "get", "(", "\"trn_cat\"", ",", "0", ")", ",", "\n", ")", "\n", "ckpt_path", "=", "config", ".", "_args", ".", "resume", "\n", "logger", ".", "info", "(", "f\"Loading checkpoint: {ckpt_path} ...\"", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "ckpt_path", ",", "map_location", "=", "device", ")", "\n", "state_dict", "=", "checkpoint", "[", "'state_dict'", "]", "\n", "if", "config", "[", "'n_gpu'", "]", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "# support backwards compatibility", "\n", "", "deprecated", "=", "[", "\"ce.moe_fc_bottleneck1\"", ",", "\"ce.moe_cg\"", ",", "\"ce.moe_fc_proj\"", "]", "\n", "for", "mod", "in", "deprecated", ":", "\n", "        ", "for", "suffix", "in", "(", "\"weight\"", ",", "\"bias\"", ")", ":", "\n", "            ", "key", "=", "f\"{mod}.{suffix}\"", "\n", "if", "key", "in", "state_dict", ":", "\n", "                ", "print", "(", "f\"WARNING: Removing deprecated key {key} from model\"", ")", "\n", "state_dict", ".", "pop", "(", "key", ")", "\n", "", "", "", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "return", "model", ",", "data_loaders", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.test.evaluation": [[115, 251], ["getattr", "getattr", "config.get_logger.info", "config.get_logger.info", "config.get_logger.info", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "config.get_logger.info", "test.get_model_and_data_loaders", "config.get_logger.info", "utils.util.update_src_web_video_dir", "config.init", "config.get", "model.to.to", "model.to.eval", "nested_metrics.items", "log.items", "config.get_logger", "copy.deepcopy", "mergedeep.merge", "torch.cuda.is_available", "getattr", "torch.no_grad", "getattr", "output[].data.cpu().float().numpy", "config.init.visualize_ranking", "subval.items", "config.get_logger.info", "[].split", "open", "f.read().splitlines", "config.get", "pathlib.Path", "numpy.zeros", "numpy.zeros", "enumerate", "trainer.ctxt_mgr", "model.to.", "test.compress_predictions", "numpy.savetxt", "print", "print", "metric", "trainer.verbose", "len", "output[].data.cpu().float", "trainer.log_metrics", "str", "pathlib.Path", "f.read", "[].split", "numpy.ones", "numpy.array", "trainer.writer.set_step", "config._args.config.split", "output[].data.cpu", "video_name.split"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.test.get_model_and_data_loaders", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.update_src_web_video_dir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.get_logger", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.visualizer.Visualizer.visualize_ranking", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.ctxt_mgr", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.compress_predictions", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.verbose", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer.log_metrics", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.logger.visualization.TensorboardWriter.set_step"], ["", "def", "evaluation", "(", "config", ",", "logger", "=", "None", ",", "trainer", "=", "None", ")", ":", "\n", "\n", "    ", "if", "getattr", "(", "config", ".", "_args", ",", "\"per_class\"", ",", "False", ")", ":", "\n", "        ", "name_test_txt", "=", "config", ".", "_args", ".", "config", ".", "split", "(", "'configs/audiocaps/train-vggish-vggsound-'", ")", "[", "1", "]", ".", "split", "(", "'.json'", ")", "[", "0", "]", "\n", "name_test_txt", "=", "f\"{name_test_txt}.txt\"", "\n", "with", "open", "(", "Path", "(", "'data/AudioCaps/structured-symlinks'", ")", "/", "name_test_txt", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "relevant_ids", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "", "if", "logger", "is", "None", ":", "\n", "        ", "logger", "=", "config", ".", "get_logger", "(", "'test'", ")", "\n", "\n", "", "if", "getattr", "(", "config", ".", "_args", ",", "\"eval_from_training_config\"", ",", "False", ")", ":", "\n", "        ", "eval_conf", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "merge", "(", "eval_conf", ".", "_config", ",", "config", "[", "\"eval_settings\"", "]", ",", "strategy", "=", "Strategy", ".", "REPLACE", ")", "\n", "config", "=", "eval_conf", "\n", "\n", "", "logger", ".", "info", "(", "\"Running evaluation with configuration:\"", ")", "\n", "logger", ".", "info", "(", "config", ")", "\n", "\n", "# Set the random initial seeds", "\n", "seed", "=", "config", "[", "\"seed\"", "]", "\n", "logger", ".", "info", "(", "f\"Setting experiment random seed to {seed}\"", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "torch", ".", "backends", ".", "cudnn", ".", "enabled", "=", "False", "\n", "\n", "# prepare model for testing.  Note that some datasets fail to fit the retrieval", "\n", "# set on the GPU, so we run them on the CPU", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "config", ".", "get", "(", "\"disable_gpu\"", ",", "True", ")", ":", "\n", "        ", "device", "=", "\"cuda\"", "\n", "", "else", ":", "\n", "        ", "device", "=", "\"cpu\"", "\n", "\n", "", "logger", ".", "info", "(", "f\"Running evaluation on {device}\"", ")", "\n", "\n", "model", ",", "data_loaders", "=", "get_model_and_data_loaders", "(", "\n", "config", "=", "config", ",", "\n", "logger", "=", "logger", ",", "\n", "ckpt_path", "=", "Path", "(", "config", ".", "_args", ".", "resume", ")", ",", "\n", "device", "=", "device", "\n", ")", "\n", "logger", ".", "info", "(", "model", ")", "\n", "\n", "update_src_web_video_dir", "(", "config", ")", "\n", "visualizer", "=", "config", ".", "init", "(", "\n", "name", "=", "'visualizer'", ",", "\n", "module", "=", "module_vis", ",", "\n", "exp_name", "=", "config", ".", "_exper_name", ",", "\n", "web_dir", "=", "config", ".", "_web_log_dir", ",", "\n", ")", "\n", "\n", "metrics", "=", "[", "getattr", "(", "module_metric", ",", "met", ")", "for", "met", "in", "config", "[", "'metrics'", "]", "]", "\n", "challenge_mode", "=", "config", ".", "get", "(", "\"challenge_mode\"", ",", "False", ")", "\n", "challenge_msg", "=", "(", "\n", "\"\\n\"", "\n", "\"Evaluation ran on challenge features. To obtain a score, upload the similarity\"", "\n", "\"matrix for each dataset to the test server after running the \"", "\n", "\"`misc/cvpr2020-challenge/prepare_submission.py` script and following the \"", "\n", "\"instructions at: \"", "\n", "\"https://www.robots.ox.ac.uk/~vgg/challenges/video-pentathlon/\"", "\n", "\"\\n\"", "\n", ")", "\n", "\n", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "samples", ",", "meta", "=", "data_loaders", "[", "\"retrieval\"", "]", "\n", "shape_mask", "=", "meta", "[", "'query_masks'", "]", ".", "shape", "\n", "if", "getattr", "(", "config", ".", "_args", ",", "\"per_class\"", ",", "False", ")", ":", "\n", "            ", "video_names", "=", "meta", "[", "'paths'", "]", "\n", "video_names", "=", "[", "video_name", ".", "split", "(", "'videos/'", ")", "[", "1", "]", ".", "split", "(", "'.mp4'", ")", "[", "0", "]", "for", "video_name", "in", "video_names", "]", "\n", "query_masks_class_v2t", "=", "np", ".", "zeros", "(", "len", "(", "meta", "[", "'query_masks'", "]", ")", ")", "\n", "query_masks_class_t2v", "=", "np", ".", "zeros", "(", "shape_mask", ")", "\n", "for", "idx", ",", "video_name", "in", "enumerate", "(", "video_names", ")", ":", "\n", "                ", "if", "video_name", "in", "relevant_ids", ":", "\n", "                    ", "query_masks_class_t2v", "[", "idx", "]", "=", "np", ".", "ones", "(", "(", "1", ",", "shape_mask", "[", "1", "]", ")", ")", "\n", "query_masks_class_v2t", "[", "idx", "]", "=", "np", ".", "array", "(", "[", "1.", "]", ")", "\n", "", "", "", "else", ":", "\n", "            ", "query_masks_class_t2v", "=", "None", "\n", "query_masks_class_v2t", "=", "None", "\n", "\n", "# To use the nan-checks safely, we need make temporary copies of the data", "\n", "", "disable_nan_checks", "=", "config", ".", "_config", "[", "\"disable_nan_checks\"", "]", "\n", "with", "ctxt_mgr", "(", "samples", ",", "device", ",", "disable_nan_checks", ")", "as", "valid", ":", "\n", "            ", "output", "=", "model", "(", "**", "valid", ")", "\n", "\n", "", "sims", "=", "output", "[", "\"cross_view_conf_matrix\"", "]", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "dataset", "=", "data_loaders", ".", "dataset_name", "\n", "if", "challenge_mode", ":", "\n", "            ", "split", "=", "data_loaders", ".", "dataloaders", "[", "\"dataset\"", "]", ".", "split_name", "\n", "prediction_path", "=", "config", ".", "_log_dir", "/", "f\"{dataset}-{split}-predictions.csv\"", "\n", "compressed_preds", "=", "compress_predictions", "(", "\n", "query_masks", "=", "meta", "[", "\"query_masks\"", "]", ",", "\n", "sims", "=", "sims", ",", "\n", ")", "\n", "np", ".", "savetxt", "(", "prediction_path", ",", "compressed_preds", ",", "delimiter", "=", "','", ",", "fmt", "=", "\"%d\"", ")", "\n", "print", "(", "f\"Saved similarity matrix predictions to {prediction_path}\"", ")", "\n", "print", "(", "challenge_msg", ")", "\n", "return", "\n", "\n", "", "nested_metrics", "=", "{", "}", "\n", "\n", "for", "metric", "in", "metrics", ":", "\n", "            ", "metric_name", "=", "metric", ".", "__name__", "\n", "res", "=", "metric", "(", "sims", ",", "query_masks", "=", "meta", "[", "\"query_masks\"", "]", ",", "\n", "query_masks_class_t2v", "=", "query_masks_class_t2v", ",", "\n", "query_masks_class_v2t", "=", "query_masks_class_v2t", ")", "\n", "verbose", "(", "epoch", "=", "0", ",", "metrics", "=", "res", ",", "name", "=", "dataset", ",", "mode", "=", "metric_name", ")", "\n", "if", "trainer", "is", "not", "None", ":", "\n", "                ", "if", "not", "trainer", ".", "mini_train", ":", "\n", "                    ", "trainer", ".", "writer", ".", "set_step", "(", "step", "=", "0", ",", "mode", "=", "\"val\"", ")", "\n", "# avoid tensboard folding by prefixing", "\n", "", "metric_name_", "=", "f\"test_{metric_name}\"", "\n", "trainer", ".", "log_metrics", "(", "res", ",", "metric_name", "=", "metric_name_", ",", "mode", "=", "\"val\"", ")", "\n", "", "nested_metrics", "[", "metric_name", "]", "=", "res", "\n", "\n", "", "", "if", "data_loaders", ".", "num_test_captions", "==", "1", ":", "\n", "        ", "visualizer", ".", "visualize_ranking", "(", "\n", "sims", "=", "sims", ",", "\n", "meta", "=", "meta", ",", "\n", "epoch", "=", "0", ",", "\n", "nested_metrics", "=", "nested_metrics", ",", "\n", ")", "\n", "", "log", "=", "{", "}", "\n", "for", "subkey", ",", "subval", "in", "nested_metrics", ".", "items", "(", ")", ":", "\n", "        ", "for", "subsubkey", ",", "subsubval", "in", "subval", ".", "items", "(", ")", ":", "\n", "            ", "log", "[", "f\"test_{subkey}_{subsubkey}\"", "]", "=", "subsubval", "\n", "", "", "for", "key", ",", "value", "in", "log", ".", "items", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\" {:15s}: {}\"", ".", "format", "(", "str", "(", "key", ")", ",", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.__init__": [[20, 110], ["pathlib.Path", "zsvision.zs_utils.load_json_config", "parse_config._update_config", "parse_config.ConfigParser._config.get", "parse_config.ConfigParser.set_exper_name", "getattr", "parse_config.ConfigParser._config.get", "vars().get", "parse_config.ConfigParser.save_dir.mkdir", "parse_config.ConfigParser.log_dir.mkdir", "utils.write_json", "args.parse_args.parse_args.add_argument", "args.parse_args.parse_args.parse_args", "isinstance", "pathlib.Path", "parse_config.ConfigParser._config.get", "pathlib.Path().exists", "pathlib.Path", "pathlib.Path", "datetime.datetime.datetime.now().strftime", "logger.setup_logging", "args.parse_args.parse_args.parse_args", "vars", "list", "print", "time.time", "os.system", "print", "print", "pathlib.Path", "datetime.datetime.datetime.now", "pathlib.Path", "config_dir.glob", "parse_config.ConfigParser._config.get", "len", "time.time"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._update_config", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.set_exper_name", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.write_json", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.logger.logger.setup_logging", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "options", "=", "''", ",", "timestamp", "=", "True", ",", "slave_mode", "=", "False", ")", ":", "\n", "# slave_mode - when calling the config parser form an existing process, we", "\n", "# avoid reinitialising the logger and ignore sys.argv when argparsing.", "\n", "\n", "# parse default and custom cli options", "\n", "        ", "for", "opt", "in", "options", ":", "\n", "            ", "args", ".", "add_argument", "(", "*", "opt", ".", "flags", ",", "default", "=", "None", ",", "type", "=", "opt", ".", "type", ")", "\n", "\n", "", "if", "slave_mode", ":", "\n", "            ", "args", "=", "args", ".", "parse_args", "(", "args", "=", "[", "]", ")", "\n", "", "elif", "isinstance", "(", "args", ",", "mock", ".", "Mock", ")", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "args", "=", "args", ".", "parse_args", "(", ")", "\n", "\n", "", "if", "args", ".", "device", ":", "\n", "            ", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "args", ".", "device", "\n", "\n", "", "if", "args", ".", "resume", "and", "not", "slave_mode", ":", "\n", "            ", "self", ".", "resume", "=", "Path", "(", "args", ".", "resume", ")", "\n", "try", ":", "\n", "                ", "if", "args", ".", "finetune", ":", "\n", "                    ", "self", ".", "finetune", "=", "args", ".", "finetune", "\n", "", "", "except", "AttributeError", ":", "\n", "                ", "pass", "\n", "print", "(", "\"Finetune not being used\"", ")", "\n", "", "", "else", ":", "\n", "            ", "msg_no_cfg", "=", "\"Config file must be specified\"", "\n", "assert", "args", ".", "config", "is", "not", "None", ",", "msg_no_cfg", "\n", "self", ".", "resume", "=", "None", "\n", "", "self", ".", "cfg_fname", "=", "Path", "(", "args", ".", "config", ")", "\n", "\n", "config", "=", "load_json_config", "(", "self", ".", "cfg_fname", ")", "\n", "self", ".", "_config", "=", "_update_config", "(", "config", ",", "options", ",", "args", ")", "\n", "\n", "if", "self", ".", "_config", ".", "get", "(", "\"eval_config\"", ",", "False", ")", ":", "\n", "# validate path to evaluation file", "\n", "            ", "eval_cfg_path", "=", "self", ".", "_config", ".", "get", "(", "\"eval_config\"", ")", "\n", "msg", "=", "f\"eval_config was specified, but `{eval_cfg_path}` does not exist\"", "\n", "assert", "Path", "(", "self", ".", "_config", ".", "get", "(", "\"eval_config\"", ")", ")", ".", "exists", "(", ")", ",", "msg", "\n", "\n", "# set save_dir where trained model and log will be saved.", "\n", "", "if", "\"tester\"", "in", "self", ".", "config", ":", "\n", "            ", "save_dir", "=", "Path", "(", "self", ".", "config", "[", "'tester'", "]", "[", "'save_dir'", "]", ")", "\n", "", "else", ":", "\n", "            ", "save_dir", "=", "Path", "(", "self", ".", "config", "[", "'trainer'", "]", "[", "'save_dir'", "]", ")", "\n", "", "timestamp", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "r\"%Y-%m-%d_%H-%M-%S\"", ")", "if", "timestamp", "else", "\"\"", "\n", "\n", "if", "slave_mode", ":", "\n", "            ", "timestamp", "=", "f\"{timestamp}-eval-worker\"", "\n", "\n", "", "exper_name", "=", "self", ".", "set_exper_name", "(", "args", ",", "config", "=", "config", ")", "\n", "\n", "if", "getattr", "(", "args", ",", "\"group_id\"", ",", "False", ")", ":", "\n", "            ", "subdir", "=", "Path", "(", "args", ".", "group_id", ")", "/", "f\"seed-{args.group_seed}\"", "/", "timestamp", "\n", "", "else", ":", "\n", "            ", "subdir", "=", "timestamp", "\n", "\n", "# store challenge experiments in a further subdirectory", "\n", "", "if", "self", ".", "_config", ".", "get", "(", "\"challenge_mode\"", ",", "False", ")", ":", "\n", "            ", "challenge_tag", "=", "\"cvpr2020-challenge\"", "\n", "exper_name", "=", "f\"{challenge_tag}/{exper_name}\"", "\n", "\n", "", "self", ".", "_save_dir", "=", "save_dir", "/", "'models'", "/", "exper_name", "/", "subdir", "\n", "self", ".", "_web_log_dir", "=", "save_dir", "/", "'web'", "/", "exper_name", "/", "subdir", "\n", "self", ".", "_log_dir", "=", "save_dir", "/", "'log'", "/", "exper_name", "/", "subdir", "\n", "self", ".", "_exper_name", "=", "exper_name", "\n", "self", ".", "_args", "=", "args", "\n", "\n", "# if set, remove all previous experiments with the current config", "\n", "if", "vars", "(", "args", ")", ".", "get", "(", "\"purge_exp_dir\"", ",", "False", ")", ":", "\n", "            ", "for", "dirpath", "in", "(", "self", ".", "_save_dir", ",", "self", ".", "_log_dir", ",", "self", ".", "_web_log_dir", ")", ":", "\n", "                ", "config_dir", "=", "dirpath", ".", "parent", "\n", "existing", "=", "list", "(", "config_dir", ".", "glob", "(", "\"*\"", ")", ")", "\n", "print", "(", "f\"purging {len(existing)} directories from config_dir...\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "os", ".", "system", "(", "f\"rm -rf {config_dir}\"", ")", "\n", "print", "(", "f\"Finished purge in {time.time() - tic:.3f}s\"", ")", "\n", "\n", "", "", "self", ".", "save_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "log_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# save updated config file to the checkpoint dir", "\n", "write_json", "(", "self", ".", "config", ",", "self", ".", "save_dir", "/", "'config.json'", ")", "\n", "\n", "# configure logging module", "\n", "if", "not", "slave_mode", ":", "\n", "            ", "self", ".", "log_path", "=", "setup_logging", "(", "self", ".", "log_dir", ")", "\n", "\n", "", "self", ".", "log_levels", "=", "{", "0", ":", "logging", ".", "WARNING", ",", "1", ":", "logging", ".", "INFO", ",", "2", ":", "logging", ".", "DEBUG", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.set_exper_name": [[111, 140], ["getattr", "getattr", "args.custom_args.split", "print", "print", "print", "key_val_pair.split", "zsvision.zs_utils.set_nested_key_val", "key.replace", "val.replace.replace.replace", "key.replace.split"], "methods", ["None"], ["", "def", "set_exper_name", "(", "self", ",", "args", ",", "config", ")", ":", "\n", "# We assume that the config files are organised into directories such that", "\n", "# each directory has the name of the dataset.", "\n", "        ", "dataset_name", "=", "self", ".", "cfg_fname", ".", "parent", ".", "stem", "\n", "exper_name", "=", "f\"{dataset_name}-{self.cfg_fname.stem}\"", "\n", "if", "args", ".", "custom_args", ":", "\n", "            ", "key_val_lists", "=", "args", ".", "custom_args", ".", "split", "(", "\"+\"", ")", "\n", "for", "key_val_pair", "in", "key_val_lists", ":", "\n", "                ", "print", "(", "f\"parsing key-val pair : {key_val_pair}\"", ")", "\n", "key", ",", "val", "=", "key_val_pair", ".", "split", "(", "\"@\"", ")", "\n", "set_nested_key_val", "(", "key", ",", "val", ",", "self", ".", "_config", ")", "\n", "# remove periods from key names", "\n", "key_", "=", "key", ".", "replace", "(", "\"_.\"", ",", "\"--\"", ")", "\n", "# remove commas from value names", "\n", "val", "=", "val", ".", "replace", "(", "\",\"", ",", "\"--\"", ")", "\n", "custom_tag", "=", "\"-\"", ".", "join", "(", "key_", ".", "split", "(", "\".\"", ")", "[", "-", "2", ":", "]", ")", "\n", "exper_name", "=", "f\"{exper_name}-{custom_tag}-{val}\"", "\n", "\n", "", "", "if", "getattr", "(", "args", ",", "\"disable_workers\"", ",", "False", ")", ":", "\n", "            ", "print", "(", "\"Disabling data loader workers....\"", ")", "\n", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"num_workers\"", "]", "=", "0", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"train_single_epoch\"", ",", "False", ")", ":", "\n", "            ", "print", "(", "\"Restricting training to a single epoch....\"", ")", "\n", "config", "[", "\"trainer\"", "]", "[", "\"epochs\"", "]", "=", "1", "\n", "config", "[", "\"trainer\"", "]", "[", "\"save_period\"", "]", "=", "1", "\n", "config", "[", "\"trainer\"", "]", "[", "\"skip_first_n_saves\"", "]", "=", "0", "\n", "exper_name", "=", "f\"{exper_name}-train-single-epoch\"", "\n", "", "return", "exper_name", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.init": [[141, 154], ["dict", "all", "dict.update", "getattr"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update"], ["", "def", "init", "(", "self", ",", "name", ",", "module", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Finds a function handle with the name given as 'type' in config, and returns\n        the instance initialized with corresponding keyword args given as 'args'.\n        \"\"\"", "\n", "module_name", "=", "self", "[", "name", "]", "[", "'type'", "]", "\n", "module_args", "=", "dict", "(", "self", "[", "name", "]", "[", "'args'", "]", ")", "\n", "msg", "=", "(", "f\"Fail for {module_name}\\n\"", "\n", "f\"overwriting kwargs given in config file is not allowed\\n\"", "\n", "f\"passed kwargs: {kwargs}\\n\"", "\n", "f\"for module_args: {module_args})\"", ")", "\n", "assert", "all", "(", "[", "k", "not", "in", "module_args", "for", "k", "in", "kwargs", "]", ")", ",", "msg", "\n", "module_args", ".", "update", "(", "kwargs", ")", "\n", "return", "getattr", "(", "module", ",", "module_name", ")", "(", "*", "args", ",", "**", "module_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.__getitem__": [[155, 157], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "self", ".", "config", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.__len__": [[158, 162], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "# NOTE: This is used for boolean checking deep inside ray.tune, so we required it", "\n", "# to be defined.", "\n", "        ", "return", "len", "(", "self", ".", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.__setitem__": [[163, 165], ["None"], "methods", ["None"], ["", "def", "__setitem__", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "self", ".", "config", "[", "name", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.__contains__": [[166, 168], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "name", "in", "self", ".", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.get": [[169, 171], ["parse_config.ConfigParser.config.get"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["", "def", "get", "(", "self", ",", "name", ",", "default", ")", ":", "\n", "        ", "return", "self", ".", "config", ".", "get", "(", "name", ",", "default", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.keys": [[172, 174], ["parse_config.ConfigParser.config.keys"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["", "def", "keys", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "config", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.get_logger": [[175, 182], ["msg_verbosity.format.format.format", "logging.getLogger", "logging.getLogger.setLevel", "parse_config.ConfigParser.log_levels.keys"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["", "def", "get_logger", "(", "self", ",", "name", ",", "verbosity", "=", "2", ")", ":", "\n", "        ", "msg_verbosity", "=", "\"verbosity option {} is invalid. Valid options are {}.\"", "\n", "msg_verbosity", "=", "msg_verbosity", ".", "format", "(", "verbosity", ",", "self", ".", "log_levels", ".", "keys", "(", ")", ")", "\n", "assert", "verbosity", "in", "self", ".", "log_levels", ",", "msg_verbosity", "\n", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "self", ".", "log_levels", "[", "verbosity", "]", ")", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.config": [[184, 187], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_config", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.save_dir": [[188, 191], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "save_dir", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_save_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.log_dir": [[192, 195], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "log_dir", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_log_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.__repr__": [[196, 198], ["pprint.PrettyPrinter().pformat", "pprint.PrettyPrinter"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "pprint", ".", "PrettyPrinter", "(", ")", ".", "pformat", "(", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config.ConfigParser.items": [[199, 201], ["parse_config.ConfigParser._config.items"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "def", "items", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_config", ".", "items", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config._update_config": [[204, 210], ["getattr", "parse_config._get_opt_name", "parse_config._set_by_path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._get_opt_name", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._set_by_path"], ["", "", "def", "_update_config", "(", "config", ",", "options", ",", "args", ")", ":", "\n", "    ", "for", "opt", "in", "options", ":", "\n", "        ", "value", "=", "getattr", "(", "args", ",", "_get_opt_name", "(", "opt", ".", "flags", ")", ")", "\n", "if", "value", "is", "not", "None", ":", "\n", "            ", "_set_by_path", "(", "config", ",", "opt", ".", "target", ",", "value", ")", "\n", "", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config._get_opt_name": [[212, 217], ["flags[].replace", "flg.startswith", "flg.replace"], "function", ["None"], ["", "def", "_get_opt_name", "(", "flags", ")", ":", "\n", "    ", "for", "flg", "in", "flags", ":", "\n", "        ", "if", "flg", ".", "startswith", "(", "'--'", ")", ":", "\n", "            ", "return", "flg", ".", "replace", "(", "'--'", ",", "''", ")", "\n", "", "", "return", "flags", "[", "0", "]", ".", "replace", "(", "'--'", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config._set_by_path": [[219, 222], ["parse_config._get_by_path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._get_by_path"], ["", "def", "_set_by_path", "(", "tree", ",", "keys", ",", "value", ")", ":", "\n", "    ", "\"\"\"Set a value in a nested object in tree by sequence of keys.\"\"\"", "\n", "_get_by_path", "(", "tree", ",", "keys", "[", ":", "-", "1", "]", ")", "[", "keys", "[", "-", "1", "]", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.None.parse_config._get_by_path": [[224, 227], ["functools.reduce"], "function", ["None"], ["", "def", "_get_by_path", "(", "tree", ",", "keys", ")", ":", "\n", "    ", "\"\"\"Access a nested object in tree by sequence of keys.\"\"\"", "\n", "return", "reduce", "(", "getitem", ",", "keys", ",", "tree", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html.HTML.__init__": [[16, 37], ["os.path.join", "dominate.document", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "dominate.tags.meta", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "web_dir", ",", "title", ",", "refresh", "=", "0", ")", ":", "\n", "        ", "\"\"\"Initialize the HTML classes\n\n        Parameters:\n            web_dir (str) -- a directory that stores the webpage. HTML file will be\n            created at <web_dir>/index.html; images will be saved at <web_dir/images/\n            title (str)   -- the webpage name\n            reflect (int) -- how often the website refresh itself; if 0; no refreshing\n        \"\"\"", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "web_dir", "=", "web_dir", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "web_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "web_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "img_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "img_dir", ")", "\n", "\n", "", "self", ".", "doc", "=", "dominate", ".", "document", "(", "title", "=", "title", ")", "\n", "if", "refresh", ">", "0", ":", "\n", "            ", "with", "self", ".", "doc", ".", "head", ":", "\n", "                ", "meta", "(", "http_equiv", "=", "\"refresh\"", ",", "content", "=", "str", "(", "refresh", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html.HTML.get_image_dir": [[38, 41], ["None"], "methods", ["None"], ["", "", "", "def", "get_image_dir", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the directory that stores images\"\"\"", "\n", "return", "self", ".", "img_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html.HTML.add_header": [[42, 50], ["dominate.tags.h3"], "methods", ["None"], ["", "def", "add_header", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Insert a header to the HTML file\n\n        Parameters:\n            text (str) -- the header text\n        \"\"\"", "\n", "with", "self", ".", "doc", ":", "\n", "            ", "h3", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html.HTML.add_videos": [[51, 90], ["dominate.tags.table", "html.HTML.doc.add", "dominate.tags.tr", "zip", "dominate.tags.td", "dominate.tags.p", "str", "dominate.tags.br", "txt.split", "enumerate", "p_style.format.format.format", "dominate.tags.p", "dominate.tags.span", "dominate.tags.a", "row.startswith", "dominate.tags.video", "dominate.tags.attr", "dominate.tags.source", "str", "len", "len"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add"], ["", "", "def", "add_videos", "(", "self", ",", "vids", ",", "txts", ",", "links", ",", "width", "=", "400", ",", "hidden_tag", "=", "\"hidden\"", ")", ":", "\n", "        ", "\"\"\"add images to the HTML file\n\n        Parameters:\n            vids (str list)   -- a list of image paths\n            txts (str list)  -- a list of image names shown on the website\n            links (str list) --  a list of hyperref links; when you click an image,\n            it will redirect you to a new page\n        \"\"\"", "\n", "self", ".", "t", "=", "table", "(", "border", "=", "1", ",", "style", "=", "\"table-layout: fixed;\"", ")", "# Insert a table", "\n", "self", ".", "doc", ".", "add", "(", "self", ".", "t", ")", "\n", "colors", "=", "[", "\"red\"", ",", "\"blue\"", ",", "\"gold\"", ",", "\"salman\"", "]", "\n", "with", "self", ".", "t", ":", "\n", "            ", "with", "tr", "(", ")", ":", "\n", "                ", "for", "vid", ",", "txt", ",", "link", "in", "zip", "(", "vids", ",", "txts", ",", "links", ")", ":", "\n", "                    ", "td_style", "=", "\"word-wrap: break-word; width:{}px\"", ".", "format", "(", "width", ")", "\n", "with", "td", "(", "style", "=", "td_style", ",", "halign", "=", "\"center\"", ",", "valign", "=", "\"top\"", ")", ":", "\n", "                        ", "with", "p", "(", ")", ":", "\n", "                            ", "vid_path", "=", "str", "(", "vid", ")", "\n", "if", "vid_path", "==", "hidden_tag", ":", "\n", "                                ", "p_style", "=", "\"font-weight: bold; width:{}px;\"", "\n", "p_style", "=", "p_style", ".", "format", "(", "width", "*", "3", ")", "\n", "p", "(", "\"hidden video\"", ",", "style", "=", "p_style", ")", "\n", "", "else", ":", "\n", "                                ", "with", "a", "(", "href", "=", "str", "(", "link", ")", ")", ":", "\n", "                                    ", "with", "video", "(", ")", ":", "\n", "                                        ", "attr", "(", "controls", "=", "\"controls\"", ")", "\n", "source", "(", "src", "=", "vid_path", ",", "type", "=", "\"video/mp4\"", ")", "\n", "", "", "", "br", "(", ")", "\n", "rows", "=", "txt", ".", "split", "(", "\"<br>\"", ")", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "rows", ")", ":", "\n", "                                ", "color", "=", "colors", "[", "idx", "%", "len", "(", "colors", ")", "]", "\n", "bold_tag", "=", "\"<b>\"", "\n", "if", "not", "row", ".", "startswith", "(", "bold_tag", ")", ":", "\n", "                                    ", "s_style", "=", "\"color:{};\"", ".", "format", "(", "color", ")", "\n", "", "else", ":", "\n", "                                    ", "s_style", "=", "\"color:black; font-weight: bold;\"", "\n", "row", "=", "row", "[", "len", "(", "bold_tag", ")", ":", "]", "\n", "", "span", "(", "row", ",", "style", "=", "s_style", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html.HTML.add_images": [[91, 115], ["dominate.tags.table", "html.HTML.doc.add", "dominate.tags.tr", "zip", "dominate.tags.td", "dominate.tags.p", "dominate.tags.br", "dominate.tags.p", "dominate.tags.a", "dominate.tags.img", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add"], ["", "", "", "", "", "", "", "def", "add_images", "(", "self", ",", "ims", ",", "txts", ",", "links", ",", "width", "=", "400", ")", ":", "\n", "        ", "\"\"\"add images to the HTML file\n\n        Parameters:\n            ims (str list)   -- a list of image paths\n            txts (str list)  -- a list of image names shown on the website\n            links (str list) --  a list of hyperref links; when you click an image,\n            it will redirect you to a new page\n        \"\"\"", "\n", "self", ".", "t", "=", "table", "(", "border", "=", "1", ",", "style", "=", "\"table-layout: fixed;\"", ")", "# Insert a table", "\n", "self", ".", "doc", ".", "add", "(", "self", ".", "t", ")", "\n", "with", "self", ".", "t", ":", "\n", "            ", "with", "tr", "(", ")", ":", "\n", "                ", "for", "im", ",", "txt", ",", "link", "in", "zip", "(", "ims", ",", "txts", ",", "links", ")", ":", "\n", "                    ", "td_style", "=", "\"word-wrap: break-word;\"", "\n", "with", "td", "(", "style", "=", "td_style", ",", "halign", "=", "\"center\"", ",", "valign", "=", "\"top\"", ")", ":", "\n", "                        ", "with", "p", "(", ")", ":", "\n", "                            ", "with", "a", "(", "href", "=", "os", ".", "path", ".", "join", "(", "\"images\"", ",", "link", ")", ")", ":", "\n", "                                ", "img", "(", "\n", "style", "=", "\"width:%dpx\"", "%", "width", ",", "\n", "src", "=", "os", ".", "path", ".", "join", "(", "\"images\"", ",", "im", ")", ",", "\n", ")", "\n", "", "br", "(", ")", "\n", "p", "(", "txt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html.HTML.save": [[116, 122], ["open", "open.write", "open.close", "html.HTML.doc.render"], "methods", ["None"], ["", "", "", "", "", "", "def", "save", "(", "self", ")", ":", "\n", "        ", "\"\"\"save the current content to the HMTL file\"\"\"", "\n", "html_file", "=", "\"%s/index.html\"", "%", "self", ".", "web_dir", "\n", "f", "=", "open", "(", "html_file", ",", "\"wt\"", ")", "\n", "f", ".", "write", "(", "self", ".", "doc", ".", "render", "(", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.visualizer.Visualizer.__init__": [[37, 44], ["logger.debug", "util.mkdirs", "str"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdirs"], ["", "def", "visualize_ranking", "(", "self", ",", "sims", ",", "epoch", ",", "meta", ",", "nested_metrics", ")", ":", "\n", "        ", "if", "not", "(", "self", ".", "vis_vid_freq", "and", "epoch", "%", "self", ".", "vis_vid_freq", "==", "0", ")", ":", "\n", "            ", "return", "\n", "\n", "", "dists", "=", "-", "sims", "\n", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "sorted_ranks", "=", "np", ".", "argsort", "(", "dists", ",", "axis", "=", "1", ")", "\n", "gt_dists", "=", "np", ".", "diag", "(", "dists", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.visualizer.Visualizer.visualize_ranking": [[45, 119], ["query_masks.reshape().astype.reshape().astype.reshape().astype", "numpy.identity().astype", "numpy.repeat", "list", "numpy.random.seed", "numpy.argsort", "min", "numpy.random.choice", "itertools.compress", "numpy.reshape", "numpy.arange", "[].numpy", "tokenizer.convert_ids_to_tokens", "rankings.append", "os.path.join", "pathlib.Path().exists", "visualizer.Visualizer.display_current_results", "query_masks.reshape().astype.reshape().astype.reshape", "numpy.identity", "pathlib.Path().exists", "pathlib.Path().mkdir", "numpy.where", "numpy.array", "numpy.array", "pathlib.Path", "shutil.rmtree", "numpy.where", "print", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.WeTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.visualizer.Visualizer.display_current_results", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir"], ["rankings", "=", "[", "]", "\n", "vis_top_k", "=", "5", "\n", "hide_gt", "=", "False", "\n", "# num_indep_samples = 1", "\n", "# random_seeds = np.arange(num_indep_samples)", "\n", "sample", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "dists", ".", "shape", "[", "0", "]", ")", ",", "size", "=", "self", ".", "num_samples", ",", "\n", "replace", "=", "False", ")", "\n", "for", "ii", "in", "sample", ":", "\n", "            ", "ranked_idx", "=", "sorted_ranks", "[", "ii", "]", "[", ":", "vis_top_k", "]", "\n", "gt_captions", "=", "meta", "[", "\"raw_captions\"", "]", "[", "ii", "]", "\n", "# if args.sample_single_gt_caption:", "\n", "#     gt_captions = np.random.choice(gt_captions, 1).tolist()", "\n", "\n", "datum", "=", "{", "\n", "\"gt-sim\"", ":", "-", "gt_dists", "[", "ii", "]", ",", "\n", "\"gt-captions\"", ":", "gt_captions", ",", "\n", "\"gt-rank\"", ":", "np", ".", "where", "(", "sorted_ranks", "[", "ii", "]", "==", "ii", ")", "[", "0", "]", "[", "0", "]", ",", "\n", "\"gt-path\"", ":", "meta", "[", "\"paths\"", "]", "[", "ii", "]", ",", "\n", "\"top-k-sims\"", ":", "-", "dists", "[", "ii", "]", "[", "ranked_idx", "]", ",", "\n", "\"top-k-paths\"", ":", "np", ".", "array", "(", "meta", "[", "\"paths\"", "]", ")", "[", "ranked_idx", "]", ",", "\n", "\"hide-gt\"", ":", "hide_gt", ",", "\n", "}", "\n", "rankings", ".", "append", "(", "datum", ")", "\n", "", "self", ".", "display_current_results", "(", "\n", "rankings", ",", "\n", "epoch", "=", "epoch", ",", "\n", "metrics", "=", "nested_metrics", "[", "\"t2v_metrics\"", "]", ",", "\n", ")", "\n", "\n", "", "def", "display_current_results", "(", "self", ",", "rankings", ",", "epoch", ",", "metrics", ")", ":", "\n", "        ", "\"\"\"Display current results on visdom; save current results to an HTML file.\n\n        Parameters:\n            visuals (OrderedDict) - - dictionary of images to display or save\n            epoch (int) - - the current epoch\n            save_result (bool) - - if save the current results to an HTML file\n        \"\"\"", "\n", "if", "not", "Path", "(", "self", ".", "web_dir", ")", ".", "exists", "(", ")", ":", "\n", "            ", "Path", "(", "self", ".", "web_dir", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "", "print", "(", "f\"updating webpage at {self.web_dir}\"", ")", "\n", "title", "=", "f\"Experiment name = {self.name}\"", "\n", "refresh", "=", "True", "\n", "if", "not", "refresh", ":", "\n", "            ", "print", "(", "\"DISABLING WEB PAGE REFRESH\"", ")", "\n", "", "webpage", "=", "html", ".", "HTML", "(", "web_dir", "=", "self", ".", "web_dir", ",", "title", "=", "title", ",", "refresh", "=", "refresh", ")", "\n", "\n", "msg", "=", "f\"epoch [{epoch}] - {self.name}\"", "\n", "webpage", ".", "add_header", "(", "msg", ")", "\n", "msg", "=", "(", "f\"R1: {metrics['R1']:.1f}, \"", "\n", "f\"R5: {metrics['R5']:.1f}, \"", "\n", "f\"R10: {metrics['R10']:.1f}, \"", "\n", "f\"MedR: {metrics['MedR']}\"", ")", "\n", "webpage", ".", "add_header", "(", "msg", ")", "\n", "print", "(", "f\"Top {len(rankings[0])} retreived videos at epoch: {epoch}\"", ")", "\n", "\n", "for", "ranking", "in", "rankings", ":", "\n", "            ", "vids", ",", "txts", ",", "links", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "gt_vid_path", "=", "ranking", "[", "\"gt-path\"", "]", "\n", "gt_captions", "=", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "ranking", "[", "\"gt-captions\"", "]", "]", "\n", "gt_captions", "=", "\"<br>\"", ".", "join", "(", "gt_captions", ")", "\n", "if", "ranking", "[", "\"hide-gt\"", "]", ":", "\n", "                ", "txts", ".", "append", "(", "gt_captions", ")", "\n", "links", ".", "append", "(", "\"hidden\"", ")", "\n", "vids", ".", "append", "(", "\"hidden\"", ")", "\n", "", "else", ":", "\n", "                ", "txt", "=", "(", "f\"{gt_captions}<br><b>Rank: {ranking['gt-rank']}, \"", "\n", "f\"Sim: {ranking['gt-sim']:.3f} [{Path(ranking['gt-path']).stem}]\"", ")", "\n", "txts", ".", "append", "(", "txt", ")", "\n", "links", ".", "append", "(", "gt_vid_path", ")", "\n", "vids", ".", "append", "(", "gt_vid_path", ")", "\n", "\n", "", "for", "idx", ",", "(", "vid_path", ",", "sim", ")", "in", "enumerate", "(", "zip", "(", "ranking", "[", "\"top-k-paths\"", "]", ",", "\n", "ranking", "[", "\"top-k-sims\"", "]", ")", ")", ":", "\n", "                ", "vid_path", "=", "Path", "(", "vid_path", ")", "\n", "if", "ranking", "[", "\"hide-gt\"", "]", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.visualizer.Visualizer.display_current_results": [[121, 192], ["filepath.exists", "pathlib.Path().mkdir", "print", "html_utils.HTML", "html_utils.HTML.add_header", "html_utils.HTML.add_header", "logger.debug", "enumerate", "logger.debug", "html_utils.HTML.save", "pathlib.Path", "filepath.unlink", "logger.debug", "len", "str", "gt_captions.replace", "enumerate", "html_utils.HTML.add_videos", "len", "pathlib.Path", "txts.append", "links.append", "vids.append", "txts.append", "links.append", "vids.append", "zip", "txts.append", "str", "vids.append", "links.append", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.add_header", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.add_header", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.save", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.add_videos"], ["", "else", ":", "\n", "                    ", "txt", "=", "f\"<b>Rank: {idx}, Sim: {sim:.3f}, [{Path(vid_path).stem}]\"", "\n", "", "txts", ".", "append", "(", "txt", ")", "\n", "vids", ".", "append", "(", "vid_path", ")", "\n", "links", ".", "append", "(", "vid_path", ")", "\n", "", "webpage", ".", "add_videos", "(", "vids", ",", "txts", ",", "links", ",", "width", "=", "200", ")", "\n", "", "print", "(", "f\"added {len(vids)} videos\"", ")", "\n", "webpage", ".", "save", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.ExpertStore.__init__": [[16, 24], ["numpy.zeros", "set", "datastructures.ExpertStore.rebuild_keymap", "len"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.ExpertStore.rebuild_keymap"], ["    ", "def", "__init__", "(", "self", ",", "keylist", ",", "dim", ",", "dtype", "=", "np", ".", "float16", ")", ":", "\n", "        ", "self", ".", "keys", "=", "keylist", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "store_dtype", "=", "dtype", "\n", "self", ".", "store", "=", "np", ".", "zeros", "(", "(", "len", "(", "keylist", ")", ",", "dim", ")", ",", "dtype", "=", "dtype", ")", "\n", "self", ".", "keymap", "=", "{", "}", "\n", "self", ".", "missing", "=", "set", "(", ")", "\n", "self", ".", "rebuild_keymap", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.ExpertStore.__setitem__": [[25, 33], ["isinstance", "numpy.isnan"], "methods", ["None"], ["", "def", "__setitem__", "(", "self", ",", "key", ",", "value", ")", ":", "\n", "        ", "idx", "=", "self", ".", "keymap", "[", "key", "]", "\n", "if", "isinstance", "(", "value", ",", "np", ".", "ndarray", ")", ":", "\n", "# non-nan values must be vectors of the appropriate size", "\n", "            ", "assert", "value", ".", "size", "==", "self", ".", "dim", ",", "f\"cannot set value with size {value.size}\"", "\n", "", "else", ":", "\n", "            ", "assert", "np", ".", "isnan", "(", "value", ")", "\n", "", "self", ".", "store", "[", "idx", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.ExpertStore.rebuild_keymap": [[34, 37], ["enumerate"], "methods", ["None"], ["", "def", "rebuild_keymap", "(", "self", ")", ":", "\n", "        ", "for", "idx", ",", "key", "in", "enumerate", "(", "self", ".", "keys", ")", ":", "\n", "            ", "self", ".", "keymap", "[", "key", "]", "=", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.ExpertStore.filter_keys": [[38, 58], ["set", "print", "numpy.array", "print", "datastructures.ExpertStore.rebuild_keymap", "set", "missing.intersection", "print", "print", "numpy.array", "set", "list", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.ExpertStore.rebuild_keymap"], ["", "", "def", "filter_keys", "(", "self", ",", "keys", ",", "tag", ",", "allow_mismatch", "=", "\"\"", ",", "exceptions", "=", "None", ")", ":", "\n", "        ", "keyset", "=", "set", "(", "keys", ")", "\n", "missing", "=", "keyset", "-", "set", "(", "self", ".", "keys", ")", "\n", "if", "exceptions", "is", "not", "None", "and", "missing", ":", "\n", "            ", "excluded", "=", "missing", ".", "intersection", "(", "set", "(", "exceptions", ")", ")", "\n", "print", "(", "f\"filter_keys >>> applying exceptions for {len(excluded)} videos\"", ")", "\n", "missing", "=", "missing", "-", "excluded", "\n", "", "print", "(", "f\"filter_keys >>> {tag}\"", ")", "\n", "if", "allow_mismatch", "and", "missing", ":", "\n", "            ", "print", "(", "f\"Key mismatch (missing {len(missing)}) {allow_mismatch}\"", ")", "\n", "", "else", ":", "\n", "            ", "samples", "=", "list", "(", "missing", ")", "[", ":", "3", "]", "\n", "msg", "=", "f\"cannot apply filter since missing {len(missing)} keys e.g. {samples}\"", "\n", "assert", "not", "missing", ",", "msg", "\n", "", "keep", "=", "np", ".", "array", "(", "[", "x", "in", "keyset", "for", "x", "in", "self", ".", "keys", "]", ")", "\n", "filtered_keys", "=", "np", ".", "array", "(", "self", ".", "keys", ")", "[", "keep", "]", "\n", "print", "(", "f\"Filtering from {len(self.keys)} keys to {len(filtered_keys)} keys\"", ")", "\n", "self", ".", "keys", "=", "filtered_keys", "\n", "self", ".", "store", "=", "self", ".", "store", "[", "keep", "]", "\n", "self", ".", "rebuild_keymap", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.ExpertStore.__getitem__": [[59, 61], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "store", "[", "self", ".", "keymap", "[", "key", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.ExpertStore.__len__": [[62, 64], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.ExpertStore.__repr__": [[65, 75], ["list", "datastructures.ExpertStore.keymap.items", "len", "humanize.naturalsize"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "keep_samples", "=", "3", "\n", "samples", "=", "list", "(", "self", ".", "keymap", ".", "items", "(", ")", ")", "[", ":", "keep_samples", "]", "\n", "sample_str", "=", "\"\\n\"", ".", "join", "(", "[", "f\"{key}: {val}\"", "for", "key", ",", "val", "in", "samples", "]", ")", "\n", "summary", "=", "(", "\n", "f\"ExpertStore object with {len(self.keys)} features (dim: {self.dim})\"", "\n", "f\" (storage is using {humanize.naturalsize(self.store.nbytes)})\"", "\n", "f\"\\nFirst {keep_samples} elements of keymap: \\n{sample_str}\"", "\n", ")", "\n", "return", "summary", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.gen_dict_store": [[77, 82], ["dict", "numpy.random.rand().astype", "numpy.random.rand"], "function", ["None"], ["", "", "def", "gen_dict_store", "(", "keylist", ",", "dim", ")", ":", "\n", "    ", "store", "=", "dict", "(", ")", "\n", "for", "key", "in", "keylist", ":", "\n", "        ", "store", "[", "key", "]", "=", "np", ".", "random", ".", "rand", "(", "1", ",", "dim", ")", ".", "astype", "(", "np", ".", "float16", ")", "\n", "", "return", "store", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.main": [[84, 106], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "get_data_paths", "open", "sorted", "pickle.dumps", "print", "f.read().splitlines", "datastructures.gen_dict_store", "numpy.random.rand().astype", "f.read", "datastructures.ExpertStore", "print", "humanize.naturalsize", "numpy.random.rand", "len", "len"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.datastructures.gen_dict_store"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "default", "=", "\"moments-in-time\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dim\"", ",", "type", "=", "int", ",", "default", "=", "2048", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "from", "config", "import", "get_data_paths", "\n", "data_paths", "=", "get_data_paths", "(", "args", ".", "dataset", ")", "\n", "relevant_path", "=", "data_paths", "[", "\"relevant-id-list\"", "]", "\n", "with", "open", "(", "relevant_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "relevant_ids", "=", "sorted", "(", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", ")", "\n", "\n", "", "for", "store_name", "in", "\"dict\"", ",", "\"np\"", ",", "\"expert_store\"", ":", "\n", "        ", "if", "store_name", "==", "\"dict\"", ":", "\n", "            ", "store", "=", "gen_dict_store", "(", "keylist", "=", "relevant_ids", ",", "dim", "=", "args", ".", "dim", ")", "\n", "", "elif", "store_name", "==", "\"np\"", ":", "\n", "            ", "store", "=", "np", ".", "random", ".", "rand", "(", "len", "(", "relevant_ids", ")", ",", "args", ".", "dim", ")", ".", "astype", "(", "np", ".", "float16", ")", "\n", "", "elif", "store_name", "==", "\"expert_store\"", ":", "\n", "            ", "store", "=", "ExpertStore", "(", "keylist", "=", "relevant_ids", ",", "dim", "=", "args", ".", "dim", ")", "\n", "print", "(", "store", ")", "\n", "", "serialised", "=", "pickle", ".", "dumps", "(", "store", ")", "\n", "print", "(", "f\"Memory needs for {store_name}: {humanize.naturalsize(len(serialised))}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.cos_restart.CosineAnnealingWithRestartsLR.__init__": [[32, 40], ["torch.optim.lr_scheduler._LRScheduler.__init__"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "T_max", ",", "eta_min", "=", "0", ",", "last_epoch", "=", "-", "1", ",", "T_mult", "=", "1", ")", ":", "\n", "        ", "self", ".", "T_max", "=", "T_max", "\n", "self", ".", "T_mult", "=", "T_mult", "\n", "self", ".", "restart_every", "=", "T_max", "\n", "self", ".", "eta_min", "=", "eta_min", "\n", "self", ".", "restarts", "=", "0", "\n", "self", ".", "restarted_at", "=", "0", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.cos_restart.CosineAnnealingWithRestartsLR.restart": [[41, 44], ["None"], "methods", ["None"], ["", "def", "restart", "(", "self", ")", ":", "\n", "        ", "self", ".", "restart_every", "*=", "self", ".", "T_mult", "\n", "self", ".", "restarted_at", "=", "self", ".", "last_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.cos_restart.CosineAnnealingWithRestartsLR.cosine": [[45, 48], ["math.cos"], "methods", ["None"], ["", "def", "cosine", "(", "self", ",", "base_lr", ")", ":", "\n", "        ", "return", "self", ".", "eta_min", "+", "(", "base_lr", "-", "self", ".", "eta_min", ")", "*", "(", "1", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "self", ".", "step_n", "/", "self", ".", "restart_every", ")", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.cos_restart.CosineAnnealingWithRestartsLR.step_n": [[49, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "step_n", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "last_epoch", "-", "self", ".", "restarted_at", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.cos_restart.CosineAnnealingWithRestartsLR.get_lr": [[53, 57], ["cos_restart.CosineAnnealingWithRestartsLR.restart", "cos_restart.CosineAnnealingWithRestartsLR.cosine"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.cos_restart.CosineAnnealingWithRestartsLR.restart", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.cos_restart.CosineAnnealingWithRestartsLR.cosine"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "step_n", ">=", "self", ".", "restart_every", ":", "\n", "            ", "self", ".", "restart", "(", ")", "\n", "", "return", "[", "self", ".", "cosine", "(", "base_lr", ")", "for", "base_lr", "in", "self", ".", "base_lrs", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.radam.RAdam.__init__": [[7, 11], ["dict", "torch.optim.optimizer.Optimizer.__init__", "range"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ")", "\n", "self", ".", "buffer", "=", "[", "[", "None", ",", "None", ",", "None", "]", "for", "ind", "in", "range", "(", "10", ")", "]", "\n", "super", "(", "RAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.radam.RAdam.__setstate__": [[12, 14], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.ranger.Ranger.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "RAdam", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.radam.RAdam.step": [[15, 79], ["closure", "p.grad.data.float", "p.data.float", "exp_avg_sq.mul_().addcmul_", "exp_avg.mul_().add_", "p.data.copy_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as", "p.data.float.add_", "exp_avg_sq.sqrt().add_", "p.data.float.addcdiv_", "p.data.float.add_", "exp_avg_sq.mul_", "exp_avg.mul_", "int", "math.sqrt", "exp_avg_sq.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'RAdam does not support sparse gradients'", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "buffered", "=", "self", ".", "buffer", "[", "int", "(", "state", "[", "'step'", "]", "%", "10", ")", "]", "\n", "if", "state", "[", "'step'", "]", "==", "buffered", "[", "0", "]", ":", "\n", "                    ", "N_sma", ",", "step_size", "=", "buffered", "[", "1", "]", ",", "buffered", "[", "2", "]", "\n", "", "else", ":", "\n", "                    ", "buffered", "[", "0", "]", "=", "state", "[", "'step'", "]", "\n", "beta2_t", "=", "beta2", "**", "state", "[", "'step'", "]", "\n", "N_sma_max", "=", "2", "/", "(", "1", "-", "beta2", ")", "-", "1", "\n", "N_sma", "=", "N_sma_max", "-", "2", "*", "state", "[", "'step'", "]", "*", "beta2_t", "/", "(", "1", "-", "beta2_t", ")", "\n", "buffered", "[", "1", "]", "=", "N_sma", "\n", "\n", "# more conservative since it's an approximated value", "\n", "if", "N_sma", ">=", "5", ":", "\n", "                        ", "step_size", "=", "math", ".", "sqrt", "(", "(", "1", "-", "beta2_t", ")", "*", "(", "N_sma", "-", "4", ")", "/", "(", "N_sma_max", "-", "4", ")", "*", "(", "N_sma", "-", "2", ")", "/", "N_sma", "*", "N_sma_max", "/", "(", "N_sma_max", "-", "2", ")", ")", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "else", ":", "\n", "                        ", "step_size", "=", "1.0", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "buffered", "[", "2", "]", "=", "step_size", "\n", "\n", "", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "\n", "# more conservative since it's an approximated value", "\n", "", "if", "N_sma", ">=", "5", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "p_data_fp32", ".", "addcdiv_", "(", "-", "step_size", "*", "group", "[", "'lr'", "]", ",", "exp_avg", ",", "denom", ")", "\n", "", "else", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "step_size", "*", "group", "[", "'lr'", "]", ",", "exp_avg", ")", "\n", "\n", "", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.radam.PlainRAdam.__init__": [[82, 86], ["dict", "torch.optim.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ")", "\n", "\n", "super", "(", "PlainRAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.radam.PlainRAdam.__setstate__": [[87, 89], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.ranger.Ranger.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "PlainRAdam", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.radam.PlainRAdam.step": [[90, 143], ["closure", "p.grad.data.float", "p.data.float", "exp_avg_sq.mul_().addcmul_", "exp_avg.mul_().add_", "p.data.copy_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as", "p.data.float.add_", "exp_avg_sq.sqrt().add_", "p.data.float.addcdiv_", "p.data.float.add_", "exp_avg_sq.mul_", "exp_avg.mul_", "math.sqrt", "exp_avg_sq.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'RAdam does not support sparse gradients'", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "beta2_t", "=", "beta2", "**", "state", "[", "'step'", "]", "\n", "N_sma_max", "=", "2", "/", "(", "1", "-", "beta2", ")", "-", "1", "\n", "N_sma", "=", "N_sma_max", "-", "2", "*", "state", "[", "'step'", "]", "*", "beta2_t", "/", "(", "1", "-", "beta2_t", ")", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "\n", "# more conservative since it's an approximated value", "\n", "", "if", "N_sma", ">=", "5", ":", "\n", "                    ", "step_size", "=", "group", "[", "'lr'", "]", "*", "math", ".", "sqrt", "(", "(", "1", "-", "beta2_t", ")", "*", "(", "N_sma", "-", "4", ")", "/", "(", "N_sma_max", "-", "4", ")", "*", "(", "N_sma", "-", "2", ")", "/", "N_sma", "*", "N_sma_max", "/", "(", "N_sma_max", "-", "2", ")", ")", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "p_data_fp32", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "", "else", ":", "\n", "                    ", "step_size", "=", "group", "[", "'lr'", "]", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "p_data_fp32", ".", "add_", "(", "-", "step_size", ",", "exp_avg", ")", "\n", "\n", "", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.radam.AdamW.__init__": [[147, 151], ["dict", "torch.optim.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ",", "warmup", "=", "0", ")", ":", "\n", "        ", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "\n", "weight_decay", "=", "weight_decay", ",", "warmup", "=", "warmup", ")", "\n", "super", "(", "AdamW", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.radam.AdamW.__setstate__": [[152, 154], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.ranger.Ranger.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "AdamW", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.radam.AdamW.step": [[155, 208], ["closure", "p.grad.data.float", "p.data.float", "exp_avg_sq.mul_().addcmul_", "exp_avg.mul_().add_", "exp_avg_sq.sqrt().add_", "p.data.float.addcdiv_", "p.data.copy_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as", "p.data.float.add_", "exp_avg_sq.mul_", "exp_avg.mul_", "exp_avg_sq.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "\n", "if", "group", "[", "'warmup'", "]", ">", "state", "[", "'step'", "]", ":", "\n", "                    ", "scheduled_lr", "=", "1e-8", "+", "state", "[", "'step'", "]", "*", "group", "[", "'lr'", "]", "/", "group", "[", "'warmup'", "]", "\n", "", "else", ":", "\n", "                    ", "scheduled_lr", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "step_size", "=", "scheduled_lr", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "scheduled_lr", ",", "p_data_fp32", ")", "\n", "\n", "", "p_data_fp32", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.Timer.__init__": [[304, 306], ["datetime.datetime.datetime.now"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "cache", "=", "datetime", ".", "now", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.Timer.check": [[307, 312], ["datetime.datetime.datetime.now", "duration.total_seconds"], "methods", ["None"], ["", "def", "check", "(", "self", ")", ":", "\n", "        ", "now", "=", "datetime", ".", "now", "(", ")", "\n", "duration", "=", "now", "-", "self", ".", "cache", "\n", "self", ".", "cache", "=", "now", "\n", "return", "duration", ".", "total_seconds", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.Timer.reset": [[313, 315], ["datetime.datetime.datetime.now"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "cache", "=", "datetime", ".", "now", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.filter_cmd_args": [[25, 38], ["sorted", "cmd_args.index", "drop.append", "cmd_args.pop", "drop.append", "len", "cmd_args[].startswith"], "function", ["None"], ["@", "typechecked", "\n", "def", "filter_cmd_args", "(", "cmd_args", ":", "List", "[", "str", "]", ",", "remove", ":", "List", "[", "str", "]", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "drop", "=", "[", "]", "\n", "for", "key", "in", "remove", ":", "\n", "        ", "if", "key", "not", "in", "cmd_args", ":", "\n", "            ", "continue", "\n", "", "pos", "=", "cmd_args", ".", "index", "(", "key", ")", "\n", "drop", ".", "append", "(", "pos", ")", "\n", "if", "len", "(", "cmd_args", ")", ">", "(", "pos", "+", "1", ")", "and", "not", "cmd_args", "[", "pos", "+", "1", "]", ".", "startswith", "(", "\"--\"", ")", ":", "\n", "            ", "drop", ".", "append", "(", "pos", "+", "1", ")", "\n", "", "", "for", "pos", "in", "sorted", "(", "drop", ",", "reverse", "=", "True", ")", ":", "\n", "        ", "cmd_args", ".", "pop", "(", "pos", ")", "\n", "", "return", "cmd_args", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_short_uuid": [[40, 48], ["str().split", "str", "uuid.uuid4"], "function", ["None"], ["", "@", "typechecked", "\n", "def", "get_short_uuid", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"Return a 7 alpha-numeric character random string.  We could use the full uuid()\n    for better uniqueness properties, but it makes the filenames long and its not\n    needed for our purpose (simply grouping experiments that were run with the same\n    configuration).\n    \"\"\"", "\n", "return", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.parse_grid": [[50, 85], ["x.split", "util.get_short_uuid", "enumerate", "grid_opts.items", "list", "grid_idx.append", "list.append", "itertools.product", "copy.deepcopy", "zip", "parsed.append", "token.split", "copy.deepcopy.append"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_short_uuid", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "@", "typechecked", "\n", "def", "parse_grid", "(", "x", ":", "str", ",", "evaluation", ":", "str", "=", "'train'", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "\"\"\"Parse compact command line strings of the form:\n        --key1 val_a|val_b --key2 val_c|val_d\n\n    (here a vertical bar represents multiple values)\n\n    into a grid of separate strings e.g:\n        --key1 val_a --key2 val_c\n        --key1 val_a --key2 val_d\n        --key1 val_b --key2 val_c\n        --key1 val_b --key2 val_d\n\n    \"\"\"", "\n", "args", "=", "x", ".", "split", "(", "\" \"", ")", "\n", "group_id", "=", "get_short_uuid", "(", ")", "\n", "grid_opts", ",", "parsed", "=", "{", "}", ",", "[", "]", "\n", "for", "ii", ",", "token", "in", "enumerate", "(", "args", ")", ":", "\n", "        ", "if", "\"|\"", "in", "token", ":", "\n", "            ", "grid_opts", "[", "ii", "]", "=", "token", ".", "split", "(", "\"|\"", ")", "\n", "", "", "grid_idx", ",", "grid_vals", "=", "[", "]", ",", "[", "]", "\n", "for", "ii", ",", "val", "in", "grid_opts", ".", "items", "(", ")", ":", "\n", "        ", "grid_idx", ".", "append", "(", "ii", ")", "\n", "grid_vals", ".", "append", "(", "val", ")", "\n", "", "grid_vals", "=", "list", "(", "itertools", ".", "product", "(", "*", "grid_vals", ")", ")", "\n", "for", "cfg", "in", "grid_vals", ":", "\n", "        ", "base", "=", "copy", ".", "deepcopy", "(", "args", ")", "\n", "for", "ii", ",", "val", "in", "zip", "(", "grid_idx", ",", "cfg", ")", ":", "\n", "            ", "base", "[", "ii", "]", "=", "val", "\n", "", "if", "evaluation", "==", "'train'", ":", "\n", "            ", "base", ".", "append", "(", "f\"--group_id {group_id}\"", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "", "parsed", ".", "append", "(", "\" \"", ".", "join", "(", "base", ")", ")", "\n", "", "return", "{", "group_id", ":", "parsed", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.set_seeds": [[87, 97], ["random.seed", "numpy.random.seed", "torch.manual_seed"], "function", ["None"], ["", "@", "typechecked", "\n", "def", "set_seeds", "(", "seed", ":", "int", ")", ":", "\n", "    ", "\"\"\"Set seeds for randomisation libraries.\n\n    Args:\n        seed: the seed value\n    \"\"\"", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.update_src_web_video_dir": [[99, 116], ["pathlib.Path", "pathlib.Path", "str", "pathlib.Path"], "function", ["None"], ["", "def", "update_src_web_video_dir", "(", "config", ")", ":", "\n", "    ", "\"\"\"Provide backwards compatible support for web directories\n\n    Args:\n        config: a configuration object containing experiment paths\n    \"\"\"", "\n", "src_video_dir", "=", "Path", "(", "config", "[", "\"visualizer\"", "]", "[", "\"args\"", "]", "[", "\"src_video_dir\"", "]", ")", "\n", "dataset", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"dataset_name\"", "]", "\n", "if", "dataset", "not", "in", "str", "(", "src_video_dir", ")", ":", "\n", "        ", "lookup", "=", "{", "\n", "\"ActivityNet\"", ":", "\"activity-net/videos\"", ",", "\n", "\"QuerYD\"", ":", "\"QuerYD/videos\"", ",", "\n", "\"QuerYDSegments\"", ":", "\"QuerYDSegments/videos\"", ",", "\n", "\"AudioCaps\"", ":", "\"AudioCaps/videos\"", ",", "\n", "}", "\n", "src_video_dir", "=", "Path", "(", "src_video_dir", ".", "parts", "[", "0", "]", ")", "/", "lookup", "[", "dataset", "]", "\n", "", "config", "[", "\"visualizer\"", "]", "[", "\"args\"", "]", "[", "\"src_video_dir\"", "]", "=", "Path", "(", "src_video_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memory_summary": [[118, 125], ["psutil.virtual_memory", "print", "humanize.naturalsize", "humanize.naturalsize"], "function", ["None"], ["", "def", "memory_summary", "(", ")", ":", "\n", "    ", "vmem", "=", "psutil", ".", "virtual_memory", "(", ")", "\n", "msg", "=", "(", "\n", "f\">>> Currently using {vmem.percent}% of system memory \"", "\n", "f\"{humanize.naturalsize(vmem.used)}/{humanize.naturalsize(vmem.available)}\"", "\n", ")", "\n", "print", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.flatten_dict": [[127, 137], ["x.items", "isinstance", "util.flatten_dict", "flat_dict.update", "flat_dict.update", "flatten_dict.items"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.flatten_dict", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "def", "flatten_dict", "(", "x", ",", "keysep", "=", "\"-\"", ")", ":", "\n", "    ", "flat_dict", "=", "{", "}", "\n", "for", "key", ",", "val", "in", "x", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "val", ",", "dict", ")", ":", "\n", "            ", "flat_subdict", "=", "flatten_dict", "(", "val", ")", "\n", "flat_dict", ".", "update", "(", "{", "f\"{key}{keysep}{subkey}\"", ":", "subval", "\n", "for", "subkey", ",", "subval", "in", "flat_subdict", ".", "items", "(", ")", "}", ")", "\n", "", "else", ":", "\n", "            ", "flat_dict", ".", "update", "(", "{", "key", ":", "val", "}", ")", "\n", "", "", "return", "flat_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.expert_tensor_storage": [[139, 160], ["feat_aggregation.items", "expert_storage.items", "set", "set", "set", "config.get", "value.intersection", "expert_storage[].add", "all", "expert_storage[].add", "set", "expert_storage[].add", "ValueError", "config[].split"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add"], ["", "def", "expert_tensor_storage", "(", "experts", ",", "feat_aggregation", ")", ":", "\n", "\n", "    ", "expert_storage", "=", "{", "\"fixed\"", ":", "set", "(", ")", ",", "\"variable\"", ":", "set", "(", ")", ",", "\"flaky\"", ":", "set", "(", ")", "}", "\n", "# fixed_sz_experts, variable_sz_experts, flaky_experts = set(), set(), set()", "\n", "for", "expert", ",", "config", "in", "feat_aggregation", ".", "items", "(", ")", ":", "\n", "        ", "if", "config", "[", "\"temporal\"", "]", "in", "{", "\"vlad\"", "}", ":", "\n", "            ", "expert_storage", "[", "\"variable\"", "]", ".", "add", "(", "expert", ")", "\n", "", "elif", "all", "(", "[", "x", "in", "{", "\"avg\"", ",", "\"max\"", ",", "\"ent\"", ",", "\"std\"", "}", "for", "x", "in", "config", "[", "\"temporal\"", "]", ".", "split", "(", "\"-\"", ")", "]", ")", ":", "\n", "            ", "expert_storage", "[", "\"fixed\"", "]", ".", "add", "(", "expert", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"unknown temporal strategy: {config['temporal']}\"", ")", "\n", "# some \"flaky\" experts are only available for a fraction of videos - we need", "\n", "# to pass this information (in the form of indices) into the network for any", "\n", "# experts present in the current dataset", "\n", "", "if", "config", ".", "get", "(", "\"flaky\"", ",", "False", ")", ":", "\n", "            ", "expert_storage", "[", "\"flaky\"", "]", ".", "add", "(", "expert", ")", "\n", "\n", "# we only allocate storage for experts used by the current dataset", "\n", "", "", "for", "key", ",", "value", "in", "expert_storage", ".", "items", "(", ")", ":", "\n", "        ", "expert_storage", "[", "key", "]", "=", "value", ".", "intersection", "(", "set", "(", "experts", ")", ")", "\n", "", "return", "expert_storage", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.read_json": [[111, 115], ["fname.open", "json.load"], "function", ["None"], ["\"QuerYDSegments\"", ":", "\"QuerYDSegments/videos\"", ",", "\n", "\"AudioCaps\"", ":", "\"AudioCaps/videos\"", ",", "\n", "}", "\n", "src_video_dir", "=", "Path", "(", "src_video_dir", ".", "parts", "[", "0", "]", ")", "/", "lookup", "[", "dataset", "]", "\n", "", "config", "[", "\"visualizer\"", "]", "[", "\"args\"", "]", "[", "\"src_video_dir\"", "]", "=", "Path", "(", "src_video_dir", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.path2str": [[167, 174], ["x.items", "isinstance", "util.path2str", "isinstance", "str"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.path2str"], ["", "", "def", "path2str", "(", "x", ")", ":", "\n", "    ", "\"\"\"Recursively convert pathlib objects to strings to enable serialization\"\"\"", "\n", "for", "key", ",", "val", "in", "x", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "val", ",", "dict", ")", ":", "\n", "            ", "path2str", "(", "val", ")", "\n", "", "elif", "isinstance", "(", "val", ",", "Path", ")", ":", "\n", "            ", "x", "[", "key", "]", "=", "str", "(", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.write_json": [[117, 121], ["fname.open", "json.dump"], "function", ["None"], ["\n", "", "def", "memory_summary", "(", ")", ":", "\n", "    ", "vmem", "=", "psutil", ".", "virtual_memory", "(", ")", "\n", "msg", "=", "(", "\n", "f\">>> Currently using {vmem.percent}% of system memory \"", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.inf_loop": [[183, 187], ["itertools.repeat"], "function", ["None"], ["", "", "def", "inf_loop", "(", "data_loader", ")", ":", "\n", "    ", "''' wrapper function for endless data loader. '''", "\n", "for", "loader", "in", "itertools", ".", "repeat", "(", "data_loader", ")", ":", "\n", "        ", "yield", "from", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.compute_trn_config": [[189, 197], ["feat_agg.keys", "feat_agg[].keys"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["", "", "def", "compute_trn_config", "(", "config", ",", "logger", "=", "None", ")", ":", "\n", "    ", "trn_config", "=", "{", "}", "\n", "feat_agg", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"feat_aggregation\"", "]", "\n", "for", "static_expert", "in", "feat_agg", ".", "keys", "(", ")", ":", "\n", "        ", "if", "static_expert", "in", "feat_agg", ":", "\n", "            ", "if", "\"trn_seg\"", "in", "feat_agg", "[", "static_expert", "]", ".", "keys", "(", ")", ":", "\n", "                ", "trn_config", "[", "static_expert", "]", "=", "feat_agg", "[", "static_expert", "]", "[", "\"trn_seg\"", "]", "\n", "", "", "", "return", "trn_config", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.compute_dims": [[158, 254], ["sorted", "collections.OrderedDict", "dims.append"], "function", ["None"], ["        ", "expert_storage", "[", "key", "]", "=", "value", ".", "intersection", "(", "set", "(", "experts", ")", ")", "\n", "", "return", "expert_storage", "\n", "\n", "\n", "", "def", "read_json", "(", "fname", ")", ":", "\n", "    ", "with", "fname", ".", "open", "(", "'rt'", ")", "as", "handle", ":", "\n", "        ", "return", "json", ".", "load", "(", "handle", ",", "object_hook", "=", "OrderedDict", ")", "\n", "\n", "\n", "", "", "def", "path2str", "(", "x", ")", ":", "\n", "    ", "\"\"\"Recursively convert pathlib objects to strings to enable serialization\"\"\"", "\n", "for", "key", ",", "val", "in", "x", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "val", ",", "dict", ")", ":", "\n", "            ", "path2str", "(", "val", ")", "\n", "", "elif", "isinstance", "(", "val", ",", "Path", ")", ":", "\n", "            ", "x", "[", "key", "]", "=", "str", "(", "val", ")", "\n", "\n", "\n", "", "", "", "def", "write_json", "(", "content", ",", "fname", ",", "paths2strs", "=", "False", ")", ":", "\n", "    ", "if", "paths2strs", ":", "\n", "        ", "path2str", "(", "content", ")", "\n", "", "with", "fname", ".", "open", "(", "'wt'", ")", "as", "handle", ":", "\n", "        ", "json", ".", "dump", "(", "content", ",", "handle", ",", "indent", "=", "4", ",", "sort_keys", "=", "False", ")", "\n", "\n", "\n", "", "", "def", "inf_loop", "(", "data_loader", ")", ":", "\n", "    ", "''' wrapper function for endless data loader. '''", "\n", "for", "loader", "in", "itertools", ".", "repeat", "(", "data_loader", ")", ":", "\n", "        ", "yield", "from", "loader", "\n", "\n", "\n", "", "", "def", "compute_trn_config", "(", "config", ",", "logger", "=", "None", ")", ":", "\n", "    ", "trn_config", "=", "{", "}", "\n", "feat_agg", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"feat_aggregation\"", "]", "\n", "for", "static_expert", "in", "feat_agg", ".", "keys", "(", ")", ":", "\n", "        ", "if", "static_expert", "in", "feat_agg", ":", "\n", "            ", "if", "\"trn_seg\"", "in", "feat_agg", "[", "static_expert", "]", ".", "keys", "(", ")", ":", "\n", "                ", "trn_config", "[", "static_expert", "]", "=", "feat_agg", "[", "static_expert", "]", "[", "\"trn_seg\"", "]", "\n", "", "", "", "return", "trn_config", "\n", "\n", "\n", "", "@", "typechecked", "\n", "def", "compute_dims", "(", "\n", "config", ",", "\n", "logger", ":", "logging", ".", "Logger", "=", "None", ",", "\n", ")", "->", "Tuple", "[", "Dict", "[", "str", ",", "Tuple", "[", "int", ",", "int", "]", "]", ",", "Dict", "[", "str", ",", "int", "]", ",", "int", "]", ":", "\n", "    ", "if", "logger", "is", "None", ":", "\n", "        ", "logger", "=", "config", ".", "get_logger", "(", "'utils'", ")", "\n", "\n", "", "experts", "=", "config", "[", "\"experts\"", "]", "\n", "# TODO(Samuel): clean up the logic since it's a little convoluted", "\n", "ordered", "=", "sorted", "(", "config", "[", "\"experts\"", "]", "[", "\"modalities\"", "]", ")", "\n", "\n", "if", "experts", "[", "\"drop_feats\"", "]", ":", "\n", "        ", "to_drop", "=", "experts", "[", "\"drop_feats\"", "]", ".", "split", "(", "\",\"", ")", "\n", "logger", ".", "info", "(", "f\"dropping: {to_drop}\"", ")", "\n", "ordered", "=", "[", "x", "for", "x", "in", "ordered", "if", "x", "not", "in", "to_drop", "]", "\n", "\n", "", "feat_agg", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"feat_aggregation\"", "]", "\n", "dims", "=", "[", "]", "\n", "arch_args", "=", "config", "[", "\"arch\"", "]", "[", "\"args\"", "]", "\n", "vlad_clusters", "=", "arch_args", "[", "\"vlad_clusters\"", "]", "\n", "msg", "=", "f\"It is not valid to use both the `use_ce` and `mimic_ce_dims` options\"", "\n", "assert", "not", "(", "arch_args", "[", "\"use_ce\"", "]", "and", "arch_args", ".", "get", "(", "\"mimic_ce_dims\"", ",", "False", ")", ")", ",", "msg", "\n", "for", "expert", "in", "ordered", ":", "\n", "        ", "temporal", "=", "feat_agg", "[", "expert", "]", "[", "\"temporal\"", "]", "\n", "if", "expert", "==", "\"face\"", ":", "\n", "            ", "in_dim", ",", "out_dim", "=", "experts", "[", "\"face_dim\"", "]", ",", "experts", "[", "\"face_dim\"", "]", "\n", "", "elif", "expert", "in", "{", "\"audio\"", ",", "\"audio.vggish.0\"", "}", "and", "temporal", "==", "\"vlad\"", ":", "\n", "            ", "in_dim", ",", "out_dim", "=", "128", "*", "vlad_clusters", "[", "\"audio\"", "]", ",", "128", "\n", "", "elif", "expert", "in", "{", "\"pann\"", ",", "\"pann.pann.0\"", "}", "and", "temporal", "==", "\"vlad\"", ":", "\n", "            ", "in_dim", ",", "out_dim", "=", "2048", "*", "vlad_clusters", "[", "\"pann\"", "]", ",", "2048", "\n", "", "elif", "expert", "in", "{", "\"syncnet\"", ",", "\"audio.syncnet.0\"", "}", "and", "temporal", "==", "\"vlad\"", ":", "\n", "            ", "in_dim", ",", "out_dim", "=", "1024", "*", "vlad_clusters", "[", "\"syncnet\"", "]", ",", "1024", "\n", "", "elif", "expert", "in", "{", "\"vggsound\"", ",", "\"audio.vggsound.0\"", "}", "and", "temporal", "==", "\"vlad\"", ":", "\n", "            ", "in_dim", ",", "out_dim", "=", "512", "*", "vlad_clusters", "[", "\"vggsound\"", "]", ",", "512", "\n", "", "elif", "expert", "==", "\"speech\"", "and", "temporal", "==", "\"vlad\"", ":", "\n", "            ", "in_dim", ",", "out_dim", "=", "300", "*", "vlad_clusters", "[", "\"speech\"", "]", ",", "300", "\n", "", "elif", "expert", "==", "\"ocr\"", "and", "temporal", "==", "\"vlad\"", ":", "\n", "            ", "in_dim", ",", "out_dim", "=", "300", "*", "vlad_clusters", "[", "\"ocr\"", "]", ",", "300", "\n", "", "elif", "expert", "==", "\"detection\"", ":", "\n", "# allow for avg pooling", "\n", "            ", "det_clusters", "=", "arch_args", "[", "\"vlad_clusters\"", "]", ".", "get", "(", "\"detection\"", ",", "1", ")", "\n", "in_dim", ",", "out_dim", "=", "1541", "*", "det_clusters", ",", "1541", "\n", "", "elif", "expert", "==", "\"detection-sem\"", ":", "\n", "            ", "if", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", ".", "get", "(", "\"spatial_feats\"", ",", "False", ")", ":", "\n", "                ", "base", "=", "300", "+", "16", "\n", "", "else", ":", "\n", "                ", "base", "=", "300", "+", "5", "\n", "", "det_clusters", "=", "arch_args", "[", "\"vlad_clusters\"", "]", ".", "get", "(", "\"detection-sem\"", ",", "1", ")", "\n", "in_dim", ",", "out_dim", "=", "base", "*", "det_clusters", ",", "base", "\n", "", "elif", "expert", "==", "\"openpose\"", ":", "\n", "            ", "base", "=", "54", "\n", "det_clusters", "=", "arch_args", "[", "\"vlad_clusters\"", "]", ".", "get", "(", "\"openpose\"", ",", "1", ")", "\n", "in_dim", ",", "out_dim", "=", "base", "*", "det_clusters", ",", "base", "\n", "", "else", ":", "\n", "            ", "common_dim", "=", "feat_agg", "[", "expert", "]", "[", "\"feat_dims\"", "]", "[", "feat_agg", "[", "expert", "]", "[", "\"type\"", "]", "]", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.ensure_tensor": [[297, 301], ["isinstance", "torch.from_numpy"], "function", ["None"], ["", "def", "ensure_tensor", "(", "x", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.tensor2im": [[317, 338], ["np.tile.astype", "isinstance", "isinstance", "image_tensor[].cpu().float().numpy", "numpy.tile", "image_tensor[].cpu().float", "numpy.transpose", "image_tensor[].cpu"], "function", ["None"], ["", "", "def", "tensor2im", "(", "input_image", ",", "imtype", "=", "np", ".", "uint8", ")", ":", "\n", "    ", "\"\"\"\"Converts a Tensor array into a numpy image array.\n\n    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "input_image", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "isinstance", "(", "input_image", ",", "torch", ".", "Tensor", ")", ":", "# get the data from a variable", "\n", "            ", "image_tensor", "=", "input_image", ".", "data", "\n", "", "else", ":", "\n", "            ", "return", "input_image", "\n", "# convert it into a numpy array", "\n", "", "image_numpy", "=", "image_tensor", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "if", "image_numpy", ".", "shape", "[", "0", "]", "==", "1", ":", "# grayscale to RGB", "\n", "            ", "image_numpy", "=", "np", ".", "tile", "(", "image_numpy", ",", "(", "3", ",", "1", ",", "1", ")", ")", "\n", "# post-processing: tranpose and scaling", "\n", "", "image_numpy", "=", "(", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "+", "1", ")", "/", "2.0", "*", "255.0", "\n", "", "else", ":", "# if it is a numpy array, do nothing", "\n", "        ", "image_numpy", "=", "input_image", "\n", "", "return", "image_numpy", ".", "astype", "(", "imtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.save_image": [[340, 349], ["PIL.Image.fromarray", "Image.fromarray.save"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.save"], ["", "def", "save_image", "(", "image_numpy", ",", "image_path", ")", ":", "\n", "    ", "\"\"\"Save a numpy image to the disk\n\n    Parameters:\n        image_numpy (numpy array) -- input numpy array\n        image_path (str)          -- the path of the image\n    \"\"\"", "\n", "image_pil", "=", "Image", ".", "fromarray", "(", "image_numpy", ")", "\n", "image_pil", ".", "save", "(", "image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.print_numpy": [[351, 365], ["x.flatten.astype", "print", "x.flatten.flatten", "print", "numpy.mean", "numpy.min", "numpy.max", "numpy.median", "numpy.std"], "function", ["None"], ["", "def", "print_numpy", "(", "x", ",", "val", "=", "True", ",", "shp", "=", "False", ")", ":", "\n", "    ", "\"\"\"Print the mean, min, max, median, std, and size of a numpy array\n\n    Parameters:\n        val (bool) -- if print the values of the numpy array\n        shp (bool) -- if print the shape of the numpy array\n    \"\"\"", "\n", "x", "=", "x", ".", "astype", "(", "np", ".", "float64", ")", "\n", "if", "shp", ":", "\n", "        ", "print", "(", "'shape,'", ",", "x", ".", "shape", ")", "\n", "", "if", "val", ":", "\n", "        ", "x", "=", "x", ".", "flatten", "(", ")", "\n", "print", "(", "'mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f'", "%", "(", "\n", "np", ".", "mean", "(", "x", ")", ",", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", ",", "np", ".", "median", "(", "x", ")", ",", "np", ".", "std", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdirs": [[256, 263], ["isinstance", "util.mkdir", "isinstance", "util.mkdir"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir"], ["common_dim", "=", "common_dim", "*", "len", "(", "feat_agg", "[", "expert", "]", "[", "\"temporal\"", "]", ".", "split", "(", "\"-\"", ")", ")", "\n", "in_dim", ",", "out_dim", "=", "common_dim", ",", "common_dim", "\n", "\n", "# For the CE architecture, we need to project all features to a common", "\n", "# dimensionality", "\n", "", "is_ce", "=", "config", "[", "\"arch\"", "]", "[", "\"type\"", "]", "==", "\"CENet\"", "\n", "if", "is_ce", "and", "(", "arch_args", "[", "\"use_ce\"", "]", "or", "arch_args", ".", "get", "(", "\"mimic_ce_dims\"", ",", "False", ")", ")", ":", "\n", "            ", "out_dim", "=", "experts", "[", "\"ce_shared_dim\"", "]", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir": [[265, 269], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "dims", ".", "append", "(", "(", "expert", ",", "(", "in_dim", ",", "out_dim", ")", ")", ")", "\n", "", "expert_dims", "=", "OrderedDict", "(", "dims", ")", "\n", "\n", "if", "vlad_clusters", "[", "\"text\"", "]", "==", "0", ":", "\n", "        ", "msg", "=", "\"vlad can only be disabled for text with single tokens\"", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.gen_ablations_for_dataset.handle_moee_config": [[13, 23], ["None"], "function", ["None"], ["def", "handle_moee_config", "(", "config", ")", ":", "\n", "    ", "\"\"\"For the official ablations on MSRVTT, we provide MoEE with the same hyperparam\n    budget as CE and run a search to find the best hyperparams.  For the unofficial\n    ablations, we use the same padding/VLAD settings as CE.\n    \"\"\"", "\n", "config", "=", "{", "\n", "\"inherit_from\"", ":", "config", "[", "\"inherit_from\"", "]", ",", "\n", "\"arch\"", ":", "{", "\"type\"", ":", "\"CENet\"", ",", "\"args\"", ":", "{", "\"use_ce\"", ":", "\"\"", "}", "}", ",", "\n", "}", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.gen_ablations_for_dataset.remove_audio_streams": [[25, 41], ["dest_path.replace.replace", "[].remove"], "function", ["None"], ["", "def", "remove_audio_streams", "(", "config", ",", "dest_path", ")", ":", "\n", "    ", "\"\"\"Prune audio-based features from the config and dest_path name (necessary for\n    datasets like MSVD which do not possess sound.)  If the audio feature was the control\n    variable in the experiment, we return False for the dest_path, such that the ablation\n    is removed altogether.\n    \"\"\"", "\n", "audio_tags", "=", "[", "\"audio\"", ",", "\"speech\"", "]", "\n", "for", "audio_tag", "in", "audio_tags", ":", "\n", "        ", "if", "f\"-{audio_tag}.\"", "in", "dest_path", ":", "\n", "            ", "return", "config", ",", "False", "\n", "\n", "", "dest_path", "=", "dest_path", ".", "replace", "(", "f\"-{audio_tag}\"", ",", "\"\"", ")", "\n", "if", "\"experts\"", "in", "config", "and", "\"modalities\"", "in", "config", "[", "\"experts\"", "]", ":", "\n", "            ", "if", "audio_tag", "in", "config", "[", "\"experts\"", "]", "[", "\"modalities\"", "]", ":", "\n", "                ", "config", "[", "\"experts\"", "]", "[", "\"modalities\"", "]", ".", "remove", "(", "audio_tag", ")", "\n", "", "", "", "return", "config", ",", "dest_path", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.gen_ablations_for_dataset.main": [[43, 90], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "pathlib.Path", "open", "parser.parse_args.exp_list.replace", "pathlib.Path.exists", "print", "row.split", "any", "config_path.replace", "config[].replace", "print", "output_rows.append", "print", "open", "json.load", "gen_ablations_for_dataset.handle_moee_config", "gen_ablations_for_dataset.remove_audio_streams", "open", "json.dump", "open", "sorted", "f.read().splitlines", "len", "pathlib.Path", "list", "f.write", "set", "f.read"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.gen_ablations_for_dataset.handle_moee_config", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.gen_ablations_for_dataset.remove_audio_streams"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--refresh'", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "'--update_ablation_list'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--src_dataset'", ",", "default", "=", "\"msrvtt\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dest_dataset'", ",", "default", "=", "\"lsmdc\"", ")", "\n", "parser", ".", "add_argument", "(", "'--exp_list'", ",", "default", "=", "\"slurm/msrvtt-ablations.txt\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "with", "open", "(", "args", ".", "exp_list", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "exps", "=", "[", "x", "for", "x", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "if", "x", "]", "\n", "\n", "", "print", "(", "f\"Found {len(exps)} experiments in {args.exp_list}\"", ")", "\n", "dest_exp_path", "=", "Path", "(", "args", ".", "exp_list", ".", "replace", "(", "\"msrvtt\"", ",", "args", ".", "dest_dataset", ")", ")", "\n", "if", "dest_exp_path", ".", "exists", "(", ")", "and", "not", "args", ".", "refresh", ":", "\n", "        ", "print", "(", "f\"experiment list found at {dest_exp_path}, skipping...\"", ")", "\n", "return", "\n", "\n", "", "output_rows", "=", "[", "]", "\n", "exclude", "=", "[", "\"miech\"", ",", "\"jsfusion\"", "]", "\n", "for", "row", "in", "exps", ":", "\n", "        ", "flag", ",", "config_path", ",", "seed_flag", ",", "seed_opts", "=", "row", ".", "split", "(", ")", "\n", "if", "any", "(", "[", "x", "in", "config_path", "for", "x", "in", "exclude", "]", ")", ":", "\n", "            ", "continue", "\n", "", "with", "open", "(", "config_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "config", "=", "json", ".", "load", "(", "f", ")", "\n", "", "if", "Path", "(", "config_path", ")", ".", "stem", "==", "\"train-full-moee\"", ":", "\n", "            ", "config", "=", "handle_moee_config", "(", "config", ")", "\n", "", "dest_path", "=", "config_path", ".", "replace", "(", "args", ".", "src_dataset", ",", "args", ".", "dest_dataset", ")", "\n", "config", "[", "\"inherit_from\"", "]", "=", "config", "[", "\"inherit_from\"", "]", ".", "replace", "(", "args", ".", "src_dataset", ",", "\n", "args", ".", "dest_dataset", ")", "\n", "if", "args", ".", "dest_dataset", "==", "\"msvd\"", ":", "\n", "            ", "config", ",", "dest_path", "=", "remove_audio_streams", "(", "config", ",", "dest_path", ")", "\n", "if", "not", "dest_path", ":", "\n", "                ", "continue", "\n", "\n", "", "", "print", "(", "f\"writing config to {dest_path}\"", ")", "\n", "with", "open", "(", "dest_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "config", ",", "f", ",", "indent", "=", "4", ",", "sort_keys", "=", "False", ")", "\n", "", "output_rows", ".", "append", "(", "[", "flag", ",", "dest_path", ",", "seed_flag", ",", "seed_opts", "]", ")", "\n", "\n", "", "if", "args", ".", "update_ablation_list", ":", "\n", "        ", "print", "(", "f\"Writing new experiment list to {dest_exp_path}\"", ")", "\n", "output_rows", "=", "[", "\" \"", ".", "join", "(", "x", ")", "for", "x", "in", "output_rows", "]", "\n", "with", "open", "(", "dest_exp_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "row", "in", "sorted", "(", "list", "(", "set", "(", "output_rows", ")", ")", ")", ":", "\n", "                ", "f", ".", "write", "(", "f\"{row}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.__init__": [[20, 110], ["pathlib.Path", "zsvision.zs_utils.load_json_config", "parse_config._update_config", "parse_config.ConfigParser._config.get", "parse_config.ConfigParser.set_exper_name", "getattr", "parse_config.ConfigParser._config.get", "vars().get", "parse_config.ConfigParser.save_dir.mkdir", "parse_config.ConfigParser.log_dir.mkdir", "utils.write_json", "args.parse_args.parse_args.add_argument", "args.parse_args.parse_args.parse_args", "isinstance", "pathlib.Path", "parse_config.ConfigParser._config.get", "pathlib.Path().exists", "pathlib.Path", "pathlib.Path", "datetime.datetime.datetime.now().strftime", "logger.setup_logging", "args.parse_args.parse_args.parse_args", "vars", "list", "print", "time.time", "os.system", "print", "print", "pathlib.Path", "datetime.datetime.datetime.now", "pathlib.Path", "config_dir.glob", "parse_config.ConfigParser._config.get", "len", "time.time"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._update_config", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.set_exper_name", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.write_json", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.logger.logger.setup_logging", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "options", "=", "''", ",", "timestamp", "=", "True", ",", "slave_mode", "=", "False", ")", ":", "\n", "# slave_mode - when calling the config parser form an existing process, we", "\n", "# avoid reinitialising the logger and ignore sys.argv when argparsing.", "\n", "\n", "# parse default and custom cli options", "\n", "        ", "for", "opt", "in", "options", ":", "\n", "            ", "args", ".", "add_argument", "(", "*", "opt", ".", "flags", ",", "default", "=", "None", ",", "type", "=", "opt", ".", "type", ")", "\n", "\n", "", "if", "slave_mode", ":", "\n", "            ", "args", "=", "args", ".", "parse_args", "(", "args", "=", "[", "]", ")", "\n", "", "elif", "isinstance", "(", "args", ",", "mock", ".", "Mock", ")", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "args", "=", "args", ".", "parse_args", "(", ")", "\n", "\n", "", "if", "args", ".", "device", ":", "\n", "            ", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "args", ".", "device", "\n", "\n", "", "if", "args", ".", "resume", "and", "not", "slave_mode", ":", "\n", "            ", "self", ".", "resume", "=", "Path", "(", "args", ".", "resume", ")", "\n", "try", ":", "\n", "                ", "if", "args", ".", "finetune", ":", "\n", "                    ", "self", ".", "finetune", "=", "args", ".", "finetune", "\n", "", "", "except", "AttributeError", ":", "\n", "                ", "pass", "\n", "print", "(", "\"Finetune not being used\"", ")", "\n", "", "", "else", ":", "\n", "            ", "msg_no_cfg", "=", "\"Config file must be specified\"", "\n", "assert", "args", ".", "config", "is", "not", "None", ",", "msg_no_cfg", "\n", "self", ".", "resume", "=", "None", "\n", "", "self", ".", "cfg_fname", "=", "Path", "(", "args", ".", "config", ")", "\n", "\n", "config", "=", "load_json_config", "(", "self", ".", "cfg_fname", ")", "\n", "self", ".", "_config", "=", "_update_config", "(", "config", ",", "options", ",", "args", ")", "\n", "\n", "if", "self", ".", "_config", ".", "get", "(", "\"eval_config\"", ",", "False", ")", ":", "\n", "# validate path to evaluation file", "\n", "            ", "eval_cfg_path", "=", "self", ".", "_config", ".", "get", "(", "\"eval_config\"", ")", "\n", "msg", "=", "f\"eval_config was specified, but `{eval_cfg_path}` does not exist\"", "\n", "assert", "Path", "(", "self", ".", "_config", ".", "get", "(", "\"eval_config\"", ")", ")", ".", "exists", "(", ")", ",", "msg", "\n", "\n", "# set save_dir where trained model and log will be saved.", "\n", "", "if", "\"tester\"", "in", "self", ".", "config", ":", "\n", "            ", "save_dir", "=", "Path", "(", "self", ".", "config", "[", "'tester'", "]", "[", "'save_dir'", "]", ")", "\n", "", "else", ":", "\n", "            ", "save_dir", "=", "Path", "(", "self", ".", "config", "[", "'trainer'", "]", "[", "'save_dir'", "]", ")", "\n", "", "timestamp", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "r\"%Y-%m-%d_%H-%M-%S\"", ")", "if", "timestamp", "else", "\"\"", "\n", "\n", "if", "slave_mode", ":", "\n", "            ", "timestamp", "=", "f\"{timestamp}-eval-worker\"", "\n", "\n", "", "exper_name", "=", "self", ".", "set_exper_name", "(", "args", ",", "config", "=", "config", ")", "\n", "\n", "if", "getattr", "(", "args", ",", "\"group_id\"", ",", "False", ")", ":", "\n", "            ", "subdir", "=", "Path", "(", "args", ".", "group_id", ")", "/", "f\"seed-{args.group_seed}\"", "/", "timestamp", "\n", "", "else", ":", "\n", "            ", "subdir", "=", "timestamp", "\n", "\n", "# store challenge experiments in a further subdirectory", "\n", "", "if", "self", ".", "_config", ".", "get", "(", "\"challenge_mode\"", ",", "False", ")", ":", "\n", "            ", "challenge_tag", "=", "\"cvpr2020-challenge\"", "\n", "exper_name", "=", "f\"{challenge_tag}/{exper_name}\"", "\n", "\n", "", "self", ".", "_save_dir", "=", "save_dir", "/", "'models'", "/", "exper_name", "/", "subdir", "\n", "self", ".", "_web_log_dir", "=", "save_dir", "/", "'web'", "/", "exper_name", "/", "subdir", "\n", "self", ".", "_log_dir", "=", "save_dir", "/", "'log'", "/", "exper_name", "/", "subdir", "\n", "self", ".", "_exper_name", "=", "exper_name", "\n", "self", ".", "_args", "=", "args", "\n", "\n", "# if set, remove all previous experiments with the current config", "\n", "if", "vars", "(", "args", ")", ".", "get", "(", "\"purge_exp_dir\"", ",", "False", ")", ":", "\n", "            ", "for", "dirpath", "in", "(", "self", ".", "_save_dir", ",", "self", ".", "_log_dir", ",", "self", ".", "_web_log_dir", ")", ":", "\n", "                ", "config_dir", "=", "dirpath", ".", "parent", "\n", "existing", "=", "list", "(", "config_dir", ".", "glob", "(", "\"*\"", ")", ")", "\n", "print", "(", "f\"purging {len(existing)} directories from config_dir...\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "os", ".", "system", "(", "f\"rm -rf {config_dir}\"", ")", "\n", "print", "(", "f\"Finished purge in {time.time() - tic:.3f}s\"", ")", "\n", "\n", "", "", "self", ".", "save_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "log_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# save updated config file to the checkpoint dir", "\n", "write_json", "(", "self", ".", "config", ",", "self", ".", "save_dir", "/", "'config.json'", ")", "\n", "\n", "# configure logging module", "\n", "if", "not", "slave_mode", ":", "\n", "            ", "self", ".", "log_path", "=", "setup_logging", "(", "self", ".", "log_dir", ")", "\n", "\n", "", "self", ".", "log_levels", "=", "{", "0", ":", "logging", ".", "WARNING", ",", "1", ":", "logging", ".", "INFO", ",", "2", ":", "logging", ".", "DEBUG", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.set_exper_name": [[111, 140], ["getattr", "getattr", "args.custom_args.split", "print", "print", "print", "key_val_pair.split", "zsvision.zs_utils.set_nested_key_val", "key.replace", "val.replace.replace.replace", "key.replace.split"], "methods", ["None"], ["", "def", "set_exper_name", "(", "self", ",", "args", ",", "config", ")", ":", "\n", "# We assume that the config files are organised into directories such that", "\n", "# each directory has the name of the dataset.", "\n", "        ", "dataset_name", "=", "self", ".", "cfg_fname", ".", "parent", ".", "stem", "\n", "exper_name", "=", "f\"{dataset_name}-{self.cfg_fname.stem}\"", "\n", "if", "args", ".", "custom_args", ":", "\n", "            ", "key_val_lists", "=", "args", ".", "custom_args", ".", "split", "(", "\"+\"", ")", "\n", "for", "key_val_pair", "in", "key_val_lists", ":", "\n", "                ", "print", "(", "f\"parsing key-val pair : {key_val_pair}\"", ")", "\n", "key", ",", "val", "=", "key_val_pair", ".", "split", "(", "\"@\"", ")", "\n", "set_nested_key_val", "(", "key", ",", "val", ",", "self", ".", "_config", ")", "\n", "# remove periods from key names", "\n", "key_", "=", "key", ".", "replace", "(", "\"_.\"", ",", "\"--\"", ")", "\n", "# remove commas from value names", "\n", "val", "=", "val", ".", "replace", "(", "\",\"", ",", "\"--\"", ")", "\n", "custom_tag", "=", "\"-\"", ".", "join", "(", "key_", ".", "split", "(", "\".\"", ")", "[", "-", "2", ":", "]", ")", "\n", "exper_name", "=", "f\"{exper_name}-{custom_tag}-{val}\"", "\n", "\n", "", "", "if", "getattr", "(", "args", ",", "\"disable_workers\"", ",", "False", ")", ":", "\n", "            ", "print", "(", "\"Disabling data loader workers....\"", ")", "\n", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"num_workers\"", "]", "=", "0", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"train_single_epoch\"", ",", "False", ")", ":", "\n", "            ", "print", "(", "\"Restricting training to a single epoch....\"", ")", "\n", "config", "[", "\"trainer\"", "]", "[", "\"epochs\"", "]", "=", "1", "\n", "config", "[", "\"trainer\"", "]", "[", "\"save_period\"", "]", "=", "1", "\n", "config", "[", "\"trainer\"", "]", "[", "\"skip_first_n_saves\"", "]", "=", "0", "\n", "exper_name", "=", "f\"{exper_name}-train-single-epoch\"", "\n", "", "return", "exper_name", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.init": [[141, 154], ["dict", "all", "dict.update", "getattr"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update"], ["", "def", "init", "(", "self", ",", "name", ",", "module", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Finds a function handle with the name given as 'type' in config, and returns\n        the instance initialized with corresponding keyword args given as 'args'.\n        \"\"\"", "\n", "module_name", "=", "self", "[", "name", "]", "[", "'type'", "]", "\n", "module_args", "=", "dict", "(", "self", "[", "name", "]", "[", "'args'", "]", ")", "\n", "msg", "=", "(", "f\"Fail for {module_name}\\n\"", "\n", "f\"overwriting kwargs given in config file is not allowed\\n\"", "\n", "f\"passed kwargs: {kwargs}\\n\"", "\n", "f\"for module_args: {module_args})\"", ")", "\n", "assert", "all", "(", "[", "k", "not", "in", "module_args", "for", "k", "in", "kwargs", "]", ")", ",", "msg", "\n", "module_args", ".", "update", "(", "kwargs", ")", "\n", "return", "getattr", "(", "module", ",", "module_name", ")", "(", "*", "args", ",", "**", "module_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.__getitem__": [[155, 157], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "self", ".", "config", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.__len__": [[158, 162], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "# NOTE: This is used for boolean checking deep inside ray.tune, so we required it", "\n", "# to be defined.", "\n", "        ", "return", "len", "(", "self", ".", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.__setitem__": [[163, 165], ["None"], "methods", ["None"], ["", "def", "__setitem__", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "self", ".", "config", "[", "name", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.__contains__": [[166, 168], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "name", "in", "self", ".", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.get": [[169, 171], ["parse_config.ConfigParser.config.get"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["", "def", "get", "(", "self", ",", "name", ",", "default", ")", ":", "\n", "        ", "return", "self", ".", "config", ".", "get", "(", "name", ",", "default", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys": [[172, 174], ["parse_config.ConfigParser.config.keys"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["", "def", "keys", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "config", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.get_logger": [[175, 182], ["msg_verbosity.format.format.format", "logging.getLogger", "logging.getLogger.setLevel", "parse_config.ConfigParser.log_levels.keys"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["", "def", "get_logger", "(", "self", ",", "name", ",", "verbosity", "=", "2", ")", ":", "\n", "        ", "msg_verbosity", "=", "\"verbosity option {} is invalid. Valid options are {}.\"", "\n", "msg_verbosity", "=", "msg_verbosity", ".", "format", "(", "verbosity", ",", "self", ".", "log_levels", ".", "keys", "(", ")", ")", "\n", "assert", "verbosity", "in", "self", ".", "log_levels", ",", "msg_verbosity", "\n", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "self", ".", "log_levels", "[", "verbosity", "]", ")", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.config": [[184, 187], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_config", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.save_dir": [[188, 191], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "save_dir", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_save_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.log_dir": [[192, 195], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "log_dir", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_log_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.__repr__": [[196, 198], ["pprint.PrettyPrinter().pformat", "pprint.PrettyPrinter"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "pprint", ".", "PrettyPrinter", "(", ")", ".", "pformat", "(", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items": [[199, 201], ["parse_config.ConfigParser._config.items"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "def", "items", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_config", ".", "items", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config._update_config": [[204, 210], ["getattr", "parse_config._get_opt_name", "parse_config._set_by_path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._get_opt_name", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._set_by_path"], ["", "", "def", "_update_config", "(", "config", ",", "options", ",", "args", ")", ":", "\n", "    ", "for", "opt", "in", "options", ":", "\n", "        ", "value", "=", "getattr", "(", "args", ",", "_get_opt_name", "(", "opt", ".", "flags", ")", ")", "\n", "if", "value", "is", "not", "None", ":", "\n", "            ", "_set_by_path", "(", "config", ",", "opt", ".", "target", ",", "value", ")", "\n", "", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config._get_opt_name": [[212, 217], ["flags[].replace", "flg.startswith", "flg.replace"], "function", ["None"], ["", "def", "_get_opt_name", "(", "flags", ")", ":", "\n", "    ", "for", "flg", "in", "flags", ":", "\n", "        ", "if", "flg", ".", "startswith", "(", "'--'", ")", ":", "\n", "            ", "return", "flg", ".", "replace", "(", "'--'", ",", "''", ")", "\n", "", "", "return", "flags", "[", "0", "]", ".", "replace", "(", "'--'", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config._set_by_path": [[219, 222], ["parse_config._get_by_path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._get_by_path"], ["", "def", "_set_by_path", "(", "tree", ",", "keys", ",", "value", ")", ":", "\n", "    ", "\"\"\"Set a value in a nested object in tree by sequence of keys.\"\"\"", "\n", "_get_by_path", "(", "tree", ",", "keys", "[", ":", "-", "1", "]", ")", "[", "keys", "[", "-", "1", "]", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config._get_by_path": [[224, 227], ["functools.reduce"], "function", ["None"], ["", "def", "_get_by_path", "(", "tree", ",", "keys", ")", ":", "\n", "    ", "\"\"\"Access a nested object in tree by sequence of keys.\"\"\"", "\n", "return", "reduce", "(", "getitem", ",", "keys", ",", "tree", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.ranger.Ranger.__init__": [[33, 85], ["dict", "torch.optim.optimizer.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "range"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["            ", "raise", "ValueError", "(", "f'Invalid lookahead steps: {k}'", ")", "\n", "", "if", "not", "lr", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid Learning Rate: {lr}'", ")", "\n", "", "if", "not", "eps", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "f'Invalid eps: {eps}'", ")", "\n", "\n", "#parameter comments:", "\n", "# beta1 (momentum) of .95 seems to work better than .90...", "\n", "#N_sma_threshold of 5 seems better in testing than 4.", "\n", "#In both cases, worth testing on your dataset (.90 vs .95, 4 vs 5) to make sure which works best for you.", "\n", "\n", "#prep defaults and init torch.optim base", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "alpha", "=", "alpha", ",", "k", "=", "k", ",", "step_counter", "=", "0", ",", "betas", "=", "betas", ",", "N_sma_threshhold", "=", "N_sma_threshhold", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ")", "\n", "super", "(", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n", "#adjustable threshold", "\n", "self", ".", "N_sma_threshhold", "=", "N_sma_threshhold", "\n", "\n", "#now we can get to work...", "\n", "#removed as we now use step from RAdam...no need for duplicate step counting", "\n", "#for group in self.param_groups:", "\n", "#    group[\"step_counter\"] = 0", "\n", "#print(\"group step counter init\")", "\n", "\n", "#look ahead params", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "k", "=", "k", "\n", "\n", "#radam buffer for state", "\n", "self", ".", "radam_buffer", "=", "[", "[", "None", ",", "None", ",", "None", "]", "for", "ind", "in", "range", "(", "10", ")", "]", "\n", "\n", "#self.first_run_check=0", "\n", "\n", "#lookahead weights", "\n", "#9/2/19 - lookahead param tensors have been moved to state storage.  ", "\n", "#This should resolve issues with load/save where weights were left in GPU memory from first load, slowing down future runs.", "\n", "\n", "#self.slow_weights = [[p.clone().detach() for p in group['params']]", "\n", "#                     for group in self.param_groups]", "\n", "\n", "#don't use grad for lookahead weights", "\n", "#for w in it.chain(*self.slow_weights):", "\n", "#    w.requires_grad = False", "\n", "\n", "", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "print", "(", "\"set state called\"", ")", "\n", "super", "(", "Ranger", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n", "\n", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "loss", "=", "None", "\n", "#note - below is commented out b/c I have other work that passes back the loss as a float, and thus not a callable closure.  ", "\n", "#Uncomment if you need to use the actual closure...", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.ranger.Ranger.__setstate__": [[100, 103], ["print", "super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.ranger.Ranger.__setstate__"], ["", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "#get state dict for this param", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.ranger.Ranger.step": [[104, 196], ["p.grad.data.float", "p.data.float", "exp_avg_sq.mul_().addcmul_", "exp_avg.mul_().add_", "p.data.copy_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.empty_like", "state[].copy_", "state[].type_as", "state[].type_as", "p.data.float.add_", "exp_avg_sq.sqrt().add_", "p.data.float.addcdiv_", "p.data.float.add_", "slow_p.add_", "p.data.copy_", "exp_avg_sq.mul_", "exp_avg.mul_", "int", "math.sqrt", "exp_avg_sq.sqrt"], "methods", ["None"], ["if", "len", "(", "state", ")", "==", "0", ":", "#if first time to run...init dictionary with our desired entries", "\n", "#if self.first_run_check==0:", "\n", "#self.first_run_check=1", "\n", "#print(\"Initializing slow buffer...should not see this at load from saved model!\")", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "\n", "#look ahead weight storage now in state dict ", "\n", "state", "[", "'slow_buffer'", "]", "=", "torch", ".", "empty_like", "(", "p", ".", "data", ")", "\n", "state", "[", "'slow_buffer'", "]", ".", "copy_", "(", "p", ".", "data", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "#begin computations ", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "#compute variance mov avg", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "#compute mean moving avg", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "\n", "buffered", "=", "self", ".", "radam_buffer", "[", "int", "(", "state", "[", "'step'", "]", "%", "10", ")", "]", "\n", "if", "state", "[", "'step'", "]", "==", "buffered", "[", "0", "]", ":", "\n", "                    ", "N_sma", ",", "step_size", "=", "buffered", "[", "1", "]", ",", "buffered", "[", "2", "]", "\n", "", "else", ":", "\n", "                    ", "buffered", "[", "0", "]", "=", "state", "[", "'step'", "]", "\n", "beta2_t", "=", "beta2", "**", "state", "[", "'step'", "]", "\n", "N_sma_max", "=", "2", "/", "(", "1", "-", "beta2", ")", "-", "1", "\n", "N_sma", "=", "N_sma_max", "-", "2", "*", "state", "[", "'step'", "]", "*", "beta2_t", "/", "(", "1", "-", "beta2_t", ")", "\n", "buffered", "[", "1", "]", "=", "N_sma", "\n", "if", "N_sma", ">", "self", ".", "N_sma_threshhold", ":", "\n", "                        ", "step_size", "=", "math", ".", "sqrt", "(", "(", "1", "-", "beta2_t", ")", "*", "(", "N_sma", "-", "4", ")", "/", "(", "N_sma_max", "-", "4", ")", "*", "(", "N_sma", "-", "2", ")", "/", "N_sma", "*", "N_sma_max", "/", "(", "N_sma_max", "-", "2", ")", ")", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "else", ":", "\n", "                        ", "step_size", "=", "1.0", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "buffered", "[", "2", "]", "=", "step_size", "\n", "\n", "", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "\n", "", "if", "N_sma", ">", "self", ".", "N_sma_threshhold", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "p_data_fp32", ".", "addcdiv_", "(", "-", "step_size", "*", "group", "[", "'lr'", "]", ",", "exp_avg", ",", "denom", ")", "\n", "", "else", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "-", "step_size", "*", "group", "[", "'lr'", "]", ",", "exp_avg", ")", "\n", "\n", "", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "#integrated look ahead...", "\n", "#we do it at the param level instead of group level", "\n", "if", "state", "[", "'step'", "]", "%", "group", "[", "'k'", "]", "==", "0", ":", "\n", "                    ", "slow_p", "=", "state", "[", "'slow_buffer'", "]", "#get access to slow param tensor", "\n", "slow_p", ".", "add_", "(", "self", ".", "alpha", ",", "p", ".", "data", "-", "slow_p", ")", "#(fast weights - slow weights) * alpha", "\n", "p", ".", "data", ".", "copy_", "(", "slow_p", ")", "#copy interpolated weights to RAdam param tensor", "\n", "\n", "", "", "", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.utils.wait_until_loaded_page": [[9, 32], ["time.time", "time.time", "logging.info", "driver.find_element_by_xpath", "driver.find_element_by_xpath", "driver.find_element_by_xpath", "time.sleep"], "function", ["None"], ["def", "wait_until_loaded_page", "(", "driver", ",", "logging", ")", ":", "\n", "    ", "\"\"\"\n    Do not start scraping until page loaded fully. Could also use the\n    scroll function but we already know the link to fully loaded page.\n    \"\"\"", "\n", "ok", "=", "0", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "while", "ok", "==", "0", ":", "\n", "        ", "try", ":", "\n", "            ", "_", "=", "driver", ".", "find_element_by_xpath", "(", "\"//*[contains(text(), 'No results found')]\"", ")", "\n", "ok", "=", "1", "\n", "", "except", "NoSuchElementException", ":", "\n", "            ", "try", ":", "\n", "                ", "_", "=", "driver", ".", "find_element_by_xpath", "(", "\"//*[contains(text(), 'No more results')]\"", ")", "\n", "ok", "=", "1", "\n", "", "except", "NoSuchElementException", ":", "\n", "                ", "try", ":", "\n", "                    ", "_", "=", "driver", ".", "find_element_by_xpath", "(", "\"//*[contains(text(), 'Result limit reached')]\"", ")", "\n", "ok", "=", "1", "\n", "", "except", "NoSuchElementException", ":", "\n", "                    ", "time", ".", "sleep", "(", "1", ")", "\n", "", "", "", "", "end", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "f\"Took {end - start} time to load page\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.utils.wait_until_loaded_page_paid": [[34, 49], ["time.time", "time.time", "logging.info", "driver.find_element_by_xpath", "time.sleep"], "function", ["None"], ["", "def", "wait_until_loaded_page_paid", "(", "driver", ",", "logging", ")", ":", "\n", "    ", "\"\"\"\n    Do not start scraping until page loaded fully. Could also use the\n    scroll function but we already know the link to fully loaded page.\n    \"\"\"", "\n", "ok", "=", "0", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "while", "ok", "==", "0", ":", "\n", "        ", "try", ":", "\n", "            ", "_", "=", "driver", ".", "find_element_by_xpath", "(", "\"//*[contains(text(), 'All Sound Effects')]\"", ")", "\n", "ok", "=", "1", "\n", "", "except", "NoSuchElementException", ":", "\n", "            ", "time", ".", "sleep", "(", "1", ")", "\n", "", "", "end", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "f\"Took {end - start} time to load page\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.utils.wait_for_downloads": [[51, 77], ["logging.info", "any", "logging.info", "os.listdir", "time.sleep", "logging.info", "filename.endswith", "filename.endswith", "os.remove", "logging.info", "os.listdir", "logging.info"], "function", ["None"], ["", "def", "wait_for_downloads", "(", "zip_videos", ",", "logging", ")", ":", "\n", "    ", "\"\"\"\n    obtained from\n    https://stackoverflow.com/questions/48263317/selenium-python-waiting-for-a-download-process-to-complete-using-chrome-web/48267887\n    Script waits for all files to finish downloading before moving to next task\n    :param zip_videos: Path to where videos in zip form are downloaded\n    \"\"\"", "\n", "logging", ".", "info", "(", "\"Waiting for downloads\"", ")", "\n", "counter", "=", "0", "\n", "downloadable", "=", "True", "\n", "while", "any", "(", "[", "filename", ".", "endswith", "(", "\".crdownload\"", ")", "for", "filename", "in", "\n", "os", ".", "listdir", "(", "zip_videos", ")", "]", ")", ":", "\n", "        ", "for", "filename", "in", "os", ".", "listdir", "(", "zip_videos", ")", ":", "\n", "            ", "if", "filename", ".", "endswith", "(", "\".crdownload\"", ")", ":", "\n", "                ", "logging", ".", "info", "(", "filename", ")", "\n", "", "", "time", ".", "sleep", "(", "2", ")", "\n", "logging", ".", "info", "(", "\".\"", ")", "\n", "counter", "+=", "1", "\n", "if", "counter", "==", "20", ":", "\n", "            ", "os", ".", "remove", "(", "zip_videos", "/", "filename", ")", "\n", "logging", ".", "info", "(", "f\"Could not download {filename}\"", ")", "\n", "downloadable", "=", "False", "\n", "break", "\n", "\n", "", "", "logging", ".", "info", "(", "\"done!\"", ")", "\n", "return", "downloadable", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.utils.scroll": [[79, 103], ["time.sleep", "driver.execute_script", "driver.execute_script", "driver.find_element_by_xpath().click", "time.sleep", "driver.execute_script", "driver.find_element_by_xpath"], "function", ["None"], ["", "def", "scroll", "(", "driver", ",", "timeout", ")", ":", "\n", "    ", "\"\"\"\n    Scroll until the page cannot be loaded anymore\n    \"\"\"", "\n", "time", ".", "sleep", "(", "4", ")", "\n", "scroll_pause_time", "=", "timeout", "\n", "\n", "# Get scroll height", "\n", "last_height", "=", "driver", ".", "execute_script", "(", "\"return document.body.scrollHeight\"", ")", "\n", "\n", "while", "True", ":", "\n", "# Scroll down to bottom", "\n", "        ", "driver", ".", "execute_script", "(", "\"window.scrollTo(0, document.body.scrollHeight);\"", ")", "\n", "driver", ".", "find_element_by_xpath", "(", "'//button[text()=\"Load more\"]'", ")", ".", "click", "(", ")", "\n", "\n", "# Wait to load page", "\n", "time", ".", "sleep", "(", "scroll_pause_time", ")", "\n", "\n", "# Calculate new scroll height and compare with last scroll height", "\n", "new_height", "=", "driver", ".", "execute_script", "(", "\"return document.body.scrollHeight\"", ")", "\n", "\n", "if", "new_height", "==", "last_height", ":", "\n", "            ", "break", "\n", "", "last_height", "=", "new_height", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.utils.get_links": [[105, 111], ["selenium.webdriver.Chrome", "webdriver.Chrome.get", "utils.scroll", "bs4.BeautifulSoup"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.utils.scroll"], ["", "", "def", "get_links", "(", "main_link", ",", "chrome_exe", ")", ":", "\n", "    ", "driver", "=", "webdriver", ".", "Chrome", "(", "executable_path", "=", "chrome_exe", ")", "\n", "driver", ".", "get", "(", "main_link", ")", "\n", "timeout", "=", "1", "\n", "scroll", "(", "driver", ",", "timeout", ")", "\n", "soup", "=", "BeautifulSoup", "(", "driver", ".", "page_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.utils.move_zip_file": [[112, 120], ["shutil.move", "time.time", "any", "logging.info", "time.sleep", "logging.info", "filename.endswith", "file_id.lower", "os.listdir", "file_id.lower", "time.time"], "function", ["None"], ["", "def", "move_zip_file", "(", "element", ",", "zip_videos", ",", "file_id", ",", "logging", ")", ":", "\n", "    ", "shutil", ".", "move", "(", "zip_videos", "/", "element", ",", "zip_videos", "/", "file_id", ".", "lower", "(", ")", "/", "element", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "while", "any", "(", "[", "filename", ".", "endswith", "(", "\".zip\"", ")", "for", "filename", "in", "\n", "os", ".", "listdir", "(", "zip_videos", ")", "]", ")", ":", "\n", "        ", "time", ".", "sleep", "(", "1", ")", "\n", "logging", ".", "info", "(", "f\"Waiting for .zip file to be moved {time.time() - start}\"", ")", "\n", "", "logging", ".", "info", "(", "f\"Finished moving {element} to folder {file_id.lower()}\"", ")", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.__init__": [[50, 74], ["os.path.join", "dominate.document", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "dominate.tags.meta", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "web_dir", ",", "title", ",", "refresh", "=", "0", ")", ":", "\n", "    ", "\"\"\"Initialize the HTML classes.\n\n    Args:\n      web_dir: a directory that stores the webpage. HTML file will\n      be\n      created at <web_dir>/index.html; images will be saved at\n      <web_dir/images/\n      title: the webpage name\n      refresh: how often the website refresh itself; if 0; no\n      refreshing\n    \"\"\"", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "web_dir", "=", "web_dir", "\n", "self", ".", "img_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "web_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "web_dir", ")", ":", "\n", "      ", "os", ".", "makedirs", "(", "self", ".", "web_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "img_dir", ")", ":", "\n", "      ", "os", ".", "makedirs", "(", "self", ".", "img_dir", ")", "\n", "\n", "", "self", ".", "doc", "=", "dominate", ".", "document", "(", "title", "=", "title", ")", "\n", "if", "refresh", ">", "0", ":", "\n", "      ", "with", "self", ".", "doc", ".", "head", ":", "\n", "        ", "meta", "(", "http_equiv", "=", "\"refresh\"", ",", "content", "=", "str", "(", "refresh", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.get_image_dir": [[75, 78], ["None"], "methods", ["None"], ["", "", "", "def", "get_image_dir", "(", "self", ")", ":", "\n", "    ", "\"\"\"Return the directory that stores images.\"\"\"", "\n", "return", "self", ".", "img_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.add_header": [[79, 87], ["dominate.tags.h3"], "methods", ["None"], ["", "def", "add_header", "(", "self", ",", "text", ")", ":", "\n", "    ", "\"\"\"Insert a header to the HTML file.\n\n    Args:\n      text: the header text\n    \"\"\"", "\n", "with", "self", ".", "doc", ":", "\n", "      ", "h3", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.add_videos": [[88, 131], ["dominate.tags.table", "html_utils.HTML.doc.add", "dominate.tags.tr", "zip", "dominate.tags.td", "dominate.tags.p", "str", "dominate.tags.br", "txt.split", "enumerate", "p_style.format.format.format", "dominate.tags.p", "dominate.tags.span", "dominate.tags.br", "dominate.tags.a", "row.startswith", "dominate.tags.video", "dominate.tags.attr", "dominate.tags.source", "str", "len", "len"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add"], ["", "", "def", "add_videos", "(", "self", ",", "vids", ",", "txts", ",", "links", ",", "width", "=", "400", ",", "hidden_tag", "=", "\"hidden\"", ")", ":", "\n", "    ", "\"\"\"add images to the HTML file.\n\n    Args:\n      vids: a list of image paths\n      txts: a list of image names shown on the website\n      links:  a list of hyperref links; when you click an\n      image,\n      it will redirect you to a new page\n      width: width\n      hidden_tag: hidden_tag\n    \"\"\"", "\n", "self", ".", "t", "=", "table", "(", "border", "=", "1", ",", "style", "=", "\"table-layout: fixed;\"", ")", "# Insert a table", "\n", "self", ".", "doc", ".", "add", "(", "self", ".", "t", ")", "\n", "colors", "=", "[", "\"red\"", ",", "\"blue\"", ",", "\"gold\"", ",", "\"salman\"", "]", "\n", "with", "self", ".", "t", ":", "\n", "      ", "with", "tr", "(", ")", ":", "\n", "        ", "for", "vid", ",", "txt", ",", "link", "in", "zip", "(", "vids", ",", "txts", ",", "links", ")", ":", "\n", "          ", "td_style", "=", "\"word-wrap: break-word; width:{}px\"", ".", "format", "(", "width", ")", "\n", "with", "td", "(", "style", "=", "td_style", ",", "halign", "=", "\"center\"", ",", "valign", "=", "\"top\"", ")", ":", "\n", "            ", "with", "p", "(", ")", ":", "\n", "              ", "vid_path", "=", "str", "(", "vid", ")", "\n", "if", "vid_path", "==", "hidden_tag", ":", "\n", "                ", "p_style", "=", "\"font-weight: bold; width:{}px;\"", "\n", "p_style", "=", "p_style", ".", "format", "(", "width", "*", "3", ")", "\n", "p", "(", "\"hidden video\"", ",", "style", "=", "p_style", ")", "\n", "", "else", ":", "\n", "                ", "with", "a", "(", "href", "=", "str", "(", "link", ")", ")", ":", "\n", "                  ", "with", "video", "(", ")", ":", "\n", "                    ", "attr", "(", "controls", "=", "\"controls\"", ",", "width", "=", "width", ")", "\n", "source", "(", "src", "=", "vid_path", ",", "type", "=", "\"video/mp4\"", ")", "\n", "", "", "", "br", "(", ")", "\n", "rows", "=", "txt", ".", "split", "(", "\"<br>\"", ")", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "rows", ")", ":", "\n", "                ", "color", "=", "colors", "[", "idx", "%", "len", "(", "colors", ")", "]", "\n", "bold_tag", "=", "\"<b>\"", "\n", "if", "not", "row", ".", "startswith", "(", "bold_tag", ")", ":", "\n", "                  ", "s_style", "=", "\"color:{};\"", ".", "format", "(", "color", ")", "\n", "", "else", ":", "\n", "                  ", "s_style", "=", "\"color:black; font-weight: bold;\"", "\n", "row", "=", "row", "[", "len", "(", "bold_tag", ")", ":", "]", "\n", "", "span", "(", "row", ",", "style", "=", "s_style", ")", "\n", "br", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.add_images": [[132, 158], ["dominate.tags.table", "html_utils.HTML.doc.add", "dominate.tags.tr", "zip", "dominate.tags.td", "dominate.tags.p", "dominate.tags.br", "dominate.tags.p", "dominate.tags.a", "dominate.tags.img", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add"], ["", "", "", "", "", "", "", "def", "add_images", "(", "self", ",", "ims", ",", "txts", ",", "links", ",", "width", "=", "400", ")", ":", "\n", "    ", "\"\"\"Add images to the HTML file.\n\n    Args:\n      ims: a list of image paths\n      txts: a list of image names shown on the website\n      links:  a list of hyperref links; when you click an\n      image,\n      it will redirect you to a new page\n      width: width\n    \"\"\"", "\n", "self", ".", "t", "=", "table", "(", "border", "=", "1", ",", "style", "=", "\"table-layout: fixed;\"", ")", "# Insert a table", "\n", "self", ".", "doc", ".", "add", "(", "self", ".", "t", ")", "\n", "with", "self", ".", "t", ":", "\n", "      ", "with", "tr", "(", ")", ":", "\n", "        ", "for", "im", ",", "txt", ",", "link", "in", "zip", "(", "ims", ",", "txts", ",", "links", ")", ":", "\n", "          ", "td_style", "=", "\"word-wrap: break-word;\"", "\n", "with", "td", "(", "style", "=", "td_style", ",", "halign", "=", "\"center\"", ",", "valign", "=", "\"top\"", ")", ":", "\n", "            ", "with", "p", "(", ")", ":", "\n", "              ", "with", "a", "(", "href", "=", "os", ".", "path", ".", "join", "(", "\"images\"", ",", "link", ")", ")", ":", "\n", "                ", "img", "(", "\n", "style", "=", "\"width:%dpx\"", "%", "width", ",", "\n", "src", "=", "os", ".", "path", ".", "join", "(", "\"images\"", ",", "im", ")", ",", "\n", ")", "\n", "", "br", "(", ")", "\n", "p", "(", "txt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.save": [[159, 165], ["open", "open.write", "open.close", "html_utils.HTML.doc.render"], "methods", ["None"], ["", "", "", "", "", "", "def", "save", "(", "self", ")", ":", "\n", "    ", "\"\"\"Save the current content to the HMTL file.\"\"\"", "\n", "html_file", "=", "\"%s/index.html\"", "%", "self", ".", "web_dir", "\n", "f", "=", "open", "(", "html_file", ",", "\"wt\"", ")", "\n", "f", ".", "write", "(", "self", ".", "doc", ".", "render", "(", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.nlp_utils.create_tokenizer": [[19, 43], ["tokenizer_type.endswith", "tokenizer_type.startswith", "tokenizer_type.endswith", "tokenizer_class.from_pretrained", "tokenizer_type.startswith", "model.txt_embeddings.WeTokenizer", "tokenizer_type.startswith", "model.txt_embeddings.WeTokenizer"], "function", ["None"], ["def", "create_tokenizer", "(", "tokenizer_type", ")", ":", "\n", "  ", "\"\"\"Creates a tokenizer given a tokenizer type.\"\"\"", "\n", "if", "tokenizer_type", ".", "endswith", "(", "'frz'", ")", ":", "\n", "    ", "freeze", "=", "True", "\n", "", "elif", "tokenizer_type", ".", "endswith", "(", "'ftn'", ")", ":", "\n", "    ", "freeze", "=", "False", "\n", "", "if", "tokenizer_type", ".", "startswith", "(", "'bert'", ")", ":", "\n", "    ", "model_name_or_path", "=", "'bert-base-cased'", "\n", "do_lower_case", "=", "True", "\n", "cache_dir", "=", "'data_slurm/cache_dir'", "\n", "tokenizer_class", "=", "BertTokenizer", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "model_name_or_path", ",", "\n", "do_lower_case", "=", "do_lower_case", ",", "\n", "cache_dir", "=", "cache_dir", ")", "\n", "", "elif", "tokenizer_type", ".", "startswith", "(", "'wo2v'", ")", ":", "\n", "    ", "we_filepath", "=", "'data_slurm/word_embeddings/word2vec/GoogleNews-vectors-negative300.bin'", "\n", "tokenizer", "=", "WeTokenizer", "(", "we_filepath", ",", "freeze", "=", "freeze", ")", "\n", "", "elif", "tokenizer_type", ".", "startswith", "(", "'grvl'", ")", ":", "\n", "    ", "we_filepath", "=", "'data_slurm/word_embeddings/GrOVLE/mt_grovle.txt'", "\n", "tokenizer", "=", "WeTokenizer", "(", "we_filepath", ",", "freeze", "=", "freeze", ")", "\n", "", "else", ":", "\n", "    ", "tokenizer", "=", "None", "\n", "\n", "", "return", "tokenizer", "\n", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.timing_utils.AverageMeter.__init__": [[20, 25], ["timing_utils.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "\n", "    ", "self", ".", "dic", "=", "{", "}", "\n", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.timing_utils.AverageMeter.reset": [[26, 30], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "    ", "for", "key", "in", "self", ".", "dic", ":", "\n", "      ", "for", "metric", "in", "self", ".", "dic", "[", "key", "]", ":", "\n", "        ", "self", ".", "dic", "[", "key", "]", "[", "metric", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.timing_utils.AverageMeter.update": [[31, 38], ["timing_utils.AverageMeter.dic.setdefault"], "methods", ["None"], ["", "", "", "def", "update", "(", "self", ",", "key", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "    ", "self", ".", "dic", ".", "setdefault", "(", "key", ",", "{", "'val'", ":", "0", ",", "'sum'", ":", "0", ",", "'count'", ":", "0", ",", "'avg'", ":", "0", "}", ")", "\n", "\n", "self", ".", "dic", "[", "key", "]", "[", "'val'", "]", "=", "val", "\n", "self", ".", "dic", "[", "key", "]", "[", "'sum'", "]", "+=", "val", "*", "n", "\n", "self", ".", "dic", "[", "key", "]", "[", "'count'", "]", "+=", "n", "\n", "self", ".", "dic", "[", "key", "]", "[", "'avg'", "]", "=", "self", ".", "dic", "[", "key", "]", "[", "'sum'", "]", "/", "self", ".", "dic", "[", "key", "]", "[", "'count'", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.perf_log_utils.update_perf_log": [[18, 28], ["time.strftime", "open", "file.write"], "function", ["None"], ["def", "update_perf_log", "(", "epoch_perf", ",", "perf_log_path", ")", ":", "\n", "  ", "now", "=", "time", ".", "strftime", "(", "'%c'", ")", "\n", "line", "=", "'t: {}, '", ".", "format", "(", "now", ")", "\n", "for", "key", "in", "epoch_perf", ":", "\n", "    ", "line", "+=", "'{}: {}, '", ".", "format", "(", "key", ",", "epoch_perf", "[", "key", "]", ")", "\n", "\n", "", "line", "+=", "'\\n'", "\n", "\n", "with", "open", "(", "perf_log_path", ",", "'a'", ")", "as", "file", ":", "\n", "    ", "file", ".", "write", "(", "line", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.compress_predictions": [[38, 70], ["numpy.argsort", "query_masks.flatten().astype", "query_masks.flatten"], "function", ["None"], ["\n", "\n", "", "@", "typechecked", "\n", "def", "get_short_uuid", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"Return a 7 alpha-numeric character random string.  We could use the full uuid()\n    for better uniqueness properties, but it makes the filenames long and its not\n    needed for our purpose (simply grouping experiments that were run with the same\n    configuration).\n    \"\"\"", "\n", "return", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "\n", "\n", "\n", "", "@", "typechecked", "\n", "def", "parse_grid", "(", "x", ":", "str", ",", "evaluation", ":", "str", "=", "'train'", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "\"\"\"Parse compact command line strings of the form:\n        --key1 val_a|val_b --key2 val_c|val_d\n\n    (here a vertical bar represents multiple values)\n\n    into a grid of separate strings e.g:\n        --key1 val_a --key2 val_c\n        --key1 val_a --key2 val_d\n        --key1 val_b --key2 val_c\n        --key1 val_b --key2 val_d\n\n    \"\"\"", "\n", "args", "=", "x", ".", "split", "(", "\" \"", ")", "\n", "group_id", "=", "get_short_uuid", "(", ")", "\n", "grid_opts", ",", "parsed", "=", "{", "}", ",", "[", "]", "\n", "for", "ii", ",", "token", "in", "enumerate", "(", "args", ")", ":", "\n", "        ", "if", "\"|\"", "in", "token", ":", "\n", "            ", "grid_opts", "[", "ii", "]", "=", "token", ".", "split", "(", "\"|\"", ")", "\n", "", "", "grid_idx", ",", "grid_vals", "=", "[", "]", ",", "[", "]", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_last_checkpoint_path": [[72, 84], ["os.listdir", "re.search", "int", "re.search.group", "os.path.join"], "function", ["None"], ["        ", "grid_idx", ".", "append", "(", "ii", ")", "\n", "grid_vals", ".", "append", "(", "val", ")", "\n", "", "grid_vals", "=", "list", "(", "itertools", ".", "product", "(", "*", "grid_vals", ")", ")", "\n", "for", "cfg", "in", "grid_vals", ":", "\n", "        ", "base", "=", "copy", ".", "deepcopy", "(", "args", ")", "\n", "for", "ii", ",", "val", "in", "zip", "(", "grid_idx", ",", "cfg", ")", ":", "\n", "            ", "base", "[", "ii", "]", "=", "val", "\n", "", "if", "evaluation", "==", "'train'", ":", "\n", "            ", "base", ".", "append", "(", "f\"--group_id {group_id}\"", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "", "parsed", ".", "append", "(", "\" \"", ".", "join", "(", "base", ")", ")", "\n", "", "return", "{", "group_id", ":", "parsed", "}", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.verbose": [[86, 95], ["print"], "function", ["None"], ["\n", "", "@", "typechecked", "\n", "def", "set_seeds", "(", "seed", ":", "int", ")", ":", "\n", "    ", "\"\"\"Set seeds for randomisation libraries.\n\n    Args:\n        seed: the seed value\n    \"\"\"", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache": [[97, 109], ["pathlib.Path", "util.pickle_loader", "hickle.load", "util.np_loader", "ValueError"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.pickle_loader", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.np_loader"], ["\n", "\n", "", "def", "update_src_web_video_dir", "(", "config", ")", ":", "\n", "    ", "\"\"\"Provide backwards compatible support for web directories\n\n    Args:\n        config: a configuration object containing experiment paths\n    \"\"\"", "\n", "src_video_dir", "=", "Path", "(", "config", "[", "\"visualizer\"", "]", "[", "\"args\"", "]", "[", "\"src_video_dir\"", "]", ")", "\n", "dataset", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"dataset_name\"", "]", "\n", "if", "dataset", "not", "in", "str", "(", "src_video_dir", ")", ":", "\n", "        ", "lookup", "=", "{", "\n", "\"ActivityNet\"", ":", "\"activity-net/videos\"", ",", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.pickle_loader": [[123, 131], ["time.time", "logger.debug", "logger.debug", "open", "pickle.load", "time.time"], "function", ["None"], [")", "\n", "print", "(", "msg", ")", "\n", "\n", "\n", "", "def", "flatten_dict", "(", "x", ",", "keysep", "=", "\"-\"", ")", ":", "\n", "    ", "flat_dict", "=", "{", "}", "\n", "for", "key", ",", "val", "in", "x", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "val", ",", "dict", ")", ":", "\n", "            ", "flat_subdict", "=", "flatten_dict", "(", "val", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.np_loader": [[134, 156], ["time.time", "logger.debug", "logger.debug", "open", "numpy.load", "isinstance", "logger.debug", "isinstance", "time.time", "numpy.linalg.norm", "ValueError", "max", "numpy.maximum", "numpy.linalg.norm", "np.linalg.norm.reshape", "type"], "function", ["None"], ["", "else", ":", "\n", "            ", "flat_dict", ".", "update", "(", "{", "key", ":", "val", "}", ")", "\n", "", "", "return", "flat_dict", "\n", "\n", "\n", "", "def", "expert_tensor_storage", "(", "experts", ",", "feat_aggregation", ")", ":", "\n", "\n", "    ", "expert_storage", "=", "{", "\"fixed\"", ":", "set", "(", ")", ",", "\"variable\"", ":", "set", "(", ")", ",", "\"flaky\"", ":", "set", "(", ")", "}", "\n", "# fixed_sz_experts, variable_sz_experts, flaky_experts = set(), set(), set()", "\n", "for", "expert", ",", "config", "in", "feat_aggregation", ".", "items", "(", ")", ":", "\n", "        ", "if", "config", "[", "\"temporal\"", "]", "in", "{", "\"vlad\"", "}", ":", "\n", "            ", "expert_storage", "[", "\"variable\"", "]", ".", "add", "(", "expert", ")", "\n", "", "elif", "all", "(", "[", "x", "in", "{", "\"avg\"", ",", "\"max\"", ",", "\"ent\"", ",", "\"std\"", "}", "for", "x", "in", "config", "[", "\"temporal\"", "]", ".", "split", "(", "\"-\"", ")", "]", ")", ":", "\n", "            ", "expert_storage", "[", "\"fixed\"", "]", ".", "add", "(", "expert", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"unknown temporal strategy: {config['temporal']}\"", ")", "\n", "# some \"flaky\" experts are only available for a fraction of videos - we need", "\n", "# to pass this information (in the form of indices) into the network for any", "\n", "# experts present in the current dataset", "\n", "", "if", "config", ".", "get", "(", "\"flaky\"", ",", "False", ")", ":", "\n", "            ", "expert_storage", "[", "\"flaky\"", "]", ".", "add", "(", "expert", ")", "\n", "\n", "# we only allocate storage for experts used by the current dataset", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_len_sequences": [[271, 290], ["x.size", "torch.zeros", "fzs.max", "zs.cumsum"], "function", ["None"], ["\n", "", "if", "config", "[", "\"experts\"", "]", "[", "\"text_agg\"", "]", "==", "\"avg\"", ":", "\n", "        ", "if", "hasattr", "(", "config", "[", "\"arch\"", "]", "[", "\"args\"", "]", ",", "\"vlad_clusters\"", ")", ":", "\n", "            ", "msg", "=", "\"averaging can only be performed with text using single tokens\"", "\n", "assert", "config", "[", "\"arch\"", "]", "[", "\"args\"", "]", "[", "\"vlad_clusters\"", "]", "[", "\"text\"", "]", "==", "0", ",", "msg", "\n", "", "assert", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"max_tokens\"", "]", "[", "\"text\"", "]", "==", "1", "\n", "\n", "# To remove the dependency of dataloader on the model architecture, we create a", "\n", "# second copy of the expert dimensions which accounts for the number of vlad", "\n", "# clusters", "\n", "", "raw_input_dims", "=", "OrderedDict", "(", ")", "\n", "for", "expert", ",", "dim_pair", "in", "expert_dims", ".", "items", "(", ")", ":", "\n", "        ", "raw_dim", "=", "dim_pair", "[", "0", "]", "\n", "if", "expert", "in", "{", "\"audio\"", ",", "\"speech\"", ",", "\"ocr\"", ",", "\"detection\"", ",", "\"detection-sem\"", ",", "\"openpose\"", ",", "\n", "\"speech.mozilla.0\"", ",", "\"pann\"", ",", "\"syncnet\"", ",", "\"vggsound\"", "}", ":", "\n", "            ", "if", "feat_agg", "[", "expert", "]", "[", "\"temporal\"", "]", "==", "\"vlad\"", ":", "\n", "                ", "raw_dim", "=", "raw_dim", "//", "vlad_clusters", ".", "get", "(", "expert", ",", "1", ")", "\n", "", "", "raw_input_dims", "[", "expert", "]", "=", "raw_dim", "\n", "\n", "", "with", "open", "(", "config", "[", "\"text_embedding_model_configs\"", "]", ",", "\"r\"", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_list_of_files": [[292, 298], ["list", "os.walk", "sorted", "os.path.join"], "function", ["None"], ["", "text_dim", "=", "text_embedding_model_configs", "[", "experts", "[", "\"text_feat\"", "]", "]", "[", "\"dim\"", "]", "\n", "\n", "return", "expert_dims", ",", "raw_input_dims", ",", "text_dim", "\n", "\n", "\n", "", "def", "ensure_tensor", "(", "x", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.default_to_regular": [[300, 304], ["isinstance", "util.default_to_regular", "d.items"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.default_to_regular", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "return", "x", "\n", "\n", "\n", "", "class", "Timer", ":", "\n", "    ", "def", "__init__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_expert_paths": [[306, 376], ["nested_dict", "util.get_list_of_files", "util.default_to_regular", "collections.defaultdict", "os.path.relpath", "dir_name.startswith", "path.split", "os.path.basename", "[].lower", "os.path.basename().startswith", "os.path.basename.endswith", "os.path.basename.endswith", "os.path.basename.endswith", "os.path.basename.endswith", "os.path.basename.endswith", "os.path.basename.endswith", "os.path.basename().startswith", "os.path.basename", "os.path.basename.split", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_list_of_files", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.default_to_regular"], ["\n", "", "def", "check", "(", "self", ")", ":", "\n", "        ", "now", "=", "datetime", ".", "now", "(", ")", "\n", "duration", "=", "now", "-", "self", ".", "cache", "\n", "self", ".", "cache", "=", "now", "\n", "return", "duration", ".", "total_seconds", "(", ")", "\n", "\n", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "cache", "=", "datetime", ".", "now", "(", ")", "\n", "\n", "\n", "", "", "def", "tensor2im", "(", "input_image", ",", "imtype", "=", "np", ".", "uint8", ")", ":", "\n", "    ", "\"\"\"\"Converts a Tensor array into a numpy image array.\n\n    Parameters:\n        input_image (tensor) --  the input image tensor array\n        imtype (type)        --  the desired type of the converted numpy array\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "input_image", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "isinstance", "(", "input_image", ",", "torch", ".", "Tensor", ")", ":", "# get the data from a variable", "\n", "            ", "image_tensor", "=", "input_image", ".", "data", "\n", "", "else", ":", "\n", "            ", "return", "input_image", "\n", "# convert it into a numpy array", "\n", "", "image_numpy", "=", "image_tensor", "[", "0", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "if", "image_numpy", ".", "shape", "[", "0", "]", "==", "1", ":", "# grayscale to RGB", "\n", "            ", "image_numpy", "=", "np", ".", "tile", "(", "image_numpy", ",", "(", "3", ",", "1", ",", "1", ")", ")", "\n", "# post-processing: tranpose and scaling", "\n", "", "image_numpy", "=", "(", "np", ".", "transpose", "(", "image_numpy", ",", "(", "1", ",", "2", ",", "0", ")", ")", "+", "1", ")", "/", "2.0", "*", "255.0", "\n", "", "else", ":", "# if it is a numpy array, do nothing", "\n", "        ", "image_numpy", "=", "input_image", "\n", "", "return", "image_numpy", ".", "astype", "(", "imtype", ")", "\n", "\n", "\n", "", "def", "save_image", "(", "image_numpy", ",", "image_path", ")", ":", "\n", "    ", "\"\"\"Save a numpy image to the disk\n\n    Parameters:\n        image_numpy (numpy array) -- input numpy array\n        image_path (str)          -- the path of the image\n    \"\"\"", "\n", "image_pil", "=", "Image", ".", "fromarray", "(", "image_numpy", ")", "\n", "image_pil", ".", "save", "(", "image_path", ")", "\n", "\n", "\n", "", "def", "print_numpy", "(", "x", ",", "val", "=", "True", ",", "shp", "=", "False", ")", ":", "\n", "    ", "\"\"\"Print the mean, min, max, median, std, and size of a numpy array\n\n    Parameters:\n        val (bool) -- if print the values of the numpy array\n        shp (bool) -- if print the shape of the numpy array\n    \"\"\"", "\n", "x", "=", "x", ".", "astype", "(", "np", ".", "float64", ")", "\n", "if", "shp", ":", "\n", "        ", "print", "(", "'shape,'", ",", "x", ".", "shape", ")", "\n", "", "if", "val", ":", "\n", "        ", "x", "=", "x", ".", "flatten", "(", ")", "\n", "print", "(", "'mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f'", "%", "(", "\n", "np", ".", "mean", "(", "x", ")", ",", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", ",", "np", ".", "median", "(", "x", ")", ",", "np", ".", "std", "(", "x", ")", ")", ")", "\n", "\n", "\n", "", "", "def", "mkdirs", "(", "paths", ")", ":", "\n", "    ", "\"\"\"create empty directories if they don't exist\n\n    Parameters:\n        paths (str list) -- a list of directory paths\n    \"\"\"", "\n", "if", "isinstance", "(", "paths", ",", "list", ")", "and", "not", "isinstance", "(", "paths", ",", "str", ")", ":", "\n", "        ", "for", "path", "in", "paths", ":", "\n", "            ", "mkdir", "(", "path", ")", "\n", "", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_hparams_from_config": [[378, 473], ["isinstance", "len", "[].startswith", "len", "os.path.exists", "util.read_json", "pathlib.Path", "len", "data_dic[].keys"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.read_json", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["\n", "\n", "", "", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "\"\"\"create a single empty directory if it didn't exist\n\n    Parameters:\n        path (str) -- a single directory path\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.mil_nce_net.MNNet.__init__": [[11, 23], ["list", "base.BaseModel.__init__", "torch.nn.Parameter", "expert_dims.keys", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["    ", "@", "typechecked", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "text_dim", ":", "int", ",", "\n", "expert_dims", ":", "Dict", "[", "str", ",", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "**", "_unused", ",", "\n", ")", ":", "\n", "        ", "self", ".", "text_dim", "=", "text_dim", "\n", "self", ".", "expert_dims", "=", "expert_dims", "\n", "self", ".", "modalities", "=", "list", "(", "expert_dims", ".", "keys", "(", ")", ")", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dummy_param", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", "*", "1E-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.mil_nce_net.MNNet.forward": [[24, 45], ["mil_nce_net.MNNet.sanity_checks", "next", "text.view.view.view", "torch.matmul", "iter", "next.t", "experts.values"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.sanity_checks"], ["", "@", "typechecked", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "text", ":", "torch", ".", "Tensor", ",", "\n", "ind", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "experts", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "**", "_unused", ",", "\n", ")", ":", "\n", "        ", "self", ".", "sanity_checks", "(", "text", "=", "text", ",", "experts", "=", "experts", ",", "ind", "=", "ind", ")", "\n", "vid_embedding", "=", "next", "(", "iter", "(", "experts", ".", "values", "(", ")", ")", ")", "\n", "vid_embedding", "=", "self", ".", "dummy_param", "+", "vid_embedding", "\n", "text", "=", "text", ".", "view", "(", "text", ".", "shape", "[", "0", "]", "*", "text", ".", "shape", "[", "1", "]", ",", "text", ".", "shape", "[", "-", "1", "]", ")", "\n", "# text = text / torch.norm(text, p=2, dim=1).reshape(-1, 1)", "\n", "# vid_embedding = vid_embedding / torch.norm(vid_embedding, p=2,", "\n", "#                                            dim=1).reshape(-1, 1)", "\n", "sims", "=", "torch", ".", "matmul", "(", "text", ",", "vid_embedding", ".", "t", "(", ")", ")", "\n", "return", "{", "\n", "\"modalities\"", ":", "self", ".", "modalities", ",", "\n", "\"cross_view_conf_matrix\"", ":", "sims", ",", "\n", "\"text_embds\"", ":", "{", "self", ".", "modalities", "[", "0", "]", ":", "text", "}", ",", "\n", "\"vid_embds\"", ":", "{", "self", ".", "modalities", "[", "0", "]", ":", "vid_embedding", "}", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.mil_nce_net.MNNet.sanity_checks": [[47, 66], ["len", "len", "ind[].sum", "len"], "methods", ["None"], ["", "@", "typechecked", "\n", "def", "sanity_checks", "(", "\n", "self", ",", "\n", "text", ":", "torch", ".", "Tensor", ",", "\n", "ind", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "experts", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", ")", ":", "\n", "        ", "msg", "=", "f\"Text dim {text.shape[-1]} did not match expected {self.text_dim}\"", "\n", "assert", "text", ".", "shape", "[", "-", "1", "]", "==", "self", ".", "text_dim", ",", "msg", "\n", "assert", "len", "(", "experts", ")", "==", "1", ",", "\"Expected single modality experts\"", "\n", "assert", "len", "(", "text", ".", "shape", ")", "==", "4", ",", "\"Expected four axes for text input\"", "\n", "assert", "text", ".", "shape", "[", "2", "]", "==", "1", ",", "\"Expected singleton for text input on dim 2\"", "\n", "for", "expert", "in", "self", ".", "expert_dims", ":", "\n", "            ", "msg", "=", "f\"Expected all features to be present for {expert}\"", "\n", "assert", "ind", "[", "expert", "]", ".", "sum", "(", ")", "==", "len", "(", "ind", "[", "expert", "]", ")", ",", "msg", "\n", "feats", "=", "experts", "[", "expert", "]", "\n", "expected", "=", "self", ".", "expert_dims", "[", "expert", "]", "\n", "msg", "=", "f\"Feature shape {feats.shape[1]} did not match expected {expected}\"", "\n", "assert", "feats", ".", "shape", "[", "1", "]", "==", "expected", "[", "-", "1", "]", ",", "msg", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.net_vlad.NetVLAD.__init__": [[35, 49], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "math.sqrt", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["clusters", "=", "cluster_size", "+", "ghost_clusters", "\n", "\n", "# The `clusters` weights are the `(w,b)` in the paper", "\n", "self", ".", "clusters", "=", "nn", ".", "Parameter", "(", "init_sc", "*", "th", ".", "randn", "(", "feature_size", ",", "clusters", ")", ")", "\n", "self", ".", "batch_norm", "=", "nn", ".", "BatchNorm1d", "(", "clusters", ")", "if", "add_batch_norm", "else", "None", "\n", "# The `clusters2` weights are the visual words `c_k` in the paper", "\n", "self", ".", "clusters2", "=", "nn", ".", "Parameter", "(", "init_sc", "*", "th", ".", "randn", "(", "1", ",", "feature_size", ",", "cluster_size", ")", ")", "\n", "self", ".", "out_dim", "=", "self", ".", "cluster_size", "*", "feature_size", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "mask", "=", "None", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.net_vlad.NetVLAD.forward": [[50, 93], ["net_vlad.NetVLAD.sanity_checks", "x.view.view.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.softmax", "net_vlad.NetVLAD.view", "torch.sum", "torch.sum", "torch.sum", "net_vlad.NetVLAD.transpose", "x.view.view.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.normalize.transpose", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize.reshape", "torch.normalize", "torch.normalize", "torch.normalize", "x.view.view.size", "ipdb.set_trace", "net_vlad.NetVLAD.batch_norm"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.sanity_checks"], ["\n", "self", ".", "sanity_checks", "(", "x", ")", "\n", "max_sample", "=", "x", ".", "size", "(", ")", "[", "1", "]", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "feature_size", ")", "# B x N x D -> BN x D", "\n", "\n", "if", "x", ".", "device", "!=", "self", ".", "clusters", ".", "device", ":", "\n", "            ", "msg", "=", "f\"x.device {x.device} != cluster.device {self.clusters.device}\"", "\n", "raise", "ValueError", "(", "msg", ")", "\n", "\n", "", "assignment", "=", "th", ".", "matmul", "(", "x", ",", "self", ".", "clusters", ")", "# (BN x D) x (D x (K+G)) -> BN x (K+G)", "\n", "\n", "if", "self", ".", "batch_norm", ":", "\n", "            ", "assignment", "=", "self", ".", "batch_norm", "(", "assignment", ")", "\n", "\n", "", "assignment", "=", "F", ".", "softmax", "(", "assignment", ",", "dim", "=", "1", ")", "# BN x (K+G) -> BN x (K+G)", "\n", "# remove ghost assigments", "\n", "assignment", "=", "assignment", "[", ":", ",", ":", "self", ".", "cluster_size", "]", "\n", "assignment", "=", "assignment", ".", "view", "(", "-", "1", ",", "max_sample", ",", "self", ".", "cluster_size", ")", "# -> B x N x K", "\n", "a_sum", "=", "th", ".", "sum", "(", "assignment", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# B x N x K -> B x 1 x K", "\n", "a", "=", "a_sum", "*", "self", ".", "clusters2", "\n", "\n", "assignment", "=", "assignment", ".", "transpose", "(", "1", ",", "2", ")", "# B x N x K -> B x K x N", "\n", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "max_sample", ",", "self", ".", "feature_size", ")", "# BN x D -> B x N x D", "\n", "vlad", "=", "th", ".", "matmul", "(", "assignment", ",", "x", ")", "# (B x K x N) x (B x N x D) -> B x K x D", "\n", "vlad", "=", "vlad", ".", "transpose", "(", "1", ",", "2", ")", "# -> B x D x K", "\n", "vlad", "=", "vlad", "-", "a", "\n", "\n", "# L2 intra norm", "\n", "vlad", "=", "F", ".", "normalize", "(", "vlad", ")", "\n", "\n", "# flattening + L2 norm", "\n", "vlad", "=", "vlad", ".", "reshape", "(", "-", "1", ",", "self", ".", "cluster_size", "*", "self", ".", "feature_size", ")", "# -> B x DK", "\n", "vlad", "=", "F", ".", "normalize", "(", "vlad", ")", "\n", "return", "vlad", "# B x DK", "\n", "\n", "", "def", "sanity_checks", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Catch any nans in the inputs/clusters\"\"\"", "\n", "if", "th", ".", "isnan", "(", "th", ".", "sum", "(", "x", ")", ")", ":", "\n", "            ", "print", "(", "\"nan inputs\"", ")", "\n", "ipdb", ".", "set_trace", "(", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.net_vlad.NetVLAD.sanity_checks": [[94, 102], ["torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.sum", "torch.sum", "torch.sum", "print", "ipdb.set_trace", "print", "ipdb.set_trace"], "methods", ["None"], ["", "if", "th", ".", "isnan", "(", "self", ".", "clusters", "[", "0", "]", "[", "0", "]", ")", ":", "\n", "            ", "print", "(", "\"nan clusters\"", ")", "\n", "ipdb", ".", "set_trace", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.TextEmbedding.__init__": [[27, 39], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "Callable", ",", "\n", "tokenizer", ":", "Union", "[", "Callable", ",", "None", "]", ",", "\n", "dim", ":", "int", ",", "\n", "remove_stopwords", ":", "bool", ",", "\n", ")", ":", "\n", "        ", "self", ".", "dim", "=", "dim", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "remove_stopwords", "=", "remove_stopwords", "\n", "self", ".", "device", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.TextEmbedding.text2vec": [[40, 56], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "text2vec", "(", "self", ",", "text", ":", "str", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"Convert a string of text into an embedding.\n\n        Args:\n            text: the content to be embedded\n\n        Returns:\n            (d x n) array, where d is the dimensionality of the embedding and `n` is the\n                number of words that were successfully parsed from the text string.\n\n        NOTE: For some text embedding models (such as word2vec), not all words are\n        converted to vectors (e.g. certain kinds of stop words) - these are dropped from\n        the output.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.TextEmbedding.set_device": [[57, 61], ["text.TextEmbedding.model.to"], "methods", ["None"], ["", "@", "typechecked", "\n", "def", "set_device", "(", "self", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "        ", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "device", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.LookupEmbedding.__init__": [[270, 292], ["text.Tokenizer", "numpy.mean", "text.TextEmbedding.__init__", "zsvision.zs_utils.BlockTimer", "numpy.zeros", "enumerate", "sorted", "model", "min", "len"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "@", "typechecked", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "Callable", ",", "\n", "dim", ":", "int", ",", "\n", "remove_stopwords", ":", "bool", ",", "\n", "num_samples_for_unknown", ":", "int", "=", "50000", ",", "\n", ")", ":", "\n", "        ", "tokenizer", "=", "Tokenizer", "(", "vocab", "=", "model", ".", "vocab", ")", "\n", "with", "BlockTimer", "(", "\"generating unknown vector\"", ")", ":", "\n", "            ", "vecs", "=", "np", ".", "zeros", "(", "(", "min", "(", "num_samples_for_unknown", ",", "len", "(", "model", ".", "vocab", ")", ")", ",", "dim", ")", ")", "\n", "for", "ii", ",", "key", "in", "enumerate", "(", "sorted", "(", "model", ".", "vocab", ")", ")", ":", "\n", "                ", "if", "ii", ">=", "num_samples_for_unknown", ":", "\n", "                    ", "break", "\n", "", "vecs", "[", "ii", "]", "=", "model", "(", "key", ")", "\n", "", "", "self", ".", "unknown_vector", "=", "np", ".", "mean", "(", "vecs", ",", "0", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "dim", "=", "dim", ",", "\n", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "remove_stopwords", "=", "remove_stopwords", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.LookupEmbedding.set_device": [[294, 298], ["type"], "methods", ["None"], ["", "@", "typechecked", "\n", "def", "set_device", "(", "self", ",", "device", ":", "torch", ".", "device", ")", ":", "\n", "        ", "msg", "=", "f\"{type(self)} only supports CPU-based execution found {device.type}\"", "\n", "assert", "device", ".", "type", "==", "\"cpu\"", ",", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.LookupEmbedding.text2vec": [[299, 316], ["text.LookupEmbedding.tokenizer", "numpy.array", "gensim.parsing.preprocessing.remove_stopwords", "numpy.array.append", "print", "numpy.array", "text.LookupEmbedding.model"], "methods", ["None"], ["", "@", "typechecked", "\n", "def", "text2vec", "(", "self", ",", "text", ":", "str", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "if", "self", ".", "remove_stopwords", ":", "\n", "            ", "processed_string", "=", "gensim", ".", "parsing", ".", "preprocessing", ".", "remove_stopwords", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "processed_string", "=", "text", "\n", "", "tokens", ",", "failed", "=", "self", ".", "tokenizer", "(", "processed_string", ")", "\n", "embeddings", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "embeddings", ".", "append", "(", "self", ".", "model", "(", "token", ")", ")", "\n", "", "embeddings", "=", "np", ".", "array", "(", "embeddings", ")", "\n", "msg", "=", "(", "f\"Failed to embed any tokens! (text: {text}, processed_string: \"", "\n", "f\"{processed_string}, failed: {failed})\"", ")", "\n", "if", "embeddings", ".", "size", "==", "0", ":", "\n", "            ", "print", "(", "f\"Warning: {msg}, falling back to unknown vector\"", ")", "\n", "embeddings", "=", "np", ".", "array", "(", "[", "self", ".", "unknown_vector", "]", ")", "\n", "", "return", "embeddings", ",", "failed", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.Tokenizer.__init__": [[138, 159], ["zsvision.zs_utils.BlockTimer", "spacy.load", "symspellpy.SymSpell", "pkg_resources.resource_filename", "symspellpy.SymSpell.load_dictionary"], "methods", ["None"], ["@", "typechecked", "\n", "def", "__init__", "(", "self", ",", "vocab", ":", "Set", "[", "str", "]", ")", ":", "\n", "        ", "with", "BlockTimer", "(", "\"preparing tokenizer dicionaries\"", ")", ":", "\n", "# we only use spacy for lemmatising, so we don't need NER or the parser.", "\n", "# NOTE: all pronouns are mapped to -PRON-, because it's not clear what their", "\n", "# lemma should be (we try to handle these via the spellchecker)", "\n", "            ", "self", ".", "nlp", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ",", "disable", "=", "[", "'parser'", ",", "'ner'", "]", ")", "\n", "\n", "# Symspell is, in theory, a fast spell checker:", "\n", "sym_spell", "=", "SymSpell", "(", "max_dictionary_edit_distance", "=", "2", ",", "prefix_length", "=", "7", ")", "\n", "dictionary_path", "=", "pkg_resources", ".", "resource_filename", "(", "\n", "\"symspellpy\"", ",", "\"frequency_dictionary_en_82_765.txt\"", ")", "\n", "# term_index is the column of the term and count_index is the", "\n", "# column of the term frequency", "\n", "sym_spell", ".", "load_dictionary", "(", "dictionary_path", ",", "term_index", "=", "0", ",", "count_index", "=", "1", ")", "\n", "self", ".", "sym_spell", "=", "sym_spell", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "# For a small number of cases, the tokenization fails.", "\n", "self", ".", "custom", "=", "{", "\n", "\"roundtable\"", ":", "[", "\"round\"", ",", "\"table\"", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.Tokenizer.__call__": [[161, 191], ["text.Tokenizer.nlp", "str", "tokens.append", "tokens.append", "text.Tokenizer.sym_spell.lookup", "failed.append", "tokens.append", "failed.append", "tokens.append", "str"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "text", ":", "str", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "text", ")", "\n", "tokens", ",", "failed", "=", "[", "]", ",", "[", "]", "\n", "for", "token", "in", "doc", ":", "\n", "            ", "token", ",", "lemma", "=", "str", "(", "token", ")", ",", "token", ".", "lemma_", "\n", "if", "token", "in", "self", ".", "vocab", ":", "\n", "                ", "tokens", ".", "append", "(", "token", ")", "\n", "", "elif", "lemma", "in", "self", ".", "vocab", ":", "\n", "                ", "tokens", ".", "append", "(", "lemma", ")", "\n", "", "elif", "lemma", "in", "self", ".", "custom", ":", "\n", "                ", "for", "subtoken", "in", "self", ".", "custom", "[", "lemma", "]", ":", "\n", "                    ", "if", "subtoken", "in", "self", ".", "vocab", ":", "\n", "                        ", "tokens", ".", "append", "(", "subtoken", ")", "\n", "", "else", ":", "\n", "                        ", "failed", ".", "append", "(", "subtoken", ")", "\n", "", "", "", "else", ":", "\n", "                ", "suggestions", "=", "self", ".", "sym_spell", ".", "lookup", "(", "\n", "phrase", "=", "token", ",", "\n", "verbosity", "=", "Verbosity", ".", "CLOSEST", ",", "\n", "max_edit_distance", "=", "2", ",", "\n", ")", "\n", "success", "=", "False", "\n", "for", "suggestion", "in", "suggestions", ":", "\n", "                    ", "if", "suggestion", ".", "term", "in", "self", ".", "vocab", ":", "\n", "                        ", "success", "=", "True", "\n", "tokens", ".", "append", "(", "suggestion", ".", "term", ")", "\n", "break", "\n", "", "", "if", "not", "success", ":", "\n", "                    ", "failed", ".", "append", "(", "str", "(", "token", ")", ")", "\n", "", "", "", "return", "tokens", ",", "failed", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.OpenAI_GPT.__init__": [[202, 207], ["transformers.OpenAIGPTTokenizer.from_pretrained", "transformers.OpenAIGPTModel.from_pretrained", "transformers.OpenAIGPTModel.from_pretrained.eval", "text.TextEmbedding.__init__"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "transformers", ".", "OpenAIGPTTokenizer", ".", "from_pretrained", "(", "\"openai-gpt\"", ")", "\n", "model", "=", "transformers", ".", "OpenAIGPTModel", ".", "from_pretrained", "(", "\"openai-gpt\"", ")", "\n", "model", ".", "eval", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "model", "=", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.OpenAI_GPT.text2vec": [[208, 220], ["text.OpenAI_GPT.tokenizer.tokenize", "text.OpenAI_GPT.tokenizer.convert_tokens_to_ids", "torch.LongTensor().to", "hidden_states[].cpu().numpy.squeeze", "torch.no_grad", "text.OpenAI_GPT.model", "hidden_states[].cpu().numpy", "torch.LongTensor", "hidden_states[].cpu"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.WeTokenizer.tokenize", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.WeTokenizer.convert_tokens_to_ids"], ["", "@", "typechecked", "\n", "def", "text2vec", "(", "self", ",", "text", ":", "str", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "tokenized_text", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "\n", "# Convert token to vocabulary indices", "\n", "indexed_tokens", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "\n", "tokens_tensor", "=", "torch", ".", "LongTensor", "(", "[", "indexed_tokens", "]", ")", ".", "to", "(", "self", ".", "model", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "hidden_states", "=", "self", ".", "model", "(", "tokens_tensor", ")", "\n", "embeddings", "=", "hidden_states", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "return", "embeddings", ".", "squeeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.W2VEmbedding.__init__": [[233, 265], ["text.load_w2v_model_from_cache", "W2V_Lookup", "text.LookupEmbedding.__init__", "weights_path.exists", "text.fetch_model", "ValueError", "set", "text.W2VEmbedding.w2v.get_vector", "load_w2v_model_from_cache.vocab.keys"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.load_w2v_model_from_cache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.fetch_model", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["@", "typechecked", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "dim", ":", "int", ",", "\n", "mirror", ":", "str", ",", "\n", "embedding_name", ":", "str", ",", "\n", "weights_path", ":", "Path", ",", "\n", "remove_stopwords", ":", "bool", ",", "\n", "fetch_weights", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "if", "not", "weights_path", ".", "exists", "(", ")", ":", "\n", "            ", "if", "fetch_weights", ":", "\n", "                ", "fetch_model", "(", "url", "=", "mirror", ",", "weights_path", "=", "weights_path", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"w2v weights missing at {weights_path}\"", ")", "\n", "\n", "", "", "class", "W2V_Lookup", ":", "\n", "            ", "def", "__init__", "(", "self", ",", "w2v", ")", ":", "\n", "                ", "self", ".", "w2v", "=", "w2v", "\n", "self", ".", "vocab", "=", "set", "(", "w2v", ".", "vocab", ".", "keys", "(", ")", ")", "\n", "\n", "", "def", "__call__", "(", "self", ",", "key", ")", ":", "\n", "                ", "return", "self", ".", "w2v", ".", "get_vector", "(", "key", ")", "\n", "\n", "", "", "w2v", "=", "load_w2v_model_from_cache", "(", "weights_path", ")", "\n", "self", ".", "embedding_name", "=", "embedding_name", "\n", "model", "=", "W2V_Lookup", "(", "w2v", "=", "w2v", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "dim", "=", "dim", ",", "\n", "model", "=", "model", ",", "\n", "remove_stopwords", "=", "remove_stopwords", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.GrOVLE.__init__": [[333, 380], ["Lookup", "text.LookupEmbedding.__init__", "weights_path.exists", "zsvision.zs_utils.BlockTimer", "zipfile.ZipFile", "zipfile.ZipFile.read().decode().splitlines", "any", "row.split", "numpy.array", "text.fetch_model", "ValueError", "set", "zipfile.ZipFile.read().decode", "text.GrOVLE.keys", "float", "weights.split", "zipfile.ZipFile.read"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.fetch_model", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["@", "typechecked", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "dim", ":", "int", ",", "\n", "mirror", ":", "str", ",", "\n", "embedding_name", ":", "str", ",", "\n", "weights_path", ":", "Path", ",", "\n", "remove_stopwords", ":", "bool", ",", "\n", "fetch_weights", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "if", "not", "weights_path", ".", "exists", "(", ")", ":", "\n", "            ", "if", "fetch_weights", ":", "\n", "                ", "public_url", "=", "f\"{mirror}/{weights_path.name}\"", "\n", "fetch_model", "(", "url", "=", "public_url", ",", "weights_path", "=", "weights_path", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"GrOVLE weights missing at {weights_path}\"", ")", "\n", "\n", "", "", "with", "BlockTimer", "(", "f\"Reading weight contents from {weights_path}\"", ")", ":", "\n", "            ", "zipped", "=", "zipfile", ".", "ZipFile", "(", "weights_path", ")", "\n", "rows", "=", "zipped", ".", "read", "(", "f\"{embedding_name}.txt\"", ")", ".", "decode", "(", "\"utf-8\"", ")", ".", "splitlines", "(", ")", "\n", "\n", "# To maintain a consistent interface with w2v, we add a matching `get_vector`", "\n", "# method to the dictionary baseclass", "\n", "", "class", "Lookup", "(", "dict", ")", ":", "\n", "            ", "def", "__call__", "(", "self", ",", "key", ")", ":", "\n", "                ", "return", "self", "[", "key", "]", "\n", "\n", "", "@", "property", "\n", "def", "vocab", "(", "self", ")", ":", "\n", "                ", "return", "set", "(", "self", ".", "keys", "(", ")", ")", "\n", "\n", "", "", "model", "=", "Lookup", "(", ")", "\n", "\n", "punctuation", "=", "{", "'\"'", ",", "\"?\"", ",", "\")\"", ",", "\"(\"", "}", "\n", "for", "row", "in", "rows", ":", "\n", "# exclude puncutation", "\n", "            ", "if", "any", "(", "[", "punc", "in", "row", "for", "punc", "in", "punctuation", "]", ")", ":", "\n", "                ", "msg", "=", "f\"Only expected HGLMM models to have punctuation\"", "\n", "assert", "embedding_name", "in", "{", "\"hglmm_300d\"", ",", "\"hglmm_6kd\"", "}", ",", "msg", "\n", "continue", "\n", "", "key", ",", "weights", "=", "row", ".", "split", "(", "\" \"", ",", "1", ")", "\n", "model", "[", "key", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", ")", "for", "x", "in", "weights", ".", "split", "(", "\" \"", ")", "]", ")", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "dim", "=", "dim", ",", "\n", "model", "=", "model", ",", "\n", "remove_stopwords", "=", "remove_stopwords", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.HowTo100M_MIL_NCE.__init__": [[392, 418], ["model.s3dg.S3D.s3dg.S3D", "model.s3dg.S3D.s3dg.S3D.load_state_dict", "model.s3dg.S3D.s3dg.S3D.eval", "text.TextEmbedding.__init__", "torch.load", "path.exists", "text.fetch_model", "ValueError"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.fetch_model"], ["def", "__init__", "(", "\n", "self", ",", "\n", "word_dict_path", ":", "Path", ",", "\n", "weights_path", ":", "Path", ",", "\n", "embedding_name", ":", "str", ",", "\n", "dim", ":", "int", ",", "\n", "mirror", ":", "str", ",", "\n", "fetch_weights", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "for", "path", "in", "[", "word_dict_path", ",", "weights_path", "]", ":", "\n", "            ", "if", "not", "path", ".", "exists", "(", ")", ":", "\n", "                ", "if", "fetch_weights", ":", "\n", "                    ", "public_url", "=", "f\"{mirror}/{path.name}\"", "\n", "fetch_model", "(", "url", "=", "public_url", ",", "weights_path", "=", "path", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"howto100m weights missing at {path}\"", ")", "\n", "\n", "", "", "", "model", "=", "S3D", "(", "word_dict_path", ",", "dim", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "weights_path", ")", ")", "\n", "self", ".", "embedding_name", "=", "embedding_name", "\n", "model", ".", "eval", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "dim", "=", "dim", ",", "\n", "model", "=", "model", ",", "\n", "tokenizer", "=", "None", ",", "\n", "remove_stopwords", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.HowTo100M_MIL_NCE.text2vec": [[420, 425], ["torch.no_grad", "text.HowTo100M_MIL_NCE.model.text_module", "embedding[].cpu().numpy", "embedding[].cpu"], "methods", ["None"], ["", "@", "typechecked", "\n", "def", "text2vec", "(", "self", ",", "text", ":", "str", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "embedding", "=", "self", ".", "model", ".", "text_module", "(", "[", "text", "]", ",", "device", "=", "self", ".", "device", ")", "\n", "", "return", "embedding", "[", "\"text_embedding\"", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.HuggingFaceWrapper.__init__": [[434, 488], ["collections.defaultdict", "collections.defaultdict", "transformer_keys.get", "tokenizers[].from_pretrained", "models[].from_pretrained", "text.TextEmbedding.__init__"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "dim", ":", "int", ",", "embedding_name", ":", "str", ")", ":", "\n", "        ", "tokenizers", "=", "{", "\n", "\"openai-gpt\"", ":", "transformers", ".", "OpenAIGPTTokenizer", ",", "\n", "\"bert-base-uncased\"", ":", "transformers", ".", "BertTokenizer", ",", "\n", "\"ctrl\"", ":", "transformers", ".", "CTRLTokenizer", ",", "\n", "\"transfo-xl-wt103\"", ":", "transformers", ".", "TransfoXLTokenizer", ",", "\n", "\"electra\"", ":", "transformers", ".", "ElectraTokenizer", ",", "\n", "}", "\n", "models", "=", "{", "\n", "\"openai-gpt\"", ":", "transformers", ".", "OpenAIGPTModel", ",", "\n", "\"bert-base-uncased\"", ":", "transformers", ".", "BertModel", ",", "\n", "\"ctrl\"", ":", "transformers", ".", "CTRLModel", ",", "\n", "\"transfo-xl-wt103\"", ":", "transformers", ".", "TransfoXLModel", ",", "\n", "\"electra\"", ":", "transformers", ".", "ElectraModel", ",", "\n", "}", "\n", "add_special_tokens", "=", "defaultdict", "(", "lambda", ":", "True", ")", "\n", "add_decoder_input_ids", "=", "defaultdict", "(", "lambda", ":", "False", ")", "\n", "\n", "for", "name", "in", "[", "\"gpt2\"", ",", "\"gpt2-medium\"", ",", "\"gpt2-large\"", ",", "\"gpt2-xl\"", ",", "\"gpt2-xl-finetune\"", "]", ":", "\n", "            ", "tokenizers", "[", "name", "]", "=", "transformers", ".", "GPT2Tokenizer", "\n", "models", "[", "name", "]", "=", "transformers", ".", "GPT2Model", "\n", "\n", "", "for", "name", "in", "[", "\"t5-small\"", ",", "\"t5-base\"", ",", "\"t5-large\"", ",", "\"t5-3b\"", ",", "\"t5-11b\"", "]", ":", "\n", "            ", "tokenizers", "[", "name", "]", "=", "transformers", ".", "T5Tokenizer", "\n", "models", "[", "name", "]", "=", "transformers", ".", "T5Model", "\n", "add_special_tokens", "[", "name", "]", "=", "False", "\n", "add_decoder_input_ids", "[", "name", "]", "=", "True", "\n", "\n", "", "for", "name", "in", "[", "\"albert-base-v2\"", ",", "\"albert-large-v2\"", ",", "\"albert-xlarge-v2\"", "]", ":", "\n", "            ", "tokenizers", "[", "name", "]", "=", "transformers", ".", "AlbertTokenizer", "\n", "models", "[", "name", "]", "=", "transformers", ".", "AlbertModel", "\n", "\n", "", "for", "name", "in", "[", "\"roberta-base\"", ",", "\"roberta-large\"", "]", ":", "\n", "            ", "tokenizers", "[", "name", "]", "=", "transformers", ".", "RobertaTokenizer", "\n", "models", "[", "name", "]", "=", "transformers", ".", "RobertaModel", "\n", "\n", "", "for", "name", "in", "[", "\"xlnet-base-cased\"", ",", "\"xlnet-large-cased\"", "]", ":", "\n", "            ", "tokenizers", "[", "name", "]", "=", "transformers", ".", "XLNetTokenizer", "\n", "models", "[", "name", "]", "=", "transformers", ".", "XLNetModel", "\n", "add_special_tokens", "[", "name", "]", "=", "False", "\n", "\n", "# handle inconsistent naming scheme for electra", "\n", "", "transformer_keys", "=", "{", "\"electra\"", ":", "\"google/electra-small-discriminator\"", "}", "\n", "transformer_key", "=", "transformer_keys", ".", "get", "(", "embedding_name", ",", "embedding_name", ")", "\n", "tokenizer", "=", "tokenizers", "[", "embedding_name", "]", ".", "from_pretrained", "(", "transformer_key", ")", "\n", "model", "=", "models", "[", "embedding_name", "]", ".", "from_pretrained", "(", "transformer_key", ")", "\n", "\n", "self", ".", "add_special_tokens", "=", "add_special_tokens", "[", "embedding_name", "]", "\n", "self", ".", "add_decoder_input_ids", "=", "add_decoder_input_ids", "[", "embedding_name", "]", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "model", "=", "model", ",", "\n", "dim", "=", "dim", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "remove_stopwords", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.HuggingFaceWrapper.text2vec": [[490, 505], ["text.HuggingFaceWrapper.tokenizer.encode", "torch.LongTensor().to", "torch.LongTensor().to.unsqueeze", "torch.LongTensor().to.unsqueeze", "torch.no_grad", "text.HuggingFaceWrapper.model", "hidden_states[].cpu().numpy", "hidden_states[].cpu().numpy.squeeze", "torch.LongTensor", "hidden_states[].cpu"], "methods", ["None"], ["", "@", "typechecked", "\n", "def", "text2vec", "(", "self", ",", "text", ":", "str", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "tokens", "=", "self", ".", "tokenizer", ".", "encode", "(", "\n", "text", ",", "\n", "add_special_tokens", "=", "self", ".", "add_special_tokens", ",", "\n", "add_space_before_punct_symbol", "=", "True", ",", "\n", ")", "\n", "input_idx", "=", "torch", ".", "LongTensor", "(", "tokens", ")", ".", "to", "(", "self", ".", "model", ".", "device", ")", "\n", "kwargs", "=", "{", "\"input_ids\"", ":", "input_idx", ".", "unsqueeze", "(", "0", ")", "}", "\n", "if", "self", ".", "add_decoder_input_ids", ":", "\n", "            ", "kwargs", "[", "\"decoder_input_ids\"", "]", "=", "input_idx", ".", "unsqueeze", "(", "0", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "hidden_states", "=", "self", ".", "model", "(", "**", "kwargs", ")", "\n", "embeddings", "=", "hidden_states", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "return", "embeddings", ".", "squeeze", "(", "0", ")", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.load_w2v_model_from_cache": [[63, 73], ["functools.lru_cache", "zsvision.zs_utils.BlockTimer", "gensim.models.KeyedVectors.load_word2vec_format"], "function", ["None"], ["", "", "@", "functools", ".", "lru_cache", "(", "maxsize", "=", "64", ",", "typed", "=", "False", ")", "\n", "def", "load_w2v_model_from_cache", "(", "\n", "w2v_weights", ":", "Path", ",", "\n", ")", "->", "gensim", ".", "models", ".", "keyedvectors", ".", "Word2VecKeyedVectors", ":", "\n", "    ", "with", "BlockTimer", "(", "\"Loading w2v from disk\"", ")", ":", "\n", "        ", "model", "=", "gensim", ".", "models", ".", "KeyedVectors", ".", "load_word2vec_format", "(", "\n", "fname", "=", "w2v_weights", ",", "\n", "binary", "=", "True", ",", "\n", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.fetch_model": [[75, 82], ["weights_path.parent.mkdir", "zsvision.zs_utils.BlockTimer", "requests.get", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["", "@", "typechecked", "\n", "def", "fetch_model", "(", "url", ":", "str", ",", "weights_path", ":", "Path", ")", ":", "\n", "    ", "weights_path", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "with", "BlockTimer", "(", "f\"Fetching weights {url} -> {weights_path}\"", ")", ":", "\n", "        ", "resp", "=", "requests", ".", "get", "(", "url", ",", "verify", "=", "False", ")", "\n", "with", "open", "(", "weights_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "resp", ".", "content", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.loss.MaxMarginRankingLoss.__init__": [[32, 37], ["torch.Module.__init__", "torch.nn.MarginRankingLoss", "torch.nn.MarginRankingLoss", "torch.nn.MarginRankingLoss"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fix_norm", "=", "fix_norm", "\n", "self", ".", "loss", "=", "th", ".", "nn", ".", "MarginRankingLoss", "(", "margin", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.loss.MaxMarginRankingLoss.forward": [[38, 66], ["torch.diag", "torch.diag", "torch.diag", "torch.cat.unsqueeze", "torch.cat.expand", "torch.cat.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "x.view", "x.transpose().contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.relu.mean", "x.size", "keep.view", "keep.transpose().contiguous().view", "torch.nonzero().flatten", "torch.nonzero().flatten", "torch.nonzero().flatten", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.relu", "torch.relu", "torch.relu", "torch.cat.contiguous", "x.transpose().contiguous", "torch.ones", "torch.ones", "torch.ones", "torch.eye", "torch.eye", "torch.eye", "keep_idx.cuda.cuda.cuda", "keep.transpose().contiguous", "torch.nonzero", "torch.nonzero", "torch.nonzero", "x.transpose", "torch.cat().flatten", "torch.cat().flatten", "torch.cat().flatten", "keep.transpose", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["        ", "n", "=", "x", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "x1", "=", "th", ".", "diag", "(", "x", ")", "\n", "x1", "=", "x1", ".", "unsqueeze", "(", "1", ")", "\n", "x1", "=", "x1", ".", "expand", "(", "n", ",", "n", ")", "\n", "x1", "=", "x1", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "x1", "=", "th", ".", "cat", "(", "(", "x1", ",", "x1", ")", ",", "0", ")", "\n", "\n", "x2", "=", "x", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "x3", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "x2", "=", "th", ".", "cat", "(", "(", "x2", ",", "x3", ")", ",", "0", ")", "\n", "max_margin", "=", "F", ".", "relu", "(", "self", ".", "margin", "-", "(", "x1", "-", "x2", ")", ")", "\n", "\n", "if", "self", ".", "fix_norm", ":", "\n", "# remove the elements from the diagonal", "\n", "            ", "keep", "=", "th", ".", "ones", "(", "x", ".", "shape", ")", "-", "th", ".", "eye", "(", "x", ".", "shape", "[", "0", "]", ")", "# 128 x 128", "\n", "keep1", "=", "keep", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "keep2", "=", "keep", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "keep_idx", "=", "th", ".", "nonzero", "(", "th", ".", "cat", "(", "(", "keep1", ",", "keep2", ")", ",", "0", ")", ".", "flatten", "(", ")", ")", ".", "flatten", "(", ")", "\n", "if", "x1", ".", "is_cuda", ":", "\n", "                ", "keep_idx", "=", "keep_idx", ".", "cuda", "(", ")", "\n", "", "x1_", "=", "th", ".", "index_select", "(", "x1", ",", "dim", "=", "0", ",", "index", "=", "keep_idx", ")", "\n", "x2_", "=", "th", ".", "index_select", "(", "x2", ",", "dim", "=", "0", ",", "index", "=", "keep_idx", ")", "\n", "max_margin", "=", "F", ".", "relu", "(", "self", ".", "margin", "-", "(", "x1_", "-", "x2_", ")", ")", "\n", "\n", "", "return", "max_margin", ".", "mean", "(", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.loss.BCEWithLogitsLoss.__init__": [[69, 72], ["torch.Module.__init__", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "weight", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss", "=", "th", ".", "nn", ".", "BCEWithLogitsLoss", "(", "weight", "=", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.loss.BCEWithLogitsLoss.forward": [[73, 75], ["loss.BCEWithLogitsLoss.loss"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "target", ")", ":", "\n", "        ", "return", "self", ".", "loss", "(", "x", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.loss.CrossEntropyLoss.__init__": [[79, 82], ["torch.Module.__init__", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "weight", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss", "=", "th", ".", "nn", ".", "CrossEntropyLoss", "(", "weight", "=", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.loss.CrossEntropyLoss.forward": [[83, 85], ["loss.CrossEntropyLoss.loss", "target.long().to", "target.long"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "target", ")", ":", "\n", "        ", "return", "self", ".", "loss", "(", "x", ",", "target", ".", "long", "(", ")", ".", "to", "(", "x", ".", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.InceptionBlock.__init__": [[36, 68], ["torch.Module.__init__", "s3dg.STConv3D", "s3dg.STConv3D", "s3dg.STConv3D", "s3dg.STConv3D", "s3dg.STConv3D", "torch.nn.MaxPool3d", "torch.nn.MaxPool3d", "torch.nn.MaxPool3d", "s3dg.STConv3D", "s3dg.SelfGating", "s3dg.SelfGating", "s3dg.SelfGating", "s3dg.SelfGating"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "input_dim", ",", "\n", "num_outputs_0_0a", ",", "\n", "num_outputs_1_0a", ",", "\n", "num_outputs_1_0b", ",", "\n", "num_outputs_2_0a", ",", "\n", "num_outputs_2_0b", ",", "\n", "num_outputs_3_0b", ",", "\n", "gating", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", "InceptionBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_b0", "=", "STConv3D", "(", "input_dim", ",", "num_outputs_0_0a", ",", "[", "1", ",", "1", ",", "1", "]", ")", "\n", "self", ".", "conv_b1_a", "=", "STConv3D", "(", "input_dim", ",", "num_outputs_1_0a", ",", "[", "1", ",", "1", ",", "1", "]", ")", "\n", "self", ".", "conv_b1_b", "=", "STConv3D", "(", "\n", "num_outputs_1_0a", ",", "num_outputs_1_0b", ",", "[", "3", ",", "3", ",", "3", "]", ",", "padding", "=", "1", ",", "separable", "=", "True", "\n", ")", "\n", "self", ".", "conv_b2_a", "=", "STConv3D", "(", "input_dim", ",", "num_outputs_2_0a", ",", "[", "1", ",", "1", ",", "1", "]", ")", "\n", "self", ".", "conv_b2_b", "=", "STConv3D", "(", "\n", "num_outputs_2_0a", ",", "num_outputs_2_0b", ",", "[", "3", ",", "3", ",", "3", "]", ",", "padding", "=", "1", ",", "separable", "=", "True", "\n", ")", "\n", "self", ".", "maxpool_b3", "=", "th", ".", "nn", ".", "MaxPool3d", "(", "(", "3", ",", "3", ",", "3", ")", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "conv_b3_b", "=", "STConv3D", "(", "input_dim", ",", "num_outputs_3_0b", ",", "[", "1", ",", "1", ",", "1", "]", ")", "\n", "self", ".", "gating", "=", "gating", "\n", "self", ".", "output_dim", "=", "(", "\n", "num_outputs_0_0a", "+", "num_outputs_1_0b", "+", "num_outputs_2_0b", "+", "num_outputs_3_0b", "\n", ")", "\n", "if", "gating", ":", "\n", "            ", "self", ".", "gating_b0", "=", "SelfGating", "(", "num_outputs_0_0a", ")", "\n", "self", ".", "gating_b1", "=", "SelfGating", "(", "num_outputs_1_0b", ")", "\n", "self", ".", "gating_b2", "=", "SelfGating", "(", "num_outputs_2_0b", ")", "\n", "self", ".", "gating_b3", "=", "SelfGating", "(", "num_outputs_3_0b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.InceptionBlock.forward": [[69, 85], ["s3dg.InceptionBlock.conv_b0", "s3dg.InceptionBlock.conv_b1_a", "s3dg.InceptionBlock.conv_b1_b", "s3dg.InceptionBlock.conv_b2_a", "s3dg.InceptionBlock.conv_b2_b", "s3dg.InceptionBlock.maxpool_b3", "s3dg.InceptionBlock.conv_b3_b", "torch.cat", "torch.cat", "torch.cat", "s3dg.InceptionBlock.gating_b0", "s3dg.InceptionBlock.gating_b1", "s3dg.InceptionBlock.gating_b2", "s3dg.InceptionBlock.gating_b3"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Inception block\n      \"\"\"", "\n", "b0", "=", "self", ".", "conv_b0", "(", "input", ")", "\n", "b1", "=", "self", ".", "conv_b1_a", "(", "input", ")", "\n", "b1", "=", "self", ".", "conv_b1_b", "(", "b1", ")", "\n", "b2", "=", "self", ".", "conv_b2_a", "(", "input", ")", "\n", "b2", "=", "self", ".", "conv_b2_b", "(", "b2", ")", "\n", "b3", "=", "self", ".", "maxpool_b3", "(", "input", ")", "\n", "b3", "=", "self", ".", "conv_b3_b", "(", "b3", ")", "\n", "if", "self", ".", "gating", ":", "\n", "            ", "b0", "=", "self", ".", "gating_b0", "(", "b0", ")", "\n", "b1", "=", "self", ".", "gating_b1", "(", "b1", ")", "\n", "b2", "=", "self", ".", "gating_b2", "(", "b2", ")", "\n", "b3", "=", "self", ".", "gating_b3", "(", "b3", ")", "\n", "", "return", "th", ".", "cat", "(", "(", "b0", ",", "b1", ",", "b2", ",", "b3", ")", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.SelfGating.__init__": [[88, 91], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ")", ":", "\n", "        ", "super", "(", "SelfGating", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "input_dim", ",", "input_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.SelfGating.forward": [[92, 99], ["torch.mean", "torch.mean", "torch.mean", "s3dg.SelfGating.fc", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ")", ":", "\n", "        ", "\"\"\"Feature gating as used in S3D-G.\n      \"\"\"", "\n", "spatiotemporal_average", "=", "th", ".", "mean", "(", "input_tensor", ",", "dim", "=", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "weights", "=", "self", ".", "fc", "(", "spatiotemporal_average", ")", "\n", "weights", "=", "th", ".", "sigmoid", "(", "weights", ")", "\n", "return", "weights", "[", ":", ",", ":", ",", "None", ",", "None", ",", "None", "]", "*", "input_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.STConv3D.__init__": [[102, 153], ["torch.Module.__init__", "torch.ReLU", "torch.ReLU", "torch.ReLU", "len", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "isinstance", "isinstance", "len", "len"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "input_dim", ",", "output_dim", ",", "kernel_size", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "separable", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", "STConv3D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "separable", "=", "separable", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "assert", "len", "(", "kernel_size", ")", "==", "3", "\n", "if", "separable", "and", "kernel_size", "[", "0", "]", "!=", "1", ":", "\n", "            ", "spatial_kernel_size", "=", "[", "1", ",", "kernel_size", "[", "1", "]", ",", "kernel_size", "[", "2", "]", "]", "\n", "temporal_kernel_size", "=", "[", "kernel_size", "[", "0", "]", ",", "1", ",", "1", "]", "\n", "if", "isinstance", "(", "stride", ",", "list", ")", "and", "len", "(", "stride", ")", "==", "3", ":", "\n", "                ", "spatial_stride", "=", "[", "1", ",", "stride", "[", "1", "]", ",", "stride", "[", "2", "]", "]", "\n", "temporal_stride", "=", "[", "stride", "[", "0", "]", ",", "1", ",", "1", "]", "\n", "", "else", ":", "\n", "                ", "spatial_stride", "=", "[", "1", ",", "stride", ",", "stride", "]", "\n", "temporal_stride", "=", "[", "stride", ",", "1", ",", "1", "]", "\n", "", "if", "isinstance", "(", "padding", ",", "list", ")", "and", "len", "(", "padding", ")", "==", "3", ":", "\n", "                ", "spatial_padding", "=", "[", "0", ",", "padding", "[", "1", "]", ",", "padding", "[", "2", "]", "]", "\n", "temporal_padding", "=", "[", "padding", "[", "0", "]", ",", "0", ",", "0", "]", "\n", "", "else", ":", "\n", "                ", "spatial_padding", "=", "[", "0", ",", "padding", ",", "padding", "]", "\n", "temporal_padding", "=", "[", "padding", ",", "0", ",", "0", "]", "\n", "", "", "if", "separable", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "\n", "input_dim", ",", "\n", "output_dim", ",", "\n", "kernel_size", "=", "spatial_kernel_size", ",", "\n", "stride", "=", "spatial_stride", ",", "\n", "padding", "=", "spatial_padding", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "output_dim", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv3d", "(", "\n", "output_dim", ",", "\n", "output_dim", ",", "\n", "kernel_size", "=", "temporal_kernel_size", ",", "\n", "stride", "=", "temporal_stride", ",", "\n", "padding", "=", "temporal_padding", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm3d", "(", "output_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "\n", "input_dim", ",", "\n", "output_dim", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "output_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.STConv3D.forward": [[154, 159], ["s3dg.STConv3D.relu", "s3dg.STConv3D.bn1", "s3dg.STConv3D.relu", "s3dg.STConv3D.conv1", "s3dg.STConv3D.bn2", "s3dg.STConv3D.conv2"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "out", "=", "self", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "input", ")", ")", ")", "\n", "if", "self", ".", "separable", ":", "\n", "            ", "out", "=", "self", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.MaxPool3dTFPadding.__init__": [[162, 169], ["super().__init__", "torch.nn.MaxPool3d", "torch.nn.MaxPool3d", "torch.nn.MaxPool3d", "s3dg.MaxPool3dTFPadding._get_padding_shape", "torch.nn.ConstantPad3d", "torch.nn.ConstantPad3d", "torch.nn.ConstantPad3d"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.MaxPool3dTFPadding._get_padding_shape"], ["    ", "def", "__init__", "(", "self", ",", "kernel_size", ",", "stride", "=", "None", ",", "padding", "=", "\"SAME\"", ")", ":", "\n", "        ", "super", "(", "MaxPool3dTFPadding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "padding", "==", "\"SAME\"", ":", "\n", "            ", "padding_shape", "=", "self", ".", "_get_padding_shape", "(", "kernel_size", ",", "stride", ")", "\n", "self", ".", "padding_shape", "=", "padding_shape", "\n", "self", ".", "pad", "=", "th", ".", "nn", ".", "ConstantPad3d", "(", "padding_shape", ",", "0", ")", "\n", "", "self", ".", "pool", "=", "th", ".", "nn", ".", "MaxPool3d", "(", "kernel_size", ",", "stride", ",", "ceil_mode", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.MaxPool3dTFPadding._get_padding_shape": [[170, 187], ["zip", "padding_shape.pop", "padding_shape.pop", "padding_shape.append", "padding_shape.append", "tuple", "max", "s3dg.MaxPool3dTFPadding._get_padding_shape._pad_top_bottom"], "methods", ["None"], ["", "def", "_get_padding_shape", "(", "self", ",", "filter_shape", ",", "stride", ")", ":", "\n", "        ", "def", "_pad_top_bottom", "(", "filter_dim", ",", "stride_val", ")", ":", "\n", "            ", "pad_along", "=", "max", "(", "filter_dim", "-", "stride_val", ",", "0", ")", "\n", "pad_top", "=", "pad_along", "//", "2", "\n", "pad_bottom", "=", "pad_along", "-", "pad_top", "\n", "return", "pad_top", ",", "pad_bottom", "\n", "\n", "", "padding_shape", "=", "[", "]", "\n", "for", "filter_dim", ",", "stride_val", "in", "zip", "(", "filter_shape", ",", "stride", ")", ":", "\n", "            ", "pad_top", ",", "pad_bottom", "=", "_pad_top_bottom", "(", "filter_dim", ",", "stride_val", ")", "\n", "padding_shape", ".", "append", "(", "pad_top", ")", "\n", "padding_shape", ".", "append", "(", "pad_bottom", ")", "\n", "", "depth_top", "=", "padding_shape", ".", "pop", "(", "0", ")", "\n", "depth_bottom", "=", "padding_shape", ".", "pop", "(", "0", ")", "\n", "padding_shape", ".", "append", "(", "depth_top", ")", "\n", "padding_shape", ".", "append", "(", "depth_bottom", ")", "\n", "return", "tuple", "(", "padding_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.MaxPool3dTFPadding.forward": [[188, 192], ["s3dg.MaxPool3dTFPadding.pad", "s3dg.MaxPool3dTFPadding.pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "inp", "=", "self", ".", "pad", "(", "inp", ")", "\n", "out", "=", "self", ".", "pool", "(", "inp", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.Sentence_Embedding.__init__": [[195, 213], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "numpy.load", "enumerate"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "embd_dim", ",", "\n", "num_embeddings", "=", "66250", ",", "\n", "word_embedding_dim", "=", "300", ",", "\n", "token_to_word_path", "=", "\"dict.npy\"", ",", "\n", "max_words", "=", "16", ",", "\n", "output_dim", "=", "2048", ",", "\n", ")", ":", "\n", "        ", "super", "(", "Sentence_Embedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embd", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "word_embedding_dim", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "word_embedding_dim", ",", "output_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "output_dim", ",", "embd_dim", ")", "\n", "self", ".", "word_to_token", "=", "{", "}", "\n", "self", ".", "max_words", "=", "max_words", "\n", "token_to_word", "=", "np", ".", "load", "(", "token_to_word_path", ")", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "token_to_word", ")", ":", "\n", "            ", "self", ".", "word_to_token", "[", "t", "]", "=", "i", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.Sentence_Embedding._zero_pad_tensor_token": [[214, 220], ["len", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.cat", "torch.cat", "torch.cat", "torch.zeros", "torch.zeros", "torch.zeros", "len"], "methods", ["None"], ["", "", "def", "_zero_pad_tensor_token", "(", "self", ",", "tensor", ",", "size", ")", ":", "\n", "        ", "if", "len", "(", "tensor", ")", ">=", "size", ":", "\n", "            ", "return", "tensor", "[", ":", "size", "]", "\n", "", "else", ":", "\n", "            ", "zero", "=", "th", ".", "zeros", "(", "size", "-", "len", "(", "tensor", ")", ")", ".", "long", "(", ")", "\n", "return", "th", ".", "cat", "(", "(", "tensor", ",", "zero", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.Sentence_Embedding._split_text": [[221, 224], ["re.findall", "str"], "methods", ["None"], ["", "", "def", "_split_text", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "w", "=", "re", ".", "findall", "(", "r\"[\\w']+\"", ",", "str", "(", "sentence", ")", ")", "\n", "return", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.Sentence_Embedding._words_to_token": [[225, 234], ["s3dg.Sentence_Embedding._zero_pad_tensor_token", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.Sentence_Embedding._zero_pad_tensor_token"], ["", "def", "_words_to_token", "(", "self", ",", "words", ")", ":", "\n", "        ", "words", "=", "[", "\n", "self", ".", "word_to_token", "[", "word", "]", "for", "word", "in", "words", "if", "word", "in", "self", ".", "word_to_token", "\n", "]", "\n", "if", "words", ":", "\n", "            ", "we", "=", "self", ".", "_zero_pad_tensor_token", "(", "th", ".", "LongTensor", "(", "words", ")", ",", "self", ".", "max_words", ")", "\n", "return", "we", "\n", "", "else", ":", "\n", "            ", "return", "th", ".", "zeros", "(", "self", ".", "max_words", ")", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.Sentence_Embedding._words_to_ids": [[235, 238], ["torch.stack", "torch.stack", "torch.stack", "s3dg.Sentence_Embedding._words_to_token", "s3dg.Sentence_Embedding._split_text", "sent.lower"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.Sentence_Embedding._words_to_token", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.Sentence_Embedding._split_text"], ["", "", "def", "_words_to_ids", "(", "self", ",", "x", ")", ":", "\n", "        ", "split_x", "=", "[", "self", ".", "_words_to_token", "(", "self", ".", "_split_text", "(", "sent", ".", "lower", "(", ")", ")", ")", "for", "sent", "in", "x", "]", "\n", "return", "th", ".", "stack", "(", "split_x", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.Sentence_Embedding.forward": [[239, 248], ["s3dg.Sentence_Embedding._words_to_ids", "s3dg.Sentence_Embedding.word_embd", "torch.relu", "torch.relu", "torch.relu", "s3dg.Sentence_Embedding.fc2", "x.to.to.to", "s3dg.Sentence_Embedding.fc1", "torch.max", "torch.max", "torch.max"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.Sentence_Embedding._words_to_ids"], ["", "def", "forward", "(", "self", ",", "x", ",", "device", ":", "th", ".", "device", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "_words_to_ids", "(", "x", ")", "\n", "if", "device", ":", "\n", "            ", "x", "=", "x", ".", "to", "(", "device", ")", "\n", "", "x", "=", "self", ".", "word_embd", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "th", ".", "max", "(", "x", ",", "dim", "=", "1", ")", "[", "0", "]", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "return", "{", "'text_embedding'", ":", "x", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.S3D.__init__": [[251, 307], ["torch.Module.__init__", "s3dg.STConv3D", "s3dg.STConv3D", "s3dg.SelfGating", "s3dg.MaxPool3dTFPadding", "s3dg.MaxPool3dTFPadding", "s3dg.InceptionBlock", "s3dg.InceptionBlock", "s3dg.MaxPool3dTFPadding", "s3dg.InceptionBlock", "s3dg.InceptionBlock", "s3dg.InceptionBlock", "s3dg.InceptionBlock", "s3dg.InceptionBlock", "s3dg.MaxPool3dTFPadding", "s3dg.InceptionBlock", "s3dg.InceptionBlock", "torch.Linear", "torch.Linear", "torch.Linear", "s3dg.Sentence_Embedding", "s3dg.STConv3D", "s3dg.STConv3D"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dict_path", ",", "num_classes", "=", "512", ",", "gating", "=", "True", ",", "space_to_depth", "=", "True", ")", ":", "\n", "        ", "super", "(", "S3D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "gating", "=", "gating", "\n", "self", ".", "space_to_depth", "=", "space_to_depth", "\n", "if", "space_to_depth", ":", "\n", "            ", "self", ".", "conv1", "=", "STConv3D", "(", "\n", "24", ",", "64", ",", "[", "2", ",", "4", ",", "4", "]", ",", "stride", "=", "1", ",", "padding", "=", "(", "1", ",", "2", ",", "2", ")", ",", "separable", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "STConv3D", "(", "\n", "3", ",", "64", ",", "[", "3", ",", "7", ",", "7", "]", ",", "stride", "=", "2", ",", "padding", "=", "(", "1", ",", "3", ",", "3", ")", ",", "separable", "=", "False", "\n", ")", "\n", "", "self", ".", "conv_2b", "=", "STConv3D", "(", "64", ",", "64", ",", "[", "1", ",", "1", ",", "1", "]", ",", "separable", "=", "False", ")", "\n", "self", ".", "conv_2c", "=", "STConv3D", "(", "64", ",", "192", ",", "[", "3", ",", "3", ",", "3", "]", ",", "padding", "=", "1", ",", "separable", "=", "True", ")", "\n", "self", ".", "gating", "=", "SelfGating", "(", "192", ")", "\n", "self", ".", "maxpool_2a", "=", "MaxPool3dTFPadding", "(", "\n", "kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "padding", "=", "\"SAME\"", "\n", ")", "\n", "self", ".", "maxpool_3a", "=", "MaxPool3dTFPadding", "(", "\n", "kernel_size", "=", "(", "1", ",", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "padding", "=", "\"SAME\"", "\n", ")", "\n", "self", ".", "mixed_3b", "=", "InceptionBlock", "(", "192", ",", "64", ",", "96", ",", "128", ",", "16", ",", "32", ",", "32", ")", "\n", "self", ".", "mixed_3c", "=", "InceptionBlock", "(", "\n", "self", ".", "mixed_3b", ".", "output_dim", ",", "128", ",", "128", ",", "192", ",", "32", ",", "96", ",", "64", "\n", ")", "\n", "self", ".", "maxpool_4a", "=", "MaxPool3dTFPadding", "(", "\n", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ",", "padding", "=", "\"SAME\"", "\n", ")", "\n", "self", ".", "mixed_4b", "=", "InceptionBlock", "(", "\n", "self", ".", "mixed_3c", ".", "output_dim", ",", "192", ",", "96", ",", "208", ",", "16", ",", "48", ",", "64", "\n", ")", "\n", "self", ".", "mixed_4c", "=", "InceptionBlock", "(", "\n", "self", ".", "mixed_4b", ".", "output_dim", ",", "160", ",", "112", ",", "224", ",", "24", ",", "64", ",", "64", "\n", ")", "\n", "self", ".", "mixed_4d", "=", "InceptionBlock", "(", "\n", "self", ".", "mixed_4c", ".", "output_dim", ",", "128", ",", "128", ",", "256", ",", "24", ",", "64", ",", "64", "\n", ")", "\n", "self", ".", "mixed_4e", "=", "InceptionBlock", "(", "\n", "self", ".", "mixed_4d", ".", "output_dim", ",", "112", ",", "144", ",", "288", ",", "32", ",", "64", ",", "64", "\n", ")", "\n", "self", ".", "mixed_4f", "=", "InceptionBlock", "(", "\n", "self", ".", "mixed_4e", ".", "output_dim", ",", "256", ",", "160", ",", "320", ",", "32", ",", "128", ",", "128", "\n", ")", "\n", "self", ".", "maxpool_5a", "=", "self", ".", "maxPool3d_5a_2x2", "=", "MaxPool3dTFPadding", "(", "\n", "kernel_size", "=", "(", "2", ",", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ",", "padding", "=", "\"SAME\"", "\n", ")", "\n", "self", ".", "mixed_5b", "=", "InceptionBlock", "(", "\n", "self", ".", "mixed_4f", ".", "output_dim", ",", "256", ",", "160", ",", "320", ",", "32", ",", "128", ",", "128", "\n", ")", "\n", "self", ".", "mixed_5c", "=", "InceptionBlock", "(", "\n", "self", ".", "mixed_5b", ".", "output_dim", ",", "384", ",", "192", ",", "384", ",", "48", ",", "128", ",", "128", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "mixed_5c", ".", "output_dim", ",", "num_classes", ")", "\n", "self", ".", "text_module", "=", "Sentence_Embedding", "(", "num_classes", ",", "\n", "token_to_word_path", "=", "dict_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.S3D._space_to_depth": [[308, 316], ["input.contiguous().view.contiguous().view.view", "input.contiguous().view.contiguous().view.permute", "input.contiguous().view.contiguous().view.contiguous().view", "input.contiguous().view.contiguous().view.contiguous"], "methods", ["None"], ["", "def", "_space_to_depth", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"3D space to depth trick for TPU optimization.\n      \"\"\"", "\n", "B", ",", "C", ",", "T", ",", "H", ",", "W", "=", "input", ".", "shape", "\n", "input", "=", "input", ".", "view", "(", "B", ",", "C", ",", "T", "//", "2", ",", "2", ",", "H", "//", "2", ",", "2", ",", "W", "//", "2", ",", "2", ")", "\n", "input", "=", "input", ".", "permute", "(", "0", ",", "3", ",", "5", ",", "7", ",", "1", ",", "2", ",", "4", ",", "6", ")", "\n", "input", "=", "input", ".", "contiguous", "(", ")", ".", "view", "(", "B", ",", "8", "*", "C", ",", "T", "//", "2", ",", "H", "//", "2", ",", "W", "//", "2", ")", "\n", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.S3D.forward": [[317, 345], ["s3dg.S3D.conv1", "s3dg.S3D.maxpool_2a", "s3dg.S3D.conv_2b", "s3dg.S3D.conv_2c", "s3dg.S3D.maxpool_3a", "s3dg.S3D.mixed_3b", "s3dg.S3D.mixed_3c", "s3dg.S3D.maxpool_4a", "s3dg.S3D.mixed_4b", "s3dg.S3D.mixed_4c", "s3dg.S3D.mixed_4d", "s3dg.S3D.mixed_4e", "s3dg.S3D.mixed_4f", "s3dg.S3D.maxpool_5a", "s3dg.S3D.mixed_5b", "s3dg.S3D.mixed_5c", "torch.mean", "torch.mean", "torch.mean", "s3dg.S3D._space_to_depth", "s3dg.S3D.gating", "s3dg.S3D.fc"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.s3dg.S3D._space_to_depth"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Defines the S3DG base architecture.\n      \"\"\"", "\n", "if", "self", ".", "space_to_depth", ":", "\n", "            ", "inputs", "=", "self", ".", "_space_to_depth", "(", "inputs", ")", "\n", "", "net", "=", "self", ".", "conv1", "(", "inputs", ")", "\n", "if", "self", ".", "space_to_depth", ":", "\n", "# we need to replicate 'SAME' tensorflow padding", "\n", "            ", "net", "=", "net", "[", ":", ",", ":", ",", "1", ":", ",", "1", ":", ",", "1", ":", "]", "\n", "", "net", "=", "self", ".", "maxpool_2a", "(", "net", ")", "\n", "net", "=", "self", ".", "conv_2b", "(", "net", ")", "\n", "net", "=", "self", ".", "conv_2c", "(", "net", ")", "\n", "if", "self", ".", "gating", ":", "\n", "            ", "net", "=", "self", ".", "gating", "(", "net", ")", "\n", "", "net", "=", "self", ".", "maxpool_3a", "(", "net", ")", "\n", "net", "=", "self", ".", "mixed_3b", "(", "net", ")", "\n", "net", "=", "self", ".", "mixed_3c", "(", "net", ")", "\n", "net", "=", "self", ".", "maxpool_4a", "(", "net", ")", "\n", "net", "=", "self", ".", "mixed_4b", "(", "net", ")", "\n", "net", "=", "self", ".", "mixed_4c", "(", "net", ")", "\n", "net", "=", "self", ".", "mixed_4d", "(", "net", ")", "\n", "net", "=", "self", ".", "mixed_4e", "(", "net", ")", "\n", "net", "=", "self", ".", "mixed_4f", "(", "net", ")", "\n", "net", "=", "self", ".", "maxpool_5a", "(", "net", ")", "\n", "net", "=", "self", ".", "mixed_5b", "(", "net", ")", "\n", "net", "=", "self", ".", "mixed_5c", "(", "net", ")", "\n", "net", "=", "th", ".", "mean", "(", "net", ",", "dim", "=", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "return", "{", "'video_embedding'", ":", "self", ".", "fc", "(", "net", ")", ",", "'mixed_5c'", ":", "net", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.Mish.forward": [[41, 46], ["torch.tanh", "torch.tanh", "torch.tanh", "torch.softplus", "torch.softplus", "torch.softplus"], "methods", ["None"], ["def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "'''\n        Forward pass of the function.\n        '''", "\n", "return", "input", "*", "th", ".", "tanh", "(", "F", ".", "softplus", "(", "input", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CENet.__init__": [[48, 261], ["base.BaseModel.__init__", "list", "logger.debug", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "expert_dims.keys", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "re.match", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.Dropout", "torch.Dropout", "torch.Dropout", "model.ReduceDim", "model.GatedEmbeddingUnitReasoning", "types.SimpleNamespace", "model.bert.BertModel", "re.match.groups", "re.match.groups", "transformers.modeling_bert.BertModel.from_pretrained", "model.CENet.txt_bert.embeddings.parameters", "model.GatedEmbeddingUnit", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "re.match.groups", "re.match.groups", "logger.error", "model.txt_embeddings.TxtEmbeddings", "model.net_vlad.NetVLAD", "model.GatedEmbeddingUnit", "re.match.groups", "int", "logger.debug", "model.CENet.txt_bert.named_parameters", "model.CENet.txt_bert.named_parameters", "model.txt_embeddings.TxtEmbeddings", "model.ReduceDim", "[].isdigit", "model.txt_embeddings.TxtEmbeddings", "model.lstm.LSTMModel", "name.split", "int", "logger.debug", "name.split", "range", "name.split", "name.split"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["", "", "def", "kronecker_prod", "(", "t1", ",", "t2", ")", ":", "\n", "# kronecker is performed along the last dim", "\n", "    ", "kron", "=", "th", ".", "bmm", "(", "t1", ".", "view", "(", "-", "1", ",", "t1", ".", "size", "(", "-", "1", ")", ",", "1", ")", ",", "t2", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "1", ",", "t2", ".", "size", "(", "-", "1", ")", ")", ")", "\n", "return", "kron", ".", "view", "(", "t1", ".", "shape", "[", "0", "]", ",", "t1", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "\n", "\n", "\n", "", "def", "drop_nans", "(", "x", ",", "ind", ",", "validate_missing", ")", ":", "\n", "    ", "\"\"\"Remove nans, which we expect to find at missing indices.\n\n    Args:\n        x (th.Tensor): features\n        ind (th.Tensor): binary values denoting whether or not a given feature is\n            present\n        validate_missing (bool): whether to validate that the missing location contains\n            a nan.\n\n    Returns:\n        (th.tensor): the features, with the missing values masked to zero.\n    \"\"\"", "\n", "missing", "=", "th", ".", "nonzero", "(", "ind", "==", "0", ")", ".", "flatten", "(", ")", "\n", "if", "missing", ".", "numel", "(", ")", ":", "\n", "        ", "if", "validate_missing", ":", "\n", "            ", "vals", "=", "x", "[", "missing", "[", "0", "]", "]", "\n", "if", "not", "th", ".", "isnan", "(", "vals", ".", "view", "(", "-", "1", ")", "[", "0", "]", ")", ":", "\n", "                ", "ipdb", ".", "set_trace", "(", ")", "\n", "", "assert", "vals", ".", "view", "(", "-", "1", ")", "[", "0", "]", ",", "\"expected nans at missing locations\"", "\n", "# Prevent overwrite of the original tensor", "\n", "# x_ = x.clone()", "\n", "# TODO(samuel): This doesn't do anything, so can remove it", "\n", "", "x_", "=", "x", "\n", "x_", "[", "missing", "]", "=", "0", "\n", "x", "=", "x_", "\n", "", "if", "th", ".", "isnan", "(", "x", ")", ".", "sum", "(", ")", ">", "0", ":", "\n", "# slow, but might help us solve the mystery", "\n", "        ", "ipdb", ".", "set_trace", "(", ")", "\n", "", "return", "x", "\n", "\n", "\n", "", "class", "CENet", "(", "BaseModel", ")", ":", "\n", "    ", "def", "__init__", "(", "\n", "self", ",", "\n", "task", ",", "\n", "use_ce", ",", "\n", "text_dim", ",", "\n", "l2renorm", ",", "\n", "expert_dims", ",", "\n", "vlad_clusters", ",", "\n", "ghost_clusters", ",", "\n", "disable_nan_checks", ",", "\n", "keep_missing_modalities", ",", "\n", "test_caption_mode", ",", "\n", "randomise_feats", ",", "\n", "feat_aggregation", ",", "\n", "ce_shared_dim", ",", "\n", "trn_config", ",", "\n", "trn_cat", ",", "\n", "include_self", ",", "\n", "use_mish", ",", "\n", "use_bn_reason", ",", "\n", "num_h_layers", ",", "\n", "num_g_layers", ",", "\n", "kron_dets", "=", "False", ",", "\n", "freeze_weights", "=", "False", ",", "\n", "geometric_mlp", "=", "False", ",", "\n", "rand_proj", "=", "False", ",", "\n", "mimic_ce_dims", "=", "False", ",", "\n", "coord_dets", "=", "False", ",", "\n", "concat_experts", "=", "False", ",", "\n", "spatial_feats", "=", "False", ",", "\n", "concat_mix_experts", "=", "False", ",", "\n", "verbose", "=", "False", ",", "\n", "num_classes", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "l2renorm", "=", "l2renorm", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "geometric_mlp", "=", "geometric_mlp", "\n", "self", ".", "feat_aggregation", "=", "feat_aggregation", "\n", "self", ".", "expert_dims", "=", "expert_dims", "\n", "self", ".", "num_h_layers", "=", "num_h_layers", "\n", "self", ".", "num_g_layers", "=", "num_g_layers", "\n", "self", ".", "use_mish", "=", "use_mish", "\n", "self", ".", "use_bn_resaon", "=", "use_bn_reason", "\n", "self", ".", "include_self", "=", "include_self", "\n", "self", ".", "kron_dets", "=", "kron_dets", "\n", "self", ".", "rand_proj", "=", "rand_proj", "\n", "self", ".", "coord_dets", "=", "coord_dets", "\n", "self", ".", "disable_nan_checks", "=", "disable_nan_checks", "\n", "self", ".", "trn_config", "=", "trn_config", "\n", "self", ".", "trn_cat", "=", "trn_cat", "\n", "if", "randomise_feats", ":", "\n", "            ", "self", ".", "random_feats", "=", "set", "(", "[", "x", "for", "x", "in", "randomise_feats", ".", "split", "(", "\",\"", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "random_feats", "=", "set", "(", ")", "\n", "\n", "# sanity checks on the features that may be vladded", "\n", "", "pre_vlad_feat_sizes", "=", "{", "\"ocr\"", ":", "300", ",", "\"audio\"", ":", "128", ",", "\"speech\"", ":", "300", ",", "\"pann\"", ":", "2048", ",", "\n", "\"syncnet\"", ":", "1024", ",", "\"vggsound\"", ":", "512", "}", "\n", "pre_vlad_feat_sizes", "=", "{", "key", ":", "val", "for", "key", ",", "val", "in", "pre_vlad_feat_sizes", ".", "items", "(", ")", "\n", "if", "feat_aggregation", "[", "key", "]", "[", "\"temporal\"", "]", "==", "\"vlad\"", "}", "\n", "\n", "# we basically disable safety checks for detection-sem", "\n", "if", "spatial_feats", ":", "\n", "            ", "spatial_feat_dim", "=", "16", "\n", "", "else", ":", "\n", "            ", "spatial_feat_dim", "=", "5", "\n", "", "if", "self", ".", "geometric_mlp", ":", "\n", "            ", "self", ".", "geometric_mlp_model", "=", "SpatialMLP", "(", "spatial_feat_dim", ")", "\n", "", "if", "kron_dets", ":", "\n", "            ", "sem_det_dim", "=", "300", "*", "spatial_feat_dim", "\n", "", "elif", "coord_dets", ":", "\n", "            ", "sem_det_dim", "=", "spatial_feat_dim", "\n", "", "elif", "rand_proj", ":", "\n", "            ", "sem_det_dim", "=", "300", "+", "300", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "spatial_feat_dim", ",", "300", ")", "\n", "# random proj", "\n", "# th.nn.init.normal_(self.proj.weight, mean=0, std=1)", "\n", "# for param in self.proj.parameters():", "\n", "#     param.requires_grad = False", "\n", "# self.proj.bias.mul_(0)", "\n", "", "else", ":", "\n", "            ", "sem_det_dim", "=", "300", "+", "spatial_feat_dim", "\n", "", "self", ".", "spatial_feat_dim", "=", "spatial_feat_dim", "\n", "pre_vlad_feat_sizes", "[", "\"detection-sem\"", "]", "=", "sem_det_dim", "\n", "if", "\"detection-sem\"", "in", "expert_dims", ":", "\n", "            ", "new_in_dim", "=", "sem_det_dim", "*", "vlad_clusters", "[", "\"detection-sem\"", "]", "\n", "expert_dims", "[", "\"detection-sem\"", "]", "=", "(", "new_in_dim", ",", "expert_dims", "[", "\"detection-sem\"", "]", "[", "1", "]", ")", "\n", "\n", "", "vlad_feat_sizes", "=", "{", "key", ":", "val", "for", "key", ",", "val", "in", "vlad_clusters", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "pooling", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "for", "mod", ",", "expected", "in", "pre_vlad_feat_sizes", ".", "items", "(", ")", ":", "\n", "            ", "if", "mod", "in", "expert_dims", ".", "keys", "(", ")", ":", "\n", "                ", "feature_size", "=", "expert_dims", "[", "mod", "]", "[", "0", "]", "//", "vlad_clusters", "[", "mod", "]", "\n", "msg", "=", "f\"expected {expected} for {mod} features atm\"", "\n", "assert", "feature_size", "==", "expected", ",", "msg", "\n", "self", ".", "pooling", "[", "mod", "]", "=", "NetVLAD", "(", "\n", "feature_size", "=", "feature_size", ",", "\n", "cluster_size", "=", "vlad_clusters", "[", "mod", "]", ",", "\n", ")", "\n", "", "", "if", "\"retrieval\"", "in", "self", ".", "task", ":", "\n", "            ", "if", "vlad_clusters", "[", "\"text\"", "]", "==", "0", ":", "\n", "                ", "self", ".", "text_pooling", "=", "nn", ".", "Sequential", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "text_pooling", "=", "NetVLAD", "(", "\n", "feature_size", "=", "text_dim", ",", "\n", "cluster_size", "=", "vlad_clusters", "[", "\"text\"", "]", ",", "\n", "ghost_clusters", "=", "ghost_clusters", "[", "\"text\"", "]", ",", "\n", ")", "\n", "text_dim", "=", "self", ".", "text_pooling", ".", "out_dim", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "num_classes", "=", "num_classes", "\n", "text_dim", "=", "None", "\n", "\n", "", "self", ".", "tensor_storage", "=", "expert_tensor_storage", "(", "\n", "experts", "=", "self", ".", "expert_dims", ".", "keys", "(", ")", ",", "\n", "feat_aggregation", "=", "self", ".", "feat_aggregation", ",", "\n", ")", "\n", "# self.fixed_sz_experts = [\"rgb\", \"scene\", \"face\", \"flow\"]", "\n", "# self.variable_sz_experts = [\"audio\", \"speech\", \"ocr\"]", "\n", "# # handle features which can be either", "\n", "# for expert in {\"detection\", \"detection-sem\", \"openpose\"}:", "\n", "#     if expert in self.pooling:", "\n", "#         self.variable_sz_experts.append(expert)", "\n", "#     else:", "\n", "#         self.fixed_sz_experts.append(expert)", "\n", "\n", "self", ".", "ce", "=", "CEModule", "(", "\n", "use_ce", "=", "use_ce", ",", "\n", "task", "=", "self", ".", "task", ",", "\n", "verbose", "=", "verbose", ",", "\n", "l2renorm", "=", "l2renorm", ",", "\n", "trn_cat", "=", "self", ".", "trn_cat", ",", "\n", "trn_config", "=", "self", ".", "trn_config", ",", "\n", "random_feats", "=", "self", ".", "random_feats", ",", "\n", "freeze_weights", "=", "freeze_weights", ",", "\n", "text_dim", "=", "text_dim", ",", "\n", "test_caption_mode", "=", "test_caption_mode", ",", "\n", "concat_experts", "=", "concat_experts", ",", "\n", "concat_mix_experts", "=", "concat_mix_experts", ",", "\n", "expert_dims", "=", "expert_dims", ",", "\n", "vlad_feat_sizes", "=", "vlad_feat_sizes", ",", "\n", "disable_nan_checks", "=", "disable_nan_checks", ",", "\n", "keep_missing_modalities", "=", "keep_missing_modalities", ",", "\n", "mimic_ce_dims", "=", "mimic_ce_dims", ",", "\n", "include_self", "=", "include_self", ",", "\n", "use_mish", "=", "use_mish", ",", "\n", "use_bn_reason", "=", "use_bn_reason", ",", "\n", "num_h_layers", "=", "num_h_layers", ",", "\n", "num_g_layers", "=", "num_g_layers", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "same_dim", "=", "ce_shared_dim", ",", "\n", ")", "\n", "\n", "", "def", "randomise_feats", "(", "self", ",", "experts", ",", "key", ")", ":", "\n", "        ", "if", "key", "in", "self", ".", "random_feats", ":", "\n", "# keep expected nans", "\n", "            ", "nan_mask", "=", "th", ".", "isnan", "(", "experts", "[", "key", "]", ")", "\n", "experts", "[", "key", "]", "=", "th", ".", "randn_like", "(", "experts", "[", "key", "]", ")", "\n", "if", "not", "self", ".", "disable_nan_checks", ":", "\n", "                ", "nans", "=", "th", ".", "tensor", "(", "float", "(", "'nan'", ")", ")", "# pylint: disable=not-callable", "\n", "experts", "[", "key", "]", "[", "nan_mask", "]", "=", "nans", ".", "to", "(", "experts", "[", "key", "]", ".", "device", ")", "\n", "", "", "return", "experts", "\n", "\n", "", "def", "forward", "(", "self", ",", "experts", ",", "ind", ",", "text", "=", "None", ",", "raw_captions", "=", "None", ",", "text_token_mask", "=", "None", ")", ":", "\n", "        ", "aggregated_experts", "=", "OrderedDict", "(", ")", "\n", "\n", "if", "\"detection-sem\"", "in", "self", ".", "expert_dims", ":", "\n", "            ", "det_sem", "=", "experts", "[", "\"detection-sem\"", "]", "\n", "box_feats", "=", "det_sem", "[", ":", ",", ":", ",", ":", "self", ".", "spatial_feat_dim", "]", "\n", "sem_feats", "=", "det_sem", "[", ":", ",", ":", ",", "self", ".", "spatial_feat_dim", ":", "]", "\n", "if", "self", ".", "geometric_mlp", ":", "\n", "                ", "x", "=", "box_feats", ".", "view", "(", "-", "1", ",", "box_feats", ".", "shape", "[", "-", "1", "]", ")", "\n", "x", "=", "self", ".", "geometric_mlp_model", "(", "x", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CENet.randomise_feats": [[242, 251], ["torch.isnan", "torch.isnan", "torch.isnan", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.to", "float"], "methods", ["None"], ["", "def", "randomise_feats", "(", "self", ",", "experts", ",", "key", ")", ":", "\n", "        ", "if", "key", "in", "self", ".", "random_feats", ":", "\n", "# keep expected nans", "\n", "            ", "nan_mask", "=", "th", ".", "isnan", "(", "experts", "[", "key", "]", ")", "\n", "experts", "[", "key", "]", "=", "th", ".", "randn_like", "(", "experts", "[", "key", "]", ")", "\n", "if", "not", "self", ".", "disable_nan_checks", ":", "\n", "                ", "nans", "=", "th", ".", "tensor", "(", "float", "(", "'nan'", ")", ")", "# pylint: disable=not-callable", "\n", "experts", "[", "key", "]", "[", "nan_mask", "]", "=", "nans", ".", "to", "(", "experts", "[", "key", "]", ".", "device", ")", "\n", "", "", "return", "experts", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CENet.forward": [[312, 661], ["enumerate", "collections.OrderedDict", "token_ids.view.view.size", "len", "model.CENet.view", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "token_ids.view.view.view", "range", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "model.CENet.txt_bert", "layer", "text_.view.view.view", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "list", "enumerate", "collections.OrderedDict", "input_ids_list.append", "token_type_ids_list.append", "position_ids_list.append", "features_list.append", "attention_mask_list.append", "enumerate", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "model.CENet.vid_bert", "enumerate", "model.CENet.compute_weights_from_norm", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "enumerate", "model.CENet.compute_weights_from_emb", "enumerate", "model.sharded_cross_view_inner_product", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max", "torch.max", "torch.max", "input_ids_list.append", "token_type_ids_list.append", "position_ids_list.append", "attention_mask_list.append", "token_ids.view.view.view", "token_ids[].to", "token_ids[].to", "model.CENet.word_embeddings", "layer", "layer", "layer", "itertools.permutations", "len", "torch.div", "torch.div", "torch.div", "model.CENet.f_reason_1", "model.CENet.coll_f_dropout", "model.CENet.f_reason_2", "mod_gu", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "collections.OrderedDict", "enumerate", "enumerate", "torch.stack().to", "torch.stack().to", "torch.stack().to", "token_ids.view.view.view", "model.CENet.display_minibatch", "token_ids.view.view.view", "model.CENet.compute_weights_from_emb", "ind[].float", "torch.ones().to", "torch.ones().to", "torch.ones().to", "NotImplementedError", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "torch.functional.normalize", "vid_embds_list.append", "text_embds_list.append", "token_ids[].to", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "token_ids[].to", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.max", "torch.max", "torch.max", "torch.relu", "torch.relu", "torch.relu", "experts_feats_t[].clamp_", "experts_feats_t[].long().to", "input_ids_list.append", "token_type_ids_list.append", "position_ids_list.append", "attention_mask_list.append", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.ones().to", "torch.ones().to", "torch.ones().to", "NotImplementedError", "torch.zeros", "torch.zeros", "torch.zeros", "msg.format", "experts[].unsqueeze", "text_embd[].unsqueeze", "torch.mean", "torch.mean", "torch.mean", "float", "torch.max", "torch.max", "torch.max", "model.CENet.text_pooling", "torch.cat", "torch.cat", "torch.cat", "model.CENet.g_reason_1", "model.CENet.coll_g_dropout", "model.CENet.g_reason_2", "avai_dict[].unsqueeze", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "experts_feats[].size", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full().to", "torch.full().to", "torch.full().to", "features_list.append", "[].to().to", "input_ids_list.append", "token_type_ids_list.append", "features_list.append", "attention_mask_list.append", "torch.stack", "torch.stack", "torch.stack", "msg.format", "torch.ones", "torch.ones", "torch.ones", "utils.util.get_len_sequences", "model.CENet.text_pooling", "torch.relu", "torch.relu", "torch.relu", "experts_feats_t[].long", "torch.full().to", "torch.full().to", "torch.full().to", "features_list.append", "position_ids_list.append", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "[].to", "torch.ones", "torch.ones", "torch.ones", "torch.full", "torch.full", "torch.full", "features_list.append", "[].to", "torch.full().to", "torch.full().to", "torch.full().to", "position_ids_list.append", "ind[].float", "ind[].float", "torch.full", "torch.full", "torch.full", "position_ids_list.append", "torch.full", "torch.full", "torch.full", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full", "torch.full", "torch.full"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CENet.compute_weights_from_norm", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CENet.compute_weights_from_emb", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.sharded_cross_view_inner_product", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer.display_minibatch", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CENet.compute_weights_from_emb", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_len_sequences"], ["#         texts = th.split(text, split_size_or_sections=splits)", "\n", "#         texts = [self.text_pooling(text) for text in texts]", "\n", "#         text = th.cat(texts, dim=0)", "\n", "#         import ipdb; ipdb.set_trace()", "\n", "#     else:", "\n", "# safe = 5000", "\n", "# if text.shape[0] > safe:", "\n", "#     dev = text.device", "\n", "#     print(\"pooling text features on cpu\")", "\n", "#     text, self.text_pooling = text.to(\"cpu\"), self.text_pooling.to(\"cpu\")", "\n", "#     text = self.text_pooling(text)", "\n", "#     text, self.text_pooling = text.to(dev), self.text_pooling.to(dev)", "\n", "#     import ipdb; ipdb.set_trace()", "\n", "# else:", "\n", "if", "isinstance", "(", "self", ".", "text_pooling", ",", "NetVLAD", ")", ":", "\n", "                ", "kwargs", "=", "{", "\"mask\"", ":", "text_token_mask", "}", "\n", "", "else", ":", "\n", "                ", "kwargs", "=", "{", "}", "\n", "", "text", "=", "self", ".", "text_pooling", "(", "text", ",", "**", "kwargs", ")", "\n", "text", "=", "text", ".", "view", "(", "B", ",", "captions_per_video", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "text", "=", "None", "\n", "", "return", "self", ".", "ce", "(", "text", ",", "aggregated_experts", ",", "ind", ",", "raw_captions", ")", "\n", "\n", "\n", "", "", "class", "TemporalAttention", "(", "th", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "img_feature_dim", ",", "num_attention", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "Variable", "(", "\n", "th", ".", "randn", "(", "img_feature_dim", ",", "num_attention", ")", ",", "\n", "requires_grad", "=", "True", ")", ".", "cuda", "(", ")", "# d*seg", "\n", "self", ".", "img_feature_dim", "=", "img_feature_dim", "\n", "self", ".", "num_attention", "=", "num_attention", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "B", ",", "T", ",", "D", "=", "input", ".", "shape", "\n", "record", "=", "[", "]", "\n", "input_avg", "=", "th", ".", "mean", "(", "input", ".", "clone", "(", ")", ",", "dim", "=", "1", ")", "\n", "input_max", "=", "th", ".", "max", "(", "input", ".", "clone", "(", ")", ",", "dim", "=", "1", ")", "\n", "record", ".", "append", "(", "input_avg", ")", "\n", "record", ".", "append", "(", "input_max", "[", "0", "]", ")", "\n", "output", "=", "th", ".", "matmul", "(", "input", ",", "self", ".", "weight", ")", "\n", "attentions", "=", "F", ".", "softmax", "(", "output", ",", "dim", "=", "1", ")", "\n", "for", "idx", "in", "range", "(", "attentions", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "            ", "temp", "=", "attentions", "[", ":", ",", ":", ",", "idx", "]", "\n", "temp_output", "=", "th", ".", "sum", "(", "temp", ".", "unsqueeze", "(", "2", ")", "*", "input", ",", "dim", "=", "1", ")", "\n", "norm", "=", "temp_output", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "temp_output", "=", "temp_output", ".", "div", "(", "norm", ")", "\n", "record", ".", "append", "(", "temp_output", ")", "\n", "", "act_all", "=", "th", ".", "cat", "(", "(", "record", ")", ",", "1", ")", "\n", "return", "act_all", "\n", "\n", "\n", "", "", "class", "RelationModuleMultiScale", "(", "th", ".", "nn", ".", "Module", ")", ":", "\n", "# Temporal Relation module in multiply scale, suming over", "\n", "# [2-frame relation, 3-frame relation, ..., n-frame relation]", "\n", "    ", "def", "__init__", "(", "self", ",", "img_feature_dim", ",", "num_frames", ",", "num_class", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "subsample_num", "=", "3", "# how many relations selected to sum up", "\n", "self", ".", "img_feature_dim", "=", "img_feature_dim", "\n", "# generate the multiple frame relations", "\n", "self", ".", "scales", "=", "[", "i", "for", "i", "in", "range", "(", "num_frames", ",", "1", ",", "-", "1", ")", "]", "\n", "\n", "self", ".", "relations_scales", "=", "[", "]", "\n", "self", ".", "subsample_scales", "=", "[", "]", "\n", "for", "scale", "in", "self", ".", "scales", ":", "\n", "            ", "relations_scale", "=", "self", ".", "return_relationset", "(", "num_frames", ",", "scale", ")", "\n", "self", ".", "relations_scales", ".", "append", "(", "relations_scale", ")", "\n", "# how many samples of relation to select in each forward pass", "\n", "self", ".", "subsample_scales", ".", "append", "(", "min", "(", "self", ".", "subsample_num", ",", "len", "(", "relations_scale", ")", ")", ")", "\n", "\n", "", "self", ".", "num_class", "=", "num_class", "\n", "self", ".", "num_frames", "=", "num_frames", "\n", "num_bottleneck", "=", "256", "\n", "self", ".", "fc_fusion_scales", "=", "nn", ".", "ModuleList", "(", ")", "# high-tech modulelist", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "scales", ")", ")", ":", "\n", "            ", "scale", "=", "self", ".", "scales", "[", "i", "]", "\n", "fc_fusion", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "scale", "*", "self", ".", "img_feature_dim", ",", "num_bottleneck", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "num_bottleneck", ",", "self", ".", "num_class", ")", ",", "\n", ")", "\n", "self", ".", "fc_fusion_scales", "+=", "[", "fc_fusion", "]", "\n", "\n", "", "msg", "=", "'Multi-Scale Temporal Relation Network Module in use'", "\n", "print", "(", "msg", ",", "[", "'%d-frame relation'", "%", "i", "for", "i", "in", "self", ".", "scales", "]", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# the first one is the largest scale", "\n", "        ", "act_all", "=", "input", "[", ":", ",", "self", ".", "relations_scales", "[", "0", "]", "[", "0", "]", ",", ":", "]", "\n", "act_all", "=", "act_all", ".", "view", "(", "act_all", ".", "size", "(", "0", ")", ",", "self", ".", "scales", "[", "0", "]", "*", "self", ".", "img_feature_dim", ")", "\n", "act_all", "=", "self", ".", "fc_fusion_scales", "[", "0", "]", "(", "act_all", ")", "\n", "\n", "for", "scaleID", "in", "range", "(", "1", ",", "len", "(", "self", ".", "scales", ")", ")", ":", "\n", "# iterate over the scales", "\n", "            ", "idx_relations_randomsample", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "self", ".", "relations_scales", "[", "scaleID", "]", ")", ",", "\n", "self", ".", "subsample_scales", "[", "scaleID", "]", ",", "\n", "replace", "=", "False", ",", "\n", ")", "\n", "for", "idx", "in", "idx_relations_randomsample", ":", "\n", "                ", "act_relation", "=", "input", "[", ":", ",", "self", ".", "relations_scales", "[", "scaleID", "]", "[", "idx", "]", ",", ":", "]", "\n", "act_relation", "=", "act_relation", ".", "view", "(", "act_relation", ".", "size", "(", "0", ")", ",", "self", ".", "scales", "[", "scaleID", "]", "*", "self", ".", "img_feature_dim", ")", "\n", "act_relation", "=", "self", ".", "fc_fusion_scales", "[", "scaleID", "]", "(", "act_relation", ")", "\n", "act_all", "+=", "act_relation", "\n", "", "", "return", "act_all", "\n", "\n", "", "def", "return_relationset", "(", "self", ",", "num_frames", ",", "num_frames_relation", ")", ":", "\n", "        ", "import", "itertools", "\n", "return", "list", "(", "itertools", ".", "combinations", "(", "[", "i", "for", "i", "in", "range", "(", "num_frames", ")", "]", ",", "num_frames_relation", ")", ")", "\n", "\n", "\n", "", "", "class", "RelationModuleMultiScale_Cat", "(", "th", ".", "nn", ".", "Module", ")", ":", "\n", "# Temporal Relation module in multiply scale, suming over [2-frame relation, 3-frame relation, ..., n-frame relation]", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "img_feature_dim", ",", "num_frames", ",", "num_class", ")", ":", "\n", "        ", "super", "(", "RelationModuleMultiScale_Cat", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "subsample_num", "=", "3", "# how many relations selected to sum up", "\n", "self", ".", "img_feature_dim", "=", "img_feature_dim", "\n", "self", ".", "scales", "=", "[", "i", "for", "i", "in", "range", "(", "num_frames", ",", "1", ",", "-", "1", ")", "]", "# generate the multiple frame relations", "\n", "\n", "self", ".", "relations_scales", "=", "[", "]", "\n", "self", ".", "subsample_scales", "=", "[", "]", "\n", "for", "scale", "in", "self", ".", "scales", ":", "\n", "            ", "relations_scale", "=", "self", ".", "return_relationset", "(", "num_frames", ",", "scale", ")", "\n", "self", ".", "relations_scales", ".", "append", "(", "relations_scale", ")", "\n", "self", ".", "subsample_scales", ".", "append", "(", "min", "(", "self", ".", "subsample_num", ",", "len", "(", "relations_scale", ")", ")", ")", "# how many samples of relation to select in each forward pass", "\n", "\n", "", "self", ".", "num_class", "=", "num_class", "\n", "self", ".", "num_frames", "=", "num_frames", "\n", "num_bottleneck", "=", "256", "\n", "self", ".", "fc_fusion_scales", "=", "nn", ".", "ModuleList", "(", ")", "# high-tech modulelist", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "scales", ")", ")", ":", "\n", "            ", "scale", "=", "self", ".", "scales", "[", "i", "]", "\n", "fc_fusion", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "scale", "*", "self", ".", "img_feature_dim", ",", "num_bottleneck", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "num_bottleneck", ",", "self", ".", "num_class", ")", ",", "\n", ")", "\n", "\n", "self", ".", "fc_fusion_scales", "+=", "[", "fc_fusion", "]", "\n", "\n", "", "print", "(", "'Multi-Scale Temporal Relation Network Module in use'", ",", "[", "'%d-frame relation'", "%", "i", "for", "i", "in", "self", ".", "scales", "]", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "record", "=", "[", "]", "\n", "# the first one is the largest scale", "\n", "act_all", "=", "input", "[", ":", ",", "self", ".", "relations_scales", "[", "0", "]", "[", "0", "]", ",", ":", "]", "\n", "act_all", "=", "act_all", ".", "view", "(", "act_all", ".", "size", "(", "0", ")", ",", "self", ".", "scales", "[", "0", "]", "*", "self", ".", "img_feature_dim", ")", "\n", "act_all", "=", "self", ".", "fc_fusion_scales", "[", "0", "]", "(", "act_all", ")", "\n", "norm", "=", "act_all", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "act_all", "=", "act_all", ".", "div", "(", "norm", ")", "\n", "record", ".", "append", "(", "act_all", ")", "\n", "\n", "for", "scaleID", "in", "range", "(", "1", ",", "len", "(", "self", ".", "scales", ")", ")", ":", "\n", "# iterate over the scales", "\n", "            ", "idx_relations_randomsample", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "relations_scales", "[", "scaleID", "]", ")", ",", "self", ".", "subsample_scales", "[", "scaleID", "]", ",", "replace", "=", "False", ")", "\n", "act_all", "=", "0", "\n", "for", "idx", "in", "idx_relations_randomsample", ":", "\n", "                ", "act_relation", "=", "input", "[", ":", ",", "self", ".", "relations_scales", "[", "scaleID", "]", "[", "idx", "]", ",", ":", "]", "\n", "act_relation", "=", "act_relation", ".", "view", "(", "act_relation", ".", "size", "(", "0", ")", ",", "self", ".", "scales", "[", "scaleID", "]", "*", "self", ".", "img_feature_dim", ")", "\n", "act_relation", "=", "self", ".", "fc_fusion_scales", "[", "scaleID", "]", "(", "act_relation", ")", "\n", "act_all", "+=", "act_relation", "\n", "", "norm", "=", "act_all", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "act_all", "=", "act_all", ".", "div", "(", "norm", ")", "\n", "record", ".", "append", "(", "act_all", ")", "\n", "\n", "", "act_all", "=", "th", ".", "cat", "(", "(", "record", ")", ",", "1", ")", "\n", "return", "act_all", "\n", "\n", "", "def", "return_relationset", "(", "self", ",", "num_frames", ",", "num_frames_relation", ")", ":", "\n", "        ", "import", "itertools", "\n", "return", "list", "(", "itertools", ".", "combinations", "(", "[", "i", "for", "i", "in", "range", "(", "num_frames", ")", "]", ",", "\n", "num_frames_relation", ")", ")", "\n", "\n", "\n", "", "", "class", "CEModule", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "expert_dims", ",", "text_dim", ",", "use_ce", ",", "verbose", ",", "l2renorm", ",", "num_classes", ",", "\n", "trn_config", ",", "trn_cat", ",", "use_mish", ",", "include_self", ",", "num_h_layers", ",", "num_g_layers", ",", "\n", "disable_nan_checks", ",", "random_feats", ",", "test_caption_mode", ",", "mimic_ce_dims", ",", "\n", "concat_experts", ",", "concat_mix_experts", ",", "freeze_weights", ",", "task", ",", "\n", "keep_missing_modalities", ",", "vlad_feat_sizes", ",", "same_dim", ",", "use_bn_reason", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "modalities", "=", "list", "(", "expert_dims", ".", "keys", "(", ")", ")", "\n", "self", ".", "expert_dims", "=", "expert_dims", "\n", "self", ".", "modalities", "=", "modalities", "\n", "self", ".", "disable_nan_checks", "=", "disable_nan_checks", "\n", "self", ".", "mimic_ce_dims", "=", "mimic_ce_dims", "\n", "self", ".", "concat_experts", "=", "concat_experts", "\n", "self", ".", "same_dim", "=", "same_dim", "\n", "self", ".", "use_mish", "=", "use_mish", "\n", "self", ".", "use_bn_reason", "=", "use_bn_reason", "\n", "self", ".", "num_h_layers", "=", "num_h_layers", "\n", "self", ".", "num_g_layers", "=", "num_g_layers", "\n", "self", ".", "include_self", "=", "include_self", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "vlad_feat_sizes", "=", "vlad_feat_sizes", "\n", "self", ".", "concat_mix_experts", "=", "concat_mix_experts", "\n", "self", ".", "test_caption_mode", "=", "test_caption_mode", "\n", "self", ".", "reduce_dim", "=", "64", "\n", "self", ".", "moe_cg", "=", "ContextGating", "\n", "self", ".", "freeze_weights", "=", "freeze_weights", "\n", "self", ".", "random_feats", "=", "random_feats", "\n", "self", ".", "use_ce", "=", "use_ce", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "keep_missing_modalities", "=", "keep_missing_modalities", "\n", "self", ".", "l2renorm", "=", "l2renorm", "\n", "self", ".", "trn_config", "=", "trn_config", "\n", "self", ".", "trn_cat", "=", "trn_cat", "\n", "print", "(", "\"trn_config is {}\"", ".", "format", "(", "self", ".", "trn_config", ")", ")", "\n", "\n", "if", "self", ".", "use_mish", ":", "\n", "            ", "self", ".", "non_lin", "=", "Mish", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "non_lin", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "", "if", "\"retrieval\"", "in", "self", ".", "task", ":", "\n", "            ", "num_mods", "=", "len", "(", "expert_dims", ")", "\n", "self", ".", "moe_fc", "=", "nn", ".", "Linear", "(", "text_dim", ",", "len", "(", "expert_dims", ")", ")", "\n", "# self.moe_fc_bottleneck1 = nn.Linear(text_dim, text_dim // 4)", "\n", "# self.moe_cg = nn.Linear(text_dim // 4, text_dim // 4)", "\n", "# self.moe_fc_proj = nn.Linear(text_dim // 4, len(expert_dims))", "\n", "self", ".", "moe_weights", "=", "th", ".", "ones", "(", "1", ",", "num_mods", ")", "/", "num_mods", "\n", "\n", "# The batch size of the face input can vary (due to missing inputs), so we", "\n", "# probably shouldn't use BN on this branch. It's probably fine to leave it", "\n", "# n for the corresponding text inputs, (but we should switch to GN)", "\n", "", "use_bns", "=", "[", "True", "for", "modality", "in", "self", ".", "modalities", "]", "\n", "\n", "# NOTE: When use_ce is not used, the text features are projected to", "\n", "# subspaces of different dimensions.  When use_ce is used, they must all", "\n", "# be projected to `same_dim` (to allow fusion). The only excpetion is for an", "\n", "# ablation in which we mimic the `same_dim` reduction to measure whether this", "\n", "# projection influences overall performance.", "\n", "self", ".", "trn_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "self", ".", "repeat_temporal", "=", "{", "}", "\n", "for", "mod", "in", "modalities", ":", "\n", "            ", "self", ".", "repeat_temporal", "[", "mod", "]", "=", "1", "\n", "\n", "", "if", "self", ".", "trn_cat", "==", "2", ":", "\n", "            ", "print", "(", "\"Performing concat between random temporal attention\"", ")", "\n", "for", "mod", "in", "self", ".", "trn_config", ".", "keys", "(", ")", ":", "\n", "                ", "img_feature_dim", "=", "expert_dims", "[", "mod", "]", "[", "0", "]", "# 365", "\n", "num_frames", "=", "self", ".", "trn_config", "[", "\n", "mod", "]", "# This is exatcly how many different attention", "\n", "num_frames", "=", "1", "# mimic simple avg and max based on segments", "\n", "# num_class = expert_dims[mod][0]", "\n", "self", ".", "trn_list", "+=", "[", "TemporalAttention", "(", "img_feature_dim", ",", "num_frames", ")", "]", "\n", "self", ".", "repeat_temporal", "[", "mod", "]", "=", "num_frames", "+", "2", "\n", "", "", "elif", "self", ".", "trn_cat", "==", "1", ":", "\n", "            ", "print", "(", "\"Performing concat between segments\"", ")", "\n", "for", "mod", "in", "self", ".", "trn_config", ".", "keys", "(", ")", ":", "\n", "                ", "img_feature_dim", "=", "expert_dims", "[", "mod", "]", "[", "0", "]", "# 365", "\n", "num_frames", "=", "self", ".", "trn_config", "[", "mod", "]", "# hard code", "\n", "num_class", "=", "expert_dims", "[", "mod", "]", "[", "0", "]", "\n", "self", ".", "trn_list", "+=", "[", "\n", "RelationModuleMultiScale_Cat", "(", "img_feature_dim", ",", "num_frames", ",", "num_class", ")", "\n", "]", "\n", "self", ".", "repeat_temporal", "[", "mod", "]", "=", "len", "(", "\n", "[", "i", "for", "i", "in", "range", "(", "num_frames", ",", "1", ",", "-", "1", ")", "]", ")", "\n", "", "", "elif", "self", ".", "trn_cat", "==", "0", ":", "\n", "            ", "print", "(", "\"Performing Conventional TRN (sum) segments\"", ")", "\n", "for", "mod", "in", "self", ".", "trn_config", ".", "keys", "(", ")", ":", "\n", "                ", "img_feature_dim", "=", "expert_dims", "[", "mod", "]", "[", "0", "]", "# 365", "\n", "num_frames", "=", "self", ".", "trn_config", "[", "mod", "]", "# hard code", "\n", "num_class", "=", "expert_dims", "[", "mod", "]", "[", "0", "]", "\n", "self", ".", "trn_list", "+=", "[", "\n", "RelationModuleMultiScale", "(", "img_feature_dim", ",", "num_frames", ",", "\n", "num_class", ")", "\n", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "in_dims", "=", "[", "expert_dims", "[", "mod", "]", "[", "0", "]", "*", "self", ".", "repeat_temporal", "[", "mod", "]", "for", "mod", "in", "modalities", "]", "\n", "agg_dims", "=", "[", "expert_dims", "[", "mod", "]", "[", "1", "]", "*", "self", ".", "repeat_temporal", "[", "mod", "]", "for", "mod", "in", "modalities", "]", "\n", "\n", "if", "self", ".", "use_ce", "or", "self", ".", "mimic_ce_dims", ":", "\n", "            ", "dim_reducers", "=", "[", "ReduceDim", "(", "in_dim", ",", "same_dim", ")", "for", "in_dim", "in", "in_dims", "]", "\n", "self", ".", "video_dim_reduce", "=", "nn", ".", "ModuleList", "(", "dim_reducers", ")", "\n", "", "if", "self", ".", "use_ce", ":", "\n", "# The g_reason module has a first layer that is specific to the design choice", "\n", "# (e.g. triplet vs pairwise), then a shared component which is common to all", "\n", "# designs.", "\n", "            ", "if", "self", ".", "use_ce", "in", "{", "\"pairwise\"", ",", "\"pairwise-star\"", ",", "\"triplet\"", "}", ":", "\n", "                ", "num_inputs", "=", "3", "if", "self", ".", "use_ce", "==", "\"triplet\"", "else", "2", "\n", "self", ".", "g_reason_1", "=", "nn", ".", "Linear", "(", "same_dim", "*", "num_inputs", ",", "same_dim", ")", "\n", "", "elif", "self", ".", "use_ce", "==", "\"pairwise-star-specific\"", ":", "\n", "                ", "num_inputs", "=", "2", "\n", "g_reason_unshared_weights", "=", "[", "G_reason", "(", "same_dim", ",", "num_inputs", ",", "self", ".", "non_lin", ")", "\n", "for", "mod", "in", "modalities", "]", "\n", "self", ".", "g_reason_unshared_weights", "=", "nn", ".", "ModuleList", "(", "g_reason_unshared_weights", ")", "\n", "", "elif", "self", ".", "use_ce", "in", "{", "\"pairwise-star-tensor\"", "}", ":", "\n", "                ", "reduce_dim", "=", "self", ".", "reduce_dim", "\n", "self", ".", "dim_reduce", "=", "nn", ".", "Linear", "(", "same_dim", ",", "reduce_dim", ")", "\n", "self", ".", "g_reason_1", "=", "nn", ".", "Linear", "(", "self", ".", "reduce_dim", "*", "reduce_dim", ",", "same_dim", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"unrecognised CE config: {self.use_ce}\"", ")", "\n", "\n", "", "g_reason_shared", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "num_g_layers", "-", "1", ")", ":", "\n", "                ", "if", "self", ".", "use_bn_reason", ":", "\n", "                    ", "g_reason_shared", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "same_dim", ")", ")", "\n", "", "g_reason_shared", ".", "append", "(", "self", ".", "non_lin", ")", "\n", "g_reason_shared", ".", "append", "(", "nn", ".", "Linear", "(", "same_dim", ",", "same_dim", ")", ")", "\n", "", "self", ".", "g_reason_shared", "=", "nn", ".", "Sequential", "(", "*", "g_reason_shared", ")", "\n", "\n", "h_reason", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "num_h_layers", ")", ":", "\n", "                ", "if", "self", ".", "use_bn_reason", ":", "\n", "                    ", "h_reason", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "same_dim", ")", ")", "\n", "", "h_reason", ".", "append", "(", "self", ".", "non_lin", ")", "\n", "h_reason", ".", "append", "(", "nn", ".", "Linear", "(", "same_dim", ",", "same_dim", ")", ")", "\n", "", "self", ".", "h_reason", "=", "nn", ".", "Sequential", "(", "*", "h_reason", ")", "\n", "\n", "gated_vid_embds", "=", "[", "GatedEmbeddingUnitReasoning", "(", "same_dim", ")", "for", "_", "in", "in_dims", "]", "\n", "text_out_dims", "=", "[", "same_dim", "for", "_", "in", "agg_dims", "]", "\n", "", "elif", "self", ".", "mimic_ce_dims", ":", "# ablation study", "\n", "            ", "gated_vid_embds", "=", "[", "MimicCEGatedEmbeddingUnit", "(", "same_dim", ",", "same_dim", ",", "use_bn", "=", "True", ")", "\n", "for", "_", "in", "modalities", "]", "\n", "text_out_dims", "=", "[", "same_dim", "for", "_", "in", "agg_dims", "]", "\n", "", "elif", "self", ".", "concat_mix_experts", ":", "# ablation study", "\n", "# use a single large GEU to mix the experts - the output will be the sum", "\n", "# of the aggregation sizes", "\n", "            ", "in_dim", ",", "out_dim", "=", "sum", "(", "in_dims", ")", ",", "sum", "(", "agg_dims", ")", "\n", "gated_vid_embds", "=", "[", "GatedEmbeddingUnit", "(", "in_dim", ",", "out_dim", ",", "use_bn", "=", "True", ")", "]", "\n", "", "elif", "self", ".", "concat_experts", ":", "# ablation study", "\n", "# We do not use learnable parameters for the video combination, (we simply", "\n", "# use a high dimensional inner product).", "\n", "            ", "gated_vid_embds", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "gated_vid_embds", "=", "[", "GatedEmbeddingUnit", "(", "in_dim", ",", "dim", ",", "use_bn", ")", "for", "\n", "in_dim", ",", "dim", ",", "use_bn", "in", "zip", "(", "in_dims", ",", "agg_dims", ",", "use_bns", ")", "]", "\n", "text_out_dims", "=", "agg_dims", "\n", "", "self", ".", "video_GU", "=", "nn", ".", "ModuleList", "(", "gated_vid_embds", ")", "\n", "\n", "if", "\"retrieval\"", "in", "self", ".", "task", ":", "\n", "            ", "if", "self", ".", "concat_experts", ":", "\n", "                ", "gated_text_embds", "=", "[", "nn", ".", "Sequential", "(", ")", "]", "\n", "", "elif", "self", ".", "concat_mix_experts", ":", "\n", "# As with the video inputs, we similiarly use a single large GEU for the", "\n", "# text embedding", "\n", "                ", "gated_text_embds", "=", "[", "GatedEmbeddingUnit", "(", "text_dim", ",", "sum", "(", "agg_dims", ")", ",", "\n", "use_bn", "=", "True", ")", "]", "\n", "", "else", ":", "\n", "                ", "gated_text_embds", "=", "[", "GatedEmbeddingUnit", "(", "text_dim", ",", "dim", ",", "use_bn", "=", "True", ")", "for", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.TemporalAttention.__init__": [[338, 345], ["super().__init__", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "img_feature_dim", ",", "num_attention", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "Variable", "(", "\n", "th", ".", "randn", "(", "img_feature_dim", ",", "num_attention", ")", ",", "\n", "requires_grad", "=", "True", ")", ".", "cuda", "(", ")", "# d*seg", "\n", "self", ".", "img_feature_dim", "=", "img_feature_dim", "\n", "self", ".", "num_attention", "=", "num_attention", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.TemporalAttention.forward": [[346, 363], ["torch.mean", "torch.mean", "torch.mean", "torch.max", "torch.max", "torch.max", "record.append", "record.append", "torch.matmul", "torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.softmax", "range", "torch.cat", "torch.cat", "torch.cat", "input.clone", "input.clone", "torch.sum", "torch.sum", "torch.sum", "temp_output.div.div.norm", "temp_output.div.div.div", "record.append", "temp.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "B", ",", "T", ",", "D", "=", "input", ".", "shape", "\n", "record", "=", "[", "]", "\n", "input_avg", "=", "th", ".", "mean", "(", "input", ".", "clone", "(", ")", ",", "dim", "=", "1", ")", "\n", "input_max", "=", "th", ".", "max", "(", "input", ".", "clone", "(", ")", ",", "dim", "=", "1", ")", "\n", "record", ".", "append", "(", "input_avg", ")", "\n", "record", ".", "append", "(", "input_max", "[", "0", "]", ")", "\n", "output", "=", "th", ".", "matmul", "(", "input", ",", "self", ".", "weight", ")", "\n", "attentions", "=", "F", ".", "softmax", "(", "output", ",", "dim", "=", "1", ")", "\n", "for", "idx", "in", "range", "(", "attentions", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "            ", "temp", "=", "attentions", "[", ":", ",", ":", ",", "idx", "]", "\n", "temp_output", "=", "th", ".", "sum", "(", "temp", ".", "unsqueeze", "(", "2", ")", "*", "input", ",", "dim", "=", "1", ")", "\n", "norm", "=", "temp_output", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "temp_output", "=", "temp_output", ".", "div", "(", "norm", ")", "\n", "record", ".", "append", "(", "temp_output", ")", "\n", "", "act_all", "=", "th", ".", "cat", "(", "(", "record", ")", ",", "1", ")", "\n", "return", "act_all", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.RelationModuleMultiScale.__init__": [[368, 399], ["super().__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "print", "model.RelationModuleMultiScale.return_relationset", "model.RelationModuleMultiScale.relations_scales.append", "model.RelationModuleMultiScale.subsample_scales.append", "len", "torch.Sequential", "torch.Sequential", "torch.Sequential", "range", "min", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "len"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.RelationModuleMultiScale_Cat.return_relationset"], ["    ", "def", "__init__", "(", "self", ",", "img_feature_dim", ",", "num_frames", ",", "num_class", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "subsample_num", "=", "3", "# how many relations selected to sum up", "\n", "self", ".", "img_feature_dim", "=", "img_feature_dim", "\n", "# generate the multiple frame relations", "\n", "self", ".", "scales", "=", "[", "i", "for", "i", "in", "range", "(", "num_frames", ",", "1", ",", "-", "1", ")", "]", "\n", "\n", "self", ".", "relations_scales", "=", "[", "]", "\n", "self", ".", "subsample_scales", "=", "[", "]", "\n", "for", "scale", "in", "self", ".", "scales", ":", "\n", "            ", "relations_scale", "=", "self", ".", "return_relationset", "(", "num_frames", ",", "scale", ")", "\n", "self", ".", "relations_scales", ".", "append", "(", "relations_scale", ")", "\n", "# how many samples of relation to select in each forward pass", "\n", "self", ".", "subsample_scales", ".", "append", "(", "min", "(", "self", ".", "subsample_num", ",", "len", "(", "relations_scale", ")", ")", ")", "\n", "\n", "", "self", ".", "num_class", "=", "num_class", "\n", "self", ".", "num_frames", "=", "num_frames", "\n", "num_bottleneck", "=", "256", "\n", "self", ".", "fc_fusion_scales", "=", "nn", ".", "ModuleList", "(", ")", "# high-tech modulelist", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "scales", ")", ")", ":", "\n", "            ", "scale", "=", "self", ".", "scales", "[", "i", "]", "\n", "fc_fusion", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "scale", "*", "self", ".", "img_feature_dim", ",", "num_bottleneck", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "num_bottleneck", ",", "self", ".", "num_class", ")", ",", "\n", ")", "\n", "self", ".", "fc_fusion_scales", "+=", "[", "fc_fusion", "]", "\n", "\n", "", "msg", "=", "'Multi-Scale Temporal Relation Network Module in use'", "\n", "print", "(", "msg", ",", "[", "'%d-frame relation'", "%", "i", "for", "i", "in", "self", ".", "scales", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.RelationModuleMultiScale.forward": [[400, 419], ["act_all.view.view.view", "range", "act_all.view.view.size", "len", "numpy.random.choice", "len", "act_relation.view.view.view", "act_relation.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# the first one is the largest scale", "\n", "        ", "act_all", "=", "input", "[", ":", ",", "self", ".", "relations_scales", "[", "0", "]", "[", "0", "]", ",", ":", "]", "\n", "act_all", "=", "act_all", ".", "view", "(", "act_all", ".", "size", "(", "0", ")", ",", "self", ".", "scales", "[", "0", "]", "*", "self", ".", "img_feature_dim", ")", "\n", "act_all", "=", "self", ".", "fc_fusion_scales", "[", "0", "]", "(", "act_all", ")", "\n", "\n", "for", "scaleID", "in", "range", "(", "1", ",", "len", "(", "self", ".", "scales", ")", ")", ":", "\n", "# iterate over the scales", "\n", "            ", "idx_relations_randomsample", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "self", ".", "relations_scales", "[", "scaleID", "]", ")", ",", "\n", "self", ".", "subsample_scales", "[", "scaleID", "]", ",", "\n", "replace", "=", "False", ",", "\n", ")", "\n", "for", "idx", "in", "idx_relations_randomsample", ":", "\n", "                ", "act_relation", "=", "input", "[", ":", ",", "self", ".", "relations_scales", "[", "scaleID", "]", "[", "idx", "]", ",", ":", "]", "\n", "act_relation", "=", "act_relation", ".", "view", "(", "act_relation", ".", "size", "(", "0", ")", ",", "self", ".", "scales", "[", "scaleID", "]", "*", "self", ".", "img_feature_dim", ")", "\n", "act_relation", "=", "self", ".", "fc_fusion_scales", "[", "scaleID", "]", "(", "act_relation", ")", "\n", "act_all", "+=", "act_relation", "\n", "", "", "return", "act_all", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.RelationModuleMultiScale.return_relationset": [[420, 423], ["list", "itertools.combinations", "range"], "methods", ["None"], ["", "def", "return_relationset", "(", "self", ",", "num_frames", ",", "num_frames_relation", ")", ":", "\n", "        ", "import", "itertools", "\n", "return", "list", "(", "itertools", ".", "combinations", "(", "[", "i", "for", "i", "in", "range", "(", "num_frames", ")", "]", ",", "num_frames_relation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.RelationModuleMultiScale_Cat.__init__": [[428, 457], ["super().__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "print", "model.RelationModuleMultiScale_Cat.return_relationset", "model.RelationModuleMultiScale_Cat.relations_scales.append", "model.RelationModuleMultiScale_Cat.subsample_scales.append", "len", "torch.Sequential", "torch.Sequential", "torch.Sequential", "range", "min", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "len"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.RelationModuleMultiScale_Cat.return_relationset"], ["    ", "def", "__init__", "(", "self", ",", "img_feature_dim", ",", "num_frames", ",", "num_class", ")", ":", "\n", "        ", "super", "(", "RelationModuleMultiScale_Cat", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "subsample_num", "=", "3", "# how many relations selected to sum up", "\n", "self", ".", "img_feature_dim", "=", "img_feature_dim", "\n", "self", ".", "scales", "=", "[", "i", "for", "i", "in", "range", "(", "num_frames", ",", "1", ",", "-", "1", ")", "]", "# generate the multiple frame relations", "\n", "\n", "self", ".", "relations_scales", "=", "[", "]", "\n", "self", ".", "subsample_scales", "=", "[", "]", "\n", "for", "scale", "in", "self", ".", "scales", ":", "\n", "            ", "relations_scale", "=", "self", ".", "return_relationset", "(", "num_frames", ",", "scale", ")", "\n", "self", ".", "relations_scales", ".", "append", "(", "relations_scale", ")", "\n", "self", ".", "subsample_scales", ".", "append", "(", "min", "(", "self", ".", "subsample_num", ",", "len", "(", "relations_scale", ")", ")", ")", "# how many samples of relation to select in each forward pass", "\n", "\n", "", "self", ".", "num_class", "=", "num_class", "\n", "self", ".", "num_frames", "=", "num_frames", "\n", "num_bottleneck", "=", "256", "\n", "self", ".", "fc_fusion_scales", "=", "nn", ".", "ModuleList", "(", ")", "# high-tech modulelist", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "scales", ")", ")", ":", "\n", "            ", "scale", "=", "self", ".", "scales", "[", "i", "]", "\n", "fc_fusion", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "scale", "*", "self", ".", "img_feature_dim", ",", "num_bottleneck", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "num_bottleneck", ",", "self", ".", "num_class", ")", ",", "\n", ")", "\n", "\n", "self", ".", "fc_fusion_scales", "+=", "[", "fc_fusion", "]", "\n", "\n", "", "print", "(", "'Multi-Scale Temporal Relation Network Module in use'", ",", "[", "'%d-frame relation'", "%", "i", "for", "i", "in", "self", ".", "scales", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.RelationModuleMultiScale_Cat.forward": [[458, 483], ["act_all.div.div.view", "act_all.div.div.norm", "act_all.div.div.div", "record.append", "range", "torch.cat", "torch.cat", "torch.cat", "act_all.div.div.size", "len", "numpy.random.choice", "act_all.div.div.norm", "act_all.div.div.div", "record.append", "len", "act_relation.view.view.view", "act_relation.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "record", "=", "[", "]", "\n", "# the first one is the largest scale", "\n", "act_all", "=", "input", "[", ":", ",", "self", ".", "relations_scales", "[", "0", "]", "[", "0", "]", ",", ":", "]", "\n", "act_all", "=", "act_all", ".", "view", "(", "act_all", ".", "size", "(", "0", ")", ",", "self", ".", "scales", "[", "0", "]", "*", "self", ".", "img_feature_dim", ")", "\n", "act_all", "=", "self", ".", "fc_fusion_scales", "[", "0", "]", "(", "act_all", ")", "\n", "norm", "=", "act_all", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "act_all", "=", "act_all", ".", "div", "(", "norm", ")", "\n", "record", ".", "append", "(", "act_all", ")", "\n", "\n", "for", "scaleID", "in", "range", "(", "1", ",", "len", "(", "self", ".", "scales", ")", ")", ":", "\n", "# iterate over the scales", "\n", "            ", "idx_relations_randomsample", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "relations_scales", "[", "scaleID", "]", ")", ",", "self", ".", "subsample_scales", "[", "scaleID", "]", ",", "replace", "=", "False", ")", "\n", "act_all", "=", "0", "\n", "for", "idx", "in", "idx_relations_randomsample", ":", "\n", "                ", "act_relation", "=", "input", "[", ":", ",", "self", ".", "relations_scales", "[", "scaleID", "]", "[", "idx", "]", ",", ":", "]", "\n", "act_relation", "=", "act_relation", ".", "view", "(", "act_relation", ".", "size", "(", "0", ")", ",", "self", ".", "scales", "[", "scaleID", "]", "*", "self", ".", "img_feature_dim", ")", "\n", "act_relation", "=", "self", ".", "fc_fusion_scales", "[", "scaleID", "]", "(", "act_relation", ")", "\n", "act_all", "+=", "act_relation", "\n", "", "norm", "=", "act_all", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "act_all", "=", "act_all", ".", "div", "(", "norm", ")", "\n", "record", ".", "append", "(", "act_all", ")", "\n", "\n", "", "act_all", "=", "th", ".", "cat", "(", "(", "record", ")", ",", "1", ")", "\n", "return", "act_all", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.RelationModuleMultiScale_Cat.return_relationset": [[484, 488], ["list", "itertools.combinations", "range"], "methods", ["None"], ["", "def", "return_relationset", "(", "self", ",", "num_frames", ",", "num_frames_relation", ")", ":", "\n", "        ", "import", "itertools", "\n", "return", "list", "(", "itertools", ".", "combinations", "(", "[", "i", "for", "i", "in", "range", "(", "num_frames", ")", "]", ",", "\n", "num_frames_relation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CEModule.__init__": [[491, 671], ["torch.Module.__init__", "list", "print", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "expert_dims.keys", "model.Mish", "torch.ReLU", "torch.ReLU", "torch.ReLU", "len", "torch.Linear", "torch.Linear", "torch.Linear", "print", "model.CEModule.trn_config.keys", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "print", "model.CEModule.expert_dims.keys", "print", "torch.Linear", "torch.Linear", "torch.Linear", "len", "torch.ones", "torch.ones", "torch.ones", "print", "model.CEModule.trn_config.keys", "model.ReduceDim", "torch.Linear", "torch.Linear", "torch.Linear", "g_reason_shared.append", "g_reason_shared.append", "h_reason.append", "h_reason.append", "model.GatedEmbeddingUnitReasoning", "model.TemporalAttention", "len", "print", "model.CEModule.trn_config.keys", "NotImplementedError", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "g_reason_shared.append", "torch.Linear", "torch.Linear", "torch.Linear", "h_reason.append", "torch.Linear", "torch.Linear", "torch.Linear", "model.MimicCEGatedEmbeddingUnit", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model.RelationModuleMultiScale_Cat", "model.G_reason", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "ValueError", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "sum", "sum", "model.GatedEmbeddingUnit", "model.GatedEmbeddingUnit", "model.GatedEmbeddingUnit", "model.RelationModuleMultiScale", "model.GatedEmbeddingUnit", "sum", "range", "zip"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["    ", "def", "__init__", "(", "self", ",", "expert_dims", ",", "text_dim", ",", "use_ce", ",", "verbose", ",", "l2renorm", ",", "num_classes", ",", "\n", "trn_config", ",", "trn_cat", ",", "use_mish", ",", "include_self", ",", "num_h_layers", ",", "num_g_layers", ",", "\n", "disable_nan_checks", ",", "random_feats", ",", "test_caption_mode", ",", "mimic_ce_dims", ",", "\n", "concat_experts", ",", "concat_mix_experts", ",", "freeze_weights", ",", "task", ",", "\n", "keep_missing_modalities", ",", "vlad_feat_sizes", ",", "same_dim", ",", "use_bn_reason", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "modalities", "=", "list", "(", "expert_dims", ".", "keys", "(", ")", ")", "\n", "self", ".", "expert_dims", "=", "expert_dims", "\n", "self", ".", "modalities", "=", "modalities", "\n", "self", ".", "disable_nan_checks", "=", "disable_nan_checks", "\n", "self", ".", "mimic_ce_dims", "=", "mimic_ce_dims", "\n", "self", ".", "concat_experts", "=", "concat_experts", "\n", "self", ".", "same_dim", "=", "same_dim", "\n", "self", ".", "use_mish", "=", "use_mish", "\n", "self", ".", "use_bn_reason", "=", "use_bn_reason", "\n", "self", ".", "num_h_layers", "=", "num_h_layers", "\n", "self", ".", "num_g_layers", "=", "num_g_layers", "\n", "self", ".", "include_self", "=", "include_self", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "vlad_feat_sizes", "=", "vlad_feat_sizes", "\n", "self", ".", "concat_mix_experts", "=", "concat_mix_experts", "\n", "self", ".", "test_caption_mode", "=", "test_caption_mode", "\n", "self", ".", "reduce_dim", "=", "64", "\n", "self", ".", "moe_cg", "=", "ContextGating", "\n", "self", ".", "freeze_weights", "=", "freeze_weights", "\n", "self", ".", "random_feats", "=", "random_feats", "\n", "self", ".", "use_ce", "=", "use_ce", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "keep_missing_modalities", "=", "keep_missing_modalities", "\n", "self", ".", "l2renorm", "=", "l2renorm", "\n", "self", ".", "trn_config", "=", "trn_config", "\n", "self", ".", "trn_cat", "=", "trn_cat", "\n", "print", "(", "\"trn_config is {}\"", ".", "format", "(", "self", ".", "trn_config", ")", ")", "\n", "\n", "if", "self", ".", "use_mish", ":", "\n", "            ", "self", ".", "non_lin", "=", "Mish", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "non_lin", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "", "if", "\"retrieval\"", "in", "self", ".", "task", ":", "\n", "            ", "num_mods", "=", "len", "(", "expert_dims", ")", "\n", "self", ".", "moe_fc", "=", "nn", ".", "Linear", "(", "text_dim", ",", "len", "(", "expert_dims", ")", ")", "\n", "# self.moe_fc_bottleneck1 = nn.Linear(text_dim, text_dim // 4)", "\n", "# self.moe_cg = nn.Linear(text_dim // 4, text_dim // 4)", "\n", "# self.moe_fc_proj = nn.Linear(text_dim // 4, len(expert_dims))", "\n", "self", ".", "moe_weights", "=", "th", ".", "ones", "(", "1", ",", "num_mods", ")", "/", "num_mods", "\n", "\n", "# The batch size of the face input can vary (due to missing inputs), so we", "\n", "# probably shouldn't use BN on this branch. It's probably fine to leave it", "\n", "# n for the corresponding text inputs, (but we should switch to GN)", "\n", "", "use_bns", "=", "[", "True", "for", "modality", "in", "self", ".", "modalities", "]", "\n", "\n", "# NOTE: When use_ce is not used, the text features are projected to", "\n", "# subspaces of different dimensions.  When use_ce is used, they must all", "\n", "# be projected to `same_dim` (to allow fusion). The only excpetion is for an", "\n", "# ablation in which we mimic the `same_dim` reduction to measure whether this", "\n", "# projection influences overall performance.", "\n", "self", ".", "trn_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "self", ".", "repeat_temporal", "=", "{", "}", "\n", "for", "mod", "in", "modalities", ":", "\n", "            ", "self", ".", "repeat_temporal", "[", "mod", "]", "=", "1", "\n", "\n", "", "if", "self", ".", "trn_cat", "==", "2", ":", "\n", "            ", "print", "(", "\"Performing concat between random temporal attention\"", ")", "\n", "for", "mod", "in", "self", ".", "trn_config", ".", "keys", "(", ")", ":", "\n", "                ", "img_feature_dim", "=", "expert_dims", "[", "mod", "]", "[", "0", "]", "# 365", "\n", "num_frames", "=", "self", ".", "trn_config", "[", "\n", "mod", "]", "# This is exatcly how many different attention", "\n", "num_frames", "=", "1", "# mimic simple avg and max based on segments", "\n", "# num_class = expert_dims[mod][0]", "\n", "self", ".", "trn_list", "+=", "[", "TemporalAttention", "(", "img_feature_dim", ",", "num_frames", ")", "]", "\n", "self", ".", "repeat_temporal", "[", "mod", "]", "=", "num_frames", "+", "2", "\n", "", "", "elif", "self", ".", "trn_cat", "==", "1", ":", "\n", "            ", "print", "(", "\"Performing concat between segments\"", ")", "\n", "for", "mod", "in", "self", ".", "trn_config", ".", "keys", "(", ")", ":", "\n", "                ", "img_feature_dim", "=", "expert_dims", "[", "mod", "]", "[", "0", "]", "# 365", "\n", "num_frames", "=", "self", ".", "trn_config", "[", "mod", "]", "# hard code", "\n", "num_class", "=", "expert_dims", "[", "mod", "]", "[", "0", "]", "\n", "self", ".", "trn_list", "+=", "[", "\n", "RelationModuleMultiScale_Cat", "(", "img_feature_dim", ",", "num_frames", ",", "num_class", ")", "\n", "]", "\n", "self", ".", "repeat_temporal", "[", "mod", "]", "=", "len", "(", "\n", "[", "i", "for", "i", "in", "range", "(", "num_frames", ",", "1", ",", "-", "1", ")", "]", ")", "\n", "", "", "elif", "self", ".", "trn_cat", "==", "0", ":", "\n", "            ", "print", "(", "\"Performing Conventional TRN (sum) segments\"", ")", "\n", "for", "mod", "in", "self", ".", "trn_config", ".", "keys", "(", ")", ":", "\n", "                ", "img_feature_dim", "=", "expert_dims", "[", "mod", "]", "[", "0", "]", "# 365", "\n", "num_frames", "=", "self", ".", "trn_config", "[", "mod", "]", "# hard code", "\n", "num_class", "=", "expert_dims", "[", "mod", "]", "[", "0", "]", "\n", "self", ".", "trn_list", "+=", "[", "\n", "RelationModuleMultiScale", "(", "img_feature_dim", ",", "num_frames", ",", "\n", "num_class", ")", "\n", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "in_dims", "=", "[", "expert_dims", "[", "mod", "]", "[", "0", "]", "*", "self", ".", "repeat_temporal", "[", "mod", "]", "for", "mod", "in", "modalities", "]", "\n", "agg_dims", "=", "[", "expert_dims", "[", "mod", "]", "[", "1", "]", "*", "self", ".", "repeat_temporal", "[", "mod", "]", "for", "mod", "in", "modalities", "]", "\n", "\n", "if", "self", ".", "use_ce", "or", "self", ".", "mimic_ce_dims", ":", "\n", "            ", "dim_reducers", "=", "[", "ReduceDim", "(", "in_dim", ",", "same_dim", ")", "for", "in_dim", "in", "in_dims", "]", "\n", "self", ".", "video_dim_reduce", "=", "nn", ".", "ModuleList", "(", "dim_reducers", ")", "\n", "", "if", "self", ".", "use_ce", ":", "\n", "# The g_reason module has a first layer that is specific to the design choice", "\n", "# (e.g. triplet vs pairwise), then a shared component which is common to all", "\n", "# designs.", "\n", "            ", "if", "self", ".", "use_ce", "in", "{", "\"pairwise\"", ",", "\"pairwise-star\"", ",", "\"triplet\"", "}", ":", "\n", "                ", "num_inputs", "=", "3", "if", "self", ".", "use_ce", "==", "\"triplet\"", "else", "2", "\n", "self", ".", "g_reason_1", "=", "nn", ".", "Linear", "(", "same_dim", "*", "num_inputs", ",", "same_dim", ")", "\n", "", "elif", "self", ".", "use_ce", "==", "\"pairwise-star-specific\"", ":", "\n", "                ", "num_inputs", "=", "2", "\n", "g_reason_unshared_weights", "=", "[", "G_reason", "(", "same_dim", ",", "num_inputs", ",", "self", ".", "non_lin", ")", "\n", "for", "mod", "in", "modalities", "]", "\n", "self", ".", "g_reason_unshared_weights", "=", "nn", ".", "ModuleList", "(", "g_reason_unshared_weights", ")", "\n", "", "elif", "self", ".", "use_ce", "in", "{", "\"pairwise-star-tensor\"", "}", ":", "\n", "                ", "reduce_dim", "=", "self", ".", "reduce_dim", "\n", "self", ".", "dim_reduce", "=", "nn", ".", "Linear", "(", "same_dim", ",", "reduce_dim", ")", "\n", "self", ".", "g_reason_1", "=", "nn", ".", "Linear", "(", "self", ".", "reduce_dim", "*", "reduce_dim", ",", "same_dim", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"unrecognised CE config: {self.use_ce}\"", ")", "\n", "\n", "", "g_reason_shared", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "num_g_layers", "-", "1", ")", ":", "\n", "                ", "if", "self", ".", "use_bn_reason", ":", "\n", "                    ", "g_reason_shared", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "same_dim", ")", ")", "\n", "", "g_reason_shared", ".", "append", "(", "self", ".", "non_lin", ")", "\n", "g_reason_shared", ".", "append", "(", "nn", ".", "Linear", "(", "same_dim", ",", "same_dim", ")", ")", "\n", "", "self", ".", "g_reason_shared", "=", "nn", ".", "Sequential", "(", "*", "g_reason_shared", ")", "\n", "\n", "h_reason", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "num_h_layers", ")", ":", "\n", "                ", "if", "self", ".", "use_bn_reason", ":", "\n", "                    ", "h_reason", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "same_dim", ")", ")", "\n", "", "h_reason", ".", "append", "(", "self", ".", "non_lin", ")", "\n", "h_reason", ".", "append", "(", "nn", ".", "Linear", "(", "same_dim", ",", "same_dim", ")", ")", "\n", "", "self", ".", "h_reason", "=", "nn", ".", "Sequential", "(", "*", "h_reason", ")", "\n", "\n", "gated_vid_embds", "=", "[", "GatedEmbeddingUnitReasoning", "(", "same_dim", ")", "for", "_", "in", "in_dims", "]", "\n", "text_out_dims", "=", "[", "same_dim", "for", "_", "in", "agg_dims", "]", "\n", "", "elif", "self", ".", "mimic_ce_dims", ":", "# ablation study", "\n", "            ", "gated_vid_embds", "=", "[", "MimicCEGatedEmbeddingUnit", "(", "same_dim", ",", "same_dim", ",", "use_bn", "=", "True", ")", "\n", "for", "_", "in", "modalities", "]", "\n", "text_out_dims", "=", "[", "same_dim", "for", "_", "in", "agg_dims", "]", "\n", "", "elif", "self", ".", "concat_mix_experts", ":", "# ablation study", "\n", "# use a single large GEU to mix the experts - the output will be the sum", "\n", "# of the aggregation sizes", "\n", "            ", "in_dim", ",", "out_dim", "=", "sum", "(", "in_dims", ")", ",", "sum", "(", "agg_dims", ")", "\n", "gated_vid_embds", "=", "[", "GatedEmbeddingUnit", "(", "in_dim", ",", "out_dim", ",", "use_bn", "=", "True", ")", "]", "\n", "", "elif", "self", ".", "concat_experts", ":", "# ablation study", "\n", "# We do not use learnable parameters for the video combination, (we simply", "\n", "# use a high dimensional inner product).", "\n", "            ", "gated_vid_embds", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "gated_vid_embds", "=", "[", "GatedEmbeddingUnit", "(", "in_dim", ",", "dim", ",", "use_bn", ")", "for", "\n", "in_dim", ",", "dim", ",", "use_bn", "in", "zip", "(", "in_dims", ",", "agg_dims", ",", "use_bns", ")", "]", "\n", "text_out_dims", "=", "agg_dims", "\n", "", "self", ".", "video_GU", "=", "nn", ".", "ModuleList", "(", "gated_vid_embds", ")", "\n", "\n", "if", "\"retrieval\"", "in", "self", ".", "task", ":", "\n", "            ", "if", "self", ".", "concat_experts", ":", "\n", "                ", "gated_text_embds", "=", "[", "nn", ".", "Sequential", "(", ")", "]", "\n", "", "elif", "self", ".", "concat_mix_experts", ":", "\n", "# As with the video inputs, we similiarly use a single large GEU for the", "\n", "# text embedding", "\n", "                ", "gated_text_embds", "=", "[", "GatedEmbeddingUnit", "(", "text_dim", ",", "sum", "(", "agg_dims", ")", ",", "\n", "use_bn", "=", "True", ")", "]", "\n", "", "else", ":", "\n", "                ", "gated_text_embds", "=", "[", "GatedEmbeddingUnit", "(", "text_dim", ",", "dim", ",", "use_bn", "=", "True", ")", "for", "\n", "dim", "in", "text_out_dims", "]", "\n", "", "self", ".", "text_GU", "=", "nn", ".", "ModuleList", "(", "gated_text_embds", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"V. simple classifier, should update....\"", ")", "\n", "total_dim", "=", "0", "\n", "for", "mod", "in", "self", ".", "expert_dims", ".", "keys", "(", ")", ":", "\n", "                ", "total_dim", "+=", "self", ".", "expert_dims", "[", "mod", "]", "[", "1", "]", "*", "self", ".", "repeat_temporal", "[", "mod", "]", "\n", "", "print", "(", "f\"Total dim is {total_dim}\"", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "total_dim", ",", "self", ".", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CEModule.compute_moe_weights": [[672, 711], ["len", "text.view.view.view", "model.CEModule.moe_weights.repeat", "model.CEModule.moe_fc", "torch.softmax", "torch.softmax", "torch.softmax", "moe_weights.cuda.cuda.view", "print", "enumerate", "moe_weights.cuda.cuda.cuda", "msg.format.format.format", "print", "moe_weights[].mean().item", "moe_weights[].std().item", "moe_weights[].min().item", "moe_weights[].max().item", "moe_weights[].mean", "moe_weights[].std", "moe_weights[].min", "moe_weights[].max"], "methods", ["None"], ["", "", "def", "compute_moe_weights", "(", "self", ",", "text", ",", "ind", ")", ":", "\n", "# compute weights for all captions (including when assigned K captions to", "\n", "# the same video)", "\n", "        ", "B", ",", "K", ",", "D", "=", "text", ".", "shape", "\n", "M", "=", "len", "(", "self", ".", "modalities", ")", "\n", "msg", "=", "f\"expected between 1 and 10 modalities, found {M} ({self.modalities})\"", "\n", "assert", "1", "<=", "M", "<=", "10", ",", "msg", "\n", "\n", "# Treat each caption independently in the softmax (which runs over modalities)", "\n", "text", "=", "text", ".", "view", "(", "B", "*", "K", ",", "D", ")", "\n", "if", "self", ".", "freeze_weights", ":", "\n", "            ", "moe_weights", "=", "self", ".", "moe_weights", ".", "repeat", "(", "B", ",", "K", ",", "1", ")", "\n", "if", "text", ".", "is_cuda", ":", "\n", "                ", "moe_weights", "=", "moe_weights", ".", "cuda", "(", ")", "\n", "", "", "else", ":", "\n", "# if False:", "\n", "#     print(\"USING BIGGER WEIGHT PREDS\")", "\n", "#     moe_weights = self.moe_fc_bottleneck1(text)", "\n", "#     moe_weights = self.moe_cg(moe_weights)", "\n", "#     moe_weights = self.moe_fc_proj(moe_weights)", "\n", "#     moe_weights = moe_weights * 1", "\n", "# else:", "\n", "            ", "moe_weights", "=", "self", ".", "moe_fc", "(", "text", ")", "# BK x D -> BK x M", "\n", "moe_weights", "=", "F", ".", "softmax", "(", "moe_weights", ",", "dim", "=", "1", ")", "\n", "moe_weights", "=", "moe_weights", ".", "view", "(", "B", ",", "K", ",", "M", ")", "\n", "\n", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"--------------------------------\"", ")", "\n", "for", "idx", ",", "key", "in", "enumerate", "(", "self", ".", "modalities", ")", ":", "\n", "                ", "msg", "=", "\"{}: mean: {:.3f}, std: {:.3f}, min: {:.3f}, max: {:.3f}\"", "\n", "msg", "=", "msg", ".", "format", "(", "\n", "key", ",", "\n", "moe_weights", "[", ":", ",", ":", ",", "idx", "]", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "moe_weights", "[", ":", ",", ":", ",", "idx", "]", ".", "std", "(", ")", ".", "item", "(", ")", ",", "\n", "moe_weights", "[", ":", ",", ":", ",", "idx", "]", ".", "min", "(", ")", ".", "item", "(", ")", ",", "\n", "moe_weights", "[", ":", ",", ":", ",", "idx", "]", ".", "max", "(", ")", ".", "item", "(", ")", ",", "\n", ")", "\n", "print", "(", "msg", ")", "\n", "", "", "return", "moe_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CEModule.forward": [[712, 907], ["zip", "hasattr", "text.view.view.size", "text.view.view.view", "zip", "text.view.view.view", "model.CEModule.compute_moe_weights", "layer", "zip", "enumerate", "torch.cat", "torch.cat", "torch.cat", "model.CEModule.classifier", "layer", "torch.rand_like.view", "experts[].norm", "experts[].div", "layer", "list", "list", "len", "experts.keys", "model.CEModule.h_reason", "l", "torch.cat", "torch.cat", "torch.cat", "text_embd_.view.view.view", "tuple", "torch.matmul", "torch.matmul", "torch.matmul", "torch.rand_like", "torch.rand_like", "torch.rand_like", "itertools.product", "itertools.permutations", "ind[].float().to().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "model.CEModule.g_reason_1", "model.CEModule.g_reason_shared", "tuple", "torch.cat", "torch.cat", "torch.cat", "text_embd_.view.view.view", "zip", "experts.values", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.t", "model.sharded_cross_view_inner_product", "ind[].float().to().unsqueeze", "ind[].float().to().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "model.CEModule.g_reason_shared", "experts.values", "tuple", "layer", "ind[].float().to", "ind[].float().to().unsqueeze", "model.CEModule.dim_reduce", "mod0_reduce.unsqueeze.unsqueeze.unsqueeze", "model.CEModule.dim_reduce", "mod1_reduce.unsqueeze.unsqueeze.unsqueeze", "torch.matmul().view", "torch.matmul().view", "torch.matmul().view", "model.CEModule.g_reason_1", "model.CEModule.g_reason_shared", "experts.values", "ind[].float().to", "ind[].float().to", "ind[].float().to().unsqueeze", "torch.div", "torch.div", "torch.div", "ValueError", "ind[].float", "ind[].float().to", "torch.matmul", "torch.matmul", "torch.matmul", "ind[].float", "ind[].float", "ind[].float().to", "avai_dict[].unsqueeze", "ind[].float", "torch.cat", "torch.cat", "torch.cat", "model.CEModule.g_reason_1", "model.CEModule.g_reason_shared", "avail.to", "ind[].float", "ind[].float", "ind[].float", "torch.cat", "torch.cat", "torch.cat", "model.CEModule.g_reason_1", "model.CEModule.g_reason_shared", "ind[].float", "ind[].float", "ind[].float"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CEModule.compute_moe_weights", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.sharded_cross_view_inner_product"], ["", "def", "forward", "(", "self", ",", "text", ",", "experts", ",", "ind", ",", "raw_captions", ")", ":", "\n", "        ", "\"\"\"Compute joint embeddings and, if requested, a confusion matrix between\n        video and text representations in the minibatch.\n\n        Notation: B = batch size, M = number of modalities\n        \"\"\"", "\n", "if", "\"retrieval\"", "in", "self", ".", "task", ":", "\n", "# Pass text embeddings through gated units", "\n", "            ", "text_embd", "=", "{", "}", "\n", "\n", "# Unroll repeated captions into present minibatch", "\n", "B", ",", "captions_per_video", ",", "feat_dim", "=", "text", ".", "size", "(", ")", "\n", "text", "=", "text", ".", "view", "(", "B", "*", "captions_per_video", ",", "feat_dim", ")", "\n", "for", "modality", ",", "layer", "in", "zip", "(", "self", ".", "modalities", ",", "self", ".", "text_GU", ")", ":", "\n", "# NOTE: Due to the batch norm, the gated units are sensitive to passing", "\n", "# in a lot of zeroes, so we do the masking step after the forwards pass", "\n", "                ", "text_", "=", "layer", "(", "text", ")", "\n", "\n", "# We always assume that text is available for retrieval", "\n", "text_", "=", "text_", ".", "view", "(", "B", ",", "captions_per_video", ",", "-", "1", ")", "\n", "\n", "if", "\"text\"", "in", "self", ".", "random_feats", ":", "\n", "                    ", "text_", "=", "th", ".", "rand_like", "(", "text_", ")", "\n", "", "text_embd", "[", "modality", "]", "=", "text_", "\n", "", "text", "=", "text", ".", "view", "(", "B", ",", "captions_per_video", ",", "-", "1", ")", "\n", "\n", "# vladded nans are handled earlier (during pooling)", "\n", "# We also avoid zeroing random features, since this will leak information", "\n", "# exclude = list(self.vlad_feat_sizes.keys()) + list(self.random_feats)", "\n", "# experts = self.mask_missing_embeddings(experts, ind, exclude=exclude)", "\n", "\n", "# MOE weights computation + normalization - note that we use the first caption", "\n", "# sample to predict the weights", "\n", "moe_weights", "=", "self", ".", "compute_moe_weights", "(", "text", ",", "ind", "=", "ind", ")", "\n", "\n", "", "if", "self", ".", "l2renorm", ":", "\n", "            ", "for", "modality", "in", "self", ".", "modalities", ":", "\n", "                ", "norm", "=", "experts", "[", "modality", "]", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "experts", "[", "modality", "]", "=", "experts", "[", "modality", "]", ".", "div", "(", "norm", ")", "\n", "\n", "", "", "for", "modality", ",", "layer", "in", "zip", "(", "self", ".", "modalities", ",", "self", ".", "trn_list", ")", ":", "\n", "            ", "experts", "[", "modality", "]", "=", "layer", "(", "experts", "[", "modality", "]", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "\"video_dim_reduce\"", ")", ":", "\n", "# Embed all features to a common dimension", "\n", "            ", "for", "modality", ",", "layer", "in", "zip", "(", "self", ".", "modalities", ",", "self", ".", "video_dim_reduce", ")", ":", "\n", "                ", "experts", "[", "modality", "]", "=", "layer", "(", "experts", "[", "modality", "]", ")", "\n", "\n", "", "", "if", "self", ".", "use_ce", ":", "\n", "            ", "dev", "=", "experts", "[", "self", ".", "modalities", "[", "0", "]", "]", ".", "device", "\n", "if", "self", ".", "include_self", ":", "\n", "                ", "all_combinations", "=", "list", "(", "itertools", ".", "product", "(", "experts", ",", "repeat", "=", "2", ")", ")", "\n", "", "else", ":", "\n", "                ", "all_combinations", "=", "list", "(", "itertools", ".", "permutations", "(", "experts", ",", "2", ")", ")", "\n", "", "assert", "len", "(", "self", ".", "modalities", ")", ">", "1", ",", "\"use_ce requires multiple modalities\"", "\n", "\n", "if", "self", ".", "use_ce", "in", "{", "\"pairwise-star\"", ",", "\"pairwise-star-specific\"", ",", "\n", "\"pairwise-star-tensor\"", "}", ":", "\n", "                ", "sum_all", "=", "0", "\n", "sum_ind", "=", "0", "\n", "for", "mod0", "in", "experts", ".", "keys", "(", ")", ":", "\n", "                    ", "sum_all", "+=", "(", "experts", "[", "mod0", "]", "*", "ind", "[", "mod0", "]", ".", "float", "(", ")", ".", "to", "(", "dev", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "sum_ind", "+=", "ind", "[", "mod0", "]", ".", "float", "(", ")", ".", "to", "(", "dev", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "avg_modality", "=", "sum_all", "/", "sum_ind", "\n", "\n", "", "for", "ii", ",", "l", "in", "enumerate", "(", "self", ".", "video_GU", ")", ":", "\n", "\n", "                ", "mask_num", "=", "0", "\n", "curr_mask", "=", "0", "\n", "temp_dict", "=", "{", "}", "\n", "avai_dict", "=", "{", "}", "\n", "curr_modality", "=", "self", ".", "modalities", "[", "ii", "]", "\n", "\n", "if", "self", ".", "use_ce", "==", "\"pairwise-star\"", ":", "\n", "                    ", "fused", "=", "th", ".", "cat", "(", "(", "experts", "[", "curr_modality", "]", ",", "avg_modality", ")", ",", "1", ")", "# -> B x 2D", "\n", "temp", "=", "self", ".", "g_reason_1", "(", "fused", ")", "# B x 2D -> B x D", "\n", "temp", "=", "self", ".", "g_reason_shared", "(", "temp", ")", "# B x D -> B x D", "\n", "curr_mask", "=", "temp", "*", "ind", "[", "curr_modality", "]", ".", "float", "(", ")", ".", "to", "(", "dev", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "elif", "self", ".", "use_ce", "==", "\"pairwise-star-specific\"", ":", "\n", "                    ", "fused", "=", "th", ".", "cat", "(", "(", "experts", "[", "curr_modality", "]", ",", "avg_modality", ")", ",", "1", ")", "# -> B x 2D", "\n", "temp", "=", "self", ".", "g_reason_unshared_weights", "[", "ii", "]", "(", "fused", ")", "\n", "temp", "=", "self", ".", "g_reason_shared", "(", "temp", ")", "# B x D -> B x D", "\n", "curr_mask", "=", "temp", "*", "ind", "[", "curr_modality", "]", ".", "float", "(", ")", ".", "to", "(", "dev", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "elif", "self", ".", "use_ce", "==", "\"pairwise-star-tensor\"", ":", "\n", "                    ", "mod0_reduce", "=", "self", ".", "dim_reduce", "(", "experts", "[", "curr_modality", "]", ")", "\n", "mod0_reduce", "=", "mod0_reduce", ".", "unsqueeze", "(", "2", ")", "# B x reduced_dim x1", "\n", "mod1_reduce", "=", "self", ".", "dim_reduce", "(", "avg_modality", ")", "\n", "mod1_reduce", "=", "mod1_reduce", ".", "unsqueeze", "(", "1", ")", "# B x1 x reduced_dim", "\n", "flat_dim", "=", "self", ".", "reduce_dim", "*", "self", ".", "reduce_dim", "\n", "fused", "=", "th", ".", "matmul", "(", "mod0_reduce", ",", "mod1_reduce", ")", ".", "view", "(", "-", "1", ",", "flat_dim", ")", "\n", "temp", "=", "self", ".", "g_reason_1", "(", "fused", ")", "# B x 2D -> B x D", "\n", "temp", "=", "self", ".", "g_reason_shared", "(", "temp", ")", "# B x D -> B x D", "\n", "curr_mask", "=", "temp", "*", "ind", "[", "curr_modality", "]", ".", "float", "(", ")", ".", "to", "(", "dev", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "elif", "self", ".", "use_ce", "in", "{", "\"pairwise\"", ",", "\"triplet\"", "}", ":", "\n", "                    ", "for", "modality_pair", "in", "all_combinations", ":", "\n", "                        ", "mod0", ",", "mod1", "=", "modality_pair", "\n", "if", "self", ".", "use_ce", "==", "\"pairwise\"", ":", "\n", "                            ", "if", "mod0", "==", "curr_modality", ":", "\n", "                                ", "new_key", "=", "f\"{mod0}_{mod1}\"", "\n", "fused", "=", "th", ".", "cat", "(", "(", "experts", "[", "mod0", "]", ",", "experts", "[", "mod1", "]", ")", ",", "1", ")", "\n", "temp", "=", "self", ".", "g_reason_1", "(", "fused", ")", "# B x 2D -> B x D", "\n", "temp", "=", "self", ".", "g_reason_shared", "(", "temp", ")", "\n", "temp_dict", "[", "new_key", "]", "=", "temp", "\n", "avail", "=", "(", "ind", "[", "mod0", "]", ".", "float", "(", ")", "*", "ind", "[", "mod1", "]", ".", "float", "(", ")", ")", "\n", "avai_dict", "[", "new_key", "]", "=", "avail", ".", "to", "(", "dev", ")", "\n", "", "", "elif", "self", ".", "use_ce", "==", "\"triplet\"", ":", "\n", "                            ", "if", "(", "curr_modality", "not", "in", "{", "mod0", ",", "mod1", "}", ")", "or", "self", ".", "include_self", ":", "\n", "                                ", "new_key", "=", "f\"{curr_modality}_{mod0}_{mod1}\"", "\n", "fused", "=", "th", ".", "cat", "(", "(", "experts", "[", "curr_modality", "]", ",", "experts", "[", "mod0", "]", ",", "\n", "experts", "[", "mod1", "]", ")", ",", "1", ")", "# -> B x 2D", "\n", "temp", "=", "self", ".", "g_reason_1", "(", "fused", ")", "# B x 2D -> B x D", "\n", "temp", "=", "self", ".", "g_reason_shared", "(", "temp", ")", "\n", "temp_dict", "[", "new_key", "]", "=", "temp", "\n", "avail", "=", "(", "ind", "[", "curr_modality", "]", ".", "float", "(", ")", "*", "ind", "[", "mod0", "]", ".", "float", "(", ")", "*", "\n", "ind", "[", "mod1", "]", ".", "float", "(", ")", ")", ".", "to", "(", "dev", ")", "\n", "avai_dict", "[", "new_key", "]", "=", "avail", "\n", "\n", "# Combine the paired features into a mask through elementwise sum", "\n", "", "", "", "for", "mm", "in", "temp_dict", ":", "\n", "                        ", "curr_mask", "+=", "temp_dict", "[", "mm", "]", "*", "avai_dict", "[", "mm", "]", ".", "unsqueeze", "(", "1", ")", "\n", "mask_num", "+=", "avai_dict", "[", "mm", "]", "\n", "", "curr_mask", "=", "th", ".", "div", "(", "curr_mask", ",", "(", "mask_num", "+", "0.00000000001", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"Unknown CE mechanism: {self.use_ce}\"", ")", "\n", "", "curr_mask", "=", "self", ".", "h_reason", "(", "curr_mask", ")", "\n", "experts", "[", "curr_modality", "]", "=", "l", "(", "experts", "[", "curr_modality", "]", ",", "curr_mask", ")", "\n", "\n", "", "", "elif", "self", ".", "concat_mix_experts", ":", "\n", "            ", "concatenated", "=", "th", ".", "cat", "(", "tuple", "(", "experts", ".", "values", "(", ")", ")", ",", "dim", "=", "1", ")", "\n", "vid_embd_", "=", "self", ".", "video_GU", "[", "0", "]", "(", "concatenated", ")", "\n", "text_embd_", "=", "text_embd", "[", "self", ".", "modalities", "[", "0", "]", "]", "\n", "text_embd_", "=", "text_embd_", ".", "view", "(", "-", "1", ",", "text_embd_", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "", "elif", "self", ".", "concat_experts", ":", "\n", "            ", "vid_embd_", "=", "th", ".", "cat", "(", "tuple", "(", "experts", ".", "values", "(", ")", ")", ",", "dim", "=", "1", ")", "\n", "text_embd_", "=", "text_embd", "[", "self", ".", "modalities", "[", "0", "]", "]", "\n", "text_embd_", "=", "text_embd_", ".", "view", "(", "-", "1", ",", "text_embd_", ".", "shape", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "for", "modality", ",", "layer", "in", "zip", "(", "self", ".", "modalities", ",", "self", ".", "video_GU", ")", ":", "\n", "                ", "experts", "[", "modality", "]", "=", "layer", "(", "experts", "[", "modality", "]", ")", "\n", "\n", "", "", "if", "self", ".", "training", ":", "\n", "            ", "merge_caption_similiarities", "=", "\"avg\"", "\n", "", "else", ":", "\n", "            ", "merge_caption_similiarities", "=", "self", ".", "test_caption_mode", "\n", "\n", "", "if", "self", ".", "task", "==", "\"classification\"", ":", "\n", "# for modality, layer in zip(self.modalities, self.video_dim_reduce_later):", "\n", "#     attempt to perform affordable classifier, might be removed later", "\n", "#     experts[modality] = layer(experts[modality])", "\n", "            ", "concatenated", "=", "th", ".", "cat", "(", "tuple", "(", "experts", ".", "values", "(", ")", ")", ",", "dim", "=", "1", ")", "\n", "preds", "=", "self", ".", "classifier", "(", "concatenated", ")", "\n", "return", "{", "\"modalities\"", ":", "self", ".", "modalities", ",", "\"class_preds\"", ":", "preds", "}", "\n", "", "elif", "self", ".", "concat_experts", "or", "self", ".", "concat_mix_experts", ":", "\n", "# zero pad to accommodate mismatch in sizes (after first setting the number", "\n", "# of VLAD clusters for the text to get the two vectors as close as possible", "\n", "# in size)", "\n", "            ", "if", "text_embd_", ".", "shape", "[", "1", "]", ">", "vid_embd_", ".", "shape", "[", "1", "]", ":", "\n", "                ", "sz", "=", "(", "vid_embd_", ".", "shape", "[", "0", "]", ",", "text_embd_", ".", "shape", "[", "1", "]", ")", "\n", "dtype", ",", "device", "=", "text_embd_", ".", "dtype", ",", "text_embd_", ".", "device", "\n", "vid_embd_padded", "=", "th", ".", "zeros", "(", "size", "=", "sz", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "# try:", "\n", "#     vid_embd_padded[:, :vid_embd_.shape[1]] = vid_embd_", "\n", "# except:", "\n", "#     import ipdb; ipdb.set_trace()", "\n", "vid_embd_", "=", "vid_embd_padded", "\n", "", "else", ":", "\n", "                ", "sz", "=", "(", "text_embd_", ".", "shape", "[", "0", "]", ",", "vid_embd_", ".", "shape", "[", "1", "]", ")", "\n", "dtype", ",", "device", "=", "text_embd_", ".", "dtype", ",", "text_embd_", ".", "device", "\n", "text_embd_padded", "=", "th", ".", "zeros", "(", "size", "=", "sz", ",", "dtype", "=", "dtype", ",", "device", "=", "device", ")", "\n", "text_embd_padded", "[", ":", ",", ":", "text_embd_", ".", "shape", "[", "1", "]", "]", "=", "text_embd_", "\n", "text_embd_", "=", "text_embd_padded", "\n", "", "cross_view_conf_matrix", "=", "th", ".", "matmul", "(", "text_embd_", ",", "vid_embd_", ".", "t", "(", ")", ")", "\n", "", "elif", "self", ".", "task", "==", "\"compute_video_embeddings\"", ":", "\n", "            ", "return", "{", "\"modalities\"", ":", "self", ".", "modalities", ",", "\"embeddings\"", ":", "experts", "}", "\n", "", "else", ":", "\n", "            ", "cross_view_conf_matrix", "=", "sharded_cross_view_inner_product", "(", "\n", "ind", "=", "ind", ",", "\n", "vid_embds", "=", "experts", ",", "\n", "text_embds", "=", "text_embd", ",", "\n", "keep_missing_modalities", "=", "self", ".", "keep_missing_modalities", ",", "\n", "l2renorm", "=", "self", ".", "l2renorm", ",", "\n", "text_weights", "=", "moe_weights", ",", "\n", "subspaces", "=", "self", ".", "modalities", ",", "\n", "raw_captions", "=", "raw_captions", ",", "\n", "merge_caption_similiarities", "=", "merge_caption_similiarities", ",", "\n", ")", "\n", "", "return", "{", "\n", "\"modalities\"", ":", "self", ".", "modalities", ",", "\n", "\"cross_view_conf_matrix\"", ":", "cross_view_conf_matrix", ",", "\n", "\"text_embds\"", ":", "text_embd", ",", "\n", "\"vid_embds\"", ":", "experts", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.GatedEmbeddingUnit.__init__": [[690, 696], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "model.ContextGating"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["#     moe_weights = self.moe_cg(moe_weights)", "\n", "#     moe_weights = self.moe_fc_proj(moe_weights)", "\n", "#     moe_weights = moe_weights * 1", "\n", "# else:", "\n", "            ", "moe_weights", "=", "self", ".", "moe_fc", "(", "text", ")", "# BK x D -> BK x M", "\n", "moe_weights", "=", "F", ".", "softmax", "(", "moe_weights", ",", "dim", "=", "1", ")", "\n", "moe_weights", "=", "moe_weights", ".", "view", "(", "B", ",", "K", ",", "M", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.GatedEmbeddingUnit.forward": [[697, 703], ["model.GatedEmbeddingUnit.fc", "model.GatedEmbeddingUnit.cg", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["None"], ["\n", "", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "\"--------------------------------\"", ")", "\n", "for", "idx", ",", "key", "in", "enumerate", "(", "self", ".", "modalities", ")", ":", "\n", "                ", "msg", "=", "\"{}: mean: {:.3f}, std: {:.3f}, min: {:.3f}, max: {:.3f}\"", "\n", "msg", "=", "msg", ".", "format", "(", "\n", "key", ",", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.MimicCEGatedEmbeddingUnit.__init__": [[707, 710], ["torch.Module.__init__", "model.ContextGating"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["moe_weights", "[", ":", ",", ":", ",", "idx", "]", ".", "max", "(", ")", ".", "item", "(", ")", ",", "\n", ")", "\n", "print", "(", "msg", ")", "\n", "", "", "return", "moe_weights", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.MimicCEGatedEmbeddingUnit.forward": [[711, 715], ["model.MimicCEGatedEmbeddingUnit.cg", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["None"], ["\n", "", "def", "forward", "(", "self", ",", "text", ",", "experts", ",", "ind", ",", "raw_captions", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.ReduceDim.__init__": [[719, 722], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["# Pass text embeddings through gated units", "\n", "            ", "text_embd", "=", "{", "}", "\n", "\n", "# Unroll repeated captions into present minibatch", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.ReduceDim.forward": [[723, 727], ["model.ReduceDim.fc", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["None"], ["B", ",", "captions_per_video", ",", "feat_dim", "=", "text", ".", "size", "(", ")", "\n", "text", "=", "text", ".", "view", "(", "B", "*", "captions_per_video", ",", "feat_dim", ")", "\n", "for", "modality", ",", "layer", "in", "zip", "(", "self", ".", "modalities", ",", "self", ".", "text_GU", ")", ":", "\n", "# NOTE: Due to the batch norm, the gated units are sensitive to passing", "\n", "# in a lot of zeroes, so we do the masking step after the forwards pass", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.ContextGating.__init__": [[739, 744], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["# We also avoid zeroing random features, since this will leak information", "\n", "# exclude = list(self.vlad_feat_sizes.keys()) + list(self.random_feats)", "\n", "# experts = self.mask_missing_embeddings(experts, ind, exclude=exclude)", "\n", "\n", "# MOE weights computation + normalization - note that we use the first caption", "\n", "# sample to predict the weights", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.ContextGating.forward": [[745, 751], ["model.ContextGating.fc", "torch.cat", "torch.cat", "torch.cat", "torch.glu", "torch.glu", "torch.glu", "model.ContextGating.batch_norm"], "methods", ["None"], ["moe_weights", "=", "self", ".", "compute_moe_weights", "(", "text", ",", "ind", "=", "ind", ")", "\n", "\n", "", "if", "self", ".", "l2renorm", ":", "\n", "            ", "for", "modality", "in", "self", ".", "modalities", ":", "\n", "                ", "norm", "=", "experts", "[", "modality", "]", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "experts", "[", "modality", "]", "=", "experts", "[", "modality", "]", ".", "div", "(", "norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.GatedEmbeddingUnitReasoning.__init__": [[755, 758], ["torch.Module.__init__", "model.ContextGatingReasoning"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["", "if", "hasattr", "(", "self", ",", "\"video_dim_reduce\"", ")", ":", "\n", "# Embed all features to a common dimension", "\n", "            ", "for", "modality", ",", "layer", "in", "zip", "(", "self", ".", "modalities", ",", "self", ".", "video_dim_reduce", ")", ":", "\n", "                ", "experts", "[", "modality", "]", "=", "layer", "(", "experts", "[", "modality", "]", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.GatedEmbeddingUnitReasoning.forward": [[759, 763], ["model.GatedEmbeddingUnitReasoning.cg", "torch.normalize", "torch.normalize", "torch.normalize"], "methods", ["None"], ["\n", "", "", "if", "self", ".", "use_ce", ":", "\n", "            ", "dev", "=", "experts", "[", "self", ".", "modalities", "[", "0", "]", "]", ".", "device", "\n", "if", "self", ".", "include_self", ":", "\n", "                ", "all_combinations", "=", "list", "(", "itertools", ".", "product", "(", "experts", ",", "repeat", "=", "2", ")", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.SpatialMLP.__init__": [[977, 981], ["torch.Module.__init__", "model.ContextGating", "model.ContextGating"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dimension", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "cg1", "=", "ContextGating", "(", "dimension", ")", "\n", "self", ".", "cg2", "=", "ContextGating", "(", "dimension", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.SpatialMLP.forward": [[982, 985], ["model.SpatialMLP.cg1", "model.SpatialMLP.cg2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "cg1", "(", "x", ")", "\n", "return", "self", ".", "cg2", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.ContextGatingReasoning.__init__": [[768, 774], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["if", "self", ".", "use_ce", "in", "{", "\"pairwise-star\"", ",", "\"pairwise-star-specific\"", ",", "\n", "\"pairwise-star-tensor\"", "}", ":", "\n", "                ", "sum_all", "=", "0", "\n", "sum_ind", "=", "0", "\n", "for", "mod0", "in", "experts", ".", "keys", "(", ")", ":", "\n", "                    ", "sum_all", "+=", "(", "experts", "[", "mod0", "]", "*", "ind", "[", "mod0", "]", ".", "float", "(", ")", ".", "to", "(", "dev", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "sum_ind", "+=", "ind", "[", "mod0", "]", ".", "float", "(", ")", ".", "to", "(", "dev", ")", ".", "unsqueeze", "(", "1", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.ContextGatingReasoning.forward": [[775, 787], ["model.ContextGatingReasoning.fc", "torch.cat", "torch.cat", "torch.cat", "torch.glu", "torch.glu", "torch.glu", "model.ContextGatingReasoning.batch_norm", "model.ContextGatingReasoning.batch_norm2"], "methods", ["None"], ["", "avg_modality", "=", "sum_all", "/", "sum_ind", "\n", "\n", "", "for", "ii", ",", "l", "in", "enumerate", "(", "self", ".", "video_GU", ")", ":", "\n", "\n", "                ", "mask_num", "=", "0", "\n", "curr_mask", "=", "0", "\n", "temp_dict", "=", "{", "}", "\n", "avai_dict", "=", "{", "}", "\n", "curr_modality", "=", "self", ".", "modalities", "[", "ii", "]", "\n", "\n", "if", "self", ".", "use_ce", "==", "\"pairwise-star\"", ":", "\n", "                    ", "fused", "=", "th", ".", "cat", "(", "(", "experts", "[", "curr_modality", "]", ",", "avg_modality", ")", ",", "1", ")", "# -> B x 2D", "\n", "temp", "=", "self", ".", "g_reason_1", "(", "fused", ")", "# B x 2D -> B x D", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.G_reason.__init__": [[1020, 1025], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "same_dim", ",", "num_inputs", ",", "non_lin", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "g_reason_1_specific", "=", "nn", ".", "Linear", "(", "same_dim", "*", "num_inputs", ",", "same_dim", ")", "\n", "self", ".", "g_reason_2_specific", "=", "nn", ".", "Linear", "(", "same_dim", ",", "same_dim", ")", "\n", "self", ".", "non_lin", "=", "non_lin", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.G_reason.forward": [[1026, 1031], ["model.G_reason.g_reason_1_specific", "model.G_reason.non_lin", "model.G_reason.g_reason_2_specific"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "g_reason_1_specific", "(", "x", ")", "# B x 2D -> B x D", "\n", "x", "=", "self", ".", "non_lin", "(", "x", ")", "\n", "x", "=", "self", ".", "g_reason_2_specific", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.kronecker_prod": [[48, 52], ["torch.bmm", "th.bmm.view", "t1.view", "t2.contiguous().view", "t1.size", "t2.size", "t2.contiguous"], "function", ["None"], ["", "", "def", "kronecker_prod", "(", "t1", ",", "t2", ")", ":", "\n", "# kronecker is performed along the last dim", "\n", "    ", "kron", "=", "th", ".", "bmm", "(", "t1", ".", "view", "(", "-", "1", ",", "t1", ".", "size", "(", "-", "1", ")", ",", "1", ")", ",", "t2", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "1", ",", "t2", ".", "size", "(", "-", "1", ")", ")", ")", "\n", "return", "kron", ".", "view", "(", "t1", ".", "shape", "[", "0", "]", ",", "t1", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.drop_nans": [[54, 84], ["torch.nonzero().flatten", "th.nonzero().flatten.numel", "torch.isnan().sum", "ipdb.set_trace", "torch.nonzero", "torch.isnan", "ipdb.set_trace", "vals.view", "torch.isnan", "vals.view"], "function", ["None"], ["", "def", "drop_nans", "(", "x", ",", "ind", ",", "validate_missing", ")", ":", "\n", "    ", "\"\"\"Remove nans, which we expect to find at missing indices.\n\n    Args:\n        x (th.Tensor): features\n        ind (th.Tensor): binary values denoting whether or not a given feature is\n            present\n        validate_missing (bool): whether to validate that the missing location contains\n            a nan.\n\n    Returns:\n        (th.tensor): the features, with the missing values masked to zero.\n    \"\"\"", "\n", "missing", "=", "th", ".", "nonzero", "(", "ind", "==", "0", ")", ".", "flatten", "(", ")", "\n", "if", "missing", ".", "numel", "(", ")", ":", "\n", "        ", "if", "validate_missing", ":", "\n", "            ", "vals", "=", "x", "[", "missing", "[", "0", "]", "]", "\n", "if", "not", "th", ".", "isnan", "(", "vals", ".", "view", "(", "-", "1", ")", "[", "0", "]", ")", ":", "\n", "                ", "ipdb", ".", "set_trace", "(", ")", "\n", "", "assert", "vals", ".", "view", "(", "-", "1", ")", "[", "0", "]", ",", "\"expected nans at missing locations\"", "\n", "# Prevent overwrite of the original tensor", "\n", "# x_ = x.clone()", "\n", "# TODO(samuel): This doesn't do anything, so can remove it", "\n", "", "x_", "=", "x", "\n", "x_", "[", "missing", "]", "=", "0", "\n", "x", "=", "x_", "\n", "", "if", "th", ".", "isnan", "(", "x", ")", ".", "sum", "(", ")", ">", "0", ":", "\n", "# slow, but might help us solve the mystery", "\n", "        ", "ipdb", ".", "set_trace", "(", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.sharded_cross_view_inner_product": [[789, 838], ["vid_embds[].size", "text_embds[].size", "len", "torch.zeros", "text_weights.view.view", "vid_weights.view.view", "torch.sum", "norm_weights.unsqueeze.unsqueeze", "torch.div", "enumerate", "list", "text_embds[].view", "th.div.size", "torch.matmul", "sims.view.view", "torch.mean", "sims.view.view", "vid_embds[].t", "ValueError", "msg.format"], "function", ["None"], ["curr_mask", "=", "temp", "*", "ind", "[", "curr_modality", "]", ".", "float", "(", ")", ".", "to", "(", "dev", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "elif", "self", ".", "use_ce", "==", "\"pairwise-star-specific\"", ":", "\n", "                    ", "fused", "=", "th", ".", "cat", "(", "(", "experts", "[", "curr_modality", "]", ",", "avg_modality", ")", ",", "1", ")", "# -> B x 2D", "\n", "temp", "=", "self", ".", "g_reason_unshared_weights", "[", "ii", "]", "(", "fused", ")", "\n", "temp", "=", "self", ".", "g_reason_shared", "(", "temp", ")", "# B x D -> B x D", "\n", "curr_mask", "=", "temp", "*", "ind", "[", "curr_modality", "]", ".", "float", "(", ")", ".", "to", "(", "dev", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "elif", "self", ".", "use_ce", "==", "\"pairwise-star-tensor\"", ":", "\n", "                    ", "mod0_reduce", "=", "self", ".", "dim_reduce", "(", "experts", "[", "curr_modality", "]", ")", "\n", "mod0_reduce", "=", "mod0_reduce", ".", "unsqueeze", "(", "2", ")", "# B x reduced_dim x1", "\n", "mod1_reduce", "=", "self", ".", "dim_reduce", "(", "avg_modality", ")", "\n", "mod1_reduce", "=", "mod1_reduce", ".", "unsqueeze", "(", "1", ")", "# B x1 x reduced_dim", "\n", "flat_dim", "=", "self", ".", "reduce_dim", "*", "self", ".", "reduce_dim", "\n", "fused", "=", "th", ".", "matmul", "(", "mod0_reduce", ",", "mod1_reduce", ")", ".", "view", "(", "-", "1", ",", "flat_dim", ")", "\n", "temp", "=", "self", ".", "g_reason_1", "(", "fused", ")", "# B x 2D -> B x D", "\n", "temp", "=", "self", ".", "g_reason_shared", "(", "temp", ")", "# B x D -> B x D", "\n", "curr_mask", "=", "temp", "*", "ind", "[", "curr_modality", "]", ".", "float", "(", ")", ".", "to", "(", "dev", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "elif", "self", ".", "use_ce", "in", "{", "\"pairwise\"", ",", "\"triplet\"", "}", ":", "\n", "                    ", "for", "modality_pair", "in", "all_combinations", ":", "\n", "                        ", "mod0", ",", "mod1", "=", "modality_pair", "\n", "if", "self", ".", "use_ce", "==", "\"pairwise\"", ":", "\n", "                            ", "if", "mod0", "==", "curr_modality", ":", "\n", "                                ", "new_key", "=", "f\"{mod0}_{mod1}\"", "\n", "fused", "=", "th", ".", "cat", "(", "(", "experts", "[", "mod0", "]", ",", "experts", "[", "mod1", "]", ")", ",", "1", ")", "\n", "temp", "=", "self", ".", "g_reason_1", "(", "fused", ")", "# B x 2D -> B x D", "\n", "temp", "=", "self", ".", "g_reason_shared", "(", "temp", ")", "\n", "temp_dict", "[", "new_key", "]", "=", "temp", "\n", "avail", "=", "(", "ind", "[", "mod0", "]", ".", "float", "(", ")", "*", "ind", "[", "mod1", "]", ".", "float", "(", ")", ")", "\n", "avai_dict", "[", "new_key", "]", "=", "avail", ".", "to", "(", "dev", ")", "\n", "", "", "elif", "self", ".", "use_ce", "==", "\"triplet\"", ":", "\n", "                            ", "if", "(", "curr_modality", "not", "in", "{", "mod0", ",", "mod1", "}", ")", "or", "self", ".", "include_self", ":", "\n", "                                ", "new_key", "=", "f\"{curr_modality}_{mod0}_{mod1}\"", "\n", "fused", "=", "th", ".", "cat", "(", "(", "experts", "[", "curr_modality", "]", ",", "experts", "[", "mod0", "]", ",", "\n", "experts", "[", "mod1", "]", ")", ",", "1", ")", "# -> B x 2D", "\n", "temp", "=", "self", ".", "g_reason_1", "(", "fused", ")", "# B x 2D -> B x D", "\n", "temp", "=", "self", ".", "g_reason_shared", "(", "temp", ")", "\n", "temp_dict", "[", "new_key", "]", "=", "temp", "\n", "avail", "=", "(", "ind", "[", "curr_modality", "]", ".", "float", "(", ")", "*", "ind", "[", "mod0", "]", ".", "float", "(", ")", "*", "\n", "ind", "[", "mod1", "]", ".", "float", "(", ")", ")", ".", "to", "(", "dev", ")", "\n", "avai_dict", "[", "new_key", "]", "=", "avail", "\n", "\n", "# Combine the paired features into a mask through elementwise sum", "\n", "", "", "", "for", "mm", "in", "temp_dict", ":", "\n", "                        ", "curr_mask", "+=", "temp_dict", "[", "mm", "]", "*", "avai_dict", "[", "mm", "]", ".", "unsqueeze", "(", "1", ")", "\n", "mask_num", "+=", "avai_dict", "[", "mm", "]", "\n", "", "curr_mask", "=", "th", ".", "div", "(", "curr_mask", ",", "(", "mask_num", "+", "0.00000000001", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"Unknown CE mechanism: {self.use_ce}\"", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.sharded_single_view_inner_product": [[1155, 1206], ["list", "torch.zeros", "enumerate", "torch.isnan().sum().item", "embds.keys", "len", "enumerate", "torch.sqrt().unsqueeze", "torch.matmul", "ValueError", "len", "ValueError", "embds[].reshape", "embds[].reshape.pow().sum", "embds[].reshape.reshape", "embds[].reshape.t", "torch.isnan().sum", "torch.sqrt", "len", "embds[].reshape.pow", "th.sqrt().unsqueeze.clamp", "torch.isnan"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["", "def", "sharded_single_view_inner_product", "(", "embds", ",", "subspaces", ",", "text_weights", "=", "None", ",", "\n", "l2renorm", "=", "True", ")", ":", "\n", "    ", "\"\"\"Compute a similarity matrix from sharded vectors.\n\n    Args:\n        embds (dict[str:th.Tensor]): the set of sub-embeddings that, when concatenated,\n            form the whole. The ith shard has shape `B x K x F_i` (i.e. they can\n            differ in the last dimension), or shape `B x F_i`\n        l2norm (bool::True): whether to l2 normalize the full embedding.\n\n    Returns:\n        (th.tensor): similarity matrix of size `BK x BK`.\n    \"\"\"", "\n", "subspaces", "=", "list", "(", "embds", ".", "keys", "(", ")", ")", "\n", "device", "=", "embds", "[", "subspaces", "[", "0", "]", "]", ".", "device", "\n", "shape", "=", "embds", "[", "subspaces", "[", "0", "]", "]", ".", "shape", "\n", "if", "len", "(", "shape", ")", "==", "3", ":", "\n", "        ", "B", ",", "K", ",", "_", "=", "shape", "\n", "num_embds", "=", "B", "*", "K", "\n", "assert", "text_weights", "is", "not", "None", ",", "\"Expected 3-dim tensors for text (+ weights)\"", "\n", "assert", "text_weights", ".", "shape", "[", "0", "]", "==", "B", "\n", "assert", "text_weights", ".", "shape", "[", "1", "]", "==", "K", "\n", "", "elif", "len", "(", "shape", ")", "==", "2", ":", "\n", "        ", "B", ",", "_", "=", "shape", "\n", "num_embds", "=", "B", "\n", "assert", "text_weights", "is", "None", ",", "\"Expected 2-dim tensors for non-text (no weights)\"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"input tensor with {} dims unrecognised\"", ".", "format", "(", "len", "(", "shape", ")", ")", ")", "\n", "", "sims", "=", "th", ".", "zeros", "(", "num_embds", ",", "num_embds", ",", "device", "=", "device", ")", "\n", "if", "l2renorm", ":", "\n", "        ", "l2_mass", "=", "0", "\n", "for", "idx", ",", "modality", "in", "enumerate", "(", "subspaces", ")", ":", "\n", "            ", "embd_", "=", "embds", "[", "modality", "]", "\n", "if", "text_weights", "is", "not", "None", ":", "\n", "# text_weights (i.e. moe_weights) are shared among subspace for video", "\n", "                ", "embd_", "=", "text_weights", "[", ":", ",", ":", ",", "idx", ":", "idx", "+", "1", "]", "*", "embd_", "\n", "", "embd_", "=", "embds", "[", "modality", "]", ".", "reshape", "(", "num_embds", ",", "-", "1", ")", "\n", "l2_mass", "+=", "embd_", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ")", "\n", "", "l2_mass", "=", "th", ".", "sqrt", "(", "l2_mass", ".", "clamp", "(", "min", "=", "1E-6", ")", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "        ", "l2_mass", "=", "1", "\n", "\n", "", "for", "idx", ",", "modality", "in", "enumerate", "(", "subspaces", ")", ":", "\n", "        ", "embd_", "=", "embds", "[", "modality", "]", "\n", "if", "text_weights", "is", "not", "None", ":", "\n", "            ", "embd_", "=", "text_weights", "[", ":", ",", ":", ",", "idx", ":", "idx", "+", "1", "]", "*", "embd_", "\n", "", "embd_", "=", "embd_", ".", "reshape", "(", "num_embds", ",", "-", "1", ")", "/", "l2_mass", "\n", "sims", "+=", "th", ".", "matmul", "(", "embd_", ",", "embd_", ".", "t", "(", ")", ")", "\n", "", "if", "th", ".", "isnan", "(", "sims", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Found nans in similarity matrix!\"", ")", "\n", "", "return", "sims", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.__init__": [[325, 329], ["metric.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.reset"], ["def", "__init__", "(", "self", ",", "name", ",", "fmt", "=", "':f'", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "fmt", "=", "fmt", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.reset": [[330, 335], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update": [[336, 341], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.__str__": [[342, 345], ["fmtstr.format"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "fmtstr", "=", "'{name} {val'", "+", "self", ".", "fmt", "+", "'} ({avg'", "+", "self", ".", "fmt", "+", "'})'", "\n", "return", "fmtstr", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.Meter.reset": [[352, 355], ["None"], "methods", ["None"], ["def", "reset", "(", "self", ")", ":", "\n", "        ", "'''Resets the meter to default settings.'''", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.Meter.add": [[356, 362], ["None"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "value", ")", ":", "\n", "        ", "'''Log a new value to the meter\n        Args:\n            value: Next restult to include.\n        '''", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.Meter.value": [[363, 366], ["None"], "methods", ["None"], ["", "def", "value", "(", "self", ")", ":", "\n", "        ", "'''Get the value of the meter in the current state.'''", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.APMeter.__init__": [[382, 385], ["object.__init__", "metric.APMeter.reset"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "APMeter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.APMeter.reset": [[386, 391], ["torch.FloatTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatStorage", "torch.LongStorage", "torch.FloatStorage"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the meter with empty member variables\"\"\"", "\n", "self", ".", "scores", "=", "torch", ".", "FloatTensor", "(", "torch", ".", "FloatStorage", "(", ")", ")", "\n", "self", ".", "targets", "=", "torch", ".", "LongTensor", "(", "torch", ".", "LongStorage", "(", ")", ")", "\n", "self", ".", "weights", "=", "torch", ".", "FloatTensor", "(", "torch", ".", "FloatStorage", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.APMeter.add": [[392, 457], ["torch.equal", "metric.APMeter.scores.resize_", "metric.APMeter.targets.resize_", "metric.APMeter.scores.narrow().copy_", "metric.APMeter.targets.narrow().copy_", "torch.is_tensor", "torch.from_numpy", "torch.is_tensor", "torch.from_numpy", "torch.from_numpy.squeeze", "output.view.view.dim", "output.view.view.view", "target.view.view.dim", "target.view.view.view", "metric.APMeter.scores.numel", "metric.APMeter.scores.storage().size", "math.ceil", "math.ceil", "metric.APMeter.scores.storage().resize_", "metric.APMeter.targets.storage().resize_", "metric.APMeter.scores.size", "output.view.view.size", "target.view.view.size", "metric.APMeter.weights.resize_", "metric.APMeter.weights.narrow().copy_", "torch.is_tensor", "torch.from_numpy", "output.view.view.dim", "target.view.view.dim", "torch.from_numpy.dim", "torch.from_numpy.numel", "target.view.view.size", "torch.min", "target.view.view.size", "metric.APMeter.targets.size", "metric.APMeter.scores.numel", "output.view.view.numel", "int", "int", "metric.APMeter.weights.storage().resize_", "metric.APMeter.scores.dim", "output.view.view.size", "target.view.view.size", "metric.APMeter.scores.narrow", "metric.APMeter.targets.narrow", "metric.APMeter.scores.storage", "metric.APMeter.scores.storage().size", "metric.APMeter.weights.storage().size", "metric.APMeter.scores.storage", "metric.APMeter.targets.storage", "int", "output.view.view.size", "target.view.view.size", "torch.from_numpy.size", "metric.APMeter.weights.narrow", "output.view.view.numel", "output.view.view.numel", "metric.APMeter.weights.storage", "torch.from_numpy.size", "metric.APMeter.scores.storage", "metric.APMeter.weights.storage", "output.view.view.size"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "output", ",", "target", ",", "weight", "=", "None", ")", ":", "\n", "        ", "\"\"\"Add a new observation\n        Args:\n            output (Tensor): NxK tensor that for each of the N examples\n                indicates the probability of the example belonging to each of\n                the K classes, according to the model. The probabilities should\n                sum to one over all classes\n            target (Tensor): binary NxK tensort that encodes which of the K\n                classes are associated with the N-th input\n                (eg: a row [0, 1, 0, 1] indicates that the example is\n                associated with classes 2 and 4)\n            weight (optional, Tensor): Nx1 tensor representing the weight for\n                each example (each weight > 0)\n        \"\"\"", "\n", "if", "not", "torch", ".", "is_tensor", "(", "output", ")", ":", "\n", "            ", "output", "=", "torch", ".", "from_numpy", "(", "output", ")", "\n", "", "if", "not", "torch", ".", "is_tensor", "(", "target", ")", ":", "\n", "            ", "target", "=", "torch", ".", "from_numpy", "(", "target", ")", "\n", "\n", "", "if", "weight", "is", "not", "None", ":", "\n", "            ", "if", "not", "torch", ".", "is_tensor", "(", "weight", ")", ":", "\n", "                ", "weight", "=", "torch", ".", "from_numpy", "(", "weight", ")", "\n", "", "weight", "=", "weight", ".", "squeeze", "(", ")", "\n", "", "if", "output", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "output", "=", "output", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "assert", "output", ".", "dim", "(", ")", "==", "2", ",", "'wrong output size (should be 1D or 2D with one column \\\n                per class)'", "\n", "", "if", "target", ".", "dim", "(", ")", "==", "1", ":", "\n", "            ", "target", "=", "target", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "assert", "target", ".", "dim", "(", ")", "==", "2", ",", "'wrong target size (should be 1D or 2D with one column \\\n                per class)'", "\n", "", "if", "weight", "is", "not", "None", ":", "\n", "            ", "assert", "weight", ".", "dim", "(", ")", "==", "1", ",", "'Weight dimension should be 1'", "\n", "assert", "weight", ".", "numel", "(", ")", "==", "target", ".", "size", "(", "0", ")", ",", "'Weight dimension 1 should be the same as that of target'", "\n", "assert", "torch", ".", "min", "(", "weight", ")", ">=", "0", ",", "'Weight should be non-negative only'", "\n", "", "assert", "torch", ".", "equal", "(", "target", "**", "2", ",", "target", ")", ",", "'targets should be binary (0 or 1)'", "\n", "if", "self", ".", "scores", ".", "numel", "(", ")", ">", "0", ":", "\n", "            ", "assert", "target", ".", "size", "(", "1", ")", "==", "self", ".", "targets", ".", "size", "(", "1", ")", ",", "'dimensions for output should match previously added examples.'", "\n", "\n", "# make sure storage is of sufficient size", "\n", "", "if", "self", ".", "scores", ".", "storage", "(", ")", ".", "size", "(", ")", "<", "self", ".", "scores", ".", "numel", "(", ")", "+", "output", ".", "numel", "(", ")", ":", "\n", "            ", "new_size", "=", "math", ".", "ceil", "(", "self", ".", "scores", ".", "storage", "(", ")", ".", "size", "(", ")", "*", "1.5", ")", "\n", "new_weight_size", "=", "math", ".", "ceil", "(", "self", ".", "weights", ".", "storage", "(", ")", ".", "size", "(", ")", "*", "1.5", ")", "\n", "self", ".", "scores", ".", "storage", "(", ")", ".", "resize_", "(", "int", "(", "new_size", "+", "output", ".", "numel", "(", ")", ")", ")", "\n", "self", ".", "targets", ".", "storage", "(", ")", ".", "resize_", "(", "int", "(", "new_size", "+", "output", ".", "numel", "(", ")", ")", ")", "\n", "if", "weight", "is", "not", "None", ":", "\n", "                ", "self", ".", "weights", ".", "storage", "(", ")", ".", "resize_", "(", "int", "(", "new_weight_size", "+", "output", ".", "size", "(", "0", ")", ")", ")", "\n", "\n", "# store scores and targets", "\n", "", "", "offset", "=", "self", ".", "scores", ".", "size", "(", "0", ")", "if", "self", ".", "scores", ".", "dim", "(", ")", ">", "0", "else", "0", "\n", "self", ".", "scores", ".", "resize_", "(", "offset", "+", "output", ".", "size", "(", "0", ")", ",", "output", ".", "size", "(", "1", ")", ")", "\n", "self", ".", "targets", ".", "resize_", "(", "offset", "+", "target", ".", "size", "(", "0", ")", ",", "target", ".", "size", "(", "1", ")", ")", "\n", "self", ".", "scores", ".", "narrow", "(", "0", ",", "offset", ",", "output", ".", "size", "(", "0", ")", ")", ".", "copy_", "(", "output", ")", "\n", "self", ".", "targets", ".", "narrow", "(", "0", ",", "offset", ",", "target", ".", "size", "(", "0", ")", ")", ".", "copy_", "(", "target", ")", "\n", "\n", "if", "weight", "is", "not", "None", ":", "\n", "            ", "self", ".", "weights", ".", "resize_", "(", "offset", "+", "weight", ".", "size", "(", "0", ")", ")", "\n", "self", ".", "weights", ".", "narrow", "(", "0", ",", "offset", ",", "weight", ".", "size", "(", "0", ")", ")", ".", "copy_", "(", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.APMeter.value": [[458, 499], ["torch.zeros", "hasattr", "range", "metric.APMeter.scores.numel", "metric.APMeter.scores.size", "torch.arange().float", "torch.range().float", "metric.APMeter.weights.numel", "metric.APMeter.weights.new", "metric.APMeter.weights.new", "metric.APMeter.scores.size", "torch.sort", "truth.float().cumsum.div", "metric.APMeter.weights.size", "metric.APMeter.weights.size", "metric.APMeter.weights.numel", "metric.APMeter.cumsum", "metric.APMeter.weights.numel", "metric.APMeter.cumsum", "truth.float().cumsum", "precision[].sum", "max", "torch.arange", "torch.range", "truth.float", "float", "metric.APMeter.scores.size", "truth.float", "truth.sum", "metric.APMeter.scores.size", "truth.byte"], "methods", ["None"], ["", "", "def", "value", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the model's average precision for each class\n        Return:\n            ap (FloatTensor): 1xK tensor, with avg precision for each class k\n        \"\"\"", "\n", "\n", "if", "self", ".", "scores", ".", "numel", "(", ")", "==", "0", ":", "\n", "            ", "return", "0", "\n", "", "ap", "=", "torch", ".", "zeros", "(", "self", ".", "scores", ".", "size", "(", "1", ")", ")", "\n", "if", "hasattr", "(", "torch", ",", "\"arange\"", ")", ":", "\n", "            ", "rg", "=", "torch", ".", "arange", "(", "1", ",", "self", ".", "scores", ".", "size", "(", "0", ")", "+", "1", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "            ", "rg", "=", "torch", ".", "range", "(", "1", ",", "self", ".", "scores", ".", "size", "(", "0", ")", ")", ".", "float", "(", ")", "\n", "", "if", "self", ".", "weights", ".", "numel", "(", ")", ">", "0", ":", "\n", "            ", "weight", "=", "self", ".", "weights", ".", "new", "(", "self", ".", "weights", ".", "size", "(", ")", ")", "\n", "weighted_truth", "=", "self", ".", "weights", ".", "new", "(", "self", ".", "weights", ".", "size", "(", ")", ")", "\n", "\n", "# compute average precision for each class", "\n", "", "for", "k", "in", "range", "(", "self", ".", "scores", ".", "size", "(", "1", ")", ")", ":", "\n", "# sort scores", "\n", "            ", "scores", "=", "self", ".", "scores", "[", ":", ",", "k", "]", "\n", "targets", "=", "self", ".", "targets", "[", ":", ",", "k", "]", "\n", "_", ",", "sortind", "=", "torch", ".", "sort", "(", "scores", ",", "0", ",", "True", ")", "\n", "truth", "=", "targets", "[", "sortind", "]", "\n", "if", "self", ".", "weights", ".", "numel", "(", ")", ">", "0", ":", "\n", "                ", "weight", "=", "self", ".", "weights", "[", "sortind", "]", "\n", "weighted_truth", "=", "truth", ".", "float", "(", ")", "*", "weight", "\n", "rg", "=", "weight", ".", "cumsum", "(", "0", ")", "\n", "\n", "# compute true positive sums", "\n", "", "if", "self", ".", "weights", ".", "numel", "(", ")", ">", "0", ":", "\n", "                ", "tp", "=", "weighted_truth", ".", "cumsum", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "tp", "=", "truth", ".", "float", "(", ")", ".", "cumsum", "(", "0", ")", "\n", "\n", "# compute precision curve", "\n", "", "precision", "=", "tp", ".", "div", "(", "rg", ")", "\n", "\n", "# compute average precision", "\n", "ap", "[", "k", "]", "=", "precision", "[", "truth", ".", "byte", "(", ")", "]", ".", "sum", "(", ")", "/", "max", "(", "float", "(", "truth", ".", "sum", "(", ")", ")", ",", "1", ")", "\n", "", "return", "ap", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.APMeterChallenge.value": [[515, 534], ["range", "torch.from_numpy", "metric.APMeterChallenge.scores.numel", "metric.APMeterChallenge.scores.cpu().numpy", "metric.APMeterChallenge.targets.cpu().numpy", "numpy.argsort", "numpy.squeeze", "numpy.squeeze", "range", "sklearn.metrics.average_precision_score", "numpy.asarray", "metric.APMeterChallenge.scores.cpu", "metric.APMeterChallenge.targets.cpu"], "methods", ["None"], ["def", "value", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the model's average precision for each class\n        Return:\n            ap (FloatTensor): 1xK tensor, with avg precision for each class k\n        \"\"\"", "\n", "if", "not", "self", ".", "scores", ".", "numel", "(", ")", ":", "\n", "            ", "return", "0", "\n", "\n", "", "mAP", "=", "0.0", "\n", "scores_np", ",", "target_np", "=", "self", ".", "scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "self", ".", "targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "ii", "in", "range", "(", "self", ".", "targets", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "sorted_ind", "=", "np", ".", "argsort", "(", "-", "1", "*", "scores_np", "[", "ii", ",", ":", "]", ")", "\n", "gt_label", "=", "np", ".", "squeeze", "(", "target_np", "[", "ii", ",", ":", "]", ")", "\n", "pred_label", "=", "np", ".", "squeeze", "(", "scores_np", "[", "ii", ",", ":", "]", ")", "\n", "for", "jj", "in", "range", "(", "target_np", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "pred_label", "[", "sorted_ind", "[", "jj", "]", "]", "=", "target_np", ".", "shape", "[", "1", "]", "-", "1", "-", "jj", "\n", "", "mAP", "+=", "average_precision_score", "(", "gt_label", ",", "pred_label", ",", "average", "=", "'macro'", ")", "\n", "", "ap", "=", "mAP", "/", "target_np", ".", "shape", "[", "0", "]", "\n", "return", "torch", ".", "from_numpy", "(", "np", ".", "asarray", "(", "ap", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.__init__": [[537, 542], ["object.__init__", "numpy.sort", "metric.ClassErrorMeter.reset"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.reset"], ["    ", "def", "__init__", "(", "self", ",", "topk", "=", "[", "1", ",", "5", ",", "10", ",", "50", "]", ",", "accuracy", "=", "True", ")", ":", "\n", "        ", "super", "(", "ClassErrorMeter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "topk", "=", "np", ".", "sort", "(", "topk", ")", "\n", "self", ".", "accuracy", "=", "accuracy", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.reset": [[543, 546], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "sum", "=", "{", "v", ":", "0", "for", "v", "in", "self", ".", "topk", "}", "\n", "self", ".", "n", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add": [[547, 573], ["torch.is_tensor", "torch.is_tensor", "int", "[].numpy", "output.cpu().squeeze().numpy.cpu().squeeze().numpy.cpu().squeeze().numpy", "numpy.atleast_1d", "isinstance", "numpy.ndim", "target[].repeat", "numpy.asarray.cpu().squeeze().numpy", "numpy.asarray", "numpy.ndim", "numpy.ndim", "correct[].sum", "output.cpu().squeeze().numpy.cpu().squeeze().numpy.cpu().squeeze", "torch.from_numpy().topk", "numpy.asarray.cpu().squeeze", "output.cpu().squeeze().numpy.cpu().squeeze().numpy.cpu", "torch.from_numpy", "numpy.asarray.cpu"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "output", ",", "target", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "output", ")", ":", "\n", "            ", "output", "=", "output", ".", "cpu", "(", ")", ".", "squeeze", "(", ")", ".", "numpy", "(", ")", "\n", "", "if", "torch", ".", "is_tensor", "(", "target", ")", ":", "\n", "            ", "target", "=", "np", ".", "atleast_1d", "(", "target", ".", "cpu", "(", ")", ".", "squeeze", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "target", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "target", "=", "np", ".", "asarray", "(", "[", "target", "]", ")", "\n", "", "if", "np", ".", "ndim", "(", "output", ")", "==", "1", ":", "\n", "            ", "output", "=", "output", "[", "np", ".", "newaxis", "]", "\n", "", "else", ":", "\n", "            ", "assert", "np", ".", "ndim", "(", "output", ")", "==", "2", ",", "'wrong output size (1D or 2D expected)'", "\n", "assert", "np", ".", "ndim", "(", "target", ")", "==", "1", ",", "'target and output do not match'", "\n", "", "assert", "target", ".", "shape", "[", "0", "]", "==", "output", ".", "shape", "[", "0", "]", ",", "'target and output do not match'", "\n", "topk", "=", "self", ".", "topk", "\n", "maxk", "=", "int", "(", "topk", "[", "-", "1", "]", ")", "# seems like Python3 wants int and not np.int64", "\n", "no", "=", "output", ".", "shape", "[", "0", "]", "\n", "\n", "pred", "=", "torch", ".", "from_numpy", "(", "output", ")", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "[", "1", "]", ".", "numpy", "(", ")", "\n", "correct", "=", "pred", "==", "target", "[", ":", ",", "np", ".", "newaxis", "]", ".", "repeat", "(", "pred", ".", "shape", "[", "1", "]", ",", "1", ")", "\n", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "self", ".", "sum", "[", "k", "]", "+=", "no", "-", "correct", "[", ":", ",", "0", ":", "k", "]", ".", "sum", "(", ")", "\n", "", "self", ".", "n", "+=", "no", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.value": [[574, 584], ["metric.ClassErrorMeter.sum.keys", "metric.ClassErrorMeter.value", "float", "float"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.value"], ["", "def", "value", "(", "self", ",", "k", "=", "-", "1", ")", ":", "\n", "        ", "if", "k", "!=", "-", "1", ":", "\n", "            ", "assert", "k", "in", "self", ".", "sum", ".", "keys", "(", ")", ",", "'invalid k (this k was not provided at construction time)'", "\n", "if", "self", ".", "accuracy", ":", "\n", "                ", "return", "(", "1.", "-", "float", "(", "self", ".", "sum", "[", "k", "]", ")", "/", "self", ".", "n", ")", "*", "100.0", "\n", "", "else", ":", "\n", "                ", "return", "float", "(", "self", ".", "sum", "[", "k", "]", ")", "/", "self", ".", "n", "*", "100.0", "\n", "", "", "else", ":", "\n", "            ", "return", "[", "self", ".", "value", "(", "k_", ")", "for", "k_", "in", "self", ".", "topk", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.t2v_metrics": [[26, 151], ["numpy.sort", "numpy.array", "numpy.where", "metric.cols2metrics", "dists.reshape", "ipdb.set_trace", "query_masks.sum", "numpy.ravel_multi_index", "range", "np.array.reshape", "numpy.unique", "query_masks.sum", "range", "numpy.unique", "numpy.argwhere", "numpy.diff", "numpy.insert", "numpy.add.reduceat", "numpy.diff", "query_masks.reshape().astype", "numpy.append", "numpy.nonzero", "query_masks.reshape"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.cols2metrics"], ["\n", "assert", "sims", ".", "ndim", "==", "2", ",", "\"expected a matrix\"", "\n", "\n", "num_queries", ",", "num_vids", "=", "sims", ".", "shape", "\n", "dists", "=", "-", "sims", "\n", "sorted_dists", "=", "np", ".", "sort", "(", "dists", ",", "axis", "=", "1", ")", "\n", "\n", "if", "False", ":", "\n", "        ", "import", "sys", "\n", "import", "matplotlib", "\n", "from", "pathlib", "import", "Path", "\n", "matplotlib", ".", "use", "(", "\"Agg\"", ")", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "sys", ".", "path", ".", "insert", "(", "0", ",", "str", "(", "Path", ".", "home", "(", ")", "/", "\"coding/src/zsvision/python\"", ")", ")", "\n", "from", "zsvision", ".", "zs_iterm", "import", "zs_dispFig", "# NOQA", "\n", "plt", ".", "matshow", "(", "dists", ")", "\n", "zs_dispFig", "(", ")", "\n", "import", "ipdb", ";", "ipdb", ".", "set_trace", "(", ")", "\n", "\n", "# The indices are computed such that they slice out the ground truth distances", "\n", "# from the psuedo-rectangular dist matrix", "\n", "", "queries_per_video", "=", "num_queries", "//", "num_vids", "\n", "gt_idx", "=", "[", "[", "np", ".", "ravel_multi_index", "(", "[", "ii", ",", "jj", "]", ",", "(", "num_queries", ",", "num_vids", ")", ")", "\n", "for", "ii", "in", "range", "(", "jj", "*", "queries_per_video", ",", "(", "jj", "+", "1", ")", "*", "queries_per_video", ")", "]", "\n", "for", "jj", "in", "range", "(", "num_vids", ")", "]", "\n", "gt_idx", "=", "np", ".", "array", "(", "gt_idx", ")", "\n", "gt_dists", "=", "dists", ".", "reshape", "(", "-", "1", ")", "[", "gt_idx", ".", "reshape", "(", "-", "1", ")", "]", "\n", "gt_dists", "=", "gt_dists", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "rows", ",", "cols", "=", "np", ".", "where", "(", "(", "sorted_dists", "-", "gt_dists", ")", "==", "0", ")", "# find column position of GT", "\n", "\n", "# --------------------------------", "\n", "# NOTE: Breaking ties", "\n", "# --------------------------------", "\n", "# We sometimes need to break ties (in general, these should occur extremely rarely,", "\n", "# but there are pathological cases when they can distort the scores, such as when", "\n", "# the similarity matrix is all zeros). Previous implementations (e.g. the t2i", "\n", "# evaluation function used", "\n", "# here: https://github.com/niluthpol/multimodal_vtt/blob/master/evaluation.py and", "\n", "# here: https://github.com/linxd5/VSE_Pytorch/blob/master/evaluation.py#L87) generally", "\n", "# break ties \"optimistically\".  However, if the similarity matrix is constant this", "\n", "# can evaluate to a perfect ranking. A principled option is to average over all", "\n", "# possible partial orderings implied by the ties. See # this paper for a discussion:", "\n", "#    McSherry, Frank, and Marc Najork,", "\n", "#    \"Computing information retrieval performance measures efficiently in the presence", "\n", "#    of tied scores.\" European conference on information retrieval. Springer, Berlin, ", "\n", "#    Heidelberg, 2008.", "\n", "# http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.145.8892&rep=rep1&type=pdf", "\n", "\n", "# break_ties = \"optimistically\"", "\n", "break_ties", "=", "\"averaging\"", "\n", "\n", "if", "rows", ".", "size", ">", "num_queries", ":", "\n", "        ", "assert", "np", ".", "unique", "(", "rows", ")", ".", "size", "==", "num_queries", ",", "\"issue in metric evaluation\"", "\n", "if", "break_ties", "==", "\"optimistically\"", ":", "\n", "            ", "_", ",", "idx", "=", "np", ".", "unique", "(", "rows", ",", "return_index", "=", "True", ")", "\n", "cols", "=", "cols", "[", "idx", "]", "\n", "", "elif", "break_ties", "==", "\"averaging\"", ":", "\n", "# fast implementation, based on this code:", "\n", "# https://stackoverflow.com/a/49239335", "\n", "            ", "locs", "=", "np", ".", "argwhere", "(", "(", "sorted_dists", "-", "gt_dists", ")", "==", "0", ")", "\n", "\n", "# Find the split indices", "\n", "steps", "=", "np", ".", "diff", "(", "locs", "[", ":", ",", "0", "]", ")", "\n", "splits", "=", "np", ".", "nonzero", "(", "steps", ")", "[", "0", "]", "+", "1", "\n", "splits", "=", "np", ".", "insert", "(", "splits", ",", "0", ",", "0", ")", "\n", "\n", "# Compute the result columns", "\n", "summed_cols", "=", "np", ".", "add", ".", "reduceat", "(", "locs", "[", ":", ",", "1", "]", ",", "splits", ")", "\n", "counts", "=", "np", ".", "diff", "(", "np", ".", "append", "(", "splits", ",", "locs", ".", "shape", "[", "0", "]", ")", ")", "\n", "avg_cols", "=", "summed_cols", "/", "counts", "\n", "if", "False", ":", "\n", "                ", "print", "(", "\"Running slower code to verify rank averaging across ties\"", ")", "\n", "# slow, but more interpretable version, used for testing", "\n", "avg_cols_slow", "=", "[", "np", ".", "mean", "(", "cols", "[", "rows", "==", "idx", "]", ")", "for", "idx", "in", "range", "(", "num_queries", ")", "]", "\n", "assert", "np", ".", "array_equal", "(", "avg_cols", ",", "avg_cols_slow", ")", ",", "\"slow vs fast difference\"", "\n", "print", "(", "\"passed num check\"", ")", "\n", "", "cols", "=", "avg_cols", "\n", "\n", "", "", "msg", "=", "\"expected ranks to match queries ({} vs {}) \"", "\n", "if", "cols", ".", "size", "!=", "num_queries", ":", "\n", "        ", "import", "ipdb", ";", "ipdb", ".", "set_trace", "(", ")", "\n", "", "assert", "cols", ".", "size", "==", "num_queries", ",", "msg", "\n", "\n", "if", "False", ":", "\n", "# overload mask to check that we can recover the scores for single-query", "\n", "# retrieval", "\n", "        ", "print", "(", "\"DEBUGGING MODE\"", ")", "\n", "query_masks", "=", "np", ".", "zeros_like", "(", "query_masks", ")", "\n", "query_masks", "[", ":", ",", "0", "]", "=", "1", "# recover single query score", "\n", "\n", "", "if", "query_masks", "is", "not", "None", ":", "\n", "# remove invalid queries", "\n", "        ", "assert", "query_masks", ".", "size", "==", "num_queries", ",", "\"invalid query mask shape\"", "\n", "cols", "=", "cols", "[", "query_masks", ".", "reshape", "(", "-", "1", ")", ".", "astype", "(", "np", ".", "bool", ")", "]", "\n", "assert", "cols", ".", "size", "==", "query_masks", ".", "sum", "(", ")", ",", "\"masking was not applied correctly\"", "\n", "# update number of queries to account for those that were missing", "\n", "num_queries", "=", "query_masks", ".", "sum", "(", ")", "\n", "\n", "", "if", "False", ":", "\n", "# sanity check against old logic for square matrices", "\n", "        ", "gt_dists_old", "=", "np", ".", "diag", "(", "dists", ")", "\n", "gt_dists_old", "=", "gt_dists_old", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "_", ",", "cols_old", "=", "np", ".", "where", "(", "(", "sorted_dists", "-", "gt_dists_old", ")", "==", "0", ")", "\n", "assert", "np", ".", "array_equal", "(", "cols_old", ",", "cols", ")", ",", "\"new metric doesn't match\"", "\n", "\n", "", "return", "cols2metrics", "(", "cols", ",", "num_queries", ",", "query_masks_class_t2v", ")", "\n", "\n", "\n", "", "def", "v2t_metrics", "(", "sims", ",", "query_masks", "=", "None", ",", "query_masks_class_t2v", "=", "None", ",", "\n", "query_masks_class_v2t", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute retrieval metrics from a similiarity matrix.\n\n    Args:\n        sims (th.Tensor): N x M matrix of similarities between embeddings, where\n             x_{i,j} = <text_embd[i], vid_embed[j]>\n        query_masks (th.Tensor): mask any missing captions from the dataset\n\n    Returns:\n        (dict[str:float]): retrieval metrics\n\n    NOTES: We find the closest \"GT caption\" in the style of VSE, which corresponds\n    to finding the rank of the closest relevant caption in embedding space:\n    github.com/ryankiros/visual-semantic-embedding/blob/master/evaluation.py#L52-L56\n    \"\"\"", "\n", "# switch axes of text and video", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.v2t_metrics": [[153, 244], ["range", "numpy.array", "metric.cols2metrics", "numpy.sort", "range", "np.array.append", "numpy.where", "numpy.logical_not", "ranks.mean", "query_masks.reshape"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.cols2metrics"], ["\n", "if", "False", ":", "\n", "# experiment with toy example", "\n", "        ", "sims", "=", "np", ".", "ones", "(", "(", "3", ",", "3", ")", ")", "\n", "sims", "[", "0", ",", "0", "]", "=", "2", "\n", "sims", "[", "1", ",", "1", ":", "2", "]", "=", "2", "\n", "sims", "[", "2", ",", ":", "]", "=", "2", "\n", "query_masks", "=", "None", "\n", "\n", "", "assert", "sims", ".", "ndim", "==", "2", ",", "\"expected a matrix\"", "\n", "num_queries", ",", "num_caps", "=", "sims", ".", "shape", "\n", "dists", "=", "-", "sims", "\n", "caps_per_video", "=", "num_caps", "//", "num_queries", "\n", "break_ties", "=", "\"averaging\"", "\n", "\n", "MISSING_VAL", "=", "1E8", "\n", "query_ranks", "=", "[", "]", "\n", "for", "ii", "in", "range", "(", "num_queries", ")", ":", "\n", "        ", "row_dists", "=", "dists", "[", "ii", ",", ":", "]", "\n", "if", "query_masks", "is", "not", "None", ":", "\n", "# Set missing queries to have a distance of infinity.  A missing query", "\n", "# refers to a query position `n` for a video that had less than `n`", "\n", "# captions (for example, a few MSRVTT videos only have 19 queries)", "\n", "            ", "row_dists", "[", "np", ".", "logical_not", "(", "query_masks", ".", "reshape", "(", "-", "1", ")", ")", "]", "=", "MISSING_VAL", "\n", "\n", "# NOTE: Using distance subtraction to perform the ranking is easier to make", "\n", "# deterministic than using argsort, which suffers from the issue of defining", "\n", "# \"stability\" for equal distances.  Example of distance subtraction code:", "\n", "# github.com/antoine77340/Mixture-of-Embedding-Experts/blob/master/train.py", "\n", "", "sorted_dists", "=", "np", ".", "sort", "(", "row_dists", ")", "\n", "\n", "min_rank", "=", "np", ".", "inf", "\n", "for", "jj", "in", "range", "(", "ii", "*", "caps_per_video", ",", "(", "ii", "+", "1", ")", "*", "caps_per_video", ")", ":", "\n", "            ", "if", "row_dists", "[", "jj", "]", "==", "MISSING_VAL", ":", "\n", "# skip rankings of missing captions", "\n", "                ", "continue", "\n", "", "ranks", "=", "np", ".", "where", "(", "(", "sorted_dists", "-", "row_dists", "[", "jj", "]", ")", "==", "0", ")", "[", "0", "]", "\n", "if", "break_ties", "==", "\"optimistically\"", ":", "\n", "                ", "rank", "=", "ranks", "[", "0", "]", "\n", "", "elif", "break_ties", "==", "\"averaging\"", ":", "\n", "# NOTE: If there is more than one caption per video, its possible for the", "\n", "# method to do \"worse than chance\" in the degenerate case when all", "\n", "# similarities are tied.  TODO(Samuel): Address this case.", "\n", "                ", "rank", "=", "ranks", ".", "mean", "(", ")", "\n", "", "if", "rank", "<", "min_rank", ":", "\n", "                ", "min_rank", "=", "rank", "\n", "", "", "query_ranks", ".", "append", "(", "min_rank", ")", "\n", "", "query_ranks", "=", "np", ".", "array", "(", "query_ranks", ")", "\n", "\n", "# sanity check against old version of code", "\n", "if", "False", ":", "\n", "        ", "sorted_dists", "=", "np", ".", "sort", "(", "dists", ",", "axis", "=", "1", ")", "\n", "gt_dists_old", "=", "np", ".", "diag", "(", "dists", ")", "\n", "gt_dists_old", "=", "gt_dists_old", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "rows_old", ",", "cols_old", "=", "np", ".", "where", "(", "(", "sorted_dists", "-", "gt_dists_old", ")", "==", "0", ")", "\n", "if", "rows_old", ".", "size", ">", "num_queries", ":", "\n", "            ", "_", ",", "idx", "=", "np", ".", "unique", "(", "rows_old", ",", "return_index", "=", "True", ")", "\n", "cols_old", "=", "cols_old", "[", "idx", "]", "\n", "", "num_diffs", "=", "(", "1", "-", "(", "cols_old", "==", "query_ranks", ")", ")", ".", "sum", "(", ")", "\n", "msg", "=", "f\"new metric doesn't match in {num_diffs} places\"", "\n", "assert", "np", ".", "array_equal", "(", "cols_old", ",", "query_ranks", ")", ",", "msg", "\n", "\n", "# visualise the distance matrix", "\n", "import", "sys", "\n", "import", "matplotlib", "\n", "matplotlib", ".", "use", "(", "\"Agg\"", ")", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "sys", ".", "path", ".", "insert", "(", "0", ",", "str", "(", "Path", ".", "home", "(", ")", "/", "\"coding/src/zsvision/python\"", ")", ")", "\n", "from", "zsvision", ".", "zs_iterm", "import", "zs_dispFig", "# NOQA", "\n", "plt", ".", "matshow", "(", "dists", ")", "\n", "zs_dispFig", "(", ")", "\n", "\n", "", "return", "cols2metrics", "(", "query_ranks", ",", "num_queries", ",", "query_masks_class_v2t", ")", "\n", "\n", "", "def", "retrieval_as_classification", "(", "sims", ",", "query_masks", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute classification metrics from a similiarity matrix.\n    \"\"\"", "\n", "assert", "sims", ".", "ndim", "==", "2", ",", "\"expected a matrix\"", "\n", "\n", "# switch axes of query-labels and video", "\n", "sims", "=", "sims", ".", "T", "\n", "query_masks", "=", "query_masks", ".", "T", "\n", "dists", "=", "-", "sims", "\n", "num_queries", ",", "num_labels", "=", "sims", ".", "shape", "\n", "break_ties", "=", "\"averaging\"", "\n", "\n", "query_ranks", "=", "[", "]", "\n", "for", "ii", "in", "range", "(", "num_queries", ")", ":", "\n", "        ", "row_dists", "=", "dists", "[", "ii", ",", ":", "]", "\n", "\n", "# NOTE: Using distance subtraction to perform the ranking is easier to make", "\n", "# deterministic than using argsort, which suffers from the issue of defining", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.retrieval_as_classification": [[227, 290], ["range", "numpy.array", "metric.cols2metrics", "numpy.sort", "np.array.extend", "matplotlib.use", "sys.path.insert", "plt.hist", "plt.grid", "zs_dispFig", "ipdb.set_trace", "numpy.where", "label_ranks.append", "str", "len", "numpy.where", "enumerate", "ranks.mean", "ValueError", "pathlib.Path.home"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.cols2metrics"], ["", "def", "retrieval_as_classification", "(", "sims", ",", "query_masks", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute classification metrics from a similiarity matrix.\n    \"\"\"", "\n", "assert", "sims", ".", "ndim", "==", "2", ",", "\"expected a matrix\"", "\n", "\n", "# switch axes of query-labels and video", "\n", "sims", "=", "sims", ".", "T", "\n", "query_masks", "=", "query_masks", ".", "T", "\n", "dists", "=", "-", "sims", "\n", "num_queries", ",", "num_labels", "=", "sims", ".", "shape", "\n", "break_ties", "=", "\"averaging\"", "\n", "\n", "query_ranks", "=", "[", "]", "\n", "for", "ii", "in", "range", "(", "num_queries", ")", ":", "\n", "        ", "row_dists", "=", "dists", "[", "ii", ",", ":", "]", "\n", "\n", "# NOTE: Using distance subtraction to perform the ranking is easier to make", "\n", "# deterministic than using argsort, which suffers from the issue of defining", "\n", "# \"stability\" for equal distances.  Example of distance subtraction code:", "\n", "# github.com/antoine77340/Mixture-of-Embedding-Experts/blob/master/train.py", "\n", "sorted_dists", "=", "np", ".", "sort", "(", "row_dists", ")", "\n", "\n", "# min_rank = np.inf", "\n", "label_ranks", "=", "[", "]", "\n", "for", "gt_label", "in", "np", ".", "where", "(", "query_masks", "[", "ii", ",", ":", "]", ")", "[", "0", "]", ":", "\n", "            ", "ranks", "=", "np", ".", "where", "(", "(", "sorted_dists", "-", "row_dists", "[", "gt_label", "]", ")", "==", "0", ")", "[", "0", "]", "\n", "if", "break_ties", "==", "\"optimistically\"", ":", "\n", "                ", "rank", "=", "ranks", "[", "0", "]", "\n", "", "elif", "break_ties", "==", "\"averaging\"", ":", "\n", "# NOTE: If there is more than one caption per video, its possible for the", "\n", "# method to do \"worse than chance\" in the degenerate case when all", "\n", "# similarities are tied.  TODO(Samuel): Address this case.", "\n", "                ", "rank", "=", "ranks", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"unknown tie-breaking method: {break_ties}\"", ")", "\n", "", "label_ranks", ".", "append", "(", "rank", ")", "\n", "# Avoid penalising for assigning higher similarity to other gt labels. This is", "\n", "# done by subtracting out the better ranked query labels.  Note that this step", "\n", "# introduces a slight skew in favour of videos with lots of labels.  We can", "\n", "# address this later with a normalisation step if needed.", "\n", "", "label_ranks", "=", "[", "x", "-", "idx", "for", "idx", ",", "x", "in", "enumerate", "(", "label_ranks", ")", "]", "\n", "\n", "# Include all labels in the final calculation", "\n", "query_ranks", ".", "extend", "(", "label_ranks", ")", "\n", "", "query_ranks", "=", "np", ".", "array", "(", "query_ranks", ")", "\n", "\n", "# sanity check against old version of code", "\n", "if", "False", ":", "\n", "# visualise the distance matrix", "\n", "        ", "import", "sys", "\n", "import", "matplotlib", "\n", "matplotlib", ".", "use", "(", "\"Agg\"", ")", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "sys", ".", "path", ".", "insert", "(", "0", ",", "str", "(", "Path", ".", "home", "(", ")", "/", "\"coding/src/zsvision/python\"", ")", ")", "\n", "from", "zsvision", ".", "zs_iterm", "import", "zs_dispFig", "# NOQA", "\n", "# plt.matshow(dists)", "\n", "# zs_dispFig()", "\n", "plt", ".", "hist", "(", "query_ranks", ",", "bins", "=", "313", ",", "alpha", "=", "0.5", ")", "\n", "plt", ".", "grid", "(", ")", "\n", "zs_dispFig", "(", ")", "\n", "import", "ipdb", ";", "ipdb", ".", "set_trace", "(", ")", "\n", "\n", "", "return", "cols2metrics", "(", "query_ranks", ",", "num_queries", "=", "len", "(", "query_ranks", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.cols2metrics": [[246, 259], ["scipy.stats.mstats.gmean", "numpy.median", "numpy.mean", "int", "float", "float", "float", "float", "list", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum"], "function", ["None"], ["# github.com/antoine77340/Mixture-of-Embedding-Experts/blob/master/train.py", "\n", "sorted_dists", "=", "np", ".", "sort", "(", "row_dists", ")", "\n", "\n", "# min_rank = np.inf", "\n", "label_ranks", "=", "[", "]", "\n", "for", "gt_label", "in", "np", ".", "where", "(", "query_masks", "[", "ii", ",", ":", "]", ")", "[", "0", "]", ":", "\n", "            ", "ranks", "=", "np", ".", "where", "(", "(", "sorted_dists", "-", "row_dists", "[", "gt_label", "]", ")", "==", "0", ")", "[", "0", "]", "\n", "if", "break_ties", "==", "\"optimistically\"", ":", "\n", "                ", "rank", "=", "ranks", "[", "0", "]", "\n", "", "elif", "break_ties", "==", "\"averaging\"", ":", "\n", "# NOTE: If there is more than one caption per video, its possible for the", "\n", "# method to do \"worse than chance\" in the degenerate case when all", "\n", "# similarities are tied.  TODO(Samuel): Address this case.", "\n", "                ", "rank", "=", "ranks", ".", "mean", "(", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.mean_average_precision": [[317, 321], ["metric.APMeter", "metric.APMeter.add", "APMeter.value().mean", "metric.APMeter.value"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.value"], ["", "def", "mean_average_precision", "(", "sims", ",", "query_masks", "=", "None", ")", ":", "\n", "    ", "ap_meter", "=", "APMeter", "(", ")", "\n", "ap_meter", ".", "add", "(", "output", "=", "sims", ".", "T", ",", "target", "=", "query_masks", ".", "T", ")", "\n", "return", "{", "\"mAP\"", ":", "ap_meter", ".", "value", "(", ")", ".", "mean", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertEmbeddings.__init__": [[77, 86], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "\n", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "\n", "config", ".", "hidden_size", ")", "\n", "self", ".", "layer_norm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "\n", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertEmbeddings.forward": [[87, 106], ["bert.BertEmbeddings.token_type_embeddings", "bert.BertEmbeddings.layer_norm", "bert.BertEmbeddings.dropout", "torch.zeros_like", "bert.BertEmbeddings.position_embeddings"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "input_ids", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "features", "=", "None", ")", ":", "\n", "    ", "if", "token_type_ids", "is", "None", ":", "\n", "      ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "if", "position_ids", "is", "not", "None", ":", "\n", "      ", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "embeddings", "=", "position_embeddings", "+", "token_type_embeddings", "+", "features", "\n", "", "else", ":", "\n", "      ", "embeddings", "=", "token_type_embeddings", "+", "features", "\n", "\n", "", "embeddings", "=", "self", ".", "layer_norm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertSelfAttention.__init__": [[111, 129], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "output_attentions", "=", "False", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "\n", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertSelfAttention.transpose_for_scores": [[130, 135], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "    ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "\n", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertSelfAttention.forward": [[136, 173], ["bert.BertSelfAttention.query", "bert.BertSelfAttention.key", "bert.BertSelfAttention.value", "bert.BertSelfAttention.transpose_for_scores", "bert.BertSelfAttention.transpose_for_scores", "bert.BertSelfAttention.transpose_for_scores", "torch.matmul", "bert.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "bert.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.value", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ")", ":", "\n", "    ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention", "\n", "# scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel", "\n", "# forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "      ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "\n", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertSelfOutput.__init__": [[178, 184], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "layer_norm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "\n", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertSelfOutput.forward": [[185, 190], ["bert.BertSelfOutput.dense", "bert.BertSelfOutput.dropout", "bert.BertSelfOutput.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "    ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "layer_norm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertAttention.__init__": [[195, 199], ["torch.nn.Module.__init__", "bert.BertSelfAttention", "bert.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertAttention.forward": [[200, 206], ["bert.BertAttention.self", "bert.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", ",", "head_mask", "=", "None", ")", ":", "\n", "    ", "self_outputs", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ",", "head_mask", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "input_tensor", ")", "\n", "outputs", "=", "(", "attention_output", ",", "\n", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertIntermediate.__init__": [[211, 215], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "# self.intermediate_act_fn = config.hidden_act", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertIntermediate.forward": [[217, 221], ["bert.BertIntermediate.dense", "bert.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "    ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertOutput.__init__": [[226, 232], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "layer_norm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "\n", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertOutput.forward": [[233, 238], ["bert.BertOutput.dense", "bert.BertOutput.dropout", "bert.BertOutput.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "    ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "layer_norm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertLayer.__init__": [[243, 248], ["torch.nn.Module.__init__", "bert.BertAttention", "bert.BertIntermediate", "bert.BertOutput"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertLayer.forward": [[249, 257], ["bert.BertLayer.attention", "bert.BertLayer.intermediate", "bert.BertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ")", ":", "\n", "    ", "attention_outputs", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", ")", "\n", "attention_output", "=", "attention_outputs", "[", "0", "]", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "outputs", "=", "(", "layer_output", ",", "\n", ")", "+", "attention_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertEncoder.__init__": [[262, 268], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "bert.BertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "False", "\n", "self", ".", "output_hidden_states", "=", "False", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "\n", "[", "BertLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertEncoder.forward": [[269, 293], ["enumerate", "layer_module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "None", ")", ":", "\n", "    ", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "      ", "if", "self", ".", "output_hidden_states", ":", "\n", "        ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "        ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "      ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "      ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "      ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertPooler.__init__": [[298, 302], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertPooler.forward": [[303, 310], ["bert.BertPooler.dense", "bert.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "    ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertModel.__init__": [[349, 360], ["torch.nn.Module.__init__", "bert.BertEmbeddings", "bert.BertEncoder", "bert.BertPooler", "bert.BertModel.apply"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "    ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "# Weights initialization", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertModel._init_weights": [[361, 370], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "    ", "\"\"\"Initialize the weights.\"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "      ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "      ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "      ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.BertModel.forward": [[371, 415], ["torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "bert.BertModel.embeddings", "bert.BertModel.encoder", "bert.BertModel.pooler", "torch.ones_like", "torch.zeros_like", "torch.ones_like.unsqueeze", "next", "bert.BertModel.parameters"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "features", "=", "None", ")", ":", "\n", "    ", "if", "attention_mask", "is", "None", ":", "\n", "      ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "      ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to", "\n", "# [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "features", "=", "features", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "\n", "sequence_output", ",", "\n", "pooled_output", ",", "\n", ")", "+", "encoder_outputs", "[", "1", ":", "]", "# add hidden_states and attentions if they are here", "\n", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.gelu": [[37, 54], ["torch.erf", "math.sqrt"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "  ", "\"\"\"Implementation of the gelu activation function.\n\n  For information: OpenAI GPT's gelu is slightly different (and gives\n  slightly different results):\n  0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 *\n  torch.pow(x, 3))))\n  Also see https://arxiv.org/abs/1606.08415\n\n  Args:\n    x: input\n\n  Returns:\n    gelu(x)\n\n  \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.bert.swish": [[56, 58], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "  ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.lstm.LSTMModel.__init__": [[22, 37], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "hidden_dim", ",", "layer_dim", ",", "output_dim", ")", ":", "\n", "    ", "super", "(", "LSTMModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Hidden dimensions", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "\n", "# Number of hidden layers", "\n", "self", ".", "layer_dim", "=", "layer_dim", "\n", "\n", "# Building your LSTM", "\n", "# batch_first=True causes input/output tensors to be of shape", "\n", "# (batch_dim, seq_dim, feature_dim)", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_dim", ",", "hidden_dim", ",", "layer_dim", ",", "batch_first", "=", "True", ")", "\n", "\n", "# Readout layer", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "output_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.lstm.LSTMModel.forward": [[38, 72], ["torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "h0.to.to.to", "torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "torch.zeros().requires_grad_", "c0.to.to.to", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "lstm.LSTMModel.lstm", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "lstm.LSTMModel.fc", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "h0.to.to.detach", "c0.to.to.detach", "torch.nn.utils.rnn.pack_padded_sequence.size", "torch.nn.utils.rnn.pack_padded_sequence.size", "torch.nn.utils.rnn.pack_padded_sequence.size", "torch.nn.utils.rnn.pack_padded_sequence.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "x_lengths", ")", ":", "\n", "    ", "device", "=", "x", ".", "device", "\n", "\n", "# Initialize hidden state with zeros", "\n", "h0", "=", "torch", ".", "zeros", "(", "self", ".", "layer_dim", ",", "x", ".", "size", "(", "0", ")", ",", "\n", "self", ".", "hidden_dim", ")", ".", "requires_grad_", "(", ")", "\n", "h0", "=", "h0", ".", "to", "(", "device", ")", "\n", "\n", "# Initialize cell state", "\n", "c0", "=", "torch", ".", "zeros", "(", "self", ".", "layer_dim", ",", "x", ".", "size", "(", "0", ")", ",", "\n", "self", ".", "hidden_dim", ")", ".", "requires_grad_", "(", ")", "\n", "c0", "=", "c0", ".", "to", "(", "device", ")", "\n", "\n", "# pack_padded_sequence so that padded items in the sequence won't be shown", "\n", "# to the LSTM.", "\n", "x", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pack_padded_sequence", "(", "x", ",", "\n", "x_lengths", ",", "\n", "enforce_sorted", "=", "False", ",", "\n", "batch_first", "=", "True", ")", "\n", "\n", "# We need to detach as we are doing truncated backpropagation through time", "\n", "# (BPTT).", "\n", "# If we don't, we'll backprop all the way to the start even after going", "\n", "# through another batch.", "\n", "out", ",", "(", "hn", ",", "_", ")", "=", "self", ".", "lstm", "(", "x", ",", "(", "h0", ".", "detach", "(", ")", ",", "c0", ".", "detach", "(", ")", ")", ")", "\n", "\n", "# undo the packing operation", "\n", "out", ",", "_", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_packed_sequence", "(", "out", ",", "batch_first", "=", "True", ")", "\n", "\n", "# We just want the last hidden states", "\n", "# Apply fc layer to them", "\n", "res", "=", "self", ".", "fc", "(", "hn", "[", "-", "1", "]", ")", "\n", "\n", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.loss.InfoNceLoss.__init__": [[71, 74], ["torch.Module.__init__", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["self", ".", "loss", "=", "th", ".", "nn", ".", "BCEWithLogitsLoss", "(", "weight", "=", "weight", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "target", ")", ":", "\n", "        ", "return", "self", ".", "loss", "(", "x", ",", "target", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.loss.InfoNceLoss.forward": [[75, 82], ["torch.arange", "torch.arange", "torch.arange", "x.size", "target.cuda.cuda.cuda", "loss.InfoNceLoss.loss", "loss.InfoNceLoss.loss", "torch.transpose", "torch.transpose", "torch.transpose"], "methods", ["None"], ["\n", "\n", "", "", "class", "CrossEntropyLoss", "(", "nn", ".", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "weight", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss", "=", "th", ".", "nn", ".", "CrossEntropyLoss", "(", "weight", "=", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CENet.compute_weights_from_emb": [[262, 284], ["len", "model.CENet.moe_vid_dropout", "torch.cat", "torch.cat", "torch.cat", "torch.softmax", "torch.softmax", "torch.softmax", "embd.view.view.size", "len", "model.CENet.moe_txt_dropout", "embd.view.view.size", "len", "embd.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.softmax", "torch.softmax", "torch.softmax", "moe_weights.view.view.view", "embd.view.view.size"], "methods", ["None"], ["box_feats", "=", "x", ".", "view", "(", "box_feats", ".", "shape", ")", "\n", "\n", "", "if", "self", ".", "kron_dets", ":", "\n", "                ", "feats", "=", "kronecker_prod", "(", "box_feats", ",", "sem_feats", ")", "\n", "", "elif", "self", ".", "coord_dets", ":", "\n", "                ", "feats", "=", "box_feats", ".", "contiguous", "(", ")", "\n", "", "elif", "self", ".", "rand_proj", ":", "\n", "                ", "feats", "=", "box_feats", ".", "contiguous", "(", ")", "\n", "projected", "=", "self", ".", "proj", "(", "feats", ")", "\n", "feats", "=", "th", ".", "cat", "(", "(", "projected", ",", "sem_feats", ".", "contiguous", "(", ")", ")", ",", "dim", "=", "2", ")", "\n", "", "else", ":", "\n", "                ", "feats", "=", "th", ".", "cat", "(", "(", "box_feats", ",", "sem_feats", ".", "contiguous", "(", ")", ")", ",", "dim", "=", "2", ")", "\n", "", "experts", "[", "\"detection-sem\"", "]", "=", "feats", "\n", "\n", "# Handle all nan-checks", "\n", "", "for", "mod", "in", "self", ".", "expert_dims", ":", "\n", "            ", "experts", "=", "self", ".", "randomise_feats", "(", "experts", ",", "mod", ")", "\n", "experts", "[", "mod", "]", "=", "drop_nans", "(", "x", "=", "experts", "[", "mod", "]", ",", "ind", "=", "ind", "[", "mod", "]", ",", "validate_missing", "=", "True", ")", "\n", "if", "mod", "in", "self", ".", "tensor_storage", "[", "\"fixed\"", "]", ":", "\n", "                ", "aggregated_experts", "[", "mod", "]", "=", "experts", "[", "mod", "]", "\n", "", "elif", "mod", "in", "self", ".", "tensor_storage", "[", "\"variable\"", "]", ":", "\n", "                ", "aggregated_experts", "[", "mod", "]", "=", "self", ".", "pooling", "[", "mod", "]", "(", "experts", "[", "mod", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CENet.compute_weights_from_norm": [[285, 311], ["len", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "enumerate", "torch.sum", "torch.sum", "torch.sum", "sum_norm.unsqueeze.unsqueeze.unsqueeze", "torch.div", "torch.div", "torch.div", "len", "embds[].size", "torch.norm", "torch.norm", "torch.norm", "embds[].size", "len", "embds[].size", "torch.zeros", "torch.zeros", "torch.zeros", "embds[].size", "embds[].view"], "methods", ["None"], ["# for mod in variable_sz_experts:", "\n", "#     if mod in self.expert_dims.keys():", "\n", "#         experts[mod] = drop_nans(x=experts[mod], ind=ind[mod],", "\n", "#                                  validate_missing=True)", "\n", "#         experts = self.randomise_feats(experts, mod)", "\n", "\n", "# if \"rgb\" in self.expert_dims.keys():", "\n", "#     experts = self.randomise_feats(experts, \"rgb\")", "\n", "#     # If only average pooling has been performed, we will have an input of the", "\n", "#     # form N x 1 x D, so we need to flatten out the middle dimension to", "\n", "#     # maintain consistency", "\n", "#     aggregated_experts[\"rgb\"] = experts[\"rgb\"].view(experts[\"rgb\"].shape[0], -1)", "\n", "\n", "", "", "if", "\"retrieval\"", "in", "self", ".", "task", ":", "\n", "# When pooling multiple captions for a single video, we treat them as separate", "\n", "# members of the minibatch, so the total pooling op does the following:", "\n", "# pooling: B x captions_per_video x max_sentence_length x text_feat_dim", "\n", "# -> B x captions_per_video (cluster_dim * text_feat_dim)", "\n", "            ", "B", ",", "captions_per_video", ",", "max_words", ",", "text_feat_dim", "=", "text", ".", "size", "(", ")", "\n", "text", "=", "text", ".", "view", "(", "B", "*", "captions_per_video", ",", "max_words", ",", "text_feat_dim", ")", "\n", "\n", "# avoid OOM errors on old GPUs during inference", "\n", "# if not self.text_pooling.training:", "\n", "#     safe = 5000", "\n", "#     if text.shape[0] > safe:", "\n", "#         splits = [safe] * (text.shape[0] // safe)", "\n", "#         splits += [text.shape[0] - sum(splits)]", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.CENet.display_minibatch": [[663, 681], ["range", "logger.debug", "logger.debug", "token_ids[].cpu().numpy", "logger.debug", "model.CENet.tokenizer.convert_ids_to_tokens", "logger.debug", "logger.debug", "logger.debug", "token_ids[].cpu"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.WeTokenizer.convert_ids_to_tokens"], ["", "self", ".", "text_GU", "=", "nn", ".", "ModuleList", "(", "gated_text_embds", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"V. simple classifier, should update....\"", ")", "\n", "total_dim", "=", "0", "\n", "for", "mod", "in", "self", ".", "expert_dims", ".", "keys", "(", ")", ":", "\n", "                ", "total_dim", "+=", "self", ".", "expert_dims", "[", "mod", "]", "[", "1", "]", "*", "self", ".", "repeat_temporal", "[", "mod", "]", "\n", "", "print", "(", "f\"Total dim is {total_dim}\"", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "total_dim", ",", "self", ".", "num_classes", ")", "\n", "\n", "", "", "def", "compute_moe_weights", "(", "self", ",", "text", ",", "ind", ")", ":", "\n", "# compute weights for all captions (including when assigned K captions to", "\n", "# the same video)", "\n", "        ", "B", ",", "K", ",", "D", "=", "text", ".", "shape", "\n", "M", "=", "len", "(", "self", ".", "modalities", ")", "\n", "msg", "=", "f\"expected between 1 and 10 modalities, found {M} ({self.modalities})\"", "\n", "assert", "1", "<=", "M", "<=", "10", ",", "msg", "\n", "\n", "# Treat each caption independently in the softmax (which runs over modalities)", "\n", "text", "=", "text", ".", "view", "(", "B", "*", "K", ",", "D", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.GatedLinearUnit.forward": [[731, 734], ["torch.cat", "torch.cat", "torch.cat", "torch.glu", "torch.glu", "torch.glu"], "methods", ["None"], ["text_", "=", "text_", ".", "view", "(", "B", ",", "captions_per_video", ",", "-", "1", ")", "\n", "\n", "if", "\"text\"", "in", "self", ".", "random_feats", ":", "\n", "                    ", "text_", "=", "th", ".", "rand_like", "(", "text_", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.TxtEmbeddings.__init__": [[29, 58], ["torch.nn.Module.__init__", "isinstance", "logger.debug", "torch.nn.Embedding.from_pretrained", "torch.nn.Embedding", "logger.debug", "torch.load", "isinstance", "weight.size", "weight.size", "model.parameters"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "vocab_size", "=", "None", ",", "emb_dim", "=", "None", ",", "ckpt", "=", "None", ",", "freeze", "=", "False", ")", ":", "\n", "    ", "super", "(", "TxtEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "ckpt", "is", "not", "None", ":", "\n", "      ", "if", "isinstance", "(", "ckpt", ",", "str", ")", ":", "\n", "        ", "logger", ".", "debug", "(", "'Loading the pretrained word embeddings from %s ...'", ",", "ckpt", ")", "\n", "pretrained_dict", "=", "torch", ".", "load", "(", "ckpt", ")", "\n", "weight", "=", "pretrained_dict", "[", "'bert.embeddings.word_embeddings.weight'", "]", "\n", "\n", "", "elif", "isinstance", "(", "ckpt", ",", "torch", ".", "FloatTensor", ")", ":", "\n", "        ", "weight", "=", "ckpt", "\n", "\n", "", "self", ".", "nb_words", "=", "weight", ".", "size", "(", ")", "[", "0", "]", "\n", "logger", ".", "debug", "(", "'Nb of words in the embedding table: %d'", ",", "self", ".", "nb_words", ")", "\n", "self", ".", "text_dim", "=", "weight", ".", "size", "(", ")", "[", "1", "]", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "weight", ",", "\n", "freeze", "=", "freeze", ",", "\n", "padding_idx", "=", "0", ")", "\n", "\n", "", "else", ":", "\n", "# padding_idx=0 means the first row will be set at zeros and will stay so", "\n", "# (zero gradients). To be used for padding.", "\n", "      ", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "emb_dim", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "text_dim", "=", "emb_dim", "\n", "\n", "if", "freeze", ":", "\n", "        ", "model", "=", "self", ".", "word_embeddings", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "          ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.TxtEmbeddings.forward": [[59, 62], ["txt_embeddings.TxtEmbeddings.word_embeddings"], "methods", ["None"], ["", "", "", "", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ")", ":", "\n", "    ", "inputs_embeds", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "return", "inputs_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.WeTokenizer.__init__": [[67, 89], ["we_filepath.endswith", "torch.zeros", "torch.FloatTensor", "torch.cat", "txt_embeddings.TxtEmbeddings", "gensim.models.keyedvectors.KeyedVectors.load_word2vec_format", "we_filepath.endswith", "list", "we_filepath.replace", "gensim.models.keyedvectors.KeyedVectors.load_word2vec_format", "txt_embeddings.WeTokenizer.we.vocab.keys", "os.path.exists", "gensim.scripts.glove2word2vec.glove2word2vec"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["def", "__init__", "(", "self", ",", "we_filepath", ",", "freeze", "=", "False", ")", ":", "\n", "    ", "if", "we_filepath", ".", "endswith", "(", "'.bin'", ")", ":", "\n", "      ", "binary", "=", "True", "\n", "self", ".", "we", "=", "KeyedVectors", ".", "load_word2vec_format", "(", "we_filepath", ",", "binary", "=", "binary", ")", "\n", "", "elif", "we_filepath", ".", "endswith", "(", "'.txt'", ")", ":", "\n", "      ", "w2v_format_path", "=", "we_filepath", ".", "replace", "(", "'.txt'", ",", "'.w2v'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "w2v_format_path", ")", ":", "\n", "# Convert to right format", "\n", "        ", "glove2word2vec", "(", "we_filepath", ",", "w2v_format_path", ")", "\n", "", "self", ".", "we", "=", "KeyedVectors", ".", "load_word2vec_format", "(", "w2v_format_path", ",", "binary", "=", "False", ")", "\n", "\n", "", "self", ".", "text_dim", "=", "self", ".", "we", ".", "vectors", ".", "shape", "[", "1", "]", "\n", "\n", "# Add a line of zeros corresponding to the padding token and unknown token", "\n", "pad_vec", "=", "torch", ".", "zeros", "(", "(", "2", ",", "self", ".", "text_dim", ")", ")", "\n", "raw_table", "=", "torch", ".", "FloatTensor", "(", "self", ".", "we", ".", "vectors", ")", "\n", "self", ".", "weights", "=", "torch", ".", "cat", "(", "(", "pad_vec", ",", "raw_table", ")", ")", "\n", "\n", "# Add the padding token", "\n", "self", ".", "words", "=", "[", "'[PAD]'", ",", "'[UNK]'", "]", "+", "list", "(", "self", ".", "we", ".", "vocab", ".", "keys", "(", ")", ")", "\n", "\n", "self", ".", "we_model", "=", "TxtEmbeddings", "(", "ckpt", "=", "self", ".", "weights", ",", "freeze", "=", "freeze", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.WeTokenizer.tokenize": [[90, 108], ["text.lower.lower.lower", "text.lower.lower.split", "e.isalnum"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "    ", "\"\"\"Convert a text into tokens.\"\"\"", "\n", "# Un-capitalize", "\n", "text", "=", "text", ".", "lower", "(", ")", "\n", "\n", "# Split the text into words", "\n", "words", "=", "text", ".", "split", "(", "' '", ")", "\n", "\n", "# Remove special characters from words", "\n", "words", "=", "[", "''", ".", "join", "(", "e", "for", "e", "in", "word", "if", "e", ".", "isalnum", "(", ")", ")", "for", "word", "in", "words", "]", "\n", "\n", "# Remove the words out of vocabulary", "\n", "words", "=", "[", "word", "for", "word", "in", "words", "if", "word", "in", "self", ".", "words", "]", "\n", "\n", "if", "not", "words", ":", "\n", "      ", "words", "=", "[", "'[UNK]'", "]", "\n", "\n", "", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.WeTokenizer.convert_tokens_to_ids": [[109, 111], ["txt_embeddings.WeTokenizer.words.index"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "    ", "return", "[", "self", ".", "words", ".", "index", "(", "token", ")", "for", "token", "in", "tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.WeTokenizer.convert_ids_to_tokens": [[112, 114], ["None"], "methods", ["None"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ")", ":", "\n", "    ", "return", "[", "self", ".", "words", "[", "idx", "]", "for", "idx", "in", "ids", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer.__init__": [[62, 119], ["base.BaseTrainer.__init__", "int", "list", "int", "min", "numpy.sqrt", "expert_dims.keys", "len", "pytorch_warmup.LinearWarmup"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["self", ".", "cache_targets", "=", "cache_targets", "\n", "self", ".", "data_loaders", "=", "data_loaders", "\n", "self", ".", "lr_scheduler", "=", "lr_scheduler", "\n", "self", ".", "mini_train", "=", "mini_train", "\n", "self", ".", "disable_nan_checks", "=", "disable_nan_checks", "\n", "self", ".", "len_epoch", "=", "len", "(", "self", ".", "data_loaders", "[", "\"train\"", "]", ")", "\n", "self", ".", "log_step", "=", "int", "(", "np", ".", "sqrt", "(", "data_loaders", "[", "\"train\"", "]", ".", "batch_size", ")", ")", "\n", "self", ".", "visualizer", "=", "visualizer", "\n", "self", ".", "force_cpu_val", "=", "force_cpu_val", "\n", "self", ".", "val_freq", "=", "val_freq", "\n", "self", ".", "skip_first_n_saves", "=", "skip_first_n_saves", "\n", "self", ".", "include_optim_in_ckpts", "=", "include_optim_in_ckpts", "\n", "self", ".", "seen", "=", "{", "\"train\"", ":", "0", ",", "\"val\"", ":", "0", "}", "\n", "self", ".", "distil_loss", "=", "distil_loss", "\n", "self", ".", "distil_params", "=", "distil_params", "\n", "self", ".", "tt_loss", "=", "torch", ".", "nn", ".", "SmoothL1Loss", "(", "reduction", "=", "\"elementwise_mean\"", ")", "\n", "\n", "", "def", "_train_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Training logic for an epoch\n\n        :param epoch: Current training epoch.\n        :return: A log that contains all information you want to save.\n\n        Note:\n            If you have additional information to record, for example:\n                > additional_log = {\"x\": x, \"y\": y}\n            merge it with log before return. i.e.\n                > log = {**log, **additional_log}\n                > return log\n\n            The metrics in log must have the key 'metrics'.\n        \"\"\"", "\n", "total_loss", "=", "0", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "memory_summary", "(", ")", "\n", "\n", "for", "batch_idx", ",", "minibatch", "in", "enumerate", "(", "self", ".", "data_loaders", "[", "\"train\"", "]", ")", ":", "\n", "            ", "for", "key", ",", "val", "in", "minibatch", "[", "\"experts\"", "]", ".", "items", "(", ")", ":", "\n", "                ", "minibatch", "[", "\"experts\"", "]", "[", "key", "]", "=", "val", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "for", "key", "in", "{", "\"text\"", ",", "\"text_token_mask\"", "}", ":", "\n", "                ", "if", "key", "in", "minibatch", ":", "\n", "                    ", "minibatch", "[", "key", "]", "=", "minibatch", "[", "key", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "", "if", "\"labels\"", "in", "minibatch", ":", "\n", "                ", "labels", "=", "minibatch", ".", "pop", "(", "\"labels\"", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "if", "\"distil_video\"", "in", "minibatch", ":", "\n", "                ", "distil", "=", "minibatch", ".", "pop", "(", "\"distil_video\"", ")", "\n", "distil_text", "=", "minibatch", ".", "pop", "(", "\"distil_text\"", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "new_sims", "=", "None", "\n", "for", "t", "in", "distil", ":", "\n", "                        ", "t_sim", "=", "None", "\n", "\n", "for", "new_mod", "in", "distil", "[", "t", "]", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer._train_epoch": [[120, 250], ["trainer.Trainer.model.train", "logger.debug", "time.time", "enumerate", "time.time", "trainer.Trainer.timer.update", "logger.debug", "isinstance", "trainer.Trainer.timer.update", "time.time", "trainer.move_dict_to_device", "trainer.Trainer.optimizer.zero_grad", "trainer.Trainer.timer.update", "time.time", "trainer.Trainer.model", "trainer.Trainer.timer.update", "time.time", "trainer.Trainer.timer.update", "time.time", "trainer.Trainer.backward", "trainer.Trainer.optimizer.step", "trainer.Trainer.item", "trainer.Trainer.timer.update", "trainer.Trainer.timer.update", "time.time", "trainer.Trainer.timer.update", "time.time", "trainer.Trainer.lr_scheduler.get_lr", "trainer.Trainer.lr_scheduler.step", "trainer.Trainer.lr_scheduler.get_lr", "trainer.Trainer.display_minibatch", "trainer.Trainer.warmup_scheduler.dampen", "trainer.Trainer.loss", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "model.model.sharded_cross_view_inner_product", "trainer.Trainer.loss", "trainer.Trainer._progress", "logger.info", "time.time", "time.time", "time.time", "time.time", "time.time", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer.train", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.move_dict_to_device", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.ranger.Ranger.step", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.cos_restart.CosineAnnealingWithRestartsLR.get_lr", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.ranger.Ranger.step", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.cos_restart.CosineAnnealingWithRestartsLR.get_lr", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer.display_minibatch", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.sharded_cross_view_inner_product", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer._progress"], ["                            ", "distil_text", "[", "t", "]", "[", "new_mod", "]", "=", "distil_text", "[", "t", "]", "[", "new_mod", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "distil", "[", "t", "]", "[", "new_mod", "]", "=", "distil", "[", "t", "]", "[", "new_mod", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "tmp_sim", "=", "torch", ".", "matmul", "(", "distil_text", "[", "t", "]", "[", "new_mod", "]", ".", "view", "(", "-", "1", ",", "distil_text", "[", "t", "]", "[", "new_mod", "]", ".", "shape", "[", "-", "1", "]", ")", ",", "distil", "[", "t", "]", "[", "new_mod", "]", ".", "t", "(", ")", ")", "\n", "\n", "if", "t_sim", "is", "None", ":", "\n", "                                ", "t_sim", "=", "tmp_sim", "\n", "", "else", ":", "\n", "                                ", "t_sim", "=", "t_sim", "+", "tmp_sim", "\n", "\n", "", "", "if", "new_sims", "is", "None", ":", "\n", "                            ", "new_sims", "=", "t_sim", "\n", "", "else", ":", "\n", "                            ", "new_sims", "=", "new_sims", "+", "t_sim", "\n", "\n", "", "", "new_sims", "=", "new_sims", "/", "len", "(", "distil", ".", "keys", "(", ")", ")", "\n", "\n", "", "", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "output", "=", "self", ".", "model", "(", "**", "minibatch", ")", "\n", "if", "\"retrieval\"", "in", "self", ".", "data_loaders", ".", "dataloaders", ":", "\n", "                ", "loss", "=", "self", ".", "loss", "(", "output", "[", "\"cross_view_conf_matrix\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "self", ".", "loss", "(", "x", "=", "output", "[", "\"class_preds\"", "]", ",", "target", "=", "labels", ")", "\n", "\n", "", "if", "self", ".", "distil_loss", ":", "\n", "                ", "loss", "+=", "self", ".", "tt_loss", "(", "output", "[", "\"cross_view_conf_matrix\"", "]", ",", "new_sims", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "sample_key", "=", "list", "(", "minibatch", "[", "\"experts\"", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "batch_size", "=", "minibatch", "[", "\"experts\"", "]", "[", "sample_key", "]", ".", "shape", "[", "0", "]", "\n", "self", ".", "seen", "[", "\"train\"", "]", "+=", "batch_size", "\n", "\n", "if", "not", "self", ".", "skip_tboard", ":", "\n", "# self.writer.set_step((epoch - 1) * self.len_epoch + batch_idx)", "\n", "                ", "self", ".", "writer", ".", "set_step", "(", "self", ".", "seen", "[", "\"train\"", "]", ",", "mode", "=", "\"train\"", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'loss'", ",", "loss", ".", "item", "(", ")", ")", "\n", "", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "batch_idx", "%", "self", ".", "log_step", "==", "0", ":", "\n", "                ", "prog", "=", "self", ".", "_progress", "(", "batch_idx", ")", "\n", "self", ".", "logger", ".", "info", "(", "f\"Train Epoch: {epoch} {prog} Loss: {loss.item():.6f}\"", ")", "\n", "\n", "", "if", "batch_idx", "==", "self", ".", "len_epoch", "or", "(", "self", ".", "mini_train", "and", "batch_idx", ">", "3", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "log", "=", "{", "'loss'", ":", "total_loss", "/", "self", ".", "len_epoch", "}", "\n", "if", "epoch", "%", "self", ".", "val_freq", "==", "0", ":", "\n", "            ", "nested_log", ",", "cached_preds", "=", "self", ".", "_valid_epoch", "(", "epoch", ")", "\n", "log", ".", "update", "(", "nested_log", ")", "\n", "", "else", ":", "\n", "            ", "nested_log", ",", "cached_preds", "=", "{", "}", ",", "None", "\n", "self", ".", "logger", ".", "info", "(", "f\"skipping val for epoch: {epoch}\"", ")", "\n", "\n", "", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "f\"LR {self.lr_scheduler.get_lr()}\"", ")", "\n", "return", "log", ",", "cached_preds", "\n", "\n", "", "def", "log_metrics", "(", "self", ",", "metric_store", ",", "metric_name", ",", "mode", ")", ":", "\n", "        ", "if", "not", "self", ".", "skip_tboard", ":", "\n", "            ", "print", "(", "f\"logging metrics: {metric_name}\"", ")", "\n", "self", ".", "writer", ".", "set_step", "(", "step", "=", "self", ".", "seen", "[", "mode", "]", ",", "mode", "=", "mode", ")", "\n", "for", "key", ",", "value", "in", "metric_store", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "writer", ".", "add_scalar", "(", "f\"{metric_name}/{key}\"", ",", "value", ")", "\n", "\n", "", "", "", "def", "_valid_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"Validate model after an epoch of training and store results to disk.\n\n        Args:\n            epoch (int): the current epoch\n\n        Returns:\n            A log that contains information about validation\n\n        NOTE: The validation metrics in log must have the key 'val_metrics'.\n        \"\"\"", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "if", "not", "self", ".", "skip_tboard", ":", "\n", "            ", "self", ".", "writer", ".", "mode", "=", "\"val\"", "\n", "", "cached_preds", "=", "{", "key", ":", "{", "\"vid_name\"", ":", "[", "]", ",", "\"preds\"", ":", "[", "]", ",", "\"labels\"", ":", "[", "]", "}", "\n", "for", "key", "in", "self", ".", "cache_targets", "}", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "\"retrieval\"", "in", "self", ".", "data_loaders", ".", "dataloaders", ":", "\n", "                ", "samples", ",", "meta", "=", "self", ".", "data_loaders", "[", "\"retrieval\"", "]", "\n", "\n", "sample_key", "=", "list", "(", "samples", "[", "\"experts\"", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "batch_size", "=", "samples", "[", "\"experts\"", "]", "[", "sample_key", "]", ".", "shape", "[", "0", "]", "\n", "self", ".", "seen", "[", "\"val\"", "]", "+=", "batch_size", "\n", "\n", "num_queries", "=", "samples", "[", "\"text\"", "]", ".", "shape", "[", "0", "]", "*", "samples", "[", "\"text\"", "]", ".", "shape", "[", "1", "]", "\n", "safe_queries", "=", "256", "\n", "if", "num_queries", ">", "safe_queries", ":", "\n", "                    ", "partitions", "=", "int", "(", "np", ".", "ceil", "(", "num_queries", "/", "safe_queries", ")", ")", "\n", "chunk_size", "=", "int", "(", "np", ".", "ceil", "(", "samples", "[", "\"text\"", "]", ".", "shape", "[", "0", "]", "/", "partitions", ")", ")", "\n", "texts", "=", "copy", ".", "deepcopy", "(", "samples", "[", "\"text\"", "]", ")", "\n", "sim_chunks", "=", "[", "]", "\n", "for", "chunk_idx", "in", "range", "(", "partitions", ")", ":", "\n", "                        ", "chunk_start", "=", "chunk_idx", "*", "chunk_size", "\n", "chunk_stop", "=", "(", "chunk_idx", "+", "1", ")", "*", "chunk_size", "\n", "samples", "[", "\"text\"", "]", "=", "texts", "[", "chunk_start", ":", "chunk_stop", "]", "\n", "if", "samples", "[", "'text'", "]", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "                            ", "continue", "\n", "", "with", "ctxt_mgr", "(", "samples", ",", "self", ".", "device", ",", "\n", "self", ".", "disable_nan_checks", ")", "as", "xx", ":", "\n", "                            ", "output", "=", "self", ".", "model", "(", "**", "xx", ")", "\n", "", "sims", "=", "output", "[", "\"cross_view_conf_matrix\"", "]", ".", "data", "\n", "sim_chunks", ".", "append", "(", "sims", ")", "\n", "\n", "", "samples", "[", "\"text\"", "]", "=", "texts", "# restore pointer to original tensor", "\n", "del", "texts", "\n", "sims", "=", "torch", ".", "cat", "(", "sim_chunks", ",", "dim", "=", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                    ", "with", "ctxt_mgr", "(", "samples", ",", "self", ".", "device", ",", "self", ".", "disable_nan_checks", ")", "as", "xx", ":", "\n", "                        ", "output", "=", "self", ".", "model", "(", "**", "xx", ")", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "sims", "=", "output", "[", "\"cross_view_conf_matrix\"", "]", ".", "data", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# sample the loss (using only the first query for each video)", "\n", "", "queries_per_vid", "=", "meta", "[", "\"query_masks\"", "]", ".", "shape", "[", "1", "]", "\n", "sims_", "=", "torch", ".", "from_numpy", "(", "sims", ")", ".", "view", "(", "-", "1", ",", "queries_per_vid", ",", "sims", ".", "shape", "[", "-", "1", "]", ")", "\n", "loss", "=", "self", ".", "loss", "(", "sims_", "[", ":", ",", "0", ",", ":", "]", ".", "contiguous", "(", ")", ")", "\n", "if", "not", "self", ".", "skip_tboard", ":", "\n", "                    ", "self", ".", "writer", ".", "add_scalar", "(", "'first-query-loss'", ",", "loss", ".", "item", "(", ")", ")", "\n", "", "dataset", "=", "self", ".", "data_loaders", ".", "dataset_name", "\n", "nested_metrics", "=", "{", "}", "\n", "for", "metric", "in", "self", ".", "metrics", ":", "\n", "                    ", "metric_name", "=", "metric", ".", "__name__", "\n", "res", "=", "metric", "(", "sims", ",", "query_masks", "=", "meta", "[", "\"query_masks\"", "]", ")", "\n", "if", "metric_name", "==", "\"mean_average_precision\"", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer.log_metrics": [[280, 285], ["metric_store.items", "trainer.Trainer.writer.add_scalar"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["\n", "", "for", "metric", "in", "metrics", ":", "\n", "                        ", "metric", ".", "add", "(", "output", "=", "output", "[", "\"class_preds\"", "]", ",", "target", "=", "labels", ")", "\n", "", "if", "batch_idx", "%", "self", ".", "log_step", "==", "0", ":", "\n", "                        ", "prog", "=", "self", ".", "_progress", "(", "batch_idx", ")", "\n", "self", ".", "logger", ".", "info", "(", "f\"Val Epoch: {epoch} {prog}\"", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer._valid_epoch": [[370, 482], ["time.time", "trainer.Trainer.model.eval", "torch.no_grad", "enumerate", "trainer.Trainer.timer.update", "loaders_embds.items", "logger.debug", "trainer.Trainer._get_embeddings", "time.time", "logger.debug", "model.model.sharded_cross_view_inner_product", "model.model.sharded_cross_view_inner_product.data.cpu().float().numpy", "embds[].numpy", "trainer.Trainer.timer.update", "time.time", "logger.debug", "trainer.Trainer.timer.update", "time.time", "trainer.Trainer.timer.update", "time.time", "dataset_name.split", "dataset_name.split", "dataset_name.split", "numpy.save", "logger.info", "logger.debug", "metric", "logger.debug", "trainer.Trainer.log_metrics", "logger.debug", "trainer.Trainer.visualizer.visualize_ranking", "model.model.sharded_cross_view_inner_product.data.cpu().float", "utils.util.compress_predictions", "numpy.savetxt", "logger.debug", "pathlib.Path", "str", "time.time", "time.time", "time.time", "pathlib.Path", "model.model.sharded_cross_view_inner_product.data.cpu"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer._get_embeddings", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.model.sharded_cross_view_inner_product", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.save", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer.log_metrics", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.visualizer.Visualizer.visualize_ranking", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.compress_predictions"], []], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer._progress": [[483, 491], ["base.format"], "methods", ["None"], []], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.verbose": [[11, 17], ["print"], "function", ["None"], ["def", "verbose", "(", "epoch", ",", "metrics", ",", "mode", ",", "name", "=", "\"TEST\"", ")", ":", "\n", "    ", "r1", ",", "r5", ",", "r10", ",", "r50", "=", "metrics", "[", "\"R1\"", "]", ",", "metrics", "[", "\"R5\"", "]", ",", "metrics", "[", "\"R10\"", "]", ",", "metrics", "[", "\"R50\"", "]", "\n", "msg", "=", "f\"[{mode}]{name:s} epoch {epoch}, R@1: {r1:.1f}\"", "\n", "msg", "+=", "f\", R@5: {r5:.1f}, R@10 {r10:.1f}, R@50 {r50:.1f}\"", "\n", "msg", "+=", "f\"MedR: {metrics['MedR']:g}, MeanR: {metrics['MeanR']:.1f}\"", "\n", "print", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.ctxt_mgr": [[19, 46], ["print", "samples[].items", "val.clone().to", "samples[].to", "samples[].to", "val.clone"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "@", "contextmanager", "\n", "def", "ctxt_mgr", "(", "samples", ",", "device", ",", "disable_nan_checks", ")", ":", "\n", "    ", "\"\"\"Provide a context for managing temporary, cloned copies of retrieval\n    sample tensors.\n\n    The rationale here is that to use nan-checking in the model (to validate the\n    positions of missing experts), we need to modify the underlying tensors. This\n    function lets the evaluation code run (and modify) temporary copies, without\n    modifying the originals.\n    \"\"\"", "\n", "if", "disable_nan_checks", ":", "\n", "        ", "print", "(", "\"running without nan checks\"", ")", "\n", "yield", "samples", "\n", "", "else", ":", "\n", "        ", "exp_dict", "=", "samples", "[", "\"experts\"", "]", ".", "items", "(", ")", "\n", "experts", "=", "{", "key", ":", "val", ".", "clone", "(", ")", ".", "to", "(", "device", ")", "for", "key", ",", "val", "in", "exp_dict", "}", "\n", "samples_", "=", "{", "\n", "\"experts\"", ":", "experts", ",", "\n", "\"ind\"", ":", "samples", "[", "\"ind\"", "]", ",", "\n", "\"text\"", ":", "samples", "[", "\"text\"", "]", ".", "to", "(", "device", ")", ",", "\n", "}", "\n", "if", "\"text_token_mask\"", "in", "samples", ":", "\n", "            ", "samples_", "[", "\"text_token_mask\"", "]", "=", "samples", "[", "\"text_token_mask\"", "]", ".", "to", "(", "device", ")", "\n", "", "try", ":", "\n", "            ", "yield", "samples_", "\n", "", "finally", ":", "\n", "            ", "del", "samples_", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer.display_minibatch": [[251, 258], ["len", "range", "logger.debug", "logger.debug"], "methods", ["None"], ["                        ", "print", "(", "f\"Epoch: {epoch}, mean AP: {res['mAP']}\"", ")", "\n", "", "else", ":", "\n", "                        ", "verbose", "(", "epoch", "=", "epoch", ",", "metrics", "=", "res", ",", "name", "=", "dataset", ",", "mode", "=", "metric_name", ")", "\n", "", "self", ".", "log_metrics", "(", "res", ",", "metric_name", "=", "metric_name", ",", "mode", "=", "\"val\"", ")", "\n", "nested_metrics", "[", "metric_name", "]", "=", "res", "\n", "\n", "# TODO(Samuel) disabled visualisation for now, simple to add in later", "\n", "", "num_test_caps", "=", "self", ".", "data_loaders", ".", "num_test_captions", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer._get_embeddings": [[286, 369], ["torch.no_grad", "collections.OrderedDict", "collections.OrderedDict", "logger.debug", "time.time", "enumerate", "torch.cat", "torch.cat", "torch.cat", "enumerate", "numpy.concatenate", "trainer.move_dict_to_device", "trainer.Trainer.timer.update", "time.time", "query_masks_list.append", "trainer.move_dict_to_device", "trainer.Trainer.timer.update", "time.time", "trainer.Trainer.model", "vid_weights_list.append", "text_weights_list.append", "enumerate", "trainer.Trainer.timer.update", "trainer.Trainer.timer.update", "time.time", "torch.cat", "torch.cat", "move_dict_to_device.keys", "raw_captions_list.extend", "paths_list.extend", "minibatch[].size", "raw_captions_list.extend", "paths_list.extend", "move_dict_to_device.keys", "token_ids_list.extend", "torch.from_numpy", "trainer.Trainer.display_minibatch", "collections.OrderedDict.setdefault().append", "collections.OrderedDict.setdefault().append", "time.time", "time.time", "time.time", "time.time", "pathlib.Path", "collections.OrderedDict.setdefault", "collections.OrderedDict.setdefault", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.move_dict_to_device", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.move_dict_to_device", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.Trainer.display_minibatch"], ["\n", "", "", "nested_metrics", "=", "{", "}", "\n", "for", "metric", "in", "metrics", ":", "\n", "                    ", "if", "hasattr", "(", "metric", ",", "\"topk\"", ")", ":", "\n", "                        ", "res", "=", "{", "f\"top{key}\"", ":", "val", "for", "key", ",", "val", "in", "\n", "zip", "(", "metric", ".", "topk", ",", "metric", ".", "value", "(", ")", ")", "}", "\n", "self", ".", "log_metrics", "(", "res", ",", "mode", "=", "\"val\"", ",", "metric_name", "=", "\"accuracy\"", ")", "\n", "nested_metrics", "[", "\"accuracy\"", "]", "=", "res", "\n", "", "elif", "isinstance", "(", "metric", ",", "APMeter", ")", ":", "\n", "                        ", "res", "=", "{", "\"mAP\"", ":", "metric", ".", "value", "(", ")", ".", "mean", "(", ")", "}", "\n", "self", ".", "log_metrics", "(", "res", ",", "mode", "=", "\"val\"", ",", "\n", "metric_name", "=", "\"mean_ap_non_challenge\"", ")", "\n", "nested_metrics", "[", "\"mean_ap_non_challenge\"", "]", "=", "res", "\n", "", "elif", "isinstance", "(", "metric", ",", "APMeterChallenge", ")", ":", "\n", "                        ", "res", "=", "{", "\"mAP\"", ":", "metric", ".", "value", "(", ")", ".", "mean", "(", ")", "}", "\n", "self", ".", "log_metrics", "(", "res", ",", "mode", "=", "\"val\"", ",", "\n", "metric_name", "=", "\"mean_average_precision\"", ")", "\n", "nested_metrics", "[", "\"mean_ap\"", "]", "=", "res", "\n", "", "else", ":", "\n", "                        ", "raise", "ValueError", "(", "f\"unsupported mettric: {type(metric)}\"", ")", "\n", "", "", "nested", "=", "{", "\"nested_val_metrics\"", ":", "nested_metrics", "}", "\n", "\n", "for", "target", "in", "self", ".", "cache_targets", "-", "{", "\"val\"", "}", ":", "\n", "                    ", "for", "batch_idx", ",", "minibatch", "in", "enumerate", "(", "self", ".", "data_loaders", "[", "\"tiny\"", "]", ")", ":", "\n", "                        ", "for", "key", ",", "val", "in", "minibatch", "[", "\"experts\"", "]", ".", "items", "(", ")", ":", "\n", "                            ", "minibatch", "[", "\"experts\"", "]", "[", "key", "]", "=", "val", ".", "to", "(", "self", ".", "device", ")", "\n", "", "if", "\"labels\"", "in", "minibatch", ":", "\n", "                            ", "cached_preds", "[", "target", "]", "[", "\"labels\"", "]", ".", "append", "(", "minibatch", ".", "pop", "(", "\"labels\"", ")", ")", "\n", "", "cached_preds", "[", "target", "]", "[", "\"vid_name\"", "]", ".", "append", "(", "minibatch", ".", "pop", "(", "\"vid_name\"", ")", ")", "\n", "output", "=", "self", ".", "model", "(", "**", "minibatch", ")", "\n", "cached_preds", "[", "target", "]", "[", "\"preds\"", "]", ".", "append", "(", "output", "[", "\"class_preds\"", "]", ")", "\n", "\n", "# aggregate all cached predictions", "\n", "", "", "for", "target", "in", "self", ".", "cache_targets", ":", "\n", "                    ", "for", "key", ",", "val", "in", "cached_preds", "[", "target", "]", ".", "items", "(", ")", ":", "\n", "                        ", "cached_preds", "[", "key", "]", "=", "torch", ".", "cat", "(", "val", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "return", "nested", ",", "cached_preds", "\n", "\n", "", "", "", "def", "_progress", "(", "self", ",", "batch_idx", ")", ":", "\n", "        ", "base", "=", "'[{}/{} ({:.0f}%)]'", "\n", "if", "hasattr", "(", "self", ".", "data_loaders", ",", "'n_samples'", ")", ":", "\n", "            ", "current", "=", "batch_idx", "*", "self", ".", "data_loaders", ".", "batch_size", "\n", "total", "=", "self", ".", "data_loaders", ".", "n_samples", "\n", "", "else", ":", "\n", "            ", "current", "=", "batch_idx", "\n", "total", "=", "self", ".", "len_epoch", "\n", "", "return", "base", ".", "format", "(", "current", ",", "total", ",", "100.0", "*", "current", "/", "total", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.move_dict_to_device": [[36, 53], ["list", "res.keys", "isinstance", "torch.from_numpy", "isinstance", "res[].to", "value.to", "isinstance", "isinstance", "trainer.move_dict_to_device", "res.pop"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.trainer.trainer.move_dict_to_device"], ["\"experts\"", ":", "experts", ",", "\n", "\"ind\"", ":", "samples", "[", "\"ind\"", "]", ",", "\n", "\"text\"", ":", "samples", "[", "\"text\"", "]", ".", "to", "(", "device", ")", ",", "\n", "}", "\n", "if", "\"text_token_mask\"", "in", "samples", ":", "\n", "            ", "samples_", "[", "\"text_token_mask\"", "]", "=", "samples", "[", "\"text_token_mask\"", "]", ".", "to", "(", "device", ")", "\n", "", "try", ":", "\n", "            ", "yield", "samples_", "\n", "", "finally", ":", "\n", "            ", "del", "samples_", "\n", "\n", "\n", "", "", "", "class", "Trainer", "(", "BaseTrainer", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.launch_exps_from_list.main": [[17, 76], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "utils.util.filter_cmd_args", "open", "f.read().splitlines", "parsed.update", "yaspi.yaspi.Yaspi", "yaspi.yaspi.Yaspi.submit", "utils.util.parse_grid", "parsed.values", "open", "json.load", "json.load.update", "print", "os.system", "misc.aggregate_logs_and_stats.summarise", "f.read", "len", "len", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.filter_cmd_args", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_exps.parse_grid", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.aggregate_logs_and_stats.summarise"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--exp_list\"", ",", "default", "=", "\"data/job-queues/latest.txt\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--yaspify\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"launch via slurm\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--slurm\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--limit\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--mini_train'", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_cnodes\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_single_epoch'", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--yaspi_defaults_path\"", ",", "type", "=", "Path", ",", "\n", "default", "=", "\"misc/yaspi_gpu_defaults.json\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluation\"", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "choices", "=", "[", "'train'", ",", "'test'", "]", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# construct list of experiments from text file", "\n", "with", "open", "(", "args", ".", "exp_list", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "custom_args", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "# remove blank lines", "\n", "", "custom_args", "=", "[", "x", "for", "x", "in", "custom_args", "if", "x", "]", "\n", "\n", "if", "args", ".", "limit", ":", "\n", "        ", "custom_args", "=", "custom_args", "[", ":", "args", ".", "limit", "]", "\n", "\n", "", "parsed", "=", "{", "}", "\n", "for", "line", "in", "custom_args", ":", "\n", "        ", "parsed", ".", "update", "(", "parse_grid", "(", "line", ",", "args", ".", "evaluation", ")", ")", "\n", "\n", "# flatten all parsed experiments", "\n", "", "custom_args", "=", "[", "x", "for", "group", "in", "parsed", ".", "values", "(", ")", "for", "x", "in", "group", "]", "\n", "\n", "cmd_args", "=", "sys", ".", "argv", "[", "1", ":", "]", "\n", "remove", "=", "[", "\"--yaspify\"", ",", "\"--exp_list\"", ",", "\"--use_cnodes\"", ",", "\"--evaluation\"", "]", "\n", "cmd_args", "=", "filter_cmd_args", "(", "cmd_args", ",", "remove", "=", "remove", ")", "\n", "base_cmd", "=", "f\"python {args.evaluation}.py {' '.join(cmd_args)}\"", "\n", "\n", "if", "args", ".", "yaspify", ":", "\n", "        ", "with", "open", "(", "args", ".", "yaspi_defaults_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "yaspi_defaults", "=", "json", ".", "load", "(", "f", ")", "\n", "", "if", "args", ".", "use_cnodes", ":", "\n", "            ", "yaspi_defaults", ".", "update", "(", "{", "\"partition\"", ":", "\"compute\"", ",", "\"gpus_per_task\"", ":", "0", "}", ")", "\n", "", "job_name", "=", "f\"{Path(args.exp_list).stem}-{len(custom_args)}-exps\"", "\n", "job_queue", "=", "[", "f'\"{x}\"'", "for", "x", "in", "custom_args", "]", "\n", "job_queue", "=", "\" \"", ".", "join", "(", "job_queue", ")", "\n", "job", "=", "Yaspi", "(", "\n", "cmd", "=", "base_cmd", ",", "\n", "job_queue", "=", "job_queue", ",", "\n", "job_name", "=", "job_name", ",", "\n", "job_array_size", "=", "len", "(", "custom_args", ")", ",", "\n", "**", "yaspi_defaults", ",", "\n", ")", "\n", "job", ".", "submit", "(", "watch", "=", "True", ",", "conserve_resources", "=", "5", ")", "\n", "", "else", ":", "\n", "        ", "for", "custom_args_", "in", "custom_args", ":", "\n", "            ", "base_cmd", "=", "f\"{base_cmd} {custom_args_}\"", "\n", "print", "(", "f\"Running cmd: {base_cmd}\"", ")", "\n", "os", ".", "system", "(", "base_cmd", ")", "\n", "", "", "if", "args", ".", "evaluation", "==", "'train'", ":", "\n", "        ", "for", "group_id", "in", "parsed", ":", "\n", "            ", "summarise", "(", "group_id", "=", "group_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_exps.generate_configs": [[12, 34], ["datetime.datetime.now().strftime", "list", "list", "pathlib.Path().parent.mkdir", "print", "print", "itertools.product", "grid.keys", "job_queue.append", "open", "f.write", "open", "f.write", "datetime.datetime.now", "grid.values", "str", "str", "zip", "pathlib.Path", "len", "pathlib.Path", "len"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["def", "generate_configs", "(", "base_config", ",", "grid", ")", ":", "\n", "    ", "job_queue", "=", "[", "]", "\n", "timestamp", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "r\"%Y-%m-%d_%H-%M-%S\"", ")", "\n", "hparam_vals", "=", "[", "x", "for", "x", "in", "grid", ".", "values", "(", ")", "]", "\n", "grid_vals", "=", "list", "(", "itertools", ".", "product", "(", "*", "hparam_vals", ")", ")", "\n", "hparams", "=", "list", "(", "grid", ".", "keys", "(", ")", ")", "\n", "\n", "for", "cfg_vals", "in", "grid_vals", ":", "\n", "        ", "custom_tokens", "=", "[", "f\"{hparam}@{val}\"", "for", "hparam", ",", "val", "in", "zip", "(", "hparams", ",", "cfg_vals", ")", "]", "\n", "custom_args", "=", "\"+\"", ".", "join", "(", "custom_tokens", ")", "\n", "job", "=", "f\"--config {base_config} --custom_args {custom_args}\"", "\n", "job_queue", ".", "append", "(", "job", ")", "\n", "\n", "", "job_queue_path", "=", "f\"data/job-queues/latest.txt\"", "\n", "Path", "(", "job_queue_path", ")", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "with", "open", "(", "str", "(", "job_queue_path", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "job_queue", ")", ")", "\n", "", "print", "(", "f\"Wrote {len(job_queue)} jobs to queue at {job_queue_path}\"", ")", "\n", "job_queue_path", "=", "f\"data/job-queues/{Path(base_config).stem}-{timestamp}.txt\"", "\n", "with", "open", "(", "str", "(", "job_queue_path", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "job_queue", ")", ")", "\n", "", "print", "(", "f\"Wrote backup {len(job_queue)} jobs to queue at {job_queue_path}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_exps.parse_grid": [[36, 52], ["print", "key_val_strs.split", "collections.OrderedDict", "pair.split", "vals.append", "val_str.split", "token.split"], "function", ["None"], ["", "def", "parse_grid", "(", "key_val_strs", ")", ":", "\n", "    ", "print", "(", "f\"parsing grid str: {key_val_strs}\"", ")", "\n", "key_val_pairs", "=", "key_val_strs", ".", "split", "(", "\"+\"", ")", "\n", "parsed", "=", "OrderedDict", "(", ")", "\n", "for", "pair", "in", "key_val_pairs", ":", "\n", "        ", "key", ",", "val_str", "=", "pair", ".", "split", "(", "\"@\"", ")", "\n", "vals", "=", "[", "]", "\n", "opts", "=", "[", "x", "for", "x", "in", "val_str", ".", "split", "(", "\":\"", ")", "]", "\n", "for", "token", "in", "opts", ":", "\n", "            ", "if", "\",\"", "in", "token", ":", "\n", "                ", "val", "=", "[", "x", "for", "x", "in", "token", ".", "split", "(", "\",\"", ")", "if", "x", "]", "\n", "", "else", ":", "\n", "                ", "val", "=", "token", "\n", "", "vals", ".", "append", "(", "val", ")", "\n", "", "parsed", "[", "key", "]", "=", "vals", "\n", "", "return", "parsed", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_exps.main": [[54, 64], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "generate_exps.parse_grid", "generate_exps.generate_configs"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_exps.parse_grid", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_exps.generate_configs"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--grid'", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "default", "=", "\"configs/msrvtt/only-i3d.json\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "grid", "=", "parse_grid", "(", "args", ".", "grid", ")", "\n", "generate_configs", "(", "\n", "grid", "=", "grid", ",", "\n", "base_config", "=", "args", ".", "config", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.prepare_text_embeddings.prepare_embedding_model": [[43, 63], ["collections.defaultdict", "collections.defaultdict.update", "key.endswith", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update"], ["@", "typechecked", "\n", "def", "prepare_embedding_model", "(", "\n", "embedding_name", ":", "str", ",", "\n", "text_embedding_config", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Union", "[", "str", ",", "int", "]", "]", "]", ",", "\n", ")", "->", "TextEmbedding", ":", "\n", "    ", "conf", "=", "text_embedding_config", "[", "embedding_name", "]", "\n", "for", "key", "in", "conf", ":", "\n", "        ", "if", "key", ".", "endswith", "(", "\"_path\"", ")", ":", "\n", "            ", "conf", "[", "key", "]", "=", "Path", "(", "conf", "[", "key", "]", ")", "\n", "", "", "cls_map", "=", "defaultdict", "(", "lambda", ":", "HuggingFaceWrapper", ")", "\n", "cls_map", ".", "update", "(", "{", "\n", "\"w2v\"", ":", "W2VEmbedding", ",", "\n", "\"grovle\"", ":", "GrOVLE", ",", "\n", "\"mt_grovle\"", ":", "GrOVLE", ",", "\n", "\"hglmm_300d\"", ":", "GrOVLE", ",", "\n", "\"hglmm_6kd\"", ":", "GrOVLE", ",", "\n", "\"howto100m_mil_nce\"", ":", "HowTo100M_MIL_NCE", ",", "\n", "}", ")", "\n", "\n", "return", "cls_map", "[", "embedding_name", "]", "(", "embedding_name", "=", "embedding_name", ",", "**", "conf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.prepare_text_embeddings.validate_embeddings_against_reference": [[65, 91], ["misc.gen_readme.dataset_paths", "[].values", "print", "tqdm.tqdm", "reference_dict.update", "zsvision.zs_utils.memcache", "computed_embeddings.items", "zip", "zsvision.zs_utils.memcache", "len", "len", "zsvision.zs_utils.memcache.items", "reference_dict.items", "len", "len", "numpy.abs().max", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.dataset_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "@", "typechecked", "\n", "def", "validate_embeddings_against_reference", "(", "\n", "computed_embeddings", ":", "Dict", "[", "str", ",", "List", "[", "np", ".", "ndarray", "]", "]", ",", "\n", "embedding_name", ":", "str", ",", "\n", "dataset", ":", "str", ",", "\n", ")", ":", "\n", "    ", "root_feat", ",", "paths", "=", "dataset_paths", "(", "dataset", ")", "\n", "reference_dict", "=", "{", "}", "\n", "for", "path", "in", "paths", "[", "\"text_feat_paths\"", "]", "[", "embedding_name", "]", ".", "values", "(", ")", ":", "\n", "        ", "reference_dict", ".", "update", "(", "memcache", "(", "root_feat", "/", "path", ")", ")", "\n", "\n", "# We handle MSVD as a special case, because video keys != feature keys", "\n", "", "if", "dataset", "==", "\"MSVD\"", ":", "\n", "        ", "key_map", "=", "memcache", "(", "root_feat", "/", "paths", "[", "\"dict_youtube_mapping_path\"", "]", ")", "\n", "inverse_map", "=", "{", "val", ":", "key", "for", "key", ",", "val", "in", "key_map", ".", "items", "(", ")", "}", "\n", "reference_dict", "=", "{", "inverse_map", "[", "key", "]", ":", "val", "for", "key", ",", "val", "in", "reference_dict", ".", "items", "(", ")", "}", "\n", "\n", "", "print", "(", "f\"Validating embeddings against reference....\"", ")", "\n", "for", "key", ",", "val", "in", "tqdm", ".", "tqdm", "(", "computed_embeddings", ".", "items", "(", ")", ")", ":", "\n", "        ", "ref_val", "=", "reference_dict", "[", "key", "]", "\n", "msg", "=", "(", "f\"[{embedding_name}] {key} Different number of \"", "\n", "f\"embeddings {len(ref_val)} vs {len(val)}\"", ")", "\n", "assert", "len", "(", "ref_val", ")", "==", "len", "(", "val", ")", ",", "msg", "\n", "msg", "=", "f\"[{embedding_name}] Embedding mismatch for {key}\"", "\n", "for", "vec", ",", "ref_vec", "in", "zip", "(", "val", ",", "ref_val", ")", ":", "\n", "            ", "assert", "np", ".", "abs", "(", "vec", "-", "ref_vec", ")", ".", "max", "(", ")", "<", "1E-5", ",", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.prepare_text_embeddings.extract_embeddings_for_video": [[93, 115], ["isinstance", "embeddings_for_video.append", "failed_tokens.extend", "isinstance", "model.text2vec", "type", "print"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.HuggingFaceWrapper.text2vec"], ["", "", "", "def", "extract_embeddings_for_video", "(", "\n", "descriptions", ":", "List", "[", "str", "]", ",", "\n", "key", ":", "str", ",", "\n", "model", ",", "\n", ")", "->", "Tuple", "[", "List", "[", "np", ".", "ndarray", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "    ", "embeddings_for_video", ",", "failed_tokens", "=", "[", "]", ",", "[", "]", "\n", "for", "description", "in", "descriptions", ":", "\n", "        ", "msg", "=", "(", "f\"Expected descripton to be a list of string tokens, \"", "\n", "f\" but was {type(description)} instead for {key}\"", ")", "\n", "assert", "isinstance", "(", "description", ",", "List", ")", ",", "msg", "\n", "# msg2 = (f\"for {key} description[0] gives index out of range\")", "\n", "try", ":", "\n", "            ", "assert", "isinstance", "(", "description", "[", "0", "]", ",", "str", ")", ",", "msg", "\n", "description_str", "=", "\" \"", ".", "join", "(", "description", ")", "\n", "embedded", ",", "failed", "=", "model", ".", "text2vec", "(", "description_str", ")", "\n", "", "except", "IndexError", ":", "\n", "# import ipdb; ipdb.set_trace()", "\n", "            ", "print", "(", "key", ")", "\n", "embedded", ",", "failed", "=", "[", "]", ",", "[", "]", "\n", "", "embeddings_for_video", ".", "append", "(", "embedded", ")", "\n", "failed_tokens", ".", "extend", "(", "failed", ")", "\n", "", "return", "embeddings_for_video", ",", "failed_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.prepare_text_embeddings.extract_embeddings": [[117, 222], ["dest_dir.mkdir", "zsvision.zs_utils.memcache", "text_embedding_config[].pop", "torch.device", "prepare_text_embeddings.prepare_embedding_model", "prepare_embedding_model.set_device", "tqdm.tqdm", "print", "print", "open", "json.load", "set", "zsvision.zs_utils.memcache.items", "kwarg_list.append", "ray.remote", "ray.init", "ray.put", "zip", "tqdm.tqdm", "tqdm.tqdm", "len", "len", "numpy.sum", "prepare_text_embeddings.validate_embeddings_against_reference", "zsvision.zs_utils.BlockTimer", "ray.remote.remote", "prepare_text_embeddings.extract_embeddings.to_iterator"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.prepare_text_embeddings.prepare_embedding_model", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.text.LookupEmbedding.set_device", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.prepare_text_embeddings.validate_embeddings_against_reference"], ["", "@", "typechecked", "\n", "def", "extract_embeddings", "(", "\n", "text_embedding_config_path", ":", "Path", ",", "\n", "rel_dest_dir", ":", "Path", ",", "\n", "data_dir", ":", "Path", ",", "\n", "refresh", ":", "bool", ",", "\n", "validate_embeddings", ":", "bool", ",", "\n", "limit", ":", "int", ",", "\n", "processes", ":", "int", ",", "\n", "embedding_name", ":", "str", ",", "\n", "datasets", ":", "List", "[", "str", "]", ",", "\n", "speech_feats", ":", "bool", ",", "\n", ")", ":", "\n", "    ", "for", "dataset", "in", "datasets", ":", "\n", "        ", "if", "speech_feats", ":", "\n", "            ", "dest_dir", "=", "data_dir", "/", "dataset", "/", "\"processing/aggregated_speech\"", "\n", "", "else", ":", "\n", "            ", "dest_dir", "=", "data_dir", "/", "dataset", "/", "rel_dest_dir", "\n", "", "dest_name", "=", "embedding_name", "\n", "if", "limit", ":", "\n", "            ", "dest_name", "=", "f\"{embedding_name}-limit{limit}\"", "\n", "", "dest_path", "=", "dest_dir", "/", "f\"{dest_name}.pkl\"", "\n", "# if dest_path.exists() and not refresh:", "\n", "#     print(f\"Found existing text embeddings at {dest_path}, skipping....\")", "\n", "#     return", "\n", "\n", "dest_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "# handle the activity-net exception", "\n", "if", "dataset", "==", "\"activity-net\"", ":", "\n", "            ", "fname", "=", "\"raw-captions-train-val_1.pkl\"", "\n", "", "elif", "dataset", "==", "\"QuerYDSegments\"", ":", "\n", "            ", "fname", "=", "\"split_raw_captions_filtered.pkl\"", "\n", "", "elif", "dataset", "==", "\"QuerYD\"", ":", "\n", "            ", "fname", "=", "\"raw_captions_combined_filtered.pkl\"", "\n", "", "else", ":", "\n", "            ", "fname", "=", "\"raw-captions.pkl\"", "\n", "", "if", "speech_feats", ":", "\n", "            ", "captions_path", "=", "data_dir", "/", "dataset", "/", "'processing/transcribed_speech.pkl'", "\n", "", "else", ":", "\n", "            ", "captions_path", "=", "data_dir", "/", "dataset", "/", "\"structured-symlinks\"", "/", "fname", "\n", "\n", "# import ipdb; ipdb.set_trace()", "\n", "", "video_descriptions", "=", "memcache", "(", "captions_path", ")", "\n", "with", "open", "(", "text_embedding_config_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "text_embedding_config", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "force_cpu", "=", "text_embedding_config", "[", "embedding_name", "]", ".", "pop", "(", "\"force_cpu\"", ",", "False", ")", "\n", "dev_name", "=", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "0", "and", "not", "force_cpu", "else", "\"cpu\"", "\n", "device", "=", "torch", ".", "device", "(", "dev_name", ")", "\n", "\n", "model", "=", "prepare_embedding_model", "(", "embedding_name", ",", "text_embedding_config", ")", "\n", "model", ".", "set_device", "(", "device", ")", "\n", "if", "limit", ":", "\n", "            ", "keep", "=", "set", "(", "list", "(", "video_descriptions", ".", "keys", "(", ")", ")", "[", ":", "limit", "]", ")", "\n", "video_descriptions", "=", "{", "key", ":", "val", "for", "key", ",", "val", "in", "video_descriptions", ".", "items", "(", ")", "\n", "if", "key", "in", "keep", "}", "\n", "\n", "", "computed_embeddings", "=", "{", "}", "\n", "kwarg_list", "=", "[", "]", "\n", "for", "key", ",", "descriptions", "in", "tqdm", ".", "tqdm", "(", "video_descriptions", ".", "items", "(", ")", ")", ":", "\n", "            ", "kwarg_list", ".", "append", "(", "{", "\"key\"", ":", "key", ",", "\"descriptions\"", ":", "descriptions", "}", ")", "\n", "\n", "", "all_failed_tokens", "=", "[", "]", "\n", "func", "=", "extract_embeddings_for_video", "\n", "if", "processes", ">", "1", ":", "\n", "# Note: An experimental approach with Ray.  Unfortunately, it seems that", "\n", "# the overhead is too great to justify this approach (it's slower than", "\n", "# using a single process). TODO(Samuel): revisit.", "\n", "            ", "func", "=", "ray", ".", "remote", "(", "extract_embeddings_for_video", ")", "\n", "ray", ".", "init", "(", "num_cpus", "=", "processes", ")", "\n", "\n", "# Store model in shared memory object store to avoid multiple copies", "\n", "model_id", "=", "ray", ".", "put", "(", "model", ")", "\n", "\n", "def", "to_iterator", "(", "obj_ids", ")", ":", "\n", "                ", "while", "obj_ids", ":", "\n", "                    ", "done", ",", "obj_ids", "=", "ray", ".", "wait", "(", "obj_ids", ")", "\n", "yield", "ray", ".", "get", "(", "done", "[", "0", "]", ")", "\n", "\n", "", "", "result_ids", "=", "[", "func", ".", "remote", "(", "model", "=", "model_id", ",", "**", "kwargs", ")", "for", "kwargs", "in", "kwarg_list", "]", "\n", "zipped", "=", "zip", "(", "to_iterator", "(", "result_ids", ")", ",", "kwarg_list", ")", "\n", "for", "(", "embeddings", ",", "failed", ")", ",", "kwargs", "in", "tqdm", ".", "tqdm", "(", "zipped", ",", "total", "=", "len", "(", "result_ids", ")", ")", ":", "\n", "                ", "computed_embeddings", "[", "kwargs", "[", "\"key\"", "]", "]", "=", "embeddings", "\n", "all_failed_tokens", ".", "extend", "(", "failed", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "kwargs", "in", "tqdm", ".", "tqdm", "(", "kwarg_list", ")", ":", "\n", "                ", "embeddings_for_video", ",", "failed_tokens", "=", "func", "(", "**", "kwargs", ",", "model", "=", "model", ")", "\n", "computed_embeddings", "[", "kwargs", "[", "\"key\"", "]", "]", "=", "embeddings_for_video", "\n", "all_failed_tokens", ".", "extend", "(", "failed_tokens", ")", "\n", "\n", "", "", "stats", "=", "[", "len", "(", "x", ")", "for", "sublist", "in", "computed_embeddings", ".", "values", "(", ")", "for", "x", "in", "sublist", "]", "\n", "print", "(", "f\"Average num embedding tokens: {np.mean(stats):.1f} tokens\"", ")", "\n", "fail_rate", "=", "len", "(", "all_failed_tokens", ")", "/", "np", ".", "sum", "(", "stats", ")", "\n", "stat_str", "=", "f\"{len(all_failed_tokens)}/{np.sum(stats)} [{100 * fail_rate:.1f}%]\"", "\n", "print", "(", "f\"Failed tokens: {stat_str} tokens\"", ")", "\n", "\n", "if", "validate_embeddings", ":", "\n", "            ", "validate_embeddings_against_reference", "(", "\n", "computed_embeddings", "=", "computed_embeddings", ",", "\n", "embedding_name", "=", "embedding_name", ",", "\n", "dataset", "=", "dataset", ",", "\n", ")", "\n", "", "with", "BlockTimer", "(", "f\"Writing embeddings to {dest_path}\"", ")", ":", "\n", "            ", "with", "open", "(", "dest_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "computed_embeddings", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.prepare_text_embeddings.prepare_text_with_yaspi": [[224, 256], ["utils.util.filter_cmd_args", "list", "yaspi.yaspi.Yaspi", "yaspi.yaspi.Yaspi.submit", "prepare_text_embeddings.extract_embeddings", "embedding_acronyms.append", "itertools.product", "job_queue.append", "len", "x[].upper", "embedding_name.split"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.filter_cmd_args", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.prepare_text_embeddings.extract_embeddings"], ["", "", "", "", "@", "typechecked", "\n", "def", "prepare_text_with_yaspi", "(", "\n", "yaspi_defaults", ":", "Dict", "[", "str", ",", "Union", "[", "str", ",", "int", "]", "]", ",", "\n", "common_kwargs", ":", "Dict", ",", "\n", "datasets", ":", "List", "[", "str", "]", ",", "\n", "embedding_names", ":", "List", "[", "str", "]", ",", "\n", ")", ":", "\n", "    ", "cmd_args", "=", "sys", ".", "argv", "\n", "remove", "=", "[", "\"--yaspify\"", ",", "\"--datasets\"", ",", "\"--embedding_name\"", "]", "\n", "cmd_args", "=", "filter_cmd_args", "(", "cmd_args", ",", "remove", "=", "remove", ")", "\n", "base_cmd", "=", "f\"python {' '.join(cmd_args)} --slurm\"", "\n", "# avoid filename limit", "\n", "embedding_acronyms", "=", "[", "]", "\n", "for", "embedding_name", "in", "embedding_names", ":", "\n", "        ", "acronym", "=", "\"\"", ".", "join", "(", "[", "x", "[", "0", "]", ".", "upper", "(", ")", "for", "x", "in", "embedding_name", ".", "split", "(", "\"-\"", ")", "]", ")", "\n", "embedding_acronyms", ".", "append", "(", "acronym", ")", "\n", "\n", "", "job_name", "=", "f\"prepare-text-{'-'.join(datasets)}-{'-'.join(embedding_acronyms)}\"", "\n", "pairs", "=", "list", "(", "itertools", ".", "product", "(", "embedding_names", ",", "datasets", ")", ")", "\n", "job_queue", "=", "[", "]", "\n", "for", "embedding_name", ",", "dataset", "in", "pairs", ":", "\n", "        ", "job_queue", ".", "append", "(", "f'\"--embedding_name {embedding_name} --datasets {dataset}\"'", ")", "\n", "", "job_queue", "=", "\" \"", ".", "join", "(", "job_queue", ")", "\n", "job", "=", "Yaspi", "(", "\n", "cmd", "=", "base_cmd", ",", "\n", "job_queue", "=", "job_queue", ",", "\n", "job_name", "=", "job_name", ",", "\n", "job_array_size", "=", "len", "(", "pairs", ")", ",", "\n", "**", "yaspi_defaults", ",", "\n", ")", "\n", "job", ".", "submit", "(", "watch", "=", "True", ",", "conserve_resources", "=", "5", ")", "\n", "extract_embeddings", "(", "**", "common_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.prepare_text_embeddings.main": [[258, 354], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "dict", "prepare_text_embeddings.prepare_text_with_yaspi", "prepare_text_embeddings.extract_embeddings", "open", "json.load", "json.load.update", "os.system", "print", "open", "json.load().items", "str", "json.load", "vals.get", "embedding_names.append", "pathlib.Path.home", "socket.gethostname"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.prepare_text_embeddings.prepare_text_with_yaspi", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.prepare_text_embeddings.extract_embeddings", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\"Prepare text embeddings for a given dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "'--refresh'", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "'--limit'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--processes'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "Path", ",", "default", "=", "\"data\"", ",", "\n", "help", "=", "\"the location of the data directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "\"MSVD\"", ",", "\n", "help", "=", "\"the name of the dataset to process\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--datasets\"", ",", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "\"activity-net\"", ",", "\"QuerYD\"", ",", "\"QuerYDSegments\"", ",", "\n", "\"AudioCaps\"", ",", "\"CLOTHO\"", "]", ",", "\n", "help", "=", "\"The datasets to prepare text embeddings for\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--rel_dest_dir\"", ",", "type", "=", "Path", ",", "\n", "default", "=", "\"processing/text_embeddings\"", ",", "\n", "help", "=", "\"the relative path of destination folder\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--embedding_name\"", ",", "type", "=", "str", ",", "default", "=", "\"all-but-slow\"", ",", "\n", "choices", "=", "[", "\n", "\"w2v\"", ",", "\"bert\"", ",", "\"grovle\"", ",", "\"mt_grovle\"", ",", "\n", "\"electra\"", ",", "\"howto100m_mil_nce\"", ",", "\"hglmm_300d\"", ",", "\n", "\"hglmm_6kd\"", ",", "\"openai-gpt\"", ",", "\"gpt2\"", ",", "\"gpt2-medium\"", ",", "\n", "\"gpt2-large\"", ",", "\"gpt2-xl\"", ",", "\"bert-base-uncased\"", ",", "\"t5-small\"", ",", "\n", "\"t5-base\"", ",", "\"t5-large\"", ",", "\"t5-3b\"", ",", "\"t5-11b\"", ",", "\"ctrl\"", ",", "\n", "\"albert-base-v2\"", ",", "\"albert-large-v2\"", ",", "\"albert-xlarge-v2\"", ",", "\n", "\"roberta-base\"", ",", "\"roberta-large\"", ",", "\"xlnet-base-cased\"", ",", "\n", "\"xlnet-large-cased\"", ",", "\"transfo-xl-wt103\"", ",", "\"all\"", ",", "\n", "\"all-but-slow\"", "\n", "]", ",", "\n", "help", "=", "\"the name of the embedding model to prepare\"", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "default", "=", "\"0\"", ",", "help", "=", "\"indices of GPUs to enable\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--yaspify\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"launch via slurm\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--slurm\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_cnodes\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--text_embedding_config_path\"", ",", "type", "=", "Path", ",", "\n", "default", "=", "\"model/text_embedding_models.json\"", ",", "\n", "help", "=", "\"the location of the config file containing the model paths\"", ")", "\n", "parser", ".", "add_argument", "(", "'--validate_embeddings'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If given, compare the embeddings to a reference set\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--yaspi_defaults_path\"", ",", "type", "=", "Path", ",", "\n", "default", "=", "\"misc/yaspi_gpu_defaults.json\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--speech_feats\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"set if embedding of transcribed-speech wanted\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "args", ".", "device", "\n", "\n", "common_kwargs", "=", "dict", "(", "\n", "refresh", "=", "args", ".", "refresh", ",", "\n", "limit", "=", "args", ".", "limit", ",", "\n", "processes", "=", "args", ".", "processes", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "rel_dest_dir", "=", "args", ".", "rel_dest_dir", ",", "\n", "datasets", "=", "args", ".", "datasets", ",", "\n", "embedding_name", "=", "args", ".", "embedding_name", ",", "\n", "text_embedding_config_path", "=", "args", ".", "text_embedding_config_path", ",", "\n", "validate_embeddings", "=", "args", ".", "validate_embeddings", ",", "\n", "speech_feats", "=", "args", ".", "speech_feats", ",", "\n", ")", "\n", "\n", "if", "args", ".", "yaspify", ":", "\n", "        ", "slow_models", "=", "{", "\n", "\"ctrl\"", ",", "\n", "\"t5-3b\"", ",", "\n", "\"t5-11b\"", ",", "\n", "\"xlnet-base-cased\"", ",", "\n", "\"xlnet-large-cased\"", ",", "\n", "\"transfo-xl-wt103\"", ",", "\n", "\"roberta-large\"", ",", "\n", "}", "\n", "with", "open", "(", "args", ".", "yaspi_defaults_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "yaspi_defaults", "=", "json", ".", "load", "(", "f", ")", "\n", "", "if", "args", ".", "use_cnodes", ":", "\n", "            ", "yaspi_defaults", ".", "update", "(", "{", "\"partition\"", ":", "\"compute\"", ",", "\"gpus_per_task\"", ":", "0", "}", ")", "\n", "", "if", "args", ".", "embedding_name", "in", "{", "\"all\"", ",", "\"all-but-slow\"", "}", ":", "\n", "            ", "embedding_names", "=", "[", "]", "\n", "with", "open", "(", "args", ".", "text_embedding_config_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "for", "name", ",", "vals", "in", "json", ".", "load", "(", "f", ")", ".", "items", "(", ")", ":", "\n", "                    ", "if", "args", ".", "embedding_name", "==", "\"all-but-slow\"", ":", "\n", "                        ", "if", "name", "in", "slow_models", ":", "\n", "                            ", "continue", "\n", "", "", "if", "not", "vals", ".", "get", "(", "\"custom_pipeline\"", ",", "False", ")", ":", "\n", "                        ", "embedding_names", ".", "append", "(", "name", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "embedding_names", "=", "[", "args", ".", "embedding_name", "]", "\n", "\n", "", "prepare_text_with_yaspi", "(", "\n", "datasets", "=", "args", ".", "datasets", ",", "\n", "common_kwargs", "=", "common_kwargs", ",", "\n", "yaspi_defaults", "=", "yaspi_defaults", ",", "\n", "embedding_names", "=", "embedding_names", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "slurm", ":", "\n", "            ", "os", ".", "system", "(", "str", "(", "Path", ".", "home", "(", ")", "/", "\"configure_tmp_data.sh\"", ")", ")", "\n", "print", "(", "f\"Preparing embeddings via slurm on {socket.gethostname()}\"", ")", "\n", "", "extract_embeddings", "(", "**", "common_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.sync_experts.get_archive_name": [[23, 36], ["release.startswith", "NotImplementedError"], "function", ["None"], ["@", "typechecked", "\n", "def", "get_archive_name", "(", "dataset", ":", "str", ",", "release", ":", "str", ",", "archive_type", ":", "str", ")", "->", "str", ":", "\n", "    ", "if", "release", ".", "startswith", "(", "\"challenge-release\"", ")", ":", "\n", "        ", "archive_name", "=", "f\"{release}-{dataset}-experts.tar.gz\"", "\n", "", "else", ":", "\n", "        ", "archive_name", "=", "f\"{dataset}-experts-audio-only.tar.gz\"", "\n", "", "if", "archive_type", "==", "\"features\"", ":", "\n", "        ", "pass", "\n", "", "elif", "archive_type", "==", "\"videos\"", ":", "\n", "        ", "archive_name", "=", "f\"{archive_type}-{archive_name}\"", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "f\"Unsupported archive type: {archive_type}\"", ")", "\n", "", "return", "archive_name", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.sync_experts.upload_to_server": [[38, 107], ["subprocess.call", "release.startswith", "zip", "tar_lists.items", "sync_experts.get_archive_name", "time.time", "subprocess.call", "time.strftime", "print", "str", "pathlib.Path", "tar_includes.append", "sync_experts.get_archive_name", "compressed_paths.append", "compressed_path.parent.exists", "compressed_path.parent.mkdir", "print", "time.time", "os.system", "time.strftime", "print", "print", "str", "rsync_args.insert", "time.gmtime", "pathlib.Path().exists", "time.gmtime", "str", "pathlib.Path", "pathlib.Path", "pathlib.Path", "dataset.lower", "str", "time.time", "pathlib.Path", "pathlib.Path", "time.time", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.sync_experts.get_archive_name", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.sync_experts.get_archive_name", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir"], ["", "@", "typechecked", "\n", "def", "upload_to_server", "(", "\n", "web_dir", ":", "Path", ",", "\n", "dataset", ":", "str", ",", "\n", "release", ":", "str", ",", "\n", "webserver", ":", "str", ",", "\n", "refresh", ":", "Dict", "[", "str", ",", "bool", "]", ",", "\n", "experiments", ":", "Path", ",", "\n", ")", ":", "\n", "    ", "server_dir", "=", "web_dir", "/", "\"data\"", "/", "release", "\n", "subprocess", ".", "call", "(", "[", "\"ssh\"", ",", "webserver", ",", "\"mkdir -p\"", ",", "str", "(", "server_dir", ")", "]", ")", "\n", "if", "release", ".", "startswith", "(", "\"challenge-release\"", ")", ":", "\n", "        ", "dataset_dir", "=", "Path", "(", "\"misc/cvpr2020_challenge/datasets\"", ")", "/", "dataset", "\n", "# tar_include = dataset_dir / release / \"tar_include.txt\"", "\n", "tar_lists", "=", "{", "\n", "\"features\"", ":", "\"tar_include.txt\"", ",", "\n", "\"videos\"", ":", "\"video_tar_include.txt\"", ",", "\n", "}", "\n", "tar_includes", ",", "compressed_paths", "=", "[", "]", ",", "[", "]", "\n", "for", "key", ",", "tar_list", "in", "tar_lists", ".", "items", "(", ")", ":", "\n", "            ", "tar_includes", ".", "append", "(", "dataset_dir", "/", "release", "/", "tar_list", ")", "\n", "compressed_file", "=", "get_archive_name", "(", "\n", "dataset", "=", "dataset", ",", "\n", "release", "=", "release", ",", "\n", "archive_type", "=", "key", ",", "\n", ")", "\n", "if", "dataset", "==", "\"activity-net\"", ":", "\n", "                ", "(", "Path", "(", "\"data\"", ")", "/", "\"activity-net-2\"", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "compressed_path", "=", "Path", "(", "f\"data/activity-net-2/webserver-files-audio\"", ")", "/", "compressed_file", "\n", "", "else", ":", "\n", "                ", "compressed_path", "=", "Path", "(", "f\"data/{dataset}/webserver-files-audio\"", ")", "/", "compressed_file", "\n", "", "compressed_paths", ".", "append", "(", "compressed_path", ")", "\n", "", "", "else", ":", "\n", "        ", "tar_includes", "=", "[", "Path", "(", "\"misc/datasets\"", ")", "/", "dataset", ".", "lower", "(", ")", "/", "\"tar_include.txt\"", "]", "\n", "compressed_file", "=", "get_archive_name", "(", "\n", "dataset", "=", "dataset", ",", "\n", "release", "=", "release", ",", "\n", "archive_type", "=", "\"features\"", ",", "\n", ")", "\n", "if", "dataset", "==", "\"activity-net\"", ":", "\n", "            ", "(", "Path", "(", "\"data\"", ")", "/", "\"activity-net-2\"", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "compressed_paths", "=", "[", "Path", "(", "\"data\"", ")", "/", "\"activity-net-2\"", "/", "\"webserver-files-audio\"", "/", "compressed_file", "]", "\n", "", "else", ":", "\n", "            ", "compressed_paths", "=", "[", "Path", "(", "\"data\"", ")", "/", "dataset", "/", "\"webserver-files-audio\"", "/", "compressed_file", "]", "\n", "\n", "", "", "for", "tar_include", ",", "compressed_path", "in", "zip", "(", "tar_includes", ",", "compressed_paths", ")", ":", "\n", "        ", "if", "not", "compressed_path", ".", "parent", ".", "exists", "(", ")", ":", "\n", "            ", "compressed_path", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "", "if", "not", "Path", "(", "compressed_path", ")", ".", "exists", "(", ")", "or", "refresh", "[", "\"compression\"", "]", ":", "\n", "            ", "compression_args", "=", "(", "f\"tar --dereference --create --verbose\"", "\n", "f\" --file={str(compressed_path)}\"", "\n", "f\" --use-compress-program=pigz\"", "\n", "f\" --files-from={tar_include}\"", ")", "\n", "print", "(", "f\"running command {compression_args}\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "os", ".", "system", "(", "compression_args", ")", "\n", "duration", "=", "time", ".", "strftime", "(", "'%Hh%Mm%Ss'", ",", "time", ".", "gmtime", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "print", "(", "f\"Finished tar contents features in {duration}\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"Found existing compressed file at {compressed_path}, skipping....\"", ")", "\n", "\n", "", "dest", "=", "f\"{webserver}:{str(server_dir / compressed_path.name)}\"", "\n", "rsync_args", "=", "[", "\"rsync\"", ",", "\"-av\"", ",", "\"--progress\"", ",", "str", "(", "compressed_path", ")", ",", "dest", "]", "\n", "if", "not", "refresh", "[", "\"server\"", "]", ":", "\n", "            ", "rsync_args", ".", "insert", "(", "1", ",", "\"--ignore-existing\"", ")", "\n", "", "tic", "=", "time", ".", "time", "(", ")", "\n", "subprocess", ".", "call", "(", "rsync_args", ")", "\n", "duration", "=", "time", ".", "strftime", "(", "'%Hh%Mm%Ss'", ",", "time", ".", "gmtime", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "print", "(", "f\"Finished transferring tar file in {duration}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.sync_experts.upload_models_to_robots": [[112, 160], ["json.load.items", "open", "json.load", "sorted", "os.listdir", "os.listdir", "subprocess.call", "subprocess.call", "time.time", "subprocess.call", "time.strftime", "print", "time.time", "subprocess.call", "time.strftime", "print", "time.time", "subprocess.call", "time.strftime", "print", "pathlib.Path", "os.listdir", "str", "time.gmtime", "str", "time.gmtime", "str", "time.gmtime", "pathlib.Path", "str", "str", "str", "str", "pathlib.Path", "pathlib.Path", "time.time", "pathlib.Path", "pathlib.Path", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "", "@", "typechecked", "\n", "def", "upload_models_to_robots", "(", "web_dir", ":", "Path", ",", "experiments", ":", "Path", ",", "\n", "save_dir", ":", "Path", ",", "webserver", ":", "str", ")", ":", "\n", "    ", "with", "open", "(", "experiments", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "experiments", "=", "json", ".", "load", "(", "f", ")", "\n", "", "experiments_items", "=", "experiments", ".", "items", "(", ")", "\n", "server_dir", "=", "web_dir", "/", "\"data\"", "\n", "# import pdb; pdb.set_trace()", "\n", "for", "exp_name", ",", "meta", "in", "experiments_items", ":", "\n", "        ", "group_id", ",", "timestamp", "=", "meta", "\n", "group_id_path", "=", "Path", "(", "save_dir", ")", "/", "\"log\"", "/", "Path", "(", "exp_name", ")", "/", "group_id", "\n", "seed_folders", "=", "sorted", "(", "os", ".", "listdir", "(", "group_id_path", ")", ")", "\n", "for", "seed_folder", "in", "seed_folders", ":", "\n", "            ", "updated_timestamp", "=", "os", ".", "listdir", "(", "group_id_path", "/", "seed_folder", ")", "[", "0", "]", "\n", "files_in_seed_folder", "=", "os", ".", "listdir", "(", "group_id_path", "/", "seed_folder", "/", "updated_timestamp", ")", "\n", "for", "file", "in", "files_in_seed_folder", ":", "\n", "                ", "if", "\".json\"", "in", "file", "and", "\".bak\"", "not", "in", "file", ":", "\n", "                    ", "fname", "=", "file", "\n", "break", "\n", "", "", "rel_path", "=", "Path", "(", "exp_name", ")", "/", "group_id", "/", "seed_folder", "/", "updated_timestamp", "\n", "log_path", "=", "Path", "(", "save_dir", ")", "/", "\"log\"", "/", "rel_path", "/", "fname", "\n", "server_log_path", "=", "server_dir", "/", "\"log\"", "/", "rel_path", "\n", "model_config_path", "=", "server_dir", "/", "\"models\"", "/", "rel_path", "\n", "\n", "subprocess", ".", "call", "(", "[", "\"ssh\"", ",", "webserver", ",", "\"mkdir -p\"", ",", "str", "(", "server_log_path", ")", "]", ")", "\n", "subprocess", ".", "call", "(", "[", "\"ssh\"", ",", "webserver", ",", "\"mkdir -p\"", ",", "str", "(", "model_config_path", ")", "]", ")", "\n", "dest_log", "=", "f\"{webserver}:{str(server_log_path)}\"", "\n", "rsync_args_log", "=", "[", "\"rsync\"", ",", "\"-av\"", ",", "\"--progress\"", ",", "\"--ignore-existing\"", ",", "str", "(", "log_path", ")", ",", "dest_log", "]", "\n", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "subprocess", ".", "call", "(", "rsync_args_log", ")", "\n", "duration", "=", "time", ".", "strftime", "(", "'%Hh%Mm%Ss'", ",", "time", ".", "gmtime", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "print", "(", "f\"Finished transferring log file for experiment {exp_name} in {duration} and {seed_folder}\"", ")", "\n", "\n", "model_path", "=", "Path", "(", "save_dir", ")", "/", "\"models\"", "/", "rel_path", "/", "\"trained_model.pth\"", "\n", "config_path", "=", "Path", "(", "save_dir", ")", "/", "\"models\"", "/", "rel_path", "/", "\"config.json\"", "\n", "\n", "dest_model_config", "=", "f\"{webserver}:{str(model_config_path)}\"", "\n", "rsync_args_model", "=", "[", "\"rsync\"", ",", "\"-av\"", ",", "\"--progress\"", ",", "\"--ignore-existing\"", ",", "str", "(", "model_path", ")", ",", "dest_model_config", "]", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "subprocess", ".", "call", "(", "rsync_args_model", ")", "\n", "duration", "=", "time", ".", "strftime", "(", "'%Hh%Mm%Ss'", ",", "time", ".", "gmtime", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "print", "(", "f\"Finished transferring model for experiment {exp_name} in {duration} and {seed_folder}\"", ")", "\n", "rsync_args_config", "=", "[", "\"rsync\"", ",", "\"-av\"", ",", "\"--progress\"", ",", "\"--ignore-existing\"", ",", "str", "(", "config_path", ")", ",", "dest_model_config", "]", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "subprocess", ".", "call", "(", "rsync_args_config", ")", "\n", "duration", "=", "time", ".", "strftime", "(", "'%Hh%Mm%Ss'", ",", "time", ".", "gmtime", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "print", "(", "f\"Finished transferring config file for experiment {exp_name} in {duration} and {seed_folder}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.sync_experts.fetch_from_server": [[163, 197], ["local_data_dir.mkdir", "sync_experts.get_archive_name", "subprocess.call", "pathlib.Path", "symlinked_feats_dir.exists", "print", "local_archive.exists", "print", "subprocess.call", "print", "str", "local_archive.unlink", "hashlib.sha256().hexdigest", "str", "hashlib.sha256", "access_code.encode"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.sync_experts.get_archive_name"], ["", "", "", "@", "typechecked", "\n", "def", "fetch_from_server", "(", "\n", "dataset", ":", "str", ",", "\n", "root_url", ":", "str", ",", "\n", "purge_tar_file", ":", "bool", ",", "\n", "release", ":", "str", ",", "\n", "refresh", ":", "Dict", "[", "str", ",", "bool", "]", ",", "\n", "access_code", ":", "str", "=", "None", ",", "\n", ")", ":", "\n", "    ", "local_data_dir", "=", "Path", "(", "\"data\"", ")", "/", "dataset", "\n", "symlinked_feats_dir", "=", "local_data_dir", "/", "\"symlinked-feats\"", "\n", "if", "symlinked_feats_dir", ".", "exists", "(", ")", "and", "not", "refresh", "[", "\"symlinked-feats\"", "]", ":", "\n", "        ", "print", "(", "f\"Found symlinked feats at {symlinked_feats_dir}, skipping\"", ")", "\n", "return", "\n", "\n", "", "local_data_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "archive_name", "=", "get_archive_name", "(", "dataset", ",", "release", "=", "release", ",", "archive_type", "=", "\"features\"", ")", "\n", "local_archive", "=", "local_data_dir", "/", "archive_name", "\n", "if", "not", "local_archive", ".", "exists", "(", ")", ":", "\n", "        ", "if", "access_code", ":", "\n", "            ", "access_hash", "=", "hashlib", ".", "sha256", "(", "access_code", ".", "encode", "(", "\"utf-8\"", ")", ")", ".", "hexdigest", "(", ")", "[", ":", "10", "]", "\n", "archive_name", "=", "f\"{access_hash}-{archive_name}\"", "\n", "", "src_url", "=", "f\"{root_url}/{release}/{archive_name}\"", "\n", "wget_args", "=", "[", "\"wget\"", ",", "f\"--output-document={str(local_archive)}\"", ",", "src_url", "]", "\n", "print", "(", "f\"running command: {' '.join(wget_args)}\"", ")", "\n", "subprocess", ".", "call", "(", "wget_args", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "f\"found archive at {local_archive}, skipping...\"", ")", "\n", "\n", "# unpack the archive and optionally clean up", "\n", "", "untar_args", "=", "[", "\"tar\"", ",", "\"-xvf\"", ",", "str", "(", "local_archive", ")", "]", "\n", "subprocess", ".", "call", "(", "untar_args", ")", "\n", "if", "purge_tar_file", ":", "\n", "        ", "local_archive", ".", "unlink", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.sync_experts.main": [[199, 266], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "sync_experts.upload_to_server", "sync_experts.fetch_from_server", "sync_experts.upload_models_to_robots", "ValueError"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.sync_experts.upload_to_server", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.sync_experts.fetch_from_server", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.sync_experts.upload_models_to_robots"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "\"SoundDescs\"", "]", ",", "\n", "choices", "=", "[", "\"activity-net\"", ",", "\"QuerYD\"", ",", "\"QuerYDSegments\"", ",", "\n", "\"AudioCaps\"", ",", "\"CLOTHO\"", ",", "\"SoundDescs\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--action\"", ",", "default", "=", "\"fetch\"", ",", "choices", "=", "[", "\"upload\"", ",", "\"fetch\"", ",", "\"model\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--webserver\"", ",", "default", "=", "\"login.robots.ox.ac.uk\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--refresh_compression\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--refresh_server\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--refresh_symlinked_feats\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--purge_tar_file\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--experiments_path\"", ",", "type", "=", "Path", ",", "default", "=", "\"misc/experiments.json\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_dir\"", ",", "default", "=", "\"data/saved\"", ",", "type", "=", "Path", ")", "\n", "parser", ".", "add_argument", "(", "\"--release\"", ",", "default", "=", "\"features-v2\"", ",", "\n", "choices", "=", "[", "\"features-v2\"", ",", "\"challenge-release-1\"", ",", "\n", "\"challenge-release-2\"", "]", ",", "\n", "help", "=", "(", "\"The features to fetch (features-v2 refers to the features\"", "\n", "\" that can be used to reproduce the collaborative experts\"", "\n", "\"paper\"", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--access_code\"", ",", "help", "=", "\"Code to access LSMDC\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--web_dir\"", ",", "type", "=", "Path", ",", "\n", "default", "=", "\"/projects/vgg/vgg/WWW/research/collaborative-experts\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--root_url\"", ",", "\n", "default", "=", "\"http://www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data\"", ",", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "refresh_targets", "=", "{", "\n", "\"server\"", ":", "args", ".", "refresh_server", ",", "\n", "\"compression\"", ":", "args", ".", "refresh_compression", ",", "\n", "\"symlinked-feats\"", ":", "args", ".", "refresh_symlinked_feats", ",", "\n", "}", "\n", "\n", "for", "dataset", "in", "args", ".", "dataset", ":", "\n", "        ", "if", "dataset", "==", "\"LSMDC\"", ":", "\n", "            ", "msg", "=", "(", "\"To download LSMDC, you must obtain an access code (please see \"", "\n", "\"README.md for details\"", ")", "\n", "assert", "args", ".", "access_code", ",", "msg", "\n", "", "if", "args", ".", "action", "==", "\"upload\"", ":", "\n", "            ", "upload_to_server", "(", "\n", "web_dir", "=", "args", ".", "web_dir", ",", "\n", "dataset", "=", "dataset", ",", "\n", "refresh", "=", "refresh_targets", ",", "\n", "webserver", "=", "args", ".", "webserver", ",", "\n", "release", "=", "args", ".", "release", ",", "\n", "experiments", "=", "args", ".", "experiments_path", ",", "\n", ")", "\n", "", "elif", "args", ".", "action", "==", "\"fetch\"", ":", "\n", "            ", "fetch_from_server", "(", "\n", "dataset", "=", "dataset", ",", "\n", "release", "=", "args", ".", "release", ",", "\n", "root_url", "=", "args", ".", "root_url", ",", "\n", "refresh", "=", "refresh_targets", ",", "\n", "purge_tar_file", "=", "args", ".", "purge_tar_file", ",", "\n", "access_code", "=", "args", ".", "access_code", ",", "\n", ")", "\n", "", "elif", "args", ".", "action", "==", "\"model\"", ":", "\n", "            ", "upload_models_to_robots", "(", "\n", "web_dir", "=", "args", ".", "web_dir", ",", "\n", "experiments", "=", "args", ".", "experiments_path", ",", "\n", "save_dir", "=", "args", ".", "save_dir", ",", "\n", "webserver", "=", "args", ".", "webserver", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"unknown action: {args.action}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_tar_lists.generate_tar_lists": [[16, 80], ["tqdm.tqdm", "all_feat_paths.items", "experiments.items", "set", "gen_readme.dataset_paths", "gen_readme.model_specs2path", "all_feat_paths[].update", "paths[].items", "all_feat_paths[].update", "all_feat_paths[].add", "tar_include_list.parent.mkdir", "exp_name.split", "set", "split_names.append", "set", "all_feat_paths[].add", "set", "all_feat_paths[].update", "tar_include_list.exists", "print", "open", "sorted", "open", "json.load", "x.lower", "feat_aggregation.items", "all_feat_paths[].add", "pathlib.Path", "pathlib.Path", "open", "json.load", "pathlib.Path", "str", "print", "f.write", "[].values", "pathlib.Path", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.dataset_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.model_specs2path", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add"], ["@", "beartype", "\n", "def", "generate_tar_lists", "(", "\n", "save_dir", ":", "Path", ",", "\n", "experiments", ":", "Dict", "[", "str", ",", "Tuple", "[", "str", ",", "str", "]", "]", ",", "\n", "datasets", ":", "List", "[", "str", "]", ",", "\n", "refresh", ":", "bool", ",", "\n", ")", ":", "\n", "    ", "all_feat_paths", "=", "{", "}", "\n", "# import pdb; pdb.set_trace()", "\n", "for", "exp_name", ",", "(", "group_id", ",", "timestamp", ")", "in", "tqdm", ".", "tqdm", "(", "experiments", ".", "items", "(", ")", ")", ":", "\n", "        ", "rel_path", "=", "Path", "(", "group_id", ")", "/", "\"seed-0\"", "/", "timestamp", "/", "\"config.json\"", "\n", "config_path", "=", "Path", "(", "save_dir", ")", "/", "\"models\"", "/", "exp_name", "/", "rel_path", "\n", "try", ":", "\n", "            ", "with", "open", "(", "config_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "config", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "except", "FileNotFoundError", ":", "\n", "            ", "rel_path", "=", "Path", "(", "group_id", ")", "/", "\"seed-1\"", "/", "timestamp", "/", "\"config.json\"", "\n", "config_path", "=", "Path", "(", "save_dir", ")", "/", "\"models\"", "/", "exp_name", "/", "rel_path", "\n", "with", "open", "(", "config_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "config", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "", "feat_aggregation", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"feat_aggregation\"", "]", "\n", "dataset_name", "=", "exp_name", ".", "split", "(", "\"-train\"", ")", "[", "0", "]", "\n", "if", "dataset_name", "not", "in", "[", "x", ".", "lower", "(", ")", "for", "x", "in", "datasets", "]", ":", "\n", "            ", "continue", "\n", "", "if", "dataset_name", "not", "in", "all_feat_paths", ":", "\n", "            ", "all_feat_paths", "[", "dataset_name", "]", "=", "set", "(", ")", "\n", "", "split_names", "=", "[", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"split_name\"", "]", "]", "\n", "if", "\"eval_settings\"", "in", "config", "and", "config", "[", "\"eval_settings\"", "]", ":", "\n", "            ", "test_split", "=", "config", "[", "\"eval_settings\"", "]", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"split_name\"", "]", "\n", "split_names", ".", "append", "(", "test_split", ")", "\n", "", "keep", "=", "set", "(", "config", "[", "\"experts\"", "]", "[", "\"modalities\"", "]", ")", "\n", "text_feat", "=", "config", "[", "\"experts\"", "]", "[", "\"text_feat\"", "]", "\n", "root_feat", ",", "paths", "=", "dataset_paths", "(", "dataset_name", ")", "\n", "modern_feat_agg", "=", "{", "key", ":", "val", "for", "key", ",", "val", "in", "feat_aggregation", ".", "items", "(", ")", "\n", "if", "key", "in", "paths", "[", "\"feature_names\"", "]", "}", "\n", "feat_paths", "=", "model_specs2path", "(", "modern_feat_agg", ",", "keep", ")", "\n", "all_feat_paths", "[", "dataset_name", "]", ".", "update", "(", "{", "root_feat", "/", "x", "for", "x", "in", "feat_paths", "}", ")", "\n", "for", "key", ",", "feat_list", "in", "paths", "[", "\"custom_paths\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "for", "feat_path", "in", "feat_list", ":", "\n", "                ", "all_feat_paths", "[", "dataset_name", "]", ".", "add", "(", "root_feat", "/", "feat_path", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "", "", "text_paths", "=", "[", "root_feat", "/", "paths", "[", "\"text_feat_paths\"", "]", "[", "text_feat", "]", "]", "\n", "all_feat_paths", "[", "dataset_name", "]", ".", "update", "(", "set", "(", "text_paths", ")", ")", "\n", "all_feat_paths", "[", "dataset_name", "]", ".", "add", "(", "root_feat", "/", "paths", "[", "\"raw_captions_path\"", "]", ")", "\n", "if", "\"dict_youtube_mapping_path\"", "in", "paths", ":", "\n", "            ", "all_feat_paths", "[", "dataset_name", "]", ".", "add", "(", "\n", "root_feat", "/", "paths", "[", "\"dict_youtube_mapping_path\"", "]", ")", "\n", "", "for", "split_name", "in", "split_names", ":", "\n", "            ", "split_paths", "=", "set", "(", "root_feat", "/", "x", "for", "x", "in", "\n", "paths", "[", "\"subset_list_paths\"", "]", "[", "split_name", "]", ".", "values", "(", ")", ")", "\n", "all_feat_paths", "[", "dataset_name", "]", ".", "update", "(", "split_paths", ")", "\n", "\n", "", "", "for", "dataset_name", ",", "paths", "in", "all_feat_paths", ".", "items", "(", ")", ":", "\n", "        ", "tar_include_list", "=", "Path", "(", "\"misc\"", ")", "/", "\"datasets\"", "/", "dataset_name", "/", "\"tar_include.txt\"", "\n", "tar_include_list", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "if", "tar_include_list", ".", "exists", "(", ")", "and", "not", "refresh", ":", "\n", "            ", "print", "(", "f\"Found existing tar include list at {tar_include_list}, skipping...\"", ")", "\n", "continue", "\n", "", "with", "open", "(", "tar_include_list", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "path", "in", "sorted", "(", "paths", ")", ":", "\n", "                ", "if", "\"aggregated_speech\"", "not", "in", "str", "(", "path", ")", ":", "\n", "                    ", "print", "(", "f\"Writing {path} to {tar_include_list}\"", ")", "\n", "f", ".", "write", "(", "f\"{path}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_tar_lists.main": [[82, 104], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "gen_tar_lists.generate_tar_lists", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.generate_tar_lists"], ["", "", "", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_dir\"", ",", "default", "=", "\"data/saved\"", ",", "type", "=", "Path", ")", "\n", "parser", ".", "add_argument", "(", "\"--refresh\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--experiments_path\"", ",", "default", "=", "\"misc/experiments.json\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--target\"", ",", "default", "=", "\"main\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "type", "=", "Path", ",", "default", "=", "\"data\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--challenge_phase\"", ",", "default", "=", "\"public_server_val\"", ",", "\n", "choices", "=", "[", "\"public_server_val\"", ",", "\"public_server_test\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\"--datasets\"", ",", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "\"activity-net\"", ",", "\n", "\"QuerYD\"", ",", "\"QuerYDSegments\"", "]", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "with", "open", "(", "args", ".", "experiments_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "experiments", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "generate_tar_lists", "(", "\n", "save_dir", "=", "args", ".", "save_dir", ",", "\n", "datasets", "=", "args", ".", "datasets", ",", "\n", "experiments", "=", "experiments", ",", "\n", "refresh", "=", "args", ".", "refresh", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.find_latest_checkpoints.formatted_summary": [[10, 35], ["print", "sorted", "list", "summary.relative_to", "latest.items", "print", "pathlib.Path().glob", "list", "datetime.datetime.strptime", "datetime.datetime.strptime", "pathlib.Path().glob", "len", "pathlib.Path", "str", "pathlib.Path", "str"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["def", "formatted_summary", "(", "dataset", ",", "exp_root", ",", "fname", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "summaries", "=", "list", "(", "Path", "(", "exp_root", ")", ".", "glob", "(", "f\"**/*{fname}\"", ")", ")", "\n", "summaries", "=", "[", "x", "for", "x", "in", "summaries", "if", "dataset", "in", "str", "(", "x", ")", "]", "\n", "", "except", "FileNotFoundError", ":", "\n", "        ", "fname", "=", "\"summary-seed-1_seed-2_seed-3.json\"", "\n", "summaries", "=", "list", "(", "Path", "(", "exp_root", ")", ".", "glob", "(", "f\"**/*{fname}\"", ")", ")", "\n", "summaries", "=", "[", "x", "for", "x", "in", "summaries", "if", "dataset", "in", "str", "(", "x", ")", "]", "\n", "", "print", "(", "f\"Found {len(summaries)}\"", ")", "\n", "latest", "=", "{", "}", "\n", "time_format", "=", "\"%Y-%m-%d_%H-%M-%S\"", "\n", "for", "summary", "in", "summaries", ":", "\n", "        ", "rel_path", "=", "summary", ".", "relative_to", "(", "exp_root", ")", "\n", "key", ",", "group", ",", "timestamp", "=", "rel_path", ".", "parts", "[", "0", "]", ",", "rel_path", ".", "parts", "[", "1", "]", ",", "rel_path", ".", "parts", "[", "3", "]", "\n", "val", "=", "{", "\"timestamp\"", ":", "timestamp", ",", "\"group\"", ":", "group", "}", "\n", "if", "key", "in", "latest", ":", "\n", "            ", "prev_ts", "=", "datetime", ".", "strptime", "(", "latest", "[", "key", "]", "[", "\"timestamp\"", "]", ",", "time_format", ")", "\n", "curr_ts", "=", "datetime", ".", "strptime", "(", "timestamp", ",", "time_format", ")", "\n", "if", "curr_ts", ">", "prev_ts", ":", "\n", "                ", "latest", "[", "key", "]", "=", "val", "\n", "", "", "else", ":", "\n", "            ", "latest", "[", "key", "]", "=", "val", "\n", "", "", "for", "key", ",", "val", "in", "sorted", "(", "latest", ".", "items", "(", ")", ")", ":", "\n", "        ", "ts", ",", "group", "=", "val", "[", "\"timestamp\"", "]", ",", "val", "[", "\"group\"", "]", "\n", "print", "(", "f'\"{key}\": [\"{group}\", \"{ts}\"],'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.find_latest_checkpoints.main": [[37, 48], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "find_latest_checkpoints.formatted_summary"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.find_latest_checkpoints.formatted_summary"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "default", "=", "\"audiocaps\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--exp_root\"", ",", "default", "=", "\"data/saved/log\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fname\"", ",", "default", "=", "\"summary-seed-0_seed-1_seed-2.json\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "formatted_summary", "(", "\n", "fname", "=", "args", ".", "fname", ",", "\n", "dataset", "=", "args", ".", "dataset", ",", "\n", "exp_root", "=", "args", ".", "exp_root", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.gen_latex_version_of_table": [[34, 86], ["content[].startswith", "list", "pylatex.Tabular", "pylatex.Tabular.add_hline", "pylatex.Tabular.add_hline", "pylatex.Tabular.add_row", "pylatex.Tabular.add_hline", "pylatex.Tabular.dumps", "latex_table_dir.mkdir", "pathlib.Path", "reversed", "x.strip", "col_names[].lower", "col_names.pop", "tuple", "pylatex.Tabular.add_row", "pylatex.Tabular.add_hline", "open", "f.write", "x.strip", "tokens.pop", "re.findall", "row_contents.append", "tuple", "x.startswith", "markdown_table[].split", "range", "re.findall", "pylatex.NoEscape", "reversed", "len", "row.split", "len", "len"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir"], ["@", "typechecked", "\n", "def", "gen_latex_version_of_table", "(", "\n", "latex_table_dir", ":", "Path", ",", "\n", "content", ":", "List", "[", "str", "]", ",", "\n", "table_name", ":", "str", ",", "\n", "branch_name", ":", "str", "=", "\"dev\"", ",", "\n", ")", "->", "Path", ":", "\n", "    ", "msg", "=", "\"Expected latexify tag to be placed directly following a table\"", "\n", "assert", "content", "[", "-", "1", "]", ".", "startswith", "(", "\"|\"", ")", ",", "msg", "\n", "num_table_rows", "=", "[", "x", ".", "startswith", "(", "\"|\"", ")", "for", "x", "in", "reversed", "(", "content", ")", "]", ".", "index", "(", "False", ")", "\n", "assert", "num_table_rows", ">", "2", ",", "\"expected at least three table rows (including header)\"", "\n", "markdown_table", "=", "list", "(", "reversed", "(", "content", "[", "-", "1", ":", "-", "(", "num_table_rows", "+", "1", ")", ":", "-", "1", "]", ")", ")", "\n", "col_names", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "markdown_table", "[", "0", "]", ".", "split", "(", "\"|\"", ")", "[", "1", ":", "-", "1", "]", "]", "\n", "\n", "# remove last column of links", "\n", "remove_links", "=", "col_names", "[", "-", "1", "]", ".", "lower", "(", ")", "==", "\"links\"", "\n", "if", "remove_links", ":", "\n", "        ", "col_names", ".", "pop", "(", ")", "\n", "", "cols", "=", "\"|\"", ".", "join", "(", "[", "\"c\"", "for", "_", "in", "range", "(", "len", "(", "col_names", ")", ")", "]", ")", "\n", "table", "=", "pylatex", ".", "Tabular", "(", "cols", ")", "\n", "table", ".", "add_hline", "(", ")", "\n", "table", ".", "add_hline", "(", ")", "\n", "table", ".", "add_row", "(", "tuple", "(", "col_names", ")", ")", "\n", "table", ".", "add_hline", "(", ")", "\n", "for", "row", "in", "markdown_table", "[", "2", ":", "]", ":", "\n", "        ", "tokens", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "row", ".", "split", "(", "\"|\"", ")", "[", "1", ":", "-", "1", "]", "]", "\n", "if", "remove_links", ":", "\n", "            ", "tokens", ".", "pop", "(", ")", "\n", "", "row_contents", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "mean_regexp", "=", "r\"<sub><sup>([0-9]+[.][0-9]+)<sub>\"", "\n", "# std_regexp = r\"<sub>\\(([0-9]+[.][0-9]+|[a-z]+)\\)<\\/sub>\"", "\n", "std_regexp", "=", "r\"<sub>\\(([0-9]+[.][0-9]+e*-*[0-9]*|[a-z]+|)\\)<\\/sub>\"", "\n", "mean_strs", "=", "re", ".", "findall", "(", "mean_regexp", ",", "token", ")", "\n", "if", "mean_strs", ":", "\n", "                ", "assert", "len", "(", "mean_strs", ")", "==", "1", ",", "\"expected a unique mean specifier\"", "\n", "std_strs", "=", "re", ".", "findall", "(", "std_regexp", ",", "token", ")", "\n", "assert", "len", "(", "std_strs", ")", "==", "1", ",", "\"expected a unique std specifier\"", "\n", "mean_str", ",", "std_str", "=", "mean_strs", "[", "0", "]", ",", "std_strs", "[", "0", "]", "\n", "raw_str", "=", "\"$\"", "+", "mean_str", "+", "r\"_{\\pm\"", "+", "std_str", "+", "r\"}$\"", "\n", "token", "=", "pylatex", ".", "NoEscape", "(", "raw_str", ")", "\n", "", "row_contents", ".", "append", "(", "token", ")", "\n", "", "table", ".", "add_row", "(", "tuple", "(", "row_contents", ")", ")", "\n", "table", ".", "add_hline", "(", ")", "\n", "", "latex_str", "=", "table", ".", "dumps", "(", ")", "\n", "latex_table_dir", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "dest_path", "=", "latex_table_dir", "/", "f\"{table_name}.txt\"", "\n", "with", "open", "(", "dest_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "latex_str", ")", "\n", "", "github_project_root", "=", "f\"/../../tree/{branch_name}/\"", "\n", "markdown_link", "=", "Path", "(", "f\"{github_project_root}{dest_path}\"", ")", "\n", "return", "markdown_link", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.generate_url": [[88, 102], ["str", "pathlib.Path", "pathlib.Path"], "function", ["None"], ["", "@", "typechecked", "\n", "def", "generate_url", "(", "root_url", ":", "str", ",", "target", ":", "str", ",", "\n", "exp_name", ":", "str", ",", "experiments", ":", "Dict", ",", "\n", "fnames", ":", "dict", ",", "seed_folders", ":", "dict", ")", "->", "str", ":", "\n", "    ", "path_store", "=", "{", "\n", "\"log\"", ":", "{", "\"parent\"", ":", "\"log\"", ",", "\"fname\"", ":", "fnames", "[", "exp_name", "]", "}", ",", "\n", "\"log_TT\"", ":", "{", "\"parent\"", ":", "\"logTT\"", ",", "\"fname\"", ":", "fnames", "[", "exp_name", "]", "}", ",", "\n", "\"config\"", ":", "{", "\"parent\"", ":", "\"models\"", ",", "\"fname\"", ":", "\"config.json\"", "}", ",", "\n", "\"model\"", ":", "{", "\"parent\"", ":", "\"models\"", ",", "\"fname\"", ":", "\"trained_model.pth\"", "}", "\n", "}", "\n", "paths", "=", "path_store", "[", "target", "]", "\n", "group_id", ",", "timestamp", "=", "experiments", "[", "exp_name", "]", "\n", "rel_path", "=", "Path", "(", "group_id", ")", "/", "seed_folders", "[", "exp_name", "]", "/", "timestamp", "/", "paths", "[", "\"fname\"", "]", "\n", "return", "str", "(", "Path", "(", "root_url", ")", "/", "paths", "[", "\"parent\"", "]", "/", "exp_name", "/", "rel_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.small_font_str": [[104, 107], ["None"], "function", ["None"], ["", "def", "small_font_str", "(", "tokens", ")", ":", "\n", "    ", "tokens", "=", "[", "f\"<sub><sup>{x}</sup></sub>\"", "for", "x", "in", "tokens", "]", "\n", "return", "\" | \"", ".", "join", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.sync_files": [[109, 136], ["experiments.items", "filetypes.items", "timestamp.startswith", "print", "subprocess.call", "print", "subprocess.call", "pathlib.Path", "pathlib.Path.exists", "str", "pathlib.Path.exists", "str", "str().replace", "str", "str", "pathlib.Path", "pathlib.Path", "pathlib.Path().expanduser", "str", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "def", "sync_files", "(", "experiments", ",", "save_dir", ",", "webserver", ",", "web_dir", ")", ":", "\n", "    ", "filetypes", "=", "{", "\n", "\"log\"", ":", "[", "\"summary-seed-1_seed-2_seed-3.json\"", "]", ",", "\n", "\"log_TT\"", ":", "[", "\"summary-seed-1_seed-2_seed-3.json\"", "]", ",", "\n", "\"models\"", ":", "[", "\"trained_model.pth\"", ",", "\"config.json\"", "]", "\n", "}", "\n", "for", "key", ",", "(", "group_id", ",", "timestamp", ")", "in", "experiments", ".", "items", "(", ")", ":", "\n", "# copy experiment artifacts", "\n", "        ", "for", "filetype", ",", "fnames", "in", "filetypes", ".", "items", "(", ")", ":", "\n", "            ", "for", "fname", "in", "fnames", ":", "\n", "                ", "if", "timestamp", ".", "startswith", "(", "\"TODO\"", ")", ":", "\n", "                    ", "continue", "\n", "", "rel_path", "=", "Path", "(", "group_id", ")", "/", "\"seed-1\"", "/", "timestamp", "/", "fname", "\n", "local_path", "=", "Path", "(", "save_dir", ")", "/", "filetype", "/", "key", "/", "rel_path", "\n", "server_path", "=", "Path", "(", "web_dir", ")", ".", "expanduser", "(", ")", "/", "filetype", "/", "key", "/", "rel_path", "\n", "if", "not", "local_path", ".", "exists", "(", ")", "and", "\"/log/\"", "in", "str", "(", "local_path", ")", ":", "\n", "# try historical logs", "\n", "                    ", "old", ",", "new", "=", "\"/log/\"", ",", "\"/log-includes-some-final-exps/\"", "\n", "local_path", "=", "Path", "(", "str", "(", "local_path", ")", ".", "replace", "(", "old", ",", "new", ")", ")", "\n", "msg", "=", "f\"neither original log nor historical data exist ({local_path})\"", "\n", "assert", "local_path", ".", "exists", "(", ")", ",", "msg", "\n", "", "dest", "=", "f\"{webserver}:{str(server_path)}\"", "\n", "print", "(", "f\"{key} -> {webserver} [{local_path} -> {server_path}]\"", ")", "\n", "subprocess", ".", "call", "(", "[", "\"ssh\"", ",", "webserver", ",", "\"mkdir -p\"", ",", "str", "(", "server_path", ".", "parent", ")", "]", ")", "\n", "rsync_args", "=", "[", "\"rsync\"", ",", "\"-hvrPt\"", ",", "str", "(", "local_path", ")", ",", "dest", "]", "\n", "print", "(", "f\"running command {' '.join(rsync_args)}\"", ")", "\n", "subprocess", ".", "call", "(", "rsync_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.model_specs2path": [[138, 166], ["feat_aggregation.items", "model_spec.split", "aggs[].split", "aggs.get", "feat_paths.append", "feat_type.replace", "aggs.get", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["", "", "", "", "@", "typechecked", "\n", "def", "model_specs2path", "(", "feat_aggregation", ":", "Dict", ",", "keep", ":", "set", ",", "tag", ":", "str", "=", "None", ")", "->", "List", "[", "Path", "]", ":", "\n", "    ", "feat_paths", "=", "[", "]", "\n", "for", "model_spec", ",", "aggs", "in", "feat_aggregation", ".", "items", "(", ")", ":", "\n", "        ", "if", "model_spec", "not", "in", "keep", ":", "\n", "            ", "continue", "\n", "\n", "", "feat_type", ",", "model_name", ",", "_", "=", "model_spec", ".", "split", "(", "\".\"", ")", "\n", "base", "=", "f\"aggregated_{feat_type.replace('-', '_')}\"", "\n", "required", "=", "(", "\"fps\"", ",", "\"pixel_dim\"", ",", "\"stride\"", ")", "\n", "fps", ",", "pixel_dim", ",", "stride", "=", "[", "aggs", ".", "get", "(", "x", ",", "None", ")", "for", "x", "in", "required", "]", "\n", "if", "feat_type", "in", "{", "\"facecrops\"", ",", "\"faceboxes\"", "}", ":", "\n", "            ", "base", "=", "f\"{base}_{fps}fps_{pixel_dim}px_stride{stride}\"", "\n", "", "elif", "feat_type", "not", "in", "{", "\"ocr\"", ",", "\"speech\"", ",", "\"audio\"", ",", "\"pann\"", ",", "\"syncnet\"", ",", "\"vggsound\"", "}", ":", "\n", "            ", "base", "=", "f\"{base}_{fps}fps_{pixel_dim}px_stride{stride}\"", "\n", "\n", "", "for", "option", "in", "\"offset\"", ",", "\"inner_stride\"", ",", "\"num_segments\"", ":", "\n", "            ", "if", "aggs", ".", "get", "(", "option", ",", "None", ")", "is", "not", "None", ":", "\n", "                ", "base", "+=", "f\"_{option}{aggs[option]}\"", "\n", "\n", "", "", "for", "agg", "in", "aggs", "[", "\"temporal\"", "]", ".", "split", "(", "\"-\"", ")", ":", "\n", "            ", "fname", "=", "f\"{model_name}-{agg}\"", "\n", "if", "aggs", "[", "\"type\"", "]", "==", "\"logits\"", ":", "\n", "                ", "fname", "=", "f\"{fname}-logits\"", "\n", "", "if", "tag", "is", "not", "None", ":", "\n", "                ", "fname", "+=", "f\"-{tag}\"", "\n", "", "feat_paths", ".", "append", "(", "Path", "(", "base", ")", "/", "f\"{fname}.pickle\"", ")", "\n", "", "", "return", "feat_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.dataset_paths": [[168, 192], ["importlib.import_module", "getattr", "pathlib.Path", "getattr.", "set", "getattr", "name_map.values"], "function", ["None"], ["", "@", "typechecked", "\n", "def", "dataset_paths", "(", "\n", "dataset", ":", "str", "\n", ")", "->", "Tuple", "[", "Path", ",", "Dict", "[", "str", ",", "Union", "[", "str", ",", "List", "[", "str", "]", ",", "Dict", ",", "Path", "]", "]", "]", ":", "\n", "    ", "name_map", "=", "{", "\n", "\"activity-net\"", ":", "\"ActivityNet\"", ",", "\n", "\"queryd\"", ":", "\"QuerYD\"", ",", "\n", "\"querydsegments\"", ":", "\"QuerYDSegments\"", ",", "\n", "\"clotho\"", ":", "\"CLOTHO\"", ",", "\n", "\"audiocaps\"", ":", "\"AudioCaps\"", "\n", "}", "\n", "if", "dataset", "in", "set", "(", "name_map", ".", "values", "(", ")", ")", ":", "\n", "        ", "class_name", "=", "dataset", "\n", "", "else", ":", "\n", "        ", "class_name", "=", "name_map", "[", "dataset", "]", "\n", "", "mod", "=", "importlib", ".", "import_module", "(", "f\"data_loader.{class_name}_dataset\"", ")", "\n", "get_dataset_paths", "=", "getattr", "(", "getattr", "(", "mod", ",", "class_name", ")", ",", "\"dataset_paths\"", ")", "\n", "if", "dataset", "==", "\"activity-net\"", ":", "\n", "        ", "data_dir", "=", "dataset", "\n", "", "else", ":", "\n", "        ", "data_dir", "=", "class_name", "\n", "", "root_feat", "=", "Path", "(", "f\"data/{data_dir}/structured-symlinks\"", ")", "\n", "paths", "=", "get_dataset_paths", "(", ")", "\n", "return", "root_feat", ",", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.generate_tar_lists": [[194, 238], ["tqdm.tqdm", "all_feat_paths.items", "experiments.items", "set", "gen_readme.dataset_paths", "gen_readme.model_specs2path", "all_feat_paths[].update", "paths[].items", "all_feat_paths[].update", "all_feat_paths[].add", "tar_include_list.parent.mkdir", "open", "json.load", "exp_name.split", "set", "split_names.append", "set", "all_feat_paths[].add", "set", "all_feat_paths[].update", "open", "sorted", "feat_aggregation.items", "all_feat_paths[].add", "[].values", "print", "f.write", "pathlib.Path", "pathlib.Path", "pathlib.Path", "[].values"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.dataset_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.model_specs2path", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.add"], ["", "def", "generate_tar_lists", "(", "save_dir", ",", "experiments", ")", ":", "\n", "    ", "all_feat_paths", "=", "{", "}", "\n", "for", "exp_name", ",", "(", "group_id", ",", "timestamp", ")", "in", "tqdm", ".", "tqdm", "(", "experiments", ".", "items", "(", ")", ")", ":", "\n", "        ", "rel_path", "=", "Path", "(", "group_id", ")", "/", "\"seed-1\"", "/", "timestamp", "/", "\"config.json\"", "\n", "config_path", "=", "Path", "(", "save_dir", ")", "/", "\"models\"", "/", "exp_name", "/", "rel_path", "\n", "with", "open", "(", "config_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "config", "=", "json", ".", "load", "(", "f", ")", "\n", "", "feat_aggregation", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"feat_aggregation\"", "]", "\n", "dataset_name", "=", "exp_name", ".", "split", "(", "\"-train\"", ")", "[", "0", "]", "\n", "if", "dataset_name", "not", "in", "all_feat_paths", ":", "\n", "            ", "all_feat_paths", "[", "dataset_name", "]", "=", "set", "(", ")", "\n", "", "split_names", "=", "[", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"split_name\"", "]", "]", "\n", "if", "\"eval_settings\"", "in", "config", "and", "config", "[", "\"eval_settings\"", "]", ":", "\n", "            ", "test_split", "=", "config", "[", "\"eval_settings\"", "]", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"split_name\"", "]", "\n", "split_names", ".", "append", "(", "test_split", ")", "\n", "", "keep", "=", "set", "(", "config", "[", "\"experts\"", "]", "[", "\"modalities\"", "]", ")", "\n", "text_feat", "=", "config", "[", "\"experts\"", "]", "[", "\"text_feat\"", "]", "\n", "root_feat", ",", "paths", "=", "dataset_paths", "(", "dataset_name", ")", "\n", "modern_feat_agg", "=", "{", "key", ":", "val", "for", "key", ",", "val", "in", "feat_aggregation", ".", "items", "(", ")", "\n", "if", "key", "in", "paths", "[", "\"feature_names\"", "]", "}", "\n", "feat_paths", "=", "model_specs2path", "(", "modern_feat_agg", ",", "keep", ")", "\n", "all_feat_paths", "[", "dataset_name", "]", ".", "update", "(", "{", "root_feat", "/", "x", "for", "x", "in", "feat_paths", "}", ")", "\n", "for", "key", ",", "feat_list", "in", "paths", "[", "\"custom_paths\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "for", "feat_path", "in", "feat_list", ":", "\n", "                ", "all_feat_paths", "[", "dataset_name", "]", ".", "add", "(", "root_feat", "/", "feat_path", ")", "\n", "", "", "text_paths", "=", "[", "root_feat", "/", "rel_path", "for", "rel_path", "in", "\n", "paths", "[", "\"text_feat_paths\"", "]", "[", "text_feat", "]", ".", "values", "(", ")", "]", "\n", "all_feat_paths", "[", "dataset_name", "]", ".", "update", "(", "set", "(", "text_paths", ")", ")", "\n", "all_feat_paths", "[", "dataset_name", "]", ".", "add", "(", "root_feat", "/", "paths", "[", "\"raw_captions_path\"", "]", ")", "\n", "if", "\"dict_youtube_mapping_path\"", "in", "paths", ":", "\n", "            ", "all_feat_paths", "[", "dataset_name", "]", ".", "add", "(", "\n", "root_feat", "/", "paths", "[", "\"dict_youtube_mapping_path\"", "]", ")", "\n", "", "for", "split_name", "in", "split_names", ":", "\n", "            ", "split_paths", "=", "set", "(", "root_feat", "/", "x", "for", "x", "in", "\n", "paths", "[", "\"subset_list_paths\"", "]", "[", "split_name", "]", ".", "values", "(", ")", ")", "\n", "all_feat_paths", "[", "dataset_name", "]", ".", "update", "(", "split_paths", ")", "\n", "\n", "", "", "for", "dataset_name", ",", "paths", "in", "all_feat_paths", ".", "items", "(", ")", ":", "\n", "        ", "tar_include_list", "=", "Path", "(", "\"misc\"", ")", "/", "\"datasets\"", "/", "dataset_name", "/", "\"tar_include.txt\"", "\n", "tar_include_list", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "with", "open", "(", "tar_include_list", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "path", "in", "sorted", "(", "paths", ")", ":", "\n", "                ", "print", "(", "f\"Writing {path} to {tar_include_list}\"", ")", "\n", "f", ".", "write", "(", "f\"{path}\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.parse_geom_means_from_val_runs": [[239, 281], ["scores.items", "zip", "sum", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "subdict.items", "geometric_means.append", "re.search", "row.split", "agg_scores[].append", "scipy.stats.mstats.gmean", "len", "re.search.groups", "re.search.groups", "float", "[].append", "row.split.index"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "", "", "", "@", "typechecked", "\n", "def", "parse_geom_means_from_val_runs", "(", "log", ":", "List", "[", "str", "]", ",", "group", ":", "str", ")", "->", "List", "[", "float", "]", ":", "\n", "    ", "\"\"\"TODO: Samuel - this is redundant due to log_summary() func in log_parser\n    should refactor after deadline.\n    \"\"\"", "\n", "subset", "=", "\"val\"", "\n", "# sanity check, should not be used for experiments with test sets", "\n", "assert", "sum", "(", "[", "\"test_t2v\"", "in", "x", "for", "x", "in", "log", "]", ")", "==", "0", ",", "\"should not parse test runs\"", "\n", "scores", "=", "{", "\n", "\"R1\"", ":", "defaultdict", "(", "list", ")", ",", "\n", "\"R5\"", ":", "defaultdict", "(", "list", ")", ",", "\n", "\"R10\"", ":", "defaultdict", "(", "list", ")", ",", "\n", "}", "\n", "# Regex tag for finding the seed", "\n", "seed_tag", "=", "\"Setting experiment random seed to\"", "\n", "\n", "for", "row", "in", "log", ":", "\n", "        ", "if", "seed_tag", "in", "row", ":", "\n", "# Search for the log file entry describing the current random seed", "\n", "            ", "match", "=", "re", ".", "search", "(", "seed_tag", "+", "\" (\\d+)$\"", ",", "row", ")", "# NOQA", "\n", "assert", "len", "(", "match", ".", "groups", "(", ")", ")", "==", "1", ",", "\"expected a single regex match\"", "\n", "current_seed", "=", "match", ".", "groups", "(", ")", "[", "0", "]", "\n", "\n", "", "if", "f\"{subset}_{group}_metrics\"", "in", "row", ":", "\n", "            ", "tokens", "=", "row", ".", "split", "(", "\" \"", ")", "\n", "for", "key", "in", "scores", ":", "\n", "                ", "tag", "=", "f\"{subset}_{group}_metrics_{key}:\"", "\n", "if", "tag", "in", "tokens", ":", "\n", "                    ", "pos", "=", "tokens", ".", "index", "(", "tag", ")", "+", "1", "\n", "val", "=", "tokens", "[", "pos", "]", "\n", "val", "=", "float", "(", "val", ")", "\n", "assert", "current_seed", "is", "not", "None", ",", "\"failed to determine the seed\"", "\n", "scores", "[", "key", "]", "[", "current_seed", "]", ".", "append", "(", "val", ")", "\n", "# keep last score", "\n", "", "", "", "", "agg_scores", "=", "{", "key", ":", "[", "]", "for", "key", "in", "scores", "}", "\n", "for", "metric", ",", "subdict", "in", "scores", ".", "items", "(", ")", ":", "\n", "        ", "for", "seed", ",", "values", "in", "subdict", ".", "items", "(", ")", ":", "\n", "            ", "agg_scores", "[", "metric", "]", ".", "append", "(", "values", "[", "-", "1", "]", ")", "\n", "", "", "geometric_means", "=", "[", "]", "\n", "for", "r1", ",", "r5", ",", "r10", "in", "zip", "(", "agg_scores", "[", "\"R1\"", "]", ",", "agg_scores", "[", "\"R5\"", "]", ",", "agg_scores", "[", "\"R10\"", "]", ")", ":", "\n", "        ", "geometric_means", ".", "append", "(", "scipy", ".", "stats", ".", "mstats", ".", "gmean", "(", "[", "r1", ",", "r5", ",", "r10", "]", ")", ")", "\n", "", "return", "geometric_means", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.parse_log": [[283, 334], ["open", "f.read().splitlines", "collections.OrderedDict", "[].item", "zip", "sum", "row.replace.replace", "row.replace.split", "len", "len", "numpy.std", "round", "round", "[].replace", "int", "f.read", "sum", "ValueError", "float", "float", "float", "len", "print", "sum", "any", "gen_readme.parse_geom_means_from_val_runs", "numpy.mean", "numpy.where", "len", "[].replace", "tokens[].split", "row.replace.split", "len", "str", "x.split"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.parse_geom_means_from_val_runs"], ["", "def", "parse_log", "(", "log_path", ")", ":", "\n", "# import pdb; pdb.set_trace()", "\n", "    ", "with", "open", "(", "log_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "log", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "results", "=", "{", "}", "\n", "for", "group", "in", "{", "\"t2v\"", ",", "\"v2t\"", "}", ":", "\n", "        ", "tag", "=", "f\"[{group}] loaded log file\"", "\n", "results", "[", "group", "]", "=", "OrderedDict", "(", ")", "\n", "presence", "=", "[", "tag", "in", "row", "for", "row", "in", "log", "]", "\n", "msg", "=", "f\"expected single occurence of log tag, found {sum(presence)} in {log_path}\"", "\n", "assert", "sum", "(", "presence", ")", "==", "1", ",", "msg", "\n", "metrics", "=", "[", "\"R1\"", ",", "\"R5\"", ",", "\"R10\"", ",", "\"R50\"", ",", "\"MedR\"", ",", "\"MeanR\"", "]", "\n", "pos", "=", "np", ".", "where", "(", "presence", ")", "[", "0", "]", ".", "item", "(", ")", "\n", "if", "\"fixed training length\"", "in", "log", "[", "pos", "+", "2", "]", ":", "\n", "            ", "pos", "+=", "3", "\n", "", "else", ":", "\n", "            ", "pos", "+=", "2", "\n", "", "rows", "=", "log", "[", "pos", ":", "pos", "+", "len", "(", "metrics", ")", "]", "\n", "for", "row", ",", "metric", "in", "zip", "(", "rows", ",", "metrics", ")", ":", "\n", "            ", "row", "=", "row", ".", "replace", "(", "\"INFO:summary:\"", ",", "\"\"", ")", "\n", "tokens", "=", "row", ".", "split", "(", "\" \"", ")", "\n", "if", "tokens", "[", "-", "3", "]", "!=", "f\"{metric}:\"", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Unexpteced log format [{row}]\"", ")", "\n", "", "assert", "tokens", "[", "-", "3", "]", "==", "f\"{metric}:\"", ",", "f\"unexpected row format {row}\"", "\n", "mean", ",", "std", "=", "float", "(", "tokens", "[", "-", "2", "]", ".", "split", "(", "\",\"", ")", "[", "0", "]", ")", ",", "float", "(", "tokens", "[", "-", "1", "]", ")", "\n", "results", "[", "group", "]", "[", "metric", "]", "=", "(", "mean", ",", "std", ")", "\n", "# geometric means are recomputed from summaries", "\n", "", "tag", "=", "f\"test_{group}_metrics_geometric_mean\"", "\n", "nan_tag", "=", "\"INFO:summary:R1: nan\"", "\n", "matches", "=", "[", "x", "for", "x", "in", "log", "if", "tag", "in", "x", "]", "\n", "if", "len", "(", "matches", ")", "in", "{", "1", ",", "2", ",", "3", "}", ":", "\n", "            ", "geoms", "=", "[", "float", "(", "x", ".", "split", "(", ")", "[", "-", "1", "]", ".", "replace", "(", "\"INFO:summary:\"", ",", "\"\"", ")", ")", "for", "x", "in", "matches", "]", "\n", "if", "len", "(", "matches", ")", "<", "3", ":", "\n", "                ", "print", "(", "f\"WARNING: Getting stds from {len(matches)} runs for {log_path}!\"", ")", "\n", "", "", "elif", "sum", "(", "[", "nan_tag", "in", "x", "for", "x", "in", "log", "]", ")", ">", "0", ":", "\n", "            ", "geoms", "=", "[", "np", ".", "nan", ",", "np", ".", "nan", ",", "np", ".", "nan", "]", "\n", "", "else", ":", "\n", "            ", "valid_exceptions", "=", "[", "\"miechfeats-moee\"", ",", "\"miech-ce\"", ",", "\"jsfusion\"", "]", "\n", "msg", "=", "f\"Did not expect fixed length training for {log_path}\"", "\n", "assert", "any", "(", "[", "x", "in", "str", "(", "log_path", ")", "for", "x", "in", "valid_exceptions", "]", ")", ",", "msg", "\n", "geoms", "=", "parse_geom_means_from_val_runs", "(", "log", ",", "group", "=", "group", ")", "\n", "", "if", "len", "(", "geoms", ")", "==", "1", ":", "\n", "            ", "std", "=", "np", ".", "nan", "\n", "", "else", ":", "\n", "            ", "std", "=", "np", ".", "std", "(", "geoms", ")", "\n", "", "results", "[", "group", "]", "[", "\"geom\"", "]", "=", "(", "round", "(", "np", ".", "mean", "(", "geoms", ")", ",", "1", ")", ",", "round", "(", "std", ",", "1", ")", ")", "\n", "", "for", "row", "in", "log", ":", "\n", "        ", "if", "\"Trainable parameters\"", "in", "row", ":", "\n", "            ", "param_token", "=", "row", ".", "split", "(", "\" \"", ")", "[", "-", "1", "]", ".", "replace", "(", "\"INFO:summary:\"", ",", "\"\"", ")", "\n", "results", "[", "\"params\"", "]", "=", "int", "(", "param_token", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.multiprocessing_parsing": [[335, 364], ["timestamp.startswith", "print", "os.path.exists", "os.listdir", "gen_readme.parse_log", "open", "pickle.dump", "print", "sorted", "pathlib.Path", "aggregate_logs_and_stats.summarise", "os.listdir", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.parse_log", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.aggregate_logs_and_stats.summarise"], ["", "@", "typechecked", "\n", "def", "multiprocessing_parsing", "(", "exp_name", ":", "str", ",", "meta", ":", "list", ",", "\n", "save_dir", ":", "Path", ",", "refresh_summaries", ":", "bool", ",", "teachText", ":", "bool", ",", "pickle_files", ":", "str", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "Path", "(", "save_dir", ")", "/", "pickle_files", "/", "f'log_results_{exp_name}.pkl'", ")", "is", "False", "or", "refresh_summaries", "is", "True", ":", "\n", "        ", "group_id", ",", "timestamp", "=", "meta", "\n", "_log_path", "=", "\"log\"", "\n", "# if teachText:", "\n", "#     _log_path = \"log\"", "\n", "if", "timestamp", ".", "startswith", "(", "\"TODO\"", ")", ":", "\n", "            ", "log_results", "[", "exp_name", "]", "=", "{", "\"timestamp\"", ":", "\"TODO\"", ",", "\"results\"", ":", "{", "}", "}", "\n", "", "else", ":", "\n", "            ", "seed_folder", "=", "sorted", "(", "os", ".", "listdir", "(", "Path", "(", "save_dir", ")", "/", "_log_path", "/", "Path", "(", "exp_name", ")", "/", "group_id", ")", ")", "[", "0", "]", "\n", "files_in_seed_folder", "=", "os", ".", "listdir", "(", "Path", "(", "save_dir", ")", "/", "_log_path", "/", "Path", "(", "exp_name", ")", "/", "group_id", "/", "seed_folder", "/", "Path", "(", "timestamp", ")", ")", "\n", "for", "file", "in", "files_in_seed_folder", ":", "\n", "                ", "if", "\".json\"", "in", "file", "and", "\".bak\"", "not", "in", "file", ":", "\n", "                    ", "fname", "=", "file", "\n", "break", "\n", "", "", "rel_fname", "=", "Path", "(", "timestamp", ")", "/", "fname", "\n", "rel_path", "=", "Path", "(", "exp_name", ")", "/", "group_id", "/", "seed_folder", "/", "rel_fname", "\n", "log_path", "=", "Path", "(", "save_dir", ")", "/", "_log_path", "/", "rel_path", "\n", "if", "refresh_summaries", ":", "\n", "                ", "summarise", "(", "group_id", "=", "group_id", ",", "log_dir", "=", "Path", "(", "save_dir", ")", "/", "_log_path", ")", "\n", "", "results", "=", "parse_log", "(", "log_path", ")", "\n", "log_results", "=", "{", "\"timestamp\"", ":", "timestamp", ",", "\"results\"", ":", "results", "}", "\n", "", "with", "open", "(", "Path", "(", "save_dir", ")", "/", "pickle_files", "/", "f'log_results_{exp_name}.pkl'", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "[", "log_results", ",", "fname", ",", "seed_folder", "]", ",", "f", ")", "\n", "print", "(", "f\"Saved experiment {exp_name}\"", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "f\"Experiment log_results_{exp_name}.pkl already saved\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.parse_results": [[365, 412], ["time.time", "experiments.items", "print", "os.path.exists", "os.mkdir", "gen_readme.multiprocessing_parsing", "open", "pickle.load", "pathlib.Path", "pathlib.Path", "time.time", "open", "pickle.dump", "open", "pickle.dump", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.multiprocessing_parsing"], ["", "", "@", "typechecked", "\n", "def", "parse_results", "(", "\n", "experiments", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "\n", "save_dir", ":", "Path", ",", "\n", "refresh_summaries", ":", "bool", ",", "\n", "teachText", ":", "bool", ",", "\n", ")", "->", "(", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "Union", "[", "str", ",", "Dict", "]", "]", "]", ",", "\n", "dict", ",", "dict", ")", ":", "\n", "    ", "starttime", "=", "time", ".", "time", "(", ")", "\n", "processes", "=", "[", "]", "\n", "experiments_items", "=", "experiments", ".", "items", "(", ")", "\n", "pickle_files", "=", "\"pickle_files\"", "\n", "if", "teachText", ":", "\n", "        ", "pickle_files", "=", "\"pickle_files_teachText\"", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "Path", "(", "save_dir", ")", "/", "pickle_files", ")", "is", "False", ":", "\n", "        ", "os", ".", "mkdir", "(", "Path", "(", "save_dir", ")", "/", "pickle_files", ")", "\n", "# for exp_name, meta in experiments_items:", "\n", "#     p = multiprocessing.Process(target=multiprocessing_parsing,", "\n", "#                                 args=(exp_name, meta,", "\n", "#                                       save_dir, refresh_summaries, teachText, pickle_files))", "\n", "#     processes.append(p)", "\n", "#     p.start()", "\n", "# for process in processes:", "\n", "#     process.join()", "\n", "", "for", "exp_name", ",", "meta", "in", "experiments_items", ":", "\n", "# import pdb; pdb.set_trace()", "\n", "        ", "multiprocessing_parsing", "(", "exp_name", ",", "meta", ",", "save_dir", ",", "refresh_summaries", ",", "teachText", ",", "pickle_files", ")", "\n", "", "print", "(", "'That took {} seconds'", ".", "format", "(", "time", ".", "time", "(", ")", "-", "starttime", ")", ")", "\n", "log_results", "=", "{", "}", "\n", "fnames", "=", "{", "}", "\n", "seed_folders", "=", "{", "}", "\n", "for", "exp_name", ",", "_", "in", "experiments_items", ":", "\n", "        ", "with", "open", "(", "Path", "(", "save_dir", ")", "/", "pickle_files", "/", "f'log_results_{exp_name}.pkl'", ",", "\n", "'rb'", ")", "as", "f", ":", "\n", "            ", "log_results", "[", "exp_name", "]", ",", "fnames", "[", "exp_name", "]", ",", "seed_folders", "[", "exp_name", "]", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "if", "not", "teachText", ":", "\n", "            ", "with", "open", "(", "Path", "(", "save_dir", ")", "/", "'log_results2.pkl'", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "[", "log_results", ",", "fnames", ",", "seed_folders", "]", ",", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "with", "open", "(", "Path", "(", "save_dir", ")", "/", "'log_results_teachText.pkl'", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "[", "log_results", ",", "fnames", ",", "seed_folders", "]", ",", "f", ")", "\n", "\n", "\n", "\n", "", "", "", "return", "log_results", ",", "fnames", ",", "seed_folders", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.generate_results_string": [[414, 432], ["print", "stats.items", "gen_readme.small_font_str", "print", "tokens.append", "str_tokens.insert"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.small_font_str"], ["", "def", "generate_results_string", "(", "target", ",", "exp_name", ",", "results", ",", "latexify", ",", "drop", "=", "None", ")", ":", "\n", "    ", "stats", "=", "results", "[", "exp_name", "]", "[", "\"results\"", "]", "[", "target", "]", "\n", "print", "(", "f\"Filling template values for {exp_name}\"", ")", "\n", "tokens", "=", "[", "]", "\n", "prepad", "=", "False", "\n", "for", "metric", ",", "values", "in", "stats", ".", "items", "(", ")", ":", "\n", "        ", "mean", ",", "std", "=", "values", "\n", "if", "drop", "and", "metric", "in", "drop", ":", "\n", "            ", "continue", "\n", "", "print", "(", "f\"{metric}: {mean} ({std})\"", ")", "\n", "if", "latexify", ":", "\n", "            ", "str_tokens", "=", "[", "\"&$\"", ",", "f\"{mean}_{{\\\\pm{std}}}$\"", "]", "\n", "if", "prepad", ":", "\n", "                ", "str_tokens", ".", "insert", "(", "1", ",", "r\"\\prepad\"", ")", "\n", "", "tokens", ".", "append", "(", "\" \"", ".", "join", "(", "str_tokens", ")", ")", "\n", "", "else", ":", "\n", "            ", "tokens", "+=", "[", "f\"{mean}<sub>({std})</sub>\"", "]", "\n", "", "", "return", "small_font_str", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.generate_readme": [[434, 550], ["zip", "open", "f.read().splitlines", "re.finditer", "re.finditer", "generated.append", "match.groups", "groups[].split", "full_readme.extend", "full_readme.append", "match.groups", "groups[].split", "target.startswith", "edits.append", "itertools.zip_longest", "open", "f.write", "open", "f.write", "f.read", "len", "open", "f.read().splitlines", "subrow.replace.replace", "subrow.replace.replace", "len", "gen_readme.gen_latex_version_of_table", "str", "src_name.upper", "dest_name.upper", "subrows.append", "match.span", "zip", "f.read", "subrow.replace.replace", "gen_readme.generate_url", "len", "print", "gen_readme.generate_results_string", "target.split", "gen_readme.generate_results_string", "target.split", "millify.millify"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.gen_latex_version_of_table", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.generate_url", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.generate_results_string", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.generate_results_string"], ["", "def", "generate_readme", "(", "\n", "experiments", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "\n", "root_url", ":", "str", ",", "\n", "readme_templates", ":", "List", "[", "Path", "]", ",", "\n", "readme_dests", ":", "List", "[", "Path", "]", ",", "\n", "results_path", ":", "Path", ",", "\n", "latex_table_dir", ":", "Path", ",", "\n", "save_dir", ":", "Path", ",", "\n", "latexify", ":", "bool", ",", "\n", "keep_mnr", ":", "bool", ",", "\n", "refresh_summaries", ":", "bool", ",", "\n", "results", ":", "Dict", ",", "\n", "fnames", ":", "Dict", ",", "\n", "seed_folders", ":", "Dict", ",", "\n", "append_to_existing_readme", ":", "bool", ",", "\n", ")", ":", "\n", "    ", "for", "readme_template", ",", "readme_dest", "in", "zip", "(", "readme_templates", ",", "readme_dests", ")", ":", "\n", "        ", "with", "open", "(", "readme_template", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "readme", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "# insert sub-templates", "\n", "", "full_readme", "=", "[", "]", "\n", "for", "row", "in", "readme", ":", "\n", "            ", "regex", "=", "r\"\\<\\<(.*?)\\>\\>\"", "\n", "matched", "=", "False", "\n", "for", "match", "in", "re", ".", "finditer", "(", "regex", ",", "row", ")", ":", "\n", "                ", "matched", "=", "True", "\n", "groups", "=", "match", ".", "groups", "(", ")", "\n", "assert", "len", "(", "groups", ")", "==", "1", ",", "\"expected single group\"", "\n", "subtemplate_path", ",", "src_name", ",", "dest_name", "=", "groups", "[", "0", "]", ".", "split", "(", "\":\"", ")", "\n", "with", "open", "(", "subtemplate_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                    ", "subtemplate", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "subrows", "=", "[", "]", "\n", "for", "subrow", "in", "subtemplate", ":", "\n", "                    ", "drop_subrow", "=", "False", "\n", "subrow", "=", "subrow", ".", "replace", "(", "src_name", ",", "dest_name", ")", "\n", "subrow", "=", "subrow", ".", "replace", "(", "src_name", ".", "upper", "(", ")", ",", "dest_name", ".", "upper", "(", ")", ")", "\n", "# Handle the missing audio modalities of MSVD", "\n", "if", "dest_name", "==", "\"msvd\"", ":", "\n", "                        ", "for", "tag", "in", "(", "\"speech\"", ",", "\"audio\"", ")", ":", "\n", "# drop experiments for which the audio/speech features form", "\n", "# the control variable", "\n", "                            ", "if", "f\"-{tag}.\"", "in", "subrow", ":", "\n", "                                ", "print", "(", "\"skipping\"", ",", "subrow", ")", "\n", "drop_subrow", "=", "True", "\n", "break", "\n", "# remove audio features from other experiments", "\n", "", "subrow", "=", "subrow", ".", "replace", "(", "f\"-{tag}\"", ",", "\"\"", ")", "\n", "\n", "", "", "if", "not", "drop_subrow", ":", "\n", "                        ", "subrows", ".", "append", "(", "subrow", ")", "\n", "", "", "full_readme", ".", "extend", "(", "subrows", ")", "\n", "", "if", "not", "matched", ":", "\n", "                ", "full_readme", ".", "append", "(", "row", ")", "\n", "\n", "", "", "generated", "=", "[", "]", "\n", "for", "row", "in", "full_readme", ":", "\n", "            ", "edits", "=", "[", "]", "\n", "regex", "=", "r\"\\{\\{(.*?)\\}\\}\"", "\n", "for", "match", "in", "re", ".", "finditer", "(", "regex", ",", "row", ")", ":", "\n", "                ", "groups", "=", "match", ".", "groups", "(", ")", "\n", "assert", "len", "(", "groups", ")", "==", "1", ",", "\"expected single group\"", "\n", "exp_name", ",", "target", "=", "groups", "[", "0", "]", ".", "split", "(", "\".\"", ")", "\n", "if", "target", ".", "startswith", "(", "\"latexify\"", ")", ":", "\n", "                    ", "latex_link", "=", "gen_latex_version_of_table", "(", "\n", "content", "=", "generated", "[", ":", "]", ",", "\n", "table_name", "=", "exp_name", ",", "\n", "latex_table_dir", "=", "latex_table_dir", ",", "\n", ")", "\n", "token", "=", "f\"[latex]({latex_link}) | | | | | | | |\"", "\n", "", "elif", "results", "[", "exp_name", "]", "[", "\"timestamp\"", "]", "==", "\"TODO\"", ":", "\n", "                    ", "token", "=", "\"TODO\"", "\n", "", "elif", "target", "in", "{", "\"config\"", ",", "\"model\"", ",", "\"log\"", ",", "\"log_TT\"", "}", ":", "\n", "                    ", "token", "=", "generate_url", "(", "root_url", ",", "target", ",", "exp_name", ",", "\n", "experiments", "=", "experiments", ",", "\n", "fnames", "=", "fnames", ",", "\n", "seed_folders", "=", "seed_folders", ")", "\n", "", "elif", "target", "in", "{", "\"t2v\"", ",", "\"v2t\"", ",", "\"geomt2v\"", ",", "\"geomv2t\"", "}", ":", "\n", "                    ", "if", "not", "\"geom\"", "in", "target", ":", "\n", "                        ", "drop", "=", "{", "\"geom\"", "}", "\n", "", "else", ":", "\n", "                        ", "drop", "=", "{", "}", "\n", "", "target_", "=", "target", ".", "split", "(", "\"geom\"", ")", "[", "-", "1", "]", "\n", "token", "=", "generate_results_string", "(", "target_", ",", "exp_name", ",", "results", ",", "\n", "drop", "=", "drop", ",", "latexify", "=", "latexify", ")", "\n", "", "elif", "target", "in", "{", "\"short-t2v\"", ",", "\"short-v2t\"", "}", ":", "\n", "                    ", "if", "keep_mnr", ":", "\n", "                        ", "drop", "=", "{", "\"R50\"", ",", "\"geom\"", "}", "\n", "", "else", ":", "\n", "                        ", "drop", "=", "{", "\"R50\"", ",", "\"MeanR\"", ",", "\"geom\"", "}", "\n", "", "target_", "=", "target", ".", "split", "(", "\"-\"", ")", "[", "1", "]", "\n", "token", "=", "generate_results_string", "(", "target_", ",", "exp_name", ",", "results", ",", "\n", "drop", "=", "drop", ",", "latexify", "=", "latexify", ")", "\n", "", "elif", "target", "in", "{", "\"params\"", "}", ":", "\n", "                    ", "token", "=", "millify", "(", "results", "[", "exp_name", "]", "[", "\"results\"", "]", "[", "\"params\"", "]", ",", "precision", "=", "2", ")", "\n", "\n", "", "edits", ".", "append", "(", "(", "match", ".", "span", "(", ")", ",", "token", ")", ")", "\n", "", "if", "edits", ":", "\n", "# invert the spans", "\n", "                ", "spans", "=", "[", "(", "None", ",", "0", ")", "]", "+", "[", "x", "[", "0", "]", "for", "x", "in", "edits", "]", "+", "[", "(", "len", "(", "row", ")", ",", "None", ")", "]", "\n", "inverse_spans", "=", "[", "(", "x", "[", "1", "]", ",", "y", "[", "0", "]", ")", "for", "x", ",", "y", "in", "zip", "(", "spans", ",", "spans", "[", "1", ":", "]", ")", "]", "\n", "tokens", "=", "[", "row", "[", "start", ":", "stop", "]", "for", "start", ",", "stop", "in", "inverse_spans", "]", "\n", "urls", "=", "[", "str", "(", "x", "[", "1", "]", ")", "for", "x", "in", "edits", "]", "\n", "new_row", "=", "\"\"", "\n", "for", "token", ",", "url", "in", "zip_longest", "(", "tokens", ",", "urls", ",", "fillvalue", "=", "\"\"", ")", ":", "\n", "                    ", "new_row", "+=", "token", "+", "url", "\n", "", "row", "=", "new_row", "\n", "\n", "", "generated", ".", "append", "(", "row", ")", "\n", "\n", "", "if", "not", "append_to_existing_readme", ":", "\n", "            ", "with", "open", "(", "readme_dest", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "generated", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "with", "open", "(", "readme_dest", ",", "\"a\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "generated", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.parse_generate_readme": [[553, 621], ["gen_readme.parse_results", "gen_readme.generate_readme", "open", "json.dump", "gen_readme.parse_results", "gen_readme.generate_readme", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.parse_results", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.generate_readme", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.parse_results", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.generate_readme"], ["", "", "", "", "def", "parse_generate_readme", "(", "\n", "experiments", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "\n", "root_url", ":", "str", ",", "\n", "readme_templates", ":", "List", "[", "Path", "]", ",", "\n", "readme_dests", ":", "List", "[", "Path", "]", ",", "\n", "results_path", ":", "Path", ",", "\n", "latex_table_dir", ":", "Path", ",", "\n", "save_dir", ":", "Path", ",", "\n", "latexify", ":", "bool", ",", "\n", "keep_mnr", ":", "bool", ",", "\n", "refresh_summaries", ":", "bool", ",", "\n", "drop_experiments_hq", ":", "bool", ",", "\n", "results_path_teachText", ":", "Path", ",", "\n", "experiments_teachText", ":", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ",", "\n", "teachText_template", ":", "Path", ",", "\n", ")", ":", "\n", "\n", "    ", "results", ",", "fnames", ",", "seed_folders", "=", "parse_results", "(", "experiments", "=", "experiments", ",", "\n", "save_dir", "=", "save_dir", ",", "\n", "refresh_summaries", "=", "refresh_summaries", ",", "\n", "teachText", "=", "False", ",", "\n", ")", "\n", "\n", "append_to_existing_readme", "=", "False", "\n", "with", "open", "(", "results_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "results", ",", "f", ",", "indent", "=", "4", ",", "sort_keys", "=", "False", ")", "\n", "\n", "", "if", "not", "drop_experiments_hq", ":", "\n", "        ", "results_teachText", ",", "fnames_teachText", ",", "seed_folders_teachText", "=", "parse_results", "(", "experiments", "=", "experiments_teachText", ",", "\n", "save_dir", "=", "save_dir", ",", "\n", "refresh_summaries", "=", "refresh_summaries", ",", "\n", "teachText", "=", "True", ",", "\n", ")", "\n", "with", "open", "(", "results_path_teachText", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "results", ",", "f", ",", "indent", "=", "4", ",", "sort_keys", "=", "False", ")", "\n", "\n", "", "generate_readme", "(", "experiments", "=", "experiments_teachText", ",", "\n", "root_url", "=", "root_url", ",", "\n", "readme_templates", "=", "[", "teachText_template", "]", ",", "\n", "readme_dests", "=", "readme_dests", ",", "\n", "results_path", "=", "results_path_teachText", ",", "\n", "latex_table_dir", "=", "latex_table_dir", ",", "\n", "save_dir", "=", "save_dir", ",", "\n", "latexify", "=", "latexify", ",", "\n", "keep_mnr", "=", "keep_mnr", ",", "\n", "refresh_summaries", "=", "refresh_summaries", ",", "\n", "results", "=", "results_teachText", ",", "\n", "fnames", "=", "fnames_teachText", ",", "\n", "seed_folders", "=", "seed_folders_teachText", ",", "\n", "append_to_existing_readme", "=", "False", ",", "\n", ")", "\n", "\n", "append_to_existing_readme", "=", "True", "\n", "\n", "", "generate_readme", "(", "experiments", "=", "experiments", ",", "\n", "root_url", "=", "root_url", ",", "\n", "readme_templates", "=", "readme_templates", ",", "\n", "readme_dests", "=", "readme_dests", ",", "\n", "results_path", "=", "results_path", ",", "\n", "latex_table_dir", "=", "latex_table_dir", ",", "\n", "save_dir", "=", "save_dir", ",", "\n", "latexify", "=", "latexify", ",", "\n", "keep_mnr", "=", "keep_mnr", ",", "\n", "refresh_summaries", "=", "refresh_summaries", ",", "\n", "results", "=", "results", ",", "\n", "fnames", "=", "fnames", ",", "\n", "seed_folders", "=", "seed_folders", ",", "\n", "append_to_existing_readme", "=", "append_to_existing_readme", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.main": [[624, 706], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "open", "json.load", "open", "json.load", "gen_readme.sync_files", "gen_readme.parse_generate_readme"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.sync_files", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.gen_readme.parse_generate_readme"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_dir\"", ",", "default", "=", "\"data/saved\"", ",", "type", "=", "Path", ")", "\n", "parser", ".", "add_argument", "(", "\"--webserver\"", ",", "default", "=", "\"login.robots.ox.ac.uk\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--results_path\"", ",", "default", "=", "\"misc/results.json\"", ",", "type", "=", "Path", ")", "\n", "parser", ".", "add_argument", "(", "\"--results_path_teachText\"", ",", "default", "=", "\"misc/results_teachText.json\"", ",", "type", "=", "Path", ")", "\n", "parser", ".", "add_argument", "(", "\"--experiments_path\"", ",", "default", "=", "\"misc/experiments.json\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--experiments_teachText\"", ",", "default", "=", "\"misc/experiments_teachText.json\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--readme_template\"", ",", "default", "=", "\"misc/README-template.md\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--teachText_template\"", ",", "default", "=", "\"misc/README-teachText.md\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--latexify\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--drop_experiments_hq\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--keep_mnr\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--refresh_summaries\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--readme_dest\"", ",", "default", "=", "\"README.md\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--latex_table_dir\"", ",", "default", "=", "\"latex-tables\"", ",", "type", "=", "Path", ")", "\n", "parser", ".", "add_argument", "(", "\"--ablation_readme_dest\"", ",", "default", "=", "\"misc/ablations.md\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--challenge_readme_dest\"", ",", "default", "=", "\"misc/challenge.md\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ablation_readme_template\"", ",", "\n", "default", "=", "\"misc/ablations-template.md\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--challenge_readme_template\"", ",", "\n", "default", "=", "\"misc/README-challenge-template.md\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task\"", ",", "default", "=", "\"generate_readme\"", ",", "\n", "choices", "=", "[", "\"sync_files\"", ",", "\"generate_readme\"", "]", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--web_dir\"", ",", "\n", "default", "=", "\"/projects/vgg/vgg/WWW/research/collaborative-experts/data\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--root_url\"", ",", "\n", "default", "=", "\"http://www.robots.ox.ac.uk/~vgg/research/collaborative-experts/data\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--only_one_readme\"", ",", "action", "=", "\"store_true\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "with", "open", "(", "args", ".", "experiments_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "experiments", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "with", "open", "(", "args", ".", "experiments_teachText", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "experiments_teachText", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "args", ".", "task", "==", "\"sync_files\"", ":", "\n", "        ", "sync_files", "(", "\n", "web_dir", "=", "args", ".", "web_dir", ",", "\n", "save_dir", "=", "args", ".", "save_dir", ",", "\n", "webserver", "=", "args", ".", "webserver", ",", "\n", "experiments", "=", "experiments", ",", "\n", ")", "\n", "", "elif", "args", ".", "task", "==", "\"generate_readme\"", ":", "\n", "        ", "readme_dests", "=", "[", "\n", "args", ".", "readme_dest", ",", "\n", "args", ".", "ablation_readme_dest", ",", "\n", "args", ".", "challenge_readme_dest", ",", "\n", "]", "\n", "readme_templates", "=", "[", "\n", "args", ".", "readme_template", ",", "\n", "args", ".", "ablation_readme_template", ",", "\n", "args", ".", "challenge_readme_template", ",", "\n", "]", "\n", "if", "args", ".", "only_one_readme", "is", "True", ":", "\n", "            ", "readme_dests", "=", "[", "\n", "args", ".", "readme_dest", ",", "\n", "]", "\n", "", "readme_templates", "=", "[", "\n", "args", ".", "readme_template", ",", "\n", "]", "\n", "\n", "parse_generate_readme", "(", "\n", "root_url", "=", "args", ".", "root_url", ",", "\n", "save_dir", "=", "args", ".", "save_dir", ",", "\n", "latexify", "=", "args", ".", "latexify", ",", "\n", "experiments", "=", "experiments", ",", "\n", "latex_table_dir", "=", "args", ".", "latex_table_dir", ",", "\n", "keep_mnr", "=", "args", ".", "keep_mnr", ",", "\n", "readme_dests", "=", "readme_dests", ",", "\n", "results_path", "=", "args", ".", "results_path", ",", "\n", "readme_templates", "=", "readme_templates", ",", "\n", "refresh_summaries", "=", "args", ".", "refresh_summaries", ",", "\n", "drop_experiments_hq", "=", "args", ".", "drop_experiments_hq", ",", "\n", "results_path_teachText", "=", "args", ".", "results_path_teachText", ",", "\n", "experiments_teachText", "=", "experiments_teachText", ",", "\n", "teachText_template", "=", "args", ".", "teachText_template", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.fill_template": [[31, 56], ["open", "f.read().splitlines", "re.finditer", "generated.append", "match.groups", "edits.append", "itertools.zip_longest", "f.read", "len", "str", "match.span", "zip", "len"], "function", ["None"], ["def", "fill_template", "(", "template_path", ",", "rules", ")", ":", "\n", "    ", "generated", "=", "[", "]", "\n", "with", "open", "(", "template_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "template", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "for", "row", "in", "template", ":", "\n", "        ", "edits", "=", "[", "]", "\n", "regex", "=", "r\"\\{\\{(.*?)\\}\\}\"", "\n", "for", "match", "in", "re", ".", "finditer", "(", "regex", ",", "row", ")", ":", "\n", "            ", "groups", "=", "match", ".", "groups", "(", ")", "\n", "assert", "len", "(", "groups", ")", "==", "1", ",", "\"expected single group\"", "\n", "key", "=", "groups", "[", "0", "]", "\n", "token", "=", "rules", "[", "key", "]", "\n", "edits", ".", "append", "(", "(", "match", ".", "span", "(", ")", ",", "token", ")", ")", "\n", "", "if", "edits", ":", "\n", "# invert the spans", "\n", "            ", "spans", "=", "[", "(", "None", ",", "0", ")", "]", "+", "[", "x", "[", "0", "]", "for", "x", "in", "edits", "]", "+", "[", "(", "len", "(", "row", ")", ",", "None", ")", "]", "\n", "inverse_spans", "=", "[", "(", "x", "[", "1", "]", ",", "y", "[", "0", "]", ")", "for", "x", ",", "y", "in", "zip", "(", "spans", ",", "spans", "[", "1", ":", "]", ")", "]", "\n", "tokens", "=", "[", "row", "[", "start", ":", "stop", "]", "for", "start", ",", "stop", "in", "inverse_spans", "]", "\n", "urls", "=", "[", "str", "(", "x", "[", "1", "]", ")", "for", "x", "in", "edits", "]", "\n", "new_row", "=", "\"\"", "\n", "for", "token", ",", "url", "in", "zip_longest", "(", "tokens", ",", "urls", ",", "fillvalue", "=", "\"\"", ")", ":", "\n", "                ", "new_row", "+=", "token", "+", "url", "\n", "", "row", "=", "new_row", "\n", "", "generated", ".", "append", "(", "row", ")", "\n", "", "return", "\"\\n\"", ".", "join", "(", "generated", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.parse_group_ids": [[58, 67], ["collections.OrderedDict", "enumerate", "cmd.split", "group_ids[].append", "cmd.split.index"], "function", ["None"], ["", "def", "parse_group_ids", "(", "parsed_cmds", ")", ":", "\n", "    ", "group_ids", "=", "OrderedDict", "(", ")", "\n", "for", "ii", ",", "cmd", "in", "enumerate", "(", "parsed_cmds", ")", ":", "\n", "        ", "tokens", "=", "cmd", ".", "split", "(", "\" \"", ")", "\n", "group_id", "=", "tokens", "[", "tokens", ".", "index", "(", "\"--group_id\"", ")", "+", "1", "]", "\n", "if", "group_id", "not", "in", "group_ids", ":", "\n", "            ", "group_ids", "[", "group_id", "]", "=", "[", "]", "\n", "", "group_ids", "[", "group_id", "]", ".", "append", "(", "ii", "+", "1", ")", "# slurm arrays are 1-indexed", "\n", "", "return", "group_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.generate_slurm_dependency_script": [[69, 82], ["aggregation_scripts.items", "generate_slurm_scripts.fill_template", "deps.append", "str"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.fill_template"], ["", "def", "generate_slurm_dependency_script", "(", "group_ids", ",", "dependency_template", ",", "aggregation_scripts", ",", "\n", "generated_script_paths", ")", ":", "\n", "    ", "deps", "=", "[", "]", "\n", "for", "group_id", ",", "aggregation_script", "in", "aggregation_scripts", ".", "items", "(", ")", ":", "\n", "        ", "array_id_list", "=", "group_ids", "[", "group_id", "]", "\n", "array_deps", "=", "\":\"", ".", "join", "(", "[", "f\"${{job_id}}_{x}\"", "for", "x", "in", "array_id_list", "]", ")", "\n", "dep", "=", "f\"sbatch --dependency=afterok:{array_deps} {aggregation_script}\"", "\n", "deps", ".", "append", "(", "dep", ")", "\n", "", "rules", "=", "{", "\n", "\"dependencies\"", ":", "\"\\n\"", ".", "join", "(", "deps", ")", ",", "\n", "\"job_script_path\"", ":", "str", "(", "generated_script_paths", "[", "\"array-job\"", "]", ")", ",", "\n", "}", "\n", "return", "fill_template", "(", "template_path", "=", "dependency_template", ",", "rules", "=", "rules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.jobn_name2agg_log_path": [[84, 86], ["pathlib.Path"], "function", ["None"], ["", "def", "jobn_name2agg_log_path", "(", "exp_dir", ",", "job_name", ")", ":", "\n", "    ", "return", "Path", "(", "exp_dir", ")", "/", "\"data/slurm\"", "/", "job_name", "/", "\"log.txt\"", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.generate_aggregation_script": [[88, 95], ["generate_slurm_scripts.aggregation_script_path2job_name", "generate_slurm_scripts.jobn_name2agg_log_path", "jobn_name2agg_log_path.parent.mkdir", "generate_slurm_scripts.fill_template"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.aggregation_script_path2job_name", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.jobn_name2agg_log_path", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.fill_template"], ["", "def", "generate_aggregation_script", "(", "exp_dir", ",", "group_id", ",", "aggregation_template", ",", "\n", "aggregation_script_path", ")", ":", "\n", "    ", "job_name", "=", "aggregation_script_path2job_name", "(", "aggregation_script_path", ")", "\n", "log_path", "=", "jobn_name2agg_log_path", "(", "exp_dir", ",", "job_name", ")", "\n", "log_path", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "rules", "=", "{", "\"job-name\"", ":", "job_name", ",", "\"group_id\"", ":", "group_id", ",", "\"log-path\"", ":", "log_path", "}", "\n", "return", "fill_template", "(", "template_path", "=", "aggregation_template", ",", "rules", "=", "rules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.aggregation_script_path2job_name": [[97, 100], ["None"], "function", ["None"], ["", "def", "aggregation_script_path2job_name", "(", "aggregation_script_path", ")", ":", "\n", "    ", "job_name", "=", "f\"{aggregation_script_path.parent.stem}-{aggregation_script_path.stem}\"", "\n", "return", "job_name", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.generate_script": [[101, 198], ["len", "generate_slurm_scripts.parse_group_ids", "zip", "generated_script_paths.update", "array_log_path.parent.mkdir", "range", "aggregation_scripts.values", "zip", "print", "generated_script_paths.items", "open", "f.read().splitlines", "parsed.extend", "config.replace", "arg_list.replace.replace().replace().replace", "arg_list.replace.replace", "pathlib.Path", "watched_logs[].append", "watched_logs[].append", "generate_slurm_scripts.aggregation_script_path2job_name", "generate_slurm_scripts.jobn_name2agg_log_path", "watched_logs[].append", "watched_logs[].append", "jobn_name2agg_log_path.parent.mkdir", "open", "f.write", "dest_path.parent.mkdir", "utils.util.parse_grid", "pathlib.Path", "pathlib.Path", "parsed[].split", "pathlib.Path", "generated_script_paths.items", "pathlib.Path", "str().replace", "jobn_name2agg_log_path.exists", "print", "jobn_name2agg_log_path.touch", "generate_slurm_scripts.fill_template", "open", "print", "f.write", "f.read", "arg_list.replace.replace().replace", "pathlib.Path", "open", "f.write", "str", "generate_slurm_scripts.generate_aggregation_script", "str", "str", "str", "generate_slurm_scripts.generate_slurm_dependency_script", "arg_list.replace.replace", "str"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.parse_group_ids", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.aggregation_script_path2job_name", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.jobn_name2agg_log_path", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_exps.parse_grid", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.fill_template", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.generate_aggregation_script", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.generate_slurm_dependency_script"], ["", "def", "generate_script", "(", "template_path", ",", "slurm_script_dir", ",", "job_queue", ",", "exp_dir", ",", "\n", "monitor_script", ",", "constraints", ",", "dependency_template", ",", "\n", "aggregation_template", ")", ":", "\n", "\n", "    ", "with", "open", "(", "job_queue", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "custom_args", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "# remove blank lines", "\n", "", "custom_args", "=", "[", "x", "for", "x", "in", "custom_args", "if", "x", "]", "\n", "parsed", "=", "[", "]", "\n", "for", "line", "in", "custom_args", ":", "\n", "        ", "parsed", ".", "extend", "(", "parse_grid", "(", "line", ")", ")", "\n", "", "num_array_workers", "=", "len", "(", "parsed", ")", "\n", "\n", "if", "Path", "(", "job_queue", ")", ".", "stem", "!=", "\"latest\"", ":", "\n", "        ", "array_job_name", "=", "Path", "(", "job_queue", ")", ".", "stem", "\n", "", "else", ":", "\n", "        ", "config", "=", "parsed", "[", "0", "]", ".", "split", "(", "\" \"", ")", "[", "1", "]", "\n", "array_job_name", "=", "config", ".", "replace", "(", "\"/\"", ",", "\"-\"", ")", "\n", "\n", "", "generated_script_paths", "=", "{", "\n", "\"main\"", ":", "\"slurm-dependencies.sh\"", ",", "\n", "\"array-job\"", ":", "\"slurm-job.sh\"", ",", "\n", "\"backup\"", ":", "f\"{array_job_name}.sh\"", ",", "\n", "}", "\n", "group_ids", "=", "parse_group_ids", "(", "parsed", ")", "\n", "generated_script_paths", "=", "{", "key", ":", "Path", "(", "slurm_script_dir", ")", "/", "val", "\n", "for", "key", ",", "val", "in", "generated_script_paths", ".", "items", "(", ")", "}", "\n", "\n", "aggregation_scripts", "=", "{", "}", "\n", "for", "group_id", ",", "arg_list", "in", "zip", "(", "group_ids", ",", "custom_args", ")", ":", "\n", "        ", "arg_list", "=", "arg_list", ".", "replace", "(", "\"--\"", ",", "\"\"", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ".", "replace", "(", "\".json\"", ",", "\"\"", ")", "\n", "arg_list", "=", "arg_list", ".", "replace", "(", "\"|\"", ",", "\"_\"", ")", "\n", "fname", "=", "f\"{array_job_name}-{arg_list}_agg_{group_id}.sh\"", "\n", "path", "=", "Path", "(", "slurm_script_dir", ")", "/", "fname", "\n", "aggregation_scripts", "[", "group_id", "]", "=", "path", "\n", "", "generated_script_paths", ".", "update", "(", "aggregation_scripts", ")", "\n", "\n", "# worker logs", "\n", "array_log_path", "=", "Path", "(", "exp_dir", ")", "/", "\"data/slurm\"", "/", "array_job_name", "/", "\"%4a-log.txt\"", "\n", "array_log_path", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "watched_logs", "=", "{", "\"paths\"", ":", "[", "]", ",", "\"dividers\"", ":", "[", "]", "}", "\n", "\n", "for", "idx", "in", "range", "(", "num_array_workers", ")", ":", "\n", "        ", "slurm_id", "=", "idx", "+", "1", "\n", "watched_log", "=", "Path", "(", "str", "(", "array_log_path", ")", ".", "replace", "(", "\"%4a\"", ",", "f\"{slurm_id:04d}\"", ")", ")", "\n", "msg", "=", "f\">>  START OF NEW JOB [{idx}/{num_array_workers}] <<\\n\"", "\n", "watched_logs", "[", "\"paths\"", "]", ".", "append", "(", "watched_log", ")", "\n", "watched_logs", "[", "\"dividers\"", "]", ".", "append", "(", "msg", ")", "\n", "\n", "", "for", "aggregation_script_path", "in", "aggregation_scripts", ".", "values", "(", ")", ":", "\n", "        ", "job_name", "=", "aggregation_script_path2job_name", "(", "aggregation_script_path", ")", "\n", "watched_log", "=", "jobn_name2agg_log_path", "(", "exp_dir", ",", "job_name", ")", "\n", "watched_logs", "[", "\"paths\"", "]", ".", "append", "(", "watched_log", ")", "\n", "watched_logs", "[", "\"dividers\"", "]", ".", "append", "(", "f\">>  STARTING AGGREGATION job [{job_name}] <<\\n\"", ")", "\n", "\n", "", "for", "watched_log", ",", "divider", "in", "zip", "(", "watched_logs", "[", "\"paths\"", "]", ",", "watched_logs", "[", "\"dividers\"", "]", ")", ":", "\n", "        ", "watched_log", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "if", "not", "watched_log", ".", "exists", "(", ")", ":", "\n", "            ", "print", "(", "f\"Creating watch log: {watched_log} for the first time\"", ")", "\n", "watched_log", ".", "touch", "(", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "str", "(", "watched_log", ")", ",", "\"a\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "divider", ")", "\n", "\n", "", "", "", "with", "open", "(", "monitor_script", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "cmd", "=", "f\"watchlogs {','.join([str(x) for x in watched_logs['paths']])}\"", "\n", "f", ".", "write", "(", "f\"{cmd}\\n\"", ")", "\n", "", "print", "(", "f\"Watching logs: {','.join(watched_logs)}\"", ")", "\n", "for", "script_name", ",", "dest_path", "in", "generated_script_paths", ".", "items", "(", ")", ":", "\n", "        ", "dest_path", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "if", "script_name", "in", "{", "\"array-job\"", ",", "\"backup\"", "}", ":", "\n", "            ", "rules", "=", "{", "\n", "\"job-name\"", ":", "array_job_name", ",", "\n", "\"job_queue\"", ":", "\" \"", ".", "join", "(", "[", "f'\"{x}\"'", "for", "x", "in", "parsed", "]", ")", ",", "\n", "\"constraints\"", ":", "constraints", ",", "\n", "\"array-range\"", ":", "f\"1-{num_array_workers}\"", ",", "\n", "\"log-path\"", ":", "str", "(", "array_log_path", ")", ",", "\n", "\n", "}", "\n", "script", "=", "fill_template", "(", "template_path", ",", "rules", ")", "\n", "", "elif", "script_name", "in", "aggregation_scripts", ":", "\n", "            ", "script", "=", "generate_aggregation_script", "(", "\n", "exp_dir", "=", "exp_dir", ",", "\n", "group_id", "=", "script_name", ",", "\n", "aggregation_script_path", "=", "dest_path", ",", "\n", "aggregation_template", "=", "aggregation_template", ",", "\n", ")", "\n", "", "elif", "script_name", "==", "\"main\"", ":", "\n", "            ", "script", "=", "generate_slurm_dependency_script", "(", "\n", "group_ids", "=", "group_ids", ",", "\n", "generated_script_paths", "=", "generated_script_paths", ",", "\n", "aggregation_scripts", "=", "aggregation_scripts", ",", "\n", "dependency_template", "=", "dependency_template", ",", "\n", ")", "\n", "", "with", "open", "(", "str", "(", "dest_path", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "print", "(", "f\"Writing slurm script ({script_name}) to {dest_path}\"", ")", "\n", "f", ".", "write", "(", "script", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.main": [[200, 225], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "generate_slurm_scripts.generate_script"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.generate_slurm_scripts.generate_script"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--job_queue\"", ",", "default", "=", "\"data/job-queues/latest.txt\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--slurm_script_dir\"", ",", "default", "=", "\"data/slurm/scripts\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--slurm_template\"", ",", "default", "=", "\"misc/slurm/gpu-template_v2.sh\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dependency_template\"", ",", "default", "=", "\"misc/slurm/dependencies.sh\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--aggregation_template\"", ",", "\n", "default", "=", "\"misc/slurm/aggregate-logs-and-stats.sh\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--constraints\"", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--exp_dir\"", ",", "\n", "#default=\"/users/albanie/coding/libs/pt/collaborative-experts\")", "\n", "# default=\"/users/ioana/collaborative-experts-internal/collaborative-experts-internal\")", "\n", "default", "=", "\"/scratch/shared/beegfs/oncescu/shared-datasets/QuerYD/collaborative\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "monitor_script", "=", "f\"slurm/monitor-jobs.sh\"", "\n", "generate_script", "(", "\n", "exp_dir", "=", "args", ".", "exp_dir", ",", "\n", "job_queue", "=", "args", ".", "job_queue", ",", "\n", "monitor_script", "=", "monitor_script", ",", "\n", "template_path", "=", "args", ".", "slurm_template", ",", "\n", "slurm_script_dir", "=", "args", ".", "slurm_script_dir", ",", "\n", "dependency_template", "=", "args", ".", "dependency_template", ",", "\n", "aggregation_template", "=", "args", ".", "aggregation_template", ",", "\n", "constraints", "=", "args", ".", "constraints", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.aggregate_logs_and_stats.summarise": [[14, 62], ["sorted", "print", "collections.OrderedDict", "collections.OrderedDict.items", "print", "config_path.exists", "utils.util.read_json", "logging.getLogger", "logging.basicConfig", "logger.log_parser.log_summary", "list", "len", "list", "summary_log.extend", "list", "open", "f.write", "first_info_log.relative_to", "logging.root.removeHandler", "logging.getLogger.addHandler", "pathlib.Path().glob", "pathlib.Path().glob", "len", "open", "f.read().splitlines", "collections.OrderedDict.values", "pathlib.Path", "logging.StreamHandler", "len", "len", "list", "pathlib.Path", "pathlib.Path", "f.read", "collections.OrderedDict.keys"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.read_json", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.logger.log_parser.log_summary", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["def", "summarise", "(", "group_id", ",", "log_dir", "=", "\"data/saved/log\"", ",", "model_dir", "=", "\"data/saved/models\"", ")", ":", "\n", "    ", "seeded_runs", "=", "sorted", "(", "list", "(", "Path", "(", "log_dir", ")", ".", "glob", "(", "f\"**/{group_id}/seed-*\"", ")", ")", ")", "\n", "print", "(", "f\"Found a total of {len(seeded_runs)} seed runs in {group_id}\"", ")", "\n", "msg", "=", "f\"Found no seeded runs for group_id: {group_id} in {log_dir}\"", "\n", "assert", "len", "(", "seeded_runs", ")", ">", "0", ",", "msg", "\n", "\n", "info_logs", "=", "OrderedDict", "(", ")", "\n", "for", "seeded_run", "in", "seeded_runs", ":", "\n", "        ", "info_log_matches", "=", "list", "(", "Path", "(", "seeded_run", ")", ".", "glob", "(", "\"**/info.log\"", ")", ")", "\n", "msg", "=", "f\"expected to find a single info.log file, found {len(info_log_matches)}\"", "\n", "assert", "len", "(", "info_log_matches", ")", "==", "1", ",", "msg", "\n", "info_logs", "[", "seeded_run", ".", "stem", "]", "=", "info_log_matches", "[", "0", "]", "\n", "\n", "", "summary_log", "=", "[", "]", "\n", "for", "seeded_run", ",", "info_log_path", "in", "info_logs", ".", "items", "(", ")", ":", "\n", "        ", "with", "open", "(", "info_log_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "log", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "summary_log", ".", "extend", "(", "log", ")", "\n", "", "first_info_log", "=", "list", "(", "info_logs", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "summary_log_name", "=", "f\"summary-{'_'.join(list(info_logs.keys()))}.json\"", "\n", "summary_log_path", "=", "first_info_log", ".", "parent", "/", "summary_log_name", "\n", "with", "open", "(", "summary_log_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "\"\\n\"", ".", "join", "(", "summary_log", ")", ")", "\n", "", "print", "(", "f\"Wrote concatenated logs to {summary_log_path}\"", ")", "\n", "\n", "# retrieve the config from the first run", "\n", "rel_path", "=", "first_info_log", ".", "relative_to", "(", "log_dir", ")", ".", "parent", "\n", "config_path", "=", "Path", "(", "model_dir", ")", "/", "rel_path", "/", "\"config.json\"", "\n", "assert", "config_path", ".", "exists", "(", ")", ",", "f\"Could not find config at {config_path}\"", "\n", "config", "=", "read_json", "(", "config_path", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "\"summary\"", ")", "\n", "\n", "# some care is required with logging to avoid sending all experiment logs", "\n", "# to the same file.  We avoid this by essentially resetting the logging utility", "\n", "\n", "# Remove all handlers associated with the root logger object", "\n", "for", "handler", "in", "logging", ".", "root", ".", "handlers", "[", ":", "]", ":", "\n", "        ", "logging", ".", "root", ".", "removeHandler", "(", "handler", ")", "\n", "", "logging", ".", "basicConfig", "(", "filename", "=", "summary_log_path", ",", "level", "=", "logging", ".", "INFO", ")", "\n", "if", "not", "logger", ".", "handlers", ":", "\n", "        ", "logger", ".", "addHandler", "(", "logging", ".", "StreamHandler", "(", ")", ")", "\n", "\n", "", "log_summary", "(", "\n", "logger", "=", "logger", ",", "\n", "log_path", "=", "summary_log_path", ",", "\n", "eval_mode", "=", "config", "[", "\"eval_mode\"", "]", ",", "\n", "fixed_num_epochs", "=", "config", "[", "\"trainer\"", "]", "[", "\"epochs\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.aggregate_logs_and_stats.main": [[65, 70], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "aggregate_logs_and_stats.summarise"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.misc.aggregate_logs_and_stats.summarise"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--group_id\"", ",", "default", "=", "\"ed53d01d\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "summarise", "(", "group_id", "=", "args", ".", "group_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.AudioCaps_dataset.AudioCaps.__init__": [[15, 21], ["base.base_dataset.BaseDataset.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "@", "typechecked", "\n", "def", "__init__", "(", "self", ",", "testing_file", ":", "Union", "[", "None", ",", "str", "]", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "testing_file", "=", "testing_file", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "print", "(", "f\"self.testing_file: {self.testing_file}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.AudioCaps_dataset.AudioCaps.dataset_paths": [[22, 82], ["test_splits.items", "base.base_dataset.BaseDataset.common_feat_names", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_text_feat_paths", "print", "print", "print", "print", "print", "pathlib.Path", "base.base_dataset.BaseDataset.common_text_feat_paths.items", "[].split", "training_file.split"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_feat_names", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_text_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "@", "staticmethod", "\n", "@", "typechecked", "\n", "def", "dataset_paths", "(", "training_file", "=", "None", ",", "testing_file", "=", "None", ")", "->", "Dict", "[", "str", ",", "Union", "[", "str", ",", "List", "[", "str", "]", ",", "Path", ",", "Dict", "]", "]", ":", "\n", "        ", "subset_paths", "=", "{", "}", "\n", "# import pdb; pdb.set_trace()", "\n", "if", "testing_file", "is", "None", ":", "\n", "            ", "test_splits", "=", "{", "\n", "\"val\"", ":", "\"filtered_val_list.txt\"", ",", "\n", "\"test\"", ":", "\"final_filtered_test_list.txt\"", ",", "\n", "}", "\n", "using_testing_file", "=", "False", "\n", "", "else", ":", "\n", "            ", "test_splits", "=", "{", "\n", "\"val\"", ":", "\"filtered_val_list.txt\"", ",", "\n", "\"test\"", ":", "testing_file", ",", "\n", "}", "\n", "using_testing_file", "=", "True", "\n", "print", "(", "f\"using {testing_file}\"", ")", "\n", "", "if", "training_file", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "val_per", "=", "training_file", ".", "split", "(", "'.txt'", ")", "[", "0", "]", ".", "split", "(", "'train_list_'", ")", "[", "1", "]", "\n", "test_splits", "[", "'val'", "]", "=", "f\"filtered_val_list_{val_per}.txt\"", "\n", "", "except", "IndexError", ":", "\n", "                ", "pass", "\n", "", "", "for", "split_name", ",", "fname", "in", "test_splits", ".", "items", "(", ")", ":", "\n", "            ", "if", "training_file", "is", "None", ":", "\n", "                ", "print", "(", "f\"using {test_splits['test']} is {using_testing_file} split {split_name}\"", ")", "\n", "subset_paths", "[", "split_name", "]", "=", "{", "\"train\"", ":", "\"train_list.txt\"", ",", "\"val\"", ":", "fname", "}", "\n", "print", "(", "f\"using {subset_paths[split_name]['train']} and {subset_paths[split_name]['val']}\"", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "f\"using {test_splits['test']} is {using_testing_file} split {split_name}\"", ")", "\n", "subset_paths", "[", "split_name", "]", "=", "{", "\"train\"", ":", "training_file", ",", "\"val\"", ":", "fname", "}", "\n", "print", "(", "f\"using {subset_paths[split_name]['train']} and {subset_paths[split_name]['val']}\"", ")", "\n", "\n", "", "", "feature_names", "=", "BaseDataset", ".", "common_feat_names", "(", ")", "\n", "feature_names", ".", "append", "(", "\"audio.vggish.0\"", ")", "\n", "feature_names", ".", "append", "(", "\"pann.pann.0\"", ")", "\n", "feature_names", ".", "append", "(", "\"syncnet.syncnet.0\"", ")", "\n", "feature_names", ".", "append", "(", "\"vggsound.vggsound.0\"", ")", "\n", "text_feat_paths", "=", "BaseDataset", ".", "common_text_feat_paths", "(", ")", "\n", "text_feat_paths", "=", "{", "key", ":", "Path", "(", "\"text_embeddings\"", ")", "/", "fname", "\n", "for", "key", ",", "fname", "in", "text_feat_paths", ".", "items", "(", ")", "}", "\n", "challenge_text_feat_paths", "=", "{", "key", ":", "f\"text_embeddings/{key}.pkl\"", "\n", "for", "key", "in", "text_feat_paths", "}", "\n", "custom_paths", "=", "{", "\n", "\"audio\"", ":", "[", "\"aggregated_audio/vggish-raw.hickle\"", "]", ",", "\n", "\"pann\"", ":", "[", "\"aggregated_pann/pann-raw.hickle\"", "]", ",", "\n", "\"syncnet\"", ":", "[", "\"aggregated_syncnet/syncnet-raw.hickle\"", "]", ",", "\n", "\"vggsound\"", ":", "[", "\"aggregated_vggsound/vggsound-raw.hickle\"", "]", ",", "\n", "\"speech\"", ":", "[", "\"aggregated_speech/w2v_mean.pkl\"", "]", "\n", "}", "\n", "feature_info", "=", "{", "\n", "\"custom_paths\"", ":", "custom_paths", ",", "\n", "\"feature_names\"", ":", "feature_names", ",", "\n", "\"subset_list_paths\"", ":", "subset_paths", ",", "\n", "\"text_feat_paths\"", ":", "text_feat_paths", ",", "\n", "\"challenge_text_feat_paths\"", ":", "challenge_text_feat_paths", ",", "\n", "\"raw_captions_path\"", ":", "\"structured-symlinks/raw-captions.pkl\"", ",", "\n", "}", "\n", "return", "feature_info", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.AudioCaps_dataset.AudioCaps.load_features": [[83, 127], ["feat_names.update", "feat_names.items", "AudioCaps_dataset.AudioCaps.visual_feat_paths", "tuple", "AudioCaps_dataset.AudioCaps.load_challenge_text_features", "zsvision.zs_utils.memcache", "zsvision.zs_utils.memcache", "len", "zsvision.zs_utils.memcache", "print", "zsvision.zs_utils.concat_features.cache_info", "print", "zsvision.zs_utils.concat_features", "utils.memory_summary", "copy.deepcopy", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.visual_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.load_challenge_text_features", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memory_summary"], ["", "def", "load_features", "(", "self", ")", ":", "\n", "        ", "root_feat", "=", "self", ".", "root_feat", "\n", "feat_names", "=", "{", "key", ":", "self", ".", "visual_feat_paths", "(", "key", ")", "for", "key", "in", "\n", "self", ".", "paths", "[", "\"feature_names\"", "]", "}", "\n", "feat_names", ".", "update", "(", "self", ".", "paths", "[", "\"custom_paths\"", "]", ")", "\n", "features", "=", "{", "}", "\n", "for", "expert", ",", "rel_names", "in", "feat_names", ".", "items", "(", ")", ":", "\n", "            ", "if", "expert", "not", "in", "self", ".", "ordered_experts", ":", "\n", "                ", "continue", "\n", "", "feat_paths", "=", "tuple", "(", "[", "Path", "(", "root_feat", ")", "/", "rel_name", "for", "rel_name", "in", "rel_names", "]", ")", "\n", "if", "len", "(", "feat_paths", ")", "==", "1", ":", "\n", "                ", "features", "[", "expert", "]", "=", "memcache", "(", "feat_paths", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "# support multiple forms of feature (e.g. max and avg pooling). For", "\n", "# now, we only support direct concatenation", "\n", "                ", "msg", "=", "f\"{expert}: Only direct concatenation of muliple feats is possible\"", "\n", "print", "(", "f\"Concatenating aggregates for {expert}....\"", ")", "\n", "assert", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate\"", "]", "==", "\"concat\"", ",", "msg", "\n", "axis", "=", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate-axis\"", "]", "\n", "x", "=", "concat_features", ".", "cache_info", "(", ")", "# pylint: disable=no-value-for-parameter", "\n", "print", "(", "f\"concat cache info: {x}\"", ")", "\n", "features_", "=", "concat_features", "(", "feat_paths", ",", "axis", "=", "axis", ")", "\n", "\n", "memory_summary", "(", ")", "\n", "\n", "#if expert == \"speech\":", "\n", "#    features_defaults = defaultdict(lambda: np.zeros((1, 300)))", "\n", "#    features_defaults.update(features_)", "\n", "#    features_ = features_defaults", "\n", "# Make separate feature copies for each split to allow in-place filtering", "\n", "features", "[", "expert", "]", "=", "copy", ".", "deepcopy", "(", "features_", ")", "\n", "\n", "", "", "self", ".", "features", "=", "features", "\n", "if", "self", ".", "challenge_mode", ":", "\n", "            ", "self", ".", "load_challenge_text_features", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "raw_captions", "=", "memcache", "(", "root_feat", "/", "self", ".", "paths", "[", "\"raw_captions_path\"", "]", ")", "\n", "# keys = list(raw_captions.keys())", "\n", "# raw_captions_fused = {}", "\n", "# for key in keys:", "\n", "#     raw_captions_fused[key] = list(itertools.chain.from_iterable(raw_captions[key]))", "\n", "# self.raw_captions = raw_captions_fused", "\n", "text_feat_path", "=", "root_feat", "/", "self", ".", "paths", "[", "\"text_feat_paths\"", "]", "[", "self", ".", "text_feat", "]", "\n", "self", ".", "text_features", "=", "memcache", "(", "text_feat_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.AudioCaps_dataset.AudioCaps.sanity_checks": [[129, 134], ["None"], "methods", ["None"], ["", "", "def", "sanity_checks", "(", "self", ")", ":", "\n", "        ", "msg", "=", "(", "f\"Expected to have single test caption for AudioCaps, since we assume\"", "\n", "f\"that the captions are fused (but using {self.num_test_captions})\"", ")", "\n", "if", "self", ".", "fuse_captions", "is", "True", ":", "\n", "            ", "assert", "self", ".", "num_test_captions", "==", "1", ",", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.AudioCaps_dataset.AudioCaps.configure_train_test_splits": [[135, 161], ["print", "type().dataset_paths", "print", "time.time", "[].items", "print", "type", "pathlib.Path", "pathlib.Path", "open", "f.read().splitlines", "time.time", "f.read"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.dataset_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "", "def", "configure_train_test_splits", "(", "self", ",", "split_name", ")", ":", "\n", "        ", "\"\"\"Partition the datset into train/val/test splits.\n\n        Args:\n            split_name (str): the name of the split\n        \"\"\"", "\n", "print", "(", "f\"Now working on {split_name}\"", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "self", ".", "paths", "=", "type", "(", "self", ")", ".", "dataset_paths", "(", "training_file", "=", "self", ".", "training_file", ",", "testing_file", "=", "self", ".", "testing_file", ")", "\n", "print", "(", "\"loading training/val splits....\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "for", "subset", ",", "path", "in", "self", ".", "paths", "[", "\"subset_list_paths\"", "]", "[", "split_name", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "self", ".", "challenge_mode", "and", "split_name", "==", "\"public_server_test\"", "and", "subset", "==", "\"val\"", ":", "\n", "                ", "root_feat", "=", "Path", "(", "self", ".", "challenge_test_root_feat_folder", ")", "\n", "", "else", ":", "\n", "                ", "root_feat", "=", "Path", "(", "self", ".", "root_feat", ")", "\n", "", "subset_list_path", "=", "root_feat", "/", "path", "\n", "if", "subset", "==", "\"train\"", "and", "self", ".", "eval_only", ":", "\n", "                ", "rows", "=", "[", "]", "\n", "", "else", ":", "\n", "                ", "with", "open", "(", "subset_list_path", ")", "as", "f", ":", "\n", "                    ", "rows", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "", "self", ".", "partition_lists", "[", "subset", "]", "=", "rows", "\n", "", "print", "(", "\"done in {:.3f}s\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "self", ".", "split_name", "=", "split_name", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.QuerYDSegments_dataset.QuerYDSegments.dataset_paths": [[14, 44], ["test_splits.items", "base.base_dataset.BaseDataset.common_feat_names", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_text_feat_paths", "pathlib.Path", "base.base_dataset.BaseDataset.common_text_feat_paths.items"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_feat_names", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_text_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["    ", "@", "staticmethod", "\n", "@", "typechecked", "\n", "def", "dataset_paths", "(", "training_file", "=", "None", ")", "->", "Dict", "[", "str", ",", "Union", "[", "str", ",", "List", "[", "str", "]", ",", "Path", ",", "Dict", "]", "]", ":", "\n", "        ", "subset_paths", "=", "{", "}", "\n", "test_splits", "=", "{", "\n", "\"val\"", ":", "\"val_list.txt\"", ",", "\n", "\"test\"", ":", "\"test_list.txt\"", ",", "\n", "}", "\n", "for", "split_name", ",", "fname", "in", "test_splits", ".", "items", "(", ")", ":", "\n", "            ", "subset_paths", "[", "split_name", "]", "=", "{", "\"train\"", ":", "\"train_list.txt\"", ",", "\"val\"", ":", "fname", "}", "\n", "\n", "", "feature_names", "=", "BaseDataset", ".", "common_feat_names", "(", ")", "\n", "feature_names", ".", "append", "(", "\"audio.vggish.0\"", ")", "\n", "text_feat_paths", "=", "BaseDataset", ".", "common_text_feat_paths", "(", ")", "\n", "text_feat_paths", "=", "{", "key", ":", "Path", "(", "\"text_embeddings\"", ")", "/", "fname", "\n", "for", "key", ",", "fname", "in", "text_feat_paths", ".", "items", "(", ")", "}", "\n", "challenge_text_feat_paths", "=", "{", "key", ":", "f\"text_embeddings/{key}.pkl\"", "\n", "for", "key", "in", "text_feat_paths", "}", "\n", "custom_paths", "=", "{", "\n", "\"audio\"", ":", "[", "\"aggregated_audio/vggish-raw.hickle\"", "]", ",", "\n", "}", "\n", "feature_info", "=", "{", "\n", "\"custom_paths\"", ":", "custom_paths", ",", "\n", "\"feature_names\"", ":", "feature_names", ",", "\n", "\"subset_list_paths\"", ":", "subset_paths", ",", "\n", "\"text_feat_paths\"", ":", "text_feat_paths", ",", "\n", "\"challenge_text_feat_paths\"", ":", "challenge_text_feat_paths", ",", "\n", "\"raw_captions_path\"", ":", "\"structured-symlinks/split_raw_captions_filtered.pkl\"", ",", "\n", "}", "\n", "return", "feature_info", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.QuerYDSegments_dataset.QuerYDSegments.load_features": [[45, 85], ["feat_names.update", "feat_names.items", "QuerYDSegments_dataset.QuerYDSegments.visual_feat_paths", "tuple", "QuerYDSegments_dataset.QuerYDSegments.load_challenge_text_features", "zsvision.zs_utils.memcache", "zsvision.zs_utils.memcache", "len", "zsvision.zs_utils.memcache", "print", "zsvision.zs_utils.concat_features.cache_info", "print", "zsvision.zs_utils.concat_features", "utils.memory_summary", "copy.deepcopy", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.visual_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.load_challenge_text_features", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memory_summary"], ["", "def", "load_features", "(", "self", ")", ":", "\n", "        ", "root_feat", "=", "self", ".", "root_feat", "\n", "# import pdb; pdb.set_trace()", "\n", "feat_names", "=", "{", "key", ":", "self", ".", "visual_feat_paths", "(", "key", ")", "for", "key", "in", "\n", "self", ".", "paths", "[", "\"feature_names\"", "]", "}", "\n", "feat_names", ".", "update", "(", "self", ".", "paths", "[", "\"custom_paths\"", "]", ")", "\n", "features", "=", "{", "}", "\n", "for", "expert", ",", "rel_names", "in", "feat_names", ".", "items", "(", ")", ":", "\n", "            ", "if", "expert", "not", "in", "self", ".", "ordered_experts", ":", "\n", "                ", "continue", "\n", "", "feat_paths", "=", "tuple", "(", "[", "Path", "(", "root_feat", ")", "/", "rel_name", "for", "rel_name", "in", "rel_names", "]", ")", "\n", "if", "len", "(", "feat_paths", ")", "==", "1", ":", "\n", "                ", "features", "[", "expert", "]", "=", "memcache", "(", "feat_paths", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "# support multiple forms of feature (e.g. max and avg pooling). For", "\n", "# now, we only support direct concatenation", "\n", "                ", "msg", "=", "f\"{expert}: Only direct concatenation of muliple feats is possible\"", "\n", "print", "(", "f\"Concatenating aggregates for {expert}....\"", ")", "\n", "assert", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate\"", "]", "==", "\"concat\"", ",", "msg", "\n", "axis", "=", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate-axis\"", "]", "\n", "x", "=", "concat_features", ".", "cache_info", "(", ")", "# pylint: disable=no-value-for-parameter", "\n", "print", "(", "f\"concat cache info: {x}\"", ")", "\n", "features_", "=", "concat_features", "(", "feat_paths", ",", "axis", "=", "axis", ")", "\n", "memory_summary", "(", ")", "\n", "\n", "# Make separate feature copies for each split to allow in-place filtering", "\n", "features", "[", "expert", "]", "=", "copy", ".", "deepcopy", "(", "features_", ")", "\n", "\n", "", "", "self", ".", "features", "=", "features", "\n", "if", "self", ".", "challenge_mode", ":", "\n", "            ", "self", ".", "load_challenge_text_features", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "raw_captions", "=", "memcache", "(", "root_feat", "/", "self", ".", "paths", "[", "\"raw_captions_path\"", "]", ")", "\n", "text_feat_path", "=", "root_feat", "/", "self", ".", "paths", "[", "\"text_feat_paths\"", "]", "[", "self", ".", "text_feat", "]", "\n", "self", ".", "text_features", "=", "memcache", "(", "text_feat_path", ")", "\n", "\n", "\n", "# overload video paths", "\n", "", "self", ".", "video_path_retrieval", "=", "[", "f\"videos/{x}.mp4\"", "\n", "for", "x", "in", "self", ".", "partition_lists", "[", "\"val\"", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.QuerYDSegments_dataset.QuerYDSegments.sanity_checks": [[86, 90], ["None"], "methods", ["None"], ["", "def", "sanity_checks", "(", "self", ")", ":", "\n", "        ", "msg", "=", "(", "f\"Expected to have single test caption for QuerYD, since we assume\"", "\n", "f\"that the captions are fused (but using {self.num_test_captions})\"", ")", "\n", "assert", "self", ".", "num_test_captions", "==", "1", ",", "msg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.data_loaders.ExpertDataLoader.__init__": [[26, 68], ["float", "data_loader.mix_dataset.MixDataset", "torch.utils.data.DataLoader", "logger.debug"], "methods", ["None"], ["eval_only", ":", "bool", ",", "\n", "task", ":", "str", ",", "\n", "data_dir", ":", "str", ",", "\n", "text_agg", ":", "str", ",", "\n", "text_feat", ":", "str", ",", "\n", "split_name", ":", "str", ",", "\n", "dataset_name", ":", "str", ",", "\n", "cls_partition", ":", "str", ",", "\n", "root_feat_folder", ":", "str", ",", "\n", "challenge_test_root_feat_folder", ":", "str", ",", "\n", "text_dim", ":", "int", ",", "\n", "num_test_captions", ":", "int", ",", "\n", "restrict_train_captions", ":", "int", ",", "\n", "logger", ":", "logging", ".", "Logger", ",", "\n", "max_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "raw_input_dims", ":", "HashableOrderedDict", ",", "\n", "feat_aggregation", ":", "HashableDict", ",", "\n", "distil_params", ":", "Union", "[", "None", ",", "Dict", "]", ",", "\n", "training_file", ":", "Union", "[", "None", ",", "str", "]", ",", "\n", "caption_masks", ":", "Union", "[", "None", ",", "str", "]", ",", "\n", "ce_shared_dim", ":", "Union", "[", "None", ",", "int", "]", ",", "\n", "**", "args", ",", "\n", ")", ":", "\n", "    ", "print", "(", "f\"refreshing cache for {dataset_name} data loader [{split_name}]\"", ")", "\n", "kwargs", "=", "dict", "(", "\n", "task", "=", "task", ",", "\n", "data_dir", "=", "Path", "(", "data_dir", ")", ",", "\n", "text_dim", "=", "text_dim", ",", "\n", "logger", "=", "logger", ",", "\n", "eval_only", "=", "eval_only", ",", "\n", "text_agg", "=", "text_agg", ",", "\n", "text_feat", "=", "text_feat", ",", "\n", "max_tokens", "=", "max_tokens", ",", "\n", "split_name", "=", "split_name", ",", "\n", "cls_partition", "=", "cls_partition", ",", "\n", "spatial_feats", "=", "spatial_feats", ",", "\n", "text_dropout", "=", "text_dropout", ",", "\n", "fuse_captions", "=", "fuse_captions", ",", "\n", "raw_input_dims", "=", "raw_input_dims", ",", "\n", "challenge_mode", "=", "challenge_mode", ",", "\n", "root_feat_folder", "=", "root_feat_folder", ",", "\n", "feat_aggregation", "=", "feat_aggregation", ",", "\n", "num_test_captions", "=", "num_test_captions", ",", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.data_loaders.ExpertDataLoader.__getitem__": [[69, 71], ["None"], "methods", ["None"], ["use_zeros_for_missing", "=", "use_zeros_for_missing", ",", "\n", "restrict_train_captions", "=", "restrict_train_captions", ",", "\n", "challenge_test_root_feat_folder", "=", "challenge_test_root_feat_folder", ",", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.data_loaders.dataset_loader": [[19, 91], ["functools.lru_cache", "print", "dict", "data_loader.ActivityNet_dataset.ActivityNet", "pathlib.Path", "data_loader.QuerYD_dataset.QuerYD", "data_loader.QuerYDSegments_dataset.QuerYDSegments", "data_loader.AudioCaps_dataset.AudioCaps", "data_loader.CLOTHO_dataset.CLOTHO", "data_loader.SoundDescs_dataset.SoundDescs"], "function", ["None"], ["@", "functools", ".", "lru_cache", "(", "maxsize", "=", "64", ",", "typed", "=", "False", ")", "\n", "def", "dataset_loader", "(", "\n", "text_dropout", ":", "float", ",", "\n", "fuse_captions", ":", "bool", ",", "\n", "spatial_feats", ":", "bool", ",", "\n", "use_zeros_for_missing", ":", "bool", ",", "\n", "challenge_mode", ":", "bool", ",", "\n", "eval_only", ":", "bool", ",", "\n", "task", ":", "str", ",", "\n", "data_dir", ":", "str", ",", "\n", "text_agg", ":", "str", ",", "\n", "text_feat", ":", "str", ",", "\n", "split_name", ":", "str", ",", "\n", "dataset_name", ":", "str", ",", "\n", "cls_partition", ":", "str", ",", "\n", "root_feat_folder", ":", "str", ",", "\n", "challenge_test_root_feat_folder", ":", "str", ",", "\n", "text_dim", ":", "int", ",", "\n", "num_test_captions", ":", "int", ",", "\n", "restrict_train_captions", ":", "int", ",", "\n", "logger", ":", "logging", ".", "Logger", ",", "\n", "max_tokens", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "raw_input_dims", ":", "HashableOrderedDict", ",", "\n", "feat_aggregation", ":", "HashableDict", ",", "\n", "distil_params", ":", "Union", "[", "None", ",", "Dict", "]", ",", "\n", "training_file", ":", "Union", "[", "None", ",", "str", "]", ",", "\n", "caption_masks", ":", "Union", "[", "None", ",", "str", "]", ",", "\n", "ce_shared_dim", ":", "Union", "[", "None", ",", "int", "]", ",", "\n", "**", "args", ",", "\n", ")", ":", "\n", "    ", "print", "(", "f\"refreshing cache for {dataset_name} data loader [{split_name}]\"", ")", "\n", "kwargs", "=", "dict", "(", "\n", "task", "=", "task", ",", "\n", "data_dir", "=", "Path", "(", "data_dir", ")", ",", "\n", "text_dim", "=", "text_dim", ",", "\n", "logger", "=", "logger", ",", "\n", "eval_only", "=", "eval_only", ",", "\n", "text_agg", "=", "text_agg", ",", "\n", "text_feat", "=", "text_feat", ",", "\n", "max_tokens", "=", "max_tokens", ",", "\n", "split_name", "=", "split_name", ",", "\n", "cls_partition", "=", "cls_partition", ",", "\n", "spatial_feats", "=", "spatial_feats", ",", "\n", "text_dropout", "=", "text_dropout", ",", "\n", "fuse_captions", "=", "fuse_captions", ",", "\n", "raw_input_dims", "=", "raw_input_dims", ",", "\n", "challenge_mode", "=", "challenge_mode", ",", "\n", "root_feat_folder", "=", "root_feat_folder", ",", "\n", "feat_aggregation", "=", "feat_aggregation", ",", "\n", "num_test_captions", "=", "num_test_captions", ",", "\n", "use_zeros_for_missing", "=", "use_zeros_for_missing", ",", "\n", "restrict_train_captions", "=", "restrict_train_captions", ",", "\n", "challenge_test_root_feat_folder", "=", "challenge_test_root_feat_folder", ",", "\n", "distil_params", "=", "distil_params", ",", "\n", "training_file", "=", "training_file", ",", "\n", "caption_masks", "=", "caption_masks", ",", "\n", "ce_shared_dim", "=", "ce_shared_dim", ",", "\n", "**", "args", ",", "\n", ")", "\n", "if", "dataset_name", "==", "\"ActivityNet\"", ":", "\n", "        ", "dataset", "=", "ActivityNet", "(", "**", "kwargs", ")", "\n", "", "elif", "dataset_name", "==", "\"QuerYD\"", ":", "\n", "        ", "dataset", "=", "QuerYD", "(", "**", "kwargs", ")", "\n", "", "elif", "dataset_name", "==", "\"QuerYDSegments\"", ":", "\n", "        ", "dataset", "=", "QuerYDSegments", "(", "**", "kwargs", ")", "\n", "", "elif", "dataset_name", "==", "\"AudioCaps\"", ":", "\n", "        ", "dataset", "=", "AudioCaps", "(", "**", "kwargs", ")", "\n", "", "elif", "dataset_name", "==", "\"CLOTHO\"", ":", "\n", "        ", "dataset", "=", "CLOTHO", "(", "**", "kwargs", ")", "\n", "", "elif", "dataset_name", "==", "\"SoundDescs\"", ":", "\n", "        ", "dataset", "=", "SoundDescs", "(", "**", "kwargs", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.SoundDescs_dataset.SoundDescs.__init__": [[15, 21], ["base.base_dataset.BaseDataset.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "@", "typechecked", "\n", "def", "__init__", "(", "self", ",", "testing_file", ":", "Union", "[", "None", ",", "str", "]", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "testing_file", "=", "testing_file", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "print", "(", "f\"self.testing_file: {self.testing_file}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.SoundDescs_dataset.SoundDescs.dataset_paths": [[22, 76], ["test_splits.items", "base.base_dataset.BaseDataset.common_feat_names", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_text_feat_paths", "print", "print", "print", "print", "print", "pathlib.Path", "base.base_dataset.BaseDataset.common_text_feat_paths.items", "[].split", "training_file.split"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_feat_names", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_text_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "@", "staticmethod", "\n", "@", "typechecked", "\n", "def", "dataset_paths", "(", "training_file", "=", "None", ",", "testing_file", "=", "None", ")", "->", "Dict", "[", "str", ",", "Union", "[", "str", ",", "List", "[", "str", "]", ",", "Path", ",", "Dict", "]", "]", ":", "\n", "        ", "subset_paths", "=", "{", "}", "\n", "if", "testing_file", "is", "None", ":", "\n", "            ", "test_splits", "=", "{", "\n", "\"val\"", ":", "\"val_list.txt\"", ",", "\n", "\"test\"", ":", "\"test_list.txt\"", ",", "\n", "}", "\n", "using_testing_file", "=", "False", "\n", "", "else", ":", "\n", "            ", "test_splits", "=", "{", "\n", "\"val\"", ":", "\"val_list.txt\"", ",", "\n", "\"test\"", ":", "testing_file", ",", "\n", "}", "\n", "using_testing_file", "=", "True", "\n", "print", "(", "f\"using {testing_file}\"", ")", "\n", "", "if", "training_file", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "val_per", "=", "training_file", ".", "split", "(", "'.txt'", ")", "[", "0", "]", ".", "split", "(", "'train_list_'", ")", "[", "1", "]", "\n", "test_splits", "[", "'val'", "]", "=", "f\"val_list_{val_per}.txt\"", "\n", "", "except", "IndexError", ":", "\n", "                ", "pass", "\n", "", "", "for", "split_name", ",", "fname", "in", "test_splits", ".", "items", "(", ")", ":", "\n", "            ", "if", "training_file", "is", "None", ":", "\n", "                ", "print", "(", "f\"using {test_splits['test']} is {using_testing_file} split {split_name}\"", ")", "\n", "subset_paths", "[", "split_name", "]", "=", "{", "\"train\"", ":", "\"train_list.txt\"", ",", "\"val\"", ":", "fname", "}", "\n", "print", "(", "f\"using {subset_paths[split_name]['train']} and {subset_paths[split_name]['val']}\"", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "f\"using {test_splits['test']} is {using_testing_file} split {split_name}\"", ")", "\n", "subset_paths", "[", "split_name", "]", "=", "{", "\"train\"", ":", "training_file", ",", "\"val\"", ":", "fname", "}", "\n", "print", "(", "f\"using {subset_paths[split_name]['train']} and {subset_paths[split_name]['val']}\"", ")", "\n", "\n", "", "", "feature_names", "=", "BaseDataset", ".", "common_feat_names", "(", ")", "\n", "feature_names", ".", "append", "(", "\"audio.vggish.0\"", ")", "\n", "feature_names", ".", "append", "(", "\"vggsound.vggsound.0\"", ")", "\n", "text_feat_paths", "=", "BaseDataset", ".", "common_text_feat_paths", "(", ")", "\n", "text_feat_paths", "=", "{", "key", ":", "Path", "(", "\"text_embeddings\"", ")", "/", "fname", "\n", "for", "key", ",", "fname", "in", "text_feat_paths", ".", "items", "(", ")", "}", "\n", "challenge_text_feat_paths", "=", "{", "key", ":", "f\"text_embeddings/{key}.pkl\"", "\n", "for", "key", "in", "text_feat_paths", "}", "\n", "custom_paths", "=", "{", "\n", "\"audio\"", ":", "[", "\"aggregated_audio/vggish-raw.pkl\"", "]", ",", "\n", "\"vggsound\"", ":", "[", "\"aggregated_vggsound/vggsound-raw.pkl\"", "]", "\n", "}", "\n", "feature_info", "=", "{", "\n", "\"custom_paths\"", ":", "custom_paths", ",", "\n", "\"feature_names\"", ":", "feature_names", ",", "\n", "\"subset_list_paths\"", ":", "subset_paths", ",", "\n", "\"text_feat_paths\"", ":", "text_feat_paths", ",", "\n", "\"challenge_text_feat_paths\"", ":", "challenge_text_feat_paths", ",", "\n", "\"raw_captions_path\"", ":", "\"structured-symlinks/raw-captions.pkl\"", ",", "\n", "}", "\n", "return", "feature_info", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.SoundDescs_dataset.SoundDescs.load_features": [[77, 120], ["feat_names.update", "feat_names.items", "SoundDescs_dataset.SoundDescs.visual_feat_paths", "tuple", "SoundDescs_dataset.SoundDescs.load_challenge_text_features", "zsvision.zs_utils.memcache", "zsvision.zs_utils.memcache", "len", "zsvision.zs_utils.memcache", "print", "zsvision.zs_utils.concat_features.cache_info", "print", "zsvision.zs_utils.concat_features", "utils.memory_summary", "copy.deepcopy", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.visual_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.load_challenge_text_features", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memory_summary"], ["", "def", "load_features", "(", "self", ")", ":", "\n", "        ", "root_feat", "=", "self", ".", "root_feat", "\n", "feat_names", "=", "{", "key", ":", "self", ".", "visual_feat_paths", "(", "key", ")", "for", "key", "in", "\n", "self", ".", "paths", "[", "\"feature_names\"", "]", "}", "\n", "feat_names", ".", "update", "(", "self", ".", "paths", "[", "\"custom_paths\"", "]", ")", "\n", "features", "=", "{", "}", "\n", "for", "expert", ",", "rel_names", "in", "feat_names", ".", "items", "(", ")", ":", "\n", "            ", "if", "expert", "not", "in", "self", ".", "ordered_experts", ":", "\n", "                ", "continue", "\n", "", "feat_paths", "=", "tuple", "(", "[", "Path", "(", "root_feat", ")", "/", "rel_name", "for", "rel_name", "in", "rel_names", "]", ")", "\n", "if", "len", "(", "feat_paths", ")", "==", "1", ":", "\n", "                ", "features", "[", "expert", "]", "=", "memcache", "(", "feat_paths", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "# support multiple forms of feature (e.g. max and avg pooling). For", "\n", "# now, we only support direct concatenation", "\n", "                ", "msg", "=", "f\"{expert}: Only direct concatenation of muliple feats is possible\"", "\n", "print", "(", "f\"Concatenating aggregates for {expert}....\"", ")", "\n", "assert", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate\"", "]", "==", "\"concat\"", ",", "msg", "\n", "axis", "=", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate-axis\"", "]", "\n", "x", "=", "concat_features", ".", "cache_info", "(", ")", "# pylint: disable=no-value-for-parameter", "\n", "print", "(", "f\"concat cache info: {x}\"", ")", "\n", "features_", "=", "concat_features", "(", "feat_paths", ",", "axis", "=", "axis", ")", "\n", "memory_summary", "(", ")", "\n", "\n", "# if expert == \"speech\":", "\n", "#     features_defaults = defaultdict(lambda: np.zeros((1, 300)))", "\n", "#     features_defaults.update(features_)", "\n", "#     features_ = features_defaults", "\n", "# Make separate feature copies for each split to allow in-place filtering", "\n", "features", "[", "expert", "]", "=", "copy", ".", "deepcopy", "(", "features_", ")", "\n", "\n", "", "", "self", ".", "features", "=", "features", "\n", "if", "self", ".", "challenge_mode", ":", "\n", "            ", "self", ".", "load_challenge_text_features", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "raw_captions", "=", "memcache", "(", "root_feat", "/", "self", ".", "paths", "[", "\"raw_captions_path\"", "]", ")", "\n", "# keys = list(raw_captions.keys())", "\n", "# raw_captions_fused = {}", "\n", "# for key in keys:", "\n", "#     raw_captions_fused[key] = list(itertools.chain.from_iterable(raw_captions[key]))", "\n", "# self.raw_captions = raw_captions_fused", "\n", "text_feat_path", "=", "root_feat", "/", "self", ".", "paths", "[", "\"text_feat_paths\"", "]", "[", "self", ".", "text_feat", "]", "\n", "self", ".", "text_features", "=", "memcache", "(", "text_feat_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.SoundDescs_dataset.SoundDescs.sanity_checks": [[121, 126], ["None"], "methods", ["None"], ["", "", "def", "sanity_checks", "(", "self", ")", ":", "\n", "        ", "msg", "=", "(", "f\"Expected to have single test caption for SoundDescs, since we assume\"", "\n", "f\"that the captions are fused (but using {self.num_test_captions})\"", ")", "\n", "if", "self", ".", "fuse_captions", "is", "True", ":", "\n", "            ", "assert", "self", ".", "num_test_captions", "==", "1", ",", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.SoundDescs_dataset.SoundDescs.configure_train_test_splits": [[127, 153], ["print", "type().dataset_paths", "print", "time.time", "[].items", "print", "type", "pathlib.Path", "pathlib.Path", "open", "f.read().splitlines", "time.time", "f.read"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.dataset_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "", "def", "configure_train_test_splits", "(", "self", ",", "split_name", ")", ":", "\n", "        ", "\"\"\"Partition the datset into train/val/test splits.\n\n        Args:\n            split_name (str): the name of the split\n        \"\"\"", "\n", "print", "(", "f\"Now working on {split_name}\"", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "self", ".", "paths", "=", "type", "(", "self", ")", ".", "dataset_paths", "(", "training_file", "=", "self", ".", "training_file", ",", "testing_file", "=", "self", ".", "testing_file", ")", "\n", "print", "(", "\"loading training/val splits....\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "for", "subset", ",", "path", "in", "self", ".", "paths", "[", "\"subset_list_paths\"", "]", "[", "split_name", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "self", ".", "challenge_mode", "and", "split_name", "==", "\"public_server_test\"", "and", "subset", "==", "\"val\"", ":", "\n", "                ", "root_feat", "=", "Path", "(", "self", ".", "challenge_test_root_feat_folder", ")", "\n", "", "else", ":", "\n", "                ", "root_feat", "=", "Path", "(", "self", ".", "root_feat", ")", "\n", "", "subset_list_path", "=", "root_feat", "/", "path", "\n", "if", "subset", "==", "\"train\"", "and", "self", ".", "eval_only", ":", "\n", "                ", "rows", "=", "[", "]", "\n", "", "else", ":", "\n", "                ", "with", "open", "(", "subset_list_path", ")", "as", "f", ":", "\n", "                    ", "rows", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "", "self", ".", "partition_lists", "[", "subset", "]", "=", "rows", "\n", "", "print", "(", "\"done in {:.3f}s\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "self", ".", "split_name", "=", "split_name", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.CLOTHO_dataset.CLOTHO.__init__": [[15, 21], ["base.base_dataset.BaseDataset.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["    ", "@", "typechecked", "\n", "def", "__init__", "(", "self", ",", "testing_file", ":", "Union", "[", "None", ",", "str", "]", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "testing_file", "=", "testing_file", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "print", "(", "f\"self.testing_file: {self.testing_file}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.CLOTHO_dataset.CLOTHO.dataset_paths": [[22, 89], ["test_splits.items", "base.base_dataset.BaseDataset.common_feat_names", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_text_feat_paths", "print", "print", "print", "print", "print", "pathlib.Path", "base.base_dataset.BaseDataset.common_text_feat_paths.items", "[].split", "training_file.split"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_feat_names", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_text_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "@", "staticmethod", "\n", "@", "typechecked", "\n", "def", "dataset_paths", "(", "training_file", "=", "None", ",", "testing_file", "=", "None", ")", "->", "Dict", "[", "str", ",", "Union", "[", "str", ",", "List", "[", "str", "]", ",", "Path", ",", "Dict", "]", "]", ":", "\n", "        ", "subset_paths", "=", "{", "}", "\n", "if", "testing_file", "is", "None", ":", "\n", "            ", "test_splits", "=", "{", "\n", "\"val\"", ":", "\"val_list.txt\"", ",", "\n", "\"test\"", ":", "\"test_list.txt\"", ",", "\n", "}", "\n", "using_testing_file", "=", "False", "\n", "", "else", ":", "\n", "            ", "test_splits", "=", "{", "\n", "\"val\"", ":", "\"val_list.txt\"", ",", "\n", "\"test\"", ":", "testing_file", ",", "\n", "}", "\n", "using_testing_file", "=", "True", "\n", "print", "(", "f\"using {testing_file}\"", ")", "\n", "", "if", "training_file", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "val_per", "=", "training_file", ".", "split", "(", "'.txt'", ")", "[", "0", "]", ".", "split", "(", "'train_list_'", ")", "[", "1", "]", "\n", "test_splits", "[", "'val'", "]", "=", "f\"val_list_{val_per}.txt\"", "\n", "", "except", "IndexError", ":", "\n", "                ", "pass", "\n", "", "", "for", "split_name", ",", "fname", "in", "test_splits", ".", "items", "(", ")", ":", "\n", "            ", "if", "training_file", "is", "None", ":", "\n", "                ", "print", "(", "f\"using {test_splits['test']} is {using_testing_file} split {split_name}\"", ")", "\n", "subset_paths", "[", "split_name", "]", "=", "{", "\"train\"", ":", "\"train_list.txt\"", ",", "\"val\"", ":", "fname", "}", "\n", "print", "(", "f\"using {subset_paths[split_name]['train']} and {subset_paths[split_name]['val']}\"", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "f\"using {test_splits['test']} is {using_testing_file} split {split_name}\"", ")", "\n", "subset_paths", "[", "split_name", "]", "=", "{", "\"train\"", ":", "training_file", ",", "\"val\"", ":", "fname", "}", "\n", "print", "(", "f\"using {subset_paths[split_name]['train']} and {subset_paths[split_name]['val']}\"", ")", "\n", "\n", "", "", "feature_names", "=", "BaseDataset", ".", "common_feat_names", "(", ")", "\n", "feature_names", ".", "append", "(", "\"audio.vggish.0\"", ")", "\n", "feature_names", ".", "append", "(", "\"audio.audiocaps.0\"", ")", "\n", "feature_names", ".", "append", "(", "\"audio.audiocaps_cnn14.0\"", ")", "\n", "feature_names", ".", "append", "(", "\"audio.cnn10.0\"", ")", "\n", "feature_names", ".", "append", "(", "\"audio.cnn14.0\"", ")", "\n", "feature_names", ".", "append", "(", "\"audio.cnn14_16k.0\"", ")", "\n", "text_feat_paths", "=", "BaseDataset", ".", "common_text_feat_paths", "(", ")", "\n", "text_feat_paths", "=", "{", "key", ":", "Path", "(", "\"text_embeddings\"", ")", "/", "fname", "\n", "for", "key", ",", "fname", "in", "text_feat_paths", ".", "items", "(", ")", "}", "\n", "challenge_text_feat_paths", "=", "{", "key", ":", "f\"text_embeddings/{key}.pkl\"", "\n", "for", "key", "in", "text_feat_paths", "}", "\n", "custom_paths", "=", "{", "\n", "\"audio\"", ":", "[", "\"aggregated_audio/vggish-raw.hickle\"", "]", ",", "\n", "\"pann\"", ":", "[", "\"aggregated_pann/pann-raw.hickle\"", "]", ",", "\n", "\"syncnet\"", ":", "[", "\"aggregated_syncnet/syncnet-raw.hickle\"", "]", ",", "\n", "\"vggsound\"", ":", "[", "\"aggregated_vggsound/vggsound-raw.hickle\"", "]", ",", "\n", "# \"vggsound\": [\"aggregated_vggsound/vggsound-avg.pickle\"],", "\n", "\"audiocaps\"", ":", "[", "\"aggregated_audiocaps/audiocaps-raw.hickle\"", "]", ",", "\n", "\"audiocaps_cnn14\"", ":", "[", "\"aggregated_audiocaps_cnn14/audiocaps_cnn14-raw.hickle\"", "]", ",", "\n", "\"cnn14_16k\"", ":", "[", "\"aggregated_cnn14_16k/cnn14_16k-raw.hickle\"", "]", ",", "\n", "\"cnn14\"", ":", "[", "\"aggregated_cnn14/cnn14-raw.hickle\"", "]", ",", "\n", "\"cnn10\"", ":", "[", "\"aggregated_cnn10/cnn10-raw.hickle\"", "]", ",", "\n", "\"speech\"", ":", "[", "\"aggregated_speech/w2v_mean.pkl\"", "]", "\n", "}", "\n", "feature_info", "=", "{", "\n", "\"custom_paths\"", ":", "custom_paths", ",", "\n", "\"feature_names\"", ":", "feature_names", ",", "\n", "\"subset_list_paths\"", ":", "subset_paths", ",", "\n", "\"text_feat_paths\"", ":", "text_feat_paths", ",", "\n", "\"challenge_text_feat_paths\"", ":", "challenge_text_feat_paths", ",", "\n", "\"raw_captions_path\"", ":", "\"structured-symlinks/raw-captions.pkl\"", ",", "\n", "}", "\n", "return", "feature_info", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.CLOTHO_dataset.CLOTHO.load_features": [[90, 133], ["feat_names.update", "feat_names.items", "CLOTHO_dataset.CLOTHO.visual_feat_paths", "tuple", "CLOTHO_dataset.CLOTHO.load_challenge_text_features", "zsvision.zs_utils.memcache", "zsvision.zs_utils.memcache", "len", "zsvision.zs_utils.memcache", "print", "zsvision.zs_utils.concat_features.cache_info", "print", "zsvision.zs_utils.concat_features", "utils.memory_summary", "copy.deepcopy", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.visual_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.load_challenge_text_features", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memory_summary"], ["", "def", "load_features", "(", "self", ")", ":", "\n", "        ", "root_feat", "=", "self", ".", "root_feat", "\n", "feat_names", "=", "{", "key", ":", "self", ".", "visual_feat_paths", "(", "key", ")", "for", "key", "in", "\n", "self", ".", "paths", "[", "\"feature_names\"", "]", "}", "\n", "feat_names", ".", "update", "(", "self", ".", "paths", "[", "\"custom_paths\"", "]", ")", "\n", "features", "=", "{", "}", "\n", "for", "expert", ",", "rel_names", "in", "feat_names", ".", "items", "(", ")", ":", "\n", "            ", "if", "expert", "not", "in", "self", ".", "ordered_experts", ":", "\n", "                ", "continue", "\n", "", "feat_paths", "=", "tuple", "(", "[", "Path", "(", "root_feat", ")", "/", "rel_name", "for", "rel_name", "in", "rel_names", "]", ")", "\n", "if", "len", "(", "feat_paths", ")", "==", "1", ":", "\n", "                ", "features", "[", "expert", "]", "=", "memcache", "(", "feat_paths", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "# support multiple forms of feature (e.g. max and avg pooling). For", "\n", "# now, we only support direct concatenation", "\n", "                ", "msg", "=", "f\"{expert}: Only direct concatenation of muliple feats is possible\"", "\n", "print", "(", "f\"Concatenating aggregates for {expert}....\"", ")", "\n", "assert", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate\"", "]", "==", "\"concat\"", ",", "msg", "\n", "axis", "=", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate-axis\"", "]", "\n", "x", "=", "concat_features", ".", "cache_info", "(", ")", "# pylint: disable=no-value-for-parameter", "\n", "print", "(", "f\"concat cache info: {x}\"", ")", "\n", "features_", "=", "concat_features", "(", "feat_paths", ",", "axis", "=", "axis", ")", "\n", "memory_summary", "(", ")", "\n", "\n", "# if expert == \"speech\":", "\n", "#     features_defaults = defaultdict(lambda: np.zeros((1, 300)))", "\n", "#     features_defaults.update(features_)", "\n", "#     features_ = features_defaults", "\n", "# Make separate feature copies for each split to allow in-place filtering", "\n", "features", "[", "expert", "]", "=", "copy", ".", "deepcopy", "(", "features_", ")", "\n", "\n", "", "", "self", ".", "features", "=", "features", "\n", "if", "self", ".", "challenge_mode", ":", "\n", "            ", "self", ".", "load_challenge_text_features", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "raw_captions", "=", "memcache", "(", "root_feat", "/", "self", ".", "paths", "[", "\"raw_captions_path\"", "]", ")", "\n", "# keys = list(raw_captions.keys())", "\n", "# raw_captions_fused = {}", "\n", "# for key in keys:", "\n", "#     raw_captions_fused[key] = list(itertools.chain.from_iterable(raw_captions[key]))", "\n", "# self.raw_captions = raw_captions_fused", "\n", "text_feat_path", "=", "root_feat", "/", "self", ".", "paths", "[", "\"text_feat_paths\"", "]", "[", "self", ".", "text_feat", "]", "\n", "self", ".", "text_features", "=", "memcache", "(", "text_feat_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.CLOTHO_dataset.CLOTHO.sanity_checks": [[134, 139], ["None"], "methods", ["None"], ["", "", "def", "sanity_checks", "(", "self", ")", ":", "\n", "        ", "msg", "=", "(", "f\"Expected to have single test caption for CLOTHO, since we assume\"", "\n", "f\"that the captions are fused (but using {self.num_test_captions})\"", ")", "\n", "if", "self", ".", "fuse_captions", "is", "True", ":", "\n", "            ", "assert", "self", ".", "num_test_captions", "==", "1", ",", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.CLOTHO_dataset.CLOTHO.configure_train_test_splits": [[140, 166], ["print", "type().dataset_paths", "print", "time.time", "[].items", "print", "type", "pathlib.Path", "pathlib.Path", "open", "f.read().splitlines", "time.time", "f.read"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.dataset_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "", "def", "configure_train_test_splits", "(", "self", ",", "split_name", ")", ":", "\n", "        ", "\"\"\"Partition the datset into train/val/test splits.\n\n        Args:\n            split_name (str): the name of the split\n        \"\"\"", "\n", "print", "(", "f\"Now working on {split_name}\"", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "self", ".", "paths", "=", "type", "(", "self", ")", ".", "dataset_paths", "(", "training_file", "=", "self", ".", "training_file", ",", "testing_file", "=", "self", ".", "testing_file", ")", "\n", "print", "(", "\"loading training/val splits....\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "for", "subset", ",", "path", "in", "self", ".", "paths", "[", "\"subset_list_paths\"", "]", "[", "split_name", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "self", ".", "challenge_mode", "and", "split_name", "==", "\"public_server_test\"", "and", "subset", "==", "\"val\"", ":", "\n", "                ", "root_feat", "=", "Path", "(", "self", ".", "challenge_test_root_feat_folder", ")", "\n", "", "else", ":", "\n", "                ", "root_feat", "=", "Path", "(", "self", ".", "root_feat", ")", "\n", "", "subset_list_path", "=", "root_feat", "/", "path", "\n", "if", "subset", "==", "\"train\"", "and", "self", ".", "eval_only", ":", "\n", "                ", "rows", "=", "[", "]", "\n", "", "else", ":", "\n", "                ", "with", "open", "(", "subset_list_path", ")", "as", "f", ":", "\n", "                    ", "rows", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "", "self", ".", "partition_lists", "[", "subset", "]", "=", "rows", "\n", "", "print", "(", "\"done in {:.3f}s\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "self", ".", "split_name", "=", "split_name", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.ActivityNet_dataset.ActivityNet.dataset_paths": [[14, 61], ["test_splits.items", "base.base_dataset.BaseDataset.common_feat_names", "base.base_dataset.BaseDataset.common_text_feat_paths", "pathlib.Path", "base.base_dataset.BaseDataset.common_text_feat_paths.items", "text_feat_names.items"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_feat_names", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_text_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["    ", "@", "staticmethod", "\n", "@", "typechecked", "\n", "def", "dataset_paths", "(", "training_file", "=", "None", ")", "->", "Dict", "[", "str", ",", "Union", "[", "str", ",", "List", "[", "str", "]", ",", "Path", ",", "Dict", "]", "]", ":", "\n", "        ", "subset_paths", "=", "{", "}", "\n", "test_splits", "=", "{", "\n", "\"val1\"", ":", "\"val_1_list.txt\"", ",", "\n", "\"val\"", ":", "\"val_list.txt\"", ",", "\n", "\"public_server_val\"", ":", "\"public_server_val.txt\"", ",", "\n", "\"public_server_test\"", ":", "\"public_server_test.txt\"", ",", "\n", "}", "\n", "for", "split_name", ",", "fname", "in", "test_splits", ".", "items", "(", ")", ":", "\n", "            ", "if", "training_file", "is", "None", ":", "\n", "                ", "subset_paths", "[", "split_name", "]", "=", "{", "\"train\"", ":", "\"train_list.txt\"", ",", "\"val\"", ":", "fname", "}", "\n", "", "else", ":", "\n", "                ", "subset_paths", "[", "split_name", "]", "=", "{", "\"train\"", ":", "training_file", ",", "\"val\"", ":", "fname", "}", "\n", "\n", "\n", "", "", "feature_names", "=", "BaseDataset", ".", "common_feat_names", "(", ")", "\n", "custom_paths", "=", "{", "\n", "\"audio\"", ":", "[", "\"aggregated_audio/vggish-audio-raw.pickle\"", "]", ",", "\n", "\"speech\"", ":", "[", "\"aggregated_speech/goog_w2v-speech-raw.pickle\"", "]", ",", "\n", "\"ocr\"", ":", "[", "\"aggregated_ocr_feats/ocr-w2v.pkl\"", "]", ",", "\n", "\"face\"", ":", "[", "\"aggregated_facefeats_25fps_256px_stride1/face-avg.pickle\"", "]", ",", "\n", "}", "\n", "text_feat_paths", "=", "BaseDataset", ".", "common_text_feat_paths", "(", ")", "\n", "text_feat_dir", "=", "Path", "(", "\"aggregated_text_feats\"", ")", "\n", "\n", "text_feat_paths", "=", "{", "key", ":", "text_feat_dir", "/", "fname", "\n", "for", "key", ",", "fname", "in", "text_feat_paths", ".", "items", "(", ")", "}", "\n", "challenge_text_feat_paths", "=", "{", "}", "\n", "# include non-standard text features", "\n", "for", "text_feat", "in", "(", "\"openai\"", ",", ")", ":", "\n", "            ", "text_feat_names", "=", "{", "key", ":", "f\"{text_feat}-{key}\"", "\n", "for", "key", "in", "{", "\"train\"", ",", "\"val1\"", "}", "}", "\n", "text_feat_paths", "[", "text_feat", "]", "=", "{", "key", ":", "f\"aggregated_text_feats/{val}.pkl\"", "\n", "for", "key", ",", "val", "in", "text_feat_names", ".", "items", "(", ")", "}", "\n", "challenge_text_feat_paths", "[", "text_feat", "]", "=", "f\"aggregated_text_feats/{text_feat}.pkl\"", "\n", "", "feature_info", "=", "{", "\n", "\"custom_paths\"", ":", "custom_paths", ",", "\n", "\"feature_names\"", ":", "feature_names", ",", "\n", "\"subset_list_paths\"", ":", "subset_paths", ",", "\n", "\"text_feat_paths\"", ":", "text_feat_paths", ",", "\n", "\"challenge_text_feat_paths\"", ":", "challenge_text_feat_paths", ",", "\n", "\"raw_captions_path\"", ":", "\"raw-captions-train-val_1.pkl\"", ",", "\n", "}", "\n", "return", "feature_info", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.ActivityNet_dataset.ActivityNet.load_features": [[62, 113], ["feat_names.update", "feat_names.items", "list", "enumerate", "ActivityNet_dataset.ActivityNet.visual_feat_paths", "tuple", "ActivityNet_dataset.ActivityNet.load_challenge_text_features", "isinstance", "zsvision.zs_utils.memcache", "map", "zsvision.zs_utils.memcache", "len", "zsvision.zs_utils.memcache", "print", "zsvision.zs_utils.concat_features.cache_info", "print", "zsvision.zs_utils.concat_features", "utils.memory_summary", "copy.deepcopy", "zsvision.zs_utils.memcache", "zsvision.zs_utils.memcache.update", "isinstance", "zsvision.zs_utils.memcache", "zsvision.zs_utils.memcache", "TypeError", "pathlib.Path", "pathlib.Path", "type"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.visual_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.load_challenge_text_features", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memory_summary", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache"], ["", "def", "load_features", "(", "self", ")", ":", "\n", "        ", "root_feat", "=", "self", ".", "root_feat", "\n", "if", "self", ".", "distil_params", "is", "not", "None", ":", "\n", "            ", "self", ".", "distil_features", "=", "{", "}", "\n", "d_base_path", "=", "self", ".", "distil_params", "[", "'base_path'", "]", "\n", "\n", "teachers", "=", "list", "(", "map", "(", "lambda", "x", ":", "root_feat", "/", "Path", "(", "d_base_path", "+", "x", ")", ",", "self", ".", "distil_params", "[", "'teachers'", "]", ")", ")", "\n", "\n", "for", "i", ",", "f_name", "in", "enumerate", "(", "teachers", ")", ":", "\n", "                ", "self", ".", "distil_features", "[", "i", "]", "=", "memcache", "(", "f_name", ")", "\n", "\n", "", "", "feat_names", "=", "{", "key", ":", "self", ".", "visual_feat_paths", "(", "key", ")", "for", "key", "in", "\n", "self", ".", "paths", "[", "\"feature_names\"", "]", "}", "\n", "feat_names", ".", "update", "(", "self", ".", "paths", "[", "\"custom_paths\"", "]", ")", "\n", "features", "=", "{", "}", "\n", "for", "expert", ",", "rel_names", "in", "feat_names", ".", "items", "(", ")", ":", "\n", "            ", "if", "expert", "not", "in", "self", ".", "ordered_experts", ":", "\n", "                ", "continue", "\n", "", "feat_paths", "=", "tuple", "(", "[", "Path", "(", "root_feat", ")", "/", "rel_name", "for", "rel_name", "in", "rel_names", "]", ")", "\n", "if", "len", "(", "feat_paths", ")", "==", "1", ":", "\n", "                ", "features", "[", "expert", "]", "=", "memcache", "(", "feat_paths", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "# support multiple forms of feature (e.g. max and avg pooling). For", "\n", "# now, we only support direct concatenation", "\n", "                ", "msg", "=", "f\"{expert}: Only direct concatenation of muliple feats is possible\"", "\n", "print", "(", "f\"Concatenating aggregates for {expert}....\"", ")", "\n", "assert", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate\"", "]", "==", "\"concat\"", ",", "msg", "\n", "axis", "=", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate-axis\"", "]", "\n", "x", "=", "concat_features", ".", "cache_info", "(", ")", "# pylint: disable=no-value-for-parameter", "\n", "print", "(", "f\"concat cache info: {x}\"", ")", "\n", "features_", "=", "concat_features", "(", "feat_paths", ",", "axis", "=", "axis", ")", "\n", "memory_summary", "(", ")", "\n", "\n", "# Make separate feature copies for each split to allow in-place filtering", "\n", "features", "[", "expert", "]", "=", "copy", ".", "deepcopy", "(", "features_", ")", "\n", "\n", "", "", "self", ".", "features", "=", "features", "\n", "if", "self", ".", "challenge_mode", ":", "\n", "            ", "self", ".", "load_challenge_text_features", "(", ")", "\n", "", "else", ":", "\n", "            ", "text_feat_paths", "=", "self", ".", "paths", "[", "\"text_feat_paths\"", "]", "[", "self", ".", "text_feat", "]", "\n", "if", "isinstance", "(", "text_feat_paths", ",", "dict", ")", ":", "\n", "                ", "text_features", "=", "memcache", "(", "root_feat", "/", "text_feat_paths", "[", "\"train\"", "]", ")", "\n", "text_features", ".", "update", "(", "memcache", "(", "\n", "root_feat", "/", "text_feat_paths", "[", "self", ".", "split_name", "]", ")", ")", "\n", "", "elif", "isinstance", "(", "text_feat_paths", ",", "(", "Path", ",", "str", ")", ")", ":", "\n", "                ", "text_features", "=", "memcache", "(", "root_feat", "/", "text_feat_paths", ")", "\n", "", "else", ":", "\n", "                ", "raise", "TypeError", "(", "f\"Unexpected type {type(text_feat_paths)}\"", ")", "\n", "", "self", ".", "text_features", "=", "text_features", "\n", "self", ".", "raw_captions", "=", "memcache", "(", "root_feat", "/", "self", ".", "paths", "[", "\"raw_captions_path\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.ActivityNet_dataset.ActivityNet.sanity_checks": [[114, 118], ["None"], "methods", ["None"], ["", "", "def", "sanity_checks", "(", "self", ")", ":", "\n", "        ", "msg", "=", "(", "f\"Expected to have single test caption for ANet, since we assume\"", "\n", "f\"that the captions are fused (but using {self.num_test_captions})\"", ")", "\n", "assert", "self", ".", "num_test_captions", "==", "1", ",", "msg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.QuerYD_dataset.QuerYD.dataset_paths": [[14, 44], ["test_splits.items", "base.base_dataset.BaseDataset.common_feat_names", "base.base_dataset.BaseDataset.common_feat_names.append", "base.base_dataset.BaseDataset.common_text_feat_paths", "pathlib.Path", "base.base_dataset.BaseDataset.common_text_feat_paths.items"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_feat_names", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_text_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["    ", "@", "staticmethod", "\n", "@", "typechecked", "\n", "def", "dataset_paths", "(", "training_file", "=", "None", ")", "->", "Dict", "[", "str", ",", "Union", "[", "str", ",", "List", "[", "str", "]", ",", "Path", ",", "Dict", "]", "]", ":", "\n", "        ", "subset_paths", "=", "{", "}", "\n", "test_splits", "=", "{", "\n", "\"val\"", ":", "\"val_list.txt\"", ",", "\n", "\"test\"", ":", "\"test_list.txt\"", ",", "\n", "}", "\n", "for", "split_name", ",", "fname", "in", "test_splits", ".", "items", "(", ")", ":", "\n", "            ", "subset_paths", "[", "split_name", "]", "=", "{", "\"train\"", ":", "\"train_list.txt\"", ",", "\"val\"", ":", "fname", "}", "\n", "\n", "", "feature_names", "=", "BaseDataset", ".", "common_feat_names", "(", ")", "\n", "feature_names", ".", "append", "(", "\"audio.vggish.0\"", ")", "\n", "text_feat_paths", "=", "BaseDataset", ".", "common_text_feat_paths", "(", ")", "\n", "text_feat_paths", "=", "{", "key", ":", "Path", "(", "\"text_embeddings\"", ")", "/", "fname", "\n", "for", "key", ",", "fname", "in", "text_feat_paths", ".", "items", "(", ")", "}", "\n", "challenge_text_feat_paths", "=", "{", "key", ":", "f\"text_embeddings/{key}.pkl\"", "\n", "for", "key", "in", "text_feat_paths", "}", "\n", "custom_paths", "=", "{", "\n", "\"audio\"", ":", "[", "\"aggregated_audio/vggish-raw.hickle\"", "]", ",", "\n", "}", "\n", "feature_info", "=", "{", "\n", "\"custom_paths\"", ":", "custom_paths", ",", "\n", "\"feature_names\"", ":", "feature_names", ",", "\n", "\"subset_list_paths\"", ":", "subset_paths", ",", "\n", "\"text_feat_paths\"", ":", "text_feat_paths", ",", "\n", "\"challenge_text_feat_paths\"", ":", "challenge_text_feat_paths", ",", "\n", "\"raw_captions_path\"", ":", "\"structured-symlinks/raw_captions_combined_filtered.pkl\"", ",", "\n", "}", "\n", "return", "feature_info", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.QuerYD_dataset.QuerYD.load_features": [[45, 88], ["feat_names.update", "feat_names.items", "QuerYD_dataset.QuerYD.visual_feat_paths", "tuple", "QuerYD_dataset.QuerYD.load_challenge_text_features", "zsvision.zs_utils.memcache", "zsvision.zs_utils.memcache", "len", "zsvision.zs_utils.memcache", "print", "zsvision.zs_utils.concat_features.cache_info", "print", "zsvision.zs_utils.concat_features", "utils.memory_summary", "copy.deepcopy", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.visual_feat_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.load_challenge_text_features", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memory_summary"], ["", "def", "load_features", "(", "self", ")", ":", "\n", "        ", "root_feat", "=", "self", ".", "root_feat", "\n", "feat_names", "=", "{", "key", ":", "self", ".", "visual_feat_paths", "(", "key", ")", "for", "key", "in", "\n", "self", ".", "paths", "[", "\"feature_names\"", "]", "}", "\n", "feat_names", ".", "update", "(", "self", ".", "paths", "[", "\"custom_paths\"", "]", ")", "\n", "features", "=", "{", "}", "\n", "for", "expert", ",", "rel_names", "in", "feat_names", ".", "items", "(", ")", ":", "\n", "            ", "if", "expert", "not", "in", "self", ".", "ordered_experts", ":", "\n", "                ", "continue", "\n", "", "feat_paths", "=", "tuple", "(", "[", "Path", "(", "root_feat", ")", "/", "rel_name", "for", "rel_name", "in", "rel_names", "]", ")", "\n", "if", "len", "(", "feat_paths", ")", "==", "1", ":", "\n", "                ", "features", "[", "expert", "]", "=", "memcache", "(", "feat_paths", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "# support multiple forms of feature (e.g. max and avg pooling). For", "\n", "# now, we only support direct concatenation", "\n", "                ", "msg", "=", "f\"{expert}: Only direct concatenation of muliple feats is possible\"", "\n", "print", "(", "f\"Concatenating aggregates for {expert}....\"", ")", "\n", "assert", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate\"", "]", "==", "\"concat\"", ",", "msg", "\n", "axis", "=", "self", ".", "feat_aggregation", "[", "expert", "]", "[", "\"aggregate-axis\"", "]", "\n", "x", "=", "concat_features", ".", "cache_info", "(", ")", "# pylint: disable=no-value-for-parameter", "\n", "print", "(", "f\"concat cache info: {x}\"", ")", "\n", "features_", "=", "concat_features", "(", "feat_paths", ",", "axis", "=", "axis", ")", "\n", "memory_summary", "(", ")", "\n", "\n", "# Make separate feature copies for each split to allow in-place filtering", "\n", "features", "[", "expert", "]", "=", "copy", ".", "deepcopy", "(", "features_", ")", "\n", "\n", "", "", "self", ".", "features", "=", "features", "\n", "if", "self", ".", "challenge_mode", ":", "\n", "            ", "self", ".", "load_challenge_text_features", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "raw_captions", "=", "memcache", "(", "root_feat", "/", "self", ".", "paths", "[", "\"raw_captions_path\"", "]", ")", "\n", "# keys = list(raw_captions.keys())", "\n", "# raw_captions_fused = {}", "\n", "# for key in keys:", "\n", "#     raw_captions_fused[key] = list(itertools.chain.from_iterable(raw_captions[key]))", "\n", "# self.raw_captions = raw_captions_fused", "\n", "text_feat_path", "=", "root_feat", "/", "self", ".", "paths", "[", "\"text_feat_paths\"", "]", "[", "self", ".", "text_feat", "]", "\n", "self", ".", "text_features", "=", "memcache", "(", "text_feat_path", ")", "\n", "\n", "# overload video paths, which are structured differently for YouCook2", "\n", "", "self", ".", "video_path_retrieval", "=", "[", "f\"videos/{x}.mp4\"", "\n", "for", "x", "in", "self", ".", "partition_lists", "[", "\"val\"", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.QuerYD_dataset.QuerYD.sanity_checks": [[89, 93], ["None"], "methods", ["None"], ["", "def", "sanity_checks", "(", "self", ")", ":", "\n", "        ", "msg", "=", "(", "f\"Expected to have single test caption for QuerYD, since we assume\"", "\n", "f\"that the captions are fused (but using {self.num_test_captions})\"", ")", "\n", "assert", "self", ".", "num_test_captions", "==", "1", ",", "msg", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.audiocaps_dataset.AudioCaps.configure_train_test_splits": [[25, 77], ["utils.util.get_expert_paths", "ValueError", "os.path.join", "len", "os.path.join", "len", "os.path.join", "msg.format", "open", "f.readlines", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_expert_paths"], ["def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "    ", "if", "cut_name", "in", "[", "\"c\"", "]", ":", "\n", "      ", "self", ".", "expert_paths", "=", "get_expert_paths", "(", "self", ".", "data_dir", ")", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", "]", ":", "\n", "        ", "train_list_path", "=", "\"train_list.txt\"", "\n", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "val_list_path", "=", "\"filtered_val_list.txt\"", "\n", "val_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "val_list_path", ")", "\n", "with", "open", "(", "val_list_path", ")", "as", "f", ":", "\n", "          ", "val_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_val_samples", "=", "len", "(", "val_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "+", "val_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "if", "self", ".", "cross_seed", "!=", "0", ":", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "          ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"train\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_train_samples", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "# In order to monitor performance on the training set, we sample", "\n", "# from it as many samples as there are validation samples.", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_val_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_train_samples", ":", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "split_name", "==", "\"test\"", ":", "\n", "          ", "list_path", "=", "\"final_filtered_test_list.txt\"", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "list_path", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "          ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "else", ":", "\n", "      ", "msg", "=", "\"unrecognised cut: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "cut_name", ")", ")", "\n", "\n", "", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "dataset_name", "=", "f\"AudioCaps_{cut_name}_{split_name}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.sounddescs_dataset.SoundDescs.configure_train_test_splits": [[25, 77], ["utils.util.get_expert_paths", "ValueError", "os.path.join", "len", "os.path.join", "len", "os.path.join", "msg.format", "open", "f.readlines", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_expert_paths"], ["def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "    ", "if", "cut_name", "in", "[", "\"c\"", "]", ":", "\n", "      ", "self", ".", "expert_paths", "=", "get_expert_paths", "(", "self", ".", "data_dir", ")", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", "]", ":", "\n", "        ", "train_list_path", "=", "\"train_list.txt\"", "\n", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "val_list_path", "=", "\"val_list.txt\"", "\n", "val_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "val_list_path", ")", "\n", "with", "open", "(", "val_list_path", ")", "as", "f", ":", "\n", "          ", "val_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_val_samples", "=", "len", "(", "val_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "+", "val_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "if", "self", ".", "cross_seed", "!=", "0", ":", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "          ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"train\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_train_samples", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "# In order to monitor performance on the training set, we sample", "\n", "# from it as many samples as there are validation samples.", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_val_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_train_samples", ":", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "split_name", "==", "\"test\"", ":", "\n", "          ", "list_path", "=", "\"test_list.txt\"", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "list_path", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "          ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "else", ":", "\n", "      ", "msg", "=", "\"unrecognised cut: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "cut_name", ")", ")", "\n", "\n", "", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "dataset_name", "=", "f\"BBCSound_{cut_name}_{split_name}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.didemo_dataset.DiDeMo.configure_train_test_splits": [[25, 107], ["os.path.join", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "utils.util.get_expert_paths", "ValueError", "os.path.join", "len", "os.path.join", "len", "os.path.join", "msg.format", "ValueError", "open", "f.readlines", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_expert_paths"], ["def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "    ", "if", "cut_name", "in", "[", "\"full\"", "]", ":", "\n", "      ", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "        ", "list_path", "=", "\"train_list.txt\"", "\n", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "        ", "list_path", "=", "\"val_list.txt\"", "\n", "", "elif", "split_name", "in", "[", "\"test\"", "]", ":", "\n", "        ", "list_path", "=", "\"test_list.txt\"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"unrecognised DiDeMo split: {split_name}\"", ")", "\n", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_feat", ",", "list_path", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "        ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "# We want the trn split to be the same size as the val set", "\n", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "        ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "if", "cut_name", "in", "[", "\"c\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "840", "]", "\n", "", "else", ":", "\n", "          ", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "1065", "]", "\n", "\n", "", "", "", "elif", "cut_name", "in", "[", "\"c\"", "]", ":", "\n", "      ", "self", ".", "expert_paths", "=", "get_expert_paths", "(", "self", ".", "data_dir", ")", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "train_list_path", "=", "\"train_list.txt\"", "\n", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "val_list_path", "=", "\"val_list.txt\"", "\n", "val_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "val_list_path", ")", "\n", "with", "open", "(", "val_list_path", ")", "as", "f", ":", "\n", "          ", "val_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_val_samples", "=", "len", "(", "val_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "+", "val_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "if", "self", ".", "cross_seed", "!=", "0", ":", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "          ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"trainval\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"trainval\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "\n", "", "elif", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_train_samples", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "# In order to monitor performance on the training set, we sample", "\n", "# from it as many samples as there are validation samples.", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_val_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_train_samples", ":", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "split_name", "==", "\"test1\"", ":", "\n", "          ", "list_path", "=", "\"public_server_val.txt\"", "\n", "", "elif", "split_name", "==", "\"test2\"", ":", "\n", "          ", "list_path", "=", "\"public_server_test.txt\"", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "list_path", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "          ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "else", ":", "\n", "      ", "msg", "=", "\"unrecognised cut: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "cut_name", ")", ")", "\n", "\n", "", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "dataset_name", "=", "f\"DiDeMo_{cut_name}_{split_name}\"", "\n", "\n", "self", ".", "expert_timings", "=", "{", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.clotho_dataset.Clotho.configure_train_test_splits": [[25, 77], ["utils.util.get_expert_paths", "ValueError", "os.path.join", "len", "os.path.join", "len", "os.path.join", "msg.format", "open", "f.readlines", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_expert_paths"], ["def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "    ", "if", "cut_name", "in", "[", "\"c\"", "]", ":", "\n", "      ", "self", ".", "expert_paths", "=", "get_expert_paths", "(", "self", ".", "data_dir", ")", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", "]", ":", "\n", "        ", "train_list_path", "=", "\"train_list.txt\"", "\n", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "val_list_path", "=", "\"val_list.txt\"", "\n", "val_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "val_list_path", ")", "\n", "with", "open", "(", "val_list_path", ")", "as", "f", ":", "\n", "          ", "val_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_val_samples", "=", "len", "(", "val_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "+", "val_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "if", "self", ".", "cross_seed", "!=", "0", ":", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "          ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"train\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_train_samples", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "# In order to monitor performance on the training set, we sample", "\n", "# from it as many samples as there are validation samples.", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_val_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_train_samples", ":", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "split_name", "==", "\"test\"", ":", "\n", "          ", "list_path", "=", "\"test_list.txt\"", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "list_path", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "          ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "else", ":", "\n", "      ", "msg", "=", "\"unrecognised cut: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "cut_name", ")", ")", "\n", "\n", "", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "dataset_name", "=", "f\"Clotho_{cut_name}_{split_name}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.youcook2_dataset.YouCook2.configure_train_test_splits": [[26, 105], ["os.path.join", "print", "time.time", "print", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "utils.util.get_expert_paths", "ValueError", "os.path.join", "len", "os.path.join", "len", "os.path.join", "msg.format", "ValueError", "time.time", "open", "f.readlines", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_expert_paths"], ["def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "    ", "if", "cut_name", "in", "[", "\"full\"", "]", ":", "\n", "      ", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "        ", "list_path", "=", "\"train_list.txt\"", "\n", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "        ", "list_path", "=", "\"val_list.txt\"", "\n", "", "elif", "split_name", "in", "[", "\"test\"", "]", ":", "\n", "        ", "list_path", "=", "\"test_list.txt\"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"unrecognised split: {split_name}\"", ")", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_feat", ",", "list_path", ")", "\n", "print", "(", "\"loading split ...\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "        ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "print", "(", "\"done in {:.3f}s\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "\n", "# We want the trn split to be the same size as the val set", "\n", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "        ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "3310", "]", "\n", "\n", "", "", "elif", "cut_name", "in", "[", "\"c\"", "]", ":", "\n", "      ", "self", ".", "expert_paths", "=", "get_expert_paths", "(", "self", ".", "data_dir", ")", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "train_list_path", "=", "\"train_list.txt\"", "\n", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "val_list_path", "=", "\"val_list.txt\"", "\n", "val_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "val_list_path", ")", "\n", "with", "open", "(", "val_list_path", ")", "as", "f", ":", "\n", "          ", "val_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_val_samples", "=", "len", "(", "val_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "+", "val_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "if", "self", ".", "cross_seed", "!=", "0", ":", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "          ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"trainval\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"trainval\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "\n", "", "elif", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_train_samples", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "# In order to monitor performance on the training set, we sample", "\n", "# from it as many samples as there are validation samples.", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_val_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_train_samples", ":", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "split_name", "==", "\"test1\"", ":", "\n", "          ", "list_path", "=", "\"public_server_val.txt\"", "\n", "", "elif", "split_name", "==", "\"test2\"", ":", "\n", "          ", "list_path", "=", "\"public_server_test.txt\"", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "list_path", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "          ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "else", ":", "\n", "      ", "msg", "=", "\"unrecognised cut: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "cut_name", ")", ")", "\n", "\n", "", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "dataset_name", "=", "f\"YouCook2_{cut_name}_{split_name}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.msvd_dataset.MSVD.configure_train_test_splits": [[26, 110], ["os.path.join", "print", "time.time", "print", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "utils.util.get_expert_paths", "ValueError", "os.path.join", "len", "os.path.join", "len", "os.path.join", "msg.format", "ValueError", "time.time", "open", "f.readlines", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_expert_paths"], ["def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "    ", "if", "cut_name", "in", "[", "\"full\"", "]", ":", "\n", "      ", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "        ", "list_path", "=", "\"train_list.txt\"", "\n", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "        ", "list_path", "=", "\"val_list.txt\"", "\n", "", "elif", "split_name", "in", "[", "\"test\"", "]", ":", "\n", "        ", "list_path", "=", "\"test_list.txt\"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"unrecognised MSVD split: {split_name}\"", ")", "\n", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_feat", ",", "list_path", ")", "\n", "\n", "print", "(", "\"loading split ...\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "        ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "print", "(", "\"done in {:.3f}s\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "\n", "# We want the trn split to be the same size as the val set", "\n", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "        ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "if", "cut_name", "in", "[", "\"c\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "120", "]", "\n", "", "else", ":", "\n", "          ", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "670", "]", "\n", "\n", "", "", "", "elif", "cut_name", "in", "[", "\"c\"", "]", ":", "\n", "      ", "self", ".", "expert_paths", "=", "get_expert_paths", "(", "self", ".", "data_dir", ")", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "train_list_path", "=", "\"train_list.txt\"", "\n", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "val_list_path", "=", "\"val_list.txt\"", "\n", "val_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "val_list_path", ")", "\n", "with", "open", "(", "val_list_path", ")", "as", "f", ":", "\n", "          ", "val_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_val_samples", "=", "len", "(", "val_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "+", "val_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "if", "self", ".", "cross_seed", "!=", "0", ":", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "          ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"trainval\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"trainval\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "\n", "", "elif", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_train_samples", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "# In order to monitor performance on the training set, we sample", "\n", "# from it as many samples as there are validation samples.", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_val_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_train_samples", ":", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "split_name", "==", "\"test1\"", ":", "\n", "          ", "list_path", "=", "\"public_server_val.txt\"", "\n", "", "elif", "split_name", "==", "\"test2\"", ":", "\n", "          ", "list_path", "=", "\"public_server_test.txt\"", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "list_path", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "          ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "else", ":", "\n", "      ", "msg", "=", "\"unrecognised cut: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "cut_name", ")", ")", "\n", "\n", "", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "dataset_name", "=", "f\"MSVD_{cut_name}_{split_name}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.mix_dataset.MixDataset.configure_train_test_splits": [[38, 42], ["None"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "configure_train_test_splits", "(", "self", ",", "split_name", ")", ":", "\n", "    ", "\"\"\"Partition the datset into train/val/test splits.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.mix_dataset.MixDataset.sanity_checks": [[43, 47], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "sanity_checks", "(", "self", ")", ":", "\n", "    ", "\"\"\"Run sanity checks on loaded data.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.mix_dataset.MixDataset.load_features": [[48, 52], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "load_features", "(", "self", ")", ":", "\n", "    ", "\"\"\"Load features from disk.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.mix_dataset.MixDataset.__init__": [[53, 118], ["set", "logger.debug", "logger.debug", "raw_input_dims.keys", "len", "config.copy", "mix_dataset.MixDataset.dataset_names.append", "config.copy.pop", "mix_dataset.MixDataset.datasets.append", "config.copy.keys", "mix_dataset.MixDataset.mix_weights.append", "config.copy.pop", "mix_dataset.MixDataset.mix_weights.append", "float", "sum"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["", "def", "__init__", "(", "self", ",", "\n", "mix", ",", "\n", "raw_input_dims", ",", "\n", "training", "=", "False", ",", "\n", "tokenizer", "=", "None", ",", "\n", "n_pairs", "=", "1", ",", "\n", "loaded_data", "=", "None", ",", "\n", "cross_seed", "=", "0", ")", ":", "\n", "\n", "    ", "self", ".", "sanity_checks", "=", "False", "\n", "self", ".", "mix", "=", "mix", "\n", "self", ".", "experts", "=", "set", "(", "raw_input_dims", ".", "keys", "(", ")", ")", "\n", "self", ".", "train", "=", "training", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "n_pairs", "=", "n_pairs", "\n", "\n", "if", "len", "(", "mix", ")", "==", "1", ":", "\n", "      ", "self", ".", "dataset_name", "=", "\"_\"", ".", "join", "(", "\n", "[", "mix", "[", "0", "]", "[", "\"dataset_name\"", "]", ",", "mix", "[", "0", "]", "[", "\"cut_name\"", "]", ",", "mix", "[", "0", "]", "[", "\"split_name\"", "]", "]", ")", "\n", "self", ".", "split_name", "=", "mix", "[", "0", "]", "[", "\"split_name\"", "]", "\n", "", "else", ":", "\n", "      ", "self", ".", "dataset_name", "=", "\"Mix\"", "\n", "self", ".", "split_name", "=", "\"mic\"", "\n", "\n", "", "dataset_classes", "=", "{", "\n", "\"MSVD\"", ":", "MSVD", ",", "\n", "\"LSMDC\"", ":", "LSMDC", ",", "\n", "\"MSRVTT\"", ":", "MSRVTT", ",", "\n", "\"DiDeMo\"", ":", "DiDeMo", ",", "\n", "\"ActivityNet\"", ":", "ActivityNet", ",", "\n", "\"YouCook2\"", ":", "YouCook2", ",", "\n", "\"HowTo100M\"", ":", "HowTo100M", ",", "\n", "\"AudioCaps\"", ":", "AudioCaps", ",", "\n", "\"Clotho\"", ":", "Clotho", ",", "\n", "\"SoundDescs\"", ":", "SoundDescs", "\n", "}", "\n", "\n", "self", ".", "datasets", "=", "[", "]", "\n", "self", ".", "mix_weights", "=", "[", "]", "\n", "self", ".", "dataset_names", "=", "[", "]", "\n", "for", "config", "in", "mix", ":", "\n", "      ", "dataset_config", "=", "config", ".", "copy", "(", ")", "\n", "if", "\"mix_weight\"", "in", "dataset_config", ".", "keys", "(", ")", ":", "\n", "        ", "self", ".", "mix_weights", ".", "append", "(", "dataset_config", "[", "\"mix_weight\"", "]", ")", "\n", "dataset_config", ".", "pop", "(", "\"mix_weight\"", ")", "\n", "", "else", ":", "\n", "        ", "self", ".", "mix_weights", ".", "append", "(", "1", ")", "\n", "\n", "", "dataset_name", "=", "dataset_config", "[", "\"dataset_name\"", "]", "\n", "self", ".", "dataset_names", ".", "append", "(", "dataset_name", ")", "\n", "dataset_config", ".", "pop", "(", "\"dataset_name\"", ")", "\n", "dataset", "=", "dataset_classes", "[", "dataset_name", "]", "(", "**", "dataset_config", ",", "\n", "raw_input_dims", "=", "raw_input_dims", ",", "\n", "training", "=", "training", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "n_pairs", "=", "n_pairs", ",", "\n", "loaded_data", "=", "loaded_data", ",", "\n", "cross_seed", "=", "cross_seed", ")", "\n", "self", ".", "datasets", ".", "append", "(", "dataset", ")", "\n", "\n", "", "self", ".", "mix_weights", "=", "[", "\n", "float", "(", "i", ")", "/", "sum", "(", "self", ".", "mix_weights", ")", "for", "i", "in", "self", ".", "mix_weights", "\n", "]", "\n", "logger", ".", "debug", "(", "\"Datasets: %s\"", ",", "self", ".", "dataset_names", ")", "\n", "logger", ".", "debug", "(", "\"mix_weights: %s\"", ",", "self", ".", "mix_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.mix_dataset.MixDataset.collate_data": [[119, 152], ["[].keys", "[].keys", "[].keys", "enumerate", "numpy.concatenate().astype", "text_tensors[].append", "lists[].extend", "numpy.concatenate().astype", "[].append", "numpy.concatenate", "numpy.concatenate", "numpy.expand_dims"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["", "def", "collate_data", "(", "self", ",", "data", ")", ":", "\n", "    ", "text_keys", "=", "data", "[", "0", "]", "[", "\"text_tensors\"", "]", ".", "keys", "(", ")", "\n", "text_tensors", "=", "{", "key", ":", "[", "]", "for", "key", "in", "text_keys", "}", "\n", "\n", "vid_keys", "=", "data", "[", "0", "]", "[", "\"vid_tensors\"", "]", ".", "keys", "(", ")", "\n", "vid_tensors", "=", "{", "\n", "key", ":", "{", "expert", ":", "[", "]", "for", "expert", "in", "self", ".", "experts", "}", "for", "key", "in", "vid_keys", "\n", "}", "\n", "\n", "l_keys", "=", "data", "[", "0", "]", "[", "\"lists\"", "]", ".", "keys", "(", ")", "\n", "lists", "=", "{", "key", ":", "[", "]", "for", "key", "in", "l_keys", "}", "\n", "\n", "for", "_", ",", "vid", "in", "enumerate", "(", "data", ")", ":", "\n", "      ", "for", "key", "in", "text_keys", ":", "\n", "        ", "text_tensors", "[", "key", "]", ".", "append", "(", "vid", "[", "\"text_tensors\"", "]", "[", "key", "]", ")", "\n", "", "for", "key", "in", "vid_keys", ":", "\n", "        ", "for", "expert", "in", "self", ".", "experts", ":", "\n", "          ", "vid_tensors", "[", "key", "]", "[", "expert", "]", ".", "append", "(", "vid", "[", "\"vid_tensors\"", "]", "[", "key", "]", "[", "expert", "]", ")", "\n", "", "", "for", "key", "in", "l_keys", ":", "\n", "        ", "lists", "[", "key", "]", ".", "extend", "(", "vid", "[", "\"lists\"", "]", "[", "key", "]", ")", "\n", "\n", "# Concatenate the arrays of each sample to form a batch", "\n", "", "", "for", "key", "in", "text_keys", ":", "\n", "      ", "text_tensors", "[", "key", "]", "=", "np", ".", "concatenate", "(", "text_tensors", "[", "key", "]", ",", "\n", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "", "for", "key", "in", "vid_keys", ":", "\n", "      ", "for", "expert", "in", "self", ".", "experts", ":", "\n", "        ", "vid_tensors", "[", "key", "]", "[", "expert", "]", "=", "np", ".", "concatenate", "(", "np", ".", "expand_dims", "(", "vid_tensors", "[", "key", "]", "[", "expert", "]", ",", "axis", "=", "0", ")", ",", "\n", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "", "minibatch", "=", "{", "**", "text_tensors", ",", "**", "vid_tensors", ",", "**", "lists", "}", "\n", "\n", "return", "minibatch", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.mix_dataset.MixDataset.__len__": [[153, 169], ["len", "int", "len", "int"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "if", "len", "(", "self", ".", "mix", ")", "==", "1", ":", "\n", "      ", "if", "self", ".", "train", ":", "\n", "# If it is a training dataset, we let the trainer decide when the epoch", "\n", "# is completed.", "\n", "        ", "return", "int", "(", "1E7", ")", "\n", "", "else", ":", "\n", "        ", "return", "len", "(", "self", ".", "datasets", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "      ", "if", "self", ".", "train", ":", "\n", "# If it is a training dataset, we let the trainer decide when the epoch", "\n", "# is completed.", "\n", "        ", "return", "int", "(", "1E7", ")", "\n", "", "else", ":", "\n", "# Normaly there should not be evaluation on the mix dataset", "\n", "        ", "return", "1000", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.mix_dataset.MixDataset.__getitem__": [[170, 182], ["numpy.random.RandomState.choice", "numpy.random.RandomState", "len"], "methods", ["None"], ["", "", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "    ", "if", "self", ".", "train", ":", "\n", "      ", "rng", "=", "np", ".", "random", "\n", "", "else", ":", "\n", "# Deterministic", "\n", "      ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "idx", ")", "\n", "\n", "# Select the dataset", "\n", "", "dataset_nb", "=", "rng", ".", "choice", "(", "len", "(", "self", ".", "mix", ")", ",", "p", "=", "self", ".", "mix_weights", ")", "\n", "dataset", "=", "self", ".", "datasets", "[", "dataset_nb", "]", "\n", "return", "dataset", "[", "idx", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.activitynet_dataset.ActivityNet.configure_train_test_splits": [[25, 119], ["os.path.join", "len", "open", "f.readlines", "os.path.join", "len", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "utils.util.get_expert_paths", "ValueError", "open", "f.readlines", "x.strip", "os.path.join", "len", "os.path.join", "len", "os.path.join", "msg.format", "x.strip", "open", "f.readlines", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_expert_paths"], ["def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "    ", "if", "cut_name", "in", "[", "\"val1\"", "]", ":", "\n", "      ", "train_list_path", "=", "\"train_list.txt\"", "\n", "test_list_path", "=", "\"val_1_list.txt\"", "\n", "\n", "test_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "test_list_path", ")", "\n", "with", "open", "(", "test_list_path", ")", "as", "f", ":", "\n", "        ", "test_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_test_samples", "=", "len", "(", "test_vid_list", ")", "\n", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"trainval\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"trainval\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "\n", "", "elif", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_test_samples", ":", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_test_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_test_samples", "]", "\n", "\n", "", "", "elif", "split_name", "==", "\"test\"", ":", "\n", "        ", "self", ".", "vid_list", "=", "test_vid_list", "\n", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "elif", "cut_name", "in", "[", "\"c\"", "]", ":", "\n", "      ", "self", ".", "expert_paths", "=", "get_expert_paths", "(", "self", ".", "data_dir", ")", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "train_list_path", "=", "\"train_list.txt\"", "\n", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "val_list_path", "=", "\"val_list.txt\"", "\n", "val_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "val_list_path", ")", "\n", "with", "open", "(", "val_list_path", ")", "as", "f", ":", "\n", "          ", "val_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_val_samples", "=", "len", "(", "val_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "+", "val_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "if", "self", ".", "cross_seed", "!=", "0", ":", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "          ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"trainval\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"trainval\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "\n", "", "elif", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_train_samples", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "# In order to monitor performance on the training set, we sample", "\n", "# from it as many samples as there are validation samples.", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_val_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_train_samples", ":", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "split_name", "==", "\"test1\"", ":", "\n", "          ", "list_path", "=", "\"public_server_val.txt\"", "\n", "", "elif", "split_name", "==", "\"test2\"", ":", "\n", "          ", "list_path", "=", "\"public_server_test.txt\"", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "list_path", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "          ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "else", ":", "\n", "      ", "msg", "=", "\"unrecognised cut: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "cut_name", ")", ")", "\n", "\n", "", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "dataset_name", "=", "f\"ActivityNet_{cut_name}_{split_name}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.lsmdc_dataset.LSMDC.configure_train_test_splits": [[25, 79], ["os.path.join", "pandas.read_csv", "list", "len", "os.path.join", "pandas.read_csv", "list", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "lsmdc_dataset.LSMDC.vid_list.remove", "x.strip", "x.strip"], "methods", ["None"], ["def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "\n", "    ", "if", "cut_name", "in", "[", "\"full\"", "]", ":", "\n", "      ", "train_list_path", "=", "\"LSMDC16_annos_training.csv\"", "\n", "test_list_path", "=", "\"LSMDC16_challenge_1000_publictect.csv\"", "\n", "\n", "test_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "test_list_path", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "test_list_path", ",", "delimiter", "=", "\"\\t\"", ",", "header", "=", "None", ")", "\n", "test_vid_list", "=", "list", "(", "df", "[", "0", "]", ")", "\n", "nb_test_samples", "=", "len", "(", "test_vid_list", ")", "\n", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "train_list_path", ",", "delimiter", "=", "\"\\t\"", ",", "header", "=", "None", ")", "\n", "train_vid_list", "=", "list", "(", "df", "[", "0", "]", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"trainval\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"trainval\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "\n", "", "elif", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_test_samples", ":", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_test_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_test_samples", "]", "\n", "\n", "", "", "elif", "split_name", "==", "\"test\"", ":", "\n", "        ", "self", ".", "vid_list", "=", "test_vid_list", "\n", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "# There are five videos without captions in the training set, so we drop", "\n", "# them.", "\n", "", "", "movies", "=", "[", "\n", "\"0024_THE_LORD_OF_THE_RINGS_THE_FELLOWSHIP_OF_THE_RING_00.31.10.217-00.31.10.706\"", ",", "\n", "\"1014_2012_00.01.21.399-00.01.23.997\"", ",", "\n", "\"1014_2012_00.27.58.174-00.27.59.021\"", ",", "\n", "\"1018_Body_Of_Lies_00.42.15.677-00.42.18.534\"", ",", "\n", "\"1037_The_Curious_Case_Of_Benjamin_Button_02.25.14.743-02.25.17.312\"", ",", "\n", "]", "\n", "for", "movie", "in", "movies", ":", "\n", "      ", "if", "movie", "in", "self", ".", "vid_list", ":", "\n", "        ", "self", ".", "vid_list", ".", "remove", "(", "movie", ")", "\n", "\n", "", "", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "dataset_name", "=", "f\"LSMDC_{cut_name}_{split_name}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.msrvtt_dataset.MSRVTT.configure_train_test_splits": [[27, 156], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "open", "f.readlines", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "utils.util.memcache", "open", "f.readlines", "x.strip", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "utils.util.get_expert_paths", "ValueError", "x.strip", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "msg.format", "ValueError", "open", "f.readlines", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_expert_paths"], ["def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "    ", "self", ".", "restrict_test_captions", "=", "None", "\n", "\n", "if", "cut_name", "in", "[", "\"miech\"", ",", "\"jsfusion\"", "]", ":", "\n", "      ", "if", "cut_name", "in", "[", "\"miech\"", "]", ":", "\n", "# For now, we follow Antoine's approach of using the first text caption", "\n", "# for the retrieval task when evaluating on his custom split.", "\n", "        ", "train_list_path", "=", "\"train_list_miech.txt\"", "\n", "test_list_path", "=", "\"test_list_miech.txt\"", "\n", "", "elif", "cut_name", "in", "[", "\"jsfusion\"", "]", ":", "\n", "        ", "train_list_path", "=", "\"train_list_jsfusion.txt\"", "\n", "test_list_path", "=", "\"val_list_jsfusion.txt\"", "\n", "# NOTE: The JSFusion split (referred to as 1k-A in the paper) uses all", "\n", "# videos, but randomly samples a single caption per video from the test", "\n", "# set for evaluation. To reproduce this evaluation, we use the indices", "\n", "# of the test captions, and restrict to this subset during eval.", "\n", "test_cap_idx_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "\n", "\"jsfusion_val_caption_idx.pkl\"", ")", "\n", "self", ".", "restrict_test_captions", "=", "memcache", "(", "test_cap_idx_path", ")", "\n", "\n", "", "test_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "test_list_path", ")", "\n", "with", "open", "(", "test_list_path", ")", "as", "f", ":", "\n", "        ", "test_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_test_samples", "=", "len", "(", "test_vid_list", ")", "\n", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"trainval\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"trainval\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "\n", "", "elif", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_test_samples", ":", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_test_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_test_samples", "]", "\n", "\n", "", "", "elif", "split_name", "==", "\"test\"", ":", "\n", "        ", "self", ".", "vid_list", "=", "test_vid_list", "\n", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "elif", "cut_name", "in", "[", "\"full\"", "]", ":", "\n", "      ", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "        ", "list_path", "=", "\"train_list.txt\"", "\n", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "        ", "list_path", "=", "\"val_list.txt\"", "\n", "", "elif", "split_name", "in", "[", "\"test\"", "]", ":", "\n", "        ", "list_path", "=", "\"test_list.txt\"", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"unrecognised split: {split_name}\"", ")", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "list_path", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "        ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "# We want the trn split to be the same size as the val set", "\n", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "        ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "497", "]", "\n", "\n", "", "", "elif", "cut_name", "in", "[", "\"c\"", "]", ":", "\n", "      ", "self", ".", "expert_paths", "=", "get_expert_paths", "(", "self", ".", "data_dir", ")", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "train_list_path", "=", "\"train_list.txt\"", "\n", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "val_list_path", "=", "\"val_list.txt\"", "\n", "val_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "val_list_path", ")", "\n", "with", "open", "(", "val_list_path", ")", "as", "f", ":", "\n", "          ", "val_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_val_samples", "=", "len", "(", "val_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "+", "val_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "if", "self", ".", "cross_seed", "!=", "0", ":", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "          ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"trainval\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"trainval\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "\n", "", "elif", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_train_samples", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "# In order to monitor performance on the training set, we sample", "\n", "# from it as many samples as there are validation samples.", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_val_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_train_samples", ":", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "split_name", "==", "\"test1\"", ":", "\n", "          ", "list_path", "=", "\"public_server_val.txt\"", "\n", "", "elif", "split_name", "==", "\"test2\"", ":", "\n", "          ", "list_path", "=", "\"public_server_test.txt\"", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "list_path", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "          ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "else", ":", "\n", "      ", "msg", "=", "\"unrecognised cut: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "cut_name", ")", ")", "\n", "\n", "", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "dataset_name", "=", "f\"MSRVTT_{cut_name}_{split_name}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.howto100m_dataset.HowTo100M.configure_train_test_splits": [[23, 50], ["os.path.join", "print", "time.time", "print", "ValueError", "open", "f.readlines", "x.strip", "msg.format", "time.time"], "methods", ["None"], ["def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "    ", "self", ".", "restrict_test_captions", "=", "None", "\n", "list_path", "=", "None", "\n", "if", "cut_name", "in", "[", "\"full\"", "]", ":", "\n", "      ", "if", "split_name", "in", "[", "\"train\"", "]", ":", "\n", "        ", "list_path", "=", "\"train_list_full.txt\"", "\n", "", "elif", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "        ", "list_path", "=", "\"trn_list_full.txt\"", "\n", "", "elif", "split_name", "in", "[", "\"val\"", ",", "\"valong\"", ",", "\"val3-30\"", "]", ":", "\n", "        ", "list_path", "=", "\"val_list_full.txt\"", "\n", "", "elif", "split_name", "in", "[", "\"test\"", ",", "\"testlong\"", ",", "\"test3-30\"", "]", ":", "\n", "        ", "list_path", "=", "\"test_list_full.txt\"", "\n", "", "", "else", ":", "\n", "      ", "msg", "=", "\"unrecognised HowTo100M cut: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "cut_name", ")", ")", "\n", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_feat", ",", "list_path", ")", "\n", "\n", "print", "(", "\"loading training/val splits....\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "      ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "print", "(", "\"done in {:.3f}s\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "\n", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "dataset_name", "=", "f\"HowTo100M_{cut_name}_{split_name}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.data_loader.activitynet_dataset_backup.ActivityNet.configure_train_test_splits": [[25, 119], ["os.path.join", "len", "open", "f.readlines", "os.path.join", "len", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "utils.util.get_expert_paths", "ValueError", "open", "f.readlines", "x.strip", "os.path.join", "len", "os.path.join", "len", "os.path.join", "msg.format", "x.strip", "open", "f.readlines", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle", "open", "f.readlines", "x.strip", "numpy.random.RandomState", "numpy.random.RandomState.shuffle"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_expert_paths"], ["def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "    ", "if", "cut_name", "in", "[", "\"val1\"", "]", ":", "\n", "      ", "train_list_path", "=", "\"train_list.txt\"", "\n", "test_list_path", "=", "\"val_1_list.txt\"", "\n", "\n", "test_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "test_list_path", ")", "\n", "with", "open", "(", "test_list_path", ")", "as", "f", ":", "\n", "        ", "test_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_test_samples", "=", "len", "(", "test_vid_list", ")", "\n", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"trainval\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"trainval\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "\n", "", "elif", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_test_samples", ":", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_test_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_test_samples", "]", "\n", "\n", "", "", "elif", "split_name", "==", "\"test\"", ":", "\n", "        ", "self", ".", "vid_list", "=", "test_vid_list", "\n", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "elif", "cut_name", "in", "[", "\"c\"", "]", ":", "\n", "      ", "self", ".", "expert_paths", "=", "get_expert_paths", "(", "self", ".", "data_dir", ")", "\n", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"val\"", ",", "\"trainval\"", "]", ":", "\n", "        ", "train_list_path", "=", "\"train_list.txt\"", "\n", "train_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "train_list_path", ")", "\n", "with", "open", "(", "train_list_path", ")", "as", "f", ":", "\n", "          ", "train_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_train_samples", "=", "len", "(", "train_vid_list", ")", "\n", "\n", "val_list_path", "=", "\"val_list.txt\"", "\n", "val_list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "val_list_path", ")", "\n", "with", "open", "(", "val_list_path", ")", "as", "f", ":", "\n", "          ", "val_vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "nb_val_samples", "=", "len", "(", "val_vid_list", ")", "\n", "\n", "cross_vid_list", "=", "train_vid_list", "+", "val_vid_list", "\n", "cross_vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "cross_vid_list", "]", "\n", "\n", "if", "self", ".", "cross_seed", "!=", "0", ":", "\n", "# The cross seed is used to split training videos into different", "\n", "# cross validation splits.", "\n", "          ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "self", ".", "cross_seed", ")", "\n", "rng", ".", "shuffle", "(", "cross_vid_list", ")", "\n", "\n", "", "if", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", ",", "\"trainval\"", "]", ":", "\n", "          ", "if", "split_name", "in", "[", "\"trainval\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "\n", "", "elif", "split_name", "in", "[", "\"train\"", ",", "\"trn\"", "]", ":", "\n", "            ", "self", ".", "vid_list", "=", "cross_vid_list", "[", ":", "nb_train_samples", "]", "\n", "", "if", "split_name", "in", "[", "\"trn\"", "]", ":", "\n", "# In order to monitor performance on the training set, we sample", "\n", "# from it as many samples as there are validation samples.", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "rng", ".", "shuffle", "(", "self", ".", "vid_list", ")", "\n", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_val_samples", "]", "\n", "\n", "", "", "elif", "split_name", "in", "[", "\"val\"", "]", ":", "\n", "          ", "self", ".", "vid_list", "=", "cross_vid_list", "[", "nb_train_samples", ":", "]", "\n", "\n", "", "", "else", ":", "\n", "        ", "if", "split_name", "==", "\"test1\"", ":", "\n", "          ", "list_path", "=", "\"public_server_val.txt\"", "\n", "", "elif", "split_name", "==", "\"test2\"", ":", "\n", "          ", "list_path", "=", "\"public_server_test.txt\"", "\n", "", "list_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "list_path", ")", "\n", "with", "open", "(", "list_path", ")", "as", "f", ":", "\n", "          ", "self", ".", "vid_list", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "vid_list", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "self", ".", "vid_list", "]", "\n", "\n", "", "", "else", ":", "\n", "      ", "msg", "=", "\"unrecognised cut: {}\"", "\n", "raise", "ValueError", "(", "msg", ".", "format", "(", "cut_name", ")", ")", "\n", "\n", "", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "dataset_name", "=", "f\"ActivityNet_{cut_name}_{split_name}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.logger.log_parser.log_summary": [[8, 103], ["open", "f.read().splitlines", "logger.info", "logger.info", "logger.info", "logger.info", "collections.defaultdict", "scores.items", "agg_scores.items", "str", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "NotImplementedError", "list", "subdict.items", "logger.info", "logger.info", "f.read", "re.search", "row.split", "scores[].keys", "scores.items", "numpy.array", "scipy.stats.mstats.gmean", "numpy.argmax", "agg_scores[].append", "len", "len", "re.search.groups", "re.search.groups", "float", "[].append", "geometric_stats[].append", "ValueError", "numpy.mean", "numpy.std", "row.split.index"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["def", "log_summary", "(", "logger", ",", "log_path", ",", "eval_mode", "=", "\"test_run\"", ",", "fixed_num_epochs", "=", "None", ")", ":", "\n", "    ", "\"\"\"Extract performace statistics from experiment log files.\n\n    Args:\n        logger (logger): reference to primary logging instance\n        log_path (Path): the path to the log file\n        eval_mode (str): the method use to collect the statistics. Can be one of:\n            `test_run`, `fixed_num_epochs` or `geometric_mean`\n\n    NOTE: The `eval_mode` argument differs by dataset: for datasets which provide a\n    validation set, we use validation set performance to complete a single test run.  For\n    datasets where no validation set is available, we aim to match prior work by either\n    fixing the number of training epochs, or selecting directly from validation set\n    performance (Details can be found in the supplementary material of the paper.)\n    \"\"\"", "\n", "with", "open", "(", "str", "(", "log_path", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "log", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "# keep track of the random seed used for the part of the logfile being processed", "\n", "", "current_seed", "=", "None", "\n", "\n", "# Regex tag for finding the seed", "\n", "seed_tag", "=", "\"Setting experiment random seed to\"", "\n", "\n", "if", "eval_mode", "==", "\"test_run\"", ":", "\n", "        ", "subset", "=", "\"test\"", "\n", "", "else", ":", "\n", "        ", "subset", "=", "\"val\"", "\n", "\n", "", "for", "mode", "in", "\"t2v\"", ",", "\"v2t\"", ":", "\n", "        ", "logger", ".", "info", "(", "\"\"", ")", "\n", "logger", ".", "info", "(", "\"----------------------------------------------------\"", ")", "\n", "logger", ".", "info", "(", "f\"[{mode}] loaded log file with {len(log)} lines....\"", ")", "\n", "logger", ".", "info", "(", "\"----------------------------------------------------\"", ")", "\n", "\n", "# Search for the following metrics", "\n", "scores", "=", "{", "\n", "\"R1\"", ":", "defaultdict", "(", "list", ")", ",", "\n", "\"R5\"", ":", "defaultdict", "(", "list", ")", ",", "\n", "\"R10\"", ":", "defaultdict", "(", "list", ")", ",", "\n", "\"R50\"", ":", "defaultdict", "(", "list", ")", ",", "\n", "\"MedR\"", ":", "defaultdict", "(", "list", ")", ",", "\n", "\"MeanR\"", ":", "defaultdict", "(", "list", ")", ",", "\n", "}", "\n", "\n", "for", "row", "in", "log", ":", "\n", "            ", "if", "seed_tag", "in", "row", ":", "\n", "# Search for the log file entry describing the current random seed", "\n", "                ", "match", "=", "re", ".", "search", "(", "seed_tag", "+", "\" (\\d+)$\"", ",", "row", ")", "# NOQA", "\n", "assert", "len", "(", "match", ".", "groups", "(", ")", ")", "==", "1", ",", "\"expected a single regex match\"", "\n", "current_seed", "=", "match", ".", "groups", "(", ")", "[", "0", "]", "\n", "\n", "", "if", "f\"{subset}_{mode}_metrics\"", "in", "row", ":", "\n", "                ", "tokens", "=", "row", ".", "split", "(", "\" \"", ")", "\n", "for", "key", "in", "scores", ":", "\n", "                    ", "tag", "=", "f\"{subset}_{mode}_metrics_{key}:\"", "\n", "if", "tag", "in", "tokens", ":", "\n", "                        ", "pos", "=", "tokens", ".", "index", "(", "tag", ")", "+", "1", "\n", "val", "=", "tokens", "[", "pos", "]", "\n", "val", "=", "float", "(", "val", ")", "\n", "assert", "current_seed", "is", "not", "None", ",", "\"failed to determine the seed\"", "\n", "scores", "[", "key", "]", "[", "current_seed", "]", ".", "append", "(", "val", ")", "\n", "\n", "", "", "", "", "agg_scores", "=", "{", "\"R1\"", ":", "[", "]", ",", "\"R5\"", ":", "[", "]", ",", "\"R10\"", ":", "[", "]", ",", "\"R50\"", ":", "[", "]", ",", "\"MedR\"", ":", "[", "]", ",", "\"MeanR\"", ":", "[", "]", "}", "\n", "\n", "# compute the best performance for a single epoch (i.e. sharing the same model", "\n", "# to compute all stats)", "\n", "geometric_stats", "=", "defaultdict", "(", "list", ")", "\n", "best_epochs", "=", "{", "}", "\n", "if", "eval_mode", "==", "\"geometric_mean\"", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Need to fix this for new log format\"", ")", "\n", "consider", "=", "[", "\"R1\"", ",", "\"R5\"", ",", "\"R10\"", "]", "\n", "seeds", "=", "list", "(", "scores", "[", "\"R1\"", "]", ".", "keys", "(", ")", ")", "\n", "for", "seed", "in", "seeds", ":", "\n", "                ", "for", "metric", ",", "subdict", "in", "scores", ".", "items", "(", ")", ":", "\n", "                    ", "if", "metric", "in", "consider", ":", "\n", "                        ", "geometric_stats", "[", "seed", "]", ".", "append", "(", "subdict", "[", "seed", "]", ")", "\n", "", "", "gms_raw", "=", "np", ".", "array", "(", "geometric_stats", "[", "seed", "]", ")", "\n", "geo_means", "=", "scipy", ".", "stats", ".", "mstats", ".", "gmean", "(", "gms_raw", ",", "axis", "=", "0", ")", "\n", "best_epochs", "[", "seed", "]", "=", "np", ".", "argmax", "(", "geo_means", ")", "\n", "\n", "", "", "for", "metric", ",", "subdict", "in", "scores", ".", "items", "(", ")", ":", "\n", "            ", "for", "seed", ",", "values", "in", "subdict", ".", "items", "(", ")", ":", "\n", "                ", "if", "eval_mode", "==", "\"test_run\"", ":", "\n", "                    ", "stat", "=", "values", "[", "0", "]", "\n", "", "elif", "eval_mode", "==", "\"fixed_num_epochs\"", ":", "\n", "                    ", "stat", "=", "values", "[", "fixed_num_epochs", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"unrecognised eval_mode: {eval_mode}\"", ")", "\n", "", "agg_scores", "[", "metric", "]", ".", "append", "(", "stat", ")", "\n", "\n", "", "", "if", "eval_mode", "==", "\"fixed_num_epochs\"", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Reporting stats with fixed training length: {fixed_num_epochs}\"", ")", "\n", "", "for", "metric", ",", "values", "in", "agg_scores", ".", "items", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"{metric}: {np.mean(values):.1f}, {np.std(values, ddof=1):.1f}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.logger.visualization.TensorboardWriter.__init__": [[6, 43], ["utils.Timer", "str", "logger.warning", "importlib.import_module().SummaryWriter", "importlib.import_module"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "log_dir", ",", "logger", ",", "enabled", ")", ":", "\n", "        ", "self", ".", "writer", "=", "None", "\n", "self", ".", "selected_module", "=", "\"\"", "\n", "\n", "if", "enabled", ":", "\n", "            ", "log_dir", "=", "str", "(", "log_dir", ")", "\n", "\n", "# Retrieve vizualization writer", "\n", "succeeded", "=", "False", "\n", "for", "module", "in", "[", "\"torch.utils.tensorboard\"", ",", "\"tensorboardX\"", "]", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "writer", "=", "importlib", ".", "import_module", "(", "module", ")", ".", "SummaryWriter", "(", "log_dir", ")", "\n", "succeeded", "=", "True", "\n", "break", "\n", "", "except", "ImportError", ":", "\n", "                    ", "succeeded", "=", "False", "\n", "", "self", ".", "selected_module", "=", "module", "\n", "\n", "", "if", "not", "succeeded", ":", "\n", "                ", "message", "=", "(", "\"Warning: visualization (Tensorboard) is configured to use, \"", "\n", "\"but currently not installed on this machine. Please install\"", "\n", "\" either TensorboardX with 'pip install tensorboardx', \"", "\n", "\" upgrade PyTorch to version >= 1.1 for using \"", "\n", "\"'torch.utils.tensorboard' or turn off the option in \"", "\n", "\"the 'config.json' file.\"", ")", "\n", "logger", ".", "warning", "(", "message", ")", "\n", "\n", "", "", "self", ".", "step", "=", "0", "\n", "self", ".", "mode", "=", "''", "\n", "\n", "self", ".", "tb_writer_ftns", "=", "{", "\n", "'add_scalar'", ",", "'add_scalars'", ",", "'add_image'", ",", "'add_images'", ",", "'add_audio'", ",", "\n", "'add_text'", ",", "'add_histogram'", ",", "'add_pr_curve'", ",", "'add_embedding'", "\n", "}", "\n", "self", ".", "tag_mode_exceptions", "=", "{", "'add_histogram'", ",", "'add_embedding'", "}", "\n", "\n", "self", ".", "timer", "=", "Timer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.logger.visualization.TensorboardWriter.set_step": [[44, 52], ["visualization.TensorboardWriter.timer.reset", "visualization.TensorboardWriter.timer.check", "visualization.TensorboardWriter.add_scalar"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.ClassErrorMeter.reset", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.Timer.check"], ["", "def", "set_step", "(", "self", ",", "step", ",", "mode", "=", "'train'", ")", ":", "\n", "        ", "self", ".", "mode", "=", "mode", "\n", "self", ".", "step", "=", "step", "\n", "if", "step", "==", "0", ":", "\n", "            ", "self", ".", "timer", ".", "reset", "(", ")", "\n", "", "else", ":", "\n", "            ", "duration", "=", "self", ".", "timer", ".", "check", "(", ")", "\n", "self", ".", "add_scalar", "(", "'steps_per_sec'", ",", "1", "/", "duration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.logger.visualization.TensorboardWriter.__getattr__": [[53, 80], ["getattr", "object.__getattr__", "getattr.", "AttributeError", "msg.format"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.logger.visualization.TensorboardWriter.__getattr__"], ["", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        If visualization is configured to use:\n            return add_data() methods of tensorboard with additional information\n            (step, tag) added.\n        Otherwise:\n            return a blank function handle that does nothing\n        \"\"\"", "\n", "if", "name", "in", "self", ".", "tb_writer_ftns", ":", "\n", "            ", "add_data", "=", "getattr", "(", "self", ".", "writer", ",", "name", ",", "None", ")", "\n", "\n", "def", "wrapper", "(", "tag", ",", "data", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "if", "add_data", "is", "not", "None", ":", "\n", "# add mode(train/valid) tag", "\n", "                    ", "if", "name", "not", "in", "self", ".", "tag_mode_exceptions", ":", "\n", "                        ", "tag", "=", "'{}/{}'", ".", "format", "(", "tag", ",", "self", ".", "mode", ")", "\n", "", "add_data", "(", "tag", ",", "data", ",", "self", ".", "step", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "return", "wrapper", "\n", "", "else", ":", "\n", "# default action for returning methods defined in this class, set_step()", "\n", "# for instance.", "\n", "            ", "try", ":", "\n", "                ", "attr", "=", "object", ".", "__getattr__", "(", "name", ")", "\n", "", "except", "AttributeError", ":", "\n", "                ", "msg", "=", "\"type object '{}' has no attribute '{}'\"", "\n", "raise", "AttributeError", "(", "msg", ".", "format", "(", "self", ".", "selected_module", ",", "name", ")", ")", "\n", "", "return", "attr", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.logger.logger.setup_logging": [[8, 26], ["print", "pathlib.Path", "print", "pathlib.Path.is_file", "os.getcwd", "utils.read_json", "config[].items", "logging.config.dictConfig", "logging.config.dictConfig", "print", "logging.basicConfig", "logging.basicConfig", "pathlib.Path.exists", "str"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.read_json", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["def", "setup_logging", "(", "save_dir", ",", "log_config", "=", "'logger/logger_config.json'", ",", "\n", "default_level", "=", "logging", ".", "INFO", ")", ":", "\n", "    ", "\"\"\"Setup logging configuration.\"\"\"", "\n", "print", "(", "os", ".", "getcwd", "(", ")", ")", "\n", "log_config", "=", "Path", "(", "log_config", ")", "\n", "print", "(", "f\"log config: {log_config} exists: {log_config.exists()}\"", ")", "\n", "if", "log_config", ".", "is_file", "(", ")", ":", "\n", "        ", "config", "=", "read_json", "(", "log_config", ")", "\n", "# modify logging paths based on run config", "\n", "for", "_", ",", "handler", "in", "config", "[", "'handlers'", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "'filename'", "in", "handler", ":", "\n", "                ", "handler", "[", "'filename'", "]", "=", "str", "(", "save_dir", "/", "handler", "[", "'filename'", "]", ")", "\n", "\n", "", "", "logging", ".", "config", ".", "dictConfig", "(", "config", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "f\"Warning: logging configuration file is not found in {log_config}.\"", ")", "\n", "logging", ".", "basicConfig", "(", "level", "=", "default_level", ")", "\n", "", "return", "config", "[", "\"handlers\"", "]", "[", "\"info_file_handler\"", "]", "[", "\"filename\"", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.train.download_models": [[47, 56], ["str().split", "os.path.exists", "print", "pathlib.Path().mkdir", "wget.download", "print", "str", "pathlib.Path", "str"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir"], ["        ", "seeds", "=", "[", "int", "(", "config", ".", "_args", ".", "group_seed", ")", "]", "\n", "", "else", ":", "\n", "        ", "seeds", "=", "[", "int", "(", "x", ")", "for", "x", "in", "config", ".", "_args", ".", "seeds", ".", "split", "(", "\",\"", ")", "]", "\n", "\n", "# set up local filesystem on the cluster", "\n", "", "if", "socket", ".", "gethostname", "(", ")", ".", "endswith", "(", "\"cluster\"", ")", ":", "\n", "        ", "os", ".", "system", "(", "str", "(", "Path", ".", "home", "(", ")", "/", "\"configure_tmp_data.sh\"", ")", ")", "\n", "\n", "", "for", "ii", ",", "seed", "in", "enumerate", "(", "seeds", ")", ":", "\n", "        ", "tic", "=", "time", ".", "time", "(", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.train.train": [[58, 164], ["utils.util.compute_dims", "utils.util.compute_dims.items", "utils.nlp_utils.create_tokenizer", "time.time", "config.get", "logger.debug", "random.seed", "numpy.random.seed", "torch.manual_seed", "logger.info", "config.init", "config.init", "filter", "config.init", "config.init", "trainer.Trainer", "logger.info", "trainer.Trainer.evaluate", "time.strftime", "logger.info", "os.path.exists", "enumerate", "getattr", "config.init.parameters", "config.init", "config.init", "logger.info", "trainer.Trainer.train", "time.gmtime", "logger.info", "config.get", "data_loaders[].append", "config[].get", "config[].get", "str", "time.time", "getattr"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.compute_dims", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.nlp_utils.create_tokenizer", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer.evaluate", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer.train", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["set_seeds", "(", "seed", ")", "\n", "config", "[", "\"seed\"", "]", "=", "seed", "\n", "\n", "model", "=", "config", ".", "init", "(", "\n", "name", "=", "'arch'", ",", "\n", "module", "=", "module_arch", ",", "\n", "expert_dims", "=", "expert_dims", ",", "\n", "text_dim", "=", "text_dim", ",", "\n", "disable_nan_checks", "=", "config", "[", "\"disable_nan_checks\"", "]", ",", "\n", "spatial_feats", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", ".", "get", "(", "\"spatial_feats\"", ",", "False", ")", ",", "\n", "task", "=", "config", ".", "get", "(", "\"task\"", ",", "\"retrieval\"", ")", ",", "\n", "ce_shared_dim", "=", "config", "[", "\"experts\"", "]", ".", "get", "(", "\"ce_shared_dim\"", ",", "None", ")", ",", "\n", "feat_aggregation", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"feat_aggregation\"", "]", ",", "\n", "trn_config", "=", "trn_config", ",", "\n", "trn_cat", "=", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", ".", "get", "(", "\"trn_cat\"", ",", "0", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "model", ")", "\n", "\n", "data_loaders", "=", "config", ".", "init", "(", "\n", "name", "=", "'data_loader'", ",", "\n", "module", "=", "module_data", ",", "\n", "logger", "=", "logger", ",", "\n", "raw_input_dims", "=", "raw_input_dims", ",", "\n", "challenge_mode", "=", "config", ".", "get", "(", "\"challenge_mode\"", ",", "False", ")", ",", "\n", "text_dim", "=", "text_dim", ",", "\n", "text_feat", "=", "config", "[", "\"experts\"", "]", "[", "\"text_feat\"", "]", ",", "\n", "text_agg", "=", "config", "[", "\"experts\"", "]", "[", "\"text_agg\"", "]", ",", "\n", "use_zeros_for_missing", "=", "config", "[", "\"experts\"", "]", ".", "get", "(", "\"use_zeros_for_missing\"", ",", "False", ")", ",", "\n", "task", "=", "config", ".", "get", "(", "\"task\"", ",", "\"retrieval\"", ")", ",", "\n", "eval_only", "=", "False", ",", "\n", "distil_params", "=", "config", ".", "get", "(", "\"distil_params\"", ",", "None", ")", ",", "\n", "training_file", "=", "config", ".", "get", "(", "\"training_file\"", ",", "None", ")", ",", "\n", "testing_file", "=", "config", ".", "get", "(", "\"testing_file\"", ",", "None", ")", ",", "\n", "caption_masks", "=", "config", ".", "get", "(", "\"caption_masks\"", ",", "None", ")", ",", "\n", "ce_shared_dim", "=", "config", "[", "\"experts\"", "]", ".", "get", "(", "\"ce_shared_dim\"", ",", "None", ")", ",", "\n", ")", "\n", "\n", "if", "config", ".", "get", "(", "\"manual_linear_init\"", ",", "False", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"manually setting init for linear layers\"", ")", "\n", "\n", "def", "init_weights", "(", "m", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "xavier_uniform", "(", "m", ".", "weight", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0.01", ")", "\n", "", "", "model", ".", "apply", "(", "init_weights", ")", "\n", "\n", "", "loss", "=", "config", ".", "init", "(", "name", "=", "\"loss\"", ",", "module", "=", "module_loss", ")", "\n", "metrics", "=", "[", "getattr", "(", "module_metric", ",", "met", ")", "for", "met", "in", "config", "[", "'metrics'", "]", "]", "\n", "trainable_params", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "if", "config", "[", "\"optimizer\"", "]", "[", "\"type\"", "]", "==", "\"RAdam\"", ":", "\n", "            ", "optimizer", "=", "config", ".", "init", "(", "'optimizer'", ",", "radam", ",", "trainable_params", ")", "\n", "", "elif", "config", "[", "\"optimizer\"", "]", "[", "\"type\"", "]", "==", "\"Ranger\"", ":", "\n", "            ", "optimizer", "=", "config", ".", "init", "(", "'optimizer'", ",", "ranger", ",", "trainable_params", ")", "\n", "", "elif", "config", "[", "\"optimizer\"", "]", "[", "\"type\"", "]", "==", "\"SWATS\"", ":", "\n", "            ", "optimizer", "=", "config", ".", "init", "(", "'optimizer'", ",", "swats", ",", "trainable_params", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "config", ".", "init", "(", "'optimizer'", ",", "torch", ".", "optim", ",", "trainable_params", ")", "\n", "\n", "", "if", "config", "[", "\"lr_scheduler\"", "]", "[", "\"type\"", "]", "==", "\"StepLR\"", ":", "\n", "            ", "lr_scheduler", "=", "config", ".", "init", "(", "'lr_scheduler'", ",", "torch", ".", "optim", ".", "lr_scheduler", ",", "\n", "optimizer", ")", "\n", "", "else", ":", "\n", "            ", "lr_scheduler", "=", "config", ".", "init", "(", "'lr_scheduler'", ",", "cos_restart", ",", "optimizer", ")", "\n", "\n", "", "update_src_web_video_dir", "(", "config", ")", "\n", "visualizer", "=", "config", ".", "init", "(", "\n", "name", "=", "'visualizer'", ",", "\n", "module", "=", "module_vis", ",", "\n", "exp_name", "=", "config", ".", "_exper_name", ",", "\n", "web_dir", "=", "config", ".", "_web_log_dir", ",", "\n", ")", "\n", "\n", "trainer", "=", "Trainer", "(", "\n", "model", ",", "\n", "loss", ",", "\n", "metrics", ",", "\n", "optimizer", ",", "\n", "config", "=", "config", ",", "\n", "data_loaders", "=", "data_loaders", ",", "\n", "lr_scheduler", "=", "lr_scheduler", ",", "\n", "mini_train", "=", "config", ".", "_args", ".", "mini_train", ",", "\n", "disable_nan_checks", "=", "config", "[", "\"disable_nan_checks\"", "]", ",", "\n", "visualizer", "=", "visualizer", ",", "\n", "val_freq", "=", "config", "[", "\"trainer\"", "]", ".", "get", "(", "\"val_freq\"", ",", "1", ")", ",", "\n", "distil_loss", "=", "config", ".", "get", "(", "\"distil_loss\"", ",", "False", ")", ",", "\n", "distil_params", "=", "config", ".", "get", "(", "\"distil_params\"", ",", "None", ")", ",", "\n", "force_cpu_val", "=", "config", ".", "get", "(", "\"force_cpu_val\"", ",", "False", ")", ",", "\n", "skip_first_n_saves", "=", "config", "[", "\"trainer\"", "]", ".", "get", "(", "\"skip_first_n_saves\"", ",", "0", ")", ",", "\n", "include_optim_in_ckpts", "=", "config", "[", "\"trainer\"", "]", ".", "get", "(", "\"include_optim_in_ckpts\"", ",", "1", ")", ",", "\n", "cache_targets", "=", "set", "(", "config", ".", "get", "(", "\"cache_targets\"", ",", "[", "]", ")", ")", ",", "\n", ")", "\n", "trainer", ".", "train", "(", ")", "\n", "best_ckpt_path", "=", "config", ".", "save_dir", "/", "\"trained_model.pth\"", "\n", "duration", "=", "time", ".", "strftime", "(", "'%Hh%Mm%Ss'", ",", "time", ".", "gmtime", "(", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "logger", ".", "info", "(", "f\"Training took {duration}\"", ")", "\n", "\n", "if", "config", ".", "_config", ".", "get", "(", "\"eval_settings\"", ",", "False", ")", ":", "\n", "# import pdb; pdb.set_trace()", "\n", "            ", "eval_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "merge", "(", "eval_config", ".", "_config", ",", "config", "[", "\"eval_settings\"", "]", ",", "strategy", "=", "Strategy", ".", "REPLACE", ")", "\n", "eval_config", ".", "_args", ".", "resume", "=", "best_ckpt_path", "\n", "evaluation", "(", "eval_config", ",", "logger", "=", "logger", ",", "trainer", "=", "trainer", ")", "\n", "\n", "# If multiple runs were conducted, report relevant statistics", "\n", "", "", "if", "len", "(", "seeds", ")", ">", "1", ":", "\n", "        ", "log_summary", "(", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.train.main_train": [[166, 236], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "enumerate", "collections.defaultdict", "collections.defaultdict", "print", "print", "list", "print", "int", "setattr", "print", "parse_config.ConfigParser", "train.train", "os.path.split", "os.path.join", "os.path.join", "collections.defaultdict.keys", "parser.parse_args.seeds.split", "logging.info", "train.download_models", "open", "json.load", "[].items", "pathlib.Path", "pathlib.Path", "pathlib.Path", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "k.split", "metrics_t2v[].append", "metrics_v2t[].append", "list", "json_content[].keys"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer.train", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.train.download_models", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["log_path", "=", "config", ".", "log_path", ",", "\n", "eval_mode", "=", "config", "[", "\"eval_mode\"", "]", ",", "\n", "fixed_num_epochs", "=", "config", "[", "\"trainer\"", "]", "[", "\"epochs\"", "]", ",", "\n", ")", "\n", "", "print", "(", "f\"Log file stored at {config.log_path}\"", ")", "\n", "\n", "# Report the location of the \"best\" checkpoint of the final seeded run (here", "\n", "# \"best\" corresponds to the model with the highest geometric mean over the", "\n", "# R@1, R@5 and R@10 metrics when a validation set is used, or simply the final", "\n", "# epoch of training for fixed-length schedules).", "\n", "print", "(", "f\"The best performing ckpt can be found at {str(best_ckpt_path)}\"", ")", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Main entry point for training'", ")", "\n", "args", ".", "add_argument", "(", "'--config'", ",", "help", "=", "'config file path'", ")", "\n", "args", ".", "add_argument", "(", "'--resume'", ",", "help", "=", "'path to latest checkpoint (default: None)'", ")", "\n", "args", ".", "add_argument", "(", "'--finetune'", ",", "action", "=", "\"store_true\"", ",", "help", "=", "'set to true if finetuning (default: None)'", ")", "\n", "args", ".", "add_argument", "(", "'--leaderboard'", ",", "default", "=", "\"data/leaderboards/exp.txt\"", ",", "\n", "help", "=", "'path we want to draw on leadboard'", ")", "\n", "args", ".", "add_argument", "(", "'--device'", ",", "help", "=", "\"indices of GPUs to enable\"", ")", "\n", "args", ".", "add_argument", "(", "'--mini_train'", ",", "action", "=", "\"store_true\"", ")", "\n", "args", ".", "add_argument", "(", "'--group_id'", ",", "help", "=", "\"if supplied, group these experiments\"", ")", "\n", "args", ".", "add_argument", "(", "'--disable_workers'", ",", "action", "=", "\"store_true\"", ")", "\n", "args", ".", "add_argument", "(", "'--refresh_lru_cache'", ",", "action", "=", "\"store_true\"", ")", "\n", "args", ".", "add_argument", "(", "'--train_single_epoch'", ",", "action", "=", "\"store_true\"", ")", "\n", "args", ".", "add_argument", "(", "'--purge_exp_dir'", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"remove all previous experiments with the given config\"", ")", "\n", "args", ".", "add_argument", "(", "\"--dbg\"", ",", "default", "=", "\"ipdb.set_trace\"", ")", "\n", "args", ".", "add_argument", "(", "\"--custom_args\"", ",", "help", "=", "\"qualified key,val pairs\"", ")", "\n", "\n", "# Seeds can either be passed directly as a comma separated list at the command line,", "\n", "# or individually for separate experiments as a group (used for slurm experiments)", "\n", "seed_args", "=", "args", ".", "add_mutually_exclusive_group", "(", ")", "\n", "seed_args", ".", "add_argument", "(", "'--seeds'", ",", "default", "=", "\"0\"", ",", "help", "=", "\"comma separated list of seeds\"", ")", "\n", "seed_args", ".", "add_argument", "(", "'--group_seed'", ",", "help", "=", "\"seed for group member\"", ")", "\n", "\n", "args", "=", "ConfigParser", "(", "args", ")", "\n", "\n", "os", ".", "environ", "[", "\"PYTHONBREAKPOINT\"", "]", "=", "args", ".", "_args", ".", "dbg", "\n", "args", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"refresh_lru_cache\"", "]", "=", "args", ".", "_args", ".", "refresh_lru_cache", "\n", "msg", "=", "(", "f\"Expected the number of training epochs ({args['trainer']['epochs']})\"", "\n", "f\"to exceed the save period ({args['trainer']['save_period']}), otherwise\"", "\n", "\" no checkpoints will be saved.\"", ")", "\n", "assert", "args", "[", "\"trainer\"", "]", "[", "\"epochs\"", "]", ">=", "args", "[", "\"trainer\"", "]", "[", "\"save_period\"", "]", ",", "msg", "\n", "print", "(", "\"Launching experiment with config:\"", ")", "\n", "print", "(", "args", ")", "\n", "run_exp", "(", "config", "=", "args", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.__init__": [[39, 138], ["utils.read_json", "parse_config._update_config", "parse_config.ConfigParser.save_dir.mkdir", "parse_config.ConfigParser.log_dir.mkdir", "logger.info", "torch.cuda.device_count", "logger.debug", "utils.write_json", "logging.debug", "pathlib.Path", "utils.get_last_checkpoint_path", "pathlib.Path", "parse_config.ConfigParser.config.keys", "pathlib.Path", "parse_config.ConfigParser.config[].keys", "pathlib.Path", "str", "parse_config.ConfigParser.config[].keys", "pathlib.Path", "parse_config.ConfigParser._web_dirs.append", "external_save_root.exists", "logging.basicConfig", "logging.basicConfig", "pprint.pformat", "pathlib.Path", "pathlib.Path.cwd", "str", "parse_config.ConfigParser._web_dirs.append", "logger.debug", "pathlib.Path.cwd", "os.environ.get", "os.environ.get", "logging.FileHandler", "logging.StreamHandler"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.read_json", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._update_config", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.mkdir", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.write_json", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_last_checkpoint_path", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["            ", "self", ".", "resume", "=", "Path", "(", "args", ".", "resume", ")", "\n", "try", ":", "\n", "                ", "if", "args", ".", "finetune", ":", "\n", "                    ", "self", ".", "finetune", "=", "args", ".", "finetune", "\n", "", "", "except", "AttributeError", ":", "\n", "                ", "pass", "\n", "print", "(", "\"Finetune not being used\"", ")", "\n", "", "", "else", ":", "\n", "            ", "msg_no_cfg", "=", "\"Config file must be specified\"", "\n", "assert", "args", ".", "config", "is", "not", "None", ",", "msg_no_cfg", "\n", "self", ".", "resume", "=", "None", "\n", "", "self", ".", "cfg_fname", "=", "Path", "(", "args", ".", "config", ")", "\n", "\n", "config", "=", "load_json_config", "(", "self", ".", "cfg_fname", ")", "\n", "self", ".", "_config", "=", "_update_config", "(", "config", ",", "options", ",", "args", ")", "\n", "\n", "if", "self", ".", "_config", ".", "get", "(", "\"eval_config\"", ",", "False", ")", ":", "\n", "# validate path to evaluation file", "\n", "            ", "eval_cfg_path", "=", "self", ".", "_config", ".", "get", "(", "\"eval_config\"", ")", "\n", "msg", "=", "f\"eval_config was specified, but `{eval_cfg_path}` does not exist\"", "\n", "assert", "Path", "(", "self", ".", "_config", ".", "get", "(", "\"eval_config\"", ")", ")", ".", "exists", "(", ")", ",", "msg", "\n", "\n", "# set save_dir where trained model and log will be saved.", "\n", "", "if", "\"tester\"", "in", "self", ".", "config", ":", "\n", "            ", "save_dir", "=", "Path", "(", "self", ".", "config", "[", "'tester'", "]", "[", "'save_dir'", "]", ")", "\n", "", "else", ":", "\n", "            ", "save_dir", "=", "Path", "(", "self", ".", "config", "[", "'trainer'", "]", "[", "'save_dir'", "]", ")", "\n", "", "timestamp", "=", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "r\"%Y-%m-%d_%H-%M-%S\"", ")", "if", "timestamp", "else", "\"\"", "\n", "\n", "if", "slave_mode", ":", "\n", "            ", "timestamp", "=", "f\"{timestamp}-eval-worker\"", "\n", "\n", "", "exper_name", "=", "self", ".", "set_exper_name", "(", "args", ",", "config", "=", "config", ")", "\n", "\n", "if", "getattr", "(", "args", ",", "\"group_id\"", ",", "False", ")", ":", "\n", "            ", "subdir", "=", "Path", "(", "args", ".", "group_id", ")", "/", "f\"seed-{args.group_seed}\"", "/", "timestamp", "\n", "", "else", ":", "\n", "            ", "subdir", "=", "timestamp", "\n", "\n", "# store challenge experiments in a further subdirectory", "\n", "", "if", "self", ".", "_config", ".", "get", "(", "\"challenge_mode\"", ",", "False", ")", ":", "\n", "            ", "challenge_tag", "=", "\"cvpr2020-challenge\"", "\n", "exper_name", "=", "f\"{challenge_tag}/{exper_name}\"", "\n", "\n", "", "self", ".", "_save_dir", "=", "save_dir", "/", "'models'", "/", "exper_name", "/", "subdir", "\n", "self", ".", "_web_log_dir", "=", "save_dir", "/", "'web'", "/", "exper_name", "/", "subdir", "\n", "self", ".", "_log_dir", "=", "save_dir", "/", "'log'", "/", "exper_name", "/", "subdir", "\n", "self", ".", "_exper_name", "=", "exper_name", "\n", "self", ".", "_args", "=", "args", "\n", "\n", "# if set, remove all previous experiments with the current config", "\n", "if", "vars", "(", "args", ")", ".", "get", "(", "\"purge_exp_dir\"", ",", "False", ")", ":", "\n", "            ", "for", "dirpath", "in", "(", "self", ".", "_save_dir", ",", "self", ".", "_log_dir", ",", "self", ".", "_web_log_dir", ")", ":", "\n", "                ", "config_dir", "=", "dirpath", ".", "parent", "\n", "existing", "=", "list", "(", "config_dir", ".", "glob", "(", "\"*\"", ")", ")", "\n", "print", "(", "f\"purging {len(existing)} directories from config_dir...\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "os", ".", "system", "(", "f\"rm -rf {config_dir}\"", ")", "\n", "print", "(", "f\"Finished purge in {time.time() - tic:.3f}s\"", ")", "\n", "\n", "", "", "self", ".", "save_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "log_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# save updated config file to the checkpoint dir", "\n", "write_json", "(", "self", ".", "config", ",", "self", ".", "save_dir", "/", "'config.json'", ")", "\n", "\n", "# configure logging module", "\n", "if", "not", "slave_mode", ":", "\n", "            ", "self", ".", "log_path", "=", "setup_logging", "(", "self", ".", "log_dir", ")", "\n", "\n", "", "self", ".", "log_levels", "=", "{", "0", ":", "logging", ".", "WARNING", ",", "1", ":", "logging", ".", "INFO", ",", "2", ":", "logging", ".", "DEBUG", "}", "\n", "\n", "", "def", "set_exper_name", "(", "self", ",", "args", ",", "config", ")", ":", "\n", "# We assume that the config files are organised into directories such that", "\n", "# each directory has the name of the dataset.", "\n", "        ", "dataset_name", "=", "self", ".", "cfg_fname", ".", "parent", ".", "stem", "\n", "exper_name", "=", "f\"{dataset_name}-{self.cfg_fname.stem}\"", "\n", "if", "args", ".", "custom_args", ":", "\n", "            ", "key_val_lists", "=", "args", ".", "custom_args", ".", "split", "(", "\"+\"", ")", "\n", "for", "key_val_pair", "in", "key_val_lists", ":", "\n", "                ", "print", "(", "f\"parsing key-val pair : {key_val_pair}\"", ")", "\n", "key", ",", "val", "=", "key_val_pair", ".", "split", "(", "\"@\"", ")", "\n", "set_nested_key_val", "(", "key", ",", "val", ",", "self", ".", "_config", ")", "\n", "# remove periods from key names", "\n", "key_", "=", "key", ".", "replace", "(", "\"_.\"", ",", "\"--\"", ")", "\n", "# remove commas from value names", "\n", "val", "=", "val", ".", "replace", "(", "\",\"", ",", "\"--\"", ")", "\n", "custom_tag", "=", "\"-\"", ".", "join", "(", "key_", ".", "split", "(", "\".\"", ")", "[", "-", "2", ":", "]", ")", "\n", "exper_name", "=", "f\"{exper_name}-{custom_tag}-{val}\"", "\n", "\n", "", "", "if", "getattr", "(", "args", ",", "\"disable_workers\"", ",", "False", ")", ":", "\n", "            ", "print", "(", "\"Disabling data loader workers....\"", ")", "\n", "config", "[", "\"data_loader\"", "]", "[", "\"args\"", "]", "[", "\"num_workers\"", "]", "=", "0", "\n", "\n", "", "if", "getattr", "(", "args", ",", "\"train_single_epoch\"", ",", "False", ")", ":", "\n", "            ", "print", "(", "\"Restricting training to a single epoch....\"", ")", "\n", "config", "[", "\"trainer\"", "]", "[", "\"epochs\"", "]", "=", "1", "\n", "config", "[", "\"trainer\"", "]", "[", "\"save_period\"", "]", "=", "1", "\n", "config", "[", "\"trainer\"", "]", "[", "\"skip_first_n_saves\"", "]", "=", "0", "\n", "exper_name", "=", "f\"{exper_name}-train-single-epoch\"", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.init": [[139, 147], ["dict", "all", "dict.update", "getattr"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update"], ["", "return", "exper_name", "\n", "\n", "", "def", "init", "(", "self", ",", "name", ",", "module", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Finds a function handle with the name given as 'type' in config, and returns\n        the instance initialized with corresponding keyword args given as 'args'.\n        \"\"\"", "\n", "module_name", "=", "self", "[", "name", "]", "[", "'type'", "]", "\n", "module_args", "=", "dict", "(", "self", "[", "name", "]", "[", "'args'", "]", ")", "\n", "msg", "=", "(", "f\"Fail for {module_name}\\n\"", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.__getitem__": [[148, 150], ["None"], "methods", ["None"], ["f\"overwriting kwargs given in config file is not allowed\\n\"", "\n", "f\"passed kwargs: {kwargs}\\n\"", "\n", "f\"for module_args: {module_args})\"", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.__setitem__": [[151, 153], ["None"], "methods", ["None"], ["assert", "all", "(", "[", "k", "not", "in", "module_args", "for", "k", "in", "kwargs", "]", ")", ",", "msg", "\n", "module_args", ".", "update", "(", "kwargs", ")", "\n", "return", "getattr", "(", "module", ",", "module_name", ")", "(", "*", "args", ",", "**", "module_args", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get": [[154, 156], ["parse_config.ConfigParser.config.get"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["\n", "", "def", "__getitem__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "self", ".", "config", "[", "name", "]", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.config": [[158, 161], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "# NOTE: This is used for boolean checking deep inside ray.tune, so we required it", "\n", "# to be defined.", "\n", "        ", "return", "len", "(", "self", ".", "config", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.save_dir": [[162, 165], ["None"], "methods", ["None"], ["\n", "", "def", "__setitem__", "(", "self", ",", "name", ",", "value", ")", ":", "\n", "        ", "self", ".", "config", "[", "name", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.log_dir": [[166, 169], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "name", ")", ":", "\n", "        ", "return", "name", "in", "self", ".", "config", "\n", "\n", "", "def", "get", "(", "self", ",", "name", ",", "default", ")", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.exper_name": [[170, 173], ["None"], "methods", ["None"], ["        ", "return", "self", ".", "config", ".", "get", "(", "name", ",", "default", ")", "\n", "\n", "", "def", "keys", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "config", ".", "keys", "(", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.web_dirs": [[174, 177], ["None"], "methods", ["None"], ["\n", "", "def", "get_logger", "(", "self", ",", "name", ",", "verbosity", "=", "2", ")", ":", "\n", "        ", "msg_verbosity", "=", "\"verbosity option {} is invalid. Valid options are {}.\"", "\n", "msg_verbosity", "=", "msg_verbosity", ".", "format", "(", "verbosity", ",", "self", ".", "log_levels", ".", "keys", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.__repr__": [[178, 180], ["pprint.PrettyPrinter().pprint.pformat", "pprint.PrettyPrinter"], "methods", ["None"], ["assert", "verbosity", "in", "self", ".", "log_levels", ",", "msg_verbosity", "\n", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "self", ".", "log_levels", "[", "verbosity", "]", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._update_config": [[183, 189], ["getattr", "parse_config._get_opt_name", "parse_config._set_by_path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._get_opt_name", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._set_by_path"], ["# setting read-only attributes", "\n", "", "@", "property", "\n", "def", "config", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_config", "\n", "\n", "", "@", "property", "\n", "def", "save_dir", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._get_opt_name": [[191, 196], ["flags[].replace", "flg.startswith", "flg.replace"], "function", ["None"], ["\n", "", "@", "property", "\n", "def", "log_dir", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_log_dir", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._set_by_path": [[198, 201], ["parse_config._get_by_path"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._get_by_path"], ["\n", "", "def", "items", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_config", ".", "items", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config._get_by_path": [[203, 206], ["functools.reduce"], "function", ["None"], ["# helper functions used to update config dict with custom cli options", "\n", "", "", "def", "_update_config", "(", "config", ",", "options", ",", "args", ")", ":", "\n", "    ", "for", "opt", "in", "options", ":", "\n", "        ", "value", "=", "getattr", "(", "args", ",", "_get_opt_name", "(", "opt", ".", "flags", ")", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.configure_train_test_splits": [[292, 318], ["print", "type().dataset_paths", "print", "time.time", "[].items", "print", "type", "pathlib.Path", "pathlib.Path", "open", "f.read().splitlines", "time.time", "f.read"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.dataset_paths", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["            ", "logger", ".", "debug", "(", "i", ")", "\n", "", "self", ".", "data", "[", "vid", "]", "=", "self", ".", "get_sample_data", "(", "vid", ")", "\n", "", "", "elif", "self", ".", "reading_from", "==", "\"pkl\"", ":", "\n", "        ", "self", ".", "data_exp", "=", "self", ".", "loaded_data", "[", "data_source", "]", "\n", "for", "expert", "in", "self", ".", "experts", ":", "\n", "          ", "if", "expert", "not", "in", "self", ".", "data_exp", ":", "\n", "            ", "self", ".", "data_exp", "[", "expert", "]", "=", "{", "}", "\n", "\n", "", "if", "expert", "in", "self", ".", "expert_paths", ".", "keys", "(", ")", ":", "\n", "            ", "for", "agg", ",", "path", "in", "self", ".", "expert_paths", "[", "expert", "]", ".", "items", "(", ")", ":", "\n", "              ", "data_path", "=", "pathlib", ".", "Path", "(", "self", ".", "data_dir", ")", "/", "pathlib", ".", "Path", "(", "path", ")", "\n", "if", "agg", "not", "in", "self", ".", "data_exp", "[", "expert", "]", ":", "\n", "                ", "self", ".", "data_exp", "[", "expert", "]", "[", "agg", "]", "=", "memcache", "(", "data_path", ")", "\n", "", "", "", "else", ":", "\n", "            ", "logger", ".", "warning", "(", "\"The expert %s is not available for dataset %s\"", ",", "\n", "expert", ",", "self", ".", "dataset_name", ")", "\n", "\n", "", "", "if", "self", ".", "split_name", "==", "\"test2\"", ":", "\n", "          ", "path", "=", "self", ".", "expert_paths", "[", "\"raw_captions_test2\"", "]", "\n", "", "else", ":", "\n", "          ", "path", "=", "self", ".", "expert_paths", "[", "\"raw_captions\"", "]", "\n", "", "data_path", "=", "pathlib", ".", "Path", "(", "self", ".", "data_dir", ")", "/", "pathlib", ".", "Path", "(", "path", ")", "\n", "additionnal_captions", "=", "memcache", "(", "data_path", ")", "\n", "if", "\"raw_captions\"", "not", "in", "self", ".", "data_exp", ":", "\n", "          ", "self", ".", "data_exp", "[", "\"raw_captions\"", "]", "=", "{", "}", "\n", "", "self", ".", "data_exp", "[", "\"raw_captions\"", "]", ".", "update", "(", "additionnal_captions", ")", "\n", "", "self", ".", "loaded_in_ram", "=", "True", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.sanity_checks": [[37, 42], ["None"], "methods", ["None"], ["    ", "return", "True", "\n", "", "else", ":", "\n", "    ", "return", "False", "\n", "\n", "\n", "", "", "def", "is_stop_word", "(", "word", ")", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.load_features": [[43, 48], ["None"], "methods", ["None"], ["  ", "word_pure", "=", "get_clean_word", "(", "word", ")", "\n", "if", "word_pure", "in", "stop_words", ".", "ENGLISH_STOP_WORDS", ":", "\n", "    ", "return", "True", "\n", "", "if", "not", "word_pure", ".", "isalnum", "(", ")", ":", "\n", "    ", "return", "True", "\n", "", "for", "word_piece", "in", "word_pure", ".", "split", "(", "\"\\'\"", ")", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.__init__": [[49, 291], ["set", "list", "base_dataset.BaseDataset.configure_train_test_splits", "base_dataset.BaseDataset.logger.info", "len", "len", "base_dataset.BaseDataset.load_features", "utils.util.expert_tensor_storage", "retrieval.update", "enumerate", "base_dataset.BaseDataset.sanity_checks", "raw_input_dims.keys", "raw_input_dims.keys", "pickle.load", "len", "base_dataset.BaseDataset.logger.info", "base_dataset.BaseDataset.logger.info", "base_dataset.BaseDataset.text_features.items", "base_dataset.BaseDataset.logger.info", "numpy.zeros", "torch.ones", "len", "numpy.zeros", "numpy.zeros", "enumerate", "base_dataset.BaseDataset.label_features.items", "base_dataset.BaseDataset.tensor_storage[].intersection", "base_dataset.BaseDataset.tensor_storage[].intersection", "open", "numpy.zeros", "numpy.mean", "numpy.zeros", "numpy.zeros", "numpy.zeros", "ValueError", "base_dataset.BaseDataset.has_missing_values", "base_dataset.BaseDataset.feat_aggregation[].get", "base_dataset.BaseDataset.has_missing_values", "base_dataset.BaseDataset.feat_aggregation[].get", "numpy.mean", "base_dataset.BaseDataset.feat_aggregation[].keys", "numpy.logical_not", "numpy.ones_like", "numpy.logical_not", "numpy.ones_like", "min", "numpy.vstack", "min", "range", "pathlib.Path", "numpy.isnan", "numpy.isnan", "len", "len", "min", "numpy.array", "len", "len", "len", "base_dataset.BaseDataset.logger.info", "ValueError", "len", "len"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.configure_train_test_splits", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.load_features", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.expert_tensor_storage", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.sanity_checks", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.has_missing_values", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.has_missing_values", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["    ", "if", "word_piece", "in", "stop_words", ".", "ENGLISH_STOP_WORDS", ":", "\n", "      ", "return", "True", "\n", "", "", "return", "False", "\n", "\n", "\n", "", "def", "get_clean_word", "(", "word", ")", ":", "\n", "# Remove invalid characters from word", "\n", "  ", "word_pure", "=", "word", "\n", "invalid_char", "=", "[", "\".\"", ",", "\",\"", ",", "\"?\"", ",", "\"!\"", "]", "\n", "for", "char", "in", "invalid_char", ":", "\n", "    ", "word_pure", "=", "word_pure", ".", "replace", "(", "char", ",", "\"\"", ")", "\n", "", "return", "word_pure", ".", "lower", "(", ")", "\n", "\n", "\n", "", "def", "crop_or_pad_to_len", "(", "token_ids", ",", "max_text_words", ")", ":", "\n", "  ", "token_ids_tensor", "=", "np", ".", "zeros", "(", "(", "max_text_words", ",", "2", ")", ")", "\n", "keep", "=", "min", "(", "len", "(", "token_ids", ")", ",", "max_text_words", ")", "\n", "token_ids_tensor", "[", ":", "keep", ",", "0", "]", "=", "token_ids", "[", ":", "keep", "]", "\n", "token_ids_tensor", "[", ":", "keep", ",", "1", "]", "=", "1", "\n", "return", "token_ids_tensor", "\n", "\n", "\n", "", "def", "choose_or_pad_to_len", "(", "features", ",", "\n", "features_t", ",", "\n", "max_tokens", ",", "\n", "training", ",", "\n", "shuffle", "=", "False", ",", "\n", "seed", "=", "0", ")", ":", "\n", "  ", "\"\"\"Outputs a fixed length sequence of features from a variable length input.\n\n  Performs a selection if there are too many input features.\n  Pads the sequence if there are too few features.\n\n  Args:\n    features: Input features.\n    features_t: Input features timestamps.\n    max_tokens: Length of the output sequence.\n    training: If True, the features will be deterministically sampled.\n    shuffle: If True, the features are shuffled.\n    seed: Seed used for the random shuffling.\n\n  Returns:\n    Fixed length sequence of features.\n  \"\"\"", "\n", "feature_dim", "=", "features", ".", "shape", "[", "-", "1", "]", "\n", "tensor", "=", "np", ".", "zeros", "(", "(", "max_tokens", ",", "feature_dim", ")", ")", "\n", "tensor_t", "=", "np", ".", "ones", "(", "(", "max_tokens", ")", ")", "\n", "tensor_ind", "=", "np", ".", "zeros", "(", "(", "max_tokens", ")", ")", "\n", "keep", "=", "min", "(", "len", "(", "features", ")", ",", "max_tokens", ")", "\n", "if", "training", ":", "\n", "# If training, we randomly pick features", "\n", "    ", "pick", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "features", ")", ",", "size", "=", "keep", ",", "replace", "=", "False", ")", "\n", "", "else", ":", "\n", "# If not training, the choice of features is deterministic", "\n", "    ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "pick", "=", "rng", ".", "choice", "(", "len", "(", "features", ")", ",", "size", "=", "keep", ",", "replace", "=", "False", ")", "\n", "", "pick", "=", "np", ".", "sort", "(", "pick", ")", "\n", "tensor", "[", ":", "keep", ",", ":", "]", "=", "features", "[", "pick", "]", "\n", "if", "shuffle", "and", "training", ":", "\n", "# Shuffle temporal encoding so that the model cannot use temporal", "\n", "# information.", "\n", "    ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "tensor_t", "[", ":", "keep", "]", "=", "rng", ".", "shuffle", "(", "features_t", "[", "pick", "]", ")", "\n", "", "else", ":", "\n", "    ", "tensor_t", "[", ":", "keep", "]", "=", "features_t", "[", "pick", "]", "\n", "", "tensor_ind", "[", ":", "keep", "]", "=", "1", "\n", "return", "tensor", ",", "tensor_t", ",", "tensor_ind", "\n", "\n", "\n", "", "def", "remove_caption_stop_words", "(", "cap", ",", "cap_t", ")", ":", "\n", "  ", "\"\"\"Removes the stop words from a caption.\"\"\"", "\n", "res", "=", "[", "]", "\n", "res_t", "=", "[", "]", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "cap", ")", ":", "\n", "    ", "word_t", "=", "cap_t", "[", "i", "]", "\n", "if", "not", "is_stop_word", "(", "word", ")", ":", "\n", "      ", "res", ".", "append", "(", "get_clean_word", "(", "word", ")", ")", "\n", "res_t", ".", "append", "(", "word_t", ")", "\n", "", "", "if", "len", "(", "res", ")", "<", "1", ":", "\n", "    ", "res", ".", "append", "(", "\".\"", ")", "\n", "res_t", ".", "append", "(", "np", ".", "array", "(", "[", "0.", ",", "0.", "]", ")", ")", "\n", "", "return", "res", ",", "res_t", "\n", "\n", "\n", "", "class", "BaseDataset", "(", "Dataset", ")", ":", "\n", "  ", "\"\"\"Base class for a caption-video pairs dataset.\"\"\"", "\n", "\n", "@", "abc", ".", "abstractmethod", "\n", "def", "configure_train_test_splits", "(", "self", ",", "cut_name", ",", "split_name", ")", ":", "\n", "    ", "\"\"\"Partition the datset into train/val/test splits.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "@", "abc", ".", "abstractmethod", "\n", "def", "sanity_checks", "(", "self", ")", ":", "\n", "    ", "\"\"\"Run sanity checks on loaded data.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "@", "abc", ".", "abstractmethod", "\n", "def", "load_features", "(", "self", ")", ":", "\n", "    ", "\"\"\"Load features from disk.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "__init__", "(", "self", ",", "\n", "data_dir", ",", "\n", "raw_input_dims", ",", "\n", "cut_name", ",", "\n", "split_name", ",", "\n", "max_text_words", "=", "30", ",", "\n", "max_expert_tokens", "=", "8", ",", "\n", "clip_duration", "=", "float", "(", "\"Inf\"", ")", ",", "\n", "caption_length", "=", "float", "(", "\"Inf\"", ")", ",", "\n", "captions_per_video", "=", "1", ",", "\n", "restrict_train_captions", "=", "0", ",", "\n", "training", "=", "False", ",", "\n", "split_size", "=", "1.0", ",", "\n", "load_in_ram", "=", "False", ",", "\n", "remove_stop_words", "=", "False", ",", "\n", "n_pairs", "=", "1", ",", "\n", "tokenizer", "=", "None", ",", "\n", "shuffle_feats_t", "=", "False", ",", "\n", "loaded_data", "=", "None", ",", "\n", "query_shuffling", "=", "\"indiv\"", ",", "\n", "cross_seed", "=", "0", ",", "\n", "temporal_encoding_window", "=", "1", ")", ":", "\n", "\n", "    ", "self", ".", "sanity_checks", "=", "False", "\n", "self", ".", "train", "=", "training", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "restrict_train_captions", "=", "restrict_train_captions", "\n", "self", ".", "max_text_words", "=", "max_text_words", "\n", "self", ".", "max_expert_tokens", "=", "max_expert_tokens", "\n", "self", ".", "root_feat", "=", "pathlib", ".", "Path", "(", "data_dir", ")", "/", "\"symlinked-feats\"", "\n", "self", ".", "experts", "=", "set", "(", "raw_input_dims", ".", "keys", "(", ")", ")", "\n", "self", ".", "rgb_shots", "=", "1", "\n", "self", ".", "cut_name", "=", "cut_name", "\n", "self", ".", "split_name", "=", "split_name", "\n", "self", ".", "split_size", "=", "split_size", "\n", "self", ".", "load_in_ram", "=", "load_in_ram", "\n", "self", ".", "remove_stop_words", "=", "remove_stop_words", "\n", "self", ".", "n_pairs", "=", "n_pairs", "\n", "self", ".", "clip_duration", "=", "clip_duration", "\n", "self", ".", "caption_length", "=", "caption_length", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "shuffle_feats_t", "=", "shuffle_feats_t", "\n", "self", ".", "query_shuffling", "=", "query_shuffling", "\n", "self", ".", "cross_seed", "=", "cross_seed", "\n", "self", ".", "temporal_encoding_window", "=", "temporal_encoding_window", "\n", "\n", "self", ".", "data_aug", "=", "False", "\n", "self", ".", "max_ratio_rem", "=", "0", "\n", "\n", "if", "self", ".", "cut_name", "==", "\"c\"", ":", "\n", "# The challenge features are stored in pkl files", "\n", "      ", "self", ".", "reading_from", "=", "\"pkl\"", "\n", "", "else", ":", "\n", "# The ECCV20 paper features are stored in multiple h5 files", "\n", "      ", "self", ".", "reading_from", "=", "\"mult_h5\"", "\n", "\n", "", "self", ".", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "data_dir", ")", ",", "\"vid_feat_files\"", ",", "\n", "self", ".", "reading_from", ")", "\n", "logger", ".", "debug", "(", "\"Cache_dir: %s\"", ",", "self", ".", "cache_dir", ")", "\n", "\n", "# This attribute can be overloaded by different datasets, so it must be set", "\n", "# before the `configure_train_test_splits() method call`", "\n", "self", ".", "restrict_test_captions", "=", "None", "\n", "\n", "# Use a single caption per video when forming training minibatches", "\n", "# (different captions from the same video may still be used across", "\n", "# different minibatches)", "\n", "if", "self", ".", "train", ":", "\n", "      ", "self", ".", "captions_per_video", "=", "1", "\n", "", "else", ":", "\n", "      ", "self", ".", "captions_per_video", "=", "captions_per_video", "\n", "\n", "", "self", ".", "ordered_experts", "=", "list", "(", "raw_input_dims", ".", "keys", "(", ")", ")", "\n", "self", ".", "configure_train_test_splits", "(", "cut_name", "=", "cut_name", ",", "split_name", "=", "split_name", ")", "\n", "self", ".", "expert_timings", "=", "expert_timings", ".", "expert_timings", "\n", "\n", "# If split_size is type(int) it represents the number of samples that we", "\n", "# keep.", "\n", "# If split_size is type(float) it represents the ratio of the original", "\n", "# split size that we keep.", "\n", "original_size", "=", "len", "(", "self", ".", "vid_list", ")", "\n", "if", "split_size", ">=", "2", "and", "isinstance", "(", "split_size", ",", "int", ")", ":", "\n", "      ", "nb_samples", "=", "split_size", "\n", "", "elif", "0", "<=", "split_size", "<=", "1", "and", "isinstance", "(", "split_size", ",", "float", ")", ":", "\n", "      ", "nb_samples", "=", "int", "(", "split_size", "*", "original_size", ")", "\n", "\n", "", "self", ".", "vid_list", "=", "self", ".", "vid_list", "[", ":", "nb_samples", "]", "\n", "self", ".", "num_train", "=", "len", "(", "self", ".", "vid_list", ")", "\n", "\n", "# Display info about the dataset split size", "\n", "main_msg", "=", "f\"Number of videos in {self.dataset_name}: {original_size}\"", "\n", "if", "self", ".", "num_train", "==", "original_size", ":", "\n", "      ", "msg", "=", "\"\"", "\n", "", "else", ":", "\n", "      ", "msg", "=", "f\" but we keep only {self.num_train} (split_size = {split_size})\"", "\n", "", "logger", ".", "debug", "(", "main_msg", "+", "msg", ")", "\n", "\n", "# Log how many captions per video are kept", "\n", "logger", ".", "debug", "(", "\"We consider %s captions per video\"", ",", "self", ".", "captions_per_video", ")", "\n", "self", ".", "raw_input_dims", "=", "raw_input_dims", "\n", "\n", "visualisations", "=", "True", "\n", "if", "visualisations", ":", "\n", "      ", "logger", ".", "debug", "(", "\"Storing paths to enable visualisations ...\"", ")", "\n", "\n", "symlink_to_root", "=", "pathlib", ".", "Path", ".", "cwd", "(", ")", "/", "\"project_root\"", "\n", "# If symlink to root can be accessed, follow that path", "\n", "# Otherwise, follow the current working directory", "\n", "# (that should be the project root)", "\n", "if", "symlink_to_root", ".", "exists", "(", ")", ":", "\n", "        ", "video_paths", "=", "[", "\n", "os", ".", "readlink", "(", "str", "(", "symlink_to_root", ")", ")", "/", "pathlib", ".", "Path", "(", "data_dir", ")", "\n", "/", "f\"videos/{x}.mp4\"", "for", "x", "in", "self", ".", "vid_list", "\n", "]", "\n", "", "else", ":", "\n", "        ", "video_paths", "=", "[", "\n", "pathlib", ".", "Path", ".", "cwd", "(", ")", "/", "pathlib", ".", "Path", "(", "data_dir", ")", "/", "f\"videos/{x}.mp4\"", "\n", "for", "x", "in", "self", ".", "vid_list", "\n", "]", "\n", "\n", "", "self", ".", "video_paths", "=", "video_paths", "\n", "\n", "", "self", ".", "missing_val", "=", "0", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "cache_dir", ")", "and", "self", ".", "reading_from", "!=", "\"pkl\"", ":", "\n", "      ", "logger", ".", "warning", "(", "\"%s does not exist\"", ",", "self", ".", "cache_dir", ")", "\n", "\n", "", "self", ".", "variable_sz_experts", "=", "self", ".", "experts", "\n", "self", ".", "flaky_experts", "=", "self", ".", "experts", "\n", "\n", "self", ".", "loaded_in_ram", "=", "False", "\n", "self", ".", "loaded_data", "=", "loaded_data", "\n", "data_source", "=", "self", ".", "dataset_name", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "if", "data_source", "not", "in", "self", ".", "loaded_data", ":", "\n", "      ", "self", ".", "loaded_data", "[", "data_source", "]", "=", "{", "}", "\n", "", "if", "self", ".", "load_in_ram", ":", "\n", "      ", "logger", ".", "info", "(", "\"Loading dataset {self.dataset_name} in ram ...\"", ")", "\n", "if", "self", ".", "reading_from", "==", "\"mult_h5\"", ":", "\n", "        ", "self", ".", "data_vid", "=", "{", "}", "\n", "for", "i", ",", "vid", "in", "enumerate", "(", "self", ".", "vid_list", ")", ":", "\n", "          ", "if", "i", "%", "100", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.tokenize_caption": [[320, 354], ["len", "ipdb.set_trace", "txt_caption.capitalize.capitalize.strip", "txt_caption.capitalize.capitalize.capitalize", "base_dataset.BaseDataset.tokenizer.tokenize", "base_dataset.BaseDataset.tokenizer.convert_tokens_to_ids", "list", "len", "ipdb.set_trace", "range", "len"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.WeTokenizer.tokenize", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.txt_embeddings.WeTokenizer.convert_tokens_to_ids"], ["", "", "def", "tokenize_caption", "(", "self", ",", "raw_caption", ",", "special_tokens", "=", "True", ")", ":", "\n", "    ", "tokenize", "=", "True", "\n", "\n", "word_list", "=", "raw_caption", "\n", "if", "len", "(", "word_list", ")", "==", "0", ":", "\n", "# Empty list of words.", "\n", "      ", "ipdb", ".", "set_trace", "(", ")", "\n", "", "if", "tokenize", ":", "\n", "      ", "txt_caption", "=", "\" \"", ".", "join", "(", "word_list", ")", "\n", "# Remove whitespace at beginning and end of the sentence.", "\n", "txt_caption", "=", "txt_caption", ".", "strip", "(", ")", "\n", "# Add period at the end of the sentence if not already there.", "\n", "if", "txt_caption", "[", "-", "1", "]", "not", "in", "[", "\".\"", ",", "\"?\"", ",", "\"!\"", "]", ":", "\n", "        ", "txt_caption", "+=", "\".\"", "\n", "", "txt_caption", "=", "txt_caption", ".", "capitalize", "(", ")", "\n", "tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "txt_caption", ")", "\n", "if", "special_tokens", ":", "\n", "        ", "cls", "=", "[", "self", ".", "tokenizer", ".", "cls_token", "]", "\n", "sep", "=", "[", "self", ".", "tokenizer", ".", "sep_token", "]", "# [SEP] token", "\n", "tokens", "=", "cls", "+", "tokens", "+", "sep", "\n", "", "tokens", "=", "tokens", "[", ":", "self", ".", "max_text_words", "]", "\n", "# Make sure that the last token is", "\n", "# the [SEP] token", "\n", "if", "special_tokens", ":", "\n", "        ", "tokens", "[", "-", "1", "]", "=", "self", ".", "tokenizer", ".", "sep_token", "\n", "\n", "", "ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "", "else", ":", "\n", "      ", "ids", "=", "list", "(", "range", "(", "len", "(", "word_list", ")", ")", ")", "\n", "\n", "", "if", "len", "(", "ids", ")", "<=", "0", ":", "\n", "      ", "ipdb", ".", "set_trace", "(", ")", "\n", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.get_feature_timings": [[357, 380], ["numpy.linspace", "numpy.linspace", "numpy.stack", "numpy.empty", "base_dataset.BaseDataset.get_feature_timings", "numpy.repeat"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.get_feature_timings"], ["", "def", "get_feature_timings", "(", "self", ",", "nb_feats", ",", "feat_width", ",", "stride", "=", "None", ",", "group", "=", "None", ")", ":", "\n", "# Return an array containing the start time of each feature in the first", "\n", "# line and the end time of each feature in the second line.", "\n", "    ", "if", "feat_width", "is", "None", ":", "\n", "      ", "timings", "=", "np", ".", "empty", "(", "(", "nb_feats", ",", "2", ")", ")", "\n", "timings", "[", ":", "]", "=", "-", "1", "\n", "return", "timings", "\n", "", "if", "group", "is", "not", "None", ":", "\n", "      ", "assert", "nb_feats", "%", "group", "==", "0", "\n", "nb_feats_top", "=", "nb_feats", "//", "group", "\n", "top_timings", "=", "self", ".", "get_feature_timings", "(", "nb_feats_top", ",", "\n", "feat_width", ",", "\n", "stride", ",", "\n", "group", "=", "None", ")", "\n", "bot_timings", "=", "np", ".", "repeat", "(", "top_timings", ",", "group", ",", "axis", "=", "-", "1", ")", "\n", "return", "bot_timings", "\n", "", "if", "stride", "is", "None", ":", "\n", "      ", "stride", "=", "feat_width", "\n", "", "starts", "=", "np", ".", "linspace", "(", "0", ",", "(", "nb_feats", "-", "1", ")", "*", "stride", ",", "num", "=", "nb_feats", ")", "\n", "ends", "=", "np", ".", "linspace", "(", "feat_width", ",", "(", "nb_feats", "-", "1", ")", "*", "stride", "+", "feat_width", ",", "\n", "num", "=", "nb_feats", ")", "\n", "res", "=", "np", ".", "stack", "(", "(", "starts", ",", "ends", ")", ",", "axis", "=", "-", "1", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.aggregate_feats": [[381, 391], ["numpy.mean", "numpy.max", "NotImplementedError", "msg.format"], "methods", ["None"], ["", "def", "aggregate_feats", "(", "self", ",", "feats", ",", "mode", ")", ":", "\n", "    ", "assert", "feats", ".", "ndim", "==", "2", "\n", "if", "mode", "==", "\"avg\"", ":", "\n", "      ", "agg", "=", "np", ".", "mean", "(", "feats", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "", "elif", "mode", "==", "\"max\"", ":", "\n", "      ", "agg", "=", "np", ".", "max", "(", "feats", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "", "else", ":", "\n", "      ", "msg", "=", "\"aggregation mode {} not supported\"", "\n", "raise", "NotImplementedError", "(", "msg", ".", "format", "(", "mode", ")", ")", "\n", "", "return", "agg", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.collate_data": [[319, 436], ["len", "tensors.update", "enumerate", "collections.OrderedDict", "numpy.zeros", "numpy.zeros", "numpy.zeros", "utils.util.ensure_tensor", "base_dataset.BaseDataset.feat_aggregation[].get", "torch.from_numpy().float", "torch.from_numpy", "base_dataset.BaseDataset.trn_config.keys", "numpy.zeros", "numpy.zeros", "[].keys", "numpy.zeros", "numpy.zeros", "range", "ind.items", "collections.OrderedDict", "collections.OrderedDict", "numpy.logical_not", "torch.ones_like", "numpy.zeros", "min", "min", "vid_name.append", "torch.from_numpy().float", "torch.isnan", "torch.from_numpy", "torch.from_numpy().float", "isinstance", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "len", "len", "torch.from_numpy", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "isinstance", "torch.from_numpy", "torch.from_numpy", "list", "base_dataset.BaseDataset.distil_features[].keys"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.ensure_tensor", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["\n", "", "", "def", "tokenize_caption", "(", "self", ",", "raw_caption", ",", "special_tokens", "=", "True", ")", ":", "\n", "    ", "tokenize", "=", "True", "\n", "\n", "word_list", "=", "raw_caption", "\n", "if", "len", "(", "word_list", ")", "==", "0", ":", "\n", "# Empty list of words.", "\n", "      ", "ipdb", ".", "set_trace", "(", ")", "\n", "", "if", "tokenize", ":", "\n", "      ", "txt_caption", "=", "\" \"", ".", "join", "(", "word_list", ")", "\n", "# Remove whitespace at beginning and end of the sentence.", "\n", "txt_caption", "=", "txt_caption", ".", "strip", "(", ")", "\n", "# Add period at the end of the sentence if not already there.", "\n", "if", "txt_caption", "[", "-", "1", "]", "not", "in", "[", "\".\"", ",", "\"?\"", ",", "\"!\"", "]", ":", "\n", "        ", "txt_caption", "+=", "\".\"", "\n", "", "txt_caption", "=", "txt_caption", ".", "capitalize", "(", ")", "\n", "tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "txt_caption", ")", "\n", "if", "special_tokens", ":", "\n", "        ", "cls", "=", "[", "self", ".", "tokenizer", ".", "cls_token", "]", "\n", "sep", "=", "[", "self", ".", "tokenizer", ".", "sep_token", "]", "# [SEP] token", "\n", "tokens", "=", "cls", "+", "tokens", "+", "sep", "\n", "", "tokens", "=", "tokens", "[", ":", "self", ".", "max_text_words", "]", "\n", "# Make sure that the last token is", "\n", "# the [SEP] token", "\n", "if", "special_tokens", ":", "\n", "        ", "tokens", "[", "-", "1", "]", "=", "self", ".", "tokenizer", ".", "sep_token", "\n", "\n", "", "ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "", "else", ":", "\n", "      ", "ids", "=", "list", "(", "range", "(", "len", "(", "word_list", ")", ")", ")", "\n", "\n", "", "if", "len", "(", "ids", ")", "<=", "0", ":", "\n", "      ", "ipdb", ".", "set_trace", "(", ")", "\n", "\n", "", "return", "ids", "\n", "\n", "\n", "\n", "", "def", "get_feature_timings", "(", "self", ",", "nb_feats", ",", "feat_width", ",", "stride", "=", "None", ",", "group", "=", "None", ")", ":", "\n", "# Return an array containing the start time of each feature in the first", "\n", "# line and the end time of each feature in the second line.", "\n", "    ", "if", "feat_width", "is", "None", ":", "\n", "      ", "timings", "=", "np", ".", "empty", "(", "(", "nb_feats", ",", "2", ")", ")", "\n", "timings", "[", ":", "]", "=", "-", "1", "\n", "return", "timings", "\n", "", "if", "group", "is", "not", "None", ":", "\n", "      ", "assert", "nb_feats", "%", "group", "==", "0", "\n", "nb_feats_top", "=", "nb_feats", "//", "group", "\n", "top_timings", "=", "self", ".", "get_feature_timings", "(", "nb_feats_top", ",", "\n", "feat_width", ",", "\n", "stride", ",", "\n", "group", "=", "None", ")", "\n", "bot_timings", "=", "np", ".", "repeat", "(", "top_timings", ",", "group", ",", "axis", "=", "-", "1", ")", "\n", "return", "bot_timings", "\n", "", "if", "stride", "is", "None", ":", "\n", "      ", "stride", "=", "feat_width", "\n", "", "starts", "=", "np", ".", "linspace", "(", "0", ",", "(", "nb_feats", "-", "1", ")", "*", "stride", ",", "num", "=", "nb_feats", ")", "\n", "ends", "=", "np", ".", "linspace", "(", "feat_width", ",", "(", "nb_feats", "-", "1", ")", "*", "stride", "+", "feat_width", ",", "\n", "num", "=", "nb_feats", ")", "\n", "res", "=", "np", ".", "stack", "(", "(", "starts", ",", "ends", ")", ",", "axis", "=", "-", "1", ")", "\n", "return", "res", "\n", "\n", "", "def", "aggregate_feats", "(", "self", ",", "feats", ",", "mode", ")", ":", "\n", "    ", "assert", "feats", ".", "ndim", "==", "2", "\n", "if", "mode", "==", "\"avg\"", ":", "\n", "      ", "agg", "=", "np", ".", "mean", "(", "feats", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "", "elif", "mode", "==", "\"max\"", ":", "\n", "      ", "agg", "=", "np", ".", "max", "(", "feats", ",", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "", "else", ":", "\n", "      ", "msg", "=", "\"aggregation mode {} not supported\"", "\n", "raise", "NotImplementedError", "(", "msg", ".", "format", "(", "mode", ")", ")", "\n", "", "return", "agg", "\n", "\n", "", "def", "collate_data", "(", "self", ",", "data", ")", ":", "\n", "    ", "text_keys", "=", "data", "[", "0", "]", "[", "\"text_tensors\"", "]", ".", "keys", "(", ")", "\n", "text_tensors", "=", "{", "key", ":", "[", "]", "for", "key", "in", "text_keys", "}", "\n", "\n", "vid_keys", "=", "data", "[", "0", "]", "[", "\"vid_tensors\"", "]", ".", "keys", "(", ")", "\n", "vid_tensors", "=", "{", "\n", "key", ":", "{", "expert", ":", "[", "]", "for", "expert", "in", "self", ".", "experts", "}", "for", "key", "in", "vid_keys", "\n", "}", "\n", "\n", "l_keys", "=", "data", "[", "0", "]", "[", "\"lists\"", "]", ".", "keys", "(", ")", "\n", "lists", "=", "{", "key", ":", "[", "]", "for", "key", "in", "l_keys", "}", "\n", "\n", "for", "vid", "in", "data", ":", "\n", "      ", "for", "key", "in", "text_keys", ":", "\n", "        ", "text_tensors", "[", "key", "]", ".", "append", "(", "vid", "[", "\"text_tensors\"", "]", "[", "key", "]", ")", "\n", "", "for", "key", "in", "vid_keys", ":", "\n", "        ", "for", "expert", "in", "self", ".", "experts", ":", "\n", "          ", "vid_tensors", "[", "key", "]", "[", "expert", "]", ".", "append", "(", "vid", "[", "\"vid_tensors\"", "]", "[", "key", "]", "[", "expert", "]", ")", "\n", "", "", "for", "key", "in", "l_keys", ":", "\n", "        ", "lists", "[", "key", "]", ".", "extend", "(", "vid", "[", "\"lists\"", "]", "[", "key", "]", ")", "\n", "\n", "# Concatenate the arrays of each sample to form a batch", "\n", "", "", "for", "key", "in", "text_keys", ":", "\n", "      ", "text_tensors", "[", "key", "]", "=", "np", ".", "concatenate", "(", "text_tensors", "[", "key", "]", ",", "\n", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "int32", ")", "\n", "", "for", "key", "in", "vid_keys", ":", "\n", "      ", "for", "expert", "in", "self", ".", "experts", ":", "\n", "        ", "vid_tensors", "[", "key", "]", "[", "expert", "]", "=", "np", ".", "concatenate", "(", "vid_tensors", "[", "key", "]", "[", "expert", "]", ",", "\n", "axis", "=", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "", "", "minibatch", "=", "{", "**", "text_tensors", ",", "**", "vid_tensors", ",", "**", "lists", "}", "\n", "\n", "return", "minibatch", "\n", "\n", "", "def", "get_sample_data", "(", "self", ",", "vid", ")", ":", "\n", "    ", "if", "self", ".", "reading_from", "==", "\"mult_h5\"", ":", "\n", "      ", "if", "self", ".", "loaded_in_ram", ":", "\n", "        ", "return", "self", ".", "data_vid", "[", "vid", "]", "\n", "", "else", ":", "\n", "        ", "if", "vid", ".", "endswith", "(", "\".h5\"", ")", ":", "\n", "          ", "dataset_file_path", "=", "vid", "\n", "", "else", ":", "\n", "          ", "output_basename", "=", "f\"{vid[0]}/{vid[1]}/{vid[2]}/{vid}.h5\"", "\n", "dataset_file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cache_dir", ",", "output_basename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.get_sample_data": [[426, 566], ["vid.endswith", "h5py.File", "os.path.join", "h5py.File", "list", "len", "range", "video_data.keys", "logger.warning", "raw_captions.append", "video_data.keys", "len", "range", "video_data.keys", "raw_captions_t.append", "len", "numpy.zeros", "raw_captions_t.append", "video_data.keys", "len", "numpy.zeros", "raw_captions_t.append", "base_dataset.BaseDataset.data_exp[].keys", "video_data.keys", "base_dataset.BaseDataset.data_exp[].keys", "base_dataset.BaseDataset.data_exp[].keys", "k.startswith", "len", "numpy.average", "base_dataset.BaseDataset.get_feature_timings", "numpy.average", "len", "numpy.isnan", "video_data.keys", "base_dataset.BaseDataset.get_feature_timings", "isinstance", "numpy.isnan", "base_dataset.BaseDataset.expert_timings.keys", "len", "numpy.isnan", "len", "numpy.isnan", "len", "print", "base_dataset.BaseDataset.get_feature_timings", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.get_feature_timings", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.get_feature_timings", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.get_feature_timings"], ["", "def", "get_sample_data", "(", "self", ",", "vid", ")", ":", "\n", "    ", "if", "self", ".", "reading_from", "==", "\"mult_h5\"", ":", "\n", "      ", "if", "self", ".", "loaded_in_ram", ":", "\n", "        ", "return", "self", ".", "data_vid", "[", "vid", "]", "\n", "", "else", ":", "\n", "        ", "if", "vid", ".", "endswith", "(", "\".h5\"", ")", ":", "\n", "          ", "dataset_file_path", "=", "vid", "\n", "", "else", ":", "\n", "          ", "output_basename", "=", "f\"{vid[0]}/{vid[1]}/{vid[2]}/{vid}.h5\"", "\n", "dataset_file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "cache_dir", ",", "output_basename", ")", "\n", "\n", "", "dataset_file", "=", "h5py", ".", "File", "(", "dataset_file_path", ",", "\"r\"", ")", "\n", "with", "h5py", ".", "File", "(", "dataset_file_path", ",", "\"r\"", ")", "as", "dataset_file", ":", "\n", "          ", "video_data", "=", "dataset_file", "\n", "keys_list", "=", "list", "(", "video_data", ".", "keys", "(", ")", ")", "\n", "nb_captions", "=", "len", "(", "\n", "[", "k", "for", "k", "in", "keys_list", "if", "k", ".", "startswith", "(", "\"raw_captions.\"", ")", "]", ")", "\n", "if", "nb_captions", "==", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "\"No caption for %s\"", ",", "dataset_file_path", ")", "\n", "", "assert", "nb_captions", ">", "0", "\n", "raw_captions", "=", "[", "]", "\n", "raw_captions_t", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nb_captions", ")", ":", "\n", "            ", "raw_caption", "=", "video_data", "[", "f\"raw_captions.{i}\"", "]", ".", "value", "\n", "raw_captions", ".", "append", "(", "raw_caption", ")", "\n", "if", "f\"raw_captions_t.{i}\"", "in", "video_data", ".", "keys", "(", ")", ":", "\n", "              ", "raw_caption_t", "=", "video_data", "[", "f\"raw_captions_t.{i}\"", "]", ".", "value", "\n", "if", "raw_caption_t", ".", "shape", "[", "0", "]", "!=", "len", "(", "raw_caption", ")", ":", "\n", "                ", "raw_caption_t", "=", "raw_caption_t", "[", ":", "len", "(", "raw_caption", ")", "]", "\n", "", "raw_captions_t", ".", "append", "(", "raw_caption_t", ")", "\n", "", "else", ":", "\n", "              ", "nb_words", "=", "len", "(", "raw_caption", ")", "\n", "raw_caption_t", "=", "np", ".", "zeros", "(", "(", "nb_words", ",", "2", ")", ")", "\n", "raw_captions_t", ".", "append", "(", "raw_caption_t", ")", "\n", "\n", "", "", "features", "=", "{", "}", "\n", "features_t", "=", "{", "}", "\n", "features_avgpool", "=", "{", "}", "\n", "features_maxpool", "=", "{", "}", "\n", "for", "expert", "in", "self", ".", "experts", ":", "\n", "            ", "if", "f\"features.{expert}\"", "in", "video_data", ".", "keys", "(", ")", ":", "\n", "              ", "x", "=", "video_data", "[", "f\"features.{expert}\"", "]", ".", "value", "\n", "if", "len", "(", "x", ")", ">", "0", "and", "not", "np", ".", "isnan", "(", "x", "[", "0", "]", "[", "0", "]", ")", ":", "\n", "                ", "features", "[", "expert", "]", "=", "video_data", "[", "f\"features.{expert}\"", "]", ".", "value", "\n", "\n", "if", "f\"features_t.{expert}\"", "in", "video_data", ".", "keys", "(", ")", ":", "\n", "                  ", "x", "=", "video_data", "[", "f\"features_t.{expert}\"", "]", ".", "value", "\n", "# if not np.isnan(x[0][0]):", "\n", "if", "expert", "in", "[", "\"s3d\"", ",", "\"vggish\"", ",", "\"vggsound\"", "]", ":", "\n", "                    ", "features_t", "[", "expert", "]", "=", "video_data", "[", "\n", "f\"features_t.{expert}\"", "]", ".", "value", "\n", "print", "(", "video_data", "[", "f\"features_t.{expert}\"", "]", ".", "value", ")", "\n", "if", "features_t", "[", "expert", "]", ".", "shape", "[", "0", "]", "!=", "features", "[", "expert", "]", ".", "shape", "[", "0", "]", ":", "\n", "                      ", "logger", ".", "warning", "(", "\n", "\"Incorrect number of features_t values \"", "\n", "\"for %s\"", ",", "dataset_file_path", ")", "\n", "features_t", "[", "expert", "]", "=", "features_t", "[", "expert", "]", "[", ":", "features", "[", "expert", "]", ".", "\n", "shape", "[", "0", "]", "]", "\n", "", "", "else", ":", "\n", "                    ", "nb_feats", "=", "features", "[", "expert", "]", ".", "shape", "[", "0", "]", "\n", "expert_timing", "=", "self", ".", "expert_timings", "[", "expert", "]", "\n", "features_t", "[", "expert", "]", "=", "self", ".", "get_feature_timings", "(", "\n", "nb_feats", ",", "**", "expert_timing", ")", "\n", "", "", "else", ":", "\n", "                  ", "nb_feats", "=", "features", "[", "expert", "]", ".", "shape", "[", "0", "]", "\n", "expert_timing", "=", "self", ".", "expert_timings", "[", "expert", "]", "\n", "features_t", "[", "expert", "]", "=", "self", ".", "get_feature_timings", "(", "\n", "nb_feats", ",", "**", "expert_timing", ")", "\n", "", "features_t", "[", "expert", "]", "=", "np", ".", "average", "(", "features_t", "[", "expert", "]", ",", "axis", "=", "1", ")", "\n", "", "", "features_avgpool", "[", "expert", "]", "=", "None", "\n", "features_maxpool", "[", "expert", "]", "=", "None", "\n", "", "", "return", "(", "raw_captions", ",", "raw_captions_t", ",", "features", ",", "features_t", ",", "\n", "features_avgpool", ",", "features_maxpool", ")", "\n", "\n", "", "", "elif", "self", ".", "reading_from", "==", "\"pkl\"", ":", "\n", "      ", "if", "self", ".", "loaded_in_ram", ":", "\n", "# Raw captions", "\n", "        ", "video_data", "=", "self", ".", "data_exp", "[", "\"raw_captions\"", "]", "\n", "if", "vid", "in", "video_data", ".", "keys", "(", ")", ":", "\n", "          ", "x", "=", "video_data", "[", "vid", "]", "\n", "nb_captions", "=", "len", "(", "x", ")", "\n", "assert", "nb_captions", ">", "0", "\n", "raw_captions", "=", "video_data", "[", "vid", "]", "\n", "raw_captions_t", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nb_captions", ")", ":", "\n", "            ", "raw_caption", "=", "raw_captions", "[", "i", "]", "\n", "nb_words", "=", "len", "(", "raw_caption", ")", "\n", "raw_caption_t", "=", "np", ".", "zeros", "(", "(", "nb_words", ",", "2", ")", ")", "\n", "raw_captions_t", ".", "append", "(", "raw_caption_t", ")", "\n", "\n", "# Video features", "\n", "", "", "features", "=", "{", "}", "\n", "features_t", "=", "{", "}", "\n", "for", "expert", "in", "self", ".", "experts", ":", "\n", "          ", "if", "\"fixed_seg\"", "not", "in", "self", ".", "data_exp", "[", "expert", "]", ".", "keys", "(", ")", ":", "\n", "            ", "continue", "\n", "", "video_data", "=", "self", ".", "data_exp", "[", "expert", "]", "[", "\"fixed_seg\"", "]", "\n", "\n", "if", "vid", "in", "video_data", ".", "keys", "(", ")", ":", "\n", "            ", "x", "=", "video_data", "[", "vid", "]", "\n", "if", "not", "isinstance", "(", "x", ",", "float", ")", "and", "not", "np", ".", "isnan", "(", "x", "[", "0", "]", "[", "0", "]", ")", ":", "\n", "              ", "features", "[", "expert", "]", "=", "x", "\n", "\n", "# Timings", "\n", "nb_feats", "=", "features", "[", "expert", "]", ".", "shape", "[", "0", "]", "\n", "if", "expert", "in", "self", ".", "expert_timings", ".", "keys", "(", ")", ":", "\n", "                ", "expert_timing", "=", "self", ".", "expert_timings", "[", "expert", "]", "\n", "", "else", ":", "\n", "                ", "expert_timing", "=", "{", "\"feat_width\"", ":", "1.0", "}", "\n", "", "features_t", "[", "expert", "]", "=", "self", ".", "get_feature_timings", "(", "\n", "nb_feats", ",", "**", "expert_timing", ")", "\n", "features_t", "[", "expert", "]", "=", "np", ".", "average", "(", "features_t", "[", "expert", "]", ",", "axis", "=", "1", ")", "\n", "\n", "#print(1+'1')", "\n", "", "", "", "features_avgpool", "=", "{", "}", "\n", "agg", "=", "\"avg\"", "\n", "for", "expert", "in", "self", ".", "experts", ":", "\n", "          ", "if", "agg", "not", "in", "self", ".", "data_exp", "[", "expert", "]", ".", "keys", "(", ")", ":", "\n", "            ", "features_avgpool", "[", "expert", "]", "=", "None", "\n", "continue", "\n", "", "video_data", "=", "self", ".", "data_exp", "[", "expert", "]", "[", "agg", "]", "\n", "if", "vid", "in", "video_data", ".", "keys", ":", "\n", "            ", "x", "=", "video_data", "[", "vid", "]", "\n", "#if len(x) > 0 and not np.isnan(x[0][0]):", "\n", "if", "len", "(", "x", ")", ">", "0", "and", "not", "np", ".", "isnan", "(", "x", "[", "0", "]", ")", ":", "\n", "              ", "features_avgpool", "[", "expert", "]", "=", "x", "\n", "", "", "", "features_maxpool", "=", "{", "}", "\n", "agg", "=", "\"max\"", "\n", "for", "expert", "in", "self", ".", "experts", ":", "\n", "          ", "if", "agg", "not", "in", "self", ".", "data_exp", "[", "expert", "]", ".", "keys", "(", ")", ":", "\n", "            ", "features_maxpool", "[", "expert", "]", "=", "None", "\n", "continue", "\n", "", "video_data", "=", "self", ".", "data_exp", "[", "expert", "]", "[", "agg", "]", "\n", "if", "vid", "in", "video_data", ".", "keys", ":", "\n", "            ", "x", "=", "video_data", "[", "vid", "]", "\n", "#if len(x) > 0 and not np.isnan(x[0][0]):", "\n", "if", "len", "(", "x", ")", ">", "0", "and", "not", "np", ".", "isnan", "(", "x", "[", "0", "]", ")", ":", "\n", "              ", "features_maxpool", "[", "expert", "]", "=", "x", "\n", "", "", "", "return", "(", "raw_captions", ",", "raw_captions_t", ",", "features", ",", "features_t", ",", "\n", "features_avgpool", ",", "features_maxpool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.__len__": [[437, 439], ["None"], "methods", ["None"], ["", "dataset_file", "=", "h5py", ".", "File", "(", "dataset_file_path", ",", "\"r\"", ")", "\n", "with", "h5py", ".", "File", "(", "dataset_file_path", ",", "\"r\"", ")", "as", "dataset_file", ":", "\n", "          ", "video_data", "=", "dataset_file", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.__getitem__": [[440, 562], ["sample.update", "sample.update", "sample.update", "ValueError", "base_dataset.BaseDataset.trn_config.keys", "isinstance", "numpy.random.random", "ind.items", "numpy.multiply", "numpy.random.randint", "numpy.zeros", "enumerate", "base_dataset.BaseDataset.has_missing_values", "numpy.vstack", "numpy.random.choice", "numpy.random.random", "NotImplementedError", "len", "ValueError", "base_dataset.BaseDataset.raw_config.keys", "numpy.mean", "list", "numpy.random.choice", "numpy.random.choice", "numpy.array", "len", "numpy.zeros", "range", "numpy.sum", "len", "len", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.has_missing_values", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys"], ["keys_list", "=", "list", "(", "video_data", ".", "keys", "(", ")", ")", "\n", "nb_captions", "=", "len", "(", "\n", "[", "k", "for", "k", "in", "keys_list", "if", "k", ".", "startswith", "(", "\"raw_captions.\"", ")", "]", ")", "\n", "if", "nb_captions", "==", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "\"No caption for %s\"", ",", "dataset_file_path", ")", "\n", "", "assert", "nb_captions", ">", "0", "\n", "raw_captions", "=", "[", "]", "\n", "raw_captions_t", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nb_captions", ")", ":", "\n", "            ", "raw_caption", "=", "video_data", "[", "f\"raw_captions.{i}\"", "]", ".", "value", "\n", "raw_captions", ".", "append", "(", "raw_caption", ")", "\n", "if", "f\"raw_captions_t.{i}\"", "in", "video_data", ".", "keys", "(", ")", ":", "\n", "              ", "raw_caption_t", "=", "video_data", "[", "f\"raw_captions_t.{i}\"", "]", ".", "value", "\n", "if", "raw_caption_t", ".", "shape", "[", "0", "]", "!=", "len", "(", "raw_caption", ")", ":", "\n", "                ", "raw_caption_t", "=", "raw_caption_t", "[", ":", "len", "(", "raw_caption", ")", "]", "\n", "", "raw_captions_t", ".", "append", "(", "raw_caption_t", ")", "\n", "", "else", ":", "\n", "              ", "nb_words", "=", "len", "(", "raw_caption", ")", "\n", "raw_caption_t", "=", "np", ".", "zeros", "(", "(", "nb_words", ",", "2", ")", ")", "\n", "raw_captions_t", ".", "append", "(", "raw_caption_t", ")", "\n", "\n", "", "", "features", "=", "{", "}", "\n", "features_t", "=", "{", "}", "\n", "features_avgpool", "=", "{", "}", "\n", "features_maxpool", "=", "{", "}", "\n", "for", "expert", "in", "self", ".", "experts", ":", "\n", "            ", "if", "f\"features.{expert}\"", "in", "video_data", ".", "keys", "(", ")", ":", "\n", "              ", "x", "=", "video_data", "[", "f\"features.{expert}\"", "]", ".", "value", "\n", "if", "len", "(", "x", ")", ">", "0", "and", "not", "np", ".", "isnan", "(", "x", "[", "0", "]", "[", "0", "]", ")", ":", "\n", "                ", "features", "[", "expert", "]", "=", "video_data", "[", "f\"features.{expert}\"", "]", ".", "value", "\n", "\n", "if", "f\"features_t.{expert}\"", "in", "video_data", ".", "keys", "(", ")", ":", "\n", "                  ", "x", "=", "video_data", "[", "f\"features_t.{expert}\"", "]", ".", "value", "\n", "# if not np.isnan(x[0][0]):", "\n", "if", "expert", "in", "[", "\"s3d\"", ",", "\"vggish\"", ",", "\"vggsound\"", "]", ":", "\n", "                    ", "features_t", "[", "expert", "]", "=", "video_data", "[", "\n", "f\"features_t.{expert}\"", "]", ".", "value", "\n", "print", "(", "video_data", "[", "f\"features_t.{expert}\"", "]", ".", "value", ")", "\n", "if", "features_t", "[", "expert", "]", ".", "shape", "[", "0", "]", "!=", "features", "[", "expert", "]", ".", "shape", "[", "0", "]", ":", "\n", "                      ", "logger", ".", "warning", "(", "\n", "\"Incorrect number of features_t values \"", "\n", "\"for %s\"", ",", "dataset_file_path", ")", "\n", "features_t", "[", "expert", "]", "=", "features_t", "[", "expert", "]", "[", ":", "features", "[", "expert", "]", ".", "\n", "shape", "[", "0", "]", "]", "\n", "", "", "else", ":", "\n", "                    ", "nb_feats", "=", "features", "[", "expert", "]", ".", "shape", "[", "0", "]", "\n", "expert_timing", "=", "self", ".", "expert_timings", "[", "expert", "]", "\n", "features_t", "[", "expert", "]", "=", "self", ".", "get_feature_timings", "(", "\n", "nb_feats", ",", "**", "expert_timing", ")", "\n", "", "", "else", ":", "\n", "                  ", "nb_feats", "=", "features", "[", "expert", "]", ".", "shape", "[", "0", "]", "\n", "expert_timing", "=", "self", ".", "expert_timings", "[", "expert", "]", "\n", "features_t", "[", "expert", "]", "=", "self", ".", "get_feature_timings", "(", "\n", "nb_feats", ",", "**", "expert_timing", ")", "\n", "", "features_t", "[", "expert", "]", "=", "np", ".", "average", "(", "features_t", "[", "expert", "]", ",", "axis", "=", "1", ")", "\n", "", "", "features_avgpool", "[", "expert", "]", "=", "None", "\n", "features_maxpool", "[", "expert", "]", "=", "None", "\n", "", "", "return", "(", "raw_captions", ",", "raw_captions_t", ",", "features", ",", "features_t", ",", "\n", "features_avgpool", ",", "features_maxpool", ")", "\n", "\n", "", "", "elif", "self", ".", "reading_from", "==", "\"pkl\"", ":", "\n", "      ", "if", "self", ".", "loaded_in_ram", ":", "\n", "# Raw captions", "\n", "        ", "video_data", "=", "self", ".", "data_exp", "[", "\"raw_captions\"", "]", "\n", "if", "vid", "in", "video_data", ".", "keys", "(", ")", ":", "\n", "          ", "x", "=", "video_data", "[", "vid", "]", "\n", "nb_captions", "=", "len", "(", "x", ")", "\n", "assert", "nb_captions", ">", "0", "\n", "raw_captions", "=", "video_data", "[", "vid", "]", "\n", "raw_captions_t", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nb_captions", ")", ":", "\n", "            ", "raw_caption", "=", "raw_captions", "[", "i", "]", "\n", "nb_words", "=", "len", "(", "raw_caption", ")", "\n", "raw_caption_t", "=", "np", ".", "zeros", "(", "(", "nb_words", ",", "2", ")", ")", "\n", "raw_captions_t", ".", "append", "(", "raw_caption_t", ")", "\n", "\n", "# Video features", "\n", "", "", "features", "=", "{", "}", "\n", "features_t", "=", "{", "}", "\n", "for", "expert", "in", "self", ".", "experts", ":", "\n", "          ", "if", "\"fixed_seg\"", "not", "in", "self", ".", "data_exp", "[", "expert", "]", ".", "keys", "(", ")", ":", "\n", "            ", "continue", "\n", "", "video_data", "=", "self", ".", "data_exp", "[", "expert", "]", "[", "\"fixed_seg\"", "]", "\n", "\n", "if", "vid", "in", "video_data", ".", "keys", "(", ")", ":", "\n", "            ", "x", "=", "video_data", "[", "vid", "]", "\n", "if", "not", "isinstance", "(", "x", ",", "float", ")", "and", "not", "np", ".", "isnan", "(", "x", "[", "0", "]", "[", "0", "]", ")", ":", "\n", "              ", "features", "[", "expert", "]", "=", "x", "\n", "\n", "# Timings", "\n", "nb_feats", "=", "features", "[", "expert", "]", ".", "shape", "[", "0", "]", "\n", "if", "expert", "in", "self", ".", "expert_timings", ".", "keys", "(", ")", ":", "\n", "                ", "expert_timing", "=", "self", ".", "expert_timings", "[", "expert", "]", "\n", "", "else", ":", "\n", "                ", "expert_timing", "=", "{", "\"feat_width\"", ":", "1.0", "}", "\n", "", "features_t", "[", "expert", "]", "=", "self", ".", "get_feature_timings", "(", "\n", "nb_feats", ",", "**", "expert_timing", ")", "\n", "features_t", "[", "expert", "]", "=", "np", ".", "average", "(", "features_t", "[", "expert", "]", ",", "axis", "=", "1", ")", "\n", "\n", "#print(1+'1')", "\n", "", "", "", "features_avgpool", "=", "{", "}", "\n", "agg", "=", "\"avg\"", "\n", "for", "expert", "in", "self", ".", "experts", ":", "\n", "          ", "if", "agg", "not", "in", "self", ".", "data_exp", "[", "expert", "]", ".", "keys", "(", ")", ":", "\n", "            ", "features_avgpool", "[", "expert", "]", "=", "None", "\n", "continue", "\n", "", "video_data", "=", "self", ".", "data_exp", "[", "expert", "]", "[", "agg", "]", "\n", "if", "vid", "in", "video_data", ".", "keys", ":", "\n", "            ", "x", "=", "video_data", "[", "vid", "]", "\n", "#if len(x) > 0 and not np.isnan(x[0][0]):", "\n", "if", "len", "(", "x", ")", ">", "0", "and", "not", "np", ".", "isnan", "(", "x", "[", "0", "]", ")", ":", "\n", "              ", "features_avgpool", "[", "expert", "]", "=", "x", "\n", "", "", "", "features_maxpool", "=", "{", "}", "\n", "agg", "=", "\"max\"", "\n", "for", "expert", "in", "self", ".", "experts", ":", "\n", "          ", "if", "agg", "not", "in", "self", ".", "data_exp", "[", "expert", "]", ".", "keys", "(", ")", ":", "\n", "            ", "features_maxpool", "[", "expert", "]", "=", "None", "\n", "continue", "\n", "", "video_data", "=", "self", ".", "data_exp", "[", "expert", "]", "[", "agg", "]", "\n", "if", "vid", "in", "video_data", ".", "keys", ":", "\n", "            ", "x", "=", "video_data", "[", "vid", "]", "\n", "#if len(x) > 0 and not np.isnan(x[0][0]):", "\n", "if", "len", "(", "x", ")", ">", "0", "and", "not", "np", ".", "isnan", "(", "x", "[", "0", "]", ")", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.is_end_of_sentence": [[35, 40], ["None"], "function", ["None"], ["def", "is_end_of_sentence", "(", "word", ")", ":", "\n", "  ", "if", "word", "[", "-", "1", "]", "in", "[", "\".\"", ",", "\"?\"", ",", "\"!\"", "]", ":", "\n", "    ", "return", "True", "\n", "", "else", ":", "\n", "    ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.is_stop_word": [[42, 52], ["base_dataset.get_clean_word", "get_clean_word.split", "get_clean_word.isalnum"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.get_clean_word"], ["", "", "def", "is_stop_word", "(", "word", ")", ":", "\n", "  ", "word_pure", "=", "get_clean_word", "(", "word", ")", "\n", "if", "word_pure", "in", "stop_words", ".", "ENGLISH_STOP_WORDS", ":", "\n", "    ", "return", "True", "\n", "", "if", "not", "word_pure", ".", "isalnum", "(", ")", ":", "\n", "    ", "return", "True", "\n", "", "for", "word_piece", "in", "word_pure", ".", "split", "(", "\"\\'\"", ")", ":", "\n", "    ", "if", "word_piece", "in", "stop_words", ".", "ENGLISH_STOP_WORDS", ":", "\n", "      ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.get_clean_word": [[54, 61], ["word_pure.replace.lower", "word_pure.replace.replace"], "function", ["None"], ["", "def", "get_clean_word", "(", "word", ")", ":", "\n", "# Remove invalid characters from word", "\n", "  ", "word_pure", "=", "word", "\n", "invalid_char", "=", "[", "\".\"", ",", "\",\"", ",", "\"?\"", ",", "\"!\"", "]", "\n", "for", "char", "in", "invalid_char", ":", "\n", "    ", "word_pure", "=", "word_pure", ".", "replace", "(", "char", ",", "\"\"", ")", "\n", "", "return", "word_pure", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.crop_or_pad_to_len": [[63, 69], ["numpy.zeros", "min", "len"], "function", ["None"], ["", "def", "crop_or_pad_to_len", "(", "token_ids", ",", "max_text_words", ")", ":", "\n", "  ", "token_ids_tensor", "=", "np", ".", "zeros", "(", "(", "max_text_words", ",", "2", ")", ")", "\n", "keep", "=", "min", "(", "len", "(", "token_ids", ")", ",", "max_text_words", ")", "\n", "token_ids_tensor", "[", ":", "keep", ",", "0", "]", "=", "token_ids", "[", ":", "keep", "]", "\n", "token_ids_tensor", "[", ":", "keep", ",", "1", "]", "=", "1", "\n", "return", "token_ids_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.choose_or_pad_to_len": [[71, 116], ["numpy.zeros", "numpy.ones", "numpy.zeros", "min", "numpy.sort", "len", "numpy.random.choice", "numpy.random.RandomState", "np.random.RandomState.choice", "numpy.random.RandomState", "np.random.RandomState.shuffle", "len", "len"], "function", ["None"], ["", "def", "choose_or_pad_to_len", "(", "features", ",", "\n", "features_t", ",", "\n", "max_tokens", ",", "\n", "training", ",", "\n", "shuffle", "=", "False", ",", "\n", "seed", "=", "0", ")", ":", "\n", "  ", "\"\"\"Outputs a fixed length sequence of features from a variable length input.\n\n  Performs a selection if there are too many input features.\n  Pads the sequence if there are too few features.\n\n  Args:\n    features: Input features.\n    features_t: Input features timestamps.\n    max_tokens: Length of the output sequence.\n    training: If True, the features will be deterministically sampled.\n    shuffle: If True, the features are shuffled.\n    seed: Seed used for the random shuffling.\n\n  Returns:\n    Fixed length sequence of features.\n  \"\"\"", "\n", "feature_dim", "=", "features", ".", "shape", "[", "-", "1", "]", "\n", "tensor", "=", "np", ".", "zeros", "(", "(", "max_tokens", ",", "feature_dim", ")", ")", "\n", "tensor_t", "=", "np", ".", "ones", "(", "(", "max_tokens", ")", ")", "\n", "tensor_ind", "=", "np", ".", "zeros", "(", "(", "max_tokens", ")", ")", "\n", "keep", "=", "min", "(", "len", "(", "features", ")", ",", "max_tokens", ")", "\n", "if", "training", ":", "\n", "# If training, we randomly pick features", "\n", "    ", "pick", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "features", ")", ",", "size", "=", "keep", ",", "replace", "=", "False", ")", "\n", "", "else", ":", "\n", "# If not training, the choice of features is deterministic", "\n", "    ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "pick", "=", "rng", ".", "choice", "(", "len", "(", "features", ")", ",", "size", "=", "keep", ",", "replace", "=", "False", ")", "\n", "", "pick", "=", "np", ".", "sort", "(", "pick", ")", "\n", "tensor", "[", ":", "keep", ",", ":", "]", "=", "features", "[", "pick", "]", "\n", "if", "shuffle", "and", "training", ":", "\n", "# Shuffle temporal encoding so that the model cannot use temporal", "\n", "# information.", "\n", "    ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "tensor_t", "[", ":", "keep", "]", "=", "rng", ".", "shuffle", "(", "features_t", "[", "pick", "]", ")", "\n", "", "else", ":", "\n", "    ", "tensor_t", "[", ":", "keep", "]", "=", "features_t", "[", "pick", "]", "\n", "", "tensor_ind", "[", ":", "keep", "]", "=", "1", "\n", "return", "tensor", ",", "tensor_t", ",", "tensor_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.remove_caption_stop_words": [[118, 131], ["enumerate", "len", "res.append", "res_t.append", "base_dataset.is_stop_word", "res.append", "res_t.append", "numpy.array", "base_dataset.get_clean_word"], "function", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.is_stop_word", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.get_clean_word"], ["", "def", "remove_caption_stop_words", "(", "cap", ",", "cap_t", ")", ":", "\n", "  ", "\"\"\"Removes the stop words from a caption.\"\"\"", "\n", "res", "=", "[", "]", "\n", "res_t", "=", "[", "]", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "cap", ")", ":", "\n", "    ", "word_t", "=", "cap_t", "[", "i", "]", "\n", "if", "not", "is_stop_word", "(", "word", ")", ":", "\n", "      ", "res", ".", "append", "(", "get_clean_word", "(", "word", ")", ")", "\n", "res_t", ".", "append", "(", "word_t", ")", "\n", "", "", "if", "len", "(", "res", ")", "<", "1", ":", "\n", "    ", "res", ".", "append", "(", "\".\"", ")", "\n", "res_t", ".", "append", "(", "np", ".", "array", "(", "[", "0.", ",", "0.", "]", ")", ")", "\n", "", "return", "res", ",", "res_t", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer.__init__": [[17, 68], ["config.get_logger", "base_trainer.BaseTrainer._prepare_device", "model.to", "cfg_trainer.get", "cfg_trainer.get", "config[].get", "len", "torch.nn.DataParallel", "base_trainer.BaseTrainer.monitor.split", "cfg_trainer.get", "logger.TensorboardWriter", "base_trainer.BaseTrainer._resume_checkpoint"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.get_logger", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._prepare_device", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._resume_checkpoint"], ["\n", "import", "abc", "\n", "import", "collections", "\n", "import", "json", "\n", "import", "logging", "\n", "import", "os", "\n", "import", "re", "\n", "import", "time", "\n", "\n", "from", "numpy", "import", "inf", "\n", "from", "tensorboardX", "import", "SummaryWriter", "\n", "import", "torch", "\n", "from", "utils", ".", "perf_log_utils", "import", "update_perf_log", "\n", "from", "utils", ".", "timing_utils", "import", "AverageMeter", "\n", "from", "utils", ".", "util", "import", "get_hparams_from_config", "\n", "from", "utils", ".", "util", "import", "get_last_checkpoint_path", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "class", "BaseTrainer", ":", "\n", "  ", "\"\"\"Base class for all trainers.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "model", ",", "loss", ",", "metrics", ",", "optimizer", ",", "lr_scheduler", ",", "config", ")", ":", "\n", "    ", "self", ".", "config", "=", "config", "\n", "self", ".", "hparams", "=", "get_hparams_from_config", "(", "self", ".", "config", ")", "\n", "\n", "# setup GPU device if available, move model into configured device", "\n", "self", ".", "device", ",", "device_ids", "=", "self", ".", "_prepare_device", "(", "config", "[", "'n_gpu'", "]", ")", "\n", "self", ".", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "len", "(", "device_ids", ")", ">", "1", ":", "\n", "      ", "self", ".", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "device_ids", ")", "\n", "\n", "", "self", ".", "loss", "=", "loss", "\n", "self", ".", "metrics", "=", "metrics", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "lr_scheduler", "=", "lr_scheduler", "\n", "\n", "self", ".", "exp_dir", "=", "config", ".", "save_dir", "\n", "self", ".", "checkpoint_dir", "=", "config", ".", "save_dir", "\n", "self", ".", "perf_log_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "save_dir", ",", "'perf_log.txt'", ")", "\n", "self", ".", "info_checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "save_dir", ",", "\n", "'info_checkpoint.txt'", ")", "\n", "self", ".", "monitoring_path", "=", "os", ".", "path", ".", "join", "(", "config", ".", "save_dir", ",", "'monitoring.json'", ")", "\n", "\n", "cfg_trainer", "=", "config", "[", "'trainer'", "]", "\n", "self", ".", "epochs", "=", "cfg_trainer", "[", "'epochs'", "]", "\n", "self", ".", "save_period", "=", "cfg_trainer", "[", "'save_period'", "]", "\n", "self", ".", "monitor", "=", "cfg_trainer", ".", "get", "(", "'monitor'", ",", "'off'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._train_epoch": [[69, 76], ["None"], "methods", ["None"], ["self", ".", "timer", "=", "AverageMeter", "(", ")", "\n", "\n", "# configuration to monitor model performance and save best", "\n", "if", "self", ".", "monitor", "==", "'off'", ":", "\n", "      ", "self", ".", "mnt_mode", "=", "'off'", "\n", "self", ".", "mnt_best", "=", "0", "\n", "", "elif", "self", ".", "monitor", ".", "startswith", "(", "'given_epoch'", ")", ":", "\n", "      ", "self", ".", "mnt_mode", ",", "self", ".", "given_epoch", "=", "self", ".", "monitor", ".", "split", "(", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._valid_epoch": [[106, 110], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "_valid_epoch", "(", "self", ",", "epoch", ",", "sets", ")", ":", "\n", "    ", "\"\"\"Validation logic for an epoch.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer.train": [[77, 192], ["range", "base_trainer.BaseTrainer._train_epoch", "result.items", "log.items", "base_trainer.BaseTrainer.logger.info", "base_trainer.BaseTrainer.logger.info", "base_trainer.BaseTrainer._save_checkpoint", "print", "base_trainer.BaseTrainer.purge_stale_checkpoints", "log.update", "copy.deepcopy().cpu", "base_trainer.BaseTrainer.logger.info", "print", "base_trainer.BaseTrainer._save_checkpoint", "cached_preds.items", "log.update", "str", "base_trainer.BaseTrainer.logger.warning", "ValueError", "pathlib.Path", "numpy.save", "numpy.save", "base_trainer.BaseTrainer.logger.info", "base_trainer.BaseTrainer.logger.info", "value.items", "msg.format", "copy.deepcopy", "cached[].cpu().numpy", "numpy.argsort", "open", "range", "open", "pickle.dump", "enumerate", "subval.items", "str", "print", "vid_names.append", "enumerate", "cached[].cpu", "str", "str", "vid_name[].split"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._train_epoch", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._save_checkpoint", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer.purge_stale_checkpoints", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._save_checkpoint", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.model.metric.AverageMeter.update", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.save", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.save", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["assert", "self", ".", "mnt_mode", "in", "[", "'given_epoch'", "]", "\n", "self", ".", "mnt_best", "=", "0", "\n", "self", ".", "given_epoch", "=", "int", "(", "self", ".", "given_epoch", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "mnt_mode", ",", "self", ".", "mnt_metric", "=", "self", ".", "monitor", ".", "split", "(", ")", "\n", "assert", "self", ".", "mnt_mode", "in", "[", "'min'", ",", "'max'", "]", "\n", "\n", "self", ".", "mnt_best", "=", "inf", "if", "self", ".", "mnt_mode", "==", "'min'", "else", "-", "inf", "\n", "\n", "self", ".", "early_stop", "=", "cfg_trainer", ".", "get", "(", "'early_stop'", ",", "inf", ")", "\n", "\n", "", "self", ".", "start_epoch", "=", "0", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "n_samples", "=", "0", "\n", "self", ".", "n_steps", "=", "0", "\n", "\n", "self", ".", "writer", "=", "SummaryWriter", "(", "config", ".", "log_dir", ")", "\n", "\n", "self", ".", "include_optim_in_ckpts", "=", "config", "[", "'trainer'", "]", ".", "get", "(", "\n", "'include_optim_in_ckpts'", ",", "False", ")", "\n", "\n", "if", "config", ".", "resume", "is", "not", "None", ":", "\n", "      ", "self", ".", "_resume_checkpoint", "(", "config", ".", "resume", ")", "\n", "\n", "", "", "@", "abc", ".", "abstractmethod", "\n", "def", "_train_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "    ", "\"\"\"Training logic for an epoch.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "@", "abc", ".", "abstractmethod", "\n", "def", "_valid_epoch", "(", "self", ",", "epoch", ",", "sets", ")", ":", "\n", "    ", "\"\"\"Validation logic for an epoch.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "train", "(", "self", ")", ":", "\n", "    ", "\"\"\"Full training logic.\"\"\"", "\n", "not_improved_count", "=", "0", "\n", "for", "epoch", "in", "range", "(", "self", ".", "start_epoch", ",", "self", ".", "epochs", "+", "1", ")", ":", "\n", "\n", "      ", "self", ".", "epoch", "=", "epoch", "\n", "epoch_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "logger", ".", "debug", "(", "'Starting training epoch %s ...'", ",", "str", "(", "epoch", ")", ")", "\n", "train_start", "=", "time", ".", "time", "(", ")", "\n", "result", "=", "self", ".", "_train_epoch", "(", "epoch", ")", "\n", "for", "key", ",", "val", "in", "result", ".", "items", "(", ")", ":", "\n", "        ", "self", ".", "writer", ".", "add_scalar", "(", "f'{key}'", ",", "val", ",", "epoch", ")", "\n", "", "self", ".", "timer", ".", "update", "(", "'epoch.train'", ",", "time", ".", "time", "(", ")", "-", "train_start", ")", "\n", "\n", "logger", ".", "debug", "(", "'Starting evaluating epoch %s ...'", ",", "str", "(", "epoch", ")", ")", "\n", "valid_start", "=", "time", ".", "time", "(", ")", "\n", "val_log", "=", "self", ".", "_valid_epoch", "(", "epoch", ",", "sets", "=", "'continuous_eval'", ")", "\n", "logger", ".", "debug", "(", "'Updating val log with results ...'", ")", "\n", "result", ".", "update", "(", "val_log", ")", "\n", "self", ".", "timer", ".", "update", "(", "'epoch.valid'", ",", "time", ".", "time", "(", ")", "-", "valid_start", ")", "\n", "\n", "checkpoint_start", "=", "time", ".", "time", "(", ")", "\n", "# save logged informations into log dict", "\n", "log", "=", "{", "'epoch'", ":", "epoch", "}", "\n", "for", "key", ",", "value", "in", "result", ".", "items", "(", ")", ":", "\n", "# Metrics recorded during the continuous eval", "\n", "        ", "if", "key", "==", "'metrics'", ":", "\n", "          ", "for", "dataset_name", ",", "dataset_metrics", "in", "value", ".", "items", "(", ")", ":", "\n", "            ", "for", "metric_type", ",", "metric_dict", "in", "dataset_metrics", ".", "items", "(", ")", ":", "\n", "              ", "for", "metric_name", ",", "metric_value", "in", "metric_dict", ".", "items", "(", ")", ":", "\n", "                ", "log", "[", "f'{dataset_name}/{metric_type}'", "\n", "f'/{metric_name}'", "]", "=", "metric_value", "\n", "", "", "", "", "else", ":", "\n", "          ", "log", "[", "key", "]", "=", "value", "\n", "\n", "# eval model according to configured metric, save best # ckpt as", "\n", "# trained_model.", "\n", "", "", "best", "=", "False", "\n", "if", "self", ".", "mnt_mode", "in", "[", "'min'", ",", "'max'", "]", ":", "\n", "        ", "try", ":", "\n", "# check whether specified metric improved or not, according to", "\n", "# specified metric(mnt_metric)", "\n", "          ", "lower", "=", "log", "[", "self", ".", "mnt_metric", "]", "<=", "self", ".", "mnt_best", "\n", "higher", "=", "log", "[", "self", ".", "mnt_metric", "]", ">=", "self", ".", "mnt_best", "\n", "improved", "=", "(", "self", ".", "mnt_mode", "==", "'min'", "and", "lower", ")", "or", "(", "self", ".", "mnt_mode", "==", "'max'", "and", "higher", ")", "\n", "", "except", "KeyError", ":", "\n", "          ", "logger", ".", "warning", "(", "\n", "'Warning: Metric %s not found, '", "\n", "'perf monitoring is disabled.'", ",", "self", ".", "mnt_metric", ")", "\n", "self", ".", "mnt_mode", "=", "'off'", "\n", "improved", "=", "False", "\n", "not_improved_count", "=", "0", "\n", "\n", "", "if", "improved", ":", "\n", "          ", "self", ".", "mnt_best", "=", "log", "[", "self", ".", "mnt_metric", "]", "\n", "not_improved_count", "=", "0", "\n", "best", "=", "True", "\n", "", "else", ":", "\n", "          ", "not_improved_count", "+=", "1", "\n", "\n", "", "if", "not_improved_count", ">", "self", ".", "early_stop", ":", "\n", "          ", "logger", ".", "info", "(", "\n", "'Val performance didn\\'t improve for %s epochs. '", "\n", "'Training stops.'", ",", "self", ".", "early_stop", ")", "\n", "break", "\n", "\n", "# If checkpointing is done intermittently, still save models that", "\n", "# outperform the best metric.", "\n", "", "", "save_best", "=", "best", "and", "self", ".", "mnt_metric", "!=", "'epoch'", "\n", "\n", "if", "self", ".", "mnt_mode", "in", "[", "'given_epoch'", "]", "and", "epoch", "==", "self", ".", "given_epoch", ":", "\n", "        ", "save_best", "=", "True", "\n", "\n", "# Due to the fast runtime/slow HDD combination, checkpointing can dominate", "\n", "# the total training time, so we optionally skip checkpoints for some of", "\n", "# the first epochs", "\n", "", "if", "epoch", "<", "self", ".", "skip_first_n_saves", ":", "\n", "        ", "msg", "=", "f'Skipping ckpt save at epoch {epoch} < {self.skip_first_n_saves}'", "\n", "logger", ".", "info", "(", "msg", ")", "\n", "", "elif", "epoch", "%", "self", ".", "save_period", "==", "0", "or", "save_best", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer.evaluate": [[244, 298], ["os.path.exists", "base_trainer.BaseTrainer._valid_epoch", "nested_metrics.items", "log.items", "os.path.join", "os.path.exists", "logger.info", "os.path.join", "base_trainer.BaseTrainer._resume_checkpoint", "logger.info", "dataset_metrics.items", "logger.info", "metric_dict.items", "collections.OrderedDict", "json.load.keys", "open", "json.dump", "open", "os.utime", "metric_dict.items", "open", "json.load", "logger.debug", "logger.info", "str", "str"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._valid_epoch", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._resume_checkpoint", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.keys", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "    ", "\"\"\"Final evaluation.\"\"\"", "\n", "sets", "=", "'final_eval'", "\n", "ckpt_path", "=", "self", ".", "config", ".", "save_dir", "/", "'trained_model.pth'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "ckpt_path", ")", ":", "\n", "      ", "self", ".", "_resume_checkpoint", "(", "ckpt_path", ")", "\n", "", "else", ":", "\n", "      ", "msg", "=", "(", "f'The checkpoint {ckpt_path} does not exist and cannot be loaded. '", "\n", "f'The model will not be resumed to that checkpoint.'", ")", "\n", "logger", ".", "info", "(", "msg", ")", "\n", "\n", "", "final_result", "=", "self", ".", "_valid_epoch", "(", "epoch", "=", "self", ".", "epoch", ",", "sets", "=", "sets", ")", "\n", "nested_metrics", "=", "final_result", "[", "'metrics'", "]", "\n", "\n", "log", "=", "{", "}", "\n", "for", "dataset_name", ",", "dataset_metrics", "in", "nested_metrics", ".", "items", "(", ")", ":", "\n", "      ", "log", "[", "dataset_name", "]", "=", "{", "}", "\n", "for", "metric_type", ",", "metric_dict", "in", "dataset_metrics", ".", "items", "(", ")", ":", "\n", "        ", "for", "metric_name", ",", "metric_value", "in", "metric_dict", ".", "items", "(", ")", ":", "\n", "          ", "log", "[", "dataset_name", "]", "[", "\n", "f'{metric_type}/{metric_name}/{sets}'", "]", "=", "metric_value", "\n", "\n", "# Print results", "\n", "", "", "", "for", "dataset_name", ",", "metric_dict", "in", "log", ".", "items", "(", ")", ":", "\n", "      ", "logger", ".", "info", "(", "'%s:'", ",", "dataset_name", ")", "\n", "for", "metric_name", ",", "metric_value", "in", "metric_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "'/cols'", "in", "metric_name", ":", "\n", "          ", "continue", "\n", "", "if", "'timer.'", "in", "metric_name", ":", "\n", "          ", "logger", ".", "debug", "(", "' {:15s}: {}'", ".", "format", "(", "str", "(", "metric_name", ")", ",", "metric_value", ")", ")", "\n", "", "else", ":", "\n", "          ", "logger", ".", "info", "(", "' {:15s}: {}'", ".", "format", "(", "str", "(", "metric_name", ")", ",", "metric_value", ")", ")", "\n", "\n", "# Logging dataset perfs", "\n", "", "", "", "save_dir", "=", "self", ".", "config", ".", "save_dir", "\n", "results_on_datasets_log_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'exp_results.json'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "results_on_datasets_log_path", ")", ":", "\n", "      ", "with", "open", "(", "results_on_datasets_log_path", ")", "as", "json_file", ":", "\n", "        ", "res", "=", "json", ".", "load", "(", "json_file", ")", "\n", "", "", "else", ":", "\n", "      ", "res", "=", "collections", ".", "OrderedDict", "(", "{", "}", ")", "\n", "", "if", "'perfs'", "not", "in", "res", ".", "keys", "(", ")", ":", "\n", "      ", "res", "[", "'perfs'", "]", "=", "{", "}", "\n", "", "res", "[", "'perfs'", "]", "=", "log", "\n", "res", "[", "'checkpoint_epoch'", "]", "=", "self", ".", "loaded_epoch", "\n", "logger", ".", "info", "(", "'Best epoch for the monitored metric: %s'", ",", "self", ".", "loaded_epoch", ")", "\n", "with", "open", "(", "results_on_datasets_log_path", ",", "'w'", ")", "as", "fp", ":", "\n", "      ", "json", ".", "dump", "(", "res", ",", "fp", ",", "indent", "=", "4", ")", "\n", "\n", "", "exp_completed_flag_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'exp_completed_flag.txt'", ")", "\n", "# Touch the exp_completed_flag_path to mark that the experiment is completed", "\n", "with", "open", "(", "exp_completed_flag_path", ",", "'a'", ")", ":", "\n", "      ", "os", ".", "utime", "(", "exp_completed_flag_path", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer.purge_stale_checkpoints": [[193, 219], ["list", "list", "sorted", "base_trainer.BaseTrainer.checkpoint_dir.glob", "base_trainer.BaseTrainer.checkpoint_dir.glob", "len", "print", "int", "list", "time.time", "stale_ckpt.unlink", "base_trainer.BaseTrainer.logger.info", "len", "len", "zip", "re.search().groups", "time.time", "re.search", "str"], "methods", ["None"], ["        ", "self", ".", "_save_checkpoint", "(", "epoch", ",", "save_best", "=", "best", ")", "\n", "\n", "", "if", "epoch", ">", "self", ".", "num_keep_ckpts", ":", "\n", "        ", "self", ".", "purge_stale_checkpoints", "(", ")", "\n", "", "self", ".", "timer", ".", "update", "(", "'epoch.checkpoint'", ",", "time", ".", "time", "(", ")", "-", "checkpoint_start", ")", "\n", "\n", "self", ".", "timer", ".", "update", "(", "'epoch.total'", ",", "time", ".", "time", "(", ")", "-", "epoch_start", ")", "\n", "for", "key", ",", "val", "in", "self", ".", "timer", ".", "dic", ".", "items", "(", ")", ":", "\n", "        ", "for", "metric", "in", "[", "'avg'", ",", "'sum'", "]", ":", "\n", "          ", "log", "[", "f'timer.{key}.{metric}'", "]", "=", "self", ".", "timer", ".", "dic", "[", "key", "]", "[", "metric", "]", "\n", "", "self", ".", "writer", ".", "add_scalar", "(", "f'timer_epoch/{key}'", ",", "self", ".", "timer", ".", "dic", "[", "key", "]", "[", "'sum'", "]", ",", "\n", "epoch", ")", "\n", "", "self", ".", "writer", ".", "add_text", "(", "'exp_dir'", ",", "str", "(", "self", ".", "exp_dir", ")", ",", "epoch", ")", "\n", "self", ".", "timer", ".", "reset", "(", ")", "\n", "\n", "log", "[", "'mnt_best'", "]", "=", "self", ".", "mnt_best", "\n", "log", "[", "'not_improved_count'", "]", "=", "not_improved_count", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'mnt_best'", ",", "self", ".", "mnt_best", ",", "epoch", ")", "\n", "\n", "# print results", "\n", "for", "metric_name", ",", "metric_value", "in", "log", ".", "items", "(", ")", ":", "\n", "        ", "if", "'/cols'", "in", "metric_name", ":", "\n", "          ", "continue", "\n", "", "if", "'timer.'", "in", "metric_name", ":", "\n", "          ", "logger", ".", "debug", "(", "' {:15s}: {}'", ".", "format", "(", "str", "(", "metric_name", ")", ",", "metric_value", ")", ")", "\n", "", "else", ":", "\n", "          ", "logger", ".", "info", "(", "' {:15s}: {}'", ".", "format", "(", "str", "(", "metric_name", ")", ",", "metric_value", ")", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._prepare_device": [[220, 237], ["torch.cuda.device_count", "torch.device", "list", "base_trainer.BaseTrainer.logger.warning", "base_trainer.BaseTrainer.logger.warning", "range"], "methods", ["None"], ["\n", "# Save main results in the perf log", "\n", "", "", "log_light", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "log", ".", "items", "(", ")", ":", "\n", "        ", "if", "not", "key", ".", "endswith", "(", "'cols'", ")", ":", "\n", "          ", "log_light", "[", "key", "]", "=", "value", "\n", "", "", "update_perf_log", "(", "log_light", ",", "self", ".", "perf_log_path", ")", "\n", "\n", "# Log results to Tensorboard", "\n", "self", ".", "writer", ".", "add_hparams", "(", "self", ".", "hparams", ",", "{", "\n", "'hparam/accuracy'", ":", "log", "[", "self", ".", "mnt_metric", "]", ",", "\n", "'hparam/mnt_best'", ":", "self", ".", "mnt_best", ",", "\n", "'hparam/epoch'", ":", "epoch", "\n", "}", ",", "\n", "name", "=", "'hparams'", ")", "\n", "\n", "# # Ray-tune recording", "\n", "# try:", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._save_checkpoint": [[238, 267], ["str", "time.time", "base_trainer.BaseTrainer.logger.info", "torch.save", "base_trainer.BaseTrainer.logger.info", "type", "base_trainer.BaseTrainer.model.state_dict", "base_trainer.BaseTrainer.optimizer.state_dict", "base_trainer.BaseTrainer.logger.info", "str", "torch.save", "base_trainer.BaseTrainer.logger.info", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.save", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.html_utils.HTML.save"], ["#   from ray.tune import track", "\n", "#   acc = log[self.mnt_metric]", "\n", "#   track.log(mean_accuracy=acc, exp_dir=self.exp_dir, **log_light)", "\n", "# except Exception as e:", "\n", "#   print(e)", "\n", "\n", "", "", "def", "evaluate", "(", "self", ")", ":", "\n", "    ", "\"\"\"Final evaluation.\"\"\"", "\n", "sets", "=", "'final_eval'", "\n", "ckpt_path", "=", "self", ".", "config", ".", "save_dir", "/", "'trained_model.pth'", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "ckpt_path", ")", ":", "\n", "      ", "self", ".", "_resume_checkpoint", "(", "ckpt_path", ")", "\n", "", "else", ":", "\n", "      ", "msg", "=", "(", "f'The checkpoint {ckpt_path} does not exist and cannot be loaded. '", "\n", "f'The model will not be resumed to that checkpoint.'", ")", "\n", "logger", ".", "info", "(", "msg", ")", "\n", "\n", "", "final_result", "=", "self", ".", "_valid_epoch", "(", "epoch", "=", "self", ".", "epoch", ",", "sets", "=", "sets", ")", "\n", "nested_metrics", "=", "final_result", "[", "'metrics'", "]", "\n", "\n", "log", "=", "{", "}", "\n", "for", "dataset_name", ",", "dataset_metrics", "in", "nested_metrics", ".", "items", "(", ")", ":", "\n", "      ", "log", "[", "dataset_name", "]", "=", "{", "}", "\n", "for", "metric_type", ",", "metric_dict", "in", "dataset_metrics", ".", "items", "(", ")", ":", "\n", "        ", "for", "metric_name", ",", "metric_value", "in", "metric_dict", ".", "items", "(", ")", ":", "\n", "          ", "log", "[", "dataset_name", "]", "[", "\n", "f'{metric_type}/{metric_name}/{sets}'", "]", "=", "metric_value", "\n", "\n", "# Print results", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._resume_last_checkpoint": [[387, 390], ["utils.util.get_last_checkpoint_path", "base_trainer.BaseTrainer._resume_checkpoint"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.get_last_checkpoint_path", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._resume_checkpoint"], ["", "", "def", "_resume_last_checkpoint", "(", "self", ")", ":", "\n", "    ", "checkpoint_path", "=", "get_last_checkpoint_path", "(", "self", ".", "exp_dir", ")", "\n", "self", ".", "_resume_checkpoint", "(", "checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer.match_checkpoint_to_model": [[391, 407], ["list", "torch.cat", "logger.warning", "torch.zeros"], "methods", ["None"], ["", "def", "match_checkpoint_to_model", "(", "self", ",", "checkpoint", ",", "model", ")", ":", "\n", "    ", "\"\"\"Adapt the loaded checkpoint so that is fits the current architecture.\"\"\"", "\n", "\n", "modules", "=", "[", "'vid_bert.embeddings.position_embeddings.weight'", "]", "\n", "\n", "for", "module", "in", "modules", ":", "\n", "      ", "if", "module", "in", "model", "and", "checkpoint", "[", "module", "]", ".", "shape", "!=", "model", "[", "module", "]", ".", "shape", ":", "\n", "        ", "padding", "=", "model", "[", "module", "]", ".", "shape", "[", "0", "]", "-", "checkpoint", "[", "module", "]", ".", "shape", "[", "0", "]", "\n", "padding_shape", "=", "list", "(", "model", "[", "module", "]", ".", "shape", ")", "\n", "padding_shape", "[", "0", "]", "=", "padding", "\n", "device", "=", "checkpoint", "[", "module", "]", ".", "device", "\n", "checkpoint", "[", "module", "]", "=", "torch", ".", "cat", "(", "\n", "[", "checkpoint", "[", "module", "]", ",", "\n", "torch", ".", "zeros", "(", "padding_shape", ",", "device", "=", "device", ")", "]", ",", "0", ")", "\n", "logger", ".", "warning", "(", "'Size mismatch for module %s fixed by zero padding'", ",", "\n", "module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_trainer.BaseTrainer._resume_checkpoint": [[268, 302], ["str", "base_trainer.BaseTrainer.logger.info", "torch.load", "base_trainer.BaseTrainer.model.load_state_dict", "base_trainer.BaseTrainer.logger.info", "base_trainer.BaseTrainer.logger.warning", "base_trainer.BaseTrainer.logger.warning", "base_trainer.BaseTrainer.optimizer.load_state_dict"], "methods", ["None"], ["", "", "", "for", "dataset_name", ",", "metric_dict", "in", "log", ".", "items", "(", ")", ":", "\n", "      ", "logger", ".", "info", "(", "'%s:'", ",", "dataset_name", ")", "\n", "for", "metric_name", ",", "metric_value", "in", "metric_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "'/cols'", "in", "metric_name", ":", "\n", "          ", "continue", "\n", "", "if", "'timer.'", "in", "metric_name", ":", "\n", "          ", "logger", ".", "debug", "(", "' {:15s}: {}'", ".", "format", "(", "str", "(", "metric_name", ")", ",", "metric_value", ")", ")", "\n", "", "else", ":", "\n", "          ", "logger", ".", "info", "(", "' {:15s}: {}'", ".", "format", "(", "str", "(", "metric_name", ")", ",", "metric_value", ")", ")", "\n", "\n", "# Logging dataset perfs", "\n", "", "", "", "save_dir", "=", "self", ".", "config", ".", "save_dir", "\n", "results_on_datasets_log_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'exp_results.json'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "results_on_datasets_log_path", ")", ":", "\n", "      ", "with", "open", "(", "results_on_datasets_log_path", ")", "as", "json_file", ":", "\n", "        ", "res", "=", "json", ".", "load", "(", "json_file", ")", "\n", "", "", "else", ":", "\n", "      ", "res", "=", "collections", ".", "OrderedDict", "(", "{", "}", ")", "\n", "", "if", "'perfs'", "not", "in", "res", ".", "keys", "(", ")", ":", "\n", "      ", "res", "[", "'perfs'", "]", "=", "{", "}", "\n", "", "res", "[", "'perfs'", "]", "=", "log", "\n", "res", "[", "'checkpoint_epoch'", "]", "=", "self", ".", "loaded_epoch", "\n", "logger", ".", "info", "(", "'Best epoch for the monitored metric: %s'", ",", "self", ".", "loaded_epoch", ")", "\n", "with", "open", "(", "results_on_datasets_log_path", ",", "'w'", ")", "as", "fp", ":", "\n", "      ", "json", ".", "dump", "(", "res", ",", "fp", ",", "indent", "=", "4", ")", "\n", "\n", "", "exp_completed_flag_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'exp_completed_flag.txt'", ")", "\n", "# Touch the exp_completed_flag_path to mark that the experiment is completed", "\n", "with", "open", "(", "exp_completed_flag_path", ",", "'a'", ")", ":", "\n", "      ", "os", ".", "utime", "(", "exp_completed_flag_path", ",", "None", ")", "\n", "\n", "", "", "def", "purge_stale_checkpoints", "(", "self", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__": [[25, 49], ["len", "base_data_loader.BaseDataLoader._split_sampler", "torch.utils.data.DataLoader.__init__"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader._split_sampler", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.__init__"], ["def", "__init__", "(", "self", ",", "\n", "dataset", ",", "\n", "batch_size", ",", "\n", "shuffle", ",", "\n", "validation_split", ",", "\n", "num_workers", ",", "\n", "collate_fn", "=", "default_collate", ")", ":", "\n", "    ", "self", ".", "validation_split", "=", "validation_split", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n", "self", ".", "batch_idx", "=", "0", "\n", "self", ".", "n_samples", "=", "len", "(", "dataset", ")", "\n", "\n", "self", ".", "sampler", ",", "self", ".", "valid_sampler", "=", "self", ".", "_split_sampler", "(", "\n", "self", ".", "validation_split", ")", "\n", "\n", "self", ".", "init_kwargs", "=", "{", "\n", "'dataset'", ":", "dataset", ",", "\n", "'batch_size'", ":", "batch_size", ",", "\n", "'shuffle'", ":", "self", ".", "shuffle", ",", "\n", "'collate_fn'", ":", "collate_fn", ",", "\n", "'num_workers'", ":", "num_workers", "\n", "}", "\n", "super", "(", ")", ".", "__init__", "(", "sampler", "=", "self", ".", "sampler", ",", "**", "self", ".", "init_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader._split_sampler": [[50, 78], ["numpy.arange", "numpy.random.seed", "numpy.random.shuffle", "isinstance", "numpy.delete", "torch.utils.data.sampler.SubsetRandomSampler", "torch.utils.data.sampler.SubsetRandomSampler", "len", "int", "numpy.arange"], "methods", ["None"], ["", "def", "_split_sampler", "(", "self", ",", "split", ")", ":", "\n", "    ", "if", "split", "==", "0.0", ":", "\n", "      ", "return", "None", ",", "None", "\n", "\n", "", "idx_full", "=", "np", ".", "arange", "(", "self", ".", "n_samples", ")", "\n", "\n", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx_full", ")", "\n", "\n", "if", "isinstance", "(", "split", ",", "int", ")", ":", "\n", "      ", "assert", "split", ">", "0", "\n", "assert", "split", "<", "self", ".", "n_samples", ",", "(", "'validation set size is configured to be '", "\n", "'larger than entire dataset.'", ")", "\n", "len_valid", "=", "split", "\n", "", "else", ":", "\n", "      ", "len_valid", "=", "int", "(", "self", ".", "n_samples", "*", "split", ")", "\n", "\n", "", "valid_idx", "=", "idx_full", "[", "0", ":", "len_valid", "]", "\n", "train_idx", "=", "np", ".", "delete", "(", "idx_full", ",", "np", ".", "arange", "(", "0", ",", "len_valid", ")", ")", "\n", "\n", "train_sampler", "=", "SubsetRandomSampler", "(", "train_idx", ")", "\n", "valid_sampler", "=", "SubsetRandomSampler", "(", "valid_idx", ")", "\n", "\n", "# turn off shuffle option which is mutually exclusive with sampler", "\n", "self", ".", "shuffle", "=", "False", "\n", "self", ".", "n_samples", "=", "len", "(", "train_idx", ")", "\n", "\n", "return", "train_sampler", ",", "valid_sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_data_loader.BaseDataLoader.split_validation": [[79, 84], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "split_validation", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "valid_sampler", "is", "None", ":", "\n", "      ", "return", "None", "\n", "", "else", ":", "\n", "      ", "return", "DataLoader", "(", "sampler", "=", "self", ".", "valid_sampler", ",", "**", "self", ".", "init_kwargs", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_model.BaseModel.forward": [[10, 18], ["None"], "methods", ["None"], ["\n", "@", "abc", ".", "abstractmethod", "\n", "def", "forward", "(", "self", ",", "*", "inputs", ")", ":", "\n", "    ", "\"\"\"Forward pass logic.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "__str__", "(", "self", ")", ":", "\n", "    ", "\"\"\"Model prints with number of trainable parameters.\"\"\"", "\n", "model_parameters", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "parameters", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_model.BaseModel.__str__": [[19, 26], ["filter", "sum", "base_model.BaseModel.parameters", "torch.Module.__str__", "numpy.prod", "p.size"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_model.BaseModel.__str__"], ["params", "=", "sum", "(", "[", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "for", "p", "in", "model_parameters", "]", ")", "\n", "return", "super", "(", ")", ".", "__str__", "(", ")", "+", "f\"\\nTrainable parameters: {params}\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.dataset_paths": [[29, 36], ["None"], "methods", ["None"], ["import", "utils", ".", "stop_words", "as", "stop_words", "\n", "from", "utils", ".", "util", "import", "memcache", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "def", "is_end_of_sentence", "(", "word", ")", ":", "\n", "  ", "if", "word", "[", "-", "1", "]", "in", "[", "\".\"", ",", "\"?\"", ",", "\"!\"", "]", ":", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.get_retrieval_data": [[563, 579], ["collections.OrderedDict", "utils.util.ensure_tensor().float", "torch.from_numpy().float", "utils.util.ensure_tensor", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.ensure_tensor"], ["              ", "features_maxpool", "[", "expert", "]", "=", "x", "\n", "", "", "", "return", "(", "raw_captions", ",", "raw_captions_t", ",", "features", ",", "features_t", ",", "\n", "features_avgpool", ",", "features_maxpool", ")", "\n", "\n", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "if", "self", ".", "train", ":", "\n", "# If it is a training dataset, we let the trainer decide when the epoch", "\n", "# is completed.", "\n", "      ", "return", "max", "(", "self", ".", "num_train", ",", "1e6", ")", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "num_train", "\n", "\n", "", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "    ", "idx", "=", "idx", "%", "self", ".", "num_train", "\n", "\n", "vid", "=", "self", ".", "vid_list", "[", "idx", "]", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.has_missing_values": [[580, 582], ["isinstance", "numpy.isnan"], "methods", ["None"], ["path", "=", "self", ".", "video_paths", "[", "idx", "]", "\n", "\n", "(", "captions", ",", "captions_t", ",", "features", ",", "features_t", ",", "features_avgpool_provided", ",", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.visual_feat_paths": [[583, 613], ["model_spec.split", "aggs[].split", "base_dataset.BaseDataset.logger.info", "aggs.get", "feat_paths.append", "feat_type.replace", "aggs.get", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.mmt.parse_config.ConfigParser.get"], ["features_maxpool_provided", ")", "=", "self", ".", "get_sample_data", "(", "vid", ")", "\n", "\n", "if", "self", ".", "restrict_test_captions", "and", "vid", "in", "self", ".", "restrict_test_captions", ".", "keys", "(", "\n", ")", ":", "\n", "      ", "keep_sent_idx", "=", "self", ".", "restrict_test_captions", "[", "vid", "]", "\n", "# text = [text[keep_sent_idx]]", "\n", "captions", "=", "[", "captions", "[", "keep_sent_idx", "]", "]", "\n", "captions_t", "=", "[", "captions_t", "[", "keep_sent_idx", "]", "]", "\n", "\n", "", "raw_captions", "=", "[", "]", "\n", "raw_captions_t", "=", "[", "]", "\n", "\n", "captions_picked", "=", "min", "(", "len", "(", "captions", ")", ",", "self", ".", "captions_per_video", ")", "\n", "for", "cap_nb", "in", "range", "(", "captions_picked", ")", ":", "\n", "\n", "# For the evaluation", "\n", "# (no shuffling, only ok if self.captions_per_video != 1)", "\n", "      ", "if", "self", ".", "query_shuffling", "==", "\"indiv\"", ":", "\n", "# Not concatenating the captions", "\n", "        ", "raw_captions", ".", "append", "(", "captions", "[", "cap_nb", "]", ")", "\n", "raw_captions_t", ".", "append", "(", "captions_t", "[", "cap_nb", "]", ")", "\n", "\n", "", "if", "self", ".", "query_shuffling", "==", "\"cat\"", ":", "\n", "# Concatenating the captions and keeping the original order", "\n", "        ", "raw_captions", ".", "append", "(", "np", ".", "concatenate", "(", "captions", ")", ")", "\n", "raw_captions_t", ".", "append", "(", "np", ".", "concatenate", "(", "captions_t", ")", ")", "\n", "\n", "", "if", "self", ".", "query_shuffling", "==", "\"shuf\"", ":", "\n", "# Shuffling then concatenating the captions", "\n", "        ", "c", "=", "list", "(", "zip", "(", "captions", ",", "captions_t", ")", ")", "\n", "random", ".", "shuffle", "(", "c", ")", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.log_assert": [[614, 634], ["base_dataset.BaseDataset.logger.debug", "AssertionError", "inspect.stack", "open().readlines", "[].strip", "open"], "methods", ["None"], ["captions", ",", "captions_t", "=", "zip", "(", "*", "c", ")", "\n", "raw_captions", ".", "append", "(", "np", ".", "concatenate", "(", "captions", ")", ")", "\n", "raw_captions_t", ".", "append", "(", "np", ".", "concatenate", "(", "captions_t", ")", ")", "\n", "\n", "", "z", "=", "re", ".", "match", "(", "r\"shufk(\\d*)\"", ",", "self", ".", "query_shuffling", ")", "\n", "if", "z", ":", "\n", "# Shuffling then concatenating the captions and keeping the first few", "\n", "        ", "nb_keep", "=", "min", "(", "int", "(", "z", ".", "groups", "(", ")", "[", "0", "]", ")", ",", "len", "(", "captions", ")", ")", "\n", "c", "=", "list", "(", "zip", "(", "captions", ",", "captions_t", ")", ")", "\n", "random", ".", "shuffle", "(", "c", ")", "\n", "captions", ",", "captions_t", "=", "zip", "(", "*", "c", ")", "\n", "keep_captions", "=", "captions", "[", ":", "nb_keep", "]", "\n", "keep_captions_t", "=", "captions_t", "[", ":", "nb_keep", "]", "\n", "raw_captions", ".", "append", "(", "np", ".", "concatenate", "(", "keep_captions", ")", ")", "\n", "raw_captions_t", ".", "append", "(", "np", ".", "concatenate", "(", "keep_captions_t", ")", ")", "\n", "\n", "", "", "raw_captions", "=", "np", ".", "array", "(", "raw_captions", ",", "dtype", "=", "object", ")", "\n", "raw_captions_t", "=", "np", ".", "array", "(", "raw_captions_t", ")", "\n", "\n", "paths", "=", "[", "]", "\n", "sources", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.summary_stats": [[635, 662], ["base_dataset.BaseDataset.logger.info", "base_dataset.BaseDataset.partition_lists.items", "set", "print", "base_dataset.BaseDataset.has_missing_values", "print", "sizes.append", "len", "numpy.min", "numpy.max", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.parse_config.ConfigParser.items", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.has_missing_values"], ["raw_captions_list", "=", "[", "]", "\n", "raw_captions_t_list", "=", "[", "]", "\n", "token_ids_list", "=", "[", "]", "\n", "query_masks_list", "=", "[", "]", "\n", "features_dic", "=", "{", "}", "\n", "features_t_dic", "=", "{", "}", "\n", "features_ind_dic", "=", "{", "}", "\n", "features_avgpool_dic", "=", "{", "}", "\n", "features_maxpool_dic", "=", "{", "}", "\n", "for", "expert", "in", "self", ".", "experts", ":", "\n", "      ", "features_dic", "[", "expert", "]", "=", "[", "]", "\n", "features_t_dic", "[", "expert", "]", "=", "[", "]", "\n", "features_ind_dic", "[", "expert", "]", "=", "[", "]", "\n", "features_avgpool_dic", "[", "expert", "]", "=", "[", "]", "\n", "features_maxpool_dic", "[", "expert", "]", "=", "[", "]", "\n", "\n", "", "split_sentences_list", "=", "[", "]", "\n", "for", "cap_idx", "in", "range", "(", "self", ".", "captions_per_video", ")", ":", "\n", "      ", "if", "cap_idx", "<", "len", "(", "raw_captions", ")", ":", "\n", "        ", "cap", "=", "np", ".", "array", "(", "[", "\n", "el", "if", "isinstance", "(", "el", ",", "str", ")", "else", "el", ".", "decode", "(", "\"UTF-8\"", ")", "\n", "for", "el", "in", "raw_captions", "[", "cap_idx", "]", "\n", "]", ")", "\n", "cap_t", "=", "np", ".", "array", "(", "raw_captions_t", "[", "cap_idx", "]", ")", "\n", "\n", "# HowTo100M have no video features extracted beyond 500s, so ignore text", "\n", "# after that.", "\n", "keep_ids", "=", "cap_t", "[", ":", ",", "0", "]", "<", "500", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_text_feat_paths": [[663, 671], ["open", "json.load"], "methods", ["None"], ["cap", "=", "np", ".", "expand_dims", "(", "cap", "[", "keep_ids", "]", ",", "axis", "=", "-", "1", ")", "\n", "cap_t", "=", "np", ".", "expand_dims", "(", "cap_t", "[", "keep_ids", "]", ",", "axis", "=", "-", "1", ")", "\n", "if", "len", "(", "cap", ")", "<", "1", ":", "\n", "# The cap length can be 0 when there are no words pronounced in the", "\n", "# first 500s.", "\n", "          ", "cap", "=", "np", ".", "array", "(", "[", "[", "\".\"", "]", "]", ")", "\n", "cap_t", "=", "np", ".", "array", "(", "[", "[", "[", "0", ",", "0", "]", "]", "]", ")", "\n", "", "", "else", ":", "\n", "# Requested more captions than available, zero padding", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.common_feat_names": [[672, 695], ["None"], "methods", ["None"], ["        ", "cap", "=", "np", ".", "array", "(", "[", "[", "\"0\"", "]", "]", ")", "\n", "cap_t", "=", "np", ".", "array", "(", "[", "[", "[", "0", ",", "0", "]", "]", "]", ")", "\n", "\n", "", "split_sentences_list", ".", "append", "(", "(", "cap", ",", "cap_t", ")", ")", "\n", "\n", "", "captions_query_masks", "=", "np", ".", "zeros", "(", "(", "self", ".", "captions_per_video", ")", ")", "\n", "captions_query_masks", "[", ":", "len", "(", "raw_captions", ")", "]", "=", "1", "\n", "\n", "# n_pairs number of clips to sample from each video", "\n", "for", "_", "in", "range", "(", "self", ".", "n_pairs", ")", ":", "\n", "      ", "token_ids", "=", "[", "]", "\n", "raw_captions_", "=", "[", "]", "\n", "raw_captions_t_", "=", "[", "]", "\n", "for", "cap_idx", "in", "range", "(", "self", ".", "captions_per_video", ")", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "          ", "rng", "=", "np", ".", "random", "\n", "", "else", ":", "\n", "# Same data selection across epochs", "\n", "          ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "idx", ")", "\n", "\n", "# Number of sentences to pick per caption", "\n", "", "if", "isinstance", "(", "self", ".", "caption_length", ",", "list", ")", ":", "\n", "          ", "min_picked_sentences", "=", "self", ".", "caption_length", "[", "0", "]", "\n", "max_picked_sentences", "=", "self", ".", "caption_length", "[", "1", "]", "\n"]], "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.base.base_dataset.BaseDataset.load_challenge_text_features": [[696, 709], ["zsvision.zs_utils.memcache", "zsvision.zs_utils.memcache", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache", "home.repos.pwc.inspect_result.akoepke_audio-retrieval-benchmark.utils.util.memcache"], ["", "else", ":", "\n", "          ", "min_picked_sentences", "=", "self", ".", "caption_length", "\n", "max_picked_sentences", "=", "self", ".", "caption_length", "\n", "\n", "", "if", "min_picked_sentences", "==", "float", "(", "\"Inf\"", ")", ":", "\n", "          ", "nb_sentences", "=", "float", "(", "\"Inf\"", ")", "\n", "", "else", ":", "\n", "          ", "nb_sentences", "=", "rng", ".", "randint", "(", "min_picked_sentences", ",", "\n", "max_picked_sentences", "+", "1", ")", "\n", "\n", "# Duration in seconds of the video crop to consider", "\n", "", "if", "isinstance", "(", "self", ".", "clip_duration", ",", "list", ")", ":", "\n", "          ", "clip_duration_min", "=", "self", ".", "clip_duration", "[", "0", "]", "\n", "clip_duration_max", "=", "self", ".", "clip_duration", "[", "1", "]", "\n"]]}