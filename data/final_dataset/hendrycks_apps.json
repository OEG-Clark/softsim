{"home.repos.pwc.inspect_result.hendrycks_apps.eval.merge_codes.combine_codes": [[6, 27], ["os.listdir", "os.path.join", "open", "json.dump", "print", "os.path.join", "open", "json.load"], "function", ["None"], ["def", "combine_codes", "(", "args", ")", ":", "\n", "    ", "result_files", "=", "os", ".", "listdir", "(", "args", ".", "root", ")", "\n", "tmp_codes", "=", "{", "}", "\n", "\n", "# load the results and combine them", "\n", "for", "r_file", "in", "result_files", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "r_file", ")", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "print", "(", "path", ")", "\n", "", "elif", "\"bleu\"", "in", "path", ":", "\n", "            ", "continue", "\n", "", "elif", "\"results.json\"", "in", "path", ":", "\n", "           ", "continue", "\n", "", "elif", "\"codes\"", "in", "path", "and", "args", ".", "save", "not", "in", "path", ":", "\n", "            ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "results", "=", "json", ".", "load", "(", "f", ")", "\n", "", "for", "res", "in", "results", ":", "\n", "                ", "tmp_codes", "[", "res", "]", "=", "results", "[", "res", "]", "\n", "", "continue", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "args", ".", "save", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "tmp_codes", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.merge_codes.main": [[29, 38], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "merge_codes.combine_codes"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.parse_args", "home.repos.pwc.inspect_result.hendrycks_apps.eval.merge_codes.combine_codes"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--debug\"", ",", "help", "=", "\"print debugging statements\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--root\"", ",", "default", "=", "\"./results\"", ",", "type", "=", "str", ",", "help", "=", "\"which folder to merge the results\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-s\"", ",", "\"--save\"", ",", "default", "=", "\"all_codes.json\"", ",", "type", "=", "str", ",", "help", "=", "\"Large final save file name. Note other files use the default value.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "combine_codes", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.Capturing.__enter__": [[43, 49], ["io.StringIO"], "methods", ["None"], ["    ", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_stdout", "=", "sys", ".", "stdout", "\n", "sys", ".", "stdout", "=", "self", ".", "_stringio", "=", "StringIO", "(", ")", "\n", "# Make closing the StringIO a no-op", "\n", "self", ".", "_stringio", ".", "close", "=", "lambda", "x", ":", "1", "\n", "return", "self", "\n", "", "def", "__exit__", "(", "self", ",", "*", "args", ")", ":", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.Capturing.__exit__": [[49, 53], ["testing_util.Capturing.extend", "testing_util.Capturing._stringio.getvalue().splitlines", "testing_util.Capturing._stringio.getvalue"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "extend", "(", "self", ".", "_stringio", ".", "getvalue", "(", ")", ".", "splitlines", "(", ")", ")", "\n", "del", "self", ".", "_stringio", "# free up some memory", "\n", "sys", ".", "stdout", "=", "self", ".", "_stdout", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.timeout_handler": [[32, 36], ["print"], "function", ["None"], ["", "def", "timeout_handler", "(", "signum", ",", "frame", ")", ":", "\n", "    ", "print", "(", "\"alarm went off\"", ")", "\n", "#return", "\n", "raise", "TimeoutException", "\n", "", "signal", ".", "signal", "(", "signal", ".", "SIGALRM", ",", "timeout_handler", ")", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.parse_args": [[55, 70], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Utility for testing code generation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-v\"", ",", "\"--verbosity-level\"", ",", "action", "=", "\"store\"", ",", "type", "=", "int", ",", "\n", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-s\"", ",", "\"--source\"", ",", "type", "=", "str", ",", "default", "=", "\"leetcode\"", ",", "\n", "choices", "=", "[", "\"leetcode\"", ",", "\"atcoder\"", ",", "\"codewars\"", ",", "]", ",", "\n", "help", "=", "\"which data source to gather from.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-d\"", ",", "\"--data\"", ",", "type", "=", "str", ",", "default", "=", "\"question\"", ",", "\n", "choices", "=", "[", "\"question\"", ",", "\"q\"", ",", "\"solutions\"", ",", "\"sol\"", ",", "\"s\"", ",", "\"starter\"", ",", "\"tests\"", ",", "\"t\"", "]", ",", "\n", "help", "=", "\"which type of data to receive.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-n\"", ",", "\"--number\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"which problem to query.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.get_valid_problems": [[72, 98], ["os.path.join", "os.path.exists", "os.listdir", "sorted", "os.path.join", "os.path.join", "os.path.join", "os.listdir", "open", "json.load", "sorted.append", "os.path.join"], "function", ["None"], ["", "def", "get_valid_problems", "(", "data_dir", "=", "\"leetcode\"", ")", ":", "\n", "# these are unnecessary atm", "\n", "    ", "if", "data_dir", "==", "\"leetcode\"", ":", "\n", "        ", "root", "=", "os", ".", "path", ".", "join", "(", "args", ".", "source", ",", "\"data\"", ")", "\n", "", "elif", "data_dir", "==", "\"atcoder\"", ":", "\n", "        ", "pass", "\n", "\n", "", "root", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"data\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"valid_problems.json\"", ")", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"valid_problems.json\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n", "# after we compute it once let's save it and load that instead", "\n", "# TODO determine if might be better to reload each time", "\n", "", "", "tmp", "=", "os", ".", "listdir", "(", "root", ")", "\n", "valid_probs", "=", "[", "]", "\n", "for", "folder", "in", "tmp", ":", "\n", "        ", "prob_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "folder", ")", "\n", "files", "=", "os", ".", "listdir", "(", "prob_path", ")", "\n", "#TODO add more validity checks", "\n", "if", "\"input_output.json\"", "in", "files", "or", "\"sols.json\"", "in", "files", ":", "\n", "            ", "valid_probs", ".", "append", "(", "prob_path", ")", "\n", "", "", "valid_probs", "=", "sorted", "(", "valid_probs", ")", "\n", "#with open(os.path.join(args.source,\"valid_problems.json\"), \"w\") as f:", "\n", "#    json.dump(valid_probs, f)", "\n", "return", "valid_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.get_question": [[100, 111], ["os.path.exists", "os.path.join", "print", "open", "f.readlines", "os.path.join"], "function", ["None"], ["", "def", "get_question", "(", "problem_list", ",", "prob_index", ")", ":", "\n", "    ", "root", "=", "problem_list", "[", "prob_index", "]", "\n", "#print(\"get q\", root)", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"question.txt\"", ")", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"question.txt\"", ")", ")", "as", "f", ":", "\n", "            ", "question", "=", "f", ".", "readlines", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "\"question prompt not found\"", ")", "\n", "question", "=", "\"\"", "\n", "", "question", "=", "\"\"", ".", "join", "(", "question", ")", "\n", "return", "question", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.get_solutions": [[113, 119], ["os.path.exists", "os.path.join", "open", "json.load", "os.path.join"], "function", ["None"], ["", "def", "get_solutions", "(", "problem_list", ",", "prob_index", ")", ":", "\n", "    ", "root", "=", "problem_list", "[", "prob_index", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"solutions.json\"", ")", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"solutions.json\"", ")", ")", "as", "f", ":", "\n", "            ", "sols", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "return", "sols", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.run_test": [[121, 469], ["os.path.exists", "print", "exit", "print", "os.path.join", "print", "open", "json.load", "enumerate", "os.path.join", "print", "json.load.get", "print", "signal.alarm", "signal.alarm", "print", "getattr", "datetime.datetime.now().time", "datetime.datetime.now().time", "print", "pyext.RuntimeModule.from_string", "signal.alarm", "test.split", "signal.alarm", "signal.alarm", "signal.alarm", "sys.exc_info", "print", "isinstance", "isinstance", "isinstance", "print", "signal.alarm", "faulthandler.enable", "faulthandler.disable", "signal.alarm", "RuntimeModule.from_string.Solution", "signal.alarm", "print", "results.append", "print", "pyext.RuntimeModule.from_string", "signal.alarm", "getattr.", "isinstance", "results.append", "signal.alarm", "print", "faulthandler.enable", "signal.alarm", "isinstance", "isinstance", "testing_util.custom_compare_", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "results.append", "datetime.datetime.now", "datetime.datetime.now", "datetime.datetime.now().time", "new_test.append", "new_test.append", "i.startswith", "signal.alarm", "print", "results.append", "datetime.datetime.now().time", "list", "isinstance", "isinstance", "signal.alarm", "faulthandler.disable", "print", "results.append", "testing_util.Capturing", "signal.alarm", "print", "results.append", "list", "isinstance", "results.append", "enumerate", "[].split", "list", "list", "isinstance", "results.append", "list", "results.append", "isinstance", "isinstance", "results.append", "enumerate", "set", "results.append", "enumerate", "list", "enumerate", "set.split", "list", "set", "print", "x.startswith", "x.startswith", "int", "int", "int", "datetime.datetime.now().time", "type", "testing_util.call_method", "signal.alarm", "isinstance", "print", "i.split", "filter", "map", "print", "filter", "isinstance", "print", "print", "print", "float", "float", "set", "[].split", "print", "i.split", "filter", "set", "filter", "set", "set", "print", "print", "isinstance", "print", "print", "datetime.datetime.now", "i.startswith", "i.startswith", "datetime.datetime.now", "inputs[].items", "[].items", "[].items", "type", "signal.alarm", "print", "results.append", "isinstance", "print", "print", "x.strip", "numpy.allclose", "float", "float", "i.split", "set", "set", "datetime.datetime.now", "x.strip", "len", "len", "numpy.allclose", "frozenset", "frozenset", "list", "inputs.replace", "type", "type", "len", "len", "frozenset", "frozenset", "inputs.replace", "type", "type", "repr", "inputs.replace", "type", "type", "sys.exc_info.strip", "round", "round", "float", "float"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.custom_compare_", "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.call_method"], ["", "def", "run_test", "(", "prob_path", ":", "str", "=", "None", ",", "problem_list", ":", "List", "[", "str", "]", "=", "None", ",", "prob_index", ":", "int", "=", "None", ",", "\n", "test", ":", "str", "=", "None", ",", "debug", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    if test is not None it'll try to run the code.\n    otherwise it'll just return an input and output pair.\n    \"\"\"", "\n", "if", "prob_path", "is", "None", "and", "problem_list", "is", "None", ":", "\n", "        ", "print", "(", "\"please provide either prob_path or problem_list\"", ")", "\n", "exit", "(", ")", "\n", "\n", "", "if", "debug", ":", "\n", "        ", "print", "(", "f\"start = {datetime.now().time()}\"", ")", "\n", "", "if", "prob_path", "is", "not", "None", ":", "\n", "        ", "root", "=", "prob_path", "\n", "", "elif", "problem_list", "is", "not", "None", ":", "\n", "        ", "root", "=", "problem_list", "[", "prob_index", "]", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"input_output.json\"", ")", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "\"input_output.json\"", ")", ")", "as", "f", ":", "\n", "            ", "in_outs", "=", "json", ".", "load", "(", "f", ")", "\n", "if", "debug", ":", "\n", "                ", "print", "(", "f\"test cases json = {in_outs['inputs']} {in_outs['outputs']}\"", ")", "\n", "\n", "", "if", "in_outs", ".", "get", "(", "\"fn_name\"", ")", "is", "None", ":", "\n", "                ", "which_type", "=", "CODE_TYPE", ".", "standard_input", "# Standard input", "\n", "method_name", "=", "None", "\n", "", "else", ":", "\n", "                ", "which_type", "=", "CODE_TYPE", ".", "call_based", "# Call-based", "\n", "method_name", "=", "in_outs", "[", "\"fn_name\"", "]", "\n", "", "", "", "if", "debug", ":", "\n", "        ", "print", "(", "f\"loaded json = {datetime.now().time()}\"", ")", "\n", "\n", "#else:", "\n", "#    continue", "\n", "", "if", "test", "is", "None", ":", "\n", "        ", "return", "in_outs", "\n", "", "elif", "test", "is", "not", "None", ":", "\n", "        ", "results", "=", "[", "]", "\n", "sol", "=", "\"import sys\\nimport time\\nimport itertools\\nfrom itertools import accumulate, product, permutations, combinations\\nimport collections\\nfrom collections import Counter, OrderedDict, deque, defaultdict, ChainMap\\nfrom functools import lru_cache\\nimport math\\nfrom math import sqrt, sin, cos, tan, ceil, fabs, floor, gcd, exp, log, log2\\nimport fractions\\nfrom typing import List, Tuple\\nimport numpy as np\\nimport random\\nimport heapq\\nfrom heapq import *\\n\"", "\n", "if", "debug", ":", "\n", "            ", "print", "(", "f\"loading test code = {datetime.now().time()}\"", ")", "\n", "\n", "", "if", "which_type", "==", "CODE_TYPE", ".", "call_based", ":", "\n", "            ", "sol", "+=", "test", "\n", "if", "debug", ":", "# or True:", "\n", "                ", "print", "(", "f\"sol = {sol}\"", ")", "\n", "", "signal", ".", "alarm", "(", "timeout", ")", "\n", "try", ":", "\n", "                ", "tmp_sol", "=", "RuntimeModule", ".", "from_string", "(", "\"tmp_sol\"", ",", "\"\"", ",", "sol", ")", "\n", "if", "\"class Solution\"", "not", "in", "test", ":", "\n", "                    ", "tmp", "=", "tmp_sol", "\n", "", "else", ":", "\n", "                    ", "tmp", "=", "tmp_sol", ".", "Solution", "(", ")", "\n", "", "signal", ".", "alarm", "(", "0", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "signal", ".", "alarm", "(", "0", ")", "\n", "print", "(", "f\"type 0 compilation error = {e}\"", ")", "\n", "results", ".", "append", "(", "-", "2", ")", "\n", "return", "results", "\n", "", "signal", ".", "alarm", "(", "0", ")", "\n", "\n", "", "elif", "which_type", "==", "CODE_TYPE", ".", "standard_input", ":", "\n", "# sol", "\n", "            ", "tmp_test", "=", "test", ".", "split", "(", "\"\\n\"", ")", "\n", "\n", "new_test", "=", "[", "]", "\n", "for", "x", "in", "tmp_test", ":", "\n", "                ", "if", "(", "not", "x", ".", "startswith", "(", "\"from \"", ")", ")", "and", "(", "not", "x", ".", "startswith", "(", "\"import \"", ")", ")", ":", "\n", "                    ", "new_test", ".", "append", "(", "\"\\t\"", "+", "x", "+", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "                    ", "new_test", ".", "append", "(", "x", "+", "\"\\n\"", ")", "\n", "", "", "tmp_test", "=", "new_test", "\n", "\n", "new_test", "=", "\"\"", "\n", "started", "=", "False", "\n", "for", "i", "in", "tmp_test", ":", "\n", "                ", "if", "i", ".", "startswith", "(", "\"\\t\"", ")", "and", "not", "started", ":", "\n", "                    ", "new_test", "+=", "\"stdin = sys.stdin\\nstdout = sys.stdout\\n\"", "\n", "new_test", "+=", "\"def code():\\n\"", "\n", "new_test", "+=", "i", "\n", "started", "=", "True", "\n", "", "elif", "started", "and", "(", "(", "i", ".", "startswith", "(", "\"from \"", ")", ")", "or", "(", "i", ".", "startswith", "(", "\"import \"", ")", ")", ")", ":", "\n", "                    ", "new_test", "+=", "\"\\t\"", "+", "i", "\n", "", "else", ":", "\n", "                    ", "new_test", "+=", "i", "\n", "", "", "tmp_test", "=", "new_test", "\n", "\n", "sol", "+=", "tmp_test", "\n", "if", "debug", ":", "\n", "                ", "print", "(", "f\"sol = {sol}\"", ")", "\n", "# print(f\"{o}\") ", "\n", "", "method_name", "=", "\"code\"", "\n", "signal", ".", "alarm", "(", "timeout", ")", "\n", "try", ":", "\n", "                ", "tmp_sol", "=", "RuntimeModule", ".", "from_string", "(", "\"tmp_sol\"", ",", "\"\"", ",", "sol", ")", "\n", "tmp", "=", "tmp_sol", "\n", "signal", ".", "alarm", "(", "0", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "signal", ".", "alarm", "(", "0", ")", "\n", "print", "(", "f\"type 1 compilation error = {e}\"", ")", "\n", "results", ".", "append", "(", "-", "2", ")", "\n", "return", "results", "\n", "", "signal", ".", "alarm", "(", "0", ")", "\n", "", "if", "debug", ":", "\n", "            ", "print", "(", "f\"get method = {datetime.now().time()}\"", ")", "\n", "\n", "", "try", ":", "\n", "            ", "method", "=", "getattr", "(", "tmp", ",", "method_name", ")", "# get_attr second arg must be str", "\n", "", "except", ":", "\n", "            ", "signal", ".", "alarm", "(", "0", ")", "\n", "e", "=", "sys", ".", "exc_info", "(", ")", "\n", "print", "(", "f\"unable to get function error = {e}\"", ")", "\n", "return", "results", "\n", "\n", "", "for", "index", ",", "inputs", "in", "enumerate", "(", "in_outs", "[", "\"inputs\"", "]", ")", ":", "\n", "# JSON forces dictionaries to have string keys; this undoes this (assuming a singleton list)", "\n", "            ", "try", ":", "\n", "                ", "if", "isinstance", "(", "inputs", "[", "0", "]", ",", "dict", ")", ":", "\n", "                    ", "inputs", "=", "[", "{", "int", "(", "k", ")", ":", "v", "for", "k", ",", "v", "in", "inputs", "[", "0", "]", ".", "items", "(", ")", "}", "]", "\n", "", "", "except", ":", "\n", "                ", "True", "\n", "", "try", ":", "\n", "                ", "if", "isinstance", "(", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ",", "dict", ")", ":", "\n", "                    ", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "=", "[", "{", "int", "(", "k", ")", ":", "v", "for", "k", ",", "v", "in", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ".", "items", "(", ")", "}", "]", "\n", "", "", "except", ":", "\n", "                ", "True", "\n", "", "try", ":", "\n", "                ", "if", "isinstance", "(", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "[", "0", "]", ",", "dict", ")", ":", "\n", "                    ", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "=", "[", "{", "int", "(", "k", ")", ":", "v", "for", "k", ",", "v", "in", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "[", "0", "]", ".", "items", "(", ")", "}", "]", "\n", "", "", "except", ":", "\n", "                ", "True", "\n", "\n", "", "if", "debug", ":", "\n", "                ", "print", "(", "f\"time: {datetime.now().time()} testing index = {index}  inputs = {inputs}, {type(inputs)}. type = {which_type}\"", ")", "\n", "", "if", "which_type", "==", "CODE_TYPE", ".", "call_based", ":", "# Call-based", "\n", "                ", "signal", ".", "alarm", "(", "timeout", ")", "\n", "faulthandler", ".", "enable", "(", ")", "\n", "try", ":", "\n", "# print(\"------------\")", "\n", "# print(inputs)", "\n", "                    ", "output", "=", "method", "(", "*", "inputs", ")", "\n", "\n", "# ground truth sequences are not tuples", "\n", "if", "isinstance", "(", "output", ",", "tuple", ")", ":", "\n", "                        ", "output", "=", "list", "(", "output", ")", "\n", "\n", "", "tmp_result", "=", "output", "==", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "\n", "if", "isinstance", "(", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ",", "list", ")", "and", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ":", "\n", "                        ", "tmp_result", "=", "tmp_result", "or", "(", "output", "==", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "[", "0", "]", ")", "\n", "\n", "# ground truth sequences are not tuples", "\n", "", "try", ":", "\n", "                        ", "if", "isinstance", "(", "output", "[", "0", "]", ",", "tuple", ")", ":", "\n", "                            ", "tmp_result", "=", "tmp_result", "or", "(", "[", "list", "(", "x", ")", "for", "x", "in", "output", "]", "==", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "[", "0", "]", ")", "\n", "", "", "except", ":", "\n", "                        ", "True", "\n", "", "results", ".", "append", "(", "tmp_result", ")", "\n", "\n", "# reset the alarm", "\n", "signal", ".", "alarm", "(", "0", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "signal", ".", "alarm", "(", "0", ")", "\n", "faulthandler", ".", "disable", "(", ")", "\n", "print", "(", "f\"Standard input runtime error or time limit exceeded error = {e}\"", ")", "\n", "results", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "", "faulthandler", ".", "disable", "(", ")", "\n", "signal", ".", "alarm", "(", "0", ")", "\n", "if", "debug", ":", "\n", "                    ", "print", "(", "f\"outputs = {output}, test outputs = {in_outs['outputs'][index]}, inputs = {inputs}, {type(inputs)}, {output == [in_outs['outputs'][index]]}\"", ")", "\n", "", "", "elif", "which_type", "==", "CODE_TYPE", ".", "standard_input", ":", "# Standard input", "\n", "                ", "faulthandler", ".", "enable", "(", ")", "\n", "signal", ".", "alarm", "(", "timeout", ")", "\n", "passed", "=", "False", "\n", "\n", "if", "isinstance", "(", "inputs", ",", "list", ")", ":", "\n", "                    ", "inputs", "=", "\"\\n\"", ".", "join", "(", "inputs", ")", "\n", "", "if", "isinstance", "(", "in_outs", "[", "'outputs'", "]", "[", "index", "]", ",", "list", ")", ":", "\n", "                    ", "in_outs", "[", "'outputs'", "]", "[", "index", "]", "=", "\"\\n\"", ".", "join", "(", "in_outs", "[", "'outputs'", "]", "[", "index", "]", ")", "\n", "\n", "", "with", "Capturing", "(", ")", "as", "output", ":", "\n", "                    ", "try", ":", "\n", "                        ", "call_method", "(", "method", ",", "inputs", ")", "\n", "# reset the alarm", "\n", "signal", ".", "alarm", "(", "0", ")", "\n", "passed", "=", "True", "\n", "", "except", "Exception", "as", "e", ":", "\n", "# runtime error or took too long", "\n", "                        ", "signal", ".", "alarm", "(", "0", ")", "\n", "print", "(", "f\"Call-based runtime error or time limit exceeded error = {repr(e)}{e}\"", ")", "\n", "results", ".", "append", "(", "-", "1", ")", "\n", "", "signal", ".", "alarm", "(", "0", ")", "\n", "\n", "", "if", "not", "passed", ":", "\n", "                    ", "if", "debug", ":", "\n", "                        ", "nl", "=", "\"\\n\"", "\n", "if", "not", "isinstance", "(", "inputs", ",", "list", ")", ":", "\n", "                            ", "print", "(", "f\"not passed output = {output}, test outputs = {in_outs['outputs'][index]}, inputs = {inputs.replace(nl,' new-line ')}, {type(inputs)}, {output == [in_outs['outputs'][index]]}\"", ")", "\n", "", "else", ":", "\n", "                            ", "print", "(", "f\"not passed output = {output}, test outputs = {in_outs['outputs'][index]}, inputs = {inputs}, {type(inputs)}, {output == [in_outs['outputs'][index]]}\"", ")", "\n", "", "", "continue", "\n", "\n", "", "if", "passed", "and", "debug", ":", "\n", "                    ", "print", "(", "f\"==> output = {output}, test outputs = {in_outs['outputs'][index]}\"", ")", "\n", "\n", "", "if", "custom_compare_", "(", "output", ",", "in_outs", "[", "'outputs'", "]", "[", "index", "]", ")", ":", "\n", "                    ", "tmp_result", "=", "True", "\n", "results", ".", "append", "(", "tmp_result", ")", "\n", "continue", "\n", "\n", "# ground truth sequences are expressed as lists not tuples", "\n", "", "if", "isinstance", "(", "output", ",", "tuple", ")", ":", "\n", "                    ", "output", "=", "list", "(", "output", ")", "\n", "\n", "", "tmp_result", "=", "False", "\n", "try", ":", "\n", "                    ", "tmp_result", "=", "(", "output", "==", "[", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "]", ")", "\n", "if", "isinstance", "(", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ",", "list", ")", ":", "\n", "                        ", "tmp_result", "=", "tmp_result", "or", "(", "output", "==", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ")", "\n", "if", "isinstance", "(", "output", "[", "0", "]", ",", "str", ")", ":", "\n", "                            ", "tmp_result", "=", "tmp_result", "or", "(", "[", "e", ".", "strip", "(", ")", "for", "e", "in", "output", "]", "==", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ")", "\n", "", "", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "f\"Failed check1 exception = {e}\"", ")", "\n", "pass", "\n", "\n", "", "if", "tmp_result", "==", "True", ":", "\n", "                    ", "results", ".", "append", "(", "tmp_result", ")", "\n", "continue", "\n", "\n", "# try one more time without \\n", "\n", "", "if", "isinstance", "(", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ",", "list", ")", ":", "\n", "                    ", "for", "tmp_index", ",", "i", "in", "enumerate", "(", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ")", ":", "\n", "                        ", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "[", "tmp_index", "]", "=", "i", ".", "split", "(", "\"\\n\"", ")", "\n", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "[", "tmp_index", "]", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "[", "tmp_index", "]", "if", "x", "]", "\n", "", "", "else", ":", "\n", "                    ", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "=", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ".", "split", "(", "\"\\n\"", ")", "\n", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "=", "list", "(", "filter", "(", "len", ",", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ")", ")", "\n", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", ".", "strip", "(", ")", ",", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ")", ")", "\n", "\n", "", "try", ":", "\n", "                    ", "tmp_result", "=", "(", "output", "==", "[", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "]", ")", "\n", "if", "isinstance", "(", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ",", "list", ")", ":", "\n", "                        ", "tmp_result", "=", "tmp_result", "or", "(", "output", "==", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "f\"Failed check2 exception = {e}\"", ")", "\n", "pass", "\n", "\n", "", "if", "tmp_result", "==", "True", ":", "\n", "                    ", "results", ".", "append", "(", "tmp_result", ")", "\n", "continue", "\n", "\n", "# try by converting the output into a split up list too", "\n", "", "if", "isinstance", "(", "output", ",", "list", ")", ":", "\n", "                    ", "output", "=", "list", "(", "filter", "(", "len", ",", "output", ")", ")", "\n", "\n", "", "if", "debug", ":", "\n", "                    ", "nl", "=", "\"\\n\"", "\n", "if", "not", "isinstance", "(", "inputs", ",", "list", ")", ":", "\n", "                        ", "print", "(", "f\"output = {output}, test outputs = {in_outs['outputs'][index]}, inputs = {inputs.replace(nl,' new-line ')}, {type(inputs)}, {output == [in_outs['outputs'][index]]}\"", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "f\"output = {output}, test outputs = {in_outs['outputs'][index]}, inputs = {inputs}, {type(inputs)}, {output == [in_outs['outputs'][index]]}\"", ")", "\n", "\n", "", "", "if", "tmp_result", "==", "True", ":", "\n", "                    ", "results", ".", "append", "(", "tmp_result", ")", "\n", "continue", "\n", "\n", "", "try", ":", "\n", "                    ", "tmp_result", "=", "(", "output", "==", "[", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "]", ")", "\n", "if", "isinstance", "(", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ",", "list", ")", ":", "\n", "                        ", "tmp_result", "=", "tmp_result", "or", "(", "output", "==", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "f\"Failed check3 exception = {e}\"", ")", "\n", "pass", "\n", "\n", "", "try", ":", "\n", "                    ", "output_float", "=", "[", "float", "(", "e", ")", "for", "e", "in", "output", "]", "\n", "gt_float", "=", "[", "float", "(", "e", ")", "for", "e", "in", "in_outs", "[", "'outputs'", "]", "[", "index", "]", "]", "\n", "tmp_result", "=", "tmp_result", "or", "(", "(", "len", "(", "output_float", ")", "==", "len", "(", "gt_float", ")", ")", "and", "np", ".", "allclose", "(", "output_float", ",", "gt_float", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "pass", "\n", "", "try", ":", "\n", "                    ", "if", "isinstance", "(", "output", "[", "0", "]", ",", "list", ")", ":", "\n", "                        ", "output_float", "=", "[", "float", "(", "e", ")", "for", "e", "in", "output", "[", "0", "]", "]", "\n", "gt_float", "=", "[", "float", "(", "e", ")", "for", "e", "in", "in_outs", "[", "'outputs'", "]", "[", "index", "]", "[", "0", "]", "]", "\n", "tmp_result", "=", "tmp_result", "or", "(", "(", "len", "(", "output_float", ")", "==", "len", "(", "gt_float", ")", ")", "and", "np", ".", "allclose", "(", "output_float", ",", "gt_float", ")", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "pass", "\n", "\n", "", "if", "tmp_result", "==", "True", ":", "\n", "                    ", "results", ".", "append", "(", "tmp_result", ")", "\n", "continue", "\n", "\n", "# try by converting the stuff into split up list", "\n", "", "if", "isinstance", "(", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ",", "list", ")", ":", "\n", "                    ", "for", "tmp_index", ",", "i", "in", "enumerate", "(", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ")", ":", "\n", "                        ", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "[", "tmp_index", "]", "=", "set", "(", "i", ".", "split", "(", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", "=", "set", "(", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ".", "split", "(", ")", ")", "\n", "\n", "", "try", ":", "\n", "                    ", "tmp_result", "=", "(", "output", "==", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "f\"Failed check4 exception = {e}\"", ")", "\n", "continue", "\n", "\n", "", "if", "tmp_result", "==", "True", ":", "\n", "                    ", "results", ".", "append", "(", "tmp_result", ")", "\n", "continue", "\n", "\n", "# try by converting the output into a split up list too", "\n", "", "if", "isinstance", "(", "output", ",", "list", ")", ":", "\n", "                    ", "for", "tmp_index", ",", "i", "in", "enumerate", "(", "output", ")", ":", "\n", "                        ", "output", "[", "tmp_index", "]", "=", "i", ".", "split", "(", ")", "\n", "", "output", "=", "list", "(", "filter", "(", "len", ",", "output", ")", ")", "\n", "for", "tmp_index", ",", "i", "in", "enumerate", "(", "output", ")", ":", "\n", "                        ", "output", "[", "tmp_index", "]", "=", "set", "(", "i", ")", "\n", "", "", "else", ":", "\n", "                    ", "output", "=", "output", ".", "split", "(", ")", "\n", "output", "=", "list", "(", "filter", "(", "len", ",", "output", ")", ")", "\n", "output", "=", "set", "(", "output", ")", "\n", "\n", "", "try", ":", "\n", "                    ", "tmp_result", "=", "(", "set", "(", "frozenset", "(", "s", ")", "for", "s", "in", "output", ")", "==", "set", "(", "frozenset", "(", "s", ")", "for", "s", "in", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "f\"Failed check5 exception = {e}\"", ")", "\n", "\n", "\n", "# if they are all numbers, round so that similar numbers are treated as identical", "\n", "", "try", ":", "\n", "                    ", "tmp_result", "=", "tmp_result", "or", "(", "set", "(", "frozenset", "(", "round", "(", "float", "(", "t", ")", ",", "3", ")", "for", "t", "in", "s", ")", "for", "s", "in", "output", ")", "==", "set", "(", "frozenset", "(", "round", "(", "float", "(", "t", ")", ",", "3", ")", "for", "t", "in", "s", ")", "for", "s", "in", "in_outs", "[", "\"outputs\"", "]", "[", "index", "]", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "f\"Failed check6 exception = {e}\"", ")", "\n", "\n", "", "if", "tmp_result", "==", "True", "and", "debug", ":", "\n", "                    ", "print", "(", "\"PASSED\"", ")", "\n", "\n", "", "results", ".", "append", "(", "tmp_result", ")", "\n", "\n", "if", "debug", ":", "\n", "                    ", "nl", "=", "\"\\n\"", "\n", "if", "not", "isinstance", "(", "inputs", ",", "list", ")", ":", "\n", "                        ", "print", "(", "f\"output = {output}, test outputs = {in_outs['outputs'][index]}, inputs = {inputs.replace(nl,' new-line ')}, {type(inputs)}, {output == [in_outs['outputs'][index]]}\"", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "f\"output = {output}, test outputs = {in_outs['outputs'][index]}, inputs = {inputs}, {type(inputs)}, {output == [in_outs['outputs'][index]]}\"", ")", "\n", "\n", "\n", "", "", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.custom_compare_": [[470, 484], ["isinstance", "isinstance", "testing_util.stripped_string_compare", "testing_util.stripped_string_compare", "o.lstrip().rstrip", "o.lstrip"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.stripped_string_compare", "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.stripped_string_compare"], ["", "def", "custom_compare_", "(", "output", ",", "ground_truth", ")", ":", "\n", "\n", "    ", "if", "isinstance", "(", "output", ",", "list", ")", ":", "\n", "        ", "output_1", "=", "\"\\n\"", ".", "join", "(", "output", ")", "\n", "if", "stripped_string_compare", "(", "output_1", ",", "ground_truth", ")", ":", "\n", "            ", "return", "True", "\n", "\n", "", "", "if", "isinstance", "(", "output", ",", "list", ")", ":", "\n", "        ", "output_2", "=", "[", "o", ".", "lstrip", "(", ")", ".", "rstrip", "(", ")", "for", "o", "in", "output", "]", "\n", "output_2", "=", "\"\\n\"", ".", "join", "(", "output_2", ")", "\n", "if", "stripped_string_compare", "(", "output_2", ",", "ground_truth", ")", ":", "\n", "            ", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.stripped_string_compare": [[485, 489], ["s1.lstrip().rstrip.lstrip().rstrip", "s2.lstrip().rstrip.lstrip().rstrip", "s1.lstrip().rstrip.lstrip", "s2.lstrip().rstrip.lstrip"], "function", ["None"], ["", "def", "stripped_string_compare", "(", "s1", ",", "s2", ")", ":", "\n", "    ", "s1", "=", "s1", ".", "lstrip", "(", ")", ".", "rstrip", "(", ")", "\n", "s2", "=", "s2", ".", "lstrip", "(", ")", ".", "rstrip", "(", ")", "\n", "return", "s1", "==", "s2", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.call_method": [[490, 514], ["isinstance", "iter", "unittest.mock.patch", "unittest.mock.patch", "unittest.mock.patch", "unittest.mock.patch", "unittest.mock.patch", "testing_util.call_method._inner_call_method"], "function", ["None"], ["", "def", "call_method", "(", "method", ",", "inputs", ")", ":", "\n", "\n", "    ", "if", "isinstance", "(", "inputs", ",", "list", ")", ":", "\n", "        ", "inputs", "=", "\"\\n\"", ".", "join", "(", "inputs", ")", "\n", "\n", "", "inputs_line_iterator", "=", "iter", "(", "inputs", ".", "split", "(", "\"\\n\"", ")", ")", "\n", "\n", "# sys.setrecursionlimit(10000)", "\n", "\n", "# @patch('builtins.input', side_effect=inputs.split(\"\\n\"))", "\n", "@", "patch", "(", "'builtins.open'", ",", "mock_open", "(", "read_data", "=", "inputs", ")", ")", "\n", "@", "patch", "(", "'sys.stdin'", ",", "StringIO", "(", "inputs", ")", ")", "\n", "@", "patch", "(", "'sys.stdin.readline'", ",", "lambda", "*", "args", ":", "next", "(", "inputs_line_iterator", ")", ")", "\n", "@", "patch", "(", "'sys.stdin.readlines'", ",", "lambda", "*", "args", ":", "inputs", ".", "split", "(", "\"\\n\"", ")", ")", "\n", "@", "patch", "(", "'sys.stdin.read'", ",", "lambda", "*", "args", ":", "inputs", ")", "\n", "# @patch('sys.stdout.write', print)", "\n", "def", "_inner_call_method", "(", "_method", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "_method", "(", ")", "\n", "", "except", "SystemExit", "as", "e", ":", "\n", "            ", "pass", "\n", "", "finally", ":", "\n", "            ", "pass", "\n", "", "", "return", "_inner_call_method", "(", "method", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.main": [[515, 541], ["print", "sorted", "print", "print", "testing_util.get_valid_problems", "len", "testing_util.get_question", "print", "testing_util.get_solutions", "print", "len", "get_starter", "print", "testing_util.get_solutions", "testing_util.run_test", "print", "print"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.get_valid_problems", "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.get_question", "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.get_solutions", "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.get_solutions", "home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.run_test"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "print", "(", "args", ")", "\n", "problem_list", "=", "sorted", "(", "get_valid_problems", "(", "args", ".", "source", ")", ")", "\n", "print", "(", "f\"number of problems = {len(problem_list)}\"", ")", "\n", "prob_index", "=", "args", ".", "number", "\n", "print", "(", "f\"problem is {problem_list[prob_index]}\"", ")", "\n", "\n", "# This checks it correctly loaded. remove this later", "\n", "assert", "prob_index", "<", "len", "(", "problem_list", ")", "\n", "\n", "if", "args", ".", "data", "==", "\"q\"", "or", "args", ".", "data", "==", "\"question\"", ":", "\n", "        ", "tmp", "=", "get_question", "(", "problem_list", ",", "prob_index", ")", "\n", "print", "(", "\"q\"", ",", "tmp", ")", "\n", "", "elif", "args", ".", "data", "in", "[", "\"solutions\"", ",", "\"sol\"", ",", "\"s\"", ",", "]", ":", "\n", "        ", "tmp", "=", "get_solutions", "(", "problem_list", ",", "prob_index", ")", "\n", "print", "(", "\"sol\"", ",", "tmp", ")", "\n", "", "elif", "args", ".", "data", "==", "\"starter\"", ":", "\n", "        ", "tmp", "=", "get_starter", "(", "problem_list", ",", "prob_index", ")", "\n", "print", "(", "\"starter\"", ",", "tmp", ")", "\n", "", "elif", "args", ".", "data", "in", "[", "\"test\"", ",", "\"t\"", "]", ":", "\n", "# test it with sols", "\n", "        ", "sols", "=", "get_solutions", "(", "problem_list", ",", "prob_index", ")", "\n", "tmp", "=", "run_test", "(", "problem_list", ",", "prob_index", ",", "test", "=", "sols", "[", "0", "]", ")", "\n", "\n", "print", "(", "\"results = \"", ",", "tmp", ")", "\n", "print", "(", "\"-2 = compile error, -1 is runtime error, False failed test, True passed test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.eval_bleu.calc_bleu": [[28, 36], ["sacrebleu.corpus_bleu", "sacrebleu.corpus_bleu"], "function", ["None"], ["def", "calc_bleu", "(", "output", ":", "List", "[", "str", "]", ",", "targets", ":", "List", "[", "List", "[", "str", "]", "]", ")", ":", "\n", "    ", "max_bleu", "=", "0", "\n", "bleu", "=", "sacrebleu", ".", "corpus_bleu", "(", "output", ",", "targets", ")", "\n", "for", "item", "in", "targets", "[", "0", "]", ":", "\n", "        ", "tmp_bleu", "=", "sacrebleu", ".", "corpus_bleu", "(", "output", ",", "[", "[", "item", "]", "]", ")", "\n", "if", "tmp_bleu", ".", "score", ">", "max_bleu", ":", "\n", "            ", "max_bleu", "=", "tmp_bleu", ".", "score", "\n", "", "", "return", "bleu", ".", "score", ",", "max_bleu", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.eval_bleu.eval_and_save_bleu_scores": [[37, 114], ["os.path.join", "os.path.exists", "enumerate", "open", "json.load", "os.path.exists", "os.path.join", "tqdm.tqdm", "os.path.join", "random.shuffle", "isinstance", "open", "json.load", "print", "len", "print", "print", "open", "json.load", "tmp.append", "eval_bleu.calc_bleu", "os.path.exists", "os.makedirs", "os.path.join", "open", "json.dump", "len", "len", "os.path.join", "gpt_bleu[].extend", "os.path.join", "os.path.join", "str", "eval_bleu.calc_bleu", "len"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.eval.eval_bleu.calc_bleu", "home.repos.pwc.inspect_result.hendrycks_apps.eval.eval_bleu.calc_bleu"], ["", "def", "eval_and_save_bleu_scores", "(", "args", ")", ":", "\n", "    ", "with", "open", "(", "args", ".", "test_loc", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "problems", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "gpt_codes", "=", "{", "}", "\n", "gpt_bleu", "=", "{", "}", "\n", "codes_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"all_codes.json\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "codes_loc", ")", ":", "\n", "        ", "codes_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"{args.start}-{args.end}_codes.json\"", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "codes_loc", ")", ":", "\n", "        ", "with", "open", "(", "codes_loc", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "gpt_codes", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "", "if", "args", ".", "index", ":", "\n", "        ", "problems", "=", "[", "problems", "[", "args", ".", "index", "]", "]", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "start", ">", "len", "(", "problems", ")", "or", "args", ".", "start", "<", "0", ":", "\n", "            ", "print", "(", "f\"start index {args.start} > number of problems {len(problems)}\"", ")", "\n", "return", "\n", "", "start", "=", "args", ".", "start", "\n", "if", "args", ".", "end", "is", "None", "or", "args", ".", "end", ">", "len", "(", "problems", ")", ":", "\n", "            ", "end", "=", "len", "(", "problems", ")", "\n", "", "else", ":", "\n", "            ", "end", "=", "args", ".", "end", "\n", "", "problems", "=", "problems", "[", "start", ":", "end", "]", "\n", "\n", "# main eval loop", "\n", "", "for", "index", ",", "problem", "in", "enumerate", "(", "tqdm", "(", "problems", ")", ")", ":", "\n", "        ", "prob_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "problem", ")", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "print", "(", "f\"problem path = {problem}\"", ")", "\n", "", "try", ":", "\n", "            ", "output_strs", "=", "gpt_codes", "[", "str", "(", "index", "+", "args", ".", "start", ")", "]", "\n", "", "except", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "args", ".", "debug", ":", "\n", "            ", "print", "(", "output_str", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "prob_path", ",", "\"solutions.json\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "sols", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "random", ".", "shuffle", "(", "sols", ")", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "sols", "=", "sols", "[", ":", "100", "]", "\n", "\n", "", "tmp", "=", "[", "]", "\n", "for", "sol", "in", "sols", ":", "\n", "            ", "tmp", ".", "append", "(", "[", "sol", "]", ")", "\n", "\n", "", "sols", "=", "tmp", "\n", "\n", "# this is if we generated multiple outputs per problem", "\n", "if", "isinstance", "(", "output_strs", ",", "list", ")", ":", "\n", "            ", "gpt_bleu", "[", "index", "+", "args", ".", "start", "]", "=", "[", "]", "\n", "for", "output_str", "in", "output_strs", ":", "\n", "                ", "gpt_bleu", "[", "index", "+", "args", ".", "start", "]", ".", "extend", "(", "calc_bleu", "(", "[", "output_str", "]", ",", "sols", ")", ")", "\n", "# one output per problem", "\n", "", "", "else", ":", "\n", "            ", "output_str", "=", "output_strs", "\n", "gpt_bleu", "[", "index", "+", "args", ".", "start", "]", "=", "calc_bleu", "(", "[", "output_str", "]", ",", "sols", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "save", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "save", ")", "\n", "\n", "", "if", "args", ".", "end", "is", "None", "and", "args", ".", "index", "is", "None", ":", "\n", "            ", "bleu_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"all_bleu_results.json\"", ")", "\n", "", "elif", "args", ".", "index", ":", "\n", "            ", "bleu_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"{args.index}_bleu_results.json\"", ")", "\n", "", "else", ":", "\n", "            ", "bleu_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"{args.start}-{args.end}_bleu_results.json\"", ")", "\n", "\n", "", "with", "open", "(", "bleu_loc", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "gpt_bleu", ",", "f", ")", "\n", "\n", "", "", "return", "gpt_bleu", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.eval_bleu.print_results": [[115, 124], ["print", "print", "bleu_scores.append", "max_bleu_scores.append", "numpy.mean", "numpy.mean"], "function", ["None"], ["", "def", "print_results", "(", "results", ")", ":", "\n", "    ", "bleu_scores", "=", "[", "]", "\n", "max_bleu_scores", "=", "[", "]", "\n", "for", "res", "in", "results", ":", "\n", "        ", "bleu_scores", ".", "append", "(", "results", "[", "res", "]", "[", "0", "]", ")", "\n", "max_bleu_scores", ".", "append", "(", "results", "[", "res", "]", "[", "1", "]", ")", "\n", "\n", "", "print", "(", "f\"Average BLEU Score = {np.mean(bleu_scores)}\"", ")", "\n", "print", "(", "f\"Average of Max BLEU Score = {np.mean(max_bleu_scores)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.eval_bleu.main": [[126, 143], ["vars", "print", "eval_bleu.print_results", "pprint.pformat", "os.path.join", "os.path.exists", "eval_bleu.eval_and_save_bleu_scores", "print", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.eval.test_one_solution.print_results", "home.repos.pwc.inspect_result.hendrycks_apps.eval.eval_bleu.eval_and_save_bleu_scores"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "argsdict", "=", "vars", "(", "args", ")", "\n", "print", "(", "pprint", ".", "pformat", "(", "argsdict", ")", ")", "\n", "\n", "if", "args", ".", "print_results", ":", "\n", "        ", "bleu_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"all_bleu_results.json\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "bleu_loc", ")", ":", "\n", "            ", "with", "open", "(", "bleu_loc", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "results", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "f\"Error file does not exist in this path {bleu_loc}. Exiting.\"", ")", "\n", "return", "\n", "", "", "else", ":", "\n", "        ", "results", "=", "eval_and_save_bleu_scores", "(", "args", ")", "\n", "\n", "", "print_results", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.test_one_solution.print_results": [[22, 53], ["len", "len", "len", "print", "print", "numpy.asarray", "res.extend", "per_prob_res.append", "all_correct.append", "print", "print", "print", "numpy.mean", "numpy.all", "numpy.mean", "numpy.mean"], "function", ["None"], ["def", "print_results", "(", "results", ":", "Dict", ",", "args", ":", "argparse", ".", "Namespace", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given the results evaluated against the testcases we output some statistics.\n\n    >>> print_results(EXAMPLE_RESULTS, EXAMPLE_ARGS)\n    number of compile errors = 1 avg = 0.2\n    number of runtime errors = 1 avg = 0.2\n    number of test cases run = 5\n    Test Case Average (average accuracy over problems) = 0.3\n    Strict Accuracy (all test cases passed / total problems) = 0.2\n    \"\"\"", "\n", "res", "=", "[", "]", "\n", "per_prob_res", "=", "[", "]", "\n", "all_correct", "=", "[", "]", "\n", "for", "index", "in", "results", ":", "\n", "        ", "problem_results", "=", "np", ".", "asarray", "(", "results", "[", "index", "]", ")", "\n", "res", ".", "extend", "(", "problem_results", ")", "\n", "per_prob_res", ".", "append", "(", "np", ".", "mean", "(", "problem_results", ">", "0", ")", ")", "\n", "all_correct", ".", "append", "(", "np", ".", "all", "(", "problem_results", ">", "0", ")", ")", "\n", "\n", "# We count both compile errors and runtime errors for multiple tests as one error.", "\n", "", "compile_errors", "=", "len", "(", "[", "e", "for", "e", "in", "res", "if", "-", "2", "in", "e", "]", ")", "\n", "runtime_errors", "=", "len", "(", "[", "e", "for", "e", "in", "res", "if", "-", "1", "in", "e", "]", ")", "\n", "total_testcases", "=", "len", "(", "res", ")", "\n", "if", "args", "and", "args", ".", "debug", ":", "\n", "        ", "print", "(", "f\"number of compile errors = {compile_errors} avg = {compile_errors / total_testcases }\"", ")", "\n", "print", "(", "f\"number of runtime errors = {runtime_errors} avg = {runtime_errors / total_testcases}\"", ")", "\n", "print", "(", "f\"number of test cases run = {total_testcases}\"", ")", "\n", "\n", "", "print", "(", "f\"Test Case Average (average accuracy over problems) = {np.mean(per_prob_res)}\"", ")", "\n", "print", "(", "f\"Strict Accuracy (all test cases passed / total problems) = {np.mean(all_correct)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.test_one_solution.eval_and_save_problems": [[55, 148], ["print", "os.path.join", "os.path.exists", "print", "enumerate", "open", "sorted", "len", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "open", "json.load", "tqdm.tqdm", "os.path.join", "enumerate", "json.load", "print", "len", "open", "json.load", "os.path.exists", "os.makedirs", "print", "open", "len", "len", "print", "print", "os.path.join", "print", "testing_util.run_test", "isinstance", "res.append", "f.write", "str", "isinstance", "isinstance", "fixed.append", "numpy.all", "print", "print", "json.dumps", "pdb.set_trace", "print", "len", "bool.item", "bool", "repr"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.eval.testing_util.run_test"], ["", "def", "eval_and_save_problems", "(", "args", ")", ":", "\n", "    ", "with", "open", "(", "args", ".", "test_loc", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "problems", "=", "sorted", "(", "json", ".", "load", "(", "f", ")", ")", "\n", "\n", "", "print", "(", "len", "(", "problems", ")", ")", "\n", "gpt_codes", "=", "{", "}", "\n", "gpt_bleu", "=", "{", "}", "\n", "gpt_codebleu", "=", "{", "}", "\n", "results", "=", "{", "}", "\n", "codes_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"all_codes.json\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "codes_loc", ")", ":", "\n", "        ", "codes_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"{args.start}-{args.end}_codes.json\"", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "codes_loc", ")", ":", "\n", "        ", "results_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"all_results.json\"", ")", "\n", "", "else", ":", "\n", "        ", "results_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"{args.start}-{args.end}_results.json\"", ")", "\n", "", "print", "(", "codes_loc", ",", "results_loc", ")", "\n", "\n", "with", "open", "(", "codes_loc", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "gpt_codes", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "args", ".", "index", ":", "\n", "        ", "problems", "=", "[", "problems", "[", "args", ".", "index", "]", "]", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "start", ">", "len", "(", "problems", ")", "or", "args", ".", "start", "<", "0", ":", "\n", "            ", "print", "(", "f\"start index {args.start} > number of problems {len(problems)}\"", ")", "\n", "return", "\n", "", "start", "=", "args", ".", "start", "\n", "if", "args", ".", "end", "is", "None", "or", "args", ".", "end", ">", "len", "(", "problems", ")", ":", "\n", "            ", "end", "=", "len", "(", "problems", ")", "\n", "", "else", ":", "\n", "            ", "end", "=", "args", ".", "end", "\n", "", "problems", "=", "problems", "[", "start", ":", "end", "]", "\n", "\n", "", "if", "args", ".", "stop_early", ":", "\n", "        ", "problems", "=", "problems", "[", ":", "args", ".", "stop_early", "]", "\n", "\n", "# main eval loop", "\n", "", "for", "index", ",", "problem", "in", "enumerate", "(", "tqdm", "(", "problems", ")", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "if", "args", ".", "debug", ":", "\n", "                ", "print", "(", "f\"\\n\\nproblem path = {problem}\"", ")", "\n", "", "output_str", "=", "gpt_codes", "[", "str", "(", "index", "+", "args", ".", "start", ")", "]", "\n", "", "except", ":", "\n", "            ", "print", "(", "\"CANNOT FIND OUTPUT_STR FOR\"", ",", "problem", ")", "\n", "continue", "\n", "", "prob_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "problem", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "prob_path", ",", "\"solutions.json\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "sols", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "save", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "save", ")", "\n", "\n", "", "res", "=", "[", "]", "\n", "for", "o_idx", ",", "o", "in", "enumerate", "(", "output_str", ")", ":", "\n", "            ", "if", "args", ".", "debug", ":", "\n", "                ", "print", "(", "f\"\\nTesting solution {o_idx}\"", ")", "\n", "", "curr_res", "=", "[", "-", "2", "]", "\n", "try", ":", "\n", "                ", "curr_res", "=", "test_util", ".", "run_test", "(", "prob_path", "=", "prob_path", ",", "test", "=", "o", ",", "debug", "=", "args", ".", "debug", ")", "\n", "fixed", "=", "[", "]", "\n", "for", "e", "in", "curr_res", ":", "\n", "                    ", "if", "isinstance", "(", "e", ",", "np", ".", "ndarray", ")", ":", "\n", "                       ", "e", "=", "e", ".", "item", "(", "0", ")", "\n", "", "if", "isinstance", "(", "e", ",", "np", ".", "bool_", ")", ":", "\n", "                        ", "e", "=", "bool", "(", "e", ")", "\n", "", "fixed", ".", "append", "(", "e", ")", "\n", "", "curr_res", "=", "fixed", "\n", "if", "not", "np", ".", "all", "(", "curr_res", ")", ":", "\n", "                    ", "print", "(", "f\"Results were not all True: {curr_res}\"", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "f\"test framework exception = {repr(e)}{e}\\n\"", ")", "\n", "break", "\n", "", "finally", ":", "\n", "                ", "assert", "isinstance", "(", "curr_res", ",", "list", ")", "\n", "res", ".", "append", "(", "curr_res", ")", "\n", "\n", "", "", "if", "args", ".", "debug", ":", "\n", "            ", "print", "(", "f\"\\nHow to read results [-2] = compile error, [-1] = runtime error [False] = failed test case [True] = passed test case\"", ")", "\n", "#print(f\"results = {res}\")", "\n", "\n", "", "results", "[", "index", "+", "args", ".", "start", "+", "args", ".", "index", "]", "=", "res", "\n", "\n", "with", "open", "(", "results_loc", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "try", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "results", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "print", "(", "\"didn't save problem due to {e}\"", ")", "\n", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.test_one_solution.main": [[150, 168], ["vars", "print", "test_one_solution.print_results", "pprint.pformat", "os.path.join", "os.path.exists", "test_one_solution.eval_and_save_problems", "os.path.join", "os.path.join", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.eval.test_one_solution.print_results", "home.repos.pwc.inspect_result.hendrycks_apps.eval.test_one_solution.eval_and_save_problems"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "argsdict", "=", "vars", "(", "args", ")", "\n", "print", "(", "pprint", ".", "pformat", "(", "argsdict", ")", ")", "\n", "\n", "if", "args", ".", "print_results", ":", "\n", "        ", "results", "=", "{", "}", "\n", "codes_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"all_codes.json\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "codes_loc", ")", ":", "\n", "            ", "results_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"all_results.json\"", ")", "\n", "", "else", ":", "\n", "            ", "results_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"{args.start}-{args.end}_results.json\"", ")", "\n", "", "with", "open", "(", "results_loc", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "results", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "results", "=", "eval_and_save_problems", "(", "args", ")", "\n", "\n", "", "print_results", "(", "results", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.reindent._find_indentation": [[15, 26], ["len", "list", "line.isspace"], "function", ["None"], ["def", "_find_indentation", "(", "line", ",", "config", ")", ":", "\n", "    ", "if", "len", "(", "line", ")", "and", "line", "[", "0", "]", "in", "(", "\" \"", ",", "\"\\t\"", ")", "and", "not", "line", ".", "isspace", "(", ")", ":", "\n", "        ", "if", "line", "[", "0", "]", "==", "\"\\t\"", ":", "\n", "            ", "config", "[", "'is-tabs'", "]", "=", "True", "\n", "# Find indentation", "\n", "", "i", "=", "0", "\n", "for", "char", "in", "list", "(", "line", ")", ":", "\n", "            ", "if", "char", "not", "in", "(", "\" \"", ",", "\"\\t\"", ")", ":", "\n", "                ", "break", "\n", "", "i", "+=", "1", "\n", "", "config", "[", "\"from\"", "]", "=", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.reindent.find_indentation": [[28, 47], ["reindent._find_indentation"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent._find_indentation"], ["", "", "def", "find_indentation", "(", "line", ",", "config", ")", ":", "\n", "# Find indentation level used in file", "\n", "    ", "if", "config", "[", "'from'", "]", "<", "0", ":", "\n", "        ", "_find_indentation", "(", "line", ",", "config", ")", "\n", "\n", "", "if", "config", "[", "'from'", "]", ">=", "0", ":", "\n", "# Set old indent", "\n", "        ", "indent", "=", "\" \"", "if", "not", "config", "[", "'is-tabs'", "]", "else", "\"\\t\"", "\n", "indent", "=", "indent", "*", "config", "[", "'from'", "]", "\n", "\n", "# Set new indent", "\n", "newindent", "=", "\" \"", "if", "not", "config", "[", "'tabs'", "]", "else", "\"\\t\"", "\n", "if", "not", "config", "[", "'tabs'", "]", ":", "\n", "            ", "newindent", "=", "newindent", "*", "config", "[", "'to'", "]", "\n", "\n", "", "return", "indent", ",", "newindent", "\n", "\n", "# Continue to the next line, indentation not found", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.reindent.replace_inline_tabs": [[49, 62], ["range", "len"], "function", ["None"], ["", "def", "replace_inline_tabs", "(", "content", ",", "config", ")", ":", "\n", "    ", "newcontent", "=", "\"\"", "\n", "imagined_i", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "content", ")", ")", ":", "\n", "        ", "char", "=", "content", "[", "i", "]", "\n", "if", "char", "==", "'\\t'", ":", "\n", "            ", "spaces", "=", "config", "[", "'tabsize'", "]", "-", "(", "imagined_i", "%", "config", "[", "'tabsize'", "]", ")", "\n", "newcontent", "+=", "\" \"", "*", "spaces", "\n", "imagined_i", "+=", "spaces", "\n", "", "else", ":", "\n", "            ", "newcontent", "+=", "char", "\n", "imagined_i", "+=", "1", "\n", "", "", "return", "newcontent", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.reindent.run": [[64, 94], ["fd_in.readline", "line.rstrip.rstrip", "print", "reindent.find_indentation", "reindent.replace_inline_tabs", "print", "len", "len", "sys.stdin", "sys.stdout"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.find_indentation", "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.replace_inline_tabs"], ["", "def", "run", "(", "fd_in", ",", "fd_out", ",", "config", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "line", "=", "fd_in", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "            ", "break", "\n", "", "line", "=", "line", ".", "rstrip", "(", "'\\r\\n'", ")", "\n", "\n", "# Find indentation style used in file if not set", "\n", "if", "config", "[", "'from'", "]", "<", "0", ":", "\n", "            ", "indent", "=", "find_indentation", "(", "line", ",", "config", ")", "\n", "if", "not", "indent", ":", "\n", "                ", "print", "(", "line", ",", "file", "=", "fd_out", ")", "\n", "continue", "\n", "", "indent", ",", "newindent", "=", "indent", "\n", "\n", "# Find current indentation level", "\n", "", "level", "=", "0", "\n", "while", "True", ":", "\n", "            ", "whitespace", "=", "line", "[", ":", "len", "(", "indent", ")", "*", "(", "level", "+", "1", ")", "]", "\n", "if", "whitespace", "==", "indent", "*", "(", "level", "+", "1", ")", ":", "\n", "                ", "level", "+=", "1", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "", "content", "=", "line", "[", "len", "(", "indent", ")", "*", "level", ":", "]", "\n", "if", "config", "[", "'all-tabs'", "]", ":", "\n", "            ", "content", "=", "replace_inline_tabs", "(", "content", ",", "config", ")", "\n", "\n", "", "line", "=", "(", "newindent", "*", "level", ")", "+", "content", "\n", "print", "(", "line", ",", "file", "=", "fd_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.reindent.run_files": [[96, 113], ["codecs.open", "reindent.run", "print", "tempfile.NamedTemporaryFile", "codecs.open.close", "codecs.open", "codecs.open.close", "shutil.copy", "os.remove"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.run"], ["", "", "def", "run_files", "(", "filenames", ",", "config", ")", ":", "\n", "    ", "for", "filename", "in", "filenames", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "filename", ",", "encoding", "=", "config", "[", "'encoding'", "]", ")", "as", "fd_in", ":", "\n", "            ", "if", "config", "[", "'dry-run'", "]", ":", "\n", "                ", "print", "(", "\"Filename: %s\"", "%", "filename", ")", "\n", "fd_out", "=", "sys", ".", "stdout", "\n", "", "else", ":", "\n", "                ", "fd_out", "=", "tempfile", ".", "NamedTemporaryFile", "(", "mode", "=", "'wb'", ",", "delete", "=", "False", ")", "\n", "fd_out", ".", "close", "(", ")", "\n", "fd_out", "=", "codecs", ".", "open", "(", "fd_out", ".", "name", ",", "\"wb\"", ",", "encoding", "=", "config", "[", "'encoding'", "]", ")", "\n", "\n", "", "run", "(", "fd_in", ",", "fd_out", ",", "config", ")", "\n", "\n", "if", "not", "config", "[", "\"dry-run\"", "]", ":", "\n", "                ", "fd_out", ".", "close", "(", ")", "\n", "shutil", ".", "copy", "(", "fd_out", ".", "name", ",", "filename", ")", "\n", "os", ".", "remove", "(", "fd_out", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.reindent.main": [[115, 192], ["getopt.getopt", "possible_args.values", "shortargs.append", "longargs.append", "opt.lstrip.lstrip", "isinstance", "print", "sys.exit", "reindent.run_files", "reindent.run", "possible_args.keys", "shortarg.rstrip", "possible_args[].rstrip", "isinstance", "int", "shortargs.index", "help[].split"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.run_files", "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.run"], ["", "", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "config", "=", "{", "\n", "\"dry-run\"", ":", "False", ",", "\n", "\"help\"", ":", "False", ",", "\n", "\"to\"", ":", "4", ",", "\n", "\"from\"", ":", "-", "1", ",", "\n", "\"tabs\"", ":", "False", ",", "\n", "\"encoding\"", ":", "\"utf-8\"", ",", "\n", "\"is-tabs\"", ":", "False", ",", "\n", "\"tabsize\"", ":", "4", ",", "\n", "\"all-tabs\"", ":", "False", "\n", "}", "\n", "possible_args", "=", "{", "\n", "\"d\"", ":", "\"dry-run\"", ",", "\n", "\"h\"", ":", "\"help\"", ",", "\n", "\"t:\"", ":", "\"to=\"", ",", "\n", "\"f:\"", ":", "\"from=\"", ",", "\n", "\"n\"", ":", "\"tabs\"", ",", "\n", "\"e:\"", ":", "\"encoding=\"", ",", "\n", "\"s:\"", ":", "\"tabsize=\"", ",", "\n", "\"a\"", ":", "\"all-tabs\"", ",", "\n", "}", "\n", "optlist", ",", "filenames", "=", "getopt", ".", "getopt", "(", "\n", "args", "[", "1", ":", "]", ",", "\n", "\"\"", ".", "join", "(", "possible_args", ".", "keys", "(", ")", ")", ",", "\n", "possible_args", ".", "values", "(", ")", "\n", ")", "\n", "\n", "shortargs", ",", "longargs", "=", "[", "]", ",", "[", "]", "\n", "for", "shortarg", "in", "possible_args", ":", "\n", "        ", "shortargs", ".", "append", "(", "shortarg", ".", "rstrip", "(", "\":\"", ")", ")", "\n", "longargs", ".", "append", "(", "possible_args", "[", "shortarg", "]", ".", "rstrip", "(", "\"=\"", ")", ")", "\n", "\n", "", "for", "opt", ",", "val", "in", "optlist", ":", "\n", "        ", "opt", "=", "opt", ".", "lstrip", "(", "\"-\"", ")", "\n", "if", "opt", "in", "shortargs", ":", "\n", "            ", "opt", "=", "longargs", "[", "shortargs", ".", "index", "(", "opt", ")", "]", "\n", "", "if", "isinstance", "(", "config", "[", "opt", "]", ",", "bool", ")", ":", "\n", "            ", "config", "[", "opt", "]", "=", "True", "\n", "", "elif", "isinstance", "(", "config", "[", "opt", "]", ",", "int", ")", ":", "\n", "            ", "config", "[", "opt", "]", "=", "int", "(", "val", ")", "\n", "", "else", ":", "\n", "            ", "config", "[", "opt", "]", "=", "val", "\n", "\n", "", "", "if", "config", "[", "'help'", "]", ":", "\n", "        ", "help", "=", "\"\"\"\n        Usage: %s [options] filename(s)\n        Options:\n            -h, --help              Show this message\n            -d, --dry-run           Don't save anything, just print\n                                    the result\n            -t <n>, --to <n>        Convert to this number of spaces\n                                    (default: 4)\n            -f <n>, --from <n>      Convert from this number of spaces\n                                    (default: auto-detect, will also\n                                    detect tabs)\n            -n, --tabs              Don't convert indentation to spaces,\n                                    convert to tabs instead. -t and\n                                    --to will have no effect.\n            -a, --all-tabs          Also convert tabs used for alignment\n                                    in the code (Warning: will replace\n                                    all tabs in the file, even if inside\n                                    a string)\n            -s <n>, --tabsize <n>   Set how many spaces one tab is\n                                    (only has an effect on -a, default: 4)\n            -e <s>, --encoding <s>  Open files with specified encoding\n                                    (default: utf-8)\n        \"\"\"", "%", "args", "[", "0", "]", "\n", "\n", "# Also removes 8 leading spaces to remove our indentation", "\n", "print", "(", "\"\\n\"", ".", "join", "(", "[", "x", "[", "8", ":", "]", "for", "x", "in", "help", "[", "1", ":", "]", ".", "split", "(", "\"\\n\"", ")", "]", ")", ")", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "\n", "", "if", "filenames", ":", "\n", "        ", "run_files", "(", "filenames", ",", "config", ")", "\n", "", "else", ":", "\n", "        ", "run", "(", "sys", ".", "stdin", ",", "sys", ".", "stdout", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.generate_gpt_codes.reindent_code": [[25, 50], ["io.StringIO", "io.StringIO", "reindent.run", "io.StringIO.getvalue"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.run"], ["def", "reindent_code", "(", "codestr", ")", ":", "\n", "    ", "\"\"\"\n    Given code string, reindent it in the same way that the\n    Github dataset was indented\n    \"\"\"", "\n", "codestr", "=", "io", ".", "StringIO", "(", "codestr", ")", "\n", "ret", "=", "io", ".", "StringIO", "(", ")", "\n", "\n", "run_reindent", "(", "\n", "codestr", ",", "\n", "ret", ",", "\n", "config", "=", "{", "\n", "\"dry-run\"", ":", "False", ",", "\n", "\"help\"", ":", "False", ",", "\n", "\"to\"", ":", "10", ",", "\n", "\"from\"", ":", "-", "1", ",", "\n", "\"tabs\"", ":", "True", ",", "\n", "\"encoding\"", ":", "\"utf-8\"", ",", "\n", "\"is-tabs\"", ":", "False", ",", "\n", "\"tabsize\"", ":", "10", ",", "\n", "\"all-tabs\"", ":", "False", "\n", "}", "\n", ")", "\n", "\n", "return", "ret", ".", "getvalue", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.generate_gpt_codes.generate_prompt": [[51, 104], ["open", "f.readlines", "open", "json.load", "f.readlines.get", "random.choice", "generate_gpt_codes.reindent_code", "tokenizer.encode", "int", "tokenizer.decode", "open", "f.readlines", "open", "json.load", "len"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.reindent_code"], ["", "def", "generate_prompt", "(", "args", ",", "test_case_path", ",", "prompt_path", ",", "solutions_path", ",", "tokenizer", ",", "starter_path", "=", "None", ")", ":", "\n", "    ", "_input", "=", "\"\\nQUESTION:\\n\"", "\n", "with", "open", "(", "prompt_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "data", "=", "f", ".", "readlines", "(", ")", "\n", "data", "=", "\"\"", ".", "join", "(", "data", ")", "\n", "", "_input", "+=", "data", "\n", "if", "starter_path", "!=", "None", ":", "\n", "        ", "with", "open", "(", "starter_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "data", "=", "f", ".", "readlines", "(", ")", "\n", "data", "=", "\"\"", ".", "join", "(", "data", ")", "\n", "data", "=", "\"\\n\"", "+", "data", "#+ \"\\n\"", "\n", "", "_input", "+=", "data", "\n", "", "else", ":", "\n", "#_input += \"\\n\\n\"", "\n", "        ", "pass", "\n", "\n", "", "with", "open", "(", "test_case_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "if", "not", "data", ".", "get", "(", "\"fn_name\"", ")", ":", "\n", "        ", "_input", "+=", "\"\\nUse Standard Input format\"", "#\\n\"", "\n", "", "else", ":", "\n", "        ", "_input", "+=", "\"\\nUse Call-Based format\"", "#\\n\"", "\n", "\n", "", "_input", "+=", "\"\\nANSWER:\\n\"", "\n", "\n", "if", "args", ".", "peeking", ">", "0.0", ":", "\n", "# Need to do some peeking. ", "\n", "\n", "# Read one example solution", "\n", "        ", "with", "open", "(", "solutions_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "sols", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "# Choose the shortest solution for the model to use.", "\n", "# This is so we can conserve tokens (1024 max)", "\n", "# sample_sol = min(sols, key=len)", "\n", "\n", "# # Add args.peeking% of that solution to the prompt", "\n", "# sample_sol_token_ids = tokenizer.encode(sample_sol, verbose=False)", "\n", "# num_to_keep = int(len(sample_sol_token_ids) * args.peeking)", "\n", "# sample_sol_token_ids = sample_sol_token_ids[:num_to_keep]", "\n", "# _input += tokenizer.decode(sample_sol_token_ids)", "\n", "\n", "# Alternatively take a random solution", "\n", "", "sample_sol", "=", "random", ".", "choice", "(", "sols", ")", "\n", "rand_sol", "=", "reindent_code", "(", "sample_sol", ")", "\n", "rand_sol", "=", "tokenizer", ".", "encode", "(", "rand_sol", ",", "verbose", "=", "False", ")", "\n", "tokens_taken", "=", "int", "(", "args", ".", "peek_frac", "*", "len", "(", "rand_sol", ")", ")", "\n", "rand_sol", "=", "rand_sol", "[", ":", "tokens_taken", "]", "\n", "_input", "+=", "tokenizer", ".", "decode", "(", "rand_sol", ")", "\n", "", "else", ":", "\n", "        ", "sample_sol", "=", "None", "\n", "\n", "", "return", "_input", ",", "sample_sol", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.eval.generate_gpt_codes.main": [[106, 208], ["vars", "print", "sorted", "transformers.GPT2Tokenizer.from_pretrained", "print", "transformers.GPT2LMHeadModel.from_pretrained", "transformers.GPT2LMHeadModel.from_pretrained.cuda", "print", "enumerate", "pprint.pformat", "open", "json.load", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "tqdm.tqdm", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "generate_gpt_codes.generate_prompt", "time.time", "time.time", "open", "json.dump", "print", "len", "print", "os.path.exists", "print", "print", "len", "print", "print", "print", "print", "len", "len", "os.path.exists", "os.path.exists", "torch.no_grad", "torch.LongTensor().unsqueeze().cuda", "transformers.GPT2LMHeadModel.from_pretrained.generate", "transformers.GPT2Tokenizer.from_pretrained.decode", "[].replace", "isinstance", "print", "print", "len", "torch.LongTensor().unsqueeze", "str", "print", "print", "len", "[].replace.split", "torch.LongTensor", "transformers.GPT2Tokenizer.from_pretrained.encode"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.eval.generate_gpt_codes.generate_prompt"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "argsdict", "=", "vars", "(", "args", ")", "\n", "print", "(", "pprint", ".", "pformat", "(", "argsdict", ")", ")", "\n", "\n", "with", "open", "(", "args", ".", "test_loc", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "problems", "=", "json", ".", "load", "(", "f", ")", "\n", "", "problems", "=", "sorted", "(", "problems", ")", "# Pin some ordering", "\n", "\n", "gpt_codes", "=", "{", "}", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "save", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "save", ",", "exist_ok", "=", "True", ")", "\n", "", "if", "not", "args", ".", "end", ":", "\n", "        ", "codes_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"all_codes.json\"", ")", "\n", "", "else", ":", "\n", "        ", "codes_loc", "=", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "f\"{args.start}-{args.end}_codes.json\"", ")", "\n", "\n", "# Only do the problems that are specified.", "\n", "", "if", "args", ".", "index", ":", "\n", "        ", "problems", "=", "[", "problems", "[", "args", ".", "index", "]", "]", "\n", "", "else", ":", "\n", "        ", "if", "args", ".", "start", ">", "len", "(", "problems", ")", "or", "args", ".", "start", "<", "0", ":", "\n", "            ", "print", "(", "f\"start index {args.start} > number of problems {len(problems)}\"", ")", "\n", "return", "\n", "", "start", "=", "args", ".", "start", "\n", "if", "args", ".", "end", "is", "None", "or", "args", ".", "end", ">", "len", "(", "problems", ")", ":", "\n", "            ", "end", "=", "len", "(", "problems", ")", "\n", "", "else", ":", "\n", "            ", "end", "=", "args", ".", "end", "\n", "", "problems", "=", "problems", "[", "start", ":", "end", "]", "\n", "\n", "# Tokenizer", "\n", "", "tokenizer", "=", "transformers", ".", "GPT2Tokenizer", ".", "from_pretrained", "(", "args", ".", "arch", ")", "\n", "\n", "# Set up model", "\n", "print", "(", "\"Loading model...\"", ")", "\n", "model", "=", "transformers", ".", "GPT2LMHeadModel", ".", "from_pretrained", "(", "args", ".", "load", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "print", "(", "f\"Loaded {args.load}.\"", ")", "\n", "\n", "# main eval loop", "\n", "for", "index", ",", "problem", "in", "enumerate", "(", "tqdm", "(", "problems", ")", ")", ":", "\n", "        ", "prob_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "root", ",", "problem", ")", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "print", "(", "f\"problem path = {prob_path}\"", ")", "\n", "\n", "", "test_case_path", "=", "os", ".", "path", ".", "join", "(", "prob_path", ",", "\"input_output.json\"", ")", "\n", "prompt_path", "=", "os", ".", "path", ".", "join", "(", "prob_path", ",", "\"question.txt\"", ")", "\n", "starter_path", "=", "os", ".", "path", ".", "join", "(", "prob_path", ",", "\"starter_code.py\"", ")", "\n", "solutions_path", "=", "os", ".", "path", ".", "join", "(", "prob_path", ",", "\"solutions.json\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "starter_path", ")", ":", "\n", "                ", "starter_path", "=", "None", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "test_case_path", ")", "or", "not", "os", ".", "path", ".", "exists", "(", "prompt_path", ")", ":", "\n", "            ", "continue", "\n", "\n", "# Read the question in", "\n", "", "prompt_text", ",", "sample_sol", "=", "generate_prompt", "(", "args", ",", "test_case_path", ",", "prompt_path", ",", "solutions_path", ",", "tokenizer", ",", "starter_path", ")", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "print", "(", "\"PROMPT_TEXT:\"", ")", "\n", "print", "(", "prompt_text", ")", "\n", "\n", "# Feed this into the model.", "\n", "", "start", "=", "time", ".", "time", "(", ")", "\n", "try", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "input_ids", "=", "torch", ".", "LongTensor", "(", "tokenizer", ".", "encode", "(", "prompt_text", ",", "verbose", "=", "False", ")", ")", ".", "unsqueeze", "(", "0", ")", ".", "cuda", "(", ")", "\n", "output_ids", "=", "model", ".", "generate", "(", "\n", "input_ids", ",", "\n", "num_beams", "=", "args", ".", "num_beams", ",", "\n", "early_stopping", "=", "True", ",", "\n", "max_length", "=", "1024", "-", "len", "(", "input_ids", ")", "\n", ")", "\n", "output_str", "=", "tokenizer", ".", "decode", "(", "output_ids", "[", "0", "]", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "if", "isinstance", "(", "e", ",", "UnboundLocalError", ")", "and", "str", "(", "e", ")", "==", "\"local variable 'next_tokens' referenced before assignment\"", ":", "\n", "# See https://github.com/huggingface/transformers/issues/5118", "\n", "                ", "if", "args", ".", "debug", ":", "\n", "                    ", "print", "(", "\"Problem text was > 1024 tokens, so cannot do generation\"", ")", "\n", "print", "(", "e", ")", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "\"Unexpected exception in generating solution\"", ")", "\n", "print", "(", "e", ")", "\n", "# Default to empty string on errors", "\n", "", "output_str", "=", "\"\"", "\n", "", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "args", ".", "peeking", "==", "1.0", ":", "\n", "            ", "output_str", "=", "sample_sol", "\n", "", "elif", "len", "(", "output_str", ")", ":", "\n", "            ", "output_str", "=", "output_str", ".", "split", "(", "\"ANSWER:\\n\"", ")", "[", "1", "]", ".", "replace", "(", "\"<|endoftext|>\"", ",", "\"\"", ")", "\n", "\n", "# Save the generated sol", "\n", "", "gpt_codes", "[", "index", "+", "args", ".", "start", "]", "=", "output_str", "\n", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "print", "(", "f\"Generation time: {end - start}\"", ")", "\n", "print", "(", "f\"Generated output string:\"", ")", "\n", "print", "(", "output_str", ")", "\n", "print", "(", "\"------------------------------------------------------------\"", ")", "\n", "\n", "", "", "with", "open", "(", "codes_loc", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "gpt_codes", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.train.CustomTensorboardCallback.CustomTensorBoardCallback.__init__": [[45, 47], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tb_writer", "=", "None", ")", ":", "\n", "        ", "self", ".", "tb_writer", "=", "tb_writer", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.train.CustomTensorboardCallback.CustomTensorBoardCallback._init_summary_writer": [[48, 51], ["tensorboardX.SummaryWriter"], "methods", ["None"], ["", "def", "_init_summary_writer", "(", "self", ",", "args", ",", "log_dir", "=", "None", ")", ":", "\n", "        ", "log_dir", "=", "log_dir", "or", "args", ".", "logging_dir", "\n", "self", ".", "tb_writer", "=", "SummaryWriter", "(", "log_dir", "=", "log_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.train.CustomTensorboardCallback.CustomTensorBoardCallback.on_train_begin": [[52, 75], ["CustomTensorboardCallback.CustomTensorBoardCallback._init_summary_writer", "CustomTensorboardCallback.CustomTensorBoardCallback.tb_writer.add_text", "hasattr", "os.path.join", "args.to_json_string", "CustomTensorboardCallback.CustomTensorBoardCallback.tb_writer.add_hparams", "hasattr", "model.config.to_json_string", "CustomTensorboardCallback.CustomTensorBoardCallback.tb_writer.add_text", "args.to_sanitized_dict"], "methods", ["home.repos.pwc.inspect_result.hendrycks_apps.train.CustomTensorboardCallback.CustomTensorBoardCallback._init_summary_writer"], ["", "def", "on_train_begin", "(", "self", ",", "args", ",", "state", ",", "control", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "state", ".", "is_world_process_zero", ":", "\n", "            ", "return", "\n", "\n", "", "log_dir", "=", "None", "\n", "\n", "if", "state", ".", "is_hyper_param_search", ":", "\n", "            ", "trial_name", "=", "state", ".", "trial_name", "\n", "if", "trial_name", "is", "not", "None", ":", "\n", "                ", "log_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "logging_dir", ",", "trial_name", ")", "\n", "\n", "", "", "self", ".", "_init_summary_writer", "(", "args", ",", "log_dir", ")", "\n", "\n", "if", "self", ".", "tb_writer", "is", "not", "None", ":", "\n", "            ", "self", ".", "tb_writer", ".", "add_text", "(", "\"args\"", ",", "args", ".", "to_json_string", "(", ")", ")", "\n", "if", "\"model\"", "in", "kwargs", ":", "\n", "                ", "model", "=", "kwargs", "[", "\"model\"", "]", "\n", "if", "hasattr", "(", "model", ",", "\"config\"", ")", "and", "model", ".", "config", "is", "not", "None", ":", "\n", "                    ", "model_config_json", "=", "model", ".", "config", ".", "to_json_string", "(", ")", "\n", "self", ".", "tb_writer", ".", "add_text", "(", "\"model_config\"", ",", "model_config_json", ")", "\n", "# Version of TensorBoard coming from tensorboardX does not have this method.", "\n", "", "", "if", "hasattr", "(", "self", ".", "tb_writer", ",", "\"add_hparams\"", ")", ":", "\n", "                ", "self", ".", "tb_writer", ".", "add_hparams", "(", "args", ".", "to_sanitized_dict", "(", ")", ",", "metric_dict", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.train.CustomTensorboardCallback.CustomTensorBoardCallback.on_log": [[76, 100], ["CustomTensorboardCallback.rewrite_logs", "rewrite_logs.update", "CustomTensorboardCallback.get_system_info", "rewrite_logs.items", "CustomTensorboardCallback.CustomTensorBoardCallback.tb_writer.flush", "CustomTensorboardCallback.CustomTensorBoardCallback._init_summary_writer", "isinstance", "CustomTensorboardCallback.CustomTensorBoardCallback.tb_writer.add_scalar", "logger.warning", "type"], "methods", ["home.repos.pwc.inspect_result.hendrycks_apps.train.CustomTensorboardCallback.rewrite_logs", "home.repos.pwc.inspect_result.hendrycks_apps.train.CustomTensorboardCallback.get_system_info", "home.repos.pwc.inspect_result.hendrycks_apps.train.CustomTensorboardCallback.CustomTensorBoardCallback._init_summary_writer"], ["", "", "", "def", "on_log", "(", "self", ",", "args", ",", "state", ",", "control", ",", "logs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "logs", "=", "rewrite_logs", "(", "logs", ")", "\n", "logs", ".", "update", "(", "get_system_info", "(", ")", ")", "\n", "\n", "if", "state", ".", "is_world_process_zero", ":", "\n", "            ", "if", "self", ".", "tb_writer", "is", "None", ":", "\n", "                ", "self", ".", "_init_summary_writer", "(", "args", ")", "\n", "\n", "", "", "if", "self", ".", "tb_writer", ":", "\n", "            ", "for", "k", ",", "v", "in", "logs", ".", "items", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "v", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "                    ", "self", ".", "tb_writer", ".", "add_scalar", "(", "k", ",", "v", ",", "state", ".", "global_step", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"Trainer is attempting to log a value of \"", "\n", "'\"%s\" of type %s for key \"%s\" as a scalar. '", "\n", "\"This invocation of Tensorboard's writer.add_scalar() \"", "\n", "\"is incorrect so we dropped this attribute.\"", ",", "\n", "v", ",", "\n", "type", "(", "v", ")", ",", "\n", "k", ",", "\n", ")", "\n", "", "", "self", ".", "tb_writer", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.train.CustomTensorboardCallback.CustomTensorBoardCallback.on_train_end": [[101, 104], ["CustomTensorboardCallback.CustomTensorBoardCallback.tb_writer.close"], "methods", ["None"], ["", "", "def", "on_train_end", "(", "self", ",", "args", ",", "state", ",", "control", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "self", ".", "tb_writer", ":", "\n", "            ", "self", ".", "tb_writer", ".", "close", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.hendrycks_apps.train.CustomTensorboardCallback.get_system_info": [[6, 18], ["psutil.Process", "os.getpid", "psutil.Process.memory_info", "psutil.virtual_memory", "psutil.virtual_memory"], "function", ["None"], ["def", "get_system_info", "(", ")", ":", "\n", "    ", "this", "=", "psutil", ".", "Process", "(", "os", ".", "getpid", "(", ")", ")", "\n", "mem_usage_bytes", "=", "this", ".", "memory_info", "(", ")", ".", "rss", "\n", "mem_usage_gb", "=", "mem_usage_bytes", "/", "(", "1024", "**", "3", ")", "\n", "\n", "total_mem_usage_gb", "=", "psutil", ".", "virtual_memory", "(", ")", ".", "used", "/", "(", "1024", "**", "3", ")", "\n", "total_mem_usage_percent", "=", "psutil", ".", "virtual_memory", "(", ")", ".", "percent", "\n", "\n", "return", "{", "\n", "'system/proc_mem_usage_gb'", ":", "mem_usage_gb", ",", "\n", "'system/total_mem_usage_gb'", ":", "total_mem_usage_gb", ",", "\n", "'system/total_mem_usage_percent'", ":", "total_mem_usage_percent", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.train.CustomTensorboardCallback.rewrite_logs": [[23, 33], ["len", "d.items", "k.startswith"], "function", ["None"], ["def", "rewrite_logs", "(", "d", ")", ":", "\n", "    ", "new_d", "=", "{", "}", "\n", "eval_prefix", "=", "\"eval_\"", "\n", "eval_prefix_len", "=", "len", "(", "eval_prefix", ")", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", ".", "startswith", "(", "eval_prefix", ")", ":", "\n", "            ", "new_d", "[", "\"eval/\"", "+", "k", "[", "eval_prefix_len", ":", "]", "]", "=", "v", "\n", "", "else", ":", "\n", "            ", "new_d", "[", "\"train/\"", "+", "k", "]", "=", "v", "\n", "", "", "return", "new_d", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.train.tune_apps_gpt.run_training": [[38, 115], ["print", "transformers.TrainingArguments", "transformers.Trainer", "transformers.Trainer.remove_callback", "transformers.Trainer.add_callback", "transformers.Trainer.train", "print", "transformers.GPT2LMHeadModel.from_pretrained", "print", "int", "print", "CustomTensorboardCallback.CustomTensorBoardCallback", "transformers.GPT2LMHeadModel.from_pretrained.save_pretrained", "transformers.GPTNeoForCausalLM.from_pretrained", "transformers.GPT2LMHeadModel.from_pretrained", "transformers.GPTNeoForCausalLM.from_pretrained", "transformers.GPT2LMHeadModel.from_pretrained", "os.path.join", "args.resume.split"], "function", ["None"], ["def", "run_training", "(", "args", ",", "train_data", ")", ":", "\n", "\n", "## Checkpoint Loading ######################################################## ", "\n", "    ", "if", "args", ".", "load", ":", "\n", "        ", "if", "'2700'", "in", "args", ".", "load", ":", "\n", "            ", "model", "=", "transformers", ".", "GPTNeoForCausalLM", ".", "from_pretrained", "(", "args", ".", "load", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "transformers", ".", "GPT2LMHeadModel", ".", "from_pretrained", "(", "args", ".", "load", ")", "\n", "", "print", "(", "f\"Loaded model from {args.load}\"", ")", "\n", "", "else", ":", "\n", "        ", "if", "\"EleutherAI\"", "in", "args", ".", "arch", ":", "\n", "            ", "model", "=", "transformers", ".", "GPTNeoForCausalLM", ".", "from_pretrained", "(", "args", ".", "arch", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "transformers", ".", "GPT2LMHeadModel", ".", "from_pretrained", "(", "args", ".", "arch", ")", "\n", "\n", "", "", "if", "args", ".", "resume", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "model", "=", "transformers", ".", "GPT2LMHeadModel", ".", "from_pretrained", "(", "args", ".", "resume", ")", "\n", "print", "(", "f\"Loaded model from {args.resume}\"", ")", "\n", "start_epoch", "=", "0", "\n", "start_iteration", "=", "int", "(", "args", ".", "resume", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ")", "\n", "print", "(", "\"start_iteration = \"", ",", "start_iteration", ")", "\n", "", "else", ":", "\n", "        ", "start_iteration", "=", "0", "\n", "\n", "## Dataloading ######################################################## ", "\n", "", "train_data", ".", "start_iteration", "=", "start_iteration", "\n", "\n", "## Start Loop ########################################################", "\n", "print", "(", "f\"Starting main loop\"", ")", "\n", "\n", "training_args", "=", "transformers", ".", "TrainingArguments", "(", "\n", "output_dir", "=", "args", ".", "save_dir", ",", "\n", "overwrite_output_dir", "=", "False", ",", "\n", "\n", "do_train", "=", "True", ",", "\n", "do_eval", "=", "False", ",", "\n", "do_predict", "=", "True", ",", "\n", "evaluation_strategy", "=", "'no'", ",", "\n", "eval_steps", "=", "0", ",", "\n", "\n", "num_train_epochs", "=", "args", ".", "epochs", ",", "\n", "per_device_train_batch_size", "=", "args", ".", "batch_size_per_replica", ",", "\n", "gradient_accumulation_steps", "=", "args", ".", "grad_acc_steps", ",", "\n", "\n", "learning_rate", "=", "args", ".", "lr", ",", "\n", "weight_decay", "=", "0.05", ",", "\n", "# warmup_steps=args.lr_warmup_steps,", "\n", "# max_grad_norm=100000.0,", "\n", "\n", "logging_dir", "=", "args", ".", "save_dir", ",", "\n", "logging_first_step", "=", "True", ",", "\n", "logging_steps", "=", "args", ".", "log_freq", ",", "\n", "save_steps", "=", "args", ".", "save_freq", ",", "\n", "save_total_limit", "=", "2", ",", "\n", "\n", "dataloader_drop_last", "=", "True", ",", "\n", "dataloader_num_workers", "=", "3", ",", "\n", "\n", "local_rank", "=", "args", ".", "local_rank", ",", "\n", "\n", "deepspeed", "=", "args", ".", "deepspeed", ",", "\n", "fp16", "=", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "trainer", "=", "transformers", ".", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_data", ",", "\n", ")", "\n", "trainer", ".", "remove_callback", "(", "transformers", ".", "integrations", ".", "TensorBoardCallback", ")", "\n", "trainer", ".", "add_callback", "(", "CustomTensorBoardCallback", "(", ")", ")", "\n", "\n", "trainer", ".", "train", "(", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "model", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "\"final_checkpoint\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.train.tune_apps_gpt.get_dataset": [[117, 130], ["os.listdir", "dataset_apps.APPSBaseDataset.APPSBaseDataset"], "function", ["None"], ["", "", "def", "get_dataset", "(", "args", ")", ":", "\n", "\n", "    ", "fnames", "=", "os", ".", "listdir", "(", "args", ".", "apps_train_files", ")", "\n", "\n", "train_data", "=", "APPSBaseDataset", "(", "\n", "dataroot", "=", "args", ".", "apps_dataroot", ",", "\n", "problem_dirs", "=", "fnames", ",", "\n", "mode", "=", "args", ".", "arch", ",", "\n", "max_tokens", "=", "2048", "if", "(", "'EleutherAI'", "in", "args", ".", "arch", "or", "'2700'", "in", "args", ".", "load", ")", "else", "1024", ",", "\n", "sample_mode", "=", "args", ".", "apps_sample_mode", "\n", ")", "\n", "\n", "return", "train_data", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.train.tune_apps_gpt.main": [[132, 146], ["vars", "print", "os.makedirs", "tune_apps_gpt.get_dataset", "tune_apps_gpt.run_training", "pprint.pformat", "open", "f.write", "os.path.join", "pprint.pformat"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.train.tune_apps_gpt.get_dataset", "home.repos.pwc.inspect_result.hendrycks_apps.train.tune_apps_gpt.run_training"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "argsdict", "=", "vars", "(", "args", ")", "\n", "print", "(", "pprint", ".", "pformat", "(", "argsdict", ")", ")", "\n", "\n", "os", ".", "makedirs", "(", "args", ".", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "train_data", "=", "get_dataset", "(", "args", ")", "\n", "\n", "# Save command to file", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save_dir", ",", "\"command.txt\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "pprint", ".", "pformat", "(", "argsdict", ")", ")", "\n", "\n", "", "run_training", "(", "args", ",", "train_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.train.apps_create_split.create_split": [[5, 17], ["sorted", "os.listdir", "os.path.join", "paths.append", "open", "json.dump"], "function", ["None"], ["def", "create_split", "(", "split", "=", "\"train\"", ",", "name", "=", "\"train\"", ")", ":", "\n", "    ", "paths", "=", "[", "]", "\n", "roots", "=", "sorted", "(", "os", ".", "listdir", "(", "split", ")", ")", "\n", "for", "folder", "in", "roots", ":", "\n", "        ", "root_path", "=", "os", ".", "path", ".", "join", "(", "split", ",", "folder", ")", "\n", "paths", ".", "append", "(", "root_path", ")", "\n", "\n", "\n", "", "with", "open", "(", "name", "+", "\".json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "paths", ",", "f", ")", "\n", "\n", "", "return", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.base_lm_dataset.BaseLMDataset.__init__": [[26, 77], ["multiprocessing.Manager", "sorted", "random.seed", "random.shuffle", "multiprocessing.Manager.list", "len", "print", "print", "transformers.GPT2Tokenizer.from_pretrained", "print", "sorted.extend", "transformers.BartTokenizer.from_pretrained", "NotImplementedError", "glob.glob", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataroots", ",", "mode", ",", "max_tokens", ",", "mask_probability", "=", "None", ",", "english_data", "=", "None", ")", ":", "\n", "        ", "\"\"\"Initializes the dataset with given configuration.\n        Args:\n            dataroot: str\n                Glob format data.\n        \"\"\"", "\n", "self", ".", "dataroots", "=", "dataroots", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "max_tokens", "=", "max_tokens", "\n", "self", ".", "mask_probability", "=", "mask_probability", "\n", "\n", "self", ".", "start_iteration", "=", "0", "# Set elsewhere right before training", "\n", "\n", "if", "self", ".", "mode", "==", "'dummy'", ":", "\n", "            ", "self", ".", "num_examples", "=", "1000000", "\n", "", "else", ":", "\n", "\n", "            ", "if", "self", ".", "mode", "in", "{", "'gpt2'", ",", "'gpt2-medium'", "}", ":", "\n", "                ", "self", ".", "tokenizer", "=", "transformers", ".", "GPT2Tokenizer", ".", "from_pretrained", "(", "mode", ")", "\n", "", "elif", "self", ".", "mode", "in", "{", "'facebook/bart-large'", "}", ":", "\n", "                ", "self", ".", "tokenizer", "=", "transformers", ".", "BartTokenizer", ".", "from_pretrained", "(", "mode", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "# Fixes some memory leak issues", "\n", "# https://gist.github.com/mprostock/2850f3cd465155689052f0fa3a177a50", "\n", "# https://gist.github.com/vadimkantorov/86c3a46bf25bed3ad45d043ae86fff57", "\n", "", "manager", "=", "Manager", "(", ")", "\n", "\n", "# Ensure ordering since we want to be able to resume in the middle of training", "\n", "# - glob.glob() does not guarantee the same ordering across machines or arcoss runs", "\n", "# - sorting() guarantees ordering but might give us entire batches from the same git repo.", "\n", "# - Setting random seed before shuffling should be reproducible across machines.", "\n", "l", "=", "[", "]", "\n", "for", "dataroot_info", "in", "self", ".", "dataroots", ":", "\n", "                ", "globstr", "=", "dataroot_info", "[", "'globstr'", "]", "\n", "print", "(", "f\"Loading globstr {globstr}\"", ")", "\n", "l", ".", "extend", "(", "glob", ".", "glob", "(", "globstr", ")", ")", "\n", "\n", "", "l", "=", "sorted", "(", "l", ")", "\n", "random", ".", "seed", "(", "1234", ")", "\n", "random", ".", "shuffle", "(", "l", ")", "\n", "\n", "self", ".", "all_files", "=", "manager", ".", "list", "(", "l", ")", "\n", "del", "l", "\n", "\n", "self", ".", "num_examples", "=", "len", "(", "self", ".", "all_files", ")", "\n", "print", "(", "f\"Found {self.num_examples} training examples\"", ")", "\n", "\n", "self", ".", "english_data", "=", "english_data", "\n", "print", "(", "f\"English data has {len(self.english_data)} samples\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.base_lm_dataset.BaseLMDataset._get_english_fraction": [[78, 88], ["RuntimeError", "fnmatch.fnmatch"], "methods", ["None"], ["", "", "def", "_get_english_fraction", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\"\n        Given a filename, return the english fraction for that filename\n        \"\"\"", "\n", "for", "dataroot_info", "in", "self", ".", "dataroots", ":", "\n", "            ", "globstr", "=", "dataroot_info", "[", "'globstr'", "]", "\n", "english_frac", "=", "dataroot_info", "[", "'english_frac'", "]", "\n", "if", "fnmatch", ".", "fnmatch", "(", "filename", ",", "globstr", ")", ":", "\n", "                ", "return", "english_frac", "\n", "", "", "raise", "RuntimeError", "(", "f\"{filename} does not match any globstr.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.base_lm_dataset.BaseLMDataset._get_english_sample": [[89, 100], ["random.randint", "len", "base_lm_dataset.BaseLMDataset.tokenizer.tokenize", "len"], "methods", ["None"], ["", "def", "_get_english_sample", "(", "self", ")", ":", "\n", "        ", "sample_str", "=", "\"\"", "\n", "curr_num_tokens", "=", "0", "\n", "while", "curr_num_tokens", "<", "self", ".", "max_tokens", ":", "\n", "            ", "rand_index", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "english_data", ")", "-", "10000", ")", "\n", "sample_str", "+=", "self", ".", "english_data", "[", "rand_index", "]", "[", "'text'", "]", "\n", "# print(f\"{os.getpid()}: _get_english_sample 1\")", "\n", "curr_num_tokens", "+=", "len", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "sample_str", ")", ")", "\n", "# print(f\"{os.getpid()}: _get_english_sample 2\")", "\n", "rand_index", "+=", "1", "\n", "", "return", "sample_str", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.base_lm_dataset.BaseLMDataset.__len__": [[101, 103], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_examples", "-", "self", ".", "start_iteration", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.base_lm_dataset.BaseLMDataset.__getitem__": [[104, 146], ["random.seed", "base_lm_dataset.BaseLMDataset._get_english_fraction", "gc.collect", "dataset_lm.dummy_gpt_task", "random.random", "base_lm_dataset.BaseLMDataset._get_english_sample", "dataset_lm.batch_gpt_task", "os.getpid", "time.time", "open", "f.read", "dataset_lm.batch_bart_task", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.base_lm_dataset.BaseLMDataset._get_english_fraction", "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util.dummy_gpt_task", "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.base_lm_dataset.BaseLMDataset._get_english_sample", "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util.batch_gpt_task", "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util.batch_bart_task"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# Each worker needs a different seed....", "\n", "        ", "random", ".", "seed", "(", "os", ".", "getpid", "(", ")", "+", "time", ".", "time", "(", ")", ")", "\n", "\n", "index", "=", "index", "+", "self", ".", "start_iteration", "\n", "\n", "if", "self", ".", "mode", "==", "'dummy'", ":", "\n", "            ", "return", "dsutil", ".", "dummy_gpt_task", "(", "\n", "max_tokens", "=", "self", ".", "max_tokens", "\n", ")", "\n", "\n", "# Get a file from self.all_files", "\n", "", "fname", "=", "self", ".", "all_files", "[", "index", "]", "\n", "english_frac", "=", "self", ".", "_get_english_fraction", "(", "fname", ")", "\n", "if", "random", ".", "random", "(", ")", "<", "english_frac", ":", "\n", "# Use English data", "\n", "            ", "sample_str", "=", "self", ".", "_get_english_sample", "(", ")", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "fname", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "sample_str", "=", "f", ".", "read", "(", ")", "\n", "\n", "# Never remove. Fixes stalling bug.", "\n", "", "", "sample_str", "=", "sample_str", "[", ":", "150000", "]", "\n", "\n", "if", "self", ".", "mode", "in", "{", "'gpt2'", ",", "'gpt2-medium'", "}", ":", "\n", "            ", "retval", "=", "dsutil", ".", "batch_gpt_task", "(", "\n", "sample_str", ",", "\n", "max_tokens", "=", "self", ".", "max_tokens", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", ")", "\n", "", "elif", "self", ".", "mode", "in", "{", "'facebook/bart-large'", "}", ":", "\n", "            ", "retval", "=", "dsutil", ".", "batch_bart_task", "(", "\n", "sample_str", ",", "\n", "max_tokens", "=", "self", ".", "max_tokens", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", "mask_probability", "=", "self", ".", "mask_probability", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "gc", ".", "collect", "(", ")", "\n", "return", "retval", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent._find_indentation": [[15, 26], ["len", "list", "line.isspace"], "function", ["None"], ["def", "_find_indentation", "(", "line", ",", "config", ")", ":", "\n", "    ", "if", "len", "(", "line", ")", "and", "line", "[", "0", "]", "in", "(", "\" \"", ",", "\"\\t\"", ")", "and", "not", "line", ".", "isspace", "(", ")", ":", "\n", "        ", "if", "line", "[", "0", "]", "==", "\"\\t\"", ":", "\n", "            ", "config", "[", "'is-tabs'", "]", "=", "True", "\n", "# Find indentation", "\n", "", "i", "=", "0", "\n", "for", "char", "in", "list", "(", "line", ")", ":", "\n", "            ", "if", "char", "not", "in", "(", "\" \"", ",", "\"\\t\"", ")", ":", "\n", "                ", "break", "\n", "", "i", "+=", "1", "\n", "", "config", "[", "\"from\"", "]", "=", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.find_indentation": [[28, 47], ["reindent._find_indentation"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent._find_indentation"], ["", "", "def", "find_indentation", "(", "line", ",", "config", ")", ":", "\n", "# Find indentation level used in file", "\n", "    ", "if", "config", "[", "'from'", "]", "<", "0", ":", "\n", "        ", "_find_indentation", "(", "line", ",", "config", ")", "\n", "\n", "", "if", "config", "[", "'from'", "]", ">=", "0", ":", "\n", "# Set old indent", "\n", "        ", "indent", "=", "\" \"", "if", "not", "config", "[", "'is-tabs'", "]", "else", "\"\\t\"", "\n", "indent", "=", "indent", "*", "config", "[", "'from'", "]", "\n", "\n", "# Set new indent", "\n", "newindent", "=", "\" \"", "if", "not", "config", "[", "'tabs'", "]", "else", "\"\\t\"", "\n", "if", "not", "config", "[", "'tabs'", "]", ":", "\n", "            ", "newindent", "=", "newindent", "*", "config", "[", "'to'", "]", "\n", "\n", "", "return", "indent", ",", "newindent", "\n", "\n", "# Continue to the next line, indentation not found", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.replace_inline_tabs": [[49, 62], ["range", "len"], "function", ["None"], ["", "def", "replace_inline_tabs", "(", "content", ",", "config", ")", ":", "\n", "    ", "newcontent", "=", "\"\"", "\n", "imagined_i", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "content", ")", ")", ":", "\n", "        ", "char", "=", "content", "[", "i", "]", "\n", "if", "char", "==", "'\\t'", ":", "\n", "            ", "spaces", "=", "config", "[", "'tabsize'", "]", "-", "(", "imagined_i", "%", "config", "[", "'tabsize'", "]", ")", "\n", "newcontent", "+=", "\" \"", "*", "spaces", "\n", "imagined_i", "+=", "spaces", "\n", "", "else", ":", "\n", "            ", "newcontent", "+=", "char", "\n", "imagined_i", "+=", "1", "\n", "", "", "return", "newcontent", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.run": [[64, 94], ["fd_in.readline", "line.rstrip.rstrip", "print", "reindent.find_indentation", "reindent.replace_inline_tabs", "print", "len", "len", "sys.stdin", "sys.stdout"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.find_indentation", "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.replace_inline_tabs"], ["", "def", "run", "(", "fd_in", ",", "fd_out", ",", "config", ")", ":", "\n", "    ", "while", "True", ":", "\n", "        ", "line", "=", "fd_in", ".", "readline", "(", ")", "\n", "if", "not", "line", ":", "\n", "            ", "break", "\n", "", "line", "=", "line", ".", "rstrip", "(", "'\\r\\n'", ")", "\n", "\n", "# Find indentation style used in file if not set", "\n", "if", "config", "[", "'from'", "]", "<", "0", ":", "\n", "            ", "indent", "=", "find_indentation", "(", "line", ",", "config", ")", "\n", "if", "not", "indent", ":", "\n", "                ", "print", "(", "line", ",", "file", "=", "fd_out", ")", "\n", "continue", "\n", "", "indent", ",", "newindent", "=", "indent", "\n", "\n", "# Find current indentation level", "\n", "", "level", "=", "0", "\n", "while", "True", ":", "\n", "            ", "whitespace", "=", "line", "[", ":", "len", "(", "indent", ")", "*", "(", "level", "+", "1", ")", "]", "\n", "if", "whitespace", "==", "indent", "*", "(", "level", "+", "1", ")", ":", "\n", "                ", "level", "+=", "1", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "", "content", "=", "line", "[", "len", "(", "indent", ")", "*", "level", ":", "]", "\n", "if", "config", "[", "'all-tabs'", "]", ":", "\n", "            ", "content", "=", "replace_inline_tabs", "(", "content", ",", "config", ")", "\n", "\n", "", "line", "=", "(", "newindent", "*", "level", ")", "+", "content", "\n", "print", "(", "line", ",", "file", "=", "fd_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.run_files": [[96, 113], ["codecs.open", "reindent.run", "print", "tempfile.NamedTemporaryFile", "codecs.open.close", "codecs.open", "codecs.open.close", "shutil.copy", "os.remove"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.run"], ["", "", "def", "run_files", "(", "filenames", ",", "config", ")", ":", "\n", "    ", "for", "filename", "in", "filenames", ":", "\n", "        ", "with", "codecs", ".", "open", "(", "filename", ",", "encoding", "=", "config", "[", "'encoding'", "]", ")", "as", "fd_in", ":", "\n", "            ", "if", "config", "[", "'dry-run'", "]", ":", "\n", "                ", "print", "(", "\"Filename: %s\"", "%", "filename", ")", "\n", "fd_out", "=", "sys", ".", "stdout", "\n", "", "else", ":", "\n", "                ", "fd_out", "=", "tempfile", ".", "NamedTemporaryFile", "(", "mode", "=", "'wb'", ",", "delete", "=", "False", ")", "\n", "fd_out", ".", "close", "(", ")", "\n", "fd_out", "=", "codecs", ".", "open", "(", "fd_out", ".", "name", ",", "\"wb\"", ",", "encoding", "=", "config", "[", "'encoding'", "]", ")", "\n", "\n", "", "run", "(", "fd_in", ",", "fd_out", ",", "config", ")", "\n", "\n", "if", "not", "config", "[", "\"dry-run\"", "]", ":", "\n", "                ", "fd_out", ".", "close", "(", ")", "\n", "shutil", ".", "copy", "(", "fd_out", ".", "name", ",", "filename", ")", "\n", "os", ".", "remove", "(", "fd_out", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.main": [[115, 192], ["getopt.getopt", "possible_args.values", "shortargs.append", "longargs.append", "opt.lstrip.lstrip", "isinstance", "print", "sys.exit", "reindent.run_files", "reindent.run", "possible_args.keys", "shortarg.rstrip", "possible_args[].rstrip", "isinstance", "int", "shortargs.index", "help[].split"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.run_files", "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.run"], ["", "", "", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "config", "=", "{", "\n", "\"dry-run\"", ":", "False", ",", "\n", "\"help\"", ":", "False", ",", "\n", "\"to\"", ":", "4", ",", "\n", "\"from\"", ":", "-", "1", ",", "\n", "\"tabs\"", ":", "False", ",", "\n", "\"encoding\"", ":", "\"utf-8\"", ",", "\n", "\"is-tabs\"", ":", "False", ",", "\n", "\"tabsize\"", ":", "4", ",", "\n", "\"all-tabs\"", ":", "False", "\n", "}", "\n", "possible_args", "=", "{", "\n", "\"d\"", ":", "\"dry-run\"", ",", "\n", "\"h\"", ":", "\"help\"", ",", "\n", "\"t:\"", ":", "\"to=\"", ",", "\n", "\"f:\"", ":", "\"from=\"", ",", "\n", "\"n\"", ":", "\"tabs\"", ",", "\n", "\"e:\"", ":", "\"encoding=\"", ",", "\n", "\"s:\"", ":", "\"tabsize=\"", ",", "\n", "\"a\"", ":", "\"all-tabs\"", ",", "\n", "}", "\n", "optlist", ",", "filenames", "=", "getopt", ".", "getopt", "(", "\n", "args", "[", "1", ":", "]", ",", "\n", "\"\"", ".", "join", "(", "possible_args", ".", "keys", "(", ")", ")", ",", "\n", "possible_args", ".", "values", "(", ")", "\n", ")", "\n", "\n", "shortargs", ",", "longargs", "=", "[", "]", ",", "[", "]", "\n", "for", "shortarg", "in", "possible_args", ":", "\n", "        ", "shortargs", ".", "append", "(", "shortarg", ".", "rstrip", "(", "\":\"", ")", ")", "\n", "longargs", ".", "append", "(", "possible_args", "[", "shortarg", "]", ".", "rstrip", "(", "\"=\"", ")", ")", "\n", "\n", "", "for", "opt", ",", "val", "in", "optlist", ":", "\n", "        ", "opt", "=", "opt", ".", "lstrip", "(", "\"-\"", ")", "\n", "if", "opt", "in", "shortargs", ":", "\n", "            ", "opt", "=", "longargs", "[", "shortargs", ".", "index", "(", "opt", ")", "]", "\n", "", "if", "isinstance", "(", "config", "[", "opt", "]", ",", "bool", ")", ":", "\n", "            ", "config", "[", "opt", "]", "=", "True", "\n", "", "elif", "isinstance", "(", "config", "[", "opt", "]", ",", "int", ")", ":", "\n", "            ", "config", "[", "opt", "]", "=", "int", "(", "val", ")", "\n", "", "else", ":", "\n", "            ", "config", "[", "opt", "]", "=", "val", "\n", "\n", "", "", "if", "config", "[", "'help'", "]", ":", "\n", "        ", "help", "=", "\"\"\"\n        Usage: %s [options] filename(s)\n        Options:\n            -h, --help              Show this message\n            -d, --dry-run           Don't save anything, just print\n                                    the result\n            -t <n>, --to <n>        Convert to this number of spaces\n                                    (default: 4)\n            -f <n>, --from <n>      Convert from this number of spaces\n                                    (default: auto-detect, will also\n                                    detect tabs)\n            -n, --tabs              Don't convert indentation to spaces,\n                                    convert to tabs instead. -t and\n                                    --to will have no effect.\n            -a, --all-tabs          Also convert tabs used for alignment\n                                    in the code (Warning: will replace\n                                    all tabs in the file, even if inside\n                                    a string)\n            -s <n>, --tabsize <n>   Set how many spaces one tab is\n                                    (only has an effect on -a, default: 4)\n            -e <s>, --encoding <s>  Open files with specified encoding\n                                    (default: utf-8)\n        \"\"\"", "%", "args", "[", "0", "]", "\n", "\n", "# Also removes 8 leading spaces to remove our indentation", "\n", "print", "(", "\"\\n\"", ".", "join", "(", "[", "x", "[", "8", ":", "]", "for", "x", "in", "help", "[", "1", ":", "]", ".", "split", "(", "\"\\n\"", ")", "]", ")", ")", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "\n", "", "if", "filenames", ":", "\n", "        ", "run_files", "(", "filenames", ",", "config", ")", "\n", "", "else", ":", "\n", "        ", "run", "(", "sys", ".", "stdin", ",", "sys", ".", "stdout", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util.batch_gpt_task": [[15, 38], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "F.pad.detach().clone", "tokenizer.encode", "len", "len", "torch.pad", "F.pad.detach"], "function", ["None"], ["def", "batch_gpt_task", "(", "sample", ",", "max_tokens", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\"\n    Take sample, which is a raw string, and then \n    \"\"\"", "\n", "\n", "# print(f\"{os.getpid()}: batch_gpt_task 1: {sample[:200]} END\")", "\n", "sample_input_ids", "=", "torch", ".", "LongTensor", "(", "tokenizer", ".", "encode", "(", "sample", ",", "max_length", "=", "max_tokens", ",", "truncation", "=", "True", ")", ")", "\n", "# print(f\"{os.getpid()}: batch_gpt_task 2\")", "\n", "\n", "assert", "len", "(", "sample_input_ids", ")", "<=", "max_tokens", "\n", "\n", "N_pad_inputs", "=", "max_tokens", "-", "len", "(", "sample_input_ids", ")", "\n", "if", "N_pad_inputs", ">", "0", ":", "\n", "        ", "sample_input_ids", "=", "F", ".", "pad", "(", "sample_input_ids", ",", "[", "0", ",", "N_pad_inputs", "]", ",", "mode", "=", "'constant'", ",", "value", "=", "tokenizer", ".", "eos_token_id", ")", "\n", "\n", "", "target_ids", "=", "sample_input_ids", ".", "detach", "(", ")", ".", "clone", "(", ")", "# Will be shifted right inside the model.", "\n", "target_ids", "[", "target_ids", "==", "tokenizer", ".", "eos_token_id", "]", "=", "-", "100", "\n", "\n", "# import pdb; pdb.set_trace()", "\n", "\n", "return", "{", "\n", "\"input_ids\"", ":", "sample_input_ids", ",", "\n", "\"labels\"", ":", "target_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util.batch_bart_task": [[40, 60], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "F.pad.detach().clone", "F.pad.long", "tokenizer.encode", "len", "torch.pad", "torch.ones_like", "torch.ones_like", "torch.ones_like", "F.pad.detach", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "function", ["None"], ["", "def", "batch_bart_task", "(", "sample", ",", "max_tokens", ",", "tokenizer", ",", "mask_probability", ")", ":", "\n", "\n", "    ", "sample_input_ids", "=", "torch", ".", "LongTensor", "(", "tokenizer", ".", "encode", "(", "sample", ",", "max_length", "=", "max_tokens", ",", "truncation", "=", "True", ")", ")", "\n", "\n", "N_pad_inputs", "=", "max_tokens", "-", "len", "(", "sample_input_ids", ")", "\n", "if", "N_pad_inputs", ">", "0", ":", "\n", "        ", "sample_input_ids", "=", "F", ".", "pad", "(", "sample_input_ids", ",", "[", "0", ",", "N_pad_inputs", "]", ",", "mode", "=", "'constant'", ",", "value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "", "mask", "=", "torch", ".", "bernoulli", "(", "torch", ".", "ones_like", "(", "sample_input_ids", ")", "*", "mask_probability", ")", "# 1's in mask_probability% of the places", "\n", "\n", "target_ids", "=", "sample_input_ids", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "target_ids", "[", "target_ids", "==", "tokenizer", ".", "pad_token_id", "]", "=", "-", "100", "\n", "target_ids", "[", "mask", "==", "0", "]", "=", "-", "100", "\n", "\n", "sample_input_ids", "=", "(", "sample_input_ids", "*", "(", "1", "-", "mask", ")", ")", "+", "(", "torch", ".", "ones_like", "(", "sample_input_ids", ")", "*", "tokenizer", ".", "mask_token_id", "*", "mask", ")", "# Mask input", "\n", "sample_input_ids", "=", "sample_input_ids", ".", "long", "(", ")", "\n", "\n", "return", "{", "\n", "\"input_ids\"", ":", "sample_input_ids", ",", "\n", "\"labels\"", ":", "target_ids", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util.dummy_gpt_task": [[62, 68], ["torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["None"], ["", "def", "dummy_gpt_task", "(", "max_tokens", ")", ":", "\n", "    ", "seq", "=", "torch", ".", "zeros", "(", "(", "max_tokens", ")", ")", ".", "long", "(", ")", "\n", "return", "{", "\n", "\"input_ids\"", ":", "seq", ",", "\n", "\"labels\"", ":", "seq", ",", "\n", "\"attention_mask\"", ":", "torch", ".", "ones_like", "(", "seq", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util._T5_mask": [[74, 84], ["torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "util._T5_apply_mask", "util._T5_apply_mask", "len", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util._T5_apply_mask", "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util._T5_apply_mask"], ["", "def", "_T5_mask", "(", "sample", ",", "mask_probability", ",", "tokenizer", ")", ":", "\n", "\n", "    ", "assert", "len", "(", "sample", ".", "shape", ")", "==", "1", "\n", "\n", "mask", "=", "torch", ".", "bernoulli", "(", "torch", ".", "ones_like", "(", "sample", ")", "*", "mask_probability", ")", ".", "bool", "(", ")", "# 15 % are 1s ", "\n", "\n", "new_sample", "=", "_T5_apply_mask", "(", "sample", ",", "mask", ",", "tokenizer", ")", "\n", "target", "=", "_T5_apply_mask", "(", "sample", ",", "torch", ".", "logical_not", "(", "mask", ")", ",", "tokenizer", ")", "\n", "\n", "return", "new_sample", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util._T5_apply_mask": [[85, 123], ["torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.pad", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.where", "torch.where", "torch.where", "torch.masked_select", "torch.masked_select", "torch.masked_select", "len", "torch.eq", "torch.eq", "torch.eq", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_not", "torch.logical_not", "torch.logical_not"], "function", ["None"], ["", "def", "_T5_apply_mask", "(", "sample", ",", "mask", ",", "tokenizer", ",", "hide_sentinels", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Applies T5's masking scheme to batch. From the paper:\n\n    Inspired by BERT\u2019s \u201cmasked language modeling\u201d objective and the \u201cword dropout\u201d regularization technique \n    (Bowman et al., 2015), we design an objective that randomly samples and then drops out 15% of tokens in the input \n    sequence. All consecutive spans of dropped-out tokens are replaced by a single sentinel token. Each sentinel token\n    is assigned a token ID that is unique to the sequence. The sentinel IDs are special tokens which are added to our \n    vocabulary and do not correspond to any wordpiece. The target then corresponds to all of the dropped-out spans of \n    tokens, delimited by the same sentinel tokens used in the input sequence plus a final sentinel token to mark the end of \n    the target sequence. Our choices to mask consecutive spans of tokens and only predict dropped-out tokens were \n    made to reduce the computational cost of pre-training.\u00a0\n    \"\"\"", "\n", "\n", "assert", "len", "(", "sample", ".", "shape", ")", "==", "1", "\n", "\n", "sample_not_padding_tokens", "=", "torch", ".", "logical_not", "(", "torch", ".", "eq", "(", "sample", ",", "tokenizer", ".", "pad_token_id", ")", ")", "\n", "\n", "# Do masking. See below link for more info:", "\n", "# TODO: Right now, this is being done twice per mask. Move it out so it is only done once per mask?", "\n", "# https://github.com/google-research/text-to-text-transfer-transformer/blob/9fd7b14a769417be33bc6c850f9598764913c833/t5/data/preprocessors.py#L2117", "\n", "# Shift to the right", "\n", "prev_token_is_masked", "=", "F", ".", "pad", "(", "mask", "[", ":", "-", "1", "]", ",", "(", "1", ",", "0", ")", ",", "mode", "=", "'constant'", ",", "value", "=", "0", ")", "\n", "first_mask_tokens", "=", "torch", ".", "logical_and", "(", "mask", ",", "torch", ".", "logical_not", "(", "prev_token_is_masked", ")", ")", "\n", "subsequent_mask_tokens", "=", "torch", ".", "logical_and", "(", "mask", ",", "prev_token_is_masked", ")", "\n", "# Magic formula. See https://github.com/huggingface/transformers/blob/master/src/transformers/tokenization_t5.py#L241", "\n", "# Note we do NOT need to subtract the number of tokens added with T5_new_tokens since", "\n", "# tokenizer.vocab_size does NOT include those.", "\n", "sentinel_idxs", "=", "tokenizer", ".", "vocab_size", "-", "torch", ".", "cumsum", "(", "first_mask_tokens", ",", "dim", "=", "0", ")", "\n", "\n", "sample", "=", "torch", ".", "where", "(", "\n", "torch", ".", "logical_and", "(", "first_mask_tokens", ",", "sample_not_padding_tokens", ")", ",", "\n", "sentinel_idxs", ",", "\n", "sample", "\n", ")", "\n", "sample", "=", "torch", ".", "masked_select", "(", "sample", ",", "torch", ".", "logical_not", "(", "subsequent_mask_tokens", ")", ")", "\n", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util.apply_mask_denoising": [[124, 153], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "util._T5_mask", "tokenizer.encode", "len", "len", "len", "torch.pad", "len", "torch.pad", "torch.eq", "torch.eq", "torch.eq"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util._T5_mask"], ["", "def", "apply_mask_denoising", "(", "sample", ",", "max_tokens", ",", "tokenizer", ",", "mask_probability", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        sample: string, already with bad characters replaced with T5_replace_chars()\n    Returns:\n        dict: With the input (raw string), input_ids (Tensor), labels (Tensor), attention_mask (Tensor)\n    \"\"\"", "\n", "sample_input_ids", "=", "torch", ".", "LongTensor", "(", "tokenizer", ".", "encode", "(", "sample", ",", "padding", "=", "'max_length'", ",", "max_length", "=", "max_tokens", ",", "truncation", "=", "True", ")", ")", "\n", "\n", "masked_sample_input_ids", ",", "masked_sample_labels", "=", "_T5_mask", "(", "sample_input_ids", ",", "mask_probability", ",", "tokenizer", ")", "\n", "\n", "assert", "len", "(", "masked_sample_input_ids", ")", "<=", "max_tokens", "\n", "assert", "len", "(", "masked_sample_labels", ")", "<=", "max_tokens", "\n", "\n", "N_pad_inputs", "=", "max_tokens", "-", "len", "(", "masked_sample_input_ids", ")", "\n", "if", "N_pad_inputs", ">", "0", ":", "\n", "        ", "masked_sample_input_ids", "=", "F", ".", "pad", "(", "masked_sample_input_ids", ",", "[", "0", ",", "N_pad_inputs", "]", ",", "mode", "=", "'constant'", ",", "value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "", "N_pad_labels", "=", "max_tokens", "-", "len", "(", "masked_sample_labels", ")", "\n", "if", "N_pad_labels", ">", "0", ":", "\n", "        ", "masked_sample_labels", "=", "F", ".", "pad", "(", "masked_sample_labels", ",", "[", "0", ",", "N_pad_labels", "]", ",", "mode", "=", "'constant'", ",", "value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "", "attention_mask", "=", "~", "torch", ".", "eq", "(", "masked_sample_input_ids", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "return", "{", "\n", "\"raw_strings\"", ":", "sample", ",", "\n", "\"input_ids\"", ":", "masked_sample_input_ids", ",", "\n", "\"labels\"", ":", "masked_sample_labels", ",", "\n", "\"attention_mask\"", ":", "attention_mask", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util._BERT_mlm_mask": [[160, 177], ["torch.bernoulli().bool", "torch.bernoulli().bool", "torch.bernoulli().bool", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.bernoulli", "torch.bernoulli", "torch.bernoulli", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "function", ["None"], ["", "def", "_BERT_mlm_mask", "(", "sample", ",", "mask_probability", ",", "tokenizer", ")", ":", "\n", "    ", "mask", "=", "torch", ".", "bernoulli", "(", "torch", ".", "ones_like", "(", "sample", ")", "*", "mask_probability", ")", ".", "bool", "(", ")", "# 15 % are 1s ", "\n", "sentinel_idxs", "=", "tokenizer", ".", "vocab_size", "-", "torch", ".", "ones_like", "(", "sample", ")", "\n", "\n", "new_sample", "=", "torch", ".", "where", "(", "\n", "mask", ",", "\n", "sentinel_idxs", ",", "\n", "sample", "\n", ")", "\n", "\n", "target", "=", "torch", ".", "where", "(", "\n", "mask", ",", "\n", "sample", ",", "\n", "torch", ".", "ones_like", "(", "sample", ")", "*", "-", "100", ",", "\n", ")", "\n", "\n", "return", "new_sample", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util.apply_mask_bert_mlm": [[179, 205], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "util._BERT_mlm_mask", "tokenizer.encode", "len", "len", "len", "torch.pad", "len", "torch.pad", "torch.eq", "torch.eq", "torch.eq"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.util._BERT_mlm_mask"], ["", "def", "apply_mask_bert_mlm", "(", "sample", ",", "max_tokens", ",", "tokenizer", ",", "mask_probability", ")", ":", "\n", "    ", "\"\"\"\n    Apply BERT-MLM-style masking to the given sample\n    \"\"\"", "\n", "sample_input_ids", "=", "torch", ".", "LongTensor", "(", "tokenizer", ".", "encode", "(", "sample", ",", "padding", "=", "'max_length'", ",", "max_length", "=", "max_tokens", ",", "truncation", "=", "True", ")", ")", "\n", "\n", "masked_sample_input_ids", ",", "masked_sample_labels", "=", "_BERT_mlm_mask", "(", "sample_input_ids", ",", "mask_probability", ",", "tokenizer", ")", "\n", "\n", "assert", "len", "(", "masked_sample_input_ids", ")", "<=", "max_tokens", "\n", "assert", "len", "(", "masked_sample_labels", ")", "<=", "max_tokens", "\n", "\n", "N_pad_inputs", "=", "max_tokens", "-", "len", "(", "masked_sample_input_ids", ")", "\n", "if", "N_pad_inputs", ">", "0", ":", "\n", "        ", "masked_sample_input_ids", "=", "F", ".", "pad", "(", "masked_sample_input_ids", ",", "[", "0", ",", "N_pad_inputs", "]", ",", "mode", "=", "'constant'", ",", "value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "", "N_pad_labels", "=", "max_tokens", "-", "len", "(", "masked_sample_labels", ")", "\n", "if", "N_pad_labels", ">", "0", ":", "\n", "        ", "masked_sample_labels", "=", "F", ".", "pad", "(", "masked_sample_labels", ",", "[", "0", ",", "N_pad_labels", "]", ",", "mode", "=", "'constant'", ",", "value", "=", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "", "attention_mask", "=", "~", "torch", ".", "eq", "(", "masked_sample_input_ids", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "return", "{", "\n", "\"raw_strings\"", ":", "sample", ",", "\n", "\"input_ids\"", ":", "masked_sample_input_ids", ",", "\n", "\"labels\"", ":", "masked_sample_labels", ",", "\n", "\"attention_mask\"", ":", "attention_mask", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.APPSBaseDataset.__init__": [[28, 47], ["APPSBaseDataset.APPSBaseDataset.initialize", "transformers.GPT2Tokenizer.from_pretrained", "transformers.GPT2Tokenizer.from_pretrained", "transformers.RobertaTokenizer.from_pretrained", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.APPSBaseDataset.initialize"], ["    ", "def", "__init__", "(", "self", ",", "dataroot", ",", "problem_dirs", ",", "mode", ",", "max_tokens", ",", "sample_mode", ")", ":", "\n", "        ", "self", ".", "dataroot", "=", "dataroot", "\n", "self", ".", "problem_dirs", "=", "problem_dirs", "# Loaded from train/test split json files", "\n", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "sample_mode", "=", "sample_mode", "# Either \"uniform_sol\" or \"uniform_prob\"", "\n", "self", ".", "max_tokens", "=", "max_tokens", "\n", "\n", "self", ".", "samples", "=", "[", "]", "# Should be set in initialize()", "\n", "self", ".", "initialize", "(", ")", "\n", "\n", "if", "(", "'EleutherAI'", "in", "mode", "or", "'2700'", "in", "mode", ")", ":", "\n", "            ", "self", ".", "tokenizer", "=", "transformers", ".", "GPT2Tokenizer", ".", "from_pretrained", "(", "\"EleutherAI/gpt-neo-2.7B\"", ")", "\n", "", "elif", "'gpt'", "in", "self", ".", "mode", ":", "# Should handle GPT-2 and GPT-Neo", "\n", "            ", "self", ".", "tokenizer", "=", "transformers", ".", "GPT2Tokenizer", ".", "from_pretrained", "(", "mode", ")", "\n", "", "elif", "self", ".", "mode", "in", "{", "'codebert'", "}", ":", "\n", "            ", "self", ".", "tokenizer", "=", "transformers", ".", "RobertaTokenizer", ".", "from_pretrained", "(", "\"microsoft/codebert-base\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.APPSBaseDataset.initialize": [[49, 103], ["print", "tqdm.tqdm.tqdm", "print", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.isfile", "skipped_problems.append", "open", "f.read", "open", "json.load", "len", "os.path.isfile", "os.path.isfile", "open", "f.read", "APPSBaseDataset.reindent_code", "all_samples.append", "len", "len", "all_samples_dict[].append"], "methods", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.reindent_code"], ["", "", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Assume self.dataroot is set to folderName/data\n        \"\"\"", "\n", "\n", "all_samples", "=", "[", "]", "\n", "skipped_problems", "=", "[", "]", "\n", "\n", "all_samples_dict", "=", "{", "}", "# Mapping from question_fname to list of samples", "\n", "\n", "print", "(", "f\"Loading {len(self.problem_dirs)} problems from {self.dataroot}.\"", ")", "\n", "for", "problem_name", "in", "tqdm", "(", "self", ".", "problem_dirs", ")", ":", "\n", "            ", "question_fname", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dataroot", ",", "problem_name", ",", "\"question.txt\"", ")", "\n", "sols_fname", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dataroot", ",", "problem_name", ",", "\"solutions.json\"", ")", "\n", "starter_code", "=", "os", ".", "path", ".", "join", "(", "self", ".", "dataroot", ",", "problem_name", ",", "\"starter_code.py\"", ")", "\n", "\n", "# print(question_fname)", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "starter_code", ")", ":", "\n", "                ", "answer_type", "=", "\"\\nUse Call-Based format\\n\"", "\n", "", "else", ":", "\n", "                ", "answer_type", "=", "\"\\nUse Standard Input format\\n\"", "\n", "\n", "", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "question_fname", ")", ")", "or", "(", "not", "os", ".", "path", ".", "isfile", "(", "sols_fname", ")", ")", ":", "\n", "                ", "skipped_problems", ".", "append", "(", "problem_name", ")", "\n", "continue", "\n", "\n", "", "if", "(", "os", ".", "path", ".", "isfile", "(", "starter_code", ")", ")", ":", "\n", "                ", "with", "open", "(", "starter_code", ",", "'r'", ")", "as", "f", ":", "\n", "                    ", "starter_code", "=", "f", ".", "read", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "starter_code", "=", "\"\"", "\n", "\n", "# Read the question description", "\n", "", "with", "open", "(", "question_fname", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "question_str", "=", "f", ".", "read", "(", ")", "\n", "\n", "# Read all the solutions", "\n", "", "with", "open", "(", "sols_fname", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "sols_str_list", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "sol_str", "in", "sols_str_list", ":", "\n", "                    ", "sol_str", "=", "reindent_code", "(", "sol_str", ")", "\n", "sample", "=", "(", "question_str", ",", "starter_code", ",", "sol_str", ",", "answer_type", ")", "\n", "\n", "all_samples", ".", "append", "(", "sample", ")", "\n", "if", "question_str", "in", "all_samples_dict", ":", "\n", "                        ", "all_samples_dict", "[", "question_str", "]", ".", "append", "(", "sample", ")", "\n", "", "else", ":", "\n", "                        ", "all_samples_dict", "[", "question_str", "]", "=", "[", "sample", "]", "\n", "\n", "", "", "", "", "print", "(", "f\"Loaded {len(all_samples)} saamples from {self.dataroot}.\"", ")", "\n", "print", "(", "f\"Skipped {len(skipped_problems)} problems from {self.dataroot}.\"", ")", "\n", "self", ".", "samples", "=", "all_samples", "\n", "self", ".", "samples_dict", "=", "all_samples_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.APPSBaseDataset.__len__": [[105, 107], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.APPSBaseDataset.pack_samples": [[109, 156], ["len", "len", "len", "curr_samples.append", "random.choice", "random.choice", "NotImplementedError", "random.choice.replace", "curr_s.replace.replace.replace", "curr_a.replace.replace.replace", "APPSBaseDataset.APPSBaseDataset.tokenizer.tokenize", "APPSBaseDataset.APPSBaseDataset.tokenizer.tokenize", "APPSBaseDataset.APPSBaseDataset.tokenizer.tokenize", "random.choice", "list", "random.choice", "random.choice", "NotImplementedError", "APPSBaseDataset.APPSBaseDataset.samples_dict.keys", "list", "APPSBaseDataset.APPSBaseDataset.samples_dict.keys"], "methods", ["None"], ["", "def", "pack_samples", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"\n        Repeatedly pick question, answer pairs from self.dataroot until we hit max_tokens.\n        This will not include the tokens for the QUESTION and ANSWER prompt, as well as the  \n        self.question_prefix. These will be added later and the total input will be \n        truncated if necessary.\n\n        Always include the sample at idx at the beginning.\n        \"\"\"", "\n", "curr_num_tokens", "=", "0", "\n", "curr_samples", "=", "[", "]", "\n", "\n", "if", "self", ".", "sample_mode", "==", "'uniform_sol'", ":", "\n", "            ", "curr_q", ",", "curr_s", ",", "curr_a", ",", "curr_q_prefix", "=", "self", ".", "samples", "[", "idx", "]", "\n", "", "elif", "self", ".", "sample_mode", "==", "'uniform_prob'", ":", "\n", "            ", "curr_q", "=", "random", ".", "choice", "(", "list", "(", "self", ".", "samples_dict", ".", "keys", "(", ")", ")", ")", "\n", "curr_q", ",", "curr_s", ",", "curr_a", ",", "curr_q_prefix", "=", "random", ".", "choice", "(", "self", ".", "samples_dict", "[", "curr_q", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "while", "curr_num_tokens", "<", "self", ".", "max_tokens", ":", "\n", "\n", "# Never remove. Fixes stalling bug.", "\n", "            ", "curr_q", "=", "curr_q", "[", ":", "150000", "]", "\n", "curr_s", "=", "curr_s", "[", ":", "150000", "]", "\n", "curr_a", "=", "curr_a", "[", ":", "150000", "]", "\n", "\n", "if", "self", ".", "mode", "in", "{", "'codebert'", "}", ":", "\n", "                ", "curr_q", "=", "curr_q", ".", "replace", "(", "'\\t'", ",", "'\\0'", ")", "\n", "curr_s", "=", "curr_s", ".", "replace", "(", "'\\t'", ",", "'\\0'", ")", "\n", "curr_a", "=", "curr_a", ".", "replace", "(", "'\\t'", ",", "'\\0'", ")", "\n", "\n", "", "curr_num_tokens", "+=", "len", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "curr_q", ")", ")", "\n", "curr_num_tokens", "+=", "len", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "curr_s", ")", ")", "\n", "curr_num_tokens", "+=", "len", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "curr_a", ")", ")", "\n", "\n", "curr_samples", ".", "append", "(", "(", "curr_q", ",", "curr_s", ",", "curr_a", ",", "curr_q_prefix", ")", ")", "\n", "\n", "if", "self", ".", "sample_mode", "==", "'uniform_sol'", ":", "\n", "                ", "curr_q", ",", "curr_s", ",", "curr_a", ",", "curr_q_prefix", "=", "random", ".", "choice", "(", "self", ".", "samples", ")", "\n", "", "elif", "self", ".", "sample_mode", "==", "'uniform_prob'", ":", "\n", "                ", "curr_q", "=", "random", ".", "choice", "(", "list", "(", "self", ".", "samples_dict", ".", "keys", "(", ")", ")", ")", "\n", "curr_q", ",", "curr_s", ",", "curr_a", ",", "curr_q_prefix", "=", "random", ".", "choice", "(", "self", ".", "samples_dict", "[", "curr_q", "]", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "", "return", "curr_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.APPSBaseDataset.__getitem__": [[157, 178], ["APPSBaseDataset.APPSBaseDataset.pack_samples", "gc.collect", "APPSBaseDataset.sample_gpt_task", "APPSBaseDataset.sample_gpt_task", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.APPSBaseDataset.pack_samples", "home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.sample_gpt_task", "home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.sample_gpt_task"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "\n", "        ", "raw_samples", "=", "self", ".", "pack_samples", "(", "idx", ")", "\n", "\n", "if", "'gpt'", "in", "self", ".", "mode", ":", "\n", "            ", "retval", "=", "sample_gpt_task", "(", "\n", "raw_samples", ",", "\n", "max_tokens", "=", "self", ".", "max_tokens", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", ")", "\n", "", "elif", "self", ".", "mode", "in", "{", "'codebert'", "}", ":", "\n", "            ", "retval", "=", "sample_gpt_task", "(", "\n", "raw_samples", ",", "\n", "max_tokens", "=", "self", ".", "max_tokens", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "gc", ".", "collect", "(", ")", "\n", "return", "retval", "\n", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.sample_gpt_task": [[179, 216], ["tokenizer.encode", "tokenizer.encode", "tokenizer.encode.append", "input_ids.extend", "input_ids.extend", "label_ids.extend", "label_ids.extend", "len", "len", "len", "print", "pdb.set_trace", "torch.LongTensor", "torch.LongTensor", "len", "len"], "function", ["None"], ["", "", "def", "sample_gpt_task", "(", "raw_samples", ",", "max_tokens", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\"\n    Create the true sample used for the GPT task\n    \"\"\"", "\n", "\n", "input_ids", "=", "[", "]", "\n", "label_ids", "=", "[", "]", "\n", "\n", "for", "q_str", ",", "s_str", ",", "a_str", ",", "answer_type", "in", "raw_samples", ":", "\n", "\n", "# Loss is not calculated on this", "\n", "        ", "q_str", "=", "\"\\nQUESTION:\\n\"", "+", "q_str", "+", "\"\\n\"", "+", "s_str", "+", "\"\\n\"", "+", "answer_type", "+", "\"\\nANSWER:\\n\"", "\n", "\n", "question_token_ids", "=", "tokenizer", ".", "encode", "(", "q_str", ",", "verbose", "=", "False", ")", "\n", "answer_token_ids", "=", "tokenizer", ".", "encode", "(", "a_str", ",", "verbose", "=", "False", ")", "\n", "answer_token_ids", ".", "append", "(", "tokenizer", ".", "eos_token_id", ")", "\n", "\n", "input_ids", ".", "extend", "(", "question_token_ids", ")", "\n", "input_ids", ".", "extend", "(", "answer_token_ids", ")", "\n", "\n", "label_ids", ".", "extend", "(", "[", "-", "100", "]", "*", "len", "(", "question_token_ids", ")", ")", "\n", "label_ids", ".", "extend", "(", "answer_token_ids", ")", "\n", "\n", "# Sanity check", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "len", "(", "label_ids", ")", "\n", "\n", "if", "len", "(", "input_ids", ")", "<", "max_tokens", ":", "\n", "        ", "print", "(", "len", "(", "input_ids", ")", ")", "\n", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "\n", "# Cut off the excess", "\n", "", "input_ids", "=", "input_ids", "[", ":", "max_tokens", "]", "\n", "label_ids", "=", "label_ids", "[", ":", "max_tokens", "]", "\n", "\n", "return", "{", "\n", "\"input_ids\"", ":", "torch", ".", "LongTensor", "(", "input_ids", ")", ",", "\n", "\"labels\"", ":", "torch", ".", "LongTensor", "(", "label_ids", ")", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.hendrycks_apps.dataset_apps.APPSBaseDataset.reindent_code": [[219, 244], ["io.StringIO", "io.StringIO", "dataset_lm.reindent.run", "io.StringIO.getvalue"], "function", ["home.repos.pwc.inspect_result.hendrycks_apps.dataset_lm.reindent.run"], ["", "def", "reindent_code", "(", "codestr", ")", ":", "\n", "    ", "\"\"\"\n    Given code string, reindent it in the same way that the\n    Github dataset was indented\n    \"\"\"", "\n", "codestr", "=", "io", ".", "StringIO", "(", "codestr", ")", "\n", "ret", "=", "io", ".", "StringIO", "(", ")", "\n", "\n", "run_reindent", "(", "\n", "codestr", ",", "\n", "ret", ",", "\n", "config", "=", "{", "\n", "\"dry-run\"", ":", "False", ",", "\n", "\"help\"", ":", "False", ",", "\n", "\"to\"", ":", "4", ",", "\n", "\"from\"", ":", "-", "1", ",", "\n", "\"tabs\"", ":", "True", ",", "\n", "\"encoding\"", ":", "\"utf-8\"", ",", "\n", "\"is-tabs\"", ":", "False", ",", "\n", "\"tabsize\"", ":", "4", ",", "\n", "\"all-tabs\"", ":", "False", "\n", "}", "\n", ")", "\n", "\n", "return", "ret", ".", "getvalue", "(", ")", "\n", "\n"]]}