{"home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.RNN.__init__": [[17, 30], ["torch.nn.Module.__init__", "torch.nn.RNN", "torch.nn.RNN", "torch.nn.RNN", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "fc_hidden_size", ",", "output_size", ",", "bidirectional", ",", "num_layers", "=", "1", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "RNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "RNN", "(", "\n", "input_size", "=", "input_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "dropout", "=", "dropout", "\n", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "fc_hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "fc_hidden_size", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.RNN.forward": [[32, 38], ["models.RNN.rnn", "models.RNN.fc2", "torch.relu", "torch.relu", "torch.relu", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "models.RNN.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "r_out", ",", "h_n", "=", "self", ".", "rnn", "(", "x", ",", "None", ")", "# r_out: (batch_size, seq_len, hidden_size)", "\n", "last_time_step_out", "=", "r_out", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "last_layer_output", "=", "self", ".", "fc2", "(", "F", ".", "relu", "(", "self", ".", "fc1", "(", "last_time_step_out", ")", ")", ")", "\n", "\n", "return", "r_out", ",", "nn", ".", "functional", ".", "log_softmax", "(", "last_layer_output", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.GRU.__init__": [[41, 54], ["torch.nn.Module.__init__", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.GRU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "fc_hidden_size", ",", "output_size", ",", "bidirectional", ",", "num_layers", "=", "1", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "GRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gru", "=", "nn", ".", "GRU", "(", "\n", "input_size", "=", "input_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "dropout", "=", "dropout", "\n", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "fc_hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "fc_hidden_size", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.GRU.forward": [[57, 64], ["models.GRU.gru", "models.GRU.fc2", "torch.relu", "torch.relu", "torch.relu", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "models.GRU.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "r_out", ",", "h_n", "=", "self", ".", "gru", "(", "x", ",", "None", ")", "# r_out: (batch_size, seq_len, hidden_size)", "\n", "\n", "last_time_step_out", "=", "r_out", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "last_layer_output", "=", "self", ".", "fc2", "(", "F", ".", "relu", "(", "self", ".", "fc1", "(", "last_time_step_out", ")", ")", ")", "\n", "\n", "return", "r_out", ",", "nn", ".", "functional", ".", "log_softmax", "(", "last_layer_output", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.LSTM.__init__": [[67, 80], ["torch.nn.Module.__init__", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "fc_hidden_size", ",", "output_size", ",", "bidirectional", ",", "num_layers", "=", "1", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "LSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "\n", "input_size", "=", "input_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "dropout", "=", "dropout", "\n", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "fc_hidden_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "fc_hidden_size", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.LSTM.forward": [[83, 90], ["models.LSTM.rnn", "models.LSTM.fc2", "torch.relu", "torch.relu", "torch.relu", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "models.LSTM.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "r_out", ",", "h_n", "=", "self", ".", "rnn", "(", "x", ",", "None", ")", "# r_out: (batch_size, seq_len, hidden_size)", "\n", "\n", "last_time_step_out", "=", "r_out", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "last_layer_output", "=", "self", ".", "fc2", "(", "F", ".", "relu", "(", "self", ".", "fc1", "(", "last_time_step_out", ")", ")", ")", "\n", "\n", "return", "r_out", ",", "nn", ".", "functional", ".", "log_softmax", "(", "last_layer_output", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.FNN.__init__": [[126, 141], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "len", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "models.FNN.hidden.append", "models.FNN.bn.append", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "output_size", ",", "non_linear", "=", "'tanh'", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "FNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", "[", "0", "]", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "hidden_size", "[", "0", "]", ")", "\n", "\n", "self", ".", "num_hidden", "=", "len", "(", "hidden_size", ")", "\n", "self", ".", "non_linear", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "hidden", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "bn", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_hidden", "-", "1", ")", ":", "\n", "            ", "self", ".", "hidden", ".", "append", "(", "nn", ".", "Linear", "(", "hidden_size", "[", "i", "]", ",", "hidden_size", "[", "i", "+", "1", "]", ")", ")", "\n", "self", ".", "bn", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "hidden_size", "[", "i", "+", "1", "]", ")", ")", "\n", "", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_size", "[", "self", ".", "num_hidden", "-", "1", "]", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.FNN.forward": [[142, 151], ["x.to", "models.FNN.dropout", "range", "models.FNN.fc2", "models.FNN.non_linear", "models.FNN.dropout", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "models.FNN.bn1", "models.FNN.non_linear", "models.FNN.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "global", "device", "\n", "var_x", "=", "x", ".", "to", "(", "device", "=", "device", ")", "#(100, 20, 160)", "\n", "logitis", "=", "self", ".", "dropout", "(", "self", ".", "non_linear", "(", "self", ".", "bn1", "(", "self", ".", "fc1", "(", "var_x", ")", ")", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_hidden", "-", "1", ")", ":", "\n", "            ", "logitis", "=", "self", ".", "dropout", "(", "self", ".", "non_linear", "(", "self", ".", "bn", "[", "i", "]", "(", "self", ".", "hidden", "[", "i", "]", "(", "logitis", ")", ")", ")", ")", "\n", "", "compressed_signal", "=", "logitis", "\n", "logitis", "=", "self", ".", "fc2", "(", "logitis", ")", "\n", "return", "compressed_signal", ",", "nn", ".", "functional", ".", "log_softmax", "(", "logitis", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.FNN_crelu.__init__": [[153, 180], ["torch.nn.Module.__init__", "len", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "models.FNN_crelu.w_real.append", "models.FNN_crelu.w_imag.append", "models.FNN_crelu.bn.append", "models.FNN_crelu.b.append", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.random.randn", "numpy.sqrt", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.random.randn", "numpy.sqrt", "numpy.random.randn", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "output_size", ",", "non_linear", "=", "'tanh'", ",", "dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "FNN_crelu", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden", "=", "len", "(", "hidden_size", ")", "\n", "self", ".", "non_linear", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n", "self", ".", "fc1_w_real", "=", "nn", ".", "Linear", "(", "input_size", "//", "2", ",", "hidden_size", "[", "0", "]", "//", "2", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc1_w_imag", "=", "nn", ".", "Linear", "(", "input_size", "//", "2", ",", "hidden_size", "[", "0", "]", "//", "2", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc1_b", "=", "torch", ".", "Tensor", "(", "np", ".", "random", ".", "randn", "(", "hidden_size", "[", "0", "]", ")", "/", "np", ".", "sqrt", "(", "hidden_size", "[", "0", "]", ")", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "hidden_size", "[", "0", "]", ")", "\n", "\n", "\n", "self", ".", "w_real", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "w_imag", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "bn", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "b", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_hidden", "-", "1", ")", ":", "\n", "            ", "self", ".", "w_real", ".", "append", "(", "nn", ".", "Linear", "(", "hidden_size", "[", "i", "]", "//", "2", ",", "hidden_size", "[", "i", "+", "1", "]", "//", "2", ",", "bias", "=", "False", ")", ")", "\n", "self", ".", "w_imag", ".", "append", "(", "nn", ".", "Linear", "(", "hidden_size", "[", "i", "]", "//", "2", ",", "hidden_size", "[", "i", "+", "1", "]", "//", "2", ",", "bias", "=", "False", ")", ")", "\n", "self", ".", "bn", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "hidden_size", "[", "i", "+", "1", "]", ")", ")", "\n", "self", ".", "b", ".", "append", "(", "torch", ".", "Tensor", "(", "np", ".", "random", ".", "randn", "(", "hidden_size", "[", "i", "+", "1", "]", ")", "/", "np", ".", "sqrt", "(", "hidden_size", "[", "i", "+", "1", "]", ")", ")", ".", "to", "(", "device", "=", "device", ")", ")", "\n", "\n", "", "self", ".", "fc2_w_real", "=", "nn", ".", "Linear", "(", "hidden_size", "[", "self", ".", "num_hidden", "-", "1", "]", "//", "2", ",", "output_size", "//", "2", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc2_w_imag", "=", "nn", ".", "Linear", "(", "hidden_size", "[", "self", ".", "num_hidden", "-", "1", "]", "//", "2", ",", "output_size", "//", "2", ",", "bias", "=", "False", ")", "\n", "self", ".", "fc2_b", "=", "torch", ".", "Tensor", "(", "np", ".", "random", ".", "randn", "(", "output_size", ")", "/", "np", ".", "sqrt", "(", "output_size", ")", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.FNN_crelu.forward": [[181, 217], ["x.to.to.to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.FNN_crelu.dropout", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.FNN_crelu.non_linear", "models.FNN_crelu.fc1_w_real", "models.FNN_crelu.fc1_w_imag", "models.FNN_crelu.fc1_w_imag", "models.FNN_crelu.fc1_w_real", "models.FNN_crelu.non_linear", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "models.FNN_crelu.dropout", "models.FNN_crelu.fc2_w_real", "models.FNN_crelu.fc2_w_imag", "models.FNN_crelu.fc2_w_imag", "models.FNN_crelu.fc2_w_real", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "models.FNN_crelu.bn1", "models.FNN_crelu.non_linear", "range", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "global", "device", "\n", "x", "=", "x", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "even_indices", "=", "torch", ".", "tensor", "(", "[", "i", "for", "i", "in", "range", "(", "self", ".", "input_size", ")", "if", "i", "%", "2", "==", "0", "]", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "odd_indices", "=", "torch", ".", "tensor", "(", "[", "i", "for", "i", "in", "range", "(", "self", ".", "input_size", ")", "if", "i", "%", "2", "==", "1", "]", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "real_input", "=", "torch", ".", "index_select", "(", "x", ",", "1", ",", "even_indices", ")", "# (bs, input_size/2) ", "\n", "imag_input", "=", "torch", ".", "index_select", "(", "x", ",", "1", ",", "odd_indices", ")", "# (bs, input_size/2) ", "\n", "up", "=", "self", ".", "fc1_w_real", "(", "real_input", ")", "-", "self", ".", "fc1_w_imag", "(", "imag_input", ")", "\n", "down", "=", "self", ".", "fc1_w_imag", "(", "real_input", ")", "+", "self", ".", "fc1_w_real", "(", "imag_input", ")", "\n", "logitis", "=", "torch", ".", "cat", "(", "(", "up", ",", "down", ")", ",", "dim", "=", "1", ")", "\n", "logitis", "+=", "self", ".", "fc1_b", "\n", "logitis", "=", "self", ".", "dropout", "(", "self", ".", "non_linear", "(", "self", ".", "bn1", "(", "logitis", ")", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_hidden", "-", "1", ")", ":", "\n", "            ", "real_input", "=", "logitis", "[", ":", ",", ":", "self", ".", "hidden_size", "[", "i", "]", "//", "2", "]", "\n", "imag_input", "=", "logitis", "[", ":", ",", "self", ".", "hidden_size", "[", "i", "]", "//", "2", ":", "]", "\n", "up", "=", "self", ".", "w_real", "[", "i", "]", "(", "real_input", ")", "-", "self", ".", "w_imag", "[", "i", "]", "(", "imag_input", ")", "\n", "down", "=", "self", ".", "w_imag", "[", "i", "]", "(", "real_input", ")", "+", "self", ".", "w_real", "[", "i", "]", "(", "imag_input", ")", "\n", "logitis", "=", "torch", ".", "cat", "(", "(", "up", ",", "down", ")", ",", "dim", "=", "1", ")", "\n", "logitis", "+=", "self", ".", "b", "[", "i", "]", "\n", "logitis", "=", "self", ".", "dropout", "(", "self", ".", "non_linear", "(", "self", ".", "bn", "[", "i", "]", "(", "logitis", ")", ")", ")", "\n", "\n", "", "compressed_signal", "=", "logitis", "\n", "\n", "var_real_input", "=", "logitis", "[", ":", ",", ":", "self", ".", "hidden_size", "[", "self", ".", "num_hidden", "-", "1", "]", "//", "2", "]", "\n", "var_imag_input", "=", "logitis", "[", ":", ",", "self", ".", "hidden_size", "[", "self", ".", "num_hidden", "-", "1", "]", "//", "2", ":", "]", "\n", "\n", "up", "=", "self", ".", "fc2_w_real", "(", "var_real_input", ")", "-", "self", ".", "fc2_w_imag", "(", "var_imag_input", ")", "\n", "down", "=", "self", ".", "fc2_w_imag", "(", "var_real_input", ")", "+", "self", ".", "fc2_w_real", "(", "var_imag_input", ")", "\n", "logitis", "=", "torch", ".", "cat", "(", "(", "up", ",", "down", ")", ",", "dim", "=", "1", ")", "\n", "logitis", "+=", "self", ".", "fc2_b", "\n", "logitis", "=", "self", ".", "non_linear", "(", "logitis", ")", "\n", "\n", "return", "compressed_signal", ",", "nn", ".", "functional", ".", "log_softmax", "(", "logitis", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexSequential.forward": [[219, 223], ["models.ComplexSequential._modules.values", "module"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "input_r", ",", "input_t", ")", ":", "\n", "        ", "for", "module", "in", "self", ".", "_modules", ".", "values", "(", ")", ":", "\n", "            ", "input_r", ",", "input_t", "=", "module", "(", "input_r", ",", "input_t", ")", "\n", "", "return", "input_r", ",", "input_t", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexDropout.__init__": [[225, 231], ["torch.nn.Module.__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "p", "=", "0.5", ",", "inplace", "=", "False", ")", ":", "\n", "        ", "super", "(", "ComplexDropout", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "inplace", "=", "inplace", "\n", "self", ".", "dropout_r", "=", "nn", ".", "Dropout", "(", "p", ",", "inplace", ")", "\n", "self", ".", "dropout_i", "=", "nn", ".", "Dropout", "(", "p", ",", "inplace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexDropout.forward": [[232, 234], ["models.ComplexDropout.dropout_r", "models.ComplexDropout.dropout_i"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_r", ",", "input_i", ")", ":", "\n", "        ", "return", "self", ".", "dropout_r", "(", "input_r", ")", ",", "self", ".", "dropout_i", "(", "input_i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexReLU.__init__": [[236, 240], ["torch.nn.Module.__init__", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ComplexReLU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "relu_r", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "relu_i", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexReLU.forward": [[241, 243], ["models.ComplexReLU.relu_r", "models.ComplexReLU.relu_i"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_r", ",", "input_i", ")", ":", "\n", "        ", "return", "self", ".", "relu_r", "(", "input_r", ")", ",", "self", ".", "relu_i", "(", "input_i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexConv1d.__init__": [[246, 251], ["torch.nn.Module.__init__", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "ComplexConv1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_r", "=", "nn", ".", "Conv1d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "padding", ",", "dilation", ",", "groups", ",", "bias", ")", "\n", "self", ".", "conv_i", "=", "nn", ".", "Conv1d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "padding", ",", "dilation", ",", "groups", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexConv1d.forward": [[252, 255], ["models.ComplexConv1d.conv_r", "models.ComplexConv1d.conv_i", "models.ComplexConv1d.conv_r", "models.ComplexConv1d.conv_i"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_r", ",", "input_i", ")", ":", "\n", "        ", "return", "self", ".", "conv_r", "(", "input_r", ")", "-", "self", ".", "conv_i", "(", "input_i", ")", ",", "self", ".", "conv_r", "(", "input_i", ")", "+", "self", ".", "conv_i", "(", "input_r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexMaxPool1d.__init__": [[258, 275], ["torch.nn.Module.__init__", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "kernel_size", ",", "stride", "=", "None", ",", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "return_indices", "=", "False", ",", "ceil_mode", "=", "False", ")", ":", "\n", "        ", "super", "(", "ComplexMaxPool1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "ceil_mode", "=", "ceil_mode", "\n", "self", ".", "return_indices", "=", "return_indices", "\n", "self", ".", "maxpool_r", "=", "nn", ".", "MaxPool1d", "(", "kernel_size", "=", "self", ".", "kernel_size", ",", "\n", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ",", "\n", "dilation", "=", "self", ".", "dilation", ",", "ceil_mode", "=", "self", ".", "ceil_mode", ",", "\n", "return_indices", "=", "self", ".", "return_indices", ")", "\n", "self", ".", "maxpool_i", "=", "nn", ".", "MaxPool1d", "(", "kernel_size", "=", "self", ".", "kernel_size", ",", "\n", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ",", "\n", "dilation", "=", "self", ".", "dilation", ",", "ceil_mode", "=", "self", ".", "ceil_mode", ",", "\n", "return_indices", "=", "self", ".", "return_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexMaxPool1d.forward": [[276, 278], ["models.ComplexMaxPool1d.maxpool_r", "models.ComplexMaxPool1d.maxpool_i"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_r", ",", "input_i", ")", ":", "\n", "        ", "return", "self", ".", "maxpool_r", "(", "input_r", ")", ",", "self", ".", "maxpool_i", "(", "input_i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexLinear.__init__": [[281, 285], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ")", ":", "\n", "        ", "super", "(", "ComplexLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc_r", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ")", "\n", "self", ".", "fc_i", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexLinear.forward": [[286, 289], ["models.ComplexLinear.fc_r", "models.ComplexLinear.fc_i", "models.ComplexLinear.fc_r", "models.ComplexLinear.fc_i"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_r", ",", "input_i", ")", ":", "\n", "        ", "return", "self", ".", "fc_r", "(", "input_r", ")", "-", "self", ".", "fc_i", "(", "input_i", ")", ",", "self", ".", "fc_r", "(", "input_i", ")", "+", "self", ".", "fc_i", "(", "input_r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models._ComplexBatchNorm.__init__": [[292, 317], ["torch.nn.Module.__init__", "models._ComplexBatchNorm.reset_parameters", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "models._ComplexBatchNorm.register_parameter", "models._ComplexBatchNorm.register_parameter", "models._ComplexBatchNorm.register_buffer", "models._ComplexBatchNorm.register_buffer", "models._ComplexBatchNorm.register_buffer", "models._ComplexBatchNorm.register_parameter", "models._ComplexBatchNorm.register_parameter", "models._ComplexBatchNorm.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "\n", "track_running_stats", "=", "True", ")", ":", "\n", "        ", "super", "(", "_ComplexBatchNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "momentum", "=", "momentum", "\n", "self", ".", "affine", "=", "affine", "\n", "self", ".", "track_running_stats", "=", "track_running_stats", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "num_features", ",", "3", ")", ")", "\n", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "num_features", ",", "2", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'weight'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "", "if", "self", ".", "track_running_stats", ":", "\n", "            ", "self", ".", "register_buffer", "(", "'running_mean'", ",", "torch", ".", "zeros", "(", "num_features", ",", "2", ")", ")", "\n", "self", ".", "register_buffer", "(", "'running_covar'", ",", "torch", ".", "zeros", "(", "num_features", ",", "3", ")", ")", "\n", "self", ".", "running_covar", "[", ":", ",", "0", "]", "=", "1.4142135623730951", "\n", "self", ".", "running_covar", "[", ":", ",", "1", "]", "=", "1.4142135623730951", "\n", "self", ".", "register_buffer", "(", "'num_batches_tracked'", ",", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'running_mean'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'running_covar'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'num_batches_tracked'", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models._ComplexBatchNorm.reset_running_stats": [[318, 325], ["models._ComplexBatchNorm.running_mean.zero_", "models._ComplexBatchNorm.running_covar.zero_", "models._ComplexBatchNorm.num_batches_tracked.zero_"], "methods", ["None"], ["", "def", "reset_running_stats", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "track_running_stats", ":", "\n", "            ", "self", ".", "running_mean", ".", "zero_", "(", ")", "\n", "self", ".", "running_covar", ".", "zero_", "(", ")", "\n", "self", ".", "running_covar", "[", ":", ",", "0", "]", "=", "1.4142135623730951", "\n", "self", ".", "running_covar", "[", ":", ",", "1", "]", "=", "1.4142135623730951", "\n", "self", ".", "num_batches_tracked", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models._ComplexBatchNorm.reset_parameters": [[326, 332], ["models._ComplexBatchNorm.reset_running_stats", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models._ComplexBatchNorm.reset_running_stats"], ["", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset_running_stats", "(", ")", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "weight", "[", ":", ",", ":", "2", "]", ",", "1.4142135623730951", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "weight", "[", ":", ",", "2", "]", ")", "\n", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexBatchNorm1d.forward": [[335, 415], ["input_r.reshape.reshape.reshape", "input_i.reshape.reshape.reshape", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "input_r.reshape.reshape.reshape", "input_i.reshape.reshape.reshape", "input_r.reshape.reshape.size", "input_i.reshape.reshape.size", "input_r.reshape.reshape.mean", "input_i.reshape.reshape.mean", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "input_r.reshape.reshape.mul().mean", "input_r.reshape.mul().mean.pow", "input_r.reshape.reshape.numel", "input_r.reshape.reshape.size", "input_r.reshape.reshape.var", "input_i.reshape.reshape.var", "input_r.reshape.reshape.mul", "float"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "input_r", ",", "input_i", ")", ":", "\n", "        ", "assert", "(", "input_r", ".", "size", "(", ")", "==", "input_i", ".", "size", "(", ")", ")", "\n", "shape", "=", "input_r", ".", "shape", "\n", "input_r", "=", "input_r", ".", "reshape", "(", "-", "1", ",", "shape", "[", "1", "]", ")", "\n", "input_i", "=", "input_i", ".", "reshape", "(", "-", "1", ",", "shape", "[", "1", "]", ")", "\n", "\n", "exponential_average_factor", "=", "0.0", "\n", "\n", "\n", "if", "self", ".", "training", "and", "self", ".", "track_running_stats", ":", "\n", "            ", "if", "self", ".", "num_batches_tracked", "is", "not", "None", ":", "\n", "                ", "self", ".", "num_batches_tracked", "+=", "1", "\n", "if", "self", ".", "momentum", "is", "None", ":", "# use cumulative moving average", "\n", "                    ", "exponential_average_factor", "=", "1.0", "/", "float", "(", "self", ".", "num_batches_tracked", ")", "\n", "", "else", ":", "# use exponential moving average", "\n", "                    ", "exponential_average_factor", "=", "self", ".", "momentum", "\n", "\n", "", "", "", "if", "self", ".", "training", ":", "\n", "\n", "# calculate mean of real and imaginary part", "\n", "            ", "mean_r", "=", "input_r", ".", "mean", "(", "dim", "=", "0", ")", "\n", "mean_i", "=", "input_i", ".", "mean", "(", "dim", "=", "0", ")", "\n", "mean", "=", "torch", ".", "stack", "(", "(", "mean_r", ",", "mean_i", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# update running mean", "\n", "self", ".", "running_mean", "=", "exponential_average_factor", "*", "mean", "+", "(", "1", "-", "exponential_average_factor", ")", "*", "self", ".", "running_mean", "\n", "\n", "# zero mean values", "\n", "input_r", "=", "input_r", "-", "mean_r", "[", "None", ",", ":", "]", "\n", "input_i", "=", "input_i", "-", "mean_i", "[", "None", ",", ":", "]", "\n", "\n", "\n", "# Elements of the covariance matrix (biased for train)", "\n", "n", "=", "input_r", ".", "numel", "(", ")", "/", "input_r", ".", "size", "(", "1", ")", "\n", "Crr", "=", "input_r", ".", "var", "(", "dim", "=", "0", ",", "unbiased", "=", "False", ")", "+", "self", ".", "eps", "\n", "Cii", "=", "input_i", ".", "var", "(", "dim", "=", "0", ",", "unbiased", "=", "False", ")", "+", "self", ".", "eps", "\n", "Cri", "=", "(", "input_r", ".", "mul", "(", "input_i", ")", ")", ".", "mean", "(", "dim", "=", "0", ")", "\n", "\n", "self", ".", "running_covar", "[", ":", ",", "0", "]", "=", "exponential_average_factor", "*", "Crr", "*", "n", "/", "(", "n", "-", "1", ")", "+", "(", "1", "-", "exponential_average_factor", ")", "*", "self", ".", "running_covar", "[", ":", ",", "0", "]", "\n", "\n", "self", ".", "running_covar", "[", ":", ",", "1", "]", "=", "exponential_average_factor", "*", "Cii", "*", "n", "/", "(", "n", "-", "1", ")", "+", "(", "1", "-", "exponential_average_factor", ")", "*", "self", ".", "running_covar", "[", ":", ",", "1", "]", "\n", "\n", "self", ".", "running_covar", "[", ":", ",", "2", "]", "=", "exponential_average_factor", "*", "Cri", "*", "n", "/", "(", "n", "-", "1", ")", "+", "(", "1", "-", "exponential_average_factor", ")", "*", "self", ".", "running_covar", "[", ":", ",", "2", "]", "\n", "\n", "", "else", ":", "\n", "            ", "mean", "=", "self", ".", "running_mean", "\n", "Crr", "=", "self", ".", "running_covar", "[", ":", ",", "0", "]", "+", "self", ".", "eps", "\n", "Cii", "=", "self", ".", "running_covar", "[", ":", ",", "1", "]", "+", "self", ".", "eps", "\n", "Cri", "=", "self", ".", "running_covar", "[", ":", ",", "2", "]", "\n", "# zero mean values", "\n", "input_r", "=", "input_r", "-", "mean", "[", "None", ",", ":", ",", "0", "]", "\n", "input_i", "=", "input_i", "-", "mean", "[", "None", ",", ":", ",", "1", "]", "\n", "\n", "# calculate the inverse square root the covariance matrix", "\n", "", "det", "=", "Crr", "*", "Cii", "-", "Cri", ".", "pow", "(", "2", ")", "\n", "s", "=", "torch", ".", "sqrt", "(", "det", ")", "\n", "t", "=", "torch", ".", "sqrt", "(", "Cii", "+", "Crr", "+", "2", "*", "s", ")", "\n", "inverse_st", "=", "1.0", "/", "(", "s", "*", "t", ")", "\n", "Rrr", "=", "(", "Cii", "+", "s", ")", "*", "inverse_st", "\n", "Rii", "=", "(", "Crr", "+", "s", ")", "*", "inverse_st", "\n", "Rri", "=", "-", "Cri", "*", "inverse_st", "\n", "\n", "input_r", ",", "input_i", "=", "Rrr", "[", "None", ",", ":", "]", "*", "input_r", "+", "Rri", "[", "None", ",", ":", "]", "*", "input_i", ",", "Rii", "[", "None", ",", ":", "]", "*", "input_i", "+", "Rri", "[", "None", ",", ":", "]", "*", "input_r", "\n", "\n", "if", "self", ".", "affine", ":", "\n", "            ", "input_r", ",", "input_i", "=", "self", ".", "weight", "[", "None", ",", ":", ",", "0", "]", "*", "input_r", "+", "self", ".", "weight", "[", "None", ",", ":", ",", "2", "]", "*", "input_i", "+", "self", ".", "bias", "[", "None", ",", ":", ",", "0", "]", ",", "self", ".", "weight", "[", "None", ",", ":", ",", "2", "]", "*", "input_r", "+", "self", ".", "weight", "[", "None", ",", ":", ",", "1", "]", "*", "input_i", "+", "self", ".", "bias", "[", "None", ",", ":", ",", "1", "]", "\n", "\n", "", "del", "Crr", ",", "Cri", ",", "Cii", ",", "Rrr", ",", "Rii", ",", "Rri", ",", "det", ",", "s", ",", "t", "\n", "input_r", "=", "input_r", ".", "reshape", "(", "shape", ")", "\n", "input_i", "=", "input_i", ".", "reshape", "(", "shape", ")", "\n", "\n", "return", "input_r", ",", "input_i", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.ComplexFlatten.forward": [[417, 421], ["input_r.view.view.view", "input_i.view.view.view", "input_r.view.view.size", "input_i.view.view.size"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "input_r", ",", "input_i", ")", ":", "\n", "        ", "input_r", "=", "input_r", ".", "view", "(", "input_r", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", "\n", "input_i", "=", "input_i", ".", "view", "(", "input_i", ".", "size", "(", ")", "[", "0", "]", ",", "-", "1", ")", "\n", "return", "input_r", ",", "input_i", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.Encoder_LSTM.__init__": [[450, 461], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "hid_dim", ",", "n_layers", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "embedding", "=", "nn", ".", "Linear", "(", "input_dim", ",", "input_dim", ")", "\n", "self", ".", "hid_dim", "=", "hid_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "\n", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_dim", ",", "hid_dim", ",", "n_layers", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.Encoder_LSTM.forward": [[462, 469], ["models.Encoder_LSTM.dropout", "models.Encoder_LSTM.lstm", "models.Encoder_LSTM.embedding"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ")", ":", "\n", "\n", "#src = [src sent len, batch size, input_dim]", "\n", "        ", "src", "=", "self", ".", "dropout", "(", "self", ".", "embedding", "(", "src", ")", ")", "\n", "outputs", ",", "(", "hidden", ",", "cell", ")", "=", "self", ".", "lstm", "(", "src", ")", "\n", "\n", "return", "hidden", ",", "cell", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.Decoder_LSTM.__init__": [[471, 485], ["torch.nn.Module.__init__", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "output_dim", ",", "hid_dim", ",", "n_layers", ",", "dropout", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "hid_dim", "=", "hid_dim", "\n", "self", ".", "output_dim", "=", "input_dim", "\n", "self", ".", "final_output_dim", "=", "output_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_dim", ",", "hid_dim", ",", "n_layers", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "input_dim", ",", "self", ".", "input_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "self", ".", "hid_dim", ",", "self", ".", "output_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.Decoder_LSTM.forward": [[486, 493], ["models.Decoder_LSTM.unsqueeze", "models.Decoder_LSTM.dropout", "models.Decoder_LSTM.lstm", "models.Decoder_LSTM.fc2", "models.Decoder_LSTM.fc1", "output.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", ",", "cell", ")", ":", "\n", "\n", "        ", "input", "=", "input", ".", "unsqueeze", "(", "0", ")", "# inserting a new dimension to be seq len ", "\n", "input", "=", "self", ".", "dropout", "(", "self", ".", "fc1", "(", "input", ")", ")", "\n", "output", ",", "(", "hidden", ",", "cell", ")", "=", "self", ".", "lstm", "(", "input", ",", "(", "hidden", ",", "cell", ")", ")", "\n", "prediction", "=", "self", ".", "fc2", "(", "output", ".", "squeeze", "(", "0", ")", ")", "\n", "return", "prediction", ",", "hidden", ",", "cell", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.Seq2Seq.__init__": [[496, 507], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "device", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "out_fc", "=", "nn", ".", "Linear", "(", "decoder", ".", "output_dim", ",", "decoder", ".", "final_output_dim", ")", "\n", "self", ".", "final_fc", "=", "nn", ".", "Linear", "(", "decoder", ".", "final_output_dim", ",", "1000", ")", "\n", "assert", "encoder", ".", "hid_dim", "==", "decoder", ".", "hid_dim", ",", "\"Hidden dimensions of encoder and decoder must be equal!\"", "\n", "assert", "encoder", ".", "n_layers", "==", "decoder", ".", "n_layers", ",", "\"Encoder and decoder must have equal number of layers!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.Seq2Seq.forward": [[508, 532], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "models.Seq2Seq.encoder", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "models.Seq2Seq.out_fc", "models.Seq2Seq.decoder", "models.Seq2Seq.final_fc", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "random.random"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "trg", ",", "dataset", ",", "teacher_forcing_ratio", "=", "0.0", ")", ":", "\n", "        ", "batch_size", "=", "trg", ".", "shape", "[", "1", "]", "\n", "max_len", "=", "trg", ".", "shape", "[", "0", "]", "\n", "trg_input_size", "=", "trg", ".", "shape", "[", "2", "]", "\n", "trg_output_dim", "=", "self", ".", "decoder", ".", "output_dim", "\n", "\n", "#tensor to store decoder outputs", "\n", "outputs", "=", "torch", ".", "zeros", "(", "max_len", ",", "batch_size", ",", "trg_output_dim", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "#last hidden state of the encoder is used as the initial hidden state of the decoder", "\n", "hidden", ",", "cell", "=", "self", ".", "encoder", "(", "src", ")", "\n", "\n", "#first input to the decoder is the <sos> tokens", "\n", "input", "=", "torch", ".", "zeros", "(", "batch_size", ",", "trg_input_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "for", "t", "in", "range", "(", "max_len", ")", ":", "\n", "            ", "output", ",", "hidden", ",", "cell", "=", "self", ".", "decoder", "(", "input", ",", "hidden", ",", "cell", ")", "# output: [batch size, output dim]", "\n", "outputs", "[", "t", "]", "=", "output", "# storing ouput at: 1 -> max_len ", "\n", "teacher_force", "=", "random", ".", "random", "(", ")", "<", "teacher_forcing_ratio", "\n", "input", "=", "(", "trg", "[", "t", "]", "if", "teacher_force", "else", "output", ")", "\n", "", "outputs", "=", "self", ".", "out_fc", "(", "outputs", ")", "\n", "if", "dataset", "==", "\"iq\"", ":", "\n", "            ", "outputs", "=", "self", ".", "final_fc", "(", "outputs", "[", "-", "1", "]", ")", "\n", "", "return", "outputs", "# (seq_len, bs, output_dim)", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.eval_RNN_Model": [[91, 123], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "model.eval", "print", "len", "data_batched.reshape.reshape", "numpy.argmax().long", "data_batched.reshape.float().to", "np.argmax().long.view().to", "numpy.asarray", "model", "loss_func().item", "numpy.argmax", "float", "float", "output.data.cpu().numpy", "numpy.argmax", "data_batched.reshape.float", "np.argmax().long.view", "loss_func", "output.data.cpu"], "function", ["None"], ["", "", "def", "eval_RNN_Model", "(", "data_loader", ",", "time_step", ",", "input_size", ",", "model", ",", "num_classes", ",", "loss_func", ",", "name", ",", "path", ")", ":", "\n", "    ", "global", "device", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "total_loss", "=", "0", "\n", "total_pred", "=", "0", "\n", "total_correct", "=", "0", "\n", "for", "data_batched", ",", "label_batched", "in", "data_loader", ":", "\n", "# prepare inputs", "\n", "            ", "cur_batch_size", "=", "len", "(", "data_batched", ")", "\n", "data_batched", "=", "data_batched", ".", "reshape", "(", "cur_batch_size", ",", "time_step", ",", "input_size", ")", "# (batch_size, feature_dim) -> (batch_size, time_step, input_size) ", "\n", "label_batched", "=", "np", ".", "argmax", "(", "label_batched", ",", "axis", "=", "1", ")", ".", "long", "(", ")", "\n", "\n", "data_var", "=", "data_batched", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "label_var", "=", "label_batched", ".", "view", "(", "-", "1", ")", ".", "to", "(", "device", "=", "device", ")", "# (batch_size)", "\n", "\n", "label_np", "=", "np", ".", "asarray", "(", "label_batched", ")", "\n", "\n", "# run model and eval ", "\n", "compressed_signal", ",", "output", "=", "model", "(", "data_var", ")", "\n", "loss", "=", "loss_func", "(", "output", ",", "label_var", ")", ".", "item", "(", ")", "\n", "pred", "=", "np", ".", "argmax", "(", "output", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", "\n", "\n", "total_loss", "+=", "loss", "\n", "total_pred", "+=", "cur_batch_size", "\n", "total_correct", "+=", "(", "pred", "==", "label_np", ")", ".", "sum", "(", ")", "\n", "\n", "", "acc", "=", "float", "(", "total_correct", ")", "/", "float", "(", "total_pred", ")", "\n", "print", "(", "\"%s loss %f and acc %f \"", "%", "(", "name", ",", "total_loss", ",", "acc", ")", ")", "\n", "\n", "", "return", "None", ",", "total_loss", ",", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.eval_FNN": [[423, 447], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "model.eval", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "numpy.argmax", "torch.from_numpy().long().view().to", "torch.from_numpy().long().view().to", "torch.from_numpy().long().view().to", "model", "output.view.view", "loss_func().item", "numpy.argmax", "numpy.mean", "print", "sklearn.metrics.confusion_matrix", "os.path.join", "numpy.save", "output.view.data.cpu().numpy", "np.argmax.reshape", "sklearn.metrics.confusion_matrix.astype", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().long().view", "torch.from_numpy().long().view", "torch.from_numpy().long().view", "loss_func", "np.argmax.reshape", "sklearn.metrics.confusion_matrix.sum", "output.view.data.cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "", "def", "eval_FNN", "(", "data", ",", "label", ",", "model", ",", "num_classes", ",", "loss_func", ",", "name", ",", "path", ")", ":", "\n", "    ", "global", "device", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "data", "=", "torch", ".", "from_numpy", "(", "data", ")", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "true_label", "=", "np", ".", "argmax", "(", "label", ",", "axis", "=", "1", ")", "\n", "label", "=", "torch", ".", "from_numpy", "(", "true_label", ")", ".", "long", "(", ")", ".", "view", "(", "-", "1", ")", ".", "to", "(", "device", "=", "device", ")", "# -1", "\n", "compressed_signal", ",", "output", "=", "model", "(", "data", ")", "\n", "output", "=", "output", ".", "view", "(", "-", "1", ",", "num_classes", ")", "\n", "l", "=", "loss_func", "(", "output", ",", "label", ")", ".", "item", "(", ")", "\n", "pred", "=", "np", ".", "argmax", "(", "output", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", "\n", "acc", "=", "np", ".", "mean", "(", "pred", "==", "true_label", ".", "reshape", "(", "-", "1", ")", ")", "\n", "print", "(", "\"%s loss %f and acc %f \"", "%", "(", "name", ",", "l", ",", "acc", ")", ")", "\n", "\n", "#Confusion Matrix Calculator", "\n", "cnf_matrix", "=", "confusion_matrix", "(", "true_label", ".", "reshape", "(", "-", "1", ")", ",", "pred", ")", "\n", "\n", "#Normalize Confusion Matrix", "\n", "cnf_matrix", "=", "cnf_matrix", ".", "astype", "(", "'float'", ")", "/", "cnf_matrix", ".", "sum", "(", "axis", "=", "1", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'confusion_matrix_'", "+", "name", ")", "\n", "np", ".", "save", "(", "save_path", ",", "cnf_matrix", ")", "\n", "", "return", "compressed_signal", ",", "l", ",", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.models.eval_Seq2Seq": [[533, 556], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "model.eval", "print", "len", "data_batched[].transpose().float().cuda", "data_batched[].transpose().float().cuda", "label_batched.cuda", "model", "criterion.detach().item", "label_batched[].transpose().cuda", "criterion", "float", "data_batched[].transpose().float", "data_batched[].transpose().float", "model.transpose().double", "label_batched[].transpose().cuda.transpose().double", "criterion", "criterion.detach", "len", "float", "label_batched[].transpose", "model.double", "label_batched[].transpose().cuda.long", "len", "data_batched[].transpose", "data_batched[].transpose", "model.transpose", "label_batched[].transpose().cuda.transpose"], "function", ["None"], ["", "", "def", "eval_Seq2Seq", "(", "data_loader", ",", "src_time_step", ",", "trg_time_step", ",", "input_size", ",", "model", ",", "criterion", ",", "name", ",", "path", ",", "device", ",", "dataset", ",", "dataset_raw", ")", ":", "\n", "    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "epoch_loss", "=", "0", "\n", "for", "data_batched", ",", "label_batched", "in", "data_loader", ":", "\n", "            ", "cur_batch_size", "=", "len", "(", "data_batched", ")", "\n", "src", "=", "data_batched", "[", ":", ",", "0", ":", "src_time_step", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg", "=", "data_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg_label", "=", "label_batched", ".", "cuda", "(", ")", "\n", "outputs", "=", "model", "(", "src", "=", "src", ",", "trg", "=", "trg", ",", "dataset", "=", "dataset", ")", "# (ts, bs, input_size)", "\n", "if", "dataset", "==", "\"music\"", ":", "\n", "                ", "trg_label", "=", "label_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "cuda", "(", ")", "\n", "loss", "=", "criterion", "(", "outputs", ".", "transpose", "(", "0", ",", "1", ")", ".", "double", "(", ")", ",", "trg_label", ".", "transpose", "(", "0", ",", "1", ")", ".", "double", "(", ")", ")", "\n", "", "elif", "dataset", "==", "\"iq\"", ":", "\n", "                ", "loss", "=", "criterion", "(", "outputs", ".", "double", "(", ")", ",", "trg_label", ".", "long", "(", ")", ")", "\n", "", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "", "if", "dataset", "==", "\"music\"", ":", "\n", "            ", "avg_loss", "=", "epoch_loss", "/", "float", "(", "len", "(", "data_loader", ")", ")", "\n", "", "elif", "dataset", "==", "\"iq\"", ":", "\n", "            ", "avg_loss", "=", "epoch_loss", "/", "float", "(", "len", "(", "dataset_raw", ")", ")", "\n", "", "print", "(", "\"%s loss %f\"", "%", "(", "name", ",", "avg_loss", ")", ")", "\n", "", "return", "avg_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.gru.save_checkpoint": [[17, 21], ["torch.save", "torch.save", "shutil.copyfile"], "function", ["None"], ["def", "save_checkpoint", "(", "state", ",", "is_best", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "filename", ",", "'model_best.pth.tar'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.fnn_iq.count_parameters": [[17, 19], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.fnn_crelu.save_checkpoint": [[11, 15], ["torch.save", "shutil.copyfile"], "function", ["None"], ["def", "save_checkpoint", "(", "state", ",", "is_best", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "filename", ",", "'model_best.pth.tar'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.SignalDataset.__init__": [[61, 81], ["utils.get_len", "sklearn.preprocessing.scale().reshape", "print", "print", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "sklearn.preprocessing.scale", "utils.SignalDataset.data.reshape"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.get_len"], ["def", "__init__", "(", "self", ",", "root_dir", ",", "train", "=", "True", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "root_dir", "=", "root_dir", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "data", "=", "None", "\n", "self", ".", "label", "=", "None", "\n", "self", ".", "len", "=", "get_len", "(", "root_dir", ",", "train", ")", "\n", "\n", "if", "train", ":", "\n", "            ", "self", ".", "data", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"train_data.npz.npy\"", ")", ")", "\n", "self", ".", "label", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"train_label.npz.npy\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "data", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"test_data.npz.npy\"", ")", ")", "\n", "self", ".", "label", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"test_label.npz.npy\"", ")", ")", "\n", "\n", "#Normalize data", "\n", "", "self", ".", "data", "=", "scale", "(", "self", ".", "data", ".", "reshape", "(", "self", ".", "len", ",", "-", "1", ")", ",", "axis", "=", "0", ")", ".", "reshape", "(", "self", ".", "data", ".", "shape", ")", "\n", "self", ".", "num_classes", "=", "self", ".", "label", ".", "shape", "[", "2", "]", "\n", "\n", "print", "(", "self", ".", "data", ".", "shape", ")", "\n", "print", "(", "self", ".", "label", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.SignalDataset.__len__": [[83, 85], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "len", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.SignalDataset.__getitem__": [[86, 92], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "data", "=", "self", ".", "data", "[", "idx", "]", "\n", "label", "=", "self", ".", "label", "[", "idx", "]", "\n", "#sample = {'data': data, 'label': label}", "\n", "\n", "return", "data", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.SignalDataset_iq.__init__": [[99, 121], ["utils.SignalDataset_iq.data.reshape", "utils.SignalDataset_iq.label.reshape", "numpy.argmax", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "root_dir", ",", "time_step", ",", "train", "=", "True", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "root_dir", "=", "root_dir", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "data", "=", "None", "\n", "self", ".", "label", "=", "None", "\n", "self", ".", "real", "=", "None", "\n", "self", ".", "imag", "=", "None", "\n", "\n", "if", "train", ":", "\n", "            ", "self", ".", "data", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"iq_train_data.npy\"", ")", ")", "\n", "self", ".", "label", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"iq_train_label.npy\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "data", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"iq_test_data.npy\"", ")", ")", "\n", "self", ".", "label", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"iq_test_label.npy\"", ")", ")", "\n", "\n", "", "out_batch", ",", "in_batch", ",", "_", ",", "_", "=", "self", ".", "data", ".", "shape", "\n", "self", ".", "len", "=", "out_batch", "*", "in_batch", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "reshape", "(", "self", ".", "len", ",", "time_step", ",", "-", "1", ")", "\n", "\n", "self", ".", "num_classes", "=", "self", ".", "label", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "label", "=", "self", ".", "label", ".", "reshape", "(", "self", ".", "len", ",", "self", ".", "num_classes", ")", "# (# data, 1)", "\n", "self", ".", "label", "=", "np", ".", "argmax", "(", "self", ".", "label", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.SignalDataset_iq.__len__": [[122, 124], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "len", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.SignalDataset_iq.__getitem__": [[125, 130], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "data", "=", "self", ".", "data", "[", "idx", "]", "\n", "label", "=", "self", ".", "label", "[", "idx", "]", "\n", "\n", "return", "data", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.SignalDataset_music.__init__": [[134, 143], ["len", "len", "glob.glob1", "glob.glob1"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "root_dir", ",", "time_step", ",", "train", ")", ":", "\n", "        ", "self", ".", "root_dir", "=", "root_dir", "\n", "self", ".", "time_step", "=", "time_step", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "len", "=", "0", "\n", "if", "self", ".", "train", ":", "\n", "            ", "self", ".", "len", "=", "len", "(", "glob", ".", "glob1", "(", "root_dir", ",", "\"*train_x*.npy\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "len", "=", "len", "(", "glob", ".", "glob1", "(", "root_dir", ",", "\"*test_x*.npy\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.SignalDataset_music.__getitem__": [[144, 154], ["numpy.load", "numpy.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "            ", "x_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "\"music_train_x_{}_{}.npy\"", ".", "format", "(", "self", ".", "time_step", ",", "idx", ")", ")", "\n", "y_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "\"music_train_y_{}_{}.npy\"", ".", "format", "(", "self", ".", "time_step", ",", "idx", ")", ")", "\n", "", "else", ":", "\n", "            ", "x_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "\"music_test_x_{}_{}.npy\"", ".", "format", "(", "self", ".", "time_step", ",", "idx", ")", ")", "\n", "y_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_dir", ",", "\"music_test_y_{}_{}.npy\"", ".", "format", "(", "self", ".", "time_step", ",", "idx", ")", ")", "\n", "", "data", "=", "np", ".", "load", "(", "x_path", ")", "\n", "label", "=", "np", ".", "load", "(", "y_path", ")", "\n", "return", "data", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.SignalDataset_music.__len__": [[155, 157], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "len", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.get_meta": [[11, 29], ["open", "open.write", "open.write", "open.close", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "str", "str", "len", "len"], "function", ["None"], ["def", "get_meta", "(", "root_dir", ")", ":", "\n", "    ", "\"\"\"Will write a meta.txt to store sample size of both train and test.\n        Format:\n        line 1: size of train\n        line 2: size of test\n        \"\"\"", "\n", "if", "'iq'", "in", "root_dir", ":", "\n", "        ", "train_label", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"iq_train_label.npy\"", ")", ")", "\n", "test_label", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"iq_test_label.npy\"", ")", ")", "\n", "", "else", ":", "\n", "        ", "train_label", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"train_label.npz.npy\"", ")", ")", "\n", "test_label", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"test_label.npz.npy\"", ")", ")", "\n", "", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'meta.txt'", ")", ",", "'w+'", ")", "\n", "#f.write(str(len(train_data)) + \"\\n\")", "\n", "f", ".", "write", "(", "str", "(", "len", "(", "train_label", ")", ")", "+", "\"\\n\"", ")", "\n", "#f.write(str(len(test_data)) + \"\\n\")", "\n", "f", ".", "write", "(", "str", "(", "len", "(", "test_label", ")", ")", "+", "\"\\n\"", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.get_len": [[30, 51], ["open", "open.read().splitlines", "open", "os.path.join", "int", "int", "os.path.join", "print", "print", "utils.get_meta", "open.read", "print", "print"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.get_meta"], ["", "def", "get_len", "(", "root_dir", ",", "train", ")", ":", "\n", "    ", "\"\"\"Will return the sample size of train or test in O(1)\"\"\"", "\n", "try", ":", "\n", "        ", "meta", "=", "open", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'meta.txt'", ")", ",", "'r'", ")", "\n", "if", "train", ":", "\n", "            ", "print", "(", "'Meta file for training data exists'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Meta file for test data exists'", ")", "\n", "", "", "except", "FileNotFoundError", ":", "\n", "        ", "get_meta", "(", "root_dir", ")", "\n", "if", "train", ":", "\n", "            ", "print", "(", "'Meta file for training data created'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Meta file for test data created'", ")", "\n", "\n", "", "", "f", "=", "open", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "'meta.txt'", ")", ",", "'r'", ")", "\n", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "if", "train", ":", "\n", "        ", "return", "int", "(", "lines", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "int", "(", "lines", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.save_checkpoint": [[53, 57], ["torch.save", "shutil.copyfile"], "function", ["None"], ["", "", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "filename", ",", "'model_best.pth.tar'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters": [[93, 95], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.music.resample.resample_musicnet": [[17, 44], ["print", "print", "float", "open", "numpy.load", "len", "enumerate", "print", "numpy.load.keys", "print", "resampy.resample", "intervaltree.IntervalTree", "open", "numpy.savez", "int", "int", "intervaltree.Interval", "resampled_intervals.append"], "function", ["None"], ["def", "resample_musicnet", "(", "file_in", ",", "file_out", ",", "frame_rate", ",", "frame_rate_out", ")", ":", "\n", "    ", "ratio", "=", "frame_rate_out", "/", "float", "(", "frame_rate", ")", "\n", "print", "(", "'.. resampling {} ({}Hz) into {} ({}Hz)'", ".", "format", "(", "\n", "file_in", ",", "frame_rate", ",", "file_out", ",", "frame_rate_out", ")", ")", "\n", "print", "(", "'.. sampling with ratio {}'", ".", "format", "(", "ratio", ")", ")", "\n", "\n", "resampled_data", "=", "{", "}", "\n", "with", "open", "(", "file_in", ",", "'rb'", ")", "as", "f_in", ":", "\n", "        ", "data_in", "=", "numpy", ".", "load", "(", "file_in", ",", "encoding", "=", "'latin1'", ")", "\n", "n_files", "=", "len", "(", "data_in", ".", "keys", "(", ")", ")", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "data_in", ")", ":", "\n", "            ", "print", "(", "'.. aggregating {} ({} / {})'", ".", "format", "(", "key", ",", "i", ",", "n_files", ")", ")", "\n", "data", "=", "data_in", "[", "key", "]", "\n", "data", "[", "0", "]", "=", "resample", "(", "data", "[", "0", "]", ",", "frame_rate", ",", "frame_rate_out", ")", "\n", "resampled_intervals", "=", "[", "]", "\n", "for", "interval", "in", "data", "[", "1", "]", ":", "\n", "                ", "resampled_begin", "=", "int", "(", "interval", ".", "begin", "*", "ratio", ")", "\n", "resampled_end", "=", "int", "(", "interval", ".", "end", "*", "ratio", ")", "\n", "resampled_interval", "=", "Interval", "(", "\n", "resampled_begin", ",", "resampled_end", ",", "interval", ".", "data", ")", "\n", "resampled_intervals", ".", "append", "(", "resampled_interval", ")", "\n", "", "data", "[", "1", "]", "=", "IntervalTree", "(", "resampled_intervals", ")", "\n", "resampled_data", "[", "key", "]", "=", "data", "\n", "\n", "", "print", "(", "'.. saving output'", ")", "\n", "with", "open", "(", "file_out", ",", "'wb'", ")", "as", "f_out", ":", "\n", "            ", "numpy", ".", "savez", "(", "f_out", ",", "**", "resampled_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen.train_transformer": [[20, 56], ["int", "model.TransformerGenerationModel", "print", "torch.nn.BCEWithLogitsLoss", "torch.optim.lr_scheduler.ReduceLROnPlateau", "train_gen.train_model", "int", "model.cuda.cuda", "getattr", "model.cuda.parameters", "utils.count_parameters"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq_concat.train_model", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["def", "train_transformer", "(", ")", ":", "\n", "    ", "if", "args", ".", "data", "==", "'iq'", ":", "\n", "        ", "input_size", "=", "int", "(", "3200", "/", "(", "args", ".", "src_time_step", "+", "args", ".", "trg_time_step", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_size", "=", "4096", "\n", "", "input_dim", "=", "int", "(", "input_size", "/", "2", ")", "\n", "\n", "model", "=", "TransformerGenerationModel", "(", "input_dims", "=", "[", "input_dim", ",", "input_dim", "]", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "embed_dim", "=", "args", ".", "embed_dim", ",", "\n", "output_dim", "=", "args", ".", "output_dim", ",", "\n", "num_heads", "=", "args", ".", "num_heads", ",", "\n", "attn_dropout", "=", "args", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "args", ".", "relu_dropout", ",", "\n", "res_dropout", "=", "args", ".", "res_dropout", ",", "\n", "out_dropout", "=", "args", ".", "out_dropout", ",", "\n", "layers", "=", "args", ".", "nlevels", ",", "\n", "attn_mask", "=", "args", ".", "attn_mask", ")", "\n", "if", "use_cuda", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "", "print", "(", "\"Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "model", ")", ")", ")", "\n", "\n", "optimizer", "=", "getattr", "(", "optim", ",", "args", ".", "optim", ")", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "0", ")", "\n", "criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "patience", "=", "2", ",", "factor", "=", "0.5", ",", "verbose", "=", "True", ")", "\n", "\n", "settings", "=", "{", "'model'", ":", "model", ",", "\n", "'optimizer'", ":", "optimizer", ",", "\n", "'criterion'", ":", "criterion", ",", "\n", "'scheduler'", ":", "scheduler", ",", "\n", "'input_size'", ":", "input_size", ",", "\n", "'src_time_step'", ":", "args", ".", "src_time_step", ",", "\n", "'trg_time_step'", ":", "args", ".", "trg_time_step", "}", "\n", "return", "train_model", "(", "settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen.train_model": [[58, 127], ["range", "model.train", "enumerate", "model.eval", "time.time", "time.time", "train_gen.train_model.train"], "function", ["None"], ["", "def", "train_model", "(", "settings", ")", ":", "\n", "    ", "model", "=", "settings", "[", "'model'", "]", "\n", "optimizer", "=", "settings", "[", "'optimizer'", "]", "\n", "criterion", "=", "settings", "[", "'criterion'", "]", "\n", "scheduler", "=", "settings", "[", "'scheduler'", "]", "\n", "input_size", "=", "settings", "[", "'input_size'", "]", "\n", "src_time_step", "=", "settings", "[", "'src_time_step'", "]", "\n", "trg_time_step", "=", "settings", "[", "'trg_time_step'", "]", "\n", "\n", "\n", "def", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "i_batch", ",", "(", "data_batched", ",", "label_batched", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "cur_batch_size", "=", "len", "(", "data_batched", ")", "\n", "src", "=", "data_batched", "[", ":", ",", "0", ":", "src_time_step", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg", "=", "data_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg_label", "=", "label_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "cuda", "(", ")", "\n", "\n", "# clear gradients", "\n", "model", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "model", "(", "x", "=", "src", ",", "y", "=", "trg", ")", "\n", "loss", "=", "criterion", "(", "outputs", ".", "transpose", "(", "0", ",", "1", ")", ".", "double", "(", ")", ",", "trg_label", ".", "transpose", "(", "0", ",", "1", ")", ".", "double", "(", ")", ")", "\n", "if", "torch", ".", "isnan", "(", "loss", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ">", "0", ":", "\n", "                ", "print", "(", "loss", ")", "\n", "assert", "False", "\n", "", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "avg_loss", "=", "epoch_loss", "/", "float", "(", "len", "(", "train_loader", ")", ")", "\n", "\n", "return", "avg_loss", "\n", "\n", "", "def", "evaluate", "(", "model", ",", "criterion", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "epoch_loss", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i_batch", ",", "(", "data_batched", ",", "label_batched", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "                ", "cur_batch_size", "=", "len", "(", "data_batched", ")", "\n", "src", "=", "data_batched", "[", ":", ",", "0", ":", "src_time_step", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg", "=", "data_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg_label", "=", "label_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "cuda", "(", ")", "\n", "outputs", "=", "model", "(", "x", "=", "src", ",", "max_len", "=", "len", "(", "trg", ")", ")", "\n", "loss", "=", "criterion", "(", "outputs", ".", "transpose", "(", "0", ",", "1", ")", ".", "double", "(", ")", ",", "trg_label", ".", "transpose", "(", "0", ",", "1", ")", ".", "double", "(", ")", ")", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "", "", "avg_loss", "=", "epoch_loss", "/", "float", "(", "len", "(", "test_loader", ")", ")", "\n", "return", "avg_loss", "\n", "\n", "\n", "\n", "", "best_valid", "=", "1e8", "\n", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", "=", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", "\n", "print", "(", "'Epoch {:2d} | Train Loss {:5.4f}'", ".", "format", "(", "epoch", ",", "train_loss", ")", ")", "\n", "test_loss", "=", "evaluate", "(", "model", ",", "criterion", ")", "\n", "scheduler", ".", "step", "(", "test_loss", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "print", "(", "'Epoch {:2d} | Test  Loss {:5.4f}'", ".", "format", "(", "epoch", ",", "test_loss", ")", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"time: %d\"", "%", "(", "end", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq.TransformerModel.__init__": [[18, 61], ["torch.nn.Module.__init__", "model_iq.TransformerModel.get_network", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "ComplexLinear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "utils.count_parameters"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerModel.get_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["    ", "def", "__init__", "(", "self", ",", "time_step", ",", "input_dims", ",", "hidden_size", ",", "embed_dim", ",", "output_dim", ",", "num_heads", ",", "attn_dropout", ",", "relu_dropout", ",", "res_dropout", ",", "out_dropout", ",", "layers", ",", "attn_mask", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Construct a basic Transfomer model.\n        \n        :param input_dims: The input dimensions of the various modalities.\n        :param hidden_size: The hidden dimensions of the fc layer.\n        :param embed_dim: The dimensions of the embedding layer.\n        :param output_dim: The dimensions of the output (128 in MuiscNet).\n        :param num_heads: The number of heads to use in the multi-headed attention. \n        :param attn_dropout: The dropout following self-attention sm((QK)^T/d)V.\n        :param relu_droput: The dropout for ReLU in residual block.\n        :param res_dropout: The dropout of each residual block.\n        :param out_dropout: The dropout of output layer.\n        :param layers: The number of transformer blocks.\n        :param attn_mask: A boolean indicating whether to use attention mask (for transformer decoder).\n        \"\"\"", "\n", "super", "(", "TransformerModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "[", "self", ".", "orig_d_a", ",", "self", ".", "orig_d_b", "]", "=", "input_dims", "\n", "assert", "self", ".", "orig_d_a", "==", "self", ".", "orig_d_b", "\n", "self", ".", "d_a", ",", "self", ".", "d_b", "=", "512", ",", "512", "\n", "final_out", "=", "embed_dim", "*", "2", "\n", "h_out", "=", "hidden_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "attn_dropout", "=", "attn_dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "\n", "# Transformer networks", "\n", "self", ".", "trans", "=", "self", ".", "get_network", "(", ")", "\n", "print", "(", "\"Encoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans", ")", ")", ")", "\n", "self", ".", "fc_a", "=", "nn", ".", "Linear", "(", "self", ".", "orig_d_a", ",", "self", ".", "d_a", ")", "\n", "self", ".", "fc_b", "=", "nn", ".", "Linear", "(", "self", ".", "orig_d_b", ",", "self", ".", "d_b", ")", "\n", "# Projection layers", "\n", "self", ".", "proj", "=", "ComplexLinear", "(", "self", ".", "d_a", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "out_fc1", "=", "nn", ".", "Linear", "(", "final_out", ",", "h_out", ")", "\n", "\n", "self", ".", "out_fc2", "=", "nn", ".", "Linear", "(", "h_out", ",", "output_dim", ")", "\n", "\n", "self", ".", "out_dropout", "=", "nn", ".", "Dropout", "(", "out_dropout", ")", "\n", "", "def", "get_network", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq.TransformerModel.get_network": [[61, 65], ["modules.transformer.TransformerEncoder"], "methods", ["None"], ["", "def", "get_network", "(", "self", ")", ":", "\n", "\n", "        ", "return", "TransformerEncoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "attn_mask", "=", "self", ".", "attn_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq.TransformerModel.forward": [[66, 82], ["model_iq.TransformerModel.fc_a", "model_iq.TransformerModel.fc_b", "model_iq.TransformerModel.proj", "model_iq.TransformerModel.trans", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_iq.TransformerModel.out_fc2", "model_iq.TransformerModel.out_dropout", "torch.relu", "torch.relu", "model_iq.TransformerModel.out_fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        x should have dimension [seq_len, batch_size, n_features] (i.e., L, N, C).\n        \"\"\"", "\n", "time_step", ",", "batch_size", ",", "n_features", "=", "x", ".", "shape", "\n", "\n", "input_a", "=", "x", "[", ":", ",", ":", ",", ":", "n_features", "//", "2", "]", "\n", "input_b", "=", "x", "[", ":", ",", ":", ",", "n_features", "//", "2", ":", "]", "\n", "\"\"\"Add linear layer here\"\"\"", "\n", "input_a", "=", "self", ".", "fc_a", "(", "input_a", ")", "\n", "input_b", "=", "self", ".", "fc_b", "(", "input_b", ")", "\n", "input_a", ",", "input_b", "=", "self", ".", "proj", "(", "input_a", ",", "input_b", ")", "\n", "h_as", ",", "h_bs", "=", "self", ".", "trans", "(", "input_a", ",", "input_b", ")", "\n", "h_concat", "=", "torch", ".", "cat", "(", "[", "h_as", "[", "-", "1", "]", ",", "h_bs", "[", "-", "1", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "h_concat", ")", ")", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq.TransformerGenerationModel.__init__": [[84, 120], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "model_iq.TransformerGenerationModel.get_encoder_network", "model_iq.TransformerGenerationModel.get_decoder_network", "print", "print", "ComplexLinear", "ComplexLinear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "utils.count_parameters", "utils.count_parameters"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.get_encoder_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.get_decoder_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_dims", ",", "hidden_size", ",", "embed_dim", ",", "output_dim", ",", "num_heads", ",", "attn_dropout", ",", "relu_dropout", ",", "res_dropout", ",", "out_dropout", ",", "layers", ",", "attn_mask", "=", "False", ",", "src_mask", "=", "False", ",", "tgt_mask", "=", "False", ")", ":", "\n", "        ", "super", "(", "TransformerGenerationModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "[", "self", ".", "orig_d_a", ",", "self", ".", "orig_d_b", "]", "=", "input_dims", "\n", "assert", "self", ".", "orig_d_a", "==", "self", ".", "orig_d_b", "\n", "self", ".", "d_a", ",", "self", ".", "d_b", "=", "512", ",", "512", "\n", "final_out", "=", "embed_dim", "*", "2", "\n", "h_out", "=", "hidden_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "attn_dropout", "=", "attn_dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "\n", "self", ".", "d_a", ",", "self", ".", "d_b", "=", "512", ",", "512", "\n", "self", ".", "fc_a", "=", "nn", ".", "Linear", "(", "self", ".", "orig_d_a", ",", "self", ".", "d_a", ")", "\n", "self", ".", "fc_b", "=", "nn", ".", "Linear", "(", "self", ".", "orig_d_b", ",", "self", ".", "d_b", ")", "\n", "\n", "self", ".", "trans_encoder", "=", "self", ".", "get_encoder_network", "(", ")", "\n", "self", ".", "trans_decoder", "=", "self", ".", "get_decoder_network", "(", ")", "\n", "\n", "print", "(", "\"Encoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans_encoder", ")", ")", ")", "\n", "print", "(", "\"Decoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans_decoder", ")", ")", ")", "\n", "\n", "# Projection layers", "\n", "self", ".", "proj_enc", "=", "ComplexLinear", "(", "self", ".", "d_a", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "proj_dec", "=", "ComplexLinear", "(", "self", ".", "orig_d_a", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "out_fc1", "=", "nn", ".", "Linear", "(", "final_out", ",", "h_out", ")", "\n", "\n", "self", ".", "out_fc2", "=", "nn", ".", "Linear", "(", "h_out", ",", "output_dim", ")", "\n", "\n", "self", ".", "out_fc3", "=", "nn", ".", "Linear", "(", "output_dim", ",", "1000", ")", "\n", "\n", "self", ".", "out_dropout", "=", "nn", ".", "Dropout", "(", "out_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq.TransformerGenerationModel.get_encoder_network": [[121, 125], ["modules.transformer.TransformerEncoder"], "methods", ["None"], ["", "def", "get_encoder_network", "(", "self", ")", ":", "\n", "\n", "        ", "return", "TransformerEncoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "attn_mask", "=", "self", ".", "attn_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq.TransformerGenerationModel.get_decoder_network": [[126, 129], ["modules.transformer.TransformerDecoder"], "methods", ["None"], ["", "def", "get_decoder_network", "(", "self", ")", ":", "\n", "        ", "return", "TransformerDecoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "src_attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "tgt_attn_dropout", "=", "self", ".", "attn_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq.TransformerGenerationModel.forward": [[130, 172], ["model_iq.TransformerGenerationModel.fc_a", "model_iq.TransformerGenerationModel.fc_b", "model_iq.TransformerGenerationModel.proj_enc", "model_iq.TransformerGenerationModel.trans_encoder", "torch.relu", "torch.relu", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_iq.TransformerGenerationModel.proj_dec", "model_iq.TransformerGenerationModel.trans_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_iq.TransformerGenerationModel.out_fc2", "model_iq.TransformerGenerationModel.out_fc3", "model_iq.TransformerGenerationModel.out_dropout", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "model_iq.TransformerGenerationModel.proj_dec", "model_iq.TransformerGenerationModel.trans_decoder", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_iq.TransformerGenerationModel.out_fc2", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.relu", "torch.relu", "model_iq.TransformerGenerationModel.trans_decoder", "model_iq.TransformerGenerationModel.out_dropout", "model_iq.TransformerGenerationModel.out_fc1", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "model_iq.TransformerGenerationModel.out_fc1", "dec_a[].unsqueeze", "dec_b[].unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        x should have dimension [seq_len, batch_size, n_features] (i.e., L, N, C).\n        \"\"\"", "\n", "time_step", ",", "batch_size", ",", "n_features", "=", "x", ".", "shape", "\n", "input_a", "=", "x", "[", ":", ",", ":", ",", ":", "n_features", "//", "2", "]", "\n", "input_b", "=", "x", "[", ":", ",", ":", ",", "n_features", "//", "2", ":", "]", "\n", "\"\"\"Add linear layer here\"\"\"", "\n", "input_a", "=", "self", ".", "fc_a", "(", "input_a", ")", "\n", "input_b", "=", "self", ".", "fc_b", "(", "input_b", ")", "\n", "input_a", ",", "input_b", "=", "self", ".", "proj_enc", "(", "input_a", ",", "input_b", ")", "\n", "h_as", ",", "h_bs", "=", "self", ".", "trans_encoder", "(", "input_a", ",", "input_b", ")", "\n", "if", "y", "is", "not", "None", ":", "\n", "            ", "seq_len", ",", "batch_size", ",", "n_features2", "=", "y", ".", "shape", "\n", "n_features", "=", "n_features2", "//", "2", "\n", "y_a", "=", "y", "[", ":", "-", "1", ",", ":", ",", ":", "self", ".", "orig_d_a", "]", "# truncate last target ", "\n", "y_b", "=", "y", "[", ":", "-", "1", ",", ":", ",", "self", ".", "orig_d_a", ":", "self", ".", "orig_d_a", "+", "self", ".", "orig_d_b", "]", "# truncate last target ", "\n", "sos_a", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features", ")", ".", "cuda", "(", ")", "\n", "sos_b", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features", ")", ".", "cuda", "(", ")", "\n", "y_a", "=", "torch", ".", "cat", "(", "[", "sos_a", ",", "y_a", "]", ",", "dim", "=", "0", ")", "# add <sos> to front ", "\n", "y_b", "=", "torch", ".", "cat", "(", "[", "sos_b", ",", "y_b", "]", ",", "dim", "=", "0", ")", "# add <sos> to front ", "\n", "y_a", ",", "y_b", "=", "self", ".", "proj_dec", "(", "y_a", ",", "y_b", ")", "\n", "out_as", ",", "out_bs", "=", "self", ".", "trans_decoder", "(", "input_A", "=", "y_a", ",", "input_B", "=", "y_b", ",", "enc_A", "=", "h_as", ",", "enc_B", "=", "h_bs", ")", "\n", "out_concat", "=", "torch", ".", "cat", "(", "[", "out_as", ",", "out_bs", "]", ",", "dim", "=", "-", "1", ")", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "out_concat", ")", ")", ")", ")", "\n", "\n", "", "elif", "max_len", "is", "not", "None", ":", "\n", "            ", "dec_a", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features", "//", "2", ")", ".", "cuda", "(", ")", "\n", "dec_b", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features", "//", "2", ")", ".", "cuda", "(", ")", "\n", "dec_a", ",", "dec_b", "=", "self", ".", "proj_dec", "(", "dec_a", ",", "dec_b", ")", "\n", "\n", "dec_a", ",", "dec_b", "=", "self", ".", "trans_decoder", "(", "input_A", "=", "dec_a", ",", "input_B", "=", "dec_b", ",", "enc_A", "=", "h_as", ",", "enc_B", "=", "h_bs", ")", "\n", "y_a", ",", "y_b", "=", "dec_a", ",", "dec_b", "\n", "\n", "for", "i", "in", "range", "(", "max_len", "-", "1", ")", ":", "\n", "                ", "dec_a", ",", "dec_b", "=", "self", ".", "trans_decoder", "(", "input_A", "=", "y_a", ",", "input_B", "=", "y_b", ",", "enc_A", "=", "h_as", ",", "enc_B", "=", "h_bs", ")", "\n", "y_a", ",", "y_b", "=", "torch", ".", "cat", "(", "[", "y_a", ",", "dec_a", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "]", ",", "dim", "=", "0", ")", ",", "torch", ".", "cat", "(", "[", "y_b", ",", "dec_b", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "]", ",", "dim", "=", "0", ")", "\n", "", "out_concat", "=", "torch", ".", "cat", "(", "[", "y_a", ",", "y_b", "]", ",", "dim", "=", "-", "1", ")", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "out_concat", ")", ")", ")", ")", "\n", "", "output", "=", "F", ".", "relu", "(", "self", ".", "out_fc3", "(", "output", "[", "-", "1", "]", ")", ")", "# use last time step to generate a label for entire sequence", "\n", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_concat.train_transformer": [[20, 46], ["model_concat.TransformerModel", "print", "torch.nn.BCEWithLogitsLoss", "torch.optim.lr_scheduler.ReduceLROnPlateau", "train_concat.train_model", "model.cuda.cuda", "getattr", "model.cuda.parameters", "count_parameters"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq_concat.train_model", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["def", "train_transformer", "(", ")", ":", "\n", "    ", "model", "=", "TransformerModel", "(", "time_step", "=", "args", ".", "time_step", ",", "\n", "input_dims", "=", "args", ".", "modal_lengths", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "embed_dim", "=", "args", ".", "embed_dim", ",", "\n", "output_dim", "=", "args", ".", "output_dim", ",", "\n", "num_heads", "=", "args", ".", "num_heads", ",", "\n", "attn_dropout", "=", "args", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "args", ".", "relu_dropout", ",", "\n", "res_dropout", "=", "args", ".", "res_dropout", ",", "\n", "out_dropout", "=", "args", ".", "out_dropout", ",", "\n", "layers", "=", "args", ".", "nlevels", ",", "\n", "attn_mask", "=", "args", ".", "attn_mask", ")", "\n", "if", "use_cuda", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "", "print", "(", "\"Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "model", ")", ")", ")", "\n", "\n", "optimizer", "=", "getattr", "(", "optim", ",", "args", ".", "optim", ")", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "1e-7", ")", "\n", "criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "patience", "=", "2", ",", "factor", "=", "0.5", ",", "verbose", "=", "True", ")", "\n", "settings", "=", "{", "'model'", ":", "model", ",", "\n", "'optimizer'", ":", "optimizer", ",", "\n", "'criterion'", ":", "criterion", ",", "\n", "'scheduler'", ":", "scheduler", "}", "\n", "return", "train_model", "(", "settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_concat.train_model": [[48, 120], ["model.to", "range", "time.time", "time.time", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model.train", "enumerate", "sklearn.metrics.average_precision_score", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model.eval", "time.time", "time.time", "train_concat.train_model.train"], "function", ["None"], ["", "def", "train_model", "(", "settings", ")", ":", "\n", "    ", "model", "=", "settings", "[", "'model'", "]", "\n", "optimizer", "=", "settings", "[", "'optimizer'", "]", "\n", "criterion", "=", "settings", "[", "'criterion'", "]", "\n", "scheduler", "=", "settings", "[", "'scheduler'", "]", "\n", "model", ".", "to", "(", "device", ")", "\n", "def", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0.0", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "num_batches", "=", "len", "(", "training_set", ")", "//", "batch_size", "\n", "total_batch_size", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "shape", "=", "(", "args", ".", "time_step", ",", "training_set", ".", "len", ",", "args", ".", "output_dim", ")", "\n", "true_vals", "=", "torch", ".", "zeros", "(", "shape", ")", "\n", "pred_vals", "=", "torch", ".", "zeros", "(", "shape", ")", "\n", "model", ".", "train", "(", ")", "\n", "for", "i_batch", ",", "(", "batch_X", ",", "batch_y", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "model", ".", "zero_grad", "(", ")", "\n", "batch_X", "=", "batch_X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_y", "=", "batch_y", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "batch_X", ",", "batch_y", "=", "batch_X", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", ",", "batch_y", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "preds", "=", "model", "(", "batch_X", ")", "\n", "true_vals", "[", ":", ",", "i_batch", "*", "batch_size", ":", "(", "i_batch", "+", "1", ")", "*", "batch_size", ",", ":", "]", "=", "batch_y", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "pred_vals", "[", ":", ",", "i_batch", "*", "batch_size", ":", "(", "i_batch", "+", "1", ")", "*", "batch_size", ",", ":", "]", "=", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "loss", "=", "criterion", "(", "preds", ",", "batch_y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "total_batch_size", "+=", "batch_size", "\n", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "*", "batch_size", "\n", "", "aps", "=", "average_precision_score", "(", "true_vals", ".", "flatten", "(", ")", ",", "pred_vals", ".", "flatten", "(", ")", ")", "\n", "return", "epoch_loss", "/", "len", "(", "training_set", ")", ",", "aps", "\n", "\n", "", "def", "evaluate", "(", "model", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0.0", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "loader", "=", "test_loader", "\n", "total_batch_size", "=", "0", "\n", "shape", "=", "(", "args", ".", "time_step", ",", "test_set", ".", "len", ",", "args", ".", "output_dim", ")", "\n", "true_vals", "=", "torch", ".", "zeros", "(", "shape", ")", "\n", "pred_vals", "=", "torch", ".", "zeros", "(", "shape", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i_batch", ",", "(", "batch_X", ",", "batch_y", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "                ", "batch_X", "=", "batch_X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_y", "=", "batch_y", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_X", ",", "batch_y", "=", "batch_X", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", ",", "batch_y", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "preds", "=", "model", "(", "batch_X", ")", "\n", "true_vals", "[", ":", ",", "i_batch", "*", "batch_size", ":", "(", "i_batch", "+", "1", ")", "*", "batch_size", ",", ":", "]", "=", "batch_y", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "pred_vals", "[", ":", ",", "i_batch", "*", "batch_size", ":", "(", "i_batch", "+", "1", ")", "*", "batch_size", ",", ":", "]", "=", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "loss", "=", "criterion", "(", "preds", ",", "batch_y", ")", "\n", "total_batch_size", "+=", "batch_size", "\n", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "*", "batch_size", "\n", "", "aps", "=", "average_precision_score", "(", "true_vals", ".", "flatten", "(", ")", ",", "pred_vals", ".", "flatten", "(", ")", ")", "\n", "", "return", "epoch_loss", "/", "len", "(", "test_set", ")", ",", "aps", "\n", "\n", "\n", "\n", "", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "acc_train", "=", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", "\n", "print", "(", "'Epoch {:2d} | Train Loss {:5.4f} | APS {:5.4f}'", ".", "format", "(", "epoch", ",", "train_loss", ",", "acc_train", ")", ")", "\n", "test_loss", ",", "acc_test", "=", "evaluate", "(", "model", ",", "criterion", ")", "\n", "scheduler", ".", "step", "(", "test_loss", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "print", "(", "'Epoch {:2d} | Test  Loss {:5.4f} | APS {:5.4f}'", ".", "format", "(", "epoch", ",", "test_loss", ",", "acc_test", ")", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"time: %d\"", "%", "(", "end", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq.train_transformer": [[20, 56], ["int", "model_iq.TransformerGenerationModel", "print", "torch.nn.CrossEntropyLoss", "torch.optim.lr_scheduler.ReduceLROnPlateau", "train_gen_iq.train_model", "int", "model.cuda.cuda", "getattr", "model.cuda.parameters", "utils.count_parameters"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq_concat.train_model", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["def", "train_transformer", "(", ")", ":", "\n", "    ", "if", "args", ".", "data", "==", "'iq'", ":", "\n", "        ", "input_size", "=", "int", "(", "3200", "/", "(", "args", ".", "src_time_step", "+", "args", ".", "trg_time_step", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_size", "=", "4096", "\n", "", "input_dim", "=", "int", "(", "input_size", "/", "2", ")", "\n", "\n", "model", "=", "TransformerGenerationModel", "(", "input_dims", "=", "[", "input_dim", ",", "input_dim", "]", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "embed_dim", "=", "args", ".", "embed_dim", ",", "\n", "output_dim", "=", "args", ".", "output_dim", ",", "\n", "num_heads", "=", "args", ".", "num_heads", ",", "\n", "attn_dropout", "=", "args", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "args", ".", "relu_dropout", ",", "\n", "res_dropout", "=", "args", ".", "res_dropout", ",", "\n", "out_dropout", "=", "args", ".", "out_dropout", ",", "\n", "layers", "=", "args", ".", "nlevels", ",", "\n", "attn_mask", "=", "args", ".", "attn_mask", ")", "\n", "if", "use_cuda", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "", "print", "(", "\"Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "model", ")", ")", ")", "\n", "\n", "optimizer", "=", "getattr", "(", "optim", ",", "args", ".", "optim", ")", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "0", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "\"sum\"", ")", "\n", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "patience", "=", "2", ",", "factor", "=", "0.5", ",", "verbose", "=", "True", ")", "\n", "\n", "settings", "=", "{", "'model'", ":", "model", ",", "\n", "'optimizer'", ":", "optimizer", ",", "\n", "'criterion'", ":", "criterion", ",", "\n", "'scheduler'", ":", "scheduler", ",", "\n", "'input_size'", ":", "input_size", ",", "\n", "'src_time_step'", ":", "args", ".", "src_time_step", ",", "\n", "'trg_time_step'", ":", "args", ".", "trg_time_step", "}", "\n", "return", "train_model", "(", "settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq.train_model": [[58, 122], ["range", "model.train", "enumerate", "model.eval", "time.time", "time.time", "train_gen_iq.train_model.train"], "function", ["None"], ["", "def", "train_model", "(", "settings", ")", ":", "\n", "    ", "model", "=", "settings", "[", "'model'", "]", "\n", "optimizer", "=", "settings", "[", "'optimizer'", "]", "\n", "criterion", "=", "settings", "[", "'criterion'", "]", "\n", "scheduler", "=", "settings", "[", "'scheduler'", "]", "\n", "input_size", "=", "settings", "[", "'input_size'", "]", "\n", "src_time_step", "=", "settings", "[", "'src_time_step'", "]", "\n", "trg_time_step", "=", "settings", "[", "'trg_time_step'", "]", "\n", "\n", "\n", "def", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "i_batch", ",", "(", "data_batched", ",", "label_batched", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "cur_batch_size", "=", "len", "(", "data_batched", ")", "\n", "src", "=", "data_batched", "[", ":", ",", "0", ":", "src_time_step", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg", "=", "data_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg_label", "=", "label_batched", ".", "cuda", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "model", "(", "x", "=", "src", ",", "y", "=", "trg", ")", "\n", "loss", "=", "criterion", "(", "outputs", ".", "double", "(", ")", ",", "trg_label", ".", "long", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "avg_loss", "=", "epoch_loss", "/", "float", "(", "len", "(", "training_set", ")", ")", "\n", "\n", "return", "avg_loss", "\n", "\n", "\n", "", "def", "evaluate", "(", "model", ",", "criterion", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "epoch_loss", "=", "0", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i_batch", ",", "(", "data_batched", ",", "label_batched", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "                ", "cur_batch_size", "=", "len", "(", "data_batched", ")", "\n", "src", "=", "data_batched", "[", ":", ",", "0", ":", "src_time_step", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg", "=", "data_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg_label", "=", "label_batched", ".", "cuda", "(", ")", "\n", "outputs", "=", "model", "(", "x", "=", "src", ",", "max_len", "=", "len", "(", "trg", ")", ")", "\n", "loss", "=", "criterion", "(", "outputs", ".", "double", "(", ")", ",", "trg_label", ".", "long", "(", ")", ")", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "", "", "avg_loss", "=", "epoch_loss", "/", "float", "(", "len", "(", "test_set", ")", ")", "\n", "return", "avg_loss", "\n", "\n", "\n", "\n", "", "best_valid", "=", "1e8", "\n", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", "=", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", "\n", "print", "(", "'Epoch {:2d} | Train Loss {:5.4f}'", ".", "format", "(", "epoch", ",", "train_loss", ")", ")", "\n", "test_loss", "=", "evaluate", "(", "model", ",", "criterion", ")", "\n", "scheduler", ".", "step", "(", "test_loss", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "print", "(", "'Epoch {:2d} | Test  Loss {:5.4f}'", ".", "format", "(", "epoch", ",", "test_loss", ")", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"time: %d\"", "%", "(", "end", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_iq_concat.train_transformer": [[20, 46], ["model_iq_concat.TransformerModel", "print", "torch.nn.CrossEntropyLoss", "torch.optim.lr_scheduler.ReduceLROnPlateau", "train_iq_concat.train_model", "model.cuda.cuda", "getattr", "model.cuda.parameters", "count_parameters"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq_concat.train_model", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["def", "train_transformer", "(", ")", ":", "\n", "    ", "model", "=", "TransformerModel", "(", "time_step", "=", "args", ".", "time_step", ",", "\n", "input_dims", "=", "args", ".", "modal_lengths", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "embed_dim", "=", "args", ".", "embed_dim", ",", "\n", "output_dim", "=", "args", ".", "output_dim", ",", "\n", "num_heads", "=", "args", ".", "num_heads", ",", "\n", "attn_dropout", "=", "args", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "args", ".", "relu_dropout", ",", "\n", "res_dropout", "=", "args", ".", "res_dropout", ",", "\n", "out_dropout", "=", "args", ".", "out_dropout", ",", "\n", "layers", "=", "args", ".", "nlevels", ",", "\n", "attn_mask", "=", "args", ".", "attn_mask", ")", "\n", "if", "use_cuda", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "", "print", "(", "\"Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "model", ")", ")", ")", "\n", "\n", "optimizer", "=", "getattr", "(", "optim", ",", "args", ".", "optim", ")", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "1e-7", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "\"sum\"", ")", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "patience", "=", "2", ",", "factor", "=", "0.5", ",", "verbose", "=", "True", ")", "\n", "settings", "=", "{", "'model'", ":", "model", ",", "\n", "'optimizer'", ":", "optimizer", ",", "\n", "'criterion'", ":", "criterion", ",", "\n", "'scheduler'", ":", "scheduler", "}", "\n", "return", "train_model", "(", "settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_iq_concat.train_model": [[48, 111], ["model.to", "range", "time.time", "time.time", "model.train", "enumerate", "model.eval", "time.time", "time.time", "train_iq_concat.train_model.train"], "function", ["None"], ["", "def", "train_model", "(", "settings", ")", ":", "\n", "    ", "model", "=", "settings", "[", "'model'", "]", "\n", "optimizer", "=", "settings", "[", "'optimizer'", "]", "\n", "criterion", "=", "settings", "[", "'criterion'", "]", "\n", "scheduler", "=", "settings", "[", "'scheduler'", "]", "\n", "model", ".", "to", "(", "device", ")", "\n", "def", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0.0", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "num_batches", "=", "len", "(", "training_set", ")", "//", "batch_size", "\n", "total_batch_size", "=", "0", "\n", "total_correct", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "for", "i_batch", ",", "(", "batch_X", ",", "batch_y", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "model", ".", "zero_grad", "(", ")", "\n", "batch_X", "=", "batch_X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_X", ",", "batch_y", "=", "batch_X", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", ",", "batch_y", ".", "to", "(", "device", "=", "device", ")", "\n", "preds", "=", "model", "(", "batch_X", ")", "\n", "loss", "=", "criterion", "(", "preds", ",", "batch_y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "total_batch_size", "+=", "batch_size", "\n", "total_correct", "+=", "(", "batch_y", "==", "preds", ".", "argmax", "(", "-", "1", ")", ")", ".", "sum", "(", ")", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "", "aps", "=", "float", "(", "total_correct", ")", "/", "float", "(", "total_batch_size", ")", "\n", "return", "epoch_loss", "/", "len", "(", "training_set", ")", ",", "aps", "\n", "\n", "", "def", "evaluate", "(", "model", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0.0", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "num_batches", "=", "len", "(", "training_set", ")", "//", "batch_size", "\n", "total_batch_size", "=", "0", "\n", "total_correct", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i_batch", ",", "(", "batch_X", ",", "batch_y", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "                ", "batch_X", "=", "batch_X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_X", ",", "batch_y", "=", "batch_X", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", ",", "batch_y", ".", "to", "(", "device", "=", "device", ")", "\n", "preds", "=", "model", "(", "batch_X", ")", "\n", "loss", "=", "criterion", "(", "preds", ",", "batch_y", ")", "\n", "total_batch_size", "+=", "batch_size", "\n", "total_correct", "+=", "(", "batch_y", "==", "preds", ".", "argmax", "(", "-", "1", ")", ")", ".", "sum", "(", ")", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "", "aps", "=", "float", "(", "total_correct", ")", "/", "float", "(", "total_batch_size", ")", "\n", "", "return", "epoch_loss", "/", "len", "(", "test_set", ")", ",", "aps", "\n", "\n", "\n", "\n", "", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "acc_train", "=", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", "\n", "print", "(", "'Epoch {:2d} | Train Loss {:5.4f} | APS {:5.4f}'", ".", "format", "(", "epoch", ",", "train_loss", ",", "acc_train", ")", ")", "\n", "test_loss", ",", "acc_test", "=", "evaluate", "(", "model", ",", "criterion", ")", "\n", "scheduler", ".", "step", "(", "test_loss", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "print", "(", "'Epoch {:2d} | Test  Loss {:5.4f} | APS {:5.4f}'", ".", "format", "(", "epoch", ",", "test_loss", ",", "acc_test", ")", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"time: %d\"", "%", "(", "end", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_iq.train_transformer": [[20, 46], ["model_iq.TransformerModel", "print", "torch.nn.CrossEntropyLoss", "torch.optim.lr_scheduler.ReduceLROnPlateau", "train_iq.train_model", "model.cuda.cuda", "getattr", "model.cuda.parameters", "count_parameters"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq_concat.train_model", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["def", "train_transformer", "(", ")", ":", "\n", "    ", "model", "=", "TransformerModel", "(", "time_step", "=", "args", ".", "time_step", ",", "\n", "input_dims", "=", "args", ".", "modal_lengths", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "embed_dim", "=", "args", ".", "embed_dim", ",", "\n", "output_dim", "=", "args", ".", "output_dim", ",", "\n", "num_heads", "=", "args", ".", "num_heads", ",", "\n", "attn_dropout", "=", "args", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "args", ".", "relu_dropout", ",", "\n", "res_dropout", "=", "args", ".", "res_dropout", ",", "\n", "out_dropout", "=", "args", ".", "out_dropout", ",", "\n", "layers", "=", "args", ".", "nlevels", ",", "\n", "attn_mask", "=", "args", ".", "attn_mask", ")", "\n", "if", "use_cuda", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "", "print", "(", "\"Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "model", ")", ")", ")", "\n", "\n", "optimizer", "=", "getattr", "(", "optim", ",", "args", ".", "optim", ")", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "1e-7", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "\"sum\"", ")", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "patience", "=", "2", ",", "factor", "=", "0.5", ",", "verbose", "=", "True", ")", "\n", "settings", "=", "{", "'model'", ":", "model", ",", "\n", "'optimizer'", ":", "optimizer", ",", "\n", "'criterion'", ":", "criterion", ",", "\n", "'scheduler'", ":", "scheduler", "}", "\n", "return", "train_model", "(", "settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_iq.train_model": [[48, 111], ["model.to", "range", "time.time", "time.time", "model.train", "enumerate", "model.eval", "time.time", "time.time", "train_iq.train_model.train"], "function", ["None"], ["", "def", "train_model", "(", "settings", ")", ":", "\n", "    ", "model", "=", "settings", "[", "'model'", "]", "\n", "optimizer", "=", "settings", "[", "'optimizer'", "]", "\n", "criterion", "=", "settings", "[", "'criterion'", "]", "\n", "scheduler", "=", "settings", "[", "'scheduler'", "]", "\n", "model", ".", "to", "(", "device", ")", "\n", "def", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0.0", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "num_batches", "=", "len", "(", "training_set", ")", "//", "batch_size", "\n", "total_batch_size", "=", "0", "\n", "total_correct", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "model", ".", "train", "(", ")", "\n", "for", "i_batch", ",", "(", "batch_X", ",", "batch_y", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "model", ".", "zero_grad", "(", ")", "\n", "batch_X", "=", "batch_X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_X", ",", "batch_y", "=", "batch_X", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", ",", "batch_y", ".", "to", "(", "device", "=", "device", ")", "\n", "preds", "=", "model", "(", "batch_X", ")", "\n", "loss", "=", "criterion", "(", "preds", ",", "batch_y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "total_batch_size", "+=", "batch_size", "\n", "total_correct", "+=", "(", "batch_y", "==", "preds", ".", "argmax", "(", "-", "1", ")", ")", ".", "sum", "(", ")", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "", "aps", "=", "float", "(", "total_correct", ")", "/", "float", "(", "total_batch_size", ")", "\n", "return", "epoch_loss", "/", "len", "(", "training_set", ")", ",", "aps", "\n", "\n", "", "def", "evaluate", "(", "model", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0.0", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "num_batches", "=", "len", "(", "training_set", ")", "//", "batch_size", "\n", "total_batch_size", "=", "0", "\n", "total_correct", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i_batch", ",", "(", "batch_X", ",", "batch_y", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "                ", "batch_X", "=", "batch_X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_X", ",", "batch_y", "=", "batch_X", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", ",", "batch_y", ".", "to", "(", "device", "=", "device", ")", "\n", "preds", "=", "model", "(", "batch_X", ")", "\n", "loss", "=", "criterion", "(", "preds", ",", "batch_y", ")", "\n", "total_batch_size", "+=", "batch_size", "\n", "total_correct", "+=", "(", "batch_y", "==", "preds", ".", "argmax", "(", "-", "1", ")", ")", ".", "sum", "(", ")", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "", "aps", "=", "float", "(", "total_correct", ")", "/", "float", "(", "total_batch_size", ")", "\n", "", "return", "epoch_loss", "/", "len", "(", "test_set", ")", ",", "aps", "\n", "\n", "\n", "\n", "", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "acc_train", "=", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", "\n", "print", "(", "'Epoch {:2d} | Train Loss {:5.4f} | APS {:5.4f}'", ".", "format", "(", "epoch", ",", "train_loss", ",", "acc_train", ")", ")", "\n", "test_loss", ",", "acc_test", "=", "evaluate", "(", "model", ",", "criterion", ")", "\n", "scheduler", ".", "step", "(", "test_loss", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "print", "(", "'Epoch {:2d} | Test  Loss {:5.4f} | APS {:5.4f}'", ".", "format", "(", "epoch", ",", "test_loss", ",", "acc_test", ")", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"time: %d\"", "%", "(", "end", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_concat.train_transformer": [[20, 56], ["int", "model_concat.TransformerGenerationModel", "print", "torch.nn.BCEWithLogitsLoss", "torch.optim.lr_scheduler.ReduceLROnPlateau", "train_gen_concat.train_model", "int", "model.cuda.cuda", "getattr", "model.cuda.parameters", "utils.count_parameters"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq_concat.train_model", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["def", "train_transformer", "(", ")", ":", "\n", "    ", "if", "args", ".", "data", "==", "'iq'", ":", "\n", "        ", "input_size", "=", "int", "(", "3200", "/", "(", "args", ".", "src_time_step", "+", "args", ".", "trg_time_step", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_size", "=", "4096", "\n", "", "input_dim", "=", "int", "(", "input_size", "/", "2", ")", "\n", "\n", "model", "=", "TransformerGenerationModel", "(", "input_dims", "=", "[", "input_dim", ",", "input_dim", "]", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "embed_dim", "=", "args", ".", "embed_dim", ",", "\n", "output_dim", "=", "args", ".", "output_dim", ",", "\n", "num_heads", "=", "args", ".", "num_heads", ",", "\n", "attn_dropout", "=", "args", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "args", ".", "relu_dropout", ",", "\n", "res_dropout", "=", "args", ".", "res_dropout", ",", "\n", "out_dropout", "=", "args", ".", "out_dropout", ",", "\n", "layers", "=", "args", ".", "nlevels", ",", "\n", "attn_mask", "=", "args", ".", "attn_mask", ")", "\n", "if", "use_cuda", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "", "print", "(", "\"Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "model", ")", ")", ")", "\n", "\n", "optimizer", "=", "getattr", "(", "optim", ",", "args", ".", "optim", ")", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "0", ")", "\n", "criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "patience", "=", "2", ",", "factor", "=", "0.5", ",", "verbose", "=", "True", ")", "\n", "\n", "settings", "=", "{", "'model'", ":", "model", ",", "\n", "'optimizer'", ":", "optimizer", ",", "\n", "'criterion'", ":", "criterion", ",", "\n", "'scheduler'", ":", "scheduler", ",", "\n", "'input_size'", ":", "input_size", ",", "\n", "'src_time_step'", ":", "args", ".", "src_time_step", ",", "\n", "'trg_time_step'", ":", "args", ".", "trg_time_step", "}", "\n", "return", "train_model", "(", "settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_concat.train_model": [[58, 123], ["range", "model.train", "enumerate", "model.eval", "time.time", "time.time", "train_gen_concat.train_model.train"], "function", ["None"], ["", "def", "train_model", "(", "settings", ")", ":", "\n", "    ", "model", "=", "settings", "[", "'model'", "]", "\n", "optimizer", "=", "settings", "[", "'optimizer'", "]", "\n", "criterion", "=", "settings", "[", "'criterion'", "]", "\n", "scheduler", "=", "settings", "[", "'scheduler'", "]", "\n", "input_size", "=", "settings", "[", "'input_size'", "]", "\n", "src_time_step", "=", "settings", "[", "'src_time_step'", "]", "\n", "trg_time_step", "=", "settings", "[", "'trg_time_step'", "]", "\n", "\n", "\n", "def", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "i_batch", ",", "(", "data_batched", ",", "label_batched", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "cur_batch_size", "=", "len", "(", "data_batched", ")", "\n", "src", "=", "data_batched", "[", ":", ",", "0", ":", "src_time_step", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg", "=", "data_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg_label", "=", "label_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "cuda", "(", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "model", "(", "x", "=", "src", ",", "y", "=", "trg", ")", "\n", "loss", "=", "criterion", "(", "outputs", ".", "transpose", "(", "0", ",", "1", ")", ".", "double", "(", ")", ",", "trg_label", ".", "transpose", "(", "0", ",", "1", ")", ".", "double", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "avg_loss", "=", "epoch_loss", "/", "float", "(", "len", "(", "train_loader", ")", ")", "\n", "\n", "return", "avg_loss", "\n", "\n", "", "def", "evaluate", "(", "model", ",", "criterion", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "epoch_loss", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i_batch", ",", "(", "data_batched", ",", "label_batched", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "                ", "cur_batch_size", "=", "len", "(", "data_batched", ")", "\n", "src", "=", "data_batched", "[", ":", ",", "0", ":", "src_time_step", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg", "=", "data_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg_label", "=", "label_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "cuda", "(", ")", "\n", "outputs", "=", "model", "(", "x", "=", "src", ",", "max_len", "=", "len", "(", "trg", ")", ")", "\n", "loss", "=", "criterion", "(", "outputs", ".", "transpose", "(", "0", ",", "1", ")", ".", "double", "(", ")", ",", "trg_label", ".", "transpose", "(", "0", ",", "1", ")", ".", "double", "(", ")", ")", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "", "", "avg_loss", "=", "epoch_loss", "/", "float", "(", "len", "(", "test_loader", ")", ")", "\n", "return", "avg_loss", "\n", "\n", "\n", "\n", "", "best_valid", "=", "1e8", "\n", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", "=", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", "\n", "print", "(", "'Epoch {:2d} | Train Loss {:5.4f}'", ".", "format", "(", "epoch", ",", "train_loss", ")", ")", "\n", "test_loss", "=", "evaluate", "(", "model", ",", "criterion", ")", "\n", "scheduler", ".", "step", "(", "test_loss", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "print", "(", "'Epoch {:2d} | Test  Loss {:5.4f}'", ".", "format", "(", "epoch", ",", "test_loss", ")", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"time: %d\"", "%", "(", "end", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train.train_transformer": [[20, 46], ["model.TransformerModel", "print", "torch.nn.BCEWithLogitsLoss", "torch.optim.lr_scheduler.ReduceLROnPlateau", "train.train_model", "model.cuda.cuda", "getattr", "model.cuda.parameters", "count_parameters"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq_concat.train_model", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["def", "train_transformer", "(", ")", ":", "\n", "    ", "model", "=", "TransformerModel", "(", "time_step", "=", "args", ".", "time_step", ",", "\n", "input_dims", "=", "args", ".", "modal_lengths", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "embed_dim", "=", "args", ".", "embed_dim", ",", "\n", "output_dim", "=", "args", ".", "output_dim", ",", "\n", "num_heads", "=", "args", ".", "num_heads", ",", "\n", "attn_dropout", "=", "args", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "args", ".", "relu_dropout", ",", "\n", "res_dropout", "=", "args", ".", "res_dropout", ",", "\n", "out_dropout", "=", "args", ".", "out_dropout", ",", "\n", "layers", "=", "args", ".", "nlevels", ",", "\n", "attn_mask", "=", "args", ".", "attn_mask", ")", "\n", "if", "use_cuda", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "", "print", "(", "\"Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "model", ")", ")", ")", "\n", "\n", "optimizer", "=", "getattr", "(", "optim", ",", "args", ".", "optim", ")", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "1e-7", ")", "\n", "criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "patience", "=", "2", ",", "factor", "=", "0.5", ",", "verbose", "=", "True", ")", "\n", "settings", "=", "{", "'model'", ":", "model", ",", "\n", "'optimizer'", ":", "optimizer", ",", "\n", "'criterion'", ":", "criterion", ",", "\n", "'scheduler'", ":", "scheduler", "}", "\n", "return", "train_model", "(", "settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train.train_model": [[48, 121], ["model.to", "range", "time.time", "time.time", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model.train", "enumerate", "sklearn.metrics.average_precision_score", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model.eval", "time.time", "time.time", "train.train_model.train"], "function", ["None"], ["", "def", "train_model", "(", "settings", ")", ":", "\n", "    ", "model", "=", "settings", "[", "'model'", "]", "\n", "optimizer", "=", "settings", "[", "'optimizer'", "]", "\n", "criterion", "=", "settings", "[", "'criterion'", "]", "\n", "scheduler", "=", "settings", "[", "'scheduler'", "]", "\n", "model", ".", "to", "(", "device", ")", "\n", "def", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0.0", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "num_batches", "=", "len", "(", "training_set", ")", "//", "batch_size", "\n", "total_batch_size", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "shape", "=", "(", "args", ".", "time_step", ",", "training_set", ".", "len", ",", "args", ".", "output_dim", ")", "\n", "true_vals", "=", "torch", ".", "zeros", "(", "shape", ")", "\n", "pred_vals", "=", "torch", ".", "zeros", "(", "shape", ")", "\n", "model", ".", "train", "(", ")", "\n", "for", "i_batch", ",", "(", "batch_X", ",", "batch_y", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "model", ".", "zero_grad", "(", ")", "\n", "batch_X", "=", "batch_X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_y", "=", "batch_y", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_X", ",", "batch_y", "=", "batch_X", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", ",", "batch_y", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "preds", "=", "model", "(", "batch_X", ")", "\n", "true_vals", "[", ":", ",", "i_batch", "*", "batch_size", ":", "(", "i_batch", "+", "1", ")", "*", "batch_size", ",", ":", "]", "=", "batch_y", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "pred_vals", "[", ":", ",", "i_batch", "*", "batch_size", ":", "(", "i_batch", "+", "1", ")", "*", "batch_size", ",", ":", "]", "=", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "loss", "=", "criterion", "(", "preds", ",", "batch_y", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "total_batch_size", "+=", "batch_size", "\n", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "*", "batch_size", "\n", "", "aps", "=", "average_precision_score", "(", "true_vals", ".", "flatten", "(", ")", ",", "pred_vals", ".", "flatten", "(", ")", ")", "\n", "aps", "=", "0", "\n", "print", "(", "sys", ".", "argv", ")", "\n", "return", "epoch_loss", "/", "len", "(", "training_set", ")", ",", "aps", "\n", "\n", "", "def", "evaluate", "(", "model", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0.0", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "loader", "=", "test_loader", "\n", "total_batch_size", "=", "0", "\n", "shape", "=", "(", "args", ".", "time_step", ",", "test_set", ".", "len", ",", "args", ".", "output_dim", ")", "\n", "true_vals", "=", "torch", ".", "zeros", "(", "shape", ")", "\n", "pred_vals", "=", "torch", ".", "zeros", "(", "shape", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i_batch", ",", "(", "batch_X", ",", "batch_y", ")", "in", "enumerate", "(", "loader", ")", ":", "\n", "                ", "batch_X", "=", "batch_X", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_y", "=", "batch_y", ".", "transpose", "(", "0", ",", "1", ")", "\n", "batch_X", ",", "batch_y", "=", "batch_X", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", ",", "batch_y", ".", "float", "(", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "preds", "=", "model", "(", "batch_X", ")", "\n", "true_vals", "[", ":", ",", "i_batch", "*", "batch_size", ":", "(", "i_batch", "+", "1", ")", "*", "batch_size", ",", ":", "]", "=", "batch_y", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "pred_vals", "[", ":", ",", "i_batch", "*", "batch_size", ":", "(", "i_batch", "+", "1", ")", "*", "batch_size", ",", ":", "]", "=", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "loss", "=", "criterion", "(", "preds", ",", "batch_y", ")", "\n", "total_batch_size", "+=", "batch_size", "\n", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "*", "batch_size", "\n", "", "aps", "=", "average_precision_score", "(", "true_vals", ".", "flatten", "(", ")", ",", "pred_vals", ".", "flatten", "(", ")", ")", "\n", "", "return", "epoch_loss", "/", "len", "(", "test_set", ")", ",", "aps", "\n", "\n", "\n", "\n", "", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", ",", "acc_train", "=", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", "\n", "print", "(", "'Epoch {:2d} | Train Loss {:5.4f} | APS {:5.4f}'", ".", "format", "(", "epoch", ",", "train_loss", ",", "acc_train", ")", ")", "\n", "test_loss", ",", "acc_test", "=", "evaluate", "(", "model", ",", "criterion", ")", "\n", "scheduler", ".", "step", "(", "test_loss", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "print", "(", "'Epoch {:2d} | Test  Loss {:5.4f} | APS {:5.4f}'", ".", "format", "(", "epoch", ",", "test_loss", ",", "acc_test", ")", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"time: %d\"", "%", "(", "end", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_concat.TransformerModel.__init__": [[18, 87], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "model_concat.TransformerModel.get_network", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "utils.count_parameters"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerModel.get_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["    ", "def", "__init__", "(", "self", ",", "time_step", ",", "input_dims", ",", "hidden_size", ",", "embed_dim", ",", "output_dim", ",", "num_heads", ",", "attn_dropout", ",", "relu_dropout", ",", "res_dropout", ",", "out_dropout", ",", "layers", ",", "attn_mask", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Construct a basic Transfomer model.\n        \n        :param input_dims: The input dimensions of the various modalities.\n        :param hidden_size: The hidden dimensions of the fc layer.\n        :param embed_dim: The dimensions of the embedding layer.\n        :param output_dim: The dimensions of the output (128 in MuiscNet).\n        :param num_heads: The number of heads to use in the multi-headed attention. \n        :param attn_dropout: The dropout following self-attention sm((QK)^T/d)V.\n        :param relu_droput: The dropout for ReLU in residual block.\n        :param res_dropout: The dropout of each residual block.\n        :param out_dropout: The dropout of output layer.\n        :param layers: The number of transformer blocks.\n        :param attn_mask: A boolean indicating whether to use attention mask (for transformer decoder).\n        \"\"\"", "\n", "super", "(", "TransformerModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "1", ",", "out_channels", "=", "16", ",", "kernel_size", "=", "6", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "16", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "16", ",", "out_channels", "=", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "32", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "32", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", ")", "\n", "[", "self", ".", "orig_d_a", ",", "self", ".", "orig_d_b", "]", "=", "input_dims", "\n", "assert", "self", ".", "orig_d_a", "==", "self", ".", "orig_d_b", "\n", "channels", "=", "(", "(", "(", "(", "(", "(", "(", "(", "(", "(", "self", ".", "orig_d_a", "+", "self", ".", "orig_d_b", "-", "6", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "\n", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "\n", "self", ".", "d_x", "=", "128", "*", "channels", "\n", "final_out", "=", "embed_dim", "\n", "h_out", "=", "hidden_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "attn_dropout", "=", "attn_dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "\n", "# Transformer networks", "\n", "self", ".", "trans", "=", "self", ".", "get_network", "(", ")", "\n", "print", "(", "\"Encoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans", ")", ")", ")", "\n", "# Projection layers", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "self", ".", "d_x", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "out_fc1", "=", "nn", ".", "Linear", "(", "final_out", ",", "h_out", ")", "\n", "\n", "self", ".", "out_fc2", "=", "nn", ".", "Linear", "(", "h_out", ",", "output_dim", ")", "\n", "\n", "self", ".", "out_dropout", "=", "nn", ".", "Dropout", "(", "out_dropout", ")", "\n", "", "def", "get_network", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_concat.TransformerModel.get_network": [[87, 91], ["modules.transformer.TransformerConcatEncoder"], "methods", ["None"], ["", "def", "get_network", "(", "self", ")", ":", "\n", "\n", "        ", "return", "TransformerConcatEncoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "attn_mask", "=", "self", ".", "attn_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_concat.TransformerModel.forward": [[92, 107], ["model_concat.TransformerModel.view", "model_concat.TransformerModel.conv", "model_concat.TransformerModel.reshape", "model_concat.TransformerModel.proj", "model_concat.TransformerModel.trans", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_concat.TransformerModel.out_fc2", "model_concat.TransformerModel.out_dropout", "torch.relu", "torch.relu", "model_concat.TransformerModel.out_fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        x should have dimension [seq_len, batch_size, n_features] (i.e., L, N, C).\n        \"\"\"", "\n", "time_step", ",", "batch_size", ",", "n_features", "=", "x", ".", "shape", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "1", ",", "n_features", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "time_step", ",", "batch_size", ",", "self", ".", "d_x", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "# Pass the input through individual transformers", "\n", "h_x", "=", "self", ".", "trans", "(", "x", ")", "\n", "h_concat", "=", "torch", ".", "cat", "(", "[", "h_x", "]", ",", "dim", "=", "-", "1", ")", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "h_concat", ")", ")", ")", ")", "\n", "# No sigmoid because we use BCEwithlogitis which contains sigmoid layer and more stable", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_concat.TransformerGenerationModel.__init__": [[109, 167], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "model_concat.TransformerGenerationModel.get_encoder_network", "model_concat.TransformerGenerationModel.get_decoder_network", "print", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.MaxPool1d", "torch.nn.MaxPool1d", "utils.count_parameters", "utils.count_parameters"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.get_encoder_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.get_decoder_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_dims", ",", "hidden_size", ",", "embed_dim", ",", "output_dim", ",", "num_heads", ",", "attn_dropout", ",", "relu_dropout", ",", "res_dropout", ",", "out_dropout", ",", "layers", ",", "attn_mask", "=", "False", ",", "src_mask", "=", "False", ",", "tgt_mask", "=", "False", ")", ":", "\n", "        ", "super", "(", "TransformerGenerationModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "[", "orig_d_a", ",", "orig_d_b", "]", "=", "input_dims", "\n", "self", ".", "orig_d_x", "=", "orig_d_a", "+", "orig_d_b", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "1", ",", "out_channels", "=", "16", ",", "kernel_size", "=", "6", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "16", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "16", ",", "out_channels", "=", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "32", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "32", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv1d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "MaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", ")", "\n", "channels", "=", "(", "(", "(", "(", "(", "(", "(", "(", "(", "(", "self", ".", "orig_d_x", "-", "6", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "\n", "self", ".", "d_x", "=", "128", "*", "channels", "\n", "final_out", "=", "embed_dim", "\n", "h_out", "=", "hidden_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "attn_dropout", "=", "attn_dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "\n", "# Transformer networks", "\n", "self", ".", "trans_encoder", "=", "self", ".", "get_encoder_network", "(", ")", "\n", "self", ".", "trans_decoder", "=", "self", ".", "get_decoder_network", "(", ")", "\n", "\n", "print", "(", "\"Encoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans_encoder", ")", ")", ")", "\n", "print", "(", "\"Decoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans_decoder", ")", ")", ")", "\n", "\n", "# Projection layers", "\n", "self", ".", "proj_enc", "=", "nn", ".", "Linear", "(", "self", ".", "d_x", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "proj_dec", "=", "nn", ".", "Linear", "(", "self", ".", "orig_d_x", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "out_fc1", "=", "nn", ".", "Linear", "(", "final_out", ",", "h_out", ")", "\n", "\n", "self", ".", "out_fc2", "=", "nn", ".", "Linear", "(", "h_out", ",", "output_dim", ")", "\n", "\n", "self", ".", "out_dropout", "=", "nn", ".", "Dropout", "(", "out_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_concat.TransformerGenerationModel.get_encoder_network": [[168, 172], ["modules.transformer.TransformerConcatEncoder"], "methods", ["None"], ["", "def", "get_encoder_network", "(", "self", ")", ":", "\n", "\n", "        ", "return", "TransformerConcatEncoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "attn_mask", "=", "self", ".", "attn_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_concat.TransformerGenerationModel.get_decoder_network": [[173, 176], ["modules.transformer.TransformerConcatDecoder"], "methods", ["None"], ["", "def", "get_decoder_network", "(", "self", ")", ":", "\n", "        ", "return", "TransformerConcatDecoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "src_attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "tgt_attn_dropout", "=", "self", ".", "attn_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_concat.TransformerGenerationModel.forward": [[177, 219], ["model_concat.TransformerGenerationModel.view", "model_concat.TransformerGenerationModel.conv", "model_concat.TransformerGenerationModel.reshape", "model_concat.TransformerGenerationModel.proj_enc", "model_concat.TransformerGenerationModel.trans_encoder", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_concat.TransformerGenerationModel.proj_dec", "model_concat.TransformerGenerationModel.trans_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_concat.TransformerGenerationModel.out_fc2", "model_concat.TransformerGenerationModel.out_dropout", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "model_concat.TransformerGenerationModel.proj_dec", "model_concat.TransformerGenerationModel.trans_decoder", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_concat.TransformerGenerationModel.out_fc2", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.relu", "torch.relu", "model_concat.TransformerGenerationModel.trans_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_concat.TransformerGenerationModel.out_dropout", "model_concat.TransformerGenerationModel.out_fc1", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.relu", "torch.relu", "dec_x[].unsqueeze", "model_concat.TransformerGenerationModel.out_fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        x should have dimension [seq_len, batch_size, n_features] (i.e., L, N, C).\n        \"\"\"", "\n", "time_step", ",", "batch_size", ",", "n_features", "=", "x", ".", "shape", "\n", "\n", "# encoder", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "1", ",", "n_features", ")", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "time_step", ",", "batch_size", ",", "self", ".", "d_x", ")", "\n", "x", "=", "self", ".", "proj_enc", "(", "x", ")", "\n", "h_x", "=", "self", ".", "trans_encoder", "(", "x", ")", "\n", "\n", "# decoder", "\n", "if", "y", "is", "not", "None", ":", "\n", "            ", "seq_len", ",", "batch_size", ",", "n_features2", "=", "y", ".", "shape", "\n", "y", "=", "y", "[", ":", "-", "1", ",", ":", ",", ":", "]", "\n", "sos", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features2", ")", ".", "cuda", "(", ")", "\n", "y", "=", "torch", ".", "cat", "(", "[", "sos", ",", "y", "]", ",", "dim", "=", "0", ")", "# add <sos> to front ", "\n", "y", "=", "self", ".", "proj_dec", "(", "y", ")", "\n", "out", "=", "self", ".", "trans_decoder", "(", "input", "=", "y", ",", "enc", "=", "h_x", ")", "\n", "out_concat", "=", "torch", ".", "cat", "(", "[", "out", "]", ",", "dim", "=", "-", "1", ")", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "out_concat", ")", ")", ")", ")", "\n", "\n", "", "elif", "max_len", "is", "not", "None", ":", "\n", "            ", "dec_x", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features", ")", ".", "cuda", "(", ")", "\n", "dec_x", "=", "self", ".", "proj_dec", "(", "dec_x", ")", "\n", "\n", "dec_x", "=", "self", ".", "trans_decoder", "(", "input", "=", "dec_x", ",", "enc", "=", "h_x", ")", "\n", "y", "=", "dec_x", "\n", "\n", "for", "i", "in", "range", "(", "max_len", "-", "1", ")", ":", "\n", "                ", "dec_x", "=", "self", ".", "trans_decoder", "(", "input", "=", "y", ",", "enc", "=", "h_x", ")", "\n", "y", "=", "torch", ".", "cat", "(", "[", "y", ",", "dec_x", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "]", ",", "dim", "=", "0", ")", "\n", "", "out_concat", "=", "torch", ".", "cat", "(", "[", "y", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "out_concat", ")", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Only one of y and max_len should be input.\"", ")", "\n", "assert", "False", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq_concat.TransformerModel.__init__": [[18, 60], ["torch.nn.Module.__init__", "model_iq_concat.TransformerModel.get_network", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "utils.count_parameters"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerModel.get_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["    ", "def", "__init__", "(", "self", ",", "time_step", ",", "input_dims", ",", "hidden_size", ",", "embed_dim", ",", "output_dim", ",", "num_heads", ",", "attn_dropout", ",", "relu_dropout", ",", "res_dropout", ",", "out_dropout", ",", "layers", ",", "attn_mask", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Construct a basic Transfomer model.\n        \n        :param input_dims: The input dimensions of the various modalities.\n        :param hidden_size: The hidden dimensions of the fc layer.\n        :param embed_dim: The dimensions of the embedding layer.\n        :param output_dim: The dimensions of the output (128 in MuiscNet).\n        :param num_heads: The number of heads to use in the multi-headed attention. \n        :param attn_dropout: The dropout following self-attention sm((QK)^T/d)V.\n        :param relu_droput: The dropout for ReLU in residual block.\n        :param res_dropout: The dropout of each residual block.\n        :param out_dropout: The dropout of output layer.\n        :param layers: The number of transformer blocks.\n        :param attn_mask: A boolean indicating whether to use attention mask (for transformer decoder).\n        \"\"\"", "\n", "super", "(", "TransformerModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "[", "self", ".", "orig_d_a", ",", "self", ".", "orig_d_b", "]", "=", "input_dims", "\n", "assert", "self", ".", "orig_d_a", "==", "self", ".", "orig_d_b", "\n", "self", ".", "d_x", "=", "1024", "\n", "final_out", "=", "embed_dim", "\n", "h_out", "=", "hidden_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "attn_dropout", "=", "attn_dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "\n", "# Transformer networks", "\n", "self", ".", "trans", "=", "self", ".", "get_network", "(", ")", "\n", "print", "(", "\"Encoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans", ")", ")", ")", "\n", "# Projection layers", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "orig_d_a", "+", "self", ".", "orig_d_b", ",", "self", ".", "d_x", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "self", ".", "d_x", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "out_fc1", "=", "nn", ".", "Linear", "(", "final_out", ",", "h_out", ")", "\n", "\n", "self", ".", "out_fc2", "=", "nn", ".", "Linear", "(", "h_out", ",", "output_dim", ")", "\n", "\n", "self", ".", "out_dropout", "=", "nn", ".", "Dropout", "(", "out_dropout", ")", "\n", "", "def", "get_network", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq_concat.TransformerModel.get_network": [[60, 64], ["modules.transformer.TransformerConcatEncoder"], "methods", ["None"], ["", "def", "get_network", "(", "self", ")", ":", "\n", "\n", "        ", "return", "TransformerConcatEncoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "attn_mask", "=", "self", ".", "attn_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq_concat.TransformerModel.forward": [[65, 77], ["model_iq_concat.TransformerModel.fc", "model_iq_concat.TransformerModel.proj", "model_iq_concat.TransformerModel.trans", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_iq_concat.TransformerModel.out_fc2", "model_iq_concat.TransformerModel.out_dropout", "torch.relu", "torch.relu", "model_iq_concat.TransformerModel.out_fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        x should have dimension [seq_len, batch_size, n_features] (i.e., L, N, C).\n        \"\"\"", "\n", "time_step", ",", "batch_size", ",", "n_features", "=", "x", ".", "shape", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "x", "=", "self", ".", "proj", "(", "x", ")", "\n", "h_x", "=", "self", ".", "trans", "(", "x", ")", "\n", "h_concat", "=", "torch", ".", "cat", "(", "[", "h_x", "[", "-", "1", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "h_concat", ")", ")", ")", ")", "\n", "# No sigmoid because we use BCEwithlogitis which contains sigmoid layer and more stable", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq_concat.TransformerGenerationModel.__init__": [[79, 113], ["torch.nn.Module.__init__", "model_iq_concat.TransformerGenerationModel.get_encoder_network", "model_iq_concat.TransformerGenerationModel.get_decoder_network", "print", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "utils.count_parameters", "utils.count_parameters"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.get_encoder_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.get_decoder_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_dims", ",", "hidden_size", ",", "embed_dim", ",", "output_dim", ",", "num_heads", ",", "attn_dropout", ",", "relu_dropout", ",", "res_dropout", ",", "out_dropout", ",", "layers", ",", "attn_mask", "=", "False", ",", "src_mask", "=", "False", ",", "tgt_mask", "=", "False", ")", ":", "\n", "        ", "super", "(", "TransformerGenerationModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "[", "orig_d_a", ",", "orig_d_b", "]", "=", "input_dims", "\n", "self", ".", "orig_d_x", "=", "orig_d_a", "+", "orig_d_b", "\n", "self", ".", "d_x", "=", "1024", "\n", "final_out", "=", "embed_dim", "\n", "h_out", "=", "hidden_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "attn_dropout", "=", "attn_dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "\n", "# Transformer networks", "\n", "self", ".", "trans_encoder", "=", "self", ".", "get_encoder_network", "(", ")", "\n", "self", ".", "trans_decoder", "=", "self", ".", "get_decoder_network", "(", ")", "\n", "\n", "print", "(", "\"Encoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans_encoder", ")", ")", ")", "\n", "print", "(", "\"Decoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans_decoder", ")", ")", ")", "\n", "\n", "# Projection layers", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "orig_d_x", ",", "self", ".", "d_x", ")", "\n", "self", ".", "proj_enc", "=", "nn", ".", "Linear", "(", "self", ".", "d_x", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "proj_dec", "=", "nn", ".", "Linear", "(", "self", ".", "orig_d_x", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "out_fc1", "=", "nn", ".", "Linear", "(", "final_out", ",", "h_out", ")", "\n", "\n", "self", ".", "out_fc2", "=", "nn", ".", "Linear", "(", "h_out", ",", "output_dim", ")", "\n", "\n", "self", ".", "out_fc3", "=", "nn", ".", "Linear", "(", "output_dim", ",", "1000", ")", "\n", "\n", "self", ".", "out_dropout", "=", "nn", ".", "Dropout", "(", "out_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq_concat.TransformerGenerationModel.get_encoder_network": [[114, 118], ["modules.transformer.TransformerConcatEncoder"], "methods", ["None"], ["", "def", "get_encoder_network", "(", "self", ")", ":", "\n", "\n", "        ", "return", "TransformerConcatEncoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "attn_mask", "=", "self", ".", "attn_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq_concat.TransformerGenerationModel.get_decoder_network": [[119, 122], ["modules.transformer.TransformerConcatDecoder"], "methods", ["None"], ["", "def", "get_decoder_network", "(", "self", ")", ":", "\n", "        ", "return", "TransformerConcatDecoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "src_attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "tgt_attn_dropout", "=", "self", ".", "attn_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model_iq_concat.TransformerGenerationModel.forward": [[123, 159], ["model_iq_concat.TransformerGenerationModel.fc", "model_iq_concat.TransformerGenerationModel.proj_enc", "model_iq_concat.TransformerGenerationModel.trans_encoder", "torch.relu", "torch.relu", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_iq_concat.TransformerGenerationModel.proj_dec", "model_iq_concat.TransformerGenerationModel.trans_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_iq_concat.TransformerGenerationModel.out_fc2", "model_iq_concat.TransformerGenerationModel.out_fc3", "model_iq_concat.TransformerGenerationModel.out_dropout", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "model_iq_concat.TransformerGenerationModel.proj_dec", "model_iq_concat.TransformerGenerationModel.trans_decoder", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_iq_concat.TransformerGenerationModel.out_fc2", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.relu", "torch.relu", "model_iq_concat.TransformerGenerationModel.trans_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_iq_concat.TransformerGenerationModel.out_dropout", "model_iq_concat.TransformerGenerationModel.out_fc1", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.relu", "torch.relu", "dec_x[].unsqueeze", "model_iq_concat.TransformerGenerationModel.out_fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        x should have dimension [seq_len, batch_size, n_features] (i.e., L, N, C).\n        \"\"\"", "\n", "time_step", ",", "batch_size", ",", "n_features", "=", "x", ".", "shape", "\n", "# encoder", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "x", "=", "self", ".", "proj_enc", "(", "x", ")", "\n", "h_x", "=", "self", ".", "trans_encoder", "(", "x", ")", "\n", "\n", "# decoder", "\n", "if", "y", "is", "not", "None", ":", "\n", "            ", "seq_len", ",", "batch_size", ",", "n_features2", "=", "y", ".", "shape", "\n", "y", "=", "y", "[", ":", "-", "1", ",", ":", ",", ":", "]", "# truncate last target ", "\n", "sos", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features2", ")", ".", "cuda", "(", ")", "\n", "y", "=", "torch", ".", "cat", "(", "[", "sos", ",", "y", "]", ",", "dim", "=", "0", ")", "# add <sos> to front ", "\n", "y", "=", "self", ".", "proj_dec", "(", "y", ")", "\n", "out", "=", "self", ".", "trans_decoder", "(", "input", "=", "y", ",", "enc", "=", "h_x", ")", "\n", "out_concat", "=", "torch", ".", "cat", "(", "[", "out", "]", ",", "dim", "=", "-", "1", ")", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "out_concat", ")", ")", ")", ")", "\n", "", "elif", "max_len", "is", "not", "None", ":", "\n", "            ", "dec_x", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features", ")", ".", "cuda", "(", ")", "\n", "dec_x", "=", "self", ".", "proj_dec", "(", "dec_x", ")", "\n", "dec_x", "=", "self", ".", "trans_decoder", "(", "input", "=", "dec_x", ",", "enc", "=", "h_x", ")", "\n", "y", "=", "dec_x", "\n", "for", "i", "in", "range", "(", "max_len", "-", "1", ")", ":", "\n", "                ", "dec_x", "=", "self", ".", "trans_decoder", "(", "input", "=", "y", ",", "enc", "=", "h_x", ")", "\n", "y", "=", "torch", ".", "cat", "(", "[", "y", ",", "dec_x", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "]", ",", "dim", "=", "0", ")", "\n", "", "out_concat", "=", "torch", ".", "cat", "(", "[", "y", "]", ",", "dim", "=", "-", "1", ")", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "out_concat", ")", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Only one of y and max_len should be input.\"", ")", "\n", "assert", "False", "\n", "", "output", "=", "F", ".", "relu", "(", "self", ".", "out_fc3", "(", "output", "[", "-", "1", "]", ")", ")", "# use last time step to generate a label for entire sequence", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerModel.__init__": [[18, 88], ["torch.nn.Module.__init__", "ComplexSequential", "model.TransformerModel.get_network", "print", "ComplexLinear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "ComplexConv1d", "ComplexBatchNorm1d", "ComplexReLU", "ComplexMaxPool1d", "ComplexConv1d", "ComplexBatchNorm1d", "ComplexReLU", "ComplexMaxPool1d", "ComplexConv1d", "ComplexBatchNorm1d", "ComplexReLU", "ComplexMaxPool1d", "ComplexConv1d", "ComplexBatchNorm1d", "ComplexReLU", "ComplexMaxPool1d", "ComplexConv1d", "ComplexBatchNorm1d", "ComplexReLU", "ComplexMaxPool1d", "ComplexFlatten", "utils.count_parameters"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerModel.get_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["    ", "def", "__init__", "(", "self", ",", "time_step", ",", "input_dims", ",", "hidden_size", ",", "embed_dim", ",", "output_dim", ",", "num_heads", ",", "attn_dropout", ",", "relu_dropout", ",", "res_dropout", ",", "out_dropout", ",", "layers", ",", "attn_mask", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Construct a basic Transfomer model.\n        \n        :param input_dims: The input dimensions of the various modalities.\n        :param hidden_size: The hidden dimensions of the fc layer.\n        :param embed_dim: The dimensions of the embedding layer.\n        :param output_dim: The dimensions of the output (128 in MuiscNet).\n        :param num_heads: The number of heads to use in the multi-headed attention. \n        :param attn_dropout: The dropout following self-attention sm((QK)^T/d)V.\n        :param relu_droput: The dropout for ReLU in residual block.\n        :param res_dropout: The dropout of each residual block.\n        :param out_dropout: The dropout of output layer.\n        :param layers: The number of transformer blocks.\n        :param attn_mask: A boolean indicating whether to use attention mask (for transformer decoder).\n        \"\"\"", "\n", "super", "(", "TransformerModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "ComplexSequential", "(", "\n", "ComplexConv1d", "(", "in_channels", "=", "1", ",", "out_channels", "=", "16", ",", "kernel_size", "=", "6", ",", "stride", "=", "1", ")", ",", "\n", "ComplexBatchNorm1d", "(", "16", ")", ",", "\n", "ComplexReLU", "(", ")", ",", "\n", "ComplexMaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "ComplexConv1d", "(", "in_channels", "=", "16", ",", "out_channels", "=", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "ComplexBatchNorm1d", "(", "32", ")", ",", "\n", "ComplexReLU", "(", ")", ",", "\n", "ComplexMaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "ComplexConv1d", "(", "in_channels", "=", "32", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "ComplexBatchNorm1d", "(", "64", ")", ",", "\n", "ComplexReLU", "(", ")", ",", "\n", "ComplexMaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "ComplexConv1d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "ComplexBatchNorm1d", "(", "64", ")", ",", "\n", "ComplexReLU", "(", ")", ",", "\n", "ComplexMaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "ComplexConv1d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "ComplexBatchNorm1d", "(", "128", ")", ",", "\n", "ComplexReLU", "(", ")", ",", "\n", "ComplexMaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "ComplexFlatten", "(", ")", ",", "\n", ")", "\n", "[", "self", ".", "orig_d_a", ",", "self", ".", "orig_d_b", "]", "=", "input_dims", "\n", "assert", "self", ".", "orig_d_a", "==", "self", ".", "orig_d_b", "\n", "channels", "=", "(", "(", "(", "(", "(", "(", "(", "(", "(", "(", "self", ".", "orig_d_a", "-", "6", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "\n", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "\n", "self", ".", "d_a", ",", "self", ".", "d_b", "=", "128", "*", "channels", ",", "128", "*", "channels", "\n", "final_out", "=", "embed_dim", "*", "2", "\n", "h_out", "=", "hidden_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "attn_dropout", "=", "attn_dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "\n", "# Transformer networks", "\n", "self", ".", "trans", "=", "self", ".", "get_network", "(", ")", "\n", "print", "(", "\"Encoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans", ")", ")", ")", "\n", "# Projection layers", "\n", "self", ".", "proj", "=", "ComplexLinear", "(", "self", ".", "d_a", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "out_fc1", "=", "nn", ".", "Linear", "(", "final_out", ",", "h_out", ")", "\n", "\n", "self", ".", "out_fc2", "=", "nn", ".", "Linear", "(", "h_out", ",", "output_dim", ")", "\n", "\n", "self", ".", "out_dropout", "=", "nn", ".", "Dropout", "(", "out_dropout", ")", "\n", "", "def", "get_network", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerModel.get_network": [[88, 92], ["modules.transformer.TransformerEncoder"], "methods", ["None"], ["", "def", "get_network", "(", "self", ")", ":", "\n", "\n", "        ", "return", "TransformerEncoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "attn_mask", "=", "self", ".", "attn_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerModel.forward": [[93, 110], ["x[].view", "x[].view", "model.TransformerModel.conv", "input_a.reshape.reshape.reshape", "input_b.reshape.reshape.reshape", "model.TransformerModel.proj", "model.TransformerModel.trans", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.TransformerModel.out_fc2", "model.TransformerModel.out_dropout", "torch.relu", "torch.relu", "model.TransformerModel.out_fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        x should have dimension [seq_len, batch_size, n_features] (i.e., L, N, C).\n        \"\"\"", "\n", "time_step", ",", "batch_size", ",", "n_features", "=", "x", ".", "shape", "\n", "input_a", "=", "x", "[", ":", ",", ":", ",", ":", "n_features", "//", "2", "]", ".", "view", "(", "-", "1", ",", "1", ",", "n_features", "//", "2", ")", "\n", "input_b", "=", "x", "[", ":", ",", ":", ",", "n_features", "//", "2", ":", "]", ".", "view", "(", "-", "1", ",", "1", ",", "n_features", "//", "2", ")", "\n", "input_a", ",", "input_b", "=", "self", ".", "conv", "(", "input_a", ",", "input_b", ")", "\n", "input_a", "=", "input_a", ".", "reshape", "(", "time_step", ",", "batch_size", ",", "self", ".", "d_a", ")", "\n", "input_b", "=", "input_b", ".", "reshape", "(", "time_step", ",", "batch_size", ",", "self", ".", "d_b", ")", "\n", "input_a", ",", "input_b", "=", "self", ".", "proj", "(", "input_a", ",", "input_b", ")", "\n", "# Pass the input through individual transformers", "\n", "h_as", ",", "h_bs", "=", "self", ".", "trans", "(", "input_a", ",", "input_b", ")", "\n", "h_concat", "=", "torch", ".", "cat", "(", "[", "h_as", ",", "h_bs", "]", ",", "dim", "=", "-", "1", ")", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "h_concat", ")", ")", ")", ")", "\n", "# No sigmoid because we use BCEwithlogitis which contains sigmoid layer and more stable", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.__init__": [[112, 172], ["torch.nn.Module.__init__", "ComplexSequential", "model.TransformerGenerationModel.get_encoder_network", "model.TransformerGenerationModel.get_decoder_network", "print", "print", "ComplexLinear", "ComplexLinear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "ComplexConv1d", "ComplexBatchNorm1d", "ComplexReLU", "ComplexMaxPool1d", "ComplexConv1d", "ComplexBatchNorm1d", "ComplexReLU", "ComplexMaxPool1d", "ComplexConv1d", "ComplexBatchNorm1d", "ComplexReLU", "ComplexMaxPool1d", "ComplexConv1d", "ComplexBatchNorm1d", "ComplexReLU", "ComplexMaxPool1d", "ComplexConv1d", "ComplexBatchNorm1d", "ComplexReLU", "ComplexMaxPool1d", "ComplexFlatten", "utils.count_parameters", "utils.count_parameters"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.get_encoder_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.get_decoder_network", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_dims", ",", "hidden_size", ",", "embed_dim", ",", "output_dim", ",", "num_heads", ",", "attn_dropout", ",", "relu_dropout", ",", "res_dropout", ",", "out_dropout", ",", "layers", ",", "attn_mask", "=", "False", ",", "src_mask", "=", "False", ",", "tgt_mask", "=", "False", ")", ":", "\n", "        ", "super", "(", "TransformerGenerationModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "ComplexSequential", "(", "\n", "ComplexConv1d", "(", "in_channels", "=", "1", ",", "out_channels", "=", "16", ",", "kernel_size", "=", "6", ",", "stride", "=", "1", ")", ",", "\n", "ComplexBatchNorm1d", "(", "16", ")", ",", "\n", "ComplexReLU", "(", ")", ",", "\n", "ComplexMaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "ComplexConv1d", "(", "in_channels", "=", "16", ",", "out_channels", "=", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "ComplexBatchNorm1d", "(", "32", ")", ",", "\n", "ComplexReLU", "(", ")", ",", "\n", "ComplexMaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "ComplexConv1d", "(", "in_channels", "=", "32", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "ComplexBatchNorm1d", "(", "64", ")", ",", "\n", "ComplexReLU", "(", ")", ",", "\n", "ComplexMaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "ComplexConv1d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "ComplexBatchNorm1d", "(", "64", ")", ",", "\n", "ComplexReLU", "(", ")", ",", "\n", "ComplexMaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "ComplexConv1d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "ComplexBatchNorm1d", "(", "128", ")", ",", "\n", "ComplexReLU", "(", ")", ",", "\n", "ComplexMaxPool1d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "ComplexFlatten", "(", ")", ",", "\n", ")", "\n", "[", "self", ".", "orig_d_a", ",", "self", ".", "orig_d_b", "]", "=", "input_dims", "\n", "assert", "self", ".", "orig_d_a", "==", "self", ".", "orig_d_b", "\n", "channels", "=", "(", "(", "(", "(", "(", "(", "(", "(", "(", "(", "self", ".", "orig_d_a", "-", "6", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "\n", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "-", "3", ")", "//", "1", "+", "1", "-", "2", ")", "//", "2", "+", "1", "\n", "self", ".", "d_a", ",", "self", ".", "d_b", "=", "128", "*", "channels", ",", "128", "*", "channels", "\n", "final_out", "=", "embed_dim", "*", "2", "\n", "h_out", "=", "hidden_size", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "layers", "=", "layers", "\n", "self", ".", "attn_dropout", "=", "attn_dropout", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "\n", "# Transformer networks", "\n", "self", ".", "trans_encoder", "=", "self", ".", "get_encoder_network", "(", ")", "\n", "self", ".", "trans_decoder", "=", "self", ".", "get_decoder_network", "(", ")", "\n", "\n", "print", "(", "\"Encoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans_encoder", ")", ")", ")", "\n", "print", "(", "\"Decoder Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "self", ".", "trans_decoder", ")", ")", ")", "\n", "\n", "# Projection layers", "\n", "self", ".", "proj_enc", "=", "ComplexLinear", "(", "self", ".", "d_a", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "proj_dec", "=", "ComplexLinear", "(", "self", ".", "orig_d_a", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "out_fc1", "=", "nn", ".", "Linear", "(", "final_out", ",", "h_out", ")", "\n", "\n", "self", ".", "out_fc2", "=", "nn", ".", "Linear", "(", "h_out", ",", "output_dim", ")", "\n", "\n", "self", ".", "out_dropout", "=", "nn", ".", "Dropout", "(", "out_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.get_encoder_network": [[173, 177], ["modules.transformer.TransformerEncoder"], "methods", ["None"], ["", "def", "get_encoder_network", "(", "self", ")", ":", "\n", "\n", "        ", "return", "TransformerEncoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "attn_mask", "=", "self", ".", "attn_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.get_decoder_network": [[178, 181], ["modules.transformer.TransformerDecoder"], "methods", ["None"], ["", "def", "get_decoder_network", "(", "self", ")", ":", "\n", "        ", "return", "TransformerDecoder", "(", "embed_dim", "=", "self", ".", "embed_dim", ",", "num_heads", "=", "self", ".", "num_heads", ",", "layers", "=", "self", ".", "layers", ",", "src_attn_dropout", "=", "self", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "self", ".", "relu_dropout", ",", "res_dropout", "=", "self", ".", "res_dropout", ",", "tgt_attn_dropout", "=", "self", ".", "attn_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.model.TransformerGenerationModel.forward": [[182, 234], ["x[].view", "x[].view", "model.TransformerGenerationModel.conv", "input_a.reshape.reshape.reshape", "input_b.reshape.reshape.reshape", "model.TransformerGenerationModel.proj_enc", "model.TransformerGenerationModel.trans_encoder", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.TransformerGenerationModel.proj_dec", "model.TransformerGenerationModel.trans_decoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.TransformerGenerationModel.out_fc2", "model.TransformerGenerationModel.out_dropout", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "model.TransformerGenerationModel.proj_dec", "model.TransformerGenerationModel.trans_decoder", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.TransformerGenerationModel.out_fc2", "print", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.relu", "torch.relu", "model.TransformerGenerationModel.trans_decoder", "model.TransformerGenerationModel.out_dropout", "model.TransformerGenerationModel.out_fc1", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "model.TransformerGenerationModel.out_fc1", "dec_a[].unsqueeze", "dec_b[].unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        x should have dimension [seq_len, batch_size, n_features] (i.e., L, N, C).\n        \"\"\"", "\n", "time_step", ",", "batch_size", ",", "n_features", "=", "x", ".", "shape", "\n", "input_a", "=", "x", "[", ":", ",", ":", ",", ":", "n_features", "//", "2", "]", ".", "view", "(", "-", "1", ",", "1", ",", "n_features", "//", "2", ")", "\n", "input_b", "=", "x", "[", ":", ",", ":", ",", "n_features", "//", "2", ":", "]", ".", "view", "(", "-", "1", ",", "1", ",", "n_features", "//", "2", ")", "\n", "input_a", ",", "input_b", "=", "self", ".", "conv", "(", "input_a", ",", "input_b", ")", "\n", "input_a", "=", "input_a", ".", "reshape", "(", "-", "1", ",", "batch_size", ",", "self", ".", "d_a", ")", "\n", "input_b", "=", "input_b", ".", "reshape", "(", "-", "1", ",", "batch_size", ",", "self", ".", "d_b", ")", "\n", "input_a", ",", "input_b", "=", "self", ".", "proj_enc", "(", "input_a", ",", "input_b", ")", "\n", "# Pass the input through individual transformers", "\n", "h_as", ",", "h_bs", "=", "self", ".", "trans_encoder", "(", "input_a", ",", "input_b", ")", "\n", "\n", "if", "y", "is", "not", "None", ":", "\n", "            ", "seq_len", ",", "batch_size", ",", "n_features2", "=", "y", ".", "shape", "\n", "n_features", "=", "n_features2", "//", "2", "\n", "\n", "y_a", "=", "y", "[", ":", "-", "1", ",", ":", ",", ":", "self", ".", "orig_d_a", "]", "# truncate last target ", "\n", "y_b", "=", "y", "[", ":", "-", "1", ",", ":", ",", "self", ".", "orig_d_a", ":", "self", ".", "orig_d_a", "+", "self", ".", "orig_d_b", "]", "# truncate last target ", "\n", "\n", "sos_a", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features", ")", ".", "cuda", "(", ")", "\n", "sos_b", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features", ")", ".", "cuda", "(", ")", "\n", "y_a", "=", "torch", ".", "cat", "(", "[", "sos_a", ",", "y_a", "]", ",", "dim", "=", "0", ")", "# add <sos> to front ", "\n", "y_b", "=", "torch", ".", "cat", "(", "[", "sos_b", ",", "y_b", "]", ",", "dim", "=", "0", ")", "# add <sos> to front ", "\n", "\n", "y_a", ",", "y_b", "=", "self", ".", "proj_dec", "(", "y_a", ",", "y_b", ")", "\n", "out_as", ",", "out_bs", "=", "self", ".", "trans_decoder", "(", "input_A", "=", "y_a", ",", "input_B", "=", "y_b", ",", "enc_A", "=", "h_as", ",", "enc_B", "=", "h_bs", ")", "\n", "out_concat", "=", "torch", ".", "cat", "(", "[", "out_as", ",", "out_bs", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "out_concat", ")", ")", ")", ")", "\n", "\n", "", "elif", "max_len", "is", "not", "None", ":", "\n", "            ", "dec_a", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features", "//", "2", ")", ".", "cuda", "(", ")", "\n", "dec_b", "=", "torch", ".", "zeros", "(", "1", ",", "batch_size", ",", "n_features", "//", "2", ")", ".", "cuda", "(", ")", "\n", "dec_a", ",", "dec_b", "=", "self", ".", "proj_dec", "(", "dec_a", ",", "dec_b", ")", "\n", "\n", "dec_a", ",", "dec_b", "=", "self", ".", "trans_decoder", "(", "input_A", "=", "dec_a", ",", "input_B", "=", "dec_b", ",", "enc_A", "=", "h_as", ",", "enc_B", "=", "h_bs", ")", "\n", "y_a", ",", "y_b", "=", "dec_a", ",", "dec_b", "\n", "\n", "for", "i", "in", "range", "(", "max_len", "-", "1", ")", ":", "\n", "                ", "dec_a", ",", "dec_b", "=", "self", ".", "trans_decoder", "(", "input_A", "=", "y_a", ",", "input_B", "=", "y_b", ",", "enc_A", "=", "h_as", ",", "enc_B", "=", "h_bs", ")", "\n", "y_a", ",", "y_b", "=", "torch", ".", "cat", "(", "[", "y_a", ",", "dec_a", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "]", ",", "dim", "=", "0", ")", ",", "torch", ".", "cat", "(", "[", "y_b", ",", "dec_b", "[", "-", "1", "]", ".", "unsqueeze", "(", "0", ")", "]", ",", "dim", "=", "0", ")", "\n", "", "out_concat", "=", "torch", ".", "cat", "(", "[", "y_a", ",", "y_b", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "output", "=", "self", ".", "out_fc2", "(", "self", ".", "out_dropout", "(", "F", ".", "relu", "(", "self", ".", "out_fc1", "(", "out_concat", ")", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Only one of y and max_len should be input.\"", ")", "\n", "assert", "False", "\n", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq_concat.train_transformer": [[20, 55], ["int", "model_iq_concat.TransformerGenerationModel", "print", "torch.nn.CrossEntropyLoss", "torch.optim.lr_scheduler.ReduceLROnPlateau", "train_gen_iq_concat.train_model", "int", "model.cuda.cuda", "getattr", "model.cuda.parameters", "utils.count_parameters"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq_concat.train_model", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.None.utils.count_parameters"], ["def", "train_transformer", "(", ")", ":", "\n", "    ", "if", "args", ".", "data", "==", "'iq'", ":", "\n", "        ", "input_size", "=", "int", "(", "3200", "/", "(", "args", ".", "src_time_step", "+", "args", ".", "trg_time_step", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_size", "=", "4096", "\n", "", "input_dim", "=", "int", "(", "input_size", "/", "2", ")", "\n", "\n", "model", "=", "TransformerGenerationModel", "(", "input_dims", "=", "[", "input_dim", ",", "input_dim", "]", ",", "\n", "hidden_size", "=", "args", ".", "hidden_size", ",", "\n", "embed_dim", "=", "args", ".", "embed_dim", ",", "\n", "output_dim", "=", "args", ".", "output_dim", ",", "\n", "num_heads", "=", "args", ".", "num_heads", ",", "\n", "attn_dropout", "=", "args", ".", "attn_dropout", ",", "\n", "relu_dropout", "=", "args", ".", "relu_dropout", ",", "\n", "res_dropout", "=", "args", ".", "res_dropout", ",", "\n", "out_dropout", "=", "args", ".", "out_dropout", ",", "\n", "layers", "=", "args", ".", "nlevels", ",", "\n", "attn_mask", "=", "args", ".", "attn_mask", ")", "\n", "if", "use_cuda", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "", "print", "(", "\"Model size: {0}\"", ".", "format", "(", "count_parameters", "(", "model", ")", ")", ")", "\n", "\n", "optimizer", "=", "getattr", "(", "optim", ",", "args", ".", "optim", ")", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "0", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "\"sum\"", ")", "\n", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", ",", "mode", "=", "'min'", ",", "patience", "=", "2", ",", "factor", "=", "0.5", ",", "verbose", "=", "True", ")", "\n", "\n", "settings", "=", "{", "'model'", ":", "model", ",", "\n", "'optimizer'", ":", "optimizer", ",", "\n", "'criterion'", ":", "criterion", ",", "\n", "'scheduler'", ":", "scheduler", ",", "\n", "'input_size'", ":", "input_size", ",", "\n", "'src_time_step'", ":", "args", ".", "src_time_step", ",", "\n", "'trg_time_step'", ":", "args", ".", "trg_time_step", "}", "\n", "return", "train_model", "(", "settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.transformer.train_gen_iq_concat.train_model": [[57, 122], ["range", "model.train", "enumerate", "model.eval", "time.time", "time.time", "train_gen_iq_concat.train_model.train"], "function", ["None"], ["", "def", "train_model", "(", "settings", ")", ":", "\n", "    ", "model", "=", "settings", "[", "'model'", "]", "\n", "optimizer", "=", "settings", "[", "'optimizer'", "]", "\n", "criterion", "=", "settings", "[", "'criterion'", "]", "\n", "scheduler", "=", "settings", "[", "'scheduler'", "]", "\n", "input_size", "=", "settings", "[", "'input_size'", "]", "\n", "src_time_step", "=", "settings", "[", "'src_time_step'", "]", "\n", "trg_time_step", "=", "settings", "[", "'trg_time_step'", "]", "\n", "\n", "\n", "def", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", ":", "\n", "        ", "epoch_loss", "=", "0", "\n", "\n", "model", ".", "train", "(", ")", "\n", "for", "i_batch", ",", "(", "data_batched", ",", "label_batched", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "cur_batch_size", "=", "len", "(", "data_batched", ")", "\n", "src", "=", "data_batched", "[", ":", ",", "0", ":", "src_time_step", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg", "=", "data_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg_label", "=", "label_batched", ".", "cuda", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "model", "(", "x", "=", "src", ",", "y", "=", "trg", ")", "\n", "loss", "=", "criterion", "(", "outputs", ".", "double", "(", ")", ",", "trg_label", ".", "long", "(", ")", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "avg_loss", "=", "epoch_loss", "/", "float", "(", "len", "(", "training_set", ")", ")", "\n", "\n", "return", "avg_loss", "\n", "\n", "\n", "", "def", "evaluate", "(", "model", ",", "criterion", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "epoch_loss", "=", "0", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i_batch", ",", "(", "data_batched", ",", "label_batched", ")", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "                ", "cur_batch_size", "=", "len", "(", "data_batched", ")", "\n", "src", "=", "data_batched", "[", ":", ",", "0", ":", "src_time_step", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg", "=", "data_batched", "[", ":", ",", "src_time_step", ":", ",", ":", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", "trg_label", "=", "label_batched", ".", "cuda", "(", ")", "\n", "outputs", "=", "model", "(", "x", "=", "src", ",", "max_len", "=", "len", "(", "trg", ")", ")", "\n", "loss", "=", "criterion", "(", "outputs", ".", "double", "(", ")", ",", "trg_label", ".", "long", "(", ")", ")", "\n", "epoch_loss", "+=", "loss", ".", "detach", "(", ")", ".", "item", "(", ")", "\n", "", "", "avg_loss", "=", "epoch_loss", "/", "float", "(", "len", "(", "test_set", ")", ")", "\n", "return", "avg_loss", "\n", "\n", "\n", "\n", "\n", "", "best_valid", "=", "1e8", "\n", "for", "epoch", "in", "range", "(", "args", ".", "num_epochs", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_loss", "=", "train", "(", "model", ",", "optimizer", ",", "criterion", ")", "\n", "print", "(", "'Epoch {:2d} | Train Loss {:5.4f}'", ".", "format", "(", "epoch", ",", "train_loss", ")", ")", "\n", "test_loss", "=", "evaluate", "(", "model", ",", "criterion", ")", "\n", "scheduler", ".", "step", "(", "test_loss", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "print", "(", "'Epoch {:2d} | Test  Loss {:5.4f}'", ".", "format", "(", "epoch", ",", "test_loss", ")", ")", "\n", "print", "(", "\"-\"", "*", "50", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"time: %d\"", "%", "(", "end", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.__init__": [[12, 37], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "multihead_attention.MultiheadAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.Parameter", "torch.nn.Parameter", "multihead_attention.MultiheadAttention.register_parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.reset_parameters"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "attn_dropout", "=", "0.", ",", "bias", "=", "True", ",", "add_bias_kv", "=", "False", ",", "add_zero_attn", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "attn_dropout", "=", "attn_dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "in_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "in_proj_bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'in_proj_bias'", ",", "None", ")", "\n", "", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "bias", ")", "\n", "\n", "if", "add_bias_kv", ":", "\n", "            ", "self", ".", "bias_k", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "self", ".", "bias_v", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "embed_dim", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias_k", "=", "self", ".", "bias_v", "=", "None", "\n", "\n", "", "self", ".", "add_zero_attn", "=", "add_zero_attn", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.reset_parameters": [[38, 48], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_", "torch.nn.init.xavier_normal_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "in_proj_weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "out_proj", ".", "weight", ")", "\n", "if", "self", ".", "in_proj_bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_k", ")", "\n", "", "if", "self", ".", "bias_v", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "bias_v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.forward": [[49, 142], ["query.size", "multihead_attention.MultiheadAttention.contiguous().view().transpose", "multihead_attention.MultiheadAttention.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.dropout", "torch.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "multihead_attention.MultiheadAttention.transpose().contiguous().view", "multihead_attention.MultiheadAttention.out_proj", "attn_weights.view.view.view", "query.data_ptr", "key.data_ptr", "value.data_ptr", "key.data_ptr", "value.data_ptr", "list", "key.size", "value.size", "multihead_attention.MultiheadAttention.in_proj_qkv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multihead_attention.MultiheadAttention.contiguous().view().transpose", "multihead_attention.MultiheadAttention.contiguous().view().transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multihead_attention.MultiheadAttention.transpose", "list", "list", "attn_weights.view.view.sum", "query.size", "multihead_attention.MultiheadAttention.in_proj_q", "multihead_attention.MultiheadAttention.in_proj_q", "multihead_attention.MultiheadAttention.in_proj_k", "multihead_attention.MultiheadAttention.in_proj_v", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multihead_attention.MultiheadAttention.contiguous().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "attn_weights.view.view.size", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "multihead_attention.MultiheadAttention.size", "multihead_attention.MultiheadAttention.transpose().contiguous", "multihead_attention.MultiheadAttention.in_proj_kv", "multihead_attention.MultiheadAttention.bias_k.repeat", "multihead_attention.MultiheadAttention.bias_v.repeat", "multihead_attention.MultiheadAttention.contiguous().view", "multihead_attention.MultiheadAttention.contiguous().view", "multihead_attention.MultiheadAttention.new_zeros", "multihead_attention.MultiheadAttention.new_zeros", "print", "print", "torch.cat.new_zeros", "torch.cat.new_zeros", "multihead_attention.MultiheadAttention.contiguous", "torch.cat.new_zeros", "torch.cat.new_zeros", "multihead_attention.MultiheadAttention.transpose", "torch.cat.size", "torch.cat.size", "multihead_attention.MultiheadAttention.contiguous", "multihead_attention.MultiheadAttention.contiguous", "torch.cat.size", "torch.cat.size", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "multihead_attention.MultiheadAttention.size", "multihead_attention.MultiheadAttention.size", "multihead_attention.MultiheadAttention.size", "multihead_attention.MultiheadAttention.size"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.in_proj_qkv", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.in_proj_k", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.in_proj_v", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.in_proj_kv"], ["", "", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "attn_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"Input shape: Time x Batch x Channel\n        Self-attention can be implemented by passing in the same arguments for\n        query, key and value. Timesteps can be masked by supplying a T x T mask in the\n        `attn_mask` argument. Padding elements can be excluded from\n        the key by passing a binary ByteTensor (`key_padding_mask`) with shape:\n        batch x src_len, where padding elements are indicated by 1s.\n        \"\"\"", "\n", "# TODO key_padding_mask", "\n", "\n", "# print(\"[MultiheadAttention forward]\")", "\n", "qkv_same", "=", "query", ".", "data_ptr", "(", ")", "==", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "kv_same", "=", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "embed_dim", "==", "self", ".", "embed_dim", "\n", "assert", "list", "(", "query", ".", "size", "(", ")", ")", "==", "[", "tgt_len", ",", "bsz", ",", "embed_dim", "]", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "aved_state", "=", "None", "\n", "\n", "# projecting q, k, v ", "\n", "if", "qkv_same", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", ",", "v", "=", "self", ".", "in_proj_qkv", "(", "query", ")", "\n", "", "elif", "kv_same", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "if", "key", "is", "None", ":", "\n", "                ", "assert", "value", "is", "None", "\n", "k", "=", "v", "=", "None", "\n", "", "else", ":", "\n", "                ", "k", ",", "v", "=", "self", ".", "in_proj_kv", "(", "key", ")", "\n", "", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "key", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "value", ")", "\n", "# scaling q ", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "# extending k, v by one time step at the end, with self.bias_k and self.bias_v ", "\n", "if", "self", ".", "bias_k", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "bias_v", "is", "not", "None", "\n", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "self", ".", "bias_k", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "self", ".", "bias_v", ".", "repeat", "(", "1", ",", "bsz", ",", "1", ")", "]", ")", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "k", "is", "not", "None", ":", "\n", "            ", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "            ", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "\n", "# extending k, v by another time step at the end, (bsz * num_heads, 1, head_dim) of zeros ", "\n", "if", "self", ".", "add_zero_attn", ":", "\n", "\n", "            ", "src_len", "+=", "1", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k", ",", "k", ".", "new_zeros", "(", "(", "k", ".", "size", "(", "0", ")", ",", "1", ")", "+", "k", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v", ",", "v", ".", "new_zeros", "(", "(", "v", ".", "size", "(", "0", ")", ",", "1", ")", "+", "v", ".", "size", "(", ")", "[", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "                ", "attn_mask", "=", "torch", ".", "cat", "(", "[", "attn_mask", ",", "attn_mask", ".", "new_zeros", "(", "attn_mask", ".", "size", "(", "0", ")", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "attn_weights", "*=", "attn_mask", ".", "unsqueeze", "(", "0", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "attn_weights", ".", "shape", ")", "\n", "print", "(", "attn_mask", ".", "unsqueeze", "(", "0", ")", ".", "shape", ")", "\n", "assert", "False", "\n", "\n", "", "", "attn_weights", "=", "(", "attn_weights", "-", "torch", ".", "min", "(", "attn_weights", ")", ")", "/", "(", "torch", ".", "max", "(", "attn_weights", ")", "-", "torch", ".", "min", "(", "attn_weights", ")", ")", "\n", "attn_weights", "=", "F", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "attn_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "\n", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "# average attention weights over heads", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", "=", "attn_weights", ".", "sum", "(", "dim", "=", "1", ")", "/", "self", ".", "num_heads", "\n", "\n", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.in_proj_qkv": [[143, 145], ["multihead_attention.MultiheadAttention._in_proj().chunk", "multihead_attention.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention._in_proj"], ["", "def", "in_proj_qkv", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.in_proj_kv": [[146, 148], ["multihead_attention.MultiheadAttention._in_proj().chunk", "multihead_attention.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention._in_proj"], ["", "def", "in_proj_kv", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.in_proj_q": [[149, 151], ["multihead_attention.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention._in_proj"], ["", "def", "in_proj_q", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ",", "end", "=", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.in_proj_k": [[152, 154], ["multihead_attention.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention._in_proj"], ["", "def", "in_proj_k", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ",", "end", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention.in_proj_v": [[155, 157], ["multihead_attention.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention._in_proj"], ["", "def", "in_proj_v", "(", "self", ",", "value", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "value", ",", "start", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.multihead_attention.MultiheadAttention._in_proj": [[158, 165], ["torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "_in_proj", "(", "self", ",", "input", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "weight", "=", "self", ".", "in_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "weight", "=", "weight", "[", "start", ":", "end", ",", ":", "]", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.position_embedding.SinusoidalPositionalEmbedding.__init__": [[30, 41], ["torch.Module.__init__", "position_embedding.SinusoidalPositionalEmbedding.get_embedding", "position_embedding.SinusoidalPositionalEmbedding.register_buffer", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.position_embedding.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "padding_idx", "=", "0", ",", "left_pad", "=", "0", ",", "init_size", "=", "128", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "left_pad", "=", "left_pad", "\n", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "init_size", ",", "\n", "embedding_dim", ",", "\n", "padding_idx", ",", "\n", ")", "\n", "self", ".", "register_buffer", "(", "'_float_tensor'", ",", "torch", ".", "FloatTensor", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.position_embedding.SinusoidalPositionalEmbedding.get_embedding": [[42, 59], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "math.log", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "None", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "half_dim", "=", "embedding_dim", "//", "2", "\n", "emb", "=", "math", ".", "log", "(", "10000", ")", "/", "(", "half_dim", "-", "1", ")", "\n", "emb", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "half_dim", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "emb", ")", "\n", "emb", "=", "torch", ".", "arange", "(", "num_embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "*", "emb", ".", "unsqueeze", "(", "0", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "emb", ")", ",", "torch", ".", "cos", "(", "emb", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "num_embeddings", ",", "-", "1", ")", "\n", "if", "embedding_dim", "%", "2", "==", "1", ":", "\n", "# zero pad", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "torch", ".", "zeros", "(", "num_embeddings", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "padding_idx", "is", "not", "None", ":", "\n", "            ", "emb", "[", "padding_idx", ",", ":", "]", "=", "0", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.position_embedding.SinusoidalPositionalEmbedding.forward": [[60, 75], ["input.size", "position_embedding.SinusoidalPositionalEmbedding.weights.type_as", "make_positions().to", "position_embedding.SinusoidalPositionalEmbedding.weights.index_select().to().view().detach", "position_embedding.SinusoidalPositionalEmbedding.get_embedding", "position_embedding.SinusoidalPositionalEmbedding.weights.size", "position_embedding.make_positions", "position_embedding.SinusoidalPositionalEmbedding.weights.index_select().to().view", "position_embedding.SinusoidalPositionalEmbedding.weights.index_select().to", "position_embedding.SinusoidalPositionalEmbedding.weights.index_select", "make_positions().to.view"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.position_embedding.SinusoidalPositionalEmbedding.get_embedding", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.position_embedding.make_positions"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [bsz x seqlen].\"\"\"", "\n", "bsz", ",", "seq_len", "=", "input", ".", "size", "(", ")", "\n", "max_pos", "=", "self", ".", "padding_idx", "+", "1", "+", "seq_len", "\n", "if", "self", ".", "weights", "is", "None", "or", "max_pos", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "# recompute/expand embeddings if needed", "\n", "            ", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "max_pos", ",", "\n", "self", ".", "embedding_dim", ",", "\n", "self", ".", "padding_idx", ",", "\n", ")", "\n", "", "self", ".", "weights", "=", "self", ".", "weights", ".", "type_as", "(", "self", ".", "_float_tensor", ")", "\n", "\n", "positions", "=", "make_positions", "(", "input", ",", "self", ".", "padding_idx", ",", "self", ".", "left_pad", ")", ".", "to", "(", "self", ".", "weights", ".", "device", ")", "\n", "return", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ".", "view", "(", "-", "1", ")", ")", ".", "to", "(", "self", ".", "weights", ".", "device", ")", ".", "view", "(", "bsz", ",", "seq_len", ",", "-", "1", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.position_embedding.SinusoidalPositionalEmbedding.max_positions": [[76, 79], ["int"], "methods", ["None"], ["", "def", "max_positions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Maximum number of supported positions.\"\"\"", "\n", "return", "int", "(", "1e5", ")", "# an arbitrary large number", "\n", "", "", ""]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.position_embedding.make_positions": [[7, 22], ["tensor.new().type_as", "make_positions.range_buf[].expand_as", "tensor.ne().to", "tensor.clone().to().masked_scatter_().long", "tensor.size", "make_positions.range_buf.numel", "torch.arange", "torch.arange", "tensor.new", "tensor.ne", "tensor.ne().to.long().sum().unsqueeze", "tensor.clone().to().masked_scatter_", "tensor.ne().to.size", "tensor.size", "tensor.ne().to.long().sum", "tensor.clone().to", "tensor.ne().to.long", "tensor.clone"], "function", ["None"], ["def", "make_positions", "(", "tensor", ",", "padding_idx", ",", "left_pad", ")", ":", "\n", "    ", "\"\"\"Replace non-padding symbols with their position numbers.\n    Position numbers begin at padding_idx+1.\n    Padding symbols are ignored, but it is necessary to specify whether padding\n    is added on the left side (left_pad=True) or right side (left_pad=False).\n    \"\"\"", "\n", "max_pos", "=", "padding_idx", "+", "1", "+", "tensor", ".", "size", "(", "1", ")", "\n", "make_positions", ".", "range_buf", "=", "tensor", ".", "new", "(", ")", ".", "type_as", "(", "tensor", ")", "\n", "if", "make_positions", ".", "range_buf", ".", "numel", "(", ")", "<", "max_pos", ":", "\n", "        ", "torch", ".", "arange", "(", "padding_idx", "+", "1", ",", "max_pos", ",", "out", "=", "make_positions", ".", "range_buf", ")", "\n", "", "positions", "=", "make_positions", ".", "range_buf", "[", ":", "tensor", ".", "size", "(", "1", ")", "]", ".", "expand_as", "(", "tensor", ")", "\n", "mask", "=", "tensor", ".", "ne", "(", "padding_idx", ")", ".", "to", "(", "positions", ".", "device", ")", "\n", "if", "left_pad", ":", "\n", "        ", "positions", "=", "positions", "-", "mask", ".", "size", "(", "1", ")", "+", "mask", ".", "long", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "return", "tensor", ".", "clone", "(", ")", ".", "to", "(", "positions", ".", "device", ")", ".", "masked_scatter_", "(", "mask", ",", "positions", "[", "mask", "]", ")", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerEncoder.__init__": [[25, 44], ["torch.nn.Module.__init__", "modules.position_embedding.SinusoidalPositionalEmbedding", "torch.nn.ModuleList", "torch.nn.ModuleList", "transformer.TransformerEncoder.layers.extend", "transformer.TransformerEncoder.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "transformer.TransformerEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "layers", ",", "attn_dropout", ",", "relu_dropout", ",", "res_dropout", ",", "attn_mask", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "0.3", "# Embedding dropout", "\n", "self", ".", "attn_dropout", "=", "attn_dropout", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "embed_scale", "=", "1", "\n", "self", ".", "embed_positions", "=", "SinusoidalPositionalEmbedding", "(", "embed_dim", ")", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "[", "\n", "TransformerEncoderLayer", "(", "embed_dim", "=", "embed_dim", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "attn_dropout", "=", "attn_dropout", ",", "\n", "relu_dropout", "=", "relu_dropout", ",", "\n", "res_dropout", "=", "res_dropout", ",", "\n", "attn_mask", "=", "attn_mask", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", "\n", "]", ")", "\n", "self", ".", "register_buffer", "(", "'version'", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerEncoder.forward": [[45, 57], ["transformer.TransformerEncoder.scale_embed_position_dropout", "transformer.TransformerEncoder.scale_embed_position_dropout", "layer"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoder.scale_embed_position_dropout", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoder.scale_embed_position_dropout"], ["", "def", "forward", "(", "self", ",", "input_A", ",", "input_B", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_A: real part of input signal.\n            input_B: imaginary part of input signal.\n        \"\"\"", "\n", "input_A", "=", "self", ".", "scale_embed_position_dropout", "(", "input_A", ")", "\n", "input_B", "=", "self", ".", "scale_embed_position_dropout", "(", "input_B", ")", "\n", "# For each transformer encoder layer:", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "input_A", ",", "input_B", "=", "layer", "(", "input_A", ",", "input_B", ")", "\n", "", "return", "input_A", ",", "input_B", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerEncoder.scale_embed_position_dropout": [[58, 64], ["torch.dropout", "torch.dropout", "transformer.TransformerEncoder.embed_positions().transpose", "transformer.TransformerEncoder.embed_positions", "x_in.transpose"], "methods", ["None"], ["", "def", "scale_embed_position_dropout", "(", "self", ",", "x_in", ")", ":", "\n", "        ", "x", "=", "self", ".", "embed_scale", "*", "x_in", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "self", ".", "embed_positions", "(", "x_in", ".", "transpose", "(", "0", ",", "1", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerEncoderLayer.__init__": [[72, 97], ["torch.nn.Module.__init__", "modules.multihead_attention.MultiheadAttention", "ComplexLinear", "ComplexLinear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "transformer.LayerNorm", "transformer.LayerNorm", "range", "range"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.LayerNorm", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.LayerNorm"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", "=", "4", ",", "attn_dropout", "=", "0.1", ",", "relu_dropout", "=", "0.1", ",", "res_dropout", "=", "0.1", ",", "attn_mask", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "attn_dropout", "=", "attn_dropout", ",", "\n", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "True", ",", "\n", "add_zero_attn", "=", "True", "\n", ")", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "crossmodal", "=", "True", "\n", "self", ".", "normalize", "=", "True", "\n", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "self", ".", "normalize_before", "=", "True", "\n", "\n", "self", ".", "fc1", "=", "ComplexLinear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "# The \"Add & Norm\" part in the paper", "\n", "self", ".", "fc2", "=", "ComplexLinear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "# The \"Add & Norm\" part in the paper", "\n", "\n", "self", ".", "layer_norms_A", "=", "nn", ".", "ModuleList", "(", "[", "LayerNorm", "(", "self", ".", "embed_dim", ")", "for", "_", "in", "range", "(", "2", ")", "]", ")", "\n", "self", ".", "layer_norms_B", "=", "nn", ".", "ModuleList", "(", "[", "LayerNorm", "(", "self", ".", "embed_dim", ")", "for", "_", "in", "range", "(", "2", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerEncoderLayer.forward": [[98, 159], ["transformer.TransformerEncoderLayer.attention_block", "transformer.TransformerEncoderLayer.attention_block", "transformer.TransformerEncoderLayer.attention_block", "transformer.TransformerEncoderLayer.attention_block", "transformer.TransformerEncoderLayer.attention_block", "transformer.TransformerEncoderLayer.attention_block", "transformer.TransformerEncoderLayer.attention_block", "transformer.TransformerEncoderLayer.attention_block", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "transformer.TransformerEncoderLayer.fc1", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "transformer.TransformerEncoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.attention_block", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.attention_block", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.attention_block", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.attention_block", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.attention_block", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.attention_block", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.attention_block", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.attention_block"], ["", "def", "forward", "(", "self", ",", "x_A", ",", "x_B", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_A: real part of input signal.\n            input_B: imaginary part of input signal.\n        \"\"\"", "\n", "## Attention Part", "\n", "# Residual and Layer Norm", "\n", "residual_A", "=", "x_A", "\n", "residual_B", "=", "x_B", "\n", "\n", "# Multihead Attention", "\n", "x_aaa", "=", "self", ".", "attention_block", "(", "x_A", ",", "x_A", ",", "x_A", ")", "\n", "x_aab", "=", "self", ".", "attention_block", "(", "x_A", ",", "x_A", ",", "x_B", ")", "\n", "x_aba", "=", "self", ".", "attention_block", "(", "x_A", ",", "x_B", ",", "x_A", ")", "\n", "x_baa", "=", "self", ".", "attention_block", "(", "x_B", ",", "x_A", ",", "x_A", ")", "\n", "x_abb", "=", "self", ".", "attention_block", "(", "x_A", ",", "x_B", ",", "x_B", ")", "\n", "x_bab", "=", "self", ".", "attention_block", "(", "x_B", ",", "x_A", ",", "x_B", ")", "\n", "x_bba", "=", "self", ".", "attention_block", "(", "x_B", ",", "x_B", ",", "x_A", ")", "\n", "x_bbb", "=", "self", ".", "attention_block", "(", "x_B", ",", "x_B", ",", "x_B", ")", "\n", "\n", "\n", "x_A", "=", "x_aaa", "-", "x_abb", "-", "x_bab", "-", "x_bba", "\n", "x_B", "=", "-", "x_bbb", "+", "x_baa", "+", "x_aba", "+", "x_aab", "\n", "\n", "\n", "x_A", "=", "self", ".", "layer_norms_A", "[", "0", "]", "(", "x_A", ")", "\n", "x_B", "=", "self", ".", "layer_norms_B", "[", "0", "]", "(", "x_B", ")", "\n", "# Dropout and Residual", "\n", "x_A", "=", "F", ".", "dropout", "(", "x_A", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x_B", "=", "F", ".", "dropout", "(", "x_B", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "x_A", "=", "residual_A", "+", "x_A", "\n", "x_B", "=", "residual_B", "+", "x_B", "\n", "\n", "\n", "# ##FC Part", "\n", "residual_A", "=", "x_A", "\n", "residual_B", "=", "x_B", "\n", "\n", "# FC1", "\n", "x_A", ",", "x_B", "=", "self", ".", "fc1", "(", "x_A", ",", "x_B", ")", "\n", "x_A", "=", "F", ".", "relu", "(", "x_A", ")", "\n", "x_B", "=", "F", ".", "relu", "(", "x_B", ")", "\n", "x_A", "=", "F", ".", "dropout", "(", "x_A", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x_B", "=", "F", ".", "dropout", "(", "x_B", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# FC2", "\n", "x_A", ",", "x_B", "=", "self", ".", "fc2", "(", "x_A", ",", "x_B", ")", "\n", "\n", "\n", "x_A", "=", "self", ".", "layer_norms_A", "[", "1", "]", "(", "x_A", ")", "\n", "x_B", "=", "self", ".", "layer_norms_B", "[", "1", "]", "(", "x_B", ")", "\n", "\n", "x_A", "=", "F", ".", "dropout", "(", "x_A", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x_B", "=", "F", ".", "dropout", "(", "x_B", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "x_A", "=", "residual_A", "+", "x_A", "\n", "x_B", "=", "residual_B", "+", "x_B", "\n", "\n", "return", "x_A", ",", "x_B", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerEncoderLayer.scale_embed_position_dropout": [[160, 166], ["torch.dropout", "torch.dropout", "transformer.TransformerEncoderLayer.embed_positions().transpose", "transformer.TransformerEncoderLayer.embed_positions", "x_in.transpose"], "methods", ["None"], ["", "def", "scale_embed_position_dropout", "(", "self", ",", "x_in", ")", ":", "\n", "        ", "x", "=", "self", ".", "embed_scale", "*", "x_in", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "self", ".", "embed_positions", "(", "x_in", ".", "transpose", "(", "0", ",", "1", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerEncoderLayer.attention_block": [[167, 172], ["transformer.TransformerEncoderLayer.self_attn"], "methods", ["None"], ["", "def", "attention_block", "(", "self", ",", "x", ",", "x_k", ",", "x_v", ")", ":", "\n", "\n", "        ", "mask", "=", "None", "\n", "x", ",", "_", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "x_k", ",", "value", "=", "x_v", ",", "attn_mask", "=", "mask", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerDecoder.__init__": [[187, 207], ["torch.nn.Module.__init__", "modules.position_embedding.SinusoidalPositionalEmbedding", "torch.nn.ModuleList", "torch.nn.ModuleList", "transformer.TransformerDecoder.layers.extend", "transformer.TransformerDecoder.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "transformer.TransformerDecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "layers", ",", "src_attn_dropout", "=", "0.0", ",", "relu_dropout", "=", "0.0", ",", "res_dropout", "=", "0.0", ",", "tgt_attn_dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "0.3", "# Embedding dropout", "\n", "# self.attn_dropout = attn_dropout", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "embed_scale", "=", "1", "\n", "self", ".", "embed_positions", "=", "SinusoidalPositionalEmbedding", "(", "embed_dim", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "[", "\n", "TransformerDecoderLayer", "(", "embed_dim", "=", "embed_dim", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "src_attn_dropout", "=", "src_attn_dropout", ",", "\n", "relu_dropout", "=", "relu_dropout", ",", "\n", "res_dropout", "=", "res_dropout", ",", "\n", "tgt_attn_dropout", "=", "tgt_attn_dropout", "\n", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", "\n", "]", ")", "\n", "self", ".", "register_buffer", "(", "'version'", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerDecoder.forward": [[208, 223], ["transformer.TransformerDecoder.scale_embed_position_dropout", "transformer.TransformerDecoder.scale_embed_position_dropout", "layer"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoder.scale_embed_position_dropout", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoder.scale_embed_position_dropout"], ["", "def", "forward", "(", "self", ",", "input_A", ",", "input_B", ",", "enc_A", ",", "enc_B", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_A: real part of input signal.\n            input_B: imaginary part of input signal.\n            enc_A: real part of encoder output.\n            enc_B: imaginary part of encoder output.\n        \"\"\"", "\n", "input_A", "=", "self", ".", "scale_embed_position_dropout", "(", "input_A", ")", "\n", "input_B", "=", "self", ".", "scale_embed_position_dropout", "(", "input_B", ")", "\n", "\n", "# For each transformer encoder layer:", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "input_A", ",", "input_B", "=", "layer", "(", "input_A", ",", "input_B", ",", "enc_A", ",", "enc_B", ")", "\n", "", "return", "input_A", ",", "input_B", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerDecoder.scale_embed_position_dropout": [[224, 230], ["torch.dropout", "torch.dropout", "transformer.TransformerDecoder.embed_positions().transpose", "transformer.TransformerDecoder.embed_positions", "x_in.transpose"], "methods", ["None"], ["", "def", "scale_embed_position_dropout", "(", "self", ",", "x_in", ")", ":", "\n", "        ", "x", "=", "self", ".", "embed_scale", "*", "x_in", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "self", ".", "embed_positions", "(", "x_in", ".", "transpose", "(", "0", ",", "1", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerDecoderLayer.__init__": [[233, 265], ["torch.nn.Module.__init__", "modules.multihead_attention.MultiheadAttention", "modules.multihead_attention.MultiheadAttention", "ComplexLinear", "ComplexLinear", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "transformer.LayerNorm", "transformer.LayerNorm", "range", "range"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.LayerNorm", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.LayerNorm"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", "=", "4", ",", "src_attn_dropout", "=", "0.1", ",", "relu_dropout", "=", "0.1", ",", "res_dropout", "=", "0.1", ",", "tgt_attn_dropout", "=", "0.1", ",", "src_mask", "=", "True", ",", "tgt_mask", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "attn_dropout", "=", "src_attn_dropout", ",", "\n", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "True", ",", "\n", "add_zero_attn", "=", "True", ",", "\n", ")", "\n", "self", ".", "src_mask", "=", "src_mask", "# used as last arg in forward function call ", "\n", "self", ".", "tgt_mask", "=", "tgt_mask", "# used as last arg in forward function call ", "\n", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "\n", "self", ".", "attn", "=", "MultiheadAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "attn_dropout", "=", "tgt_attn_dropout", ",", "\n", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "True", ",", "\n", "add_zero_attn", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "fc1", "=", "ComplexLinear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "# The \"Add & Norm\" part in the paper", "\n", "self", ".", "fc2", "=", "ComplexLinear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "layer_norms_A", "=", "nn", ".", "ModuleList", "(", "[", "LayerNorm", "(", "self", ".", "embed_dim", ")", "for", "_", "in", "range", "(", "3", ")", "]", ")", "\n", "self", ".", "layer_norms_B", "=", "nn", ".", "ModuleList", "(", "[", "LayerNorm", "(", "self", ".", "embed_dim", ")", "for", "_", "in", "range", "(", "3", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerDecoderLayer.forward": [[266, 352], ["transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.self_attn", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "transformer.TransformerDecoderLayer.attn", "transformer.TransformerDecoderLayer.attn", "transformer.TransformerDecoderLayer.attn", "transformer.TransformerDecoderLayer.attn", "transformer.TransformerDecoderLayer.attn", "transformer.TransformerDecoderLayer.attn", "transformer.TransformerDecoderLayer.attn", "transformer.TransformerDecoderLayer.attn", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "transformer.TransformerDecoderLayer.fc1", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "transformer.TransformerDecoderLayer.fc2", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "transformer.buffered_future_mask"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.buffered_future_mask"], ["", "def", "forward", "(", "self", ",", "x_A", ",", "x_B", ",", "enc_A", ",", "enc_B", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_A: real part of input signal.\n            input_B: imaginary part of input signal.\n            enc_A: real part of encoder output.\n            enc_B: imaginary part of encoder output.\n        \"\"\"", "\n", "## Attention Part", "\n", "# Residual and Layer Norm", "\n", "residual_A", "=", "x_A", "\n", "residual_B", "=", "x_B", "\n", "\n", "# Self Attention", "\n", "if", "self", ".", "src_mask", ":", "\n", "            ", "assert", "x_A", ".", "shape", "[", "0", "]", "==", "x_B", ".", "shape", "[", "0", "]", "\n", "mask", "=", "buffered_future_mask", "(", "x_A", ")", "\n", "", "else", ":", "\n", "            ", "mask", "=", "None", "\n", "\n", "", "x_aaa", ",", "_", "=", "self", ".", "self_attn", "(", "x_A", ",", "x_A", ",", "x_A", ",", "attn_mask", "=", "mask", ")", "\n", "x_aab", ",", "_", "=", "self", ".", "self_attn", "(", "x_A", ",", "x_A", ",", "x_B", ",", "attn_mask", "=", "mask", ")", "\n", "x_aba", ",", "_", "=", "self", ".", "self_attn", "(", "x_A", ",", "x_B", ",", "x_A", ",", "attn_mask", "=", "mask", ")", "\n", "x_baa", ",", "_", "=", "self", ".", "self_attn", "(", "x_B", ",", "x_A", ",", "x_A", ",", "attn_mask", "=", "mask", ")", "\n", "x_abb", ",", "_", "=", "self", ".", "self_attn", "(", "x_A", ",", "x_B", ",", "x_B", ",", "attn_mask", "=", "mask", ")", "\n", "x_bab", ",", "_", "=", "self", ".", "self_attn", "(", "x_B", ",", "x_A", ",", "x_B", ",", "attn_mask", "=", "mask", ")", "\n", "x_bba", ",", "_", "=", "self", ".", "self_attn", "(", "x_B", ",", "x_B", ",", "x_A", ",", "attn_mask", "=", "mask", ")", "\n", "x_bbb", ",", "_", "=", "self", ".", "self_attn", "(", "x_B", ",", "x_B", ",", "x_B", ",", "attn_mask", "=", "mask", ")", "\n", "\n", "x_A", "=", "x_aaa", "-", "x_abb", "-", "x_bab", "-", "x_bba", "\n", "x_B", "=", "-", "x_bbb", "+", "x_baa", "+", "x_aba", "+", "x_aab", "\n", "\n", "# Layer Norm, Dropout and Residual;", "\n", "x_A", "=", "F", ".", "dropout", "(", "x_A", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x_B", "=", "F", ".", "dropout", "(", "x_B", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x_A", "+=", "residual_A", "\n", "x_B", "+=", "residual_B", "\n", "x_A", "=", "self", ".", "layer_norms_A", "[", "0", "]", "(", "x_A", ")", "\n", "x_B", "=", "self", ".", "layer_norms_B", "[", "0", "]", "(", "x_B", ")", "\n", "\n", "residual_A", "=", "x_A", "\n", "residual_B", "=", "x_B", "\n", "\n", "# Attention between encoder and decoder ", "\n", "x_acc", ",", "_", "=", "self", ".", "attn", "(", "x_A", ",", "enc_A", ",", "enc_A", ")", "\n", "x_add", ",", "_", "=", "self", ".", "attn", "(", "x_A", ",", "enc_B", ",", "enc_B", ")", "\n", "x_bcd", ",", "_", "=", "self", ".", "attn", "(", "x_B", ",", "enc_A", ",", "enc_B", ")", "\n", "x_bdc", ",", "_", "=", "self", ".", "attn", "(", "x_B", ",", "enc_B", ",", "enc_A", ")", "\n", "x_acd", ",", "_", "=", "self", ".", "attn", "(", "x_A", ",", "enc_A", ",", "enc_B", ")", "\n", "x_adc", ",", "_", "=", "self", ".", "attn", "(", "x_A", ",", "enc_B", ",", "enc_A", ")", "\n", "x_bcc", ",", "_", "=", "self", ".", "attn", "(", "x_B", ",", "enc_A", ",", "enc_A", ")", "\n", "x_bdd", ",", "_", "=", "self", ".", "attn", "(", "x_B", ",", "enc_B", ",", "enc_B", ")", "\n", "\n", "x_A", "=", "x_acc", "-", "x_add", "-", "x_bcd", "-", "x_bdc", "\n", "x_B", "=", "x_acd", "+", "x_adc", "+", "x_bcc", "-", "x_bdd", "\n", "\n", "# Layer Norm, Dropout and Residual;", "\n", "x_A", "=", "F", ".", "dropout", "(", "x_A", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x_B", "=", "F", ".", "dropout", "(", "x_B", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x_A", "+=", "residual_A", "\n", "x_B", "+=", "residual_B", "\n", "x_A", "=", "self", ".", "layer_norms_A", "[", "1", "]", "(", "x_A", ")", "\n", "x_B", "=", "self", ".", "layer_norms_B", "[", "1", "]", "(", "x_B", ")", "\n", "\n", "residual_A", "=", "x_A", "\n", "residual_B", "=", "x_B", "\n", "\n", "# FC1", "\n", "x_A", ",", "x_B", "=", "self", ".", "fc1", "(", "x_A", ",", "x_B", ")", "\n", "x_A", "=", "F", ".", "relu", "(", "x_A", ")", "\n", "x_B", "=", "F", ".", "relu", "(", "x_B", ")", "\n", "x_A", "=", "F", ".", "dropout", "(", "x_A", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x_B", "=", "F", ".", "dropout", "(", "x_B", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# FC2", "\n", "x_A", ",", "x_B", "=", "self", ".", "fc2", "(", "x_A", ",", "x_B", ")", "\n", "x_A", "=", "F", ".", "dropout", "(", "x_A", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x_B", "=", "F", ".", "dropout", "(", "x_B", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "x_A", "+=", "residual_A", "\n", "x_B", "+=", "residual_B", "\n", "x_A", "=", "self", ".", "layer_norms_A", "[", "2", "]", "(", "x_A", ")", "\n", "x_B", "=", "self", ".", "layer_norms_B", "[", "2", "]", "(", "x_B", ")", "\n", "#print(\"Attention here: \", x_A.mean().item(), x_B.mean().item())", "\n", "\n", "return", "x_A", ",", "x_B", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoder.__init__": [[367, 386], ["torch.nn.Module.__init__", "modules.position_embedding.SinusoidalPositionalEmbedding", "torch.nn.ModuleList", "torch.nn.ModuleList", "transformer.TransformerConcatEncoder.layers.extend", "transformer.TransformerConcatEncoder.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "transformer.TransformerConcatEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "layers", ",", "attn_dropout", ",", "relu_dropout", ",", "res_dropout", ",", "attn_mask", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "0.3", "# Embedding dropout", "\n", "self", ".", "attn_dropout", "=", "attn_dropout", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "embed_scale", "=", "1", "\n", "self", ".", "embed_positions", "=", "SinusoidalPositionalEmbedding", "(", "embed_dim", ")", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "[", "\n", "TransformerConcatEncoderLayer", "(", "embed_dim", "=", "embed_dim", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "attn_dropout", "=", "attn_dropout", ",", "\n", "relu_dropout", "=", "relu_dropout", ",", "\n", "res_dropout", "=", "res_dropout", ",", "\n", "attn_mask", "=", "attn_mask", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", "\n", "]", ")", "\n", "self", ".", "register_buffer", "(", "'version'", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoder.forward": [[387, 392], ["transformer.TransformerConcatEncoder.scale_embed_position_dropout", "layer"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoder.scale_embed_position_dropout"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "scale_embed_position_dropout", "(", "x", ")", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoder.scale_embed_position_dropout": [[393, 399], ["torch.dropout", "torch.dropout", "transformer.TransformerConcatEncoder.embed_positions().transpose", "transformer.TransformerConcatEncoder.embed_positions", "x_in.transpose"], "methods", ["None"], ["", "def", "scale_embed_position_dropout", "(", "self", ",", "x_in", ")", ":", "\n", "        ", "x", "=", "self", ".", "embed_scale", "*", "x_in", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "self", ".", "embed_positions", "(", "x_in", ".", "transpose", "(", "0", ",", "1", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.__init__": [[406, 429], ["torch.nn.Module.__init__", "modules.multihead_attention.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "transformer.LayerNorm", "range"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.LayerNorm"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", "=", "4", ",", "attn_dropout", "=", "0.1", ",", "relu_dropout", "=", "0.1", ",", "res_dropout", "=", "0.1", ",", "attn_mask", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "attn_dropout", "=", "attn_dropout", ",", "\n", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "True", ",", "\n", "add_zero_attn", "=", "True", "\n", ")", "\n", "self", ".", "attn_mask", "=", "attn_mask", "\n", "self", ".", "normalize", "=", "True", "\n", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "self", ".", "normalize_before", "=", "True", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "\n", "self", ".", "layer_norms", "=", "nn", ".", "ModuleList", "(", "[", "LayerNorm", "(", "self", ".", "embed_dim", ")", "for", "_", "in", "range", "(", "2", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.forward": [[430, 458], ["transformer.TransformerConcatEncoderLayer.attention_block", "torch.dropout", "torch.dropout", "transformer.TransformerConcatEncoderLayer.fc1", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "transformer.TransformerConcatEncoderLayer.fc2", "torch.dropout", "torch.dropout"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.attention_block"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "## Attention Part", "\n", "# Residual and Layer Norm", "\n", "        ", "residual", "=", "x", "\n", "# Multihead Attention", "\n", "x", "=", "self", ".", "attention_block", "(", "x", ",", "x", ",", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer_norms", "[", "0", "]", "(", "x", ")", "\n", "# Dropout and Residual", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "residual", "+", "x", "\n", "\n", "# ##FC Part", "\n", "residual", "=", "x", "\n", "\n", "# FC1", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer_norms", "[", "1", "]", "(", "x", ")", "\n", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "x", "=", "residual", "+", "x", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.scale_embed_position_dropout": [[459, 465], ["torch.dropout", "torch.dropout", "transformer.TransformerConcatEncoderLayer.embed_positions().transpose", "transformer.TransformerConcatEncoderLayer.embed_positions", "x_in.transpose"], "methods", ["None"], ["", "def", "scale_embed_position_dropout", "(", "self", ",", "x_in", ")", ":", "\n", "        ", "x", "=", "self", ".", "embed_scale", "*", "x_in", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "x", "+=", "self", ".", "embed_positions", "(", "x_in", ".", "transpose", "(", "0", ",", "1", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatEncoderLayer.attention_block": [[466, 471], ["transformer.TransformerConcatEncoderLayer.self_attn"], "methods", ["None"], ["", "def", "attention_block", "(", "self", ",", "x", ",", "x_k", ",", "x_v", ")", ":", "\n", "\n", "        ", "mask", "=", "None", "\n", "x", ",", "_", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "x_k", ",", "value", "=", "x_v", ",", "attn_mask", "=", "mask", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoder.__init__": [[486, 504], ["torch.nn.Module.__init__", "modules.position_embedding.SinusoidalPositionalEmbedding", "torch.nn.ModuleList", "torch.nn.ModuleList", "transformer.TransformerConcatDecoder.layers.extend", "transformer.TransformerConcatDecoder.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "transformer.TransformerConcatDecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__"], ["def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "layers", ",", "src_attn_dropout", "=", "0.0", ",", "relu_dropout", "=", "0.0", ",", "res_dropout", "=", "0.0", ",", "tgt_attn_dropout", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "0.3", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "embed_scale", "=", "1", "\n", "self", ".", "embed_positions", "=", "SinusoidalPositionalEmbedding", "(", "embed_dim", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "layers", ".", "extend", "(", "[", "\n", "TransformerConcatDecoderLayer", "(", "embed_dim", "=", "embed_dim", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "src_attn_dropout", "=", "src_attn_dropout", ",", "\n", "relu_dropout", "=", "relu_dropout", ",", "\n", "res_dropout", "=", "res_dropout", ",", "\n", "tgt_attn_dropout", "=", "tgt_attn_dropout", "\n", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", "\n", "]", ")", "\n", "self", ".", "register_buffer", "(", "'version'", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoder.forward": [[505, 510], ["transformer.TransformerConcatDecoder.scale_embed_position_dropout", "layer"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoder.scale_embed_position_dropout"], ["", "def", "forward", "(", "self", ",", "input", ",", "enc", ")", ":", "\n", "        ", "input", "=", "self", ".", "scale_embed_position_dropout", "(", "input", ")", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "input", "=", "layer", "(", "input", ",", "enc", ")", "\n", "", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoder.scale_embed_position_dropout": [[511, 518], ["torch.dropout", "torch.dropout", "transformer.TransformerConcatDecoder.embed_positions().transpose", "transformer.TransformerConcatDecoder.embed_positions().transpose", "transformer.TransformerConcatDecoder.embed_positions", "transformer.TransformerConcatDecoder.embed_positions", "x_in.transpose", "x_in.transpose"], "methods", ["None"], ["", "def", "scale_embed_position_dropout", "(", "self", ",", "x_in", ")", ":", "\n", "        ", "x", "=", "self", ".", "embed_scale", "*", "x_in", "\n", "if", "self", ".", "embed_positions", "is", "not", "None", ":", "\n", "            ", "y", "=", "self", ".", "embed_positions", "(", "x_in", ".", "transpose", "(", "0", ",", "1", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "x", "+=", "self", ".", "embed_positions", "(", "x_in", ".", "transpose", "(", "0", ",", "1", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "# may change", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__": [[521, 551], ["torch.nn.Module.__init__", "modules.multihead_attention.MultiheadAttention", "modules.multihead_attention.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ModuleList", "transformer.LayerNorm", "range"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.__init__", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear", "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.LayerNorm"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", "=", "4", ",", "src_attn_dropout", "=", "0.1", ",", "relu_dropout", "=", "0.1", ",", "res_dropout", "=", "0.1", ",", "tgt_attn_dropout", "=", "0.1", ",", "src_mask", "=", "True", ",", "tgt_mask", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "attn_dropout", "=", "src_attn_dropout", ",", "\n", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "True", ",", "\n", "add_zero_attn", "=", "True", ",", "\n", ")", "\n", "self", ".", "src_mask", "=", "src_mask", "# used as last arg in forward function call ", "\n", "self", ".", "tgt_mask", "=", "tgt_mask", "# used as last arg in forward function call ", "\n", "\n", "self", ".", "relu_dropout", "=", "relu_dropout", "\n", "self", ".", "res_dropout", "=", "res_dropout", "\n", "\n", "self", ".", "attn", "=", "MultiheadAttention", "(", "\n", "embed_dim", "=", "self", ".", "embed_dim", ",", "\n", "num_heads", "=", "self", ".", "num_heads", ",", "\n", "attn_dropout", "=", "tgt_attn_dropout", ",", "\n", "bias", "=", "True", ",", "\n", "add_bias_kv", "=", "True", ",", "\n", "add_zero_attn", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "self", ".", "embed_dim", ",", "self", ".", "embed_dim", ")", "\n", "self", ".", "layer_norms", "=", "nn", ".", "ModuleList", "(", "[", "LayerNorm", "(", "self", ".", "embed_dim", ")", "for", "_", "in", "range", "(", "3", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.TransformerConcatDecoderLayer.forward": [[552, 586], ["transformer.TransformerConcatDecoderLayer.self_attn", "torch.dropout", "torch.dropout", "transformer.TransformerConcatDecoderLayer.attn", "torch.dropout", "torch.dropout", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "transformer.TransformerConcatDecoderLayer.fc2", "torch.dropout", "torch.dropout", "transformer.buffered_future_mask", "transformer.TransformerConcatDecoderLayer.fc1"], "methods", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.buffered_future_mask"], ["", "def", "forward", "(", "self", ",", "x", ",", "enc", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "# Self Attention", "\n", "if", "self", ".", "src_mask", ":", "\n", "            ", "mask", "=", "buffered_future_mask", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "mask", "=", "None", "\n", "", "x", ",", "_", "=", "self", ".", "self_attn", "(", "x", ",", "x", ",", "x", ")", "\n", "# Layer Norm, Dropout and Residual;", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "+=", "residual", "\n", "x", "=", "self", ".", "layer_norms", "[", "0", "]", "(", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "\n", "# Attention between encoder and decoder ", "\n", "x", ",", "_", "=", "self", ".", "attn", "(", "x", ",", "enc", ",", "enc", ")", "\n", "\n", "# Layer Norm, Dropout and Residual;", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "res_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "+=", "residual", "\n", "x", "=", "self", ".", "layer_norms", "[", "1", "]", "(", "x", ")", "\n", "\n", "residual", "=", "x", "\n", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "relu_dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "x", "+=", "residual", "\n", "x", "=", "self", ".", "layer_norms", "[", "2", "]", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.fill_with_neg_inf": [[587, 589], ["t.float().fill_().type_as", "t.float().fill_", "float", "t.float"], "function", ["None"], ["", "", "def", "fill_with_neg_inf", "(", "t", ")", ":", "\n", "    ", "return", "t", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "'-inf'", ")", ")", ".", "type_as", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.fill_with_one": [[590, 592], ["t.float().fill_().type_as", "t.float().fill_", "float", "t.float"], "function", ["None"], ["", "def", "fill_with_one", "(", "t", ")", ":", "\n", "    ", "return", "t", ".", "float", "(", ")", ".", "fill_", "(", "float", "(", "1", ")", ")", ".", "type_as", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.buffered_future_mask": [[593, 601], ["tensor.size", "torch.tril", "torch.tril", "tensor2.size", "transformer.fill_with_one", "future_mask.cuda.cuda", "torch.ones", "torch.ones"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.fill_with_one"], ["", "def", "buffered_future_mask", "(", "tensor", ",", "tensor2", "=", "None", ")", ":", "\n", "    ", "dim1", "=", "dim2", "=", "tensor", ".", "size", "(", "0", ")", "\n", "if", "tensor2", "is", "not", "None", ":", "\n", "        ", "dim2", "=", "tensor2", ".", "size", "(", "0", ")", "\n", "", "future_mask", "=", "torch", ".", "tril", "(", "fill_with_one", "(", "torch", ".", "ones", "(", "dim1", ",", "dim2", ")", ")", ",", "0", ")", "\n", "if", "tensor", ".", "is_cuda", ":", "\n", "        ", "future_mask", "=", "future_mask", ".", "cuda", "(", ")", "\n", "", "return", "future_mask", "[", ":", "dim1", ",", ":", "dim2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear": [[603, 609], ["torch.nn.Linear", "torch.nn.init.xavier_uniform_", "torch.nn.init.constant_"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.Linear"], ["", "def", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "bias", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.", ")", "\n", "", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.LayerNorm": [[611, 614], ["torch.nn.LayerNorm"], "function", ["home.repos.pwc.inspect_result.muqiaoy_dl_signal.modules.transformer.LayerNorm"], ["", "def", "LayerNorm", "(", "embedding_dim", ")", ":", "\n", "    ", "m", "=", "nn", ".", "LayerNorm", "(", "embedding_dim", ",", "eps", "=", "1e-20", ")", "\n", "return", "m", "\n", "\n"]]}