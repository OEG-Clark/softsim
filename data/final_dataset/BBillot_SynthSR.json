{"home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.estimate_priors.estimate_t2_cropping": [[27, 74], ["ext.lab2im.utils.list_images_in_folder", "numpy.zeros", "numpy.zeros", "ext.lab2im.utils.LoopInfo", "enumerate", "numpy.array", "ext.lab2im.utils.mkdir", "len", "len", "len", "utils.LoopInfo.update", "ext.lab2im.utils.load_volume", "int", "ext.lab2im.edit_volumes.mask_volume", "numpy.save", "numpy.argmax", "numpy.nonzero", "numpy.maximum", "numpy.minimum", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "os.path.join", "numpy.min", "int", "numpy.max", "int"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mask_volume"], ["def", "estimate_t2_cropping", "(", "image_dir", ",", "result_dir", "=", "None", ",", "dilation", "=", "5", ")", ":", "\n", "    ", "\"\"\"This function takes all the hippocampus images (with 2 channels) within the specified directory, and estimates\n    the cropping dimensions around the hippocampus in the t2 channel.\n    It returns the mean and sts deviation for the minimal and maximal croppings, proportional to image size.\n    :param image_dir: path of the folder containing hippocampus images\n    :param result_dir: if not None, path of the folder where to write the computed statistics.\n    :param dilation: dilation coefficient used to extract full brain mask. Default is 5.\n    :returns t2_cropping_stats: numpy vector of size 4 [mean min crop, std min crop, mean max crop, std max crop]\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "if", "result_dir", "is", "not", "None", ":", "\n", "        ", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# loop through images", "\n", "", "list_image_paths", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "max_cropping_proportions", "=", "np", ".", "zeros", "(", "len", "(", "list_image_paths", ")", ")", "\n", "min_cropping_proportions", "=", "np", ".", "zeros", "(", "len", "(", "list_image_paths", ")", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "list_image_paths", ")", ",", "10", ",", "'processing'", ")", "\n", "for", "im_idx", ",", "image_path", "in", "enumerate", "(", "list_image_paths", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "im_idx", ")", "\n", "\n", "# load t2 channel", "\n", "im", "=", "utils", ".", "load_volume", "(", "image_path", ")", "\n", "t2", "=", "im", "[", "...", ",", "1", "]", "\n", "shape", "=", "t2", ".", "shape", "\n", "hdim", "=", "int", "(", "np", ".", "argmax", "(", "shape", ")", ")", "\n", "\n", "# mask image", "\n", "_", ",", "mask", "=", "edit_volumes", ".", "mask_volume", "(", "t2", ",", "threshold", "=", "0", ",", "dilate", "=", "dilation", ",", "return_mask", "=", "True", ")", "\n", "\n", "# find cropping indices", "\n", "indices", "=", "np", ".", "nonzero", "(", "mask", ")", "[", "hdim", "]", "\n", "min_cropping_proportions", "[", "im_idx", "]", "=", "np", ".", "maximum", "(", "np", ".", "min", "(", "indices", ")", "+", "int", "(", "dilation", "/", "2", ")", ",", "0", ")", "/", "shape", "[", "hdim", "]", "\n", "max_cropping_proportions", "[", "im_idx", "]", "=", "np", ".", "minimum", "(", "np", ".", "max", "(", "indices", ")", "-", "int", "(", "dilation", "/", "2", ")", ",", "shape", "[", "hdim", "]", ")", "/", "shape", "[", "hdim", "]", "\n", "\n", "# compute and save stats", "\n", "", "t2_cropping_stats", "=", "np", ".", "array", "(", "[", "np", ".", "mean", "(", "min_cropping_proportions", ")", ",", "\n", "np", ".", "std", "(", "min_cropping_proportions", ")", ",", "\n", "np", ".", "mean", "(", "max_cropping_proportions", ")", ",", "\n", "np", ".", "std", "(", "max_cropping_proportions", ")", "]", ")", "\n", "\n", "# save stats if necessary", "\n", "if", "result_dir", "is", "not", "None", ":", "\n", "        ", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "result_dir", ",", "'t2_cropping_stats.npy'", ")", ",", "t2_cropping_stats", ")", "\n", "\n", "", "return", "t2_cropping_stats", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.estimate_priors.sample_intensity_stats_from_image": [[76, 131], ["numpy.array", "numpy.unique", "len", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.stack", "ext.lab2im.utils.reformat_to_list", "numpy.array", "numpy.arange", "len", "len", "numpy.array_equal", "ValueError", "numpy.empty", "ext.lab2im.utils.reformat_to_list", "numpy.arange", "numpy.concatenate", "len", "numpy.nanmedian", "scipy.stats.median_absolute_deviation"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], ["", "def", "sample_intensity_stats_from_image", "(", "image", ",", "segmentation", ",", "labels_list", ",", "classes_list", "=", "None", ",", "keep_strictly_positive", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function takes an image and corresponding segmentation as inputs. It estimates the mean and std intensity\n    for all specified label values. Labels can share the same statistics by being regrouped into K classes.\n    :param image: image from which to evaluate mean intensity and std deviation.\n    :param segmentation: segmentation of the input image. Must have the same size as image.\n    :param labels_list: list of labels for which to evaluate mean and std intensity.\n    Can be a sequence, a 1d numpy array, or the path to a 1d numpy array.\n    :param classes_list: (optional) enables to regroup structures into classes of similar intensity statistics.\n    Intenstites associated to regrouped labels will thus contribute to the same Gaussian during statistics estimation.\n    Can be a sequence, a 1d numpy array, or the path to a 1d numpy array.\n    It should have the same length as labels_list, and contain values between 0 and K-1, where K is the total number of\n    classes. Default is all labels have different classes (K=len(labels_list)).\n    :param keep_strictly_positive: (optional) whether to only keep strictly positive intensity values when\n    computing stats. This doesn't apply to the first label in label_list (or class if class_list is provided), for\n    which we keep positive and zero values, as we consider it to be the background label.\n    :return: a numpy array of size (2, K), the first row being the mean intensity for each structure,\n    and the second being the median absolute deviation (robust estimation of std).\n    \"\"\"", "\n", "\n", "# reformat labels and classes", "\n", "labels_list", "=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "labels_list", ",", "load_as_numpy", "=", "True", ",", "dtype", "=", "'int'", ")", ")", "\n", "if", "classes_list", "is", "not", "None", ":", "\n", "        ", "classes_list", "=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "classes_list", ",", "load_as_numpy", "=", "True", ",", "dtype", "=", "'int'", ")", ")", "\n", "", "else", ":", "\n", "        ", "classes_list", "=", "np", ".", "arange", "(", "labels_list", ".", "shape", "[", "0", "]", ")", "\n", "", "assert", "len", "(", "classes_list", ")", "==", "len", "(", "labels_list", ")", ",", "'labels and classes lists should have the same length'", "\n", "\n", "# get unique classes", "\n", "unique_classes", ",", "unique_indices", "=", "np", ".", "unique", "(", "classes_list", ",", "return_index", "=", "True", ")", "\n", "n_classes", "=", "len", "(", "unique_classes", ")", "\n", "if", "not", "np", ".", "array_equal", "(", "unique_classes", ",", "np", ".", "arange", "(", "n_classes", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'classes_list should only contain values between 0 and K-1, '", "\n", "'where K is the total number of classes. Here K = %d'", "%", "n_classes", ")", "\n", "\n", "# compute mean/std of specified classes", "\n", "", "means", "=", "np", ".", "zeros", "(", "n_classes", ")", "\n", "stds", "=", "np", ".", "zeros", "(", "n_classes", ")", "\n", "for", "idx", ",", "tmp_class", "in", "enumerate", "(", "unique_classes", ")", ":", "\n", "\n", "# get list of all intensity values for the current class", "\n", "        ", "class_labels", "=", "labels_list", "[", "classes_list", "==", "tmp_class", "]", "\n", "intensities", "=", "np", ".", "empty", "(", "0", ")", "\n", "for", "label", "in", "class_labels", ":", "\n", "            ", "tmp_intensities", "=", "image", "[", "segmentation", "==", "label", "]", "\n", "intensities", "=", "np", ".", "concatenate", "(", "[", "intensities", ",", "tmp_intensities", "]", ")", "\n", "", "if", "tmp_class", ":", "# i.e. if not background", "\n", "            ", "if", "keep_strictly_positive", ":", "\n", "                ", "intensities", "=", "intensities", "[", "intensities", ">", "0", "]", "\n", "\n", "# compute stats for class and put them to the location of corresponding label values", "\n", "", "", "if", "len", "(", "intensities", ")", "!=", "0", ":", "\n", "            ", "means", "[", "idx", "]", "=", "np", ".", "nanmedian", "(", "intensities", ")", "\n", "stds", "[", "idx", "]", "=", "median_absolute_deviation", "(", "intensities", ",", "nan_policy", "=", "'omit'", ")", "\n", "\n", "", "", "return", "np", ".", "stack", "(", "[", "means", ",", "stds", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.estimate_priors.sample_intensity_stats_from_single_dataset": [[133, 222], ["ext.lab2im.utils.list_images_in_folder", "ext.lab2im.utils.list_images_in_folder", "numpy.array", "numpy.unique", "len", "ext.lab2im.utils.get_dims", "numpy.zeros", "numpy.zeros", "ext.lab2im.utils.LoopInfo", "enumerate", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.zeros", "numpy.zeros", "range", "len", "len", "ext.lab2im.utils.reformat_to_list", "numpy.array", "numpy.arange", "len", "len", "numpy.array_equal", "ValueError", "len", "zip", "utils.LoopInfo.update", "ext.lab2im.utils.load_volume", "ext.lab2im.utils.load_volume", "range", "ext.lab2im.utils.reformat_to_list", "numpy.arange", "ext.lab2im.utils.load_volume", "len", "len", "ext.lab2im.utils.add_axis", "estimate_priors.sample_intensity_stats_from_image", "ext.lab2im.edit_volumes.rescale_volume"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.estimate_priors.sample_intensity_stats_from_image", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.rescale_volume"], ["", "def", "sample_intensity_stats_from_single_dataset", "(", "image_dir", ",", "labels_dir", ",", "labels_list", ",", "classes_list", "=", "None", ",", "max_channel", "=", "3", ",", "\n", "rescale", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function aims at estimating the intensity distributions of K different structure types from a set of images.\n    The distribution of each structure type is modelled as a Gaussian, parametrised by a mean and a standard deviation.\n    Because the intensity distribution of structures can vary accross images, we additionally use Gausian priors for the\n    parameters of each Gaussian distribution. Therefore, the intensity distribution of each structure type is described\n    by 4 parameters: a mean/std for the mean intensity, and a mean/std for the std deviation.\n    This function uses a set of images along with corresponding segmentations to estimate the 4*K parameters.\n    Structures can share the same statistics by being regrouped into classes of similar structure types.\n    Images can be multi-modal (n_channels), in which case different statistics are estimated for each modality.\n    :param image_dir: path of directory with images to estimate the intensity distribution\n    :param labels_dir: path of directory with segmentation of input images.\n    They are matched with images by sorting order.\n    :param labels_list: list of labels for which to evaluate mean and std intensity.\n    Can be a sequence, a 1d numpy array, or the path to a 1d numpy array.\n    :param classes_list: (optional) enables to regroup structures into classes of similar intensity statistics.\n    Intenstites associated to regrouped labels will thus contribute to the same Gaussian during statistics estimation.\n    Can be a sequence, a 1d numpy array, or the path to a 1d numpy array.\n    It should have the same length as labels_list, and contain values between 0 and K-1, where K is the total number of\n    classes. Default is all labels have different classes (K=len(labels_list)).\n    :param max_channel: (optional) maximum number of channels to consider if the data is multispectral. Default is 3.\n    :param rescale: (optional) whether to rescale images between 0 and 255 before intensity estimation\n    :return: 2 numpy arrays of size (2*n_channels, K), one with the evaluated means/std for the mean\n    intensity, and one for the mean/std for the standard deviation.\n    Each block of two rows correspond to a different modality (channel). For each block of two rows, the first row\n    represents the mean, and the second represents the std.\n    \"\"\"", "\n", "\n", "# list files", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "assert", "len", "(", "path_images", ")", "==", "len", "(", "path_labels", ")", ",", "'image and labels folders do not have the same number of files'", "\n", "\n", "# reformat list labels and classes", "\n", "labels_list", "=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "labels_list", ",", "load_as_numpy", "=", "True", ",", "dtype", "=", "'int'", ")", ")", "\n", "if", "classes_list", "is", "not", "None", ":", "\n", "        ", "classes_list", "=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "classes_list", ",", "load_as_numpy", "=", "True", ",", "dtype", "=", "'int'", ")", ")", "\n", "", "else", ":", "\n", "        ", "classes_list", "=", "np", ".", "arange", "(", "labels_list", ".", "shape", "[", "0", "]", ")", "\n", "", "assert", "len", "(", "classes_list", ")", "==", "len", "(", "labels_list", ")", ",", "'labels and classes lists should have the same length'", "\n", "\n", "# get unique classes", "\n", "unique_classes", ",", "unique_indices", "=", "np", ".", "unique", "(", "classes_list", ",", "return_index", "=", "True", ")", "\n", "n_classes", "=", "len", "(", "unique_classes", ")", "\n", "if", "not", "np", ".", "array_equal", "(", "unique_classes", ",", "np", ".", "arange", "(", "n_classes", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'classes_list should only contain values between 0 and K-1, '", "\n", "'where K is the total number of classes. Here K = %d'", "%", "n_classes", ")", "\n", "\n", "# initialise result arrays", "\n", "", "n_dims", ",", "n_channels", "=", "utils", ".", "get_dims", "(", "utils", ".", "load_volume", "(", "path_images", "[", "0", "]", ")", ".", "shape", ",", "max_channels", "=", "max_channel", ")", "\n", "means", "=", "np", ".", "zeros", "(", "(", "len", "(", "path_images", ")", ",", "n_classes", ",", "n_channels", ")", ")", "\n", "stds", "=", "np", ".", "zeros", "(", "(", "len", "(", "path_images", ")", ",", "n_classes", ",", "n_channels", ")", ")", "\n", "\n", "# loop over images", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'estimating'", ",", "print_time", "=", "True", ")", "\n", "for", "idx", ",", "(", "path_im", ",", "path_la", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_labels", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# load image and label map", "\n", "image", "=", "utils", ".", "load_volume", "(", "path_im", ")", "\n", "la", "=", "utils", ".", "load_volume", "(", "path_la", ")", "\n", "if", "n_channels", "==", "1", ":", "\n", "            ", "image", "=", "utils", ".", "add_axis", "(", "image", ",", "-", "1", ")", "\n", "\n", "# loop over channels", "\n", "", "for", "channel", "in", "range", "(", "n_channels", ")", ":", "\n", "            ", "im", "=", "image", "[", "...", ",", "channel", "]", "\n", "if", "rescale", ":", "\n", "                ", "im", "=", "edit_volumes", ".", "rescale_volume", "(", "im", ")", "\n", "", "stats", "=", "sample_intensity_stats_from_image", "(", "im", ",", "la", ",", "labels_list", ",", "classes_list", "=", "classes_list", ")", "\n", "means", "[", "idx", ",", ":", ",", "channel", "]", "=", "stats", "[", "0", ",", ":", "]", "\n", "stds", "[", "idx", ",", ":", ",", "channel", "]", "=", "stats", "[", "1", ",", ":", "]", "\n", "\n", "# compute prior parameters for mean/std", "\n", "", "", "mean_means", "=", "np", ".", "mean", "(", "means", ",", "axis", "=", "0", ")", "\n", "std_means", "=", "np", ".", "std", "(", "means", ",", "axis", "=", "0", ")", "\n", "mean_stds", "=", "np", ".", "mean", "(", "stds", ",", "axis", "=", "0", ")", "\n", "std_stds", "=", "np", ".", "std", "(", "stds", ",", "axis", "=", "0", ")", "\n", "\n", "# regroup prior parameters in two different arrays: one for the mean and one for the std", "\n", "prior_means", "=", "np", ".", "zeros", "(", "(", "2", "*", "n_channels", ",", "n_classes", ")", ")", "\n", "prior_stds", "=", "np", ".", "zeros", "(", "(", "2", "*", "n_channels", ",", "n_classes", ")", ")", "\n", "for", "channel", "in", "range", "(", "n_channels", ")", ":", "\n", "        ", "prior_means", "[", "2", "*", "channel", ",", ":", "]", "=", "mean_means", "[", ":", ",", "channel", "]", "\n", "prior_means", "[", "2", "*", "channel", "+", "1", ",", ":", "]", "=", "std_means", "[", ":", ",", "channel", "]", "\n", "prior_stds", "[", "2", "*", "channel", ",", ":", "]", "=", "mean_stds", "[", ":", ",", "channel", "]", "\n", "prior_stds", "[", "2", "*", "channel", "+", "1", ",", ":", "]", "=", "std_stds", "[", ":", ",", "channel", "]", "\n", "\n", "", "return", "prior_means", ",", "prior_stds", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.estimate_priors.build_intensity_stats": [[224, 311], ["ext.lab2im.utils.mkdir", "ext.lab2im.utils.reformat_to_list", "ext.lab2im.utils.reformat_to_list", "numpy.array", "numpy.unique", "len", "list", "list", "zip", "numpy.concatenate", "numpy.concatenate", "numpy.save", "numpy.save", "ext.lab2im.utils.reformat_to_list", "numpy.array", "numpy.arange", "len", "len", "numpy.array_equal", "ValueError", "estimate_priors.sample_intensity_stats_from_single_dataset", "list.append", "list.append", "os.path.join", "os.path.join", "len", "ext.lab2im.utils.reformat_to_list", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.estimate_priors.sample_intensity_stats_from_single_dataset", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], ["", "def", "build_intensity_stats", "(", "list_image_dir", ",", "\n", "list_labels_dir", ",", "\n", "result_dir", ",", "\n", "estimation_labels", ",", "\n", "estimation_classes", "=", "None", ",", "\n", "max_channel", "=", "3", ",", "\n", "rescale", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function aims at estimating the intensity distributions of K different structure types from a set of images.\n    The distribution of each structure type is modelled as a Gaussian, parametrised by a mean and a standard deviation.\n    Because the intensity distribution of structures can vary accross images, we additionally use Gausian priors for the\n    parameters of each Gaussian distribution. Therefore, the intensity distribution of each structure type is described\n    by 4 parameters: a mean/std for the mean intensity, and a mean/std for the std deviation.\n    This function uses a set of images along with corresponding segmentations to estimate the 4*K parameters.\n    Additionally, it can estimate the 4*K parameters for several image datasets, that we call here n_datasets.\n    This function writes 2 numpy arrays of size (2*n_datasets, K), one with the evaluated means/std for the mean\n    intensities, and one for the mean/std for the standard deviations.\n    In these arrays, each block of two rows refer to a different dataset.\n    Within each block of two rows, the first row represents the mean, and the second represents the std.\n    SEE SCRIPTS/TUTORIALS/8-ESTIMATE_PRIORS.PY FOR EXAMPLES OF HOW TO USE THIS FUNCTION\n    :param list_image_dir: path of folders with images for intensity distribution estimation.\n    Can be the path of single directory (n_datasets=1), or a list of folders, each being a separate dataset.\n    Images can be multimodal, in which case each modality is treated as a different dataset, i.e. each modality will\n    have a separate block (of size (2, K)) in the result arrays.\n    :param list_labels_dir: path of folders with label maps corresponding to input images.\n    If list_image_dir is a list of several folders, list_labels_dir can either be a list of folders (one for each image\n    folder), or the path to a single folder, which will be used for all datasets.\n    If a dataset has multi-modal images, the same label map is applied to all modalities.\n    :param result_dir: path of directory where estimated priors will be writen.\n    :param estimation_labels: labels to estimate intensity statistics from.\n    Can be a sequence, a 1d numpy array, or the path to a 1d numpy array.\n    :param estimation_classes: (optional) enables to regroup structures into classes of similar intensity statistics.\n    Intenstites associated to regrouped labels will thus contribute to the same Gaussian during statistics estimation.\n    Can be a sequence, a 1d numpy array, or the path to a 1d numpy array.\n    It should have the same length as labels_list, and contain values between 0 and K-1, where K is the total number of\n    classes. Default is all labels have different classes (K=len(estimation_labels)).\n    :param max_channel: (optional) maximum number of channels to consider if the data is multispectral. Default is 3.\n    :param rescale: (optional) whether to rescale images between 0 and 255 before intensity estimation\n    \"\"\"", "\n", "\n", "# handle results directories", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# reformat image/labels dir into lists", "\n", "list_image_dir", "=", "utils", ".", "reformat_to_list", "(", "list_image_dir", ")", "\n", "list_labels_dir", "=", "utils", ".", "reformat_to_list", "(", "list_labels_dir", ",", "length", "=", "len", "(", "list_image_dir", ")", ")", "\n", "\n", "# reformat list estimation labels and classes", "\n", "estimation_labels", "=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "estimation_labels", ",", "load_as_numpy", "=", "True", ",", "dtype", "=", "'int'", ")", ")", "\n", "if", "estimation_classes", "is", "not", "None", ":", "\n", "        ", "estimation_classes", "=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "estimation_classes", ",", "load_as_numpy", "=", "True", ",", "dtype", "=", "'int'", ")", ")", "\n", "", "else", ":", "\n", "        ", "estimation_classes", "=", "np", ".", "arange", "(", "estimation_labels", ".", "shape", "[", "0", "]", ")", "\n", "", "assert", "len", "(", "estimation_classes", ")", "==", "len", "(", "estimation_labels", ")", ",", "'estimation labels and classes should be of same length'", "\n", "\n", "# get unique classes", "\n", "unique_estimation_classes", ",", "unique_indices", "=", "np", ".", "unique", "(", "estimation_classes", ",", "return_index", "=", "True", ")", "\n", "n_classes", "=", "len", "(", "unique_estimation_classes", ")", "\n", "if", "not", "np", ".", "array_equal", "(", "unique_estimation_classes", ",", "np", ".", "arange", "(", "n_classes", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'estimation_classes should only contain values between 0 and N-1, '", "\n", "'where K is the total number of classes. Here N = %d'", "%", "n_classes", ")", "\n", "\n", "# loop over dataset", "\n", "", "list_datasets_prior_means", "=", "list", "(", ")", "\n", "list_datasets_prior_stds", "=", "list", "(", ")", "\n", "for", "image_dir", ",", "labels_dir", "in", "zip", "(", "list_image_dir", ",", "list_labels_dir", ")", ":", "\n", "\n", "# get prior stats for dataset", "\n", "        ", "tmp_prior_means", ",", "tmp_prior_stds", "=", "sample_intensity_stats_from_single_dataset", "(", "image_dir", ",", "\n", "labels_dir", ",", "\n", "estimation_labels", ",", "\n", "estimation_classes", ",", "\n", "max_channel", "=", "max_channel", ",", "\n", "rescale", "=", "rescale", ")", "\n", "\n", "# add stats arrays to list of datasets-wise statistics", "\n", "list_datasets_prior_means", ".", "append", "(", "tmp_prior_means", ")", "\n", "list_datasets_prior_stds", ".", "append", "(", "tmp_prior_stds", ")", "\n", "\n", "# stack all modalities together", "\n", "", "prior_means", "=", "np", ".", "concatenate", "(", "list_datasets_prior_means", ",", "axis", "=", "0", ")", "\n", "prior_stds", "=", "np", ".", "concatenate", "(", "list_datasets_prior_stds", ",", "axis", "=", "0", ")", "\n", "\n", "# save files", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "result_dir", ",", "'prior_means.npy'", ")", ",", "prior_means", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "result_dir", ",", "'prior_stds.npy'", ")", ",", "prior_stds", ")", "\n", "\n", "return", "prior_means", ",", "prior_stds", "\n", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.metrics_model.IdentityLoss.__init__": [[220, 222], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "keepdims", "=", "True", ")", ":", "\n", "        ", "self", ".", "keepdims", "=", "keepdims", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.metrics_model.IdentityLoss.loss": [[223, 230], ["tensorflow.debugging.check_numerics"], "methods", ["None"], ["", "def", "loss", "(", "self", ",", "y_true", ",", "y_predicted", ")", ":", "\n", "        ", "\"\"\"Because the metrics is already calculated in the model, we simply return y_predicted.\n           We still need to put y_true in the inputs, as it's expected by keras.\"\"\"", "\n", "loss", "=", "y_predicted", "\n", "\n", "tf", ".", "debugging", ".", "check_numerics", "(", "loss", ",", "'Loss not finite'", ")", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.metrics_model.metrics_model": [[29, 133], ["keras.models.Model", "int", "list", "list", "range", "list", "input_model.get_layer", "keras.Lambda", "ext.lab2im.utils.get_dims", "ext.lab2im.utils.reformat_to_list", "list.append", "list.append", "keras.Lambda", "list.append", "len", "keras.Add", "image_gt.get_shape().as_list", "int", "keras.Lambda", "keras.Lambda", "keras.Subtract", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.Lambda", "input_model.get_layer", "keras.Lambda", "keras.Lambda", "range", "keras.Lambda", "keras.Subtract", "keras.Lambda", "image_gt.get_shape", "tensorflow.slice", "tensorflow.slice", "keras.mean", "keras.Subtract", "keras.Lambda", "Exception", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.slice", "keras.mean", "Exception", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.Lambda", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.exp", "tensorflow.math.log", "keras.square", "keras.mean", "image_gt.get_shape", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "keras.abs", "keras.abs", "tensorflow.image.ssim", "tensorflow.image.ssim", "tensorflow.image.ssim", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice"], ["def", "metrics_model", "(", "input_model", ",", "loss_cropping", "=", "16", ",", "metrics", "=", "'l1'", ",", "work_with_residual_channel", "=", "None", ")", ":", "\n", "\n", "# If probabilistic, split predictions of intensities and spreads", "\n", "    ", "if", "metrics", "==", "'laplace'", ":", "\n", "        ", "n_channels", "=", "int", "(", "input_model", ".", "outputs", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "/", "2", ")", "\n", "intensities_list", "=", "list", "(", ")", "\n", "spreads_list", "=", "list", "(", ")", "\n", "tensor", "=", "input_model", ".", "outputs", "[", "0", "]", "\n", "for", "c", "in", "range", "(", "n_channels", ")", ":", "\n", "            ", "tmp_intensities", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "expand_dims", "(", "x", "[", "...", ",", "c", "]", ",", "axis", "=", "-", "1", ")", ")", "(", "tensor", ")", "\n", "intensities_list", ".", "append", "(", "tmp_intensities", ")", "\n", "tmp_spreads", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "expand_dims", "(", "x", "[", "...", ",", "c", "+", "n_channels", "]", ",", "axis", "=", "-", "1", ")", ")", "(", "tensor", ")", "\n", "spreads_list", ".", "append", "(", "tmp_spreads", ")", "\n", "", "if", "n_channels", ">", "1", ":", "\n", "            ", "intensities_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "concat", "(", "x", ",", "axis", "=", "-", "1", ")", ")", "(", "intensities_list", ")", "\n", "spreads_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "concat", "(", "x", ",", "axis", "=", "-", "1", ")", ")", "(", "spreads_list", ")", "\n", "", "else", ":", "\n", "            ", "intensities_tensor", "=", "intensities_list", "[", "0", "]", "\n", "spreads_tensor", "=", "spreads_list", "[", "0", "]", "\n", "", "", "else", ":", "\n", "        ", "intensities_tensor", "=", "input_model", ".", "outputs", "[", "0", "]", "\n", "spreads_tensor", "=", "None", "\n", "\n", "# add residual if needed", "\n", "", "if", "work_with_residual_channel", "is", "None", ":", "\n", "        ", "intensities_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", ",", "name", "=", "'predicted_image'", ")", "(", "intensities_tensor", ")", "\n", "", "else", ":", "\n", "        ", "slice_list", "=", "list", "(", ")", "\n", "for", "c", "in", "work_with_residual_channel", ":", "\n", "            ", "tensor", "=", "input_model", ".", "get_layer", "(", "'image_out'", ")", ".", "output", "\n", "tmp_slice", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "expand_dims", "(", "x", "[", "...", ",", "c", "]", ",", "axis", "=", "-", "1", ")", ")", "(", "tensor", ")", "\n", "slice_list", ".", "append", "(", "tmp_slice", ")", "\n", "", "if", "len", "(", "slice_list", ")", ">", "1", ":", "\n", "            ", "slices", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "concat", "(", "x", ",", "axis", "=", "-", "1", ")", ")", "(", "slice_list", ")", "\n", "", "else", ":", "\n", "            ", "slices", "=", "slice_list", "[", "0", "]", "\n", "", "intensities_tensor", "=", "KL", ".", "Add", "(", "name", "=", "'predicted_image'", ")", "(", "[", "slices", ",", "intensities_tensor", "]", ")", "\n", "\n", "# get crisp, ground truth image", "\n", "", "image_gt", "=", "input_model", ".", "get_layer", "(", "'regression_target'", ")", ".", "output", "\n", "image_gt", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", ",", "name", "=", "'target'", ")", "(", "image_gt", ")", "\n", "\n", "# crop output to evaluate loss function in centre patch", "\n", "if", "loss_cropping", "is", "not", "None", ":", "\n", "# format loss_cropping", "\n", "        ", "target_shape", "=", "image_gt", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "-", "1", "]", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "target_shape", ")", "\n", "loss_cropping", "=", "utils", ".", "reformat_to_list", "(", "loss_cropping", ",", "length", "=", "n_dims", ")", "\n", "\n", "# perform cropping", "\n", "begin_idx", "=", "[", "int", "(", "(", "target_shape", "[", "i", "]", "-", "loss_cropping", "[", "i", "]", ")", "/", "2", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "image_gt", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "slice", "(", "x", ",", "begin", "=", "tf", ".", "convert_to_tensor", "(", "[", "0", "]", "+", "begin_idx", "+", "[", "0", "]", ",", "dtype", "=", "'int32'", ")", ",", "\n", "size", "=", "tf", ".", "convert_to_tensor", "(", "[", "-", "1", "]", "+", "loss_cropping", "+", "[", "-", "1", "]", ",", "dtype", "=", "'int32'", ")", ")", ",", "\n", "name", "=", "'cropping_gt'", ")", "(", "image_gt", ")", "\n", "intensities_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "\n", "tf", ".", "slice", "(", "x", ",", "begin", "=", "tf", ".", "convert_to_tensor", "(", "[", "0", "]", "+", "begin_idx", "+", "[", "0", "]", ",", "dtype", "=", "'int32'", ")", ",", "\n", "size", "=", "tf", ".", "convert_to_tensor", "(", "[", "-", "1", "]", "+", "loss_cropping", "+", "[", "-", "1", "]", ",", "dtype", "=", "'int32'", ")", ")", ",", "\n", "name", "=", "'cropping_pred'", ")", "(", "intensities_tensor", ")", "\n", "if", "metrics", "==", "'laplace'", ":", "\n", "            ", "spreads_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "\n", "tf", ".", "slice", "(", "x", ",", "begin", "=", "tf", ".", "convert_to_tensor", "(", "[", "0", "]", "+", "begin_idx", "+", "[", "0", "]", ",", "dtype", "=", "'int32'", ")", ",", "\n", "size", "=", "tf", ".", "convert_to_tensor", "(", "[", "-", "1", "]", "+", "loss_cropping", "+", "[", "-", "1", "]", ",", "dtype", "=", "'int32'", ")", ")", ",", "\n", "name", "=", "'cropping_pred_spread'", ")", "(", "spreads_tensor", ")", "\n", "\n", "# metrics is computed as part of the model", "\n", "", "", "if", "metrics", "==", "'laplace'", ":", "\n", "        ", "err_tensor", "=", "KL", ".", "Subtract", "(", ")", "(", "[", "intensities_tensor", ",", "image_gt", "]", ")", "\n", "b_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "1e-5", "+", "0.02", "*", "tf", ".", "exp", "(", "x", ")", ",", "name", "=", "'predicted_bs'", ")", "(", "spreads_tensor", ")", "\n", "loss_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "mean", "(", "tf", ".", "math", ".", "log", "(", "2", "*", "x", "[", "0", "]", ")", "+", "(", "K", ".", "abs", "(", "x", "[", "1", "]", ")", "/", "x", "[", "0", "]", ")", ")", ",", "\n", "name", "=", "'laplace_loss'", ")", "(", "[", "b_tensor", ",", "err_tensor", "]", ")", "\n", "", "elif", "metrics", "==", "'l2'", ":", "\n", "        ", "err_tensor", "=", "KL", ".", "Subtract", "(", ")", "(", "[", "intensities_tensor", ",", "image_gt", "]", ")", "\n", "loss_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "mean", "(", "K", ".", "square", "(", "x", ")", ")", ",", "name", "=", "'L2_loss'", ")", "(", "err_tensor", ")", "\n", "", "elif", "metrics", "==", "'l1'", ":", "\n", "        ", "err_tensor", "=", "KL", ".", "Subtract", "(", ")", "(", "[", "intensities_tensor", ",", "image_gt", "]", ")", "\n", "loss_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "mean", "(", "K", ".", "abs", "(", "x", ")", ")", ",", "name", "=", "'L1_loss'", ")", "(", "err_tensor", ")", "\n", "", "elif", "metrics", "==", "'ssim'", ":", "\n", "\n", "# TODO: true 3D", "\n", "\n", "# TODO: multiple output channels", "\n", "        ", "if", "image_gt", ".", "get_shape", "(", ")", "[", "-", "1", "]", ">", "1", ":", "\n", "            ", "raise", "Exception", "(", "'SSIM metric does not currently support multiple channels'", ")", "\n", "\n", "", "ssim_xy", "=", "KL", ".", "Lambda", "(", "\n", "lambda", "x", ":", "tf", ".", "image", ".", "ssim", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ",", "\n", "1.0", ")", ",", "name", "=", "'ssim_xy'", ")", "(", "[", "intensities_tensor", ",", "image_gt", "]", ")", "\n", "ssim_xz", "=", "KL", ".", "Lambda", "(", "\n", "lambda", "x", ":", "tf", ".", "image", ".", "ssim", "(", "tf", ".", "transpose", "(", "x", "[", "0", "]", ",", "perm", "=", "[", "0", ",", "1", ",", "3", ",", "2", ",", "4", "]", ")", ",", "tf", ".", "transpose", "(", "x", "[", "1", "]", ",", "perm", "=", "[", "0", ",", "1", ",", "3", ",", "2", ",", "4", "]", ")", ",", "\n", "1.0", ")", ",", "name", "=", "'ssim_xz'", ")", "(", "[", "intensities_tensor", ",", "image_gt", "]", ")", "\n", "ssim_yz", "=", "KL", ".", "Lambda", "(", "\n", "lambda", "x", ":", "tf", ".", "image", ".", "ssim", "(", "tf", ".", "transpose", "(", "x", "[", "0", "]", ",", "perm", "=", "[", "0", ",", "2", ",", "3", ",", "1", ",", "4", "]", ")", ",", "tf", ".", "transpose", "(", "x", "[", "1", "]", ",", "perm", "=", "[", "0", ",", "2", ",", "3", ",", "1", ",", "4", "]", ")", ",", "\n", "1.0", ")", ",", "name", "=", "'ssim_yz'", ")", "(", "[", "intensities_tensor", ",", "image_gt", "]", ")", "\n", "\n", "loss_tensor", "=", "KL", ".", "Lambda", "(", "\n", "lambda", "x", ":", "-", "(", "1", "/", "3", ")", "*", "tf", ".", "reduce_mean", "(", "x", "[", "0", "]", ")", "-", "(", "1", "/", "3", ")", "*", "tf", ".", "reduce_mean", "(", "x", "[", "1", "]", ")", "-", "(", "1", "/", "3", ")", "*", "tf", ".", "reduce_mean", "(", "x", "[", "2", "]", ")", ",", "\n", "name", "=", "'ssim_loss'", ")", "(", "[", "ssim_xy", ",", "ssim_xz", ",", "ssim_yz", "]", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'metrics should either be \"l1\" or \"l2\" or \"ssim\" oro \"laplace\", got {}'", ".", "format", "(", "metrics", ")", ")", "\n", "\n", "# create the model and return", "\n", "", "model", "=", "Model", "(", "inputs", "=", "input_model", ".", "inputs", ",", "outputs", "=", "loss_tensor", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.metrics_model.add_seg_loss_to_model": [[136, 216], ["ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.load_array_if_path", "list", "list", "range", "keras.models.Model", "input_model.get_layer", "input_model.get_layer", "seg_model", "seg_model", "ext.lab2im.utils.get_dims", "ext.lab2im.utils.reformat_to_list", "len", "ext.lab2im.layers.DiceLoss", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.Lambda", "predicted_image.get_shape().as_list", "int", "keras.Lambda", "keras.Lambda", "numpy.where", "len", "list.append", "list.append", "len", "keras.Lambda", "len", "keras.Lambda", "range", "keras.Lambda", "len", "keras.reverse", "keras.permute_dimensions", "predicted_image.get_shape", "tensorflow.slice", "tensorflow.slice", "keras.Lambda", "len", "tensorflow.stack", "tensorflow.stack", "keras.permute_dimensions", "keras.reverse", "tensorflow.cast", "keras.Lambda", "len", "Exception", "keras.clip", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "keras.Lambda"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack"], ["", "def", "add_seg_loss_to_model", "(", "input_model", ",", "\n", "seg_model", ",", "\n", "generation_labels", ",", "\n", "segmentation_label_equivalency", ",", "\n", "rel_weight", ",", "\n", "loss_cropping", ",", "\n", "m", "=", "None", ",", "\n", "M", "=", "None", ",", "\n", "fs_header", "=", "False", ")", ":", "\n", "\n", "# get required layers from input models", "\n", "    ", "image_loss", "=", "input_model", ".", "outputs", "[", "0", "]", "\n", "predicted_image", "=", "input_model", ".", "get_layer", "(", "'predicted_image'", ")", ".", "output", "\n", "segm_target", "=", "input_model", ".", "get_layer", "(", "'segmentation_target'", ")", ".", "output", "\n", "\n", "# normalise/clip predicted image if needed", "\n", "if", "m", "is", "None", ":", "\n", "        ", "input_norm", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "+", ".0", ",", "name", "=", "'input_normalized'", ")", "(", "predicted_image", ")", "\n", "", "else", ":", "\n", "        ", "input_norm", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "(", "K", ".", "clip", "(", "x", ",", "m", ",", "M", ")", "-", "m", ")", "/", "(", "M", "-", "m", ")", ",", "name", "=", "'input_normalized'", ")", "(", "predicted_image", ")", "\n", "\n", "# Push predicted image through segmentation CNN", "\n", "", "if", "fs_header", ":", "\n", "        ", "input_normalized_rotated", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "reverse", "(", "K", ".", "permute_dimensions", "(", "x", ",", "[", "0", ",", "1", ",", "3", ",", "2", ",", "4", "]", ")", ",", "axes", "=", "2", ")", ",", "\n", "name", "=", "'input_normalized_rotated'", ")", "(", "input_norm", ")", "\n", "predicted_seg_rotated", "=", "seg_model", "(", "input_normalized_rotated", ")", "\n", "predicted_seg", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "permute_dimensions", "(", "K", ".", "reverse", "(", "x", ",", "axes", "=", "2", ")", ",", "\n", "[", "0", ",", "1", ",", "3", ",", "2", ",", "4", "]", ")", ")", "(", "predicted_seg_rotated", ")", "\n", "", "else", ":", "\n", "        ", "predicted_seg", "=", "seg_model", "(", "input_norm", ")", "\n", "\n", "# crop output to evaluate loss function in centre patch", "\n", "", "if", "loss_cropping", "is", "not", "None", ":", "\n", "# format loss_cropping", "\n", "        ", "target_shape", "=", "predicted_image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "-", "1", "]", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "target_shape", ")", "\n", "loss_cropping", "=", "utils", ".", "reformat_to_list", "(", "loss_cropping", ",", "length", "=", "n_dims", ")", "\n", "\n", "# perform cropping", "\n", "begin_idx", "=", "[", "int", "(", "(", "target_shape", "[", "i", "]", "-", "loss_cropping", "[", "i", "]", ")", "/", "2", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "segm_target", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "slice", "(", "x", ",", "\n", "begin", "=", "tf", ".", "convert_to_tensor", "(", "[", "0", "]", "+", "begin_idx", "+", "[", "0", "]", ",", "dtype", "=", "'int32'", ")", ",", "\n", "size", "=", "tf", ".", "convert_to_tensor", "(", "[", "-", "1", "]", "+", "loss_cropping", "+", "[", "-", "1", "]", ",", "\n", "dtype", "=", "'int32'", ")", ")", ")", "(", "segm_target", ")", "\n", "predicted_seg", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "slice", "(", "x", ",", "\n", "begin", "=", "tf", ".", "convert_to_tensor", "(", "[", "0", "]", "+", "begin_idx", "+", "[", "0", "]", ",", "dtype", "=", "'int32'", ")", ",", "\n", "size", "=", "tf", ".", "convert_to_tensor", "(", "[", "-", "1", "]", "+", "loss_cropping", "+", "[", "-", "1", "]", ",", "\n", "dtype", "=", "'int32'", ")", ")", ")", "(", "predicted_seg", ")", "\n", "\n", "# reformat gt to have the same label values as for the segmentations", "\n", "", "segmentation_label_equivalency", "=", "utils", ".", "load_array_if_path", "(", "segmentation_label_equivalency", ")", "\n", "generation_labels", "=", "utils", ".", "load_array_if_path", "(", "generation_labels", ")", "\n", "gt_onehot", "=", "list", "(", ")", "\n", "pred_onehot", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "generation_labels", ")", ")", ":", "\n", "        ", "idx", "=", "np", ".", "where", "(", "segmentation_label_equivalency", "==", "generation_labels", "[", "i", "]", ")", "[", "0", "]", "\n", "if", "len", "(", "idx", ")", ">", "0", ":", "\n", "            ", "tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "cast", "(", "x", "[", "...", ",", "-", "1", "]", "==", "i", ",", "dtype", "=", "'float32'", ")", ")", "(", "segm_target", ")", "\n", "gt_onehot", ".", "append", "(", "tensor", ")", "\n", "if", "len", "(", "idx", ")", "==", "1", ":", "\n", "                ", "tensor2", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "...", ",", "idx", "[", "0", "]", "]", ")", "(", "predicted_seg", ")", "\n", "", "elif", "len", "(", "idx", ")", "==", "2", ":", "\n", "                ", "tensor2", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "...", ",", "idx", "[", "0", "]", "]", "+", "x", "[", "...", ",", "idx", "[", "1", "]", "]", ")", "(", "predicted_seg", ")", "\n", "", "elif", "len", "(", "idx", ")", "==", "3", ":", "\n", "                ", "tensor2", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "...", ",", "idx", "[", "0", "]", "]", "+", "x", "[", "...", ",", "idx", "[", "1", "]", "]", "+", "x", "[", "...", ",", "idx", "[", "2", "]", "]", ")", "(", "predicted_seg", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"uuummm weird that you're merging so many labels...\"", ")", "\n", "", "pred_onehot", ".", "append", "(", "tensor2", ")", "\n", "", "", "gt", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "stack", "(", "x", ",", "-", "1", ")", ",", "name", "=", "'gt'", ")", "(", "gt_onehot", ")", "if", "len", "(", "gt_onehot", ")", ">", "1", "else", "gt_onehot", "[", "0", "]", "\n", "pred", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "stack", "(", "x", ",", "-", "1", ")", ",", "name", "=", "'pred'", ")", "(", "pred_onehot", ")", "if", "len", "(", "pred_onehot", ")", ">", "1", "else", "pred_onehot", "[", "0", "]", "\n", "\n", "# Dice loss: it's crucial to disable the checks, so we can use incomplete segmentations", "\n", "dice_loss", "=", "layers", ".", "DiceLoss", "(", "enable_checks", "=", "False", ",", "name", "=", "'dice_loss'", ")", "(", "[", "gt", ",", "pred", "]", ")", "\n", "\n", "total_loss", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "0", "]", "+", "rel_weight", "*", "x", "[", "1", "]", ")", "(", "[", "image_loss", ",", "dice_loss", "]", ")", "\n", "\n", "# create the model and return", "\n", "model", "=", "Model", "(", "inputs", "=", "input_model", ".", "inputs", ",", "outputs", "=", "total_loss", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.RandomWeightedAverage.__init__": [[606, 610], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "shape", "=", "None", "\n", "self", ".", "n_dims", "=", "None", "\n", "super", "(", "RandomWeightedAverage", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.RandomWeightedAverage.build": [[611, 616], ["tuple", "super().build", "len"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "shape", "=", "tuple", "(", "input_shape", "[", "0", "]", ")", "\n", "self", ".", "n_dims", "=", "len", "(", "self", ".", "shape", ")", "-", "2", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "RandomWeightedAverage", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.RandomWeightedAverage.call": [[617, 622], ["tensorflow.concat", "tensorflow.random.uniform", "tensorflow.split", "tensorflow.shape", "tensorflow.ones"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "batchsize", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", "\n", "sample_shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "[", "self", ".", "n_dims", "+", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", "\n", "weights", "=", "tf", ".", "random", ".", "uniform", "(", "sample_shape", ",", "maxval", "=", "1.", ")", "\n", "return", "(", "weights", "*", "inputs", "[", "0", "]", ")", "+", "(", "(", "1", "-", "weights", ")", "*", "inputs", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.RandomWeightedAverage.compute_output_shape": [[623, 625], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "self", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.Gradients.__init__": [[629, 632], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "shape", "=", "None", "\n", "super", "(", "Gradients", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.Gradients.build": [[633, 637], ["tuple", "super().build"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "shape", "=", "tuple", "(", "input_shape", "[", "1", "]", ")", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "Gradients", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.Gradients.call": [[638, 640], ["keras.gradients", "keras.gradients"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "K", ".", "gradients", "(", "inputs", "[", "0", "]", ",", "inputs", "[", "1", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.Gradients.compute_output_shape": [[641, 643], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "self", ".", "shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.training": [[37, 480], ["len", "ext.lab2im.utils.get_list_labels", "ext.lab2im.utils.mkdir", "os.path.join", "ext.lab2im.utils.mkdir", "brain_generator.BrainGenerator", "ext.lab2im.utils.build_training_generator", "ext.neuron.models.unet", "fine_tuning_with_adversary.make_discriminator", "fine_tuning_with_adversary.build_generator_loss", "keras.models.Model", "models.Model.compile", "fine_tuning_with_adversary.build_discriminator_loss", "keras.models.Model", "models.Model.compile", "len", "numpy.array", "numpy.array", "range", "ext.lab2im.utils.reformat_to_list", "list", "len", "Exception", "any", "ext.lab2im.utils.reformat_to_list", "any", "print", "nrn_models.unet.load_weights", "numpy.load", "ext.neuron.models.unet", "nrn_models.unet.load_weights", "ext.lab2im.utils.load_array_if_path", "make_discriminator.", "make_discriminator.", "ext.lab2im.utils.load_volume", "numpy.percentile", "numpy.percentile", "nrn_models.unet.", "nrn_models.unet.get_layer", "nrn_models.unet.get_layer", "fine_tuning_with_adversary.RandomWeightedAverage", "make_discriminator.", "make_discriminator.", "make_discriminator.", "make_discriminator.", "make_discriminator.", "make_discriminator.", "str", "print", "range", "print", "print", "numpy.append", "numpy.append", "numpy.save", "numpy.save", "print", "models.Model.save", "models.Model.save", "ext.lab2im.utils.reformat_to_list", "Exception", "Exception", "Exception", "ext.lab2im.utils.get_padding_margin", "nrn_models.unet.get_layer", "ext.lab2im.layers.ConvertLabels", "keras.Lambda", "nrn_models.unet.get_layer", "keras.optimizers.Adam", "nrn_models.unet.get_layer", "ext.lab2im.layers.ConvertLabels", "keras.optimizers.Adam", "int", "len", "range", "next", "models.Model.train_on_batch", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "len", "Exception", "len", "ext.lab2im.utils.list_images_in_folder", "str", "next", "models.Model.train_on_batch", "print", "len", "len", "str", "keras.clip", "str"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_list_labels", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.build_training_generator", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.unet", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.make_discriminator", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.build_generator_loss", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.build_discriminator_loss", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.unet", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_padding_margin", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder"], ["def", "training", "(", "labels_dir", ",", "\n", "images_dir", ",", "\n", "model_dir", ",", "\n", "prior_means", ",", "\n", "prior_stds", ",", "\n", "path_generation_labels", ",", "\n", "path_segmentation_equivalency", "=", "None", ",", "\n", "segmentation_model_file", "=", "None", ",", "\n", "prior_distributions", "=", "'normal'", ",", "\n", "path_generation_classes", "=", "None", ",", "\n", "FS_sort", "=", "True", ",", "\n", "batchsize", "=", "1", ",", "\n", "input_channels", "=", "True", ",", "\n", "output_channel", "=", "None", ",", "\n", "target_res", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "flipping", "=", "True", ",", "\n", "padding_margin", "=", "None", ",", "\n", "scaling_bounds", "=", "0.2", ",", "\n", "rotation_bounds", "=", "20", ",", "\n", "shearing_bounds", "=", "0.03", ",", "\n", "translation_bounds", "=", "5", ",", "\n", "nonlin_std", "=", "5.", ",", "\n", "nonlin_shape_factor", "=", "0.04", ",", "\n", "simulate_registration_error", "=", "False", ",", "\n", "data_res", "=", "None", ",", "\n", "thickness", "=", "None", ",", "\n", "randomise_res", "=", "True", ",", "\n", "downsample", "=", "True", ",", "\n", "blur_range", "=", "1.03", ",", "\n", "build_reliability_maps", "=", "False", ",", "\n", "bias_field_std", "=", ".4", ",", "\n", "bias_shape_factor", "=", "0.04", ",", "\n", "n_levels", "=", "5", ",", "\n", "nb_conv_per_level", "=", "2", ",", "\n", "conv_size", "=", "3", ",", "\n", "unet_feat_count", "=", "24", ",", "\n", "feat_multiplier", "=", "2", ",", "\n", "dropout", "=", "0", ",", "\n", "activation", "=", "'elu'", ",", "\n", "lr_decay", "=", "0", ",", "\n", "epochs", "=", "100", ",", "\n", "steps_per_epoch", "=", "1000", ",", "\n", "work_with_residual_channel", "=", "None", ",", "\n", "loss_cropping", "=", "None", ",", "\n", "lr_generator", "=", "1e-4", ",", "\n", "lr_discriminator", "=", "1e-4", ",", "\n", "relative_weight_segmentation", "=", "0.25", ",", "\n", "relative_weight_discriminator", "=", "0.01", ",", "\n", "checkpoint_generator", "=", "None", ",", "\n", "gradient_penalty_weight", "=", "10", ",", "\n", "first_training_ratio", "=", "100", ",", "\n", "training_ratio", "=", "10", ",", "\n", "labels_to_mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This function trains a Unet to do slice imputation (and possibly synthesis) of MRI images with thick slices,\n    using synthetic scans and possibly real scans.\n\n    :param labels_dir: path of folder with all input label maps, or to a single label map (if only one training example)\n    :param model_dir: path of a directory where the models will be saved during training.\n    :param images_dir: directory with real images corresponding to the training label maps. These will be taken as\n    regression target. We recommend skull stripping them.\n\n    #---------------------------------------------- Generation parameters ----------------------------------------------\n    # label maps parameters\n    :param path_generation_labels: list of all possible label values in the input label maps.\n    Must be the path to a 1d numpy array, which should be organised as follows: background label first, then non-sided\n    labels (e.g. CSF, brainstem, etc.), then all the structures of the same hemisphere (can be left or right), and\n    finally all the corresponding contralateral structures (in the same order).\n    Example: [background_label, non-sided_1, ..., non-sided_n, left_1, ..., left_m, right_1, ..., right_m]\n    :param FS_sort: whether us FS_sort when creating list of labels with utils.get_list_labels. Default is True.\n\n    # output-related parameters\n    :param batchsize: (optional) number of images to generate per mini-batch. Default is 1.\n    :param input_channels: (optional) list of booleans indicating if each *synthetic* channel is going to be used as an\n    input for the downstream network. This also enables to know how many channels are going to be synthesised. Default\n    is True, which means generating 1 channel, and use it as input (either for plain SR with a synthetic target, or for\n    synthesis with a real target).\n    :param output_channel: (optional) a list with the indices of the output channels  (i.e. the synthetic regression\n    targets), if no real images were provided as regression target. Set to None if using real images as targets. Default\n    is the first channel (index 0).\n    :param target_res: (optional) target resolution of the generated images and corresponding label maps.\n    If None, the outputs will have the same resolution as the input label maps.\n    Can be a number (isotropic resolution), or the path to a 1d numpy array.\n    :param output_shape: (optional) desired shape of the output image, obtained by randomly cropping the generated image\n    Can be an integer (same size in all dimensions), a sequence, a 1d numpy array, or the path to a 1d numpy array.\n    Default is None, where no cropping is performed.\n\n    # GMM-sampling parameters\n    :param path_generation_classes: (optional) Indices regrouping generation labels into classes of same intensity\n    distribution. Regouped labels will thus share the same Gaussian when samling a new image. Should be the path to a 1d\n    numpy array with the same length as generation_labels. and contain values between 0 and K-1, where K is the total\n    number of classes. Default is all labels have different classes.\n    :param prior_distributions: (optional) type of distribution from which we sample the GMM parameters.\n    Can either be 'uniform', or 'normal'. Default is 'normal'.\n    :param prior_means: (optional) hyperparameters controlling the prior distributions of the GMM means. Because\n    these prior distributions are uniform or normal, they require by 2 hyperparameters. Can be a path to:\n    1) an array of shape (2, K), where K is the number of classes (K=len(generation_labels) if generation_classes is\n    not given). The mean of the Gaussian distribution associated to class k in [0, ...K-1] is sampled at each mini-batch\n    from U(prior_means[0,k], prior_means[1,k]) if prior_distributions is uniform, and from\n    N(prior_means[0,k], prior_means[1,k]) if prior_distributions is normal.\n    2) an array of shape (2*n_mod, K), where each block of two rows is associated to hyperparameters derived\n    from different modalities. In this case, if use_specific_stats_for_channel is False, we first randomly select a\n    modality from the n_mod possibilities, and we sample the GMM means like in 2).\n    If use_specific_stats_for_channel is True, each block of two rows correspond to a different channel\n    (n_mod=n_channels), thus we select the corresponding block to each channel rather than randomly drawing it.\n    Default is None, which corresponds all GMM means sampled from uniform distribution U(25, 225).\n    :param prior_stds: (optional) same as prior_means but for the standard deviations of the GMM.\n    Default is None, which corresponds to U(5, 25).\n\n    # spatial deformation parameters\n    :param flipping: (optional) whether to introduce right/left random flipping. Default is True.\n    :param  padding_margin: useful when cropping the loss but you are not using very large patches. Set to None for\n    determining it automatically from loss_cropping (not recommended if you use big volume sizes)\n    :param scaling_bounds: (optional) if apply_linear_trans is True, the scaling factor for each dimension is\n    sampled from a uniform distribution of predefined bounds. Can either be:\n    1) a number, in which case the scaling factor is independently sampled from the uniform distribution of bounds\n    (1-scaling_bounds, 1+scaling_bounds) for each dimension.\n    2) the path to a numpy array of shape (2, n_dims), in which case the scaling factor in dimension i is sampled from\n    the uniform distribution of bounds (scaling_bounds[0, i], scaling_bounds[1, i]) for the i-th dimension.\n    3) False, in which case scaling is completely turned off.\n    Default is scaling_bounds = 0.15 (case 1)\n    :param rotation_bounds: (optional) same as scaling bounds but for the rotation angle, except that for case 1 the\n    bounds are centred on 0 rather than 1, i.e. (0+rotation_bounds[i], 0-rotation_bounds[i]).\n    Default is rotation_bounds = 15.\n    :param shearing_bounds: (optional) same as scaling bounds. Default is shearing_bounds = 0.012.\n    :param translation_bounds: (optional) same as scaling bounds. Default is translation_bounds = False, but we\n    encourage using it when cropping is deactivated (i.e. when output_shape=None).\n    :param nonlin_std: (optional) Standard deviation of the normal distribution from which we sample the first\n    tensor for synthesising the deformation field. Set to 0 to completely turn the elastic deformation off.\n    :param nonlin_shape_factor: (optional) Ratio between the size of the input label maps and the size of the sampled\n    tensor for synthesising the elastic deformation field.\n    :param simulate_registration_error: (optional) whether to simulate registration errors between *synthetic* channels.\n    Can be a single value (same for all channels) or a list with one value per *synthetic* channel. For the latter,\n    the first value will automatically be reset to True since the first channel is used as reference. Default is True.\n\n    # blurring/resampling parameters\n    :param randomise_res: (optional) whether to mimic images that would have been 1) acquired at low resolution, and\n    2) resampled to high resolution. The low resolution is uniformly sampled at each minibatch from [1mm, 9mm].\n    In that process, the images generated by sampling the GMM are: 1) blurred at LR, 2) downsampled at LR, and\n    3) resampled at target_resolution.\n    :param data_res: (optional) specific acquisition resolution to mimic, as opposed to random resolution sampled when\n    randomis_res is True. This triggers a blurring which mimics the acquisition resolution, but downsampling is optional\n    (see param downsample). Default for data_res is None, where images are slighlty blurred. If the generated images are\n    uni-modal, data_res can be a number (isotropic acquisition resolution), a sequence, a 1d numpy array, or the path\n    to a 1d numy array. In the multi-modal case, it should be given as a umpy array (or a path) of size (n_mod, n_dims),\n    where each row is the acquisition resolution of the corresponding channel.\n    :param thickness: (optional) if data_res is provided, we can further specify the slice thickness of the low\n    resolution images to mimic. Must be provided in the same format as data_res. Default thickness = data_res.\n    :param downsample: (optional) whether to actually downsample the volume images to data_res after blurring.\n    Default is False, except when thickness is provided, and thickness < data_res.\n    :param blur_range: (optional) Randomise the standard deviation of the blurring kernels, (whether data_res is given\n    or not). At each mini_batch, the standard deviation of the blurring kernels are multiplied by a coefficient sampled\n    from a uniform distribution with bounds [1/blur_range, blur_range]. If None, no randomisation. Default is 1.15.\n    :param build_reliability_maps: set to True if you want to build soft masks indicating which voxels are\n    \"measured\" and which are interpolated\n\n    # bias field parameters\n    :param bias_field_std: (optional) If strictly positive, this triggers the corruption of synthesised images with a\n    bias field. This will only affect the input channels (i.e. not the synthetic regression target). The bias field is\n    obtained by sampling a first small tensor from a normal distribution, resizing it to full size, and rescaling it to\n    positive values by taking the voxel-wise exponential. bias_field_std designates the std dev of the normal\n    distribution from which we sample the first tensor. Set to 0 to completely deactivate biad field corruption.\n    :param bias_shape_factor: (optional) If bias_field_std is not False, this designates the ratio between the size of\n    the input label maps and the size of the first sampled tensor for synthesising the bias field.\n\n    # ------------------------------------------ UNet architecture parameters ------------------------------------------\n    :param n_levels: (optional) number of level for the Unet. Default is 5.\n    :param nb_conv_per_level: (optional) number of convolutional layers per level. Default is 2.\n    :param conv_size: (optional) size of the convolution kernels. Default is 2.\n    :param unet_feat_count: (optional) number of feature for the first layr of the Unet. Default is 24.\n    :param feat_multiplier: (optional) multiply the number of feature by this nummber at each new level. Default is 2.\n    :param dropout: (optional) probability of dropout for the Unet. Deafult is 0, where no dropout is applied.\n    :param activation: (optional) activation function. Can be 'elu', 'relu'.\n\n    # ----------------------------------------------- Training parameters ----------------------------------------------\n    :param lr_decay: (optional) learing rate decay. Default is 0, where no decay is applied.\n    :param epochs: (optional) number of epochs.\n    :param steps_per_epoch: (optional) number of steps per epoch. Default is 1000. Since no online validation is\n    possible, this is equivalent to the frequency at which the models are saved.\n    :param work_with_residual_channel: (optional) if you have a channel that is similar to the output (e.g., in\n    imputation), it is convenient to predict the residual, rather than the image from scratch. This parameter is a list\n    of indices of the synthetic channels you want to add the residual to (must have the same length as output_channels,\n    or have length equal to 1 if real images are used)\n    :param loss_cropping: (option)  to crop the posteriors when evaluating the loss function (specify the output size\n    Can be an int, or the path to a 1d numpy array.\n\n    # ------------------------------------------------- new parameters -------------------------------------------------\n    :param lr_generator\n    :param lr_discriminator\n    :param relative_weight_segmentation\n    :param relative_weight_discriminator: weight of the wasserstein loss when computing the generator loss\n    :param gradient_penalty_weight; weight of the gp when computing the discriminator loss\n    :param training_ratio: (optional) number of discriminator iterations to take at each training step (whereas the\n    generator is only iterated once per step). This doesn't apply to the first step of the first epoch. Default is 10.\n    :param first_training_ratio: same as above but for the very first step of the firt epoch.\n    Usually higher than training ratio.\n    :param labels_to_mask: 1d numpy array as long as generation_labels, with 1 for structures to keep for the\n    discriminator, and 0 to remove (typically extra-cerebral regions)\n    \"\"\"", "\n", "\n", "n_channels", "=", "len", "(", "utils", ".", "reformat_to_list", "(", "input_channels", ")", ")", "\n", "\n", "# convert output_channel and work_with_residual_channel to lists", "\n", "if", "output_channel", "is", "not", "None", ":", "\n", "        ", "output_channel", "=", "list", "(", "utils", ".", "reformat_to_list", "(", "output_channel", ")", ")", "\n", "n_output_channels", "=", "len", "(", "output_channel", ")", "\n", "", "else", ":", "\n", "        ", "n_output_channels", "=", "1", "\n", "\n", "# various checks", "\n", "", "if", "(", "images_dir", "is", "None", ")", "&", "(", "output_channel", "is", "None", ")", ":", "\n", "        ", "raise", "Exception", "(", "'please provide a value for output_channel or image_dir'", ")", "\n", "", "elif", "(", "images_dir", "is", "not", "None", ")", "&", "(", "output_channel", "is", "not", "None", ")", ":", "\n", "        ", "raise", "Exception", "(", "'please provide a value either for output_channel or image_dir, but not both at the same time'", ")", "\n", "", "if", "output_channel", "is", "not", "None", ":", "\n", "        ", "if", "any", "(", "x", ">=", "n_channels", "for", "x", "in", "output_channel", ")", ":", "\n", "            ", "raise", "Exception", "(", "'indices in output_channel cannot be greater than the total number of channels'", ")", "\n", "\n", "# check work_with_residual_channel", "\n", "", "", "if", "work_with_residual_channel", "is", "not", "None", ":", "\n", "        ", "work_with_residual_channel", "=", "utils", ".", "reformat_to_list", "(", "work_with_residual_channel", ")", "\n", "if", "output_channel", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "work_with_residual_channel", ")", "!=", "len", "(", "output_channel", ")", ":", "\n", "                ", "raise", "Exception", "(", "'The number or residual channels and output channels must be the same'", ")", "\n", "\n", "", "", "if", "any", "(", "x", ">=", "n_channels", "for", "x", "in", "work_with_residual_channel", ")", ":", "\n", "            ", "raise", "Exception", "(", "'indices in work_with_residual_channel cannot be greater than the total number of channels'", ")", "\n", "\n", "# get label lists", "\n", "", "", "generation_labels", ",", "n_neutral_labels", "=", "utils", ".", "get_list_labels", "(", "label_list", "=", "path_generation_labels", ",", "\n", "labels_dir", "=", "labels_dir", ",", "\n", "FS_sort", "=", "FS_sort", ")", "\n", "\n", "# prepare model folder", "\n", "utils", ".", "mkdir", "(", "model_dir", ")", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'logs'", ")", "\n", "utils", ".", "mkdir", "(", "log_dir", ")", "\n", "\n", "# compute padding_margin if needed", "\n", "if", "loss_cropping", "==", "0", ":", "\n", "        ", "padding_margin", "=", "None", "\n", "", "elif", "padding_margin", "is", "None", ":", "\n", "        ", "padding_margin", "=", "utils", ".", "get_padding_margin", "(", "output_shape", ",", "loss_cropping", ")", "\n", "\n", "# instantiate BrainGenerator object", "\n", "", "brain_generator", "=", "BrainGenerator", "(", "labels_dir", "=", "labels_dir", ",", "\n", "images_dir", "=", "images_dir", ",", "\n", "generation_labels", "=", "generation_labels", ",", "\n", "n_neutral_labels", "=", "n_neutral_labels", ",", "\n", "padding_margin", "=", "padding_margin", ",", "\n", "batchsize", "=", "batchsize", ",", "\n", "input_channels", "=", "input_channels", ",", "\n", "output_channel", "=", "output_channel", ",", "\n", "target_res", "=", "target_res", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "output_div_by_n", "=", "2", "**", "n_levels", ",", "\n", "generation_classes", "=", "path_generation_classes", ",", "\n", "prior_means", "=", "prior_means", ",", "\n", "prior_stds", "=", "prior_stds", ",", "\n", "prior_distributions", "=", "prior_distributions", ",", "\n", "flipping", "=", "flipping", ",", "\n", "scaling_bounds", "=", "scaling_bounds", ",", "\n", "rotation_bounds", "=", "rotation_bounds", ",", "\n", "shearing_bounds", "=", "shearing_bounds", ",", "\n", "translation_bounds", "=", "translation_bounds", ",", "\n", "nonlin_std", "=", "nonlin_std", ",", "\n", "nonlin_shape_factor", "=", "nonlin_shape_factor", ",", "\n", "simulate_registration_error", "=", "simulate_registration_error", ",", "\n", "randomise_res", "=", "randomise_res", ",", "\n", "data_res", "=", "data_res", ",", "\n", "thickness", "=", "thickness", ",", "\n", "downsample", "=", "downsample", ",", "\n", "blur_range", "=", "blur_range", ",", "\n", "build_reliability_maps", "=", "build_reliability_maps", ",", "\n", "bias_field_std", "=", "bias_field_std", ",", "\n", "bias_shape_factor", "=", "bias_shape_factor", ")", "\n", "\n", "# input generator", "\n", "input_generator", "=", "utils", ".", "build_training_generator", "(", "brain_generator", ".", "model_inputs_generator", ",", "batchsize", ")", "\n", "\n", "# ------------------ we create the three modules: generator, discriminator, segmentation net -------------------", "\n", "\n", "# generator model", "\n", "labels_to_image_model", "=", "brain_generator", ".", "labels_to_image_model", "\n", "unet_input_shape", "=", "brain_generator", ".", "model_output_shape", "\n", "generator", "=", "nrn_models", ".", "unet", "(", "nb_features", "=", "unet_feat_count", ",", "\n", "input_shape", "=", "unet_input_shape", ",", "\n", "nb_levels", "=", "n_levels", ",", "\n", "conv_size", "=", "conv_size", ",", "\n", "nb_labels", "=", "n_output_channels", ",", "\n", "feat_mult", "=", "feat_multiplier", ",", "\n", "nb_conv_per_level", "=", "nb_conv_per_level", ",", "\n", "conv_dropout", "=", "dropout", ",", "\n", "final_pred_activation", "=", "'linear'", ",", "\n", "batch_norm", "=", "-", "1", ",", "\n", "activation", "=", "activation", ",", "\n", "input_model", "=", "labels_to_image_model", ")", "\n", "if", "checkpoint_generator", "is", "not", "None", ":", "\n", "        ", "print", "(", "'loading'", ",", "checkpoint_generator", ")", "\n", "generator", ".", "load_weights", "(", "checkpoint_generator", ",", "by_name", "=", "True", ")", "\n", "\n", "# discriminator model", "\n", "", "mask_input", "=", "labels_to_mask", "is", "not", "None", "\n", "discriminator", "=", "make_discriminator", "(", "unet_input_shape", ",", "mask_input", "=", "mask_input", ")", "\n", "\n", "# build network for pretrained (frozen) segmentation CNN", "\n", "if", "segmentation_model_file", "is", "not", "None", ":", "\n", "        ", "segmentation_label_equivalency", "=", "np", ".", "load", "(", "path_segmentation_equivalency", ")", "\n", "seg_unet_model", "=", "nrn_models", ".", "unet", "(", "nb_features", "=", "unet_feat_count", ",", "\n", "input_shape", "=", "[", "*", "unet_input_shape", "[", ":", "-", "1", "]", ",", "1", "]", ",", "\n", "nb_levels", "=", "n_levels", ",", "\n", "conv_size", "=", "conv_size", ",", "\n", "nb_labels", "=", "len", "(", "segmentation_label_equivalency", ")", ",", "\n", "feat_mult", "=", "feat_multiplier", ",", "\n", "nb_conv_per_level", "=", "nb_conv_per_level", ",", "\n", "conv_dropout", "=", "dropout", ",", "\n", "final_pred_activation", "=", "'softmax'", ",", "\n", "batch_norm", "=", "-", "1", ",", "\n", "activation", "=", "activation", ",", "\n", "input_model", "=", "None", ")", "\n", "seg_unet_model", ".", "load_weights", "(", "segmentation_model_file", ",", "by_name", "=", "True", ")", "\n", "seg_unet_model", ".", "trainable", "=", "False", "\n", "for", "layer", "in", "seg_unet_model", ".", "layers", ":", "\n", "            ", "layer", ".", "trainable", "=", "False", "\n", "", "", "else", ":", "\n", "        ", "seg_unet_model", "=", "segmentation_label_equivalency", "=", "None", "\n", "\n", "# ------------------ now that all 3 modules are created, we build the generator training model -------------------", "\n", "\n", "# add frozen discriminator to generator for training", "\n", "", "for", "layer", "in", "discriminator", ".", "layers", ":", "\n", "        ", "layer", ".", "trainable", "=", "False", "\n", "", "discriminator", ".", "trainable", "=", "False", "\n", "generator_out", "=", "generator", ".", "output", "\n", "if", "mask_input", ":", "\n", "        ", "labels_to_mask", "=", "utils", ".", "load_array_if_path", "(", "labels_to_mask", ")", "\n", "target_seg", "=", "generator", ".", "get_layer", "(", "'segmentation_target'", ")", ".", "output", "\n", "mask", "=", "layers", ".", "ConvertLabels", "(", "generation_labels", ",", "labels_to_mask", ",", "name", "=", "'mask'", ")", "(", "target_seg", ")", "\n", "generator_discriminator_out", "=", "discriminator", "(", "[", "generator_out", ",", "mask", "]", ")", "\n", "", "else", ":", "\n", "        ", "generator_discriminator_out", "=", "discriminator", "(", "generator_out", ")", "\n", "\n", "# normalise generator output", "\n", "", "if", "segmentation_model_file", "is", "not", "None", ":", "\n", "        ", "im", "=", "utils", ".", "load_volume", "(", "utils", ".", "list_images_in_folder", "(", "images_dir", ")", "[", "0", "]", ",", "im_only", "=", "True", ")", "\n", "m", "=", "np", ".", "percentile", "(", "im", ",", "2", ")", "\n", "M", "=", "np", ".", "percentile", "(", "im", ",", "98", ")", "\n", "input_norm", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "(", "K", ".", "clip", "(", "x", ",", "m", ",", "M", ")", "-", "m", ")", "/", "(", "M", "-", "m", ")", ",", "name", "=", "'input_normalized'", ")", "(", "generator_out", ")", "\n", "seg_out", "=", "seg_unet_model", "(", "input_norm", ")", "\n", "target_seg", "=", "generator", ".", "get_layer", "(", "'segmentation_target'", ")", ".", "output", "\n", "use_seg", "=", "True", "\n", "", "else", ":", "\n", "        ", "seg_out", "=", "target_seg", "=", "None", "\n", "use_seg", "=", "False", "\n", "\n", "# add loss computation to model, because the real image is modified (= cropped) inside the generation model,", "\n", "", "target", "=", "generator", ".", "get_layer", "(", "'regression_target'", ")", ".", "output", "\n", "gen_loss", "=", "build_generator_loss", "(", "target", ",", "target_seg", ",", "generator_out", ",", "generator_discriminator_out", ",", "seg_out", ",", "\n", "generation_labels", ",", "segmentation_label_equivalency", ",", "loss_cropping", ",", "use_seg", ",", "\n", "relative_weight_segmentation", ",", "relative_weight_discriminator", ")", "\n", "\n", "# build and compile generator model", "\n", "generator_model", "=", "models", ".", "Model", "(", "inputs", "=", "generator", ".", "inputs", ",", "outputs", "=", "gen_loss", ")", "\n", "generator_model", ".", "compile", "(", "optimizer", "=", "Adam", "(", "learning_rate", "=", "lr_generator", ",", "decay", "=", "lr_decay", ")", ",", "loss", "=", "dummy_loss", ")", "\n", "\n", "# ------------------ now we build the discriminator training model -------------------", "\n", "\n", "# freeze generator when training discriminator", "\n", "for", "layer", "in", "discriminator", ".", "layers", ":", "\n", "        ", "layer", ".", "trainable", "=", "True", "\n", "", "for", "layer", "in", "generator", ".", "layers", ":", "\n", "        ", "layer", ".", "trainable", "=", "False", "\n", "", "discriminator", ".", "trainable", "=", "True", "\n", "generator", ".", "trainable", "=", "False", "\n", "\n", "# define discriminator inputs", "\n", "target", "=", "generator", ".", "get_layer", "(", "'regression_target'", ")", ".", "output", "\n", "generated_samples_for_discriminator", "=", "generator", ".", "output", "\n", "averaged_samples", "=", "RandomWeightedAverage", "(", ")", "(", "[", "target", ",", "generated_samples_for_discriminator", "]", ")", "\n", "\n", "# define discriminator outputs", "\n", "if", "mask_input", ":", "\n", "        ", "target_seg", "=", "generator", ".", "get_layer", "(", "'segmentation_target'", ")", ".", "output", "\n", "mask", "=", "layers", ".", "ConvertLabels", "(", "generation_labels", ",", "labels_to_mask", ",", "name", "=", "'mask'", ")", "(", "target_seg", ")", "\n", "discriminator_real", "=", "discriminator", "(", "[", "target", ",", "mask", "]", ")", "\n", "discriminator_fake", "=", "discriminator", "(", "[", "generated_samples_for_discriminator", ",", "mask", "]", ")", "\n", "discriminator_av", "=", "discriminator", "(", "[", "averaged_samples", ",", "mask", "]", ")", "\n", "", "else", ":", "\n", "        ", "discriminator_real", "=", "discriminator", "(", "target", ")", "\n", "discriminator_fake", "=", "discriminator", "(", "generated_samples_for_discriminator", ")", "\n", "discriminator_av", "=", "discriminator", "(", "averaged_samples", ")", "\n", "\n", "# add discriminator loss to model", "\n", "", "discr_loss", "=", "build_discriminator_loss", "(", "discriminator_real", ",", "discriminator_fake", ",", "discriminator_av", ",", "\n", "averaged_samples", ",", "gradient_penalty_weight", ",", "brain_generator", ".", "n_dims", ")", "\n", "\n", "# create discriminator model", "\n", "discriminator_model", "=", "models", ".", "Model", "(", "inputs", "=", "generator", ".", "inputs", ",", "outputs", "=", "discr_loss", ")", "\n", "discriminator_model", ".", "compile", "(", "optimizer", "=", "Adam", "(", "learning_rate", "=", "lr_discriminator", ",", "decay", "=", "lr_decay", ")", ",", "loss", "=", "dummy_loss", ")", "\n", "\n", "# ------------------ now we train -------------------", "\n", "\n", "# training loop", "\n", "le", "=", "len", "(", "str", "(", "epochs", ")", ")", "\n", "discriminator_logs", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "generator_logs", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "print", "(", "'\\nEpoch {}/{}'", ".", "format", "(", "epoch", "+", "1", ",", "epochs", ")", ")", "\n", "\n", "avg_discr_loss", "=", "0", "\n", "avg_gen_loss", "=", "0", "\n", "for", "step", "in", "range", "(", "int", "(", "steps_per_epoch", ")", ")", ":", "\n", "\n", "# take several training steps for discriminator", "\n", "            ", "tmp_training_ratio", "=", "first_training_ratio", "if", "(", "epoch", "==", "0", ")", "&", "(", "step", "==", "0", ")", "else", "training_ratio", "\n", "lt", "=", "len", "(", "str", "(", "tmp_training_ratio", ")", ")", "\n", "for", "j", "in", "range", "(", "tmp_training_ratio", ")", ":", "\n", "                ", "training_inputs", ",", "dummy_y", "=", "next", "(", "input_generator", ")", "\n", "discr_loss", "=", "discriminator_model", ".", "train_on_batch", "(", "training_inputs", ",", "dummy_y", ")", "\n", "avg_discr_loss", "+=", "(", "discr_loss", "/", "(", "steps_per_epoch", "*", "tmp_training_ratio", ")", ")", "\n", "print", "(", "'Step {0:0{1}d}/{2} ({3:0{4}d}/{5})  discriminator loss:  {6}'", ".", "format", "(", "\n", "step", "+", "1", ",", "len", "(", "str", "(", "steps_per_epoch", ")", ")", ",", "steps_per_epoch", ",", "j", "+", "1", ",", "lt", ",", "tmp_training_ratio", ",", "discr_loss", ")", ")", "\n", "\n", "# take a step in generator", "\n", "", "training_inputs", ",", "dummy_y", "=", "next", "(", "input_generator", ")", "\n", "gen_loss", "=", "generator_model", ".", "train_on_batch", "(", "training_inputs", ",", "dummy_y", ")", "\n", "avg_gen_loss", "+=", "(", "gen_loss", "/", "steps_per_epoch", ")", "\n", "print", "(", "'Step {0:0{1}d}/{2}  generator loss:  {3}'", ".", "format", "(", "\n", "step", "+", "1", ",", "len", "(", "str", "(", "steps_per_epoch", ")", ")", ",", "steps_per_epoch", ",", "gen_loss", ")", ")", "\n", "\n", "# print and save epoch metrics", "\n", "", "print", "(", "'Epoch {0:0{1}d}/{2}   average discriminator loss:   {3}'", ".", "format", "(", "epoch", "+", "1", ",", "le", ",", "epochs", ",", "avg_discr_loss", ")", ")", "\n", "print", "(", "'Epoch {0:0{1}d}/{2}   average generator loss:       {3}'", ".", "format", "(", "epoch", "+", "1", ",", "le", ",", "epochs", ",", "avg_gen_loss", ")", ")", "\n", "discriminator_logs", "=", "np", ".", "append", "(", "discriminator_logs", ",", "avg_discr_loss", ")", "\n", "generator_logs", "=", "np", ".", "append", "(", "generator_logs", ",", "avg_gen_loss", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "'discriminator_loss.npy'", ")", ",", "discriminator_logs", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "'generator_loss.npy'", ")", ",", "generator_logs", ")", "\n", "\n", "# save model", "\n", "print", "(", "'Epoch {0:0{1}d}/{2}   saving models\\n'", ".", "format", "(", "epoch", "+", "1", ",", "le", ",", "epochs", ")", ")", "\n", "generator_model", ".", "save", "(", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'generator_{0:0{1}d}.h5'", ".", "format", "(", "epoch", "+", "1", ",", "le", ")", ")", ")", "\n", "discriminator_model", ".", "save", "(", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'discriminator_{0:0{1}d}.h5'", ".", "format", "(", "epoch", "+", "1", ",", "le", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.make_discriminator": [[482, 503], ["keras.Input", "range", "keras.models.Model", "fine_tuning_with_adversary.discriminator_block", "fine_tuning_with_adversary.discriminator_block", "keras.Flatten", "keras.Dense", "keras.LeakyReLU", "keras.Dense", "keras.Input", "keras.Lambda", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.discriminator_block", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.discriminator_block"], ["", "", "def", "make_discriminator", "(", "input_shape", ",", "n_filters", "=", "32", ",", "n_levels", "=", "4", ",", "mask_input", "=", "False", ")", ":", "\n", "\n", "    ", "input_tensor", "=", "KL", ".", "Input", "(", "shape", "=", "input_shape", ",", "name", "=", "'input_discriminator'", ")", "\n", "if", "mask_input", ":", "\n", "        ", "input_tensor", "=", "[", "input_tensor", ",", "KL", ".", "Input", "(", "shape", "=", "input_shape", ",", "name", "=", "'input_mask'", ")", "]", "\n", "last_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "0", "]", "*", "tf", ".", "cast", "(", "x", "[", "1", "]", ",", "dtype", "=", "x", "[", "0", "]", ".", "dtype", ")", ")", "(", "input_tensor", ")", "\n", "", "else", ":", "\n", "        ", "last_tensor", "=", "input_tensor", "\n", "\n", "", "for", "level", "in", "range", "(", "n_levels", ")", ":", "\n", "        ", "last_tensor", "=", "discriminator_block", "(", "last_tensor", ",", "n_filters", "*", "(", "2", "**", "level", ")", ",", "strides", "=", "1", ")", "\n", "last_tensor", "=", "discriminator_block", "(", "last_tensor", ",", "n_filters", "*", "(", "2", "**", "level", ")", ",", "strides", "=", "2", ")", "\n", "\n", "", "last_tensor", "=", "KL", ".", "Flatten", "(", "data_format", "=", "'channels_last'", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "KL", ".", "Dense", "(", "n_filters", "*", "(", "2", "**", "n_levels", ")", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "KL", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "last_tensor", ")", "\n", "\n", "# output without activation", "\n", "last_tensor", "=", "KL", ".", "Dense", "(", "1", ",", "activation", "=", "None", ")", "(", "last_tensor", ")", "\n", "\n", "return", "models", ".", "Model", "(", "input_tensor", ",", "last_tensor", ",", "name", "=", "'discriminator'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.discriminator_block": [[505, 509], ["keras.Conv3D", "keras.LeakyReLU"], "function", ["None"], ["", "def", "discriminator_block", "(", "layer_input", ",", "filters", ",", "strides", ")", ":", "\n", "    ", "d", "=", "KL", ".", "Conv3D", "(", "filters", ",", "kernel_size", "=", "3", ",", "strides", "=", "strides", ",", "padding", "=", "'same'", ")", "(", "layer_input", ")", "\n", "d", "=", "KL", ".", "LeakyReLU", "(", "alpha", "=", "0.2", ")", "(", "d", ")", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.build_generator_loss": [[511, 577], ["ext.lab2im.utils.get_dims", "ext.lab2im.utils.reformat_to_list", "keras.Lambda", "keras.Lambda", "list", "list", "target.get_shape().as_list", "int", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.Lambda", "ext.lab2im.layers.DiceLoss", "keras.Lambda", "keras.Lambda", "range", "keras.Lambda", "keras.Lambda", "keras.mean", "keras.mean", "numpy.where", "len", "list.append", "list.append", "target.get_shape", "tensorflow.slice", "tensorflow.slice", "keras.abs", "keras.Lambda", "len", "tensorflow.stack", "tensorflow.stack", "tensorflow.slice", "tensorflow.slice", "keras.Lambda", "len", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.cast", "keras.Lambda", "len", "Exception", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "keras.Lambda"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice"], ["", "def", "build_generator_loss", "(", "target", ",", "target_seg", ",", "generator_output", ",", "generator_discriminator_output", ",", "seg_out", ",", "\n", "generation_labels", ",", "segmentation_equivalency", ",", "loss_cropping", ",", "use_seg", ",", "\n", "dice_weight", ",", "discr_weight", ")", ":", "\n", "\n", "# crop tensors to compute loss only in the middle", "\n", "    ", "if", "loss_cropping", "is", "not", "None", ":", "\n", "\n", "# format loss_cropping", "\n", "        ", "target_shape", "=", "target", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "-", "1", "]", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "target_shape", ")", "\n", "loss_cropping", "=", "utils", ".", "reformat_to_list", "(", "loss_cropping", ",", "length", "=", "n_dims", ")", "\n", "\n", "# perform cropping", "\n", "idx", "=", "[", "int", "(", "(", "target_shape", "[", "i", "]", "-", "loss_cropping", "[", "i", "]", ")", "/", "2", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "target", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "slice", "(", "x", ",", "begin", "=", "tf", ".", "convert_to_tensor", "(", "[", "0", "]", "+", "idx", "+", "[", "0", "]", ",", "dtype", "=", "'int32'", ")", ",", "\n", "size", "=", "tf", ".", "convert_to_tensor", "(", "[", "-", "1", "]", "+", "loss_cropping", "+", "[", "-", "1", "]", ",", "dtype", "=", "'int32'", ")", ")", ",", "\n", "name", "=", "'cropping_gt'", ")", "(", "target", ")", "\n", "generator_output", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "slice", "(", "x", ",", "begin", "=", "tf", ".", "convert_to_tensor", "(", "[", "0", "]", "+", "idx", "+", "[", "0", "]", ",", "dtype", "=", "'int32'", ")", ",", "\n", "size", "=", "tf", ".", "convert_to_tensor", "(", "[", "-", "1", "]", "+", "loss_cropping", "+", "[", "-", "1", "]", ",", "dtype", "=", "'int32'", ")", ")", ",", "\n", "name", "=", "'cropping_pred'", ")", "(", "generator_output", ")", "\n", "if", "use_seg", ":", "\n", "            ", "target_seg", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "slice", "(", "x", ",", "begin", "=", "tf", ".", "convert_to_tensor", "(", "[", "0", "]", "+", "idx", "+", "[", "0", "]", ",", "dtype", "=", "'int32'", ")", ",", "\n", "size", "=", "tf", ".", "convert_to_tensor", "(", "[", "-", "1", "]", "+", "loss_cropping", "+", "[", "-", "1", "]", ",", "dtype", "=", "'int32'", ")", ")", ",", "\n", "name", "=", "'cropping_seg_gt'", ")", "(", "target_seg", ")", "\n", "seg_out", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "slice", "(", "x", ",", "begin", "=", "tf", ".", "convert_to_tensor", "(", "[", "0", "]", "+", "idx", "+", "[", "0", "]", ",", "dtype", "=", "'int32'", ")", ",", "\n", "size", "=", "tf", ".", "convert_to_tensor", "(", "[", "-", "1", "]", "+", "loss_cropping", "+", "[", "-", "1", "]", ",", "dtype", "=", "'int32'", ")", ")", ",", "\n", "name", "=", "'cropping_seg_pred'", ")", "(", "seg_out", ")", "\n", "\n", "# compute L1 and wasserstein losses", "\n", "", "", "l1_loss", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "mean", "(", "K", ".", "abs", "(", "x", "[", "0", "]", "-", "x", "[", "1", "]", ")", ")", ",", "name", "=", "'L1_loss'", ")", "(", "[", "target", ",", "generator_output", "]", ")", "\n", "w_loss", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "mean", "(", "-", "x", ")", ",", "name", "=", "'w_loss'", ")", "(", "generator_discriminator_output", ")", "\n", "\n", "# compute segmentation loss if necessary", "\n", "if", "use_seg", ":", "\n", "        ", "gt_onehot", "=", "list", "(", ")", "\n", "pred_onehot", "=", "list", "(", ")", "\n", "for", "ll", "in", "generation_labels", ":", "\n", "            ", "idx", "=", "np", ".", "where", "(", "segmentation_equivalency", "==", "ll", ")", "[", "0", "]", "\n", "if", "len", "(", "idx", ")", ">", "0", ":", "\n", "                ", "tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "cast", "(", "x", "[", "...", ",", "-", "1", "]", "==", "ll", ",", "dtype", "=", "'float32'", ")", ")", "(", "target_seg", ")", "\n", "gt_onehot", ".", "append", "(", "tensor", ")", "\n", "if", "len", "(", "idx", ")", "==", "1", ":", "\n", "                    ", "tensor2", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "...", ",", "idx", "[", "0", "]", "]", ")", "(", "seg_out", ")", "\n", "", "elif", "len", "(", "idx", ")", "==", "2", ":", "\n", "                    ", "tensor2", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "...", ",", "idx", "[", "0", "]", "]", "+", "x", "[", "...", ",", "idx", "[", "1", "]", "]", ")", "(", "seg_out", ")", "\n", "", "elif", "len", "(", "idx", ")", "==", "3", ":", "\n", "                    ", "tensor2", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "...", ",", "idx", "[", "0", "]", "]", "+", "x", "[", "...", ",", "idx", "[", "1", "]", "]", "+", "x", "[", "...", ",", "idx", "[", "2", "]", "]", ")", "(", "seg_out", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "\"uuummm weird that you're merging so many labels...\"", ")", "\n", "", "pred_onehot", ".", "append", "(", "tensor2", ")", "\n", "", "", "gt", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "stack", "(", "x", ",", "-", "1", ")", ",", "name", "=", "'gt'", ")", "(", "gt_onehot", ")", "\n", "pred", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "stack", "(", "x", ",", "-", "1", ")", ",", "name", "=", "'pred'", ")", "(", "pred_onehot", ")", "\n", "dice_loss", "=", "layers", ".", "DiceLoss", "(", "enable_checks", "=", "False", ",", "name", "=", "'dice_loss'", ")", "(", "[", "gt", ",", "pred", "]", ")", "\n", "", "else", ":", "\n", "        ", "dice_loss", "=", "None", "\n", "\n", "# add all losses", "\n", "", "l1_weight", "=", "1", "-", "discr_weight", "\n", "if", "use_seg", ":", "\n", "        ", "l1_weight", "-=", "dice_weight", "\n", "generator_loss", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "l1_weight", "*", "x", "[", "0", "]", "+", "discr_weight", "*", "x", "[", "1", "]", "+", "dice_weight", "*", "x", "[", "2", "]", ",", "\n", "name", "=", "'gen_loss'", ")", "(", "[", "l1_loss", ",", "w_loss", ",", "dice_loss", "]", ")", "\n", "", "else", ":", "\n", "        ", "generator_loss", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "l1_weight", "*", "x", "[", "0", "]", "+", "discr_weight", "*", "x", "[", "1", "]", ",", "name", "=", "'gen_loss'", ")", "(", "[", "l1_loss", ",", "w_loss", "]", ")", "\n", "\n", "", "return", "generator_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.build_discriminator_loss": [[579, 596], ["fine_tuning_with_adversary.Gradients", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.sqrt", "keras.mean", "keras.mean", "keras.mean", "keras.sum", "keras.square", "keras.square", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], ["", "def", "build_discriminator_loss", "(", "discriminator_real", ",", "discriminator_fake", ",", "discriminator_av", ",", "averaged_samples", ",", "\n", "gradient_penalty_w", "=", "10", ",", "n_dims", "=", "3", ")", ":", "\n", "\n", "# compute gradient penalty", "\n", "    ", "gradients", "=", "Gradients", "(", ")", "(", "[", "discriminator_av", ",", "averaged_samples", "]", ")", "\n", "gradients_l2_norm", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "sqrt", "(", "K", ".", "sum", "(", "K", ".", "square", "(", "x", ")", ",", "axis", "=", "np", ".", "arange", "(", "1", ",", "n_dims", "+", "1", ")", ")", ")", ")", "(", "gradients", ")", "\n", "gradient_penalty", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "gradient_penalty_w", "*", "K", ".", "square", "(", "1", "-", "x", ")", ")", "(", "gradients_l2_norm", ")", "\n", "\n", "# create loss for discriminator", "\n", "w_loss_real", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "mean", "(", "-", "x", ")", ",", "name", "=", "'w_loss_real'", ")", "(", "discriminator_real", ")", "\n", "w_loss_fake", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "mean", "(", "x", ")", ",", "name", "=", "'w_loss_fake'", ")", "(", "discriminator_fake", ")", "\n", "gradient_penalty_loss", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "mean", "(", "x", ")", ",", "name", "=", "'gradient_penalty_loss'", ")", "(", "gradient_penalty", ")", "\n", "discriminator_loss", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "0", "]", "+", "x", "[", "1", "]", "+", "x", "[", "2", "]", ",", "name", "=", "'discriminator_loss'", ")", "(", "[", "w_loss_real", ",", "\n", "w_loss_fake", ",", "\n", "gradient_penalty_loss", "]", ")", "\n", "\n", "return", "discriminator_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.fine_tuning_with_adversary.dummy_loss": [[598, 602], ["None"], "function", ["None"], ["", "def", "dummy_loss", "(", "y_true", ",", "y_predicted", ")", ":", "\n", "    ", "\"\"\"Because the metrics is already calculated in the model, we simply return y_predicted.\n       We still need to put y_true in the inputs, as it's expected by keras.\"\"\"", "\n", "return", "y_predicted", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.model_inputs.build_model_inputs": [[25, 140], ["ext.lab2im.utils.get_volume_info", "len", "numpy.arange", "numpy.unique", "numpy.randint", "len", "ext.lab2im.utils.load_volume", "list_label_maps.append", "numpy.empty", "numpy.empty", "range", "list_means.append", "list_stds.append", "list_inputs.append", "ext.lab2im.utils.add_axis", "ext.lab2im.utils.load_volume", "list_images.append", "isinstance", "isinstance", "ext.lab2im.utils.draw_value_from_distribution", "ext.lab2im.utils.draw_value_from_distribution", "ext.lab2im.utils.add_axis", "ext.lab2im.utils.add_axis", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.eye", "numpy.eye", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.draw_value_from_distribution", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.draw_value_from_distribution", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis"], ["def", "build_model_inputs", "(", "path_label_maps", ",", "\n", "n_labels", ",", "\n", "prior_means", ",", "\n", "prior_stds", ",", "\n", "prior_distributions", ",", "\n", "path_images", "=", "None", ",", "\n", "batchsize", "=", "1", ",", "\n", "n_channels", "=", "1", ",", "\n", "generation_classes", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This function builds a generator to be fed to the lab2im model. It enables to generate all the required inputs,\n    according to the operations performed in the model.\n    :param path_label_maps: list of the paths of the input label maps.\n    :param n_labels: number of labels in the input label maps.\n    :param prior_distributions: (optional) type of distribution from which we sample the GMM parameters.\n    Can either be 'uniform', or 'normal'. Default is 'uniform'.\n    :param prior_means: (optional) hyperparameters controlling the prior distributions of the GMM means. Because\n    these prior distributions are uniform or normal, they require by 2 hyperparameters. Thus prior_means can be:\n    1) a sequence of length 2, directly defining the two hyperparameters: [min, max] if prior_distributions is\n    uniform, [mean, std] if the distribution is normal. The GMM means of are independently sampled at each\n    mini_batch from the same distribution.\n    2) an array of shape (2, K), where K is the number of classes (K=len(generation_labels) if generation_classes is\n    not given). The mean of the Gaussian distribution associated to class k in [0, ...K-1] is sampled at each mini-batch\n    from U(prior_means[0,k], prior_means[1,k]) if prior_distributions is uniform, or from\n    N(prior_means[0,k], prior_means[1,k]) if prior_distributions is normal.\n    3) an array of shape (2*n_mod, K), where each block of two rows is associated to hyperparameters derived\n    from different modalities. In this case, if use_specific_stats_for_channel is False, we first randomly select a\n    modality from the n_mod possibilities, and we sample the GMM means like in 2).\n    If use_specific_stats_for_channel is True, each block of two rows correspond to a different channel\n    (n_mod=n_channels), thus we select the corresponding block to each channel rather than randomly drawing it.\n    4) the path to such a numpy array.\n    Default is None, which corresponds to prior_means = [25, 225].\n    :param prior_stds: (optional) same as prior_means but for the standard deviations of the GMM.\n    Default is None, which corresponds to prior_stds = [5, 25].\n    :param path_images: optionally, corresponding image intensities (useful for regression)\n    :param batchsize: (optional) numbers of images to generate per mini-batch. Default is 1.\n    :param n_channels: (optional) number of channels to be synthetised. Default is 1.\n    :param generation_classes: (optional) Indices regrouping generation labels into classes of same intensity\n    distribution. Regouped labels will thus share the same Gaussian when samling a new image. Can be a sequence or a\n    1d numpy array. It should have the same length as generation_labels, and contain values between 0 and K-1, where K\n    is the total number of classes. Default is all labels have different classes.\n    \"\"\"", "\n", "\n", "# get label info", "\n", "_", ",", "_", ",", "n_dims", ",", "_", ",", "_", ",", "_", "=", "utils", ".", "get_volume_info", "(", "path_label_maps", "[", "0", "]", ")", "\n", "\n", "# allocate unique class to each label if generation classes is not given", "\n", "if", "generation_classes", "is", "None", ":", "\n", "        ", "generation_classes", "=", "np", ".", "arange", "(", "n_labels", ")", "\n", "", "n_classes", "=", "len", "(", "np", ".", "unique", "(", "generation_classes", ")", ")", "\n", "\n", "# Generate!", "\n", "while", "True", ":", "\n", "\n", "# randomly pick as many images as batchsize", "\n", "        ", "indices", "=", "npr", ".", "randint", "(", "len", "(", "path_label_maps", ")", ",", "size", "=", "batchsize", ")", "\n", "\n", "# initialise input lists", "\n", "list_label_maps", "=", "[", "]", "\n", "list_means", "=", "[", "]", "\n", "list_stds", "=", "[", "]", "\n", "list_images", "=", "[", "]", "\n", "\n", "for", "idx", "in", "indices", ":", "\n", "\n", "# add labels to inputs", "\n", "            ", "lab", "=", "utils", ".", "load_volume", "(", "path_label_maps", "[", "idx", "]", ",", "dtype", "=", "'int'", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ")", "\n", "list_label_maps", ".", "append", "(", "utils", ".", "add_axis", "(", "lab", ",", "axis", "=", "[", "0", ",", "-", "1", "]", ")", ")", "\n", "\n", "if", "path_images", "is", "not", "None", ":", "\n", "                ", "im", "=", "utils", ".", "load_volume", "(", "path_images", "[", "idx", "]", ",", "dtype", "=", "'float'", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ")", "\n", "list_images", ".", "append", "(", "im", "[", "np", ".", "newaxis", ",", ":", ",", ":", ",", ":", ",", "np", ".", "newaxis", "]", ")", "\n", "\n", "# add means and standard deviations to inputs", "\n", "", "means", "=", "np", ".", "empty", "(", "(", "1", ",", "n_labels", ",", "0", ")", ")", "\n", "stds", "=", "np", ".", "empty", "(", "(", "1", ",", "n_labels", ",", "0", ")", ")", "\n", "for", "channel", "in", "range", "(", "n_channels", ")", ":", "\n", "\n", "# retrieve channel specific stats if necessary", "\n", "                ", "if", "isinstance", "(", "prior_means", ",", "np", ".", "ndarray", ")", ":", "\n", "                    ", "if", "prior_means", ".", "shape", "[", "0", "]", "/", "2", "!=", "n_channels", ":", "\n", "                        ", "raise", "ValueError", "(", "\"the number of blocks in prior_means does not match n_channels.\"", ")", "\n", "", "tmp_prior_means", "=", "prior_means", "[", "2", "*", "channel", ":", "2", "*", "channel", "+", "2", ",", ":", "]", "\n", "", "else", ":", "\n", "                    ", "tmp_prior_means", "=", "prior_means", "\n", "", "if", "isinstance", "(", "prior_stds", ",", "np", ".", "ndarray", ")", ":", "\n", "                    ", "if", "prior_stds", ".", "shape", "[", "0", "]", "/", "2", "!=", "n_channels", ":", "\n", "                        ", "raise", "ValueError", "(", "\"the number of blocks in prior_stds does not match n_channels.\"", ")", "\n", "", "tmp_prior_stds", "=", "prior_stds", "[", "2", "*", "channel", ":", "2", "*", "channel", "+", "2", ",", ":", "]", "\n", "", "else", ":", "\n", "                    ", "tmp_prior_stds", "=", "prior_stds", "\n", "\n", "# draw means and std devs from priors", "\n", "", "tmp_classes_means", "=", "utils", ".", "draw_value_from_distribution", "(", "tmp_prior_means", ",", "n_classes", ",", "prior_distributions", ",", "\n", "125.", ",", "100.", ",", "positive_only", "=", "True", ")", "\n", "tmp_classes_stds", "=", "utils", ".", "draw_value_from_distribution", "(", "tmp_prior_stds", ",", "n_classes", ",", "prior_distributions", ",", "\n", "15.", ",", "10.", ",", "positive_only", "=", "True", ")", "\n", "tmp_means", "=", "utils", ".", "add_axis", "(", "tmp_classes_means", "[", "generation_classes", "]", ",", "axis", "=", "[", "0", ",", "-", "1", "]", ")", "\n", "tmp_stds", "=", "utils", ".", "add_axis", "(", "tmp_classes_stds", "[", "generation_classes", "]", ",", "axis", "=", "[", "0", ",", "-", "1", "]", ")", "\n", "means", "=", "np", ".", "concatenate", "(", "[", "means", ",", "tmp_means", "]", ",", "axis", "=", "-", "1", ")", "\n", "stds", "=", "np", ".", "concatenate", "(", "[", "stds", ",", "tmp_stds", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "list_means", ".", "append", "(", "means", ")", "\n", "list_stds", ".", "append", "(", "stds", ")", "\n", "\n", "# build list of inputs for generation model", "\n", "", "list_inputs", "=", "[", "list_label_maps", ",", "list_means", ",", "list_stds", "]", "\n", "if", "path_images", "is", "not", "None", ":", "\n", "            ", "list_inputs", ".", "append", "(", "list_images", ")", "\n", "\n", "", "if", "batchsize", ">", "1", ":", "# concatenate each input type if batchsize > 1", "\n", "            ", "list_inputs", "=", "[", "np", ".", "concatenate", "(", "item", ",", "0", ")", "for", "item", "in", "list_inputs", "]", "\n", "", "else", ":", "\n", "            ", "list_inputs", "=", "[", "item", "[", "0", "]", "for", "item", "in", "list_inputs", "]", "\n", "\n", "", "yield", "list_inputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.brain_generator.BrainGenerator.__init__": [[30, 265], ["ext.lab2im.utils.list_images_in_folder", "ext.lab2im.utils.get_volume_info", "numpy.array", "ext.lab2im.utils.reformat_to_list", "len", "ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.load_array_if_path", "brain_generator.BrainGenerator._build_labels_to_image_model", "brain_generator.BrainGenerator._build_model_inputs_generator", "brain_generator.BrainGenerator._build_brain_generator", "ext.lab2im.utils.list_images_in_folder", "ext.lab2im.utils.load_array_if_path", "ext.lab2im.utils.get_list_labels", "ext.lab2im.utils.reformat_to_list", "ext.lab2im.utils.load_array_if_path", "numpy.unique", "numpy.array_equal", "numpy.arange", "len", "len", "numpy.eye", "numpy.arange", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.brain_generator.BrainGenerator._build_labels_to_image_model", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.brain_generator.BrainGenerator._build_model_inputs_generator", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.brain_generator.BrainGenerator._build_brain_generator", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_list_labels", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], ["    ", "def", "__init__", "(", "self", ",", "\n", "labels_dir", ",", "\n", "prior_means", ",", "\n", "prior_stds", ",", "\n", "prior_distributions", ",", "\n", "generation_labels", ",", "\n", "images_dir", "=", "None", ",", "\n", "n_neutral_labels", "=", "None", ",", "\n", "padding_margin", "=", "None", ",", "\n", "batchsize", "=", "1", ",", "\n", "input_channels", "=", "1", ",", "\n", "output_channel", "=", "0", ",", "\n", "target_res", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "output_div_by_n", "=", "None", ",", "\n", "generation_classes", "=", "None", ",", "\n", "flipping", "=", "True", ",", "\n", "scaling_bounds", "=", "0.15", ",", "\n", "rotation_bounds", "=", "15", ",", "\n", "shearing_bounds", "=", ".012", ",", "\n", "translation_bounds", "=", "5", ",", "\n", "nonlin_std", "=", "3.", ",", "\n", "nonlin_shape_factor", "=", "0.0625", ",", "\n", "simulate_registration_error", "=", "True", ",", "\n", "randomise_res", "=", "False", ",", "\n", "data_res", "=", "None", ",", "\n", "thickness", "=", "None", ",", "\n", "downsample", "=", "False", ",", "\n", "blur_range", "=", "1.15", ",", "\n", "build_reliability_maps", "=", "False", ",", "\n", "bias_field_std", "=", "0.3", ",", "\n", "bias_shape_factor", "=", "0.025", ")", ":", "\n", "        ", "\"\"\"\n        This class is wrapper around the labels_to_image_model model. It contains the GPU model that generates images\n        from labels maps, and a python generator that suplies the input data for this model.\n        To generate pairs of image/labels you can just call the method generate_image() on an object of this class.\n\n        :param labels_dir: path of folder with all input label maps, or to a single label map.\n        :param images_dir: only required for synthesis with real data as target; set to None otherwise\n\n        # IMPORTANT !!!\n        # Each time we provide a parameter with separate values for each axis (e.g. with a numpy array or a sequence),\n        # these values refer to the RAS axes.\n\n        # label maps-related parameters\n        :param generation_labels: list of all possible label values in the input label maps.\n        Must be the path to a 1d numpy array, which should be organised as follows: background label first, then\n        non-sided labels (e.g. CSF, brainstem, etc.), then all the structures of the same hemisphere (can be left or\n        right), and finally all the corresponding contralateral structures (in the same order).\n        Example: [background_label, non-sided_1, ..., non-sided_n, left_1, ..., left_m, right_1, ..., right_m]\n        :param n_neutral_labels: (optional) number of non-sided generation labels.\n        Default is total number of label values.\n        :param padding_margin: (optional) margin by which to pad the input labels with zeros.\n        Padding is applied prior to any other operation.\n        Can be an integer (same padding in all dimensions), a sequence, a 1d numpy array, or the path to a 1d numpy\n        array. Default is no padding.\n\n        # output-related parameters\n        :param batchsize: (optional) numbers of images to generate per mini-batch. Default is 1.\n        :param input_channels: (optional) list of booleans indicating if each *synthetic* channel is going to be used as\n        an input for the downstream network. This also enables to know how many channels are going to be synthesised.\n        Default is True, which means generating 1 channel, and use it as input (either for plain SR with a synthetic\n        target, or for synthesis with a real target).\n        :param output_channel: (optional) a list with the indices of the output channels  (i.e. the synthetic regression\n        targets), if no real images were provided as regression target. Set to None if using real images as targets.\n        Default is the first channel (index 0).\n        :param target_res: (optional) target resolution of the generated images and corresponding label maps.\n        If None, the outputs will have the same resolution as the input label maps.\n        Can be a number (isotropic resolution), a sequence, a 1d numpy array, or the path to a 1d numpy array.\n        :param output_shape: (optional) shape of the output image, obtained by randomly cropping the generated image.\n        Can be an integer (same size in all dimensions), a sequence, a 1d numpy array, or the path to a 1d numpy array.\n        Default is None, where no cropping is performed.\n        :param output_div_by_n: (optional) forces the output shape to be divisible by this value. It overwrites\n        output_shape if necessary. Can be an integer (same size in all dimensions), a sequence, a 1d numpy array, or\n        the path to a 1d numpy array.\n\n        # GMM-sampling parameters\n        :param generation_classes: (optional) Indices regrouping generation labels into classes of same intensity\n        distribution. Regouped labels will thus share the same Gaussian when samling a new image. Can be a sequence, a\n        1d numpy array, or the path to a 1d numpy array. It should have the same length as generation_labels, and\n        contain values between 0 and K-1, where K is the total number of classes.\n        Default is all labels have different classes (K=len(generation_labels)).\n        :param prior_distributions: (optional) type of distribution from which we sample the GMM parameters.\n        Can either be 'uniform', or 'normal'. Default is 'uniform'.\n        :param prior_means: (optional) hyperparameters controlling the prior distributions of the GMM means. Because\n        these prior distributions are uniform or normal, they require by 2 hyperparameters. Thus prior_means can be:\n        1) a sequence of length 2, directly defining the two hyperparameters: [min, max] if prior_distributions is\n        uniform, [mean, std] if the distribution is normal. The GMM means of are independently sampled at each\n        mini_batch from the same distribution.\n        2) an array of shape (2, K), where K is the number of classes (K=len(generation_labels) if generation_classes is\n        not given). The mean of the Gaussian distribution associated to class k in [0, ...K-1] is sampled at each\n        mini-batch from U(prior_means[0,k], prior_means[1,k]) if prior_distributions is uniform, and from\n        N(prior_means[0,k], prior_means[1,k]) if prior_distributions is normal.\n        3) an array of shape (2*n_mod, K), where each block of two rows is associated to hyperparameters derived\n        from different modalities. In this case, if use_specific_stats_for_channel is False, we first randomly select a\n        modality from the n_mod possibilities, and we sample the GMM means like in 2).\n        If use_specific_stats_for_channel is True, each block of two rows correspond to a different channel\n        (n_mod=n_channels), thus we select the corresponding block to each channel rather than randomly drawing it.\n        4) the path to such a numpy array.\n        Default is None, which corresponds to prior_means = [25, 225].\n        :param prior_stds: (optional) same as prior_means but for the standard deviations of the GMM.\n        Default is None, which corresponds to prior_stds = [5, 25].\n\n        # spatial deformation parameters\n        :param flipping: (optional) whether to introduce right/left random flipping. Default is True.\n        :param scaling_bounds: (optional) range of the random saling to apply at each mini-batch. The scaling factor for\n        each dimension is sampled from a uniform distribution of predefined bounds. Can either be:\n        1) a number, in which case the scaling factor is independently sampled from the uniform distribution of bounds\n        [1-scaling_bounds, 1+scaling_bounds] for each dimension.\n        2) a sequence, in which case the scaling factor is sampled from the uniform distribution of bounds\n        (1-scaling_bounds[i], 1+scaling_bounds[i]) for the i-th dimension.\n        3) a numpy array of shape (2, n_dims), in which case the scaling factor is sampled from the uniform distribution\n         of bounds (scaling_bounds[0, i], scaling_bounds[1, i]) for the i-th dimension.\n        4) False, in which case scaling is completely turned off.\n        Default is scaling_bounds = 0.15 (case 1)\n        :param rotation_bounds: (optional) same as scaling bounds but for the rotation angle, except that for cases 1\n        and 2, the bounds are centred on 0 rather than 1, i.e. [0+rotation_bounds[i], 0-rotation_bounds[i]].\n        Default is rotation_bounds = 15.\n        :param shearing_bounds: (optional) same as scaling bounds. Default is shearing_bounds = 0.012.\n        :param translation_bounds: (optional) same as scaling bounds. Default is translation_bounds = False, but we\n        encourage using it when cropping is deactivated (i.e. when output_shape=None in BrainGenerator).\n        :param nonlin_std: (optional) Maximum value for the standard deviation of the normal distribution from which we\n        sample the first tensor for synthesising the deformation field. Set to 0 if you wish to completely turn the\n        elastic deformation off.\n        :param nonlin_shape_factor: (optional) if nonlin_std is not False, factor between the shapes of the input label\n        maps and the shape of the input non-linear tensor.\n        :param simulate_registration_error: (optional) whether to simulate registration errors between *synthetic*\n        channels. Can be a single value (same for all channels) or a list with one value per *synthetic* channel. In the\n        latter case, the first values will automatically be reset to True as the first channel is used as reference.\n        Default is True.\n\n        # blurring/resampling parameters\n        :param randomise_res: (optional) whether to mimic images that would have been 1) acquired at low resolution, and\n        2) resampled to high esolution. The low resolution is uniformly resampled at each minibatch from [1mm, 9mm].\n        In that process, the images generated by sampling the GMM are:\n        1) blurred at the sampled LR, 2) downsampled at LR, and 3) resampled at target_resolution.\n        :param data_res: (optional) specific acquisition resolution to mimic, as opposed to random resolution sampled\n        when randomis_res is True. This triggers a blurring which mimics the acquisition resolution, but downsampling\n        is optional (see param downsample). Default for data_res is None, where images are slighlty blurred.\n        If the generated images are uni-modal, data_res can be a number (isotropic acquisition resolution), a sequence,\n        a 1d numpy array, or the path to a 1d numy array. In the multi-modal case, it should be given as a umpy array (\n        or a path) of size (n_mod, n_dims), where each row is the acquisition resolution of the corresponding channel.\n        :param thickness: (optional) if data_res is provided, we can further specify the slice thickness of the low\n        resolution images to mimic. Must be provided in the same format as data_res. Default thickness = data_res.\n        :param downsample: (optional) whether to actually downsample the volume images to data_res after blurring.\n        Default is False, except when thickness is provided, and thickness < data_res.\n        :param blur_range: (optional) Randomise the standard deviation of the blurring kernels, (whether data_res is\n        given or not). At each mini_batch, the standard deviation of the blurring kernels are multiplied by a\n        coefficient sampled from a uniform distribution with bounds [1/blur_range, blur_range].\n        If None, no randomisation. Default is 1.15.\n        :param build_reliability_maps: (option) switch on if you want to produce volumes that tell you whether you are\n        in the center of a slice, or rather in interpolated land\n\n        # bias field parameters\n        :param bias_field_std: (optional) If strictly positive, this triggers the corruption of synthesised images with\n        a bias field. It will only affect the input channels (i.e. not the synthetic regression target). The bias field\n        is obtained by sampling a first small tensor from a normal distribution, resizing it to full size, and rescaling\n        it to positive values by taking the voxel-wise exponential. bias_field_std designates the std dev of the normal\n        distribution from which we sample the first tensor. Set to 0 to completely deactivate biad field corruption.\n        :param bias_shape_factor: (optional) If bias_field_std is not False, this designates the ratio between the size\n        of the input label maps and the size of the first sampled tensor for synthesising the bias field.\n        \"\"\"", "\n", "\n", "# prepare data files", "\n", "self", ".", "labels_paths", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "\n", "self", ".", "images_paths", "=", "None", "\n", "if", "images_dir", "is", "not", "None", ":", "\n", "            ", "self", ".", "images_paths", "=", "utils", ".", "list_images_in_folder", "(", "images_dir", ")", "\n", "assert", "len", "(", "self", ".", "labels_paths", ")", "==", "len", "(", "self", ".", "images_paths", ")", ",", "\"Different number of images and segmentations\"", "\n", "\n", "# generation parameters", "\n", "", "self", ".", "labels_shape", ",", "self", ".", "aff", ",", "self", ".", "n_dims", ",", "_", ",", "self", ".", "header", ",", "self", ".", "atlas_res", "=", "utils", ".", "get_volume_info", "(", "self", ".", "labels_paths", "[", "0", "]", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ")", "\n", "if", "generation_labels", "is", "not", "None", ":", "\n", "            ", "self", ".", "generation_labels", "=", "utils", ".", "load_array_if_path", "(", "generation_labels", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "generation_labels", ",", "_", "=", "utils", ".", "get_list_labels", "(", "labels_dir", "=", "labels_dir", ")", "\n", "", "if", "n_neutral_labels", "is", "not", "None", ":", "\n", "            ", "self", ".", "n_neutral_labels", "=", "n_neutral_labels", "\n", "", "else", ":", "\n", "            ", "self", ".", "n_neutral_labels", "=", "self", ".", "generation_labels", ".", "shape", "[", "0", "]", "\n", "", "self", ".", "input_channels", "=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "input_channels", ")", ")", "\n", "self", ".", "output_channel", "=", "utils", ".", "reformat_to_list", "(", "output_channel", ")", "\n", "self", ".", "n_channels", "=", "len", "(", "self", ".", "input_channels", ")", "\n", "self", ".", "target_res", "=", "utils", ".", "load_array_if_path", "(", "target_res", ")", "\n", "self", ".", "batchsize", "=", "batchsize", "\n", "# preliminary operations", "\n", "self", ".", "padding_margin", "=", "utils", ".", "load_array_if_path", "(", "padding_margin", ")", "\n", "self", ".", "flipping", "=", "flipping", "\n", "self", ".", "output_shape", "=", "utils", ".", "load_array_if_path", "(", "output_shape", ")", "\n", "self", ".", "output_div_by_n", "=", "output_div_by_n", "\n", "# GMM parameters", "\n", "self", ".", "prior_distributions", "=", "prior_distributions", "\n", "if", "generation_classes", "is", "not", "None", ":", "\n", "            ", "self", ".", "generation_classes", "=", "utils", ".", "load_array_if_path", "(", "generation_classes", ")", "\n", "assert", "self", ".", "generation_classes", ".", "shape", "==", "self", ".", "generation_labels", ".", "shape", ",", "'if provided, generation_classes should have the same shape as generation_labels'", "\n", "unique_classes", "=", "np", ".", "unique", "(", "self", ".", "generation_classes", ")", "\n", "assert", "np", ".", "array_equal", "(", "unique_classes", ",", "np", ".", "arange", "(", "np", ".", "max", "(", "unique_classes", ")", "+", "1", ")", ")", ",", "'generation_classes should a linear range between 0 and its maximum value.'", "\n", "", "else", ":", "\n", "            ", "self", ".", "generation_classes", "=", "np", ".", "arange", "(", "self", ".", "generation_labels", ".", "shape", "[", "0", "]", ")", "\n", "", "self", ".", "prior_means", "=", "utils", ".", "load_array_if_path", "(", "prior_means", ")", "\n", "self", ".", "prior_stds", "=", "utils", ".", "load_array_if_path", "(", "prior_stds", ")", "\n", "# linear transformation parameters", "\n", "self", ".", "scaling_bounds", "=", "utils", ".", "load_array_if_path", "(", "scaling_bounds", ")", "\n", "self", ".", "rotation_bounds", "=", "utils", ".", "load_array_if_path", "(", "rotation_bounds", ")", "\n", "self", ".", "shearing_bounds", "=", "utils", ".", "load_array_if_path", "(", "shearing_bounds", ")", "\n", "self", ".", "translation_bounds", "=", "utils", ".", "load_array_if_path", "(", "translation_bounds", ")", "\n", "# elastic transformation parameters", "\n", "self", ".", "nonlin_std", "=", "nonlin_std", "\n", "self", ".", "nonlin_shape_factor", "=", "nonlin_shape_factor", "\n", "self", ".", "simulate_registration_error", "=", "simulate_registration_error", "\n", "# blurring parameters", "\n", "self", ".", "randomise_res", "=", "randomise_res", "\n", "self", ".", "data_res", "=", "utils", ".", "load_array_if_path", "(", "data_res", ")", "\n", "assert", "not", "(", "self", ".", "randomise_res", "&", "(", "self", ".", "data_res", "is", "not", "None", ")", ")", ",", "'randomise_res and data_res cannot be provided at the same time'", "\n", "self", ".", "thickness", "=", "utils", ".", "load_array_if_path", "(", "thickness", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "blur_range", "=", "blur_range", "\n", "self", ".", "build_reliability_maps", "=", "build_reliability_maps", "\n", "# bias field parameters", "\n", "self", ".", "bias_field_std", "=", "bias_field_std", "\n", "self", ".", "bias_shape_factor", "=", "bias_shape_factor", "\n", "\n", "# build transformation model", "\n", "self", ".", "labels_to_image_model", ",", "self", ".", "model_output_shape", "=", "self", ".", "_build_labels_to_image_model", "(", ")", "\n", "\n", "# build generator for model inputs", "\n", "self", ".", "model_inputs_generator", "=", "self", ".", "_build_model_inputs_generator", "(", ")", "\n", "\n", "# build brain generator", "\n", "self", ".", "brain_generator", "=", "self", ".", "_build_brain_generator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.brain_generator.BrainGenerator._build_labels_to_image_model": [[266, 297], ["labels_to_image_model.labels_to_image_model.labels_to_image_model", "labels_to_image_model.labels_to_image_model.labels_to_image_model.output[].get_shape().as_list", "numpy.eye", "labels_to_image_model.labels_to_image_model.labels_to_image_model.output[].get_shape"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.labels_to_image_model.labels_to_image_model"], ["", "def", "_build_labels_to_image_model", "(", "self", ")", ":", "\n", "# build_model", "\n", "        ", "lab_to_im_model", "=", "labels_to_image_model", "(", "labels_shape", "=", "self", ".", "labels_shape", ",", "\n", "input_channels", "=", "self", ".", "input_channels", ",", "\n", "output_channel", "=", "self", ".", "output_channel", ",", "\n", "generation_labels", "=", "self", ".", "generation_labels", ",", "\n", "n_neutral_labels", "=", "self", ".", "n_neutral_labels", ",", "\n", "atlas_res", "=", "self", ".", "atlas_res", ",", "\n", "target_res", "=", "self", ".", "target_res", ",", "\n", "output_shape", "=", "self", ".", "output_shape", ",", "\n", "output_div_by_n", "=", "self", ".", "output_div_by_n", ",", "\n", "padding_margin", "=", "self", ".", "padding_margin", ",", "\n", "flipping", "=", "self", ".", "flipping", ",", "\n", "aff", "=", "np", ".", "eye", "(", "4", ")", ",", "\n", "scaling_bounds", "=", "self", ".", "scaling_bounds", ",", "\n", "rotation_bounds", "=", "self", ".", "rotation_bounds", ",", "\n", "shearing_bounds", "=", "self", ".", "shearing_bounds", ",", "\n", "translation_bounds", "=", "self", ".", "translation_bounds", ",", "\n", "nonlin_std", "=", "self", ".", "nonlin_std", ",", "\n", "nonlin_shape_factor", "=", "self", ".", "nonlin_shape_factor", ",", "\n", "simulate_registration_error", "=", "self", ".", "simulate_registration_error", ",", "\n", "randomise_res", "=", "self", ".", "randomise_res", ",", "\n", "data_res", "=", "self", ".", "data_res", ",", "\n", "thickness", "=", "self", ".", "thickness", ",", "\n", "downsample", "=", "self", ".", "downsample", ",", "\n", "build_reliability_maps", "=", "self", ".", "build_reliability_maps", ",", "\n", "blur_range", "=", "self", ".", "blur_range", ",", "\n", "bias_field_std", "=", "self", ".", "bias_field_std", ",", "\n", "bias_shape_factor", "=", "self", ".", "bias_shape_factor", ")", "\n", "out_shape", "=", "lab_to_im_model", ".", "output", "[", "0", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "return", "lab_to_im_model", ",", "out_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.brain_generator.BrainGenerator._build_model_inputs_generator": [[298, 310], ["model_inputs.build_model_inputs", "len"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.model_inputs.build_model_inputs"], ["", "def", "_build_model_inputs_generator", "(", "self", ")", ":", "\n", "# build model's inputs generator", "\n", "        ", "model_inputs_generator", "=", "build_model_inputs", "(", "path_label_maps", "=", "self", ".", "labels_paths", ",", "\n", "n_labels", "=", "len", "(", "self", ".", "generation_labels", ")", ",", "\n", "prior_means", "=", "self", ".", "prior_means", ",", "\n", "prior_stds", "=", "self", ".", "prior_stds", ",", "\n", "prior_distributions", "=", "self", ".", "prior_distributions", ",", "\n", "path_images", "=", "self", ".", "images_paths", ",", "\n", "batchsize", "=", "self", ".", "batchsize", ",", "\n", "n_channels", "=", "self", ".", "n_channels", ",", "\n", "generation_classes", "=", "self", ".", "generation_classes", ")", "\n", "return", "model_inputs_generator", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.brain_generator.BrainGenerator._build_brain_generator": [[311, 316], ["next", "brain_generator.BrainGenerator.labels_to_image_model.predict"], "methods", ["None"], ["", "def", "_build_brain_generator", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "model_inputs", "=", "next", "(", "self", ".", "model_inputs_generator", ")", "\n", "[", "image", ",", "target", "]", "=", "self", ".", "labels_to_image_model", ".", "predict", "(", "model_inputs", ")", "\n", "yield", "image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.brain_generator.BrainGenerator.generate_brain": [[317, 331], ["next", "list", "list", "range", "numpy.squeeze", "numpy.squeeze", "list.append", "list.append", "numpy.stack", "numpy.stack", "ext.lab2im.edit_volumes.align_volume_to_ref", "ext.lab2im.edit_volumes.align_volume_to_ref", "numpy.eye", "numpy.eye"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref"], ["", "", "def", "generate_brain", "(", "self", ")", ":", "\n", "        ", "\"\"\"call this method when an object of this class has been instantiated to generate new brains\"\"\"", "\n", "(", "image", ",", "target", ")", "=", "next", "(", "self", ".", "brain_generator", ")", "\n", "# put back images in native space", "\n", "list_images", "=", "list", "(", ")", "\n", "list_targets", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "batchsize", ")", ":", "\n", "            ", "list_images", ".", "append", "(", "edit_volumes", ".", "align_volume_to_ref", "(", "image", "[", "i", "]", ",", "np", ".", "eye", "(", "4", ")", ",", "\n", "aff_ref", "=", "self", ".", "aff", ",", "n_dims", "=", "self", ".", "n_dims", ")", ")", "\n", "list_targets", ".", "append", "(", "edit_volumes", ".", "align_volume_to_ref", "(", "target", "[", "i", "]", ",", "np", ".", "eye", "(", "4", ")", ",", "\n", "aff_ref", "=", "self", ".", "aff", ",", "n_dims", "=", "self", ".", "n_dims", ")", ")", "\n", "", "image", "=", "np", ".", "squeeze", "(", "np", ".", "stack", "(", "list_images", ",", "axis", "=", "0", ")", ")", "\n", "target", "=", "np", ".", "squeeze", "(", "np", ".", "stack", "(", "list_targets", ",", "axis", "=", "0", ")", ")", "\n", "return", "image", ",", "target", "\n", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.labels_to_image_model.labels_to_image_model": [[32, 265], ["len", "numpy.argmax", "ext.lab2im.utils.reformat_to_list", "ext.lab2im.utils.reformat_to_list", "ext.lab2im.utils.get_dims", "ext.lab2im.utils.reformat_to_n_channels_array", "isinstance", "labels_to_image_model.get_shapes", "keras.Input", "keras.Input", "keras.Input", "tuple", "tuple", "list", "list", "enumerate", "keras.models.Model", "ext.lab2im.utils.reformat_to_n_channels_array", "ext.lab2im.utils.reformat_to_n_channels_array", "ext.lab2im.utils.reformat_to_list", "keras.Input", "list_inputs.append", "labels.get_shape().as_list", "tuple", "tuple", "tuple", "labels.get_shape().as_list", "ext.lab2im.layers.SampleConditionalGMM", "keras.Lambda", "tuple", "tuple", "tuple", "keras.Lambda", "keras.Lambda", "numpy.min", "ext.lab2im.utils.reformat_to_n_channels_array", "ext.lab2im.layers.PadAroundCentre", "labels.get_shape().as_list", "KL.Input.get_shape().as_list", "ext.lab2im.layers.RandomSpatialDeformation", "ext.lab2im.layers.RandomSpatialDeformation", "labels.get_shape().as_list", "tuple", "labels.get_shape().as_list", "tuple", "keras.Lambda", "tuple", "et.resample_tensor.get_shape().as_list", "ext.lab2im.layers.IntensityAugmentation", "et.resample_tensor.get_shape().as_list", "ext.lab2im.layers.GaussianBlur", "any", "tuple", "list.append", "len", "keras.Lambda", "KL.Input.get_shape().as_list", "ext.lab2im.layers.IntensityAugmentation", "ext.lab2im.edit_tensors.blurring_sigma_for_downsampling", "tuple", "ext.lab2im.edit_tensors.resample_tensor", "numpy.insert", "numpy.insert", "list", "list", "ext.lab2im.layers.PadAroundCentre", "labels.get_shape", "KL.Input.get_shape().as_list", "ext.lab2im.layers.RandomCrop", "ext.lab2im.layers.RandomCrop", "KL.Input.get_shape().as_list", "ext.lab2im.layers.RandomFlip", "ext.lab2im.layers.RandomFlip", "labels.get_shape", "et.resample_tensor.get_shape().as_list", "ext.lab2im.layers.BiasFieldCorruption", "list.append", "tuple", "et.resample_tensor.get_shape().as_list", "numpy.array", "ext.lab2im.edit_tensors.blurring_sigma_for_downsampling", "ext.lab2im.edit_tensors.blurring_sigma_for_downsampling", "tuple", "tuple", "list.append", "et.resample_tensor.get_shape().as_list", "ext.lab2im.layers.GaussianBlur", "len", "keras.Lambda", "tensorflow.cast", "labels.get_shape", "KL.Input.get_shape", "labels.get_shape", "labels.get_shape", "tensorflow.split", "et.resample_tensor.get_shape", "et.resample_tensor.get_shape", "ext.lab2im.edit_tensors.blurring_sigma_for_downsampling", "tuple", "ext.lab2im.edit_tensors.resample_tensor", "et.resample_tensor.get_shape().as_list", "keras.Lambda", "keras.Lambda", "keras.Lambda", "ext.neuron.layers.SpatialTransformer", "ext.lab2im.layers.SampleResolution", "ext.lab2im.layers.DynamicGaussianBlur", "ext.lab2im.layers.MimicAcquisition", "ext.lab2im.layers.GaussianBlur", "ext.lab2im.edit_tensors.resample_tensor", "ext.lab2im.edit_tensors.resample_tensor", "et.resample_tensor.get_shape().as_list", "keras.Lambda", "keras.Lambda", "ext.neuron.layers.SpatialTransformer", "rel_map.get_shape().as_list", "ext.neuron.layers.SpatialTransformer", "tensorflow.concat", "KL.Input.get_shape", "KL.Input.get_shape", "KL.Input.get_shape", "ext.lab2im.edit_volumes.get_ras_axes", "ext.lab2im.edit_volumes.get_ras_axes", "et.resample_tensor.get_shape", "et.resample_tensor.get_shape().as_list", "ext.lab2im.layers.GaussianBlur", "et.resample_tensor.get_shape", "et.resample_tensor.get_shape", "tensorflow.concat", "et.resample_tensor.get_shape", "ext.lab2im.utils.sample_affine_transform", "tensorflow.linalg.inv", "numpy.array", "et.resample_tensor.get_shape", "ext.lab2im.utils.sample_affine_transform", "tensorflow.matmul", "rel_map.get_shape", "et.resample_tensor.get_shape", "tensorflow.split", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_n_channels_array", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.lab2im_model.get_shapes", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_n_channels_array", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_n_channels_array", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_n_channels_array", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.blurring_sigma_for_downsampling", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.resample_tensor", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.blurring_sigma_for_downsampling", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.blurring_sigma_for_downsampling", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.blurring_sigma_for_downsampling", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.resample_tensor", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.resample_tensor", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.resample_tensor", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_ras_axes", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_ras_axes", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.sample_affine_transform", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.sample_affine_transform"], ["def", "labels_to_image_model", "(", "labels_shape", ",", "\n", "input_channels", ",", "\n", "output_channel", ",", "\n", "generation_labels", ",", "\n", "n_neutral_labels", ",", "\n", "atlas_res", ",", "\n", "target_res", ",", "\n", "output_shape", "=", "None", ",", "\n", "output_div_by_n", "=", "None", ",", "\n", "padding_margin", "=", "None", ",", "\n", "flipping", "=", "True", ",", "\n", "aff", "=", "None", ",", "\n", "scaling_bounds", "=", "0.15", ",", "\n", "rotation_bounds", "=", "15", ",", "\n", "shearing_bounds", "=", "0.012", ",", "\n", "translation_bounds", "=", "False", ",", "\n", "nonlin_std", "=", "3.", ",", "\n", "nonlin_shape_factor", "=", ".0625", ",", "\n", "simulate_registration_error", "=", "True", ",", "\n", "randomise_res", "=", "False", ",", "\n", "data_res", "=", "None", ",", "\n", "thickness", "=", "None", ",", "\n", "downsample", "=", "False", ",", "\n", "build_reliability_maps", "=", "False", ",", "\n", "blur_range", "=", "1.15", ",", "\n", "bias_field_std", "=", ".3", ",", "\n", "bias_shape_factor", "=", ".025", ")", ":", "\n", "    ", "\"\"\"\n    This is used for imputation (and possibly synthesis)\n    - the target is a crisp image\n    - some channels may only be inputs, and some only targets\n    - the target can be a separate real scan\n    - it produces additional volumes that tell whether a modality is measured or interpolated at every location\n    - models the fact that registration may be needed to bring images into alignment (i.e., acquisitions are not\n      perfectly parallel / ortoghonal)\n    \"\"\"", "\n", "\n", "# vector indicating which synthetic channels will be used as inputs to the UNet", "\n", "n_channels", "=", "len", "(", "input_channels", ")", "\n", "use_real_image", "=", "False", "if", "output_channel", "is", "not", "None", "else", "True", "\n", "idx_first_input_channel", "=", "np", ".", "argmax", "(", "input_channels", ")", "\n", "\n", "# if only 1 value is given for simulate_registration_error, then replicate for all channels", "\n", "simulate_registration_error", "=", "utils", ".", "reformat_to_list", "(", "simulate_registration_error", ",", "length", "=", "n_channels", ")", "\n", "\n", "# reformat resolutions", "\n", "# insert dummy slice spacing/thickness for the indices in output_channel, if the corrupted versions of the same", "\n", "# channels are not used as inputs. The dummy values won't be used, as synthetic regression targets are not", "\n", "# downsampled before being resampled to target resolution. We only insert these dummy values for slice", "\n", "# spacing/thickness since an index referring to all channels (input/output) will be used on these two variables.", "\n", "labels_shape", "=", "utils", ".", "reformat_to_list", "(", "labels_shape", ")", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "labels_shape", ")", "\n", "atlas_res", "=", "utils", ".", "reformat_to_n_channels_array", "(", "atlas_res", ",", "n_dims", ",", "n_channels", ")", "\n", "if", "output_channel", "is", "not", "None", ":", "\n", "        ", "for", "idx", "in", "output_channel", ":", "\n", "            ", "if", "not", "input_channels", "[", "idx", "]", ":", "\n", "                ", "data_res", "=", "np", ".", "insert", "(", "data_res", ",", "idx", ",", "1", ",", "axis", "=", "0", ")", "\n", "thickness", "=", "np", ".", "insert", "(", "thickness", ",", "idx", ",", "1", ",", "axis", "=", "0", ")", "\n", "", "", "", "data_res", "=", "atlas_res", "if", "data_res", "is", "None", "else", "utils", ".", "reformat_to_n_channels_array", "(", "data_res", ",", "n_dims", ",", "n_channels", ")", "\n", "thickness", "=", "data_res", "if", "thickness", "is", "None", "else", "utils", ".", "reformat_to_n_channels_array", "(", "thickness", ",", "n_dims", ",", "n_channels", ")", "\n", "downsample", "=", "utils", ".", "reformat_to_list", "(", "downsample", ",", "n_channels", ")", "if", "downsample", "else", "(", "np", ".", "min", "(", "thickness", "-", "data_res", ",", "1", ")", "<", "0", ")", "\n", "atlas_res", "=", "atlas_res", "[", "0", "]", "\n", "target_res", "=", "atlas_res", "if", "target_res", "is", "None", "else", "utils", ".", "reformat_to_n_channels_array", "(", "target_res", ",", "n_dims", ")", "[", "0", "]", "\n", "if", "isinstance", "(", "randomise_res", ",", "bool", ")", ":", "\n", "        ", "randomise_res", "=", "n_channels", "*", "[", "randomise_res", "]", "\n", "\n", "# get shapes", "\n", "", "crop_shape", ",", "output_shape", ",", "padding_margin", "=", "get_shapes", "(", "labels_shape", ",", "output_shape", ",", "atlas_res", ",", "target_res", ",", "\n", "padding_margin", ",", "output_div_by_n", ")", "\n", "\n", "# define model inputs", "\n", "labels_input", "=", "KL", ".", "Input", "(", "shape", "=", "labels_shape", "+", "[", "1", "]", ",", "name", "=", "'labels_input'", ",", "dtype", "=", "'int32'", ")", "\n", "means_input", "=", "KL", ".", "Input", "(", "shape", "=", "list", "(", "generation_labels", ".", "shape", ")", "+", "[", "n_channels", "]", ",", "name", "=", "'means_input'", ")", "\n", "stds_input", "=", "KL", ".", "Input", "(", "shape", "=", "list", "(", "generation_labels", ".", "shape", ")", "+", "[", "n_channels", "]", ",", "name", "=", "'std_devs_input'", ")", "\n", "list_inputs", "=", "[", "labels_input", ",", "means_input", ",", "stds_input", "]", "\n", "\n", "# add real image to input list if using real regression target", "\n", "if", "use_real_image", ":", "\n", "        ", "real_image", "=", "KL", ".", "Input", "(", "shape", "=", "labels_shape", "+", "[", "1", "]", ",", "dtype", "=", "'float32'", ",", "name", "=", "'real_image_input'", ")", "\n", "list_inputs", ".", "append", "(", "real_image", ")", "\n", "", "else", ":", "\n", "        ", "real_image", "=", "None", "\n", "\n", "# pad labels", "\n", "", "if", "padding_margin", "is", "not", "None", ":", "\n", "        ", "labels", "=", "layers", ".", "PadAroundCentre", "(", "pad_margin", "=", "padding_margin", ")", "(", "labels_input", ")", "\n", "labels_shape", "=", "labels", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "n_dims", "+", "1", "]", "\n", "if", "use_real_image", ":", "\n", "            ", "real_image", "=", "layers", ".", "PadAroundCentre", "(", "pad_margin", "=", "padding_margin", ")", "(", "real_image", ")", "\n", "", "", "else", ":", "\n", "        ", "labels", "=", "labels_input", "\n", "\n", "# deform labels", "\n", "", "labels", ".", "_keras_shape", "=", "tuple", "(", "labels", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "if", "use_real_image", ":", "\n", "        ", "real_image", ".", "_keras_shape", "=", "tuple", "(", "real_image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "labels", ",", "real_image", "=", "RandomSpatialDeformation", "(", "scaling_bounds", "=", "scaling_bounds", ",", "\n", "rotation_bounds", "=", "rotation_bounds", ",", "\n", "shearing_bounds", "=", "shearing_bounds", ",", "\n", "translation_bounds", "=", "translation_bounds", ",", "\n", "nonlin_std", "=", "nonlin_std", ",", "\n", "nonlin_shape_factor", "=", "nonlin_shape_factor", ",", "\n", "inter_method", "=", "[", "'nearest'", ",", "'linear'", "]", ")", "(", "[", "labels", ",", "real_image", "]", ")", "\n", "", "else", ":", "\n", "        ", "labels", "=", "RandomSpatialDeformation", "(", "scaling_bounds", "=", "scaling_bounds", ",", "\n", "rotation_bounds", "=", "rotation_bounds", ",", "\n", "shearing_bounds", "=", "shearing_bounds", ",", "\n", "translation_bounds", "=", "translation_bounds", ",", "\n", "nonlin_std", "=", "nonlin_std", ",", "\n", "nonlin_shape_factor", "=", "nonlin_shape_factor", ",", "\n", "inter_method", "=", "'nearest'", ")", "(", "labels", ")", "\n", "\n", "# cropping", "\n", "", "if", "crop_shape", "!=", "labels_shape", ":", "\n", "        ", "labels", ".", "_keras_shape", "=", "tuple", "(", "labels", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "if", "use_real_image", ":", "\n", "            ", "real_image", ".", "_keras_shape", "=", "tuple", "(", "real_image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "labels", ",", "real_image", "=", "layers", ".", "RandomCrop", "(", "crop_shape", ")", "(", "[", "labels", ",", "real_image", "]", ")", "\n", "", "else", ":", "\n", "            ", "labels", "=", "layers", ".", "RandomCrop", "(", "crop_shape", ")", "(", "labels", ")", "\n", "\n", "# flipping", "\n", "", "", "if", "flipping", ":", "\n", "        ", "assert", "aff", "is", "not", "None", ",", "'aff should not be None if flipping is True'", "\n", "labels", ".", "_keras_shape", "=", "tuple", "(", "labels", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "if", "use_real_image", ":", "\n", "            ", "real_image", ".", "_keras_shape", "=", "tuple", "(", "real_image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "labels", ",", "real_image", "=", "RandomFlip", "(", "get_ras_axes", "(", "aff", ",", "n_dims", ")", "[", "0", "]", ",", "True", ",", "generation_labels", ",", "\n", "n_neutral_labels", ")", "(", "[", "labels", ",", "real_image", "]", ")", "\n", "", "else", ":", "\n", "            ", "labels", "=", "RandomFlip", "(", "get_ras_axes", "(", "aff", ",", "n_dims", ")", "[", "0", "]", ",", "True", ",", "generation_labels", ",", "n_neutral_labels", ")", "(", "labels", ")", "\n", "\n", "# build synthetic image", "\n", "", "", "labels", ".", "_keras_shape", "=", "tuple", "(", "labels", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "image", "=", "layers", ".", "SampleConditionalGMM", "(", "generation_labels", ")", "(", "[", "labels", ",", "means_input", ",", "stds_input", "]", ")", "\n", "\n", "# give name to output labels", "\n", "labels", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", ",", "name", "=", "'segmentation_target'", ")", "(", "labels", ")", "\n", "\n", "# loop over synthetic channels", "\n", "channels", "=", "list", "(", ")", "\n", "targets", "=", "list", "(", ")", "\n", "split", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "split", "(", "x", ",", "[", "1", "]", "*", "n_channels", ",", "axis", "=", "-", "1", ")", ")", "(", "image", ")", "if", "(", "n_channels", ">", "1", ")", "else", "[", "image", "]", "\n", "for", "i", ",", "channel", "in", "enumerate", "(", "split", ")", ":", "\n", "\n", "# apply bias field", "\n", "        ", "if", "input_channels", "[", "i", "]", ":", "\n", "            ", "channel", ".", "_keras_shape", "=", "tuple", "(", "channel", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "channel", "=", "layers", ".", "BiasFieldCorruption", "(", "bias_field_std", ",", "bias_shape_factor", ",", "False", ")", "(", "channel", ")", "\n", "\n", "# intensity augmentation", "\n", "", "channel", ".", "_keras_shape", "=", "tuple", "(", "channel", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "channel", "=", "layers", ".", "IntensityAugmentation", "(", "clip", "=", "300", ",", "normalise", "=", "True", ",", "gamma_std", "=", ".5", ")", "(", "channel", ")", "\n", "channel", ".", "_keras_shape", "=", "tuple", "(", "channel", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "channel", "=", "layers", ".", "GaussianBlur", "(", "sigma", "=", ".5", ")", "(", "channel", ")", "\n", "\n", "# resample regression target at target resolution if needed", "\n", "if", "not", "use_real_image", ":", "\n", "            ", "if", "any", "(", "c", "==", "i", "for", "c", "in", "output_channel", ")", ":", "\n", "                ", "if", "crop_shape", "!=", "output_shape", ":", "\n", "                    ", "sigma", "=", "et", ".", "blurring_sigma_for_downsampling", "(", "atlas_res", ",", "target_res", ")", "\n", "channel", ".", "_keras_shape", "=", "tuple", "(", "channel", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "channel", "=", "layers", ".", "GaussianBlur", "(", "sigma", ")", "(", "channel", ")", "\n", "channel", "=", "et", ".", "resample_tensor", "(", "channel", ",", "output_shape", ")", "\n", "", "targets", ".", "append", "(", "channel", ")", "\n", "\n", "# synthetic input channels", "\n", "", "", "if", "input_channels", "[", "i", "]", ":", "\n", "\n", "# simulate registration error relatively to the first channel (so this does not apply to the first channel)", "\n", "            ", "if", "simulate_registration_error", "[", "i", "]", "&", "(", "i", "!=", "idx_first_input_channel", ")", ":", "\n", "                ", "channel", ".", "_keras_shape", "=", "tuple", "(", "channel", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "batchsize", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "split", "(", "tf", ".", "shape", "(", "x", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", ")", "(", "channel", ")", "\n", "T", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "utils", ".", "sample_affine_transform", "(", "x", ",", "n_dims", ",", "rotation_bounds", "=", "5", ",", "\n", "translation_bounds", "=", "5", ")", ")", "(", "batchsize", ")", "\n", "Tinv", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "linalg", ".", "inv", "(", "x", ")", ")", "(", "T", ")", "\n", "channel", "=", "nrn_layers", ".", "SpatialTransformer", "(", "interp_method", "=", "'linear'", ")", "(", "[", "channel", ",", "T", "]", ")", "\n", "", "else", ":", "\n", "                ", "Tinv", "=", "batchsize", "=", "None", "\n", "\n", "", "channel", ".", "_keras_shape", "=", "tuple", "(", "channel", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "\n", "# blur and downsample channel", "\n", "if", "randomise_res", "[", "i", "]", ":", "\n", "                ", "max_res", "=", "np", ".", "array", "(", "[", "9.", "]", "*", "3", ")", "\n", "resolution", ",", "blur_res", "=", "layers", ".", "SampleResolution", "(", "atlas_res", ",", "max_res", ")", "(", "means_input", ")", "\n", "sigma", "=", "et", ".", "blurring_sigma_for_downsampling", "(", "atlas_res", ",", "resolution", ",", "mult_coef", "=", ".42", ",", "thickness", "=", "blur_res", ")", "\n", "channel", "=", "layers", ".", "DynamicGaussianBlur", "(", "0.75", "*", "max_res", "/", "np", ".", "array", "(", "atlas_res", ")", ",", "blur_range", ")", "(", "[", "channel", ",", "sigma", "]", ")", "\n", "channel", ",", "rel_map", "=", "MimicAcquisition", "(", "atlas_res", ",", "atlas_res", ",", "output_shape", ",", "True", ")", "(", "[", "channel", ",", "resolution", "]", ")", "\n", "\n", "", "else", ":", "\n", "                ", "sigma", "=", "et", ".", "blurring_sigma_for_downsampling", "(", "atlas_res", ",", "data_res", "[", "i", "]", ",", ".42", ",", "thickness", "[", "i", "]", ")", "\n", "channel", "=", "layers", ".", "GaussianBlur", "(", "sigma", ",", "blur_range", ")", "(", "channel", ")", "\n", "if", "downsample", "[", "i", "]", ":", "\n", "                    ", "channel", ",", "rel_map", "=", "et", ".", "resample_tensor", "(", "channel", ",", "output_shape", ",", "'linear'", ",", "data_res", "[", "i", "]", ",", "atlas_res", ",", "True", ")", "\n", "", "else", ":", "\n", "                    ", "channel", ",", "rel_map", "=", "et", ".", "resample_tensor", "(", "channel", ",", "output_shape", ",", "build_reliability_map", "=", "True", ")", "\n", "\n", "# align the channels back to the first one with a small error", "\n", "", "", "if", "simulate_registration_error", "[", "i", "]", "&", "(", "i", "!=", "idx_first_input_channel", ")", ":", "\n", "                ", "channel", ".", "_keras_shape", "=", "tuple", "(", "channel", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "Terr", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "utils", ".", "sample_affine_transform", "(", "x", ",", "n_dims", ",", "rotation_bounds", "=", ".5", ",", "\n", "translation_bounds", "=", ".5", ")", ")", "(", "batchsize", ")", "\n", "Tinv_err", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "matmul", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", ")", "(", "[", "Terr", ",", "Tinv", "]", ")", "\n", "channel", "=", "nrn_layers", ".", "SpatialTransformer", "(", "interp_method", "=", "'linear'", ")", "(", "[", "channel", ",", "Tinv_err", "]", ")", "\n", "rel_map", ".", "_keras_shape", "=", "tuple", "(", "rel_map", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "rel_map", "=", "nrn_layers", ".", "SpatialTransformer", "(", "interp_method", "=", "'linear'", ")", "(", "[", "rel_map", ",", "Tinv_err", "]", ")", "\n", "\n", "", "channels", ".", "append", "(", "channel", ")", "\n", "if", "build_reliability_maps", ":", "\n", "                ", "channels", ".", "append", "(", "rel_map", ")", "\n", "\n", "# concatenate all channels back", "\n", "", "", "", "image", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "concat", "(", "x", ",", "-", "1", ")", ")", "(", "channels", ")", "if", "len", "(", "channels", ")", ">", "1", "else", "channels", "[", "0", "]", "\n", "\n", "# if no synthetic image is used as regression target, we need to assign the real image to the target!", "\n", "if", "use_real_image", ":", "\n", "        ", "real_image", ".", "_keras_shape", "=", "tuple", "(", "real_image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "target", "=", "layers", ".", "IntensityAugmentation", "(", "normalise", "=", "True", ")", "(", "real_image", ")", "\n", "if", "crop_shape", "!=", "output_shape", ":", "\n", "            ", "sigma", "=", "et", ".", "blurring_sigma_for_downsampling", "(", "atlas_res", ",", "target_res", ")", "\n", "target", ".", "_keras_shape", "=", "tuple", "(", "target", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "target", "=", "layers", ".", "GaussianBlur", "(", "sigma", ")", "(", "target", ")", "\n", "target", "=", "et", ".", "resample_tensor", "(", "target", ",", "output_shape", ")", "\n", "", "", "else", ":", "\n", "        ", "target", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "concat", "(", "x", ",", "axis", "=", "-", "1", ")", ")", "(", "targets", ")", "if", "len", "(", "targets", ")", ">", "1", "else", "targets", "[", "0", "]", "\n", "", "target", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "cast", "(", "x", "[", "0", "]", ",", "dtype", "=", "'float32'", ")", ",", "name", "=", "'regression_target'", ")", "(", "[", "target", ",", "labels", "]", ")", "\n", "\n", "# build model (dummy layer enables to keep the target when plugging this model to other models)", "\n", "image", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "0", "]", ",", "name", "=", "'image_out'", ")", "(", "[", "image", ",", "target", "]", ")", "\n", "brain_model", "=", "Model", "(", "inputs", "=", "list_inputs", ",", "outputs", "=", "[", "image", ",", "target", "]", ")", "\n", "\n", "return", "brain_model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.labels_to_image_model.get_shapes": [[267, 334], ["ext.lab2im.utils.reformat_to_list", "len", "ext.lab2im.utils.reformat_to_list", "ext.lab2im.utils.reformat_to_list", "ext.lab2im.utils.reformat_to_list", "range", "float", "range", "min", "min", "ext.lab2im.utils.find_closest_number_divisible_by_m", "print", "int", "int", "range", "range", "numpy.around", "range", "int", "ext.lab2im.utils.find_closest_number_divisible_by_m", "int", "ext.lab2im.utils.find_closest_number_divisible_by_m", "int", "range", "numpy.around", "range", "range"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.find_closest_number_divisible_by_m", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.find_closest_number_divisible_by_m", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.find_closest_number_divisible_by_m", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "get_shapes", "(", "labels_shape", ",", "output_shape", ",", "atlas_res", ",", "target_res", ",", "padding_margin", ",", "output_div_by_n", ")", ":", "\n", "\n", "# reformat resolutions to lists", "\n", "    ", "atlas_res", "=", "utils", ".", "reformat_to_list", "(", "atlas_res", ")", "\n", "n_dims", "=", "len", "(", "atlas_res", ")", "\n", "target_res", "=", "utils", ".", "reformat_to_list", "(", "target_res", ")", "\n", "\n", "# get new labels shape if padding", "\n", "if", "padding_margin", "is", "not", "None", ":", "\n", "        ", "padding_margin", "=", "utils", ".", "reformat_to_list", "(", "padding_margin", ",", "length", "=", "n_dims", ",", "dtype", "=", "'int'", ")", "\n", "labels_shape", "=", "[", "labels_shape", "[", "i", "]", "+", "2", "*", "padding_margin", "[", "i", "]", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "\n", "# get resampling factor", "\n", "", "if", "atlas_res", "!=", "target_res", ":", "\n", "        ", "resample_factor", "=", "[", "atlas_res", "[", "i", "]", "/", "float", "(", "target_res", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "", "else", ":", "\n", "        ", "resample_factor", "=", "None", "\n", "\n", "# output shape specified, need to get cropping shape, and resample shape if necessary", "\n", "", "if", "output_shape", "is", "not", "None", ":", "\n", "        ", "output_shape", "=", "utils", ".", "reformat_to_list", "(", "output_shape", ",", "length", "=", "n_dims", ",", "dtype", "=", "'int'", ")", "\n", "\n", "# make sure that output shape is smaller or equal to label shape", "\n", "if", "resample_factor", "is", "not", "None", ":", "\n", "            ", "output_shape", "=", "[", "min", "(", "int", "(", "labels_shape", "[", "i", "]", "*", "resample_factor", "[", "i", "]", ")", ",", "output_shape", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "", "else", ":", "\n", "            ", "output_shape", "=", "[", "min", "(", "labels_shape", "[", "i", "]", ",", "output_shape", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "\n", "# make sure output shape is divisible by output_div_by_n", "\n", "", "if", "output_div_by_n", "is", "not", "None", ":", "\n", "            ", "tmp_shape", "=", "[", "utils", ".", "find_closest_number_divisible_by_m", "(", "s", ",", "output_div_by_n", ")", "for", "s", "in", "output_shape", "]", "\n", "if", "output_shape", "!=", "tmp_shape", ":", "\n", "                ", "print", "(", "'output shape {0} not divisible by {1}, changed to {2}'", ".", "format", "(", "output_shape", ",", "output_div_by_n", ",", "\n", "tmp_shape", ")", ")", "\n", "output_shape", "=", "tmp_shape", "\n", "\n", "# get cropping and resample shape", "\n", "", "", "if", "resample_factor", "is", "not", "None", ":", "\n", "            ", "cropping_shape", "=", "[", "int", "(", "np", ".", "around", "(", "output_shape", "[", "i", "]", "/", "resample_factor", "[", "i", "]", ",", "0", ")", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "", "else", ":", "\n", "            ", "cropping_shape", "=", "output_shape", "\n", "\n", "# no output shape specified, so no cropping unless label_shape is not divisible by output_div_by_n", "\n", "", "", "else", ":", "\n", "\n", "# make sure output shape is divisible by output_div_by_n", "\n", "        ", "if", "output_div_by_n", "is", "not", "None", ":", "\n", "\n", "# if resampling, get the potential output_shape and check if it is divisible by n", "\n", "            ", "if", "resample_factor", "is", "not", "None", ":", "\n", "                ", "output_shape", "=", "[", "int", "(", "labels_shape", "[", "i", "]", "*", "resample_factor", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "output_shape", "=", "[", "utils", ".", "find_closest_number_divisible_by_m", "(", "s", ",", "output_div_by_n", ")", "for", "s", "in", "output_shape", "]", "\n", "cropping_shape", "=", "[", "int", "(", "np", ".", "around", "(", "output_shape", "[", "i", "]", "/", "resample_factor", "[", "i", "]", ",", "0", ")", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "# if no resampling, simply check if image_shape is divisible by n", "\n", "", "else", ":", "\n", "                ", "cropping_shape", "=", "[", "utils", ".", "find_closest_number_divisible_by_m", "(", "s", ",", "output_div_by_n", ")", "for", "s", "in", "labels_shape", "]", "\n", "output_shape", "=", "cropping_shape", "\n", "\n", "# if no need to be divisible by n, simply take cropping_shape as image_shape, and build output_shape", "\n", "", "", "else", ":", "\n", "            ", "cropping_shape", "=", "labels_shape", "\n", "if", "resample_factor", "is", "not", "None", ":", "\n", "                ", "output_shape", "=", "[", "int", "(", "cropping_shape", "[", "i", "]", "*", "resample_factor", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "", "else", ":", "\n", "                ", "output_shape", "=", "cropping_shape", "\n", "\n", "", "", "", "return", "cropping_shape", ",", "output_shape", ",", "padding_margin", "\n", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.training.training": [[38, 413], ["len", "ext.lab2im.utils.get_list_labels", "ext.lab2im.utils.mkdir", "brain_generator.BrainGenerator", "ext.neuron.models.unet", "ext.lab2im.utils.build_training_generator", "keras.models.Model", "metrics_model.metrics_model", "training.train_model", "ext.lab2im.utils.reformat_to_list", "list", "len", "Exception", "any", "ext.lab2im.utils.reformat_to_list", "any", "print", "metrics_model.add_seg_loss_to_model.load_weights", "numpy.load", "ext.neuron.models.unet", "nrn_models.unet.load_weights", "metrics_model.add_seg_loss_to_model", "ext.lab2im.utils.reformat_to_list", "Exception", "Exception", "Exception", "ext.lab2im.utils.get_padding_margin", "ext.lab2im.utils.load_volume().flatten", "numpy.percentile", "numpy.percentile", "len", "len", "Exception", "len", "ext.lab2im.utils.list_images_in_folder", "ext.lab2im.utils.load_volume"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_list_labels", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.unet", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.build_training_generator", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.metrics_model.metrics_model", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.training.train_model", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.unet", "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.metrics_model.add_seg_loss_to_model", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_padding_margin", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.flatten", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume"], ["def", "training", "(", "labels_dir", ",", "\n", "model_dir", ",", "\n", "prior_means", ",", "\n", "prior_stds", ",", "\n", "path_generation_labels", ",", "\n", "segmentation_label_list", "=", "None", ",", "\n", "segmentation_label_equivalency", "=", "None", ",", "\n", "segmentation_model_file", "=", "None", ",", "\n", "fs_header_segnet", "=", "False", ",", "\n", "relative_weight_segmentation", "=", "0.25", ",", "\n", "prior_distributions", "=", "'normal'", ",", "\n", "images_dir", "=", "None", ",", "\n", "path_generation_classes", "=", "None", ",", "\n", "FS_sort", "=", "True", ",", "\n", "batchsize", "=", "1", ",", "\n", "input_channels", "=", "True", ",", "\n", "output_channel", "=", "0", ",", "\n", "target_res", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "flipping", "=", "True", ",", "\n", "padding_margin", "=", "None", ",", "\n", "scaling_bounds", "=", "0.15", ",", "\n", "rotation_bounds", "=", "15", ",", "\n", "shearing_bounds", "=", "0.02", ",", "\n", "translation_bounds", "=", "5", ",", "\n", "nonlin_std", "=", "4.", ",", "\n", "nonlin_shape_factor", "=", "0.03125", ",", "\n", "simulate_registration_error", "=", "True", ",", "\n", "data_res", "=", "None", ",", "\n", "thickness", "=", "None", ",", "\n", "randomise_res", "=", "None", ",", "\n", "downsample", "=", "True", ",", "\n", "blur_range", "=", "1.15", ",", "\n", "build_reliability_maps", "=", "True", ",", "\n", "bias_field_std", "=", ".3", ",", "\n", "bias_shape_factor", "=", "0.03125", ",", "\n", "n_levels", "=", "5", ",", "\n", "nb_conv_per_level", "=", "2", ",", "\n", "conv_size", "=", "3", ",", "\n", "unet_feat_count", "=", "24", ",", "\n", "feat_multiplier", "=", "2", ",", "\n", "dropout", "=", "0", ",", "\n", "activation", "=", "'elu'", ",", "\n", "lr", "=", "1e-4", ",", "\n", "lr_decay", "=", "0", ",", "\n", "epochs", "=", "100", ",", "\n", "steps_per_epoch", "=", "1000", ",", "\n", "regression_metric", "=", "'l1'", ",", "\n", "work_with_residual_channel", "=", "None", ",", "\n", "loss_cropping", "=", "None", ",", "\n", "checkpoint", "=", "None", ",", "\n", "model_file_has_different_lhood_layer", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    This function trains a Unet to do slice imputation (and possibly synthesis) of MRI images with thick slices,\n    using synthetic scans and possibly real scans.\n\n    :param labels_dir: path of folder with all input label maps, or to a single label map (if only one training example)\n    :param model_dir: path of a directory where the models will be saved during training.\n    :param images_dir: directory with real images corresponding to the training label maps. These will be taken as\n    regression target. We recommend skull stripping them.\n\n    #---------------------------------------------- Generation parameters ----------------------------------------------\n    # label maps parameters\n    :param path_generation_labels: list of all possible label values in the input label maps.\n    Must be the path to a 1d numpy array, which should be organised as follows: background label first, then non-sided\n    labels (e.g. CSF, brainstem, etc.), then all the structures of the same hemisphere (can be left or right), and\n    finally all the corresponding contralateral structures (in the same order).\n    Example: [background_label, non-sided_1, ..., non-sided_n, left_1, ..., left_m, right_1, ..., right_m]\n    :param FS_sort: whether us FS_sort when creating list of labels with utils.get_list_labels. Default is True.\n\n    # output-related parameters\n    :param batchsize: (optional) number of images to generate per mini-batch. Default is 1.\n    :param input_channels: (optional) list of booleans indicating if each *synthetic* channel is going to be used as an\n    input for the downstream network. This also enables to know how many channels are going to be synthesised. Default\n    is True, which means generating 1 channel, and use it as input (either for plain SR with a synthetic target, or for\n    synthesis with a real target).\n    :param output_channel: (optional) a list with the indices of the output channels  (i.e. the synthetic regression\n    targets), if no real images were provided as regression target. Set to None if using real images as targets. Default\n    is the first channel (index 0).\n    :param target_res: (optional) target resolution of the generated images and corresponding label maps.\n    If None, the outputs will have the same resolution as the input label maps.\n    Can be a number (isotropic resolution), or the path to a 1d numpy array.\n    :param output_shape: (optional) desired shape of the output image, obtained by randomly cropping the generated image\n    Can be an integer (same size in all dimensions), a sequence, a 1d numpy array, or the path to a 1d numpy array.\n    Default is None, where no cropping is performed.\n\n    # GMM-sampling parameters\n    :param path_generation_classes: (optional) Indices regrouping generation labels into classes of same intensity\n    distribution. Regouped labels will thus share the same Gaussian when samling a new image. Should be the path to a 1d\n    numpy array with the same length as generation_labels. and contain values between 0 and K-1, where K is the total\n    number of classes. Default is all labels have different classes.\n    :param prior_distributions: (optional) type of distribution from which we sample the GMM parameters.\n    Can either be 'uniform', or 'normal'. Default is 'normal'.\n    :param prior_means: (optional) hyperparameters controlling the prior distributions of the GMM means. Because\n    these prior distributions are uniform or normal, they require by 2 hyperparameters. Can be a path to:\n    1) an array of shape (2, K), where K is the number of classes (K=len(generation_labels) if generation_classes is\n    not given). The mean of the Gaussian distribution associated to class k in [0, ...K-1] is sampled at each mini-batch\n    from U(prior_means[0,k], prior_means[1,k]) if prior_distributions is uniform, and from\n    N(prior_means[0,k], prior_means[1,k]) if prior_distributions is normal.\n    2) an array of shape (2*n_mod, K), where each block of two rows is associated to hyperparameters derived\n    from different modalities. In this case, if use_specific_stats_for_channel is False, we first randomly select a\n    modality from the n_mod possibilities, and we sample the GMM means like in 2).\n    If use_specific_stats_for_channel is True, each block of two rows correspond to a different channel\n    (n_mod=n_channels), thus we select the corresponding block to each channel rather than randomly drawing it.\n    Default is None, which corresponds all GMM means sampled from uniform distribution U(25, 225).\n    :param prior_stds: (optional) same as prior_means but for the standard deviations of the GMM.\n    Default is None, which corresponds to U(5, 25).\n\n    # spatial deformation parameters\n    :param flipping: (optional) whether to introduce right/left random flipping. Default is True.\n    :param  padding_margin: useful when cropping the loss but you are not using very large patches. Set to None for\n    determining it automatically from loss_cropping (not recommended if you use big volume sizes)\n    :param scaling_bounds: (optional) if apply_linear_trans is True, the scaling factor for each dimension is\n    sampled from a uniform distribution of predefined bounds. Can either be:\n    1) a number, in which case the scaling factor is independently sampled from the uniform distribution of bounds\n    (1-scaling_bounds, 1+scaling_bounds) for each dimension.\n    2) the path to a numpy array of shape (2, n_dims), in which case the scaling factor in dimension i is sampled from\n    the uniform distribution of bounds (scaling_bounds[0, i], scaling_bounds[1, i]) for the i-th dimension.\n    3) False, in which case scaling is completely turned off.\n    Default is scaling_bounds = 0.15 (case 1)\n    :param rotation_bounds: (optional) same as scaling bounds but for the rotation angle, except that for case 1 the\n    bounds are centred on 0 rather than 1, i.e. (0+rotation_bounds[i], 0-rotation_bounds[i]).\n    Default is rotation_bounds = 15.\n    :param shearing_bounds: (optional) same as scaling bounds. Default is shearing_bounds = 0.012.\n    :param translation_bounds: (optional) same as scaling bounds. Default is translation_bounds = False, but we\n    encourage using it when cropping is deactivated (i.e. when output_shape=None).\n    :param nonlin_std: (optional) Standard deviation of the normal distribution from which we sample the first\n    tensor for synthesising the deformation field. Set to 0 to completely turn the elastic deformation off.\n    :param nonlin_shape_factor: (optional) Ratio between the size of the input label maps and the size of the sampled\n    tensor for synthesising the elastic deformation field.\n    :param simulate_registration_error: (optional) whether to simulate registration errors between *synthetic* channels.\n    Can be a single value (same for all channels) or a list with one value per *synthetic* channel. For the latter,\n    the first value will automatically be reset to True since the first channel is used as reference. Default is True.\n\n    # blurring/resampling parameters\n    :param randomise_res: (optional) whether to mimic images that would have been 1) acquired at low resolution, and\n    2) resampled to high resolution. The low resolution is uniformly sampled at each minibatch from [1mm, 9mm].\n    In that process, the images generated by sampling the GMM are: 1) blurred at LR, 2) downsampled at LR, and\n    3) resampled at target_resolution.\n    :param data_res: (optional) specific acquisition resolution to mimic, as opposed to random resolution sampled when\n    randomis_res is True. This triggers a blurring which mimics the acquisition resolution, but downsampling is optional\n    (see param downsample). Default for data_res is None, where images are slighlty blurred. If the generated images are\n    uni-modal, data_res can be a number (isotropic acquisition resolution), a sequence, a 1d numpy array, or the path\n    to a 1d numy array. In the multi-modal case, it should be given as a umpy array (or a path) of size (n_mod, n_dims),\n    where each row is the acquisition resolution of the corresponding channel.\n    :param thickness: (optional) if data_res is provided, we can further specify the slice thickness of the low\n    resolution images to mimic. Must be provided in the same format as data_res. Default thickness = data_res.\n    :param downsample: (optional) whether to actually downsample the volume images to data_res after blurring.\n    Default is False, except when thickness is provided, and thickness < data_res.\n    :param blur_range: (optional) Randomise the standard deviation of the blurring kernels, (whether data_res is given\n    or not). At each mini_batch, the standard deviation of the blurring kernels are multiplied by a coefficient sampled\n    from a uniform distribution with bounds [1/blur_range, blur_range]. If None, no randomisation. Default is 1.15.\n    :param build_reliability_maps: set to True if you want to build soft masks indicating which voxels are\n    \"measured\" and which are interpolated\n\n    # bias field parameters\n    :param bias_field_std: (optional) If strictly positive, this triggers the corruption of synthesised images with a\n    bias field. This will only affect the input channels (i.e. not the synthetic regression target). The bias field is\n    obtained by sampling a first small tensor from a normal distribution, resizing it to full size, and rescaling it to\n    positive values by taking the voxel-wise exponential. bias_field_std designates the std dev of the normal\n    distribution from which we sample the first tensor. Set to 0 to completely deactivate biad field corruption.\n    :param bias_shape_factor: (optional) If bias_field_std is not False, this designates the ratio between the size of\n    the input label maps and the size of the first sampled tensor for synthesising the bias field.\n\n    # ------------------------------------------ UNet architecture parameters ------------------------------------------\n    :param n_levels: (optional) number of level for the Unet. Default is 5.\n    :param nb_conv_per_level: (optional) number of convolutional layers per level. Default is 2.\n    :param conv_size: (optional) size of the convolution kernels. Default is 2.\n    :param unet_feat_count: (optional) number of feature for the first layr of the Unet. Default is 24.\n    :param feat_multiplier: (optional) multiply the number of feature by this nummber at each new level. Default is 2.\n    :param dropout: (optional) probability of dropout for the Unet. Deafult is 0, where no dropout is applied.\n    :param activation: (optional) activation function. Can be 'elu', 'relu'.\n\n    # ----------------------------------------------- Training parameters ----------------------------------------------\n    :param lr: (optional) learning rate for the training. Default is 1e-4\n    :param lr_decay: (optional) learing rate decay. Default is 0, where no decay is applied.\n    :param epochs: (optional) number of epochs.\n    :param steps_per_epoch: (optional) number of steps per epoch. Default is 1000. Since no online validation is\n    possible, this is equivalent to the frequency at which the models are saved.\n    :param regression_metric: (optional) loss used in training. Can be 'l1' (default), 'l2', 'ssim', or 'laplace'\n    :param work_with_residual_channel: (optional) if you have a channel that is similar to the output (e.g., in\n    imputation), it is convenient to predict the residual, rather than the image from scratch. This parameter is a list\n    of indices of the synthetic channels you want to add the residual to (must have the same length as output_channels,\n    or have length equal to 1 if real images are used)\n    :param loss_cropping: (option)  to crop the posteriors when evaluating the loss function (specify the output size\n    Can be an int, or the path to a 1d numpy array.\n    :param checkpoint: (optional) path of an already saved model to load before starting the training.\n    :param model_file_has_different_lhood_layer: (optional) set to True if eg you're loading weights from a segmetation\n    (rather than SR/synthesis) net. Useful to use models pretrained with SynthSeg or different number of channels\n\n    # ----------------------------------------------- Regularize with pretrained segmentation CNN-----------------------\n    :param segmentation_model_file: (optional) h5 model file with the weights of the segmentation model. For now, we\n    assume a Unet architecture with the shame shape as the synthesis / SR Unet. Set to None not to use.\n    :param fs_header_segnet: set to True if the segmentation network expects data in FS orientation (rather than the\n    default diagonal voxel-to-ras matrix).\n    :param segmentation_label_list: (optional) npy/npz file with an array with the list of labels segmented by the Unet\n    :param segmentation_label_equivalency: (optional) npy/npz file with an array with as many elements as\n    segmentation_label_list, pinpointing to which generation labels the segmentation labels correspond (set to -1 if you\n    don't want to use a label in the loss). You can use this array e.g., to merge left and right structures, ignore\n    structures...\n    :param relative_weight_segmentation: (optional) relative weight of the Dice loss, compared with the image term loss\n    (eg., l1 or l2)\n    \"\"\"", "\n", "\n", "n_channels", "=", "len", "(", "utils", ".", "reformat_to_list", "(", "input_channels", ")", ")", "\n", "\n", "# convert output_channel and work_with_residual_channel to lists", "\n", "if", "output_channel", "is", "not", "None", ":", "\n", "        ", "output_channel", "=", "list", "(", "utils", ".", "reformat_to_list", "(", "output_channel", ")", ")", "\n", "n_output_channels", "=", "len", "(", "output_channel", ")", "\n", "", "else", ":", "\n", "        ", "n_output_channels", "=", "1", "\n", "\n", "# various checks", "\n", "", "if", "(", "images_dir", "is", "None", ")", "&", "(", "output_channel", "is", "None", ")", ":", "\n", "        ", "raise", "Exception", "(", "'please provide a value for output_channel or image_dir'", ")", "\n", "", "elif", "(", "images_dir", "is", "not", "None", ")", "&", "(", "output_channel", "is", "not", "None", ")", ":", "\n", "        ", "raise", "Exception", "(", "'please provide a value either for output_channel or image_dir, but not both at the same time'", ")", "\n", "", "if", "output_channel", "is", "not", "None", ":", "\n", "        ", "if", "any", "(", "x", ">=", "n_channels", "for", "x", "in", "output_channel", ")", ":", "\n", "            ", "raise", "Exception", "(", "'indices in output_channel cannot be greater than the total number of channels'", ")", "\n", "\n", "# check work_with_residual_channel", "\n", "", "", "if", "work_with_residual_channel", "is", "not", "None", ":", "\n", "        ", "work_with_residual_channel", "=", "utils", ".", "reformat_to_list", "(", "work_with_residual_channel", ")", "\n", "if", "output_channel", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "work_with_residual_channel", ")", "!=", "len", "(", "output_channel", ")", ":", "\n", "                ", "raise", "Exception", "(", "'The number or residual channels and output channels must be the same'", ")", "\n", "\n", "", "", "if", "any", "(", "x", ">=", "n_channels", "for", "x", "in", "work_with_residual_channel", ")", ":", "\n", "            ", "raise", "Exception", "(", "'indices in work_with_residual_channel cannot be greater than the total number of channels'", ")", "\n", "\n", "", "if", "build_reliability_maps", ":", "# consider indices of reliability maps", "\n", "            ", "work_with_residual_channel", "=", "2", "*", "work_with_residual_channel", "\n", "\n", "# get label lists", "\n", "", "", "generation_labels", ",", "n_neutral_labels", "=", "utils", ".", "get_list_labels", "(", "label_list", "=", "path_generation_labels", ",", "\n", "labels_dir", "=", "labels_dir", ",", "\n", "FS_sort", "=", "FS_sort", ")", "\n", "\n", "# prepare model folder", "\n", "utils", ".", "mkdir", "(", "model_dir", ")", "\n", "\n", "# compute padding_margin if needed", "\n", "if", "loss_cropping", "==", "0", ":", "\n", "        ", "padding_margin", "=", "None", "\n", "", "elif", "padding_margin", "is", "None", ":", "\n", "        ", "padding_margin", "=", "utils", ".", "get_padding_margin", "(", "output_shape", ",", "loss_cropping", ")", "\n", "\n", "# instantiate BrainGenerator object", "\n", "", "brain_generator", "=", "BrainGenerator", "(", "labels_dir", "=", "labels_dir", ",", "\n", "images_dir", "=", "images_dir", ",", "\n", "generation_labels", "=", "generation_labels", ",", "\n", "n_neutral_labels", "=", "n_neutral_labels", ",", "\n", "padding_margin", "=", "padding_margin", ",", "\n", "batchsize", "=", "batchsize", ",", "\n", "input_channels", "=", "input_channels", ",", "\n", "output_channel", "=", "output_channel", ",", "\n", "target_res", "=", "target_res", ",", "\n", "output_shape", "=", "output_shape", ",", "\n", "output_div_by_n", "=", "2", "**", "n_levels", ",", "\n", "generation_classes", "=", "path_generation_classes", ",", "\n", "prior_means", "=", "prior_means", ",", "\n", "prior_stds", "=", "prior_stds", ",", "\n", "prior_distributions", "=", "prior_distributions", ",", "\n", "flipping", "=", "flipping", ",", "\n", "scaling_bounds", "=", "scaling_bounds", ",", "\n", "rotation_bounds", "=", "rotation_bounds", ",", "\n", "shearing_bounds", "=", "shearing_bounds", ",", "\n", "translation_bounds", "=", "translation_bounds", ",", "\n", "nonlin_std", "=", "nonlin_std", ",", "\n", "nonlin_shape_factor", "=", "nonlin_shape_factor", ",", "\n", "simulate_registration_error", "=", "simulate_registration_error", ",", "\n", "randomise_res", "=", "randomise_res", ",", "\n", "data_res", "=", "data_res", ",", "\n", "thickness", "=", "thickness", ",", "\n", "downsample", "=", "downsample", ",", "\n", "blur_range", "=", "blur_range", ",", "\n", "build_reliability_maps", "=", "build_reliability_maps", ",", "\n", "bias_field_std", "=", "bias_field_std", ",", "\n", "bias_shape_factor", "=", "bias_shape_factor", ")", "\n", "\n", "# transformation model", "\n", "labels_to_image_model", "=", "brain_generator", ".", "labels_to_image_model", "\n", "unet_input_shape", "=", "brain_generator", ".", "model_output_shape", "\n", "\n", "# prepare the Unet model", "\n", "if", "regression_metric", "==", "'laplace'", ":", "\n", "        ", "nb_labels_unet", "=", "2", "*", "n_output_channels", "\n", "", "else", ":", "\n", "        ", "nb_labels_unet", "=", "n_output_channels", "\n", "\n", "", "model", "=", "nrn_models", ".", "unet", "(", "nb_features", "=", "unet_feat_count", ",", "\n", "input_shape", "=", "unet_input_shape", ",", "\n", "nb_levels", "=", "n_levels", ",", "\n", "conv_size", "=", "conv_size", ",", "\n", "nb_labels", "=", "nb_labels_unet", ",", "\n", "feat_mult", "=", "feat_multiplier", ",", "\n", "nb_conv_per_level", "=", "nb_conv_per_level", ",", "\n", "conv_dropout", "=", "dropout", ",", "\n", "final_pred_activation", "=", "'linear'", ",", "\n", "batch_norm", "=", "-", "1", ",", "\n", "activation", "=", "activation", ",", "\n", "input_model", "=", "labels_to_image_model", ")", "\n", "\n", "# input generator", "\n", "input_generator", "=", "utils", ".", "build_training_generator", "(", "brain_generator", ".", "model_inputs_generator", ",", "batchsize", ")", "\n", "\n", "# model", "\n", "model", "=", "models", ".", "Model", "(", "model", ".", "inputs", ",", "model", ".", "output", ")", "\n", "model", "=", "metrics_model", "(", "input_model", "=", "model", ",", "\n", "loss_cropping", "=", "loss_cropping", ",", "\n", "metrics", "=", "regression_metric", ",", "\n", "work_with_residual_channel", "=", "work_with_residual_channel", ")", "\n", "\n", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "print", "(", "'loading'", ",", "checkpoint", ")", "\n", "\n", "# If we are loading weights from a segmentation net, we temporarily change the names of the", "\n", "# likelihood and prediction layers", "\n", "if", "model_file_has_different_lhood_layer", ":", "\n", "            ", "for", "layer", "in", "model", ".", "layers", ":", "\n", "                ", "if", "layer", ".", "name", "==", "'unet_likelihood'", ":", "\n", "                    ", "layer", ".", "name", "=", "'unet_likelihood_'", "\n", "\n", "", "", "", "model", ".", "load_weights", "(", "checkpoint", ",", "by_name", "=", "True", ")", "\n", "\n", "# Undo the namge changes if needed", "\n", "if", "model_file_has_different_lhood_layer", ":", "\n", "            ", "for", "layer", "in", "model", ".", "layers", ":", "\n", "                ", "if", "layer", ".", "name", "==", "'unet_likelihood_'", ":", "\n", "                    ", "layer", ".", "name", "=", "'unet_likelihood'", "\n", "\n", "# Load pretrained segmentation CNN and add to the model, if needed", "\n", "", "", "", "", "if", "segmentation_model_file", "is", "not", "None", ":", "\n", "        ", "segmentation_labels", "=", "np", ".", "load", "(", "segmentation_label_list", ")", "\n", "seg_unet_model", "=", "nrn_models", ".", "unet", "(", "nb_features", "=", "unet_feat_count", ",", "\n", "input_shape", "=", "[", "*", "unet_input_shape", "[", ":", "-", "1", "]", ",", "1", "]", ",", "\n", "nb_levels", "=", "n_levels", ",", "\n", "conv_size", "=", "conv_size", ",", "\n", "nb_labels", "=", "len", "(", "segmentation_labels", ")", ",", "\n", "feat_mult", "=", "feat_multiplier", ",", "\n", "nb_conv_per_level", "=", "nb_conv_per_level", ",", "\n", "conv_dropout", "=", "dropout", ",", "\n", "final_pred_activation", "=", "'softmax'", ",", "\n", "batch_norm", "=", "-", "1", ",", "\n", "activation", "=", "activation", ",", "\n", "input_model", "=", "None", ")", "\n", "\n", "seg_unet_model", ".", "load_weights", "(", "segmentation_model_file", ",", "by_name", "=", "True", ")", "\n", "seg_unet_model", ".", "trainable", "=", "False", "\n", "for", "layer", "in", "seg_unet_model", ".", "layers", ":", "\n", "            ", "layer", ".", "trainable", "=", "False", "\n", "\n", "# To decide where to clip the synthesized images, we look at the 2nd and 98th percentiles of the first case", "\n", "", "if", "images_dir", "is", "None", ":", "\n", "            ", "m", "=", "M", "=", "None", "\n", "", "else", ":", "\n", "            ", "first_image", "=", "utils", ".", "list_images_in_folder", "(", "images_dir", ")", "[", "0", "]", "\n", "im", "=", "utils", ".", "load_volume", "(", "first_image", ",", "im_only", "=", "True", ")", ".", "flatten", "(", ")", "\n", "m", "=", "np", ".", "percentile", "(", "im", ",", "2", ")", "\n", "M", "=", "np", ".", "percentile", "(", "im", ",", "98", ")", "\n", "\n", "", "model", "=", "add_seg_loss_to_model", "(", "input_model", "=", "model", ",", "\n", "seg_model", "=", "seg_unet_model", ",", "\n", "generation_labels", "=", "generation_labels", ",", "\n", "segmentation_label_equivalency", "=", "segmentation_label_equivalency", ",", "\n", "rel_weight", "=", "relative_weight_segmentation", ",", "\n", "loss_cropping", "=", "loss_cropping", ",", "\n", "m", "=", "m", ",", "\n", "M", "=", "M", ",", "\n", "fs_header", "=", "fs_header_segnet", ")", "\n", "\n", "# train", "\n", "", "train_model", "(", "model", ",", "input_generator", ",", "lr", ",", "lr_decay", ",", "epochs", ",", "steps_per_epoch", ",", "model_dir", ",", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.SynthSR.training.train_model": [[415, 454], ["os.path.join", "ext.lab2im.utils.mkdir", "os.path.join", "models.load_model.fit_generator", "keras.ModelCheckpoint", "keras.TensorBoard", "int", "keras.models.load_model", "models.load_model.compile", "inspect.getmembers", "inspect.getmembers", "metrics_model.IdentityLoss", "keras.optimizers.Adam", "metrics_model.IdentityLoss"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir"], ["", "def", "train_model", "(", "model", ",", "\n", "generator", ",", "\n", "learning_rate", ",", "\n", "lr_decay", ",", "\n", "n_epochs", ",", "\n", "n_steps", ",", "\n", "model_dir", ",", "\n", "path_checkpoint", "=", "None", ")", ":", "\n", "\n", "# prepare log folder", "\n", "    ", "log_dir", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'logs'", ")", "\n", "utils", ".", "mkdir", "(", "log_dir", ")", "\n", "\n", "# model saving callback", "\n", "save_file_name", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'{epoch:03d}.h5'", ")", "\n", "callbacks", "=", "[", "KC", ".", "ModelCheckpoint", "(", "save_file_name", ",", "verbose", "=", "1", ")", ",", "\n", "KC", ".", "TensorBoard", "(", "log_dir", "=", "log_dir", ",", "histogram_freq", "=", "0", ",", "write_graph", "=", "True", ",", "write_images", "=", "False", ")", "]", "\n", "\n", "# load checkpoint if provided (no need to recompile as momentum is comprised in checkpoints)", "\n", "if", "path_checkpoint", "is", "not", "None", ":", "\n", "        ", "init_epoch", "=", "int", "(", "path_checkpoint", "[", "-", "6", ":", "-", "3", "]", ")", "\n", "custom_l2i", "=", "{", "key", ":", "value", "for", "(", "key", ",", "value", ")", "in", "getmembers", "(", "l2i_layers", ",", "isclass", ")", "if", "key", "!=", "'Layer'", "}", "\n", "custom_nrn", "=", "{", "key", ":", "value", "for", "(", "key", ",", "value", ")", "in", "getmembers", "(", "nrn_layers", ",", "isclass", ")", "if", "key", "!=", "'Layer'", "}", "\n", "custom_objects", "=", "{", "**", "custom_l2i", ",", "**", "custom_nrn", ",", "'tf'", ":", "tf", ",", "'keras'", ":", "keras", ",", "'loss'", ":", "IdentityLoss", "(", ")", ".", "loss", "}", "\n", "model", "=", "models", ".", "load_model", "(", "path_checkpoint", ",", "custom_objects", "=", "custom_objects", ")", "\n", "\n", "# compile model from scratch otherwise", "\n", "", "else", ":", "\n", "        ", "init_epoch", "=", "0", "\n", "model", ".", "compile", "(", "optimizer", "=", "Adam", "(", "lr", "=", "learning_rate", ",", "decay", "=", "lr_decay", ")", ",", "\n", "loss", "=", "IdentityLoss", "(", ")", ".", "loss", ",", "\n", "loss_weights", "=", "[", "1.0", "]", ")", "\n", "\n", "# fit", "\n", "", "model", ".", "fit_generator", "(", "generator", ",", "\n", "epochs", "=", "n_epochs", ",", "\n", "steps_per_epoch", "=", "n_steps", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "initial_epoch", "=", "init_epoch", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.segutils.seg2contour": [[11, 55], ["numpy.unique", "numpy.delete", "ndutils.bw2contour", "numpy.where"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.bw2contour"], ["def", "seg2contour", "(", "seg", ",", "exclude_zero", "=", "True", ",", "contour_type", "=", "'inner'", ",", "thickness", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    transform nd segmentation (label maps) to contour maps\n\n    Parameters\n    ----------\n    seg : nd array\n        volume of labels/segmentations\n    exclude_zero : optional logical\n        whether to exclude the zero label.\n        default True\n    contour_type : string\n        where to draw contour voxels relative to label 'inner','outer', or 'both'\n\n    Output\n    ------\n    con : nd array\n        nd array (volume) of contour maps\n\n    See Also\n    --------\n    seg_overlap\n    \"\"\"", "\n", "\n", "# extract unique labels", "\n", "labels", "=", "np", ".", "unique", "(", "seg", ")", "\n", "if", "exclude_zero", ":", "\n", "        ", "labels", "=", "np", ".", "delete", "(", "labels", ",", "np", ".", "where", "(", "labels", "==", "0", ")", ")", "\n", "\n", "# get the contour of each label", "\n", "", "contour_map", "=", "seg", "*", "0", "\n", "for", "lab", "in", "labels", ":", "\n", "\n", "# extract binary label map for this label", "\n", "        ", "label_map", "=", "seg", "==", "lab", "\n", "\n", "# extract contour map for this label", "\n", "thickness", "=", "thickness", "+", "0.01", "\n", "label_contour_map", "=", "nd", ".", "bw2contour", "(", "label_map", ",", "type", "=", "contour_type", ",", "thr", "=", "thickness", ")", "\n", "\n", "# assign contour to this label", "\n", "contour_map", "[", "label_contour_map", "]", "=", "lab", "\n", "\n", "", "return", "contour_map", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.segutils.seg_overlap": [[57, 92], ["segutils.seg2contour", "range", "numpy.reshape", "isinstance", "numpy.max().astype", "numpy.random.random", "numpy.max"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.segutils.seg2contour", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "seg_overlap", "(", "vol", ",", "seg", ",", "do_contour", "=", "True", ",", "do_rgb", "=", "True", ",", "cmap", "=", "None", ",", "thickness", "=", "1.0", ")", ":", "\n", "    ", "'''\n    overlap a nd volume and nd segmentation (label map)\n\n    do_contour should be None, boolean, or contour_type from seg2contour\n\n    not well tested yet.\n    '''", "\n", "\n", "# compute contours for each label if necessary", "\n", "if", "do_contour", "is", "not", "None", "and", "do_contour", "is", "not", "False", ":", "\n", "        ", "if", "not", "isinstance", "(", "do_contour", ",", "str", ")", ":", "\n", "            ", "do_contour", "=", "'inner'", "\n", "", "seg", "=", "seg2contour", "(", "seg", ",", "contour_type", "=", "do_contour", ",", "thickness", "=", "thickness", ")", "\n", "\n", "# compute a rgb-contour map", "\n", "", "if", "do_rgb", ":", "\n", "        ", "if", "cmap", "is", "None", ":", "\n", "            ", "nb_labels", "=", "np", ".", "max", "(", "seg", ")", ".", "astype", "(", "int", ")", "+", "1", "\n", "colors", "=", "np", ".", "random", ".", "random", "(", "(", "nb_labels", ",", "3", ")", ")", "*", "0.5", "+", "0.5", "\n", "colors", "[", "0", ",", ":", "]", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "colors", "=", "cmap", "[", ":", ",", "0", ":", "3", "]", "\n", "\n", "", "olap", "=", "colors", "[", "seg", ".", "flat", ",", ":", "]", "\n", "sf", "=", "seg", ".", "flat", "==", "0", "\n", "for", "d", "in", "range", "(", "3", ")", ":", "\n", "            ", "olap", "[", "sf", ",", "d", "]", "=", "vol", ".", "flat", "[", "sf", "]", "\n", "", "olap", "=", "np", ".", "reshape", "(", "olap", ",", "vol", ".", "shape", "+", "(", "3", ",", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "olap", "=", "seg", "\n", "olap", "[", "seg", "==", "0", "]", "=", "vol", "[", "seg", "==", "0", "]", "\n", "\n", "", "return", "olap", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.segutils.seg_overlay": [[94, 122], ["numpy.reshape", "numpy.max", "numpy.expand_dims", "numpy.random.random"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "def", "seg_overlay", "(", "vol", ",", "seg", ",", "do_rgb", "=", "True", ",", "seg_wt", "=", "0.5", ",", "cmap", "=", "None", ")", ":", "\n", "    ", "'''\n    overlap a nd volume and nd segmentation (label map)\n\n    not well tested yet.\n    '''", "\n", "\n", "# compute contours for each label if necessary", "\n", "\n", "# compute a rgb-contour map", "\n", "if", "do_rgb", ":", "\n", "        ", "if", "cmap", "is", "None", ":", "\n", "            ", "nb_labels", "=", "np", ".", "max", "(", "seg", ")", "+", "1", "\n", "colors", "=", "np", ".", "random", ".", "random", "(", "(", "nb_labels", ",", "3", ")", ")", "*", "0.5", "+", "0.5", "\n", "colors", "[", "0", ",", ":", "]", "=", "[", "0", ",", "0", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "colors", "=", "cmap", "[", ":", ",", "0", ":", "3", "]", "\n", "\n", "", "seg_flat", "=", "colors", "[", "seg", ".", "flat", ",", ":", "]", "\n", "seg_rgb", "=", "np", ".", "reshape", "(", "seg_flat", ",", "vol", ".", "shape", "+", "(", "3", ",", ")", ")", "\n", "\n", "# get the overlap image", "\n", "olap", "=", "seg_rgb", "*", "seg_wt", "+", "np", ".", "expand_dims", "(", "vol", ",", "-", "1", ")", "*", "(", "1", "-", "seg_wt", ")", "\n", "\n", "", "else", ":", "\n", "        ", "olap", "=", "seg", "*", "seg_wt", "+", "vol", "*", "(", "1", "-", "seg_wt", ")", "\n", "\n", "", "return", "olap", "\n", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.boundingbox": [[13, 39], ["numpy.where", "numpy.concatenate", "numpy.min", "numpy.max"], "function", ["None"], ["def", "boundingbox", "(", "bwvol", ")", ":", "\n", "    ", "\"\"\"\n    bounding box coordinates of a nd volume\n\n    Parameters\n    ----------\n    vol : nd array\n        the binary (black/white) array for which to compute the boundingbox\n\n    Returns\n    -------\n    boundingbox : 1-by-(nd*2) array\n        [xstart ystart ... xend yend ...]\n    \"\"\"", "\n", "\n", "# find indices where bwvol is True", "\n", "idx", "=", "np", ".", "where", "(", "bwvol", ")", "\n", "\n", "# get the starts", "\n", "starts", "=", "[", "np", ".", "min", "(", "x", ")", "for", "x", "in", "idx", "]", "\n", "\n", "# get the ends", "\n", "ends", "=", "[", "np", ".", "max", "(", "x", ")", "for", "x", "in", "idx", "]", "\n", "\n", "# concatinate [starts, ends]", "\n", "return", "np", ".", "concatenate", "(", "(", "starts", ",", "ends", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.bwdist": [[41, 65], ["numpy.logical_not", "scipy.ndimage.morphology.distance_transform_edt"], "function", ["None"], ["", "def", "bwdist", "(", "bwvol", ")", ":", "\n", "    ", "\"\"\"\n    positive distance transform from positive entries in logical image\n\n    Parameters\n    ----------\n    bwvol : nd array\n        The logical volume\n\n    Returns\n    -------\n    possdtrf : nd array\n        the positive distance transform\n\n    See Also\n    --------\n    bw2sdtrf\n    \"\"\"", "\n", "\n", "# reverse volume to run scipy function", "\n", "revbwvol", "=", "np", ".", "logical_not", "(", "bwvol", ")", "\n", "\n", "# get distance", "\n", "return", "scipy", ".", "ndimage", ".", "morphology", ".", "distance_transform_edt", "(", "revbwvol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.bw2sdtrf": [[67, 102], ["ndutils.bwdist", "numpy.logical_not", "ndutils.bwdist"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.bwdist", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.bwdist"], ["", "def", "bw2sdtrf", "(", "bwvol", ")", ":", "\n", "    ", "\"\"\"\n    computes the signed distance transform from the surface between the\n    binary True/False elements of logical bwvol\n\n    Note: the distance transform on either side of the surface will be +1/-1\n    - i.e. there are no voxels for which the dst should be 0.\n\n    Runtime: currently the function uses bwdist twice. If there is a quick way to\n    compute the surface, bwdist could be used only once.\n\n    Parameters\n    ----------\n    bwvol : nd array\n        The logical volume\n\n    Returns\n    -------\n    sdtrf : nd array\n        the signed distance transform\n\n    See Also\n    --------\n    bwdist\n    \"\"\"", "\n", "\n", "# get the positive transform (outside the positive island)", "\n", "posdst", "=", "bwdist", "(", "bwvol", ")", "\n", "\n", "# get the negative transform (distance inside the island)", "\n", "notbwvol", "=", "np", ".", "logical_not", "(", "bwvol", ")", "\n", "negdst", "=", "bwdist", "(", "notbwvol", ")", "\n", "\n", "# combine the positive and negative map", "\n", "return", "posdst", "*", "notbwvol", "-", "negdst", "*", "bwvol", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.bw_grid": [[107, 134], ["numpy.zeros", "enumerate", "isinstance", "len", "len", "numpy.append", "len", "numpy.arange", "numpy.arange", "ndutils.ndgrid"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.ndgrid"], ["def", "bw_grid", "(", "vol_shape", ",", "spacing", ")", ":", "\n", "    ", "\"\"\"\n    draw a black and white ND grid.\n\n    Parameters\n    ----------\n        vol_shape: expected volume size\n        spacing: scalar or list the same size as vol_shape\n\n    Returns\n    -------\n        grid_vol: a volume the size of vol_shape with white lines on black background\n    \"\"\"", "\n", "\n", "# check inputs", "\n", "if", "not", "isinstance", "(", "spacing", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "spacing", "=", "[", "spacing", "]", "*", "len", "(", "vol_shape", ")", "\n", "", "assert", "len", "(", "vol_shape", ")", "==", "len", "(", "spacing", ")", "\n", "\n", "# go through axes", "\n", "grid_image", "=", "np", ".", "zeros", "(", "vol_shape", ")", "\n", "for", "d", ",", "v", "in", "enumerate", "(", "vol_shape", ")", ":", "\n", "        ", "rng", "=", "[", "np", ".", "arange", "(", "0", ",", "f", ")", "for", "f", "in", "vol_shape", "]", "\n", "rng", "[", "d", "]", "=", "np", ".", "append", "(", "np", ".", "arange", "(", "0", ",", "v", ",", "spacing", "[", "d", "]", ")", ",", "-", "1", ")", "\n", "grid_image", "[", "ndgrid", "(", "*", "rng", ")", "]", "=", "1", "\n", "\n", "", "return", "grid_image", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.bw_convex_hull": [[136, 142], ["ndutils.volsize2ndgrid", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.volsize2ndgrid"], ["", "def", "bw_convex_hull", "(", "bwvol", ")", ":", "\n", "# transform bw to nd grid.", "\n", "    ", "grid", "=", "volsize2ndgrid", "(", "bwvol", ".", "shape", ")", "\n", "\n", "# get the 1 points", "\n", "return", "np", ".", "concatenate", "(", "[", "grid", "[", "d", "]", ".", "flat", "for", "d", "in", "bwvol", ".", "ndims", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.bw2contour": [[144, 177], ["ndutils.bw2sdtrf", "numpy.logical_and", "numpy.logical_and", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.bw2sdtrf"], ["", "def", "bw2contour", "(", "bwvol", ",", "type", "=", "'both'", ",", "thr", "=", "1.01", ")", ":", "\n", "    ", "\"\"\"\n    computes the contour of island(s) on a nd logical volume\n\n    Parameters\n    ----------\n    bwvol : nd array\n        The logical volume\n    type : optional string\n        since the contour is drawn on voxels, it can be drawn on the inside\n        of the island ('inner'), outside of the island ('outer'), or both\n        ('both' - default)\n\n    Returns\n    -------\n    contour : nd array\n        the contour map of the same size of the input\n\n    See Also\n    --------\n    bwdist, bw2dstrf\n    \"\"\"", "\n", "\n", "# obtain a signed distance transform for the bw volume", "\n", "sdtrf", "=", "bw2sdtrf", "(", "bwvol", ")", "\n", "\n", "if", "type", "==", "'inner'", ":", "\n", "        ", "return", "np", ".", "logical_and", "(", "sdtrf", "<=", "0", ",", "sdtrf", ">", "-", "thr", ")", "\n", "", "elif", "type", "==", "'outer'", ":", "\n", "        ", "return", "np", ".", "logical_and", "(", "sdtrf", ">=", "0", ",", "sdtrf", "<", "thr", ")", "\n", "", "else", ":", "\n", "        ", "assert", "type", "==", "'both'", ",", "'type should only be inner, outer or both'", "\n", "return", "np", ".", "abs", "(", "sdtrf", ")", "<", "thr", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.bw_sphere": [[182, 201], ["ndutils.volsize2ndgrid", "numpy.sqrt", "len", "len", "numpy.square", "numpy.sum", "len", "len", "ndutils.range", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.volsize2ndgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["def", "bw_sphere", "(", "volshape", ",", "rad", ",", "loc", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    compute a logical (black/white) image of a sphere\n    \"\"\"", "\n", "\n", "# if the location is not given, use the center of the volume.", "\n", "if", "loc", "is", "None", ":", "\n", "        ", "loc", "=", "1.0", "*", "(", "np", ".", "array", "(", "volshape", ")", "-", "1", ")", "/", "2", "\n", "", "assert", "len", "(", "loc", ")", "==", "len", "(", "volshape", ")", ",", "'Location (%d) and volume dimensions (%d) do not match'", "%", "(", "len", "(", "loc", ")", ",", "len", "(", "volshape", ")", ")", "\n", "\n", "\n", "# compute distances between each location in the volume and ``loc``", "\n", "volgrid", "=", "volsize2ndgrid", "(", "volshape", ")", "\n", "dst", "=", "[", "np", ".", "square", "(", "loc", "[", "d", "]", "-", "volgrid", "[", "d", "]", ")", "for", "d", "in", "range", "(", "len", "(", "volshape", ")", ")", "]", "\n", "dst", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "dst", ",", "0", ")", ")", "\n", "\n", "# draw the sphere", "\n", "return", "dst", "<=", "rad", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.ndgrid": [[203, 214], ["numpy.meshgrid"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.meshgrid"], ["", "def", "ndgrid", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Disclaimer: This code is taken directly from the scitools package [1]\n    Since at the time of writing scitools predominantly requires python 2.7 while we work with 3.5+\n    To avoid issues, we copy the quick code here.\n\n    Same as calling ``meshgrid`` with *indexing* = ``'ij'`` (see\n    ``meshgrid`` for documentation).\n    \"\"\"", "\n", "kwargs", "[", "'indexing'", "]", "=", "'ij'", "\n", "return", "np", ".", "meshgrid", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.volsize2ndgrid": [[216, 223], ["ndutils.ndgrid", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.ndgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], ["", "def", "volsize2ndgrid", "(", "volsize", ")", ":", "\n", "    ", "\"\"\"\n    return the dense nd-grid for the volume with size volsize\n    essentially return the ndgrid fpr\n    \"\"\"", "\n", "ranges", "=", "[", "np", ".", "arange", "(", "e", ")", "for", "e", "in", "volsize", "]", "\n", "return", "ndgrid", "(", "*", "ranges", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.volcrop": [[225, 321], ["numpy.asarray", "len", "len", "isinstance", "len", "len", "numpy.asarray", "len", "ndutils.range", "numpy.ix_"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "volcrop", "(", "vol", ",", "new_vol_shape", "=", "None", ",", "start", "=", "None", ",", "end", "=", "None", ",", "crop", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    crop a nd volume.\n\n    Parameters\n    ----------\n    vol : nd array\n        the nd-dimentional volume to crop. If only specified parameters, is returned intact\n    new_vol_shape : nd vector, optional\n        the new size of the cropped volume\n    crop : nd tuple, optional\n        either tuple of integers or tuple of tuples.\n        If tuple of integers, will crop that amount from both sides.\n        if tuple of tuples, expect each inner tuple to specify (crop from start, crop from end)\n    start : int, optional\n        start of cropped volume\n    end : int, optional\n        end of cropped volume\n\n    Returns\n    ------\n    cropped_vol : nd array\n    \"\"\"", "\n", "\n", "vol_shape", "=", "np", ".", "asarray", "(", "vol", ".", "shape", ")", "\n", "\n", "# check which parameters are passed", "\n", "passed_new_vol_shape", "=", "new_vol_shape", "is", "not", "None", "\n", "passed_start", "=", "start", "is", "not", "None", "\n", "passed_end", "=", "end", "is", "not", "None", "\n", "passed_crop", "=", "crop", "is", "not", "None", "\n", "\n", "# from whatever is passed, we want to obtain start and end.", "\n", "if", "passed_start", "and", "passed_end", ":", "\n", "        ", "assert", "not", "(", "passed_new_vol_shape", "or", "passed_crop", ")", ",", "\"If passing start and end, don't pass anything else\"", "\n", "\n", "", "elif", "passed_new_vol_shape", ":", "\n", "# compute new volume size and crop_size", "\n", "        ", "assert", "not", "passed_crop", ",", "\"Cannot use both new volume size and crop info\"", "\n", "\n", "# compute start and end", "\n", "if", "passed_start", ":", "\n", "            ", "assert", "not", "passed_end", ",", "\"When giving passed_new_vol_shape, cannot pass both start and end\"", "\n", "end", "=", "start", "+", "new_vol_shape", "\n", "\n", "", "elif", "passed_end", ":", "\n", "            ", "assert", "not", "passed_start", ",", "\"When giving passed_new_vol_shape, cannot pass both start and end\"", "\n", "start", "=", "end", "-", "new_vol_shape", "\n", "\n", "", "else", ":", "# none of crop_size, crop, start or end are passed", "\n", "            ", "mid", "=", "np", ".", "asarray", "(", "vol_shape", ")", "//", "2", "\n", "start", "=", "mid", "-", "(", "new_vol_shape", "//", "2", ")", "\n", "end", "=", "start", "+", "new_vol_shape", "\n", "\n", "", "", "elif", "passed_crop", ":", "\n", "        ", "assert", "not", "(", "passed_start", "or", "passed_end", "or", "new_vol_shape", ")", ",", "\"Cannot pass both passed_crop and start or end or new_vol_shape\"", "\n", "\n", "if", "isinstance", "(", "crop", "[", "0", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "end", "=", "vol_shape", "-", "[", "val", "[", "1", "]", "for", "val", "in", "crop", "]", "\n", "start", "=", "[", "val", "[", "0", "]", "for", "val", "in", "crop", "]", "\n", "", "else", ":", "\n", "            ", "end", "=", "vol_shape", "-", "crop", "\n", "start", "=", "crop", "\n", "\n", "", "", "elif", "passed_start", ":", "# nothing else is passed", "\n", "        ", "end", "=", "vol_shape", "\n", "\n", "", "else", ":", "\n", "        ", "assert", "passed_end", "\n", "start", "=", "vol_shape", "*", "0", "\n", "\n", "# get indices. Since we want this to be an nd-volume crop function, we", "\n", "# idx = []", "\n", "# for i in range(len(end)):", "\n", "#     idx.append(slice(start[i], end[i]))", "\n", "\n", "# special case 1, 2, 3 since it's faster with slicing", "\n", "", "if", "len", "(", "start", ")", "==", "1", ":", "\n", "        ", "rvol", "=", "vol", "[", "start", "[", "0", "]", ":", "end", "[", "0", "]", "]", "\n", "", "elif", "len", "(", "start", ")", "==", "2", ":", "\n", "        ", "rvol", "=", "vol", "[", "start", "[", "0", "]", ":", "end", "[", "0", "]", ",", "start", "[", "1", "]", ":", "end", "[", "1", "]", "]", "\n", "", "elif", "len", "(", "start", ")", "==", "3", ":", "\n", "        ", "rvol", "=", "vol", "[", "start", "[", "0", "]", ":", "end", "[", "0", "]", ",", "start", "[", "1", "]", ":", "end", "[", "1", "]", ",", "start", "[", "2", "]", ":", "end", "[", "2", "]", "]", "\n", "", "elif", "len", "(", "start", ")", "==", "4", ":", "\n", "        ", "rvol", "=", "vol", "[", "start", "[", "0", "]", ":", "end", "[", "0", "]", ",", "start", "[", "1", "]", ":", "end", "[", "1", "]", ",", "start", "[", "2", "]", ":", "end", "[", "2", "]", ",", "start", "[", "3", "]", ":", "end", "[", "3", "]", "]", "\n", "", "elif", "len", "(", "start", ")", "==", "5", ":", "\n", "        ", "rvol", "=", "vol", "[", "start", "[", "0", "]", ":", "end", "[", "0", "]", ",", "start", "[", "1", "]", ":", "end", "[", "1", "]", ",", "start", "[", "2", "]", ":", "end", "[", "2", "]", ",", "start", "[", "3", "]", ":", "end", "[", "3", "]", ",", "start", "[", "4", "]", ":", "end", "[", "4", "]", "]", "\n", "", "else", ":", "\n", "        ", "idx", "=", "range", "(", "start", ",", "end", ")", "\n", "rvol", "=", "vol", "[", "np", ".", "ix_", "(", "*", "idx", ")", "]", "\n", "\n", "", "return", "rvol", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice": [[323, 342], ["ndutils._prep_range", "isinstance", "builtins.slice", "ndutils.slice", "ndutils.range", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils._prep_range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "slice", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    slice([start], end [,step])\n    nd version of slice, where each arg can be a vector of the same length\n\n    Parameters:\n        [start] (vector): the start\n\n    \"\"\"", "\n", "\n", "# if passed in scalars call the built-in range", "\n", "if", "not", "isinstance", "(", "args", "[", "0", "]", ",", "(", "list", ",", "tuple", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "        ", "return", "builtins", ".", "slice", "(", "*", "args", ")", "\n", "\n", "", "start", ",", "end", ",", "step", "=", "_prep_range", "(", "*", "args", ")", "\n", "\n", "# prepare", "\n", "idx", "=", "[", "slice", "(", "start", "[", "i", "]", ",", "end", "[", "i", "]", ",", "step", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "end", ")", ")", "]", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range": [[344, 363], ["ndutils._prep_range", "isinstance", "numpy.arange", "ndutils.range", "ndutils.range", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils._prep_range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "range", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    range([start], end [,step])\n    nd version of range, where each arg can be a vector of the same length\n\n    Parameters:\n        [start] (vector): the start\n\n    \"\"\"", "\n", "\n", "# if passed in scalars call the built-in range", "\n", "if", "not", "isinstance", "(", "args", "[", "0", "]", ",", "(", "list", ",", "tuple", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "        ", "return", "np", ".", "arange", "(", "*", "args", ")", "\n", "\n", "", "start", ",", "end", ",", "step", "=", "_prep_range", "(", "*", "args", ")", "\n", "\n", "# prepare", "\n", "idx", "=", "[", "range", "(", "start", "[", "i", "]", ",", "end", "[", "i", "]", ",", "step", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "end", ")", ")", "]", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange": [[365, 384], ["ndutils._prep_range", "isinstance", "builtins.range", "numpy.arange", "ndutils.range", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils._prep_range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "arange", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    aange([start], end [,step])\n    nd version of arange, where each arg can be a vector of the same length\n\n    Parameters:\n        [start] (vector): the start\n\n    \"\"\"", "\n", "\n", "# if passed in scalars call the built-in range", "\n", "if", "not", "isinstance", "(", "args", "[", "0", "]", ",", "(", "list", ",", "tuple", ",", "np", ".", "ndarray", ")", ")", ":", "\n", "        ", "return", "builtins", ".", "range", "(", "*", "args", ")", "\n", "\n", "", "start", ",", "end", ",", "step", "=", "_prep_range", "(", "*", "args", ")", "\n", "\n", "# prepare", "\n", "idx", "=", "[", "np", ".", "arange", "(", "start", "[", "i", "]", ",", "end", "[", "i", "]", ",", "step", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "end", ")", ")", "]", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.axissplit": [[386, 407], ["numpy.split"], "function", ["None"], ["", "def", "axissplit", "(", "arr", ",", "axis", ")", ":", "\n", "    ", "\"\"\"\n    Split a nd volume along an exis into n volumes, where n is the size of the axis dim.\n\n    Parameters\n    ----------\n    arr : nd array\n        array to split\n    axis : integer\n        indicating axis to split\n\n    Output\n    ------\n    outarr : 1-by-n array\n        where n is the size of the axis dim in original volume.\n        each entry is a sub-volume of the original volume\n\n    See also numpy.split()\n    \"\"\"", "\n", "nba", "=", "arr", ".", "shape", "[", "axis", "]", "\n", "return", "np", ".", "split", "(", "arr", ",", "nba", ",", "axis", "=", "axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.sub2ind": [[409, 416], ["numpy.ravel_multi_index"], "function", ["None"], ["", "def", "sub2ind", "(", "arr", ",", "size", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    similar to MATLAB's sub2ind\n\n    Note default order is C-style, not F-style (Fortran/MATLAB)\n    \"\"\"", "\n", "return", "np", ".", "ravel_multi_index", "(", "arr", ",", "size", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.ind2sub": [[418, 425], ["numpy.unravel_index"], "function", ["None"], ["", "def", "ind2sub", "(", "indices", ",", "size", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    similar to MATLAB's ind2sub\n\n    Note default order is C-style, not F-style (Fortran/MATLAB)\n    \"\"\"", "\n", "return", "np", ".", "unravel_index", "(", "indices", ",", "size", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.centroid": [[427, 434], ["ndutils.volsize2ndgrid", "numpy.array", "numpy.array", "ndutils.range", "numpy.sum", "numpy.sum", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.volsize2ndgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "centroid", "(", "im", ")", ":", "\n", "    ", "\"\"\"\n    compute centroid of a probability ndimage in 0/1\n    \"\"\"", "\n", "volgrid", "=", "volsize2ndgrid", "(", "im", ".", "shape", ")", "\n", "prob", "=", "[", "np", ".", "array", "(", "im", ")", "*", "np", ".", "array", "(", "volgrid", "[", "d", "]", ")", "for", "d", "in", "range", "(", "len", "(", "im", ".", "shape", ")", ")", "]", "\n", "return", "[", "np", ".", "sum", "(", "p", ".", "flat", ")", "/", "np", ".", "sum", "(", "im", ".", "shape", ")", "for", "p", "in", "prob", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.ind2sub_entries": [[436, 449], ["ndutils.ind2sub", "numpy.vstack().transpose", "numpy.array().flatten", "numpy.vstack", "numpy.array"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.ind2sub", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.flatten"], ["", "def", "ind2sub_entries", "(", "indices", ",", "size", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    returns a nb_entries -by- nb_dims (essentially the transpose of ind2sub)\n\n    somewhat similar to MATLAB's ind2subvec\n    https://github.com/adalca/mgt/blob/master/src/ind2subvec.m\n\n    Note default order is C-style, not F-style (Fortran/MATLAB)\n    \"\"\"", "\n", "sub", "=", "ind2sub", "(", "np", ".", "array", "(", "indices", ")", ".", "flatten", "(", ")", ",", "size", ",", "**", "kwargs", ")", "\n", "subvec", "=", "np", ".", "vstack", "(", "sub", ")", ".", "transpose", "(", ")", "\n", "# Warning this might be F-style-like stacking... it's a bit confusing", "\n", "return", "subvec", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils._prep_range": [[458, 484], ["numpy.ones", "len", "len", "numpy.zeros", "len", "len", "len", "len", "len", "ValueError", "len", "len", "len", "len"], "function", ["None"], ["", "def", "_prep_range", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"\n    _prep_range([start], end [,step])\n    prepare the start, end and step for range and arange\n\n    Parameters:\n        [start] (vector): the start\n\n    \"\"\"", "\n", "\n", "# prepare the start, step and end", "\n", "step", "=", "np", ".", "ones", "(", "len", "(", "args", "[", "0", "]", ")", ",", "'int'", ")", "\n", "if", "len", "(", "args", ")", "==", "1", ":", "\n", "        ", "end", "=", "args", "[", "0", "]", "\n", "start", "=", "np", ".", "zeros", "(", "len", "(", "end", ")", ",", "'int'", ")", "\n", "", "elif", "len", "(", "args", ")", "==", "2", ":", "\n", "        ", "assert", "len", "(", "args", "[", "0", "]", ")", "==", "len", "(", "args", "[", "1", "]", ")", ",", "\"argument vectors do not match\"", "\n", "start", ",", "end", "=", "args", "\n", "", "elif", "len", "(", "args", ")", "==", "3", ":", "\n", "        ", "assert", "len", "(", "args", "[", "0", "]", ")", "==", "len", "(", "args", "[", "1", "]", ")", ",", "\"argument vectors do not match\"", "\n", "assert", "len", "(", "args", "[", "0", "]", ")", "==", "len", "(", "args", "[", "2", "]", ")", ",", "\"argument vectors do not match\"", "\n", "start", ",", "end", ",", "step", "=", "args", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'unknown arguments'", ")", "\n", "\n", "", "return", "(", "start", ",", "end", ",", "step", ")", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.imutils.gray2color": [[5, 12], ["numpy.np.concatenate"], "function", ["None"], ["def", "gray2color", "(", "gray", ",", "color", ")", ":", "\n", "    ", "''' \n    transform a gray image (2d array) to a color image given the color (1x3 vector) \n    untested\n    '''", "\n", "\n", "return", "np", ".", "concatenate", "(", "(", "gray", "*", "c", "for", "c", "in", "color", ")", ",", "2", ")", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.image_generator.ImageGenerator.__init__": [[29, 160], ["utils.list_images_in_folder", "utils.get_volume_info", "utils.load_array_if_path", "utils.load_array_if_path", "utils.load_array_if_path", "utils.load_array_if_path", "image_generator.ImageGenerator._build_lab2im_model", "image_generator.ImageGenerator._build_model_inputs", "image_generator.ImageGenerator._build_image_generator", "utils.load_array_if_path", "utils.get_list_labels", "utils.load_array_if_path", "utils.load_array_if_path", "numpy.unique", "numpy.unique", "numpy.array_equal", "numpy.array_equal", "numpy.arange", "numpy.arange", "len", "numpy.eye", "numpy.eye", "numpy.arange", "numpy.arange", "numpy.max", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.image_generator.ImageGenerator._build_lab2im_model", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.image_generator.ImageGenerator._build_model_inputs", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.image_generator.ImageGenerator._build_image_generator", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_list_labels", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], ["    ", "def", "__init__", "(", "self", ",", "\n", "labels_dir", ",", "\n", "generation_labels", "=", "None", ",", "\n", "output_labels", "=", "None", ",", "\n", "batchsize", "=", "1", ",", "\n", "n_channels", "=", "1", ",", "\n", "target_res", "=", "None", ",", "\n", "output_shape", "=", "None", ",", "\n", "output_div_by_n", "=", "None", ",", "\n", "generation_classes", "=", "None", ",", "\n", "prior_distributions", "=", "'uniform'", ",", "\n", "prior_means", "=", "None", ",", "\n", "prior_stds", "=", "None", ",", "\n", "use_specific_stats_for_channel", "=", "False", ",", "\n", "blur_range", "=", "1.15", ")", ":", "\n", "        ", "\"\"\"\n        This class is wrapper around the lab2im_model model. It contains the GPU model that generates images from labels\n        maps, and a python generator that suplies the input data for this model.\n        To generate pairs of image/labels you can just call the method generate_image() on an object of this class.\n\n        :param labels_dir: path of folder with all input label maps, or to a single label map.\n\n        # IMPORTANT !!!\n        # Each time we provide a parameter with separate values for each axis (e.g. with a numpy array or a sequence),\n        # these values refer to the RAS axes.\n\n        # label maps-related parameters\n        :param generation_labels: (optional) list of all possible label values in the input label maps.\n        Default is None, where the label values are directly gotten from the provided label maps.\n        If not None, can be a sequence or a 1d numpy array, or the path to a 1d numpy array.\n        :param output_labels: (optional) list of the same length as generation_labels to indicate which values to use in\n        the label maps returned by this function, i.e. all occurences of generation_labels[i] in the input label maps\n        will be converted to output_labels[i] in the returned label maps. Examples:\n        Set output_labels[i] to zero if you wish to erase the value generation_labels[i] from the returned label maps.\n        Set output_labels[i]=generation_labels[i] to keep the value generation_labels[i] in the returned maps.\n        Can be a list or a 1d numpy array. By default output_labels is equal to generation_labels.\n\n        # output-related parameters\n        :param batchsize: (optional) numbers of images to generate per mini-batch. Default is 1.\n        :param n_channels: (optional) number of channels to be synthetised. Default is 1.\n        :param target_res: (optional) target resolution of the generated images and corresponding label maps.\n        If None, the outputs will have the same resolution as the input label maps.\n        Can be a number (isotropic resolution), a sequence, a 1d numpy array, or the path to a 1d numpy array.\n        :param output_shape: (optional) shape of the output image, obtained by randomly cropping the generated image.\n        Can be an integer (same size in all dimensions), a sequence, a 1d numpy array, or the path to a 1d numpy array.\n        :param output_div_by_n: (optional) forces the output shape to be divisible by this value. It overwrites\n        output_shape if necessary. Can be an integer (same size in all dimensions), a sequence, a 1d numpy array, or\n        the path to a 1d numpy array.\n\n        # GMM-sampling parameters\n        :param generation_classes: (optional) Indices regrouping generation labels into classes of same intensity\n        distribution. Regouped labels will thus share the same Gaussian when samling a new image. Can be a sequence, a\n        1d numpy array, or the path to a 1d numpy array.\n        It should have the same length as generation_labels, and contain values between 0 and K-1, where K is the total\n        number of classes. Default is all labels have different classes (K=len(generation_labels)).\n        :param prior_distributions: (optional) type of distribution from which we sample the GMM parameters.\n        Can either be 'uniform', or 'normal'. Default is 'uniform'.\n        :param prior_means: (optional) hyperparameters controlling the prior distributions of the GMM means. Because\n        these prior distributions are uniform or normal, they require by 2 hyperparameters. Thus prior_means can be:\n        1) a sequence of length 2, directly defining the two hyperparameters: [min, max] if prior_distributions is\n        uniform, [mean, std] if the distribution is normal. The GMM means of are independently sampled at each\n        mini_batch from the same distribution.\n        2) an array of shape (2, K), where K is the number of classes (K=len(generation_labels) if generation_classes is\n        not given). The mean of the Gaussian distribution associated to class k in [0, ...K-1] is sampled at each\n        mini-batch from U(prior_means[0,k], prior_means[1,k]) if prior_distributions is uniform, and from\n        N(prior_means[0,k], prior_means[1,k]) if prior_distributions is normal.\n        3) an array of shape (2*n_mod, K), where each block of two rows is associated to hyperparameters derived\n        from different modalities. In this case, if use_specific_stats_for_channel is False, we first randomly select a\n        modality from the n_mod possibilities, and we sample the GMM means like in 2).\n        If use_specific_stats_for_channel is True, each block of two rows correspond to a different channel\n        (n_mod=n_channels), thus we select the corresponding block to each channel rather than randomly drawing it.\n        4) the path to such a numpy array.\n        Default is None, which corresponds to prior_means = [25, 225].\n        :param prior_stds: (optional) same as prior_means but for the standard deviations of the GMM.\n        Default is None, which corresponds to prior_stds = [5, 25].\n        :param use_specific_stats_for_channel: (optional) whether the i-th block of two rows in the prior arrays must be\n        only used to generate the i-th channel. If True, n_mod should be equal to n_channels. Default is False.\n\n        # blurring parameters\n        :param blur_range: (optional) Randomise the standard deviation of the blurring kernels, (whether data_res is\n        given or not). At each mini_batch, the standard deviation of the blurring kernels are multiplied by a c\n        oefficient sampled from a uniform distribution with bounds [1/blur_range, blur_range].\n        If None, no randomisation. Default is 1.15.\n        \"\"\"", "\n", "\n", "# prepare data files", "\n", "self", ".", "labels_paths", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "\n", "# generation parameters", "\n", "self", ".", "labels_shape", ",", "self", ".", "aff", ",", "self", ".", "n_dims", ",", "_", ",", "self", ".", "header", ",", "self", ".", "atlas_res", "=", "utils", ".", "get_volume_info", "(", "self", ".", "labels_paths", "[", "0", "]", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ")", "\n", "self", ".", "n_channels", "=", "n_channels", "\n", "if", "generation_labels", "is", "not", "None", ":", "\n", "            ", "self", ".", "generation_labels", "=", "utils", ".", "load_array_if_path", "(", "generation_labels", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "generation_labels", ",", "_", "=", "utils", ".", "get_list_labels", "(", "labels_dir", "=", "labels_dir", ")", "\n", "", "if", "output_labels", "is", "not", "None", ":", "\n", "            ", "self", ".", "output_labels", "=", "utils", ".", "load_array_if_path", "(", "output_labels", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_labels", "=", "self", ".", "generation_labels", "\n", "", "self", ".", "target_res", "=", "utils", ".", "load_array_if_path", "(", "target_res", ")", "\n", "self", ".", "batchsize", "=", "batchsize", "\n", "# preliminary operations", "\n", "self", ".", "output_shape", "=", "utils", ".", "load_array_if_path", "(", "output_shape", ")", "\n", "self", ".", "output_div_by_n", "=", "output_div_by_n", "\n", "# GMM parameters", "\n", "self", ".", "prior_distributions", "=", "prior_distributions", "\n", "if", "generation_classes", "is", "not", "None", ":", "\n", "            ", "self", ".", "generation_classes", "=", "utils", ".", "load_array_if_path", "(", "generation_classes", ")", "\n", "assert", "self", ".", "generation_classes", ".", "shape", "==", "self", ".", "generation_labels", ".", "shape", ",", "'if provided, generation labels should have the same shape as generation_labels'", "\n", "unique_classes", "=", "np", ".", "unique", "(", "self", ".", "generation_classes", ")", "\n", "assert", "np", ".", "array_equal", "(", "unique_classes", ",", "np", ".", "arange", "(", "np", ".", "max", "(", "unique_classes", ")", "+", "1", ")", ")", ",", "'generation_classes should a linear range between 0 and its maximum value.'", "\n", "", "else", ":", "\n", "            ", "self", ".", "generation_classes", "=", "np", ".", "arange", "(", "self", ".", "generation_labels", ".", "shape", "[", "0", "]", ")", "\n", "", "self", ".", "prior_means", "=", "utils", ".", "load_array_if_path", "(", "prior_means", ")", "\n", "self", ".", "prior_stds", "=", "utils", ".", "load_array_if_path", "(", "prior_stds", ")", "\n", "self", ".", "use_specific_stats_for_channel", "=", "use_specific_stats_for_channel", "\n", "\n", "# blurring parameters", "\n", "self", ".", "blur_range", "=", "blur_range", "\n", "\n", "# build transformation model", "\n", "self", ".", "labels_to_image_model", ",", "self", ".", "model_output_shape", "=", "self", ".", "_build_lab2im_model", "(", ")", "\n", "\n", "# build generator for model inputs", "\n", "self", ".", "model_inputs_generator", "=", "self", ".", "_build_model_inputs", "(", "len", "(", "self", ".", "generation_labels", ")", ")", "\n", "\n", "# build brain generator", "\n", "self", ".", "image_generator", "=", "self", ".", "_build_image_generator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.image_generator.ImageGenerator._build_lab2im_model": [[161, 174], ["lab2im_model.lab2im_model.lab2im_model", "lab2im_model.lab2im_model.lab2im_model.output[].get_shape().as_list", "lab2im_model.lab2im_model.lab2im_model.output[].get_shape"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.lab2im_model.lab2im_model"], ["", "def", "_build_lab2im_model", "(", "self", ")", ":", "\n", "# build_model", "\n", "        ", "lab_to_im_model", "=", "lab2im_model", "(", "labels_shape", "=", "self", ".", "labels_shape", ",", "\n", "n_channels", "=", "self", ".", "n_channels", ",", "\n", "generation_labels", "=", "self", ".", "generation_labels", ",", "\n", "output_labels", "=", "self", ".", "output_labels", ",", "\n", "atlas_res", "=", "self", ".", "atlas_res", ",", "\n", "target_res", "=", "self", ".", "target_res", ",", "\n", "output_shape", "=", "self", ".", "output_shape", ",", "\n", "output_div_by_n", "=", "self", ".", "output_div_by_n", ",", "\n", "blur_range", "=", "self", ".", "blur_range", ")", "\n", "out_shape", "=", "lab_to_im_model", ".", "output", "[", "0", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "return", "lab_to_im_model", ",", "out_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.image_generator.ImageGenerator._build_image_generator": [[175, 180], ["next", "image_generator.ImageGenerator.labels_to_image_model.predict"], "methods", ["None"], ["", "def", "_build_image_generator", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "model_inputs", "=", "next", "(", "self", ".", "model_inputs_generator", ")", "\n", "[", "image", ",", "labels", "]", "=", "self", ".", "labels_to_image_model", ".", "predict", "(", "model_inputs", ")", "\n", "yield", "image", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.image_generator.ImageGenerator.generate_image": [[181, 195], ["next", "list", "list", "range", "numpy.stack", "numpy.stack", "numpy.stack", "numpy.stack", "list.append", "list.append", "numpy.squeeze", "numpy.squeeze", "numpy.squeeze", "numpy.squeeze", "edit_volumes.align_volume_to_ref", "edit_volumes.align_volume_to_ref", "numpy.eye", "numpy.eye", "numpy.eye", "numpy.eye"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref"], ["", "", "def", "generate_image", "(", "self", ")", ":", "\n", "        ", "\"\"\"call this method when an object of this class has been instantiated to generate new brains\"\"\"", "\n", "(", "image", ",", "labels", ")", "=", "next", "(", "self", ".", "image_generator", ")", "\n", "# put back images in native space", "\n", "list_images", "=", "list", "(", ")", "\n", "list_labels", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "batchsize", ")", ":", "\n", "            ", "list_images", ".", "append", "(", "edit_volumes", ".", "align_volume_to_ref", "(", "image", "[", "i", "]", ",", "np", ".", "eye", "(", "4", ")", ",", "aff_ref", "=", "self", ".", "aff", ",", "\n", "n_dims", "=", "self", ".", "n_dims", ")", ")", "\n", "list_labels", ".", "append", "(", "edit_volumes", ".", "align_volume_to_ref", "(", "labels", "[", "i", "]", ",", "np", ".", "eye", "(", "4", ")", ",", "aff_ref", "=", "self", ".", "aff", ",", "\n", "n_dims", "=", "self", ".", "n_dims", ")", ")", "\n", "", "image", "=", "np", ".", "stack", "(", "list_images", ",", "axis", "=", "0", ")", "\n", "labels", "=", "np", ".", "stack", "(", "list_labels", ",", "axis", "=", "0", ")", "\n", "return", "np", ".", "squeeze", "(", "image", ")", ",", "np", ".", "squeeze", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.image_generator.ImageGenerator._build_model_inputs": [[196, 267], ["utils.get_volume_info", "numpy.randint", "numpy.randint", "len", "utils.load_volume", "list_label_maps.append", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "range", "list_means.append", "list_stds.append", "utils.add_axis", "isinstance", "isinstance", "utils.draw_value_from_distribution", "utils.draw_value_from_distribution", "utils.add_axis", "utils.add_axis", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.eye", "numpy.eye", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.draw_value_from_distribution", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.draw_value_from_distribution", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis"], ["", "def", "_build_model_inputs", "(", "self", ",", "n_labels", ")", ":", "\n", "\n", "# get label info", "\n", "        ", "_", ",", "_", ",", "n_dims", ",", "_", ",", "_", ",", "_", "=", "utils", ".", "get_volume_info", "(", "self", ".", "labels_paths", "[", "0", "]", ")", "\n", "\n", "# Generate!", "\n", "while", "True", ":", "\n", "\n", "# randomly pick as many images as batchsize", "\n", "            ", "indices", "=", "npr", ".", "randint", "(", "len", "(", "self", ".", "labels_paths", ")", ",", "size", "=", "self", ".", "batchsize", ")", "\n", "\n", "# initialise input lists", "\n", "list_label_maps", "=", "[", "]", "\n", "list_means", "=", "[", "]", "\n", "list_stds", "=", "[", "]", "\n", "\n", "for", "idx", "in", "indices", ":", "\n", "\n", "# load label in identity space, and add them to inputs", "\n", "                ", "y", "=", "utils", ".", "load_volume", "(", "self", ".", "labels_paths", "[", "idx", "]", ",", "dtype", "=", "'int'", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ")", "\n", "list_label_maps", ".", "append", "(", "utils", ".", "add_axis", "(", "y", ",", "axis", "=", "[", "0", ",", "-", "1", "]", ")", ")", "\n", "\n", "# add means and standard deviations to inputs", "\n", "means", "=", "np", ".", "empty", "(", "(", "1", ",", "n_labels", ",", "0", ")", ")", "\n", "stds", "=", "np", ".", "empty", "(", "(", "1", ",", "n_labels", ",", "0", ")", ")", "\n", "for", "channel", "in", "range", "(", "self", ".", "n_channels", ")", ":", "\n", "\n", "# retrieve channel specific stats if necessary", "\n", "                    ", "if", "isinstance", "(", "self", ".", "prior_means", ",", "np", ".", "ndarray", ")", ":", "\n", "                        ", "if", "(", "self", ".", "prior_means", ".", "shape", "[", "0", "]", ">", "2", ")", "&", "self", ".", "use_specific_stats_for_channel", ":", "\n", "                            ", "if", "self", ".", "prior_means", ".", "shape", "[", "0", "]", "/", "2", "!=", "self", ".", "n_channels", ":", "\n", "                                ", "raise", "ValueError", "(", "\"the number of blocks in prior_means does not match n_channels. This \"", "\n", "\"message is printed because use_specific_stats_for_channel is True.\"", ")", "\n", "", "tmp_prior_means", "=", "self", ".", "prior_means", "[", "2", "*", "channel", ":", "2", "*", "channel", "+", "2", ",", ":", "]", "\n", "", "else", ":", "\n", "                            ", "tmp_prior_means", "=", "self", ".", "prior_means", "\n", "", "", "else", ":", "\n", "                        ", "tmp_prior_means", "=", "self", ".", "prior_means", "\n", "", "if", "isinstance", "(", "self", ".", "prior_stds", ",", "np", ".", "ndarray", ")", ":", "\n", "                        ", "if", "(", "self", ".", "prior_stds", ".", "shape", "[", "0", "]", ">", "2", ")", "&", "self", ".", "use_specific_stats_for_channel", ":", "\n", "                            ", "if", "self", ".", "prior_stds", ".", "shape", "[", "0", "]", "/", "2", "!=", "self", ".", "n_channels", ":", "\n", "                                ", "raise", "ValueError", "(", "\"the number of blocks in prior_stds does not match n_channels. This \"", "\n", "\"message is printed because use_specific_stats_for_channel is True.\"", ")", "\n", "", "tmp_prior_stds", "=", "self", ".", "prior_stds", "[", "2", "*", "channel", ":", "2", "*", "channel", "+", "2", ",", ":", "]", "\n", "", "else", ":", "\n", "                            ", "tmp_prior_stds", "=", "self", ".", "prior_stds", "\n", "", "", "else", ":", "\n", "                        ", "tmp_prior_stds", "=", "self", ".", "prior_stds", "\n", "\n", "# draw means and std devs from priors", "\n", "", "tmp_classes_means", "=", "utils", ".", "draw_value_from_distribution", "(", "tmp_prior_means", ",", "n_labels", ",", "\n", "self", ".", "prior_distributions", ",", "125.", ",", "100.", ",", "\n", "positive_only", "=", "True", ")", "\n", "tmp_classes_stds", "=", "utils", ".", "draw_value_from_distribution", "(", "tmp_prior_stds", ",", "n_labels", ",", "\n", "self", ".", "prior_distributions", ",", "15.", ",", "10.", ",", "\n", "positive_only", "=", "True", ")", "\n", "tmp_means", "=", "utils", ".", "add_axis", "(", "tmp_classes_means", "[", "self", ".", "generation_classes", "]", ",", "axis", "=", "[", "0", ",", "-", "1", "]", ")", "\n", "tmp_stds", "=", "utils", ".", "add_axis", "(", "tmp_classes_stds", "[", "self", ".", "generation_classes", "]", ",", "axis", "=", "[", "0", ",", "-", "1", "]", ")", "\n", "means", "=", "np", ".", "concatenate", "(", "[", "means", ",", "tmp_means", "]", ",", "axis", "=", "-", "1", ")", "\n", "stds", "=", "np", ".", "concatenate", "(", "[", "stds", ",", "tmp_stds", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "list_means", ".", "append", "(", "means", ")", "\n", "list_stds", ".", "append", "(", "stds", ")", "\n", "\n", "# build list of inputs of augmentation model", "\n", "", "list_inputs", "=", "[", "list_label_maps", ",", "list_means", ",", "list_stds", "]", "\n", "if", "self", ".", "batchsize", ">", "1", ":", "# concatenate individual input types if batchsize > 1", "\n", "                ", "list_inputs", "=", "[", "np", ".", "concatenate", "(", "item", ",", "0", ")", "for", "item", "in", "list_inputs", "]", "\n", "", "else", ":", "\n", "                ", "list_inputs", "=", "[", "item", "[", "0", "]", "for", "item", "in", "list_inputs", "]", "\n", "\n", "", "yield", "list_inputs", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.blurring_sigma_for_downsampling": [[41, 83], ["tensorflow.is_tensor", "numpy.array", "numpy.array", "numpy.minimum", "keras.Lambda", "numpy.array", "keras.Lambda", "keras.Lambda", "keras.Lambda", "tensorflow.where", "tensorflow.math.minimum", "tensorflow.where", "tensorflow.math.equal", "tensorflow.math.equal", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor"], "function", ["None"], ["def", "blurring_sigma_for_downsampling", "(", "current_res", ",", "downsample_res", ",", "mult_coef", "=", "None", ",", "thickness", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute standard deviations of 1d gaussian masks for image blurring before downsampling.\n    :param downsample_res: resolution to downsample to. Can be a 1d numpy array or list, or a tensor.\n    :param current_res: resolution of the volume before downsampling.\n    Can be a 1d numpy array or list or tensor of the same length as downsample res.\n    :param thickness: (optional) slice thickness in each dimension. Must be the same type as downsample_res.\n    :return: standard deviation of the blurring masks given as as the same type as downsample_res (list or tensor).\n    \"\"\"", "\n", "\n", "if", "not", "tf", ".", "is_tensor", "(", "downsample_res", ")", ":", "\n", "\n", "# get blurring resolution (min between downsample_res and thickness)", "\n", "        ", "current_res", "=", "np", ".", "array", "(", "current_res", ")", "\n", "downsample_res", "=", "np", ".", "array", "(", "downsample_res", ")", "\n", "if", "thickness", "is", "not", "None", ":", "\n", "            ", "downsample_res", "=", "np", ".", "minimum", "(", "downsample_res", ",", "np", ".", "array", "(", "thickness", ")", ")", "\n", "\n", "# get std deviation for blurring kernels", "\n", "", "if", "mult_coef", "is", "None", ":", "\n", "            ", "sigma", "=", "0.75", "*", "downsample_res", "/", "current_res", "\n", "sigma", "[", "downsample_res", "==", "current_res", "]", "=", "0.5", "\n", "", "else", ":", "\n", "            ", "sigma", "=", "mult_coef", "*", "downsample_res", "/", "current_res", "\n", "", "sigma", "[", "downsample_res", "==", "0", "]", "=", "0", "\n", "\n", "", "else", ":", "\n", "\n", "# reformat data resolution at which we blur", "\n", "        ", "if", "thickness", "is", "not", "None", ":", "\n", "            ", "down_res", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "math", ".", "minimum", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", ")", "(", "[", "downsample_res", ",", "thickness", "]", ")", "\n", "", "else", ":", "\n", "            ", "down_res", "=", "downsample_res", "\n", "\n", "# get std deviation for blurring kernels", "\n", "", "if", "mult_coef", "is", "None", ":", "\n", "            ", "sigma", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "where", "(", "tf", ".", "math", ".", "equal", "(", "x", ",", "tf", ".", "convert_to_tensor", "(", "current_res", ",", "dtype", "=", "'float32'", ")", ")", ",", "\n", "0.5", ",", "0.75", "*", "x", "/", "tf", ".", "convert_to_tensor", "(", "current_res", ",", "dtype", "=", "'float32'", ")", ")", ")", "(", "down_res", ")", "\n", "", "else", ":", "\n", "            ", "sigma", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "mult_coef", "*", "x", "/", "tf", ".", "convert_to_tensor", "(", "current_res", ",", "dtype", "=", "'float32'", ")", ")", "(", "down_res", ")", "\n", "", "sigma", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "where", "(", "tf", ".", "math", ".", "equal", "(", "x", "[", "0", "]", ",", "0.", ")", ",", "0.", ",", "x", "[", "1", "]", ")", ")", "(", "[", "down_res", ",", "sigma", "]", ")", "\n", "\n", "", "return", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.gaussian_kernel": [[85, 181], ["tf.expand_dims.get_shape().as_list", "tensorflow.is_tensor", "tensorflow.convert_to_tensor", "numpy.array", "numpy.array", "tensorflow.split", "list", "numpy.array", "enumerate", "tensorflow.stack", "tensorflow.equal", "keras.sum", "tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.expand_dims", "utils.reformat_to_list", "tf.expand_dims.get_shape", "tensorflow.split", "utils.reformat_to_list", "utils.reformat_to_list", "numpy.int32", "tensorflow.cast", "tensorflow.tile", "range", "range", "tensorflow.math.log", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.random.uniform", "list", "tensorflow.exp", "tf.expand_dims.append", "tf.expand_dims.append", "ext.neuron.utils.volshape_to_meshgrid", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.expand_dims", "keras.square", "tensorflow.where", "tensorflow.shape", "numpy.ceil", "itertools.combinations", "tensorflow.cast", "tensorflow.tile", "tensorflow.reduce_sum", "tensorflow.expand_dims", "tensorflow.expand_dims", "range", "tensorflow.where", "tensorflow.ones_like", "list", "tensorflow.range", "tensorflow.expand_dims", "tensorflow.concat", "keras.square", "tensorflow.math.log", "tensorflow.expand_dims", "len", "tensorflow.ones", "tensorflow.ones_like", "numpy.sqrt", "range", "tensorflow.shape", "tensorflow.ones", "numpy.sqrt", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.volshape_to_meshgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "gaussian_kernel", "(", "sigma", ",", "max_sigma", "=", "None", ",", "blur_range", "=", "None", ",", "separable", "=", "True", ")", ":", "\n", "    ", "\"\"\"Build gaussian kernels of the specified standard deviation. The outputs are given as tensorflow tensors.\n    :param sigma: standard deviation of the tensors. Can be given as a list/numpy array or as tensors. In each case,\n    sigma must have the same length as the number of dimensions of the volume that will be blurred with the output\n    tensors (e.g. sigma must have 3 values for 3D volumes).\n    :param max_sigma:\n    :param blur_range:\n    :param separable:\n    :return:\n    \"\"\"", "\n", "# convert sigma into a tensor", "\n", "if", "not", "tf", ".", "is_tensor", "(", "sigma", ")", ":", "\n", "        ", "sigma_tens", "=", "tf", ".", "convert_to_tensor", "(", "utils", ".", "reformat_to_list", "(", "sigma", ")", ",", "dtype", "=", "'float32'", ")", "\n", "", "else", ":", "\n", "        ", "assert", "max_sigma", "is", "not", "None", ",", "'max_sigma must be provided when sigma is given as a tensor'", "\n", "sigma_tens", "=", "sigma", "\n", "", "shape", "=", "sigma_tens", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "\n", "# get n_dims and batchsize", "\n", "if", "shape", "[", "0", "]", "is", "not", "None", ":", "\n", "        ", "n_dims", "=", "shape", "[", "0", "]", "\n", "batchsize", "=", "None", "\n", "", "else", ":", "\n", "        ", "n_dims", "=", "shape", "[", "1", "]", "\n", "batchsize", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "sigma_tens", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", "\n", "\n", "# reformat max_sigma", "\n", "", "if", "max_sigma", "is", "not", "None", ":", "# dynamic blurring", "\n", "        ", "max_sigma", "=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "max_sigma", ",", "length", "=", "n_dims", ")", ")", "\n", "", "else", ":", "# sigma is fixed", "\n", "        ", "max_sigma", "=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "sigma", ",", "length", "=", "n_dims", ")", ")", "\n", "\n", "# randomise the burring std dev and/or split it between dimensions", "\n", "", "if", "blur_range", "is", "not", "None", ":", "\n", "        ", "if", "blur_range", "!=", "1", ":", "\n", "            ", "sigma_tens", "=", "sigma_tens", "*", "tf", ".", "random", ".", "uniform", "(", "tf", ".", "shape", "(", "sigma_tens", ")", ",", "minval", "=", "1", "/", "blur_range", ",", "maxval", "=", "blur_range", ")", "\n", "\n", "# get size of blurring kernels", "\n", "", "", "windowsize", "=", "np", ".", "int32", "(", "np", ".", "ceil", "(", "2.5", "*", "max_sigma", ")", "/", "2", ")", "*", "2", "+", "1", "\n", "\n", "if", "separable", ":", "\n", "\n", "        ", "split_sigma", "=", "tf", ".", "split", "(", "sigma_tens", ",", "[", "1", "]", "*", "n_dims", ",", "axis", "=", "-", "1", ")", "\n", "\n", "kernels", "=", "list", "(", ")", "\n", "comb", "=", "np", ".", "array", "(", "list", "(", "combinations", "(", "list", "(", "range", "(", "n_dims", ")", ")", ",", "n_dims", "-", "1", ")", ")", "[", ":", ":", "-", "1", "]", ")", "\n", "for", "(", "i", ",", "wsize", ")", "in", "enumerate", "(", "windowsize", ")", ":", "\n", "\n", "            ", "if", "wsize", ">", "1", ":", "\n", "\n", "# build meshgrid and replicate it along batch dim if dynamic blurring", "\n", "                ", "locations", "=", "tf", ".", "cast", "(", "tf", ".", "range", "(", "0", ",", "wsize", ")", ",", "'float32'", ")", "-", "(", "wsize", "-", "1", ")", "/", "2", "\n", "if", "batchsize", "is", "not", "None", ":", "\n", "                    ", "locations", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "locations", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "tf", ".", "shape", "(", "locations", ")", ")", ",", "dtype", "=", "'int32'", ")", "]", ",", "\n", "axis", "=", "0", ")", ")", "\n", "comb", "[", "i", "]", "+=", "1", "\n", "\n", "# compute gaussians", "\n", "", "exp_term", "=", "-", "K", ".", "square", "(", "locations", ")", "/", "(", "2", "*", "split_sigma", "[", "i", "]", "**", "2", ")", "\n", "g", "=", "tf", ".", "exp", "(", "exp_term", "-", "tf", ".", "math", ".", "log", "(", "np", ".", "sqrt", "(", "2", "*", "np", ".", "pi", ")", "*", "split_sigma", "[", "i", "]", ")", ")", "\n", "g", "=", "g", "/", "tf", ".", "reduce_sum", "(", "g", ")", "\n", "\n", "for", "axis", "in", "comb", "[", "i", "]", ":", "\n", "                    ", "g", "=", "tf", ".", "expand_dims", "(", "g", ",", "axis", "=", "axis", ")", "\n", "", "kernels", ".", "append", "(", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "g", ",", "-", "1", ")", ",", "-", "1", ")", ")", "\n", "\n", "", "else", ":", "\n", "                ", "kernels", ".", "append", "(", "None", ")", "\n", "\n", "", "", "", "else", ":", "\n", "\n", "# build meshgrid", "\n", "        ", "mesh", "=", "[", "tf", ".", "cast", "(", "f", ",", "'float32'", ")", "for", "f", "in", "volshape_to_meshgrid", "(", "windowsize", ",", "indexing", "=", "'ij'", ")", "]", "\n", "diff", "=", "tf", ".", "stack", "(", "[", "mesh", "[", "f", "]", "-", "(", "windowsize", "[", "f", "]", "-", "1", ")", "/", "2", "for", "f", "in", "range", "(", "len", "(", "windowsize", ")", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# replicate meshgrid to batch size and reshape sigma_tens", "\n", "if", "batchsize", "is", "not", "None", ":", "\n", "            ", "diff", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "diff", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "tf", ".", "shape", "(", "diff", ")", ")", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "for", "i", "in", "range", "(", "n_dims", ")", ":", "\n", "                ", "sigma_tens", "=", "tf", ".", "expand_dims", "(", "sigma_tens", ",", "axis", "=", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "n_dims", ")", ":", "\n", "                ", "sigma_tens", "=", "tf", ".", "expand_dims", "(", "sigma_tens", ",", "axis", "=", "0", ")", "\n", "\n", "# compute gaussians", "\n", "", "", "sigma_is_0", "=", "tf", ".", "equal", "(", "sigma_tens", ",", "0", ")", "\n", "exp_term", "=", "-", "K", ".", "square", "(", "diff", ")", "/", "(", "2", "*", "tf", ".", "where", "(", "sigma_is_0", ",", "tf", ".", "ones_like", "(", "sigma_tens", ")", ",", "sigma_tens", ")", "**", "2", ")", "\n", "norms", "=", "exp_term", "-", "tf", ".", "math", ".", "log", "(", "tf", ".", "where", "(", "sigma_is_0", ",", "tf", ".", "ones_like", "(", "sigma_tens", ")", ",", "np", ".", "sqrt", "(", "2", "*", "np", ".", "pi", ")", "*", "sigma_tens", ")", ")", "\n", "kernels", "=", "K", ".", "sum", "(", "norms", ",", "-", "1", ")", "\n", "kernels", "=", "tf", ".", "exp", "(", "kernels", ")", "\n", "kernels", "/=", "tf", ".", "reduce_sum", "(", "kernels", ")", "\n", "kernels", "=", "tf", ".", "expand_dims", "(", "tf", ".", "expand_dims", "(", "kernels", ",", "-", "1", ")", ",", "-", "1", ")", "\n", "\n", "", "return", "kernels", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.resample_tensor": [[183, 265], ["utils.reformat_to_list", "utils.reformat_to_list", "len", "tensor.get_shape().as_list", "tuple", "len", "len", "len", "len", "tuple", "tensor.get_shape().as_list", "ext.Resize", "range", "tensor.get_shape", "int", "tensor.get_shape().as_list", "ext.Resize", "numpy.array", "numpy.array", "numpy.arange", "numpy.int32", "numpy.int32", "numpy.zeros", "keras.Lambda", "keras.Lambda", "keras.Lambda", "range", "tensor.get_shape", "numpy.floor", "numpy.clip", "numpy.reshape", "tensor.get_shape", "tensorflow.shape", "tensorflow.reshape", "tensorflow.ones_like", "tensorflow.convert_to_tensor"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "resample_tensor", "(", "tensor", ",", "\n", "resample_shape", ",", "\n", "interp_method", "=", "'linear'", ",", "\n", "subsample_res", "=", "None", ",", "\n", "volume_res", "=", "None", ",", "\n", "build_reliability_map", "=", "False", ")", ":", "\n", "    ", "\"\"\"This function resamples a volume to resample_shape. It does not apply any pre-filtering.\n    A prior downsampling step can be added if subsample_res is specified. In this case, volume_res should also be\n    specified, in order to calculate the downsampling ratio. A reliability map can also be returned to indicate which\n    slices were interpolated during resampling from the downsampled to final tensor.\n    :param tensor: tensor\n    :param resample_shape: list or numpy array of size (n_dims,)\n    :param interp_method: (optional) interpolation method for resampling, 'linear' (default) or 'nearest'\n    :param subsample_res: (optional) if not None, this triggers a downsampling of the volume, prior to the resampling\n    step. List or numpy array of size (n_dims,). Default si None.\n    :param volume_res: (optional) if subsample_res is not None, this should be provided to compute downsampling ratio.\n    list or numpy array of size (n_dims,). Default is None.\n    :param build_reliability_map: whether to return reliability map along with the resampled tensor. This map indicates\n    which slices of the resampled tensor are interpolated (0=interpolated, 1=real slice, in between=degree of realness).\n    :return: resampled volume, with reliability map if necessary.\n    \"\"\"", "\n", "\n", "# reformat resolutions to lists", "\n", "subsample_res", "=", "utils", ".", "reformat_to_list", "(", "subsample_res", ")", "\n", "volume_res", "=", "utils", ".", "reformat_to_list", "(", "volume_res", ")", "\n", "n_dims", "=", "len", "(", "resample_shape", ")", "\n", "\n", "# downsample image", "\n", "tensor_shape", "=", "tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "-", "1", "]", "\n", "downsample_shape", "=", "tensor_shape", "# will be modified if we actually downsample", "\n", "\n", "if", "subsample_res", "is", "not", "None", ":", "\n", "        ", "assert", "volume_res", "is", "not", "None", ",", "'volume_res must be given when providing a subsampling resolution.'", "\n", "assert", "len", "(", "subsample_res", ")", "==", "len", "(", "volume_res", ")", ",", "'subsample_res and volume_res must have the same length, '", "'had {0}, and {1}'", ".", "format", "(", "len", "(", "subsample_res", ")", ",", "len", "(", "volume_res", ")", ")", "\n", "if", "subsample_res", "!=", "volume_res", ":", "\n", "\n", "# get shape at which we downsample", "\n", "            ", "downsample_shape", "=", "[", "int", "(", "tensor_shape", "[", "i", "]", "*", "volume_res", "[", "i", "]", "/", "subsample_res", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "\n", "# downsample volume", "\n", "tensor", ".", "_keras_shape", "=", "tuple", "(", "tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "tensor", "=", "nrn_layers", ".", "Resize", "(", "size", "=", "downsample_shape", ",", "interp_method", "=", "'nearest'", ")", "(", "tensor", ")", "\n", "\n", "# resample image at target resolution", "\n", "", "", "if", "resample_shape", "!=", "downsample_shape", ":", "# if we didn't dowmsample downsample_shape = tensor_shape", "\n", "        ", "tensor", ".", "_keras_shape", "=", "tuple", "(", "tensor", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "tensor", "=", "nrn_layers", ".", "Resize", "(", "size", "=", "resample_shape", ",", "interp_method", "=", "interp_method", ")", "(", "tensor", ")", "\n", "\n", "# compute reliability maps if necessary and return results", "\n", "", "if", "build_reliability_map", ":", "\n", "\n", "# compute maps only if we downsampled", "\n", "        ", "if", "downsample_shape", "!=", "tensor_shape", ":", "\n", "\n", "# compute upsampling factors", "\n", "            ", "upsampling_factors", "=", "np", ".", "array", "(", "resample_shape", ")", "/", "np", ".", "array", "(", "downsample_shape", ")", "\n", "\n", "# build reliability map", "\n", "reliability_map", "=", "1", "\n", "for", "i", "in", "range", "(", "n_dims", ")", ":", "\n", "                ", "loc_float", "=", "np", ".", "arange", "(", "0", ",", "resample_shape", "[", "i", "]", ",", "upsampling_factors", "[", "i", "]", ")", "\n", "loc_floor", "=", "np", ".", "int32", "(", "np", ".", "floor", "(", "loc_float", ")", ")", "\n", "loc_ceil", "=", "np", ".", "int32", "(", "np", ".", "clip", "(", "loc_floor", "+", "1", ",", "0", ",", "resample_shape", "[", "i", "]", "-", "1", ")", ")", "\n", "tmp_reliability_map", "=", "np", ".", "zeros", "(", "resample_shape", "[", "i", "]", ")", "\n", "tmp_reliability_map", "[", "loc_floor", "]", "=", "1", "-", "(", "loc_float", "-", "loc_floor", ")", "\n", "tmp_reliability_map", "[", "loc_ceil", "]", "=", "tmp_reliability_map", "[", "loc_ceil", "]", "+", "(", "loc_float", "-", "loc_floor", ")", "\n", "shape", "=", "[", "1", ",", "1", ",", "1", "]", "\n", "shape", "[", "i", "]", "=", "resample_shape", "[", "i", "]", "\n", "reliability_map", "=", "reliability_map", "*", "np", ".", "reshape", "(", "tmp_reliability_map", ",", "shape", ")", "\n", "", "shape", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "shape", "(", "x", ")", ")", "(", "tensor", ")", "\n", "mask", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "reshape", "(", "tf", ".", "convert_to_tensor", "(", "reliability_map", ",", "dtype", "=", "'float32'", ")", ",", "\n", "shape", "=", "x", ")", ")", "(", "shape", ")", "\n", "\n", "# otherwise just return an all-one tensor", "\n", "", "else", ":", "\n", "            ", "mask", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "ones_like", "(", "x", ")", ")", "(", "tensor", ")", "\n", "\n", "", "return", "tensor", ",", "mask", "\n", "\n", "", "else", ":", "\n", "        ", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims": [[267, 273], ["utils.reformat_to_list", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "", "def", "expand_dims", "(", "tensor", ",", "axis", "=", "0", ")", ":", "\n", "    ", "\"\"\"Expand the dimensions of the input tensor along the provided axes (given as an integer or a list).\"\"\"", "\n", "axis", "=", "utils", ".", "reformat_to_list", "(", "axis", ")", "\n", "for", "ax", "in", "axis", ":", "\n", "        ", "tensor", "=", "tf", ".", "expand_dims", "(", "tensor", ",", "axis", "=", "ax", ")", "\n", "", "return", "tensor", "\n", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomSpatialDeformation.__init__": [[85, 121], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "scaling_bounds", "=", "0.15", ",", "\n", "rotation_bounds", "=", "10", ",", "\n", "shearing_bounds", "=", "0.02", ",", "\n", "translation_bounds", "=", "False", ",", "\n", "enable_90_rotations", "=", "False", ",", "\n", "nonlin_std", "=", "4.", ",", "\n", "nonlin_shape_factor", "=", ".0625", ",", "\n", "inter_method", "=", "'linear'", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# shape attributes", "\n", "        ", "self", ".", "n_inputs", "=", "1", "\n", "self", ".", "inshape", "=", "None", "\n", "self", ".", "n_dims", "=", "None", "\n", "self", ".", "small_shape", "=", "None", "\n", "\n", "# deformation attributes", "\n", "self", ".", "scaling_bounds", "=", "scaling_bounds", "\n", "self", ".", "rotation_bounds", "=", "rotation_bounds", "\n", "self", ".", "shearing_bounds", "=", "shearing_bounds", "\n", "self", ".", "translation_bounds", "=", "translation_bounds", "\n", "self", ".", "enable_90_rotations", "=", "enable_90_rotations", "\n", "self", ".", "nonlin_std", "=", "nonlin_std", "\n", "self", ".", "nonlin_shape_factor", "=", "nonlin_shape_factor", "\n", "\n", "# boolean attributes", "\n", "self", ".", "apply_affine_trans", "=", "(", "self", ".", "scaling_bounds", "is", "not", "False", ")", "|", "(", "self", ".", "rotation_bounds", "is", "not", "False", ")", "|", "(", "self", ".", "shearing_bounds", "is", "not", "False", ")", "|", "(", "self", ".", "translation_bounds", "is", "not", "False", ")", "|", "self", ".", "enable_90_rotations", "\n", "self", ".", "apply_elastic_trans", "=", "self", ".", "nonlin_std", ">", "0", "\n", "\n", "# interpolation methods", "\n", "self", ".", "inter_method", "=", "inter_method", "\n", "\n", "super", "(", "RandomSpatialDeformation", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomSpatialDeformation.get_config": [[122, 133], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"scaling_bounds\"", "]", "=", "self", ".", "scaling_bounds", "\n", "config", "[", "\"rotation_bounds\"", "]", "=", "self", ".", "rotation_bounds", "\n", "config", "[", "\"shearing_bounds\"", "]", "=", "self", ".", "shearing_bounds", "\n", "config", "[", "\"translation_bounds\"", "]", "=", "self", ".", "translation_bounds", "\n", "config", "[", "\"enable_90_rotations\"", "]", "=", "self", ".", "enable_90_rotations", "\n", "config", "[", "\"nonlin_std\"", "]", "=", "self", ".", "nonlin_std", "\n", "config", "[", "\"nonlin_shape_factor\"", "]", "=", "self", ".", "nonlin_shape_factor", "\n", "config", "[", "\"inter_method\"", "]", "=", "self", ".", "inter_method", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomSpatialDeformation.build": [[134, 154], ["utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "super().build", "isinstance", "len", "len", "utils.get_resample_shape", "ext.neuron.utils.get_resample_shape", "ext.neuron.utils.get_resample_shape"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_resample_shape", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_resample_shape", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_resample_shape"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "input_shape", ",", "list", ")", ":", "\n", "            ", "inputshape", "=", "[", "input_shape", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "n_inputs", "=", "len", "(", "input_shape", ")", "\n", "inputshape", "=", "input_shape", "\n", "", "self", ".", "inshape", "=", "inputshape", "[", "0", "]", "[", "1", ":", "]", "\n", "self", ".", "n_dims", "=", "len", "(", "self", ".", "inshape", ")", "-", "1", "\n", "\n", "if", "self", ".", "apply_elastic_trans", ":", "\n", "            ", "self", ".", "small_shape", "=", "utils", ".", "get_resample_shape", "(", "self", ".", "inshape", "[", ":", "self", ".", "n_dims", "]", ",", "\n", "self", ".", "nonlin_shape_factor", ",", "self", ".", "n_dims", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "small_shape", "=", "None", "\n", "\n", "", "self", ".", "inter_method", "=", "utils", ".", "reformat_to_list", "(", "self", ".", "inter_method", ",", "length", "=", "self", ".", "n_inputs", ",", "dtype", "=", "'str'", ")", "\n", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "RandomSpatialDeformation", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomSpatialDeformation.call": [[155, 197], ["list", "tensorflow.cast", "tensorflow.split", "utils.sample_affine_transform", "ext.neuron.utils.sample_affine_transform", "ext.neuron.utils.sample_affine_transform", "list.append", "tensorflow.concat", "tensorflow.random.uniform", "tensorflow.random.normal", "list.append", "tensorflow.cast", "tensorflow.shape", "max", "ext.Resize", "ext.VecInt", "ext.Resize", "zip", "tensorflow.convert_to_tensor", "int", "range", "ext.SpatialTransformer", "zip"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.sample_affine_transform", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.sample_affine_transform", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.sample_affine_transform", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# reformat inputs and get its shape", "\n", "        ", "if", "self", ".", "n_inputs", "<", "2", ":", "\n", "            ", "inputs", "=", "[", "inputs", "]", "\n", "", "types", "=", "[", "v", ".", "dtype", "for", "v", "in", "inputs", "]", "\n", "inputs", "=", "[", "tf", ".", "cast", "(", "v", ",", "dtype", "=", "'float32'", ")", "for", "v", "in", "inputs", "]", "\n", "batchsize", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", ",", "[", "1", ",", "self", ".", "n_dims", "+", "1", "]", ")", "[", "0", "]", "\n", "\n", "# initialise list of transfors to operate", "\n", "list_trans", "=", "list", "(", ")", "\n", "\n", "# add affine deformation to inputs list", "\n", "if", "self", ".", "apply_affine_trans", ":", "\n", "            ", "affine_trans", "=", "utils", ".", "sample_affine_transform", "(", "batchsize", ",", "\n", "self", ".", "n_dims", ",", "\n", "self", ".", "rotation_bounds", ",", "\n", "self", ".", "scaling_bounds", ",", "\n", "self", ".", "shearing_bounds", ",", "\n", "self", ".", "translation_bounds", ",", "\n", "self", ".", "enable_90_rotations", ")", "\n", "list_trans", ".", "append", "(", "affine_trans", ")", "\n", "\n", "# prepare non-linear deformation field and add it to inputs list", "\n", "", "if", "self", ".", "apply_elastic_trans", ":", "\n", "\n", "# sample small field from normal distribution of specified std dev", "\n", "            ", "trans_shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "convert_to_tensor", "(", "self", ".", "small_shape", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", "\n", "trans_std", "=", "tf", ".", "random", ".", "uniform", "(", "(", "1", ",", "1", ")", ",", "maxval", "=", "self", ".", "nonlin_std", ")", "\n", "elastic_trans", "=", "tf", ".", "random", ".", "normal", "(", "trans_shape", ",", "stddev", "=", "trans_std", ")", "\n", "\n", "# reshape this field to half size (for smoother SVF), integrate it, and reshape to full image size", "\n", "resize_shape", "=", "[", "max", "(", "int", "(", "self", ".", "inshape", "[", "i", "]", "/", "2", ")", ",", "self", ".", "small_shape", "[", "i", "]", ")", "for", "i", "in", "range", "(", "self", ".", "n_dims", ")", "]", "\n", "elastic_trans", "=", "nrn_layers", ".", "Resize", "(", "size", "=", "resize_shape", ",", "interp_method", "=", "'linear'", ")", "(", "elastic_trans", ")", "\n", "elastic_trans", "=", "nrn_layers", ".", "VecInt", "(", ")", "(", "elastic_trans", ")", "\n", "elastic_trans", "=", "nrn_layers", ".", "Resize", "(", "size", "=", "self", ".", "inshape", "[", ":", "self", ".", "n_dims", "]", ",", "interp_method", "=", "'linear'", ")", "(", "elastic_trans", ")", "\n", "list_trans", ".", "append", "(", "elastic_trans", ")", "\n", "\n", "# apply deformations and return tensors with correct dtype", "\n", "", "if", "self", ".", "apply_affine_trans", "|", "self", ".", "apply_elastic_trans", ":", "\n", "            ", "inputs", "=", "[", "nrn_layers", ".", "SpatialTransformer", "(", "m", ")", "(", "[", "v", "]", "+", "list_trans", ")", "for", "(", "m", ",", "v", ")", "in", "zip", "(", "self", ".", "inter_method", ",", "inputs", ")", "]", "\n", "", "return", "[", "tf", ".", "cast", "(", "v", ",", "t", ")", "for", "(", "t", ",", "v", ")", "in", "zip", "(", "types", ",", "inputs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomCrop.__init__": [[212, 220], ["len", "keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "crop_shape", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "self", ".", "several_inputs", "=", "True", "\n", "self", ".", "crop_max_val", "=", "None", "\n", "self", ".", "crop_shape", "=", "crop_shape", "\n", "self", ".", "n_dims", "=", "len", "(", "crop_shape", ")", "\n", "self", ".", "list_n_channels", "=", "None", "\n", "super", "(", "RandomCrop", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomCrop.get_config": [[221, 225], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"crop_shape\"", "]", "=", "self", ".", "crop_shape", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomCrop.build": [[226, 237], ["super().build", "isinstance", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "input_shape", ",", "list", ")", ":", "\n", "            ", "self", ".", "several_inputs", "=", "False", "\n", "inputshape", "=", "[", "input_shape", "]", "\n", "", "else", ":", "\n", "            ", "inputshape", "=", "input_shape", "\n", "", "self", ".", "crop_max_val", "=", "np", ".", "array", "(", "np", ".", "array", "(", "inputshape", "[", "0", "]", "[", "1", ":", "self", ".", "n_dims", "+", "1", "]", ")", ")", "-", "np", ".", "array", "(", "self", ".", "crop_shape", ")", "\n", "self", ".", "list_n_channels", "=", "[", "i", "[", "-", "1", "]", "for", "i", "in", "inputshape", "]", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "RandomCrop", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomCrop.call": [[238, 251], ["tensorflow.map_fn", "tensorflow.concat", "tensorflow.map_fn", "tensorflow.split", "tensorflow.cast", "tensorflow.cast", "zip"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# if one input only is provided, performs the cropping directly", "\n", "        ", "if", "not", "self", ".", "several_inputs", ":", "\n", "            ", "return", "tf", ".", "map_fn", "(", "self", ".", "_single_slice", ",", "inputs", ",", "dtype", "=", "inputs", ".", "dtype", ")", "\n", "\n", "# otherwise we concatenate all inputs before cropping, so that they are all cropped at the same location", "\n", "", "else", ":", "\n", "            ", "types", "=", "[", "v", ".", "dtype", "for", "v", "in", "inputs", "]", "\n", "inputs", "=", "tf", ".", "concat", "(", "[", "tf", ".", "cast", "(", "v", ",", "'float32'", ")", "for", "v", "in", "inputs", "]", ",", "axis", "=", "-", "1", ")", "\n", "inputs", "=", "tf", ".", "map_fn", "(", "self", ".", "_single_slice", ",", "inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "inputs", "=", "tf", ".", "split", "(", "inputs", ",", "self", ".", "list_n_channels", ",", "axis", "=", "-", "1", ")", "\n", "return", "[", "tf", ".", "cast", "(", "v", ",", "t", ")", "for", "(", "t", ",", "v", ")", "in", "zip", "(", "types", ",", "inputs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomCrop._single_slice": [[252, 257], ["tensorflow.cast", "tensorflow.concat", "tensorflow.convert_to_tensor", "tensorflow.slice", "tensorflow.random.uniform", "numpy.array", "tensorflow.zeros"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice"], ["", "", "def", "_single_slice", "(", "self", ",", "vol", ")", ":", "\n", "        ", "crop_idx", "=", "tf", ".", "cast", "(", "tf", ".", "random", ".", "uniform", "(", "[", "self", ".", "n_dims", "]", ",", "0", ",", "np", ".", "array", "(", "self", ".", "crop_max_val", ")", ",", "'float32'", ")", ",", "dtype", "=", "'int32'", ")", "\n", "crop_idx", "=", "tf", ".", "concat", "(", "[", "crop_idx", ",", "tf", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", "\n", "crop_size", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "crop_shape", "+", "[", "-", "1", "]", ",", "dtype", "=", "'int32'", ")", "\n", "return", "tf", ".", "slice", "(", "vol", ",", "begin", "=", "crop_idx", ",", "size", "=", "crop_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomCrop.compute_output_shape": [[258, 261], ["tuple"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "output_shape", "=", "[", "tuple", "(", "[", "None", "]", "+", "self", ".", "crop_shape", "+", "[", "v", "]", ")", "for", "v", "in", "self", ".", "list_n_channels", "]", "\n", "return", "output_shape", "if", "self", ".", "several_inputs", "else", "output_shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomFlip.__init__": [[314, 331], ["utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "flip_axis", "=", "None", ",", "swap_labels", "=", "False", ",", "label_list", "=", "None", ",", "n_neutral_labels", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "# shape attributes", "\n", "        ", "self", ".", "several_inputs", "=", "True", "\n", "self", ".", "n_dims", "=", "None", "\n", "self", ".", "list_n_channels", "=", "None", "\n", "\n", "# axis along which to flip", "\n", "self", ".", "flip_axis", "=", "utils", ".", "reformat_to_list", "(", "flip_axis", ")", "\n", "\n", "# wether to swap labels, and corresponding label list", "\n", "self", ".", "swap_labels", "=", "utils", ".", "reformat_to_list", "(", "swap_labels", ")", "\n", "self", ".", "label_list", "=", "label_list", "\n", "self", ".", "n_neutral_labels", "=", "n_neutral_labels", "\n", "self", ".", "swap_lut", "=", "None", "\n", "\n", "super", "(", "RandomFlip", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomFlip.get_config": [[332, 339], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"flip_axis\"", "]", "=", "self", ".", "flip_axis", "\n", "config", "[", "\"swap_labels\"", "]", "=", "self", ".", "swap_labels", "\n", "config", "[", "\"label_list\"", "]", "=", "self", ".", "label_list", "\n", "config", "[", "\"n_neutral_labels\"", "]", "=", "self", ".", "n_neutral_labels", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomFlip.build": [[340, 367], ["len", "utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "any", "super().build", "isinstance", "len", "len", "numpy.split", "numpy.concatenate", "utils.get_mapping_lut", "ext.neuron.utils.get_mapping_lut", "ext.neuron.utils.get_mapping_lut", "tensorflow.convert_to_tensor", "len", "int"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_mapping_lut", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_mapping_lut", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_mapping_lut"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "input_shape", ",", "list", ")", ":", "\n", "            ", "self", ".", "several_inputs", "=", "False", "\n", "inputshape", "=", "[", "input_shape", "]", "\n", "", "else", ":", "\n", "            ", "inputshape", "=", "input_shape", "\n", "", "self", ".", "n_dims", "=", "len", "(", "inputshape", "[", "0", "]", "[", "1", ":", "-", "1", "]", ")", "\n", "self", ".", "list_n_channels", "=", "[", "i", "[", "-", "1", "]", "for", "i", "in", "inputshape", "]", "\n", "self", ".", "swap_labels", "=", "utils", ".", "reformat_to_list", "(", "self", ".", "swap_labels", ",", "length", "=", "len", "(", "inputshape", ")", ")", "\n", "\n", "# create label list with swapped labels", "\n", "if", "any", "(", "self", ".", "swap_labels", ")", ":", "\n", "            ", "assert", "(", "self", ".", "label_list", "is", "not", "None", ")", "&", "(", "self", ".", "n_neutral_labels", "is", "not", "None", ")", ",", "'please provide a label_list, and n_neutral_labels when swapping the values of at least one input'", "\n", "n_labels", "=", "len", "(", "self", ".", "label_list", ")", "\n", "if", "self", ".", "n_neutral_labels", "==", "n_labels", ":", "\n", "                ", "self", ".", "swap_labels", "=", "[", "False", "]", "*", "len", "(", "self", ".", "swap_labels", ")", "\n", "", "else", ":", "\n", "                ", "rl_split", "=", "np", ".", "split", "(", "self", ".", "label_list", ",", "[", "self", ".", "n_neutral_labels", ",", "\n", "self", ".", "n_neutral_labels", "+", "int", "(", "(", "n_labels", "-", "self", ".", "n_neutral_labels", ")", "/", "2", ")", "]", ")", "\n", "label_list_swap", "=", "np", ".", "concatenate", "(", "(", "rl_split", "[", "0", "]", ",", "rl_split", "[", "2", "]", ",", "rl_split", "[", "1", "]", ")", ")", "\n", "swap_lut", "=", "utils", ".", "get_mapping_lut", "(", "self", ".", "label_list", ",", "label_list_swap", ")", "\n", "self", ".", "swap_lut", "=", "tf", ".", "convert_to_tensor", "(", "swap_lut", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "", "", "self", ".", "built", "=", "True", "\n", "super", "(", "RandomFlip", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomFlip.call": [[368, 393], ["keras.greater", "list", "range", "tensorflow.concat", "tensorflow.map_fn", "tensorflow.split", "tensorflow.split", "tensorflow.random.uniform", "len", "tensorflow.cast", "tensorflow.shape", "tensorflow.concat", "list.append", "list.append", "tensorflow.cast", "zip", "tensorflow.map_fn", "tensorflow.ones"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# convert inputs to list, and get each input type", "\n", "        ", "if", "not", "self", ".", "several_inputs", ":", "\n", "            ", "inputs", "=", "[", "inputs", "]", "\n", "", "types", "=", "[", "v", ".", "dtype", "for", "v", "in", "inputs", "]", "\n", "\n", "# sample boolean for each element of the batch", "\n", "batchsize", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", ",", "[", "1", ",", "self", ".", "n_dims", "+", "1", "]", ")", "[", "0", "]", "\n", "rand_flip", "=", "K", ".", "greater", "(", "tf", ".", "random", ".", "uniform", "(", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "1", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ",", "0", ",", "1", ")", ",", "0.5", ")", "\n", "\n", "# swap r/l labels if necessary", "\n", "swapped_inputs", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "inputs", ")", ")", ":", "\n", "            ", "if", "self", ".", "swap_labels", "[", "i", "]", ":", "\n", "                ", "swapped_inputs", ".", "append", "(", "tf", ".", "map_fn", "(", "self", ".", "_single_swap", ",", "[", "inputs", "[", "i", "]", ",", "rand_flip", "]", ",", "dtype", "=", "types", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "swapped_inputs", ".", "append", "(", "inputs", "[", "i", "]", ")", "\n", "\n", "# flip inputs and convert them back to their original type", "\n", "", "", "inputs", "=", "tf", ".", "concat", "(", "[", "tf", ".", "cast", "(", "v", ",", "'float32'", ")", "for", "v", "in", "swapped_inputs", "]", ",", "axis", "=", "-", "1", ")", "\n", "inputs", "=", "tf", ".", "map_fn", "(", "self", ".", "_single_flip", ",", "[", "inputs", ",", "rand_flip", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "inputs", "=", "tf", ".", "split", "(", "inputs", ",", "self", ".", "list_n_channels", ",", "axis", "=", "-", "1", ")", "\n", "\n", "return", "[", "tf", ".", "cast", "(", "v", ",", "t", ")", "for", "(", "t", ",", "v", ")", "in", "zip", "(", "types", ",", "inputs", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomFlip._single_swap": [[394, 396], ["keras.switch", "tensorflow.gather"], "methods", ["None"], ["", "def", "_single_swap", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "K", ".", "switch", "(", "inputs", "[", "1", "]", ",", "tf", ".", "gather", "(", "self", ".", "swap_lut", ",", "inputs", "[", "0", "]", ")", ",", "inputs", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.RandomFlip._single_flip": [[397, 404], ["keras.switch", "tensorflow.random.uniform", "tensorflow.squeeze", "tensorflow.expand_dims", "keras.reverse", "tensorflow.random.uniform", "len", "tensorflow.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "def", "_single_flip", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "flip_axis", "is", "None", ":", "\n", "            ", "flip_axis", "=", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "0", ",", "self", ".", "n_dims", ",", "dtype", "=", "'int32'", ")", "\n", "", "else", ":", "\n", "            ", "idx", "=", "tf", ".", "squeeze", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "0", ",", "len", "(", "self", ".", "flip_axis", ")", ",", "dtype", "=", "'int32'", ")", ")", "\n", "flip_axis", "=", "tf", ".", "expand_dims", "(", "tf", ".", "convert_to_tensor", "(", "self", ".", "flip_axis", ",", "dtype", "=", "'int32'", ")", "[", "idx", "]", ",", "axis", "=", "0", ")", "\n", "", "return", "K", ".", "switch", "(", "inputs", "[", "1", "]", ",", "K", ".", "reverse", "(", "inputs", "[", "0", "]", ",", "axes", "=", "flip_axis", ")", ",", "inputs", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.SampleConditionalGMM.__init__": [[424, 432], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "generation_labels", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "generation_labels", "=", "generation_labels", "\n", "self", ".", "n_labels", "=", "None", "\n", "self", ".", "n_channels", "=", "None", "\n", "self", ".", "max_label", "=", "None", "\n", "self", ".", "indices", "=", "None", "\n", "self", ".", "shape", "=", "None", "\n", "super", "(", "SampleConditionalGMM", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.SampleConditionalGMM.get_config": [[433, 437], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"generation_labels\"", "]", "=", "self", ".", "generation_labels", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.SampleConditionalGMM.build": [[438, 455], ["len", "numpy.concatenate", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "super().build", "len", "numpy.max", "utils.add_axis", "ext.neuron.utils.add_axis", "ext.neuron.utils.add_axis", "range", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "# check n_labels and n_channels", "\n", "        ", "assert", "len", "(", "input_shape", ")", "==", "3", ",", "'should have three inputs: labels, means, std devs (in that order).'", "\n", "self", ".", "n_channels", "=", "input_shape", "[", "1", "]", "[", "-", "1", "]", "\n", "self", ".", "n_labels", "=", "len", "(", "self", ".", "generation_labels", ")", "\n", "assert", "self", ".", "n_labels", "==", "input_shape", "[", "1", "]", "[", "1", "]", ",", "'means should have the same number of values as generation_labels'", "\n", "assert", "self", ".", "n_labels", "==", "input_shape", "[", "2", "]", "[", "1", "]", ",", "'stds should have the same number of values as generation_labels'", "\n", "\n", "# scatter parameters (to build mean/std lut)", "\n", "self", ".", "max_label", "=", "np", ".", "max", "(", "self", ".", "generation_labels", ")", "+", "1", "\n", "indices", "=", "np", ".", "concatenate", "(", "[", "self", ".", "generation_labels", "+", "self", ".", "max_label", "*", "i", "for", "i", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "shape", "=", "tf", ".", "convert_to_tensor", "(", "[", "np", ".", "max", "(", "indices", ")", "+", "1", "]", ",", "dtype", "=", "'int32'", ")", "\n", "self", ".", "indices", "=", "tf", ".", "convert_to_tensor", "(", "utils", ".", "add_axis", "(", "indices", ",", "axis", "=", "[", "0", ",", "-", "1", "]", ")", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "SampleConditionalGMM", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.SampleConditionalGMM.call": [[456, 475], ["tensorflow.tile", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.tile", "tensorflow.map_fn", "tensorflow.concat", "tensorflow.tile", "tensorflow.map_fn", "tensorflow.split", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.shape", "tensorflow.convert_to_tensor", "tensorflow.scatter_nd", "tensorflow.gather", "tensorflow.scatter_nd", "tensorflow.gather", "tensorflow.random.normal", "tensorflow.convert_to_tensor", "tensorflow.cast", "range", "range", "range", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# reformat labels and scatter indices", "\n", "        ", "batch", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", "\n", "tmp_indices", "=", "tf", ".", "tile", "(", "self", ".", "indices", ",", "tf", ".", "concat", "(", "[", "batch", ",", "tf", ".", "convert_to_tensor", "(", "[", "1", ",", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "labels", "=", "tf", ".", "concat", "(", "[", "tf", ".", "cast", "(", "inputs", "[", "0", "]", ",", "dtype", "=", "'int32'", ")", "+", "self", ".", "max_label", "*", "i", "for", "i", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "-", "1", ")", "\n", "\n", "# build mean map", "\n", "means", "=", "tf", ".", "concat", "(", "[", "inputs", "[", "1", "]", "[", "...", ",", "i", "]", "for", "i", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "1", ")", "\n", "tile_shape", "=", "tf", ".", "concat", "(", "[", "batch", ",", "tf", ".", "convert_to_tensor", "(", "[", "1", ",", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", "\n", "means", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "scatter_nd", "(", "tmp_indices", ",", "means", ",", "self", ".", "shape", ")", ",", "0", ")", ",", "tile_shape", ")", "\n", "means_map", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "tf", ".", "gather", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", ",", "[", "means", ",", "labels", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# same for stds", "\n", "stds", "=", "tf", ".", "concat", "(", "[", "inputs", "[", "2", "]", "[", "...", ",", "i", "]", "for", "i", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "1", ")", "\n", "stds", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "scatter_nd", "(", "tmp_indices", ",", "stds", ",", "self", ".", "shape", ")", ",", "0", ")", ",", "tile_shape", ")", "\n", "stds_map", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "tf", ".", "gather", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", ",", "[", "stds", ",", "labels", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "return", "stds_map", "*", "tf", ".", "random", ".", "normal", "(", "tf", ".", "shape", "(", "labels", ")", ")", "+", "means_map", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.SampleConditionalGMM.compute_output_shape": [[476, 478], ["tuple", "list"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "[", "0", "]", "if", "(", "self", ".", "n_channels", "==", "1", ")", "else", "tuple", "(", "list", "(", "input_shape", "[", "0", "]", "[", ":", "-", "1", "]", ")", "+", "[", "self", ".", "n_channels", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.SampleResolution.__init__": [[507, 528], ["len", "keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "min_resolution", ",", "\n", "max_res_iso", "=", "None", ",", "\n", "max_res_aniso", "=", "None", ",", "\n", "prob_iso", "=", "0.1", ",", "\n", "prob_min", "=", "0.05", ",", "\n", "return_thickness", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "self", ".", "min_res", "=", "min_resolution", "\n", "self", ".", "max_res_iso_input", "=", "max_res_iso", "\n", "self", ".", "max_res_iso", "=", "None", "\n", "self", ".", "max_res_aniso_input", "=", "max_res_aniso", "\n", "self", ".", "max_res_aniso", "=", "None", "\n", "self", ".", "prob_iso", "=", "prob_iso", "\n", "self", ".", "prob_min", "=", "prob_min", "\n", "self", ".", "return_thickness", "=", "return_thickness", "\n", "self", ".", "n_dims", "=", "len", "(", "self", ".", "min_res", ")", "\n", "self", ".", "add_batchsize", "=", "False", "\n", "self", ".", "min_res_tens", "=", "None", "\n", "super", "(", "SampleResolution", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.SampleResolution.get_config": [[529, 538], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"min_resolution\"", "]", "=", "self", ".", "min_res", "\n", "config", "[", "\"max_res_iso\"", "]", "=", "self", ".", "max_res_iso", "\n", "config", "[", "\"max_res_aniso\"", "]", "=", "self", ".", "max_res_aniso", "\n", "config", "[", "\"prob_iso\"", "]", "=", "self", ".", "prob_iso", "\n", "config", "[", "\"prob_min\"", "]", "=", "self", ".", "prob_min", "\n", "config", "[", "\"return_thickness\"", "]", "=", "self", ".", "return_thickness", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.SampleResolution.build": [[539, 573], ["numpy.array", "tensorflow.convert_to_tensor", "super().build", "numpy.array", "numpy.array_equal", "numpy.array", "numpy.array_equal", "Exception", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "# check maximum resolutions", "\n", "        ", "assert", "(", "(", "self", ".", "max_res_iso_input", "is", "not", "None", ")", "|", "(", "self", ".", "max_res_aniso_input", "is", "not", "None", ")", ")", ",", "'at least one of maximinum isotropic or anisotropic resolutions must be provided, received none'", "\n", "\n", "# reformat resolutions as numpy arrays", "\n", "self", ".", "min_res", "=", "np", ".", "array", "(", "self", ".", "min_res", ")", "\n", "if", "self", ".", "max_res_iso_input", "is", "not", "None", ":", "\n", "            ", "self", ".", "max_res_iso", "=", "np", ".", "array", "(", "self", ".", "max_res_iso_input", ")", "\n", "assert", "len", "(", "self", ".", "min_res", ")", "==", "len", "(", "self", ".", "max_res_iso", ")", ",", "'min and isotropic max resolution must have the same length, '", "'had {0} and {1}'", ".", "format", "(", "self", ".", "min_res", ",", "self", ".", "max_res_iso", ")", "\n", "if", "np", ".", "array_equal", "(", "self", ".", "min_res", ",", "self", ".", "max_res_iso", ")", ":", "\n", "                ", "self", ".", "max_res_iso", "=", "None", "\n", "", "", "if", "self", ".", "max_res_aniso_input", "is", "not", "None", ":", "\n", "            ", "self", ".", "max_res_aniso", "=", "np", ".", "array", "(", "self", ".", "max_res_aniso_input", ")", "\n", "assert", "len", "(", "self", ".", "min_res", ")", "==", "len", "(", "self", ".", "max_res_aniso", ")", ",", "'min and anisotopic max resolution must have the same length, '", "'had {} and {}'", ".", "format", "(", "self", ".", "min_res", ",", "self", ".", "max_res_aniso", ")", "\n", "if", "np", ".", "array_equal", "(", "self", ".", "min_res", ",", "self", ".", "max_res_aniso", ")", ":", "\n", "                ", "self", ".", "max_res_aniso", "=", "None", "\n", "\n", "# check prob iso", "\n", "", "", "if", "(", "self", ".", "max_res_iso", "is", "not", "None", ")", "&", "(", "self", ".", "max_res_aniso", "is", "not", "None", ")", "&", "(", "self", ".", "prob_iso", "==", "0", ")", ":", "\n", "            ", "raise", "Exception", "(", "'prob iso is 0 while sampling either isotropic and anisotropic resolutions is enabled'", ")", "\n", "\n", "", "if", "input_shape", ":", "\n", "            ", "self", ".", "add_batchsize", "=", "True", "\n", "\n", "", "self", ".", "min_res_tens", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "min_res", ",", "dtype", "=", "'float32'", ")", "\n", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "SampleResolution", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.SampleResolution.call": [[574, 623], ["tensorflow.random.uniform", "tensorflow.tensor_scatter_nd_update", "tensorflow.concat", "tensorflow.tile", "tensorflow.concat", "tensorflow.stack", "tensorflow.tensor_scatter_nd_update", "tensorflow.zeros", "tensorflow.convert_to_tensor", "tensorflow.split", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.ones", "tensorflow.random.uniform", "keras.switch", "tensorflow.random.uniform", "tensorflow.shape", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.range", "tensorflow.random.uniform", "tensorflow.squeeze", "tensorflow.random.uniform", "keras.switch", "tensorflow.random.uniform", "tensorflow.random.uniform", "keras.switch", "keras.switch", "tensorflow.shape", "keras.less", "tensorflow.squeeze", "tensorflow.where", "tensorflow.squeeze", "tensorflow.where", "tensorflow.squeeze", "tensorflow.random.uniform", "keras.less", "keras.less", "keras.less", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "not", "self", ".", "add_batchsize", ":", "\n", "            ", "shape", "=", "[", "self", ".", "n_dims", "]", "\n", "dim", "=", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "(", "1", ",", "1", ")", ",", "minval", "=", "0", ",", "maxval", "=", "self", ".", "n_dims", ",", "dtype", "=", "'int32'", ")", "\n", "mask", "=", "tf", ".", "tensor_scatter_nd_update", "(", "tf", ".", "zeros", "(", "[", "self", ".", "n_dims", "]", ",", "dtype", "=", "'bool'", ")", ",", "dim", ",", "\n", "tf", ".", "convert_to_tensor", "(", "[", "True", "]", ",", "dtype", "=", "'bool'", ")", ")", "\n", "", "else", ":", "\n", "            ", "batch", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", "\n", "tile_shape", "=", "tf", ".", "concat", "(", "[", "batch", ",", "tf", ".", "convert_to_tensor", "(", "[", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", "\n", "self", ".", "min_res_tens", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "self", ".", "min_res_tens", ",", "0", ")", ",", "tile_shape", ")", "\n", "\n", "shape", "=", "tf", ".", "concat", "(", "[", "batch", ",", "tf", ".", "convert_to_tensor", "(", "[", "self", ".", "n_dims", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "tf", ".", "range", "(", "0", ",", "batch", "[", "0", "]", ")", ",", "tf", ".", "random", ".", "uniform", "(", "batch", ",", "0", ",", "self", ".", "n_dims", ",", "dtype", "=", "'int32'", ")", "]", ",", "1", ")", "\n", "mask", "=", "tf", ".", "tensor_scatter_nd_update", "(", "tf", ".", "zeros", "(", "shape", ",", "dtype", "=", "'bool'", ")", ",", "indices", ",", "tf", ".", "ones", "(", "batch", ",", "dtype", "=", "'bool'", ")", ")", "\n", "\n", "# return min resolution as tensor if min=max", "\n", "", "if", "(", "self", ".", "max_res_iso", "is", "None", ")", "&", "(", "self", ".", "max_res_aniso", "is", "None", ")", ":", "\n", "            ", "new_resolution", "=", "self", ".", "min_res_tens", "\n", "\n", "# sample isotropic resolution only", "\n", "", "elif", "(", "self", ".", "max_res_iso", "is", "not", "None", ")", "&", "(", "self", ".", "max_res_aniso", "is", "None", ")", ":", "\n", "            ", "new_resolution_iso", "=", "tf", ".", "random", ".", "uniform", "(", "shape", ",", "minval", "=", "self", ".", "min_res", ",", "maxval", "=", "self", ".", "max_res_iso", ")", "\n", "new_resolution", "=", "K", ".", "switch", "(", "tf", ".", "squeeze", "(", "K", ".", "less", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "0", ",", "1", ")", ",", "self", ".", "prob_min", ")", ")", ",", "\n", "self", ".", "min_res_tens", ",", "\n", "new_resolution_iso", ")", "\n", "\n", "# sample anisotropic resolution only", "\n", "", "elif", "(", "self", ".", "max_res_iso", "is", "None", ")", "&", "(", "self", ".", "max_res_aniso", "is", "not", "None", ")", ":", "\n", "            ", "new_resolution_aniso", "=", "tf", ".", "random", ".", "uniform", "(", "shape", ",", "minval", "=", "self", ".", "min_res", ",", "maxval", "=", "self", ".", "max_res_aniso", ")", "\n", "new_resolution", "=", "K", ".", "switch", "(", "tf", ".", "squeeze", "(", "K", ".", "less", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "0", ",", "1", ")", ",", "self", ".", "prob_min", ")", ")", ",", "\n", "self", ".", "min_res_tens", ",", "\n", "tf", ".", "where", "(", "mask", ",", "new_resolution_aniso", ",", "self", ".", "min_res_tens", ")", ")", "\n", "\n", "# sample either anisotropic or isotropic resolution", "\n", "", "else", ":", "\n", "            ", "new_resolution_iso", "=", "tf", ".", "random", ".", "uniform", "(", "shape", ",", "minval", "=", "self", ".", "min_res", ",", "maxval", "=", "self", ".", "max_res_iso", ")", "\n", "new_resolution_aniso", "=", "tf", ".", "random", ".", "uniform", "(", "shape", ",", "minval", "=", "self", ".", "min_res", ",", "maxval", "=", "self", ".", "max_res_aniso", ")", "\n", "new_resolution", "=", "K", ".", "switch", "(", "tf", ".", "squeeze", "(", "K", ".", "less", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "0", ",", "1", ")", ",", "self", ".", "prob_iso", ")", ")", ",", "\n", "new_resolution_iso", ",", "\n", "tf", ".", "where", "(", "mask", ",", "new_resolution_aniso", ",", "self", ".", "min_res_tens", ")", ")", "\n", "new_resolution", "=", "K", ".", "switch", "(", "tf", ".", "squeeze", "(", "K", ".", "less", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "0", ",", "1", ")", ",", "self", ".", "prob_min", ")", ")", ",", "\n", "self", ".", "min_res_tens", ",", "\n", "new_resolution", ")", "\n", "\n", "", "if", "self", ".", "return_thickness", ":", "\n", "            ", "return", "[", "new_resolution", ",", "tf", ".", "random", ".", "uniform", "(", "tf", ".", "shape", "(", "self", ".", "min_res_tens", ")", ",", "self", ".", "min_res_tens", ",", "new_resolution", ")", "]", "\n", "", "else", ":", "\n", "            ", "return", "new_resolution", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.SampleResolution.compute_output_shape": [[624, 629], ["None"], "methods", ["None"], ["", "", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "self", ".", "return_thickness", ":", "\n", "            ", "return", "[", "(", "None", ",", "self", ".", "n_dims", ")", "]", "*", "2", "if", "self", ".", "add_batchsize", "else", "[", "self", ".", "n_dims", "]", "*", "2", "\n", "", "else", ":", "\n", "            ", "return", "(", "None", ",", "self", ".", "n_dims", ")", "if", "self", ".", "add_batchsize", "else", "self", ".", "n_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.GaussianBlur.__init__": [[661, 674], ["utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "numpy.all", "keras.layers.Layer.__init__", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "sigma", ",", "random_blur_range", "=", "None", ",", "use_mask", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "sigma", "=", "utils", ".", "reformat_to_list", "(", "sigma", ")", "\n", "assert", "np", ".", "all", "(", "np", ".", "array", "(", "self", ".", "sigma", ")", ">=", "0", ")", ",", "'sigma should be superior or equal to 0'", "\n", "self", ".", "use_mask", "=", "use_mask", "\n", "\n", "self", ".", "n_dims", "=", "None", "\n", "self", ".", "n_channels", "=", "None", "\n", "self", ".", "blur_range", "=", "random_blur_range", "\n", "self", ".", "stride", "=", "None", "\n", "self", ".", "separable", "=", "None", "\n", "self", ".", "kernels", "=", "None", "\n", "self", ".", "convnd", "=", "None", "\n", "super", "(", "GaussianBlur", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.GaussianBlur.get_config": [[675, 681], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"sigma\"", "]", "=", "self", ".", "sigma", "\n", "config", "[", "\"random_blur_range\"", "]", "=", "self", ".", "blur_range", "\n", "config", "[", "\"use_mask\"", "]", "=", "self", ".", "use_mask", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.GaussianBlur.build": [[682, 707], ["utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "getattr", "super().build", "numpy.linalg.norm", "edit_tensors.gaussian_kernel", "len", "len", "len", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.gaussian_kernel"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "# get shapes", "\n", "        ", "if", "self", ".", "use_mask", ":", "\n", "            ", "assert", "len", "(", "input_shape", ")", "==", "2", ",", "'please provide a mask as second layer input when use_mask=True'", "\n", "self", ".", "n_dims", "=", "len", "(", "input_shape", "[", "0", "]", ")", "-", "2", "\n", "self", ".", "n_channels", "=", "input_shape", "[", "0", "]", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "n_dims", "=", "len", "(", "input_shape", ")", "-", "2", "\n", "self", ".", "n_channels", "=", "input_shape", "[", "-", "1", "]", "\n", "\n", "# prepare blurring kernel", "\n", "", "self", ".", "stride", "=", "[", "1", "]", "*", "(", "self", ".", "n_dims", "+", "2", ")", "\n", "self", ".", "sigma", "=", "utils", ".", "reformat_to_list", "(", "self", ".", "sigma", ",", "length", "=", "self", ".", "n_dims", ")", "\n", "self", ".", "separable", "=", "np", ".", "linalg", ".", "norm", "(", "np", ".", "array", "(", "self", ".", "sigma", ")", ")", ">", "5", "\n", "if", "self", ".", "blur_range", "is", "None", ":", "# fixed kernels", "\n", "            ", "self", ".", "kernels", "=", "l2i_et", ".", "gaussian_kernel", "(", "self", ".", "sigma", ",", "separable", "=", "self", ".", "separable", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "kernels", "=", "None", "\n", "\n", "# prepare convolution", "\n", "", "self", ".", "convnd", "=", "getattr", "(", "tf", ".", "nn", ",", "'conv%dd'", "%", "self", ".", "n_dims", ")", "\n", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "GaussianBlur", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.GaussianBlur.call": [[708, 744], ["tensorflow.cast", "edit_tensors.gaussian_kernel", "any", "tensorflow.concat", "tensorflow.concat", "tensorflow.cast", "tensorflow.concat", "tensorflow.where", "tensorflow.cast", "tensorflow.concat", "tensorflow.where", "layers.GaussianBlur.convnd", "tensorflow.zeros_like", "layers.GaussianBlur.convnd", "tensorflow.zeros_like", "tensorflow.expand_dims", "range", "layers.GaussianBlur.convnd", "keras.epsilon", "tensorflow.expand_dims", "range", "layers.GaussianBlur.convnd", "keras.epsilon", "tensorflow.expand_dims", "range", "tensorflow.expand_dims", "range"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.gaussian_kernel", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "self", ".", "use_mask", ":", "\n", "            ", "image", "=", "inputs", "[", "0", "]", "\n", "mask", "=", "tf", ".", "cast", "(", "inputs", "[", "1", "]", ",", "'bool'", ")", "\n", "", "else", ":", "\n", "            ", "image", "=", "inputs", "\n", "mask", "=", "None", "\n", "\n", "# redefine the kernels at each new step when blur_range is activated", "\n", "", "if", "self", ".", "blur_range", "is", "not", "None", ":", "\n", "            ", "self", ".", "kernels", "=", "l2i_et", ".", "gaussian_kernel", "(", "self", ".", "sigma", ",", "blur_range", "=", "self", ".", "blur_range", ",", "separable", "=", "self", ".", "separable", ")", "\n", "\n", "", "if", "self", ".", "separable", ":", "\n", "            ", "for", "k", "in", "self", ".", "kernels", ":", "\n", "                ", "if", "k", "is", "not", "None", ":", "\n", "                    ", "image", "=", "tf", ".", "concat", "(", "[", "self", ".", "convnd", "(", "tf", ".", "expand_dims", "(", "image", "[", "...", ",", "n", "]", ",", "-", "1", ")", ",", "k", ",", "self", ".", "stride", ",", "'SAME'", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "use_mask", ":", "\n", "                        ", "maskb", "=", "tf", ".", "cast", "(", "mask", ",", "'float32'", ")", "\n", "maskb", "=", "tf", ".", "concat", "(", "[", "self", ".", "convnd", "(", "tf", ".", "expand_dims", "(", "maskb", "[", "...", ",", "n", "]", ",", "-", "1", ")", ",", "k", ",", "self", ".", "stride", ",", "'SAME'", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "-", "1", ")", "\n", "image", "=", "image", "/", "(", "maskb", "+", "K", ".", "epsilon", "(", ")", ")", "\n", "image", "=", "tf", ".", "where", "(", "mask", ",", "image", ",", "tf", ".", "zeros_like", "(", "image", ")", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "if", "any", "(", "self", ".", "sigma", ")", ":", "\n", "                ", "image", "=", "tf", ".", "concat", "(", "[", "self", ".", "convnd", "(", "tf", ".", "expand_dims", "(", "image", "[", "...", ",", "n", "]", ",", "-", "1", ")", ",", "self", ".", "kernels", ",", "self", ".", "stride", ",", "'SAME'", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "-", "1", ")", "\n", "if", "self", ".", "use_mask", ":", "\n", "                    ", "maskb", "=", "tf", ".", "cast", "(", "mask", ",", "'float32'", ")", "\n", "maskb", "=", "tf", ".", "concat", "(", "[", "self", ".", "convnd", "(", "tf", ".", "expand_dims", "(", "maskb", "[", "...", ",", "n", "]", ",", "-", "1", ")", ",", "self", ".", "kernels", ",", "self", ".", "stride", ",", "'SAME'", ")", "\n", "for", "n", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "-", "1", ")", "\n", "image", "=", "image", "/", "(", "maskb", "+", "K", ".", "epsilon", "(", ")", ")", "\n", "image", "=", "tf", ".", "where", "(", "mask", ",", "image", ",", "tf", ".", "zeros_like", "(", "image", ")", ")", "\n", "\n", "", "", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.DynamicGaussianBlur.__init__": [[761, 769], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "max_sigma", ",", "random_blur_range", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "max_sigma", "=", "max_sigma", "\n", "self", ".", "n_dims", "=", "None", "\n", "self", ".", "n_channels", "=", "None", "\n", "self", ".", "convnd", "=", "None", "\n", "self", ".", "blur_range", "=", "random_blur_range", "\n", "self", ".", "separable", "=", "None", "\n", "super", "(", "DynamicGaussianBlur", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.DynamicGaussianBlur.get_config": [[770, 775], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"max_sigma\"", "]", "=", "self", ".", "max_sigma", "\n", "config", "[", "\"random_blur_range\"", "]", "=", "self", ".", "blur_range", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.DynamicGaussianBlur.build": [[776, 785], ["getattr", "utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "super().build", "len", "len", "numpy.linalg.norm", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "assert", "len", "(", "input_shape", ")", "==", "2", ",", "'sigma should be provided as an input tensor for dynamic blurring'", "\n", "self", ".", "n_dims", "=", "len", "(", "input_shape", "[", "0", "]", ")", "-", "2", "\n", "self", ".", "n_channels", "=", "input_shape", "[", "0", "]", "[", "-", "1", "]", "\n", "self", ".", "convnd", "=", "getattr", "(", "tf", ".", "nn", ",", "'conv%dd'", "%", "self", ".", "n_dims", ")", "\n", "self", ".", "max_sigma", "=", "utils", ".", "reformat_to_list", "(", "self", ".", "max_sigma", ",", "length", "=", "self", ".", "n_dims", ")", "\n", "self", ".", "separable", "=", "np", ".", "linalg", ".", "norm", "(", "np", ".", "array", "(", "self", ".", "max_sigma", ")", ")", ">", "5", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "DynamicGaussianBlur", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.DynamicGaussianBlur.call": [[786, 796], ["edit_tensors.gaussian_kernel", "tensorflow.map_fn", "tensorflow.map_fn"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.gaussian_kernel"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "image", "=", "inputs", "[", "0", "]", "\n", "sigma", "=", "inputs", "[", "-", "1", "]", "\n", "kernels", "=", "l2i_et", ".", "gaussian_kernel", "(", "sigma", ",", "self", ".", "max_sigma", ",", "self", ".", "blur_range", ",", "self", ".", "separable", ")", "\n", "if", "self", ".", "separable", ":", "\n", "            ", "for", "kernel", "in", "kernels", ":", "\n", "                ", "image", "=", "tf", ".", "map_fn", "(", "self", ".", "_single_blur", ",", "[", "image", ",", "kernel", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "", "else", ":", "\n", "            ", "image", "=", "tf", ".", "map_fn", "(", "self", ".", "_single_blur", ",", "[", "image", ",", "kernels", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.DynamicGaussianBlur._single_blur": [[797, 809], ["tensorflow.split", "list", "tensorflow.concat", "layers.DynamicGaussianBlur.convnd", "tensorflow.squeeze", "layers.DynamicGaussianBlur.convnd", "list.append", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.squeeze"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "def", "_single_blur", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "n_channels", ">", "1", ":", "\n", "            ", "split_channels", "=", "tf", ".", "split", "(", "inputs", "[", "0", "]", ",", "[", "1", "]", "*", "self", ".", "n_channels", ",", "axis", "=", "-", "1", ")", "\n", "blurred_channel", "=", "list", "(", ")", "\n", "for", "channel", "in", "split_channels", ":", "\n", "                ", "blurred", "=", "self", ".", "convnd", "(", "tf", ".", "expand_dims", "(", "channel", ",", "0", ")", ",", "inputs", "[", "1", "]", ",", "[", "1", "]", "*", "(", "self", ".", "n_dims", "+", "2", ")", ",", "padding", "=", "'SAME'", ")", "\n", "blurred_channel", ".", "append", "(", "tf", ".", "squeeze", "(", "blurred", ",", "axis", "=", "0", ")", ")", "\n", "", "output", "=", "tf", ".", "concat", "(", "blurred_channel", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "convnd", "(", "tf", ".", "expand_dims", "(", "inputs", "[", "0", "]", ",", "0", ")", ",", "inputs", "[", "1", "]", ",", "[", "1", "]", "*", "(", "self", ".", "n_dims", "+", "2", ")", ",", "padding", "=", "'SAME'", ")", "\n", "output", "=", "tf", ".", "squeeze", "(", "output", ",", "axis", "=", "0", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MimicAcquisition.__init__": [[850, 872], ["len", "keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "volume_res", ",", "min_subsample_res", ",", "resample_shape", ",", "build_dist_map", "=", "False", ",", "noise_std", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "\n", "# resolutions and dimensions", "\n", "        ", "self", ".", "volume_res", "=", "volume_res", "\n", "self", ".", "min_subsample_res", "=", "min_subsample_res", "\n", "self", ".", "noise_std", "=", "noise_std", "\n", "self", ".", "n_dims", "=", "len", "(", "self", ".", "volume_res", ")", "\n", "self", ".", "n_channels", "=", "None", "\n", "self", ".", "add_batchsize", "=", "None", "\n", "\n", "# input and output shapes", "\n", "self", ".", "inshape", "=", "None", "\n", "self", ".", "resample_shape", "=", "resample_shape", "\n", "\n", "# meshgrids for resampling", "\n", "self", ".", "down_grid", "=", "None", "\n", "self", ".", "up_grid", "=", "None", "\n", "\n", "# whether to return a map indicating the distance from the interpolated voxels, to acquired ones.", "\n", "self", ".", "build_dist_map", "=", "build_dist_map", "\n", "\n", "super", "(", "MimicAcquisition", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MimicAcquisition.get_config": [[873, 881], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"volume_res\"", "]", "=", "self", ".", "volume_res", "\n", "config", "[", "\"min_subsample_res\"", "]", "=", "self", ".", "min_subsample_res", "\n", "config", "[", "\"noise_std\"", "]", "=", "self", ".", "noise_std", "\n", "config", "[", "\"resample_shape\"", "]", "=", "self", ".", "resample_shape", "\n", "config", "[", "\"build_dist_map\"", "]", "=", "self", ".", "build_dist_map", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MimicAcquisition.build": [[882, 896], ["numpy.int32", "tensorflow.expand_dims", "tensorflow.expand_dims", "super().build", "tensorflow.stack", "tensorflow.stack", "ext.neuron.utils.volshape_to_ndgrid", "ext.neuron.utils.volshape_to_ndgrid", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.volshape_to_ndgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.volshape_to_ndgrid"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "# set up input shape and acquisistion shape", "\n", "        ", "self", ".", "inshape", "=", "input_shape", "[", "0", "]", "[", "1", ":", "]", "\n", "self", ".", "n_channels", "=", "input_shape", "[", "0", "]", "[", "-", "1", "]", "\n", "self", ".", "add_batchsize", "=", "False", "if", "(", "input_shape", "[", "1", "]", "[", "0", "]", "is", "None", ")", "else", "True", "\n", "down_tensor_shape", "=", "np", ".", "int32", "(", "np", ".", "array", "(", "self", ".", "inshape", "[", ":", "-", "1", "]", ")", "*", "self", ".", "volume_res", "/", "self", ".", "min_subsample_res", ")", "\n", "\n", "# build interpolation meshgrids", "\n", "self", ".", "down_grid", "=", "tf", ".", "expand_dims", "(", "tf", ".", "stack", "(", "nrn_utils", ".", "volshape_to_ndgrid", "(", "down_tensor_shape", ")", ",", "-", "1", ")", ",", "axis", "=", "0", ")", "\n", "self", ".", "up_grid", "=", "tf", ".", "expand_dims", "(", "tf", ".", "stack", "(", "nrn_utils", ".", "volshape_to_ndgrid", "(", "self", ".", "resample_shape", ")", ",", "-", "1", ")", ",", "axis", "=", "0", ")", "\n", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "MimicAcquisition", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MimicAcquisition.call": [[897, 954], ["tensorflow.cast", "keras.reshape", "tensorflow.concat", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.tile", "tensorflow.tile", "edit_tensors.expand_dims", "keras.clip", "tensorflow.map_fn", "tensorflow.tile", "tensorflow.map_fn", "len", "tensorflow.split", "tensorflow.tile", "tensorflow.concat", "tensorflow.cast", "edit_tensors.expand_dims", "tensorflow.expand_dims", "tensorflow.cast", "tensorflow.concat", "tensorflow.random.normal", "tensorflow.concat", "tensorflow.cast", "edit_tensors.expand_dims", "tensorflow.math.floor", "tensorflow.math.ceil", "tensorflow.math.sqrt", "tensorflow.shape", "tensorflow.ones", "tensorflow.expand_dims", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.shape", "tensorflow.math.minimum", "edit_tensors.expand_dims", "tensorflow.math.reduce_sum", "tensorflow.ones", "tensorflow.ones", "tensorflow.random.uniform", "tensorflow.ones", "tensorflow.math.square", "numpy.array", "tensorflow.ones"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# sort inputs", "\n", "        ", "assert", "len", "(", "inputs", ")", "==", "2", ",", "'inputs must have two items, the tensor to resample, and the downsampling resolution'", "\n", "vol", "=", "inputs", "[", "0", "]", "\n", "subsample_res", "=", "tf", ".", "cast", "(", "inputs", "[", "1", "]", ",", "dtype", "=", "'float32'", ")", "\n", "vol", "=", "K", ".", "reshape", "(", "vol", ",", "[", "-", "1", ",", "*", "self", ".", "inshape", "]", ")", "# necessary for multi_gpu models", "\n", "batchsize", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "vol", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", "\n", "tile_shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "[", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", "\n", "\n", "# get downsampling and upsampling factors", "\n", "if", "self", ".", "add_batchsize", ":", "\n", "            ", "subsample_res", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "subsample_res", ",", "0", ")", ",", "tile_shape", ")", "\n", "", "down_shape", "=", "tf", ".", "cast", "(", "tf", ".", "convert_to_tensor", "(", "np", ".", "array", "(", "self", ".", "inshape", "[", ":", "-", "1", "]", ")", "*", "self", ".", "volume_res", ",", "dtype", "=", "'float32'", ")", "/", "\n", "subsample_res", ",", "dtype", "=", "'int32'", ")", "\n", "down_zoom_factor", "=", "tf", ".", "cast", "(", "down_shape", "/", "tf", ".", "convert_to_tensor", "(", "self", ".", "inshape", "[", ":", "-", "1", "]", ")", ",", "dtype", "=", "'float32'", ")", "\n", "up_zoom_factor", "=", "tf", ".", "cast", "(", "tf", ".", "convert_to_tensor", "(", "self", ".", "resample_shape", ",", "dtype", "=", "'int32'", ")", "/", "down_shape", ",", "dtype", "=", "'float32'", ")", "\n", "\n", "# downsample", "\n", "down_loc", "=", "tf", ".", "tile", "(", "self", ".", "down_grid", ",", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "[", "self", ".", "n_dims", "+", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", ")", "\n", "down_loc", "=", "tf", ".", "cast", "(", "down_loc", ",", "'float32'", ")", "/", "l2i_et", ".", "expand_dims", "(", "down_zoom_factor", ",", "axis", "=", "[", "1", "]", "*", "self", ".", "n_dims", ")", "\n", "inshape_tens", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "convert_to_tensor", "(", "self", ".", "inshape", "[", ":", "-", "1", "]", ")", ",", "0", ")", ",", "tile_shape", ")", "\n", "inshape_tens", "=", "l2i_et", ".", "expand_dims", "(", "inshape_tens", ",", "axis", "=", "[", "1", "]", "*", "self", ".", "n_dims", ")", "\n", "down_loc", "=", "K", ".", "clip", "(", "down_loc", ",", "0.", ",", "tf", ".", "cast", "(", "inshape_tens", ",", "'float32'", ")", ")", "\n", "vol", "=", "tf", ".", "map_fn", "(", "self", ".", "_single_down_interpn", ",", "[", "vol", ",", "down_loc", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "# add noise", "\n", "if", "self", ".", "noise_std", ">", "0", ":", "\n", "            ", "sample_shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "[", "self", ".", "n_dims", "]", ",", "dtype", "=", "'int32'", ")", ",", "\n", "self", ".", "n_channels", "*", "tf", ".", "ones", "(", "[", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", "\n", "vol", "+=", "tf", ".", "random", ".", "normal", "(", "tf", ".", "shape", "(", "vol", ")", ",", "stddev", "=", "tf", ".", "random", ".", "uniform", "(", "sample_shape", ",", "maxval", "=", "self", ".", "noise_std", ")", ")", "\n", "\n", "# upsample", "\n", "", "up_loc", "=", "tf", ".", "tile", "(", "self", ".", "up_grid", ",", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "[", "self", ".", "n_dims", "+", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "up_loc", "=", "tf", ".", "cast", "(", "up_loc", ",", "'float32'", ")", "/", "l2i_et", ".", "expand_dims", "(", "up_zoom_factor", ",", "axis", "=", "[", "1", "]", "*", "self", ".", "n_dims", ")", "\n", "vol", "=", "tf", ".", "map_fn", "(", "self", ".", "_single_up_interpn", ",", "[", "vol", ",", "up_loc", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "# return upsampled volume", "\n", "if", "not", "self", ".", "build_dist_map", ":", "\n", "            ", "return", "vol", "\n", "\n", "# return upsampled volumes with distance maps", "\n", "", "else", ":", "\n", "\n", "# get grid points", "\n", "            ", "floor", "=", "tf", ".", "math", ".", "floor", "(", "up_loc", ")", "\n", "ceil", "=", "tf", ".", "math", ".", "ceil", "(", "up_loc", ")", "\n", "\n", "# get distances of every voxel to higher and lower grid points for every dimension", "\n", "f_dist", "=", "up_loc", "-", "floor", "\n", "c_dist", "=", "ceil", "-", "up_loc", "\n", "\n", "# keep minimum 1d distances, and compute 3d distance to nearest grid point", "\n", "dist", "=", "tf", ".", "math", ".", "minimum", "(", "f_dist", ",", "c_dist", ")", "*", "l2i_et", ".", "expand_dims", "(", "subsample_res", ",", "axis", "=", "[", "1", "]", "*", "self", ".", "n_dims", ")", "\n", "dist", "=", "tf", ".", "math", ".", "sqrt", "(", "tf", ".", "math", ".", "reduce_sum", "(", "tf", ".", "math", ".", "square", "(", "dist", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "\n", "return", "[", "vol", ",", "dist", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MimicAcquisition._single_down_interpn": [[955, 958], ["ext.neuron.utils.interpn"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.interpn"], ["", "", "@", "staticmethod", "\n", "def", "_single_down_interpn", "(", "inputs", ")", ":", "\n", "        ", "return", "nrn_utils", ".", "interpn", "(", "inputs", "[", "0", "]", ",", "inputs", "[", "1", "]", ",", "interp_method", "=", "'nearest'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MimicAcquisition._single_up_interpn": [[959, 962], ["ext.neuron.utils.interpn"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.interpn"], ["", "@", "staticmethod", "\n", "def", "_single_up_interpn", "(", "inputs", ")", ":", "\n", "        ", "return", "nrn_utils", ".", "interpn", "(", "inputs", "[", "0", "]", ",", "inputs", "[", "1", "]", ",", "interp_method", "=", "'linear'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MimicAcquisition.compute_output_shape": [[963, 966], ["tuple"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "output_shape", "=", "tuple", "(", "[", "None", "]", "+", "self", ".", "resample_shape", "+", "[", "input_shape", "[", "0", "]", "[", "-", "1", "]", "]", ")", "\n", "return", "[", "output_shape", "]", "*", "2", "if", "self", ".", "build_dist_map", "else", "output_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.BiasFieldCorruption.__init__": [[983, 1001], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "bias_field_std", "=", ".5", ",", "bias_shape_factor", "=", ".025", ",", "same_bias_for_all_channels", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "\n", "# input shape", "\n", "        ", "self", ".", "several_inputs", "=", "False", "\n", "self", ".", "inshape", "=", "None", "\n", "self", ".", "n_dims", "=", "None", "\n", "self", ".", "n_channels", "=", "None", "\n", "\n", "# sampling shape", "\n", "self", ".", "std_shape", "=", "None", "\n", "self", ".", "small_bias_shape", "=", "None", "\n", "\n", "# bias field parameters", "\n", "self", ".", "bias_field_std", "=", "bias_field_std", "\n", "self", ".", "bias_shape_factor", "=", "bias_shape_factor", "\n", "self", ".", "same_bias_for_all_channels", "=", "same_bias_for_all_channels", "\n", "\n", "super", "(", "BiasFieldCorruption", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.BiasFieldCorruption.get_config": [[1002, 1008], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"bias_field_std\"", "]", "=", "self", ".", "bias_field_std", "\n", "config", "[", "\"bias_shape_factor\"", "]", "=", "self", ".", "bias_shape_factor", "\n", "config", "[", "\"same_bias_for_all_channels\"", "]", "=", "self", ".", "same_bias_for_all_channels", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.BiasFieldCorruption.build": [[1009, 1029], ["isinstance", "utils.get_resample_shape", "ext.neuron.utils.get_resample_shape", "ext.neuron.utils.get_resample_shape", "super().build", "len"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_resample_shape", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_resample_shape", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_resample_shape", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "# input shape", "\n", "        ", "if", "isinstance", "(", "input_shape", ",", "list", ")", ":", "\n", "            ", "self", ".", "several_inputs", "=", "True", "\n", "self", ".", "inshape", "=", "input_shape", "\n", "", "else", ":", "\n", "            ", "self", ".", "inshape", "=", "[", "input_shape", "]", "\n", "", "self", ".", "n_dims", "=", "len", "(", "self", ".", "inshape", "[", "0", "]", ")", "-", "2", "\n", "self", ".", "n_channels", "=", "self", ".", "inshape", "[", "0", "]", "[", "-", "1", "]", "\n", "\n", "# sampling shapes", "\n", "self", ".", "std_shape", "=", "[", "1", "]", "*", "(", "self", ".", "n_dims", "+", "1", ")", "\n", "self", ".", "small_bias_shape", "=", "utils", ".", "get_resample_shape", "(", "self", ".", "inshape", "[", "0", "]", "[", "1", ":", "self", ".", "n_dims", "+", "1", "]", ",", "self", ".", "bias_shape_factor", ",", "1", ")", "\n", "if", "not", "self", ".", "same_bias_for_all_channels", ":", "\n", "            ", "self", ".", "std_shape", "[", "-", "1", "]", "=", "self", ".", "n_channels", "\n", "self", ".", "small_bias_shape", "[", "-", "1", "]", "=", "self", ".", "n_channels", "\n", "\n", "", "self", ".", "built", "=", "True", "\n", "super", "(", "BiasFieldCorruption", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.BiasFieldCorruption.call": [[1030, 1053], ["tensorflow.concat", "tensorflow.concat", "tensorflow.random.normal", "tensorflow.math.exp", "tensorflow.split", "ext.Resize", "tensorflow.math.multiply", "tensorflow.shape", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.random.uniform"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "not", "self", ".", "several_inputs", ":", "\n", "            ", "inputs", "=", "[", "inputs", "]", "\n", "\n", "", "if", "self", ".", "bias_field_std", ">", "0", ":", "\n", "\n", "# sampling shapes", "\n", "            ", "batchsize", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", "\n", "std_shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "convert_to_tensor", "(", "self", ".", "std_shape", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", "\n", "bias_shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "convert_to_tensor", "(", "self", ".", "small_bias_shape", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", "\n", "\n", "# sample small bias field", "\n", "bias_field", "=", "tf", ".", "random", ".", "normal", "(", "bias_shape", ",", "stddev", "=", "tf", ".", "random", ".", "uniform", "(", "std_shape", ",", "maxval", "=", "self", ".", "bias_field_std", ")", ")", "\n", "\n", "# resize bias field and take exponential", "\n", "bias_field", "=", "nrn_layers", ".", "Resize", "(", "size", "=", "self", ".", "inshape", "[", "0", "]", "[", "1", ":", "self", ".", "n_dims", "+", "1", "]", ",", "interp_method", "=", "'linear'", ")", "(", "bias_field", ")", "\n", "bias_field", "=", "tf", ".", "math", ".", "exp", "(", "bias_field", ")", "\n", "\n", "return", "[", "tf", ".", "math", ".", "multiply", "(", "bias_field", ",", "v", ")", "for", "v", "in", "inputs", "]", "\n", "\n", "", "else", ":", "\n", "            ", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.IntensityAugmentation.__init__": [[1079, 1100], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "noise_std", "=", "0", ",", "clip", "=", "0", ",", "normalise", "=", "True", ",", "norm_perc", "=", "0", ",", "gamma_std", "=", "0", ",", "separate_channels", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# shape attributes", "\n", "        ", "self", ".", "n_dims", "=", "None", "\n", "self", ".", "n_channels", "=", "None", "\n", "self", ".", "flatten_shape", "=", "None", "\n", "self", ".", "expand_minmax_dim", "=", "None", "\n", "self", ".", "one", "=", "None", "\n", "\n", "# inputs", "\n", "self", ".", "noise_std", "=", "noise_std", "\n", "self", ".", "clip", "=", "clip", "\n", "self", ".", "clip_values", "=", "None", "\n", "self", ".", "normalise", "=", "normalise", "\n", "self", ".", "norm_perc", "=", "norm_perc", "\n", "self", ".", "perc", "=", "None", "\n", "self", ".", "gamma_std", "=", "gamma_std", "\n", "self", ".", "separate_channels", "=", "separate_channels", "\n", "\n", "super", "(", "IntensityAugmentation", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.IntensityAugmentation.get_config": [[1101, 1110], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"noise_std\"", "]", "=", "self", ".", "noise_std", "\n", "config", "[", "\"clip\"", "]", "=", "self", ".", "clip", "\n", "config", "[", "\"normalise\"", "]", "=", "self", ".", "normalise", "\n", "config", "[", "\"norm_perc\"", "]", "=", "self", ".", "norm_perc", "\n", "config", "[", "\"gamma_std\"", "]", "=", "self", ".", "gamma_std", "\n", "config", "[", "\"separate_channels\"", "]", "=", "self", ".", "separate_channels", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.IntensityAugmentation.build": [[1111, 1131], ["numpy.prod", "tensorflow.ones", "super().build", "len", "numpy.array", "utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "len", "len"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "n_dims", "=", "len", "(", "input_shape", ")", "-", "2", "\n", "self", ".", "n_channels", "=", "input_shape", "[", "-", "1", "]", "\n", "self", ".", "flatten_shape", "=", "np", ".", "prod", "(", "np", ".", "array", "(", "input_shape", "[", "1", ":", "-", "1", "]", ")", ")", "\n", "self", ".", "flatten_shape", "=", "self", ".", "flatten_shape", "*", "self", ".", "n_channels", "if", "not", "self", ".", "separate_channels", "else", "self", ".", "flatten_shape", "\n", "self", ".", "expand_minmax_dim", "=", "self", ".", "n_dims", "if", "self", ".", "separate_channels", "else", "self", ".", "n_dims", "+", "1", "\n", "self", ".", "one", "=", "tf", ".", "ones", "(", "[", "1", "]", ",", "dtype", "=", "'int32'", ")", "\n", "if", "self", ".", "clip", ":", "\n", "            ", "self", ".", "clip_values", "=", "utils", ".", "reformat_to_list", "(", "self", ".", "clip", ")", "\n", "self", ".", "clip_values", "=", "self", ".", "clip_values", "if", "len", "(", "self", ".", "clip_values", ")", "==", "2", "else", "[", "0", ",", "self", ".", "clip_values", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "clip_values", "=", "None", "\n", "", "if", "self", ".", "norm_perc", ":", "\n", "            ", "self", ".", "perc", "=", "utils", ".", "reformat_to_list", "(", "self", ".", "norm_perc", ")", "\n", "self", ".", "perc", "=", "self", ".", "perc", "if", "len", "(", "self", ".", "perc", ")", "==", "2", "else", "[", "self", ".", "perc", "[", "0", "]", ",", "1", "-", "self", ".", "perc", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "perc", "=", "None", "\n", "\n", "", "self", ".", "built", "=", "True", "\n", "super", "(", "IntensityAugmentation", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.IntensityAugmentation.call": [[1132, 1185], ["tensorflow.split", "tensorflow.concat", "tensorflow.random.uniform", "keras.clip", "edit_tensors.expand_dims", "edit_tensors.expand_dims", "tensorflow.clip_by_value", "tensorflow.math.pow", "tensorflow.shape", "tensorflow.concat", "tensorflow.concat", "tensorflow.random.normal", "tensorflow.random.normal", "tensorflow.tile", "tensorflow.sort", "keras.min", "keras.max", "tensorflow.math.exp", "tensorflow.ones", "tensorflow.shape", "tensorflow.shape", "tensorflow.convert_to_tensor", "tensorflow.concat", "tensorflow.concat", "tensorflow.reshape", "keras.epsilon", "tensorflow.random.normal", "list", "list", "tensorflow.split", "max", "min", "range", "range", "int", "int"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# prepare shape for sampling the noise and gamma std dev (depending on whether we augment channels separately)", "\n", "        ", "batchsize", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", "\n", "if", "(", "self", ".", "noise_std", ">", "0", ")", "|", "(", "self", ".", "gamma_std", ">", "0", ")", ":", "\n", "            ", "sample_shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "[", "self", ".", "n_dims", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", "\n", "if", "self", ".", "separate_channels", ":", "\n", "                ", "sample_shape", "=", "tf", ".", "concat", "(", "[", "sample_shape", ",", "self", ".", "n_channels", "*", "self", ".", "one", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "sample_shape", "=", "tf", ".", "concat", "(", "[", "sample_shape", ",", "self", ".", "one", "]", ",", "0", ")", "\n", "", "", "else", ":", "\n", "            ", "sample_shape", "=", "None", "\n", "\n", "# add noise", "\n", "", "if", "self", ".", "noise_std", ">", "0", ":", "\n", "            ", "noise_stddev", "=", "tf", ".", "random", ".", "uniform", "(", "sample_shape", ",", "maxval", "=", "self", ".", "noise_std", ")", "\n", "if", "self", ".", "separate_channels", ":", "\n", "                ", "noise", "=", "tf", ".", "random", ".", "normal", "(", "tf", ".", "shape", "(", "inputs", ")", ",", "stddev", "=", "noise_stddev", ")", "\n", "", "else", ":", "\n", "                ", "noise", "=", "tf", ".", "random", ".", "normal", "(", "tf", ".", "shape", "(", "tf", ".", "split", "(", "inputs", ",", "[", "1", ",", "-", "1", "]", ",", "-", "1", ")", "[", "0", "]", ")", ",", "stddev", "=", "noise_stddev", ")", "\n", "noise", "=", "tf", ".", "tile", "(", "noise", ",", "tf", ".", "convert_to_tensor", "(", "[", "1", "]", "*", "(", "self", ".", "n_dims", "+", "1", ")", "+", "[", "self", ".", "n_channels", "]", ")", ")", "\n", "", "inputs", "=", "inputs", "+", "noise", "\n", "\n", "# clip images to given values", "\n", "", "if", "self", ".", "clip_values", "is", "not", "None", ":", "\n", "            ", "inputs", "=", "K", ".", "clip", "(", "inputs", ",", "self", ".", "clip_values", "[", "0", "]", ",", "self", ".", "clip_values", "[", "1", "]", ")", "\n", "\n", "# normalise", "\n", "", "if", "self", ".", "normalise", ":", "\n", "# define robust min and max by sorting values and taking percentile", "\n", "            ", "if", "self", ".", "perc", "is", "not", "None", ":", "\n", "                ", "if", "self", ".", "separate_channels", ":", "\n", "                    ", "shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "self", ".", "flatten_shape", "*", "self", ".", "one", ",", "self", ".", "n_channels", "*", "self", ".", "one", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                    ", "shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "self", ".", "flatten_shape", "*", "self", ".", "one", "]", ",", "0", ")", "\n", "", "intensities", "=", "tf", ".", "sort", "(", "tf", ".", "reshape", "(", "inputs", ",", "shape", ")", ",", "axis", "=", "1", ")", "\n", "m", "=", "intensities", "[", ":", ",", "max", "(", "int", "(", "self", ".", "perc", "[", "0", "]", "*", "self", ".", "flatten_shape", ")", ",", "0", ")", ",", "...", "]", "\n", "M", "=", "intensities", "[", ":", ",", "min", "(", "int", "(", "self", ".", "perc", "[", "1", "]", "*", "self", ".", "flatten_shape", ")", ",", "self", ".", "flatten_shape", "-", "1", ")", ",", "...", "]", "\n", "# simple min and max", "\n", "", "else", ":", "\n", "                ", "m", "=", "K", ".", "min", "(", "inputs", ",", "axis", "=", "list", "(", "range", "(", "1", ",", "self", ".", "expand_minmax_dim", "+", "1", ")", ")", ")", "\n", "M", "=", "K", ".", "max", "(", "inputs", ",", "axis", "=", "list", "(", "range", "(", "1", ",", "self", ".", "expand_minmax_dim", "+", "1", ")", ")", ")", "\n", "# normalise", "\n", "", "m", "=", "l2i_et", ".", "expand_dims", "(", "m", ",", "axis", "=", "[", "1", "]", "*", "self", ".", "expand_minmax_dim", ")", "\n", "M", "=", "l2i_et", ".", "expand_dims", "(", "M", ",", "axis", "=", "[", "1", "]", "*", "self", ".", "expand_minmax_dim", ")", "\n", "inputs", "=", "tf", ".", "clip_by_value", "(", "inputs", ",", "m", ",", "M", ")", "\n", "inputs", "=", "(", "inputs", "-", "m", ")", "/", "(", "M", "-", "m", "+", "K", ".", "epsilon", "(", ")", ")", "\n", "\n", "# apply voxel-wise exponentiation", "\n", "", "if", "self", ".", "gamma_std", ">", "0", ":", "\n", "            ", "inputs", "=", "tf", ".", "math", ".", "pow", "(", "inputs", ",", "tf", ".", "math", ".", "exp", "(", "tf", ".", "random", ".", "normal", "(", "sample_shape", ",", "stddev", "=", "self", ".", "gamma_std", ")", ")", ")", "\n", "\n", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.DiceLoss.__init__": [[1192, 1196], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "enable_checks", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "inshape", "=", "None", "\n", "self", ".", "enable_checks", "=", "enable_checks", "\n", "super", "(", "DiceLoss", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.DiceLoss.build": [[1197, 1203], ["super().build", "len"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "assert", "len", "(", "input_shape", ")", "==", "2", ",", "'DiceLoss expects 2 inputs to compute the Dice loss.'", "\n", "assert", "input_shape", "[", "0", "]", "==", "input_shape", "[", "1", "]", ",", "'the two inputs must have the same shape.'", "\n", "self", ".", "inshape", "=", "input_shape", "[", "0", "]", "[", "1", ":", "]", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "DiceLoss", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.DiceLoss.call": [[1204, 1220], ["tensorflow.math.reduce_sum", "tensorflow.math.reduce_sum", "keras.mean", "keras.clip", "keras.clip", "tensorflow.keras.backend.epsilon", "list", "tensorflow.math.square", "tensorflow.math.square", "list", "tensorflow.math.reduce_sum", "tensorflow.math.reduce_sum", "range", "range", "len", "len"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# make sure tensors are probabilistic", "\n", "        ", "x", "=", "inputs", "[", "0", "]", "\n", "y", "=", "inputs", "[", "1", "]", "\n", "if", "self", ".", "enable_checks", ":", "# disabling is useful to, e.g., use incomplete label maps", "\n", "            ", "x", "=", "K", ".", "clip", "(", "x", "/", "tf", ".", "math", ".", "reduce_sum", "(", "x", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "0", ",", "1", ")", "\n", "y", "=", "K", ".", "clip", "(", "y", "/", "tf", ".", "math", ".", "reduce_sum", "(", "y", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ",", "0", ",", "1", ")", "\n", "\n", "# compute dice loss for each label", "\n", "", "top", "=", "tf", ".", "math", ".", "reduce_sum", "(", "2", "*", "x", "*", "y", ",", "axis", "=", "list", "(", "range", "(", "1", ",", "len", "(", "self", ".", "inshape", ")", ")", ")", ")", "\n", "bottom", "=", "tf", ".", "math", ".", "square", "(", "x", ")", "+", "tf", ".", "math", ".", "square", "(", "y", ")", "+", "tf", ".", "keras", ".", "backend", ".", "epsilon", "(", ")", "\n", "bottom", "=", "tf", ".", "math", ".", "reduce_sum", "(", "bottom", ",", "axis", "=", "list", "(", "range", "(", "1", ",", "len", "(", "self", ".", "inshape", ")", ")", ")", ")", "\n", "last_tensor", "=", "top", "/", "bottom", "\n", "\n", "return", "K", ".", "mean", "(", "1", "-", "last_tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.DiceLoss.compute_output_shape": [[1221, 1223], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "[", "[", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.WeightedL2Loss.__init__": [[1231, 1236], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "target_value", ",", "background_weight", "=", "1e-4", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "target_value", "=", "target_value", "\n", "self", ".", "background_weight", "=", "background_weight", "\n", "self", ".", "n_labels", "=", "None", "\n", "super", "(", "WeightedL2Loss", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.WeightedL2Loss.get_config": [[1237, 1242], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"target_value\"", "]", "=", "self", ".", "target_value", "\n", "config", "[", "\"background_weight\"", "]", "=", "self", ".", "background_weight", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.WeightedL2Loss.build": [[1243, 1249], ["super().build", "len"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "assert", "len", "(", "input_shape", ")", "==", "2", ",", "'DiceLoss expects 2 inputs to compute the Dice loss.'", "\n", "assert", "input_shape", "[", "0", "]", "==", "input_shape", "[", "1", "]", ",", "'the two inputs must have the same shape.'", "\n", "self", ".", "n_labels", "=", "input_shape", "[", "0", "]", "[", "-", "1", "]", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "WeightedL2Loss", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.WeightedL2Loss.call": [[1250, 1255], ["tensorflow.expand_dims", "keras.sum", "keras.sum", "keras.square"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "gt", "=", "inputs", "[", "0", "]", "\n", "pred", "=", "inputs", "[", "1", "]", "\n", "weights", "=", "tf", ".", "expand_dims", "(", "1", "-", "gt", "[", "...", ",", "0", "]", "+", "self", ".", "background_weight", ",", "-", "1", ")", "\n", "return", "K", ".", "sum", "(", "weights", "*", "K", ".", "square", "(", "pred", "-", "self", ".", "target_value", "*", "(", "2", "*", "gt", "-", "1", ")", ")", ")", "/", "(", "K", ".", "sum", "(", "weights", ")", "*", "self", ".", "n_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.WeightedL2Loss.compute_output_shape": [[1256, 1258], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "[", "[", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.ResetValuesToZero.__init__": [[1276, 1282], ["utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "len", "keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "values", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "values", "is", "not", "None", ",", "'please provide correct list of values, received None'", "\n", "self", ".", "values", "=", "utils", ".", "reformat_to_list", "(", "values", ")", "\n", "self", ".", "values_tens", "=", "None", "\n", "self", ".", "n_values", "=", "len", "(", "values", ")", "\n", "super", "(", "ResetValuesToZero", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.ResetValuesToZero.get_config": [[1283, 1287], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"values\"", "]", "=", "self", ".", "values", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.ResetValuesToZero.build": [[1288, 1292], ["tensorflow.convert_to_tensor", "super().build"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "values_tens", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "values", ")", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "ResetValuesToZero", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.ResetValuesToZero.call": [[1293, 1298], ["tensorflow.cast", "range", "tensorflow.where", "tensorflow.equal", "tensorflow.zeros_like"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "values", "=", "tf", ".", "cast", "(", "self", ".", "values_tens", ",", "dtype", "=", "inputs", ".", "dtype", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_values", ")", ":", "\n", "            ", "inputs", "=", "tf", ".", "where", "(", "tf", ".", "equal", "(", "inputs", ",", "values", "[", "i", "]", ")", ",", "tf", ".", "zeros_like", "(", "inputs", ")", ",", "inputs", ")", "\n", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.ConvertLabels.__init__": [[1312, 1317], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "source_values", ",", "dest_values", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "source_values", "=", "source_values", "\n", "self", ".", "dest_values", "=", "dest_values", "\n", "self", ".", "lut", "=", "None", "\n", "super", "(", "ConvertLabels", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.ConvertLabels.get_config": [[1318, 1323], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"source_values\"", "]", "=", "self", ".", "source_values", "\n", "config", "[", "\"dest_values\"", "]", "=", "self", ".", "dest_values", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.ConvertLabels.build": [[1324, 1328], ["tensorflow.convert_to_tensor", "super().build", "utils.get_mapping_lut", "ext.neuron.utils.get_mapping_lut", "ext.neuron.utils.get_mapping_lut"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_mapping_lut", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_mapping_lut", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_mapping_lut"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "lut", "=", "tf", ".", "convert_to_tensor", "(", "utils", ".", "get_mapping_lut", "(", "self", ".", "source_values", ",", "dest", "=", "self", ".", "dest_values", ")", ",", "dtype", "=", "'int32'", ")", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "ConvertLabels", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.ConvertLabels.call": [[1329, 1331], ["tensorflow.gather", "tensorflow.cast"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "tf", ".", "gather", "(", "self", ".", "lut", ",", "tf", ".", "cast", "(", "inputs", ",", "dtype", "=", "'int32'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.PadAroundCentre.__init__": [[1345, 1353], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "pad_margin", "=", "None", ",", "pad_shape", "=", "None", ",", "value", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "pad_margin", "=", "pad_margin", "\n", "self", ".", "pad_shape", "=", "pad_shape", "\n", "self", ".", "value", "=", "value", "\n", "self", ".", "pad_margin_tens", "=", "None", "\n", "self", ".", "pad_shape_tens", "=", "None", "\n", "self", ".", "n_dims", "=", "None", "\n", "super", "(", "PadAroundCentre", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.PadAroundCentre.get_config": [[1354, 1360], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"pad_margin\"", "]", "=", "self", ".", "pad_margin", "\n", "config", "[", "\"pad_shape\"", "]", "=", "self", ".", "pad_shape", "\n", "config", "[", "\"value\"", "]", "=", "self", ".", "value", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.PadAroundCentre.build": [[1361, 1394], ["list", "super().build", "len", "numpy.transpose", "tensorflow.convert_to_tensor", "numpy.array", "tensorflow.cast", "numpy.array", "tensorflow.convert_to_tensor", "tensorflow.math.maximum", "tensorflow.stack", "Exception", "tensorflow.convert_to_tensor", "utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "# input shape", "\n", "        ", "self", ".", "n_dims", "=", "len", "(", "input_shape", ")", "-", "2", "\n", "shape", "=", "list", "(", "input_shape", ")", "\n", "shape", "[", "0", "]", "=", "0", "\n", "shape", "[", "-", "1", "]", "=", "0", "\n", "\n", "if", "self", ".", "pad_margin", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "pad_shape", "is", "None", ",", "'please do not provide a padding shape and margin at the same time.'", "\n", "\n", "# reformat padding margins", "\n", "pad", "=", "np", ".", "transpose", "(", "np", ".", "array", "(", "[", "[", "0", "]", "+", "utils", ".", "reformat_to_list", "(", "self", ".", "pad_margin", ",", "self", ".", "n_dims", ")", "+", "[", "0", "]", "]", "*", "2", ")", ")", "\n", "self", ".", "pad_margin_tens", "=", "tf", ".", "convert_to_tensor", "(", "pad", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "", "elif", "self", ".", "pad_shape", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "pad_margin", "is", "None", ",", "'please do not provide a padding shape and margin at the same time.'", "\n", "\n", "# pad shape", "\n", "tensor_shape", "=", "tf", ".", "cast", "(", "tf", ".", "convert_to_tensor", "(", "shape", ")", ",", "'int32'", ")", "\n", "self", ".", "pad_shape_tens", "=", "np", ".", "array", "(", "[", "0", "]", "+", "utils", ".", "reformat_to_list", "(", "self", ".", "pad_shape", ",", "length", "=", "self", ".", "n_dims", ")", "+", "[", "0", "]", ")", "\n", "self", ".", "pad_shape_tens", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "pad_shape_tens", ",", "dtype", "=", "'int32'", ")", "\n", "self", ".", "pad_shape_tens", "=", "tf", ".", "math", ".", "maximum", "(", "tensor_shape", ",", "self", ".", "pad_shape_tens", ")", "\n", "\n", "# padding margin", "\n", "min_margins", "=", "(", "self", ".", "pad_shape_tens", "-", "tensor_shape", ")", "/", "2", "\n", "max_margins", "=", "self", ".", "pad_shape_tens", "-", "tensor_shape", "-", "min_margins", "\n", "self", ".", "pad_margin_tens", "=", "tf", ".", "stack", "(", "[", "min_margins", ",", "max_margins", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'please either provide a padding shape or a padding margin.'", ")", "\n", "\n", "", "self", ".", "built", "=", "True", "\n", "super", "(", "PadAroundCentre", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.PadAroundCentre.call": [[1395, 1397], ["tensorflow.pad"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "tf", ".", "pad", "(", "inputs", ",", "self", ".", "pad_margin_tens", ",", "mode", "=", "'CONSTANT'", ",", "constant_values", "=", "self", ".", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MaskEdges.__init__": [[1439, 1445], ["utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "ext.neuron.utils.reformat_to_list", "utils.reformat_to_n_channels_array", "ext.neuron.utils.reformat_to_n_channels_array", "ext.neuron.utils.reformat_to_n_channels_array", "keras.layers.Layer.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_n_channels_array", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_n_channels_array", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_n_channels_array", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "axes", ",", "boundaries", ",", "prob_mask", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "axes", "=", "utils", ".", "reformat_to_list", "(", "axes", ",", "dtype", "=", "'int'", ")", "\n", "self", ".", "boundaries", "=", "utils", ".", "reformat_to_n_channels_array", "(", "boundaries", ",", "n_dims", "=", "4", ",", "n_channels", "=", "len", "(", "self", ".", "axes", ")", ")", "\n", "self", ".", "prob_mask", "=", "prob_mask", "\n", "self", ".", "inputshape", "=", "None", "\n", "super", "(", "MaskEdges", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MaskEdges.get_config": [[1446, 1452], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"axes\"", "]", "=", "self", ".", "axes", "\n", "config", "[", "\"boundaries\"", "]", "=", "self", ".", "boundaries", "\n", "config", "[", "\"prob_mask\"", "]", "=", "self", ".", "prob_mask", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MaskEdges.build": [[1453, 1457], ["super().build"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "inputshape", "=", "input_shape", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "MaskEdges", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MaskEdges.call": [[1458, 1488], ["tensorflow.ones_like", "enumerate", "keras.switch", "tensorflow.math.round", "tensorflow.math.round", "tensorflow.cast", "tensorflow.split", "tensorflow.concat", "tensorflow.squeeze", "tensorflow.random.uniform", "tensorflow.concat", "keras.greater", "tensorflow.random.uniform", "tensorflow.zeros_like", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.random.uniform"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# build mask", "\n", "        ", "mask", "=", "tf", ".", "ones_like", "(", "inputs", ")", "\n", "for", "i", ",", "axis", "in", "enumerate", "(", "self", ".", "axes", ")", ":", "\n", "\n", "# select restricting indices", "\n", "            ", "axis_boundaries", "=", "self", ".", "boundaries", "[", "i", ",", ":", "]", "\n", "idx1", "=", "tf", ".", "math", ".", "round", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "\n", "minval", "=", "axis_boundaries", "[", "0", "]", "*", "self", ".", "inputshape", "[", "axis", "]", ",", "\n", "maxval", "=", "axis_boundaries", "[", "1", "]", "*", "self", ".", "inputshape", "[", "axis", "]", ")", ")", "\n", "idx2", "=", "tf", ".", "math", ".", "round", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "\n", "minval", "=", "axis_boundaries", "[", "2", "]", "*", "self", ".", "inputshape", "[", "axis", "]", ",", "\n", "maxval", "=", "axis_boundaries", "[", "3", "]", "*", "self", ".", "inputshape", "[", "axis", "]", "-", "1", ")", "-", "idx1", ")", "\n", "idx3", "=", "self", ".", "inputshape", "[", "axis", "]", "-", "idx1", "-", "idx2", "\n", "split_idx", "=", "tf", ".", "cast", "(", "tf", ".", "concat", "(", "[", "idx1", ",", "idx2", ",", "idx3", "]", ",", "axis", "=", "0", ")", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "# update mask", "\n", "split_list", "=", "tf", ".", "split", "(", "inputs", ",", "split_idx", ",", "axis", "=", "axis", ")", "\n", "tmp_mask", "=", "tf", ".", "concat", "(", "[", "tf", ".", "zeros_like", "(", "split_list", "[", "0", "]", ")", ",", "\n", "tf", ".", "ones_like", "(", "split_list", "[", "1", "]", ")", ",", "\n", "tf", ".", "zeros_like", "(", "split_list", "[", "2", "]", ")", "]", ",", "axis", "=", "axis", ")", "\n", "mask", "=", "mask", "*", "tmp_mask", "\n", "\n", "# mask second_channel", "\n", "", "tensor", "=", "K", ".", "switch", "(", "tf", ".", "squeeze", "(", "K", ".", "greater", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "0", ",", "1", ")", ",", "1", "-", "self", ".", "prob_mask", ")", ")", ",", "\n", "inputs", "*", "mask", ",", "\n", "inputs", ")", "\n", "\n", "return", "[", "tensor", ",", "mask", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.layers.MaskEdges.compute_output_shape": [[1489, 1491], ["None"], "methods", ["None"], ["", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "[", "input_shape", "]", "*", "2", "\n", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.lab2im_model.lab2im_model": [[28, 125], ["utils.reformat_to_list", "utils.get_dims", "lab2im_model.get_shapes", "keras.Input", "keras.Input", "keras.Input", "tuple", "tuple", "tuple", "edit_tensors.blurring_sigma_for_downsampling", "tuple", "keras.models.Model", "utils.reformat_to_n_channels_array", "layers.RandomSpatialDeformation", "tuple", "edit_tensors.resample_tensor.get_shape().as_list", "layers.SampleConditionalGMM", "edit_tensors.resample_tensor.get_shape().as_list", "layers.BiasFieldCorruption", "edit_tensors.resample_tensor.get_shape().as_list", "layers.IntensityAugmentation", "edit_tensors.resample_tensor.get_shape().as_list", "layers.GaussianBlur", "edit_tensors.resample_tensor", "edit_tensors.resample_tensor", "layers.ConvertLabels", "keras.Lambda", "utils.reformat_to_n_channels_array", "edit_tensors.resample_tensor.get_shape().as_list", "layers.RandomCrop", "list", "list", "edit_tensors.resample_tensor.get_shape", "edit_tensors.resample_tensor.get_shape", "edit_tensors.resample_tensor.get_shape", "edit_tensors.resample_tensor.get_shape", "edit_tensors.resample_tensor.get_shape"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.lab2im_model.get_shapes", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.blurring_sigma_for_downsampling", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_n_channels_array", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.resample_tensor", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.resample_tensor", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_n_channels_array"], ["def", "lab2im_model", "(", "labels_shape", ",", "\n", "n_channels", ",", "\n", "generation_labels", ",", "\n", "output_labels", ",", "\n", "atlas_res", ",", "\n", "target_res", ",", "\n", "output_shape", "=", "None", ",", "\n", "output_div_by_n", "=", "None", ",", "\n", "blur_range", "=", "1.15", ")", ":", "\n", "    ", "\"\"\"\n    This function builds a keras/tensorflow model to generate images from provided label maps.\n    The images are generated by sampling a Gaussian Mixture Model (of given parameters), conditionned on the label map.\n    The model will take as inputs:\n        -a label map\n        -a vector containing the means of the Gaussian Mixture Model for each label,\n        -a vector containing the standard deviations of the Gaussian Mixture Model for each label,\n        -an array of size batch*(n_dims+1)*(n_dims+1) representing a linear transformation\n    The model returns:\n        -the generated image normalised between 0 and 1.\n        -the corresponding label map, with only the labels present in output_labels (the other are reset to zero).\n    :param labels_shape: shape of the input label maps. Can be a sequence or a 1d numpy array.\n    :param n_channels: number of channels to be synthetised.\n    :param generation_labels: list of all possible label values in the input label maps.\n    Can be a sequence or a 1d numpy array.\n    :param output_labels: list of the same length as generation_labels to indicate which values to use in the label maps\n    returned by this model, i.e. all occurences of generation_labels[i] in the input label maps will be converted to\n    output_labels[i] in the returned label maps. Examples:\n    Set output_labels[i] to zero if you wish to erase the value generation_labels[i] from the returned label maps.\n    Set output_labels[i]=generation_labels[i] if you wish to keep the value generation_labels[i] in the returned maps.\n    Can be a list or a 1d numpy array. By default output_labels is equal to generation_labels.\n    :param atlas_res: resolution of the input label maps.\n    Can be a number (isotropic resolution), a sequence, or a 1d numpy array.\n    :param target_res: target resolution of the generated images and corresponding label maps.\n    Can be a number (isotropic resolution), a sequence, or a 1d numpy array.\n    :param output_shape: (optional) desired shape of the output images.\n    If the atlas and target resolutions are the same, the output will be cropped to output_shape, and if the two\n    resolutions are different, the output will be resized with trilinear interpolation to output_shape.\n    Can be an integer (same size in all dimensions), a sequence, or a 1d numpy array.\n    :param output_div_by_n: (optional) forces the output shape to be divisible by this value. It overwrites output_shape\n    if necessary. Can be an integer (same size in all dimensions), a sequence, or a 1d numpy array.\n    :param blur_range: (optional) Randomise the standard deviation of the blurring kernels, (whether data_res is given\n    or not). At each mini_batch, the standard deviation of the blurring kernels are multiplied by a coefficient sampled\n    from a uniform distribution with bounds [1/blur_range, blur_range]. If None, no randomisation. Default is 1.15.\n    \"\"\"", "\n", "\n", "# reformat resolutions", "\n", "labels_shape", "=", "utils", ".", "reformat_to_list", "(", "labels_shape", ")", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "labels_shape", ")", "\n", "atlas_res", "=", "utils", ".", "reformat_to_n_channels_array", "(", "atlas_res", ",", "n_dims", "=", "n_dims", ")", "[", "0", "]", "\n", "target_res", "=", "atlas_res", "if", "(", "target_res", "is", "None", ")", "else", "utils", ".", "reformat_to_n_channels_array", "(", "target_res", ",", "n_dims", ")", "[", "0", "]", "\n", "\n", "# get shapes", "\n", "crop_shape", ",", "output_shape", "=", "get_shapes", "(", "labels_shape", ",", "output_shape", ",", "atlas_res", ",", "target_res", ",", "output_div_by_n", ")", "\n", "\n", "# define model inputs", "\n", "labels_input", "=", "KL", ".", "Input", "(", "shape", "=", "labels_shape", "+", "[", "1", "]", ",", "name", "=", "'labels_input'", ",", "dtype", "=", "'int32'", ")", "\n", "means_input", "=", "KL", ".", "Input", "(", "shape", "=", "list", "(", "generation_labels", ".", "shape", ")", "+", "[", "n_channels", "]", ",", "name", "=", "'means_input'", ")", "\n", "stds_input", "=", "KL", ".", "Input", "(", "shape", "=", "list", "(", "generation_labels", ".", "shape", ")", "+", "[", "n_channels", "]", ",", "name", "=", "'stds_input'", ")", "\n", "\n", "# deform labels", "\n", "labels", "=", "layers", ".", "RandomSpatialDeformation", "(", "inter_method", "=", "'nearest'", ")", "(", "labels_input", ")", "\n", "\n", "# cropping", "\n", "if", "crop_shape", "!=", "labels_shape", ":", "\n", "        ", "labels", ".", "_keras_shape", "=", "tuple", "(", "labels", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "labels", "=", "layers", ".", "RandomCrop", "(", "crop_shape", ")", "(", "labels", ")", "\n", "\n", "# build synthetic image", "\n", "", "labels", ".", "_keras_shape", "=", "tuple", "(", "labels", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "image", "=", "layers", ".", "SampleConditionalGMM", "(", "generation_labels", ")", "(", "[", "labels", ",", "means_input", ",", "stds_input", "]", ")", "\n", "\n", "# apply bias field", "\n", "image", ".", "_keras_shape", "=", "tuple", "(", "image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "image", "=", "layers", ".", "BiasFieldCorruption", "(", ".3", ",", ".025", ",", "same_bias_for_all_channels", "=", "False", ")", "(", "image", ")", "\n", "\n", "# intensity augmentation", "\n", "image", ".", "_keras_shape", "=", "tuple", "(", "image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "image", "=", "layers", ".", "IntensityAugmentation", "(", "clip", "=", "300", ",", "normalise", "=", "True", ",", "gamma_std", "=", ".2", ")", "(", "image", ")", "\n", "\n", "# blur image", "\n", "sigma", "=", "blurring_sigma_for_downsampling", "(", "atlas_res", ",", "target_res", ")", "\n", "image", ".", "_keras_shape", "=", "tuple", "(", "image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "image", "=", "layers", ".", "GaussianBlur", "(", "sigma", "=", "sigma", ",", "random_blur_range", "=", "blur_range", ")", "(", "image", ")", "\n", "\n", "# resample to target res", "\n", "if", "crop_shape", "!=", "output_shape", ":", "\n", "        ", "image", "=", "resample_tensor", "(", "image", ",", "output_shape", ",", "interp_method", "=", "'linear'", ")", "\n", "labels", "=", "resample_tensor", "(", "labels", ",", "output_shape", ",", "interp_method", "=", "'nearest'", ")", "\n", "\n", "# reset unwanted labels to zero", "\n", "", "labels", "=", "layers", ".", "ConvertLabels", "(", "generation_labels", ",", "dest_values", "=", "output_labels", ",", "name", "=", "'labels_out'", ")", "(", "labels", ")", "\n", "\n", "# build model (dummy layer enables to keep the labels when plugging this model to other models)", "\n", "image", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", "[", "0", "]", ",", "name", "=", "'image_out'", ")", "(", "[", "image", ",", "labels", "]", ")", "\n", "brain_model", "=", "Model", "(", "inputs", "=", "[", "labels_input", ",", "means_input", ",", "stds_input", "]", ",", "outputs", "=", "[", "image", ",", "labels", "]", ")", "\n", "\n", "return", "brain_model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.lab2im_model.get_shapes": [[127, 175], ["len", "atlas_res.tolist", "target_res.tolist", "utils.reformat_to_list", "float", "range", "min", "min", "utils.find_closest_number_divisible_by_m", "print", "int", "int", "utils.find_closest_number_divisible_by_m", "int", "range", "range", "numpy.around", "range", "numpy.around", "range"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.find_closest_number_divisible_by_m", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.find_closest_number_divisible_by_m", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "get_shapes", "(", "labels_shape", ",", "output_shape", ",", "atlas_res", ",", "target_res", ",", "output_div_by_n", ")", ":", "\n", "\n", "    ", "n_dims", "=", "len", "(", "atlas_res", ")", "\n", "\n", "# get resampling factor", "\n", "if", "atlas_res", ".", "tolist", "(", ")", "!=", "target_res", ".", "tolist", "(", ")", ":", "\n", "        ", "resample_factor", "=", "[", "atlas_res", "[", "i", "]", "/", "float", "(", "target_res", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "", "else", ":", "\n", "        ", "resample_factor", "=", "None", "\n", "\n", "# output shape specified, need to get cropping shape, and resample shape if necessary", "\n", "", "if", "output_shape", "is", "not", "None", ":", "\n", "        ", "output_shape", "=", "utils", ".", "reformat_to_list", "(", "output_shape", ",", "length", "=", "n_dims", ",", "dtype", "=", "'int'", ")", "\n", "\n", "# make sure that output shape is smaller or equal to label shape", "\n", "if", "resample_factor", "is", "not", "None", ":", "\n", "            ", "output_shape", "=", "[", "min", "(", "int", "(", "labels_shape", "[", "i", "]", "*", "resample_factor", "[", "i", "]", ")", ",", "output_shape", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "", "else", ":", "\n", "            ", "output_shape", "=", "[", "min", "(", "labels_shape", "[", "i", "]", ",", "output_shape", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "\n", "# make sure output shape is divisible by output_div_by_n", "\n", "", "if", "output_div_by_n", "is", "not", "None", ":", "\n", "            ", "tmp_shape", "=", "[", "utils", ".", "find_closest_number_divisible_by_m", "(", "s", ",", "output_div_by_n", ")", "\n", "for", "s", "in", "output_shape", "]", "\n", "if", "output_shape", "!=", "tmp_shape", ":", "\n", "                ", "print", "(", "'output shape {0} not divisible by {1}, changed to {2}'", ".", "format", "(", "output_shape", ",", "output_div_by_n", ",", "\n", "tmp_shape", ")", ")", "\n", "output_shape", "=", "tmp_shape", "\n", "\n", "# get cropping and resample shape", "\n", "", "", "if", "resample_factor", "is", "not", "None", ":", "\n", "            ", "cropping_shape", "=", "[", "int", "(", "np", ".", "around", "(", "output_shape", "[", "i", "]", "/", "resample_factor", "[", "i", "]", ",", "0", ")", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "", "else", ":", "\n", "            ", "cropping_shape", "=", "output_shape", "\n", "\n", "# no output shape specified, so no cropping unless label_shape is not divisible by output_div_by_n", "\n", "", "", "else", ":", "\n", "        ", "cropping_shape", "=", "labels_shape", "\n", "if", "resample_factor", "is", "not", "None", ":", "\n", "            ", "output_shape", "=", "[", "int", "(", "np", ".", "around", "(", "cropping_shape", "[", "i", "]", "*", "resample_factor", "[", "i", "]", ",", "0", ")", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "", "else", ":", "\n", "            ", "output_shape", "=", "cropping_shape", "\n", "# make sure output shape is divisible by output_div_by_n", "\n", "", "if", "output_div_by_n", "is", "not", "None", ":", "\n", "            ", "output_shape", "=", "[", "utils", ".", "find_closest_number_divisible_by_m", "(", "s", ",", "output_div_by_n", ",", "answer_type", "=", "'closer'", ")", "\n", "for", "s", "in", "output_shape", "]", "\n", "\n", "", "", "return", "cropping_shape", ",", "output_shape", "\n", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mask_volume": [[95, 145], ["volume.copy", "list", "utils.get_dims", "utils.build_binary_structure", "scipy.ndimage.binary_dilation", "utils.build_binary_structure", "scipy.ndimage.binary_erosion", "scipy.ndimage.morphology.binary_fill_holes", "list", "list", "numpy.logical_not", "numpy.stack", "numpy.logical_not"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.build_binary_structure", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.build_binary_structure", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack"], ["def", "mask_volume", "(", "volume", ",", "mask", "=", "None", ",", "threshold", "=", "0.1", ",", "dilate", "=", "0", ",", "erode", "=", "0", ",", "fill_holes", "=", "False", ",", "masking_value", "=", "0", ",", "\n", "return_mask", "=", "False", ")", ":", "\n", "    ", "\"\"\"Mask a volume, either with a given mask, or by keeping only the values above a threshold.\n    :param volume: a numpy array, possibly with several channels\n    :param mask: (optional) a numpy array to mask volume with.\n    Mask doesn't have to be a 0/1 array, all strictly positive values of mask are considered for masking volume.\n    Mask should have the same size as volume. If volume has several channels, mask can either be uni- or multi-channel.\n     In the first case, the same mask is applied to all channels.\n    :param threshold: (optional) If mask is None, masking is performed by keeping thresholding the input.\n    :param dilate: (optional) number of voxels by which to dilate the provided or computed mask.\n    :param erode: (optional) number of voxels by which to erode the provided or computed mask.\n    :param fill_holes: (optional) whether to fill the holes in the provided or computed mask.\n    :param masking_value: (optional) masking value\n    :param return_mask: (optional) whether to return the applied mask\n    :return: the masked volume, and the applied mask if return_mask is True.\n    \"\"\"", "\n", "\n", "# get info", "\n", "new_volume", "=", "volume", ".", "copy", "(", ")", "\n", "vol_shape", "=", "list", "(", "new_volume", ".", "shape", ")", "\n", "n_dims", ",", "n_channels", "=", "utils", ".", "get_dims", "(", "vol_shape", ")", "\n", "\n", "# get mask and erode/dilate it", "\n", "if", "mask", "is", "None", ":", "\n", "        ", "mask", "=", "new_volume", ">=", "threshold", "\n", "", "else", ":", "\n", "        ", "assert", "list", "(", "mask", ".", "shape", "[", ":", "n_dims", "]", ")", "==", "vol_shape", "[", ":", "n_dims", "]", ",", "'mask should have shape {0}, or {1}, had {2}'", ".", "format", "(", "\n", "vol_shape", "[", ":", "n_dims", "]", ",", "vol_shape", "[", ":", "n_dims", "]", "+", "[", "n_channels", "]", ",", "list", "(", "mask", ".", "shape", ")", ")", "\n", "mask", "=", "mask", ">", "0", "\n", "", "if", "dilate", ">", "0", ":", "\n", "        ", "dilate_struct", "=", "utils", ".", "build_binary_structure", "(", "dilate", ",", "n_dims", ")", "\n", "mask_to_apply", "=", "binary_dilation", "(", "mask", ",", "dilate_struct", ")", "\n", "", "else", ":", "\n", "        ", "mask_to_apply", "=", "mask", "\n", "", "if", "erode", ">", "0", ":", "\n", "        ", "erode_struct", "=", "utils", ".", "build_binary_structure", "(", "erode", ",", "n_dims", ")", "\n", "mask_to_apply", "=", "binary_erosion", "(", "mask_to_apply", ",", "erode_struct", ")", "\n", "", "if", "fill_holes", ":", "\n", "        ", "mask_to_apply", "=", "binary_fill_holes", "(", "mask_to_apply", ")", "\n", "\n", "# replace values outside of mask by padding_char", "\n", "", "if", "mask_to_apply", ".", "shape", "==", "new_volume", ".", "shape", ":", "\n", "        ", "new_volume", "[", "np", ".", "logical_not", "(", "mask_to_apply", ")", "]", "=", "masking_value", "\n", "", "else", ":", "\n", "        ", "new_volume", "[", "np", ".", "stack", "(", "[", "np", ".", "logical_not", "(", "mask_to_apply", ")", "]", "*", "n_channels", ",", "axis", "=", "-", "1", ")", "]", "=", "masking_value", "\n", "\n", "", "if", "return_mask", ":", "\n", "        ", "return", "new_volume", ",", "mask_to_apply", "\n", "", "else", ":", "\n", "        ", "return", "new_volume", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.rescale_volume": [[147, 176], ["volume.copy", "numpy.clip", "np.clip.flatten", "numpy.min", "numpy.percentile", "numpy.max", "numpy.percentile", "numpy.zeros_like"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.flatten"], ["", "", "def", "rescale_volume", "(", "volume", ",", "new_min", "=", "0", ",", "new_max", "=", "255", ",", "min_percentile", "=", "2", ",", "max_percentile", "=", "98", ",", "use_positive_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"This function linearly rescales a volume between new_min and new_max.\n    :param volume: a numpy array\n    :param new_min: (optional) minimum value for the rescaled image.\n    :param new_max: (optional) maximum value for the rescaled image.\n    :param min_percentile: (optional) percentile for estimating robust minimum of volume (float in [0,...100]),\n    where 0 = np.min\n    :param max_percentile: (optional) percentile for estimating robust maximum of volume (float in [0,...100]),\n    where 100 = np.max\n    :param use_positive_only: (optional) whether to use only positive values when estimating the min and max percentile\n    :return: rescaled volume\n    \"\"\"", "\n", "\n", "# select only positive intensities", "\n", "new_volume", "=", "volume", ".", "copy", "(", ")", "\n", "intensities", "=", "new_volume", "[", "new_volume", ">", "0", "]", "if", "use_positive_only", "else", "new_volume", ".", "flatten", "(", ")", "\n", "\n", "# define min and max intensities in original image for normalisation", "\n", "robust_min", "=", "np", ".", "min", "(", "intensities", ")", "if", "min_percentile", "==", "0", "else", "np", ".", "percentile", "(", "intensities", ",", "min_percentile", ")", "\n", "robust_max", "=", "np", ".", "max", "(", "intensities", ")", "if", "max_percentile", "==", "0", "else", "np", ".", "percentile", "(", "intensities", ",", "max_percentile", ")", "\n", "\n", "# trim values outside range", "\n", "new_volume", "=", "np", ".", "clip", "(", "new_volume", ",", "robust_min", ",", "robust_max", ")", "\n", "\n", "# rescale image", "\n", "if", "robust_min", "!=", "robust_max", ":", "\n", "        ", "return", "new_min", "+", "(", "new_volume", "-", "robust_min", ")", "/", "(", "robust_max", "-", "robust_min", ")", "*", "(", "new_max", "-", "new_min", ")", "\n", "", "else", ":", "# avoid dividing by zero", "\n", "        ", "return", "np", ".", "zeros_like", "(", "new_volume", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume": [[178, 238], ["volume.copy", "utils.get_dims", "numpy.concatenate", "utils.reformat_to_list", "utils.reformat_to_list", "output.append", "output.append", "tuple", "numpy.array", "numpy.maximum", "numpy.minimum", "numpy.array", "numpy.array", "len", "numpy.array", "range", "range", "numpy.maximum", "numpy.random.randint", "numpy.minimum", "ValueError", "numpy.array", "int", "numpy.array", "numpy.array", "range", "range", "numpy.array", "numpy.array", "range"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "", "def", "crop_volume", "(", "volume", ",", "cropping_margin", "=", "None", ",", "cropping_shape", "=", "None", ",", "aff", "=", "None", ",", "return_crop_idx", "=", "False", ",", "mode", "=", "'center'", ")", ":", "\n", "    ", "\"\"\"Crop volume by a given margin, or to a given shape.\n    :param volume: 2d or 3d numpy array (possibly with multiple channels)\n    :param cropping_margin: (optional) margin by which to crop the volume. The cropping margin is applied on both sides.\n    Can be an int, sequence or 1d numpy array of size n_dims. Should be given if cropping_shape is None.\n    :param cropping_shape: (optional) shape to which the volume will be cropped. Can be an int, sequence or 1d numpy\n    array of size n_dims. Should be given if cropping_margin is None.\n    :param aff: (optional) affine matrix of the input volume.\n    If not None, this function also returns an updated version of the affine matrix for the cropped volume.\n    :param return_crop_idx: (optional) whether to return the cropping indices used to crop the given volume.\n    :param mode: (optional) if cropping_shape is not None, whether to extract the centre of the image (mode='center'),\n    or to randomly crop the volume to the provided shape (mode='random'). Default is 'center'.\n    :return: cropped volume, corresponding affine matrix if aff is not None, and cropping indices if return_crop_idx is\n    True (in that order).\n    \"\"\"", "\n", "\n", "assert", "(", "cropping_margin", "is", "not", "None", ")", "|", "(", "cropping_shape", "is", "not", "None", ")", ",", "'cropping_margin or cropping_shape should be provided'", "\n", "assert", "not", "(", "(", "cropping_margin", "is", "not", "None", ")", "&", "(", "cropping_shape", "is", "not", "None", ")", ")", ",", "'only one of cropping_margin or cropping_shape should be provided'", "\n", "\n", "# get info", "\n", "new_volume", "=", "volume", ".", "copy", "(", ")", "\n", "vol_shape", "=", "new_volume", ".", "shape", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "vol_shape", ")", "\n", "\n", "# find cropping indices", "\n", "if", "cropping_margin", "is", "not", "None", ":", "\n", "        ", "cropping_margin", "=", "utils", ".", "reformat_to_list", "(", "cropping_margin", ",", "length", "=", "n_dims", ")", "\n", "do_cropping", "=", "np", ".", "array", "(", "vol_shape", "[", ":", "n_dims", "]", ")", ">", "2", "*", "np", ".", "array", "(", "cropping_margin", ")", "\n", "min_crop_idx", "=", "[", "cropping_margin", "[", "i", "]", "if", "do_cropping", "[", "i", "]", "else", "0", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "max_crop_idx", "=", "[", "vol_shape", "[", "i", "]", "-", "cropping_margin", "[", "i", "]", "if", "do_cropping", "[", "i", "]", "else", "vol_shape", "[", "i", "]", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "", "else", ":", "\n", "        ", "cropping_shape", "=", "utils", ".", "reformat_to_list", "(", "cropping_shape", ",", "length", "=", "n_dims", ")", "\n", "if", "mode", "==", "'center'", ":", "\n", "            ", "min_crop_idx", "=", "np", ".", "maximum", "(", "[", "int", "(", "(", "vol_shape", "[", "i", "]", "-", "cropping_shape", "[", "i", "]", ")", "/", "2", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", ",", "0", ")", "\n", "max_crop_idx", "=", "np", ".", "minimum", "(", "[", "min_crop_idx", "[", "i", "]", "+", "cropping_shape", "[", "i", "]", "for", "i", "in", "range", "(", "n_dims", ")", "]", ",", "\n", "np", ".", "array", "(", "vol_shape", ")", "[", ":", "n_dims", "]", ")", "\n", "", "elif", "mode", "==", "'random'", ":", "\n", "            ", "crop_max_val", "=", "np", ".", "maximum", "(", "np", ".", "array", "(", "[", "vol_shape", "[", "i", "]", "-", "cropping_shape", "[", "i", "]", "for", "i", "in", "range", "(", "n_dims", ")", "]", ")", ",", "0", ")", "\n", "min_crop_idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "high", "=", "crop_max_val", "+", "1", ")", "\n", "max_crop_idx", "=", "np", ".", "minimum", "(", "min_crop_idx", "+", "np", ".", "array", "(", "cropping_shape", ")", ",", "np", ".", "array", "(", "vol_shape", ")", "[", ":", "n_dims", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'mode should be either \"center\" or \"random\", had %s'", "%", "mode", ")", "\n", "", "", "crop_idx", "=", "np", ".", "concatenate", "(", "[", "np", ".", "array", "(", "min_crop_idx", ")", ",", "np", ".", "array", "(", "max_crop_idx", ")", "]", ")", "\n", "\n", "# crop volume", "\n", "if", "n_dims", "==", "2", ":", "\n", "        ", "new_volume", "=", "new_volume", "[", "crop_idx", "[", "0", "]", ":", "crop_idx", "[", "2", "]", ",", "crop_idx", "[", "1", "]", ":", "crop_idx", "[", "3", "]", ",", "...", "]", "\n", "", "elif", "n_dims", "==", "3", ":", "\n", "        ", "new_volume", "=", "new_volume", "[", "crop_idx", "[", "0", "]", ":", "crop_idx", "[", "3", "]", ",", "crop_idx", "[", "1", "]", ":", "crop_idx", "[", "4", "]", ",", "crop_idx", "[", "2", "]", ":", "crop_idx", "[", "5", "]", ",", "...", "]", "\n", "\n", "# sort outputs", "\n", "", "output", "=", "[", "new_volume", "]", "\n", "if", "aff", "is", "not", "None", ":", "\n", "        ", "aff", "[", "0", ":", "3", ",", "-", "1", "]", "=", "aff", "[", "0", ":", "3", ",", "-", "1", "]", "+", "aff", "[", ":", "3", ",", ":", "3", "]", "@", "np", ".", "array", "(", "min_crop_idx", ")", "\n", "output", ".", "append", "(", "aff", ")", "\n", "", "if", "return_crop_idx", ":", "\n", "        ", "output", ".", "append", "(", "crop_idx", ")", "\n", "", "return", "output", "[", "0", "]", "if", "len", "(", "output", ")", "==", "1", "else", "tuple", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_around_region": [[240, 350], ["volume.copy", "utils.get_dims", "numpy.array", "numpy.any", "numpy.nonzero", "numpy.maximum", "numpy.minimum", "numpy.concatenate", "numpy.zeros", "edit_volumes.mask_label_map", "numpy.abs", "numpy.maximum", "numpy.concatenate", "numpy.pad", "numpy.append", "numpy.array", "numpy.array", "numpy.int32", "numpy.int32", "numpy.minimum", "numpy.any", "numpy.any", "tuple", "ValueError", "tuple", "numpy.array", "utils.reformat_to_list", "utils.find_closest_number_divisible_by_m", "numpy.ceil", "numpy.floor", "numpy.maximum", "numpy.minimum", "numpy.min", "list", "numpy.max", "range", "scipy.ndimage.label", "scipy.ndimage.label"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mask_label_map", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.find_closest_number_divisible_by_m", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "crop_volume_around_region", "(", "volume", ",", "\n", "mask", "=", "None", ",", "\n", "masking_labels", "=", "None", ",", "\n", "threshold", "=", "0.1", ",", "\n", "margin", "=", "0", ",", "\n", "cropping_shape", "=", "None", ",", "\n", "cropping_shape_div_by", "=", "None", ",", "\n", "aff", "=", "None", ")", ":", "\n", "    ", "\"\"\"Crop a volume around a specific region.\n    This region is defined by a mask obtained by either:\n    1) directly specifying it as input\n    2) keeping a set of label values (defined by masking_labels) if the volume is a label map.\n    3) thresholding the input volume\n    The cropped region is defined by either:\n    1) cropping around the non-zero values in the above-defined mask (possibly with a margin)\n    2) cropping to a specified shape, centered around the middle of the above-defined mask\n    3) cropping to a shape divisible by the given number, centered around the middle of the above-defined mask\n    :param volume: a 2d or 3d numpy array\n    :param mask: (optional) mask of region to crop around. Must be same size as volume. Can either be boolean or 0/1.\n    If no mask is given, it will be computed by either thresholding the input volume or using masking_labels.\n    :param masking_labels: (optional) if mask is None, and if the volume is a label map, it can be cropped around a\n    set of labels specified in masking_labels, which can either be a single int, a sequence or a 1d numpy array.\n    :param threshold: (optional) if mask amd masking_labels are None, lower bound to determine values to crop around.\n    :param margin: (optional) add margin around mask\n    :param cropping_shape: (optional) shape to which the input volumes must be cropped. Volumes are padded around the\n    centre of the above-defined mask is they are too small for the given shape. Can be an integer or sequence.\n    Cannot be given at the same time as margin or cropping_shape_div_by.\n    :param cropping_shape_div_by: (optional) makes sure the shape of the cropped region is divisible by the provided\n    number. If it is not, then we enlarge the cropping area. If the enlarged area is too big fort he input volume, we\n    pad it with 0. Must be a integer. Cannot be given at the same time as margin or cropping_shape.\n    :param aff: (optional) if specified, this function returns an updated affine matrix of the volume after cropping.\n    :return: the cropped volume, the cropping indices (in the order [lower_bound_dim_1, ..., upper_bound_dim_1, ...]),\n    and the updated affine matrix if aff is not None.\n    \"\"\"", "\n", "\n", "assert", "not", "(", "(", "margin", ">", "0", ")", "&", "(", "cropping_shape", "is", "not", "None", ")", ")", ",", "\"margin and cropping_shape can't be given together.\"", "\n", "assert", "not", "(", "(", "margin", ">", "0", ")", "&", "(", "cropping_shape_div_by", "is", "not", "None", ")", ")", ",", "\"margin and cropping_shape_div_by can't be given together.\"", "\n", "assert", "not", "(", "(", "cropping_shape_div_by", "is", "not", "None", ")", "&", "(", "cropping_shape", "is", "not", "None", ")", ")", ",", "\"cropping_shape_div_by and cropping_shape can't be given together.\"", "\n", "\n", "new_vol", "=", "volume", ".", "copy", "(", ")", "\n", "n_dims", ",", "n_channels", "=", "utils", ".", "get_dims", "(", "new_vol", ".", "shape", ")", "\n", "vol_shape", "=", "np", ".", "array", "(", "new_vol", ".", "shape", "[", ":", "n_dims", "]", ")", "\n", "\n", "# mask ROIs for cropping", "\n", "if", "mask", "is", "None", ":", "\n", "        ", "if", "masking_labels", "is", "not", "None", ":", "\n", "            ", "_", ",", "mask", "=", "mask_label_map", "(", "new_vol", ",", "masking_values", "=", "masking_labels", ",", "return_mask", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "mask", "=", "new_vol", ">", "threshold", "\n", "\n", "# find cropping indices", "\n", "", "", "if", "np", ".", "any", "(", "mask", ")", ":", "\n", "        ", "indices", "=", "np", ".", "nonzero", "(", "mask", ")", "\n", "min_idx", "=", "np", ".", "maximum", "(", "np", ".", "array", "(", "[", "np", ".", "min", "(", "idx", ")", "for", "idx", "in", "indices", "]", ")", "-", "margin", ",", "0", ")", "\n", "max_idx", "=", "np", ".", "minimum", "(", "np", ".", "array", "(", "[", "np", ".", "max", "(", "idx", ")", "for", "idx", "in", "indices", "]", ")", "+", "1", "+", "margin", ",", "vol_shape", ")", "\n", "cropping", "=", "np", ".", "concatenate", "(", "[", "min_idx", ",", "max_idx", "]", ")", "\n", "\n", "# modify the cropping indices if we want the output to have a given shape", "\n", "if", "(", "cropping_shape", "is", "not", "None", ")", "|", "(", "cropping_shape_div_by", "is", "not", "None", ")", ":", "\n", "\n", "# expand/retract (depending on the desired shape) the cropping region around the centre", "\n", "            ", "intermediate_vol_shape", "=", "max_idx", "-", "min_idx", "\n", "if", "cropping_shape", "is", "not", "None", ":", "\n", "                ", "cropping_shape", "=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "cropping_shape", ",", "length", "=", "n_dims", ")", ")", "\n", "", "else", ":", "\n", "                ", "cropping_shape", "=", "[", "utils", ".", "find_closest_number_divisible_by_m", "(", "s", ",", "cropping_shape_div_by", ",", "\n", "answer_type", "=", "'higher'", ")", "\n", "for", "s", "in", "intermediate_vol_shape", "]", "\n", "", "min_idx", "=", "min_idx", "-", "np", ".", "int32", "(", "np", ".", "ceil", "(", "(", "cropping_shape", "-", "intermediate_vol_shape", ")", "/", "2", ")", ")", "\n", "max_idx", "=", "max_idx", "+", "np", ".", "int32", "(", "np", ".", "floor", "(", "(", "cropping_shape", "-", "intermediate_vol_shape", ")", "/", "2", ")", ")", "\n", "\n", "# check if we need to pad the output to the desired shape", "\n", "min_padding", "=", "np", ".", "abs", "(", "np", ".", "minimum", "(", "min_idx", ",", "0", ")", ")", "\n", "max_padding", "=", "np", ".", "maximum", "(", "max_idx", "-", "vol_shape", ",", "0", ")", "\n", "if", "np", ".", "any", "(", "min_padding", ">", "0", ")", "|", "np", ".", "any", "(", "max_padding", ">", "0", ")", ":", "\n", "                ", "pad_margins", "=", "tuple", "(", "[", "(", "min_padding", "[", "i", "]", ",", "max_padding", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "pad_margins", "=", "None", "\n", "", "cropping", "=", "np", ".", "concatenate", "(", "[", "np", ".", "maximum", "(", "min_idx", ",", "0", ")", ",", "np", ".", "minimum", "(", "max_idx", ",", "vol_shape", ")", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "pad_margins", "=", "None", "\n", "\n", "# crop volume", "\n", "", "if", "n_dims", "==", "3", ":", "\n", "            ", "new_vol", "=", "new_vol", "[", "cropping", "[", "0", "]", ":", "cropping", "[", "3", "]", ",", "cropping", "[", "1", "]", ":", "cropping", "[", "4", "]", ",", "cropping", "[", "2", "]", ":", "cropping", "[", "5", "]", ",", "...", "]", "\n", "", "elif", "n_dims", "==", "2", ":", "\n", "            ", "new_vol", "=", "new_vol", "[", "cropping", "[", "0", "]", ":", "cropping", "[", "2", "]", ",", "cropping", "[", "1", "]", ":", "cropping", "[", "3", "]", ",", "...", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'cannot crop volumes with more than 3 dimensions'", ")", "\n", "\n", "# pad volume if necessary", "\n", "", "if", "pad_margins", "is", "not", "None", ":", "\n", "            ", "pad_margins", "=", "tuple", "(", "list", "(", "pad_margins", ")", "+", "[", "(", "0", ",", "0", ")", "]", ")", "if", "n_channels", ">", "1", "else", "pad_margins", "\n", "new_vol", "=", "np", ".", "pad", "(", "new_vol", ",", "pad_margins", ",", "mode", "=", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "\n", "# if there's nothing to crop around, we return the input as is", "\n", "", "", "else", ":", "\n", "        ", "min_idx", "=", "np", ".", "zeros", "(", "(", "3", ",", "1", ")", ")", "\n", "cropping", "=", "None", "\n", "\n", "", "if", "aff", "is", "not", "None", ":", "\n", "        ", "if", "n_dims", "==", "2", ":", "\n", "            ", "min_idx", "=", "np", ".", "append", "(", "min_idx", ",", "0", ")", "\n", "", "aff", "[", "0", ":", "3", ",", "-", "1", "]", "=", "aff", "[", "0", ":", "3", ",", "-", "1", "]", "+", "aff", "[", ":", "3", ",", ":", "3", "]", "@", "min_idx", "\n", "return", "new_vol", ",", "cropping", ",", "aff", "\n", "", "else", ":", "\n", "        ", "return", "new_vol", ",", "cropping", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_with_idx": [[352, 381], ["volume.copy", "int", "Exception", "numpy.array", "scipy.ndimage.label", "scipy.ndimage.label"], "function", ["None"], ["", "", "def", "crop_volume_with_idx", "(", "volume", ",", "crop_idx", ",", "aff", "=", "None", ",", "n_dims", "=", "None", ")", ":", "\n", "    ", "\"\"\"Crop a volume with given indices.\n    :param volume: a 2d or 3d numpy array\n    :param crop_idx: croppping indices, in the order [lower_bound_dim_1, ..., upper_bound_dim_1, ...].\n    Can be a list or a 1d numpy array.\n    :param aff: (optional) if aff is specified, this function returns an updated affine matrix of the volume after\n    cropping.\n    :param n_dims: (optional) number of dimensions (excluding channels) of the volume. If not provided, n_dims will be\n    inferred from the input volume.\n    :return: the cropped volume, and the updated affine matrix if aff is not None.\n    \"\"\"", "\n", "\n", "# get info", "\n", "new_volume", "=", "volume", ".", "copy", "(", ")", "\n", "n_dims", "=", "int", "(", "np", ".", "array", "(", "crop_idx", ")", ".", "shape", "[", "0", "]", "/", "2", ")", "if", "n_dims", "is", "None", "else", "n_dims", "\n", "\n", "# crop image", "\n", "if", "n_dims", "==", "2", ":", "\n", "        ", "new_volume", "=", "new_volume", "[", "crop_idx", "[", "0", "]", ":", "crop_idx", "[", "2", "]", ",", "crop_idx", "[", "1", "]", ":", "crop_idx", "[", "3", "]", ",", "...", "]", "\n", "", "elif", "n_dims", "==", "3", ":", "\n", "        ", "new_volume", "=", "new_volume", "[", "crop_idx", "[", "0", "]", ":", "crop_idx", "[", "3", "]", ",", "crop_idx", "[", "1", "]", ":", "crop_idx", "[", "4", "]", ",", "crop_idx", "[", "2", "]", ":", "crop_idx", "[", "5", "]", ",", "...", "]", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'cannot crop volumes with more than 3 dimensions'", ")", "\n", "\n", "", "if", "aff", "is", "not", "None", ":", "\n", "        ", "aff", "[", "0", ":", "3", ",", "-", "1", "]", "=", "aff", "[", "0", ":", "3", ",", "-", "1", "]", "+", "aff", "[", ":", "3", ",", ":", "3", "]", "@", "crop_idx", "[", ":", "3", "]", "\n", "return", "new_volume", ",", "aff", "\n", "", "else", ":", "\n", "        ", "return", "new_volume", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.pad_volume": [[383, 427], ["volume.copy", "utils.get_dims", "utils.reformat_to_list", "numpy.any", "numpy.maximum", "numpy.maximum", "numpy.concatenate", "tuple", "numpy.pad", "numpy.concatenate", "output.append", "output.append", "tuple", "numpy.array", "numpy.array", "numpy.int32", "numpy.int32", "tuple", "len", "numpy.floor", "numpy.ceil", "numpy.append", "numpy.array", "numpy.array", "numpy.array", "range", "list", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "scipy.ndimage.label"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "", "def", "pad_volume", "(", "volume", ",", "padding_shape", ",", "padding_value", "=", "0", ",", "aff", "=", "None", ",", "return_pad_idx", "=", "False", ")", ":", "\n", "    ", "\"\"\"Pad volume to a given shape\n    :param volume: volume to be padded\n    :param padding_shape: shape to pad volume to. Can be a number, a sequence or a 1d numpy array.\n    :param padding_value: (optional) value used for padding\n    :param aff: (optional) affine matrix of the volume\n    :return: padded volume, and updated affine matrix if aff is not None.\n    \"\"\"", "\n", "\n", "# get info", "\n", "new_volume", "=", "volume", ".", "copy", "(", ")", "\n", "vol_shape", "=", "new_volume", ".", "shape", "\n", "n_dims", ",", "n_channels", "=", "utils", ".", "get_dims", "(", "vol_shape", ")", "\n", "padding_shape", "=", "utils", ".", "reformat_to_list", "(", "padding_shape", ",", "length", "=", "n_dims", ",", "dtype", "=", "'int'", ")", "\n", "\n", "# check if need to pad", "\n", "if", "np", ".", "any", "(", "np", ".", "array", "(", "padding_shape", ",", "dtype", "=", "'int32'", ")", ">", "np", ".", "array", "(", "vol_shape", "[", ":", "n_dims", "]", ",", "dtype", "=", "'int32'", ")", ")", ":", "\n", "\n", "# get padding margins", "\n", "        ", "min_margins", "=", "np", ".", "maximum", "(", "np", ".", "int32", "(", "np", ".", "floor", "(", "(", "np", ".", "array", "(", "padding_shape", ")", "-", "np", ".", "array", "(", "vol_shape", ")", "[", ":", "n_dims", "]", ")", "/", "2", ")", ")", ",", "0", ")", "\n", "max_margins", "=", "np", ".", "maximum", "(", "np", ".", "int32", "(", "np", ".", "ceil", "(", "(", "np", ".", "array", "(", "padding_shape", ")", "-", "np", ".", "array", "(", "vol_shape", ")", "[", ":", "n_dims", "]", ")", "/", "2", ")", ")", ",", "0", ")", "\n", "pad_idx", "=", "np", ".", "concatenate", "(", "[", "min_margins", ",", "min_margins", "+", "np", ".", "array", "(", "vol_shape", "[", ":", "n_dims", "]", ")", "]", ")", "\n", "pad_margins", "=", "tuple", "(", "[", "(", "min_margins", "[", "i", "]", ",", "max_margins", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", ")", "\n", "if", "n_channels", ">", "1", ":", "\n", "            ", "pad_margins", "=", "tuple", "(", "list", "(", "pad_margins", ")", "+", "[", "(", "0", ",", "0", ")", "]", ")", "\n", "\n", "# pad volume", "\n", "", "new_volume", "=", "np", ".", "pad", "(", "new_volume", ",", "pad_margins", ",", "mode", "=", "'constant'", ",", "constant_values", "=", "padding_value", ")", "\n", "\n", "if", "aff", "is", "not", "None", ":", "\n", "            ", "if", "n_dims", "==", "2", ":", "\n", "                ", "min_margins", "=", "np", ".", "append", "(", "min_margins", ",", "0", ")", "\n", "", "aff", "[", ":", "-", "1", ",", "-", "1", "]", "=", "aff", "[", ":", "-", "1", ",", "-", "1", "]", "-", "aff", "[", ":", "-", "1", ",", ":", "-", "1", "]", "@", "min_margins", "\n", "\n", "", "", "else", ":", "\n", "        ", "pad_idx", "=", "np", ".", "concatenate", "(", "[", "np", ".", "array", "(", "[", "0", "]", "*", "n_dims", ")", ",", "np", ".", "array", "(", "vol_shape", "[", ":", "n_dims", "]", ")", "]", ")", "\n", "\n", "# sort outputs", "\n", "", "output", "=", "[", "new_volume", "]", "\n", "if", "aff", "is", "not", "None", ":", "\n", "        ", "output", ".", "append", "(", "aff", ")", "\n", "", "if", "return_pad_idx", ":", "\n", "        ", "output", ".", "append", "(", "pad_idx", ")", "\n", "", "return", "output", "[", "0", "]", "if", "len", "(", "output", ")", "==", "1", "else", "tuple", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.flip_volume": [[429, 458], ["volume.copy", "numpy.flip", "edit_volumes.get_ras_axes", "ValueError"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_ras_axes"], ["", "def", "flip_volume", "(", "volume", ",", "axis", "=", "None", ",", "direction", "=", "None", ",", "aff", "=", "None", ")", ":", "\n", "    ", "\"\"\"Flip volume along a specified axis.\n    If unknown, this axis can be inferred from an affine matrix with a specified anatomical direction.\n    :param volume: a numpy array\n    :param axis: (optional) axis along which to flip the volume. Can either be an int or a tuple.\n    :param direction: (optional) if axis is None, the volume can be flipped along an anatomical direction:\n    'rl' (right/left), 'ap' anterior/posterior), 'si' (superior/inferior).\n    :param aff: (optional) please provide an affine matrix if direction is not None\n    :return: flipped volume\n    \"\"\"", "\n", "\n", "new_volume", "=", "volume", ".", "copy", "(", ")", "\n", "assert", "(", "axis", "is", "not", "None", ")", "|", "(", "(", "aff", "is", "not", "None", ")", "&", "(", "direction", "is", "not", "None", ")", ")", ",", "'please provide either axis, or an affine matrix with a direction'", "\n", "\n", "# get flipping axis from aff if axis not provided", "\n", "if", "(", "axis", "is", "None", ")", "&", "(", "aff", "is", "not", "None", ")", ":", "\n", "        ", "volume_axes", "=", "get_ras_axes", "(", "aff", ")", "\n", "if", "direction", "==", "'rl'", ":", "\n", "            ", "axis", "=", "volume_axes", "[", "0", "]", "\n", "", "elif", "direction", "==", "'ap'", ":", "\n", "            ", "axis", "=", "volume_axes", "[", "1", "]", "\n", "", "elif", "direction", "==", "'si'", ":", "\n", "            ", "axis", "=", "volume_axes", "[", "2", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"direction should be 'rl', 'ap', or 'si', had %s\"", "%", "direction", ")", "\n", "\n", "# flip volume", "\n", "", "", "return", "np", ".", "flip", "(", "new_volume", ",", "axis", "=", "axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.resample_volume": [[460, 506], ["numpy.array", "scipy.ndimage.gaussian_filter", "numpy.arange", "numpy.arange", "numpy.arange", "scipy.interpolate.RegularGridInterpolator", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.meshgrid", "scipy.interpolate.RegularGridInterpolator.", "aff.copy", "range", "numpy.sqrt", "numpy.matmul", "numpy.sum", "numpy.ceil"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.meshgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "resample_volume", "(", "volume", ",", "aff", ",", "new_vox_size", ",", "interpolation", "=", "'linear'", ")", ":", "\n", "    ", "\"\"\"This function resizes the voxels of a volume to a new provided size, while adjusting the header to keep the RAS\n    :param volume: a numpy array\n    :param aff: affine matrix of the volume\n    :param new_vox_size: new voxel size (3 - element numpy vector) in mm\n    :return: new volume and affine matrix\n    \"\"\"", "\n", "\n", "pixdim", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "aff", "*", "aff", ",", "axis", "=", "0", ")", ")", "[", ":", "-", "1", "]", "\n", "new_vox_size", "=", "np", ".", "array", "(", "new_vox_size", ")", "\n", "factor", "=", "pixdim", "/", "new_vox_size", "\n", "sigmas", "=", "0.25", "/", "factor", "\n", "sigmas", "[", "factor", ">", "1", "]", "=", "0", "# don't blur if upsampling", "\n", "\n", "volume_filt", "=", "gaussian_filter", "(", "volume", ",", "sigmas", ")", "\n", "\n", "# volume2 = zoom(volume_filt, factor, order=1, mode='reflect', prefilter=False)", "\n", "x", "=", "np", ".", "arange", "(", "0", ",", "volume_filt", ".", "shape", "[", "0", "]", ")", "\n", "y", "=", "np", ".", "arange", "(", "0", ",", "volume_filt", ".", "shape", "[", "1", "]", ")", "\n", "z", "=", "np", ".", "arange", "(", "0", ",", "volume_filt", ".", "shape", "[", "2", "]", ")", "\n", "\n", "my_interpolating_function", "=", "RegularGridInterpolator", "(", "(", "x", ",", "y", ",", "z", ")", ",", "volume_filt", ",", "method", "=", "interpolation", ")", "\n", "\n", "start", "=", "-", "(", "factor", "-", "1", ")", "/", "(", "2", "*", "factor", ")", "\n", "step", "=", "1.0", "/", "factor", "\n", "stop", "=", "start", "+", "step", "*", "np", ".", "ceil", "(", "volume_filt", ".", "shape", "*", "factor", ")", "\n", "\n", "xi", "=", "np", ".", "arange", "(", "start", "=", "start", "[", "0", "]", ",", "stop", "=", "stop", "[", "0", "]", ",", "step", "=", "step", "[", "0", "]", ")", "\n", "yi", "=", "np", ".", "arange", "(", "start", "=", "start", "[", "1", "]", ",", "stop", "=", "stop", "[", "1", "]", ",", "step", "=", "step", "[", "1", "]", ")", "\n", "zi", "=", "np", ".", "arange", "(", "start", "=", "start", "[", "2", "]", ",", "stop", "=", "stop", "[", "2", "]", ",", "step", "=", "step", "[", "2", "]", ")", "\n", "xi", "[", "xi", "<", "0", "]", "=", "0", "\n", "yi", "[", "yi", "<", "0", "]", "=", "0", "\n", "zi", "[", "zi", "<", "0", "]", "=", "0", "\n", "xi", "[", "xi", ">", "(", "volume_filt", ".", "shape", "[", "0", "]", "-", "1", ")", "]", "=", "volume_filt", ".", "shape", "[", "0", "]", "-", "1", "\n", "yi", "[", "yi", ">", "(", "volume_filt", ".", "shape", "[", "1", "]", "-", "1", ")", "]", "=", "volume_filt", ".", "shape", "[", "1", "]", "-", "1", "\n", "zi", "[", "zi", ">", "(", "volume_filt", ".", "shape", "[", "2", "]", "-", "1", ")", "]", "=", "volume_filt", ".", "shape", "[", "2", "]", "-", "1", "\n", "\n", "xig", ",", "yig", ",", "zig", "=", "np", ".", "meshgrid", "(", "xi", ",", "yi", ",", "zi", ",", "indexing", "=", "'ij'", ",", "sparse", "=", "True", ")", "\n", "volume2", "=", "my_interpolating_function", "(", "(", "xig", ",", "yig", ",", "zig", ")", ")", "\n", "\n", "aff2", "=", "aff", ".", "copy", "(", ")", "\n", "for", "c", "in", "range", "(", "3", ")", ":", "\n", "        ", "aff2", "[", ":", "-", "1", ",", "c", "]", "=", "aff2", "[", ":", "-", "1", ",", "c", "]", "/", "factor", "[", "c", "]", "\n", "", "aff2", "[", ":", "-", "1", ",", "-", "1", "]", "=", "aff2", "[", ":", "-", "1", ",", "-", "1", "]", "-", "np", ".", "matmul", "(", "aff2", "[", ":", "-", "1", ",", ":", "-", "1", "]", ",", "0.5", "*", "(", "factor", "-", "1", ")", ")", "\n", "\n", "return", "volume2", ",", "aff2", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.resample_volume_like": [[508, 541], ["numpy.matmul", "numpy.arange", "numpy.arange", "numpy.arange", "scipy.interpolate.RegularGridInterpolator", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.meshgrid", "xrg.reshape.reshape", "yrg.reshape.reshape", "zrg.reshape.reshape", "numpy.ones_like", "numpy.stack", "scipy.interpolate.RegularGridInterpolator.", "my_interpolating_function.reshape", "numpy.linalg.inv", "numpy.matmul"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.meshgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack"], ["", "def", "resample_volume_like", "(", "vol_ref", ",", "aff_ref", ",", "vol_flo", ",", "aff_flo", ",", "interpolation", "=", "'linear'", ")", ":", "\n", "    ", "\"\"\"This function reslices a floating image to the space of a reference image\n    :param vol_ref: a numpy array with the reference volume\n    :param aff_ref: affine matrix of the reference volume\n    :param vol_flo: a numpy array with the floating volume\n    :param aff_flo: affine matrix of the floating volume\n    :return: resliced volume\n    \"\"\"", "\n", "\n", "T", "=", "np", ".", "matmul", "(", "np", ".", "linalg", ".", "inv", "(", "aff_flo", ")", ",", "aff_ref", ")", "\n", "\n", "xf", "=", "np", ".", "arange", "(", "0", ",", "vol_flo", ".", "shape", "[", "0", "]", ")", "\n", "yf", "=", "np", ".", "arange", "(", "0", ",", "vol_flo", ".", "shape", "[", "1", "]", ")", "\n", "zf", "=", "np", ".", "arange", "(", "0", ",", "vol_flo", ".", "shape", "[", "2", "]", ")", "\n", "\n", "my_interpolating_function", "=", "RegularGridInterpolator", "(", "(", "xf", ",", "yf", ",", "zf", ")", ",", "vol_flo", ",", "bounds_error", "=", "False", ",", "fill_value", "=", "0.0", ",", "\n", "method", "=", "interpolation", ")", "\n", "\n", "xr", "=", "np", ".", "arange", "(", "0", ",", "vol_ref", ".", "shape", "[", "0", "]", ")", "\n", "yr", "=", "np", ".", "arange", "(", "0", ",", "vol_ref", ".", "shape", "[", "1", "]", ")", "\n", "zr", "=", "np", ".", "arange", "(", "0", ",", "vol_ref", ".", "shape", "[", "2", "]", ")", "\n", "\n", "xrg", ",", "yrg", ",", "zrg", "=", "np", ".", "meshgrid", "(", "xr", ",", "yr", ",", "zr", ",", "indexing", "=", "'ij'", ",", "sparse", "=", "False", ")", "\n", "n", "=", "xrg", ".", "size", "\n", "xrg", "=", "xrg", ".", "reshape", "(", "[", "n", "]", ")", "\n", "yrg", "=", "yrg", ".", "reshape", "(", "[", "n", "]", ")", "\n", "zrg", "=", "zrg", ".", "reshape", "(", "[", "n", "]", ")", "\n", "bottom", "=", "np", ".", "ones_like", "(", "xrg", ")", "\n", "coords", "=", "np", ".", "stack", "(", "[", "xrg", ",", "yrg", ",", "zrg", ",", "bottom", "]", ")", "\n", "coords_new", "=", "np", ".", "matmul", "(", "T", ",", "coords", ")", "[", ":", "-", "1", ",", ":", "]", "\n", "result", "=", "my_interpolating_function", "(", "(", "coords_new", "[", "0", ",", ":", "]", ",", "coords_new", "[", "1", ",", ":", "]", ",", "coords_new", "[", "2", ",", ":", "]", ")", ")", "\n", "\n", "return", "result", ".", "reshape", "(", "vol_ref", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_ras_axes": [[543, 553], ["numpy.linalg.inv", "numpy.argmax", "numpy.absolute"], "function", ["None"], ["", "def", "get_ras_axes", "(", "aff", ",", "n_dims", "=", "3", ")", ":", "\n", "    ", "\"\"\"This function finds the RAS axes corresponding to each dimension of a volume, based on its affine matrix.\n    :param aff: affine matrix Can be a 2d numpy array of size n_dims*n_dims, n_dims+1*n_dims+1, or n_dims*n_dims+1.\n    :param n_dims: number of dimensions (excluding channels) of the volume corresponding to the provided affine matrix.\n    :return: two numpy 1d arrays of lengtn n_dims, one with the axes corresponding to RAS orientations,\n    and one with their corresponding direction.\n    \"\"\"", "\n", "aff_inverted", "=", "np", ".", "linalg", ".", "inv", "(", "aff", ")", "\n", "img_ras_axes", "=", "np", ".", "argmax", "(", "np", ".", "absolute", "(", "aff_inverted", "[", "0", ":", "n_dims", ",", "0", ":", "n_dims", "]", ")", ",", "axis", "=", "0", ")", "\n", "return", "img_ras_axes", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref": [[555, 600], ["volume.copy", "aff.copy", "edit_volumes.get_ras_axes", "edit_volumes.get_ras_axes", "range", "numpy.sum", "range", "numpy.eye", "utils.get_dims", "numpy.swapaxes", "numpy.where", "numpy.flip", "scipy.ndimage.label", "scipy.ndimage.label", "scipy.ndimage.label"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_ras_axes", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_ras_axes", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims"], ["", "def", "align_volume_to_ref", "(", "volume", ",", "aff", ",", "aff_ref", "=", "None", ",", "return_aff", "=", "False", ",", "n_dims", "=", "None", ")", ":", "\n", "    ", "\"\"\"This function aligns a volume to a reference orientation (axis and direction) specified by an affine matrix.\n    :param volume: a numpy array\n    :param aff: affine matrix of the floating volume\n    :param aff_ref: (optional) affine matrix of the target orientation. Default is identity matrix.\n    :param return_aff: (optional) whether to return the affine matrix of the aligned volume\n    :param n_dims: (optional) number of dimensions (excluding channels) of the volume. If not provided, n_dims will be\n    inferred from the input volume.\n    :return: aligned volume, with corresponding affine matrix if return_aff is True.\n    \"\"\"", "\n", "\n", "# work on copy", "\n", "new_volume", "=", "volume", ".", "copy", "(", ")", "\n", "aff_flo", "=", "aff", ".", "copy", "(", ")", "\n", "\n", "# default value for aff_ref", "\n", "if", "aff_ref", "is", "None", ":", "\n", "        ", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", "\n", "\n", "# extract ras axes", "\n", "", "if", "n_dims", "is", "None", ":", "\n", "        ", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "new_volume", ".", "shape", ")", "\n", "", "ras_axes_ref", "=", "get_ras_axes", "(", "aff_ref", ",", "n_dims", "=", "n_dims", ")", "\n", "ras_axes_flo", "=", "get_ras_axes", "(", "aff_flo", ",", "n_dims", "=", "n_dims", ")", "\n", "\n", "# align axes", "\n", "aff_flo", "[", ":", ",", "ras_axes_ref", "]", "=", "aff_flo", "[", ":", ",", "ras_axes_flo", "]", "\n", "for", "i", "in", "range", "(", "n_dims", ")", ":", "\n", "        ", "if", "ras_axes_flo", "[", "i", "]", "!=", "ras_axes_ref", "[", "i", "]", ":", "\n", "            ", "new_volume", "=", "np", ".", "swapaxes", "(", "new_volume", ",", "ras_axes_flo", "[", "i", "]", ",", "ras_axes_ref", "[", "i", "]", ")", "\n", "swapped_axis_idx", "=", "np", ".", "where", "(", "ras_axes_flo", "==", "ras_axes_ref", "[", "i", "]", ")", "\n", "ras_axes_flo", "[", "swapped_axis_idx", "]", ",", "ras_axes_flo", "[", "i", "]", "=", "ras_axes_flo", "[", "i", "]", ",", "ras_axes_flo", "[", "swapped_axis_idx", "]", "\n", "\n", "# align directions", "\n", "", "", "dot_products", "=", "np", ".", "sum", "(", "aff_flo", "[", ":", "3", ",", ":", "3", "]", "*", "aff_ref", "[", ":", "3", ",", ":", "3", "]", ",", "axis", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "n_dims", ")", ":", "\n", "        ", "if", "dot_products", "[", "i", "]", "<", "0", ":", "\n", "            ", "new_volume", "=", "np", ".", "flip", "(", "new_volume", ",", "axis", "=", "i", ")", "\n", "aff_flo", "[", ":", ",", "i", "]", "=", "-", "aff_flo", "[", ":", ",", "i", "]", "\n", "aff_flo", "[", ":", "3", ",", "3", "]", "=", "aff_flo", "[", ":", "3", ",", "3", "]", "-", "aff_flo", "[", ":", "3", ",", "i", "]", "*", "(", "new_volume", ".", "shape", "[", "i", "]", "-", "1", ")", "\n", "\n", "", "", "if", "return_aff", ":", "\n", "        ", "return", "new_volume", ",", "aff_flo", "\n", "", "else", ":", "\n", "        ", "return", "new_volume", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.blur_volume": [[602, 629], ["volume.copy", "utils.get_dims", "utils.reformat_to_list", "scipy.ndimage.gaussian_filter", "scipy.ndimage.gaussian_filter"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list"], ["", "", "def", "blur_volume", "(", "volume", ",", "sigma", ",", "mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"Blur volume with gaussian masks of given sigma.\n    :param volume: 2d or 3d numpy array\n    :param sigma: standard deviation of the gaussian kernels. Can be a number, a sequence or a 1d numpy array\n    :param mask: (optional) numpy array of the same shape as volume to correct for edge blurring effects.\n    Mask can be a boolean or numerical array. In the later, the mask is computed by keeping all values above zero.\n    :return: blurred volume\n    \"\"\"", "\n", "\n", "# initialisation", "\n", "new_volume", "=", "volume", ".", "copy", "(", ")", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "new_volume", ".", "shape", ")", "\n", "sigma", "=", "utils", ".", "reformat_to_list", "(", "sigma", ",", "length", "=", "n_dims", ",", "dtype", "=", "'float'", ")", "\n", "\n", "# blur image", "\n", "new_volume", "=", "gaussian_filter", "(", "new_volume", ",", "sigma", "=", "sigma", ",", "mode", "=", "'nearest'", ")", "# nearest refers to edge padding", "\n", "\n", "# correct edge effect if mask is not None", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "assert", "new_volume", ".", "shape", "==", "mask", ".", "shape", ",", "'volume and mask should have the same dimensions: '", "'got {0} and {1}'", ".", "format", "(", "new_volume", ".", "shape", ",", "mask", ".", "shape", ")", "\n", "mask", "=", "(", "mask", ">", "0", ")", "*", "1.0", "\n", "blurred_mask", "=", "gaussian_filter", "(", "mask", ",", "sigma", "=", "sigma", ",", "mode", "=", "'nearest'", ")", "\n", "new_volume", "=", "new_volume", "/", "(", "blurred_mask", "+", "1e-6", ")", "\n", "new_volume", "[", "mask", "==", "0", "]", "=", "0", "\n", "\n", "", "return", "new_volume", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.correct_label_map": [[633, 755], ["labels.copy", "utils.reformat_to_list", "numpy.unique", "utils.get_dims", "utils.load_array_if_path", "utils.reformat_to_list", "zip", "numpy.ones", "edit_volumes.smooth_label_map", "utils.load_array_if_path", "tuple", "isinstance", "scipy.ndimage.label", "utils.LoopInfo", "range", "numpy.where", "isinstance", "utils.LoopInfo.update", "edit_volumes.crop_volume_around_region", "edit_volumes.crop_volume_with_idx", "edit_volumes.crop_volume_with_idx", "numpy.unique", "numpy.where", "numpy.stack", "numpy.argmin", "tuple", "numpy.delete", "len", "numpy.where", "numpy.stack", "numpy.argmin", "any", "print", "edit_volumes.crop_volume_around_region", "scipy.ndimage.morphology.distance_transform_edt", "numpy.array", "numpy.where", "numpy.ones_like", "numpy.delete", "scipy.ndimage.morphology.distance_transform_edt", "numpy.array", "any", "numpy.where", "range", "numpy.unique"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.smooth_label_map", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_around_region", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_with_idx", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_with_idx", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_around_region", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "correct_label_map", "(", "labels", ",", "list_incorrect_labels", ",", "list_correct_labels", "=", "None", ",", "use_nearest_label", "=", "False", ",", "\n", "remove_zero", "=", "False", ",", "smooth", "=", "False", ")", ":", "\n", "    ", "\"\"\"This function corrects specified label values in a label map by either a list of given values, or by the nearest\n    label.\n    :param labels: a 2d or 3d label map\n    :param list_incorrect_labels: list of all label values to correct (eg [1, 2, 3]). Can also be a path to such a list.\n    :param list_correct_labels: (optional) list of correct label values to replace the incorrect ones.\n    Correct values must have the same order as their corresponding value in list_incorrect_labels.\n    When several correct values are possible for the same incorrect value, the nearest correct value will be selected at\n    each voxel to correct. In that case, the different correct values must be specified inside a list whithin\n    list_correct_labels (e.g. [10, 20, 30, [40, 50]).\n    :param use_nearest_label: (optional) whether to correct the incorrect lavel values with the nearest labels.\n    :param remove_zero: (optional) if use_nearest_label is True, set to True not to consider zero among the potential\n    candidates for the nearest neighbour.\n    :param smooth: (optional) whether to smooth the corrected label map\n    :return: corrected label map\n    \"\"\"", "\n", "\n", "assert", "(", "list_correct_labels", "is", "not", "None", ")", "|", "use_nearest_label", ",", "'please provide a list of correct labels, or set use_nearest_label to True.'", "\n", "assert", "(", "list_correct_labels", "is", "None", ")", "|", "(", "not", "use_nearest_label", ")", ",", "'cannot provide a list of correct values and set use_nearest_label to True'", "\n", "\n", "# initialisation", "\n", "new_labels", "=", "labels", ".", "copy", "(", ")", "\n", "list_incorrect_labels", "=", "utils", ".", "reformat_to_list", "(", "utils", ".", "load_array_if_path", "(", "list_incorrect_labels", ")", ")", "\n", "volume_labels", "=", "np", ".", "unique", "(", "labels", ")", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "labels", ".", "shape", ")", "\n", "\n", "# use list of correct values", "\n", "if", "list_correct_labels", "is", "not", "None", ":", "\n", "        ", "list_correct_labels", "=", "utils", ".", "reformat_to_list", "(", "utils", ".", "load_array_if_path", "(", "list_correct_labels", ")", ")", "\n", "\n", "# loop over label values", "\n", "for", "incorrect_label", ",", "correct_label", "in", "zip", "(", "list_incorrect_labels", ",", "list_correct_labels", ")", ":", "\n", "            ", "if", "incorrect_label", "in", "volume_labels", ":", "\n", "\n", "# only one possible value to replace with", "\n", "                ", "if", "isinstance", "(", "correct_label", ",", "(", "int", ",", "float", ",", "np", ".", "int64", ",", "np", ".", "int32", ",", "np", ".", "int16", ",", "np", ".", "int8", ")", ")", ":", "\n", "                    ", "incorrect_voxels", "=", "np", ".", "where", "(", "labels", "==", "incorrect_label", ")", "\n", "new_labels", "[", "incorrect_voxels", "]", "=", "correct_label", "\n", "\n", "# several possibilities", "\n", "", "elif", "isinstance", "(", "correct_label", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "\n", "# make sure at least one correct label is present", "\n", "                    ", "if", "not", "any", "(", "[", "lab", "in", "volume_labels", "for", "lab", "in", "correct_label", "]", ")", ":", "\n", "                        ", "print", "(", "'no correct values found in volume, please adjust: '", "\n", "'incorrect: {}, correct: {}'", ".", "format", "(", "incorrect_label", ",", "correct_label", ")", ")", "\n", "\n", "# crop around incorrect label until we find incorrect labels", "\n", "", "correct_label_not_found", "=", "True", "\n", "margin_mult", "=", "1", "\n", "tmp_labels", "=", "None", "\n", "crop", "=", "None", "\n", "while", "correct_label_not_found", ":", "\n", "                        ", "tmp_labels", ",", "crop", "=", "crop_volume_around_region", "(", "labels", ",", "\n", "masking_labels", "=", "incorrect_label", ",", "\n", "margin", "=", "10", "*", "margin_mult", ")", "\n", "correct_label_not_found", "=", "not", "any", "(", "[", "lab", "in", "np", ".", "unique", "(", "tmp_labels", ")", "for", "lab", "in", "correct_label", "]", ")", "\n", "margin_mult", "+=", "1", "\n", "\n", "# calculate distance maps for all new label candidates", "\n", "", "incorrect_voxels", "=", "np", ".", "where", "(", "tmp_labels", "==", "incorrect_label", ")", "\n", "distance_map_list", "=", "[", "distance_transform_edt", "(", "tmp_labels", "!=", "lab", ")", "for", "lab", "in", "correct_label", "]", "\n", "distances_correct", "=", "np", ".", "stack", "(", "[", "dist", "[", "incorrect_voxels", "]", "for", "dist", "in", "distance_map_list", "]", ")", "\n", "\n", "# select nearest values and use them to correct label map", "\n", "idx_correct_lab", "=", "np", ".", "argmin", "(", "distances_correct", ",", "axis", "=", "0", ")", "\n", "incorrect_voxels", "=", "tuple", "(", "[", "incorrect_voxels", "[", "i", "]", "+", "crop", "[", "i", "]", "for", "i", "in", "range", "(", "n_dims", ")", "]", ")", "\n", "new_labels", "[", "incorrect_voxels", "]", "=", "np", ".", "array", "(", "correct_label", ")", "[", "idx_correct_lab", "]", "\n", "\n", "# use nearest label", "\n", "", "", "", "", "else", ":", "\n", "\n", "# loop over label values", "\n", "        ", "for", "incorrect_label", "in", "list_incorrect_labels", ":", "\n", "            ", "if", "incorrect_label", "in", "volume_labels", ":", "\n", "\n", "# loop around regions", "\n", "                ", "components", ",", "n_components", "=", "scipy_label", "(", "labels", "==", "incorrect_label", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "n_components", "+", "1", ",", "100", ",", "'correcting'", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "n_components", "+", "1", ")", ":", "\n", "                    ", "loop_info", ".", "update", "(", "i", ")", "\n", "\n", "# crop each region", "\n", "_", ",", "crop", "=", "crop_volume_around_region", "(", "components", ",", "masking_labels", "=", "i", ",", "margin", "=", "1", ")", "\n", "tmp_labels", "=", "crop_volume_with_idx", "(", "labels", ",", "crop", ")", "\n", "tmp_new_labels", "=", "crop_volume_with_idx", "(", "new_labels", ",", "crop", ")", "\n", "\n", "# list all possible correct labels", "\n", "correct_labels", "=", "np", ".", "unique", "(", "tmp_labels", ")", "\n", "for", "il", "in", "list_incorrect_labels", ":", "\n", "                        ", "correct_labels", "=", "np", ".", "delete", "(", "correct_labels", ",", "np", ".", "where", "(", "correct_labels", "==", "il", ")", ")", "\n", "\n", "", "if", "len", "(", "correct_labels", ")", "==", "1", ":", "\n", "                        ", "tmp_new_labels", "=", "correct_labels", "[", "0", "]", "*", "np", ".", "ones_like", "(", "tmp_labels", ")", "\n", "", "else", ":", "\n", "                        ", "if", "remove_zero", ":", "\n", "                            ", "correct_labels", "=", "np", ".", "delete", "(", "correct_labels", ",", "np", ".", "where", "(", "correct_labels", "==", "0", ")", ")", "\n", "\n", "# calculate distance maps for all new label candidates", "\n", "", "incorrect_voxels", "=", "np", ".", "where", "(", "tmp_labels", "==", "incorrect_label", ")", "\n", "distance_map_list", "=", "[", "distance_transform_edt", "(", "tmp_labels", "!=", "lab", ")", "for", "lab", "in", "correct_labels", "]", "\n", "distances_correct", "=", "np", ".", "stack", "(", "[", "dist", "[", "incorrect_voxels", "]", "for", "dist", "in", "distance_map_list", "]", ")", "\n", "\n", "# select nearest value", "\n", "idx_correct_lab", "=", "np", ".", "argmin", "(", "distances_correct", ",", "axis", "=", "0", ")", "\n", "tmp_new_labels", "[", "incorrect_voxels", "]", "=", "np", ".", "array", "(", "correct_labels", ")", "[", "idx_correct_lab", "]", "\n", "\n", "# paste back", "\n", "", "if", "n_dims", "==", "2", ":", "\n", "                        ", "new_labels", "[", "crop", "[", "0", "]", ":", "crop", "[", "2", "]", ",", "crop", "[", "1", "]", ":", "crop", "[", "3", "]", ",", "...", "]", "=", "tmp_new_labels", "\n", "", "else", ":", "\n", "                        ", "new_labels", "[", "crop", "[", "0", "]", ":", "crop", "[", "3", "]", ",", "crop", "[", "1", "]", ":", "crop", "[", "4", "]", ",", "crop", "[", "2", "]", ":", "crop", "[", "5", "]", ",", "...", "]", "=", "tmp_new_labels", "\n", "\n", "# smoothing", "\n", "", "", "", "", "", "if", "smooth", ":", "\n", "        ", "kernel", "=", "np", ".", "ones", "(", "tuple", "(", "[", "3", "]", "*", "n_dims", ")", ")", "\n", "new_labels", "=", "smooth_label_map", "(", "new_labels", ",", "kernel", ")", "\n", "\n", "", "return", "new_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mask_label_map": [[757, 779], ["numpy.zeros", "labels.copy", "utils.reformat_to_list", "numpy.logical_not"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list"], ["", "def", "mask_label_map", "(", "labels", ",", "masking_values", ",", "masking_value", "=", "0", ",", "return_mask", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    This function masks a label map around a list of specified values.\n    :param labels: input label map\n    :param masking_values: list of values to mask around\n    :param masking_value: (optional) value to mask the label map with\n    :param return_mask: (optional) whether to return the applied mask\n    :return: the masked label map, and the applied mask if return_mask is True.\n    \"\"\"", "\n", "\n", "# build mask and mask labels", "\n", "mask", "=", "np", ".", "zeros", "(", "labels", ".", "shape", ",", "dtype", "=", "bool", ")", "\n", "masked_labels", "=", "labels", ".", "copy", "(", ")", "\n", "for", "value", "in", "utils", ".", "reformat_to_list", "(", "masking_values", ")", ":", "\n", "        ", "mask", "=", "mask", "|", "(", "labels", "==", "value", ")", "\n", "", "masked_labels", "[", "np", ".", "logical_not", "(", "mask", ")", "]", "=", "masking_value", "\n", "\n", "if", "return_mask", ":", "\n", "        ", "mask", "=", "mask", "*", "1", "\n", "return", "masked_labels", ",", "mask", "\n", "", "else", ":", "\n", "        ", "return", "masked_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.smooth_label_map": [[781, 823], ["numpy.unique().astype", "numpy.zeros", "numpy.zeros", "utils.LoopInfo", "enumerate", "edit_volumes.mask_label_map", "len", "scipy.ndimage.filters.convolve", "labels_smoothed.astype.astype", "numpy.where", "numpy.unique", "utils.LoopInfo.update"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mask_label_map", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update"], ["", "", "def", "smooth_label_map", "(", "labels", ",", "kernel", ",", "labels_list", "=", "None", ",", "print_progress", "=", "0", ")", ":", "\n", "    ", "\"\"\"This function smooth an input label map by replacing each voxel by the value of its most numerous neigbour.\n    :param labels: input label map\n    :param kernel: kernel when counting neighbours. Must contain only zeros or ones.\n    :param labels_list: list of label values to smooth. Defaults is None, where all labels are smoothed.\n    :param print_progress: (optional) If not 0, interval at which to print the number of processed labels.\n    :return: smoothed label map\n    \"\"\"", "\n", "# get info", "\n", "labels_shape", "=", "labels", ".", "shape", "\n", "unique_labels", "=", "np", ".", "unique", "(", "labels", ")", ".", "astype", "(", "'int32'", ")", "\n", "if", "labels_list", "is", "None", ":", "\n", "        ", "labels_list", "=", "unique_labels", "\n", "new_labels", "=", "mask_new_labels", "=", "None", "\n", "", "else", ":", "\n", "        ", "labels_to_keep", "=", "[", "lab", "for", "lab", "in", "unique_labels", "if", "lab", "not", "in", "labels_list", "]", "\n", "new_labels", ",", "mask_new_labels", "=", "mask_label_map", "(", "labels", ",", "labels_to_keep", ",", "return_mask", "=", "True", ")", "\n", "\n", "# loop through label values", "\n", "", "count", "=", "np", ".", "zeros", "(", "labels_shape", ")", "\n", "labels_smoothed", "=", "np", ".", "zeros", "(", "labels_shape", ",", "dtype", "=", "'int'", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "labels_list", ")", ",", "print_progress", ",", "'smoothing'", ")", "\n", "for", "la", ",", "label", "in", "enumerate", "(", "labels_list", ")", ":", "\n", "        ", "if", "print_progress", ":", "\n", "            ", "loop_info", ".", "update", "(", "la", ")", "\n", "\n", "# count neigbours with same value", "\n", "", "mask", "=", "(", "labels", "==", "label", ")", "*", "1", "\n", "n_neighbours", "=", "convolve", "(", "mask", ",", "kernel", ")", "\n", "\n", "# update label map and maximum neigbour counts", "\n", "idx", "=", "n_neighbours", ">", "count", "\n", "count", "[", "idx", "]", "=", "n_neighbours", "[", "idx", "]", "\n", "labels_smoothed", "[", "idx", "]", "=", "label", "\n", "labels_smoothed", "=", "labels_smoothed", ".", "astype", "(", "'int32'", ")", "\n", "\n", "", "if", "new_labels", "is", "None", ":", "\n", "        ", "new_labels", "=", "labels_smoothed", "\n", "", "else", ":", "\n", "        ", "new_labels", "=", "np", ".", "where", "(", "mask_new_labels", ",", "new_labels", ",", "labels_smoothed", ")", "\n", "\n", "", "return", "new_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.erode_label_map": [[825, 893], ["labels.copy", "utils.reformat_to_list", "utils.reformat_to_list", "list", "utils.get_dims", "zip", "edit_volumes.crop_volume_around_region", "edit_volumes.crop_volume_with_idx", "numpy.unique", "numpy.stack", "numpy.argmin", "len", "int", "utils.build_binary_structure", "scipy.ndimage.binary_erosion", "numpy.logical_not", "scipy.ndimage.morphology.distance_transform_edt", "numpy.array", "int", "keras.models.Model.predict", "edit_volumes.blur_volume", "numpy.squeeze", "numpy.logical_not", "keras.Input", "keras.models.Model", "utils.add_axis", "numpy.array", "layers.GaussianBlur", "numpy.float32"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_around_region", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_with_idx", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.build_binary_structure", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.blur_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis"], ["", "def", "erode_label_map", "(", "labels", ",", "labels_to_erode", ",", "erosion_factors", "=", "1.", ",", "gpu", "=", "False", ",", "model", "=", "None", ",", "return_model", "=", "False", ")", ":", "\n", "    ", "\"\"\"Erode a given set of label values within a label map.\n    :param labels: a 2d or 3d label map\n    :param labels_to_erode: list of label values to erode\n    :param erosion_factors: (optional) list of erosion factors to use for each label. If values are integers, normal\n    erosion applies. If float, we first 1) blur a mask of the corresponding label value, and 2) use the erosion factor\n    as a threshold in the blurred mask.\n    If erosion_factors is a single value, the same factor will be applied to all labels.\n    :param gpu: (optionnal) whether to use a fast gpu model for blurring (if erosion factors are floats)\n    :param model: (optionnal) gpu model for blurring masks (if erosion factors are floats)\n    :param return_model: (optional) whether to return the gpu blurring model\n    :return: eroded label map, and gpu blurring model is return_model is True.\n    \"\"\"", "\n", "# reformat labels_to_erode and erode", "\n", "new_labels", "=", "labels", ".", "copy", "(", ")", "\n", "labels_to_erode", "=", "utils", ".", "reformat_to_list", "(", "labels_to_erode", ")", "\n", "erosion_factors", "=", "utils", ".", "reformat_to_list", "(", "erosion_factors", ",", "length", "=", "len", "(", "labels_to_erode", ")", ")", "\n", "labels_shape", "=", "list", "(", "new_labels", ".", "shape", ")", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "labels_shape", ")", "\n", "\n", "# loop over labels to erode", "\n", "for", "label_to_erode", ",", "erosion_factor", "in", "zip", "(", "labels_to_erode", ",", "erosion_factors", ")", ":", "\n", "\n", "        ", "assert", "erosion_factor", ">", "0", ",", "'all erosion factors should be strictly positive, had {}'", ".", "format", "(", "erosion_factor", ")", "\n", "\n", "# get mask of current label value", "\n", "mask", "=", "(", "new_labels", "==", "label_to_erode", ")", "\n", "\n", "# erode as usual if erosion factor is int", "\n", "if", "int", "(", "erosion_factor", ")", "==", "erosion_factor", ":", "\n", "            ", "erode_struct", "=", "utils", ".", "build_binary_structure", "(", "int", "(", "erosion_factor", ")", ",", "n_dims", ")", "\n", "eroded_mask", "=", "binary_erosion", "(", "mask", ",", "erode_struct", ")", "\n", "\n", "# blur mask and use erosion factor as a threshold if float", "\n", "", "else", ":", "\n", "            ", "if", "gpu", ":", "\n", "                ", "if", "model", "is", "None", ":", "\n", "                    ", "mask_in", "=", "KL", ".", "Input", "(", "shape", "=", "labels_shape", "+", "[", "1", "]", ",", "dtype", "=", "'float32'", ")", "\n", "blurred_mask", "=", "GaussianBlur", "(", "[", "1", "]", "*", "3", ")", "(", "mask_in", ")", "\n", "model", "=", "Model", "(", "inputs", "=", "mask_in", ",", "outputs", "=", "blurred_mask", ")", "\n", "", "eroded_mask", "=", "model", ".", "predict", "(", "utils", ".", "add_axis", "(", "np", ".", "float32", "(", "mask", ")", ",", "axis", "=", "[", "0", ",", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "eroded_mask", "=", "blur_volume", "(", "np", ".", "array", "(", "mask", ",", "dtype", "=", "'float32'", ")", ",", "1", ")", "\n", "", "eroded_mask", "=", "np", ".", "squeeze", "(", "eroded_mask", ")", ">", "erosion_factor", "\n", "\n", "# crop label map and mask around values to change", "\n", "", "mask", "=", "mask", "&", "np", ".", "logical_not", "(", "eroded_mask", ")", "\n", "cropped_lab_mask", ",", "cropping", "=", "crop_volume_around_region", "(", "mask", ",", "margin", "=", "3", ")", "\n", "croppped_labels", "=", "crop_volume_with_idx", "(", "new_labels", ",", "cropping", ")", "\n", "\n", "# calculate distance maps for all labels in cropped_labels", "\n", "labels_list", "=", "np", ".", "unique", "(", "croppped_labels", ")", "\n", "labels_list", "=", "labels_list", "[", "labels_list", "!=", "label_to_erode", "]", "\n", "list_dist_maps", "=", "[", "distance_transform_edt", "(", "np", ".", "logical_not", "(", "croppped_labels", "==", "la", ")", ")", "for", "la", "in", "labels_list", "]", "\n", "candidate_distances", "=", "np", ".", "stack", "(", "[", "dist", "[", "cropped_lab_mask", "]", "for", "dist", "in", "list_dist_maps", "]", ")", "\n", "\n", "# select nearest value and put cropped labels back to full label map", "\n", "idx_correct_lab", "=", "np", ".", "argmin", "(", "candidate_distances", ",", "axis", "=", "0", ")", "\n", "croppped_labels", "[", "cropped_lab_mask", "]", "=", "np", ".", "array", "(", "labels_list", ")", "[", "idx_correct_lab", "]", "\n", "if", "n_dims", "==", "2", ":", "\n", "            ", "new_labels", "[", "cropping", "[", "0", "]", ":", "cropping", "[", "2", "]", ",", "cropping", "[", "1", "]", ":", "cropping", "[", "3", "]", ",", "...", "]", "=", "croppped_labels", "\n", "", "elif", "n_dims", "==", "3", ":", "\n", "            ", "new_labels", "[", "cropping", "[", "0", "]", ":", "cropping", "[", "3", "]", ",", "cropping", "[", "1", "]", ":", "cropping", "[", "4", "]", ",", "cropping", "[", "2", "]", ":", "cropping", "[", "5", "]", ",", "...", "]", "=", "croppped_labels", "\n", "\n", "", "if", "return_model", ":", "\n", "            ", "return", "new_labels", ",", "model", "\n", "", "else", ":", "\n", "            ", "return", "new_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_largest_connected_component": [[895, 902], ["scipy.ndimage.label", "mask.copy", "numpy.argmax", "numpy.bincount"], "function", ["None"], ["", "", "", "def", "get_largest_connected_component", "(", "mask", ",", "structure", "=", "None", ")", ":", "\n", "    ", "\"\"\"Function to get the largest connected component for a given input.\n    :param mask: a 2d or 3d label map of boolean type.\n    :param structure: numpy array defining the connectivity.\n    \"\"\"", "\n", "components", ",", "n_components", "=", "scipy_label", "(", "mask", ",", "structure", ")", "\n", "return", "components", "==", "np", ".", "argmax", "(", "np", ".", "bincount", "(", "components", ".", "flat", ")", "[", "1", ":", "]", ")", "+", "1", "if", "n_components", ">", "0", "else", "mask", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.compute_hard_volumes": [[904, 935], ["utils.reformat_to_list", "numpy.zeros", "enumerate", "numpy.unique", "utils.reformat_to_list", "len", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list"], ["", "def", "compute_hard_volumes", "(", "labels", ",", "voxel_volume", "=", "1.", ",", "label_list", "=", "None", ",", "skip_background", "=", "True", ")", ":", "\n", "    ", "\"\"\"Compute hard volumes in a label map.\n    :param labels: a label map\n    :param voxel_volume: (optional) volume of voxel. Default is 1 (i.e. returned volumes are voxel counts).\n    :param label_list: (optional) list of labels to compute volumes for. Can be an int, a sequence, or a numpy array.\n    If None, the volumes of all label values are computed.\n    :param skip_background: (optional) whether to skip computing the volume of the background.\n    If label_list is None, this assumes background value is 0.\n    If label_list is not None, this assumes the background is the first value in label list.\n    :return: numpy 1d vector with the volumes of each structure\n    \"\"\"", "\n", "\n", "# initialisation", "\n", "subject_label_list", "=", "utils", ".", "reformat_to_list", "(", "np", ".", "unique", "(", "labels", ")", ",", "dtype", "=", "'int'", ")", "\n", "if", "label_list", "is", "None", ":", "\n", "        ", "label_list", "=", "subject_label_list", "\n", "", "else", ":", "\n", "        ", "label_list", "=", "utils", ".", "reformat_to_list", "(", "label_list", ")", "\n", "", "if", "skip_background", ":", "\n", "        ", "label_list", "=", "label_list", "[", "1", ":", "]", "\n", "", "volumes", "=", "np", ".", "zeros", "(", "len", "(", "label_list", ")", ")", "\n", "\n", "# loop over label values", "\n", "for", "idx", ",", "label", "in", "enumerate", "(", "label_list", ")", ":", "\n", "        ", "if", "label", "in", "subject_label_list", ":", "\n", "            ", "mask", "=", "(", "labels", "==", "label", ")", "*", "1", "\n", "volumes", "[", "idx", "]", "=", "np", ".", "sum", "(", "mask", ")", "\n", "", "else", ":", "\n", "            ", "volumes", "[", "idx", "]", "=", "0", "\n", "\n", "", "", "return", "volumes", "*", "voxel_volume", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.compute_distance_map": [[937, 983], ["utils.get_dims", "numpy.logical_not", "scipy.ndimage.morphology.distance_transform_edt", "numpy.where", "numpy.where", "edit_volumes.crop_volume_around_region", "utils.reformat_to_list", "numpy.zeros", "scipy.ndimage.morphology.distance_transform_edt", "numpy.min", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_around_region", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list"], ["", "def", "compute_distance_map", "(", "labels", ",", "masking_labels", "=", "None", ",", "crop_margin", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute distance map for a given list of label values in a label map.\n    :param labels: a label map\n    :param masking_labels: (optional) list of label values to mask the label map with. The distances will be computed\n    for these labels only. Default is None, where all positive values are considered.\n    :param crop_margin: (optional) margin with which to crop the input label maps around the the labels for which we\n    want to compute the distance maps.\n    :return: a distance map with positive values inside the considered regions, and negative values outside.\"\"\"", "\n", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "labels", ".", "shape", ")", "\n", "\n", "# crop label map if necessary", "\n", "if", "crop_margin", "is", "not", "None", ":", "\n", "        ", "tmp_labels", ",", "crop_idx", "=", "crop_volume_around_region", "(", "labels", ",", "margin", "=", "crop_margin", ")", "\n", "", "else", ":", "\n", "        ", "tmp_labels", "=", "labels", "\n", "crop_idx", "=", "None", "\n", "\n", "# mask label map around specify values", "\n", "", "if", "masking_labels", "is", "not", "None", ":", "\n", "        ", "masking_labels", "=", "utils", ".", "reformat_to_list", "(", "masking_labels", ")", "\n", "mask", "=", "np", ".", "zeros", "(", "tmp_labels", ".", "shape", ",", "dtype", "=", "'bool'", ")", "\n", "for", "masking_label", "in", "masking_labels", ":", "\n", "            ", "mask", "=", "mask", "|", "tmp_labels", "==", "masking_label", "\n", "", "", "else", ":", "\n", "        ", "mask", "=", "tmp_labels", ">", "0", "\n", "", "not_mask", "=", "np", ".", "logical_not", "(", "mask", ")", "\n", "\n", "# compute distances", "\n", "dist_in", "=", "distance_transform_edt", "(", "mask", ")", "\n", "dist_in", "=", "np", ".", "where", "(", "mask", ",", "dist_in", "-", "0.5", ",", "dist_in", ")", "\n", "dist_out", "=", "-", "distance_transform_edt", "(", "not_mask", ")", "\n", "dist_out", "=", "np", ".", "where", "(", "not_mask", ",", "dist_out", "+", "0.5", ",", "dist_out", ")", "\n", "tmp_dist", "=", "dist_in", "+", "dist_out", "\n", "\n", "# put back in original matrix if we cropped", "\n", "if", "crop_idx", "is", "not", "None", ":", "\n", "        ", "dist", "=", "np", ".", "min", "(", "tmp_dist", ")", "*", "np", ".", "ones", "(", "labels", ".", "shape", ",", "dtype", "=", "'float32'", ")", "\n", "if", "n_dims", "==", "3", ":", "\n", "            ", "dist", "[", "crop_idx", "[", "0", "]", ":", "crop_idx", "[", "3", "]", ",", "crop_idx", "[", "1", "]", ":", "crop_idx", "[", "4", "]", ",", "crop_idx", "[", "2", "]", ":", "crop_idx", "[", "5", "]", ",", "...", "]", "=", "tmp_dist", "\n", "", "elif", "n_dims", "==", "2", ":", "\n", "            ", "dist", "[", "crop_idx", "[", "0", "]", ":", "crop_idx", "[", "2", "]", ",", "crop_idx", "[", "1", "]", ":", "crop_idx", "[", "3", "]", ",", "...", "]", "=", "tmp_dist", "\n", "", "", "else", ":", "\n", "        ", "dist", "=", "tmp_dist", "\n", "\n", "", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mask_images_in_dir": [[987, 1042], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "utils.mkdir", "utils.list_images_in_folder", "len", "zip", "utils.LoopInfo.update", "os.path.join", "len", "os.path.basename", "utils.load_volume", "edit_volumes.mask_volume", "os.path.isfile", "utils.load_volume", "os.path.join", "utils.save_volume", "utils.save_volume", "utils.save_volume", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mask_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume"], ["", "def", "mask_images_in_dir", "(", "image_dir", ",", "result_dir", ",", "mask_dir", "=", "None", ",", "threshold", "=", "0.1", ",", "dilate", "=", "0", ",", "erode", "=", "0", ",", "fill_holes", "=", "False", ",", "\n", "masking_value", "=", "0", ",", "write_mask", "=", "False", ",", "mask_result_dir", "=", "None", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"Mask all volumes in a folder, either with masks in a specified folder, or by keeping only the intensity values\n    above a specified threshold.\n    :param image_dir: path of directory with images to mask\n    :param result_dir: path of directory where masked images will be writen\n    :param mask_dir: (optional) path of directory containing masks. Masks are matched to images by sorting order.\n    Mask volumes don't have to be boolean or 0/1 arrays as all strictly positive values are used to build the masks.\n    Masks should have the same size as images. If images are multi-channel, masks can either be uni- or multi-channel.\n    In the first case, the same mask is applied to all channels.\n    :param threshold: (optional) If mask is None, masking is performed by keeping thresholding the input.\n    :param dilate: (optional) number of voxels by which to dilate the provided or computed masks.\n    :param erode: (optional) number of voxels by which to erode the provided or computed masks.\n    :param fill_holes: (optional) whether to fill the holes in the provided or computed masks.\n    :param masking_value: (optional) masking value\n    :param write_mask: (optional) whether to write the applied masks\n    :param mask_result_dir: (optional) path of resulting masks, if write_mask is True\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "if", "mask_result_dir", "is", "not", "None", ":", "\n", "        ", "utils", ".", "mkdir", "(", "mask_result_dir", ")", "\n", "\n", "# get path masks if necessary", "\n", "", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "if", "mask_dir", "is", "not", "None", ":", "\n", "        ", "path_masks", "=", "utils", ".", "list_images_in_folder", "(", "mask_dir", ")", "\n", "", "else", ":", "\n", "        ", "path_masks", "=", "[", "None", "]", "*", "len", "(", "path_images", ")", "\n", "\n", "# loop over images", "\n", "", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'masking'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_mask", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_masks", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# mask images", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "im", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "if", "path_mask", "is", "not", "None", ":", "\n", "                ", "mask", "=", "utils", ".", "load_volume", "(", "path_mask", ")", "\n", "", "else", ":", "\n", "                ", "mask", "=", "None", "\n", "", "im", "=", "mask_volume", "(", "im", ",", "mask", ",", "threshold", ",", "dilate", ",", "erode", ",", "fill_holes", ",", "masking_value", ",", "write_mask", ")", "\n", "\n", "# write mask if necessary", "\n", "if", "write_mask", ":", "\n", "                ", "assert", "mask_result_dir", "is", "not", "None", ",", "'if write_mask is True, mask_result_dir has to be specified as well'", "\n", "mask_result_path", "=", "os", ".", "path", ".", "join", "(", "mask_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "utils", ".", "save_volume", "(", "im", "[", "1", "]", ",", "aff", ",", "h", ",", "mask_result_path", ")", "\n", "utils", ".", "save_volume", "(", "im", "[", "0", "]", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "", "else", ":", "\n", "                ", "utils", ".", "save_volume", "(", "im", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.rescale_images_in_dir": [[1044, 1075], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "len", "utils.LoopInfo.update", "os.path.join", "os.path.basename", "utils.load_volume", "edit_volumes.rescale_volume", "utils.save_volume", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.rescale_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume"], ["", "", "", "", "def", "rescale_images_in_dir", "(", "image_dir", ",", "result_dir", ",", "\n", "new_min", "=", "0", ",", "new_max", "=", "255", ",", "\n", "min_percentile", "=", "2", ",", "max_percentile", "=", "98", ",", "use_positive_only", "=", "True", ",", "\n", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function linearly rescales all volumes in image_dir between new_min and new_max.\n    :param image_dir: path of directory with images to rescale\n    :param result_dir: path of directory where rescaled images will be writen\n    :param new_min: (optional) minimum value for the rescaled images.\n    :param new_max: (optional) maximum value for the rescaled images.\n    :param min_percentile: (optional) percentile for estimating robust minimum of volume (float in [0,...100]),\n    where 0 = np.min\n    :param max_percentile: (optional) percentile for estimating robust maximum of volume (float in [0,...100]),\n    where 100 = np.max\n    :param use_positive_only: (optional) whether to use only positive values when estimating the min and max percentile\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# loop over images", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'rescaling'", ",", "True", ")", "\n", "for", "idx", ",", "path_image", "in", "enumerate", "(", "path_images", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "im", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "im", "=", "rescale_volume", "(", "im", ",", "new_min", ",", "new_max", ",", "min_percentile", ",", "max_percentile", ",", "use_positive_only", ")", "\n", "utils", ".", "save_volume", "(", "im", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_images_in_dir": [[1077, 1103], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "len", "utils.LoopInfo.update", "os.path.join", "os.path.basename", "utils.load_volume", "edit_volumes.crop_volume", "utils.save_volume", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume"], ["", "", "", "def", "crop_images_in_dir", "(", "image_dir", ",", "result_dir", ",", "cropping_margin", "=", "None", ",", "cropping_shape", "=", "None", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"Crop all volumes in a folder by a given margin, or to a given shape.\n    :param image_dir: path of directory with images to rescale\n    :param result_dir: path of directory where cropped images will be writen\n    :param cropping_margin: (optional) margin by which to crop the volume.\n    Can be an int, a sequence or a 1d numpy array. Should be given if cropping_shape is None.\n    :param cropping_shape: (optional) shape to which the volume will be cropped.\n    Can be an int, a sequence or a 1d numpy array. Should be given if cropping_margin is None.\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# loop over images and masks", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'cropping'", ",", "True", ")", "\n", "for", "idx", ",", "path_image", "in", "enumerate", "(", "path_images", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# crop image", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "volume", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "volume", ",", "aff", "=", "crop_volume", "(", "volume", ",", "cropping_margin", ",", "cropping_shape", ",", "aff", ")", "\n", "utils", ".", "save_volume", "(", "volume", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_images_around_region_in_dir": [[1105, 1151], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "utils.list_images_in_folder", "len", "zip", "utils.LoopInfo.update", "os.path.join", "len", "os.path.basename", "utils.load_volume", "edit_volumes.crop_volume_around_region", "utils.save_volume", "os.path.isfile", "utils.load_volume"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_around_region", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume"], ["", "", "", "def", "crop_images_around_region_in_dir", "(", "image_dir", ",", "\n", "result_dir", ",", "\n", "mask_dir", "=", "None", ",", "\n", "threshold", "=", "0.1", ",", "\n", "masking_labels", "=", "None", ",", "\n", "crop_margin", "=", "5", ",", "\n", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"Crop all volumes in a folder around a region, which is defined for each volume by a mask obtained by either\n    1) directly providing it as input\n    2) thresholding the input volume\n    3) keeping a set of label values if the volume is a label map.\n    :param image_dir: path of directory with images to crop\n    :param result_dir: path of directory where cropped images will be writen\n    :param mask_dir: (optional) path of directory of input masks\n    :param threshold: (optional) lower bound to determine values to crop around\n    :param masking_labels: (optional) if the volume is a label map, it can be cropped around a given set of labels by\n    specifying them in masking_labels, which can either be a single int, a list or a 1d numpy array.\n    :param crop_margin: (optional) cropping margin\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# list volumes and masks", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "if", "mask_dir", "is", "not", "None", ":", "\n", "        ", "path_masks", "=", "utils", ".", "list_images_in_folder", "(", "mask_dir", ")", "\n", "", "else", ":", "\n", "        ", "path_masks", "=", "[", "None", "]", "*", "len", "(", "path_images", ")", "\n", "\n", "# loop over images and masks", "\n", "", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'cropping'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_mask", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_masks", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# crop image", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "volume", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "True", ")", "\n", "if", "path_mask", "is", "not", "None", ":", "\n", "                ", "mask", "=", "utils", ".", "load_volume", "(", "path_mask", ")", "\n", "", "else", ":", "\n", "                ", "mask", "=", "None", "\n", "", "volume", ",", "cropping", ",", "aff", "=", "crop_volume_around_region", "(", "volume", ",", "mask", ",", "threshold", ",", "masking_labels", ",", "crop_margin", ",", "aff", ")", "\n", "utils", ".", "save_volume", "(", "volume", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.pad_images_in_dir": [[1153, 1191], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "utils.get_volume_info", "numpy.array", "len", "utils.LoopInfo.update", "os.path.join", "utils.get_volume_info", "tuple", "os.path.basename", "utils.load_volume", "edit_volumes.pad_volume", "utils.save_volume", "numpy.maximum", "os.path.isfile", "numpy.asarray", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.pad_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume"], ["", "", "", "def", "pad_images_in_dir", "(", "image_dir", ",", "result_dir", ",", "max_shape", "=", "None", ",", "padding_value", "=", "0", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"Pads all the volumes in a folder to the same shape (either provided or computed).\n    :param image_dir: path of directory with images to pad\n    :param result_dir: path of directory where padded images will be writen\n    :param max_shape: (optional) shape to pad the volumes to. Can be an int, a sequence or a 1d numpy array.\n    If None, volumes will be padded to the shape of the biggest volume in image_dir.\n    :param padding_value: (optional) value to pad the volumes with.\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    :return: shape of the padded volumes.\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# list labels", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "\n", "# get maximum shape", "\n", "if", "max_shape", "is", "None", ":", "\n", "        ", "max_shape", ",", "aff", ",", "_", ",", "_", ",", "h", ",", "_", "=", "utils", ".", "get_volume_info", "(", "path_images", "[", "0", "]", ")", "\n", "for", "path_image", "in", "path_images", "[", "1", ":", "]", ":", "\n", "            ", "image_shape", ",", "aff", ",", "_", ",", "_", ",", "h", ",", "_", "=", "utils", ".", "get_volume_info", "(", "path_image", ")", "\n", "max_shape", "=", "tuple", "(", "np", ".", "maximum", "(", "np", ".", "asarray", "(", "max_shape", ")", ",", "np", ".", "asarray", "(", "image_shape", ")", ")", ")", "\n", "", "max_shape", "=", "np", ".", "array", "(", "max_shape", ")", "\n", "\n", "# loop over label maps", "\n", "", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'padding'", ",", "True", ")", "\n", "for", "idx", ",", "path_image", "in", "enumerate", "(", "path_images", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# pad map", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "im", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "im", ",", "aff", "=", "pad_volume", "(", "im", ",", "max_shape", ",", "padding_value", ",", "aff", ")", "\n", "utils", ".", "save_volume", "(", "im", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n", "", "", "return", "max_shape", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.flip_images_in_dir": [[1193, 1218], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "len", "utils.LoopInfo.update", "os.path.join", "os.path.basename", "utils.load_volume", "edit_volumes.flip_volume", "utils.save_volume", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.flip_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume"], ["", "def", "flip_images_in_dir", "(", "image_dir", ",", "result_dir", ",", "axis", "=", "None", ",", "direction", "=", "None", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"Flip all images in a diretory along a specified axis.\n    If unknown, this axis can be replaced by an anatomical direction.\n    :param image_dir: path of directory with images to flip\n    :param result_dir: path of directory where flipped images will be writen\n    :param axis: (optional) axis along which to flip the volume\n    :param direction: (optional) if axis is None, the volume can be flipped along an anatomical direction:\n    'rl' (right/left), 'ap' (anterior/posterior), 'si' (superior/inferior).\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# loop over images", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'flipping'", ",", "True", ")", "\n", "for", "idx", ",", "path_image", "in", "enumerate", "(", "path_images", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# flip image", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "im", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "im", "=", "flip_volume", "(", "im", ",", "axis", "=", "axis", ",", "direction", "=", "direction", ",", "aff", "=", "aff", ")", "\n", "utils", ".", "save_volume", "(", "im", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_images_in_dir": [[1220, 1266], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "os.path.basename", "len", "zip", "utils.LoopInfo.update", "os.path.join", "utils.load_volume", "utils.list_images_in_folder", "utils.load_array_if_path", "numpy.eye", "os.path.basename", "utils.load_volume", "edit_volumes.align_volume_to_ref", "utils.save_volume", "len", "len", "len", "os.path.isfile", "utils.load_volume"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume"], ["", "", "", "def", "align_images_in_dir", "(", "image_dir", ",", "result_dir", ",", "aff_ref", "=", "None", ",", "path_ref", "=", "None", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function aligns all images in image_dir to a reference orientation (axes and directions).\n    This reference orientation can be directly provided as an affine matrix, or can be specified by a reference volume.\n    If neither are provided, the reference orientation is assumed to be an identity matrix.\n    :param image_dir: path of directory with images to align\n    :param result_dir: path of directory where flipped images will be writen\n    :param aff_ref: (optional) reference affine matrix. Can be a numpy array, or the path to such array.\n    :param path_ref: (optional) path of a volume to which all images will be aligned. Can also be the path to a folder\n    with as many images as in image_dir, in which case each image in image_dir is aligned to its couterpart in path_ref\n    (they are matched by sorting order).\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "\n", "# read reference affine matrix", "\n", "if", "path_ref", "is", "not", "None", ":", "\n", "        ", "assert", "aff_ref", "is", "None", ",", "'cannot provide aff_ref and path_ref together.'", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "path_ref", ")", "\n", "if", "(", "'.nii.gz'", "in", "basename", ")", "|", "(", "'.nii'", "in", "basename", ")", "|", "(", "'.mgz'", "in", "basename", ")", "|", "(", "'.npz'", "in", "basename", ")", ":", "\n", "            ", "_", ",", "aff_ref", ",", "_", "=", "utils", ".", "load_volume", "(", "path_ref", ",", "im_only", "=", "False", ")", "\n", "path_refs", "=", "[", "None", "]", "*", "len", "(", "path_images", ")", "\n", "", "else", ":", "\n", "            ", "path_refs", "=", "utils", ".", "list_images_in_folder", "(", "path_ref", ")", "\n", "", "", "elif", "aff_ref", "is", "not", "None", ":", "\n", "        ", "aff_ref", "=", "utils", ".", "load_array_if_path", "(", "aff_ref", ")", "\n", "path_refs", "=", "[", "None", "]", "*", "len", "(", "path_images", ")", "\n", "", "else", ":", "\n", "        ", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", "\n", "path_refs", "=", "[", "None", "]", "*", "len", "(", "path_images", ")", "\n", "\n", "# loop over images", "\n", "", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'aligning'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_ref", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_refs", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# align image", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "im", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "if", "path_ref", "is", "not", "None", ":", "\n", "                ", "_", ",", "aff_ref", ",", "_", "=", "utils", ".", "load_volume", "(", "path_ref", ",", "im_only", "=", "False", ")", "\n", "", "im", ",", "aff", "=", "align_volume_to_ref", "(", "im", ",", "aff", ",", "aff_ref", "=", "aff_ref", ",", "return_aff", "=", "True", ")", "\n", "utils", ".", "save_volume", "(", "im", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.correct_nans_images_in_dir": [[1268, 1289], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "len", "utils.LoopInfo.update", "os.path.join", "os.path.basename", "utils.load_volume", "utils.save_volume", "os.path.isfile", "numpy.isnan"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume"], ["", "", "", "def", "correct_nans_images_in_dir", "(", "image_dir", ",", "result_dir", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"Correct NaNs in all images in a directory.\n    :param image_dir: path of directory with images to correct\n    :param result_dir: path of directory where corrected images will be writen\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# loop over images", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'correcting'", ",", "True", ")", "\n", "for", "idx", ",", "path_image", "in", "enumerate", "(", "path_images", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# flip image", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "im", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "im", "[", "np", ".", "isnan", "(", "im", ")", "]", "=", "0", "\n", "utils", ".", "save_volume", "(", "im", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.blur_images_in_dir": [[1291, 1349], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "utils.list_images_in_folder", "len", "zip", "utils.LoopInfo.update", "os.path.join", "len", "os.path.basename", "utils.get_volume_info", "utils.save_volume", "os.path.isfile", "utils.load_volume", "edit_volumes.blur_volume", "utils.reformat_to_list", "keras.models.Model", "numpy.squeeze", "numpy.squeeze", "keras.Input", "inputs.append", "keras.models.Model.predict", "keras.models.Model.predict", "layers.GaussianBlur", "keras.Input", "layers.GaussianBlur", "utils.add_axis", "utils.add_axis", "utils.add_axis"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.blur_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis"], ["", "", "", "def", "blur_images_in_dir", "(", "image_dir", ",", "result_dir", ",", "sigma", ",", "mask_dir", "=", "None", ",", "gpu", "=", "False", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function blurs all the images in image_dir with kernels of the specified std deviations.\n    :param image_dir: path of directory with images to blur\n    :param result_dir: path of directory where blurred images will be writen\n    :param sigma: standard deviation of the blurring gaussian kernels.\n    Can be a number (isotropic blurring), or a sequence witht the same length as the number of dimensions of images.\n    :param mask_dir: (optional) path of directory with masks of the region to blur.\n    Images and masks are matched by sorting order.\n    :param gpu: (optional) whether to use a fast gpu model for blurring\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# list images and masks", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "if", "mask_dir", "is", "not", "None", ":", "\n", "        ", "path_masks", "=", "utils", ".", "list_images_in_folder", "(", "mask_dir", ")", "\n", "", "else", ":", "\n", "        ", "path_masks", "=", "[", "None", "]", "*", "len", "(", "path_images", ")", "\n", "\n", "# loop over images", "\n", "", "previous_model_input_shape", "=", "None", "\n", "model", "=", "None", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'blurring'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_mask", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_masks", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# load image", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "im", ",", "im_shape", ",", "aff", ",", "n_dims", ",", "_", ",", "h", ",", "_", "=", "utils", ".", "get_volume_info", "(", "path_image", ",", "return_volume", "=", "True", ")", "\n", "if", "path_mask", "is", "not", "None", ":", "\n", "                ", "mask", "=", "utils", ".", "load_volume", "(", "path_mask", ")", "\n", "assert", "mask", ".", "shape", "==", "im", ".", "shape", ",", "'mask and image should have the same shape'", "\n", "", "else", ":", "\n", "                ", "mask", "=", "None", "\n", "\n", "# blur image", "\n", "", "if", "gpu", ":", "\n", "                ", "if", "(", "im_shape", "!=", "previous_model_input_shape", ")", "|", "(", "model", "is", "None", ")", ":", "\n", "                    ", "previous_model_input_shape", "=", "im_shape", "\n", "inputs", "=", "[", "KL", ".", "Input", "(", "shape", "=", "im_shape", "+", "[", "1", "]", ")", "]", "\n", "sigma", "=", "utils", ".", "reformat_to_list", "(", "sigma", ",", "length", "=", "n_dims", ")", "\n", "if", "mask", "is", "None", ":", "\n", "                        ", "image", "=", "GaussianBlur", "(", "sigma", "=", "sigma", ")", "(", "inputs", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                        ", "inputs", ".", "append", "(", "KL", ".", "Input", "(", "shape", "=", "im_shape", "+", "[", "1", "]", ",", "dtype", "=", "'float32'", ")", ")", "\n", "image", "=", "GaussianBlur", "(", "sigma", "=", "sigma", ",", "use_mask", "=", "True", ")", "(", "inputs", ")", "\n", "", "model", "=", "Model", "(", "inputs", "=", "inputs", ",", "outputs", "=", "image", ")", "\n", "", "if", "mask", "is", "None", ":", "\n", "                    ", "im", "=", "np", ".", "squeeze", "(", "model", ".", "predict", "(", "utils", ".", "add_axis", "(", "im", ",", "axis", "=", "[", "0", ",", "-", "1", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "im", "=", "np", ".", "squeeze", "(", "model", ".", "predict", "(", "[", "utils", ".", "add_axis", "(", "im", ",", "[", "0", ",", "-", "1", "]", ")", ",", "utils", ".", "add_axis", "(", "mask", ",", "[", "0", ",", "-", "1", "]", ")", "]", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "im", "=", "blur_volume", "(", "im", ",", "sigma", ",", "mask", "=", "mask", ")", "\n", "", "utils", ".", "save_volume", "(", "im", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.create_mutlimodal_images": [[1351, 1388], ["utils.mkdir", "isinstance", "len", "len", "utils.LoopInfo", "range", "utils.list_images_in_folder", "utils.LoopInfo.update", "os.path.join", "len", "ValueError", "os.path.basename", "list", "range", "numpy.stack", "utils.save_volume", "os.path.isfile", "utils.load_volume", "list.append"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume"], ["", "", "", "def", "create_mutlimodal_images", "(", "list_channel_dir", ",", "result_dir", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function forms multimodal images by stacking channels located in different folders.\n    :param list_channel_dir: list of all directories, each containing the same channel for all images.\n    Channels are matched between folders by sorting order.\n    :param result_dir: path of directory where multimodal images will be writen\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "assert", "isinstance", "(", "list_channel_dir", ",", "(", "list", ",", "tuple", ")", ")", ",", "'list_channel_dir should be a list or a tuple'", "\n", "\n", "# gather path of all images for all channels", "\n", "list_channel_paths", "=", "[", "utils", ".", "list_images_in_folder", "(", "d", ")", "for", "d", "in", "list_channel_dir", "]", "\n", "n_images", "=", "len", "(", "list_channel_paths", "[", "0", "]", ")", "\n", "n_channels", "=", "len", "(", "list_channel_dir", ")", "\n", "for", "channel_paths", "in", "list_channel_paths", ":", "\n", "        ", "if", "len", "(", "channel_paths", ")", "!=", "n_images", ":", "\n", "            ", "raise", "ValueError", "(", "'all directories should have the same number of files'", ")", "\n", "\n", "# loop over images", "\n", "", "", "loop_info", "=", "utils", ".", "LoopInfo", "(", "n_images", ",", "10", ",", "'processing'", ",", "True", ")", "\n", "for", "idx", "in", "range", "(", "n_images", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# stack all channels and save multichannel image", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "list_channel_paths", "[", "0", "]", "[", "idx", "]", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "list_channels", "=", "list", "(", ")", "\n", "tmp_aff", "=", "None", "\n", "tmp_h", "=", "None", "\n", "for", "channel_idx", "in", "range", "(", "n_channels", ")", ":", "\n", "                ", "tmp_channel", ",", "tmp_aff", ",", "tmp_h", "=", "utils", ".", "load_volume", "(", "list_channel_paths", "[", "channel_idx", "]", "[", "idx", "]", ",", "im_only", "=", "False", ")", "\n", "list_channels", ".", "append", "(", "tmp_channel", ")", "\n", "", "im", "=", "np", ".", "stack", "(", "list_channels", ",", "axis", "=", "-", "1", ")", "\n", "utils", ".", "save_volume", "(", "im", ",", "tmp_aff", ",", "tmp_h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.convert_images_in_dir_to_nifty": [[1390, 1428], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "utils.list_images_in_folder", "len", "zip", "utils.LoopInfo.update", "len", "os.path.join", "os.path.basename", "os.path.isfile", "utils.get_image_extension", "shutil.copy2", "utils.load_volume", "utils.save_volume", "utils.strip_extension", "utils.load_volume"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_image_extension", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.strip_extension", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume"], ["", "", "", "def", "convert_images_in_dir_to_nifty", "(", "image_dir", ",", "result_dir", ",", "aff", "=", "None", ",", "ref_aff_dir", "=", "None", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"Converts all images in image_dir to nifty format.\n    :param image_dir: path of directory with images to convert\n    :param result_dir: path of directory where converted images will be writen\n    :param aff: (optional) affine matrix in homogeneous coordinates with which to write the images.\n    Can also be 'FS' to write images with FreeSurfer typical affine matrix.\n    :param ref_aff_dir: (optional) alternatively to providing a fixed aff, different affine matrices can be used for\n    each image in image_dir by matching them to corresponding volumes contained in ref_aff_dir.\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# list images", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "if", "ref_aff_dir", "is", "not", "None", ":", "\n", "        ", "path_ref_images", "=", "utils", ".", "list_images_in_folder", "(", "ref_aff_dir", ")", "\n", "", "else", ":", "\n", "        ", "path_ref_images", "=", "[", "None", "]", "*", "len", "(", "path_images", ")", "\n", "\n", "# loop over images", "\n", "", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'converting'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_ref", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_ref_images", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# convert images to nifty format", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "utils", ".", "strip_extension", "(", "path_image", ")", ")", ")", "+", "'.nii.gz'", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "if", "utils", ".", "get_image_extension", "(", "path_image", ")", "==", "'nii.gz'", ":", "\n", "                ", "shutil", ".", "copy2", "(", "path_image", ",", "path_result", ")", "\n", "", "else", ":", "\n", "                ", "im", ",", "tmp_aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "if", "aff", "is", "not", "None", ":", "\n", "                    ", "tmp_aff", "=", "aff", "\n", "", "elif", "path_ref", "is", "not", "None", ":", "\n", "                    ", "_", ",", "tmp_aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_ref", ",", "im_only", "=", "False", ")", "\n", "", "utils", ".", "save_volume", "(", "im", ",", "tmp_aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mri_convert_images_in_dir": [[1430, 1492], ["utils.mkdir", "os.system", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "os.path.join", "len", "zip", "utils.LoopInfo.update", "os.path.join", "utils.list_images_in_folder", "len", "os.path.basename", "os.system", "len", "len", "len", "os.path.isfile", "utils.reformat_to_list", "str", "numpy.around"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list"], ["", "", "", "", "def", "mri_convert_images_in_dir", "(", "image_dir", ",", "\n", "result_dir", ",", "\n", "interpolation", "=", "None", ",", "\n", "reference_dir", "=", "None", ",", "\n", "same_reference", "=", "False", ",", "\n", "voxsize", "=", "None", ",", "\n", "path_freesurfer", "=", "'/usr/local/freesurfer'", ",", "\n", "mri_convert_path", "=", "'/usr/local/freesurfer/bin/mri_convert'", ",", "\n", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function launches mri_convert on all images contained in image_dir, and writes the results in result_dir.\n    The interpolation type can be specified (i.e. 'nearest'), as well as a folder containing references for resampling.\n    reference_dir can be the path of a single *image* if same_reference=True.\n    :param image_dir: path of directory with images to convert\n    :param result_dir: path of directory where converted images will be writen\n    :param interpolation: (optional) interpolation type, can be 'inter' (default), 'cubic', 'nearest', 'trilinear'\n    :param reference_dir: (optional) path of directory with reference images. References are matched to images by\n    sorting order. If same_reference is false, references and images are matched by sorting order.\n    This can also be the path to a single image that will be used as reference for all images im image_dir (set\n    same_reference to true in that case).\n    :param same_reference: (optional) whether to use a single image as reference for all images to interpolate.\n    :param voxsize: (optional) resolution at which to resample converted image. Must be a list of length n_dims.\n    :param path_freesurfer: (optional) path FreeSurfer home\n    :param mri_convert_path: (optional) path mri_convert binary file\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# set up FreeSurfer", "\n", "os", ".", "environ", "[", "'FREESURFER_HOME'", "]", "=", "path_freesurfer", "\n", "os", ".", "system", "(", "os", ".", "path", ".", "join", "(", "path_freesurfer", ",", "'SetUpFreeSurfer.sh'", ")", ")", "\n", "mri_convert", "=", "mri_convert_path", "+", "' '", "\n", "\n", "# list images", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "if", "reference_dir", "is", "not", "None", ":", "\n", "        ", "if", "same_reference", ":", "\n", "            ", "path_references", "=", "[", "reference_dir", "]", "*", "len", "(", "path_images", ")", "\n", "", "else", ":", "\n", "            ", "path_references", "=", "utils", ".", "list_images_in_folder", "(", "reference_dir", ")", "\n", "assert", "len", "(", "path_references", ")", "==", "len", "(", "path_images", ")", ",", "'different number of files in image_dir and reference_dir'", "\n", "", "", "else", ":", "\n", "        ", "path_references", "=", "[", "None", "]", "*", "len", "(", "path_images", ")", "\n", "\n", "# loop over images", "\n", "", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'converting'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_reference", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_references", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# convert image", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "cmd", "=", "mri_convert", "+", "path_image", "+", "' '", "+", "path_result", "+", "' -odt float'", "\n", "if", "interpolation", "is", "not", "None", ":", "\n", "                ", "cmd", "+=", "' -rt '", "+", "interpolation", "\n", "", "if", "reference_dir", "is", "not", "None", ":", "\n", "                ", "cmd", "+=", "' -rl '", "+", "path_reference", "\n", "", "if", "voxsize", "is", "not", "None", ":", "\n", "                ", "voxsize", "=", "utils", ".", "reformat_to_list", "(", "voxsize", ",", "dtype", "=", "'float'", ")", "\n", "cmd", "+=", "' --voxsize '", "+", "' '", ".", "join", "(", "[", "str", "(", "np", ".", "around", "(", "v", ",", "3", ")", ")", "for", "v", "in", "voxsize", "]", ")", "\n", "", "os", ".", "system", "(", "cmd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.samseg_images_in_dir": [[1494, 1549], ["utils.mkdir", "os.system", "os.path.join", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "os.path.join", "len", "utils.LoopInfo.update", "os.path.join", "os.path.join", "utils.strip_extension", "os.path.join", "utils.mkcmd", "os.system", "os.path.isfile", "os.path.isdir", "os.path.basename", "os.path.isfile", "utils.mkcmd", "shutil.move", "shutil.rmtree", "utils.strip_extension", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.strip_extension", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.strip_extension"], ["", "", "", "def", "samseg_images_in_dir", "(", "image_dir", ",", "\n", "result_dir", ",", "\n", "atlas_dir", "=", "None", ",", "\n", "threads", "=", "4", ",", "\n", "path_freesurfer", "=", "'/usr/local/freesurfer'", ",", "\n", "keep_segm_only", "=", "True", ",", "\n", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function launches samseg for all images contained in image_dir and writes the results in result_dir.\n    If keep_segm_only=True, the result segmentation is copied in result_dir and SAMSEG's intermediate result dir is\n    deleted.\n    :param image_dir: path of directory with input images\n    :param result_dir: path of directory where processed images folders (if keep_segm_only is False),\n    or samseg segmentation (if keep_segm_only is True) will be writen\n    :param atlas_dir: (optional) path of samseg atlas directory. If None, use samseg default atlas.\n    :param threads: (optional) number of threads to use\n    :param path_freesurfer: (optional) path FreeSurfer home\n    :param keep_segm_only: (optional) whether to keep samseg result folders, or only samseg segmentations.\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# set up FreeSurfer", "\n", "os", ".", "environ", "[", "'FREESURFER_HOME'", "]", "=", "path_freesurfer", "\n", "os", ".", "system", "(", "os", ".", "path", ".", "join", "(", "path_freesurfer", ",", "'SetUpFreeSurfer.sh'", ")", ")", "\n", "path_samseg", "=", "os", ".", "path", ".", "join", "(", "path_freesurfer", ",", "'bin'", ",", "'run_samseg'", ")", "\n", "\n", "# loop over images", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'processing'", ",", "True", ")", "\n", "for", "idx", ",", "path_image", "in", "enumerate", "(", "path_images", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# build path_result", "\n", "path_im_result_dir", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "utils", ".", "strip_extension", "(", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", ")", "\n", "path_samseg_result", "=", "os", ".", "path", ".", "join", "(", "path_im_result_dir", ",", "'seg.mgz'", ")", "\n", "if", "keep_segm_only", ":", "\n", "            ", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "utils", ".", "strip_extension", "(", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "+", "'_seg.mgz'", ")", "\n", "", "else", ":", "\n", "            ", "path_result", "=", "path_samseg_result", "\n", "\n", "# run samseg", "\n", "", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "cmd", "=", "utils", ".", "mkcmd", "(", "path_samseg", ",", "'-i'", ",", "path_image", ",", "'-o'", ",", "path_im_result_dir", ",", "'--threads'", ",", "threads", ")", "\n", "if", "atlas_dir", "is", "not", "None", ":", "\n", "                ", "cmd", "=", "utils", ".", "mkcmd", "(", "cmd", ",", "'-a'", ",", "atlas_dir", ")", "\n", "", "os", ".", "system", "(", "cmd", ")", "\n", "\n", "# move segmentation to result_dir if necessary", "\n", "", "if", "keep_segm_only", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "path_samseg_result", ")", ":", "\n", "                ", "shutil", ".", "move", "(", "path_samseg_result", ",", "path_result", ")", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "path_im_result_dir", ")", ":", "\n", "                ", "shutil", ".", "rmtree", "(", "path_im_result_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.niftyreg_images_in_dir": [[1551, 1682], ["os.path.join", "utils.list_images_in_folder", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "utils.mkdir", "utils.mkdir", "utils.reformat_to_list", "utils.reformat_to_list", "len", "len", "len", "zip", "utils.LoopInfo.update", "utils.reformat_to_list", "utils.list_files", "len", "os.path.basename", "os.path.basename", "os.path.join", "os.path.isfile", "utils.mkcmd", "os.system", "len", "len", "len", "len", "Exception", "os.path.join", "os.path.isfile", "os.path.join", "os.path.isfile", "utils.mkcmd", "utils.mkcmd", "utils.mkcmd", "utils.mkcmd", "len", "Exception", "utils.strip_extension"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_files", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.strip_extension"], ["", "", "", "", "def", "niftyreg_images_in_dir", "(", "image_dir", ",", "\n", "reference_dir", ",", "\n", "nifty_reg_function", "=", "'reg_resample'", ",", "\n", "input_transformation_dir", "=", "None", ",", "\n", "result_dir", "=", "None", ",", "\n", "result_transformation_dir", "=", "None", ",", "\n", "interpolation", "=", "None", ",", "\n", "same_floating", "=", "False", ",", "\n", "same_reference", "=", "False", ",", "\n", "same_transformation", "=", "False", ",", "\n", "path_nifty_reg", "=", "'/home/benjamin/Softwares/niftyreg-gpu/build/reg-apps'", ",", "\n", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function launches one of niftyreg functions (reg_aladin, reg_f3d, reg_resample) on all images contained\n    in image_dir.\n    :param image_dir: path of directory with images to register. Can also be a single image, in that case set\n    same_floating to True.\n    :param reference_dir: path of directory with reference images. If same_reference is false, references and images are\n    matched by sorting order. This can also be the path to a single image that will be used as reference for all images\n    im image_dir (set same_reference to True in that case).\n    :param nifty_reg_function: (optional) name of the niftyreg function to use. Can be 'reg_aladin', 'reg_f3d', or\n    'reg_resample'. Default is 'reg_resample'.\n    :param input_transformation_dir: (optional) path of a directory containing all the input transformation (for\n    reg_resample, or reg_f3d). Can also be the path to a single transformation that will be used for all images\n    in image_dir (set same_transformation to True in that case).\n    :param result_dir: path of directory where output images will be writen.\n    :param result_transformation_dir: path of directory where resulting trnaformations will be writen (for\n    reg_aladin and reg_f3d).\n    :param interpolation: (optional) integer describing the order of the interpolation to apply (0 = nearest neighbours)\n    :param same_floating: (optional) set to true if only one image is used as floating image.\n    :param same_reference: (optional) whether to use a single image as reference for all input images.\n    :param same_transformation: (optional) whether to apply the same transformation to all floating images.\n    :param path_nifty_reg: (optional) path of the folder containing nigty-reg funtions\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dirs", "\n", "if", "result_dir", "is", "not", "None", ":", "\n", "        ", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "", "if", "result_transformation_dir", "is", "not", "None", ":", "\n", "        ", "utils", ".", "mkdir", "(", "result_transformation_dir", ")", "\n", "\n", "", "nifty_reg", "=", "os", ".", "path", ".", "join", "(", "path_nifty_reg", ",", "nifty_reg_function", ")", "\n", "\n", "# list reference and floating images", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "path_references", "=", "utils", ".", "list_images_in_folder", "(", "reference_dir", ")", "\n", "if", "same_reference", ":", "\n", "        ", "path_references", "=", "utils", ".", "reformat_to_list", "(", "path_references", ",", "length", "=", "len", "(", "path_images", ")", ")", "\n", "", "if", "same_floating", ":", "\n", "        ", "path_images", "=", "utils", ".", "reformat_to_list", "(", "path_images", ",", "length", "=", "len", "(", "path_references", ")", ")", "\n", "", "assert", "len", "(", "path_references", ")", "==", "len", "(", "path_images", ")", ",", "'different number of files in image_dir and reference_dir'", "\n", "\n", "# list input transformations", "\n", "if", "input_transformation_dir", "is", "not", "None", ":", "\n", "        ", "if", "same_transformation", ":", "\n", "            ", "path_input_transfs", "=", "utils", ".", "reformat_to_list", "(", "input_transformation_dir", ",", "length", "=", "len", "(", "path_images", ")", ")", "\n", "", "else", ":", "\n", "            ", "path_input_transfs", "=", "utils", ".", "list_files", "(", "input_transformation_dir", ")", "\n", "assert", "len", "(", "path_input_transfs", ")", "==", "len", "(", "path_images", ")", ",", "'different number of transformations and images'", "\n", "", "", "else", ":", "\n", "        ", "path_input_transfs", "=", "[", "None", "]", "*", "len", "(", "path_images", ")", "\n", "\n", "# define flag input trans", "\n", "", "if", "input_transformation_dir", "is", "not", "None", ":", "\n", "        ", "if", "nifty_reg_function", "==", "'reg_aladin'", ":", "\n", "            ", "flag_input_trans", "=", "'-inaff'", "\n", "", "elif", "nifty_reg_function", "==", "'reg_f3d'", ":", "\n", "            ", "flag_input_trans", "=", "'-aff'", "\n", "", "elif", "nifty_reg_function", "==", "'reg_resample'", ":", "\n", "            ", "flag_input_trans", "=", "'-trans'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'nifty_reg_function can only be \"reg_aladin\", \"reg_f3d\", or \"reg_resample\"'", ")", "\n", "", "", "else", ":", "\n", "        ", "flag_input_trans", "=", "None", "\n", "\n", "# define flag result transformation", "\n", "", "if", "result_transformation_dir", "is", "not", "None", ":", "\n", "        ", "if", "nifty_reg_function", "==", "'reg_aladin'", ":", "\n", "            ", "flag_result_trans", "=", "'-aff'", "\n", "", "elif", "nifty_reg_function", "==", "'reg_f3d'", ":", "\n", "            ", "flag_result_trans", "=", "'-cpp'", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'result_transformation_dir can only be used with \"reg_aladin\" or \"reg_f3d\"'", ")", "\n", "", "", "else", ":", "\n", "        ", "flag_result_trans", "=", "None", "\n", "\n", "# loop over images", "\n", "", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'processing'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_ref", ",", "path_input_trans", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "\n", "path_references", ",", "\n", "path_input_transfs", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# define path registered image", "\n", "name", "=", "os", ".", "path", ".", "basename", "(", "path_ref", ")", "if", "same_floating", "else", "os", ".", "path", ".", "basename", "(", "path_image", ")", "\n", "if", "result_dir", "is", "not", "None", ":", "\n", "            ", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "name", ")", "\n", "result_already_computed", "=", "os", ".", "path", ".", "isfile", "(", "path_result", ")", "\n", "", "else", ":", "\n", "            ", "path_result", "=", "None", "\n", "result_already_computed", "=", "True", "\n", "\n", "# define path resulting transformation", "\n", "", "if", "result_transformation_dir", "is", "not", "None", ":", "\n", "            ", "if", "nifty_reg_function", "==", "'reg_aladin'", ":", "\n", "                ", "path_result_trans", "=", "os", ".", "path", ".", "join", "(", "result_transformation_dir", ",", "utils", ".", "strip_extension", "(", "name", ")", "+", "'.txt'", ")", "\n", "result_trans_already_computed", "=", "os", ".", "path", ".", "isfile", "(", "path_result_trans", ")", "\n", "", "else", ":", "\n", "                ", "path_result_trans", "=", "os", ".", "path", ".", "join", "(", "result_transformation_dir", ",", "name", ")", "\n", "result_trans_already_computed", "=", "os", ".", "path", ".", "isfile", "(", "path_result_trans", ")", "\n", "", "", "else", ":", "\n", "            ", "path_result_trans", "=", "None", "\n", "result_trans_already_computed", "=", "True", "\n", "\n", "", "if", "(", "not", "result_already_computed", ")", "|", "(", "not", "result_trans_already_computed", ")", "|", "recompute", ":", "\n", "\n", "# build main command", "\n", "            ", "cmd", "=", "utils", ".", "mkcmd", "(", "nifty_reg", ",", "'-ref'", ",", "path_ref", ",", "'-flo'", ",", "path_image", ",", "'-pad 0'", ")", "\n", "\n", "# add options", "\n", "if", "path_result", "is", "not", "None", ":", "\n", "                ", "cmd", "=", "utils", ".", "mkcmd", "(", "cmd", ",", "'-res'", ",", "path_result", ")", "\n", "", "if", "flag_input_trans", "is", "not", "None", ":", "\n", "                ", "cmd", "=", "utils", ".", "mkcmd", "(", "cmd", ",", "flag_input_trans", ",", "path_input_trans", ")", "\n", "", "if", "flag_result_trans", "is", "not", "None", ":", "\n", "                ", "cmd", "=", "utils", ".", "mkcmd", "(", "cmd", ",", "flag_result_trans", ",", "path_result_trans", ")", "\n", "", "if", "interpolation", "is", "not", "None", ":", "\n", "                ", "cmd", "=", "utils", ".", "mkcmd", "(", "cmd", ",", "'-inter'", ",", "interpolation", ")", "\n", "\n", "# execute", "\n", "", "os", ".", "system", "(", "cmd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.upsample_anisotropic_images": [[1684, 1748], ["utils.mkdir", "os.system", "os.path.join", "utils.list_images_in_folder", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "os.path.join", "len", "len", "len", "zip", "utils.LoopInfo.update", "utils.get_volume_info", "os.path.join", "os.path.join", "os.path.basename", "utils.mkcmd", "os.system", "utils.load_volume", "numpy.meshgrid", "utils.mkdir", "list", "enumerate", "utils.load_volume", "numpy.stack", "shutil.rmtree", "numpy.floor", "numpy.ceil", "numpy.sqrt", "utils.save_volume", "os.path.isfile", "os.path.basename", "os.path.isfile", "utils.strip_extension", "os.path.join", "os.path.join", "utils.save_volume", "utils.mkcmd", "os.system", "list.append", "numpy.minimum", "utils.add_axis", "numpy.sum", "numpy.arange", "os.path.basename", "os.path.basename", "utils.load_volume"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.meshgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.strip_extension", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume"], ["", "", "", "def", "upsample_anisotropic_images", "(", "image_dir", ",", "\n", "resample_image_result_dir", ",", "\n", "resample_like_dir", ",", "\n", "path_freesurfer", "=", "'/usr/local/freesurfer/'", ",", "\n", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function takes as input a set of LR images and resample them to HR with respect to reference images.\n    :param image_dir: path of directory with input images (only uni-modal images supported)\n    :param resample_image_result_dir: path of directory where resampled images will be writen\n    :param resample_like_dir: path of directory with reference images.\n    :param path_freesurfer: (optional) path freesurfer home, as this function uses mri_convert\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "resample_image_result_dir", ")", "\n", "\n", "# set up FreeSurfer", "\n", "os", ".", "environ", "[", "'FREESURFER_HOME'", "]", "=", "path_freesurfer", "\n", "os", ".", "system", "(", "os", ".", "path", ".", "join", "(", "path_freesurfer", ",", "'SetUpFreeSurfer.sh'", ")", ")", "\n", "mri_convert", "=", "os", ".", "path", ".", "join", "(", "path_freesurfer", ",", "'bin/mri_convert'", ")", "\n", "\n", "# list images and labels", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "path_ref_images", "=", "utils", ".", "list_images_in_folder", "(", "resample_like_dir", ")", "\n", "assert", "len", "(", "path_images", ")", "==", "len", "(", "path_ref_images", ")", ",", "'the folders containing the images and their references are not the same size'", "\n", "\n", "# loop over images", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'upsampling'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_ref", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_ref_images", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# upsample image", "\n", "_", ",", "_", ",", "n_dims", ",", "_", ",", "_", ",", "image_res", "=", "utils", ".", "get_volume_info", "(", "path_image", ",", "return_volume", "=", "False", ")", "\n", "path_im_upsampled", "=", "os", ".", "path", ".", "join", "(", "resample_image_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_im_upsampled", ")", ")", "|", "recompute", ":", "\n", "            ", "cmd", "=", "utils", ".", "mkcmd", "(", "mri_convert", ",", "path_image", ",", "path_im_upsampled", ",", "'-rl'", ",", "path_ref", ",", "'-odt float'", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n", "", "path_dist_map", "=", "os", ".", "path", ".", "join", "(", "resample_image_result_dir", ",", "'dist_map_'", "+", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_dist_map", ")", ")", "|", "recompute", ":", "\n", "            ", "im", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "dist_map", "=", "np", ".", "meshgrid", "(", "*", "[", "np", ".", "arange", "(", "s", ")", "for", "s", "in", "im", ".", "shape", "]", ",", "indexing", "=", "'ij'", ")", "\n", "tmp_dir", "=", "utils", ".", "strip_extension", "(", "path_im_upsampled", ")", "+", "'_meshes'", "\n", "utils", ".", "mkdir", "(", "tmp_dir", ")", "\n", "path_meshes_up", "=", "list", "(", ")", "\n", "for", "(", "i", ",", "maps", ")", "in", "enumerate", "(", "dist_map", ")", ":", "\n", "                ", "path_mesh", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'%s_'", "%", "i", "+", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "path_mesh_up", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'up_%s_'", "%", "i", "+", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "utils", ".", "save_volume", "(", "maps", ",", "aff", ",", "h", ",", "path_mesh", ")", "\n", "cmd", "=", "utils", ".", "mkcmd", "(", "mri_convert", ",", "path_mesh", ",", "path_mesh_up", ",", "'-rl'", ",", "path_im_upsampled", ",", "'-odt float'", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "path_meshes_up", ".", "append", "(", "path_mesh_up", ")", "\n", "", "mesh_up_0", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_meshes_up", "[", "0", "]", ",", "im_only", "=", "False", ")", "\n", "mesh_up", "=", "np", ".", "stack", "(", "[", "mesh_up_0", "]", "+", "[", "utils", ".", "load_volume", "(", "p", ")", "for", "p", "in", "path_meshes_up", "[", "1", ":", "]", "]", ",", "-", "1", ")", "\n", "shutil", ".", "rmtree", "(", "tmp_dir", ")", "\n", "\n", "floor", "=", "np", ".", "floor", "(", "mesh_up", ")", "\n", "ceil", "=", "np", ".", "ceil", "(", "mesh_up", ")", "\n", "f_dist", "=", "mesh_up", "-", "floor", "\n", "c_dist", "=", "ceil", "-", "mesh_up", "\n", "dist", "=", "np", ".", "minimum", "(", "f_dist", ",", "c_dist", ")", "*", "utils", ".", "add_axis", "(", "image_res", ",", "axis", "=", "[", "0", "]", "*", "n_dims", ")", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "dist", "**", "2", ",", "axis", "=", "-", "1", ")", ")", "\n", "utils", ".", "save_volume", "(", "dist", ",", "aff", ",", "h", ",", "path_dist_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.simulate_upsampled_anisotropic_images": [[1750, 1875], ["utils.mkdir", "utils.mkdir", "os.system", "os.path.join", "utils.list_images_in_folder", "utils.get_volume_info", "numpy.squeeze", "utils.reformat_to_list", "utils.LoopInfo", "enumerate", "utils.mkdir", "os.path.join", "utils.list_images_in_folder", "utils.reformat_to_n_channels_array", "len", "zip", "utils.LoopInfo.update", "os.path.join", "os.path.join", "len", "numpy.eye", "os.path.basename", "utils.get_volume_info", "edit_volumes.align_volume_to_ref", "list", "edit_tensors.blurring_sigma_for_downsampling", "utils.save_volume", "utils.mkcmd", "os.system", "os.path.join", "os.path.basename", "utils.mkcmd", "os.system", "os.path.join", "os.path.isfile", "numpy.squeeze", "edit_volumes.blur_volume", "os.path.basename", "utils.mkcmd", "os.system", "os.path.isfile", "utils.load_volume", "numpy.meshgrid", "utils.mkdir", "list", "enumerate", "utils.load_volume", "numpy.stack", "shutil.rmtree", "numpy.floor", "numpy.ceil", "numpy.sqrt", "utils.save_volume", "numpy.eye", "range", "keras.Input", "keras.models.Model", "keras.models.Model.predict", "str", "os.path.isfile", "os.path.basename", "os.path.isfile", "utils.strip_extension", "os.path.join", "os.path.join", "utils.save_volume", "utils.mkcmd", "os.system", "list.append", "numpy.minimum", "utils.add_axis", "numpy.sum", "layers.GaussianBlur", "utils.add_axis", "numpy.arange", "os.path.basename", "os.path.basename", "utils.load_volume"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_n_channels_array", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.blurring_sigma_for_downsampling", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.blur_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.meshgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.strip_extension", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume"], ["", "", "", "def", "simulate_upsampled_anisotropic_images", "(", "image_dir", ",", "\n", "downsample_image_result_dir", ",", "\n", "resample_image_result_dir", ",", "\n", "data_res", ",", "\n", "labels_dir", "=", "None", ",", "\n", "downsample_labels_result_dir", "=", "None", ",", "\n", "slice_thickness", "=", "None", ",", "\n", "build_dist_map", "=", "False", ",", "\n", "path_freesurfer", "=", "'/usr/local/freesurfer/'", ",", "\n", "gpu", "=", "True", ",", "\n", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function takes as input a set of HR images and creates two datasets with it:\n    1) a set of LR images obtained by downsampling the HR images with nearest neighbour interpolation,\n    2) a set of HR images obtained by resampling the LR images to native HR with linear interpolation.\n    Additionally, this function can also create a set of LR labels from label maps corresponding to the input images.\n    :param image_dir: path of directory with input images (only uni-model images supported)\n    :param downsample_image_result_dir: path of directory where downsampled images will be writen\n    :param resample_image_result_dir: path of directory where resampled images will be writen\n    :param data_res: resolution of LR images. Can either be: an int, a float, a list or a numpy array.\n    :param labels_dir: (optional) path of directory with label maps corresponding to input images\n    :param downsample_labels_result_dir: (optional) path of directory where downsampled label maps will be writen\n    :param slice_thickness: (optional) thickness of slices to simulate. Can be a number, a list or a numpy array.\n    :param build_dist_map: (optional) whether to return the resampled images with an additional channel indicating the\n    distace of each voxel to the nearest acquired voxel. Default is False.\n    :param path_freesurfer: (optional) path freesurfer home, as this function uses mri_convert\n    :param gpu: (optional) whether to use a fast gpu model for blurring\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "resample_image_result_dir", ")", "\n", "utils", ".", "mkdir", "(", "downsample_image_result_dir", ")", "\n", "if", "labels_dir", "is", "not", "None", ":", "\n", "        ", "assert", "downsample_labels_result_dir", "is", "not", "None", ",", "'downsample_labels_result_dir should not be None if labels_dir is specified'", "\n", "utils", ".", "mkdir", "(", "downsample_labels_result_dir", ")", "\n", "\n", "# set up FreeSurfer", "\n", "", "os", ".", "environ", "[", "'FREESURFER_HOME'", "]", "=", "path_freesurfer", "\n", "os", ".", "system", "(", "os", ".", "path", ".", "join", "(", "path_freesurfer", ",", "'SetUpFreeSurfer.sh'", ")", ")", "\n", "mri_convert", "=", "os", ".", "path", ".", "join", "(", "path_freesurfer", ",", "'bin/mri_convert'", ")", "\n", "\n", "# list images and labels", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "path_labels", "=", "[", "None", "]", "*", "len", "(", "path_images", ")", "if", "labels_dir", "is", "None", "else", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "\n", "# initialisation", "\n", "_", ",", "_", ",", "n_dims", ",", "_", ",", "_", ",", "image_res", "=", "utils", ".", "get_volume_info", "(", "path_images", "[", "0", "]", ",", "return_volume", "=", "False", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ")", "\n", "data_res", "=", "np", ".", "squeeze", "(", "utils", ".", "reformat_to_n_channels_array", "(", "data_res", ",", "n_dims", ",", "n_channels", "=", "1", ")", ")", "\n", "slice_thickness", "=", "utils", ".", "reformat_to_list", "(", "slice_thickness", ",", "length", "=", "n_dims", ")", "\n", "\n", "# loop over images", "\n", "previous_model_input_shape", "=", "None", "\n", "model", "=", "None", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'processing'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_labels", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_labels", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# downsample image", "\n", "path_im_downsampled", "=", "os", ".", "path", ".", "join", "(", "downsample_image_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_im_downsampled", ")", ")", "|", "recompute", ":", "\n", "            ", "im", ",", "_", ",", "aff", ",", "n_dims", ",", "_", ",", "h", ",", "image_res", "=", "utils", ".", "get_volume_info", "(", "path_image", ",", "return_volume", "=", "True", ")", "\n", "im", ",", "aff_aligned", "=", "align_volume_to_ref", "(", "im", ",", "aff", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ",", "return_aff", "=", "True", ",", "n_dims", "=", "n_dims", ")", "\n", "im_shape", "=", "list", "(", "im", ".", "shape", "[", ":", "n_dims", "]", ")", "\n", "sigma", "=", "blurring_sigma_for_downsampling", "(", "image_res", ",", "data_res", ",", "thickness", "=", "slice_thickness", ")", "\n", "sigma", "=", "[", "0", "if", "data_res", "[", "i", "]", "==", "image_res", "[", "i", "]", "else", "sigma", "[", "i", "]", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "\n", "# blur image", "\n", "if", "gpu", ":", "\n", "                ", "if", "(", "im_shape", "!=", "previous_model_input_shape", ")", "|", "(", "model", "is", "None", ")", ":", "\n", "                    ", "previous_model_input_shape", "=", "im_shape", "\n", "image_in", "=", "KL", ".", "Input", "(", "shape", "=", "im_shape", "+", "[", "1", "]", ")", "\n", "image", "=", "GaussianBlur", "(", "sigma", "=", "sigma", ")", "(", "image_in", ")", "\n", "model", "=", "Model", "(", "inputs", "=", "image_in", ",", "outputs", "=", "image", ")", "\n", "", "im", "=", "np", ".", "squeeze", "(", "model", ".", "predict", "(", "utils", ".", "add_axis", "(", "im", ",", "axis", "=", "[", "0", ",", "-", "1", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "im", "=", "blur_volume", "(", "im", ",", "sigma", ",", "mask", "=", "None", ")", "\n", "", "utils", ".", "save_volume", "(", "im", ",", "aff_aligned", ",", "h", ",", "path_im_downsampled", ")", "\n", "\n", "# downsample blurred image", "\n", "voxsize", "=", "' '", ".", "join", "(", "[", "str", "(", "r", ")", "for", "r", "in", "data_res", "]", ")", "\n", "cmd", "=", "utils", ".", "mkcmd", "(", "mri_convert", ",", "path_im_downsampled", ",", "path_im_downsampled", ",", "'--voxsize'", ",", "voxsize", ",", "\n", "'-odt float -rt nearest'", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n", "# downsample labels if necessary", "\n", "", "if", "path_labels", "is", "not", "None", ":", "\n", "            ", "path_lab_downsampled", "=", "os", ".", "path", ".", "join", "(", "downsample_labels_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_labels", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_lab_downsampled", ")", ")", "|", "recompute", ":", "\n", "                ", "cmd", "=", "utils", ".", "mkcmd", "(", "mri_convert", ",", "path_labels", ",", "path_lab_downsampled", ",", "'-rl'", ",", "path_im_downsampled", ",", "\n", "'-odt float -rt nearest'", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n", "# upsample image", "\n", "", "", "path_im_upsampled", "=", "os", ".", "path", ".", "join", "(", "resample_image_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_im_upsampled", ")", ")", "|", "recompute", ":", "\n", "            ", "cmd", "=", "utils", ".", "mkcmd", "(", "mri_convert", ",", "path_im_downsampled", ",", "path_im_upsampled", ",", "'-rl'", ",", "path_image", ",", "'-odt float'", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n", "", "if", "build_dist_map", ":", "\n", "            ", "path_dist_map", "=", "os", ".", "path", ".", "join", "(", "resample_image_result_dir", ",", "'dist_map_'", "+", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_dist_map", ")", ")", "|", "recompute", ":", "\n", "                ", "im", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_im_downsampled", ",", "im_only", "=", "False", ")", "\n", "dist_map", "=", "np", ".", "meshgrid", "(", "*", "[", "np", ".", "arange", "(", "s", ")", "for", "s", "in", "im", ".", "shape", "]", ",", "indexing", "=", "'ij'", ")", "\n", "tmp_dir", "=", "utils", ".", "strip_extension", "(", "path_im_downsampled", ")", "+", "'_meshes'", "\n", "utils", ".", "mkdir", "(", "tmp_dir", ")", "\n", "path_meshes_up", "=", "list", "(", ")", "\n", "for", "(", "i", ",", "d_map", ")", "in", "enumerate", "(", "dist_map", ")", ":", "\n", "                    ", "path_mesh", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'%s_'", "%", "i", "+", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "path_mesh_up", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "'up_%s_'", "%", "i", "+", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "utils", ".", "save_volume", "(", "d_map", ",", "aff", ",", "h", ",", "path_mesh", ")", "\n", "cmd", "=", "utils", ".", "mkcmd", "(", "mri_convert", ",", "path_mesh", ",", "path_mesh_up", ",", "'-rl'", ",", "path_image", ",", "'-odt float'", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "path_meshes_up", ".", "append", "(", "path_mesh_up", ")", "\n", "", "mesh_up_0", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_meshes_up", "[", "0", "]", ",", "im_only", "=", "False", ")", "\n", "mesh_up", "=", "np", ".", "stack", "(", "[", "mesh_up_0", "]", "+", "[", "utils", ".", "load_volume", "(", "p", ")", "for", "p", "in", "path_meshes_up", "[", "1", ":", "]", "]", ",", "-", "1", ")", "\n", "shutil", ".", "rmtree", "(", "tmp_dir", ")", "\n", "\n", "floor", "=", "np", ".", "floor", "(", "mesh_up", ")", "\n", "ceil", "=", "np", ".", "ceil", "(", "mesh_up", ")", "\n", "f_dist", "=", "mesh_up", "-", "floor", "\n", "c_dist", "=", "ceil", "-", "mesh_up", "\n", "dist", "=", "np", ".", "minimum", "(", "f_dist", ",", "c_dist", ")", "*", "utils", ".", "add_axis", "(", "data_res", ",", "axis", "=", "[", "0", "]", "*", "n_dims", ")", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "dist", "**", "2", ",", "axis", "=", "-", "1", ")", ")", "\n", "utils", ".", "save_volume", "(", "dist", ",", "aff", ",", "h", ",", "path_dist_map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.check_images_in_dir": [[1877, 1920], ["list", "list", "list", "list", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "list", "len", "utils.LoopInfo.update", "utils.get_volume_info", "get_ras_axes().tolist", "numpy.eye", "list.append", "list.append", "list.append", "list.append", "numpy.unique().tolist", "edit_volumes.get_ras_axes", "list.append", "numpy.arange", "numpy.int32", "numpy.int32", "numpy.unique", "numpy.round", "numpy.round", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_ras_axes", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], ["", "", "", "", "def", "check_images_in_dir", "(", "image_dir", ",", "check_values", "=", "False", ",", "keep_unique", "=", "True", ",", "max_channels", "=", "10", ")", ":", "\n", "    ", "\"\"\"Check if all volumes within the same folder share the same characteristics: shape, affine matrix, resolution.\n    Also have option to check if all volumes have the same intensity values (useful for label maps).\n    :return four lists, each containing the different values detected for a specific parameter among those to check.\"\"\"", "\n", "\n", "# define information to check", "\n", "list_shape", "=", "list", "(", ")", "\n", "list_aff", "=", "list", "(", ")", "\n", "list_res", "=", "list", "(", ")", "\n", "list_axes", "=", "list", "(", ")", "\n", "if", "check_values", ":", "\n", "        ", "list_unique_values", "=", "list", "(", ")", "\n", "", "else", ":", "\n", "        ", "list_unique_values", "=", "None", "\n", "\n", "# loop through files", "\n", "", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'checking'", ",", "True", ")", "\n", "for", "idx", ",", "path_image", "in", "enumerate", "(", "path_images", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# get info", "\n", "im", ",", "shape", ",", "aff", ",", "n_dims", ",", "_", ",", "h", ",", "res", "=", "utils", ".", "get_volume_info", "(", "path_image", ",", "True", ",", "np", ".", "eye", "(", "4", ")", ",", "max_channels", ")", "\n", "axes", "=", "get_ras_axes", "(", "aff", ",", "n_dims", "=", "n_dims", ")", ".", "tolist", "(", ")", "\n", "aff", "[", ":", ",", "np", ".", "arange", "(", "n_dims", ")", "]", "=", "aff", "[", ":", ",", "axes", "]", "\n", "aff", "=", "(", "np", ".", "int32", "(", "np", ".", "round", "(", "np", ".", "array", "(", "aff", "[", ":", "3", ",", ":", "3", "]", ")", ",", "2", ")", "*", "100", ")", "/", "100", ")", ".", "tolist", "(", ")", "\n", "res", "=", "(", "np", ".", "int32", "(", "np", ".", "round", "(", "np", ".", "array", "(", "res", ")", ",", "2", ")", "*", "100", ")", "/", "100", ")", ".", "tolist", "(", ")", "\n", "\n", "# add values to list if not already there", "\n", "if", "(", "shape", "not", "in", "list_shape", ")", "|", "(", "not", "keep_unique", ")", ":", "\n", "            ", "list_shape", ".", "append", "(", "shape", ")", "\n", "", "if", "(", "aff", "not", "in", "list_aff", ")", "|", "(", "not", "keep_unique", ")", ":", "\n", "            ", "list_aff", ".", "append", "(", "aff", ")", "\n", "", "if", "(", "res", "not", "in", "list_res", ")", "|", "(", "not", "keep_unique", ")", ":", "\n", "            ", "list_res", ".", "append", "(", "res", ")", "\n", "", "if", "(", "axes", "not", "in", "list_axes", ")", "|", "(", "not", "keep_unique", ")", ":", "\n", "            ", "list_axes", ".", "append", "(", "axes", ")", "\n", "", "if", "list_unique_values", "is", "not", "None", ":", "\n", "            ", "uni", "=", "np", ".", "unique", "(", "im", ")", ".", "tolist", "(", ")", "\n", "if", "(", "uni", "not", "in", "list_unique_values", ")", "|", "(", "not", "keep_unique", ")", ":", "\n", "                ", "list_unique_values", ".", "append", "(", "uni", ")", "\n", "\n", "", "", "", "return", "list_shape", ",", "list_aff", ",", "list_res", ",", "list_axes", ",", "list_unique_values", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.correct_labels_in_dir": [[1924, 1959], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "len", "utils.LoopInfo.update", "os.path.join", "os.path.basename", "utils.load_volume", "edit_volumes.correct_label_map", "utils.save_volume", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.correct_label_map", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume"], ["", "def", "correct_labels_in_dir", "(", "labels_dir", ",", "results_dir", ",", "incorrect_labels", ",", "correct_labels", "=", "None", ",", "\n", "use_nearest_label", "=", "False", ",", "remove_zero", "=", "False", ",", "smooth", "=", "False", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function corrects label values for all label maps in a folder with either\n    - a list a given values,\n    - or with the nearest label value.\n    :param labels_dir: path of directory with input label maps\n    :param results_dir: path of directory where corrected label maps will be writen\n    :param incorrect_labels: list of all label values to correct (e.g. [1, 2, 3, 4]).\n    :param correct_labels: (optional) list of correct label values to replace the incorrect ones.\n    Correct values must have the same order as their corresponding value in list_incorrect_labels.\n    When several correct values are possible for the same incorrect value, the nearest correct value will be selected at\n    each voxel to correct. In that case, the different correct values must be specified inside a list whithin\n    list_correct_labels (e.g. [10, 20, 30, [40, 50]).\n    :param use_nearest_label: (optional) whether to correct the incorrect lavel values with the nearest labels.\n    :param remove_zero: (optional) if use_nearest_label is True, set to True not to consider zero among the potential\n    candidates for the nearest neighbour.\n    :param smooth: (optional) whether to smooth the corrected label maps\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "results_dir", ")", "\n", "\n", "# prepare data files", "\n", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_labels", ")", ",", "10", ",", "'correcting'", ",", "True", ")", "\n", "for", "idx", ",", "path_label", "in", "enumerate", "(", "path_labels", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# correct labels", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "im", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_label", ",", "im_only", "=", "False", ",", "dtype", "=", "'int32'", ")", "\n", "im", "=", "correct_label_map", "(", "im", ",", "incorrect_labels", ",", "correct_labels", ",", "use_nearest_label", ",", "remove_zero", ",", "smooth", ")", "\n", "utils", ".", "save_volume", "(", "im", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mask_labels_in_dir": [[1961, 2002], ["utils.mkdir", "utils.reformat_to_list", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "utils.mkdir", "len", "utils.LoopInfo.update", "os.path.join", "os.path.basename", "os.path.join", "utils.load_volume", "utils.save_volume", "os.path.basename", "edit_volumes.mask_label_map", "os.path.join", "utils.save_volume", "edit_volumes.mask_label_map", "os.path.isfile", "os.path.basename", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mask_label_map", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mask_label_map"], ["", "", "", "def", "mask_labels_in_dir", "(", "labels_dir", ",", "result_dir", ",", "values_to_keep", ",", "masking_value", "=", "0", ",", "mask_result_dir", "=", "None", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This function masks all label maps in a folder by keeping a set of given label values.\n    :param labels_dir: path of directory with input label maps\n    :param result_dir: path of directory where corrected label maps will be writen\n    :param values_to_keep: list of values for masking the label maps.\n    :param masking_value: (optional) value to mask the label maps with\n    :param mask_result_dir: (optional) path of directory where applied masks will be writen\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "if", "mask_result_dir", "is", "not", "None", ":", "\n", "        ", "utils", ".", "mkdir", "(", "mask_result_dir", ")", "\n", "\n", "# reformat values to keep", "\n", "", "values_to_keep", "=", "utils", ".", "reformat_to_list", "(", "values_to_keep", ",", "load_as_numpy", "=", "True", ")", "\n", "\n", "# loop over labels", "\n", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_labels", ")", ",", "10", ",", "'masking'", ",", "True", ")", "\n", "for", "idx", ",", "path_label", "in", "enumerate", "(", "path_labels", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# mask labels", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "\n", "if", "mask_result_dir", "is", "not", "None", ":", "\n", "            ", "path_result_mask", "=", "os", ".", "path", ".", "join", "(", "mask_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "\n", "", "else", ":", "\n", "            ", "path_result_mask", "=", "''", "\n", "", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "(", "mask_result_dir", "is", "not", "None", ")", "&", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result_mask", ")", ")", "|", "recompute", ":", "\n", "            ", "lab", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_label", ",", "im_only", "=", "False", ")", "\n", "if", "mask_result_dir", "is", "not", "None", ":", "\n", "                ", "labels", ",", "mask", "=", "mask_label_map", "(", "lab", ",", "values_to_keep", ",", "masking_value", ",", "return_mask", "=", "True", ")", "\n", "path_result_mask", "=", "os", ".", "path", ".", "join", "(", "mask_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "\n", "utils", ".", "save_volume", "(", "mask", ",", "aff", ",", "h", ",", "path_result_mask", ")", "\n", "", "else", ":", "\n", "                ", "labels", "=", "mask_label_map", "(", "lab", ",", "values_to_keep", ",", "masking_value", ",", "return_mask", "=", "False", ")", "\n", "", "utils", ".", "save_volume", "(", "labels", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.smooth_labels_in_dir": [[2004, 2067], ["utils.mkdir", "utils.list_images_in_folder", "utils.get_list_labels", "utils.LoopInfo", "enumerate", "utils.get_volume_info", "utils.build_binary_structure", "utils.LoopInfo", "enumerate", "len", "utils.LoopInfo.update", "os.path.join", "len", "utils.LoopInfo.update", "os.path.join", "os.path.basename", "utils.get_volume_info", "numpy.unique().astype", "utils.save_volume", "os.path.basename", "utils.load_volume", "edit_volumes.smooth_label_map", "utils.save_volume", "os.path.isfile", "edit_volumes.smoothing_gpu_model", "smoothing_gpu_model.predict", "edit_volumes.mask_label_map", "smoothing_gpu_model.predict", "numpy.where", "numpy.squeeze", "os.path.isfile", "numpy.unique", "utils.add_axis", "utils.add_axis"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_list_labels", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.build_binary_structure", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.smooth_label_map", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.smoothing_gpu_model", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.mask_label_map", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis"], ["", "", "", "def", "smooth_labels_in_dir", "(", "labels_dir", ",", "result_dir", ",", "gpu", "=", "False", ",", "labels_list", "=", "None", ",", "connectivity", "=", "1", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"Smooth all label maps in a folder by replacing each voxel by the value of its most numerous neigbours.\n    :param labels_dir: path of directory with input label maps\n    :param result_dir: path of directory where smoothed label maps will be writen\n    :param gpu: (optional) whether to use a gpu implementation for faster processing\n    :param labels_list: (optionnal) if gpu is True, path of numpy array with all label values.\n    Automatically computed if not provided.\n    :param connectivity: (optional) connectivity to use when smoothing the label maps\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# list label maps", "\n", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "\n", "if", "labels_list", "is", "not", "None", ":", "\n", "        ", "labels_list", ",", "_", "=", "utils", ".", "get_list_labels", "(", "label_list", "=", "labels_list", ",", "FS_sort", "=", "True", ")", "\n", "\n", "", "if", "gpu", ":", "\n", "# initialisation", "\n", "        ", "previous_model_input_shape", "=", "None", "\n", "smoothing_model", "=", "None", "\n", "\n", "# loop over label maps", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_labels", ")", ",", "10", ",", "'smoothing'", ",", "True", ")", "\n", "for", "idx", ",", "path_label", "in", "enumerate", "(", "path_labels", ")", ":", "\n", "            ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# smooth label map", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "                ", "labels", ",", "label_shape", ",", "aff", ",", "n_dims", ",", "_", ",", "h", ",", "_", "=", "utils", ".", "get_volume_info", "(", "path_label", ",", "return_volume", "=", "True", ")", "\n", "if", "label_shape", "!=", "previous_model_input_shape", ":", "\n", "                    ", "previous_model_input_shape", "=", "label_shape", "\n", "smoothing_model", "=", "smoothing_gpu_model", "(", "label_shape", ",", "labels_list", ",", "connectivity", ")", "\n", "", "unique_labels", "=", "np", ".", "unique", "(", "labels", ")", ".", "astype", "(", "'int32'", ")", "\n", "if", "labels_list", "is", "None", ":", "\n", "                    ", "labels", "=", "smoothing_model", ".", "predict", "(", "utils", ".", "add_axis", "(", "labels", ")", ")", "\n", "", "else", ":", "\n", "                    ", "labels_to_keep", "=", "[", "lab", "for", "lab", "in", "unique_labels", "if", "lab", "not", "in", "labels_list", "]", "\n", "new_labels", ",", "mask_new_labels", "=", "mask_label_map", "(", "labels", ",", "labels_to_keep", ",", "return_mask", "=", "True", ")", "\n", "labels", "=", "smoothing_model", ".", "predict", "(", "utils", ".", "add_axis", "(", "labels", ")", ")", "\n", "labels", "=", "np", ".", "where", "(", "mask_new_labels", ",", "new_labels", ",", "labels", ")", "\n", "", "utils", ".", "save_volume", "(", "np", ".", "squeeze", "(", "labels", ")", ",", "aff", ",", "h", ",", "path_result", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "", "", "", "else", ":", "\n", "# build kernel", "\n", "        ", "_", ",", "_", ",", "n_dims", ",", "_", ",", "_", ",", "_", "=", "utils", ".", "get_volume_info", "(", "path_labels", "[", "0", "]", ")", "\n", "kernel", "=", "utils", ".", "build_binary_structure", "(", "connectivity", ",", "n_dims", ",", "shape", "=", "n_dims", ")", "\n", "\n", "# loop over label maps", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_labels", ")", ",", "10", ",", "'smoothing'", ",", "True", ")", "\n", "for", "idx", ",", "path", "in", "enumerate", "(", "path_labels", ")", ":", "\n", "            ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# smooth label map", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "                ", "volume", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path", ",", "im_only", "=", "False", ")", "\n", "new_volume", "=", "smooth_label_map", "(", "volume", ",", "kernel", ",", "labels_list", ")", "\n", "utils", ".", "save_volume", "(", "new_volume", ",", "aff", ",", "h", ",", "path_result", ",", "dtype", "=", "'int32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.smoothing_gpu_model": [[2069, 2098], ["keras.Input", "utils.get_dims", "utils.add_axis", "range", "keras.models.Model", "layers.ConvertLabels", "keras.Lambda", "utils.build_binary_structure", "keras.Lambda", "keras.Lambda", "keras.Lambda", "keras.Lambda", "layers.ConvertLabels", "keras.Lambda", "keras.Lambda", "numpy.arange", "tensorflow.one_hot", "tensorflow.convert_to_tensor", "tensorflow.split", "tensorflow.nn.convolution", "tensorflow.math.argmax", "tensorflow.cast", "tensorflow.nn.convolution", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.build_binary_structure", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], ["", "", "", "", "def", "smoothing_gpu_model", "(", "label_shape", ",", "label_list", ",", "connectivity", "=", "1", ")", ":", "\n", "    ", "\"\"\"This function builds a gpu model in keras with a tensorflow backend to smooth label maps.\n    This model replaces each voxel of the input by the value of its most numerous neigbour.\n    :param label_shape: shape of the label map\n    :param label_list: list of all labels to consider\n    :param connectivity: (optional) connectivity to use when smoothing the label maps\n    :return: gpu smoothing model\n    \"\"\"", "\n", "\n", "# convert labels so values are in [0, ..., N-1] and use one hot encoding", "\n", "n_labels", "=", "label_list", ".", "shape", "[", "0", "]", "\n", "labels_in", "=", "KL", ".", "Input", "(", "shape", "=", "label_shape", ",", "name", "=", "'lab_input'", ",", "dtype", "=", "'int32'", ")", "\n", "labels", "=", "ConvertLabels", "(", "label_list", ")", "(", "labels_in", ")", "\n", "labels", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "one_hot", "(", "tf", ".", "cast", "(", "x", ",", "dtype", "=", "'int32'", ")", ",", "depth", "=", "n_labels", ",", "axis", "=", "-", "1", ")", ")", "(", "labels", ")", "\n", "\n", "# count neighbouring voxels", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "label_shape", ")", "\n", "k", "=", "utils", ".", "add_axis", "(", "utils", ".", "build_binary_structure", "(", "connectivity", ",", "n_dims", ",", "shape", "=", "n_dims", ")", ",", "axis", "=", "[", "-", "1", ",", "-", "1", "]", ")", "\n", "kernel", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "convert_to_tensor", "(", "k", ",", "dtype", "=", "'float32'", ")", ")", "(", "[", "]", ")", "\n", "split", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "split", "(", "x", ",", "[", "1", "]", "*", "n_labels", ",", "axis", "=", "-", "1", ")", ")", "(", "labels", ")", "\n", "labels", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "nn", ".", "convolution", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ",", "padding", "=", "'SAME'", ")", ")", "(", "[", "split", "[", "0", "]", ",", "kernel", "]", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "n_labels", ")", ":", "\n", "        ", "tmp", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "nn", ".", "convolution", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ",", "padding", "=", "'SAME'", ")", ")", "(", "[", "split", "[", "i", "]", ",", "kernel", "]", ")", "\n", "labels", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "concat", "(", "[", "x", "[", "0", "]", ",", "x", "[", "1", "]", "]", ",", "-", "1", ")", ")", "(", "[", "labels", ",", "tmp", "]", ")", "\n", "\n", "# take the argmax and convert labels to original values", "\n", "", "labels", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "math", ".", "argmax", "(", "x", ",", "-", "1", ")", ")", "(", "labels", ")", "\n", "labels", "=", "ConvertLabels", "(", "np", ".", "arange", "(", "n_labels", ")", ",", "label_list", ")", "(", "labels", ")", "\n", "return", "Model", "(", "inputs", "=", "labels_in", ",", "outputs", "=", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.erode_labels_in_dir": [[2100, 2128], ["utils.mkdir", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "len", "utils.LoopInfo.update", "utils.load_volume", "os.path.join", "os.path.basename", "edit_volumes.erode_label_map", "utils.save_volume", "os.path.isfile"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.erode_label_map", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume"], ["", "def", "erode_labels_in_dir", "(", "labels_dir", ",", "result_dir", ",", "labels_to_erode", ",", "erosion_factors", "=", "1.", ",", "gpu", "=", "False", ",", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"Erode a given set of label values for all label maps in a folder.\n    :param labels_dir: path of directory with input label maps\n    :param result_dir: path of directory where cropped label maps will be writen\n    :param labels_to_erode: list of label values to erode\n    :param erosion_factors: (optional) list of erosion factors to use for each label value. If values are integers,\n    normal erosion applies. If float, we first 1) blur a mask of the corresponding label value with a gpu model,\n    and 2) use the erosion factor as a threshold in the blurred mask.\n    If erosion_factors is a single value, the same factor will be applied to all labels.\n    :param gpu: (optionnal) whether to use a fast gpu model for blurring (if erosion factors are floats)\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# loop over label maps", "\n", "model", "=", "None", "\n", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_labels", ")", ",", "5", ",", "'eroding'", ",", "True", ")", "\n", "for", "idx", ",", "path_label", "in", "enumerate", "(", "path_labels", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# erode label map", "\n", "labels", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_label", ",", "im_only", "=", "False", ")", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "            ", "labels", ",", "model", "=", "erode_label_map", "(", "labels", ",", "labels_to_erode", ",", "erosion_factors", ",", "gpu", ",", "model", ",", "return_model", "=", "True", ")", "\n", "utils", ".", "save_volume", "(", "labels", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.upsample_labels_in_dir": [[2130, 2207], ["utils.mkdir", "os.system", "os.path.join", "utils.list_images_in_folder", "utils.get_volume_info", "utils.reformat_to_list", "utils.get_list_labels", "numpy.arange", "utils.get_mapping_lut", "utils.LoopInfo", "enumerate", "os.path.join", "len", "len", "utils.LoopInfo.update", "os.path.join", "os.path.basename", "utils.load_volume", "utils.strip_extension", "os.path.join", "os.path.join", "utils.mkdir", "utils.mkdir", "utils.load_volume", "numpy.zeros", "utils.save_volume", "os.path.isfile", "os.path.basename", "os.path.join", "os.path.join", "os.path.join", "utils.load_volume", "str", "np.zeros.astype", "os.path.isfile", "utils.save_volume", "os.path.isfile", "utils.mkcmd", "os.system", "os.path.join", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_list_labels", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_mapping_lut", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.strip_extension", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd"], ["", "", "", "def", "upsample_labels_in_dir", "(", "labels_dir", ",", "\n", "target_res", ",", "\n", "result_dir", ",", "\n", "path_label_list", "=", "None", ",", "\n", "path_freesurfer", "=", "'/usr/local/freesurfer/'", ",", "\n", "recompute", "=", "True", ")", ":", "\n", "    ", "\"\"\"This funtion upsamples all label maps within a folder. Importantly, each label map is converted into probability\n    maps for all label values, and all these maps are upsampled separetely. The upsampled label maps are recovered by\n    taking the argmax of the label values probability maps.\n    :param labels_dir: path of directory with label maps to upsample\n    :param target_res: resolution at which to upsample the label maps. can be a single number (isotropic), or a list.\n    :param result_dir: path of directory where the upsampled label maps will be writen\n    :param path_label_list: (optional) path of numpy array containing all label values.\n    Computed automatically if not given.\n    :param path_freesurfer: (optional) path freesurfer home (upsampling performed with mri_convert)\n    :param recompute: (optional) whether to recompute result files even if they already exists\n    \"\"\"", "\n", "\n", "# prepare result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "\n", "# set up FreeSurfer", "\n", "os", ".", "environ", "[", "'FREESURFER_HOME'", "]", "=", "path_freesurfer", "\n", "os", ".", "system", "(", "os", ".", "path", ".", "join", "(", "path_freesurfer", ",", "'SetUpFreeSurfer.sh'", ")", ")", "\n", "mri_convert", "=", "os", ".", "path", ".", "join", "(", "path_freesurfer", ",", "'bin/mri_convert'", ")", "\n", "\n", "# list label maps", "\n", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "labels_shape", ",", "aff", ",", "n_dims", ",", "_", ",", "h", ",", "_", "=", "utils", ".", "get_volume_info", "(", "path_labels", "[", "0", "]", ",", "max_channels", "=", "3", ")", "\n", "\n", "# build command", "\n", "target_res", "=", "utils", ".", "reformat_to_list", "(", "target_res", ",", "length", "=", "n_dims", ")", "\n", "post_cmd", "=", "'-voxsize '", "+", "' '", ".", "join", "(", "[", "str", "(", "r", ")", "for", "r", "in", "target_res", "]", ")", "+", "' -odt float'", "\n", "\n", "# load label list and corresponding LUT to make sure that labels go from 0 to N-1", "\n", "label_list", ",", "_", "=", "utils", ".", "get_list_labels", "(", "path_label_list", ",", "labels_dir", "=", "path_labels", ",", "FS_sort", "=", "False", ")", "\n", "new_label_list", "=", "np", ".", "arange", "(", "len", "(", "label_list", ")", ",", "dtype", "=", "'int32'", ")", "\n", "lut", "=", "utils", ".", "get_mapping_lut", "(", "label_list", ")", "\n", "\n", "# loop over label maps", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_labels", ")", ",", "5", ",", "'upsampling'", ",", "True", ")", "\n", "for", "idx", ",", "path_label", "in", "enumerate", "(", "path_labels", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_result", ")", ")", "|", "recompute", ":", "\n", "\n", "# load volume", "\n", "            ", "labels", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_label", ",", "im_only", "=", "False", ")", "\n", "labels", "=", "lut", "[", "labels", ".", "astype", "(", "'int'", ")", "]", "\n", "\n", "# create individual folders for label map", "\n", "basefilename", "=", "utils", ".", "strip_extension", "(", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "\n", "indiv_label_dir", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "basefilename", ")", "\n", "upsample_indiv_label_dir", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "basefilename", "+", "'_upsampled'", ")", "\n", "utils", ".", "mkdir", "(", "indiv_label_dir", ")", "\n", "utils", ".", "mkdir", "(", "upsample_indiv_label_dir", ")", "\n", "\n", "# loop over label values", "\n", "for", "label", "in", "new_label_list", ":", "\n", "                ", "path_mask", "=", "os", ".", "path", ".", "join", "(", "indiv_label_dir", ",", "str", "(", "label", ")", "+", "'.nii.gz'", ")", "\n", "path_mask_upsampled", "=", "os", ".", "path", ".", "join", "(", "upsample_indiv_label_dir", ",", "str", "(", "label", ")", "+", "'.nii.gz'", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "path_mask", ")", ":", "\n", "                    ", "mask", "=", "(", "labels", "==", "label", ")", "*", "1.0", "\n", "utils", ".", "save_volume", "(", "mask", ",", "aff", ",", "h", ",", "path_mask", ")", "\n", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "path_mask_upsampled", ")", ":", "\n", "                    ", "cmd", "=", "utils", ".", "mkcmd", "(", "mri_convert", ",", "path_mask", ",", "path_mask_upsampled", ",", "post_cmd", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n", "# compute argmax of upsampled probability maps (upload them one at a time)", "\n", "", "", "probmax", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "os", ".", "path", ".", "join", "(", "upsample_indiv_label_dir", ",", "'0.nii.gz'", ")", ",", "im_only", "=", "False", ")", "\n", "labels", "=", "np", ".", "zeros", "(", "probmax", ".", "shape", ",", "dtype", "=", "'int'", ")", "\n", "for", "label", "in", "new_label_list", ":", "\n", "                ", "prob", "=", "utils", ".", "load_volume", "(", "os", ".", "path", ".", "join", "(", "upsample_indiv_label_dir", ",", "str", "(", "label", ")", "+", "'.nii.gz'", ")", ")", "\n", "idx", "=", "prob", ">", "probmax", "\n", "labels", "[", "idx", "]", "=", "label", "\n", "probmax", "[", "idx", "]", "=", "prob", "[", "idx", "]", "\n", "", "utils", ".", "save_volume", "(", "label_list", "[", "labels", "]", ",", "aff", ",", "h", ",", "path_result", ",", "dtype", "=", "'int32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.compute_hard_volumes_in_dir": [[2209, 2283], ["utils.get_list_labels", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "utils.mkdir", "utils.mkdir", "csvFile.close", "numpy.zeros", "numpy.zeros", "len", "utils.LoopInfo.update", "utils.get_volume_info", "edit_volumes.compute_hard_volumes", "numpy.save", "os.path.dirname", "os.path.dirname", "open", "csv.writer", "csv.writer.writerows", "float", "numpy.around", "csvFile.close", "len", "len", "numpy.prod", "open", "csv.writer", "csv.writer.writerow", "utils.strip_suffix", "str", "str", "str", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_list_labels", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.compute_hard_volumes", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.strip_suffix"], ["", "", "", "def", "compute_hard_volumes_in_dir", "(", "labels_dir", ",", "\n", "voxel_volume", "=", "None", ",", "\n", "path_label_list", "=", "None", ",", "\n", "skip_background", "=", "True", ",", "\n", "path_numpy_result", "=", "None", ",", "\n", "path_csv_result", "=", "None", ",", "\n", "FS_sort", "=", "False", ")", ":", "\n", "    ", "\"\"\"Compute hard volumes of structures for all label maps in a folder.\n    :param labels_dir: path of directory with input label maps\n    :param voxel_volume: (optional) volume of the voxels. If None, it will be directly inferred from the file header.\n    Set to 1 for a voxel count.\n    :param path_label_list: (optional) list of labels to compute volumes for.\n    Can be an int, a sequence, or a numpy array. If None, the volumes of all label values are computed for each subject.\n    :param skip_background: (optional) whether to skip computing the volume of the background.\n    If label_list is None, this assumes background value is 0.\n    If label_list is not None, this assumes the background is the first value in label list.\n    :param path_numpy_result: (optional) path where to write the result volumes as a numpy array.\n    :param path_csv_result: (optional) path where to write the results as csv file.\n    :param FS_sort: (optional) whether to sort the labels in FreeSurfer order.\n    :return: numpy array with the volume of each structure for all subjects.\n    Rows represent label values, and columns represent subjects.\n    \"\"\"", "\n", "\n", "# create result directories", "\n", "if", "path_numpy_result", "is", "not", "None", ":", "\n", "        ", "utils", ".", "mkdir", "(", "os", ".", "path", ".", "dirname", "(", "path_numpy_result", ")", ")", "\n", "", "if", "path_csv_result", "is", "not", "None", ":", "\n", "        ", "utils", ".", "mkdir", "(", "os", ".", "path", ".", "dirname", "(", "path_csv_result", ")", ")", "\n", "\n", "# load or compute labels list", "\n", "", "label_list", ",", "_", "=", "utils", ".", "get_list_labels", "(", "path_label_list", ",", "labels_dir", ",", "FS_sort", "=", "FS_sort", ")", "\n", "\n", "# create csv volume file if necessary", "\n", "if", "path_csv_result", "is", "not", "None", ":", "\n", "        ", "if", "skip_background", ":", "\n", "            ", "cvs_header", "=", "[", "[", "'subject'", "]", "+", "[", "str", "(", "lab", ")", "for", "lab", "in", "label_list", "[", "1", ":", "]", "]", "]", "\n", "", "else", ":", "\n", "            ", "cvs_header", "=", "[", "[", "'subject'", "]", "+", "[", "str", "(", "lab", ")", "for", "lab", "in", "label_list", "]", "]", "\n", "", "with", "open", "(", "path_csv_result", ",", "'w'", ")", "as", "csvFile", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "csvFile", ")", "\n", "writer", ".", "writerows", "(", "cvs_header", ")", "\n", "", "csvFile", ".", "close", "(", ")", "\n", "\n", "# loop over label maps", "\n", "", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "if", "skip_background", ":", "\n", "        ", "volumes", "=", "np", ".", "zeros", "(", "(", "label_list", ".", "shape", "[", "0", "]", "-", "1", ",", "len", "(", "path_labels", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "volumes", "=", "np", ".", "zeros", "(", "(", "label_list", ".", "shape", "[", "0", "]", ",", "len", "(", "path_labels", ")", ")", ")", "\n", "", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_labels", ")", ",", "10", ",", "'processing'", ",", "True", ")", "\n", "for", "idx", ",", "path_label", "in", "enumerate", "(", "path_labels", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# load segmentation, and compute unique labels", "\n", "labels", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "subject_res", "=", "utils", ".", "get_volume_info", "(", "path_label", ",", "return_volume", "=", "True", ")", "\n", "if", "voxel_volume", "is", "None", ":", "\n", "            ", "voxel_volume", "=", "float", "(", "np", ".", "prod", "(", "subject_res", ")", ")", "\n", "", "subject_volumes", "=", "compute_hard_volumes", "(", "labels", ",", "voxel_volume", ",", "label_list", ",", "skip_background", ")", "\n", "volumes", "[", ":", ",", "idx", "]", "=", "subject_volumes", "\n", "\n", "# write volumes", "\n", "if", "path_csv_result", "is", "not", "None", ":", "\n", "            ", "subject_volumes", "=", "np", ".", "around", "(", "volumes", "[", ":", ",", "idx", "]", ",", "3", ")", "\n", "row", "=", "[", "utils", ".", "strip_suffix", "(", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "]", "+", "[", "str", "(", "vol", ")", "for", "vol", "in", "subject_volumes", "]", "\n", "with", "open", "(", "path_csv_result", ",", "'a'", ")", "as", "csvFile", ":", "\n", "                ", "writer", "=", "csv", ".", "writer", "(", "csvFile", ")", "\n", "writer", ".", "writerow", "(", "row", ")", "\n", "", "csvFile", ".", "close", "(", ")", "\n", "\n", "# write numpy array if necessary", "\n", "", "", "if", "path_numpy_result", "is", "not", "None", ":", "\n", "        ", "np", ".", "save", "(", "path_numpy_result", ",", "volumes", ")", "\n", "\n", "", "return", "volumes", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.build_atlas": [[2285, 2355], ["utils.list_images_in_folder", "len", "utils.mkdir", "numpy.array", "utils.get_mapping_lut", "len", "utils.get_volume_info", "numpy.zeros", "utils.LoopInfo", "enumerate", "edit_volumes.align_volume_to_ref", "os.path.dirname", "utils.reformat_to_list", "utils.LoopInfo.update", "utils.load_volume", "edit_volumes.correct_label_map", "edit_volumes.pad_volume", "edit_volumes.crop_volume", "numpy.where", "numpy.eye", "utils.save_volume", "numpy.eye", "utils.reformat_to_list", "len", "numpy.array", "numpy.eye", "crop_volume.astype", "numpy.identity", "numpy.mean", "numpy.mean", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_mapping_lut", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.correct_label_map", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.pad_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list"], ["", "def", "build_atlas", "(", "labels_dir", ",", "\n", "label_list", ",", "\n", "align_centre_of_mass", "=", "False", ",", "\n", "margin", "=", "15", ",", "\n", "shape", "=", "None", ",", "\n", "path_atlas", "=", "None", ")", ":", "\n", "    ", "\"\"\"This function builds a binary atlas (defined by label values > 0) from several label maps.\n    :param labels_dir: path of directory with input label maps\n    :param label_list: list of all labels in the label maps. If there is more than 1 value here, the different channels\n    of the atlas (each corresponding to the probability map of a given label) will in the same order as in this list.\n    :param align_centre_of_mass: whether to build the atlas by aligning the center of mass of each label map.\n    If False, the atlas has the same size as the input label maps, which are assumed to be aligned.\n    :param margin: (optional) If align_centre_of_mass is True, margin by which to crop the input label maps around\n    their center of mass. Therefore it controls the size of the output atlas: (2*margin + 1)**n_dims.\n    :param shape: shape of the output atlas.\n    :param path_atlas: (optional) path where the output atlas will be writen.\n    Default is None, where the atlas is not saved.\"\"\"", "\n", "\n", "# list of all label maps and create result dir", "\n", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "n_label_maps", "=", "len", "(", "path_labels", ")", "\n", "utils", ".", "mkdir", "(", "os", ".", "path", ".", "dirname", "(", "path_atlas", ")", ")", "\n", "\n", "# read list labels and create lut", "\n", "label_list", "=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "label_list", ",", "load_as_numpy", "=", "True", ",", "dtype", "=", "'int'", ")", ")", "\n", "lut", "=", "utils", ".", "get_mapping_lut", "(", "label_list", ")", "\n", "n_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# create empty atlas", "\n", "im_shape", ",", "aff", ",", "n_dims", ",", "_", ",", "h", ",", "_", "=", "utils", ".", "get_volume_info", "(", "path_labels", "[", "0", "]", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ")", "\n", "if", "align_centre_of_mass", ":", "\n", "        ", "shape", "=", "[", "margin", "*", "2", "]", "*", "n_dims", "\n", "", "else", ":", "\n", "        ", "shape", "=", "utils", ".", "reformat_to_list", "(", "shape", ",", "length", "=", "n_dims", ")", "if", "shape", "is", "not", "None", "else", "im_shape", "\n", "", "shape", "=", "shape", "+", "[", "n_labels", "]", "if", "n_labels", ">", "1", "else", "shape", "\n", "atlas", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "\n", "# loop over label maps", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "n_label_maps", ",", "10", ",", "'processing'", ",", "True", ")", "\n", "for", "idx", ",", "path_label", "in", "enumerate", "(", "path_labels", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# load label map and build mask", "\n", "lab", "=", "utils", ".", "load_volume", "(", "path_label", ",", "dtype", "=", "'int32'", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ")", "\n", "lab", "=", "correct_label_map", "(", "lab", ",", "[", "31", ",", "63", ",", "72", "]", ",", "[", "4", ",", "43", ",", "0", "]", ")", "\n", "lab", "=", "lut", "[", "lab", ".", "astype", "(", "'int'", ")", "]", "\n", "lab", "=", "pad_volume", "(", "lab", ",", "shape", "[", ":", "n_dims", "]", ")", "\n", "lab", "=", "crop_volume", "(", "lab", ",", "cropping_shape", "=", "shape", "[", ":", "n_dims", "]", ")", "\n", "indices", "=", "np", ".", "where", "(", "lab", ">", "0", ")", "\n", "\n", "if", "len", "(", "label_list", ")", ">", "1", ":", "\n", "            ", "lab", "=", "np", ".", "identity", "(", "n_labels", ")", "[", "lab", "]", "\n", "\n", "# crop label map around centre of mass", "\n", "", "if", "align_centre_of_mass", ":", "\n", "            ", "centre_of_mass", "=", "np", ".", "array", "(", "[", "np", ".", "mean", "(", "indices", "[", "0", "]", ")", ",", "np", ".", "mean", "(", "indices", "[", "1", "]", ")", ",", "np", ".", "mean", "(", "indices", "[", "2", "]", ")", "]", ",", "dtype", "=", "'int32'", ")", "\n", "min_crop", "=", "centre_of_mass", "-", "margin", "\n", "max_crop", "=", "centre_of_mass", "+", "margin", "\n", "atlas", "+=", "lab", "[", "min_crop", "[", "0", "]", ":", "max_crop", "[", "0", "]", ",", "min_crop", "[", "1", "]", ":", "max_crop", "[", "1", "]", ",", "min_crop", "[", "2", "]", ":", "max_crop", "[", "2", "]", ",", "...", "]", "\n", "# otherwise just add the one-hot labels", "\n", "", "else", ":", "\n", "            ", "atlas", "+=", "lab", "\n", "\n", "# normalise atlas and save it if necessary", "\n", "", "", "atlas", "/=", "n_label_maps", "\n", "atlas", "=", "align_volume_to_ref", "(", "atlas", ",", "np", ".", "eye", "(", "4", ")", ",", "aff_ref", "=", "aff", ",", "n_dims", "=", "n_dims", ")", "\n", "if", "path_atlas", "is", "not", "None", ":", "\n", "        ", "utils", ".", "save_volume", "(", "atlas", ",", "aff", ",", "h", ",", "path_atlas", ")", "\n", "\n", "", "return", "atlas", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.check_images_and_labels": [[2359, 2395], ["utils.list_images_in_folder", "utils.list_images_in_folder", "utils.LoopInfo", "enumerate", "len", "len", "len", "zip", "utils.LoopInfo.update", "utils.load_volume", "utils.load_volume", "numpy.round().tolist", "numpy.round().tolist", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "numpy.round", "numpy.round"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume"], ["", "def", "check_images_and_labels", "(", "image_dir", ",", "labels_dir", ")", ":", "\n", "    ", "\"\"\"Check if corresponding images and labels have the same affine matrices and shapes.\n    Labels are matched to images by sorting order.\n    :param image_dir: path of directory with input images\n    :param labels_dir: path of directory with corresponding label maps\n    \"\"\"", "\n", "\n", "# list images and labels", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "assert", "len", "(", "path_images", ")", "==", "len", "(", "path_labels", ")", ",", "'different number of files in image_dir and labels_dir'", "\n", "\n", "# loop over images and labels", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'checking'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_label", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_labels", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# load images and labels", "\n", "im", ",", "aff_im", ",", "h_im", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "lab", ",", "aff_lab", ",", "h_lab", "=", "utils", ".", "load_volume", "(", "path_label", ",", "im_only", "=", "False", ")", "\n", "aff_im_list", "=", "np", ".", "round", "(", "aff_im", ",", "2", ")", ".", "tolist", "(", ")", "\n", "aff_lab_list", "=", "np", ".", "round", "(", "aff_lab", ",", "2", ")", ".", "tolist", "(", ")", "\n", "\n", "# check matching affine and shape", "\n", "if", "aff_lab_list", "!=", "aff_im_list", ":", "\n", "            ", "print", "(", "'aff mismatch :\\n'", "+", "path_image", ")", "\n", "print", "(", "aff_im_list", ")", "\n", "print", "(", "path_label", ")", "\n", "print", "(", "aff_lab_list", ")", "\n", "print", "(", "''", ")", "\n", "", "if", "lab", ".", "shape", "!=", "im", ".", "shape", ":", "\n", "            ", "print", "(", "'shape mismatch :\\n'", "+", "path_image", ")", "\n", "print", "(", "im", ".", "shape", ")", "\n", "print", "(", "'\\n'", "+", "path_label", ")", "\n", "print", "(", "lab", ".", "shape", ")", "\n", "print", "(", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_dataset_to_minimum_size": [[2397, 2460], ["utils.mkdir", "utils.list_images_in_folder", "utils.get_volume_info", "print", "numpy.zeros", "utils.LoopInfo", "enumerate", "print", "utils.LoopInfo", "enumerate", "utils.mkdir", "utils.list_images_in_folder", "len", "zip", "utils.LoopInfo.update", "utils.load_volume", "edit_volumes.crop_volume_around_region", "utils.save_volume", "numpy.maximum", "len", "zip", "utils.LoopInfo.update", "os.path.join", "utils.load_volume", "edit_volumes.pad_volume", "utils.save_volume", "len", "os.path.join", "utils.load_volume", "edit_volumes.crop_volume_with_idx", "utils.save_volume", "os.path.basename", "os.path.join", "utils.load_volume", "edit_volumes.pad_volume", "utils.save_volume", "os.path.basename", "numpy.array", "os.path.join", "os.path.basename", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_around_region", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.pad_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_with_idx", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.pad_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume"], ["", "", "", "def", "crop_dataset_to_minimum_size", "(", "labels_dir", ",", "result_dir", ",", "image_dir", "=", "None", ",", "image_result_dir", "=", "None", ",", "margin", "=", "5", ")", ":", "\n", "    ", "\"\"\"Crop all label maps in a directory to the minimum possible common size, with a margin.\n    This is achieved by cropping each label map individually to the minimum size, and by padding all the cropped maps to\n    the same size (taken to be the maximum size of the cropped maps).\n    If images are provided, they undergo the same transformations as their corresponding label maps.\n    :param labels_dir: path of directory with input label maps\n    :param result_dir: path of directory where cropped label maps will be writen\n    :param image_dir: (optional) if not None, the cropping will be applied to all images in this directory\n    :param image_result_dir: (optional) path of directory where cropped images will be writen\n    :param margin: (optional) margin to apply around the label maps during cropping\n    \"\"\"", "\n", "\n", "# create result dir", "\n", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "if", "image_dir", "is", "not", "None", ":", "\n", "        ", "assert", "image_result_dir", "is", "not", "None", ",", "'image_result_dir should not be None if image_dir is specified'", "\n", "utils", ".", "mkdir", "(", "image_result_dir", ")", "\n", "\n", "# list labels and images", "\n", "", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "if", "image_dir", "is", "not", "None", ":", "\n", "        ", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "", "else", ":", "\n", "        ", "path_images", "=", "[", "None", "]", "*", "len", "(", "path_labels", ")", "\n", "", "_", ",", "_", ",", "n_dims", ",", "_", ",", "_", ",", "_", "=", "utils", ".", "get_volume_info", "(", "path_labels", "[", "0", "]", ")", "\n", "\n", "# loop over label maps for cropping", "\n", "print", "(", "'\\ncropping labels to individual minimum size'", ")", "\n", "maximum_size", "=", "np", ".", "zeros", "(", "n_dims", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_labels", ")", ",", "10", ",", "'cropping'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_label", ",", "path_image", ")", "in", "enumerate", "(", "zip", "(", "path_labels", ",", "path_images", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# crop label maps and update maximum size of cropped map", "\n", "label", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_label", ",", "im_only", "=", "False", ")", "\n", "label", ",", "cropping", ",", "aff", "=", "crop_volume_around_region", "(", "label", ",", "aff", "=", "aff", ")", "\n", "utils", ".", "save_volume", "(", "label", ",", "aff", ",", "h", ",", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", ")", "\n", "maximum_size", "=", "np", ".", "maximum", "(", "maximum_size", ",", "np", ".", "array", "(", "label", ".", "shape", ")", "+", "margin", "*", "2", ")", "# *2 to add margin on each side", "\n", "\n", "# crop images if required", "\n", "if", "path_image", "is", "not", "None", ":", "\n", "            ", "image", ",", "aff_im", ",", "h_im", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "image", ",", "aff_im", "=", "crop_volume_with_idx", "(", "image", ",", "cropping", ",", "aff", "=", "aff_im", ")", "\n", "utils", ".", "save_volume", "(", "image", ",", "aff_im", ",", "h_im", ",", "os", ".", "path", ".", "join", "(", "image_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", ")", "\n", "\n", "# loop over label maps for padding", "\n", "", "", "print", "(", "'\\npadding labels to same size'", ")", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_labels", ")", ",", "10", ",", "'padding'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_label", ",", "path_image", ")", "in", "enumerate", "(", "zip", "(", "path_labels", ",", "path_images", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# pad label maps to maximum size", "\n", "path_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "\n", "label", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_result", ",", "im_only", "=", "False", ")", "\n", "label", ",", "aff", "=", "pad_volume", "(", "label", ",", "maximum_size", ",", "aff", "=", "aff", ")", "\n", "utils", ".", "save_volume", "(", "label", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n", "# crop images if required", "\n", "if", "path_image", "is", "not", "None", ":", "\n", "            ", "path_result", "=", "os", ".", "path", ".", "join", "(", "image_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "image", ",", "aff", ",", "h", "=", "utils", ".", "load_volume", "(", "path_result", ",", "im_only", "=", "False", ")", "\n", "image", ",", "aff", "=", "pad_volume", "(", "image", ",", "maximum_size", ",", "aff", "=", "aff", ")", "\n", "utils", ".", "save_volume", "(", "image", ",", "aff", ",", "h", ",", "path_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_dataset_around_region_of_same_size": [[2462, 2562], ["utils.mkdir", "utils.list_images_in_folder", "utils.get_volume_info", "any", "numpy.zeros", "zip", "utils.mkdir", "utils.list_images_in_folder", "any", "numpy.array", "print", "os.path.join", "os.path.join", "len", "utils.load_volume", "edit_volumes.align_volume_to_ref", "edit_volumes.get_largest_connected_component", "edit_volumes.crop_volume_around_region", "numpy.maximum", "utils.reformat_to_list", "os.path.basename", "os.path.basename", "utils.load_volume", "edit_volumes.align_volume_to_ref", "numpy.array", "edit_volumes.get_largest_connected_component", "numpy.nonzero", "numpy.maximum", "numpy.minimum", "numpy.abs", "numpy.maximum", "numpy.concatenate", "edit_volumes.crop_volume_with_idx", "edit_volumes.align_volume_to_ref", "utils.save_volume", "os.path.isfile", "utils.load_volume", "edit_volumes.align_volume_to_ref", "numpy.int32", "numpy.int32", "numpy.minimum", "numpy.any", "numpy.any", "tuple", "edit_volumes.crop_volume_with_idx", "numpy.pad", "numpy.append", "edit_volumes.align_volume_to_ref", "utils.save_volume", "os.path.join", "os.path.isfile", "numpy.eye", "numpy.ones", "os.path.isfile", "os.path.isfile", "numpy.eye", "numpy.ones", "numpy.logical_not", "numpy.array", "numpy.ceil", "numpy.floor", "numpy.maximum", "numpy.minimum", "utils.get_dims", "numpy.pad", "os.path.basename", "os.path.join", "numpy.eye", "numpy.array", "tuple", "os.path.basename", "numpy.min", "range", "numpy.max", "list"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_largest_connected_component", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_around_region", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_largest_connected_component", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_with_idx", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_with_idx", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "", "", "def", "crop_dataset_around_region_of_same_size", "(", "labels_dir", ",", "\n", "result_dir", ",", "\n", "image_dir", "=", "None", ",", "\n", "image_result_dir", "=", "None", ",", "\n", "margin", "=", "0", ",", "\n", "recompute", "=", "True", ")", ":", "\n", "\n", "# create result dir", "\n", "    ", "utils", ".", "mkdir", "(", "result_dir", ")", "\n", "if", "image_dir", "is", "not", "None", ":", "\n", "        ", "assert", "image_result_dir", "is", "not", "None", ",", "'image_result_dir should not be None if image_dir is specified'", "\n", "utils", ".", "mkdir", "(", "image_result_dir", ")", "\n", "\n", "# list labels and images", "\n", "", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "if", "image_dir", "is", "not", "None", "else", "[", "None", "]", "*", "len", "(", "path_labels", ")", "\n", "_", ",", "_", ",", "n_dims", ",", "_", ",", "_", ",", "_", "=", "utils", ".", "get_volume_info", "(", "path_labels", "[", "0", "]", ")", "\n", "\n", "recompute_labels", "=", "any", "(", "[", "not", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path", ")", ")", ")", "\n", "for", "path", "in", "path_labels", "]", ")", "\n", "if", "(", "image_dir", "is", "not", "None", ")", "&", "(", "not", "recompute_labels", ")", ":", "\n", "        ", "recompute_labels", "=", "any", "(", "[", "not", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "image_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path", ")", ")", ")", "\n", "for", "path", "in", "path_images", "]", ")", "\n", "\n", "# get minimum patch shape so that no labels are left out when doing the cropping later on", "\n", "", "max_crop_shape", "=", "np", ".", "zeros", "(", "n_dims", ")", "\n", "if", "recompute_labels", ":", "\n", "        ", "for", "path_label", "in", "path_labels", ":", "\n", "            ", "label", ",", "aff", ",", "_", "=", "utils", ".", "load_volume", "(", "path_label", ",", "im_only", "=", "False", ")", "\n", "label", "=", "align_volume_to_ref", "(", "label", ",", "aff", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ")", "\n", "label", "=", "get_largest_connected_component", "(", "label", ">", "0", ",", "structure", "=", "np", ".", "ones", "(", "(", "3", ",", "3", ",", "3", ")", ")", ")", "\n", "_", ",", "cropping", "=", "crop_volume_around_region", "(", "label", ")", "\n", "max_crop_shape", "=", "np", ".", "maximum", "(", "cropping", "[", "n_dims", ":", "]", "-", "cropping", "[", ":", "n_dims", "]", ",", "max_crop_shape", ")", "\n", "", "max_crop_shape", "+=", "np", ".", "array", "(", "utils", ".", "reformat_to_list", "(", "margin", ",", "length", "=", "n_dims", ",", "dtype", "=", "'int'", ")", ")", "\n", "print", "(", "'max_crop_shape: '", ",", "max_crop_shape", ")", "\n", "\n", "# crop shapes (possibly with padding if images are smaller than crop shape)", "\n", "", "for", "path_label", ",", "path_image", "in", "zip", "(", "path_labels", ",", "path_images", ")", ":", "\n", "\n", "        ", "path_label_result", "=", "os", ".", "path", ".", "join", "(", "result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "\n", "path_image_result", "=", "os", ".", "path", ".", "join", "(", "image_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_image_result", ")", ")", "|", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_label_result", ")", ")", "|", "recompute", ":", "\n", "# load labels", "\n", "            ", "label", ",", "aff", ",", "h_la", "=", "utils", ".", "load_volume", "(", "path_label", ",", "im_only", "=", "False", ",", "dtype", "=", "'int32'", ")", "\n", "label", ",", "aff_new", "=", "align_volume_to_ref", "(", "label", ",", "aff", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ",", "return_aff", "=", "True", ")", "\n", "vol_shape", "=", "np", ".", "array", "(", "label", ".", "shape", "[", ":", "n_dims", "]", ")", "\n", "if", "path_image", "is", "not", "None", ":", "\n", "                ", "image", ",", "_", ",", "h_im", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "image", "=", "align_volume_to_ref", "(", "image", ",", "aff", ",", "aff_ref", "=", "np", ".", "eye", "(", "4", ")", ")", "\n", "", "else", ":", "\n", "                ", "image", "=", "h_im", "=", "None", "\n", "\n", "# mask labels", "\n", "", "mask", "=", "get_largest_connected_component", "(", "label", ">", "0", ",", "structure", "=", "np", ".", "ones", "(", "(", "3", ",", "3", ",", "3", ")", ")", ")", "\n", "label", "[", "np", ".", "logical_not", "(", "mask", ")", "]", "=", "0", "\n", "\n", "# find cropping indices", "\n", "indices", "=", "np", ".", "nonzero", "(", "mask", ")", "\n", "min_idx", "=", "np", ".", "maximum", "(", "np", ".", "array", "(", "[", "np", ".", "min", "(", "idx", ")", "for", "idx", "in", "indices", "]", ")", "-", "margin", ",", "0", ")", "\n", "max_idx", "=", "np", ".", "minimum", "(", "np", ".", "array", "(", "[", "np", ".", "max", "(", "idx", ")", "for", "idx", "in", "indices", "]", ")", "+", "1", "+", "margin", ",", "vol_shape", ")", "\n", "\n", "# expand/retract (depending on the desired shape) the cropping region around the centre", "\n", "intermediate_vol_shape", "=", "max_idx", "-", "min_idx", "\n", "min_idx", "=", "min_idx", "-", "np", ".", "int32", "(", "np", ".", "ceil", "(", "(", "max_crop_shape", "-", "intermediate_vol_shape", ")", "/", "2", ")", ")", "\n", "max_idx", "=", "max_idx", "+", "np", ".", "int32", "(", "np", ".", "floor", "(", "(", "max_crop_shape", "-", "intermediate_vol_shape", ")", "/", "2", ")", ")", "\n", "\n", "# check if we need to pad the output to the desired shape", "\n", "min_padding", "=", "np", ".", "abs", "(", "np", ".", "minimum", "(", "min_idx", ",", "0", ")", ")", "\n", "max_padding", "=", "np", ".", "maximum", "(", "max_idx", "-", "vol_shape", ",", "0", ")", "\n", "if", "np", ".", "any", "(", "min_padding", ">", "0", ")", "|", "np", ".", "any", "(", "max_padding", ">", "0", ")", ":", "\n", "                ", "pad_margins", "=", "tuple", "(", "[", "(", "min_padding", "[", "i", "]", ",", "max_padding", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "pad_margins", "=", "None", "\n", "", "cropping", "=", "np", ".", "concatenate", "(", "[", "np", ".", "maximum", "(", "min_idx", ",", "0", ")", ",", "np", ".", "minimum", "(", "max_idx", ",", "vol_shape", ")", "]", ")", "\n", "\n", "# crop volume", "\n", "label", "=", "crop_volume_with_idx", "(", "label", ",", "cropping", ",", "n_dims", "=", "n_dims", ")", "\n", "if", "path_image", "is", "not", "None", ":", "\n", "                ", "image", "=", "crop_volume_with_idx", "(", "image", ",", "cropping", ",", "n_dims", "=", "n_dims", ")", "\n", "\n", "# pad volume if necessary", "\n", "", "if", "pad_margins", "is", "not", "None", ":", "\n", "                ", "label", "=", "np", ".", "pad", "(", "label", ",", "pad_margins", ",", "mode", "=", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "if", "path_image", "is", "not", "None", ":", "\n", "                    ", "_", ",", "n_channels", "=", "utils", ".", "get_dims", "(", "image", ".", "shape", ")", "\n", "pad_margins", "=", "tuple", "(", "list", "(", "pad_margins", ")", "+", "[", "(", "0", ",", "0", ")", "]", ")", "if", "n_channels", ">", "1", "else", "pad_margins", "\n", "image", "=", "np", ".", "pad", "(", "image", ",", "pad_margins", ",", "mode", "=", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "\n", "# update aff", "\n", "", "", "if", "n_dims", "==", "2", ":", "\n", "                ", "min_idx", "=", "np", ".", "append", "(", "min_idx", ",", "0", ")", "\n", "", "aff_new", "[", "0", ":", "3", ",", "-", "1", "]", "=", "aff_new", "[", "0", ":", "3", ",", "-", "1", "]", "+", "aff_new", "[", ":", "3", ",", ":", "3", "]", "@", "min_idx", "\n", "\n", "# write labels", "\n", "label", ",", "aff_final", "=", "align_volume_to_ref", "(", "label", ",", "aff_new", ",", "aff_ref", "=", "aff", ",", "return_aff", "=", "True", ")", "\n", "utils", ".", "save_volume", "(", "label", ",", "aff_final", ",", "h_la", ",", "path_label_result", ",", "dtype", "=", "'int32'", ")", "\n", "if", "path_image", "is", "not", "None", ":", "\n", "                ", "image", "=", "align_volume_to_ref", "(", "image", ",", "aff_new", ",", "aff_ref", "=", "aff", ")", "\n", "utils", ".", "save_volume", "(", "image", ",", "aff_final", ",", "h_im", ",", "path_image_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_dataset_around_region": [[2564, 2632], ["utils.mkdir", "utils.mkdir", "utils.list_images_in_folder", "utils.list_images_in_folder", "utils.get_volume_info", "utils.LoopInfo", "enumerate", "len", "zip", "utils.LoopInfo.update", "os.path.join", "os.path.join", "os.path.basename", "os.path.basename", "utils.load_volume", "utils.load_volume", "edit_volumes.get_largest_connected_component", "numpy.array", "numpy.nonzero", "numpy.maximum", "numpy.minimum", "numpy.array", "numpy.abs", "numpy.maximum", "numpy.concatenate", "edit_volumes.crop_volume_with_idx", "edit_volumes.crop_volume_with_idx", "utils.save_volume", "utils.save_volume", "numpy.int32", "numpy.int32", "numpy.minimum", "numpy.any", "numpy.any", "tuple", "numpy.pad", "numpy.pad", "numpy.append", "os.path.isfile", "os.path.isfile", "numpy.ones", "numpy.logical_not", "numpy.array", "utils.find_closest_number_divisible_by_m", "numpy.ceil", "numpy.floor", "numpy.maximum", "numpy.minimum", "tuple", "numpy.array", "numpy.min", "range", "list", "numpy.max"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_largest_connected_component", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_with_idx", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.crop_volume_with_idx", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.find_closest_number_divisible_by_m", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "", "", "", "def", "crop_dataset_around_region", "(", "image_dir", ",", "labels_dir", ",", "image_result_dir", ",", "labels_result_dir", ",", "margin", "=", "0", ",", "\n", "cropping_shape_div_by", "=", "None", ",", "recompute", "=", "True", ")", ":", "\n", "\n", "# create result dir", "\n", "    ", "utils", ".", "mkdir", "(", "image_result_dir", ")", "\n", "utils", ".", "mkdir", "(", "labels_result_dir", ")", "\n", "\n", "# list volumes and masks", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "_", ",", "_", ",", "n_dims", ",", "n_channels", ",", "_", ",", "_", "=", "utils", ".", "get_volume_info", "(", "path_labels", "[", "0", "]", ")", "\n", "\n", "# loop over images and labels", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'cropping'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_label", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_labels", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "path_label_result", "=", "os", ".", "path", ".", "join", "(", "labels_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_label", ")", ")", "\n", "path_image_result", "=", "os", ".", "path", ".", "join", "(", "image_result_dir", ",", "os", ".", "path", ".", "basename", "(", "path_image", ")", ")", "\n", "\n", "if", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_label_result", ")", ")", "|", "(", "not", "os", ".", "path", ".", "isfile", "(", "path_image_result", ")", ")", "|", "recompute", ":", "\n", "\n", "            ", "image", ",", "aff", ",", "h_im", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ")", "\n", "label", ",", "_", ",", "h_lab", "=", "utils", ".", "load_volume", "(", "path_label", ",", "im_only", "=", "False", ")", "\n", "mask", "=", "get_largest_connected_component", "(", "label", ">", "0", ",", "structure", "=", "np", ".", "ones", "(", "(", "3", ",", "3", ",", "3", ")", ")", ")", "\n", "label", "[", "np", ".", "logical_not", "(", "mask", ")", "]", "=", "0", "\n", "vol_shape", "=", "np", ".", "array", "(", "label", ".", "shape", "[", ":", "n_dims", "]", ")", "\n", "\n", "# find cropping indices", "\n", "indices", "=", "np", ".", "nonzero", "(", "mask", ")", "\n", "min_idx", "=", "np", ".", "maximum", "(", "np", ".", "array", "(", "[", "np", ".", "min", "(", "idx", ")", "for", "idx", "in", "indices", "]", ")", "-", "margin", ",", "0", ")", "\n", "max_idx", "=", "np", ".", "minimum", "(", "np", ".", "array", "(", "[", "np", ".", "max", "(", "idx", ")", "for", "idx", "in", "indices", "]", ")", "+", "1", "+", "margin", ",", "vol_shape", ")", "\n", "\n", "# expand/retract (depending on the desired shape) the cropping region around the centre", "\n", "intermediate_vol_shape", "=", "max_idx", "-", "min_idx", "\n", "cropping_shape", "=", "np", ".", "array", "(", "[", "utils", ".", "find_closest_number_divisible_by_m", "(", "s", ",", "cropping_shape_div_by", ",", "\n", "answer_type", "=", "'higher'", ")", "\n", "for", "s", "in", "intermediate_vol_shape", "]", ")", "\n", "min_idx", "=", "min_idx", "-", "np", ".", "int32", "(", "np", ".", "ceil", "(", "(", "cropping_shape", "-", "intermediate_vol_shape", ")", "/", "2", ")", ")", "\n", "max_idx", "=", "max_idx", "+", "np", ".", "int32", "(", "np", ".", "floor", "(", "(", "cropping_shape", "-", "intermediate_vol_shape", ")", "/", "2", ")", ")", "\n", "\n", "# check if we need to pad the output to the desired shape", "\n", "min_padding", "=", "np", ".", "abs", "(", "np", ".", "minimum", "(", "min_idx", ",", "0", ")", ")", "\n", "max_padding", "=", "np", ".", "maximum", "(", "max_idx", "-", "vol_shape", ",", "0", ")", "\n", "if", "np", ".", "any", "(", "min_padding", ">", "0", ")", "|", "np", ".", "any", "(", "max_padding", ">", "0", ")", ":", "\n", "                ", "pad_margins", "=", "tuple", "(", "[", "(", "min_padding", "[", "i", "]", ",", "max_padding", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "pad_margins", "=", "None", "\n", "", "cropping", "=", "np", ".", "concatenate", "(", "[", "np", ".", "maximum", "(", "min_idx", ",", "0", ")", ",", "np", ".", "minimum", "(", "max_idx", ",", "vol_shape", ")", "]", ")", "\n", "\n", "# crop volume", "\n", "label", "=", "crop_volume_with_idx", "(", "label", ",", "cropping", ",", "n_dims", "=", "n_dims", ")", "\n", "image", "=", "crop_volume_with_idx", "(", "image", ",", "cropping", ",", "n_dims", "=", "n_dims", ")", "\n", "\n", "# pad volume if necessary", "\n", "if", "pad_margins", "is", "not", "None", ":", "\n", "                ", "label", "=", "np", ".", "pad", "(", "label", ",", "pad_margins", ",", "mode", "=", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "pad_margins", "=", "tuple", "(", "list", "(", "pad_margins", ")", "+", "[", "(", "0", ",", "0", ")", "]", ")", "if", "n_channels", ">", "1", "else", "pad_margins", "\n", "image", "=", "np", ".", "pad", "(", "image", ",", "pad_margins", ",", "mode", "=", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "\n", "# update aff", "\n", "", "if", "n_dims", "==", "2", ":", "\n", "                ", "min_idx", "=", "np", ".", "append", "(", "min_idx", ",", "0", ")", "\n", "", "aff", "[", "0", ":", "3", ",", "-", "1", "]", "=", "aff", "[", "0", ":", "3", ",", "-", "1", "]", "+", "aff", "[", ":", "3", ",", ":", "3", "]", "@", "min_idx", "\n", "\n", "# write results", "\n", "utils", ".", "save_volume", "(", "image", ",", "aff", ",", "h_im", ",", "path_image_result", ")", "\n", "utils", ".", "save_volume", "(", "label", ",", "aff", ",", "h_lab", ",", "path_label_result", ",", "dtype", "=", "'int32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.subdivide_dataset_to_patches": [[2634, 2777], ["utils.reformat_to_list", "utils.get_dims", "utils.LoopInfo", "enumerate", "utils.mkdir", "utils.list_images_in_folder", "utils.mkdir", "utils.list_images_in_folder", "len", "zip", "utils.LoopInfo.update", "numpy.array", "numpy.round().astype", "numpy.concatenate", "range", "len", "len", "utils.load_volume", "utils.load_volume", "range", "utils.find_closest_number_divisible_by_m", "numpy.round", "os.remove", "os.remove", "range", "utils.save_volume", "range", "numpy.array", "utils.save_volume", "os.path.join", "os.path.join", "utils.save_volume", "os.path.basename", "utils.save_volume", "os.path.basename", "os.path.join", "path_image.replace", "utils.save_volume", "os.path.join", "path_label.replace", "os.path.basename", "os.path.join", "utils.save_volume", "os.path.basename", "path_image.replace", "os.path.basename", "os.path.join", "path_image.replace", "path_label.replace", "os.path.basename", "path_image.replace"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.find_closest_number_divisible_by_m", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume"], ["", "", "", "def", "subdivide_dataset_to_patches", "(", "patch_shape", ",", "\n", "image_dir", "=", "None", ",", "\n", "image_result_dir", "=", "None", ",", "\n", "labels_dir", "=", "None", ",", "\n", "labels_result_dir", "=", "None", ",", "\n", "full_background", "=", "True", ",", "\n", "remove_after_dividing", "=", "False", ")", ":", "\n", "    ", "\"\"\"This function subdivides images and/or label maps into several smaller patches of specified shape.\n    :param patch_shape: shape of patches to create. Can either be an int, a sequence, or a 1d numpy array.\n    :param image_dir: (optional) path of directory with input images\n    :param image_result_dir: (optional) path of directory where image patches will be writen\n    :param labels_dir: (optional) path of directory with input label maps\n    :param labels_result_dir: (optional) path of directory where label map patches will be writen\n    :param full_background: (optional) whether to keep patches only labelled as background (only if label maps are\n    provided).\n    :param remove_after_dividing: (optional) whether to delete input images after having divided them in smaller\n    patches. This enables to save disk space in the subdivision process.\n    \"\"\"", "\n", "\n", "# create result dir and list images and label maps", "\n", "assert", "(", "image_dir", "is", "not", "None", ")", "|", "(", "labels_dir", "is", "not", "None", ")", ",", "'at least one of image_dir or labels_dir should not be None.'", "\n", "if", "image_dir", "is", "not", "None", ":", "\n", "        ", "assert", "image_result_dir", "is", "not", "None", ",", "'image_result_dir should not be None if image_dir is specified'", "\n", "utils", ".", "mkdir", "(", "image_result_dir", ")", "\n", "path_images", "=", "utils", ".", "list_images_in_folder", "(", "image_dir", ")", "\n", "", "else", ":", "\n", "        ", "path_images", "=", "None", "\n", "", "if", "labels_dir", "is", "not", "None", ":", "\n", "        ", "assert", "labels_result_dir", "is", "not", "None", ",", "'labels_result_dir should not be None if labels_dir is specified'", "\n", "utils", ".", "mkdir", "(", "labels_result_dir", ")", "\n", "path_labels", "=", "utils", ".", "list_images_in_folder", "(", "labels_dir", ")", "\n", "", "else", ":", "\n", "        ", "path_labels", "=", "None", "\n", "", "if", "path_images", "is", "None", ":", "\n", "        ", "path_images", "=", "[", "None", "]", "*", "len", "(", "path_labels", ")", "\n", "", "if", "path_labels", "is", "None", ":", "\n", "        ", "path_labels", "=", "[", "None", "]", "*", "len", "(", "path_images", ")", "\n", "\n", "# reformat path_shape", "\n", "", "patch_shape", "=", "utils", ".", "reformat_to_list", "(", "patch_shape", ")", "\n", "n_dims", ",", "_", "=", "utils", ".", "get_dims", "(", "patch_shape", ")", "\n", "\n", "# loop over images and labels", "\n", "loop_info", "=", "utils", ".", "LoopInfo", "(", "len", "(", "path_images", ")", ",", "10", ",", "'processing'", ",", "True", ")", "\n", "for", "idx", ",", "(", "path_image", ",", "path_label", ")", "in", "enumerate", "(", "zip", "(", "path_images", ",", "path_labels", ")", ")", ":", "\n", "        ", "loop_info", ".", "update", "(", "idx", ")", "\n", "\n", "# load image and labels", "\n", "if", "path_image", "is", "not", "None", ":", "\n", "            ", "im", ",", "aff_im", ",", "h_im", "=", "utils", ".", "load_volume", "(", "path_image", ",", "im_only", "=", "False", ",", "squeeze", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "im", "=", "aff_im", "=", "h_im", "=", "None", "\n", "", "if", "path_label", "is", "not", "None", ":", "\n", "            ", "lab", ",", "aff_lab", ",", "h_lab", "=", "utils", ".", "load_volume", "(", "path_label", ",", "im_only", "=", "False", ",", "squeeze", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "lab", "=", "aff_lab", "=", "h_lab", "=", "None", "\n", "\n", "# get volume shape", "\n", "", "if", "path_image", "is", "not", "None", ":", "\n", "            ", "shape", "=", "im", ".", "shape", "\n", "", "else", ":", "\n", "            ", "shape", "=", "lab", ".", "shape", "\n", "\n", "# crop image and label map to size divisible by patch_shape", "\n", "", "new_size", "=", "np", ".", "array", "(", "[", "utils", ".", "find_closest_number_divisible_by_m", "(", "shape", "[", "i", "]", ",", "patch_shape", "[", "i", "]", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", ")", "\n", "crop", "=", "np", ".", "round", "(", "(", "np", ".", "array", "(", "shape", "[", ":", "n_dims", "]", ")", "-", "new_size", ")", "/", "2", ")", ".", "astype", "(", "'int'", ")", "\n", "crop", "=", "np", ".", "concatenate", "(", "(", "crop", ",", "crop", "+", "new_size", ")", ",", "axis", "=", "0", ")", "\n", "if", "(", "im", "is", "not", "None", ")", "&", "(", "n_dims", "==", "2", ")", ":", "\n", "            ", "im", "=", "im", "[", "crop", "[", "0", "]", ":", "crop", "[", "2", "]", ",", "crop", "[", "1", "]", ":", "crop", "[", "3", "]", ",", "...", "]", "\n", "", "elif", "(", "im", "is", "not", "None", ")", "&", "(", "n_dims", "==", "3", ")", ":", "\n", "            ", "im", "=", "im", "[", "crop", "[", "0", "]", ":", "crop", "[", "3", "]", ",", "crop", "[", "1", "]", ":", "crop", "[", "4", "]", ",", "crop", "[", "2", "]", ":", "crop", "[", "5", "]", ",", "...", "]", "\n", "", "if", "(", "lab", "is", "not", "None", ")", "&", "(", "n_dims", "==", "2", ")", ":", "\n", "            ", "lab", "=", "lab", "[", "crop", "[", "0", "]", ":", "crop", "[", "2", "]", ",", "crop", "[", "1", "]", ":", "crop", "[", "3", "]", ",", "...", "]", "\n", "", "elif", "(", "lab", "is", "not", "None", ")", "&", "(", "n_dims", "==", "3", ")", ":", "\n", "            ", "lab", "=", "lab", "[", "crop", "[", "0", "]", ":", "crop", "[", "3", "]", ",", "crop", "[", "1", "]", ":", "crop", "[", "4", "]", ",", "crop", "[", "2", "]", ":", "crop", "[", "5", "]", ",", "...", "]", "\n", "\n", "# loop over patches", "\n", "", "n_im", "=", "0", "\n", "n_crop", "=", "(", "new_size", "/", "patch_shape", ")", ".", "astype", "(", "'int'", ")", "\n", "for", "i", "in", "range", "(", "n_crop", "[", "0", "]", ")", ":", "\n", "            ", "i", "*=", "patch_shape", "[", "0", "]", "\n", "for", "j", "in", "range", "(", "n_crop", "[", "1", "]", ")", ":", "\n", "                ", "j", "*=", "patch_shape", "[", "1", "]", "\n", "\n", "if", "n_dims", "==", "2", ":", "\n", "\n", "# crop volumes", "\n", "                    ", "if", "lab", "is", "not", "None", ":", "\n", "                        ", "temp_la", "=", "lab", "[", "i", ":", "i", "+", "patch_shape", "[", "0", "]", ",", "j", ":", "j", "+", "patch_shape", "[", "1", "]", ",", "...", "]", "\n", "", "else", ":", "\n", "                        ", "temp_la", "=", "None", "\n", "", "if", "im", "is", "not", "None", ":", "\n", "                        ", "temp_im", "=", "im", "[", "i", ":", "i", "+", "patch_shape", "[", "0", "]", ",", "j", ":", "j", "+", "patch_shape", "[", "1", "]", ",", "...", "]", "\n", "", "else", ":", "\n", "                        ", "temp_im", "=", "None", "\n", "\n", "# write patches", "\n", "", "if", "temp_la", "is", "not", "None", ":", "\n", "                        ", "if", "full_background", "|", "(", "not", "(", "temp_la", "==", "0", ")", ".", "all", "(", ")", ")", ":", "\n", "                            ", "n_im", "+=", "1", "\n", "utils", ".", "save_volume", "(", "temp_la", ",", "aff_lab", ",", "h_lab", ",", "os", ".", "path", ".", "join", "(", "labels_result_dir", ",", "\n", "os", ".", "path", ".", "basename", "(", "path_label", ".", "replace", "(", "'.nii.gz'", ",", "'_%d.nii.gz'", "%", "n_im", ")", ")", ")", ")", "\n", "if", "temp_im", "is", "not", "None", ":", "\n", "                                ", "utils", ".", "save_volume", "(", "temp_im", ",", "aff_im", ",", "h_im", ",", "os", ".", "path", ".", "join", "(", "image_result_dir", ",", "\n", "os", ".", "path", ".", "basename", "(", "path_image", ".", "replace", "(", "'.nii.gz'", ",", "'_%d.nii.gz'", "%", "n_im", ")", ")", ")", ")", "\n", "", "", "", "else", ":", "\n", "                        ", "utils", ".", "save_volume", "(", "temp_im", ",", "aff_im", ",", "h_im", ",", "os", ".", "path", ".", "join", "(", "image_result_dir", ",", "\n", "os", ".", "path", ".", "basename", "(", "path_image", ".", "replace", "(", "'.nii.gz'", ",", "'_%d.nii.gz'", "%", "n_im", ")", ")", ")", ")", "\n", "\n", "", "", "elif", "n_dims", "==", "3", ":", "\n", "                    ", "for", "k", "in", "range", "(", "n_crop", "[", "2", "]", ")", ":", "\n", "                        ", "k", "*=", "patch_shape", "[", "2", "]", "\n", "\n", "# crop volumes", "\n", "if", "lab", "is", "not", "None", ":", "\n", "                            ", "temp_la", "=", "lab", "[", "i", ":", "i", "+", "patch_shape", "[", "0", "]", ",", "j", ":", "j", "+", "patch_shape", "[", "1", "]", ",", "k", ":", "k", "+", "patch_shape", "[", "2", "]", ",", "...", "]", "\n", "", "else", ":", "\n", "                            ", "temp_la", "=", "None", "\n", "", "if", "im", "is", "not", "None", ":", "\n", "                            ", "temp_im", "=", "im", "[", "i", ":", "i", "+", "patch_shape", "[", "0", "]", ",", "j", ":", "j", "+", "patch_shape", "[", "1", "]", ",", "k", ":", "k", "+", "patch_shape", "[", "2", "]", ",", "...", "]", "\n", "", "else", ":", "\n", "                            ", "temp_im", "=", "None", "\n", "\n", "# write patches", "\n", "", "if", "temp_la", "is", "not", "None", ":", "\n", "                            ", "if", "full_background", "|", "(", "not", "(", "temp_la", "==", "0", ")", ".", "all", "(", ")", ")", ":", "\n", "                                ", "n_im", "+=", "1", "\n", "utils", ".", "save_volume", "(", "temp_la", ",", "aff_lab", ",", "h_lab", ",", "os", ".", "path", ".", "join", "(", "labels_result_dir", ",", "\n", "os", ".", "path", ".", "basename", "(", "path_label", ".", "replace", "(", "'.nii.gz'", ",", "'_%d.nii.gz'", "%", "n_im", ")", ")", ")", ")", "\n", "if", "temp_im", "is", "not", "None", ":", "\n", "                                    ", "utils", ".", "save_volume", "(", "temp_im", ",", "aff_im", ",", "h_im", ",", "os", ".", "path", ".", "join", "(", "image_result_dir", ",", "\n", "os", ".", "path", ".", "basename", "(", "path_image", ".", "replace", "(", "'.nii.gz'", ",", "\n", "'_%d.nii.gz'", "%", "n_im", ")", ")", ")", ")", "\n", "", "", "", "else", ":", "\n", "                            ", "utils", ".", "save_volume", "(", "temp_im", ",", "aff_im", ",", "h_im", ",", "os", ".", "path", ".", "join", "(", "image_result_dir", ",", "\n", "os", ".", "path", ".", "basename", "(", "path_image", ".", "replace", "(", "'.nii.gz'", ",", "'_%d.nii.gz'", "%", "n_im", ")", ")", ")", ")", "\n", "\n", "", "", "", "", "", "if", "remove_after_dividing", ":", "\n", "            ", "if", "path_image", "is", "not", "None", ":", "\n", "                ", "os", ".", "remove", "(", "path_image", ")", "\n", "", "if", "path_label", "is", "not", "None", ":", "\n", "                ", "os", ".", "remove", "(", "path_label", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.__init__": [[835, 857], ["numpy.zeros", "time.time", "time.time", "len", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "n_iterations", ",", "spacing", "=", "10", ",", "text", "=", "'processing'", ",", "print_time", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param n_iterations: total number of iterations of the for loop.\n        :param spacing: frequency at which the update info will be printed on screen.\n        :param text: text to print. Default is processing.\n        :param print_time: whether to print the estimated remaining time. Default is False.\n        \"\"\"", "\n", "\n", "# loop parameters", "\n", "self", ".", "n_iterations", "=", "n_iterations", "\n", "self", ".", "spacing", "=", "spacing", "\n", "\n", "# text parameters", "\n", "self", ".", "text", "=", "text", "\n", "self", ".", "print_time", "=", "print_time", "\n", "self", ".", "print_previous_time", "=", "False", "\n", "self", ".", "align", "=", "len", "(", "str", "(", "self", ".", "n_iterations", ")", ")", "*", "2", "+", "1", "+", "3", "\n", "\n", "# timing parameters", "\n", "self", ".", "iteration_durations", "=", "np", ".", "zeros", "(", "(", "n_iterations", ",", ")", ")", "\n", "self", ".", "start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "previous", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update": [[858, 884], ["time.time", "print", "str", "numpy.max", "numpy.mean", "int", "print", "str", "str", "print", "print", "datetime.timedelta"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "idx", ")", ":", "\n", "\n", "# time iteration", "\n", "        ", "now", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "iteration_durations", "[", "idx", "]", "=", "now", "-", "self", ".", "previous", "\n", "self", ".", "previous", "=", "now", "\n", "\n", "# print text", "\n", "if", "idx", "==", "0", ":", "\n", "            ", "print", "(", "self", ".", "text", "+", "' 1/{}'", ".", "format", "(", "self", ".", "n_iterations", ")", ")", "\n", "", "elif", "idx", "%", "self", ".", "spacing", "==", "self", ".", "spacing", "-", "1", ":", "\n", "            ", "iteration", "=", "str", "(", "idx", "+", "1", ")", "+", "'/'", "+", "str", "(", "self", ".", "n_iterations", ")", "\n", "if", "self", ".", "print_time", ":", "\n", "# estimate remaining time", "\n", "                ", "max_duration", "=", "np", ".", "max", "(", "self", ".", "iteration_durations", ")", "\n", "average_duration", "=", "np", ".", "mean", "(", "self", ".", "iteration_durations", "[", "self", ".", "iteration_durations", ">", ".01", "*", "max_duration", "]", ")", "\n", "remaining_time", "=", "int", "(", "average_duration", "*", "(", "self", ".", "n_iterations", "-", "idx", ")", ")", "\n", "# print total remaining time only if it is greater than 1s or if it was previously printed", "\n", "if", "(", "remaining_time", ">", "1", ")", "|", "self", ".", "print_previous_time", ":", "\n", "                    ", "eta", "=", "str", "(", "timedelta", "(", "seconds", "=", "remaining_time", ")", ")", "\n", "print", "(", "self", ".", "text", "+", "' {:<{x}} remaining time: {}'", ".", "format", "(", "iteration", ",", "eta", ",", "x", "=", "self", ".", "align", ")", ")", "\n", "self", ".", "print_previous_time", "=", "True", "\n", "", "else", ":", "\n", "                    ", "print", "(", "self", ".", "text", "+", "' {}'", ".", "format", "(", "iteration", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "self", ".", "text", "+", "' {}'", ".", "format", "(", "iteration", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume": [[76, 118], ["path_volume.endswith", "path_volume.endswith", "nibabel.load", "numpy.eye", "nibabel.Nifti1Header", "np.squeeze.astype", "utils.get_dims", "edit_volumes.align_volume_to_ref", "numpy.squeeze", "nib.load.get_data", "numpy.load", "numpy.squeeze", "list", "nib.load.get_data"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref"], ["def", "load_volume", "(", "path_volume", ",", "im_only", "=", "True", ",", "squeeze", "=", "True", ",", "dtype", "=", "None", ",", "aff_ref", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Load volume file.\n    :param path_volume: path of the volume to load. Can either be a nii, nii.gz, mgz, or npz format.\n    If npz format, 1) the variable name is assumed to be 'vol_data',\n    2) the volume is associated with a identity affine matrix and blank header.\n    :param im_only: (optional) if False, the function also returns the affine matrix and header of the volume.\n    :param squeeze: (optional) whether to squeeze the volume when loading.\n    :param dtype: (optional) if not None, convert the loaded volume to this numpy dtype.\n    :param aff_ref: (optional) If not None, the loaded volume is aligned to this affine matrix.\n    The returned affine matrix is also given in this new space. Must be a numpy array of dimension 4x4.\n    :return: the volume, with corresponding affine matrix and header if im_only is False.\n    \"\"\"", "\n", "assert", "path_volume", ".", "endswith", "(", "(", "'.nii'", ",", "'.nii.gz'", ",", "'.mgz'", ",", "'.npz'", ")", ")", ",", "'Unknown data file: %s'", "%", "path_volume", "\n", "\n", "if", "path_volume", ".", "endswith", "(", "(", "'.nii'", ",", "'.nii.gz'", ",", "'.mgz'", ")", ")", ":", "\n", "        ", "x", "=", "nib", ".", "load", "(", "path_volume", ")", "\n", "if", "squeeze", ":", "\n", "            ", "volume", "=", "np", ".", "squeeze", "(", "x", ".", "get_data", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "volume", "=", "x", ".", "get_data", "(", ")", "\n", "", "aff", "=", "x", ".", "affine", "\n", "header", "=", "x", ".", "header", "\n", "", "else", ":", "# npz", "\n", "        ", "volume", "=", "np", ".", "load", "(", "path_volume", ")", "[", "'vol_data'", "]", "\n", "if", "squeeze", ":", "\n", "            ", "volume", "=", "np", ".", "squeeze", "(", "volume", ")", "\n", "", "aff", "=", "np", ".", "eye", "(", "4", ")", "\n", "header", "=", "nib", ".", "Nifti1Header", "(", ")", "\n", "", "if", "dtype", "is", "not", "None", ":", "\n", "        ", "volume", "=", "volume", ".", "astype", "(", "dtype", "=", "dtype", ")", "\n", "\n", "# align image to reference affine matrix", "\n", "", "if", "aff_ref", "is", "not", "None", ":", "\n", "        ", "from", ".", "import", "edit_volumes", "# the import is done here to avoid import loops", "\n", "n_dims", ",", "_", "=", "get_dims", "(", "list", "(", "volume", ".", "shape", ")", ",", "max_channels", "=", "10", ")", "\n", "volume", ",", "aff", "=", "edit_volumes", ".", "align_volume_to_ref", "(", "volume", ",", "aff", ",", "aff_ref", "=", "aff_ref", ",", "return_aff", "=", "True", ",", "n_dims", "=", "n_dims", ")", "\n", "\n", "", "if", "im_only", ":", "\n", "        ", "return", "volume", "\n", "", "else", ":", "\n", "        ", "return", "volume", ",", "aff", ",", "header", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.save_volume": [[120, 154], ["utils.mkdir", "os.path.dirname", "numpy.savez_compressed", "isinstance", "nibabel.Nifti1Image", "nibabel.save", "nibabel.Nifti1Header", "nib.Nifti1Image.set_data_dtype", "utils.reformat_to_list", "nib.Nifti1Image.header.set_zooms", "numpy.array", "numpy.eye", "utils.get_dims"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims"], ["", "", "def", "save_volume", "(", "volume", ",", "aff", ",", "header", ",", "path", ",", "res", "=", "None", ",", "dtype", "=", "None", ",", "n_dims", "=", "3", ")", ":", "\n", "    ", "\"\"\"\n    Save a volume.\n    :param volume: volume to save\n    :param aff: affine matrix of the volume to save. If aff is None, the volume is saved with an identity affine matrix.\n    aff can also be set to 'FS', in which case the volume is saved with the affine matrix of FreeSurfer outputs.\n    :param header: header of the volume to save. If None, the volume is saved with a blank header.\n    :param path: path where to save the volume.\n    :param res: (optional) update the resolution in the header before saving the volume.\n    :param dtype: (optional) numpy dtype for the saved volume.\n    :param n_dims: (optional) number of dimensions, to avoid confusion in multi-channel case. Default is None, where\n    n_dims is automatically inferred.\n    \"\"\"", "\n", "\n", "mkdir", "(", "os", ".", "path", ".", "dirname", "(", "path", ")", ")", "\n", "if", "'.npz'", "in", "path", ":", "\n", "        ", "np", ".", "savez_compressed", "(", "path", ",", "vol_data", "=", "volume", ")", "\n", "", "else", ":", "\n", "        ", "if", "header", "is", "None", ":", "\n", "            ", "header", "=", "nib", ".", "Nifti1Header", "(", ")", "\n", "", "if", "isinstance", "(", "aff", ",", "str", ")", ":", "\n", "            ", "if", "aff", "==", "'FS'", ":", "\n", "                ", "aff", "=", "np", ".", "array", "(", "[", "[", "-", "1", ",", "0", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "1", ",", "0", "]", ",", "[", "0", ",", "-", "1", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "", "", "elif", "aff", "is", "None", ":", "\n", "            ", "aff", "=", "np", ".", "eye", "(", "4", ")", "\n", "", "nifty", "=", "nib", ".", "Nifti1Image", "(", "volume", ",", "aff", ",", "header", ")", "\n", "if", "dtype", "is", "not", "None", ":", "\n", "            ", "nifty", ".", "set_data_dtype", "(", "dtype", ")", "\n", "", "if", "res", "is", "not", "None", ":", "\n", "            ", "if", "n_dims", "is", "None", ":", "\n", "                ", "n_dims", ",", "_", "=", "get_dims", "(", "volume", ".", "shape", ")", "\n", "", "res", "=", "reformat_to_list", "(", "res", ",", "length", "=", "n_dims", ",", "dtype", "=", "None", ")", "\n", "nifty", ".", "header", ".", "set_zooms", "(", "res", ")", "\n", "", "nib", ".", "save", "(", "nifty", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_volume_info": [[156, 199], ["utils.load_volume", "list", "utils.get_dims", "numpy.array", "edit_volumes.get_ras_axes", "edit_volumes.get_ras_axes", "edit_volumes.align_volume_to_ref", "numpy.array", "numpy.array", "im_shape.tolist.tolist", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_ras_axes", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.get_ras_axes", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_volumes.align_volume_to_ref"], ["", "", "def", "get_volume_info", "(", "path_volume", ",", "return_volume", "=", "False", ",", "aff_ref", "=", "None", ",", "max_channels", "=", "10", ")", ":", "\n", "    ", "\"\"\"\n    Gather information about a volume: shape, affine matrix, number of dimensions and channels, header, and resolution.\n    :param path_volume: path of the volume to get information form.\n    :param return_volume: (optional) whether to return the volume along with the information.\n    :param aff_ref: (optional) If not None, the loaded volume is aligned to this affine matrix.\n    All info relative to the volume is then given in this new space. Must be a numpy array of dimension 4x4.\n    :return: volume (if return_volume is true), and corresponding info. If aff_ref is not None, the returned aff is\n    the original one, i.e. the affine of the image before being aligned to aff_ref.\n    \"\"\"", "\n", "# read image", "\n", "im", ",", "aff", ",", "header", "=", "load_volume", "(", "path_volume", ",", "im_only", "=", "False", ")", "\n", "\n", "# understand if image is multichannel", "\n", "im_shape", "=", "list", "(", "im", ".", "shape", ")", "\n", "n_dims", ",", "n_channels", "=", "get_dims", "(", "im_shape", ",", "max_channels", "=", "max_channels", ")", "\n", "im_shape", "=", "im_shape", "[", ":", "n_dims", "]", "\n", "\n", "# get labels res", "\n", "if", "'.nii'", "in", "path_volume", ":", "\n", "        ", "data_res", "=", "np", ".", "array", "(", "header", "[", "'pixdim'", "]", "[", "1", ":", "n_dims", "+", "1", "]", ")", "\n", "", "elif", "'.mgz'", "in", "path_volume", ":", "\n", "        ", "data_res", "=", "np", ".", "array", "(", "header", "[", "'delta'", "]", ")", "# mgz image", "\n", "", "else", ":", "\n", "        ", "data_res", "=", "np", ".", "array", "(", "[", "1.0", "]", "*", "n_dims", ")", "\n", "\n", "# align to given affine matrix", "\n", "", "if", "aff_ref", "is", "not", "None", ":", "\n", "        ", "from", ".", "import", "edit_volumes", "# the import is done here to avoid import loops", "\n", "ras_axes", "=", "edit_volumes", ".", "get_ras_axes", "(", "aff", ",", "n_dims", "=", "n_dims", ")", "\n", "ras_axes_ref", "=", "edit_volumes", ".", "get_ras_axes", "(", "aff_ref", ",", "n_dims", "=", "n_dims", ")", "\n", "im", "=", "edit_volumes", ".", "align_volume_to_ref", "(", "im", ",", "aff", ",", "aff_ref", "=", "aff_ref", ",", "n_dims", "=", "n_dims", ")", "\n", "im_shape", "=", "np", ".", "array", "(", "im_shape", ")", "\n", "data_res", "=", "np", ".", "array", "(", "data_res", ")", "\n", "im_shape", "[", "ras_axes_ref", "]", "=", "im_shape", "[", "ras_axes", "]", "\n", "data_res", "[", "ras_axes_ref", "]", "=", "data_res", "[", "ras_axes", "]", "\n", "im_shape", "=", "im_shape", ".", "tolist", "(", ")", "\n", "\n", "# return info", "\n", "", "if", "return_volume", ":", "\n", "        ", "return", "im", ",", "im_shape", ",", "aff", ",", "n_dims", ",", "n_channels", ",", "header", ",", "data_res", "\n", "", "else", ":", "\n", "        ", "return", "im_shape", ",", "aff", ",", "n_dims", ",", "n_channels", ",", "header", ",", "data_res", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_list_labels": [[201, 275], ["numpy.array", "list", "list", "list", "numpy.concatenate", "numpy.save", "utils.reformat_to_list", "print", "utils.list_images_in_folder", "numpy.empty", "utils.LoopInfo", "enumerate", "Exception", "len", "len", "numpy.int32", "numpy.int32", "numpy.int32", "len", "utils.LoopInfo.update", "utils.load_volume", "numpy.unique", "numpy.unique().astype", "sorted", "sorted", "sorted", "list.append", "len", "len", "len", "len", "numpy.unique", "list.append", "Exception", "numpy.concatenate", "list.append"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.LoopInfo.update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_volume"], ["", "", "def", "get_list_labels", "(", "label_list", "=", "None", ",", "labels_dir", "=", "None", ",", "save_label_list", "=", "None", ",", "FS_sort", "=", "False", ")", ":", "\n", "    ", "\"\"\"This function reads or computes a list of all label values used in a set of label maps.\n    It can also sort all labels according to FreeSurfer lut.\n    :param label_list: (optional) already computed label_list. Can be a sequence, a 1d numpy array, or the path to\n    a numpy 1d array.\n    :param labels_dir: (optional) if path_label_list is None, the label list is computed by reading all the label maps\n    in the given folder. Can also be the path to a single label map.\n    :param save_label_list: (optional) path where to save the label list.\n    :param FS_sort: (optional) whether to sort label values according to the FreeSurfer classification.\n    If true, the label values will be ordered as follows: neutral labels first (i.e. non-sided), left-side labels,\n    and right-side labels. If FS_sort is True, this function also returns the number of neutral labels in label_list.\n    :return: the label list (numpy 1d array), and the number of neutral (i.e. non-sided) labels if FS_sort is True.\n    If one side of the brain is not represented at all in label_list, all labels are considered as neutral, and\n    n_neutral_labels = len(label_list).\n    \"\"\"", "\n", "\n", "# load label list if previously computed", "\n", "if", "label_list", "is", "not", "None", ":", "\n", "        ", "label_list", "=", "np", ".", "array", "(", "reformat_to_list", "(", "label_list", ",", "load_as_numpy", "=", "True", ",", "dtype", "=", "'int'", ")", ")", "\n", "\n", "# compute label list from all label files", "\n", "", "elif", "labels_dir", "is", "not", "None", ":", "\n", "        ", "print", "(", "'Compiling list of unique labels'", ")", "\n", "# go through all labels files and compute unique list of labels", "\n", "labels_paths", "=", "list_images_in_folder", "(", "labels_dir", ")", "\n", "label_list", "=", "np", ".", "empty", "(", "0", ")", "\n", "loop_info", "=", "LoopInfo", "(", "len", "(", "labels_paths", ")", ",", "10", ",", "'processing'", ",", "print_time", "=", "True", ")", "\n", "for", "lab_idx", ",", "path", "in", "enumerate", "(", "labels_paths", ")", ":", "\n", "            ", "loop_info", ".", "update", "(", "lab_idx", ")", "\n", "y", "=", "load_volume", "(", "path", ",", "dtype", "=", "'int32'", ")", "\n", "y_unique", "=", "np", ".", "unique", "(", "y", ")", "\n", "label_list", "=", "np", ".", "unique", "(", "np", ".", "concatenate", "(", "(", "label_list", ",", "y_unique", ")", ")", ")", ".", "astype", "(", "'int'", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'either label_list, path_label_list or labels_dir should be provided'", ")", "\n", "\n", "# sort labels in neutral/left/right according to FS labels", "\n", "", "n_neutral_labels", "=", "0", "\n", "if", "FS_sort", ":", "\n", "        ", "neutral_FS_labels", "=", "[", "0", ",", "14", ",", "15", ",", "16", ",", "21", ",", "22", ",", "23", ",", "24", ",", "72", ",", "77", ",", "80", ",", "85", ",", "100", ",", "101", ",", "102", ",", "103", ",", "104", ",", "105", ",", "106", ",", "107", ",", "108", ",", "\n", "109", ",", "165", ",", "200", ",", "201", ",", "202", ",", "203", ",", "204", ",", "205", ",", "206", ",", "207", ",", "208", ",", "209", ",", "210", ",", "\n", "251", ",", "252", ",", "253", ",", "254", ",", "255", ",", "258", ",", "259", ",", "260", ",", "331", ",", "332", ",", "333", ",", "334", ",", "335", ",", "336", ",", "337", ",", "338", ",", "339", ",", "340", ",", "\n", "502", ",", "506", ",", "507", ",", "508", ",", "509", ",", "511", ",", "512", ",", "514", ",", "515", ",", "516", ",", "517", ",", "530", ",", "\n", "531", ",", "532", ",", "533", ",", "534", ",", "535", ",", "536", ",", "537", "]", "\n", "neutral", "=", "list", "(", ")", "\n", "left", "=", "list", "(", ")", "\n", "right", "=", "list", "(", ")", "\n", "for", "la", "in", "label_list", ":", "\n", "            ", "if", "la", "in", "neutral_FS_labels", ":", "\n", "                ", "if", "la", "not", "in", "neutral", ":", "\n", "                    ", "neutral", ".", "append", "(", "la", ")", "\n", "", "", "elif", "(", "0", "<", "la", "<", "14", ")", "|", "(", "16", "<", "la", "<", "21", ")", "|", "(", "24", "<", "la", "<", "40", ")", "|", "(", "135", "<", "la", "<", "138", ")", "|", "(", "20100", "<", "la", "<", "20110", ")", ":", "\n", "                ", "if", "la", "not", "in", "left", ":", "\n", "                    ", "left", ".", "append", "(", "la", ")", "\n", "", "", "elif", "(", "39", "<", "la", "<", "72", ")", "|", "(", "162", "<", "la", "<", "165", ")", "|", "(", "20000", "<", "la", "<", "20010", ")", ":", "\n", "                ", "if", "la", "not", "in", "right", ":", "\n", "                    ", "right", ".", "append", "(", "la", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'label {} not in our current FS classification, '", "\n", "'please update get_list_labels in utils.py'", ".", "format", "(", "la", ")", ")", "\n", "", "", "label_list", "=", "np", ".", "concatenate", "(", "[", "sorted", "(", "neutral", ")", ",", "sorted", "(", "left", ")", ",", "sorted", "(", "right", ")", "]", ")", "\n", "if", "(", "(", "len", "(", "left", ")", ">", "0", ")", "&", "(", "len", "(", "right", ")", ">", "0", ")", ")", "|", "(", "(", "len", "(", "left", ")", "==", "0", ")", "&", "(", "len", "(", "right", ")", "==", "0", ")", ")", ":", "\n", "            ", "n_neutral_labels", "=", "len", "(", "neutral", ")", "\n", "", "else", ":", "\n", "            ", "n_neutral_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# save labels if specified", "\n", "", "", "if", "save_label_list", "is", "not", "None", ":", "\n", "        ", "np", ".", "save", "(", "save_label_list", ",", "np", ".", "int32", "(", "label_list", ")", ")", "\n", "\n", "", "if", "FS_sort", ":", "\n", "        ", "return", "np", ".", "int32", "(", "label_list", ")", ",", "n_neutral_labels", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "int32", "(", "label_list", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path": [[277, 284], ["isinstance", "os.path.isfile", "numpy.load"], "function", ["None"], ["", "", "def", "load_array_if_path", "(", "var", ",", "load_as_numpy", "=", "True", ")", ":", "\n", "    ", "\"\"\"If var is a string and load_as_numpy is True, this function loads the array writen at the path indicated by var.\n    Otherwise it simply returns var as it is.\"\"\"", "\n", "if", "(", "isinstance", "(", "var", ",", "str", ")", ")", "&", "load_as_numpy", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "var", ")", ",", "'No such path: %s'", "%", "var", "\n", "var", "=", "np", ".", "load", "(", "var", ")", "\n", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.write_pickle": [[286, 291], ["open", "pickle.Pickler", "pickle.Pickler.dump"], "function", ["None"], ["", "def", "write_pickle", "(", "filepath", ",", "obj", ")", ":", "\n", "    ", "\"\"\" write a python object with a pickle at a given path\"\"\"", "\n", "with", "open", "(", "filepath", ",", "'wb'", ")", "as", "file", ":", "\n", "        ", "pickler", "=", "pickle", ".", "Pickler", "(", "file", ")", "\n", "pickler", ".", "dump", "(", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.read_pickle": [[293, 298], ["open", "pickle.Unpickler", "pickle.Unpickler.load"], "function", ["None"], ["", "", "def", "read_pickle", "(", "filepath", ")", ":", "\n", "    ", "\"\"\" read a python object with a pickle\"\"\"", "\n", "with", "open", "(", "filepath", ",", "'rb'", ")", "as", "file", ":", "\n", "        ", "unpickler", "=", "pickle", ".", "Unpickler", "(", "file", ")", "\n", "return", "unpickler", ".", "load", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.write_model_summary": [[300, 304], ["open", "model.summary", "fh.write"], "function", ["None"], ["", "", "def", "write_model_summary", "(", "model", ",", "filepath", "=", "'./model_summary.txt'", ",", "line_length", "=", "150", ")", ":", "\n", "    ", "\"\"\"Write the summary of a keras model at a given path, with a given length for each line\"\"\"", "\n", "with", "open", "(", "filepath", ",", "'w'", ")", "as", "fh", ":", "\n", "        ", "model", ".", "summary", "(", "print_fn", "=", "lambda", "x", ":", "fh", ".", "write", "(", "x", "+", "'\\n'", ")", ",", "line_length", "=", "line_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list": [[309, 361], ["utils.load_array_if_path", "isinstance", "isinstance", "isinstance", "TypeError", "list", "isinstance", "isinstance", "len", "int", "numpy.squeeze().tolist", "isinstance", "len", "ValueError", "float", "bool", "ValueError", "numpy.squeeze", "str"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path"], ["", "", "def", "reformat_to_list", "(", "var", ",", "length", "=", "None", ",", "load_as_numpy", "=", "False", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"This function takes a variable and reformat it into a list of desired\n    length and type (int, float, bool, str).\n    If variable is a string, and load_as_numpy is True, it will be loaded as a numpy array.\n    If variable is None, this funtion returns None.\n    :param var: a str, int, float, list, tuple, or numpy array\n    :param length: (optional) if var is a single item, it will be replicated to a list of this length\n    :param load_as_numpy: (optional) whether var is the path to a numpy array\n    :param dtype: (optional) convert all item to this type. Can be 'int', 'float', 'bool', or 'str'\n    :return: reformated list\n    \"\"\"", "\n", "\n", "# convert to list", "\n", "if", "var", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "var", "=", "load_array_if_path", "(", "var", ",", "load_as_numpy", "=", "load_as_numpy", ")", "\n", "if", "isinstance", "(", "var", ",", "(", "int", ",", "float", ",", "np", ".", "int", ",", "np", ".", "int32", ",", "np", ".", "int64", ",", "np", ".", "float", ",", "np", ".", "float32", ",", "np", ".", "float64", ")", ")", ":", "\n", "        ", "var", "=", "[", "var", "]", "\n", "", "elif", "isinstance", "(", "var", ",", "tuple", ")", ":", "\n", "        ", "var", "=", "list", "(", "var", ")", "\n", "", "elif", "isinstance", "(", "var", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "var", ".", "shape", "==", "(", "1", ",", ")", ":", "\n", "            ", "var", "=", "[", "var", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "            ", "var", "=", "np", ".", "squeeze", "(", "var", ")", ".", "tolist", "(", ")", "\n", "", "", "elif", "isinstance", "(", "var", ",", "str", ")", ":", "\n", "        ", "var", "=", "[", "var", "]", "\n", "", "elif", "isinstance", "(", "var", ",", "bool", ")", ":", "\n", "        ", "var", "=", "[", "var", "]", "\n", "", "if", "isinstance", "(", "var", ",", "list", ")", ":", "\n", "        ", "if", "length", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "var", ")", "==", "1", ":", "\n", "                ", "var", "=", "var", "*", "length", "\n", "", "elif", "len", "(", "var", ")", "!=", "length", ":", "\n", "                ", "raise", "ValueError", "(", "'if var is a list/tuple/numpy array, it should be of length 1 or {0}, '", "\n", "'had {1}'", ".", "format", "(", "length", ",", "var", ")", ")", "\n", "", "", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'var should be an int, float, tuple, list, numpy array, or path to numpy array'", ")", "\n", "\n", "# convert items type", "\n", "", "if", "dtype", "is", "not", "None", ":", "\n", "        ", "if", "dtype", "==", "'int'", ":", "\n", "            ", "var", "=", "[", "int", "(", "v", ")", "for", "v", "in", "var", "]", "\n", "", "elif", "dtype", "==", "'float'", ":", "\n", "            ", "var", "=", "[", "float", "(", "v", ")", "for", "v", "in", "var", "]", "\n", "", "elif", "dtype", "==", "'bool'", ":", "\n", "            ", "var", "=", "[", "bool", "(", "v", ")", "for", "v", "in", "var", "]", "\n", "", "elif", "dtype", "==", "'str'", ":", "\n", "            ", "var", "=", "[", "str", "(", "v", ")", "for", "v", "in", "var", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"dtype should be 'str', 'float', 'int', or 'bool'; had {}\"", ".", "format", "(", "dtype", ")", ")", "\n", "", "", "return", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_n_channels_array": [[363, 388], ["isinstance", "isinstance", "numpy.round", "numpy.load", "utils.reformat_to_list", "numpy.tile", "isinstance", "numpy.array", "TypeError", "np.tile.reshape", "numpy.tile", "numpy.squeeze", "np.tile.reshape", "ValueError"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list"], ["", "def", "reformat_to_n_channels_array", "(", "var", ",", "n_dims", "=", "3", ",", "n_channels", "=", "1", ")", ":", "\n", "    ", "\"\"\"This function takes an int, float, list or tuple and reformat it to an array of shape (n_channels, n_dims).\n    If resolution is a str, it will be assumed to be the path of a numpy array.\n    If resolution is a numpy array, it will be checked to have shape (n_channels, n_dims).\n    Finally if resolution is None, this function returns None as well.\"\"\"", "\n", "if", "var", "is", "None", ":", "\n", "        ", "return", "[", "None", "]", "*", "n_channels", "\n", "", "if", "isinstance", "(", "var", ",", "str", ")", ":", "\n", "        ", "var", "=", "np", ".", "load", "(", "var", ")", "\n", "# convert to numpy array", "\n", "", "if", "isinstance", "(", "var", ",", "(", "int", ",", "float", ",", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "var", "=", "reformat_to_list", "(", "var", ",", "n_dims", ")", "\n", "var", "=", "np", ".", "tile", "(", "np", ".", "array", "(", "var", ")", ",", "(", "n_channels", ",", "1", ")", ")", "\n", "# check shape if numpy array", "\n", "", "elif", "isinstance", "(", "var", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "n_channels", "==", "1", ":", "\n", "            ", "var", "=", "var", ".", "reshape", "(", "(", "1", ",", "n_dims", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "np", ".", "squeeze", "(", "var", ")", ".", "shape", "==", "(", "n_dims", ",", ")", ":", "\n", "                ", "var", "=", "np", ".", "tile", "(", "var", ".", "reshape", "(", "(", "1", ",", "n_dims", ")", ")", ",", "(", "n_channels", ",", "1", ")", ")", "\n", "", "elif", "var", ".", "shape", "!=", "(", "n_channels", ",", "n_dims", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'if array, var should be {0} or {1}'", ".", "format", "(", "(", "1", ",", "n_dims", ")", ",", "(", "n_channels", ",", "n_dims", ")", ")", ")", "\n", "", "", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'var should be int, float, list, tuple or ndarray'", ")", "\n", "", "return", "np", ".", "round", "(", "var", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_images_in_folder": [[393, 410], ["os.path.basename", "os.path.isfile", "os.path.isdir", "sorted", "Exception", "len", "glob.glob", "glob.glob", "os.path.join", "glob.glob", "glob.glob", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "list_images_in_folder", "(", "path_dir", ",", "include_single_image", "=", "True", ")", ":", "\n", "    ", "\"\"\"List all files with extension nii, nii.gz, mgz, or npz whithin a folder.\"\"\"", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "path_dir", ")", "\n", "if", "include_single_image", "&", "(", "(", "'.nii.gz'", "in", "basename", ")", "|", "(", "'.nii'", "in", "basename", ")", "|", "(", "'.mgz'", "in", "basename", ")", "|", "(", "'.npz'", "in", "basename", ")", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "path_dir", ")", ",", "'file %s does not exist'", "%", "path_dir", "\n", "list_images", "=", "[", "path_dir", "]", "\n", "", "else", ":", "\n", "        ", "if", "os", ".", "path", ".", "isdir", "(", "path_dir", ")", ":", "\n", "            ", "list_images", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "'*nii.gz'", ")", ")", "+", "\n", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "'*nii'", ")", ")", "+", "\n", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "'*.mgz'", ")", ")", "+", "\n", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "'*.npz'", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'extension not supported for %s, only use: nii.gz, .nii, .mgz, or .npz'", "%", "path_dir", ")", "\n", "", "assert", "len", "(", "list_images", ")", ">", "0", ",", "'no .nii, .nii.gz, .mgz or .npz image could be found in %s'", "%", "path_dir", "\n", "", "return", "list_images", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_files": [[412, 444], ["isinstance", "sorted", "sorted", "isinstance", "list", "sorted", "sorted", "os.path.join", "isinstance", "Exception", "os.listdir", "os.path.isfile", "os.listdir", "os.path.isfile", "os.path.join", "os.path.join", "os.path.basename"], "function", ["None"], ["", "def", "list_files", "(", "path_dir", ",", "whole_path", "=", "True", ",", "expr", "=", "None", ",", "cond_type", "=", "'or'", ")", ":", "\n", "    ", "\"\"\"This function returns a list of files contained in a folder, whith possible regexp.\n    :param path_dir: path of a folder\n    :param whole_path: (optional) whether to return whole path or just the filenames.\n    :param expr: (optional) regexp for files to list. Can be a str or a list of str.\n    :param cond_type: (optional) if exp is a list, specify the logical link between expressions in exp.\n    Can be 'or', or 'and'.\n    :return: a list of files\n    \"\"\"", "\n", "assert", "isinstance", "(", "whole_path", ",", "bool", ")", ",", "\"whole_path should be bool\"", "\n", "assert", "cond_type", "in", "[", "'or'", ",", "'and'", "]", ",", "\"cond_type should be either 'or', or 'and'\"", "\n", "if", "whole_path", ":", "\n", "        ", "files_list", "=", "sorted", "(", "[", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", "for", "f", "in", "os", ".", "listdir", "(", "path_dir", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "files_list", "=", "sorted", "(", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "path_dir", ")", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", ")", "]", ")", "\n", "", "if", "expr", "is", "not", "None", ":", "# assumed to be either str or list of str", "\n", "        ", "if", "isinstance", "(", "expr", ",", "str", ")", ":", "\n", "            ", "expr", "=", "[", "expr", "]", "\n", "", "elif", "not", "isinstance", "(", "expr", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"if specified, 'expr' should be a string or list of strings.\"", ")", "\n", "", "matched_list_files", "=", "list", "(", ")", "\n", "for", "match", "in", "expr", ":", "\n", "            ", "tmp_matched_files_list", "=", "sorted", "(", "[", "f", "for", "f", "in", "files_list", "if", "match", "in", "os", ".", "path", ".", "basename", "(", "f", ")", "]", ")", "\n", "if", "cond_type", "==", "'or'", ":", "\n", "                ", "files_list", "=", "[", "f", "for", "f", "in", "files_list", "if", "f", "not", "in", "tmp_matched_files_list", "]", "\n", "matched_list_files", "+=", "tmp_matched_files_list", "\n", "", "elif", "cond_type", "==", "'and'", ":", "\n", "                ", "files_list", "=", "tmp_matched_files_list", "\n", "matched_list_files", "=", "tmp_matched_files_list", "\n", "", "", "files_list", "=", "sorted", "(", "matched_list_files", ")", "\n", "", "return", "files_list", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.list_subfolders": [[446, 478], ["isinstance", "sorted", "sorted", "isinstance", "list", "sorted", "sorted", "os.path.join", "isinstance", "Exception", "os.listdir", "os.path.isdir", "os.listdir", "os.path.isdir", "os.path.join", "os.path.join", "os.path.basename"], "function", ["None"], ["", "def", "list_subfolders", "(", "path_dir", ",", "whole_path", "=", "True", ",", "expr", "=", "None", ",", "cond_type", "=", "'or'", ")", ":", "\n", "    ", "\"\"\"This function returns a list of subfolders contained in a folder, with possible regexp.\n    :param path_dir: path of a folder\n    :param whole_path: (optional) whether to return whole path or just the subfolder names.\n    :param expr: (optional) regexp for files to list. Can be a str or a list of str.\n    :param cond_type: (optional) if exp is a list, specify the logical link between expressions in exp.\n    Can be 'or', or 'and'.\n    :return: a list of subfolders\n    \"\"\"", "\n", "assert", "isinstance", "(", "whole_path", ",", "bool", ")", ",", "\"whole_path should be bool\"", "\n", "assert", "cond_type", "in", "[", "'or'", ",", "'and'", "]", ",", "\"cond_type should be either 'or', or 'and'\"", "\n", "if", "whole_path", ":", "\n", "        ", "subdirs_list", "=", "sorted", "(", "[", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", "for", "f", "in", "os", ".", "listdir", "(", "path_dir", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "subdirs_list", "=", "sorted", "(", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "path_dir", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", ")", "]", ")", "\n", "", "if", "expr", "is", "not", "None", ":", "# assumed to be either str or list of str", "\n", "        ", "if", "isinstance", "(", "expr", ",", "str", ")", ":", "\n", "            ", "expr", "=", "[", "expr", "]", "\n", "", "elif", "not", "isinstance", "(", "expr", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"if specified, 'expr' should be a string or list of strings.\"", ")", "\n", "", "matched_list_subdirs", "=", "list", "(", ")", "\n", "for", "match", "in", "expr", ":", "\n", "            ", "tmp_matched_list_subdirs", "=", "sorted", "(", "[", "f", "for", "f", "in", "subdirs_list", "if", "match", "in", "os", ".", "path", ".", "basename", "(", "f", ")", "]", ")", "\n", "if", "cond_type", "==", "'or'", ":", "\n", "                ", "subdirs_list", "=", "[", "f", "for", "f", "in", "subdirs_list", "if", "f", "not", "in", "tmp_matched_list_subdirs", "]", "\n", "matched_list_subdirs", "+=", "tmp_matched_list_subdirs", "\n", "", "elif", "cond_type", "==", "'and'", ":", "\n", "                ", "subdirs_list", "=", "tmp_matched_list_subdirs", "\n", "matched_list_subdirs", "=", "tmp_matched_list_subdirs", "\n", "", "", "subdirs_list", "=", "sorted", "(", "matched_list_subdirs", ")", "\n", "", "return", "subdirs_list", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_image_extension": [[480, 490], ["os.path.basename"], "function", ["None"], ["", "def", "get_image_extension", "(", "path", ")", ":", "\n", "    ", "name", "=", "os", ".", "path", ".", "basename", "(", "path", ")", "\n", "if", "name", "[", "-", "7", ":", "]", "==", "'.nii.gz'", ":", "\n", "        ", "return", "'nii.gz'", "\n", "", "elif", "name", "[", "-", "4", ":", "]", "==", "'.mgz'", ":", "\n", "        ", "return", "'mgz'", "\n", "", "elif", "name", "[", "-", "4", ":", "]", "==", "'.nii'", ":", "\n", "        ", "return", "'nii'", "\n", "", "elif", "name", "[", "-", "4", ":", "]", "==", "'.npz'", ":", "\n", "        ", "return", "'npz'", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.strip_extension": [[492, 499], ["path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace"], "function", ["None"], ["", "", "def", "strip_extension", "(", "path", ")", ":", "\n", "    ", "\"\"\"Strip classical image extensions (.nii.gz, .nii, .mgz, .npz) from a filename.\"\"\"", "\n", "path", "=", "path", ".", "replace", "(", "'.nii.gz'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.nii'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.mgz'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.npz'", ",", "''", ")", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.strip_suffix": [[501, 528], ["path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace", "path.replace.replace"], "function", ["None"], ["", "def", "strip_suffix", "(", "path", ")", ":", "\n", "    ", "\"\"\"Strip classical image suffix from a filename.\"\"\"", "\n", "path", "=", "path", ".", "replace", "(", "'_aseg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'aseg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.aseg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_aseg_1'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_aseg_2'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'aseg_1_'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'aseg_2_'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_orig'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'orig'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.orig'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_norm'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'norm'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.norm'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_talairach'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'GSP_FS_4p5'", ",", "'GSP'", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.nii_crispSegmentation'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_crispSegmentation'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_seg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.seg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'seg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_seg_1'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_seg_2'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'seg_1_'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'seg_2_'", ",", "''", ")", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir": [[530, 540], ["os.path.isdir", "reversed", "os.path.isdir", "list_dir_to_create.append", "os.mkdir", "os.path.dirname", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir"], ["", "def", "mkdir", "(", "path_dir", ")", ":", "\n", "    ", "\"\"\"Recursively creates the current dir as well as its parent folders if they do not already exist.\"\"\"", "\n", "if", "path_dir", "[", "-", "1", "]", "==", "'/'", ":", "\n", "        ", "path_dir", "=", "path_dir", "[", ":", "-", "1", "]", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "path_dir", ")", ":", "\n", "        ", "list_dir_to_create", "=", "[", "path_dir", "]", "\n", "while", "not", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "dirname", "(", "list_dir_to_create", "[", "-", "1", "]", ")", ")", ":", "\n", "            ", "list_dir_to_create", ".", "append", "(", "os", ".", "path", ".", "dirname", "(", "list_dir_to_create", "[", "-", "1", "]", ")", ")", "\n", "", "for", "dir_to_create", "in", "reversed", "(", "list_dir_to_create", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_to_create", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkcmd": [[542, 546], ["str"], "function", ["None"], ["", "", "", "def", "mkcmd", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"Creates terminal command with provided inputs.\n    Example: mkcmd('mv', 'source', 'dest') will give 'mv source dest'.\"\"\"", "\n", "return", "' '", ".", "join", "(", "[", "str", "(", "arg", ")", "for", "arg", "in", "args", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_dims": [[551, 568], ["len", "len"], "function", ["None"], ["", "def", "get_dims", "(", "shape", ",", "max_channels", "=", "10", ")", ":", "\n", "    ", "\"\"\"Get the number of dimensions and channels from the shape of an array.\n    The number of dimensions is assumed to be the length of the shape, as long as the shape of the last dimension is\n    inferior or equal to max_channels (default 3).\n    :param shape: shape of an array. Can be a sequence or a 1d numpy array.\n    :param max_channels: maximum possible number of channels.\n    :return: the number of dimensions and channels associated with the provided shape.\n    example 1: get_dims([150, 150, 150], max_channels=10) = (3, 1)\n    example 2: get_dims([150, 150, 150, 3], max_channels=10) = (3, 3)\n    example 3: get_dims([150, 150, 150, 15], max_channels=10) = (4, 1), because 5>3\"\"\"", "\n", "if", "shape", "[", "-", "1", "]", "<=", "max_channels", ":", "\n", "        ", "n_dims", "=", "len", "(", "shape", ")", "-", "1", "\n", "n_channels", "=", "shape", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "n_dims", "=", "len", "(", "shape", ")", "\n", "n_channels", "=", "1", "\n", "", "return", "n_dims", ",", "n_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_resample_shape": [[570, 582], ["utils.reformat_to_list", "math.ceil", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "get_resample_shape", "(", "patch_shape", ",", "factor", ",", "n_channels", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute the shape of a resampled array given a shape factor.\n    :param patch_shape: size of the initial array (without number of channels).\n    :param factor: resampling factor. Can be a number, sequence, or 1d numpy array.\n    :param n_channels: (optional) if not None, add a number of channel at the end of the computed shape.\n    :return: list containing the shape of the input array after being resampled by the given factor.\n    \"\"\"", "\n", "factor", "=", "reformat_to_list", "(", "factor", ",", "length", "=", "len", "(", "patch_shape", ")", ")", "\n", "shape", "=", "[", "math", ".", "ceil", "(", "patch_shape", "[", "i", "]", "*", "factor", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "patch_shape", ")", ")", "]", "\n", "if", "n_channels", "is", "not", "None", ":", "\n", "        ", "shape", "+=", "[", "n_channels", "]", "\n", "", "return", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.add_axis": [[584, 591], ["utils.reformat_to_list", "numpy.expand_dims"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "def", "add_axis", "(", "x", ",", "axis", "=", "0", ")", ":", "\n", "    ", "\"\"\"Add axis to a numpy array.\n    :param axis: index of the new axis to add. Can also be a list of indices to add several axes at the same time.\"\"\"", "\n", "axis", "=", "reformat_to_list", "(", "axis", ")", "\n", "for", "ax", "in", "axis", ":", "\n", "        ", "x", "=", "np", ".", "expand_dims", "(", "x", ",", "axis", "=", "ax", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_padding_margin": [[593, 607], ["utils.reformat_to_list", "utils.reformat_to_list", "max", "utils.reformat_to_list", "utils.reformat_to_list", "len", "len", "int", "len", "range"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "get_padding_margin", "(", "cropping", ",", "loss_cropping", ")", ":", "\n", "    ", "\"\"\"Compute padding margin\"\"\"", "\n", "if", "(", "cropping", "is", "not", "None", ")", "&", "(", "loss_cropping", "is", "not", "None", ")", ":", "\n", "        ", "cropping", "=", "reformat_to_list", "(", "cropping", ")", "\n", "loss_cropping", "=", "reformat_to_list", "(", "loss_cropping", ")", "\n", "n_dims", "=", "max", "(", "len", "(", "cropping", ")", ",", "len", "(", "loss_cropping", ")", ")", "\n", "cropping", "=", "reformat_to_list", "(", "cropping", ",", "length", "=", "n_dims", ")", "\n", "loss_cropping", "=", "reformat_to_list", "(", "loss_cropping", ",", "length", "=", "n_dims", ")", "\n", "padding_margin", "=", "[", "int", "(", "(", "cropping", "[", "i", "]", "-", "loss_cropping", "[", "i", "]", ")", "/", "2", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "if", "len", "(", "padding_margin", ")", "==", "1", ":", "\n", "            ", "padding_margin", "=", "padding_margin", "[", "0", "]", "\n", "", "", "else", ":", "\n", "        ", "padding_margin", "=", "None", "\n", "", "return", "padding_margin", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.create_affine_transformation_matrix": [[612, 665], ["numpy.eye", "numpy.eye", "numpy.eye", "numpy.append", "numpy.ones", "numpy.zeros", "numpy.zeros", "numpy.eye", "numpy.eye", "numpy.eye", "numpy.eye", "numpy.zeros", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.zeros", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.eye", "numpy.asarray", "numpy.sin", "numpy.asarray", "numpy.sin", "numpy.sin", "numpy.sin", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], ["", "def", "create_affine_transformation_matrix", "(", "n_dims", ",", "scaling", "=", "None", ",", "rotation", "=", "None", ",", "shearing", "=", "None", ",", "translation", "=", "None", ")", ":", "\n", "    ", "\"\"\"Create a 4x4 affine transformation matrix from specified values\n    :param n_dims: integer\n    :param scaling: list of 3 scaling values\n    :param rotation: list of 3 angles (degrees) for rotations around 1st, 2nd, 3rd axis\n    :param shearing: list of 6 shearing values\n    :param translation: list of 3 values\n    :return: 4x4 numpy matrix\n    \"\"\"", "\n", "\n", "T_scaling", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "T_shearing", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "T_translation", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "\n", "if", "scaling", "is", "not", "None", ":", "\n", "        ", "T_scaling", "[", "np", ".", "arange", "(", "n_dims", "+", "1", ")", ",", "np", ".", "arange", "(", "n_dims", "+", "1", ")", "]", "=", "np", ".", "append", "(", "scaling", ",", "1", ")", "\n", "\n", "", "if", "shearing", "is", "not", "None", ":", "\n", "        ", "shearing_index", "=", "np", ".", "ones", "(", "(", "n_dims", "+", "1", ",", "n_dims", "+", "1", ")", ",", "dtype", "=", "'bool'", ")", "\n", "shearing_index", "[", "np", ".", "eye", "(", "n_dims", "+", "1", ",", "dtype", "=", "'bool'", ")", "]", "=", "False", "\n", "shearing_index", "[", "-", "1", ",", ":", "]", "=", "np", ".", "zeros", "(", "(", "n_dims", "+", "1", ")", ")", "\n", "shearing_index", "[", ":", ",", "-", "1", "]", "=", "np", ".", "zeros", "(", "(", "n_dims", "+", "1", ")", ")", "\n", "T_shearing", "[", "shearing_index", "]", "=", "shearing", "\n", "\n", "", "if", "translation", "is", "not", "None", ":", "\n", "        ", "T_translation", "[", "np", ".", "arange", "(", "n_dims", ")", ",", "n_dims", "*", "np", ".", "ones", "(", "n_dims", ",", "dtype", "=", "'int'", ")", "]", "=", "translation", "\n", "\n", "", "if", "n_dims", "==", "2", ":", "\n", "        ", "if", "rotation", "is", "None", ":", "\n", "            ", "rotation", "=", "np", ".", "zeros", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "rotation", "=", "np", ".", "asarray", "(", "rotation", ")", "*", "(", "math", ".", "pi", "/", "180", ")", "\n", "", "T_rot", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "T_rot", "[", "np", ".", "array", "(", "[", "0", ",", "1", ",", "0", ",", "1", "]", ")", ",", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "1", "]", ")", "]", "=", "[", "np", ".", "cos", "(", "rotation", "[", "0", "]", ")", ",", "np", ".", "sin", "(", "rotation", "[", "0", "]", ")", ",", "\n", "np", ".", "sin", "(", "rotation", "[", "0", "]", ")", "*", "-", "1", ",", "np", ".", "cos", "(", "rotation", "[", "0", "]", ")", "]", "\n", "return", "T_translation", "@", "T_rot", "@", "T_shearing", "@", "T_scaling", "\n", "\n", "", "else", ":", "\n", "\n", "        ", "if", "rotation", "is", "None", ":", "\n", "            ", "rotation", "=", "np", ".", "zeros", "(", "n_dims", ")", "\n", "", "else", ":", "\n", "            ", "rotation", "=", "np", ".", "asarray", "(", "rotation", ")", "*", "(", "math", ".", "pi", "/", "180", ")", "\n", "", "T_rot1", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "T_rot1", "[", "np", ".", "array", "(", "[", "1", ",", "2", ",", "1", ",", "2", "]", ")", ",", "np", ".", "array", "(", "[", "1", ",", "1", ",", "2", ",", "2", "]", ")", "]", "=", "[", "np", ".", "cos", "(", "rotation", "[", "0", "]", ")", ",", "np", ".", "sin", "(", "rotation", "[", "0", "]", ")", ",", "\n", "np", ".", "sin", "(", "rotation", "[", "0", "]", ")", "*", "-", "1", ",", "np", ".", "cos", "(", "rotation", "[", "0", "]", ")", "]", "\n", "T_rot2", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "T_rot2", "[", "np", ".", "array", "(", "[", "0", ",", "2", ",", "0", ",", "2", "]", ")", ",", "np", ".", "array", "(", "[", "0", ",", "0", ",", "2", ",", "2", "]", ")", "]", "=", "[", "np", ".", "cos", "(", "rotation", "[", "1", "]", ")", ",", "np", ".", "sin", "(", "rotation", "[", "1", "]", ")", "*", "-", "1", ",", "\n", "np", ".", "sin", "(", "rotation", "[", "1", "]", ")", ",", "np", ".", "cos", "(", "rotation", "[", "1", "]", ")", "]", "\n", "T_rot3", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "T_rot3", "[", "np", ".", "array", "(", "[", "0", ",", "1", ",", "0", ",", "1", "]", ")", ",", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "1", "]", ")", "]", "=", "[", "np", ".", "cos", "(", "rotation", "[", "2", "]", ")", ",", "np", ".", "sin", "(", "rotation", "[", "2", "]", ")", ",", "\n", "np", ".", "sin", "(", "rotation", "[", "2", "]", ")", "*", "-", "1", ",", "np", ".", "cos", "(", "rotation", "[", "2", "]", ")", "]", "\n", "return", "T_translation", "@", "T_rot3", "@", "T_rot2", "@", "T_rot1", "@", "T_shearing", "@", "T_scaling", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.sample_affine_transform": [[667, 745], ["tensorflow.matmul", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.concat", "utils.create_rotation_transform", "tensorflow.tile", "utils.draw_value_from_distribution", "utils.create_shearing_transform", "tensorflow.tile", "utils.draw_value_from_distribution", "tensorflow.linalg.diag", "tensorflow.tile", "tensorflow.matmul", "utils.draw_value_from_distribution", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.concat", "utils.draw_value_from_distribution", "tensorflow.zeros", "utils.draw_value_from_distribution", "tensorflow.zeros", "tensorflow.cast", "tensorflow.eye", "tensorflow.eye", "tensorflow.eye", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.ones", "tensorflow.ones", "tensorflow.concat", "tensorflow.concat", "tensorflow.ones", "tensorflow.ones", "tensorflow.ones", "tensorflow.concat", "tensorflow.random.uniform", "tensorflow.ones", "tensorflow.shape", "tensorflow.ones", "tensorflow.ones", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.create_rotation_transform", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.draw_value_from_distribution", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.create_shearing_transform", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.draw_value_from_distribution", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.draw_value_from_distribution", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.draw_value_from_distribution", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.draw_value_from_distribution", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "", "def", "sample_affine_transform", "(", "batchsize", ",", "\n", "n_dims", ",", "\n", "rotation_bounds", "=", "False", ",", "\n", "scaling_bounds", "=", "False", ",", "\n", "shearing_bounds", "=", "False", ",", "\n", "translation_bounds", "=", "False", ",", "\n", "enable_90_rotations", "=", "False", ")", ":", "\n", "    ", "\"\"\"build batchsizex4x4 tensor representing an affine transormation in homogeneous coordinates.\n    If return_inv is True, also returns the inverse of the created affine matrix.\"\"\"", "\n", "\n", "if", "(", "rotation_bounds", "is", "not", "False", ")", "|", "(", "enable_90_rotations", "is", "not", "False", ")", ":", "\n", "        ", "if", "n_dims", "==", "2", ":", "\n", "            ", "if", "rotation_bounds", "is", "not", "False", ":", "\n", "                ", "rotation", "=", "draw_value_from_distribution", "(", "rotation_bounds", ",", "\n", "size", "=", "1", ",", "\n", "default_range", "=", "15.0", ",", "\n", "return_as_tensor", "=", "True", ",", "\n", "batchsize", "=", "batchsize", ")", "\n", "", "else", ":", "\n", "                ", "rotation", "=", "tf", ".", "zeros", "(", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "1", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "", "", "else", ":", "# n_dims = 3", "\n", "            ", "if", "rotation_bounds", "is", "not", "False", ":", "\n", "                ", "rotation", "=", "draw_value_from_distribution", "(", "rotation_bounds", ",", "\n", "size", "=", "n_dims", ",", "\n", "default_range", "=", "15.0", ",", "\n", "return_as_tensor", "=", "True", ",", "\n", "batchsize", "=", "batchsize", ")", "\n", "", "else", ":", "\n", "                ", "rotation", "=", "tf", ".", "zeros", "(", "tf", ".", "concat", "(", "[", "batchsize", ",", "3", "*", "tf", ".", "ones", "(", "1", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "", "", "if", "enable_90_rotations", ":", "\n", "            ", "rotation", "=", "tf", ".", "cast", "(", "tf", ".", "random", ".", "uniform", "(", "tf", ".", "shape", "(", "rotation", ")", ",", "maxval", "=", "4", ",", "dtype", "=", "'int32'", ")", "*", "90", ",", "'float32'", ")", "+", "rotation", "\n", "", "T_rot", "=", "create_rotation_transform", "(", "rotation", ",", "n_dims", ")", "\n", "", "else", ":", "\n", "        ", "T_rot", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "eye", "(", "n_dims", ")", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "2", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "if", "shearing_bounds", "is", "not", "False", ":", "\n", "        ", "shearing", "=", "draw_value_from_distribution", "(", "shearing_bounds", ",", "\n", "size", "=", "n_dims", "**", "2", "-", "n_dims", ",", "\n", "default_range", "=", ".01", ",", "\n", "return_as_tensor", "=", "True", ",", "\n", "batchsize", "=", "batchsize", ")", "\n", "T_shearing", "=", "create_shearing_transform", "(", "shearing", ",", "n_dims", ")", "\n", "", "else", ":", "\n", "        ", "T_shearing", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "eye", "(", "n_dims", ")", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "2", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "if", "scaling_bounds", "is", "not", "False", ":", "\n", "        ", "scaling", "=", "draw_value_from_distribution", "(", "scaling_bounds", ",", "\n", "size", "=", "n_dims", ",", "\n", "centre", "=", "1", ",", "\n", "default_range", "=", ".15", ",", "\n", "return_as_tensor", "=", "True", ",", "\n", "batchsize", "=", "batchsize", ")", "\n", "T_scaling", "=", "tf", ".", "linalg", ".", "diag", "(", "scaling", ")", "\n", "", "else", ":", "\n", "        ", "T_scaling", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "eye", "(", "n_dims", ")", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "2", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "T", "=", "tf", ".", "matmul", "(", "T_scaling", ",", "tf", ".", "matmul", "(", "T_shearing", ",", "T_rot", ")", ")", "\n", "\n", "if", "translation_bounds", "is", "not", "False", ":", "\n", "        ", "translation", "=", "draw_value_from_distribution", "(", "translation_bounds", ",", "\n", "size", "=", "n_dims", ",", "\n", "default_range", "=", "5", ",", "\n", "return_as_tensor", "=", "True", ",", "\n", "batchsize", "=", "batchsize", ")", "\n", "T", "=", "tf", ".", "concat", "(", "[", "T", ",", "tf", ".", "expand_dims", "(", "translation", ",", "axis", "=", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "T", "=", "tf", ".", "concat", "(", "[", "T", ",", "tf", ".", "zeros", "(", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "T", ")", "[", ":", "2", "]", ",", "tf", ".", "ones", "(", "1", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# build rigid transform", "\n", "", "T_last_row", "=", "tf", ".", "expand_dims", "(", "tf", ".", "concat", "(", "[", "tf", ".", "zeros", "(", "(", "1", ",", "n_dims", ")", ")", ",", "tf", ".", "ones", "(", "(", "1", ",", "1", ")", ")", "]", ",", "axis", "=", "1", ")", ",", "0", ")", "\n", "T_last_row", "=", "tf", ".", "tile", "(", "T_last_row", ",", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "2", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "T", "=", "tf", ".", "concat", "(", "[", "T", ",", "T_last_row", "]", ",", "axis", "=", "1", ")", "\n", "\n", "return", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.create_rotation_transform": [[747, 787], ["tensorflow.shape", "tensorflow.expand_dims", "tensorflow.stack", "tensorflow.stack", "tensorflow.concat", "tensorflow.stack", "tensorflow.expand_dims", "tensorflow.stack", "tensorflow.concat", "tensorflow.stack", "tensorflow.stack", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.matmul", "tensorflow.expand_dims", "tensorflow.tile", "tensorflow.tile", "tensorflow.tile", "tensorflow.matmul", "tensorflow.stack", "tensorflow.stack", "tensorflow.concat", "Exception", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.zeros", "tensorflow.expand_dims", "tensorflow.convert_to_tensor", "tensorflow.cos", "tensorflow.sin", "tensorflow.cos", "tensorflow.cos", "tensorflow.sin", "tensorflow.convert_to_tensor", "tensorflow.cos", "tensorflow.cos", "tensorflow.sin", "tensorflow.cos", "tensorflow.convert_to_tensor", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.sin", "tensorflow.sin", "tensorflow.sin", "tensorflow.cos", "tensorflow.sin", "tensorflow.cos", "tensorflow.sin"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "def", "create_rotation_transform", "(", "rotation", ",", "n_dims", ")", ":", "\n", "    ", "\"\"\"build rotation transform from 3d or 2d rotation coefficients. Angles are given in degrees.\"\"\"", "\n", "rotation", "=", "rotation", "*", "np", ".", "pi", "/", "180", "\n", "if", "n_dims", "==", "3", ":", "\n", "        ", "shape", "=", "tf", ".", "shape", "(", "tf", ".", "expand_dims", "(", "rotation", "[", "...", ",", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "Rx_row0", "=", "tf", ".", "expand_dims", "(", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "convert_to_tensor", "(", "[", "1.", ",", "0.", ",", "0.", "]", ")", ",", "0", ")", ",", "shape", ")", ",", "axis", "=", "1", ")", "\n", "Rx_row1", "=", "tf", ".", "stack", "(", "[", "tf", ".", "zeros", "(", "shape", ")", ",", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "-", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Rx_row2", "=", "tf", ".", "stack", "(", "[", "tf", ".", "zeros", "(", "shape", ")", ",", "tf", ".", "expand_dims", "(", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Rx", "=", "tf", ".", "concat", "(", "[", "Rx_row0", ",", "Rx_row1", ",", "Rx_row2", "]", ",", "axis", "=", "1", ")", "\n", "\n", "Ry_row0", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "1", "]", ")", ",", "-", "1", ")", ",", "tf", ".", "zeros", "(", "shape", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "1", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Ry_row1", "=", "tf", ".", "expand_dims", "(", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "convert_to_tensor", "(", "[", "0.", ",", "1.", ",", "0.", "]", ")", ",", "0", ")", ",", "shape", ")", ",", "axis", "=", "1", ")", "\n", "Ry_row2", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "-", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "1", "]", ")", ",", "-", "1", ")", ",", "tf", ".", "zeros", "(", "shape", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "1", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Ry", "=", "tf", ".", "concat", "(", "[", "Ry_row0", ",", "Ry_row1", ",", "Ry_row2", "]", ",", "axis", "=", "1", ")", "\n", "\n", "Rz_row0", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "2", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "-", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "2", "]", ")", ",", "-", "1", ")", ",", "tf", ".", "zeros", "(", "shape", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Rz_row1", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "2", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "2", "]", ")", ",", "-", "1", ")", ",", "tf", ".", "zeros", "(", "shape", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Rz_row2", "=", "tf", ".", "expand_dims", "(", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "convert_to_tensor", "(", "[", "0.", ",", "0.", ",", "1.", "]", ")", ",", "0", ")", ",", "shape", ")", ",", "axis", "=", "1", ")", "\n", "Rz", "=", "tf", ".", "concat", "(", "[", "Rz_row0", ",", "Rz_row1", ",", "Rz_row2", "]", ",", "axis", "=", "1", ")", "\n", "\n", "T_rot", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "Rx", ",", "Ry", ")", ",", "Rz", ")", "\n", "\n", "", "elif", "n_dims", "==", "2", ":", "\n", "        ", "R_row0", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "R_row1", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "-", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "T_rot", "=", "tf", ".", "concat", "(", "[", "R_row0", ",", "R_row1", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'only supports 2 or 3D.'", ")", "\n", "\n", "", "return", "T_rot", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.create_shearing_transform": [[789, 808], ["tensorflow.shape", "tensorflow.expand_dims", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "tensorflow.concat", "tensorflow.stack", "tensorflow.stack", "tensorflow.concat", "Exception", "tensorflow.ones", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.ones", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.ones", "tensorflow.ones", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.ones"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "def", "create_shearing_transform", "(", "shearing", ",", "n_dims", ")", ":", "\n", "    ", "\"\"\"build shearing transform from 2d/3d shearing coefficients\"\"\"", "\n", "shape", "=", "tf", ".", "shape", "(", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "0", "]", ",", "-", "1", ")", ")", "\n", "if", "n_dims", "==", "3", ":", "\n", "        ", "shearing_row0", "=", "tf", ".", "stack", "(", "[", "tf", ".", "ones", "(", "shape", ")", ",", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "0", "]", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "1", "]", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "shearing_row1", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "2", "]", ",", "-", "1", ")", ",", "tf", ".", "ones", "(", "shape", ")", ",", "\n", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "3", "]", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "shearing_row2", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "4", "]", ",", "-", "1", ")", ",", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "5", "]", ",", "-", "1", ")", ",", "\n", "tf", ".", "ones", "(", "shape", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "T_shearing", "=", "tf", ".", "concat", "(", "[", "shearing_row0", ",", "shearing_row1", ",", "shearing_row2", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "elif", "n_dims", "==", "2", ":", "\n", "        ", "shearing_row0", "=", "tf", ".", "stack", "(", "[", "tf", ".", "ones", "(", "shape", ")", ",", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "0", "]", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "shearing_row1", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "1", "]", ",", "-", "1", ")", ",", "tf", ".", "ones", "(", "shape", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "T_shearing", "=", "tf", ".", "concat", "(", "[", "shearing_row0", ",", "shearing_row1", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'only supports 2 or 3D.'", ")", "\n", "", "return", "T_shearing", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.infer": [[813, 825], ["float", "isinstance", "TypeError", "type"], "function", ["None"], ["", "def", "infer", "(", "x", ")", ":", "\n", "    ", "''' Try to parse input to float. If it fails, tries boolean, and otherwise keep it as string '''", "\n", "try", ":", "\n", "        ", "x", "=", "float", "(", "x", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "if", "x", "==", "'False'", ":", "\n", "            ", "x", "=", "False", "\n", "", "elif", "x", "==", "'True'", ":", "\n", "            ", "x", "=", "True", "\n", "", "elif", "not", "isinstance", "(", "x", ",", "str", ")", ":", "\n", "            ", "raise", "TypeError", "(", "'input should be an int/float/boolean/str, had {}'", ".", "format", "(", "type", "(", "x", ")", ")", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.get_mapping_lut": [[886, 907], ["numpy.array", "numpy.zeros", "zip", "utils.reformat_to_list", "numpy.arange", "numpy.array", "len", "len", "utils.reformat_to_list", "numpy.max"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list"], ["", "", "", "", "def", "get_mapping_lut", "(", "source", ",", "dest", "=", "None", ")", ":", "\n", "    ", "\"\"\"This functions returns the look-up table to map a list of N values (source) to another list (dest).\n    If the second list is not given, we assume it is equal to [0, ..., N-1].\"\"\"", "\n", "\n", "# initialise", "\n", "source", "=", "np", ".", "array", "(", "reformat_to_list", "(", "source", ")", ",", "dtype", "=", "'int32'", ")", "\n", "n_labels", "=", "source", ".", "shape", "[", "0", "]", "\n", "\n", "# build new label list if neccessary", "\n", "if", "dest", "is", "None", ":", "\n", "        ", "dest", "=", "np", ".", "arange", "(", "n_labels", ",", "dtype", "=", "'int32'", ")", "\n", "", "else", ":", "\n", "        ", "assert", "len", "(", "source", ")", "==", "len", "(", "dest", ")", ",", "'label_list and new_label_list should have the same length'", "\n", "dest", "=", "np", ".", "array", "(", "reformat_to_list", "(", "dest", ",", "dtype", "=", "'int'", ")", ")", "\n", "\n", "# build look-up table", "\n", "", "lut", "=", "np", ".", "zeros", "(", "np", ".", "max", "(", "source", ")", "+", "1", ",", "dtype", "=", "'int32'", ")", "\n", "for", "source", ",", "dest", "in", "zip", "(", "source", ",", "dest", ")", ":", "\n", "        ", "lut", "[", "source", "]", "=", "dest", "\n", "\n", "", "return", "lut", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.build_training_generator": [[909, 918], ["next", "numpy.concatenate", "numpy.zeros", "numpy.zeros"], "function", ["None"], ["", "def", "build_training_generator", "(", "gen", ",", "batchsize", ")", ":", "\n", "    ", "\"\"\"Build generator for training a network.\"\"\"", "\n", "while", "True", ":", "\n", "        ", "inputs", "=", "next", "(", "gen", ")", "\n", "if", "batchsize", ">", "1", ":", "\n", "            ", "target", "=", "np", ".", "concatenate", "(", "[", "np", ".", "zeros", "(", "(", "1", ",", "1", ")", ")", "]", "*", "batchsize", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "target", "=", "np", ".", "zeros", "(", "(", "1", ",", "1", ")", ")", "\n", "", "yield", "inputs", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.find_closest_number_divisible_by_m": [[920, 937], ["int", "Exception"], "function", ["None"], ["", "", "def", "find_closest_number_divisible_by_m", "(", "n", ",", "m", ",", "answer_type", "=", "'lower'", ")", ":", "\n", "    ", "\"\"\"Return the closest integer to n that is divisible by m. answer_type can either be 'closer', 'lower' (only returns\n    values lower than n), or 'higher (only returns values higher than m).\"\"\"", "\n", "if", "n", "%", "m", "==", "0", ":", "\n", "        ", "return", "n", "\n", "", "else", ":", "\n", "        ", "q", "=", "int", "(", "n", "/", "m", ")", "\n", "lower", "=", "q", "*", "m", "\n", "higher", "=", "(", "q", "+", "1", ")", "*", "m", "\n", "if", "answer_type", "==", "'lower'", ":", "\n", "            ", "return", "lower", "\n", "", "elif", "answer_type", "==", "'higher'", ":", "\n", "            ", "return", "higher", "\n", "", "elif", "answer_type", "==", "'closer'", ":", "\n", "            ", "return", "lower", "if", "(", "n", "-", "lower", ")", "<", "(", "higher", "-", "n", ")", "else", "higher", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'answer_type should be lower, higher, or closer, had : %s'", "%", "answer_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.build_binary_structure": [[939, 951], ["numpy.ones", "tuple", "scipy.ndimage.morphology.distance_transform_edt", "utils.reformat_to_list", "tuple", "int"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.reformat_to_list"], ["", "", "", "def", "build_binary_structure", "(", "connectivity", ",", "n_dims", ",", "shape", "=", "None", ")", ":", "\n", "    ", "\"\"\"Return a dilation/erosion element with provided connectivity\"\"\"", "\n", "if", "shape", "is", "None", ":", "\n", "        ", "shape", "=", "[", "connectivity", "*", "2", "+", "1", "]", "*", "n_dims", "\n", "", "else", ":", "\n", "        ", "shape", "=", "reformat_to_list", "(", "shape", ",", "length", "=", "n_dims", ")", "\n", "", "dist", "=", "np", ".", "ones", "(", "shape", ")", "\n", "center", "=", "tuple", "(", "[", "tuple", "(", "[", "int", "(", "s", "/", "2", ")", "]", ")", "for", "s", "in", "shape", "]", ")", "\n", "dist", "[", "center", "]", "=", "0", "\n", "dist", "=", "distance_transform_edt", "(", "dist", ")", "\n", "struct", "=", "(", "dist", "<=", "connectivity", ")", "*", "1", "\n", "return", "struct", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.draw_value_from_distribution": [[953, 1039], ["utils.load_array_if_path", "isinstance", "isinstance", "numpy.array", "isinstance", "int", "keras.Lambda", "numpy.random.uniform", "numpy.array", "isinstance", "numpy.random.randint", "keras.Lambda", "keras.Lambda", "ValueError", "keras.Lambda", "numpy.random.normal", "ValueError", "numpy.transpose", "ValueError", "tensorflow.convert_to_tensor", "keras.Lambda", "len", "numpy.tile", "tensorflow.concat", "tensorflow.random.uniform", "keras.clip", "numpy.array", "tensorflow.random.normal", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.load_array_if_path", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "def", "draw_value_from_distribution", "(", "hyperparameter", ",", "\n", "size", "=", "1", ",", "\n", "distribution", "=", "'uniform'", ",", "\n", "centre", "=", "0.", ",", "\n", "default_range", "=", "10.0", ",", "\n", "positive_only", "=", "False", ",", "\n", "return_as_tensor", "=", "False", ",", "\n", "batchsize", "=", "None", ")", ":", "\n", "    ", "\"\"\"Sample values from a uniform, or normal distribution of given hyper-parameters.\n    These hyper-parameters are to the number of 2 in both uniform and normal cases.\n    :param hyperparameter: values of the hyper-parameters. Can either be:\n    1) None, in each case the two hyper-parameters are given by [center-default_range, center+default_range],\n    2) a number, where the two hyper-parameters are given by [centre-hyperparameter, centre+hyperparameter],\n    3) a sequence of length 2, directly defining the two hyper-parameters: [min, max] if the distribution is uniform,\n    [mean, std] if the distribution is normal.\n    4) a numpy array, with size (2, m). In this case, the function returns a 1d array of size m, where each value has\n    been sampled independently with the specified hyper-parameters. If the distribution is uniform, rows correspond to\n    its lower and upper bounds, and if the distribution is normal, rows correspond to its mean and std deviation.\n    5) a numpy array of size (2*n, m). Same as 4) but we first randomly select a block of two rows among the\n    n possibilities.\n    6) the path to a numpy array corresponding to case 4 or 5.\n    7) False, in which case this function returns None.\n    :param size: (optional) number of values to sample. All values are sampled independently.\n    Used only if hyperparameter is not a numpy array.\n    :param distribution: (optional) the distribution type. Can be 'uniform' or 'normal'. Default is 'uniform'.\n    :param centre: (optional) default centre to use if hyperparameter is None or a number.\n    :param default_range: (optional) default range to use if hyperparameter is None.\n    :param positive_only: (optional) wheter to reset all negative values to zero.\n    :return: a float, or a numpy 1d array if size > 1, or hyperparameter is itself a numpy array.\n    Returns None if hyperparmeter is False.\n    \"\"\"", "\n", "\n", "# return False is hyperparameter is False", "\n", "if", "hyperparameter", "is", "False", ":", "\n", "        ", "return", "None", "\n", "\n", "# reformat parameter_range", "\n", "", "hyperparameter", "=", "load_array_if_path", "(", "hyperparameter", ",", "load_as_numpy", "=", "True", ")", "\n", "if", "not", "isinstance", "(", "hyperparameter", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "hyperparameter", "is", "None", ":", "\n", "            ", "hyperparameter", "=", "np", ".", "array", "(", "[", "[", "centre", "-", "default_range", "]", "*", "size", ",", "[", "centre", "+", "default_range", "]", "*", "size", "]", ")", "\n", "", "elif", "isinstance", "(", "hyperparameter", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "            ", "hyperparameter", "=", "np", ".", "array", "(", "[", "[", "centre", "-", "hyperparameter", "]", "*", "size", ",", "[", "centre", "+", "hyperparameter", "]", "*", "size", "]", ")", "\n", "", "elif", "isinstance", "(", "hyperparameter", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "assert", "len", "(", "hyperparameter", ")", "==", "2", ",", "'if list, parameter_range should be of length 2.'", "\n", "hyperparameter", "=", "np", ".", "transpose", "(", "np", ".", "tile", "(", "np", ".", "array", "(", "hyperparameter", ")", ",", "(", "size", ",", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'parameter_range should either be None, a nummber, a sequence, or a numpy array.'", ")", "\n", "", "", "elif", "isinstance", "(", "hyperparameter", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "assert", "hyperparameter", ".", "shape", "[", "0", "]", "%", "2", "==", "0", ",", "'number of rows of parameter_range should be divisible by 2'", "\n", "n_modalities", "=", "int", "(", "hyperparameter", ".", "shape", "[", "0", "]", "/", "2", ")", "\n", "modality_idx", "=", "2", "*", "np", ".", "random", ".", "randint", "(", "n_modalities", ")", "\n", "hyperparameter", "=", "hyperparameter", "[", "modality_idx", ":", "modality_idx", "+", "2", ",", ":", "]", "\n", "\n", "# draw values as tensor", "\n", "", "if", "return_as_tensor", ":", "\n", "        ", "shape", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "convert_to_tensor", "(", "hyperparameter", ".", "shape", "[", "1", "]", ",", "'int32'", ")", ")", "(", "[", "]", ")", "\n", "if", "batchsize", "is", "not", "None", ":", "\n", "            ", "shape", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "concat", "(", "[", "x", "[", "0", "]", ",", "tf", ".", "expand_dims", "(", "x", "[", "1", "]", ",", "axis", "=", "0", ")", "]", ",", "axis", "=", "0", ")", ")", "(", "[", "batchsize", ",", "shape", "]", ")", "\n", "", "if", "distribution", "==", "'uniform'", ":", "\n", "            ", "parameter_value", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "x", ",", "\n", "minval", "=", "hyperparameter", "[", "0", ",", ":", "]", ",", "\n", "maxval", "=", "hyperparameter", "[", "1", ",", ":", "]", ")", ")", "(", "shape", ")", "\n", "", "elif", "distribution", "==", "'normal'", ":", "\n", "            ", "parameter_value", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "random", ".", "normal", "(", "shape", "=", "x", ",", "\n", "mean", "=", "hyperparameter", "[", "0", ",", ":", "]", ",", "\n", "stddev", "=", "hyperparameter", "[", "1", ",", ":", "]", ")", ")", "(", "shape", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Distribution not supported, should be 'uniform' or 'normal'.\"", ")", "\n", "\n", "", "if", "positive_only", ":", "\n", "            ", "parameter_value", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "clip", "(", "x", ",", "0", ",", "None", ")", ")", "(", "parameter_value", ")", "\n", "\n", "# draw values as numpy array", "\n", "", "", "else", ":", "\n", "        ", "if", "distribution", "==", "'uniform'", ":", "\n", "            ", "parameter_value", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "hyperparameter", "[", "0", ",", ":", "]", ",", "high", "=", "hyperparameter", "[", "1", ",", ":", "]", ")", "\n", "", "elif", "distribution", "==", "'normal'", ":", "\n", "            ", "parameter_value", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "hyperparameter", "[", "0", ",", ":", "]", ",", "scale", "=", "hyperparameter", "[", "1", ",", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Distribution not supported, should be 'uniform' or 'normal'.\"", ")", "\n", "\n", "", "if", "positive_only", ":", "\n", "            ", "parameter_value", "[", "parameter_value", "<", "0", "]", "=", "0", "\n", "\n", "", "", "return", "parameter_value", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.build_exp": [[1041, 1047], ["numpy.log", "numpy.exp"], "function", ["None"], ["", "def", "build_exp", "(", "x", ",", "first", ",", "last", ",", "fix_point", ")", ":", "\n", "# first = f(0), last = f(+inf), fix_point = [x0, f(x0))]", "\n", "    ", "a", "=", "last", "\n", "b", "=", "first", "-", "last", "\n", "c", "=", "-", "(", "1", "/", "fix_point", "[", "0", "]", ")", "*", "np", ".", "log", "(", "(", "fix_point", "[", "1", "]", "-", "last", ")", "/", "(", "first", "-", "last", ")", ")", "\n", "return", "a", "+", "b", "*", "np", ".", "exp", "(", "-", "c", "*", "x", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models._VAESample.__init__": [[1013, 1016], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "# , nb_z):", "\n", "# self.nb_z = nb_z", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models._VAESample.sample_z": [[1017, 1023], ["keras.shape", "keras.shape", "keras.shape", "keras.random_normal", "keras.random_normal", "keras.random_normal", "keras.exp", "keras.exp", "keras.exp"], "methods", ["None"], ["", "def", "sample_z", "(", "self", ",", "args", ")", ":", "\n", "        ", "mu", ",", "log_var", "=", "args", "\n", "# shape = (K.shape(mu)[0], self.nb_z)", "\n", "shape", "=", "K", ".", "shape", "(", "mu", ")", "\n", "eps", "=", "K", ".", "random_normal", "(", "shape", "=", "shape", ",", "mean", "=", "0.", ",", "stddev", "=", "1.", ")", "\n", "return", "mu", "+", "K", ".", "exp", "(", "log_var", "/", "2", ")", "*", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.dilation_net": [[27, 67], ["models.unet"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.unet"], ["def", "dilation_net", "(", "nb_features", ",", "\n", "input_shape", ",", "# input layer shape, vector of size ndims + 1(nb_channels)", "\n", "nb_levels", ",", "\n", "conv_size", ",", "\n", "nb_labels", ",", "\n", "name", "=", "'dilation_net'", ",", "\n", "prefix", "=", "None", ",", "\n", "feat_mult", "=", "1", ",", "\n", "pool_size", "=", "2", ",", "\n", "use_logp", "=", "True", ",", "\n", "padding", "=", "'same'", ",", "\n", "dilation_rate_mult", "=", "1", ",", "\n", "activation", "=", "'elu'", ",", "\n", "use_residuals", "=", "False", ",", "\n", "final_pred_activation", "=", "'softmax'", ",", "\n", "nb_conv_per_level", "=", "1", ",", "\n", "add_prior_layer", "=", "False", ",", "\n", "add_prior_layer_reg", "=", "0", ",", "\n", "layer_nb_feats", "=", "None", ",", "\n", "batch_norm", "=", "None", ")", ":", "\n", "    ", "return", "unet", "(", "nb_features", ",", "\n", "input_shape", ",", "# input layer shape, vector of size ndims + 1(nb_channels)", "\n", "nb_levels", ",", "\n", "conv_size", ",", "\n", "nb_labels", ",", "\n", "name", "=", "'unet'", ",", "\n", "prefix", "=", "None", ",", "\n", "feat_mult", "=", "1", ",", "\n", "pool_size", "=", "2", ",", "\n", "use_logp", "=", "True", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'elu'", ",", "\n", "use_residuals", "=", "False", ",", "\n", "dilation_rate_mult", "=", "dilation_rate_mult", ",", "\n", "final_pred_activation", "=", "'softmax'", ",", "\n", "nb_conv_per_level", "=", "1", ",", "\n", "add_prior_layer", "=", "False", ",", "\n", "add_prior_layer_reg", "=", "0", ",", "\n", "layer_nb_feats", "=", "None", ",", "\n", "batch_norm", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.unet": [[69, 194], ["isinstance", "models.conv_enc", "models.conv_dec", "len", "models.add_prior"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.conv_enc", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.conv_dec", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.add_prior"], ["", "def", "unet", "(", "nb_features", ",", "\n", "input_shape", ",", "\n", "nb_levels", ",", "\n", "conv_size", ",", "\n", "nb_labels", ",", "\n", "name", "=", "'unet'", ",", "\n", "prefix", "=", "None", ",", "\n", "feat_mult", "=", "1", ",", "\n", "pool_size", "=", "2", ",", "\n", "use_logp", "=", "True", ",", "\n", "padding", "=", "'same'", ",", "\n", "dilation_rate_mult", "=", "1", ",", "\n", "activation", "=", "'elu'", ",", "\n", "use_residuals", "=", "False", ",", "\n", "final_pred_activation", "=", "'softmax'", ",", "\n", "nb_conv_per_level", "=", "1", ",", "\n", "add_prior_layer", "=", "False", ",", "\n", "add_prior_layer_reg", "=", "0", ",", "\n", "layer_nb_feats", "=", "None", ",", "\n", "conv_dropout", "=", "0", ",", "\n", "batch_norm", "=", "None", ",", "\n", "input_model", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    unet-style keras model with an overdose of parametrization.\n\n    downsampling: \n\n    for U-net like architecture, we need to use Deconvolution3D.\n    However, this is not yet available (maybe soon, it's on a dev branch in github I believe)\n    Until then, we'll upsample and convolve.\n    TODO: Need to check that UpSampling3D actually does NN-upsampling!\n\n    Parameters:\n        nb_features: the number of features at each convolutional level\n            see below for `feat_mult` and `layer_nb_feats` for modifiers to this number\n        input_shape: input layer shape, vector of size ndims + 1 (nb_channels)\n        conv_size: the convolution kernel size\n        nb_levels: the number of Unet levels (number of downsamples) in the \"encoder\" \n            (e.g. 4 would give you 4 levels in encoder, 4 in decoder)\n        nb_labels: number of output channels\n        name (default: 'unet'): the name of the network\n        prefix (default: `name` value): prefix to be added to layer names\n        feat_mult (default: 1) multiple for `nb_features` as we go down the encoder levels.\n            e.g. feat_mult of 2 and nb_features of 16 would yield 32 features in the \n            second layer, 64 features in the third layer, etc\n        pool_size (default: 2): max pooling size (integer or list if specifying per dimension)\n        use_logp:\n        padding:\n        dilation_rate_mult:\n        activation:\n        use_residuals:\n        final_pred_activation:\n        nb_conv_per_level:\n        add_prior_layer:\n        add_prior_layer_reg:\n        layer_nb_feats: list of the number of features for each layer. Automatically used if specified\n        conv_dropout: dropout probability\n        batch_norm:\n        input_model: concatenate the provided input_model to this current model.\n            Only the first output of input_model is used.\n    \"\"\"", "\n", "\n", "# naming", "\n", "model_name", "=", "name", "\n", "if", "prefix", "is", "None", ":", "\n", "        ", "prefix", "=", "model_name", "\n", "\n", "# volume size data", "\n", "", "ndims", "=", "len", "(", "input_shape", ")", "-", "1", "\n", "if", "isinstance", "(", "pool_size", ",", "int", ")", ":", "\n", "        ", "pool_size", "=", "(", "pool_size", ",", ")", "*", "ndims", "\n", "\n", "# get encoding model", "\n", "", "enc_model", "=", "conv_enc", "(", "nb_features", ",", "\n", "input_shape", ",", "\n", "nb_levels", ",", "\n", "conv_size", ",", "\n", "name", "=", "model_name", ",", "\n", "prefix", "=", "prefix", ",", "\n", "feat_mult", "=", "feat_mult", ",", "\n", "pool_size", "=", "pool_size", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation_rate_mult", "=", "dilation_rate_mult", ",", "\n", "activation", "=", "activation", ",", "\n", "use_residuals", "=", "use_residuals", ",", "\n", "nb_conv_per_level", "=", "nb_conv_per_level", ",", "\n", "layer_nb_feats", "=", "layer_nb_feats", ",", "\n", "conv_dropout", "=", "conv_dropout", ",", "\n", "batch_norm", "=", "batch_norm", ",", "\n", "input_model", "=", "input_model", ")", "\n", "\n", "# get decoder", "\n", "# use_skip_connections=True makes it a u-net", "\n", "lnf", "=", "layer_nb_feats", "[", "(", "nb_levels", "*", "nb_conv_per_level", ")", ":", "]", "if", "layer_nb_feats", "is", "not", "None", "else", "None", "\n", "dec_model", "=", "conv_dec", "(", "nb_features", ",", "\n", "None", ",", "\n", "nb_levels", ",", "\n", "conv_size", ",", "\n", "nb_labels", ",", "\n", "name", "=", "model_name", ",", "\n", "prefix", "=", "prefix", ",", "\n", "feat_mult", "=", "feat_mult", ",", "\n", "pool_size", "=", "pool_size", ",", "\n", "use_skip_connections", "=", "True", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation_rate_mult", "=", "dilation_rate_mult", ",", "\n", "activation", "=", "activation", ",", "\n", "use_residuals", "=", "use_residuals", ",", "\n", "final_pred_activation", "=", "'linear'", "if", "add_prior_layer", "else", "final_pred_activation", ",", "\n", "nb_conv_per_level", "=", "nb_conv_per_level", ",", "\n", "batch_norm", "=", "batch_norm", ",", "\n", "layer_nb_feats", "=", "lnf", ",", "\n", "conv_dropout", "=", "conv_dropout", ",", "\n", "input_model", "=", "enc_model", ")", "\n", "final_model", "=", "dec_model", "\n", "\n", "if", "add_prior_layer", ":", "\n", "        ", "final_model", "=", "add_prior", "(", "dec_model", ",", "\n", "[", "*", "input_shape", "[", ":", "-", "1", "]", ",", "nb_labels", "]", ",", "\n", "name", "=", "model_name", "+", "'_prior'", ",", "\n", "use_logp", "=", "use_logp", ",", "\n", "final_pred_activation", "=", "final_pred_activation", ",", "\n", "add_prior_layer_reg", "=", "add_prior_layer_reg", ")", "\n", "\n", "", "return", "final_model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.ae": [[196, 318], ["isinstance", "models.conv_enc", "models.single_ae", "models.conv_dec", "len", "models.add_prior", "conv_enc.output.shape.as_list", "single_ae.output.shape.as_list"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.conv_enc", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.single_ae", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.conv_dec", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.add_prior"], ["", "def", "ae", "(", "nb_features", ",", "\n", "input_shape", ",", "\n", "nb_levels", ",", "\n", "conv_size", ",", "\n", "nb_labels", ",", "\n", "enc_size", ",", "\n", "name", "=", "'ae'", ",", "\n", "prefix", "=", "None", ",", "\n", "feat_mult", "=", "1", ",", "\n", "pool_size", "=", "2", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'elu'", ",", "\n", "use_residuals", "=", "False", ",", "\n", "nb_conv_per_level", "=", "1", ",", "\n", "batch_norm", "=", "None", ",", "\n", "enc_batch_norm", "=", "None", ",", "\n", "ae_type", "=", "'conv'", ",", "# 'dense', or 'conv'", "\n", "enc_lambda_layers", "=", "None", ",", "\n", "add_prior_layer", "=", "False", ",", "\n", "add_prior_layer_reg", "=", "0", ",", "\n", "use_logp", "=", "True", ",", "\n", "conv_dropout", "=", "0", ",", "\n", "include_mu_shift_layer", "=", "False", ",", "\n", "single_model", "=", "False", ",", "# whether to return a single model, or a tuple of models that can be stacked.", "\n", "final_pred_activation", "=", "'softmax'", ",", "\n", "do_vae", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Convolutional Auto-Encoder.\n    Optionally Variational.\n    Optionally Dense middle layer\n\n    \"Mostly\" in that the inner encoding can be (optionally) constructed via dense features.\n\n    Parameters:\n        do_vae (bool): whether to do a variational auto-encoder or not.\n\n    enc_lambda_layers functions to try:\n        K.softsign\n\n        a = 1\n        longtanh = lambda x: K.tanh(x) *  K.log(2 + a * abs(x))\n    \"\"\"", "\n", "\n", "# naming", "\n", "model_name", "=", "name", "\n", "\n", "# volume size data", "\n", "ndims", "=", "len", "(", "input_shape", ")", "-", "1", "\n", "if", "isinstance", "(", "pool_size", ",", "int", ")", ":", "\n", "        ", "pool_size", "=", "(", "pool_size", ",", ")", "*", "ndims", "\n", "\n", "# get encoding model", "\n", "", "enc_model", "=", "conv_enc", "(", "nb_features", ",", "\n", "input_shape", ",", "\n", "nb_levels", ",", "\n", "conv_size", ",", "\n", "name", "=", "model_name", ",", "\n", "feat_mult", "=", "feat_mult", ",", "\n", "pool_size", "=", "pool_size", ",", "\n", "padding", "=", "padding", ",", "\n", "activation", "=", "activation", ",", "\n", "use_residuals", "=", "use_residuals", ",", "\n", "nb_conv_per_level", "=", "nb_conv_per_level", ",", "\n", "conv_dropout", "=", "conv_dropout", ",", "\n", "batch_norm", "=", "batch_norm", ")", "\n", "\n", "# middle AE structure", "\n", "if", "single_model", ":", "\n", "        ", "in_input_shape", "=", "None", "\n", "in_model", "=", "enc_model", "\n", "", "else", ":", "\n", "        ", "in_input_shape", "=", "enc_model", ".", "output", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "in_model", "=", "None", "\n", "", "mid_ae_model", "=", "single_ae", "(", "enc_size", ",", "\n", "in_input_shape", ",", "\n", "conv_size", "=", "conv_size", ",", "\n", "name", "=", "model_name", ",", "\n", "ae_type", "=", "ae_type", ",", "\n", "input_model", "=", "in_model", ",", "\n", "batch_norm", "=", "enc_batch_norm", ",", "\n", "enc_lambda_layers", "=", "enc_lambda_layers", ",", "\n", "include_mu_shift_layer", "=", "include_mu_shift_layer", ",", "\n", "do_vae", "=", "do_vae", ")", "\n", "\n", "# decoder", "\n", "if", "single_model", ":", "\n", "        ", "in_input_shape", "=", "None", "\n", "in_model", "=", "mid_ae_model", "\n", "", "else", ":", "\n", "        ", "in_input_shape", "=", "mid_ae_model", ".", "output", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "in_model", "=", "None", "\n", "", "dec_model", "=", "conv_dec", "(", "nb_features", ",", "\n", "in_input_shape", ",", "\n", "nb_levels", ",", "\n", "conv_size", ",", "\n", "nb_labels", ",", "\n", "name", "=", "model_name", ",", "\n", "feat_mult", "=", "feat_mult", ",", "\n", "pool_size", "=", "pool_size", ",", "\n", "use_skip_connections", "=", "False", ",", "\n", "padding", "=", "padding", ",", "\n", "activation", "=", "activation", ",", "\n", "use_residuals", "=", "use_residuals", ",", "\n", "final_pred_activation", "=", "'linear'", ",", "\n", "nb_conv_per_level", "=", "nb_conv_per_level", ",", "\n", "batch_norm", "=", "batch_norm", ",", "\n", "conv_dropout", "=", "conv_dropout", ",", "\n", "input_model", "=", "in_model", ")", "\n", "\n", "if", "add_prior_layer", ":", "\n", "        ", "dec_model", "=", "add_prior", "(", "dec_model", ",", "\n", "[", "*", "input_shape", "[", ":", "-", "1", "]", ",", "nb_labels", "]", ",", "\n", "name", "=", "model_name", ",", "\n", "prefix", "=", "model_name", "+", "'_prior'", ",", "\n", "use_logp", "=", "use_logp", ",", "\n", "final_pred_activation", "=", "final_pred_activation", ",", "\n", "add_prior_layer_reg", "=", "add_prior_layer_reg", ")", "\n", "\n", "", "if", "single_model", ":", "\n", "        ", "return", "dec_model", "\n", "", "else", ":", "\n", "        ", "return", "(", "dec_model", ",", "mid_ae_model", ",", "enc_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.conv_enc": [[320, 431], ["tuple", "isinstance", "getattr", "getattr", "range", "keras.models.Model", "keras.Input", "isinstance", "len", "numpy.round().astype", "range", "keras.Reshape", "KL.add.shape.as_list", "keras.add", "numpy.round", "lvl_first_tensor.get_shape", "convarm_layer.get_shape", "keras.Activation", "keras.BatchNormalization", "getattr.", "getattr.", "getattr.", "keras.Dropout", "getattr.", "keras.Dropout"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "", "def", "conv_enc", "(", "nb_features", ",", "\n", "input_shape", ",", "\n", "nb_levels", ",", "\n", "conv_size", ",", "\n", "name", "=", "None", ",", "\n", "prefix", "=", "None", ",", "\n", "feat_mult", "=", "1", ",", "\n", "pool_size", "=", "2", ",", "\n", "dilation_rate_mult", "=", "1", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'elu'", ",", "\n", "layer_nb_feats", "=", "None", ",", "\n", "use_residuals", "=", "False", ",", "\n", "nb_conv_per_level", "=", "2", ",", "\n", "conv_dropout", "=", "0", ",", "\n", "batch_norm", "=", "None", ",", "\n", "input_model", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Fully Convolutional Encoder\n    \"\"\"", "\n", "\n", "# naming", "\n", "model_name", "=", "name", "\n", "if", "prefix", "is", "None", ":", "\n", "        ", "prefix", "=", "model_name", "\n", "\n", "# first layer: input", "\n", "", "name", "=", "'%s_input'", "%", "prefix", "\n", "if", "input_model", "is", "None", ":", "\n", "        ", "input_tensor", "=", "KL", ".", "Input", "(", "shape", "=", "input_shape", ",", "name", "=", "name", ")", "\n", "last_tensor", "=", "input_tensor", "\n", "", "else", ":", "\n", "        ", "input_tensor", "=", "input_model", ".", "inputs", "\n", "last_tensor", "=", "input_model", ".", "outputs", "\n", "if", "isinstance", "(", "last_tensor", ",", "list", ")", ":", "\n", "            ", "last_tensor", "=", "last_tensor", "[", "0", "]", "\n", "", "last_tensor", "=", "KL", ".", "Reshape", "(", "input_shape", ")", "(", "last_tensor", ")", "\n", "input_shape", "=", "last_tensor", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "\n", "# volume size data", "\n", "", "ndims", "=", "len", "(", "input_shape", ")", "-", "1", "\n", "input_shape", "=", "tuple", "(", "input_shape", ")", "\n", "if", "isinstance", "(", "pool_size", ",", "int", ")", ":", "\n", "        ", "pool_size", "=", "(", "pool_size", ",", ")", "*", "ndims", "\n", "\n", "# prepare layers", "\n", "", "convL", "=", "getattr", "(", "KL", ",", "'Conv%dD'", "%", "ndims", ")", "\n", "conv_kwargs", "=", "{", "'padding'", ":", "padding", ",", "'activation'", ":", "activation", ",", "'data_format'", ":", "'channels_last'", "}", "\n", "maxpool", "=", "getattr", "(", "KL", ",", "'MaxPooling%dD'", "%", "ndims", ")", "\n", "\n", "# down arm:", "\n", "# add nb_levels of conv + ReLu + conv + ReLu. Pool after each of first nb_levels - 1 layers", "\n", "lfidx", "=", "0", "# level feature index", "\n", "for", "level", "in", "range", "(", "nb_levels", ")", ":", "\n", "        ", "lvl_first_tensor", "=", "last_tensor", "\n", "nb_lvl_feats", "=", "np", ".", "round", "(", "nb_features", "*", "feat_mult", "**", "level", ")", ".", "astype", "(", "int", ")", "\n", "conv_kwargs", "[", "'dilation_rate'", "]", "=", "dilation_rate_mult", "**", "level", "\n", "\n", "for", "conv", "in", "range", "(", "nb_conv_per_level", ")", ":", "# does several conv per level, max pooling applied at the end", "\n", "            ", "if", "layer_nb_feats", "is", "not", "None", ":", "# None or List of all the feature numbers", "\n", "                ", "nb_lvl_feats", "=", "layer_nb_feats", "[", "lfidx", "]", "\n", "lfidx", "+=", "1", "\n", "\n", "", "name", "=", "'%s_conv_downarm_%d_%d'", "%", "(", "prefix", ",", "level", ",", "conv", ")", "\n", "if", "conv", "<", "(", "nb_conv_per_level", "-", "1", ")", "or", "(", "not", "use_residuals", ")", ":", "\n", "                ", "last_tensor", "=", "convL", "(", "nb_lvl_feats", ",", "conv_size", ",", "**", "conv_kwargs", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "", "else", ":", "# no activation", "\n", "                ", "last_tensor", "=", "convL", "(", "nb_lvl_feats", ",", "conv_size", ",", "padding", "=", "padding", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "", "if", "conv_dropout", ">", "0", ":", "\n", "# conv dropout along feature space only", "\n", "                ", "name", "=", "'%s_dropout_downarm_%d_%d'", "%", "(", "prefix", ",", "level", ",", "conv", ")", "\n", "noise_shape", "=", "[", "None", ",", "*", "[", "1", "]", "*", "ndims", ",", "nb_lvl_feats", "]", "\n", "last_tensor", "=", "KL", ".", "Dropout", "(", "conv_dropout", ",", "noise_shape", "=", "noise_shape", ")", "(", "last_tensor", ")", "\n", "\n", "", "", "if", "use_residuals", ":", "\n", "            ", "convarm_layer", "=", "last_tensor", "\n", "\n", "# the \"add\" layer is the original input", "\n", "# However, it may not have the right number of features to be added", "\n", "nb_feats_in", "=", "lvl_first_tensor", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "nb_feats_out", "=", "convarm_layer", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "add_layer", "=", "lvl_first_tensor", "\n", "if", "nb_feats_in", ">", "1", "and", "nb_feats_out", ">", "1", "and", "(", "nb_feats_in", "!=", "nb_feats_out", ")", ":", "\n", "                ", "name", "=", "'%s_expand_down_merge_%d'", "%", "(", "prefix", ",", "level", ")", "\n", "last_tensor", "=", "convL", "(", "nb_lvl_feats", ",", "conv_size", ",", "**", "conv_kwargs", ",", "name", "=", "name", ")", "(", "lvl_first_tensor", ")", "\n", "add_layer", "=", "last_tensor", "\n", "\n", "if", "conv_dropout", ">", "0", ":", "\n", "                    ", "name", "=", "'%s_dropout_down_merge_%d_%d'", "%", "(", "prefix", ",", "level", ",", "conv", ")", "\n", "noise_shape", "=", "[", "None", ",", "*", "[", "1", "]", "*", "ndims", ",", "nb_lvl_feats", "]", "\n", "last_tensor", "=", "KL", ".", "Dropout", "(", "conv_dropout", ",", "noise_shape", "=", "noise_shape", ")", "(", "last_tensor", ")", "\n", "\n", "", "", "name", "=", "'%s_res_down_merge_%d'", "%", "(", "prefix", ",", "level", ")", "\n", "last_tensor", "=", "KL", ".", "add", "(", "[", "add_layer", ",", "convarm_layer", "]", ",", "name", "=", "name", ")", "\n", "\n", "name", "=", "'%s_res_down_merge_act_%d'", "%", "(", "prefix", ",", "level", ")", "\n", "last_tensor", "=", "KL", ".", "Activation", "(", "activation", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "", "if", "batch_norm", "is", "not", "None", ":", "\n", "            ", "name", "=", "'%s_bn_down_%d'", "%", "(", "prefix", ",", "level", ")", "\n", "last_tensor", "=", "KL", ".", "BatchNormalization", "(", "axis", "=", "batch_norm", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "# max pool if we're not at the last level", "\n", "", "if", "level", "<", "(", "nb_levels", "-", "1", ")", ":", "\n", "            ", "name", "=", "'%s_maxpool_%d'", "%", "(", "prefix", ",", "level", ")", "\n", "last_tensor", "=", "maxpool", "(", "pool_size", "=", "pool_size", ",", "name", "=", "name", ",", "padding", "=", "padding", ")", "(", "last_tensor", ")", "\n", "\n", "# create the model and return", "\n", "", "", "model", "=", "Model", "(", "inputs", "=", "input_tensor", ",", "outputs", "=", "[", "last_tensor", "]", ",", "name", "=", "model_name", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.conv_dec": [[433, 578], ["tuple", "isinstance", "getattr", "getattr", "range", "keras.models.Model", "keras.Input", "len", "numpy.round().astype", "range", "getattr.", "KL.add.shape.as_list", "getattr.", "keras.concatenate", "keras.add", "keras.activations.softmax", "keras.activations.softmax", "keras.activations.softmax", "keras.Lambda", "keras.Activation", "numpy.round", "input_model.get_layer", "add_layer.get_shape", "KL.add.get_shape", "keras.Activation", "keras.BatchNormalization", "getattr.", "getattr.", "keras.Dropout", "getattr.", "keras.Dropout"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.softmax", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.softmax", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.softmax"], ["", "def", "conv_dec", "(", "nb_features", ",", "\n", "input_shape", ",", "\n", "nb_levels", ",", "\n", "conv_size", ",", "\n", "nb_labels", ",", "\n", "name", "=", "None", ",", "\n", "prefix", "=", "None", ",", "\n", "feat_mult", "=", "1", ",", "\n", "pool_size", "=", "2", ",", "\n", "use_skip_connections", "=", "False", ",", "\n", "padding", "=", "'same'", ",", "\n", "dilation_rate_mult", "=", "1", ",", "\n", "activation", "=", "'elu'", ",", "\n", "use_residuals", "=", "False", ",", "\n", "final_pred_activation", "=", "'softmax'", ",", "\n", "nb_conv_per_level", "=", "2", ",", "\n", "layer_nb_feats", "=", "None", ",", "\n", "batch_norm", "=", "None", ",", "\n", "conv_dropout", "=", "0", ",", "\n", "input_model", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Fully Convolutional Decoder\n\n    Parameters:\n        ...\n        use_skip_connections (bool): if true, turns an Enc-Dec to a U-Net.\n            If true, input_tensor and tensors are required.\n            It assumes a particular naming of layers. conv_enc...\n    \"\"\"", "\n", "\n", "# naming", "\n", "model_name", "=", "name", "\n", "if", "prefix", "is", "None", ":", "\n", "        ", "prefix", "=", "model_name", "\n", "\n", "# if using skip connections, make sure need to use them.", "\n", "", "if", "use_skip_connections", ":", "\n", "        ", "assert", "input_model", "is", "not", "None", ",", "\"is using skip connections, tensors dictionary is required\"", "\n", "\n", "# first layer: input", "\n", "", "input_name", "=", "'%s_input'", "%", "prefix", "\n", "if", "input_model", "is", "None", ":", "\n", "        ", "input_tensor", "=", "KL", ".", "Input", "(", "shape", "=", "input_shape", ",", "name", "=", "input_name", ")", "\n", "last_tensor", "=", "input_tensor", "\n", "", "else", ":", "\n", "        ", "input_tensor", "=", "input_model", ".", "input", "\n", "last_tensor", "=", "input_model", ".", "output", "\n", "input_shape", "=", "last_tensor", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "\n", "# vol size info", "\n", "", "ndims", "=", "len", "(", "input_shape", ")", "-", "1", "\n", "input_shape", "=", "tuple", "(", "input_shape", ")", "\n", "if", "isinstance", "(", "pool_size", ",", "int", ")", ":", "\n", "        ", "if", "ndims", ">", "1", ":", "\n", "            ", "pool_size", "=", "(", "pool_size", ",", ")", "*", "ndims", "\n", "\n", "# prepare layers", "\n", "", "", "convL", "=", "getattr", "(", "KL", ",", "'Conv%dD'", "%", "ndims", ")", "\n", "conv_kwargs", "=", "{", "'padding'", ":", "padding", ",", "'activation'", ":", "activation", "}", "\n", "upsample", "=", "getattr", "(", "KL", ",", "'UpSampling%dD'", "%", "ndims", ")", "\n", "\n", "# up arm:", "\n", "# nb_levels - 1 layers of Deconvolution3D", "\n", "#    (approx via up + conv + ReLu) + merge + conv + ReLu + conv + ReLu", "\n", "lfidx", "=", "0", "\n", "for", "level", "in", "range", "(", "nb_levels", "-", "1", ")", ":", "\n", "        ", "nb_lvl_feats", "=", "np", ".", "round", "(", "nb_features", "*", "feat_mult", "**", "(", "nb_levels", "-", "2", "-", "level", ")", ")", ".", "astype", "(", "int", ")", "\n", "conv_kwargs", "[", "'dilation_rate'", "]", "=", "dilation_rate_mult", "**", "(", "nb_levels", "-", "2", "-", "level", ")", "\n", "\n", "# upsample matching the max pooling layers size", "\n", "name", "=", "'%s_up_%d'", "%", "(", "prefix", ",", "nb_levels", "+", "level", ")", "\n", "last_tensor", "=", "upsample", "(", "size", "=", "pool_size", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "up_tensor", "=", "last_tensor", "\n", "\n", "# merge layers combining previous layer", "\n", "if", "use_skip_connections", ":", "\n", "            ", "conv_name", "=", "'%s_conv_downarm_%d_%d'", "%", "(", "prefix", ",", "nb_levels", "-", "2", "-", "level", ",", "nb_conv_per_level", "-", "1", ")", "\n", "cat_tensor", "=", "input_model", ".", "get_layer", "(", "conv_name", ")", ".", "output", "\n", "name", "=", "'%s_merge_%d'", "%", "(", "prefix", ",", "nb_levels", "+", "level", ")", "\n", "last_tensor", "=", "KL", ".", "concatenate", "(", "[", "cat_tensor", ",", "last_tensor", "]", ",", "axis", "=", "ndims", "+", "1", ",", "name", "=", "name", ")", "\n", "\n", "# convolution layers", "\n", "", "for", "conv", "in", "range", "(", "nb_conv_per_level", ")", ":", "\n", "            ", "if", "layer_nb_feats", "is", "not", "None", ":", "\n", "                ", "nb_lvl_feats", "=", "layer_nb_feats", "[", "lfidx", "]", "\n", "lfidx", "+=", "1", "\n", "\n", "", "name", "=", "'%s_conv_uparm_%d_%d'", "%", "(", "prefix", ",", "nb_levels", "+", "level", ",", "conv", ")", "\n", "if", "conv", "<", "(", "nb_conv_per_level", "-", "1", ")", "or", "(", "not", "use_residuals", ")", ":", "\n", "                ", "last_tensor", "=", "convL", "(", "nb_lvl_feats", ",", "conv_size", ",", "**", "conv_kwargs", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "", "else", ":", "\n", "                ", "last_tensor", "=", "convL", "(", "nb_lvl_feats", ",", "conv_size", ",", "padding", "=", "padding", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "", "if", "conv_dropout", ">", "0", ":", "\n", "                ", "name", "=", "'%s_dropout_uparm_%d_%d'", "%", "(", "prefix", ",", "level", ",", "conv", ")", "\n", "noise_shape", "=", "[", "None", ",", "*", "[", "1", "]", "*", "ndims", ",", "nb_lvl_feats", "]", "\n", "last_tensor", "=", "KL", ".", "Dropout", "(", "conv_dropout", ",", "noise_shape", "=", "noise_shape", ")", "(", "last_tensor", ")", "\n", "\n", "# residual block", "\n", "", "", "if", "use_residuals", ":", "\n", "\n", "# the \"add\" layer is the original input", "\n", "# However, it may not have the right number of features to be added", "\n", "            ", "add_layer", "=", "up_tensor", "\n", "nb_feats_in", "=", "add_layer", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "nb_feats_out", "=", "last_tensor", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "if", "nb_feats_in", ">", "1", "and", "nb_feats_out", ">", "1", "and", "(", "nb_feats_in", "!=", "nb_feats_out", ")", ":", "\n", "                ", "name", "=", "'%s_expand_up_merge_%d'", "%", "(", "prefix", ",", "level", ")", "\n", "add_layer", "=", "convL", "(", "nb_lvl_feats", ",", "conv_size", ",", "**", "conv_kwargs", ",", "name", "=", "name", ")", "(", "add_layer", ")", "\n", "\n", "if", "conv_dropout", ">", "0", ":", "\n", "                    ", "name", "=", "'%s_dropout_up_merge_%d_%d'", "%", "(", "prefix", ",", "level", ",", "conv", ")", "\n", "noise_shape", "=", "[", "None", ",", "*", "[", "1", "]", "*", "ndims", ",", "nb_lvl_feats", "]", "\n", "last_tensor", "=", "KL", ".", "Dropout", "(", "conv_dropout", ",", "noise_shape", "=", "noise_shape", ")", "(", "last_tensor", ")", "\n", "\n", "", "", "name", "=", "'%s_res_up_merge_%d'", "%", "(", "prefix", ",", "level", ")", "\n", "last_tensor", "=", "KL", ".", "add", "(", "[", "last_tensor", ",", "add_layer", "]", ",", "name", "=", "name", ")", "\n", "\n", "name", "=", "'%s_res_up_merge_act_%d'", "%", "(", "prefix", ",", "level", ")", "\n", "last_tensor", "=", "KL", ".", "Activation", "(", "activation", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "", "if", "batch_norm", "is", "not", "None", ":", "\n", "            ", "name", "=", "'%s_bn_up_%d'", "%", "(", "prefix", ",", "level", ")", "\n", "last_tensor", "=", "KL", ".", "BatchNormalization", "(", "axis", "=", "batch_norm", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "# Compute likelyhood prediction (no activation yet)", "\n", "", "", "name", "=", "'%s_likelihood'", "%", "prefix", "\n", "last_tensor", "=", "convL", "(", "nb_labels", ",", "1", ",", "activation", "=", "None", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "like_tensor", "=", "last_tensor", "\n", "\n", "# output prediction layer", "\n", "# we use a softmax to compute P(L_x|I) where x is each location", "\n", "if", "final_pred_activation", "==", "'softmax'", ":", "\n", "        ", "name", "=", "'%s_prediction'", "%", "prefix", "\n", "softmax_lambda_fcn", "=", "lambda", "x", ":", "keras", ".", "activations", ".", "softmax", "(", "x", ",", "axis", "=", "ndims", "+", "1", ")", "\n", "pred_tensor", "=", "KL", ".", "Lambda", "(", "softmax_lambda_fcn", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "# otherwise create a layer that does nothing.", "\n", "", "else", ":", "\n", "        ", "name", "=", "'%s_prediction'", "%", "prefix", "\n", "pred_tensor", "=", "KL", ".", "Activation", "(", "'linear'", ",", "name", "=", "name", ")", "(", "like_tensor", ")", "\n", "\n", "# create the model and retun", "\n", "", "model", "=", "Model", "(", "inputs", "=", "input_tensor", ",", "outputs", "=", "pred_tensor", ",", "name", "=", "model_name", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.add_prior": [[580, 638], ["keras.Input", "merge_op", "keras.models.Model", "print", "print", "keras.Activation", "keras.activations.softmax", "keras.activations.softmax", "keras.activations.softmax", "keras.Lambda", "keras.Activation"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.softmax", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.softmax", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.softmax"], ["", "def", "add_prior", "(", "input_model", ",", "\n", "prior_shape", ",", "\n", "name", "=", "'prior_model'", ",", "\n", "prefix", "=", "None", ",", "\n", "use_logp", "=", "True", ",", "\n", "final_pred_activation", "=", "'softmax'", ",", "\n", "add_prior_layer_reg", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Append post-prior layer to a given model\n    \"\"\"", "\n", "\n", "# naming", "\n", "model_name", "=", "name", "\n", "if", "prefix", "is", "None", ":", "\n", "        ", "prefix", "=", "model_name", "\n", "\n", "# prior input layer", "\n", "", "prior_input_name", "=", "'%s-input'", "%", "prefix", "\n", "prior_tensor", "=", "KL", ".", "Input", "(", "shape", "=", "prior_shape", ",", "name", "=", "prior_input_name", ")", "\n", "prior_tensor_input", "=", "prior_tensor", "\n", "like_tensor", "=", "input_model", ".", "output", "\n", "\n", "# operation varies depending on whether we log() prior or not.", "\n", "if", "use_logp", ":", "\n", "# name = '%s-log' % prefix", "\n", "# prior_tensor = KL.Lambda(_log_layer_wrap(add_prior_layer_reg), name=name)(prior_tensor)", "\n", "        ", "print", "(", "\"Breaking change: use_logp option now requires log input!\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "merge_op", "=", "KL", ".", "add", "\n", "\n", "", "else", ":", "\n", "# using sigmoid to get the likelihood values between 0 and 1", "\n", "# note: they won't add up to 1.", "\n", "        ", "name", "=", "'%s_likelihood_sigmoid'", "%", "prefix", "\n", "like_tensor", "=", "KL", ".", "Activation", "(", "'sigmoid'", ",", "name", "=", "name", ")", "(", "like_tensor", ")", "\n", "merge_op", "=", "KL", ".", "multiply", "\n", "\n", "# merge the likelihood and prior layers into posterior layer", "\n", "", "name", "=", "'%s_posterior'", "%", "prefix", "\n", "post_tensor", "=", "merge_op", "(", "[", "prior_tensor", ",", "like_tensor", "]", ",", "name", "=", "name", ")", "\n", "\n", "# output prediction layer", "\n", "# we use a softmax to compute P(L_x|I) where x is each location", "\n", "pred_name", "=", "'%s_prediction'", "%", "prefix", "\n", "if", "final_pred_activation", "==", "'softmax'", ":", "\n", "        ", "assert", "use_logp", ",", "'cannot do softmax when adding prior via P()'", "\n", "print", "(", "\"using final_pred_activation %s for %s\"", "%", "(", "final_pred_activation", ",", "model_name", ")", ")", "\n", "softmax_lambda_fcn", "=", "lambda", "x", ":", "keras", ".", "activations", ".", "softmax", "(", "x", ",", "axis", "=", "-", "1", ")", "\n", "pred_tensor", "=", "KL", ".", "Lambda", "(", "softmax_lambda_fcn", ",", "name", "=", "pred_name", ")", "(", "post_tensor", ")", "\n", "\n", "", "else", ":", "\n", "        ", "pred_tensor", "=", "KL", ".", "Activation", "(", "'linear'", ",", "name", "=", "pred_name", ")", "(", "post_tensor", ")", "\n", "\n", "# create the model", "\n", "", "model_inputs", "=", "[", "*", "input_model", ".", "inputs", ",", "prior_tensor_input", "]", "\n", "model", "=", "Model", "(", "inputs", "=", "model_inputs", ",", "outputs", "=", "[", "pred_tensor", "]", ",", "name", "=", "model_name", ")", "\n", "\n", "# compile", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.single_ae": [[640, 841], ["keras.models.Model", "keras.Input", "last_tensor.shape.as_list", "getattr", "keras.Lambda", "last_tensor.shape.as_list", "len", "len", "keras.Flatten", "len", "keras.Dense", "len", "len", "all", "all", "layers.LocalBias", "keras.Lambda", "keras.BatchNormalization", "keras.Lambda", "models._VAESample", "keras.Lambda", "layers.LocalBias", "keras.Dense", "len", "all", "all", "getattr.", "keras.BatchNormalization", "len", "len", "getattr.", "layers.Resize", "keras.Dense", "all", "all", "keras.Lambda", "keras.BatchNormalization", "numpy.prod", "keras.Reshape", "layers.Resize", "list", "list", "range", "keras.Lambda", "getattr.", "getattr.", "tensorflow.image.resize_bilinear", "keras.Lambda", "list", "list", "range", "list", "list", "len", "getattr.", "getattr.", "last_tensor.shape.as_list", "len", "last_tensor.shape.as_list", "len", "pre_enc_layer.shape.as_list"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "single_ae", "(", "enc_size", ",", "\n", "input_shape", ",", "\n", "name", "=", "'single_ae'", ",", "\n", "prefix", "=", "None", ",", "\n", "ae_type", "=", "'dense'", ",", "# 'dense', or 'conv'", "\n", "conv_size", "=", "None", ",", "\n", "input_model", "=", "None", ",", "\n", "enc_lambda_layers", "=", "None", ",", "\n", "batch_norm", "=", "True", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "None", ",", "\n", "include_mu_shift_layer", "=", "False", ",", "\n", "do_vae", "=", "False", ")", ":", "\n", "    ", "\"\"\"single-layer Autoencoder (i.e. input - encoding - output\"\"\"", "\n", "\n", "# naming", "\n", "model_name", "=", "name", "\n", "if", "prefix", "is", "None", ":", "\n", "        ", "prefix", "=", "model_name", "\n", "\n", "", "if", "enc_lambda_layers", "is", "None", ":", "\n", "        ", "enc_lambda_layers", "=", "[", "]", "\n", "\n", "# prepare input", "\n", "", "input_name", "=", "'%s_input'", "%", "prefix", "\n", "if", "input_model", "is", "None", ":", "\n", "        ", "assert", "input_shape", "is", "not", "None", ",", "'input_shape of input_model is necessary'", "\n", "input_tensor", "=", "KL", ".", "Input", "(", "shape", "=", "input_shape", ",", "name", "=", "input_name", ")", "\n", "last_tensor", "=", "input_tensor", "\n", "", "else", ":", "\n", "        ", "input_tensor", "=", "input_model", ".", "input", "\n", "last_tensor", "=", "input_model", ".", "output", "\n", "input_shape", "=", "last_tensor", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "", "input_nb_feats", "=", "last_tensor", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "# prepare conv type based on input", "\n", "if", "ae_type", "==", "'conv'", ":", "\n", "        ", "ndims", "=", "len", "(", "input_shape", ")", "-", "1", "\n", "convL", "=", "getattr", "(", "KL", ",", "'Conv%dD'", "%", "ndims", ")", "\n", "assert", "conv_size", "is", "not", "None", ",", "'with conv ae, need conv_size'", "\n", "", "conv_kwargs", "=", "{", "'padding'", ":", "padding", ",", "'activation'", ":", "activation", "}", "\n", "\n", "# if want to go through a dense layer in the middle of the U, need to:", "\n", "# - flatten last layer if not flat", "\n", "# - do dense encoding and decoding", "\n", "# - unflatten (rehsape spatially) at end", "\n", "if", "ae_type", "==", "'dense'", "and", "len", "(", "input_shape", ")", ">", "1", ":", "\n", "        ", "name", "=", "'%s_ae_%s_down_flat'", "%", "(", "prefix", ",", "ae_type", ")", "\n", "last_tensor", "=", "KL", ".", "Flatten", "(", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "# recall this layer", "\n", "", "pre_enc_layer", "=", "last_tensor", "\n", "\n", "# encoding layer", "\n", "if", "ae_type", "==", "'dense'", ":", "\n", "        ", "assert", "len", "(", "enc_size", ")", "==", "1", ",", "\"enc_size should be of length 1 for dense layer\"", "\n", "\n", "enc_size_str", "=", "''", ".", "join", "(", "[", "'%d_'", "%", "d", "for", "d", "in", "enc_size", "]", ")", "[", ":", "-", "1", "]", "\n", "name", "=", "'%s_ae_mu_enc_dense_%s'", "%", "(", "prefix", ",", "enc_size_str", ")", "\n", "last_tensor", "=", "KL", ".", "Dense", "(", "enc_size", "[", "0", "]", ",", "name", "=", "name", ")", "(", "pre_enc_layer", ")", "\n", "\n", "", "else", ":", "# convolution", "\n", "# convolve then resize. enc_size should be [nb_dim1, nb_dim2, ..., nb_feats]", "\n", "        ", "assert", "len", "(", "enc_size", ")", "==", "len", "(", "input_shape", ")", ",", "\"encoding size does not match input shape %d %d\"", "%", "(", "len", "(", "enc_size", ")", ",", "len", "(", "input_shape", ")", ")", "\n", "\n", "if", "list", "(", "enc_size", ")", "[", ":", "-", "1", "]", "!=", "list", "(", "input_shape", ")", "[", ":", "-", "1", "]", "and", "all", "(", "[", "f", "is", "not", "None", "for", "f", "in", "input_shape", "[", ":", "-", "1", "]", "]", ")", "and", "all", "(", "[", "f", "is", "not", "None", "for", "f", "in", "enc_size", "[", ":", "-", "1", "]", "]", ")", ":", "\n", "\n", "# assert len(enc_size) - 1 == 2, \"Sorry, I have not yet implemented non-2D resizing -- need to check out interpn!\"", "\n", "            ", "name", "=", "'%s_ae_mu_enc_conv'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "convL", "(", "enc_size", "[", "-", "1", "]", ",", "conv_size", ",", "name", "=", "name", ",", "**", "conv_kwargs", ")", "(", "pre_enc_layer", ")", "\n", "\n", "name", "=", "'%s_ae_mu_enc'", "%", "(", "prefix", ")", "\n", "zf", "=", "[", "enc_size", "[", ":", "-", "1", "]", "[", "f", "]", "/", "last_tensor", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "-", "1", "]", "[", "f", "]", "for", "f", "in", "range", "(", "len", "(", "enc_size", ")", "-", "1", ")", "]", "\n", "last_tensor", "=", "layers", ".", "Resize", "(", "zoom_factor", "=", "zf", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "# resize_fn = lambda x: tf.image.resize_bilinear(x, enc_size[:-1])", "\n", "# last_tensor = KL.Lambda(resize_fn, name=name)(last_tensor)", "\n", "\n", "", "elif", "enc_size", "[", "-", "1", "]", "is", "None", ":", "# convolutional, but won't tell us bottleneck", "\n", "            ", "name", "=", "'%s_ae_mu_enc'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", ",", "name", "=", "name", ")", "(", "pre_enc_layer", ")", "\n", "\n", "", "else", ":", "\n", "            ", "name", "=", "'%s_ae_mu_enc'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "convL", "(", "enc_size", "[", "-", "1", "]", ",", "conv_size", ",", "name", "=", "name", ",", "**", "conv_kwargs", ")", "(", "pre_enc_layer", ")", "\n", "\n", "", "", "if", "include_mu_shift_layer", ":", "\n", "# shift", "\n", "        ", "name", "=", "'%s_ae_mu_shift'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "layers", ".", "LocalBias", "(", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "# encoding clean-up layers", "\n", "", "for", "layer_fcn", "in", "enc_lambda_layers", ":", "\n", "        ", "lambda_name", "=", "layer_fcn", ".", "__name__", "\n", "name", "=", "'%s_ae_mu_%s'", "%", "(", "prefix", ",", "lambda_name", ")", "\n", "last_tensor", "=", "KL", ".", "Lambda", "(", "layer_fcn", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "", "if", "batch_norm", "is", "not", "None", ":", "\n", "        ", "name", "=", "'%s_ae_mu_bn'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "KL", ".", "BatchNormalization", "(", "axis", "=", "batch_norm", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "# have a simple layer that does nothing to have a clear name before sampling", "\n", "", "name", "=", "'%s_ae_mu'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "# if doing variational AE, will need the sigma layer as well.", "\n", "if", "do_vae", ":", "\n", "        ", "mu_tensor", "=", "last_tensor", "\n", "\n", "# encoding layer", "\n", "if", "ae_type", "==", "'dense'", ":", "\n", "            ", "name", "=", "'%s_ae_sigma_enc_dense_%s'", "%", "(", "prefix", ",", "enc_size_str", ")", "\n", "last_tensor", "=", "KL", ".", "Dense", "(", "enc_size", "[", "0", "]", ",", "name", "=", "name", ",", "\n", "#    kernel_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=1e-5),", "\n", "#    bias_initializer=keras.initializers.RandomNormal(mean=-5.0, stddev=1e-5)", "\n", ")", "(", "pre_enc_layer", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "list", "(", "enc_size", ")", "[", ":", "-", "1", "]", "!=", "list", "(", "input_shape", ")", "[", ":", "-", "1", "]", "and", "all", "(", "[", "f", "is", "not", "None", "for", "f", "in", "input_shape", "[", ":", "-", "1", "]", "]", ")", "and", "all", "(", "[", "f", "is", "not", "None", "for", "f", "in", "enc_size", "[", ":", "-", "1", "]", "]", ")", ":", "\n", "\n", "                ", "assert", "len", "(", "enc_size", ")", "-", "1", "==", "2", ",", "\"Sorry, I have not yet implemented non-2D resizing...\"", "\n", "name", "=", "'%s_ae_sigma_enc_conv'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "convL", "(", "enc_size", "[", "-", "1", "]", ",", "conv_size", ",", "name", "=", "name", ",", "**", "conv_kwargs", ")", "(", "pre_enc_layer", ")", "\n", "\n", "name", "=", "'%s_ae_sigma_enc'", "%", "(", "prefix", ")", "\n", "resize_fn", "=", "lambda", "x", ":", "tf", ".", "image", ".", "resize_bilinear", "(", "x", ",", "enc_size", "[", ":", "-", "1", "]", ")", "\n", "last_tensor", "=", "KL", ".", "Lambda", "(", "resize_fn", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "", "elif", "enc_size", "[", "-", "1", "]", "is", "None", ":", "# convolutional, but won't tell us bottleneck", "\n", "                ", "name", "=", "'%s_ae_sigma_enc'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "convL", "(", "pre_enc_layer", ".", "shape", ".", "as_list", "(", ")", "[", "-", "1", "]", ",", "conv_size", ",", "name", "=", "name", ",", "**", "conv_kwargs", ")", "(", "\n", "pre_enc_layer", ")", "\n", "# cannot use lambda, then mu and sigma will be same layer.", "\n", "# last_tensor = KL.Lambda(lambda x: x, name=name)(pre_enc_layer)", "\n", "\n", "", "else", ":", "\n", "                ", "name", "=", "'%s_ae_sigma_enc'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "convL", "(", "enc_size", "[", "-", "1", "]", ",", "conv_size", ",", "name", "=", "name", ",", "**", "conv_kwargs", ")", "(", "pre_enc_layer", ")", "\n", "\n", "# encoding clean-up layers", "\n", "", "", "for", "layer_fcn", "in", "enc_lambda_layers", ":", "\n", "            ", "lambda_name", "=", "layer_fcn", ".", "__name__", "\n", "name", "=", "'%s_ae_sigma_%s'", "%", "(", "prefix", ",", "lambda_name", ")", "\n", "last_tensor", "=", "KL", ".", "Lambda", "(", "layer_fcn", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "", "if", "batch_norm", "is", "not", "None", ":", "\n", "            ", "name", "=", "'%s_ae_sigma_bn'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "KL", ".", "BatchNormalization", "(", "axis", "=", "batch_norm", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "# have a simple layer that does nothing to have a clear name before sampling", "\n", "", "name", "=", "'%s_ae_sigma'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "x", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "logvar_tensor", "=", "last_tensor", "\n", "\n", "# VAE sampling", "\n", "sampler", "=", "_VAESample", "(", ")", ".", "sample_z", "\n", "\n", "name", "=", "'%s_ae_sample'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "KL", ".", "Lambda", "(", "sampler", ",", "name", "=", "name", ")", "(", "[", "mu_tensor", ",", "logvar_tensor", "]", ")", "\n", "\n", "", "if", "include_mu_shift_layer", ":", "\n", "# shift", "\n", "        ", "name", "=", "'%s_ae_sample_shift'", "%", "(", "prefix", ")", "\n", "last_tensor", "=", "layers", ".", "LocalBias", "(", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "# decoding layer", "\n", "", "if", "ae_type", "==", "'dense'", ":", "\n", "        ", "name", "=", "'%s_ae_%s_dec_flat_%s'", "%", "(", "prefix", ",", "ae_type", ",", "enc_size_str", ")", "\n", "last_tensor", "=", "KL", ".", "Dense", "(", "np", ".", "prod", "(", "input_shape", ")", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "# unflatten if dense method", "\n", "if", "len", "(", "input_shape", ")", ">", "1", ":", "\n", "            ", "name", "=", "'%s_ae_%s_dec'", "%", "(", "prefix", ",", "ae_type", ")", "\n", "last_tensor", "=", "KL", ".", "Reshape", "(", "input_shape", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "", "", "else", ":", "\n", "\n", "        ", "if", "list", "(", "enc_size", ")", "[", ":", "-", "1", "]", "!=", "list", "(", "input_shape", ")", "[", ":", "-", "1", "]", "and", "all", "(", "[", "f", "is", "not", "None", "for", "f", "in", "input_shape", "[", ":", "-", "1", "]", "]", ")", "and", "all", "(", "[", "f", "is", "not", "None", "for", "f", "in", "enc_size", "[", ":", "-", "1", "]", "]", ")", ":", "\n", "            ", "name", "=", "'%s_ae_mu_dec'", "%", "(", "prefix", ")", "\n", "zf", "=", "[", "last_tensor", ".", "shape", ".", "as_list", "(", ")", "[", "1", ":", "-", "1", "]", "[", "f", "]", "/", "enc_size", "[", ":", "-", "1", "]", "[", "f", "]", "for", "f", "in", "range", "(", "len", "(", "enc_size", ")", "-", "1", ")", "]", "\n", "last_tensor", "=", "layers", ".", "Resize", "(", "zoom_factor", "=", "zf", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "# resize_fn = lambda x: tf.image.resize_bilinear(x, input_shape[:-1])", "\n", "# last_tensor = KL.Lambda(resize_fn, name=name)(last_tensor)", "\n", "\n", "", "name", "=", "'%s_ae_%s_dec'", "%", "(", "prefix", ",", "ae_type", ")", "\n", "last_tensor", "=", "convL", "(", "input_nb_feats", ",", "conv_size", ",", "name", "=", "name", ",", "**", "conv_kwargs", ")", "(", "last_tensor", ")", "\n", "\n", "", "if", "batch_norm", "is", "not", "None", ":", "\n", "        ", "name", "=", "'%s_bn_ae_%s_dec'", "%", "(", "prefix", ",", "ae_type", ")", "\n", "last_tensor", "=", "KL", ".", "BatchNormalization", "(", "axis", "=", "batch_norm", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "# create the model and retun", "\n", "", "model", "=", "Model", "(", "inputs", "=", "input_tensor", ",", "outputs", "=", "[", "last_tensor", "]", ",", "name", "=", "model_name", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models.design_dnn": [[843, 991], ["len", "tuple", "getattr", "isinstance", "keras.Input", "range", "keras.models.Model", "keras.constraints.maxnorm", "range", "len", "numpy.round().astype", "keras.Flatten", "keras.Dense", "getattr.", "getattr.", "maxpool", "keras.Flatten", "keras.Dense", "keras.Activation", "keras.Dropout", "numpy.round", "keras.Flatten", "keras.Dense", "keras.BatchNormalization", "keras.Lambda", "keras.Reshape", "keras.Conv1D", "keras.Conv3D", "keras.GlobalMaxPooling3D", "keras.Activation"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "design_dnn", "(", "nb_features", ",", "input_shape", ",", "nb_levels", ",", "conv_size", ",", "nb_labels", ",", "\n", "feat_mult", "=", "1", ",", "\n", "pool_size", "=", "2", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "'elu'", ",", "\n", "final_layer", "=", "'dense-sigmoid'", ",", "\n", "conv_dropout", "=", "0", ",", "\n", "conv_maxnorm", "=", "0", ",", "\n", "nb_input_features", "=", "1", ",", "\n", "batch_norm", "=", "False", ",", "\n", "name", "=", "None", ",", "\n", "prefix", "=", "None", ",", "\n", "use_strided_convolution_maxpool", "=", "True", ",", "\n", "nb_conv_per_level", "=", "2", ")", ":", "\n", "    ", "\"\"\"\n    \"deep\" cnn with dense or global max pooling layer @ end...\n\n    Could use sequential...\n    \"\"\"", "\n", "\n", "model_name", "=", "name", "\n", "if", "model_name", "is", "None", ":", "\n", "        ", "model_name", "=", "'model_1'", "\n", "", "if", "prefix", "is", "None", ":", "\n", "        ", "prefix", "=", "model_name", "\n", "\n", "", "ndims", "=", "len", "(", "input_shape", ")", "\n", "input_shape", "=", "tuple", "(", "input_shape", ")", "\n", "\n", "convL", "=", "getattr", "(", "KL", ",", "'Conv%dD'", "%", "ndims", ")", "\n", "maxpool", "=", "KL", ".", "MaxPooling3D", "if", "len", "(", "input_shape", ")", "==", "3", "else", "KL", ".", "MaxPooling2D", "\n", "if", "isinstance", "(", "pool_size", ",", "int", ")", ":", "\n", "        ", "pool_size", "=", "(", "pool_size", ",", ")", "*", "ndims", "\n", "\n", "# kwargs for the convolution layer", "\n", "", "conv_kwargs", "=", "{", "'padding'", ":", "padding", ",", "'activation'", ":", "activation", "}", "\n", "if", "conv_maxnorm", ">", "0", ":", "\n", "        ", "conv_kwargs", "[", "'kernel_constraint'", "]", "=", "maxnorm", "(", "conv_maxnorm", ")", "\n", "\n", "# initialize a dictionary", "\n", "", "enc_tensors", "=", "{", "}", "\n", "\n", "# first layer: input", "\n", "name", "=", "'%s_input'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Input", "(", "shape", "=", "input_shape", "+", "(", "nb_input_features", ",", ")", ",", "name", "=", "name", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "# down arm:", "\n", "# add nb_levels of conv + ReLu + conv + ReLu. Pool after each of first nb_levels - 1 layers", "\n", "for", "level", "in", "range", "(", "nb_levels", ")", ":", "\n", "        ", "for", "conv", "in", "range", "(", "nb_conv_per_level", ")", ":", "\n", "            ", "if", "conv_dropout", ">", "0", ":", "\n", "                ", "name", "=", "'%s_dropout_%d_%d'", "%", "(", "prefix", ",", "level", ",", "conv", ")", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Dropout", "(", "conv_dropout", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "", "name", "=", "'%s_conv_%d_%d'", "%", "(", "prefix", ",", "level", ",", "conv", ")", "\n", "nb_lvl_feats", "=", "np", ".", "round", "(", "nb_features", "*", "feat_mult", "**", "level", ")", ".", "astype", "(", "int", ")", "\n", "enc_tensors", "[", "name", "]", "=", "convL", "(", "nb_lvl_feats", ",", "conv_size", ",", "**", "conv_kwargs", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "# max pool", "\n", "", "if", "use_strided_convolution_maxpool", ":", "\n", "            ", "name", "=", "'%s_strided_conv_%d'", "%", "(", "prefix", ",", "level", ")", "\n", "enc_tensors", "[", "name", "]", "=", "convL", "(", "nb_lvl_feats", ",", "pool_size", ",", "**", "conv_kwargs", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "", "else", ":", "\n", "            ", "name", "=", "'%s_maxpool_%d'", "%", "(", "prefix", ",", "level", ")", "\n", "enc_tensors", "[", "name", "]", "=", "maxpool", "(", "pool_size", "=", "pool_size", ",", "name", "=", "name", ",", "padding", "=", "padding", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "# dense layer", "\n", "", "", "if", "final_layer", "==", "'dense-sigmoid'", ":", "\n", "\n", "        ", "name", "=", "\"%s_flatten\"", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Flatten", "(", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "name", "=", "'%s_dense'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Dense", "(", "1", ",", "name", "=", "name", ",", "activation", "=", "\"sigmoid\"", ")", "(", "last_tensor", ")", "\n", "\n", "", "elif", "final_layer", "==", "'dense-tanh'", ":", "\n", "\n", "        ", "name", "=", "\"%s_flatten\"", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Flatten", "(", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "name", "=", "'%s_dense'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Dense", "(", "1", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "# Omittting BatchNorm for now, it seems to have a cpu vs gpu problem", "\n", "# https://github.com/tensorflow/tensorflow/pull/8906", "\n", "# https://github.com/fchollet/keras/issues/5802", "\n", "# name = '%s_%s_bn' % prefix", "\n", "# enc_tensors[name] = KL.BatchNormalization(axis=batch_norm, name=name)(last_tensor)", "\n", "# last_tensor = enc_tensors[name]", "\n", "\n", "name", "=", "'%s_%s_tanh'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Activation", "(", "activation", "=", "\"tanh\"", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "", "elif", "final_layer", "==", "'dense-softmax'", ":", "\n", "\n", "        ", "name", "=", "\"%s_flatten\"", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Flatten", "(", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "name", "=", "'%s_dense'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Dense", "(", "nb_labels", ",", "name", "=", "name", ",", "activation", "=", "\"softmax\"", ")", "(", "last_tensor", ")", "\n", "\n", "# global max pooling layer", "\n", "", "elif", "final_layer", "==", "'myglobalmaxpooling'", ":", "\n", "\n", "        ", "name", "=", "'%s_batch_norm'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "BatchNormalization", "(", "axis", "=", "batch_norm", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "name", "=", "'%s_global_max_pool'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Lambda", "(", "_global_max_nd", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "name", "=", "'%s_global_max_pool_reshape'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Reshape", "(", "(", "1", ",", "1", ")", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "# cannot do activation in lambda layer. Could code inside, but will do extra lyaer", "\n", "name", "=", "'%s_global_max_pool_sigmoid'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Conv1D", "(", "1", ",", "1", ",", "name", "=", "name", ",", "activation", "=", "\"sigmoid\"", ",", "use_bias", "=", "True", ")", "(", "last_tensor", ")", "\n", "\n", "", "elif", "final_layer", "==", "'globalmaxpooling'", ":", "\n", "\n", "        ", "name", "=", "'%s_conv_to_featmaps'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Conv3D", "(", "2", ",", "1", ",", "name", "=", "name", ",", "activation", "=", "\"relu\"", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "name", "=", "'%s_global_max_pool'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "GlobalMaxPooling3D", "(", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "# cannot do activation in lambda layer. Could code inside, but will do extra lyaer", "\n", "name", "=", "'%s_global_max_pool_softmax'", "%", "prefix", "\n", "enc_tensors", "[", "name", "]", "=", "KL", ".", "Activation", "(", "'softmax'", ",", "name", "=", "name", ")", "(", "last_tensor", ")", "\n", "\n", "", "last_tensor", "=", "enc_tensors", "[", "name", "]", "\n", "\n", "# create the model", "\n", "model", "=", "Model", "(", "inputs", "=", "[", "enc_tensors", "[", "'%s_input'", "%", "prefix", "]", "]", ",", "outputs", "=", "[", "last_tensor", "]", ",", "name", "=", "model_name", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models._global_max_nd": [[997, 1000], ["keras.batch_flatten", "keras.max"], "function", ["None"], ["", "def", "_global_max_nd", "(", "xtens", ")", ":", "\n", "    ", "ytens", "=", "K", ".", "batch_flatten", "(", "xtens", ")", "\n", "return", "K", ".", "max", "(", "ytens", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models._log_layer_wrap": [[1002, 1007], ["keras.epsilon", "keras.log"], "function", ["None"], ["", "def", "_log_layer_wrap", "(", "reg", "=", "K", ".", "epsilon", "(", ")", ")", ":", "\n", "    ", "def", "_log_layer", "(", "tens", ")", ":", "\n", "        ", "return", "K", ".", "log", "(", "tens", "+", "reg", ")", "\n", "\n", "", "return", "_log_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.models._softmax": [[1025, 1049], ["keras.ndim", "keras.softmax", "keras.exp", "keras.sum", "ValueError", "keras.max"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.softmax"], ["", "", "def", "_softmax", "(", "x", ",", "axis", "=", "-", "1", ",", "alpha", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    building on keras implementation, allow alpha parameter\n\n    Softmax activation function.\n    # Arguments\n        x : Tensor.\n        axis: Integer, axis along which the softmax normalization is applied.\n        alpha: a value to multiply all x\n    # Returns\n        Tensor, output of softmax transformation.\n    # Raises\n        ValueError: In case `dim(x) == 1`.\n    \"\"\"", "\n", "x", "=", "alpha", "*", "x", "\n", "ndim", "=", "K", ".", "ndim", "(", "x", ")", "\n", "if", "ndim", "==", "2", ":", "\n", "        ", "return", "K", ".", "softmax", "(", "x", ")", "\n", "", "elif", "ndim", ">", "2", ":", "\n", "        ", "e", "=", "K", ".", "exp", "(", "x", "-", "K", ".", "max", "(", "x", ",", "axis", "=", "axis", ",", "keepdims", "=", "True", ")", ")", "\n", "s", "=", "K", ".", "sum", "(", "e", ",", "axis", "=", "axis", ",", "keepdims", "=", "True", ")", "\n", "return", "e", "/", "s", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Cannot apply softmax to a tensor that is 1D'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.dataproc.proc_mgh_vols": [[34, 82], ["tqdm", "range", "nibabel.load", "nib.load.get_data().astype", "numpy.savez_compressed", "print", "os.listdir", "f.endswith", "len", "os.path.join", "dataproc.vol_proc", "nib.load.get_data", "print", "os.path.splitext", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.dataproc.vol_proc"], ["def", "proc_mgh_vols", "(", "inpath", ",", "\n", "outpath", ",", "\n", "ext", "=", "'.mgz'", ",", "\n", "label_idx", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "''' process mgh data from mgz format and save to numpy format\n\n    1. load file\n    2. normalize intensity\n    3. resize\n    4. save as python block\n\n    TODO: check header info and such.?\n    '''", "\n", "\n", "# get files in input directory", "\n", "files", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "inpath", ")", "if", "f", ".", "endswith", "(", "ext", ")", "]", "\n", "\n", "# go through each file", "\n", "list_skipped_files", "=", "(", ")", "\n", "for", "fileidx", "in", "tqdm", "(", "range", "(", "len", "(", "files", ")", ")", ",", "ncols", "=", "80", ")", ":", "\n", "\n", "# load nifti volume", "\n", "        ", "volnii", "=", "nib", ".", "load", "(", "os", ".", "path", ".", "join", "(", "inpath", ",", "files", "[", "fileidx", "]", ")", ")", "\n", "\n", "# get the data out", "\n", "vol_data", "=", "volnii", ".", "get_data", "(", ")", ".", "astype", "(", "float", ")", "\n", "\n", "if", "(", "'dim'", "in", "volnii", ".", "header", ")", "and", "volnii", ".", "header", "[", "'dim'", "]", "[", "4", "]", ">", "1", ":", "\n", "            ", "vol_data", "=", "vol_data", "[", ":", ",", ":", ",", ":", ",", "-", "1", "]", "\n", "\n", "# process volume", "\n", "", "try", ":", "\n", "            ", "vol_data", "=", "vol_proc", "(", "vol_data", ",", "**", "kwargs", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "list_skipped_files", "+=", "(", "files", "[", "fileidx", "]", ",", ")", "\n", "print", "(", "\"Skipping %s\\nError: %s\"", "%", "(", "files", "[", "fileidx", "]", ",", "str", "(", "e", ")", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "continue", "\n", "\n", "", "if", "label_idx", "is", "not", "None", ":", "\n", "            ", "vol_data", "=", "(", "vol_data", "==", "label_idx", ")", ".", "astype", "(", "int", ")", "\n", "\n", "# save numpy file", "\n", "", "outname", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "join", "(", "outpath", ",", "files", "[", "fileidx", "]", ")", ")", "[", "0", "]", "+", "'.npz'", "\n", "np", ".", "savez_compressed", "(", "outname", ",", "vol_data", "=", "vol_data", ")", "\n", "\n", "", "for", "file", "in", "list_skipped_files", ":", "\n", "        ", "print", "(", "\"Skipped: %s\"", "%", "file", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.dataproc.scans_to_slices": [[84, 154], ["tqdm", "range", "nibabel.load", "nib.load.get_data().astype", "os.listdir", "f.endswith", "len", "os.path.join", "dataproc.vol_proc", "range", "range", "nib.load.get_data", "print", "numpy.squeeze", "PIL.Image.fromarray().convert().save", "nibabel.Nifti1Image", "nibabel.save", "numpy.squeeze", "numpy.squeeze", "numpy.expand_dims", "numpy.diag", "os.path.splitext", "PIL.Image.fromarray().convert", "os.path.splitext", "str", "os.path.join", "os.path.join", "PIL.Image.fromarray"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.dataproc.vol_proc", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "", "def", "scans_to_slices", "(", "inpath", ",", "outpath", ",", "slice_nrs", ",", "\n", "ext", "=", "'.mgz'", ",", "\n", "label_idx", "=", "None", ",", "\n", "dim_idx", "=", "2", ",", "\n", "out_ext", "=", "'.png'", ",", "\n", "slice_pad", "=", "0", ",", "\n", "vol_inner_pad_for_slice_nrs", "=", "0", ",", "\n", "**", "kwargs", ")", ":", "# vol_proc args", "\n", "\n", "# get files in input directory", "\n", "    ", "files", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "inpath", ")", "if", "f", ".", "endswith", "(", "ext", ")", "]", "\n", "\n", "# go through each file", "\n", "list_skipped_files", "=", "(", ")", "\n", "for", "fileidx", "in", "tqdm", "(", "range", "(", "len", "(", "files", ")", ")", ",", "ncols", "=", "80", ")", ":", "\n", "\n", "# load nifti volume", "\n", "        ", "volnii", "=", "nib", ".", "load", "(", "os", ".", "path", ".", "join", "(", "inpath", ",", "files", "[", "fileidx", "]", ")", ")", "\n", "\n", "# get the data out", "\n", "vol_data", "=", "volnii", ".", "get_data", "(", ")", ".", "astype", "(", "float", ")", "\n", "\n", "if", "(", "'dim'", "in", "volnii", ".", "header", ")", "and", "volnii", ".", "header", "[", "'dim'", "]", "[", "4", "]", ">", "1", ":", "\n", "            ", "vol_data", "=", "vol_data", "[", ":", ",", ":", ",", ":", ",", "-", "1", "]", "\n", "\n", "", "if", "slice_pad", ">", "0", ":", "\n", "            ", "assert", "(", "out_ext", "!=", "'.png'", ")", ",", "\"slice pad can only be used with volumes\"", "\n", "\n", "# process volume", "\n", "", "try", ":", "\n", "            ", "vol_data", "=", "vol_proc", "(", "vol_data", ",", "**", "kwargs", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "list_skipped_files", "+=", "(", "files", "[", "fileidx", "]", ",", ")", "\n", "print", "(", "\"Skipping %s\\nError: %s\"", "%", "(", "files", "[", "fileidx", "]", ",", "str", "(", "e", ")", ")", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "continue", "\n", "\n", "", "mult_fact", "=", "255", "\n", "if", "label_idx", "is", "not", "None", ":", "\n", "            ", "vol_data", "=", "(", "vol_data", "==", "label_idx", ")", ".", "astype", "(", "int", ")", "\n", "mult_fact", "=", "1", "\n", "\n", "# extract slice", "\n", "", "if", "slice_nrs", "is", "None", ":", "\n", "            ", "slice_nrs_sel", "=", "range", "(", "vol_inner_pad_for_slice_nrs", "+", "slice_pad", ",", "vol_data", ".", "shape", "[", "dim_idx", "]", "-", "slice_pad", "-", "vol_inner_pad_for_slice_nrs", ")", "\n", "", "else", ":", "\n", "            ", "slice_nrs_sel", "=", "slice_nrs", "\n", "\n", "", "for", "slice_nr", "in", "slice_nrs_sel", ":", "\n", "            ", "slice_nr_out", "=", "range", "(", "slice_nr", "-", "slice_pad", ",", "slice_nr", "+", "slice_pad", "+", "1", ")", "\n", "if", "dim_idx", "==", "2", ":", "# TODO: fix in one line", "\n", "                ", "vol_img", "=", "np", ".", "squeeze", "(", "vol_data", "[", ":", ",", ":", ",", "slice_nr_out", "]", ")", "\n", "", "elif", "dim_idx", "==", "1", ":", "\n", "                ", "vol_img", "=", "np", ".", "squeeze", "(", "vol_data", "[", ":", ",", "slice_nr_out", ",", ":", "]", ")", "\n", "", "else", ":", "\n", "                ", "vol_img", "=", "np", ".", "squeeze", "(", "vol_data", "[", "slice_nr_out", ",", ":", ",", ":", "]", ")", "\n", "\n", "# save file", "\n", "", "if", "out_ext", "==", "'.png'", ":", "\n", "# save png file", "\n", "                ", "img", "=", "(", "vol_img", "*", "mult_fact", ")", ".", "astype", "(", "'uint8'", ")", "\n", "outname", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "join", "(", "outpath", ",", "files", "[", "fileidx", "]", ")", ")", "[", "0", "]", "+", "'_slice%d.png'", "%", "slice_nr", "\n", "Image", ".", "fromarray", "(", "img", ")", ".", "convert", "(", "'RGB'", ")", ".", "save", "(", "outname", ")", "\n", "", "else", ":", "\n", "                ", "if", "slice_pad", "==", "0", ":", "# dimenion has collapsed", "\n", "                    ", "assert", "vol_img", ".", "ndim", "==", "2", "\n", "vol_img", "=", "np", ".", "expand_dims", "(", "vol_img", ",", "dim_idx", ")", "\n", "# assuming nibabel saving image", "\n", "", "nii", "=", "nib", ".", "Nifti1Image", "(", "vol_img", ",", "np", ".", "diag", "(", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", ")", "\n", "outname", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "join", "(", "outpath", ",", "files", "[", "fileidx", "]", ")", ")", "[", "0", "]", "+", "'_slice%d.nii.gz'", "%", "slice_nr", "\n", "nib", ".", "save", "(", "nii", ",", "outname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.dataproc.vol_proc": [[156, 225], ["numpy.multiply", "numpy.percentile", "numpy.multiply", "numpy.divide", "scipy.ndimage.interpolation.zoom", "ext.volcrop", "numpy.clip", "np.clip.astype", "numpy.divide", "numpy.round().astype", "numpy.max", "numpy.min", "numpy.where", "len", "numpy.ix_", "numpy.round"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.volcrop"], ["", "", "", "", "def", "vol_proc", "(", "vol_data", ",", "\n", "crop", "=", "None", ",", "\n", "resize_shape", "=", "None", ",", "# None (to not resize), or vector. If vector, third entry can be None", "\n", "interp_order", "=", "None", ",", "\n", "rescale", "=", "None", ",", "\n", "rescale_prctle", "=", "None", ",", "\n", "resize_slices", "=", "None", ",", "\n", "resize_slices_dim", "=", "None", ",", "\n", "offset", "=", "None", ",", "\n", "clip", "=", "None", ",", "\n", "extract_nd", "=", "None", ",", "# extracts a particular section", "\n", "force_binary", "=", "None", ",", "# forces anything > 0 to be 1", "\n", "permute", "=", "None", ")", ":", "\n", "    ", "''' process a volume with a series of intensity rescale, resize and crop rescale'''", "\n", "\n", "if", "offset", "is", "not", "None", ":", "\n", "        ", "vol_data", "=", "vol_data", "+", "offset", "\n", "\n", "# intensity normalize data .* rescale", "\n", "", "if", "rescale", "is", "not", "None", ":", "\n", "        ", "vol_data", "=", "np", ".", "multiply", "(", "vol_data", ",", "rescale", ")", "\n", "\n", "", "if", "rescale_prctle", "is", "not", "None", ":", "\n", "# print(\"max:\", np.max(vol_data.flat))", "\n", "# print(\"test\")", "\n", "        ", "rescale", "=", "np", ".", "percentile", "(", "vol_data", ".", "flat", ",", "rescale_prctle", ")", "\n", "# print(\"rescaling by 1/%f\" % (rescale))", "\n", "vol_data", "=", "np", ".", "multiply", "(", "vol_data", ".", "astype", "(", "float", ")", ",", "1", "/", "rescale", ")", "\n", "\n", "", "if", "resize_slices", "is", "not", "None", ":", "\n", "        ", "resize_slices", "=", "[", "*", "resize_slices", "]", "\n", "assert", "resize_shape", "is", "None", ",", "\"if resize_slices is given, resize_shape has to be None\"", "\n", "resize_shape", "=", "resize_slices", "\n", "if", "resize_slices_dim", "is", "None", ":", "\n", "            ", "resize_slices_dim", "=", "np", ".", "where", "(", "[", "f", "is", "None", "for", "f", "in", "resize_slices", "]", ")", "[", "0", "]", "\n", "assert", "len", "(", "resize_slices_dim", ")", "==", "1", ",", "\"Could not find dimension or slice resize\"", "\n", "resize_slices_dim", "=", "resize_slices_dim", "[", "0", "]", "\n", "", "resize_shape", "[", "resize_slices_dim", "]", "=", "vol_data", ".", "shape", "[", "resize_slices_dim", "]", "\n", "\n", "# resize (downsample) matrices", "\n", "", "if", "resize_shape", "is", "not", "None", "and", "resize_shape", "!=", "vol_data", ".", "shape", ":", "\n", "        ", "resize_shape", "=", "[", "*", "resize_shape", "]", "\n", "# allow for the last entry to be None", "\n", "if", "resize_shape", "[", "-", "1", "]", "is", "None", ":", "\n", "            ", "resize_ratio", "=", "np", ".", "divide", "(", "resize_shape", "[", "0", "]", ",", "vol_data", ".", "shape", "[", "0", "]", ")", "\n", "resize_shape", "[", "-", "1", "]", "=", "np", ".", "round", "(", "resize_ratio", "*", "vol_data", ".", "shape", "[", "-", "1", "]", ")", ".", "astype", "(", "'int'", ")", "\n", "", "resize_ratio", "=", "np", ".", "divide", "(", "resize_shape", ",", "vol_data", ".", "shape", ")", "\n", "vol_data", "=", "scipy", ".", "ndimage", ".", "interpolation", ".", "zoom", "(", "vol_data", ",", "resize_ratio", ",", "order", "=", "interp_order", ")", "\n", "\n", "# crop data if necessary", "\n", "", "if", "crop", "is", "not", "None", ":", "\n", "        ", "vol_data", "=", "nd", ".", "volcrop", "(", "vol_data", ",", "crop", "=", "crop", ")", "\n", "\n", "# needs to be last to guarantee clip limits.", "\n", "# For e.g., resize might screw this up due to bicubic interpolation if it was done after.", "\n", "", "if", "clip", "is", "not", "None", ":", "\n", "        ", "vol_data", "=", "np", ".", "clip", "(", "vol_data", ",", "clip", "[", "0", "]", ",", "clip", "[", "1", "]", ")", "\n", "\n", "", "if", "extract_nd", "is", "not", "None", ":", "\n", "        ", "vol_data", "=", "vol_data", "[", "np", ".", "ix_", "(", "*", "extract_nd", ")", "]", "\n", "\n", "", "if", "force_binary", ":", "\n", "        ", "vol_data", "=", "(", "vol_data", ">", "0", ")", ".", "astype", "(", "float", ")", "\n", "\n", "# return with checks. this check should be right at the end before rturn", "\n", "", "if", "clip", "is", "not", "None", ":", "\n", "        ", "assert", "np", ".", "max", "(", "vol_data", ")", "<=", "clip", "[", "1", "]", ",", "\"clip failed\"", "\n", "assert", "np", ".", "min", "(", "vol_data", ")", ">=", "clip", "[", "0", "]", ",", "\"clip failed\"", "\n", "", "return", "vol_data", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.dataproc.prior_to_weights": [[227, 281], ["isinstance", "numpy.reshape", "numpy.sum", "numpy.any", "numpy.sum", "numpy.delete", "numpy.sum", "numpy.sum", "print", "numpy.sum", "matplotlib.subplots", "ax1.bar", "ax1.set_title", "ax2.bar", "ax2.set_title", "ax3.bar", "ax3.set_title", "f.set_size_inches", "matplotlib.show", "numpy.set_printoptions", "numpy.load", "numpy.ndim", "numpy.ndim", "numpy.prod", "range", "range", "numpy.log", "range", "range", "numpy.log", "numpy.min", "numpy.log", "numpy.ndim"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "prior_to_weights", "(", "prior_filename", ",", "nargout", "=", "1", ",", "min_freq", "=", "0", ",", "force_binary", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "\n", "    ", "''' transform a 4D prior (3D + nb_labels) into a class weight vector '''", "\n", "\n", "# load prior", "\n", "if", "isinstance", "(", "prior_filename", ",", "six", ".", "string_types", ")", ":", "\n", "        ", "prior", "=", "np", ".", "load", "(", "prior_filename", ")", "[", "'prior'", "]", "\n", "", "else", ":", "\n", "        ", "prior", "=", "prior_filename", "\n", "\n", "# assumes prior is 4D.", "\n", "", "assert", "np", ".", "ndim", "(", "prior", ")", "==", "4", "or", "np", ".", "ndim", "(", "prior", ")", "==", "3", ",", "\"prior is the wrong number of dimensions\"", "\n", "prior_flat", "=", "np", ".", "reshape", "(", "prior", ",", "(", "np", ".", "prod", "(", "prior", ".", "shape", "[", "0", ":", "(", "np", ".", "ndim", "(", "prior", ")", "-", "1", ")", "]", ")", ",", "prior", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "\n", "if", "force_binary", ":", "\n", "        ", "nb_labels", "=", "prior_flat", ".", "shape", "[", "-", "1", "]", "\n", "prior_flat", "[", ":", ",", "1", "]", "=", "np", ".", "sum", "(", "prior_flat", "[", ":", ",", "1", ":", "nb_labels", "]", ",", "1", ")", "\n", "prior_flat", "=", "np", ".", "delete", "(", "prior_flat", ",", "range", "(", "2", ",", "nb_labels", ")", ",", "1", ")", "\n", "\n", "# sum total class votes", "\n", "", "class_count", "=", "np", ".", "sum", "(", "prior_flat", ",", "0", ")", "\n", "class_prior", "=", "class_count", "/", "np", ".", "sum", "(", "class_count", ")", "\n", "\n", "# adding minimum frequency", "\n", "class_prior", "[", "class_prior", "<", "min_freq", "]", "=", "min_freq", "\n", "class_prior", "=", "class_prior", "/", "np", ".", "sum", "(", "class_prior", ")", "\n", "\n", "if", "np", ".", "any", "(", "class_prior", "==", "0", ")", ":", "\n", "        ", "print", "(", "\"Warning, found a label with 0 support. Setting its weight to 0!\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "class_prior", "[", "class_prior", "==", "0", "]", "=", "np", ".", "inf", "\n", "\n", "# compute weights from class frequencies", "\n", "", "weights", "=", "1", "/", "class_prior", "\n", "weights", "=", "weights", "/", "np", ".", "sum", "(", "weights", ")", "\n", "# weights[0] = 0 # explicitly don't care about bg", "\n", "\n", "# a bit of verbosity", "\n", "if", "verbose", ":", "\n", "        ", "f", ",", "(", "ax1", ",", "ax2", ",", "ax3", ")", "=", "plt", ".", "subplots", "(", "1", ",", "3", ")", "\n", "ax1", ".", "bar", "(", "range", "(", "prior", ".", "size", ")", ",", "np", ".", "log", "(", "prior", ")", ")", "\n", "ax1", ".", "set_title", "(", "'log class freq'", ")", "\n", "ax2", ".", "bar", "(", "range", "(", "weights", ".", "size", ")", ",", "weights", ")", "\n", "ax2", ".", "set_title", "(", "'weights'", ")", "\n", "ax3", ".", "bar", "(", "range", "(", "weights", ".", "size", ")", ",", "np", ".", "log", "(", "(", "weights", ")", ")", "-", "np", ".", "min", "(", "np", ".", "log", "(", "(", "weights", ")", ")", ")", ")", "\n", "ax3", ".", "set_title", "(", "'log(weights)-minlog'", ")", "\n", "f", ".", "set_size_inches", "(", "12", ",", "3", ")", "\n", "plt", ".", "show", "(", ")", "\n", "np", ".", "set_printoptions", "(", "precision", "=", "3", ")", "\n", "\n", "# return", "\n", "", "if", "nargout", "==", "1", ":", "\n", "        ", "return", "weights", "\n", "", "else", ":", "\n", "        ", "return", "(", "weights", ",", "prior", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.dataproc.filestruct_change": [[285, 353], ["tqdm", "os.path.isdir", "os.mkdir", "os.listdir", "os.listdir", "os.path.join", "sum", "os.path.splitext", "isinstance", "os.path.join", "os.path.join", "os.path.join", "re.match", "os.path.isdir", "os.mkdir", "os.symlink", "shutil.copyfile", "re_map.keys", "enumerate", "list", "re_map.keys"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir"], ["", "", "def", "filestruct_change", "(", "in_path", ",", "out_path", ",", "re_map", ",", "\n", "mode", "=", "'subj_to_type'", ",", "\n", "use_symlinks", "=", "False", ",", "name", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"\n    change from independent subjects in a folder to breakdown structure \n\n    example: filestruct_change('/../in_path', '/../out_path', {'asegs.nii.gz':'asegs', 'norm.nii.gz':'vols'})\n\n\n    input structure: \n        /.../in_path/subj_1 --> with files that match regular repressions defined in re_map.keys()\n        /.../in_path/subj_2 --> with files that match regular repressions defined in re_map.keys()\n        ...\n    output structure:\n        /.../out_path/asegs/subj_1.nii.gz, subj_2.nii.gz\n        /.../out_path/vols/subj_1.nii.gz, subj_2.nii.gz\n\n    Parameters:\n        in_path (string): input path\n        out_path (string): output path\n        re_map (dictionary): keys are reg-exs that match files in the input folders. \n            values are the folders to put those files in the new structure. \n            values can also be tuples, in which case values[0] is the dst folder, \n            and values[1] is the extension of the output file\n        mode (optional)\n        use_symlinks (bool): whether to just use symlinks rather than copy files\n            default:True\n    \"\"\"", "\n", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "out_path", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "out_path", ")", "\n", "\n", "# go through folders", "\n", "", "for", "subj", "in", "tqdm", "(", "os", ".", "listdir", "(", "in_path", ")", ",", "desc", "=", "name", ")", ":", "\n", "\n", "# go through files in a folder", "\n", "        ", "files", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "in_path", ",", "subj", ")", ")", "\n", "for", "file", "in", "files", ":", "\n", "\n", "# see which key matches. Make sure only one does.", "\n", "            ", "matches", "=", "[", "re", ".", "match", "(", "k", ",", "file", ")", "for", "k", "in", "re_map", ".", "keys", "(", ")", "]", "\n", "nb_matches", "=", "sum", "(", "[", "f", "is", "not", "None", "for", "f", "in", "matches", "]", ")", "\n", "assert", "nb_matches", "==", "1", ",", "\"Found %d matches for file %s/%s\"", "%", "(", "nb_matches", ",", "file", ",", "subj", ")", "\n", "\n", "# get the matches key", "\n", "match_idx", "=", "[", "i", "for", "i", ",", "f", "in", "enumerate", "(", "matches", ")", "if", "f", "is", "not", "None", "]", "[", "0", "]", "\n", "matched_dst", "=", "re_map", "[", "list", "(", "re_map", ".", "keys", "(", ")", ")", "[", "match_idx", "]", "]", "\n", "_", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "file", ")", "\n", "if", "isinstance", "(", "matched_dst", ",", "tuple", ")", ":", "\n", "                ", "ext", "=", "matched_dst", "[", "1", "]", "\n", "matched_dst", "=", "matched_dst", "[", "0", "]", "\n", "\n", "# prepare source and destination file", "\n", "", "src_file", "=", "os", ".", "path", ".", "join", "(", "in_path", ",", "subj", ",", "file", ")", "\n", "dst_path", "=", "os", ".", "path", ".", "join", "(", "out_path", ",", "matched_dst", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "dst_path", ")", ":", "\n", "                ", "os", ".", "mkdir", "(", "dst_path", ")", "\n", "", "dst_file", "=", "os", ".", "path", ".", "join", "(", "dst_path", ",", "subj", "+", "ext", ")", "\n", "\n", "if", "use_symlinks", ":", "\n", "# on windows there are permission problems. ", "\n", "# Can try : call(['mklink', 'LINK', 'TARGET'], shell=True)", "\n", "# or note https://stackoverflow.com/questions/6260149/os-symlink-support-in-windows", "\n", "                ", "os", ".", "symlink", "(", "src_file", ",", "dst_file", ")", "\n", "\n", "", "else", ":", "\n", "                ", "shutil", ".", "copyfile", "(", "src_file", ",", "dst_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.dataproc.ml_split": [[355, 405], ["sorted", "len", "numpy.random.permutation", "numpy.cumsum", "numpy.round().astype", "enumerate", "numpy.random.seed", "os.path.isdir", "os.makedirs", "os.listdir", "print", "tqdm", "numpy.array", "numpy.round", "os.path.isdir", "os.mkdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.symlink", "os.path.isdir", "shutil.copytree", "shutil.copyfile"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.utils.mkdir"], ["", "", "", "", "def", "ml_split", "(", "in_path", ",", "out_path", ",", "\n", "cat_titles", "=", "[", "'train'", ",", "'validate'", ",", "'test'", "]", ",", "\n", "cat_prop", "=", "[", "0.5", ",", "0.3", ",", "0.2", "]", ",", "\n", "use_symlinks", "=", "False", ",", "\n", "seed", "=", "None", ",", "\n", "tqdm", "=", "tqdm", ")", ":", "\n", "    ", "\"\"\"\n    split dataset \n    \"\"\"", "\n", "\n", "if", "seed", "is", "not", "None", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "out_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_path", ")", "\n", "\n", "# get subjects and randomize their order", "\n", "", "subjs", "=", "sorted", "(", "os", ".", "listdir", "(", "in_path", ")", ")", "\n", "nb_subj", "=", "len", "(", "subjs", ")", "\n", "subj_order", "=", "np", ".", "random", ".", "permutation", "(", "nb_subj", ")", "\n", "\n", "# prepare split", "\n", "cat_tot", "=", "np", ".", "cumsum", "(", "cat_prop", ")", "\n", "if", "not", "cat_tot", "[", "-", "1", "]", "==", "1", ":", "\n", "        ", "print", "(", "\"split_prop sums to %f, re-normalizing\"", "%", "cat_tot", ")", "\n", "cat_tot", "=", "np", ".", "array", "(", "cat_tot", ")", "/", "cat_tot", "[", "-", "1", "]", "\n", "", "nb_cat_subj", "=", "np", ".", "round", "(", "cat_tot", "*", "nb_subj", ")", ".", "astype", "(", "int", ")", "\n", "cat_subj_start", "=", "[", "0", ",", "*", "nb_cat_subj", "[", ":", "-", "1", "]", "]", "\n", "\n", "# go through each category", "\n", "for", "cat_idx", ",", "cat", "in", "enumerate", "(", "cat_titles", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "cat", ")", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "out_path", ",", "cat", ")", ")", "\n", "\n", "", "cat_subj_idx", "=", "subj_order", "[", "cat_subj_start", "[", "cat_idx", "]", ":", "nb_cat_subj", "[", "cat_idx", "]", "]", "\n", "for", "subj_idx", "in", "tqdm", "(", "cat_subj_idx", ",", "desc", "=", "cat", ")", ":", "\n", "            ", "src_folder", "=", "os", ".", "path", ".", "join", "(", "in_path", ",", "subjs", "[", "subj_idx", "]", ")", "\n", "dst_folder", "=", "os", ".", "path", ".", "join", "(", "out_path", ",", "cat", ",", "subjs", "[", "subj_idx", "]", ")", "\n", "\n", "if", "use_symlinks", ":", "\n", "# on windows there are permission problems. ", "\n", "# Can try : call(['mklink', 'LINK', 'TARGET'], shell=True)", "\n", "# or note https://stackoverflow.com/questions/6260149/os-symlink-support-in-windows", "\n", "                ", "os", ".", "symlink", "(", "src_folder", ",", "dst_folder", ")", "\n", "\n", "", "else", ":", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "src_folder", ")", ":", "\n", "                    ", "shutil", ".", "copytree", "(", "src_folder", ",", "dst_folder", ")", "\n", "", "else", ":", "\n", "                    ", "shutil", ".", "copyfile", "(", "src_folder", ",", "dst_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.CategoricalCrossentropy.__init__": [[40, 60], ["utils.batch_gather"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.batch_gather"], ["def", "__init__", "(", "self", ",", "weights", "=", "None", ",", "use_float16", "=", "False", ",", "vox_weights", "=", "None", ",", "crop_indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            vox_weights is either a numpy array the same size as y_true,\n                or a string: 'y_true' or 'expy_true'\n            crop_indices: indices to crop each element of the batch\n                if each element is N-D (so y_true is N+1 dimensional)\n                then crop_indices is a Tensor of crop ranges (indices)\n                of size <= N-D. If it's < N-D, then it acts as a slice\n                for the last few dimensions.\n                See Also: tf.gather_nd\n        \"\"\"", "\n", "\n", "self", ".", "weights", "=", "weights", "if", "(", "weights", "is", "not", "None", ")", "else", "None", "\n", "self", ".", "use_float16", "=", "use_float16", "\n", "self", ".", "vox_weights", "=", "vox_weights", "\n", "self", ".", "crop_indices", "=", "crop_indices", "\n", "\n", "if", "self", ".", "crop_indices", "is", "not", "None", "and", "vox_weights", "is", "not", "None", ":", "\n", "            ", "self", ".", "vox_weights", "=", "utils", ".", "batch_gather", "(", "self", ".", "vox_weights", ",", "self", ".", "crop_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.CategoricalCrossentropy.loss": [[61, 95], ["keras.sum", "keras.clip", "keras.log", "keras.mean", "tensorflow.verify_tensor_all_finite", "utils.batch_gather", "utils.batch_gather", "keras.cast", "keras.cast", "keras.epsilon", "keras.sum", "keras.cast"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.batch_gather", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.batch_gather"], ["", "", "def", "loss", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "\n", "        ", "\"\"\" categorical crossentropy loss \"\"\"", "\n", "\n", "if", "self", ".", "crop_indices", "is", "not", "None", ":", "\n", "            ", "y_true", "=", "utils", ".", "batch_gather", "(", "y_true", ",", "self", ".", "crop_indices", ")", "\n", "y_pred", "=", "utils", ".", "batch_gather", "(", "y_pred", ",", "self", ".", "crop_indices", ")", "\n", "\n", "", "if", "self", ".", "use_float16", ":", "\n", "            ", "y_true", "=", "K", ".", "cast", "(", "y_true", ",", "'float16'", ")", "\n", "y_pred", "=", "K", ".", "cast", "(", "y_pred", ",", "'float16'", ")", "\n", "\n", "# scale and clip probabilities", "\n", "# this should not be necessary for softmax output.", "\n", "", "y_pred", "/=", "K", ".", "sum", "(", "y_pred", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "y_pred", "=", "K", ".", "clip", "(", "y_pred", ",", "K", ".", "epsilon", "(", ")", ",", "1", ")", "\n", "\n", "# compute log probability", "\n", "log_post", "=", "K", ".", "log", "(", "y_pred", ")", "# likelihood", "\n", "\n", "# loss", "\n", "loss", "=", "-", "y_true", "*", "log_post", "\n", "\n", "# weighted loss", "\n", "if", "self", ".", "weights", "is", "not", "None", ":", "\n", "            ", "loss", "*=", "self", ".", "weights", "\n", "\n", "", "if", "self", ".", "vox_weights", "is", "not", "None", ":", "\n", "            ", "loss", "*=", "self", ".", "vox_weights", "\n", "\n", "# take the total loss", "\n", "# loss = K.batch_flatten(loss)", "\n", "", "mloss", "=", "K", ".", "mean", "(", "K", ".", "sum", "(", "K", ".", "cast", "(", "loss", ",", "'float32'", ")", ",", "-", "1", ")", ")", "\n", "tf", ".", "verify_tensor_all_finite", "(", "mloss", ",", "'Loss not finite'", ")", "\n", "return", "mloss", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.Dice.__init__": [[157, 188], ["keras.variable", "keras.variable", "utils.batch_gather"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.batch_gather"], ["def", "__init__", "(", "self", ",", "nb_labels", ",", "\n", "weights", "=", "None", ",", "\n", "input_type", "=", "'prob'", ",", "\n", "dice_type", "=", "'soft'", ",", "\n", "approx_hard_max", "=", "True", ",", "\n", "vox_weights", "=", "None", ",", "\n", "crop_indices", "=", "None", ",", "\n", "area_reg", "=", "0.1", ")", ":", "# regularization for bottom of Dice coeff", "\n", "        ", "\"\"\"\n        input_type is 'prob', or 'max_label'\n        dice_type is hard or soft\n        approx_hard_max - see note below\n\n        Note: for hard dice, we grab the most likely label and then compute a\n        one-hot encoding for each voxel with respect to possible labels. To grab the most\n        likely labels, argmax() can be used, but only when Dice is used as a metric\n        For a Dice *loss*, argmax is not differentiable, and so we can't use it\n        Instead, we approximate the prob->one_hot translation when approx_hard_max is True.\n        \"\"\"", "\n", "\n", "self", ".", "nb_labels", "=", "nb_labels", "\n", "self", ".", "weights", "=", "None", "if", "weights", "is", "None", "else", "K", ".", "variable", "(", "weights", ")", "\n", "self", ".", "vox_weights", "=", "None", "if", "vox_weights", "is", "None", "else", "K", ".", "variable", "(", "vox_weights", ")", "\n", "self", ".", "input_type", "=", "input_type", "\n", "self", ".", "dice_type", "=", "dice_type", "\n", "self", ".", "approx_hard_max", "=", "approx_hard_max", "\n", "self", ".", "area_reg", "=", "area_reg", "\n", "self", ".", "crop_indices", "=", "crop_indices", "\n", "\n", "if", "self", ".", "crop_indices", "is", "not", "None", "and", "vox_weights", "is", "not", "None", ":", "\n", "            ", "self", ".", "vox_weights", "=", "utils", ".", "batch_gather", "(", "self", ".", "vox_weights", ",", "self", ".", "crop_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.Dice.dice": [[189, 257], ["range", "keras.square", "keras.square", "range", "keras.maximum", "utils.batch_gather", "utils.batch_gather", "keras.sum", "keras.clip", "keras.sum", "keras.clip", "keras.sum", "keras.sum", "keras.sum", "keras.epsilon", "keras.epsilon", "metrics._label_to_one_hot", "metrics._label_to_one_hot", "len", "len", "metrics._hard_max", "metrics._hard_max", "metrics._label_to_one_hot", "metrics._label_to_one_hot", "keras.int_shape", "keras.int_shape", "keras.argmax", "keras.argmax"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.batch_gather", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.batch_gather", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics._label_to_one_hot", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics._label_to_one_hot", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics._hard_max", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics._hard_max", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics._label_to_one_hot", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics._label_to_one_hot"], ["", "", "def", "dice", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "\n", "        ", "\"\"\"\n        compute dice for given Tensors\n\n        \"\"\"", "\n", "if", "self", ".", "crop_indices", "is", "not", "None", ":", "\n", "            ", "y_true", "=", "utils", ".", "batch_gather", "(", "y_true", ",", "self", ".", "crop_indices", ")", "\n", "y_pred", "=", "utils", ".", "batch_gather", "(", "y_pred", ",", "self", ".", "crop_indices", ")", "\n", "\n", "", "if", "self", ".", "input_type", "==", "'prob'", ":", "\n", "# We assume that y_true is probabilistic, but just in case:", "\n", "            ", "y_true", "/=", "K", ".", "sum", "(", "y_true", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "y_true", "=", "K", ".", "clip", "(", "y_true", ",", "K", ".", "epsilon", "(", ")", ",", "1", ")", "\n", "# make sure pred is a probability", "\n", "y_pred", "/=", "K", ".", "sum", "(", "y_pred", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "y_pred", "=", "K", ".", "clip", "(", "y_pred", ",", "K", ".", "epsilon", "(", ")", ",", "1", ")", "\n", "\n", "# Prepare the volumes to operate on", "\n", "# If we're doing 'hard' Dice, then we will prepare one-hot-based matrices of size", "\n", "# [batch_size, nb_voxels, nb_labels], where for each voxel in each batch entry,", "\n", "# the entries are either 0 or 1", "\n", "", "if", "self", ".", "dice_type", "==", "'hard'", ":", "\n", "\n", "# if given predicted probability, transform to \"hard max\"\"", "\n", "            ", "if", "self", ".", "input_type", "==", "'prob'", ":", "\n", "                ", "if", "self", ".", "approx_hard_max", ":", "\n", "                    ", "y_pred_op", "=", "_hard_max", "(", "y_pred", ",", "axis", "=", "-", "1", ")", "\n", "y_true_op", "=", "_hard_max", "(", "y_true", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "y_pred_op", "=", "_label_to_one_hot", "(", "K", ".", "argmax", "(", "y_pred", ",", "axis", "=", "-", "1", ")", ",", "self", ".", "nb_labels", ")", "\n", "y_true_op", "=", "_label_to_one_hot", "(", "K", ".", "argmax", "(", "y_true", ",", "axis", "=", "-", "1", ")", ",", "self", ".", "nb_labels", ")", "\n", "\n", "# if given predicted label, transform to one hot notation", "\n", "", "", "else", ":", "\n", "                ", "assert", "self", ".", "input_type", "==", "'max_label'", "\n", "y_pred_op", "=", "_label_to_one_hot", "(", "y_pred", ",", "self", ".", "nb_labels", ")", "\n", "y_true_op", "=", "_label_to_one_hot", "(", "y_true", ",", "self", ".", "nb_labels", ")", "\n", "\n", "# If we're doing soft Dice, require prob output, and the data already is as we need it", "\n", "# [batch_size, nb_voxels, nb_labels]", "\n", "", "", "else", ":", "\n", "            ", "assert", "self", ".", "input_type", "==", "'prob'", ",", "\"cannot do soft dice with max_label input\"", "\n", "y_pred_op", "=", "y_pred", "\n", "y_true_op", "=", "y_true", "\n", "\n", "# compute dice for each entry in batch.", "\n", "# dice will now be [batch_size, nb_labels]", "\n", "", "sum_dim", "=", "1", "\n", "\n", "# Edited by eugenio", "\n", "# top = 2 * K.sum(y_true_op * y_pred_op, sum_dim)", "\n", "sum_dim", "=", "1", "\n", "top", "=", "2", "*", "y_true_op", "*", "y_pred_op", "\n", "for", "dims_to_sum", "in", "range", "(", "len", "(", "K", ".", "int_shape", "(", "y_true_op", ")", ")", "-", "2", ")", ":", "\n", "            ", "top", "=", "K", ".", "sum", "(", "top", ",", "sum_dim", ")", "\n", "\n", "# Edited by eugenio", "\n", "# bottom = K.sum(K.square(y_true_op), sum_dim) + K.sum(K.square(y_pred_op), sum_dim)", "\n", "", "bottom_true", "=", "K", ".", "square", "(", "y_true_op", ")", "\n", "bottom_pred", "=", "K", ".", "square", "(", "y_pred_op", ")", "\n", "for", "dims_to_sum", "in", "range", "(", "len", "(", "K", ".", "int_shape", "(", "y_true_op", ")", ")", "-", "2", ")", ":", "\n", "            ", "bottom_true", "=", "K", ".", "sum", "(", "bottom_true", ",", "sum_dim", ")", "\n", "bottom_pred", "=", "K", ".", "sum", "(", "bottom_pred", ",", "sum_dim", ")", "\n", "", "bottom", "=", "bottom_pred", "+", "bottom_true", "\n", "\n", "# make sure we have no 0s on the bottom. K.epsilon()", "\n", "bottom", "=", "K", ".", "maximum", "(", "bottom", ",", "self", ".", "area_reg", ")", "\n", "return", "top", "/", "bottom", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.Dice.mean_dice": [[258, 274], ["metrics.Dice.dice", "keras.mean", "tensorflow.verify_tensor_all_finite"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.Dice.dice"], ["", "def", "mean_dice", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "\n", "        ", "\"\"\" weighted mean dice across all patches and labels \"\"\"", "\n", "\n", "# compute dice, which will now be [batch_size, nb_labels]", "\n", "dice_metric", "=", "self", ".", "dice", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "# weigh the entries in the dice matrix:", "\n", "if", "self", ".", "weights", "is", "not", "None", ":", "\n", "            ", "dice_metric", "*=", "self", ".", "weights", "\n", "", "if", "self", ".", "vox_weights", "is", "not", "None", ":", "\n", "            ", "dice_metric", "*=", "self", ".", "vox_weights", "\n", "\n", "# return one minus mean dice as loss", "\n", "", "mean_dice_metric", "=", "K", ".", "mean", "(", "dice_metric", ")", "\n", "tf", ".", "verify_tensor_all_finite", "(", "mean_dice_metric", ",", "'metric not finite'", ")", "\n", "return", "mean_dice_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.Dice.loss": [[276, 293], ["metrics.Dice.dice", "keras.mean", "tensorflow.verify_tensor_all_finite"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.Dice.dice"], ["", "def", "loss", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "\n", "        ", "\"\"\" the loss. Assumes y_pred is prob (in [0,1] and sum_row = 1) \"\"\"", "\n", "\n", "# compute dice, which will now be [batch_size, nb_labels]", "\n", "dice_metric", "=", "self", ".", "dice", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "# loss", "\n", "dice_loss", "=", "1", "-", "dice_metric", "\n", "\n", "# weigh the entries in the dice matrix:", "\n", "if", "self", ".", "weights", "is", "not", "None", ":", "\n", "            ", "dice_loss", "*=", "self", ".", "weights", "\n", "\n", "# return one minus mean dice as loss", "\n", "", "mean_dice_loss", "=", "K", ".", "mean", "(", "dice_loss", ")", "\n", "tf", ".", "verify_tensor_all_finite", "(", "mean_dice_loss", ",", "'Loss not finite'", ")", "\n", "return", "mean_dice_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.MeanSquaredError.__init__": [[301, 319], ["utils.batch_gather"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.batch_gather"], ["def", "__init__", "(", "self", ",", "weights", "=", "None", ",", "vox_weights", "=", "None", ",", "crop_indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            vox_weights is either a numpy array the same size as y_true,\n                or a string: 'y_true' or 'expy_true'\n            crop_indices: indices to crop each element of the batch\n                if each element is N-D (so y_true is N+1 dimensional)\n                then crop_indices is a Tensor of crop ranges (indices)\n                of size <= N-D. If it's < N-D, then it acts as a slice\n                for the last few dimensions.\n                See Also: tf.gather_nd\n        \"\"\"", "\n", "self", ".", "weights", "=", "weights", "\n", "self", ".", "vox_weights", "=", "vox_weights", "\n", "self", ".", "crop_indices", "=", "crop_indices", "\n", "\n", "if", "self", ".", "crop_indices", "is", "not", "None", "and", "vox_weights", "is", "not", "None", ":", "\n", "            ", "self", ".", "vox_weights", "=", "utils", ".", "batch_gather", "(", "self", ".", "vox_weights", ",", "self", ".", "crop_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.MeanSquaredError.loss": [[320, 340], ["keras.square", "keras.mean", "utils.batch_gather", "utils.batch_gather", "tensorflow.exp"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.batch_gather", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.batch_gather"], ["", "", "def", "loss", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "\n", "\n", "        ", "if", "self", ".", "crop_indices", "is", "not", "None", ":", "\n", "            ", "y_true", "=", "utils", ".", "batch_gather", "(", "y_true", ",", "self", ".", "crop_indices", ")", "\n", "y_pred", "=", "utils", ".", "batch_gather", "(", "y_pred", ",", "self", ".", "crop_indices", ")", "\n", "\n", "", "ksq", "=", "K", ".", "square", "(", "y_pred", "-", "y_true", ")", "\n", "\n", "if", "self", ".", "vox_weights", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "vox_weights", "==", "'y_true'", ":", "\n", "                ", "ksq", "*=", "y_true", "\n", "", "elif", "self", ".", "vox_weights", "==", "'expy_true'", ":", "\n", "                ", "ksq", "*=", "tf", ".", "exp", "(", "y_true", ")", "\n", "", "else", ":", "\n", "                ", "ksq", "*=", "self", ".", "vox_weights", "\n", "\n", "", "", "if", "self", ".", "weights", "is", "not", "None", ":", "\n", "            ", "ksq", "*=", "self", ".", "weights", "\n", "\n", "", "return", "K", ".", "mean", "(", "ksq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.Mix.__init__": [[345, 350], ["numpy.ones", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "losses", ",", "loss_wts", "=", "None", ")", ":", "\n", "        ", "self", ".", "losses", "=", "losses", "\n", "self", ".", "loss_wts", "=", "loss_wts", "\n", "if", "loss_wts", "is", "None", ":", "\n", "            ", "self", ".", "loss_wts", "=", "np", ".", "ones", "(", "len", "(", "loss_wts", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.Mix.loss": [[351, 356], ["keras.variable", "enumerate", "metrics.Mix.loss"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.Nonbg.loss"], ["", "", "def", "loss", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "\n", "        ", "total_loss", "=", "K", ".", "variable", "(", "0", ")", "\n", "for", "idx", ",", "loss", "in", "enumerate", "(", "self", ".", "losses", ")", ":", "\n", "            ", "total_loss", "+=", "self", ".", "loss_wts", "[", "idx", "]", "*", "loss", "(", "y_true", ",", "y_pred", ")", "\n", "", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.WGAN_GP.__init__": [[363, 367], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "disc", ",", "batch_size", "=", "1", ",", "lambda_gp", "=", "10", ")", ":", "\n", "        ", "self", ".", "disc", "=", "disc", "\n", "self", ".", "lambda_gp", "=", "lambda_gp", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.WGAN_GP.loss": [[368, 389], ["metrics.WGAN_GP.disc", "metrics.WGAN_GP.disc", "keras.random_uniform", "keras.mean", "keras.gradients", "keras.square", "metrics.WGAN_GP.disc", "keras.mean", "keras.mean", "keras.sqrt", "keras.shape", "keras.sum", "keras.square"], "methods", ["None"], ["", "def", "loss", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "\n", "\n", "# get the value for the true and fake images", "\n", "        ", "disc_true", "=", "self", ".", "disc", "(", "y_true", ")", "\n", "disc_pred", "=", "self", ".", "disc", "(", "y_pred", ")", "\n", "\n", "# sample a x_hat by sampling along the line between true and pred", "\n", "# z = tf.placeholder(tf.float32, shape=[None, 1])", "\n", "# shp = y_true.get_shape()[0]", "\n", "# WARNING: SHOULD REALLY BE shape=[batch_size, 1] !!!", "\n", "# self.batch_size does not work, since it's not None!!!", "\n", "alpha", "=", "K", ".", "random_uniform", "(", "shape", "=", "[", "K", ".", "shape", "(", "y_pred", ")", "[", "0", "]", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "diff", "=", "y_pred", "-", "y_true", "\n", "interp", "=", "y_true", "+", "alpha", "*", "diff", "\n", "\n", "# take gradient of D(x_hat)", "\n", "gradients", "=", "K", ".", "gradients", "(", "self", ".", "disc", "(", "interp", ")", ",", "[", "interp", "]", ")", "[", "0", "]", "\n", "grad_pen", "=", "K", ".", "mean", "(", "K", ".", "square", "(", "K", ".", "sqrt", "(", "K", ".", "sum", "(", "K", ".", "square", "(", "gradients", ")", ",", "axis", "=", "1", ")", ")", "-", "1", ")", ")", "\n", "\n", "# compute loss", "\n", "return", "(", "K", ".", "mean", "(", "disc_pred", ")", "-", "K", ".", "mean", "(", "disc_true", ")", ")", "+", "self", ".", "lambda_gp", "*", "grad_pen", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.Nonbg.__init__": [[403, 405], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "metric", ")", ":", "\n", "        ", "self", ".", "metric", "=", "metric", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.Nonbg.loss": [[406, 413], ["numpy.where", "keras.variable", "keras.variable", "metrics.Nonbg.metric", "yt.flat", "y_pred.flat"], "methods", ["None"], ["", "def", "loss", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "\n", "        ", "\"\"\" prepare a loss of the given metric/loss operating on non-bg data \"\"\"", "\n", "yt", "=", "y_true", "#.eval()", "\n", "ytbg", "=", "np", ".", "where", "(", "yt", "==", "0", ")", "\n", "y_true_fix", "=", "K", ".", "variable", "(", "yt", ".", "flat", "(", "ytbg", ")", ")", "\n", "y_pred_fix", "=", "K", ".", "variable", "(", "y_pred", ".", "flat", "(", "ytbg", ")", ")", "\n", "return", "self", ".", "metric", "(", "y_true_fix", ",", "y_pred_fix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.l1": [[415, 418], ["keras.losses.mean_absolute_error"], "function", ["None"], ["", "", "def", "l1", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "\"\"\" L1 metric (MAE) \"\"\"", "\n", "return", "losses", ".", "mean_absolute_error", "(", "y_true", ",", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics.l2": [[420, 423], ["keras.losses.mean_squared_error"], "function", ["None"], ["", "def", "l2", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "\"\"\" L2 metric (MSE) \"\"\"", "\n", "return", "losses", ".", "mean_squared_error", "(", "y_true", ",", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics._label_to_one_hot": [[429, 436], ["keras.batch_flatten", "keras.one_hot"], "function", ["None"], ["", "def", "_label_to_one_hot", "(", "tens", ",", "nb_labels", ")", ":", "\n", "    ", "\"\"\"\n    Transform a label nD Tensor to a one-hot 3D Tensor. The input tensor is first\n    batch-flattened, and then each batch and each voxel gets a one-hot representation\n    \"\"\"", "\n", "y", "=", "K", ".", "batch_flatten", "(", "tens", ")", "\n", "return", "K", ".", "one_hot", "(", "y", ",", "nb_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.metrics._hard_max": [[438, 449], ["keras.max", "keras.maximum", "keras.epsilon", "keras.epsilon"], "function", ["None"], ["", "def", "_hard_max", "(", "tens", ",", "axis", ")", ":", "\n", "    ", "\"\"\"\n    we can't use the argmax function in a loss, as it's not differentiable\n    We can use it in a metric, but not in a loss function\n    therefore, we replace the 'hard max' operation (i.e. argmax + onehot)\n    with this approximation\n    \"\"\"", "\n", "tensmax", "=", "K", ".", "max", "(", "tens", ",", "axis", "=", "axis", ",", "keepdims", "=", "True", ")", "\n", "eps_hot", "=", "K", ".", "maximum", "(", "tens", "-", "tensmax", "+", "K", ".", "epsilon", "(", ")", ",", "0", ")", "\n", "one_hot", "=", "eps_hot", "/", "K", ".", "epsilon", "(", ")", "\n", "return", "one_hot", "\n", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.Vol.__init__": [[29, 61], ["generators._get_file_list", "len", "generators._load_medical_volume", "os.path.join", "data_proc_fn", "all", "numpy.prod", "ext.pytools.patchlib.gridsize", "generators._npz_headers"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._get_file_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._load_medical_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.gridsize", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._npz_headers"], ["    ", "def", "__init__", "(", "self", ",", "\n", "volpath", ",", "\n", "ext", "=", "'.npz'", ",", "\n", "nb_restart_cycle", "=", "None", ",", "# number of files to restart after", "\n", "name", "=", "'single_vol'", ",", "# name", "\n", "fixed_vol_size", "=", "True", ",", "# assumes each volume is fixed size", "\n", ")", ":", "\n", "\n", "# get filenames at given paths", "\n", "        ", "volfiles", "=", "_get_file_list", "(", "volpath", ",", "ext", ",", "vol_rand_seed", ")", "\n", "nb_files", "=", "len", "(", "volfiles", ")", "\n", "assert", "nb_files", ">", "0", ",", "\"Could not find any files at %s with extension %s\"", "%", "(", "volpath", ",", "ext", ")", "\n", "\n", "# set up restart cycle for volume files --", "\n", "# i.e. after how many volumes do we restart", "\n", "if", "nb_restart_cycle", "is", "None", ":", "\n", "            ", "nb_restart_cycle", "=", "nb_files", "\n", "\n", "# compute subvolume split", "\n", "", "vol_data", "=", "_load_medical_volume", "(", "os", ".", "path", ".", "join", "(", "volpath", ",", "volfiles", "[", "0", "]", ")", ",", "ext", ")", "\n", "# process volume", "\n", "if", "data_proc_fn", "is", "not", "None", ":", "\n", "            ", "vol_data", "=", "data_proc_fn", "(", "vol_data", ")", "\n", "[", "f", "for", "f", "in", "_npz_headers", "(", "npz", ",", "namelist", "=", "[", "'vol_data.npy'", "]", ")", "]", "[", "0", "]", "[", "1", "]", "\n", "\n", "", "nb_patches_per_vol", "=", "1", "\n", "if", "fixed_vol_size", "and", "(", "patch_size", "is", "not", "None", ")", "and", "all", "(", "f", "is", "not", "None", "for", "f", "in", "patch_size", ")", ":", "\n", "            ", "nb_patches_per_vol", "=", "np", ".", "prod", "(", "pl", ".", "gridsize", "(", "vol_data", ".", "shape", ",", "patch_size", ",", "patch_stride", ")", ")", "\n", "\n", "", "assert", "nb_restart_cycle", "<=", "(", "nb_files", "*", "nb_patches_per_vol", ")", ",", "'%s restart cycle (%s) too big (%s) in %s'", "%", "(", "name", ",", "nb_restart_cycle", ",", "nb_files", "*", "nb_patches_per_vol", ",", "volpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol": [[63, 242], ["generators._get_file_list", "len", "generators._load_medical_volume", "os.path.join", "data_proc_fn", "all", "numpy.prod", "print", "print", "numpy.mod", "numpy.all", "generators.patch", "len", "len", "ext.pytools.patchlib.gridsize", "print", "print", "print", "os.path.join", "generators._load_medical_volume", "data_proc_fn", "generators._relabel", "enumerate", "numpy.any", "numpy.isfinite", "ValueError", "len", "len", "len", "len", "len", "print", "print", "numpy.isnan", "numpy.mod", "numpy.concatenate", "vol_data_feats.astype.astype", "numpy.mod", "len", "print", "numpy.mod", "print", "numpy.vstack", "os.path.join", "numpy.ndim", "numpy.vstack", "len", "sys.exc_info", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._get_file_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._load_medical_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.patch", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.gridsize", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._load_medical_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._relabel"], ["", "", "def", "vol", "(", "volpath", ",", "\n", "ext", "=", "'.npz'", ",", "\n", "batch_size", "=", "1", ",", "\n", "expected_nb_files", "=", "-", "1", ",", "\n", "expected_files", "=", "None", ",", "\n", "data_proc_fn", "=", "None", ",", "# processing function that takes in one arg (the volume)", "\n", "relabel", "=", "None", ",", "# relabeling array", "\n", "nb_labels_reshape", "=", "0", ",", "# reshape to categorial format for keras, need # labels", "\n", "keep_vol_size", "=", "False", ",", "# whether to keep the volume size on categorical resizing", "\n", "name", "=", "'single_vol'", ",", "# name, optional", "\n", "nb_restart_cycle", "=", "None", ",", "# number of files to restart after", "\n", "patch_size", "=", "None", ",", "# split the volume in patches? if so, get patch_size", "\n", "patch_stride", "=", "1", ",", "# split the volume in patches? if so, get patch_stride", "\n", "collapse_2d", "=", "None", ",", "\n", "extract_slice", "=", "None", ",", "\n", "force_binary", "=", "False", ",", "\n", "nb_feats", "=", "1", ",", "\n", "patch_rand", "=", "False", ",", "\n", "patch_rand_seed", "=", "None", ",", "\n", "vol_rand_seed", "=", "None", ",", "\n", "binary", "=", "False", ",", "\n", "yield_incomplete_final_batch", "=", "True", ",", "\n", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    generator for single volume (or volume patches) from a list of files\n\n    simple volume generator that loads a volume (via npy/mgz/nii/niigz), processes it,\n    and prepares it for keras model formats\n\n    if a patch size is passed, breaks the volume into patches and generates those\n    \"\"\"", "\n", "\n", "# get filenames at given paths", "\n", "volfiles", "=", "_get_file_list", "(", "volpath", ",", "ext", ",", "vol_rand_seed", ")", "\n", "nb_files", "=", "len", "(", "volfiles", ")", "\n", "assert", "nb_files", ">", "0", ",", "\"Could not find any files at %s with extension %s\"", "%", "(", "volpath", ",", "ext", ")", "\n", "\n", "# compute subvolume split", "\n", "vol_data", "=", "_load_medical_volume", "(", "os", ".", "path", ".", "join", "(", "volpath", ",", "volfiles", "[", "0", "]", ")", ",", "ext", ")", "\n", "\n", "# process volume", "\n", "if", "data_proc_fn", "is", "not", "None", ":", "\n", "        ", "vol_data", "=", "data_proc_fn", "(", "vol_data", ")", "\n", "\n", "", "nb_patches_per_vol", "=", "1", "\n", "if", "patch_size", "is", "not", "None", "and", "all", "(", "f", "is", "not", "None", "for", "f", "in", "patch_size", ")", ":", "\n", "        ", "if", "relabel", "is", "None", "and", "len", "(", "patch_size", ")", "==", "(", "len", "(", "vol_data", ".", "shape", ")", "-", "1", ")", ":", "\n", "            ", "tmp_patch_size", "=", "[", "f", "for", "f", "in", "patch_size", "]", "\n", "patch_size", "=", "[", "*", "patch_size", ",", "vol_data", ".", "shape", "[", "-", "1", "]", "]", "\n", "patch_stride", "=", "[", "f", "for", "f", "in", "patch_stride", "]", "\n", "patch_stride", "=", "[", "*", "patch_stride", ",", "vol_data", ".", "shape", "[", "-", "1", "]", "]", "\n", "", "assert", "len", "(", "vol_data", ".", "shape", ")", "==", "len", "(", "patch_size", ")", ",", "\"Vol dims %d are  not equal to patch dims %d\"", "%", "(", "len", "(", "vol_data", ".", "shape", ")", ",", "len", "(", "patch_size", ")", ")", "\n", "nb_patches_per_vol", "=", "np", ".", "prod", "(", "pl", ".", "gridsize", "(", "vol_data", ".", "shape", ",", "patch_size", ",", "patch_stride", ")", ")", "\n", "", "if", "nb_restart_cycle", "is", "None", ":", "\n", "        ", "print", "(", "\"setting restart cycle to\"", ",", "nb_files", ")", "\n", "nb_restart_cycle", "=", "nb_files", "\n", "\n", "", "assert", "nb_restart_cycle", "<=", "(", "nb_files", "*", "nb_patches_per_vol", ")", ",", "'%s restart cycle (%s) too big (%s) in %s'", "%", "(", "name", ",", "nb_restart_cycle", ",", "nb_files", "*", "nb_patches_per_vol", ",", "volpath", ")", "\n", "\n", "# check the number of files matches expected (if passed)", "\n", "if", "expected_nb_files", ">=", "0", ":", "\n", "        ", "assert", "nb_files", "==", "expected_nb_files", ",", "\"number of files do not match: %d, %d\"", "%", "(", "nb_files", ",", "expected_nb_files", ")", "\n", "", "if", "expected_files", "is", "not", "None", ":", "\n", "        ", "if", "not", "(", "volfiles", "==", "expected_files", ")", ":", "\n", "            ", "print", "(", "'file lists did not match. You should probably stop execution.'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "len", "(", "volfiles", ")", ",", "len", "(", "expected_files", ")", ")", "\n", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'nb_restart_cycle:'", ",", "nb_restart_cycle", ")", "\n", "\n", "# iterate through files", "\n", "", "fileidx", "=", "-", "1", "\n", "batch_idx", "=", "-", "1", "\n", "feat_idx", "=", "0", "\n", "batch_shape", "=", "None", "\n", "while", "1", ":", "\n", "        ", "fileidx", "=", "np", ".", "mod", "(", "fileidx", "+", "1", ",", "nb_restart_cycle", ")", "\n", "if", "verbose", "and", "fileidx", "==", "0", ":", "\n", "            ", "print", "(", "'starting %s cycle'", "%", "name", ")", "\n", "\n", "# read next file (circular)", "\n", "\n", "", "try", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'opening %s'", "%", "os", ".", "path", ".", "join", "(", "volpath", ",", "volfiles", "[", "fileidx", "]", ")", ")", "\n", "", "file_name", "=", "os", ".", "path", ".", "join", "(", "volpath", ",", "volfiles", "[", "fileidx", "]", ")", "\n", "vol_data", "=", "_load_medical_volume", "(", "file_name", ",", "ext", ",", "verbose", ")", "\n", "# print(file_name, \" was loaded\", vol_data.shape)", "\n", "", "except", ":", "\n", "            ", "debug_error_msg", "=", "\"#files: %d, fileidx: %d, nb_restart_cycle: %d. error: %s\"", "\n", "print", "(", "debug_error_msg", "%", "(", "len", "(", "volfiles", ")", ",", "fileidx", ",", "nb_restart_cycle", ",", "sys", ".", "exc_info", "(", ")", "[", "0", "]", ")", ")", "\n", "raise", "\n", "\n", "# process volume", "\n", "", "if", "data_proc_fn", "is", "not", "None", ":", "\n", "            ", "vol_data", "=", "data_proc_fn", "(", "vol_data", ")", "\n", "\n", "# the original segmentation files have non-sequential relabel (i.e. some relabel are", "\n", "# missing to avoid exploding our model, we only care about the relabel that exist.", "\n", "", "if", "relabel", "is", "not", "None", ":", "\n", "            ", "vol_data", "=", "_relabel", "(", "vol_data", ",", "relabel", ")", "\n", "\n", "# split volume into patches if necessary and yield", "\n", "", "if", "patch_size", "is", "None", ":", "\n", "            ", "this_patch_size", "=", "vol_data", ".", "shape", "\n", "patch_stride", "=", "[", "1", "for", "f", "in", "this_patch_size", "]", "\n", "\n", "", "else", ":", "\n", "            ", "this_patch_size", "=", "[", "f", "for", "f", "in", "patch_size", "]", "\n", "for", "pi", ",", "p", "in", "enumerate", "(", "this_patch_size", ")", ":", "\n", "                ", "if", "p", "is", "None", ":", "\n", "                    ", "this_patch_size", "[", "pi", "]", "=", "vol_data", ".", "shape", "[", "pi", "]", "\n", "patch_stride", "[", "pi", "]", "=", "1", "\n", "\n", "", "", "", "assert", "~", "np", ".", "any", "(", "np", ".", "isnan", "(", "vol_data", ")", ")", ",", "\"Found a nan for %s\"", "%", "volfiles", "[", "fileidx", "]", "\n", "assert", "np", ".", "all", "(", "np", ".", "isfinite", "(", "vol_data", ")", ")", ",", "\"Found a inf for %s\"", "%", "volfiles", "[", "fileidx", "]", "\n", "\n", "patch_gen", "=", "patch", "(", "vol_data", ",", "this_patch_size", ",", "\n", "patch_stride", "=", "patch_stride", ",", "\n", "nb_labels_reshape", "=", "nb_labels_reshape", ",", "\n", "batch_size", "=", "1", ",", "\n", "infinite", "=", "False", ",", "\n", "collapse_2d", "=", "collapse_2d", ",", "\n", "patch_rand", "=", "patch_rand", ",", "\n", "patch_rand_seed", "=", "patch_rand_seed", ",", "\n", "keep_vol_size", "=", "keep_vol_size", ")", "\n", "\n", "empty_gen", "=", "True", "\n", "patch_idx", "=", "-", "1", "\n", "for", "lpatch", "in", "patch_gen", ":", "\n", "            ", "empty_gen", "=", "False", "\n", "patch_idx", "+=", "1", "\n", "\n", "# add to feature", "\n", "if", "np", ".", "mod", "(", "feat_idx", ",", "nb_feats", ")", "==", "0", ":", "\n", "                ", "vol_data_feats", "=", "lpatch", "\n", "\n", "", "else", ":", "\n", "                ", "vol_data_feats", "=", "np", ".", "concatenate", "(", "[", "vol_data_feats", ",", "lpatch", "]", ",", "np", ".", "ndim", "(", "lpatch", ")", "-", "1", ")", "\n", "", "feat_idx", "+=", "1", "\n", "\n", "if", "binary", ":", "\n", "                ", "vol_data_feats", "=", "vol_data_feats", ".", "astype", "(", "bool", ")", "\n", "\n", "", "if", "np", ".", "mod", "(", "feat_idx", ",", "nb_feats", ")", "==", "0", ":", "\n", "                ", "feats_shape", "=", "vol_data_feats", "[", "1", ":", "]", "\n", "\n", "# yield previous batch if the new volume has different patch sizes", "\n", "if", "batch_shape", "is", "not", "None", "and", "(", "feats_shape", "!=", "batch_shape", ")", ":", "\n", "                    ", "batch_idx", "=", "-", "1", "\n", "batch_shape", "=", "None", "\n", "print", "(", "'switching patch sizes'", ")", "\n", "yield", "np", ".", "vstack", "(", "vol_data_batch", ")", "\n", "\n", "# add to batch of volume data, unless the batch is currently empty", "\n", "", "if", "batch_idx", "==", "-", "1", ":", "\n", "                    ", "vol_data_batch", "=", "[", "vol_data_feats", "]", "\n", "batch_shape", "=", "vol_data_feats", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                    ", "vol_data_batch", "=", "[", "*", "vol_data_batch", ",", "vol_data_feats", "]", "\n", "\n", "# yield patch", "\n", "", "batch_idx", "+=", "1", "\n", "batch_done", "=", "batch_idx", "==", "batch_size", "-", "1", "\n", "files_done", "=", "np", ".", "mod", "(", "fileidx", "+", "1", ",", "nb_restart_cycle", ")", "==", "0", "\n", "final_batch", "=", "yield_incomplete_final_batch", "and", "files_done", "and", "patch_idx", "==", "(", "nb_patches_per_vol", "-", "1", ")", "\n", "if", "final_batch", ":", "# verbose and ", "\n", "                    ", "print", "(", "'last batch in %s cycle %d. nb_batch:%d'", "%", "(", "name", ",", "fileidx", ",", "len", "(", "vol_data_batch", ")", ")", ")", "\n", "\n", "", "if", "batch_done", "or", "final_batch", ":", "\n", "                    ", "batch_idx", "=", "-", "1", "\n", "q", "=", "np", ".", "vstack", "(", "vol_data_batch", ")", "\n", "yield", "q", "\n", "\n", "", "", "", "if", "empty_gen", ":", "\n", "            ", "raise", "ValueError", "(", "'Patch generator was empty for file %s'", ",", "volfiles", "[", "fileidx", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.patch": [[244, 321], ["enumerate", "ext.pytools.patchlib.patch_gen", "generators._categorical_prep", "numpy.squeeze", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.patch_gen", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._categorical_prep"], ["", "", "", "def", "patch", "(", "vol_data", ",", "# the volume", "\n", "patch_size", ",", "# patch size", "\n", "patch_stride", "=", "1", ",", "# patch stride (spacing)", "\n", "nb_labels_reshape", "=", "1", ",", "# number of labels for categorical resizing. 0 if no resizing", "\n", "keep_vol_size", "=", "False", ",", "# whether to keep the volume size on categorical resizing", "\n", "batch_size", "=", "1", ",", "# batch size", "\n", "collapse_2d", "=", "None", ",", "\n", "patch_rand", "=", "False", ",", "\n", "patch_rand_seed", "=", "None", ",", "\n", "variable_batch_size", "=", "False", ",", "\n", "infinite", "=", "False", ")", ":", "# whether the generator should continue (re)-generating patches", "\n", "    ", "\"\"\"\n    generate patches from volume for keras package\n\n    Yields:\n        patch: nd array of shape [batch_size, *patch_size], unless resized via nb_labels_reshape\n    \"\"\"", "\n", "\n", "# some parameter setup", "\n", "assert", "batch_size", ">=", "1", ",", "\"batch_size should be at least 1\"", "\n", "if", "patch_size", "is", "None", ":", "\n", "        ", "patch_size", "=", "vol_data", ".", "shape", "\n", "", "for", "pi", ",", "p", "in", "enumerate", "(", "patch_size", ")", ":", "\n", "        ", "if", "p", "is", "None", ":", "\n", "            ", "patch_size", "[", "pi", "]", "=", "vol_data", ".", "shape", "[", "pi", "]", "\n", "", "", "batch_idx", "=", "-", "1", "\n", "if", "variable_batch_size", ":", "\n", "        ", "batch_size", "=", "yield", "\n", "\n", "\n", "# do while. if not infinite, will break at the end", "\n", "", "while", "True", ":", "\n", "# create patch generator", "\n", "        ", "gen", "=", "pl", ".", "patch_gen", "(", "vol_data", ",", "patch_size", ",", "\n", "stride", "=", "patch_stride", ",", "\n", "rand", "=", "patch_rand", ",", "\n", "rand_seed", "=", "patch_rand_seed", ")", "\n", "\n", "# go through the patch generator", "\n", "empty_gen", "=", "True", "\n", "for", "lpatch", "in", "gen", ":", "\n", "\n", "            ", "empty_gen", "=", "False", "\n", "# reshape output layer as categorical and prep proper size", "\n", "# print(lpatch.shape, nb_labels_reshape, keep_vol_size, patch_size)", "\n", "lpatch", "=", "_categorical_prep", "(", "lpatch", ",", "nb_labels_reshape", ",", "keep_vol_size", ",", "patch_size", ")", "\n", "\n", "if", "collapse_2d", "is", "not", "None", ":", "\n", "                ", "lpatch", "=", "np", ".", "squeeze", "(", "lpatch", ",", "collapse_2d", "+", "1", ")", "# +1 due to batch in first dim", "\n", "\n", "# add this patch to the stack", "\n", "", "if", "batch_idx", "==", "-", "1", ":", "\n", "                ", "if", "batch_size", "==", "1", ":", "\n", "                    ", "patch_data_batch", "=", "lpatch", "\n", "", "else", ":", "\n", "                    ", "patch_data_batch", "=", "np", ".", "zeros", "(", "[", "batch_size", ",", "*", "lpatch", ".", "shape", "[", "1", ":", "]", "]", ")", "\n", "patch_data_batch", "[", "0", ",", ":", "]", "=", "lpatch", "\n", "\n", "", "", "else", ":", "\n", "                ", "patch_data_batch", "[", "batch_idx", "+", "1", ",", ":", "]", "=", "lpatch", "\n", "\n", "# yield patch", "\n", "", "batch_idx", "+=", "1", "\n", "if", "batch_idx", "==", "batch_size", "-", "1", ":", "\n", "                ", "batch_idx", "=", "-", "1", "\n", "batch_size_y", "=", "yield", "patch_data_batch", "\n", "if", "variable_batch_size", ":", "\n", "                    ", "batch_size", "=", "batch_size_y", "\n", "\n", "", "", "", "assert", "not", "empty_gen", ",", "'generator was empty. vol size was %s'", "%", "''", ".", "join", "(", "[", "'%d '", "%", "d", "for", "d", "in", "vol_data", ".", "shape", "]", ")", "\n", "\n", "# if not infinite generation, yield the last batch and break the while", "\n", "if", "not", "infinite", ":", "\n", "            ", "if", "batch_idx", ">=", "0", ":", "\n", "                ", "patch_data_batch", "=", "patch_data_batch", "[", ":", "(", "batch_idx", "+", "1", ")", ",", ":", "]", "\n", "yield", "patch_data_batch", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol_seg": [[323, 374], ["generators.vol", "generators.vol", "f.replace", "next().astype", "next().astype", "generators._get_file_list", "next", "next"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._get_file_list"], ["", "", "", "def", "vol_seg", "(", "volpath", ",", "\n", "segpath", ",", "\n", "proc_vol_fn", "=", "None", ",", "\n", "proc_seg_fn", "=", "None", ",", "\n", "verbose", "=", "False", ",", "\n", "name", "=", "'vol_seg'", ",", "# name, optional", "\n", "ext", "=", "'.npz'", ",", "\n", "nb_restart_cycle", "=", "None", ",", "# number of files to restart after", "\n", "nb_labels_reshape", "=", "-", "1", ",", "\n", "collapse_2d", "=", "None", ",", "\n", "force_binary", "=", "False", ",", "\n", "nb_input_feats", "=", "1", ",", "\n", "relabel", "=", "None", ",", "\n", "vol_rand_seed", "=", "None", ",", "\n", "seg_binary", "=", "False", ",", "\n", "vol_subname", "=", "'norm'", ",", "# subname of volume", "\n", "seg_subname", "=", "'aseg'", ",", "# subname of segmentation", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    generator with (volume, segmentation)\n\n    verbose is passed down to the base generators.py primitive generator (e.g. vol, here)\n\n    ** kwargs are any named arguments for vol(...),\n        except verbose, data_proc_fn, ext, nb_labels_reshape and name\n            (which this function will control when calling vol())\n    \"\"\"", "\n", "\n", "# get vol generator", "\n", "vol_gen", "=", "vol", "(", "volpath", ",", "**", "kwargs", ",", "ext", "=", "ext", ",", "\n", "nb_restart_cycle", "=", "nb_restart_cycle", ",", "collapse_2d", "=", "collapse_2d", ",", "force_binary", "=", "False", ",", "\n", "relabel", "=", "None", ",", "data_proc_fn", "=", "proc_vol_fn", ",", "nb_labels_reshape", "=", "1", ",", "name", "=", "name", "+", "' vol'", ",", "\n", "verbose", "=", "verbose", ",", "nb_feats", "=", "nb_input_feats", ",", "vol_rand_seed", "=", "vol_rand_seed", ")", "\n", "\n", "# get seg generator, matching nb_files", "\n", "# vol_files = [f.replace('norm', 'aseg') for f in _get_file_list(volpath, ext)]", "\n", "# vol_files = [f.replace('orig', 'aseg') for f in vol_files]", "\n", "vol_files", "=", "[", "f", ".", "replace", "(", "vol_subname", ",", "seg_subname", ")", "for", "f", "in", "_get_file_list", "(", "volpath", ",", "ext", ",", "vol_rand_seed", ")", "]", "\n", "seg_gen", "=", "vol", "(", "segpath", ",", "**", "kwargs", ",", "ext", "=", "ext", ",", "nb_restart_cycle", "=", "nb_restart_cycle", ",", "collapse_2d", "=", "collapse_2d", ",", "\n", "force_binary", "=", "force_binary", ",", "relabel", "=", "relabel", ",", "vol_rand_seed", "=", "vol_rand_seed", ",", "\n", "data_proc_fn", "=", "proc_seg_fn", ",", "nb_labels_reshape", "=", "nb_labels_reshape", ",", "keep_vol_size", "=", "True", ",", "\n", "expected_files", "=", "vol_files", ",", "name", "=", "name", "+", "' seg'", ",", "binary", "=", "seg_binary", ",", "verbose", "=", "False", ")", "\n", "\n", "# on next (while):", "\n", "while", "1", ":", "\n", "# get input and output (seg) vols", "\n", "        ", "input_vol", "=", "next", "(", "vol_gen", ")", ".", "astype", "(", "'float16'", ")", "\n", "output_vol", "=", "next", "(", "seg_gen", ")", ".", "astype", "(", "'float16'", ")", "# was int8. Why? need float possibility...", "\n", "\n", "# output input and output", "\n", "yield", "(", "input_vol", ",", "output_vol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol_cat": [[376, 429], ["dataproc.vol_proc", "generators.vol", "print", "numpy.hstack().astype", "numpy.random.shuffle", "sorted", "os.path.join", "len", "numpy.zeros", "next().astype", "os.listdir", "generators._get_file_list", "numpy.hstack", "os.path.join", "next", "numpy.zeros", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.dataproc.vol_proc", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._get_file_list"], ["", "", "def", "vol_cat", "(", "volpaths", ",", "# expect two folders in here", "\n", "crop", "=", "None", ",", "resize_shape", "=", "None", ",", "rescale", "=", "None", ",", "# processing parameters", "\n", "verbose", "=", "False", ",", "\n", "name", "=", "'vol_cat'", ",", "# name, optional", "\n", "ext", "=", "'.npz'", ",", "\n", "nb_labels_reshape", "=", "-", "1", ",", "\n", "vol_rand_seed", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "# named arguments for vol(...), except verbose, data_proc_fn, ext, nb_labels_reshape and name (which this function will control when calling vol()) ", "\n", "    ", "\"\"\"\n    generator with (volume, binary_bit) (random order)\n    ONLY works with abtch size of 1 for now\n\n    verbose is passed down to the base generators.py primitive generator (e.g. vol, here)\n    \"\"\"", "\n", "\n", "folders", "=", "[", "f", "for", "f", "in", "sorted", "(", "os", ".", "listdir", "(", "volpaths", ")", ")", "]", "\n", "\n", "# compute processing function", "\n", "proc_vol_fn", "=", "lambda", "x", ":", "nrn_proc", ".", "vol_proc", "(", "x", ",", "crop", "=", "crop", ",", "resize_shape", "=", "resize_shape", ",", "\n", "interp_order", "=", "2", ",", "rescale", "=", "rescale", ")", "\n", "\n", "# get vol generators", "\n", "generators", "=", "(", ")", "\n", "generators_len", "=", "(", ")", "\n", "for", "folder", "in", "folders", ":", "\n", "        ", "vol_gen", "=", "vol", "(", "os", ".", "path", ".", "join", "(", "volpaths", ",", "folder", ")", ",", "**", "kwargs", ",", "ext", "=", "ext", ",", "vol_rand_seed", "=", "vol_rand_seed", ",", "\n", "data_proc_fn", "=", "proc_vol_fn", ",", "nb_labels_reshape", "=", "1", ",", "name", "=", "folder", ",", "verbose", "=", "False", ")", "\n", "generators_len", "+=", "(", "len", "(", "_get_file_list", "(", "os", ".", "path", ".", "join", "(", "volpaths", ",", "folder", ")", ",", "'.npz'", ")", ")", ",", ")", "\n", "generators", "+=", "(", "vol_gen", ",", ")", "\n", "\n", "", "bake_data_test", "=", "False", "\n", "if", "bake_data_test", ":", "\n", "        ", "print", "(", "'fake_data_test'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "# on next (while):", "\n", "", "while", "1", ":", "\n", "# build the random order stack", "\n", "        ", "order", "=", "np", ".", "hstack", "(", "(", "np", ".", "zeros", "(", "generators_len", "[", "0", "]", ")", ",", "np", ".", "ones", "(", "generators_len", "[", "1", "]", ")", ")", ")", ".", "astype", "(", "'int'", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "order", ")", "# shuffle", "\n", "for", "idx", "in", "order", ":", "\n", "            ", "gen", "=", "generators", "[", "idx", "]", "\n", "\n", "# for idx, gen in enumerate(generators):", "\n", "z", "=", "np", ".", "zeros", "(", "[", "1", ",", "2", "]", ")", "#1,1,2 for categorical binary style", "\n", "z", "[", "0", ",", "idx", "]", "=", "1", "#", "\n", "# z[0,0,0] = idx", "\n", "\n", "data", "=", "next", "(", "gen", ")", ".", "astype", "(", "'float32'", ")", "\n", "if", "bake_data_test", "and", "idx", "==", "0", ":", "\n", "# data = data*idx", "\n", "                ", "data", "=", "-", "data", "\n", "\n", "", "yield", "(", "data", ",", "z", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.add_prior": [[431, 510], ["generators.patch", "ext.pynd.ndutils.volsize2ndgrid", "numpy.transpose", "numpy.expand_dims", "numpy.sum", "numpy.delete", "isinstance", "len", "len", "next", "next", "generators._get_shape", "patch.send", "range", "numpy.ndim", "numpy.ndim", "ext.pytools.timer.Timer", "numpy.load", "data[].astype", "ext.pytools.timer.Timer", "prior_file.astype"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.patch", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.volsize2ndgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._get_shape", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "", "", "def", "add_prior", "(", "gen", ",", "\n", "proc_vol_fn", "=", "None", ",", "\n", "proc_seg_fn", "=", "None", ",", "\n", "prior_type", "=", "'location'", ",", "# file-static, file-gen, location", "\n", "prior_file", "=", "None", ",", "# prior filename", "\n", "prior_feed", "=", "'input'", ",", "# input or output", "\n", "patch_stride", "=", "1", ",", "\n", "patch_size", "=", "None", ",", "\n", "batch_size", "=", "1", ",", "\n", "collapse_2d", "=", "None", ",", "\n", "extract_slice", "=", "None", ",", "\n", "force_binary", "=", "False", ",", "\n", "verbose", "=", "False", ",", "\n", "patch_rand", "=", "False", ",", "\n", "patch_rand_seed", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    #\n    # add a prior generator to a given generator\n    # with the number of patches in batch matching output of gen\n    \"\"\"", "\n", "\n", "# get prior", "\n", "if", "prior_type", "==", "'location'", ":", "\n", "        ", "prior_vol", "=", "nd", ".", "volsize2ndgrid", "(", "vol_size", ")", "\n", "prior_vol", "=", "np", ".", "transpose", "(", "prior_vol", ",", "[", "1", ",", "2", ",", "3", ",", "0", "]", ")", "\n", "prior_vol", "=", "np", ".", "expand_dims", "(", "prior_vol", ",", "axis", "=", "0", ")", "# reshape for model", "\n", "\n", "", "elif", "prior_type", "==", "'file'", ":", "# assumes a npz filename passed in prior_file", "\n", "        ", "with", "timer", ".", "Timer", "(", "'loading prior'", ",", "True", ")", ":", "\n", "            ", "data", "=", "np", ".", "load", "(", "prior_file", ")", "\n", "prior_vol", "=", "data", "[", "'prior'", "]", ".", "astype", "(", "'float16'", ")", "\n", "\n", "", "", "else", ":", "# assumes a volume", "\n", "        ", "with", "timer", ".", "Timer", "(", "'loading prior'", ",", "True", ")", ":", "\n", "            ", "prior_vol", "=", "prior_file", ".", "astype", "(", "'float16'", ")", "\n", "\n", "", "", "if", "force_binary", ":", "\n", "        ", "nb_labels", "=", "prior_vol", ".", "shape", "[", "-", "1", "]", "\n", "prior_vol", "[", ":", ",", ":", ",", ":", ",", "1", "]", "=", "np", ".", "sum", "(", "prior_vol", "[", ":", ",", ":", ",", ":", ",", "1", ":", "nb_labels", "]", ",", "3", ")", "\n", "prior_vol", "=", "np", ".", "delete", "(", "prior_vol", ",", "range", "(", "2", ",", "nb_labels", ")", ",", "3", ")", "\n", "\n", "", "nb_channels", "=", "prior_vol", ".", "shape", "[", "-", "1", "]", "\n", "\n", "if", "extract_slice", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "extract_slice", ",", "int", ")", ":", "\n", "            ", "prior_vol", "=", "prior_vol", "[", ":", ",", ":", ",", "extract_slice", ",", "np", ".", "newaxis", ",", ":", "]", "\n", "", "else", ":", "# assume slices", "\n", "            ", "prior_vol", "=", "prior_vol", "[", ":", ",", ":", ",", "extract_slice", ",", ":", "]", "\n", "\n", "# get the prior to have the right volume [x, y, z, nb_channels]", "\n", "", "", "assert", "np", ".", "ndim", "(", "prior_vol", ")", "==", "4", "or", "np", ".", "ndim", "(", "prior_vol", ")", "==", "3", ",", "\"prior is the wrong size\"", "\n", "\n", "# prior generator", "\n", "if", "patch_size", "is", "None", ":", "\n", "        ", "patch_size", "=", "prior_vol", ".", "shape", "[", "0", ":", "3", "]", "\n", "", "assert", "len", "(", "patch_size", ")", "==", "len", "(", "patch_stride", ")", "\n", "prior_gen", "=", "patch", "(", "prior_vol", ",", "[", "*", "patch_size", ",", "nb_channels", "]", ",", "\n", "patch_stride", "=", "[", "*", "patch_stride", ",", "nb_channels", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "collapse_2d", "=", "collapse_2d", ",", "\n", "keep_vol_size", "=", "True", ",", "\n", "infinite", "=", "True", ",", "\n", "patch_rand", "=", "patch_rand", ",", "\n", "patch_rand_seed", "=", "patch_rand_seed", ",", "\n", "variable_batch_size", "=", "True", ",", "\n", "nb_labels_reshape", "=", "0", ")", "\n", "assert", "next", "(", "prior_gen", ")", "is", "None", ",", "\"bad prior gen setup\"", "\n", "\n", "# generator loop", "\n", "while", "1", ":", "\n", "\n", "# generate input and output volumes", "\n", "        ", "gen_sample", "=", "next", "(", "gen", ")", "\n", "\n", "# generate prior batch", "\n", "gs_sample", "=", "_get_shape", "(", "gen_sample", ")", "\n", "prior_batch", "=", "prior_gen", ".", "send", "(", "gs_sample", ")", "\n", "\n", "yield", "(", "gen_sample", ",", "prior_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol_prior": [[512, 590], ["generators.vol", "generators.vol", "generators.add_prior", "numpy.random.random", "next"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.add_prior"], ["", "", "def", "vol_prior", "(", "*", "args", ",", "\n", "proc_vol_fn", "=", "None", ",", "\n", "proc_seg_fn", "=", "None", ",", "\n", "prior_type", "=", "'location'", ",", "# file-static, file-gen, location", "\n", "prior_file", "=", "None", ",", "# prior filename", "\n", "prior_feed", "=", "'input'", ",", "# input or output", "\n", "patch_stride", "=", "1", ",", "\n", "patch_size", "=", "None", ",", "\n", "batch_size", "=", "1", ",", "\n", "collapse_2d", "=", "None", ",", "\n", "extract_slice", "=", "None", ",", "\n", "force_binary", "=", "False", ",", "\n", "nb_input_feats", "=", "1", ",", "\n", "verbose", "=", "False", ",", "\n", "vol_rand_seed", "=", "None", ",", "\n", "patch_rand", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "# anything else you'd like to pass to vol()", "\n", "    ", "\"\"\"\n    generator that appends prior to (volume, segmentation) depending on input\n    e.g. could be ((volume, prior), segmentation)\n    \"\"\"", "\n", "\n", "patch_rand_seed", "=", "None", "\n", "if", "patch_rand", ":", "\n", "        ", "patch_rand_seed", "=", "np", ".", "random", ".", "random", "(", ")", "\n", "\n", "\n", "# prepare the vol_seg", "\n", "", "vol_gen", "=", "vol", "(", "*", "args", ",", "\n", "**", "kwargs", ",", "\n", "collapse_2d", "=", "collapse_2d", ",", "\n", "force_binary", "=", "False", ",", "\n", "verbose", "=", "verbose", ",", "\n", "vol_rand_seed", "=", "vol_rand_seed", ")", "\n", "gen", "=", "vol", "(", "*", "args", ",", "**", "kwargs", ",", "\n", "proc_vol_fn", "=", "None", ",", "\n", "proc_seg_fn", "=", "None", ",", "\n", "collapse_2d", "=", "collapse_2d", ",", "\n", "extract_slice", "=", "extract_slice", ",", "\n", "force_binary", "=", "force_binary", ",", "\n", "verbose", "=", "verbose", ",", "\n", "patch_size", "=", "patch_size", ",", "\n", "patch_stride", "=", "patch_stride", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "vol_rand_seed", "=", "vol_rand_seed", ",", "\n", "patch_rand", "=", "patch_rand", ",", "\n", "patch_rand_seed", "=", "patch_rand_seed", ",", "\n", "nb_input_feats", "=", "nb_input_feats", ")", "\n", "\n", "# add prior to output", "\n", "pgen", "=", "add_prior", "(", "gen", ",", "\n", "proc_vol_fn", "=", "proc_vol_fn", ",", "\n", "proc_seg_fn", "=", "proc_seg_fn", ",", "\n", "prior_type", "=", "prior_type", ",", "\n", "prior_file", "=", "prior_file", ",", "\n", "prior_feed", "=", "prior_feed", ",", "\n", "patch_stride", "=", "patch_stride", ",", "\n", "patch_size", "=", "patch_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "collapse_2d", "=", "collapse_2d", ",", "\n", "extract_slice", "=", "extract_slice", ",", "\n", "force_binary", "=", "force_binary", ",", "\n", "verbose", "=", "verbose", ",", "\n", "patch_rand", "=", "patch_rand", ",", "\n", "patch_rand_seed", "=", "patch_rand_seed", ",", "\n", "vol_rand_seed", "=", "vol_rand_seed", ")", "\n", "\n", "# generator loop", "\n", "while", "1", ":", "\n", "\n", "        ", "gen_sample", ",", "prior_batch", "=", "next", "(", "pgen", ")", "\n", "input_vol", ",", "output_vol", "=", "gen_sample", "\n", "\n", "if", "prior_feed", "==", "'input'", ":", "\n", "            ", "yield", "(", "[", "input_vol", ",", "prior_batch", "]", ",", "output_vol", ")", "\n", "", "else", ":", "\n", "            ", "assert", "prior_feed", "==", "'output'", "\n", "yield", "(", "input_vol", ",", "[", "output_vol", ",", "prior_batch", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol_seg_prior": [[592, 663], ["generators.vol_seg", "generators.add_prior", "numpy.random.random", "next"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol_seg", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.add_prior"], ["", "", "", "def", "vol_seg_prior", "(", "*", "args", ",", "\n", "proc_vol_fn", "=", "None", ",", "\n", "proc_seg_fn", "=", "None", ",", "\n", "prior_type", "=", "'location'", ",", "# file-static, file-gen, location", "\n", "prior_file", "=", "None", ",", "# prior filename", "\n", "prior_feed", "=", "'input'", ",", "# input or output", "\n", "patch_stride", "=", "1", ",", "\n", "patch_size", "=", "None", ",", "\n", "batch_size", "=", "1", ",", "\n", "collapse_2d", "=", "None", ",", "\n", "extract_slice", "=", "None", ",", "\n", "force_binary", "=", "False", ",", "\n", "nb_input_feats", "=", "1", ",", "\n", "verbose", "=", "False", ",", "\n", "vol_rand_seed", "=", "None", ",", "\n", "patch_rand", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    generator that appends prior to (volume, segmentation) depending on input\n    e.g. could be ((volume, prior), segmentation)\n    \"\"\"", "\n", "\n", "\n", "patch_rand_seed", "=", "None", "\n", "if", "patch_rand", ":", "\n", "        ", "patch_rand_seed", "=", "np", ".", "random", ".", "random", "(", ")", "\n", "\n", "# prepare the vol_seg", "\n", "", "gen", "=", "vol_seg", "(", "*", "args", ",", "**", "kwargs", ",", "\n", "proc_vol_fn", "=", "None", ",", "\n", "proc_seg_fn", "=", "None", ",", "\n", "collapse_2d", "=", "collapse_2d", ",", "\n", "extract_slice", "=", "extract_slice", ",", "\n", "force_binary", "=", "force_binary", ",", "\n", "verbose", "=", "verbose", ",", "\n", "patch_size", "=", "patch_size", ",", "\n", "patch_stride", "=", "patch_stride", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "vol_rand_seed", "=", "vol_rand_seed", ",", "\n", "patch_rand", "=", "patch_rand", ",", "\n", "patch_rand_seed", "=", "patch_rand_seed", ",", "\n", "nb_input_feats", "=", "nb_input_feats", ")", "\n", "\n", "# add prior to output", "\n", "pgen", "=", "add_prior", "(", "gen", ",", "\n", "proc_vol_fn", "=", "proc_vol_fn", ",", "\n", "proc_seg_fn", "=", "proc_seg_fn", ",", "\n", "prior_type", "=", "prior_type", ",", "\n", "prior_file", "=", "prior_file", ",", "\n", "prior_feed", "=", "prior_feed", ",", "\n", "patch_stride", "=", "patch_stride", ",", "\n", "patch_size", "=", "patch_size", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "collapse_2d", "=", "collapse_2d", ",", "\n", "extract_slice", "=", "extract_slice", ",", "\n", "force_binary", "=", "force_binary", ",", "\n", "verbose", "=", "verbose", ",", "\n", "patch_rand", "=", "patch_rand", ",", "\n", "patch_rand_seed", "=", "patch_rand_seed", ")", "\n", "\n", "# generator loop", "\n", "while", "1", ":", "\n", "\n", "        ", "gen_sample", ",", "prior_batch", "=", "next", "(", "pgen", ")", "\n", "input_vol", ",", "output_vol", "=", "gen_sample", "\n", "\n", "if", "prior_feed", "==", "'input'", ":", "\n", "            ", "yield", "(", "[", "input_vol", ",", "prior_batch", "]", ",", "output_vol", ")", "\n", "", "else", ":", "\n", "            ", "assert", "prior_feed", "==", "'output'", "\n", "yield", "(", "input_vol", ",", "[", "output_vol", ",", "prior_batch", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol_prior_hack": [[665, 763], ["generators.vol_seg_hack", "generators.patch", "ext.pynd.ndutils.volsize2ndgrid", "numpy.transpose", "numpy.expand_dims", "numpy.sum", "numpy.delete", "isinstance", "len", "len", "next", "next", "range", "numpy.ndim", "numpy.ndim", "numpy.all", "print", "ext.pytools.timer.Timer", "numpy.load", "data[].astype", "ext.pytools.timer.Timer", "prior_vol.astype.astype"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol_seg_hack", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.patch", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.volsize2ndgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "", "", "def", "vol_prior_hack", "(", "*", "args", ",", "\n", "proc_vol_fn", "=", "None", ",", "\n", "proc_seg_fn", "=", "None", ",", "\n", "prior_type", "=", "'location'", ",", "# file-static, file-gen, location", "\n", "prior_file", "=", "None", ",", "# prior filename", "\n", "prior_feed", "=", "'input'", ",", "# input or output", "\n", "patch_stride", "=", "1", ",", "\n", "patch_size", "=", "None", ",", "\n", "batch_size", "=", "1", ",", "\n", "collapse_2d", "=", "None", ",", "\n", "extract_slice", "=", "None", ",", "\n", "force_binary", "=", "False", ",", "\n", "nb_input_feats", "=", "1", ",", "\n", "verbose", "=", "False", ",", "\n", "vol_rand_seed", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    \n    \"\"\"", "\n", "# prepare the vol_seg", "\n", "gen", "=", "vol_seg_hack", "(", "*", "args", ",", "**", "kwargs", ",", "\n", "proc_vol_fn", "=", "None", ",", "\n", "proc_seg_fn", "=", "None", ",", "\n", "collapse_2d", "=", "collapse_2d", ",", "\n", "extract_slice", "=", "extract_slice", ",", "\n", "force_binary", "=", "force_binary", ",", "\n", "verbose", "=", "verbose", ",", "\n", "patch_size", "=", "patch_size", ",", "\n", "patch_stride", "=", "patch_stride", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "vol_rand_seed", "=", "vol_rand_seed", ",", "\n", "nb_input_feats", "=", "nb_input_feats", ")", "\n", "\n", "# get prior", "\n", "if", "prior_type", "==", "'location'", ":", "\n", "        ", "prior_vol", "=", "nd", ".", "volsize2ndgrid", "(", "vol_size", ")", "\n", "prior_vol", "=", "np", ".", "transpose", "(", "prior_vol", ",", "[", "1", ",", "2", ",", "3", ",", "0", "]", ")", "\n", "prior_vol", "=", "np", ".", "expand_dims", "(", "prior_vol", ",", "axis", "=", "0", ")", "# reshape for model", "\n", "\n", "", "elif", "prior_type", "==", "'file'", ":", "# assumes a npz filename passed in prior_file", "\n", "        ", "with", "timer", ".", "Timer", "(", "'loading prior'", ",", "True", ")", ":", "\n", "            ", "data", "=", "np", ".", "load", "(", "prior_file", ")", "\n", "prior_vol", "=", "data", "[", "'prior'", "]", ".", "astype", "(", "'float16'", ")", "\n", "", "", "else", ":", "# assumes a volume", "\n", "        ", "with", "timer", ".", "Timer", "(", "'astyping prior'", ",", "verbose", ")", ":", "\n", "            ", "prior_vol", "=", "prior_file", "\n", "if", "not", "(", "prior_vol", ".", "dtype", "==", "'float16'", ")", ":", "\n", "                ", "prior_vol", "=", "prior_vol", ".", "astype", "(", "'float16'", ")", "\n", "\n", "", "", "", "if", "force_binary", ":", "\n", "        ", "nb_labels", "=", "prior_vol", ".", "shape", "[", "-", "1", "]", "\n", "prior_vol", "[", ":", ",", ":", ",", ":", ",", "1", "]", "=", "np", ".", "sum", "(", "prior_vol", "[", ":", ",", ":", ",", ":", ",", "1", ":", "nb_labels", "]", ",", "3", ")", "\n", "prior_vol", "=", "np", ".", "delete", "(", "prior_vol", ",", "range", "(", "2", ",", "nb_labels", ")", ",", "3", ")", "\n", "\n", "", "nb_channels", "=", "prior_vol", ".", "shape", "[", "-", "1", "]", "\n", "\n", "if", "extract_slice", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "extract_slice", ",", "int", ")", ":", "\n", "            ", "prior_vol", "=", "prior_vol", "[", ":", ",", ":", ",", "extract_slice", ",", "np", ".", "newaxis", ",", ":", "]", "\n", "", "else", ":", "# assume slices", "\n", "            ", "prior_vol", "=", "prior_vol", "[", ":", ",", ":", ",", "extract_slice", ",", ":", "]", "\n", "\n", "# get the prior to have the right volume [x, y, z, nb_channels]", "\n", "", "", "assert", "np", ".", "ndim", "(", "prior_vol", ")", "==", "4", "or", "np", ".", "ndim", "(", "prior_vol", ")", "==", "3", ",", "\"prior is the wrong size\"", "\n", "\n", "# prior generator", "\n", "if", "patch_size", "is", "None", ":", "\n", "        ", "patch_size", "=", "prior_vol", ".", "shape", "[", "0", ":", "3", "]", "\n", "", "assert", "len", "(", "patch_size", ")", "==", "len", "(", "patch_stride", ")", "\n", "prior_gen", "=", "patch", "(", "prior_vol", ",", "[", "*", "patch_size", ",", "nb_channels", "]", ",", "\n", "patch_stride", "=", "[", "*", "patch_stride", ",", "nb_channels", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "collapse_2d", "=", "collapse_2d", ",", "\n", "keep_vol_size", "=", "True", ",", "\n", "infinite", "=", "True", ",", "\n", "#variable_batch_size=True,  # this", "\n", "nb_labels_reshape", "=", "0", ")", "\n", "# assert next(prior_gen) is None, \"bad prior gen setup\"", "\n", "\n", "# generator loop", "\n", "while", "1", ":", "\n", "\n", "# generate input and output volumes", "\n", "        ", "input_vol", "=", "next", "(", "gen", ")", "\n", "\n", "if", "verbose", "and", "np", ".", "all", "(", "input_vol", ".", "flat", "==", "0", ")", ":", "\n", "            ", "print", "(", "\"all entries are 0\"", ")", "\n", "\n", "# generate prior batch", "\n", "# with timer.Timer(\"with send?\"):", "\n", "# prior_batch = prior_gen.send(input_vol.shape[0])", "\n", "", "prior_batch", "=", "next", "(", "prior_gen", ")", "\n", "\n", "if", "prior_feed", "==", "'input'", ":", "\n", "            ", "yield", "(", "[", "input_vol", ",", "prior_batch", "]", ",", "input_vol", ")", "\n", "", "else", ":", "\n", "            ", "assert", "prior_feed", "==", "'output'", "\n", "yield", "(", "input_vol", ",", "[", "input_vol", ",", "prior_batch", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol_seg_hack": [[765, 807], ["generators.vol", "next().astype", "next"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol"], ["", "", "", "def", "vol_seg_hack", "(", "volpath", ",", "\n", "segpath", ",", "\n", "proc_vol_fn", "=", "None", ",", "\n", "proc_seg_fn", "=", "None", ",", "\n", "verbose", "=", "False", ",", "\n", "name", "=", "'vol_seg'", ",", "# name, optional", "\n", "ext", "=", "'.npz'", ",", "\n", "nb_restart_cycle", "=", "None", ",", "# number of files to restart after", "\n", "nb_labels_reshape", "=", "-", "1", ",", "\n", "collapse_2d", "=", "None", ",", "\n", "force_binary", "=", "False", ",", "\n", "nb_input_feats", "=", "1", ",", "\n", "relabel", "=", "None", ",", "\n", "vol_rand_seed", "=", "None", ",", "\n", "seg_binary", "=", "False", ",", "\n", "vol_subname", "=", "'norm'", ",", "# subname of volume", "\n", "seg_subname", "=", "'aseg'", ",", "# subname of segmentation", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    generator with (volume, segmentation)\n\n    verbose is passed down to the base generators.py primitive generator (e.g. vol, here)\n\n    ** kwargs are any named arguments for vol(...),\n        except verbose, data_proc_fn, ext, nb_labels_reshape and name\n            (which this function will control when calling vol())\n    \"\"\"", "\n", "\n", "# get vol generator", "\n", "vol_gen", "=", "vol", "(", "volpath", ",", "**", "kwargs", ",", "ext", "=", "ext", ",", "\n", "nb_restart_cycle", "=", "nb_restart_cycle", ",", "collapse_2d", "=", "collapse_2d", ",", "force_binary", "=", "False", ",", "\n", "relabel", "=", "None", ",", "data_proc_fn", "=", "proc_vol_fn", ",", "nb_labels_reshape", "=", "1", ",", "name", "=", "name", "+", "' vol'", ",", "\n", "verbose", "=", "verbose", ",", "nb_feats", "=", "nb_input_feats", ",", "vol_rand_seed", "=", "vol_rand_seed", ")", "\n", "\n", "\n", "# on next (while):", "\n", "while", "1", ":", "\n", "# get input and output (seg) vols", "\n", "        ", "input_vol", "=", "next", "(", "vol_gen", ")", ".", "astype", "(", "'float16'", ")", "\n", "\n", "# output input and output", "\n", "yield", "input_vol", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.vol_sr_slices": [[809, 895], ["print", "generators._get_file_list", "len", "numpy.expand_dims", "numpy.expand_dims", "numpy.reshape", "numpy.mod", "numpy.expand_dims", "numpy.vstack", "numpy.vstack", "print", "generators._load_medical_volume", "list", "range", "os.path.join", "print", "numpy.random.randint", "range", "len", "generators.vol_sr_slices.indices_to_batch"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._get_file_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._load_medical_volume", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "", "def", "vol_sr_slices", "(", "volpath", ",", "\n", "nb_input_slices", ",", "\n", "nb_slice_spacing", ",", "\n", "batch_size", "=", "1", ",", "\n", "ext", "=", "'.npz'", ",", "\n", "vol_rand_seed", "=", "None", ",", "\n", "nb_restart_cycle", "=", "None", ",", "\n", "name", "=", "'vol_sr_slices'", ",", "\n", "rand_slices", "=", "True", ",", "# randomize init slice order (i.e. across entries per batch) given a volume", "\n", "simulate_whole_sparse_vol", "=", "False", ",", "\n", "verbose", "=", "False", "\n", ")", ":", "\n", "    ", "\"\"\"\n    default generator for slice-wise super resolution\n    \"\"\"", "\n", "\n", "def", "indices_to_batch", "(", "vol_data", ",", "start_indices", ",", "nb_slices_in_subvol", ",", "nb_slice_spacing", ")", ":", "\n", "        ", "idx", "=", "start_indices", "[", "0", "]", "\n", "output_batch", "=", "np", ".", "expand_dims", "(", "vol_data", "[", ":", ",", ":", ",", "idx", ":", "idx", "+", "nb_slices_in_subvol", "]", ",", "0", ")", "\n", "input_batch", "=", "np", ".", "expand_dims", "(", "vol_data", "[", ":", ",", ":", ",", "idx", ":", "(", "idx", "+", "nb_slices_in_subvol", ")", ":", "(", "nb_slice_spacing", "+", "1", ")", "]", ",", "0", ")", "\n", "\n", "for", "idx", "in", "start_indices", "[", "1", ":", "]", ":", "\n", "            ", "out_sel", "=", "np", ".", "expand_dims", "(", "vol_data", "[", ":", ",", ":", ",", "idx", ":", "idx", "+", "nb_slices_in_subvol", "]", ",", "0", ")", "\n", "output_batch", "=", "np", ".", "vstack", "(", "[", "output_batch", ",", "out_sel", "]", ")", "\n", "input_batch", "=", "np", ".", "vstack", "(", "[", "input_batch", ",", "np", ".", "expand_dims", "(", "vol_data", "[", ":", ",", ":", ",", "idx", ":", "(", "idx", "+", "nb_slices_in_subvol", ")", ":", "(", "nb_slice_spacing", "+", "1", ")", "]", ",", "0", ")", "]", ")", "\n", "", "output_batch", "=", "np", ".", "reshape", "(", "output_batch", ",", "[", "batch_size", ",", "-", "1", ",", "output_batch", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "\n", "return", "(", "input_batch", ",", "output_batch", ")", "\n", "\n", "\n", "", "print", "(", "'vol_sr_slices: SHOULD PROPERLY RANDOMIZE accross different subjects'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "volfiles", "=", "_get_file_list", "(", "volpath", ",", "ext", ",", "vol_rand_seed", ")", "\n", "nb_files", "=", "len", "(", "volfiles", ")", "\n", "\n", "if", "nb_restart_cycle", "is", "None", ":", "\n", "        ", "nb_restart_cycle", "=", "nb_files", "\n", "\n", "# compute the number of slices we'll need in a subvolume", "\n", "", "nb_slices_in_subvol", "=", "(", "nb_input_slices", "-", "1", ")", "*", "(", "nb_slice_spacing", "+", "1", ")", "+", "1", "\n", "\n", "# iterate through files", "\n", "fileidx", "=", "-", "1", "\n", "while", "1", ":", "\n", "        ", "fileidx", "=", "np", ".", "mod", "(", "fileidx", "+", "1", ",", "nb_restart_cycle", ")", "\n", "if", "verbose", "and", "fileidx", "==", "0", ":", "\n", "            ", "print", "(", "'starting %s cycle'", "%", "name", ")", "\n", "\n", "\n", "", "try", ":", "\n", "            ", "vol_data", "=", "_load_medical_volume", "(", "os", ".", "path", ".", "join", "(", "volpath", ",", "volfiles", "[", "fileidx", "]", ")", ",", "ext", ",", "verbose", ")", "\n", "", "except", ":", "\n", "            ", "debug_error_msg", "=", "\"#files: %d, fileidx: %d, nb_restart_cycle: %d. error: %s\"", "\n", "print", "(", "debug_error_msg", "%", "(", "len", "(", "volfiles", ")", ",", "fileidx", ",", "nb_restart_cycle", ",", "sys", ".", "exc_info", "(", ")", "[", "0", "]", ")", ")", "\n", "raise", "\n", "\n", "# compute some random slice", "\n", "", "nb_slices", "=", "vol_data", ".", "shape", "[", "2", "]", "\n", "nb_start_slices", "=", "nb_slices", "-", "nb_slices_in_subvol", "+", "1", "\n", "\n", "# prepare batches", "\n", "if", "simulate_whole_sparse_vol", ":", "# if essentially simulate a whole sparse volume for consistent inputs, and yield slices like that:", "\n", "            ", "init_slice", "=", "0", "\n", "if", "rand_slices", ":", "\n", "                ", "init_slice", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "high", "=", "nb_start_slices", "-", "1", ")", "\n", "\n", "", "all_start_indices", "=", "list", "(", "range", "(", "init_slice", ",", "nb_start_slices", ",", "nb_slice_spacing", "+", "1", ")", ")", "\n", "\n", "for", "batch_start", "in", "range", "(", "0", ",", "len", "(", "all_start_indices", ")", ",", "batch_size", "*", "(", "nb_input_slices", "-", "1", ")", ")", ":", "\n", "                ", "start_indices", "=", "[", "all_start_indices", "[", "s", "]", "for", "s", "in", "range", "(", "batch_start", ",", "batch_start", "+", "batch_size", ")", "]", "\n", "input_batch", ",", "output_batch", "=", "indices_to_batch", "(", "vol_data", ",", "start_indices", ",", "nb_slices_in_subvol", ",", "nb_slice_spacing", ")", "\n", "yield", "(", "input_batch", ",", "output_batch", ")", "\n", "\n", "# if just random slices, get a batch of random starts from this volume and that's it.", "\n", "", "", "elif", "rand_slices", ":", "\n", "            ", "assert", "not", "simulate_whole_sparse_vol", "\n", "start_indices", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "nb_start_slices", ")", ",", "size", "=", "batch_size", ",", "replace", "=", "False", ")", "\n", "input_batch", ",", "output_batch", "=", "indices_to_batch", "(", "vol_data", ",", "start_indices", ",", "nb_slices_in_subvol", ",", "nb_slice_spacing", ")", "\n", "yield", "(", "input_batch", ",", "output_batch", ")", "\n", "\n", "# go slice by slice (overlapping regions)", "\n", "", "else", ":", "\n", "            ", "for", "batch_start", "in", "range", "(", "0", ",", "nb_start_slices", ",", "batch_size", ")", ":", "\n", "                ", "start_indices", "=", "list", "(", "range", "(", "batch_start", ",", "batch_start", "+", "batch_size", ")", ")", "\n", "input_batch", ",", "output_batch", "=", "indices_to_batch", "(", "vol_data", ",", "start_indices", ",", "nb_slices_in_subvol", ",", "nb_slice_spacing", ")", "\n", "yield", "(", "input_batch", ",", "output_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators.img_seg": [[897, 937], ["generators.img_seg.imggen"], "function", ["None"], ["", "", "", "", "def", "img_seg", "(", "volpath", ",", "\n", "segpath", ",", "\n", "batch_size", "=", "1", ",", "\n", "verbose", "=", "False", ",", "\n", "nb_restart_cycle", "=", "None", ",", "\n", "name", "=", "'img_seg'", ",", "# name, optional", "\n", "ext", "=", "'.png'", ",", "\n", "vol_rand_seed", "=", "None", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    generator for (image, segmentation)\n    \"\"\"", "\n", "\n", "def", "imggen", "(", "path", ",", "ext", ",", "nb_restart_cycle", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        TODO: should really use the volume generators for this\n        \"\"\"", "\n", "files", "=", "_get_file_list", "(", "path", ",", "ext", ",", "vol_rand_seed", ")", "\n", "if", "nb_restart_cycle", "is", "None", ":", "\n", "            ", "nb_restart_cycle", "=", "len", "(", "files", ")", "\n", "\n", "", "idx", "=", "-", "1", "\n", "while", "1", ":", "\n", "            ", "idx", "=", "np", ".", "mod", "(", "idx", "+", "1", ",", "nb_restart_cycle", ")", "\n", "im", "=", "scipy", ".", "misc", ".", "imread", "(", "os", ".", "path", ".", "join", "(", "path", ",", "files", "[", "idx", "]", ")", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "yield", "im", ".", "reshape", "(", "(", "1", ",", ")", "+", "im", ".", "shape", ")", "\n", "\n", "", "", "img_gen", "=", "imggen", "(", "volpath", ",", "ext", ",", "nb_restart_cycle", ")", "\n", "seg_gen", "=", "imggen", "(", "segpath", ",", "ext", ")", "\n", "\n", "# on next (while):", "\n", "while", "1", ":", "\n", "        ", "input_vol", "=", "np", ".", "vstack", "(", "[", "next", "(", "img_gen", ")", ".", "astype", "(", "'float16'", ")", "/", "255", "for", "i", "in", "range", "(", "batch_size", ")", "]", ")", "\n", "input_vol", "=", "np", ".", "expand_dims", "(", "input_vol", ",", "axis", "=", "-", "1", ")", "\n", "\n", "output_vols", "=", "[", "np_utils", ".", "to_categorical", "(", "next", "(", "seg_gen", ")", ".", "astype", "(", "'int8'", ")", ",", "num_classes", "=", "2", ")", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "output_vol", "=", "np", ".", "vstack", "(", "[", "np", ".", "expand_dims", "(", "f", ",", "axis", "=", "0", ")", "for", "f", "in", "output_vols", "]", ")", "\n", "\n", "# output input and output", "\n", "yield", "(", "input_vol", ",", "output_vol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._get_file_list": [[941, 950], ["numpy.random.seed", "numpy.random.permutation().tolist", "sorted", "os.listdir", "f.endswith", "numpy.random.permutation"], "function", ["None"], ["", "", "def", "_get_file_list", "(", "volpath", ",", "ext", "=", "None", ",", "vol_rand_seed", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    get a list of files at the given path with the given extension\n    \"\"\"", "\n", "files", "=", "[", "f", "for", "f", "in", "sorted", "(", "os", ".", "listdir", "(", "volpath", ")", ")", "if", "ext", "is", "None", "or", "f", ".", "endswith", "(", "ext", ")", "]", "\n", "if", "vol_rand_seed", "is", "not", "None", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "vol_rand_seed", ")", "\n", "files", "=", "np", ".", "random", ".", "permutation", "(", "files", ")", ".", "tolist", "(", ")", "\n", "", "return", "files", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._load_medical_volume": [[952, 969], ["ext.pytools.timer.Timer", "numpy.load", "numpy.load", "nibabel.load", "nib.load.get_data", "ValueError"], "function", ["None"], ["", "def", "_load_medical_volume", "(", "filename", ",", "ext", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    load a medical volume from one of a number of file types\n    \"\"\"", "\n", "with", "timer", ".", "Timer", "(", "'load_vol'", ",", "verbose", ">=", "2", ")", ":", "\n", "        ", "if", "ext", "==", "'.npz'", ":", "\n", "            ", "vol_file", "=", "np", ".", "load", "(", "filename", ")", "\n", "vol_data", "=", "vol_file", "[", "'vol_data'", "]", "\n", "", "elif", "ext", "==", "'npy'", ":", "\n", "            ", "vol_data", "=", "np", ".", "load", "(", "filename", ")", "\n", "", "elif", "ext", "==", "'.mgz'", "or", "ext", "==", "'.nii'", "or", "ext", "==", "'.nii.gz'", ":", "\n", "            ", "vol_med", "=", "nib", ".", "load", "(", "filename", ")", "\n", "vol_data", "=", "vol_med", ".", "get_data", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unexpected extension %s\"", "%", "ext", ")", "\n", "\n", "", "", "return", "vol_data", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._categorical_prep": [[971, 986], ["numpy.expand_dims", "generators._to_categorical", "numpy.expand_dims"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._to_categorical", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["", "def", "_categorical_prep", "(", "vol_data", ",", "nb_labels_reshape", ",", "keep_vol_size", ",", "patch_size", ")", ":", "\n", "\n", "    ", "if", "nb_labels_reshape", ">", "1", ":", "\n", "\n", "        ", "lpatch", "=", "_to_categorical", "(", "vol_data", ",", "nb_labels_reshape", ",", "keep_vol_size", ")", "\n", "# if keep_vol_size:", "\n", "# lpatch = np.reshape(lpatch, [*patch_size, nb_labels_reshape])", "\n", "", "elif", "nb_labels_reshape", "==", "1", ":", "\n", "        ", "lpatch", "=", "np", ".", "expand_dims", "(", "vol_data", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "assert", "nb_labels_reshape", "==", "0", "\n", "lpatch", "=", "vol_data", "\n", "", "lpatch", "=", "np", ".", "expand_dims", "(", "lpatch", ",", "axis", "=", "0", ")", "\n", "\n", "return", "lpatch", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._to_categorical": [[989, 1017], ["numpy.array().ravel", "numpy.zeros", "numpy.reshape", "numpy.array", "numpy.max", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], ["", "def", "_to_categorical", "(", "y", ",", "num_classes", "=", "None", ",", "reshape", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    # copy of keras.utils.np_utils.to_categorical, but with a boolean matrix instead of float\n\n    Converts a class vector (integers) to binary class matrix.\n\n    E.g. for use with categorical_crossentropy.\n\n    # Arguments\n        y: class vector to be converted into a matrix\n            (integers from 0 to num_classes).\n        num_classes: total number of classes.\n\n    # Returns\n        A binary matrix representation of the input.\n    \"\"\"", "\n", "oshape", "=", "y", ".", "shape", "\n", "y", "=", "np", ".", "array", "(", "y", ",", "dtype", "=", "'int'", ")", ".", "ravel", "(", ")", "\n", "if", "not", "num_classes", ":", "\n", "        ", "num_classes", "=", "np", ".", "max", "(", "y", ")", "+", "1", "\n", "", "n", "=", "y", ".", "shape", "[", "0", "]", "\n", "categorical", "=", "np", ".", "zeros", "(", "(", "n", ",", "num_classes", ")", ",", "bool", ")", "\n", "categorical", "[", "np", ".", "arange", "(", "n", ")", ",", "y", "]", "=", "1", "\n", "\n", "if", "reshape", ":", "\n", "        ", "categorical", "=", "np", ".", "reshape", "(", "categorical", ",", "[", "*", "oshape", ",", "num_classes", "]", ")", "\n", "\n", "", "return", "categorical", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._relabel": [[1018, 1030], ["numpy.zeros", "numpy.ndenumerate", "numpy.unique", "len", "len"], "function", ["None"], ["", "def", "_relabel", "(", "vol_data", ",", "labels", ",", "forcecheck", "=", "False", ")", ":", "\n", "\n", "    ", "if", "forcecheck", ":", "\n", "        ", "vd", "=", "np", ".", "unique", "(", "vol_data", ".", "flat", ")", "\n", "assert", "len", "(", "vd", ")", "==", "len", "(", "labels", ")", ",", "\"number of given labels does not match number of actual labels\"", "\n", "\n", "# by doing zeros, any label not in labels gets left to 0", "\n", "", "new_vol_data", "=", "np", ".", "zeros", "(", "vol_data", ".", "shape", ",", "vol_data", ".", "dtype", ")", "\n", "for", "idx", ",", "val", "in", "np", ".", "ndenumerate", "(", "labels", ")", ":", "\n", "        ", "new_vol_data", "[", "vol_data", "==", "val", "]", "=", "idx", "\n", "\n", "", "return", "new_vol_data", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._npz_headers": [[1032, 1054], ["zipfile.ZipFile", "archive.namelist", "archive.open", "numpy.lib.format.read_magic", "numpy.lib.format._read_array_header", "name.endswith"], "function", ["None"], ["", "def", "_npz_headers", "(", "npz", ",", "namelist", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    taken from https://stackoverflow.com/a/43223420\n\n    Takes a path to an .npz file, which is a Zip archive of .npy files.\n    Generates a sequence of (name, shape, np.dtype).\n\n    namelist is a list with variable names, ending in '.npy'. \n    e.g. if variable 'var' is in the file, namelist could be ['var.npy']\n    \"\"\"", "\n", "with", "zipfile", ".", "ZipFile", "(", "npz", ")", "as", "archive", ":", "\n", "        ", "if", "namelist", "is", "None", ":", "\n", "            ", "namelist", "=", "archive", ".", "namelist", "(", ")", "\n", "\n", "", "for", "name", "in", "namelist", ":", "\n", "            ", "if", "not", "name", ".", "endswith", "(", "'.npy'", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "npy", "=", "archive", ".", "open", "(", "name", ")", "\n", "version", "=", "np", ".", "lib", ".", "format", ".", "read_magic", "(", "npy", ")", "\n", "shape", ",", "fortran", ",", "dtype", "=", "np", ".", "lib", ".", "format", ".", "_read_array_header", "(", "npy", ",", "version", ")", "\n", "yield", "name", "[", ":", "-", "4", "]", ",", "shape", ",", "dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._get_shape": [[1055, 1060], ["isinstance", "generators._get_shape"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.generators._get_shape"], ["", "", "", "def", "_get_shape", "(", "x", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "return", "_get_shape", "(", "x", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "x", ".", "shape", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatialTransformer.__init__": [[55, 78], ["list", "keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatialTransformer.get_config": [[79, 85], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["\n", "\n", "def", "__init__", "(", "self", ",", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatialTransformer.build": [[86, 127], ["enumerate", "len", "Exception", "len", "layers.SpatialTransformer.is_affine.append", "len", "Exception", "Exception", "len", "all", "len"], "methods", ["None"], ["scaling_bounds", "=", "0.15", ",", "\n", "rotation_bounds", "=", "10", ",", "\n", "shearing_bounds", "=", "0.02", ",", "\n", "translation_bounds", "=", "False", ",", "\n", "enable_90_rotations", "=", "False", ",", "\n", "nonlin_std", "=", "4.", ",", "\n", "nonlin_shape_factor", "=", ".0625", ",", "\n", "inter_method", "=", "'linear'", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# shape attributes", "\n", "        ", "self", ".", "n_inputs", "=", "1", "\n", "self", ".", "inshape", "=", "None", "\n", "self", ".", "n_dims", "=", "None", "\n", "self", ".", "small_shape", "=", "None", "\n", "\n", "# deformation attributes", "\n", "self", ".", "scaling_bounds", "=", "scaling_bounds", "\n", "self", ".", "rotation_bounds", "=", "rotation_bounds", "\n", "self", ".", "shearing_bounds", "=", "shearing_bounds", "\n", "self", ".", "translation_bounds", "=", "translation_bounds", "\n", "self", ".", "enable_90_rotations", "=", "enable_90_rotations", "\n", "self", ".", "nonlin_std", "=", "nonlin_std", "\n", "self", ".", "nonlin_shape_factor", "=", "nonlin_shape_factor", "\n", "\n", "# boolean attributes", "\n", "self", ".", "apply_affine_trans", "=", "(", "self", ".", "scaling_bounds", "is", "not", "False", ")", "|", "(", "self", ".", "rotation_bounds", "is", "not", "False", ")", "|", "(", "self", ".", "shearing_bounds", "is", "not", "False", ")", "|", "(", "self", ".", "translation_bounds", "is", "not", "False", ")", "|", "self", ".", "enable_90_rotations", "\n", "self", ".", "apply_elastic_trans", "=", "self", ".", "nonlin_std", ">", "0", "\n", "\n", "# interpolation methods", "\n", "self", ".", "inter_method", "=", "inter_method", "\n", "\n", "super", "(", "RandomSpatialDeformation", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"scaling_bounds\"", "]", "=", "self", ".", "scaling_bounds", "\n", "config", "[", "\"rotation_bounds\"", "]", "=", "self", ".", "rotation_bounds", "\n", "config", "[", "\"shearing_bounds\"", "]", "=", "self", ".", "shearing_bounds", "\n", "config", "[", "\"translation_bounds\"", "]", "=", "self", ".", "translation_bounds", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatialTransformer.call": [[128, 170], ["keras.backend.reshape", "range", "len", "len", "len", "keras.backend.reshape", "len", "tensorflow.split", "tensorflow.concat", "tensorflow.map_fn", "tensorflow.map_fn", "sorted", "tensorflow.map_fn", "len", "tensorflow.map_fn", "enumerate", "layers.SpatialTransformer._single_aff_to_shift", "layers.SpatialTransformer._non_linear_and_aff_to_shift"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatialTransformer._single_aff_to_shift", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatialTransformer._non_linear_and_aff_to_shift"], ["config", "[", "\"enable_90_rotations\"", "]", "=", "self", ".", "enable_90_rotations", "\n", "config", "[", "\"nonlin_std\"", "]", "=", "self", ".", "nonlin_std", "\n", "config", "[", "\"nonlin_shape_factor\"", "]", "=", "self", ".", "nonlin_shape_factor", "\n", "config", "[", "\"inter_method\"", "]", "=", "self", ".", "inter_method", "\n", "return", "config", "\n", "\n", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "input_shape", ",", "list", ")", ":", "\n", "            ", "inputshape", "=", "[", "input_shape", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "n_inputs", "=", "len", "(", "input_shape", ")", "\n", "inputshape", "=", "input_shape", "\n", "", "self", ".", "inshape", "=", "inputshape", "[", "0", "]", "[", "1", ":", "]", "\n", "self", ".", "n_dims", "=", "len", "(", "self", ".", "inshape", ")", "-", "1", "\n", "\n", "if", "self", ".", "apply_elastic_trans", ":", "\n", "            ", "self", ".", "small_shape", "=", "utils", ".", "get_resample_shape", "(", "self", ".", "inshape", "[", ":", "self", ".", "n_dims", "]", ",", "\n", "self", ".", "nonlin_shape_factor", ",", "self", ".", "n_dims", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "small_shape", "=", "None", "\n", "\n", "", "self", ".", "inter_method", "=", "utils", ".", "reformat_to_list", "(", "self", ".", "inter_method", ",", "length", "=", "self", ".", "n_inputs", ",", "dtype", "=", "'str'", ")", "\n", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "RandomSpatialDeformation", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n", "", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# reformat inputs and get its shape", "\n", "        ", "if", "self", ".", "n_inputs", "<", "2", ":", "\n", "            ", "inputs", "=", "[", "inputs", "]", "\n", "", "types", "=", "[", "v", ".", "dtype", "for", "v", "in", "inputs", "]", "\n", "inputs", "=", "[", "tf", ".", "cast", "(", "v", ",", "dtype", "=", "'float32'", ")", "for", "v", "in", "inputs", "]", "\n", "batchsize", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", ",", "[", "1", ",", "self", ".", "n_dims", "+", "1", "]", ")", "[", "0", "]", "\n", "\n", "# initialise list of transfors to operate", "\n", "list_trans", "=", "list", "(", ")", "\n", "\n", "# add affine deformation to inputs list", "\n", "if", "self", ".", "apply_affine_trans", ":", "\n", "            ", "affine_trans", "=", "utils", ".", "sample_affine_transform", "(", "batchsize", ",", "\n", "self", ".", "n_dims", ",", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatialTransformer._single_aff_to_shift": [[171, 175], ["utils.affine_to_shift", "len", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.affine_to_shift"], ["self", ".", "rotation_bounds", ",", "\n", "self", ".", "scaling_bounds", ",", "\n", "self", ".", "shearing_bounds", ",", "\n", "self", ".", "translation_bounds", ",", "\n", "self", ".", "enable_90_rotations", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatialTransformer._non_linear_and_aff_to_shift": [[176, 180], ["utils.combine_non_linear_and_aff_to_shift", "len", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.combine_non_linear_and_aff_to_shift"], ["list_trans", ".", "append", "(", "affine_trans", ")", "\n", "\n", "# prepare non-linear deformation field and add it to inputs list", "\n", "", "if", "self", ".", "apply_elastic_trans", ":", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatialTransformer._single_transform": [[181, 183], ["utils.transform"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.transform"], ["# sample small field from normal distribution of specified std dev", "\n", "            ", "trans_shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "convert_to_tensor", "(", "self", ".", "small_shape", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", "\n", "trans_std", "=", "tf", ".", "random", ".", "uniform", "(", "(", "1", ",", "1", ")", ",", "maxval", "=", "self", ".", "nonlin_std", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.VecInt.__init__": [[199, 221], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["", "", "class", "RandomCrop", "(", "Layer", ")", ":", "\n", "\n", "    ", "\"\"\"Randomly crop all input tensors to a given shape. This cropping is applied to all channels.\n    The input tensors are expected to have shape [batchsize, shape_dim1, ..., shape_dimn, channel].\n    :param crop_shape: list with cropping shape in each dimension (excluding batch and channel dimension)\n\n    example:\n    if input is a tensor of shape [batchsize, 160, 160, 160, 3],\n    output = RandomCrop(crop_shape=[96, 128, 96])(input)\n    will yield an output of shape [batchsize, 96, 128, 96, 3] that is obtained by cropping with randomly selected\n    cropping indices.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "crop_shape", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "self", ".", "several_inputs", "=", "True", "\n", "self", ".", "crop_max_val", "=", "None", "\n", "self", ".", "crop_shape", "=", "crop_shape", "\n", "self", ".", "n_dims", "=", "len", "(", "crop_shape", ")", "\n", "self", ".", "list_n_channels", "=", "None", "\n", "super", "(", "RandomCrop", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "", "def", "get_config", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.VecInt.get_config": [[222, 231], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"crop_shape\"", "]", "=", "self", ".", "crop_shape", "\n", "return", "config", "\n", "\n", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "input_shape", ",", "list", ")", ":", "\n", "            ", "self", ".", "several_inputs", "=", "False", "\n", "inputshape", "=", "[", "input_shape", "]", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.VecInt.build": [[232, 244], ["isinstance", "Exception", "len", "len"], "methods", ["None"], ["            ", "inputshape", "=", "input_shape", "\n", "", "self", ".", "crop_max_val", "=", "np", ".", "array", "(", "np", ".", "array", "(", "inputshape", "[", "0", "]", "[", "1", ":", "self", ".", "n_dims", "+", "1", "]", ")", ")", "-", "np", ".", "array", "(", "self", ".", "crop_shape", ")", "\n", "self", ".", "list_n_channels", "=", "[", "i", "[", "-", "1", "]", "for", "i", "in", "inputshape", "]", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "RandomCrop", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n", "", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# if one input only is provided, performs the cropping directly", "\n", "        ", "if", "not", "self", ".", "several_inputs", ":", "\n", "            ", "return", "tf", ".", "map_fn", "(", "self", ".", "_single_slice", ",", "inputs", ",", "dtype", "=", "inputs", ".", "dtype", ")", "\n", "\n", "# otherwise we concatenate all inputs before cropping, so that they are all cropped at the same location", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.VecInt.call": [[245, 267], ["keras.backend.reshape", "tensorflow.map_fn", "isinstance", "tensorflow.split", "tensorflow.concat", "len"], "methods", ["None"], ["", "else", ":", "\n", "            ", "types", "=", "[", "v", ".", "dtype", "for", "v", "in", "inputs", "]", "\n", "inputs", "=", "tf", ".", "concat", "(", "[", "tf", ".", "cast", "(", "v", ",", "'float32'", ")", "for", "v", "in", "inputs", "]", ",", "axis", "=", "-", "1", ")", "\n", "inputs", "=", "tf", ".", "map_fn", "(", "self", ".", "_single_slice", ",", "inputs", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "inputs", "=", "tf", ".", "split", "(", "inputs", ",", "self", ".", "list_n_channels", ",", "axis", "=", "-", "1", ")", "\n", "return", "[", "tf", ".", "cast", "(", "v", ",", "t", ")", "for", "(", "t", ",", "v", ")", "in", "zip", "(", "types", ",", "inputs", ")", "]", "\n", "\n", "", "", "def", "_single_slice", "(", "self", ",", "vol", ")", ":", "\n", "        ", "crop_idx", "=", "tf", ".", "cast", "(", "tf", ".", "random", ".", "uniform", "(", "[", "self", ".", "n_dims", "]", ",", "0", ",", "np", ".", "array", "(", "self", ".", "crop_max_val", ")", ",", "'float32'", ")", ",", "dtype", "=", "'int32'", ")", "\n", "crop_idx", "=", "tf", ".", "concat", "(", "[", "crop_idx", ",", "tf", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", "\n", "crop_size", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "crop_shape", "+", "[", "-", "1", "]", ",", "dtype", "=", "'int32'", ")", "\n", "return", "tf", ".", "slice", "(", "vol", ",", "begin", "=", "crop_idx", ",", "size", "=", "crop_size", ")", "\n", "\n", "", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "output_shape", "=", "[", "tuple", "(", "[", "None", "]", "+", "self", ".", "crop_shape", "+", "[", "v", "]", ")", "for", "v", "in", "self", ".", "list_n_channels", "]", "\n", "return", "output_shape", "if", "self", ".", "several_inputs", "else", "output_shape", "[", "0", "]", "\n", "\n", "\n", "", "", "class", "RandomFlip", "(", "Layer", ")", ":", "\n", "\n", "    "]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.VecInt._single_int": [[268, 279], ["utils.integrate_vec", "len"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.integrate_vec"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.Resize.__init__": [[294, 313], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.Resize.get_config": [[314, 320], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["def", "__init__", "(", "self", ",", "flip_axis", "=", "None", ",", "swap_labels", "=", "False", ",", "label_list", "=", "None", ",", "n_neutral_labels", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "\n", "# shape attributes", "\n", "        ", "self", ".", "several_inputs", "=", "True", "\n", "self", ".", "n_dims", "=", "None", "\n", "self", ".", "list_n_channels", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.Resize.build": [[321, 370], ["isinstance", "isinstance", "isinstance", "super().build", "isinstance", "Exception", "len", "len", "isinstance", "isinstance", "copy.deepcopy", "Exception", "copy.deepcopy", "Exception", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["# axis along which to flip", "\n", "self", ".", "flip_axis", "=", "utils", ".", "reformat_to_list", "(", "flip_axis", ")", "\n", "\n", "# wether to swap labels, and corresponding label list", "\n", "self", ".", "swap_labels", "=", "utils", ".", "reformat_to_list", "(", "swap_labels", ")", "\n", "self", ".", "label_list", "=", "label_list", "\n", "self", ".", "n_neutral_labels", "=", "n_neutral_labels", "\n", "self", ".", "swap_lut", "=", "None", "\n", "\n", "super", "(", "RandomFlip", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"flip_axis\"", "]", "=", "self", ".", "flip_axis", "\n", "config", "[", "\"swap_labels\"", "]", "=", "self", ".", "swap_labels", "\n", "config", "[", "\"label_list\"", "]", "=", "self", ".", "label_list", "\n", "config", "[", "\"n_neutral_labels\"", "]", "=", "self", ".", "n_neutral_labels", "\n", "return", "config", "\n", "\n", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "input_shape", ",", "list", ")", ":", "\n", "            ", "self", ".", "several_inputs", "=", "False", "\n", "inputshape", "=", "[", "input_shape", "]", "\n", "", "else", ":", "\n", "            ", "inputshape", "=", "input_shape", "\n", "", "self", ".", "n_dims", "=", "len", "(", "inputshape", "[", "0", "]", "[", "1", ":", "-", "1", "]", ")", "\n", "self", ".", "list_n_channels", "=", "[", "i", "[", "-", "1", "]", "for", "i", "in", "inputshape", "]", "\n", "self", ".", "swap_labels", "=", "utils", ".", "reformat_to_list", "(", "self", ".", "swap_labels", ",", "length", "=", "len", "(", "inputshape", ")", ")", "\n", "\n", "# create label list with swapped labels", "\n", "if", "any", "(", "self", ".", "swap_labels", ")", ":", "\n", "            ", "assert", "(", "self", ".", "label_list", "is", "not", "None", ")", "&", "(", "self", ".", "n_neutral_labels", "is", "not", "None", ")", ",", "'please provide a label_list, and n_neutral_labels when swapping the values of at least one input'", "\n", "n_labels", "=", "len", "(", "self", ".", "label_list", ")", "\n", "if", "self", ".", "n_neutral_labels", "==", "n_labels", ":", "\n", "                ", "self", ".", "swap_labels", "=", "[", "False", "]", "*", "len", "(", "self", ".", "swap_labels", ")", "\n", "", "else", ":", "\n", "                ", "rl_split", "=", "np", ".", "split", "(", "self", ".", "label_list", ",", "[", "self", ".", "n_neutral_labels", ",", "\n", "self", ".", "n_neutral_labels", "+", "int", "(", "(", "n_labels", "-", "self", ".", "n_neutral_labels", ")", "/", "2", ")", "]", ")", "\n", "label_list_swap", "=", "np", ".", "concatenate", "(", "(", "rl_split", "[", "0", "]", ",", "rl_split", "[", "2", "]", ",", "rl_split", "[", "1", "]", ")", ")", "\n", "swap_lut", "=", "utils", ".", "get_mapping_lut", "(", "self", ".", "label_list", ",", "label_list_swap", ")", "\n", "self", ".", "swap_lut", "=", "tf", ".", "convert_to_tensor", "(", "swap_lut", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "", "", "self", ".", "built", "=", "True", "\n", "super", "(", "RandomFlip", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n", "", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# convert inputs to list, and get each input type", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.Resize.call": [[371, 395], ["isinstance", "keras.backend.reshape", "tensorflow.map_fn", "any", "len", "len", "int", "range", "range"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["        ", "if", "not", "self", ".", "several_inputs", ":", "\n", "            ", "inputs", "=", "[", "inputs", "]", "\n", "", "types", "=", "[", "v", ".", "dtype", "for", "v", "in", "inputs", "]", "\n", "\n", "# sample boolean for each element of the batch", "\n", "batchsize", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", ",", "[", "1", ",", "self", ".", "n_dims", "+", "1", "]", ")", "[", "0", "]", "\n", "rand_flip", "=", "K", ".", "greater", "(", "tf", ".", "random", ".", "uniform", "(", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "1", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ",", "0", ",", "1", ")", ",", "0.5", ")", "\n", "\n", "# swap r/l labels if necessary", "\n", "swapped_inputs", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "inputs", ")", ")", ":", "\n", "            ", "if", "self", ".", "swap_labels", "[", "i", "]", ":", "\n", "                ", "swapped_inputs", ".", "append", "(", "tf", ".", "map_fn", "(", "self", ".", "_single_swap", ",", "[", "inputs", "[", "i", "]", ",", "rand_flip", "]", ",", "dtype", "=", "types", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "swapped_inputs", ".", "append", "(", "inputs", "[", "i", "]", ")", "\n", "\n", "# flip inputs and convert them back to their original type", "\n", "", "", "inputs", "=", "tf", ".", "concat", "(", "[", "tf", ".", "cast", "(", "v", ",", "'float32'", ")", "for", "v", "in", "swapped_inputs", "]", ",", "axis", "=", "-", "1", ")", "\n", "inputs", "=", "tf", ".", "map_fn", "(", "self", ".", "_single_flip", ",", "[", "inputs", ",", "rand_flip", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "inputs", "=", "tf", ".", "split", "(", "inputs", ",", "self", ".", "list_n_channels", ",", "axis", "=", "-", "1", ")", "\n", "\n", "return", "[", "tf", ".", "cast", "(", "v", ",", "t", ")", "for", "(", "t", ",", "v", ")", "in", "zip", "(", "types", ",", "inputs", ")", "]", "\n", "\n", "", "def", "_single_swap", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "return", "K", ".", "switch", "(", "inputs", "[", "1", "]", ",", "tf", ".", "gather", "(", "self", ".", "swap_lut", ",", "inputs", "[", "0", "]", ")", ",", "inputs", "[", "0", "]", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.Resize.compute_output_shape": [[396, 402], ["tuple", "int", "range"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["\n", "", "def", "_single_flip", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "flip_axis", "is", "None", ":", "\n", "            ", "flip_axis", "=", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "0", ",", "self", ".", "n_dims", ",", "dtype", "=", "'int32'", ")", "\n", "", "else", ":", "\n", "            ", "idx", "=", "tf", ".", "squeeze", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "0", ",", "len", "(", "self", ".", "flip_axis", ")", ",", "dtype", "=", "'int32'", ")", ")", "\n", "flip_axis", "=", "tf", ".", "expand_dims", "(", "tf", ".", "convert_to_tensor", "(", "self", ".", "flip_axis", ",", "dtype", "=", "'int32'", ")", "[", "idx", "]", ",", "axis", "=", "0", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.Resize._single_resize": [[403, 405], ["utils.resize"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.resize"], ["", "return", "K", ".", "switch", "(", "inputs", "[", "1", "]", ",", "K", ".", "reverse", "(", "inputs", "[", "0", "]", ",", "axes", "=", "flip_axis", ")", ",", "inputs", "[", "0", "]", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatiallySparse_Dense.__init__": [[425, 435], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["        ", "self", ".", "generation_labels", "=", "generation_labels", "\n", "self", ".", "n_labels", "=", "None", "\n", "self", ".", "n_channels", "=", "None", "\n", "self", ".", "max_label", "=", "None", "\n", "self", ".", "indices", "=", "None", "\n", "self", ".", "shape", "=", "None", "\n", "super", "(", "SampleConditionalGMM", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"generation_labels\"", "]", "=", "self", ".", "generation_labels", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatiallySparse_Dense.get_config": [[436, 444], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["return", "config", "\n", "\n", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "# check n_labels and n_channels", "\n", "        ", "assert", "len", "(", "input_shape", ")", "==", "3", ",", "'should have three inputs: labels, means, std devs (in that order).'", "\n", "self", ".", "n_channels", "=", "input_shape", "[", "1", "]", "[", "-", "1", "]", "\n", "self", ".", "n_labels", "=", "len", "(", "self", ".", "generation_labels", ")", "\n", "assert", "self", ".", "n_labels", "==", "input_shape", "[", "1", "]", "[", "1", "]", ",", "'means should have the same number of values as generation_labels'", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatiallySparse_Dense.build": [[445, 471], ["layers.SpatiallySparse_Dense.add_weight", "keras.backend.reshape", "keras.backend.transpose", "tensorflow.matrix_inverse", "keras.backend.dot", "super().build", "keras.backend.dot", "layers.SpatiallySparse_Dense.add_weight", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["assert", "self", ".", "n_labels", "==", "input_shape", "[", "2", "]", "[", "1", "]", ",", "'stds should have the same number of values as generation_labels'", "\n", "\n", "# scatter parameters (to build mean/std lut)", "\n", "self", ".", "max_label", "=", "np", ".", "max", "(", "self", ".", "generation_labels", ")", "+", "1", "\n", "indices", "=", "np", ".", "concatenate", "(", "[", "self", ".", "generation_labels", "+", "self", ".", "max_label", "*", "i", "for", "i", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "shape", "=", "tf", ".", "convert_to_tensor", "(", "[", "np", ".", "max", "(", "indices", ")", "+", "1", "]", ",", "dtype", "=", "'int32'", ")", "\n", "self", ".", "indices", "=", "tf", ".", "convert_to_tensor", "(", "utils", ".", "add_axis", "(", "indices", ",", "axis", "=", "[", "0", ",", "-", "1", "]", ")", ",", "dtype", "=", "'int32'", ")", "\n", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "SampleConditionalGMM", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n", "", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# reformat labels and scatter indices", "\n", "        ", "batch", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", "[", "0", "]", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", "\n", "tmp_indices", "=", "tf", ".", "tile", "(", "self", ".", "indices", ",", "tf", ".", "concat", "(", "[", "batch", ",", "tf", ".", "convert_to_tensor", "(", "[", "1", ",", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "labels", "=", "tf", ".", "concat", "(", "[", "tf", ".", "cast", "(", "inputs", "[", "0", "]", ",", "dtype", "=", "'int32'", ")", "+", "self", ".", "max_label", "*", "i", "for", "i", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "-", "1", ")", "\n", "\n", "# build mean map", "\n", "means", "=", "tf", ".", "concat", "(", "[", "inputs", "[", "1", "]", "[", "...", ",", "i", "]", "for", "i", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "1", ")", "\n", "tile_shape", "=", "tf", ".", "concat", "(", "[", "batch", ",", "tf", ".", "convert_to_tensor", "(", "[", "1", ",", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", "\n", "means", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "scatter_nd", "(", "tmp_indices", ",", "means", ",", "self", ".", "shape", ")", ",", "0", ")", ",", "tile_shape", ")", "\n", "means_map", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "tf", ".", "gather", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", ",", "[", "means", ",", "labels", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# same for stds", "\n", "stds", "=", "tf", ".", "concat", "(", "[", "inputs", "[", "2", "]", "[", "...", ",", "i", "]", "for", "i", "in", "range", "(", "self", ".", "n_channels", ")", "]", ",", "1", ")", "\n", "stds", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "scatter_nd", "(", "tmp_indices", ",", "stds", ",", "self", ".", "shape", ")", ",", "0", ")", ",", "tile_shape", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatiallySparse_Dense.call": [[472, 517], ["len", "isinstance", "len", "int", "keras.backend.repeat_elements", "keras.backend.batch_flatten", "keras.backend.batch_flatten", "keras.backend.expand_dims", "keras.backend.permute_dimensions", "tensorflow.matrix_inverse", "keras.backend.batch_dot", "keras.backend.batch_dot", "keras.backend.shape", "keras.backend.batch_flatten", "keras.backend.dot", "tensorflow.stack", "keras.backend.reshape", "keras.backend.permute_dimensions", "keras.backend.expand_dims", "keras.backend.batch_dot", "keras.backend.expand_dims", "y.get_shape().as_list", "keras.backend.repeat_elements.get_shape().as_list", "y.get_shape", "keras.backend.repeat_elements.get_shape"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["stds_map", "=", "tf", ".", "map_fn", "(", "lambda", "x", ":", "tf", ".", "gather", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", ",", "[", "stds", ",", "labels", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "return", "stds_map", "*", "tf", ".", "random", ".", "normal", "(", "tf", ".", "shape", "(", "labels", ")", ")", "+", "means_map", "\n", "\n", "", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "return", "input_shape", "[", "0", "]", "if", "(", "self", ".", "n_channels", "==", "1", ")", "else", "tuple", "(", "list", "(", "input_shape", "[", "0", "]", "[", ":", "-", "1", "]", ")", "+", "[", "self", ".", "n_channels", "]", ")", "\n", "\n", "\n", "", "", "class", "SampleResolution", "(", "Layer", ")", ":", "\n", "    ", "\"\"\"Build a random resolution tensor by sampling a uniform distribution of provided range.\n\n    You can use this layer in the following ways:\n        resolution = SampleConditionalGMM(min_resolution)() in this case resolution will be a tensor of shape (n_dims,),\n        where n_dims is the length of the min_resolution parameter (provided as a list, see below).\n        resolution = SampleConditionalGMM(min_resolution)(input), where input is a tensor for which the first dimension\n        represents the batch_size. In this case resolution will be a tensor of shape (batchsize, n_dims,).\n\n    :param min_resolution: list of length n_dims specifying the inferior bounds of the uniform distributions to\n    sample from for each value.\n    :param max_res_iso: If not None, all the values of resolution will be equal to the same value, which is randomly\n    sampled at each minibatch in U(min_resolution, max_res_iso).\n    :param max_res_aniso: If not None, we first randomly select a direction i in the range [0, n_dims-1], and we sample\n    a value in the corresponding uniform distribution U(min_resolution[i], max_res_aniso[i]).\n    The other values of resolution will be set to min_resolution.\n    :param prob_iso: if both max_res_iso and max_res_aniso are specified, this allows to specify the probability of\n    sampling an isotropic resolution (therefore using max_res_iso) with respect to anisotropic resolution\n    (which would use max_res_aniso).\n    :param prob_min: if not zero, this allows to return with the specified probability an output resolution equal\n    to min_resolution.\n    :param return_thickness: if set to True, this layer will also return a thickness value of the same shape as\n    resolution, which will be sampled independently for each axis from the uniform distribution\n    U(min_resolution, resolution).\n\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "\n", "min_resolution", ",", "\n", "max_res_iso", "=", "None", ",", "\n", "max_res_aniso", "=", "None", ",", "\n", "prob_iso", "=", "0.1", ",", "\n", "prob_min", "=", "0.05", ",", "\n", "return_thickness", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "self", ".", "min_res", "=", "min_resolution", "\n", "self", ".", "max_res_iso_input", "=", "max_res_iso", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.SpatiallySparse_Dense.compute_output_shape": [[518, 524], ["None"], "methods", ["None"], ["self", ".", "max_res_iso", "=", "None", "\n", "self", ".", "max_res_aniso_input", "=", "max_res_aniso", "\n", "self", ".", "max_res_aniso", "=", "None", "\n", "self", ".", "prob_iso", "=", "prob_iso", "\n", "self", ".", "prob_min", "=", "prob_min", "\n", "self", ".", "return_thickness", "=", "return_thickness", "\n", "self", ".", "n_dims", "=", "len", "(", "self", ".", "min_res", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalBias.__init__": [[536, 540], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["config", "[", "\"return_thickness\"", "]", "=", "self", ".", "return_thickness", "\n", "return", "config", "\n", "\n", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalBias.get_config": [[541, 546], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["# check maximum resolutions", "\n", "        ", "assert", "(", "(", "self", ".", "max_res_iso_input", "is", "not", "None", ")", "|", "(", "self", ".", "max_res_aniso_input", "is", "not", "None", ")", ")", ",", "'at least one of maximinum isotropic or anisotropic resolutions must be provided, received none'", "\n", "\n", "# reformat resolutions as numpy arrays", "\n", "self", ".", "min_res", "=", "np", ".", "array", "(", "self", ".", "min_res", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalBias.build": [[547, 554], ["layers.LocalBias.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["if", "self", ".", "max_res_iso_input", "is", "not", "None", ":", "\n", "            ", "self", ".", "max_res_iso", "=", "np", ".", "array", "(", "self", ".", "max_res_iso_input", ")", "\n", "assert", "len", "(", "self", ".", "min_res", ")", "==", "len", "(", "self", ".", "max_res_iso", ")", ",", "'min and isotropic max resolution must have the same length, '", "'had {0} and {1}'", ".", "format", "(", "self", ".", "min_res", ",", "self", ".", "max_res_iso", ")", "\n", "if", "np", ".", "array_equal", "(", "self", ".", "min_res", ",", "self", ".", "max_res_iso", ")", ":", "\n", "                ", "self", ".", "max_res_iso", "=", "None", "\n", "", "", "if", "self", ".", "max_res_aniso_input", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalBias.call": [[555, 557], ["None"], "methods", ["None"], ["            ", "self", ".", "max_res_aniso", "=", "np", ".", "array", "(", "self", ".", "max_res_aniso_input", ")", "\n", "assert", "len", "(", "self", ".", "min_res", ")", "==", "len", "(", "self", ".", "max_res_aniso", ")", ",", "'min and anisotopic max resolution must have the same length, '"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalBias.compute_output_shape": [[558, 560], ["None"], "methods", ["None"], ["'had {} and {}'", ".", "format", "(", "self", ".", "min_res", ",", "self", ".", "max_res_aniso", ")", "\n", "if", "np", ".", "array_equal", "(", "self", ".", "min_res", ",", "self", ".", "max_res_aniso", ")", ":", "\n", "                ", "self", ".", "max_res_aniso", "=", "None", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalParam_new.__init__": [[564, 576], ["tuple", "keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["            ", "raise", "Exception", "(", "'prob iso is 0 while sampling either isotropic and anisotropic resolutions is enabled'", ")", "\n", "\n", "", "if", "input_shape", ":", "\n", "            ", "self", ".", "add_batchsize", "=", "True", "\n", "\n", "", "self", ".", "min_res_tens", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "min_res", ",", "dtype", "=", "'float32'", ")", "\n", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "SampleResolution", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n", "", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "not", "self", ".", "add_batchsize", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalParam_new.get_config": [[577, 583], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["            ", "shape", "=", "[", "self", ".", "n_dims", "]", "\n", "dim", "=", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "(", "1", ",", "1", ")", ",", "minval", "=", "0", ",", "maxval", "=", "self", ".", "n_dims", ",", "dtype", "=", "'int32'", ")", "\n", "mask", "=", "tf", ".", "tensor_scatter_nd_update", "(", "tf", ".", "zeros", "(", "[", "self", ".", "n_dims", "]", ",", "dtype", "=", "'bool'", ")", ",", "dim", ",", "\n", "tf", ".", "convert_to_tensor", "(", "[", "True", "]", ",", "dtype", "=", "'bool'", ")", ")", "\n", "", "else", ":", "\n", "            ", "batch", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", "\n", "tile_shape", "=", "tf", ".", "concat", "(", "[", "batch", ",", "tf", ".", "convert_to_tensor", "(", "[", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalParam_new.build": [[584, 592], ["layers.LocalParam_new.add_weight", "super().build", "tuple"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["self", ".", "min_res_tens", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "self", ".", "min_res_tens", ",", "0", ")", ",", "tile_shape", ")", "\n", "\n", "shape", "=", "tf", ".", "concat", "(", "[", "batch", ",", "tf", ".", "convert_to_tensor", "(", "[", "self", ".", "n_dims", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", "\n", "indices", "=", "tf", ".", "stack", "(", "[", "tf", ".", "range", "(", "0", ",", "batch", "[", "0", "]", ")", ",", "tf", ".", "random", ".", "uniform", "(", "batch", ",", "0", ",", "self", ".", "n_dims", ",", "dtype", "=", "'int32'", ")", "]", ",", "1", ")", "\n", "mask", "=", "tf", ".", "tensor_scatter_nd_update", "(", "tf", ".", "zeros", "(", "shape", ",", "dtype", "=", "'bool'", ")", ",", "indices", ",", "tf", ".", "ones", "(", "batch", ",", "dtype", "=", "'bool'", ")", ")", "\n", "\n", "# return min resolution as tensor if min=max", "\n", "", "if", "(", "self", ".", "max_res_iso", "is", "None", ")", "&", "(", "self", ".", "max_res_aniso", "is", "None", ")", ":", "\n", "            ", "new_resolution", "=", "self", ".", "min_res_tens", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalParam_new.call": [[593, 598], ["tensorflow.reshape"], "methods", ["None"], ["\n", "# sample isotropic resolution only", "\n", "", "elif", "(", "self", ".", "max_res_iso", "is", "not", "None", ")", "&", "(", "self", ".", "max_res_aniso", "is", "None", ")", ":", "\n", "            ", "new_resolution_iso", "=", "tf", ".", "random", ".", "uniform", "(", "shape", ",", "minval", "=", "self", ".", "min_res", ",", "maxval", "=", "self", ".", "max_res_iso", ")", "\n", "new_resolution", "=", "K", ".", "switch", "(", "tf", ".", "squeeze", "(", "K", ".", "less", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "0", ",", "1", ")", ",", "self", ".", "prob_min", ")", ")", ",", "\n", "self", ".", "min_res_tens", ",", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalParam_new.compute_output_shape": [[599, 604], ["None"], "methods", ["None"], ["new_resolution_iso", ")", "\n", "\n", "# sample anisotropic resolution only", "\n", "", "elif", "(", "self", ".", "max_res_iso", "is", "None", ")", "&", "(", "self", ".", "max_res_aniso", "is", "not", "None", ")", ":", "\n", "            ", "new_resolution_aniso", "=", "tf", ".", "random", ".", "uniform", "(", "shape", ",", "minval", "=", "self", ".", "min_res", ",", "maxval", "=", "self", ".", "max_res_aniso", ")", "\n", "new_resolution", "=", "K", ".", "switch", "(", "tf", ".", "squeeze", "(", "K", ".", "less", "(", "tf", ".", "random", ".", "uniform", "(", "[", "1", "]", ",", "0", ",", "1", ")", ",", "self", ".", "prob_min", ")", ")", ",", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalParam.__init__": [[617, 661], ["keras.layers.Layer.__init__", "keras.engine.topology.Node", "keras.backend.name_scope", "layers.LocalParam.add_weight", "keras.backend.get_uid"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["new_resolution", ")", "\n", "\n", "", "if", "self", ".", "return_thickness", ":", "\n", "            ", "return", "[", "new_resolution", ",", "tf", ".", "random", ".", "uniform", "(", "tf", ".", "shape", "(", "self", ".", "min_res_tens", ")", ",", "self", ".", "min_res_tens", ",", "new_resolution", ")", "]", "\n", "", "else", ":", "\n", "            ", "return", "new_resolution", "\n", "\n", "", "", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "self", ".", "return_thickness", ":", "\n", "            ", "return", "[", "(", "None", ",", "self", ".", "n_dims", ")", "]", "*", "2", "if", "self", ".", "add_batchsize", "else", "[", "self", ".", "n_dims", "]", "*", "2", "\n", "", "else", ":", "\n", "            ", "return", "(", "None", ",", "self", ".", "n_dims", ")", "if", "self", ".", "add_batchsize", "else", "self", ".", "n_dims", "\n", "\n", "\n", "", "", "", "class", "GaussianBlur", "(", "Layer", ")", ":", "\n", "    ", "\"\"\"Applies gaussian blur to an input image.\n    The input image is expected to have shape [batchsize, shape_dim1, ..., shape_dimn, channel].\n    :param sigma: standard deviation of the blurring kernels to apply. Can be a number, a list of length n_dims, or\n    a numpy array.\n    :param random_blur_range: (optional) if not None, this introduces a randomness in the blurring kernels, where\n    sigma is now multiplied by a coefficient dynamically sampled from a uniform distribution with bounds\n    [1/random_blur_range, random_blur_range].\n    :param use_mask: (optional) whether a mask of the input will be provided as an additionnal layer input. This is used\n    to mask the blurred image, and to correct for edge blurring effects.\n\n    example 1:\n    output = GaussianBlur(sigma=0.5)(input) will isotropically blur the input with a gaussian kernel of std 0.5.\n\n    example 2:\n    if input is a tensor of shape [batchsize, 10, 100, 200, 2]\n    output = GaussianBlur(sigma=[0.5, 1, 10])(input) will blur the input a different gaussian kernel in each dimension.\n\n    example 3:\n    output = GaussianBlur(sigma=0.5, random_blur_range=1.15)(input)\n    will blur the input a different gaussian kernel in each dimension, as each dimension will be associated with a\n    a kernel, whose standard deviation will be uniformly sampled from [0.5/1.15; 0.5*1.15].\n\n    example 4:\n    output = GaussianBlur(sigma=0.5, use_mask=True)([input, mask])\n    will 1) blur the input a different gaussian kernel in each dimension, 2) mask the blurred image with the provided\n    mask, and 3) correct for edge blurring effects. If the provided mask is not of boolean type, it will thresholded\n    above positive values.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "sigma", ",", "random_blur_range", "=", "None", ",", "use_mask", "=", "False", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalParam.get_config": [[662, 671], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["        ", "self", ".", "sigma", "=", "utils", ".", "reformat_to_list", "(", "sigma", ")", "\n", "assert", "np", ".", "all", "(", "np", ".", "array", "(", "self", ".", "sigma", ")", ">=", "0", ")", ",", "'sigma should be superior or equal to 0'", "\n", "self", ".", "use_mask", "=", "use_mask", "\n", "\n", "self", ".", "n_dims", "=", "None", "\n", "self", ".", "n_channels", "=", "None", "\n", "self", ".", "blur_range", "=", "random_blur_range", "\n", "self", ".", "stride", "=", "None", "\n", "self", ".", "separable", "=", "None", "\n", "self", ".", "kernels", "=", "None", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalParam.call": [[672, 675], ["layers.LocalParam.get_output", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalParam.get_output"], ["self", ".", "convnd", "=", "None", "\n", "super", "(", "GaussianBlur", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "", "def", "get_config", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalParam.compute_output_shape": [[676, 678], ["tuple"], "methods", ["None"], ["        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"sigma\"", "]", "=", "self", ".", "sigma", "\n", "config", "[", "\"random_blur_range\"", "]", "=", "self", ".", "blur_range", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalParam.get_output": [[679, 685], ["len"], "methods", ["None"], ["config", "[", "\"use_mask\"", "]", "=", "self", ".", "use_mask", "\n", "return", "config", "\n", "\n", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n", "# get shapes", "\n", "        ", "if", "self", ".", "use_mask", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalLinear.__init__": [[693, 696], ["keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["# prepare blurring kernel", "\n", "", "self", ".", "stride", "=", "[", "1", "]", "*", "(", "self", ".", "n_dims", "+", "2", ")", "\n", "self", ".", "sigma", "=", "utils", ".", "reformat_to_list", "(", "self", ".", "sigma", ",", "length", "=", "self", ".", "n_dims", ")", "\n", "self", ".", "separable", "=", "np", ".", "linalg", ".", "norm", "(", "np", ".", "array", "(", "self", ".", "sigma", ")", ")", ">", "5", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalLinear.get_config": [[697, 701], ["super().get_config"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["if", "self", ".", "blur_range", "is", "None", ":", "# fixed kernels", "\n", "            ", "self", ".", "kernels", "=", "l2i_et", ".", "gaussian_kernel", "(", "self", ".", "sigma", ",", "separable", "=", "self", ".", "separable", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "kernels", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalLinear.build": [[702, 713], ["layers.LocalLinear.add_weight", "layers.LocalLinear.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["# prepare convolution", "\n", "", "self", ".", "convnd", "=", "getattr", "(", "tf", ".", "nn", ",", "'conv%dd'", "%", "self", ".", "n_dims", ")", "\n", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "GaussianBlur", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n", "", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "self", ".", "use_mask", ":", "\n", "            ", "image", "=", "inputs", "[", "0", "]", "\n", "mask", "=", "tf", ".", "cast", "(", "inputs", "[", "1", "]", ",", "'bool'", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalLinear.call": [[714, 716], ["None"], "methods", ["None"], ["            ", "image", "=", "inputs", "\n", "mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocalLinear.compute_output_shape": [[717, 719], ["None"], "methods", ["None"], ["# redefine the kernels at each new step when blur_range is activated", "\n", "", "if", "self", ".", "blur_range", "is", "not", "None", ":", "\n", "            ", "self", ".", "kernels", "=", "l2i_et", ".", "gaussian_kernel", "(", "self", ".", "sigma", ",", "blur_range", "=", "self", ".", "blur_range", ",", "separable", "=", "self", ".", "separable", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.__init__": [[800, 837], ["keras.layers.Layer.__init__", "conv_utils.normalize_tuple", "conv_utils.normalize_tuple", "conv_utils.normalize_padding", "conv_utils.normalize_data_format", "activations.get", "initializers.get", "initializers.get", "regularizers.get", "regularizers.get", "regularizers.get", "constraints.get", "constraints.get", "InputSpec", "ValueError"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["blurred_channel", "=", "list", "(", ")", "\n", "for", "channel", "in", "split_channels", ":", "\n", "                ", "blurred", "=", "self", ".", "convnd", "(", "tf", ".", "expand_dims", "(", "channel", ",", "0", ")", ",", "inputs", "[", "1", "]", ",", "[", "1", "]", "*", "(", "self", ".", "n_dims", "+", "2", ")", ",", "padding", "=", "'SAME'", ")", "\n", "blurred_channel", ".", "append", "(", "tf", ".", "squeeze", "(", "blurred", ",", "axis", "=", "0", ")", ")", "\n", "", "output", "=", "tf", ".", "concat", "(", "blurred_channel", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "convnd", "(", "tf", ".", "expand_dims", "(", "inputs", "[", "0", "]", ",", "0", ")", ",", "inputs", "[", "1", "]", ",", "[", "1", "]", "*", "(", "self", ".", "n_dims", "+", "2", ")", ",", "padding", "=", "'SAME'", ")", "\n", "output", "=", "tf", ".", "squeeze", "(", "output", ",", "axis", "=", "0", ")", "\n", "", "return", "output", "\n", "\n", "\n", "", "", "class", "MimicAcquisition", "(", "Layer", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.build": [[838, 883], ["conv_utils.conv_output_length", "conv_utils.conv_output_length", "conv_utils.conv_output_length", "layers.LocallyConnected3D.add_weight", "ValueError", "layers.LocallyConnected3D.add_weight", "InputSpec", "InputSpec", "str"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "volume_res", ",", "min_subsample_res", ",", "resample_shape", ",", "build_dist_map", "=", "False", ",", "noise_std", "=", "0", ",", "**", "kwargs", ")", ":", "\n", "\n", "# resolutions and dimensions", "\n", "        ", "self", ".", "volume_res", "=", "volume_res", "\n", "self", ".", "min_subsample_res", "=", "min_subsample_res", "\n", "self", ".", "noise_std", "=", "noise_std", "\n", "self", ".", "n_dims", "=", "len", "(", "self", ".", "volume_res", ")", "\n", "self", ".", "n_channels", "=", "None", "\n", "self", ".", "add_batchsize", "=", "None", "\n", "\n", "# input and output shapes", "\n", "self", ".", "inshape", "=", "None", "\n", "self", ".", "resample_shape", "=", "resample_shape", "\n", "\n", "# meshgrids for resampling", "\n", "self", ".", "down_grid", "=", "None", "\n", "self", ".", "up_grid", "=", "None", "\n", "\n", "# whether to return a map indicating the distance from the interpolated voxels, to acquired ones.", "\n", "self", ".", "build_dist_map", "=", "build_dist_map", "\n", "\n", "super", "(", "MimicAcquisition", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"volume_res\"", "]", "=", "self", ".", "volume_res", "\n", "config", "[", "\"min_subsample_res\"", "]", "=", "self", ".", "min_subsample_res", "\n", "config", "[", "\"noise_std\"", "]", "=", "self", ".", "noise_std", "\n", "config", "[", "\"resample_shape\"", "]", "=", "self", ".", "resample_shape", "\n", "config", "[", "\"build_dist_map\"", "]", "=", "self", ".", "build_dist_map", "\n", "return", "config", "\n", "\n", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.compute_output_shape": [[884, 905], ["conv_utils.conv_output_length", "conv_utils.conv_output_length", "conv_utils.conv_output_length"], "methods", ["None"], ["# set up input shape and acquisistion shape", "\n", "        ", "self", ".", "inshape", "=", "input_shape", "[", "0", "]", "[", "1", ":", "]", "\n", "self", ".", "n_channels", "=", "input_shape", "[", "0", "]", "[", "-", "1", "]", "\n", "self", ".", "add_batchsize", "=", "False", "if", "(", "input_shape", "[", "1", "]", "[", "0", "]", "is", "None", ")", "else", "True", "\n", "down_tensor_shape", "=", "np", ".", "int32", "(", "np", ".", "array", "(", "self", ".", "inshape", "[", ":", "-", "1", "]", ")", "*", "self", ".", "volume_res", "/", "self", ".", "min_subsample_res", ")", "\n", "\n", "# build interpolation meshgrids", "\n", "self", ".", "down_grid", "=", "tf", ".", "expand_dims", "(", "tf", ".", "stack", "(", "nrn_utils", ".", "volshape_to_ndgrid", "(", "down_tensor_shape", ")", ",", "-", "1", ")", ",", "axis", "=", "0", ")", "\n", "self", ".", "up_grid", "=", "tf", ".", "expand_dims", "(", "tf", ".", "stack", "(", "nrn_utils", ".", "volshape_to_ndgrid", "(", "self", ".", "resample_shape", ")", ",", "-", "1", ")", ",", "axis", "=", "0", ")", "\n", "\n", "self", ".", "built", "=", "True", "\n", "super", "(", "MimicAcquisition", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n", "", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# sort inputs", "\n", "        ", "assert", "len", "(", "inputs", ")", "==", "2", ",", "'inputs must have two items, the tensor to resample, and the downsampling resolution'", "\n", "vol", "=", "inputs", "[", "0", "]", "\n", "subsample_res", "=", "tf", ".", "cast", "(", "inputs", "[", "1", "]", ",", "dtype", "=", "'float32'", ")", "\n", "vol", "=", "K", ".", "reshape", "(", "vol", ",", "[", "-", "1", ",", "*", "self", ".", "inshape", "]", ")", "# necessary for multi_gpu models", "\n", "batchsize", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "vol", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", "\n", "tile_shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "[", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.call": [[906, 921], ["layers.LocallyConnected3D.local_conv3d", "layers.LocallyConnected3D.activation", "keras.backend.bias_add"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.local_conv3d"], ["\n", "# get downsampling and upsampling factors", "\n", "if", "self", ".", "add_batchsize", ":", "\n", "            ", "subsample_res", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "subsample_res", ",", "0", ")", ",", "tile_shape", ")", "\n", "", "down_shape", "=", "tf", ".", "cast", "(", "tf", ".", "convert_to_tensor", "(", "np", ".", "array", "(", "self", ".", "inshape", "[", ":", "-", "1", "]", ")", "*", "self", ".", "volume_res", ",", "dtype", "=", "'float32'", ")", "/", "\n", "subsample_res", ",", "dtype", "=", "'int32'", ")", "\n", "down_zoom_factor", "=", "tf", ".", "cast", "(", "down_shape", "/", "tf", ".", "convert_to_tensor", "(", "self", ".", "inshape", "[", ":", "-", "1", "]", ")", ",", "dtype", "=", "'float32'", ")", "\n", "up_zoom_factor", "=", "tf", ".", "cast", "(", "tf", ".", "convert_to_tensor", "(", "self", ".", "resample_shape", ",", "dtype", "=", "'int32'", ")", "/", "down_shape", ",", "dtype", "=", "'float32'", ")", "\n", "\n", "# downsample", "\n", "down_loc", "=", "tf", ".", "tile", "(", "self", ".", "down_grid", ",", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "[", "self", ".", "n_dims", "+", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", ")", "\n", "down_loc", "=", "tf", ".", "cast", "(", "down_loc", ",", "'float32'", ")", "/", "l2i_et", ".", "expand_dims", "(", "down_zoom_factor", ",", "axis", "=", "[", "1", "]", "*", "self", ".", "n_dims", ")", "\n", "inshape_tens", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "convert_to_tensor", "(", "self", ".", "inshape", "[", ":", "-", "1", "]", ")", ",", "0", ")", ",", "tile_shape", ")", "\n", "inshape_tens", "=", "l2i_et", ".", "expand_dims", "(", "inshape_tens", ",", "axis", "=", "[", "1", "]", "*", "self", ".", "n_dims", ")", "\n", "down_loc", "=", "K", ".", "clip", "(", "down_loc", ",", "0.", ",", "tf", ".", "cast", "(", "inshape_tens", ",", "'float32'", ")", ")", "\n", "vol", "=", "tf", ".", "map_fn", "(", "self", ".", "_single_down_interpn", ",", "[", "vol", ",", "down_loc", "]", ",", "tf", ".", "float32", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config": [[922, 942], ["super().get_config", "dict", "activations.serialize", "initializers.serialize", "initializers.serialize", "regularizers.serialize", "regularizers.serialize", "regularizers.serialize", "constraints.serialize", "constraints.serialize", "list", "list", "super().get_config.items", "config.items"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.get_config"], ["\n", "# add noise", "\n", "if", "self", ".", "noise_std", ">", "0", ":", "\n", "            ", "sample_shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "[", "self", ".", "n_dims", "]", ",", "dtype", "=", "'int32'", ")", ",", "\n", "self", ".", "n_channels", "*", "tf", ".", "ones", "(", "[", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", "\n", "vol", "+=", "tf", ".", "random", ".", "normal", "(", "tf", ".", "shape", "(", "vol", ")", ",", "stddev", "=", "tf", ".", "random", ".", "uniform", "(", "sample_shape", ",", "maxval", "=", "self", ".", "noise_std", ")", ")", "\n", "\n", "# upsample", "\n", "", "up_loc", "=", "tf", ".", "tile", "(", "self", ".", "up_grid", ",", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "[", "self", ".", "n_dims", "+", "1", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "up_loc", "=", "tf", ".", "cast", "(", "up_loc", ",", "'float32'", ")", "/", "l2i_et", ".", "expand_dims", "(", "up_zoom_factor", ",", "axis", "=", "[", "1", "]", "*", "self", ".", "n_dims", ")", "\n", "vol", "=", "tf", ".", "map_fn", "(", "self", ".", "_single_up_interpn", ",", "[", "vol", ",", "up_loc", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "# return upsampled volume", "\n", "if", "not", "self", ".", "build_dist_map", ":", "\n", "            ", "return", "vol", "\n", "\n", "# return upsampled volumes with distance maps", "\n", "", "else", ":", "\n", "\n", "# get grid points", "\n", "            ", "floor", "=", "tf", ".", "math", ".", "floor", "(", "up_loc", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.LocallyConnected3D.local_conv3d": [[943, 1008], ["keras.backend.int_shape", "range", "keras.backend.concatenate", "keras.backend.batch_dot", "keras.backend.reshape", "keras.backend.image_data_format", "ValueError", "range", "keras.backend.permute_dimensions", "keras.backend.permute_dimensions", "range", "str", "slice", "slice", "slice", "xs.append", "xs.append", "keras.backend.reshape", "keras.backend.reshape"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice"], ["ceil", "=", "tf", ".", "math", ".", "ceil", "(", "up_loc", ")", "\n", "\n", "# get distances of every voxel to higher and lower grid points for every dimension", "\n", "f_dist", "=", "up_loc", "-", "floor", "\n", "c_dist", "=", "ceil", "-", "up_loc", "\n", "\n", "# keep minimum 1d distances, and compute 3d distance to nearest grid point", "\n", "dist", "=", "tf", ".", "math", ".", "minimum", "(", "f_dist", ",", "c_dist", ")", "*", "l2i_et", ".", "expand_dims", "(", "subsample_res", ",", "axis", "=", "[", "1", "]", "*", "self", ".", "n_dims", ")", "\n", "dist", "=", "tf", ".", "math", ".", "sqrt", "(", "tf", ".", "math", ".", "reduce_sum", "(", "tf", ".", "math", ".", "square", "(", "dist", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "\n", "return", "[", "vol", ",", "dist", "]", "\n", "\n", "", "", "@", "staticmethod", "\n", "def", "_single_down_interpn", "(", "inputs", ")", ":", "\n", "        ", "return", "nrn_utils", ".", "interpn", "(", "inputs", "[", "0", "]", ",", "inputs", "[", "1", "]", ",", "interp_method", "=", "'nearest'", ")", "\n", "\n", "", "@", "staticmethod", "\n", "def", "_single_up_interpn", "(", "inputs", ")", ":", "\n", "        ", "return", "nrn_utils", ".", "interpn", "(", "inputs", "[", "0", "]", ",", "inputs", "[", "1", "]", ",", "interp_method", "=", "'linear'", ")", "\n", "\n", "", "def", "compute_output_shape", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "output_shape", "=", "tuple", "(", "[", "None", "]", "+", "self", ".", "resample_shape", "+", "[", "input_shape", "[", "0", "]", "[", "-", "1", "]", "]", ")", "\n", "return", "[", "output_shape", "]", "*", "2", "if", "self", ".", "build_dist_map", "else", "output_shape", "\n", "\n", "\n", "", "", "class", "BiasFieldCorruption", "(", "Layer", ")", ":", "\n", "    ", "\"\"\"This layer applies a smooth random bias field to the input by applying the following steps:\n    1) we first sample a value for the standard deviation of a centred normal distribution\n    2) a small-size SVF is sampled from this normal distribution\n    3) the small SVF is then resized with trilinear interpolation to image size\n    4) it is rescaled to postive values by taking the voxel-wise exponential\n    5) it is multiplied to the input tensor.\n    The input tensor is expected to have shape [batchsize, shape_dim1, ..., shape_dimn, channel].\n\n    :param bias_field_std: maximum value of the standard deviation sampled in 1 (it will be sampled from the range\n    [0, bias_field_std])\n    :param bias_shape_factor: ratio between the shape of the input tensor and the shape of the sampled SVF.\n    :param same_bias_for_all_channels: whether to apply the same bias field to all the channels of the input tensor.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "bias_field_std", "=", ".5", ",", "bias_shape_factor", "=", ".025", ",", "same_bias_for_all_channels", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "\n", "# input shape", "\n", "        ", "self", ".", "several_inputs", "=", "False", "\n", "self", ".", "inshape", "=", "None", "\n", "self", ".", "n_dims", "=", "None", "\n", "self", ".", "n_channels", "=", "None", "\n", "\n", "# sampling shape", "\n", "self", ".", "std_shape", "=", "None", "\n", "self", ".", "small_bias_shape", "=", "None", "\n", "\n", "# bias field parameters", "\n", "self", ".", "bias_field_std", "=", "bias_field_std", "\n", "self", ".", "bias_shape_factor", "=", "bias_shape_factor", "\n", "self", ".", "same_bias_for_all_channels", "=", "same_bias_for_all_channels", "\n", "\n", "super", "(", "BiasFieldCorruption", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n", "config", "[", "\"bias_field_std\"", "]", "=", "self", ".", "bias_field_std", "\n", "config", "[", "\"bias_shape_factor\"", "]", "=", "self", ".", "bias_shape_factor", "\n", "config", "[", "\"same_bias_for_all_channels\"", "]", "=", "self", ".", "same_bias_for_all_channels", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.MeanStream.__init__": [[1049, 1052], ["keras.backend.variable", "keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["return", "[", "tf", ".", "math", ".", "multiply", "(", "bias_field", ",", "v", ")", "for", "v", "in", "inputs", "]", "\n", "\n", "", "else", ":", "\n", "            ", "return", "inputs", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.MeanStream.build": [[1053, 1070], ["layers.MeanStream.add_weight", "layers.MeanStream.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["\n", "\n", "", "", "", "class", "IntensityAugmentation", "(", "Layer", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.MeanStream.call": [[1071, 1086], ["layers._mean_update", "layers.MeanStream.add_update", "tensorflow.concat", "keras.backend.ones", "keras.backend.shape", "keras.backend.minimum", "keras.backend.reshape", "keras.backend.shape", "keras.backend.expand_dims"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers._mean_update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["\n", "\n", "def", "__init__", "(", "self", ",", "noise_std", "=", "0", ",", "clip", "=", "0", ",", "normalise", "=", "True", ",", "norm_perc", "=", "0", ",", "gamma_std", "=", "0", ",", "separate_channels", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "# shape attributes", "\n", "        ", "self", ".", "n_dims", "=", "None", "\n", "self", ".", "n_channels", "=", "None", "\n", "self", ".", "flatten_shape", "=", "None", "\n", "self", ".", "expand_minmax_dim", "=", "None", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.MeanStream.compute_output_shape": [[1087, 1089], ["None"], "methods", ["None"], ["self", ".", "one", "=", "None", "\n", "\n", "# inputs", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.__init__": [[1099, 1102], ["keras.backend.variable", "keras.layers.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["super", "(", "IntensityAugmentation", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", ")", ".", "get_config", "(", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build": [[1103, 1121], ["layers.CovStream.add_weight", "numpy.prod", "layers.CovStream.add_weight", "layers.CovStream.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.build"], ["config", "[", "\"noise_std\"", "]", "=", "self", ".", "noise_std", "\n", "config", "[", "\"clip\"", "]", "=", "self", ".", "clip", "\n", "config", "[", "\"normalise\"", "]", "=", "self", ".", "normalise", "\n", "config", "[", "\"norm_perc\"", "]", "=", "self", ".", "norm_perc", "\n", "config", "[", "\"gamma_std\"", "]", "=", "self", ".", "gamma_std", "\n", "config", "[", "\"separate_channels\"", "]", "=", "self", ".", "separate_channels", "\n", "return", "config", "\n", "\n", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "n_dims", "=", "len", "(", "input_shape", ")", "-", "2", "\n", "self", ".", "n_channels", "=", "input_shape", "[", "-", "1", "]", "\n", "self", ".", "flatten_shape", "=", "np", ".", "prod", "(", "np", ".", "array", "(", "input_shape", "[", "1", ":", "-", "1", "]", ")", ")", "\n", "self", ".", "flatten_shape", "=", "self", ".", "flatten_shape", "*", "self", ".", "n_channels", "if", "not", "self", ".", "separate_channels", "else", "self", ".", "flatten_shape", "\n", "self", ".", "expand_minmax_dim", "=", "self", ".", "n_dims", "if", "self", ".", "separate_channels", "else", "self", ".", "n_dims", "+", "1", "\n", "self", ".", "one", "=", "tf", ".", "ones", "(", "[", "1", "]", ",", "dtype", "=", "'int32'", ")", "\n", "if", "self", ".", "clip", ":", "\n", "            ", "self", ".", "clip_values", "=", "utils", ".", "reformat_to_list", "(", "self", ".", "clip", ")", "\n", "self", ".", "clip_values", "=", "self", ".", "clip_values", "if", "len", "(", "self", ".", "clip_values", ")", "==", "2", "else", "[", "0", ",", "self", ".", "clip_values", "[", "0", "]", "]", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.call": [[1122, 1152], ["tensorflow.cast", "keras.backend.batch_flatten", "layers._mean_update", "keras.backend.expand_dims", "keras.backend.batch_dot", "keras.backend.minimum", "layers.CovStream.add_update", "tensorflow.concat", "keras.backend.ones", "keras.backend.shape", "keras.backend.permute_dimensions", "keras.backend.sum", "keras.backend.minimum", "keras.backend.reshape", "keras.backend.shape", "keras.backend.expand_dims"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers._mean_update", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["            ", "self", ".", "clip_values", "=", "None", "\n", "", "if", "self", ".", "norm_perc", ":", "\n", "            ", "self", ".", "perc", "=", "utils", ".", "reformat_to_list", "(", "self", ".", "norm_perc", ")", "\n", "self", ".", "perc", "=", "self", ".", "perc", "if", "len", "(", "self", ".", "perc", ")", "==", "2", "else", "[", "self", ".", "perc", "[", "0", "]", ",", "1", "-", "self", ".", "perc", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "perc", "=", "None", "\n", "\n", "", "self", ".", "built", "=", "True", "\n", "super", "(", "IntensityAugmentation", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n", "", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "\n", "# prepare shape for sampling the noise and gamma std dev (depending on whether we augment channels separately)", "\n", "        ", "batchsize", "=", "tf", ".", "split", "(", "tf", ".", "shape", "(", "inputs", ")", ",", "[", "1", ",", "-", "1", "]", ")", "[", "0", "]", "\n", "if", "(", "self", ".", "noise_std", ">", "0", ")", "|", "(", "self", ".", "gamma_std", ">", "0", ")", ":", "\n", "            ", "sample_shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "[", "self", ".", "n_dims", "]", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", "\n", "if", "self", ".", "separate_channels", ":", "\n", "                ", "sample_shape", "=", "tf", ".", "concat", "(", "[", "sample_shape", ",", "self", ".", "n_channels", "*", "self", ".", "one", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "sample_shape", "=", "tf", ".", "concat", "(", "[", "sample_shape", ",", "self", ".", "one", "]", ",", "0", ")", "\n", "", "", "else", ":", "\n", "            ", "sample_shape", "=", "None", "\n", "\n", "# add noise", "\n", "", "if", "self", ".", "noise_std", ">", "0", ":", "\n", "            ", "noise_stddev", "=", "tf", ".", "random", ".", "uniform", "(", "sample_shape", ",", "maxval", "=", "self", ".", "noise_std", ")", "\n", "if", "self", ".", "separate_channels", ":", "\n", "                ", "noise", "=", "tf", ".", "random", ".", "normal", "(", "tf", ".", "shape", "(", "inputs", ")", ",", "stddev", "=", "noise_stddev", ")", "\n", "", "else", ":", "\n", "                ", "noise", "=", "tf", ".", "random", ".", "normal", "(", "tf", ".", "shape", "(", "tf", ".", "split", "(", "inputs", ",", "[", "1", ",", "-", "1", "]", ",", "-", "1", ")", "[", "0", "]", ")", ",", "stddev", "=", "noise_stddev", ")", "\n", "noise", "=", "tf", ".", "tile", "(", "noise", ",", "tf", ".", "convert_to_tensor", "(", "[", "1", "]", "*", "(", "self", ".", "n_dims", "+", "1", ")", "+", "[", "self", ".", "n_channels", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers.CovStream.compute_output_shape": [[1153, 1156], ["numpy.prod"], "methods", ["None"], ["", "inputs", "=", "inputs", "+", "noise", "\n", "\n", "# clip images to given values", "\n", "", "if", "self", ".", "clip_values", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.layers._mean_update": [[1158, 1171], ["tensorflow.reduce_sum", "tensorflow.cast", "keras.backend.minimum", "keras.backend.shape"], "function", ["None"], ["\n", "# normalise", "\n", "", "if", "self", ".", "normalise", ":", "\n", "# define robust min and max by sorting values and taking percentile", "\n", "            ", "if", "self", ".", "perc", "is", "not", "None", ":", "\n", "                ", "if", "self", ".", "separate_channels", ":", "\n", "                    ", "shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "self", ".", "flatten_shape", "*", "self", ".", "one", ",", "self", ".", "n_channels", "*", "self", ".", "one", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                    ", "shape", "=", "tf", ".", "concat", "(", "[", "batchsize", ",", "self", ".", "flatten_shape", "*", "self", ".", "one", "]", ",", "0", ")", "\n", "", "intensities", "=", "tf", ".", "sort", "(", "tf", ".", "reshape", "(", "inputs", ",", "shape", ")", ",", "axis", "=", "1", ")", "\n", "m", "=", "intensities", "[", ":", ",", "max", "(", "int", "(", "self", ".", "perc", "[", "0", "]", "*", "self", ".", "flatten_shape", ")", ",", "0", ")", ",", "...", "]", "\n", "M", "=", "intensities", "[", ":", ",", "min", "(", "int", "(", "self", ".", "perc", "[", "1", "]", "*", "self", ".", "flatten_shape", ")", ",", "self", ".", "flatten_shape", "-", "1", ")", ",", "...", "]", "\n", "# simple min and max", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.plot.slices": [[21, 126], ["len", "enumerate", "plot.slices.input_check"], "function", ["None"], ["def", "slices", "(", "slices_in", ",", "# the 2D slices", "\n", "titles", "=", "None", ",", "# list of titles", "\n", "cmaps", "=", "None", ",", "# list of colormaps", "\n", "norms", "=", "None", ",", "# list of normalizations", "\n", "do_colorbars", "=", "False", ",", "# option to show colorbars on each slice", "\n", "grid", "=", "False", ",", "# option to plot the images in a grid or a single row", "\n", "width", "=", "15", ",", "# width in in", "\n", "show", "=", "True", ",", "# option to actually show the plot (plt.show())", "\n", "axes_off", "=", "True", ",", "\n", "imshow_args", "=", "None", ")", ":", "\n", "    ", "'''\n    plot a grid of slices (2d images)\n    '''", "\n", "\n", "# input processing", "\n", "if", "type", "(", "slices_in", ")", "==", "np", ".", "ndarray", ":", "\n", "        ", "slices_in", "=", "[", "slices_in", "]", "\n", "", "nb_plots", "=", "len", "(", "slices_in", ")", "\n", "for", "si", ",", "slice_in", "in", "enumerate", "(", "slices_in", ")", ":", "\n", "        ", "if", "len", "(", "slice_in", ".", "shape", ")", "!=", "2", ":", "\n", "            ", "assert", "len", "(", "slice_in", ".", "shape", ")", "==", "3", "and", "slice_in", ".", "shape", "[", "-", "1", "]", "==", "3", ",", "'each slice has to be 2d or RGB (3 channels)'", "\n", "", "slices_in", "[", "si", "]", "=", "slice_in", ".", "astype", "(", "'float'", ")", "\n", "\n", "\n", "", "def", "input_check", "(", "inputs", ",", "nb_plots", ",", "name", ")", ":", "\n", "        ", "''' change input from None/single-link '''", "\n", "assert", "(", "inputs", "is", "None", ")", "or", "(", "len", "(", "inputs", ")", "==", "nb_plots", ")", "or", "(", "len", "(", "inputs", ")", "==", "1", ")", ",", "'number of %s is incorrect'", "%", "name", "\n", "if", "inputs", "is", "None", ":", "\n", "            ", "inputs", "=", "[", "None", "]", "\n", "", "if", "len", "(", "inputs", ")", "==", "1", ":", "\n", "            ", "inputs", "=", "[", "inputs", "[", "0", "]", "for", "i", "in", "range", "(", "nb_plots", ")", "]", "\n", "", "return", "inputs", "\n", "\n", "", "titles", "=", "input_check", "(", "titles", ",", "nb_plots", ",", "'titles'", ")", "\n", "cmaps", "=", "input_check", "(", "cmaps", ",", "nb_plots", ",", "'cmaps'", ")", "\n", "norms", "=", "input_check", "(", "norms", ",", "nb_plots", ",", "'norms'", ")", "\n", "imshow_args", "=", "input_check", "(", "imshow_args", ",", "nb_plots", ",", "'imshow_args'", ")", "\n", "for", "idx", ",", "ia", "in", "enumerate", "(", "imshow_args", ")", ":", "\n", "        ", "imshow_args", "[", "idx", "]", "=", "{", "}", "if", "ia", "is", "None", "else", "ia", "\n", "\n", "# figure out the number of rows and columns", "\n", "", "if", "grid", ":", "\n", "        ", "if", "isinstance", "(", "grid", ",", "bool", ")", ":", "\n", "            ", "rows", "=", "np", ".", "floor", "(", "np", ".", "sqrt", "(", "nb_plots", ")", ")", ".", "astype", "(", "int", ")", "\n", "cols", "=", "np", ".", "ceil", "(", "nb_plots", "/", "rows", ")", ".", "astype", "(", "int", ")", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "grid", ",", "(", "list", ",", "tuple", ")", ")", ",", "\"grid should either be bool or [rows,cols]\"", "\n", "rows", ",", "cols", "=", "grid", "\n", "", "", "else", ":", "\n", "        ", "rows", "=", "1", "\n", "cols", "=", "nb_plots", "\n", "\n", "# prepare the subplot", "\n", "", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "rows", ",", "cols", ")", "\n", "if", "rows", "==", "1", "and", "cols", "==", "1", ":", "\n", "        ", "axs", "=", "[", "axs", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "nb_plots", ")", ":", "\n", "        ", "col", "=", "np", ".", "remainder", "(", "i", ",", "cols", ")", "\n", "row", "=", "np", ".", "floor", "(", "i", "/", "cols", ")", ".", "astype", "(", "int", ")", "\n", "\n", "# get row and column axes", "\n", "row_axs", "=", "axs", "if", "rows", "==", "1", "else", "axs", "[", "row", "]", "\n", "ax", "=", "row_axs", "[", "col", "]", "\n", "\n", "# turn off axis", "\n", "ax", ".", "axis", "(", "'off'", ")", "\n", "\n", "# add titles", "\n", "if", "titles", "is", "not", "None", "and", "titles", "[", "i", "]", "is", "not", "None", ":", "\n", "            ", "ax", ".", "title", ".", "set_text", "(", "titles", "[", "i", "]", ")", "\n", "\n", "# show figure", "\n", "", "im_ax", "=", "ax", ".", "imshow", "(", "slices_in", "[", "i", "]", ",", "cmap", "=", "cmaps", "[", "i", "]", ",", "interpolation", "=", "\"nearest\"", ",", "norm", "=", "norms", "[", "i", "]", ",", "**", "imshow_args", "[", "i", "]", ")", "\n", "\n", "# colorbars", "\n", "# http://stackoverflow.com/questions/18195758/set-matplotlib-colorbar-size-to-match-graph", "\n", "if", "do_colorbars", "and", "cmaps", "[", "i", "]", "is", "not", "None", ":", "\n", "            ", "divider", "=", "make_axes_locatable", "(", "ax", ")", "\n", "cax", "=", "divider", ".", "append_axes", "(", "\"right\"", ",", "size", "=", "\"5%\"", ",", "pad", "=", "0.05", ")", "\n", "fig", ".", "colorbar", "(", "im_ax", ",", "cax", "=", "cax", ")", "\n", "\n", "# clear axes that are unnecessary", "\n", "", "", "for", "i", "in", "range", "(", "nb_plots", ",", "col", "*", "row", ")", ":", "\n", "        ", "col", "=", "np", ".", "remainder", "(", "i", ",", "cols", ")", "\n", "row", "=", "np", ".", "floor", "(", "i", "/", "cols", ")", ".", "astype", "(", "int", ")", "\n", "\n", "# get row and column axes", "\n", "row_axs", "=", "axs", "if", "rows", "==", "1", "else", "axs", "[", "row", "]", "\n", "ax", "=", "row_axs", "[", "col", "]", "\n", "\n", "if", "axes_off", ":", "\n", "            ", "ax", ".", "axis", "(", "'off'", ")", "\n", "\n", "# show the plots", "\n", "", "", "fig", ".", "set_size_inches", "(", "width", ",", "rows", "/", "cols", "*", "width", ")", "\n", "\n", "\n", "if", "show", ":", "\n", "        ", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "return", "(", "fig", ",", "axs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.plot.flow_legend": [[128, 152], ["numpy.linspace", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin", "numpy.arctan2", "matplotlib.colors.Normalize", "matplotlib.colors.Normalize.autoscale", "matplotlib.figure", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.quiver", "matplotlib.show", "colormap", "matplotlib.colors.Normalize."], "function", ["None"], ["", "def", "flow_legend", "(", ")", ":", "\n", "    ", "\"\"\"\n    show quiver plot to indicate how arrows are colored in the flow() method.\n    https://stackoverflow.com/questions/40026718/different-colours-for-arrows-in-quiver-plot\n    \"\"\"", "\n", "ph", "=", "np", ".", "linspace", "(", "0", ",", "2", "*", "np", ".", "pi", ",", "13", ")", "\n", "x", "=", "np", ".", "cos", "(", "ph", ")", "\n", "y", "=", "np", ".", "sin", "(", "ph", ")", "\n", "u", "=", "np", ".", "cos", "(", "ph", ")", "\n", "v", "=", "np", ".", "sin", "(", "ph", ")", "\n", "colors", "=", "np", ".", "arctan2", "(", "u", ",", "v", ")", "\n", "\n", "norm", "=", "Normalize", "(", ")", "\n", "norm", ".", "autoscale", "(", "colors", ")", "\n", "# we need to normalize our colors array to match it colormap domain", "\n", "# which is [0, 1]", "\n", "\n", "colormap", "=", "cm", ".", "winter", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "6", ",", "6", ")", ")", "\n", "plt", ".", "xlim", "(", "-", "2", ",", "2", ")", "\n", "plt", ".", "ylim", "(", "-", "2", ",", "2", ")", "\n", "plt", ".", "quiver", "(", "x", ",", "y", ",", "u", ",", "v", ",", "color", "=", "colormap", "(", "norm", "(", "colors", ")", ")", ",", "angles", "=", "'xy'", ",", "scale_units", "=", "'xy'", ",", "scale", "=", "1", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.plot.flow": [[154, 262], ["len", "plot.slices.input_check"], "function", ["None"], ["", "def", "flow", "(", "slices_in", ",", "# the 2D slices", "\n", "titles", "=", "None", ",", "# list of titles", "\n", "cmaps", "=", "None", ",", "# list of colormaps", "\n", "width", "=", "15", ",", "# width in in", "\n", "img_indexing", "=", "True", ",", "# whether to match the image view, i.e. flip y axis", "\n", "grid", "=", "False", ",", "# option to plot the images in a grid or a single row", "\n", "show", "=", "True", ",", "# option to actually show the plot (plt.show())", "\n", "scale", "=", "1", ")", ":", "# note quiver essentially draws quiver length = 1/scale", "\n", "    ", "'''\n    plot a grid of flows (2d+2 images)\n    '''", "\n", "\n", "# input processing", "\n", "nb_plots", "=", "len", "(", "slices_in", ")", "\n", "for", "slice_in", "in", "slices_in", ":", "\n", "        ", "assert", "len", "(", "slice_in", ".", "shape", ")", "==", "3", ",", "'each slice has to be 3d: 2d+2 channels'", "\n", "assert", "slice_in", ".", "shape", "[", "-", "1", "]", "==", "2", ",", "'each slice has to be 3d: 2d+2 channels'", "\n", "\n", "", "def", "input_check", "(", "inputs", ",", "nb_plots", ",", "name", ")", ":", "\n", "        ", "''' change input from None/single-link '''", "\n", "if", "not", "isinstance", "(", "inputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "inputs", "=", "[", "inputs", "]", "\n", "", "assert", "(", "inputs", "is", "None", ")", "or", "(", "len", "(", "inputs", ")", "==", "nb_plots", ")", "or", "(", "len", "(", "inputs", ")", "==", "1", ")", ",", "'number of %s is incorrect'", "%", "name", "\n", "if", "inputs", "is", "None", ":", "\n", "            ", "inputs", "=", "[", "None", "]", "\n", "", "if", "len", "(", "inputs", ")", "==", "1", ":", "\n", "            ", "inputs", "=", "[", "inputs", "[", "0", "]", "for", "i", "in", "range", "(", "nb_plots", ")", "]", "\n", "", "return", "inputs", "\n", "\n", "", "if", "img_indexing", ":", "\n", "        ", "for", "si", ",", "slc", "in", "enumerate", "(", "slices_in", ")", ":", "\n", "            ", "slices_in", "[", "si", "]", "=", "np", ".", "flipud", "(", "slc", ")", "\n", "\n", "", "", "titles", "=", "input_check", "(", "titles", ",", "nb_plots", ",", "'titles'", ")", "\n", "cmaps", "=", "input_check", "(", "cmaps", ",", "nb_plots", ",", "'cmaps'", ")", "\n", "scale", "=", "input_check", "(", "scale", ",", "nb_plots", ",", "'scale'", ")", "\n", "\n", "# figure out the number of rows and columns", "\n", "if", "grid", ":", "\n", "        ", "if", "isinstance", "(", "grid", ",", "bool", ")", ":", "\n", "            ", "rows", "=", "np", ".", "floor", "(", "np", ".", "sqrt", "(", "nb_plots", ")", ")", ".", "astype", "(", "int", ")", "\n", "cols", "=", "np", ".", "ceil", "(", "nb_plots", "/", "rows", ")", ".", "astype", "(", "int", ")", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "grid", ",", "(", "list", ",", "tuple", ")", ")", ",", "\"grid should either be bool or [rows,cols]\"", "\n", "rows", ",", "cols", "=", "grid", "\n", "", "", "else", ":", "\n", "        ", "rows", "=", "1", "\n", "cols", "=", "nb_plots", "\n", "\n", "# prepare the subplot", "\n", "", "fig", ",", "axs", "=", "plt", ".", "subplots", "(", "rows", ",", "cols", ")", "\n", "if", "rows", "==", "1", "and", "cols", "==", "1", ":", "\n", "        ", "axs", "=", "[", "axs", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "nb_plots", ")", ":", "\n", "        ", "col", "=", "np", ".", "remainder", "(", "i", ",", "cols", ")", "\n", "row", "=", "np", ".", "floor", "(", "i", "/", "cols", ")", ".", "astype", "(", "int", ")", "\n", "\n", "# get row and column axes", "\n", "row_axs", "=", "axs", "if", "rows", "==", "1", "else", "axs", "[", "row", "]", "\n", "ax", "=", "row_axs", "[", "col", "]", "\n", "\n", "# turn off axis", "\n", "ax", ".", "axis", "(", "'off'", ")", "\n", "\n", "# add titles", "\n", "if", "titles", "is", "not", "None", "and", "titles", "[", "i", "]", "is", "not", "None", ":", "\n", "            ", "ax", ".", "title", ".", "set_text", "(", "titles", "[", "i", "]", ")", "\n", "\n", "", "u", ",", "v", "=", "slices_in", "[", "i", "]", "[", "...", ",", "0", "]", ",", "slices_in", "[", "i", "]", "[", "...", ",", "1", "]", "\n", "colors", "=", "np", ".", "arctan2", "(", "u", ",", "v", ")", "\n", "colors", "[", "np", ".", "isnan", "(", "colors", ")", "]", "=", "0", "\n", "norm", "=", "Normalize", "(", ")", "\n", "norm", ".", "autoscale", "(", "colors", ")", "\n", "if", "cmaps", "[", "i", "]", "is", "None", ":", "\n", "            ", "colormap", "=", "cm", ".", "winter", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"custom cmaps not currently implemented for plt.flow()\"", ")", "\n", "\n", "# show figure", "\n", "", "ax", ".", "quiver", "(", "u", ",", "v", ",", "\n", "color", "=", "colormap", "(", "norm", "(", "colors", ")", ".", "flatten", "(", ")", ")", ",", "\n", "angles", "=", "'xy'", ",", "\n", "units", "=", "'xy'", ",", "\n", "scale", "=", "scale", "[", "i", "]", ")", "\n", "ax", ".", "axis", "(", "'equal'", ")", "\n", "\n", "# clear axes that are unnecessary", "\n", "", "for", "i", "in", "range", "(", "nb_plots", ",", "col", "*", "row", ")", ":", "\n", "        ", "col", "=", "np", ".", "remainder", "(", "i", ",", "cols", ")", "\n", "row", "=", "np", ".", "floor", "(", "i", "/", "cols", ")", ".", "astype", "(", "int", ")", "\n", "\n", "# get row and column axes", "\n", "row_axs", "=", "axs", "if", "rows", "==", "1", "else", "axs", "[", "row", "]", "\n", "ax", "=", "row_axs", "[", "col", "]", "\n", "\n", "ax", ".", "axis", "(", "'off'", ")", "\n", "\n", "# show the plots", "\n", "", "fig", ".", "set_size_inches", "(", "width", ",", "rows", "/", "cols", "*", "width", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "if", "show", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "\n", "", "return", "(", "fig", ",", "axs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.plot.pca": [[264, 303], ["numpy.mean", "numpy.std", "matplotlib.figure", "matplotlib.subplot", "matplotlib.plot", "matplotlib.title", "matplotlib.subplot", "matplotlib.plot", "matplotlib.ylim", "matplotlib.grid", "matplotlib.title", "matplotlib.subplot", "matplotlib.plot", "matplotlib.ylim", "matplotlib.grid", "matplotlib.title", "matplotlib.subplot", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.subplot", "matplotlib.hist", "matplotlib.title", "matplotlib.subplot", "matplotlib.imshow", "matplotlib.colorbar", "matplotlib.title", "matplotlib.show", "numpy.maximum", "numpy.cumsum", "numpy.cumsum", "numpy.transpose", "matplotlib.get_cmap", "numpy.finfo", "numpy.abs", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.grid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.grid"], ["", "def", "pca", "(", "pca", ",", "x", ",", "y", ")", ":", "\n", "    ", "x_mean", "=", "np", ".", "mean", "(", "x", ",", "0", ")", "\n", "x_std", "=", "np", ".", "std", "(", "x", ",", "0", ")", "\n", "\n", "W", "=", "pca", ".", "components_", "\n", "x_mu", "=", "W", "@", "pca", ".", "mean_", "# pca.mean_ is y_mean", "\n", "y_hat", "=", "x", "@", "W", "+", "pca", ".", "mean_", "\n", "\n", "y_err", "=", "y_hat", "-", "y", "\n", "y_rel_err", "=", "y_err", "/", "np", ".", "maximum", "(", "0.5", "*", "(", "np", ".", "abs", "(", "y", ")", "+", "np", ".", "abs", "(", "y_hat", ")", ")", ",", "np", ".", "finfo", "(", "'float'", ")", ".", "eps", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "15", ",", "7", ")", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "3", ",", "1", ")", "\n", "plt", ".", "plot", "(", "pca", ".", "explained_variance_ratio_", ")", "\n", "plt", ".", "title", "(", "'var %% explained'", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "3", ",", "2", ")", "\n", "plt", ".", "plot", "(", "np", ".", "cumsum", "(", "pca", ".", "explained_variance_ratio_", ")", ")", "\n", "plt", ".", "ylim", "(", "[", "0", ",", "1.01", "]", ")", "\n", "plt", ".", "grid", "(", ")", "\n", "plt", ".", "title", "(", "'cumvar explained'", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "3", ",", "3", ")", "\n", "plt", ".", "plot", "(", "np", ".", "cumsum", "(", "pca", ".", "explained_variance_ratio_", ")", ")", "\n", "plt", ".", "ylim", "(", "[", "0.8", ",", "1.01", "]", ")", "\n", "plt", ".", "grid", "(", ")", "\n", "plt", ".", "title", "(", "'cumvar explained'", ")", "\n", "\n", "plt", ".", "subplot", "(", "2", ",", "3", ",", "4", ")", "\n", "plt", ".", "plot", "(", "x_mean", ")", "\n", "plt", ".", "plot", "(", "x_mean", "+", "x_std", ",", "'k'", ")", "\n", "plt", ".", "plot", "(", "x_mean", "-", "x_std", ",", "'k'", ")", "\n", "plt", ".", "title", "(", "'x mean across dims (sorted)'", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "3", ",", "5", ")", "\n", "plt", ".", "hist", "(", "y_rel_err", ".", "flat", ",", "100", ")", "\n", "plt", ".", "title", "(", "'y rel err histogram'", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "3", ",", "6", ")", "\n", "plt", ".", "imshow", "(", "W", "@", "np", ".", "transpose", "(", "W", ")", ",", "cmap", "=", "plt", ".", "get_cmap", "(", "'gray'", ")", ")", "\n", "plt", ".", "colorbar", "(", ")", "\n", "plt", ".", "title", "(", "'W * W\\''", ")", "\n", "plt", ".", "show", "(", ")", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools.extract_z_dec": [[24, 68], ["keras.models.Model", "model.get_layer", "keras.layers.Input", "ext.neuron.utils.mod_submodel", "keras.models.Model", "model.get_layer.get_output_at().get_shape().as_list", "keras.utils.plot_model", "IPython.display.Image", "layer.get_weights", "model.get_layer().get_weights", "model.get_layer.get_output_at().get_shape", "tempfile.NamedTemporaryFile", "len", "numpy.all", "model.get_layer", "model.get_layer.get_output_at", "numpy.mean", "enumerate"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.mod_submodel"], ["def", "extract_z_dec", "(", "model", ",", "sample_layer_name", ",", "vis", "=", "False", ",", "wt_chk", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    extract the z_decoder [z = p(x)] and return it as a keras model\n\n    Example Layer name:\n    sample_layer_name = 'img-img-dense-vae_ae_dense_sample'\n    \"\"\"", "\n", "\n", "# need to make new model to avoid mu, sigma outputs", "\n", "tmp_model", "=", "keras", ".", "models", ".", "Model", "(", "model", ".", "inputs", ",", "model", ".", "outputs", "[", "0", "]", ")", "\n", "\n", "# get new input", "\n", "sample_layer", "=", "model", ".", "get_layer", "(", "sample_layer_name", ")", "\n", "enc_size", "=", "sample_layer", ".", "get_output_at", "(", "0", ")", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "new_z_input", "=", "KL", ".", "Input", "(", "enc_size", ",", "name", "=", "'z_input'", ")", "\n", "\n", "# prepare outputs", "\n", "# assumes z was first input.", "\n", "new_inputs", "=", "[", "new_z_input", ",", "*", "model", ".", "inputs", "[", "1", ":", "]", "]", "\n", "input_layers", "=", "[", "sample_layer_name", ",", "*", "model", ".", "input_layers", "[", "1", ":", "]", "]", "\n", "z_dec_model_outs", "=", "nrn_utils", ".", "mod_submodel", "(", "tmp_model", ",", "\n", "new_input_nodes", "=", "new_inputs", ",", "\n", "input_layers", "=", "input_layers", ")", "\n", "\n", "# get new model", "\n", "z_dec_model", "=", "keras", ".", "models", ".", "Model", "(", "new_inputs", ",", "z_dec_model_outs", ")", "\n", "\n", "if", "vis", ":", "\n", "        ", "outfile", "=", "NamedTemporaryFile", "(", ")", ".", "name", "+", "'.png'", "\n", "plot_model", "(", "z_dec_model", ",", "to_file", "=", "outfile", ",", "show_shapes", "=", "True", ")", "\n", "Image", "(", "outfile", ",", "width", "=", "100", ")", "\n", "\n", "# check model weights:", "\n", "", "if", "wt_chk", ":", "\n", "        ", "for", "layer", "in", "z_dec_model", ".", "layers", ":", "\n", "            ", "wts1", "=", "layer", ".", "get_weights", "(", ")", "\n", "if", "layer", ".", "name", "not", "in", "[", "l", ".", "name", "for", "l", "in", "model", ".", "layers", "]", ":", "\n", "                ", "continue", "\n", "", "wts2", "=", "model", ".", "get_layer", "(", "layer", ".", "name", ")", ".", "get_weights", "(", ")", "\n", "if", "len", "(", "wts1", ")", ">", "0", ":", "\n", "                ", "assert", "np", ".", "all", "(", "[", "np", ".", "mean", "(", "wts1", "[", "i", "]", "-", "wts2", "[", "i", "]", ")", "<", "1e-9", "for", "i", ",", "\n", "_", "in", "enumerate", "(", "wts1", ")", "]", ")", ",", "\"model copy failed\"", "\n", "\n", "", "", "", "return", "z_dec_model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools.z_effect": [[70, 106], ["model.get_layer().get_output_at", "keras.backend.gradients", "numpy.mean", "len", "tensorflow.Session", "sess.run", "tqdm.tqdm", "numpy.abs", "matplotlib.figure", "matplotlib.plot", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.show", "model.get_layer", "tensorflow.initialize_all_variables", "range", "next", "numpy.vstack", "numpy.sort", "model.get_input_at", "sess.run"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "z_effect", "(", "model", ",", "gen", ",", "z_layer_name", ",", "nb_samples", "=", "100", ",", "do_plot", "=", "False", ",", "tqdm", "=", "tqdm", ")", ":", "\n", "    ", "\"\"\"\n    compute the effect of each z dimension on the final outcome via derivatives\n    we attempt this by taking gradients as in\n    https://stackoverflow.com/questions/39561560/getting-gradient-of-model-output-w-r-t-weights-using-keras\n\n    e.g. layer name: 'img-img-dense-vae_ae_dense_sample'\n    \"\"\"", "\n", "\n", "outputTensor", "=", "model", ".", "outputs", "[", "0", "]", "\n", "inner", "=", "model", ".", "get_layer", "(", "z_layer_name", ")", ".", "get_output_at", "(", "1", ")", "\n", "\n", "# compute gradients", "\n", "gradients", "=", "K", ".", "gradients", "(", "outputTensor", ",", "inner", ")", "\n", "assert", "len", "(", "gradients", ")", "==", "1", ",", "\"wrong gradients\"", "\n", "\n", "# would be nice to be able to do this with K.eval() as opposed to explicit tensorflow sessions.", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "initialize_all_variables", "(", ")", ")", "\n", "\n", "evaluated_gradients", "=", "[", "None", "]", "*", "nb_samples", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "nb_samples", ")", ")", ":", "\n", "            ", "sample", "=", "next", "(", "gen", ")", "\n", "fdct", "=", "{", "model", ".", "get_input_at", "(", "0", ")", ":", "sample", "[", "0", "]", "}", "\n", "evaluated_gradients", "[", "i", "]", "=", "sess", ".", "run", "(", "gradients", ",", "feed_dict", "=", "fdct", ")", "[", "0", "]", "\n", "\n", "", "", "all_gradients", "=", "np", ".", "mean", "(", "np", ".", "abs", "(", "np", ".", "vstack", "(", "evaluated_gradients", ")", ")", ",", "0", ")", "\n", "\n", "if", "do_plot", ":", "\n", "        ", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "plot", "(", "np", ".", "sort", "(", "all_gradients", ")", ")", "\n", "plt", ".", "xlabel", "(", "'sorted z index'", ")", "\n", "plt", ".", "ylabel", "(", "'mean(|grad|)'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "return", "all_gradients", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools.sample_dec": [[108, 171], ["[].as_list", "numpy.exp", "enumerate", "numpy.zeros", "numpy.reshape", "numpy.zeros", "numpy.reshape", "numpy.linspace", "numpy.copy", "tqdm.tqdm", "z_dec_model.predict", "numpy.random.normal", "z_dec_model.inputs[].get_shape", "numpy.ones", "range", "len", "numpy.finfo"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "sample_dec", "(", "z_dec_model", ",", "\n", "z_mu", "=", "None", ",", "\n", "z_logvar", "=", "None", ",", "\n", "nb_samples", "=", "5", ",", "\n", "tqdm", "=", "tqdm", ",", "\n", "z_id", "=", "None", ",", "\n", "do_sweep", "=", "False", ",", "\n", "nb_sweep_stds", "=", "3", ",", "\n", "extra_inputs", "=", "[", "]", ",", "\n", "nargout", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    sample from the decoder (i.e. sample z, compute x_mu|z)\n\n    use z_id if you want to vary only a specific z index\n\n    use sweep parameters if you want to sweep around mu from one end to another.\n    \"\"\"", "\n", "\n", "input_shape", "=", "z_dec_model", ".", "inputs", "[", "0", "]", ".", "get_shape", "(", ")", "[", "1", ":", "]", ".", "as_list", "(", ")", "\n", "if", "z_mu", "is", "None", ":", "\n", "        ", "z_mu", "=", "np", ".", "zeros", "(", "[", "1", ",", "*", "input_shape", "]", ")", "\n", "", "else", ":", "\n", "        ", "z_mu", "=", "np", ".", "reshape", "(", "z_mu", ",", "[", "1", ",", "*", "input_shape", "]", ")", "\n", "\n", "", "if", "z_logvar", "is", "None", ":", "\n", "        ", "z_logvar", "=", "np", ".", "zeros", "(", "[", "1", ",", "*", "input_shape", "]", ")", "\n", "", "else", ":", "\n", "        ", "z_logvar", "=", "np", ".", "reshape", "(", "z_logvar", ",", "[", "1", ",", "*", "input_shape", "]", ")", "\n", "\n", "# get standard deviation", "\n", "", "z_std", "=", "np", ".", "exp", "(", "z_logvar", "/", "2", ")", "\n", "\n", "# get samples", "\n", "if", "do_sweep", ":", "\n", "        ", "if", "z_id", "is", "not", "None", ":", "\n", "            ", "low", "=", "z_mu", "\n", "high", "=", "z_mu", "\n", "low", "[", "0", ",", "z_id", "]", "=", "z_mu", "[", "0", ",", "z_id", "]", "-", "nb_sweep_stds", "*", "z_std", "[", "0", ",", "z_id", "]", "\n", "high", "[", "0", ",", "z_id", "]", "=", "z_mu", "[", "0", ",", "z_id", "]", "-", "nb_sweep_stds", "*", "z_std", "[", "0", ",", "z_id", "]", "\n", "", "else", ":", "\n", "            ", "low", "=", "z_mu", "-", "nb_sweep_stds", "*", "z_std", "\n", "high", "=", "z_mu", "-", "nb_sweep_stds", "*", "z_std", "\n", "\n", "", "x_sweep", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "nb_samples", ")", "\n", "z_samples", "=", "[", "x", "*", "high", "+", "(", "1", "-", "x", ")", "*", "low", "for", "x", "in", "x_sweep", "]", "\n", "\n", "", "else", ":", "\n", "        ", "std", "=", "np", ".", "copy", "(", "z_std", ")", "\n", "if", "z_id", "is", "not", "None", ":", "\n", "            ", "std", "=", "np", ".", "ones", "(", "len", "(", "z_std", ")", ")", "*", "np", ".", "finfo", "(", "'float'", ")", ".", "eps", "\n", "std", "[", "0", ",", "z_id", "]", "=", "z_std", "[", "0", ",", "z_id", "]", "\n", "", "z_samples", "=", "[", "np", ".", "random", ".", "normal", "(", "loc", "=", "z_mu", ",", "scale", "=", "z_std", ")", "\n", "for", "_", "in", "range", "(", "nb_samples", ")", "]", "\n", "\n", "# propagate", "\n", "", "outs", "=", "[", "None", "]", "*", "nb_samples", "\n", "for", "zi", ",", "z_sample", "in", "enumerate", "(", "tqdm", "(", "z_samples", ")", ")", ":", "\n", "        ", "outs", "[", "zi", "]", "=", "z_dec_model", ".", "predict", "(", "[", "z_sample", ",", "*", "extra_inputs", "]", ")", "\n", "\n", "", "if", "nargout", "==", "1", ":", "\n", "        ", "return", "outs", "\n", "", "else", ":", "\n", "        ", "return", "(", "outs", ",", "z_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools.sweep_dec_given_x": [[173, 219], ["keras.models.Model", "keras.models.Model.predict", "keras.models.Model.predict", "numpy.linspace", "enumerate", "full_model.get_layer().get_output_at", "tqdm.tqdm", "isinstance", "z_dec_model.predict", "z_dec_model.predict", "full_model.get_layer"], "function", ["None"], ["", "", "def", "sweep_dec_given_x", "(", "full_model", ",", "z_dec_model", ",", "sample1", ",", "sample2", ",", "sample_layer_name", ",", "\n", "sweep_z_samples", "=", "False", ",", "\n", "nb_samples", "=", "10", ",", "\n", "nargout", "=", "1", ",", "\n", "tqdm", "=", "tqdm", ")", ":", "\n", "    ", "\"\"\"\n    sweep the latent space given two samples in the original space\n    specificaly, get z_mu = enc(x) for both samples, and sweep between those z_mus\n\n    \"sweep_z_samples\" does a sweep between two samples, rather than between two z_mus.\n\n    Example:\n    sample_layer_name='img-img-dense-vae_ae_dense_sample'\n    \"\"\"", "\n", "\n", "# get a model that also outputs the samples z", "\n", "full_output", "=", "[", "*", "full_model", ".", "outputs", ",", "\n", "full_model", ".", "get_layer", "(", "sample_layer_name", ")", ".", "get_output_at", "(", "1", ")", "]", "\n", "full_model_plus", "=", "keras", ".", "models", ".", "Model", "(", "full_model", ".", "inputs", ",", "full_output", ")", "\n", "\n", "# get full predictions for these samples", "\n", "pred1", "=", "full_model_plus", ".", "predict", "(", "sample1", "[", "0", "]", ")", "\n", "pred2", "=", "full_model_plus", ".", "predict", "(", "sample2", "[", "0", "]", ")", "\n", "img1", "=", "sample1", "[", "0", "]", "\n", "img2", "=", "sample2", "[", "0", "]", "\n", "\n", "# sweep range", "\n", "x_range", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "nb_samples", ")", "\n", "\n", "# prepare outputs", "\n", "outs", "=", "[", "None", "]", "*", "nb_samples", "\n", "for", "xi", ",", "x", "in", "enumerate", "(", "tqdm", "(", "x_range", ")", ")", ":", "\n", "        ", "if", "sweep_z_samples", ":", "\n", "            ", "z", "=", "x", "*", "pred1", "[", "3", "]", "+", "(", "1", "-", "x", ")", "*", "pred2", "[", "3", "]", "\n", "", "else", ":", "\n", "            ", "z", "=", "x", "*", "pred1", "[", "1", "]", "+", "(", "1", "-", "x", ")", "*", "pred2", "[", "1", "]", "\n", "\n", "", "if", "isinstance", "(", "sample1", "[", "0", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "# assuming prior or something like that", "\n", "            ", "outs", "[", "xi", "]", "=", "z_dec_model", ".", "predict", "(", "[", "z", ",", "*", "sample1", "[", "0", "]", "[", "1", ":", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "outs", "[", "xi", "]", "=", "z_dec_model", ".", "predict", "(", "z", ")", "\n", "\n", "", "", "if", "nargout", "==", "1", ":", "\n", "        ", "return", "outs", "\n", "", "else", ":", "\n", "        ", "return", "(", "outs", ",", "[", "pred1", ",", "pred2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools.pca_init_dense": [[221, 298], ["model.get_layer", "model.get_layer", "len", "range", "vae_tools.model_output_pca", "model.get_layer.set_weights", "model.get_layer.set_weights", "model.get_layer.get_output_at().get_shape().as_list", "len", "numpy.maximum", "model.get_layer().set_weights", "model.get_layer.get_input_at", "keras.models.Model", "model.get_layer.get_input_at().get_shape().as_list", "len", "numpy.transpose", "model.get_layer.get_output_at().get_shape", "model.get_layer", "numpy.transpose", "Exception", "model.get_layer.get_input_at().get_shape", "model.get_layer.get_weights", "model.get_layer.get_output_at", "model.get_layer.get_input_at"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools.model_output_pca"], ["", "", "def", "pca_init_dense", "(", "model", ",", "mu_dense_layer_name", ",", "undense_layer_name", ",", "generator", ",", "\n", "input_len", "=", "None", ",", "\n", "do_vae", "=", "True", ",", "\n", "logvar_dense_layer_name", "=", "None", ",", "\n", "nb_samples", "=", "None", ",", "\n", "tqdm", "=", "tqdm", ",", "\n", "vis", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    initialize the (V)AE middle *dens*e layer with PCA\n    Warning: this modifies the weights in your model!\n\n    model should take input the same as the normal (V)AE, and output a flat layer before the mu dense layer\n    if nb_samples is None, we will compute at least as many as there are initial dimension (Which might be a lot)\n\n    assumes mu_dense_layer_name is of input size [None, pre_mu_len] and output size [None, enc_len]\n\n    example\n    mu_dense_layer_name = 'img-img-dense-ae_ae_mu_enc_1000'\n    undense_layer_name = 'img-img-dense-ae_ae_dense_dec_flat_1000'\n    \"\"\"", "\n", "\n", "# extract important layer", "\n", "mu_dense_layer", "=", "model", ".", "get_layer", "(", "mu_dense_layer_name", ")", "\n", "mu_undense_layer", "=", "model", ".", "get_layer", "(", "undense_layer_name", ")", "\n", "\n", "# prepare model that outputs the pre_mu flat", "\n", "nb_inbound_nodes", "=", "len", "(", "mu_dense_layer", ".", "_inbound_nodes", ")", "\n", "for", "i", "in", "range", "(", "nb_inbound_nodes", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "out_tensor", "=", "mu_dense_layer", ".", "get_input_at", "(", "i", ")", "\n", "pre_mu_model", "=", "keras", ".", "models", ".", "Model", "(", "model", ".", "inputs", ",", "out_tensor", ")", "\n", "\n", "# save the node index", "\n", "node_idx", "=", "i", "\n", "break", "\n", "\n", "", "except", ":", "\n", "            ", "if", "i", "==", "nb_inbound_nodes", "-", "1", ":", "\n", "                ", "raise", "Exception", "(", "\n", "'Could not initialize pre_mu model. Something went wrong :('", ")", "\n", "\n", "# extract PCA sizes", "\n", "", "", "", "if", "input_len", "is", "None", ":", "\n", "        ", "input_len", "=", "mu_dense_layer", ".", "get_input_at", "(", "\n", "node_idx", ")", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "assert", "len", "(", "input_len", ")", "==", "1", ",", "'layer input size is not 0'", "\n", "input_len", "=", "input_len", "[", "0", "]", "\n", "if", "input_len", "is", "None", ":", "\n", "            ", "input_len", "=", "mu_dense_layer", ".", "get_weights", "(", ")", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "", "assert", "input_len", "is", "not", "None", ",", "\"could not figure out input len\"", "\n", "\n", "", "enc_size", "=", "mu_dense_layer", ".", "get_output_at", "(", "node_idx", ")", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "\n", "assert", "len", "(", "enc_size", ")", "==", "1", ",", "'encoding size is not 0'", "\n", "enc_len", "=", "enc_size", "[", "0", "]", "\n", "\n", "# number of samples", "\n", "if", "nb_samples", "is", "None", ":", "\n", "        ", "nb_samples", "=", "np", ".", "maximum", "(", "enc_len", ",", "input_len", ")", "\n", "\n", "# mu pca", "\n", "", "pca_mu", ",", "x", ",", "y", "=", "model_output_pca", "(", "\n", "pre_mu_model", ",", "generator", ",", "nb_samples", ",", "enc_len", ",", "vis", "=", "vis", ",", "tqdm", "=", "tqdm", ")", "\n", "W_mu", "=", "pca_mu", ".", "components_", "# enc_size * input_len", "\n", "\n", "# fix pca", "\n", "# y = x @ W + y_mean = (x + x_mu) @ W", "\n", "# x = y @ np.transpose(W) - x_mu", "\n", "mu_dense_layer", ".", "set_weights", "(", "[", "np", ".", "transpose", "(", "W_mu", ")", ",", "-", "(", "W_mu", "@", "pca_mu", ".", "mean_", ")", "]", ")", "\n", "mu_undense_layer", ".", "set_weights", "(", "[", "W_mu", ",", "+", "pca_mu", ".", "mean_", "]", ")", "\n", "\n", "# set var components with mu pca as well.", "\n", "if", "do_vae", ":", "\n", "        ", "model", ".", "get_layer", "(", "logvar_dense_layer_name", ")", ".", "set_weights", "(", "\n", "[", "np", ".", "transpose", "(", "W_mu", ")", ",", "-", "x_mu", "]", ")", "\n", "\n", "# return pca data at least for debugging", "\n", "", "return", "(", "pca_mu", ",", "x", ",", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools.model_output_pca": [[300, 350], ["next", "vae_tools._sample_batch_size", "sklearn.decomposition.PCA", "sklearn.decomposition.PCA.fit_transform", "pre_mu_model.predict", "tqdm.tqdm", "numpy.vstack", "pre_mu_model.predict", "ext.neuron.pca", "range", "next", "pre_mu_model.predict"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools._sample_batch_size", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.plot.pca", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "model_output_pca", "(", "pre_mu_model", ",", "generator", ",", "nb_samples", ",", "nb_components", ",", "\n", "vis", "=", "False", ",", "\n", "tqdm", "=", "tqdm", ")", ":", "\n", "    ", "\"\"\"\n    compute PCA of model outputs\n    \"\"\"", "\n", "\n", "# go through", "\n", "sample", "=", "next", "(", "generator", ")", "\n", "nb_batch_samples", "=", "_sample_batch_size", "(", "sample", ")", "\n", "if", "nb_batch_samples", "==", "1", ":", "\n", "        ", "zs", "=", "[", "None", "]", "*", "nb_samples", "\n", "zs", "[", "0", "]", "=", "pre_mu_model", ".", "predict", "(", "sample", "[", "0", "]", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "1", ",", "nb_samples", ")", ")", ":", "\n", "            ", "sample", "=", "next", "(", "generator", ")", "\n", "zs", "[", "i", "]", "=", "pre_mu_model", ".", "predict", "(", "sample", "[", "0", "]", ")", "\n", "", "y", "=", "np", ".", "vstack", "(", "zs", ")", "\n", "\n", "", "else", ":", "\n", "        ", "assert", "nb_batch_samples", "==", "nb_samples", ",", "\"generator should either give us 1 sample or %d samples at once. got: %d\"", "%", "(", "nb_samples", ",", "nb_batch_samples", ")", "\n", "y", "=", "pre_mu_model", ".", "predict", "(", "sample", "[", "0", "]", ")", "\n", "\n", "# pca", "\n", "", "pca", "=", "PCA", "(", "n_components", "=", "nb_components", ")", "\n", "x", "=", "pca", ".", "fit_transform", "(", "y", ")", "\n", "\n", "# make sure we can recover", "\n", "if", "vis", ":", "\n", "        ", "nrn_plt", ".", "pca", "(", "pca", ",", "x", ",", "y", ")", "\n", "\n", "", "\"\"\" \n    Test pca model assaignment:\n    # make input, then dense, then dense, then output, and see if input is output for y samples.\n    inp = KL.Input(pca.mean_.shape)\n    den = KL.Dense(x_mu.shape[0])\n    den_o = den(inp)\n    unden = KL.Dense(pca.mean_.shape[0])\n    unden_o = unden(den_o)\n    test_ae = keras.models.Model(inp, [den_o, unden_o])\n\n    den.set_weights([np.transpose(W), - x_mu])\n    unden.set_weights([W, + pca.mean_])\n\n    x_pred, y_pred = test_ae.predict(y)\n    x_pred - x\n    y_pred - y\n    \"\"\"", "\n", "\n", "return", "(", "pca", ",", "x", ",", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools.latent_stats": [[352, 377], ["tqdm.tqdm", "numpy.vstack", "numpy.reshape", "numpy.vstack", "numpy.reshape", "range", "next", "model.predict"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "latent_stats", "(", "model", ",", "gen", ",", "nb_reps", "=", "100", ",", "tqdm", "=", "tqdm", ")", ":", "\n", "    ", "\"\"\"\n    Gather several latent_space statistics (mu, var)\n\n    Parameters:\n        gen: generator (will call next() on this a few times)\n        model: model (will predict from generator samples)\n    \"\"\"", "\n", "\n", "mu_data", "=", "[", "None", "]", "*", "nb_reps", "\n", "logvar_data", "=", "[", "None", "]", "*", "nb_reps", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "nb_reps", ")", ")", ":", "\n", "        ", "sample", "=", "next", "(", "gen", ")", "\n", "p", "=", "model", ".", "predict", "(", "sample", "[", "0", "]", ")", "\n", "mu_data", "[", "i", "]", "=", "p", "[", "1", "]", "\n", "logvar_data", "[", "i", "]", "=", "p", "[", "2", "]", "\n", "\n", "", "mu_data", "=", "np", ".", "vstack", "(", "mu_data", ")", "\n", "mu_data", "=", "np", ".", "reshape", "(", "mu_data", ",", "(", "mu_data", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "logvar_data", "=", "np", ".", "vstack", "(", "logvar_data", ")", "\n", "logvar_data", "=", "np", ".", "reshape", "(", "logvar_data", ",", "(", "logvar_data", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "data", "=", "{", "'mu'", ":", "mu_data", ",", "'logvar'", ":", "logvar_data", "}", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools.latent_stats_plots": [[379, 442], ["vae_tools.latent_stats", "numpy.linspace", "print", "print", "matplotlib.figure", "matplotlib.subplot", "matplotlib.scatter", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.subplot", "matplotlib.scatter", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.show", "numpy.linspace", "numpy.arange", "matplotlib.figure", "matplotlib.subplot", "numpy.mean", "numpy.argsort", "matplotlib.scatter", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.subplot", "numpy.mean", "matplotlib.scatter", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.show", "numpy.std", "numpy.std"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools.latent_stats", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], ["", "def", "latent_stats_plots", "(", "model", ",", "gen", ",", "nb_reps", "=", "100", ",", "dim_1", "=", "0", ",", "dim_2", "=", "1", ",", "figsize", "=", "(", "15", ",", "7", ")", ",", "tqdm", "=", "tqdm", ")", ":", "\n", "    ", "\"\"\"\n    Make some debug/info (mostly latent-stats-related) plots\n\n    Parameters:\n        gen: generator (will call next() on this a few times)\n        model: model (will predict from generator samples)\n    \"\"\"", "\n", "\n", "data", "=", "latent_stats", "(", "model", ",", "gen", ",", "nb_reps", "=", "nb_reps", ",", "tqdm", "=", "tqdm", ")", "\n", "mu_data", "=", "data", "[", "'mu'", "]", "\n", "logvar_data", "=", "data", "[", "'logvar'", "]", "\n", "\n", "z", "=", "mu_data", ".", "shape", "[", "0", "]", "\n", "colors", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "z", ")", "\n", "print", "(", "'colors:'", ",", "colors", ".", "shape", ")", "\n", "print", "(", "'VAE plots: colors represent sample index'", ")", "\n", "\n", "# plot", "\n", "plt", ".", "figure", "(", "figsize", "=", "figsize", ")", "\n", "plt", ".", "subplot", "(", "1", ",", "2", ",", "1", ")", "\n", "plt", ".", "scatter", "(", "mu_data", "[", ":", ",", "dim_1", "]", ",", "mu_data", "[", ":", ",", "dim_2", "]", ",", "c", "=", "colors", ")", "\n", "plt", ".", "title", "(", "'mu dist. nb_reps=%d. colors = sample idx.'", "%", "nb_reps", ")", "\n", "plt", ".", "xlabel", "(", "'dim %d'", "%", "dim_1", ")", "\n", "plt", ".", "ylabel", "(", "'dim %d'", "%", "dim_2", ")", "\n", "plt", ".", "subplot", "(", "1", ",", "2", ",", "2", ")", "\n", "plt", ".", "scatter", "(", "logvar_data", "[", ":", ",", "dim_1", "]", ",", "logvar_data", "[", ":", ",", "dim_2", "]", ",", "c", "=", "colors", ")", "\n", "plt", ".", "title", "(", "'std dist. nb_reps=%d. colors = sample idx.'", "%", "nb_reps", ")", "\n", "plt", ".", "xlabel", "(", "'dim %d'", "%", "dim_1", ")", "\n", "plt", ".", "ylabel", "(", "'dim %d'", "%", "dim_2", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "# plot means and variances", "\n", "z", "=", "mu_data", ".", "shape", "[", "1", "]", "\n", "colors", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "z", ")", "\n", "x", "=", "np", ".", "arange", "(", "z", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "figsize", ")", "\n", "plt", ".", "subplot", "(", "1", ",", "2", ",", "1", ")", "\n", "mu_mean", "=", "np", ".", "mean", "(", "mu_data", ",", "0", ")", "\n", "mu_idx", "=", "np", ".", "argsort", "(", "mu_mean", ")", "\n", "mu_mean_sort", "=", "mu_mean", "[", "mu_idx", "]", "\n", "mu_std_sort", "=", "np", ".", "std", "(", "mu_data", ",", "0", ")", "[", "mu_idx", "]", "\n", "plt", ".", "scatter", "(", "x", ",", "mu_mean_sort", ",", "c", "=", "colors", "[", "mu_idx", "]", ")", "\n", "plt", ".", "plot", "(", "x", ",", "mu_mean_sort", "+", "mu_std_sort", ",", "'k'", ")", "\n", "plt", ".", "plot", "(", "x", ",", "mu_mean_sort", "-", "mu_std_sort", ",", "'k'", ")", "\n", "plt", ".", "title", "(", "'mean mu. nb_reps=%d. colors = sorted dim.'", "%", "nb_reps", ")", "\n", "plt", ".", "xlabel", "(", "'sorted dims'", ")", "\n", "plt", ".", "ylabel", "(", "'mean mu'", ")", "\n", "\n", "plt", ".", "subplot", "(", "1", ",", "2", ",", "2", ")", "\n", "logvar_mean", "=", "np", ".", "mean", "(", "logvar_data", ",", "0", ")", "\n", "logvar_mean_sort", "=", "logvar_mean", "[", "mu_idx", "]", "\n", "logvar_std_sort", "=", "np", ".", "std", "(", "logvar_data", ",", "0", ")", "[", "mu_idx", "]", "\n", "plt", ".", "scatter", "(", "x", ",", "logvar_mean_sort", ",", "c", "=", "colors", "[", "mu_idx", "]", ")", "\n", "plt", ".", "plot", "(", "x", ",", "logvar_mean_sort", "+", "logvar_std_sort", ",", "'k'", ")", "\n", "plt", ".", "plot", "(", "x", ",", "logvar_mean_sort", "-", "logvar_std_sort", ",", "'k'", ")", "\n", "plt", ".", "title", "(", "'mean logvar. nb_reps=%d'", "%", "nb_reps", ")", "\n", "plt", ".", "xlabel", "(", "'sorted dims (diff than mu)'", ")", "\n", "plt", ".", "ylabel", "(", "'mean std'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools._sample_batch_size": [[449, 457], ["isinstance", "vae_tools._sample_batch_size"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.vae_tools._sample_batch_size"], ["", "def", "_sample_batch_size", "(", "sample", ")", ":", "\n", "    ", "\"\"\"\n    get the batch size of a sample, while not knowing how many lists are in the input object.\n    \"\"\"", "\n", "if", "isinstance", "(", "sample", "[", "0", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "return", "_sample_batch_size", "(", "sample", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "sample", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelWeightCheck.__init__": [[33, 49], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "weight_diff", "=", "False", ",", "\n", "at_batch_end", "=", "False", ",", "\n", "at_epoch_end", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Params:\n            at_batch_end: None or number indicate when to execute\n                (i.e. at_batch_end = 10 means execute every 10 batches)\n            at_epoch_end: logical, whether to execute at epoch end\n        \"\"\"", "\n", "super", "(", "ModelWeightCheck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "at_batch_end", "=", "at_batch_end", "\n", "self", ".", "at_epoch_end", "=", "at_epoch_end", "\n", "self", ".", "current_epoch", "=", "0", "\n", "self", ".", "weight_diff", "=", "weight_diff", "\n", "self", ".", "wts", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelWeightCheck.on_batch_end": [[50, 53], ["callbacks.ModelWeightCheck.on_model_check", "numpy.mod"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.CheckLossTrend.on_model_check"], ["", "def", "on_batch_end", "(", "self", ",", "batch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "at_batch_end", "is", "not", "None", "and", "np", ".", "mod", "(", "batch", "+", "1", ",", "self", ".", "at_batch_end", ")", "==", "0", ":", "\n", "            ", "self", ".", "on_model_check", "(", "self", ".", "current_epoch", ",", "batch", "+", "1", ",", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelWeightCheck.on_epoch_end": [[54, 58], ["callbacks.ModelWeightCheck.on_model_check"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.CheckLossTrend.on_model_check"], ["", "", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "at_epoch_end", ":", "\n", "            ", "self", ".", "on_model_check", "(", "epoch", ",", "0", ",", "logs", "=", "logs", ")", "\n", "", "self", ".", "current_epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelWeightCheck.on_model_check": [[59, 78], ["layer.get_weights", "callbacks.ModelWeightCheck.model.get_weights", "numpy.all", "enumerate", "numpy.any", "numpy.isfinite", "numpy.isnan", "len", "enumerate", "numpy.maximum", "numpy.max", "numpy.abs"], "methods", ["None"], ["", "def", "on_model_check", "(", "self", ",", "epoch", ",", "iter", ",", "logs", "=", "None", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "model", ".", "layers", ":", "\n", "            ", "for", "wt", "in", "layer", ".", "get_weights", "(", ")", ":", "\n", "                ", "assert", "~", "np", ".", "any", "(", "np", ".", "isnan", "(", "wt", ")", ")", ",", "'Found nan weights in model layer %s'", "%", "layer", ".", "name", "\n", "assert", "np", ".", "all", "(", "np", ".", "isfinite", "(", "wt", ")", ")", ",", "'Found infinite weights in model layer %s'", "%", "layer", ".", "name", "\n", "\n", "# compute max change", "\n", "", "", "if", "self", ".", "weight_diff", ":", "\n", "            ", "wts", "=", "self", ".", "model", ".", "get_weights", "(", ")", "\n", "diff", "=", "-", "np", ".", "inf", "\n", "\n", "if", "self", ".", "wts", "is", "not", "None", ":", "\n", "                ", "for", "wi", ",", "w", "in", "enumerate", "(", "wts", ")", ":", "\n", "                    ", "if", "len", "(", "w", ")", ">", "0", ":", "\n", "                        ", "for", "si", ",", "sw", "in", "enumerate", "(", "w", ")", ":", "\n", "                            ", "diff", "=", "np", ".", "maximum", "(", "diff", ",", "np", ".", "max", "(", "np", ".", "abs", "(", "sw", "-", "self", ".", "wts", "[", "wi", "]", "[", "si", "]", ")", ")", ")", "\n", "\n", "", "", "", "", "self", ".", "wts", "=", "wts", "\n", "logs", "[", "'max_diff'", "]", "=", "diff", "\n", "# print(\"max diff\", diff)", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.CheckLossTrend.__init__": [[86, 104], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "\n", "at_batch_end", "=", "True", ",", "\n", "at_epoch_end", "=", "False", ",", "\n", "nb_std_err", "=", "2", ",", "\n", "loss_window", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        Params:\n            at_batch_end: None or number indicate when to execute\n                (i.e. at_batch_end = 10 means execute every 10 batches)\n            at_epoch_end: logical, whether to execute at epoch end\n        \"\"\"", "\n", "super", "(", "CheckLossTrend", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "at_batch_end", "=", "at_batch_end", "\n", "self", ".", "at_epoch_end", "=", "at_epoch_end", "\n", "self", ".", "current_epoch", "=", "0", "\n", "self", ".", "loss_window", "=", "loss_window", "\n", "self", ".", "nb_std_err", "=", "nb_std_err", "\n", "self", ".", "losses", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.CheckLossTrend.on_batch_end": [[105, 108], ["callbacks.CheckLossTrend.on_model_check", "numpy.mod"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.CheckLossTrend.on_model_check"], ["", "def", "on_batch_end", "(", "self", ",", "batch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "at_batch_end", "is", "not", "None", "and", "np", ".", "mod", "(", "batch", "+", "1", ",", "self", ".", "at_batch_end", ")", "==", "0", ":", "\n", "            ", "self", ".", "on_model_check", "(", "self", ".", "current_epoch", ",", "batch", "+", "1", ",", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.CheckLossTrend.on_epoch_end": [[109, 113], ["callbacks.CheckLossTrend.on_model_check"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.CheckLossTrend.on_model_check"], ["", "", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "at_epoch_end", ":", "\n", "            ", "self", ".", "on_model_check", "(", "epoch", ",", "0", ",", "logs", "=", "logs", ")", "\n", "", "self", ".", "current_epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.CheckLossTrend.on_model_check": [[114, 134], ["len", "numpy.mean", "numpy.std", "print", "print", "ValueError"], "methods", ["None"], ["", "def", "on_model_check", "(", "self", ",", "epoch", ",", "iter", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "losses", ")", "<", "self", ".", "loss_window", ":", "\n", "            ", "self", ".", "losses", "=", "[", "*", "self", ".", "losses", ",", "logs", "[", "'loss'", "]", "]", "\n", "", "else", ":", "\n", "            ", "losses_mean", "=", "np", ".", "mean", "(", "self", ".", "losses", ")", "\n", "losses_std", "=", "np", ".", "std", "(", "self", ".", "losses", ")", "\n", "this_loss", "=", "logs", "[", "'loss'", "]", "\n", "\n", "if", "(", "this_loss", ")", ">", "(", "losses_mean", "+", "self", ".", "nb_std_err", "*", "losses_std", ")", ":", "\n", "                ", "print", "(", "logs", ")", "\n", "err", "=", "\"Found loss %f, which is much higher than %f + %f \"", "%", "(", "this_loss", ",", "losses_mean", ",", "losses_std", ")", "\n", "# raise ValueError(err)", "\n", "print", "(", "err", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "\n", "", "if", "(", "this_loss", "-", "losses_mean", ")", ">", "(", "losses_mean", "*", "100", ")", ":", "\n", "                ", "err", "=", "\"Found loss %f, which is much higher than %f * 100 \"", "%", "(", "this_loss", ",", "losses_mean", ")", "\n", "raise", "ValueError", "(", "err", ")", "\n", "\n", "# cut the first loss and stack athe latest loss.", "\n", "", "self", ".", "losses", "=", "[", "*", "self", ".", "losses", "[", "1", ":", "]", ",", "logs", "[", "'loss'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PlotTestSlices.__init__": [[141, 189], ["super().__init__", "numpy.load", "numpy.expand_dims"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["def", "__init__", "(", "self", ",", "\n", "savefilepath", ",", "\n", "generator", ",", "\n", "vol_size", ",", "\n", "run", ",", "# object with fields: patch_size, patch_stride, grid_size", "\n", "data", ",", "# object with fields:", "\n", "at_batch_end", "=", "None", ",", "# None or number indicate when to execute (i.e. at_batch_end = 10 means execute every 10 batches)", "\n", "at_epoch_end", "=", "True", ",", "# logical, whether to execute at epoch end", "\n", "verbose", "=", "False", ",", "\n", "period", "=", "1", ",", "\n", "prior", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameteres:\n            savefilepath,\n            generator,\n            vol_size,\n            run: object with fields: patch_size, patch_stride, grid_size\n            data: object with fields:\n            at_batch_end=None: None or number indicate when to execute (i.e. at_batch_end = 10 means execute every 10 batches)\n            at_epoch_end=True: logical, whether to execute at epoch end\n            verbose=False:\n            period=1\n            prior=None\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# save some parameters", "\n", "self", ".", "savefilepath", "=", "savefilepath", "\n", "self", ".", "generator", "=", "generator", "\n", "self", ".", "vol_size", "=", "vol_size", "\n", "\n", "self", ".", "run", "=", "run", "\n", "self", ".", "data", "=", "data", "\n", "\n", "self", ".", "at_batch_end", "=", "at_batch_end", "\n", "self", ".", "at_epoch_end", "=", "at_epoch_end", "\n", "self", ".", "current_epoch", "=", "0", "\n", "self", ".", "period", "=", "period", "\n", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n", "# prepare prior", "\n", "self", ".", "prior", "=", "None", "\n", "if", "prior", "is", "not", "None", ":", "\n", "            ", "data", "=", "np", ".", "load", "(", "prior", ")", "\n", "loc_vol", "=", "data", "[", "'prior'", "]", "\n", "self", ".", "prior", "=", "np", ".", "expand_dims", "(", "loc_vol", ",", "axis", "=", "0", ")", "# reshape for model", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PlotTestSlices.on_batch_end": [[190, 193], ["callbacks.PlotTestSlices.on_plot_save", "numpy.mod"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PlotTestSlices.on_plot_save"], ["", "", "def", "on_batch_end", "(", "self", ",", "batch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "if", "self", ".", "at_batch_end", "is", "not", "None", "and", "np", ".", "mod", "(", "batch", "+", "1", ",", "self", ".", "at_batch_end", ")", "==", "0", ":", "\n", "            ", "self", ".", "on_plot_save", "(", "self", ".", "current_epoch", ",", "batch", "+", "1", ",", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PlotTestSlices.on_epoch_end": [[194, 198], ["callbacks.PlotTestSlices.on_plot_save", "numpy.mod"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PlotTestSlices.on_plot_save"], ["", "", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "if", "self", ".", "at_epoch_end", "and", "np", ".", "mod", "(", "epoch", "+", "1", ",", "self", ".", "period", ")", "==", "0", ":", "\n", "            ", "self", ".", "on_plot_save", "(", "epoch", ",", "0", ",", "logs", "=", "logs", ")", "\n", "", "self", ".", "current_epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PlotTestSlices.on_plot_save": [[199, 233], ["imp.reload", "ext.pytools.timer.Timer", "nrn_sandbox.show_example_prediction_result", "enumerate", "matplotlib.close", "len", "callbacks.PlotTestSlices.savefilepath.format", "fig.savefig"], "methods", ["None"], ["", "def", "on_plot_save", "(", "self", ",", "epoch", ",", "iter", ",", "logs", "=", "{", "}", ")", ":", "\n", "# import neuron sandbox", "\n", "# has to be here, can't be at the top, due to cyclical imports (??)", "\n", "# TODO: should just pass the function to compute the figures given the model and generator", "\n", "        ", "from", "ext", "import", "neuron", "as", "nrn_sandbox", "\n", "reload", "(", "nrn_sandbox", ")", "\n", "\n", "with", "timer", ".", "Timer", "(", "'plot callback'", ",", "self", ".", "verbose", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "run", ".", "grid_size", ")", "==", "3", ":", "\n", "                ", "collapse_2d", "=", "[", "0", ",", "1", ",", "2", "]", "\n", "", "else", ":", "\n", "                ", "collapse_2d", "=", "[", "2", "]", "\n", "\n", "", "exampl", "=", "nrn_sandbox", ".", "show_example_prediction_result", "(", "self", ".", "model", ",", "\n", "self", ".", "generator", ",", "\n", "self", ".", "run", ",", "\n", "self", ".", "data", ",", "\n", "test_batch_size", "=", "1", ",", "\n", "test_model_names", "=", "None", ",", "\n", "test_grid_size", "=", "self", ".", "run", ".", "grid_size", ",", "\n", "ccmap", "=", "None", ",", "\n", "collapse_2d", "=", "collapse_2d", ",", "\n", "slice_nr", "=", "None", ",", "\n", "plt_width", "=", "17", ",", "\n", "verbose", "=", "self", ".", "verbose", ")", "\n", "\n", "# save, then close", "\n", "figs", "=", "exampl", "[", "1", ":", "]", "\n", "for", "idx", ",", "fig", "in", "enumerate", "(", "figs", ")", ":", "\n", "                ", "dirn", "=", "\"dirn_%d\"", "%", "idx", "\n", "slice_nr", "=", "0", "\n", "filename", "=", "self", ".", "savefilepath", ".", "format", "(", "epoch", "=", "epoch", ",", "iter", "=", "iter", ",", "axis", "=", "dirn", ",", "slice_nr", "=", "slice_nr", ")", "\n", "fig", ".", "savefig", "(", "filename", ")", "\n", "", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PredictMetrics.__init__": [[241, 290], ["list", "range"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["def", "__init__", "(", "self", ",", "\n", "filepath", ",", "\n", "metrics", ",", "\n", "data_generator", ",", "\n", "nb_samples", ",", "\n", "nb_labels", ",", "\n", "batch_size", ",", "\n", "label_ids", "=", "None", ",", "\n", "vol_params", "=", "None", ",", "\n", "at_batch_end", "=", "None", ",", "\n", "at_epoch_end", "=", "True", ",", "\n", "period", "=", "1", ",", "\n", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            filepath: filepath with epoch and metric\n            metrics: list of metrics (functions)\n            data_generator: validation generator\n            nb_samples: number of validation samples - volumes or batches\n                depending on whether vol_params is passed or not\n            nb_labels: number of labels\n            batch_size:\n            label_ids=None:\n            vol_params=None:\n            at_batch_end=None: None or number indicate when to execute\n                (i.e. at_batch_end = 10 means execute every 10 batches)\n            at_epoch_end=True: logical, whether to execute at epoch end\n            verbose=False\n        \"\"\"", "\n", "\n", "# pass in the parameters to object variables", "\n", "self", ".", "metrics", "=", "metrics", "\n", "self", ".", "data_generator", "=", "data_generator", "\n", "self", ".", "nb_samples", "=", "nb_samples", "\n", "self", ".", "filepath", "=", "filepath", "\n", "self", ".", "nb_labels", "=", "nb_labels", "\n", "if", "label_ids", "is", "None", ":", "\n", "            ", "self", ".", "label_ids", "=", "list", "(", "range", "(", "nb_labels", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "label_ids", "=", "label_ids", "\n", "", "self", ".", "vol_params", "=", "vol_params", "\n", "\n", "self", ".", "current_epoch", "=", "1", "\n", "self", ".", "at_batch_end", "=", "at_batch_end", "\n", "self", ".", "at_epoch_end", "=", "at_epoch_end", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "period", "=", "period", "\n", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PredictMetrics.on_batch_end": [[291, 294], ["callbacks.PredictMetrics.on_metric_call", "numpy.mod"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PredictMetrics.on_metric_call"], ["", "def", "on_batch_end", "(", "self", ",", "batch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "if", "self", ".", "at_batch_end", "is", "not", "None", "and", "np", ".", "mod", "(", "batch", "+", "1", ",", "self", ".", "at_batch_end", ")", "==", "0", ":", "\n", "            ", "self", ".", "on_metric_call", "(", "self", ".", "current_epoch", ",", "batch", "+", "1", ",", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PredictMetrics.on_epoch_end": [[295, 299], ["callbacks.PredictMetrics.on_metric_call", "numpy.mod"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PredictMetrics.on_metric_call"], ["", "", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "if", "self", ".", "at_epoch_end", "and", "np", ".", "mod", "(", "epoch", "+", "1", ",", "self", ".", "period", ")", "==", "0", ":", "\n", "            ", "self", ".", "on_metric_call", "(", "epoch", ",", "0", ",", "logs", "=", "logs", ")", "\n", "", "self", ".", "current_epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.PredictMetrics.on_metric_call": [[300, 332], ["ext.pytools.timer.Timer", "numpy.zeros", "callbacks._generate_predictions", "enumerate", "enumerate", "numpy.nanmean", "enumerate", "len", "metric", "callbacks.PredictMetrics.filepath.format", "numpy.savetxt", "range"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks._generate_predictions", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "def", "on_metric_call", "(", "self", ",", "epoch", ",", "iter", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\" compute metrics on several predictions \"\"\"", "\n", "with", "timer", ".", "Timer", "(", "'predict metrics callback'", ",", "self", ".", "verbose", ")", ":", "\n", "\n", "# prepare metric", "\n", "            ", "met", "=", "np", ".", "zeros", "(", "(", "self", ".", "nb_samples", ",", "self", ".", "nb_labels", ",", "len", "(", "self", ".", "metrics", ")", ")", ")", "\n", "\n", "# generate predictions", "\n", "# the idea is to predict either a full volume or just a slice,", "\n", "# depending on what we need", "\n", "gen", "=", "_generate_predictions", "(", "self", ".", "model", ",", "\n", "self", ".", "data_generator", ",", "\n", "self", ".", "batch_size", ",", "\n", "self", ".", "nb_samples", ",", "\n", "self", ".", "vol_params", ")", "\n", "batch_idx", "=", "0", "\n", "for", "(", "vol_true", ",", "vol_pred", ")", "in", "gen", ":", "\n", "                ", "for", "idx", ",", "metric", "in", "enumerate", "(", "self", ".", "metrics", ")", ":", "\n", "                    ", "met", "[", "batch_idx", ",", ":", ",", "idx", "]", "=", "metric", "(", "vol_true", ",", "vol_pred", ")", "\n", "", "batch_idx", "+=", "1", "\n", "\n", "# write metric to csv file", "\n", "", "if", "self", ".", "filepath", "is", "not", "None", ":", "\n", "                ", "for", "idx", ",", "metric", "in", "enumerate", "(", "self", ".", "metrics", ")", ":", "\n", "                    ", "filen", "=", "self", ".", "filepath", ".", "format", "(", "epoch", "=", "epoch", ",", "iter", "=", "iter", ",", "metric", "=", "metric", ".", "__name__", ")", "\n", "np", ".", "savetxt", "(", "filen", ",", "met", "[", ":", ",", ":", ",", "idx", "]", ",", "fmt", "=", "'%f'", ",", "delimiter", "=", "','", ")", "\n", "", "", "else", ":", "\n", "                ", "meanmet", "=", "np", ".", "nanmean", "(", "met", ",", "axis", "=", "0", ")", "\n", "for", "midx", ",", "metric", "in", "enumerate", "(", "self", ".", "metrics", ")", ":", "\n", "                    ", "for", "idx", "in", "range", "(", "self", ".", "nb_labels", ")", ":", "\n", "                        ", "varname", "=", "'%s_label_%d'", "%", "(", "metric", ".", "__name__", ",", "self", ".", "label_ids", "[", "idx", "]", ")", "\n", "logs", "[", "varname", "]", "=", "meanmet", "[", "idx", ",", "midx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpoint.__init__": [[369, 416], ["super().__init__", "warnings.warn", "callbacks.ModelCheckpoint.monitor.startswith"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "filepath", ",", "\n", "monitor", "=", "'val_loss'", ",", "\n", "save_best_only", "=", "False", ",", "\n", "save_weights_only", "=", "False", ",", "\n", "at_batch_end", "=", "None", ",", "\n", "at_epoch_end", "=", "True", ",", "\n", "mode", "=", "'auto'", ",", "period", "=", "1", ",", "\n", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parameters:\n            ...\n            at_batch_end=None: None or number indicate when to execute\n                (i.e. at_batch_end = 10 means execute every 10 batches)\n            at_epoch_end=True: logical, whether to execute at epoch end\n        \"\"\"", "\n", "super", "(", "ModelCheckpoint", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "monitor", "=", "monitor", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "filepath", "=", "filepath", "\n", "self", ".", "save_best_only", "=", "save_best_only", "\n", "self", ".", "save_weights_only", "=", "save_weights_only", "\n", "self", ".", "period", "=", "period", "\n", "self", ".", "steps_since_last_save", "=", "0", "\n", "\n", "if", "mode", "not", "in", "[", "'auto'", ",", "'min'", ",", "'max'", "]", ":", "\n", "            ", "warnings", ".", "warn", "(", "'ModelCheckpoint mode %s is unknown, '", "\n", "'fallback to auto mode.'", "%", "(", "mode", ")", ",", "\n", "RuntimeWarning", ")", "\n", "mode", "=", "'auto'", "\n", "\n", "", "if", "mode", "==", "'min'", ":", "\n", "            ", "self", ".", "monitor_op", "=", "np", ".", "less", "\n", "self", ".", "best", "=", "np", ".", "Inf", "\n", "", "elif", "mode", "==", "'max'", ":", "\n", "            ", "self", ".", "monitor_op", "=", "np", ".", "greater", "\n", "self", ".", "best", "=", "-", "np", ".", "Inf", "\n", "", "else", ":", "\n", "            ", "if", "'acc'", "in", "self", ".", "monitor", "or", "self", ".", "monitor", ".", "startswith", "(", "'fmeasure'", ")", ":", "\n", "                ", "self", ".", "monitor_op", "=", "np", ".", "greater", "\n", "self", ".", "best", "=", "-", "np", ".", "Inf", "\n", "", "else", ":", "\n", "                ", "self", ".", "monitor_op", "=", "np", ".", "less", "\n", "self", ".", "best", "=", "np", ".", "Inf", "\n", "\n", "", "", "self", ".", "at_batch_end", "=", "at_batch_end", "\n", "self", ".", "at_epoch_end", "=", "at_epoch_end", "\n", "self", ".", "current_epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpoint.on_epoch_begin": [[417, 419], ["None"], "methods", ["None"], ["", "def", "on_epoch_begin", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "self", ".", "current_epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpoint.on_batch_end": [[420, 424], ["print", "callbacks.ModelCheckpoint.on_model_save", "numpy.mod"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpointParallel.on_model_save"], ["", "def", "on_batch_end", "(", "self", ",", "batch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "at_batch_end", "is", "not", "None", "and", "np", ".", "mod", "(", "batch", "+", "1", ",", "self", ".", "at_batch_end", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"Saving model at batch end!\"", ")", "\n", "self", ".", "on_model_save", "(", "self", ".", "current_epoch", ",", "batch", "+", "1", ",", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpoint.on_epoch_end": [[425, 429], ["callbacks.ModelCheckpoint.on_model_save"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpointParallel.on_model_save"], ["", "", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "at_epoch_end", ":", "\n", "            ", "self", ".", "on_model_save", "(", "epoch", ",", "0", ",", "logs", "=", "logs", ")", "\n", "", "self", ".", "current_epoch", "=", "epoch", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpoint.on_model_save": [[430, 467], ["ext.pytools.timer.Timer", "callbacks.ModelCheckpoint.filepath.format", "logs.get", "warnings.warn", "callbacks.ModelCheckpoint.monitor_op", "print", "callbacks.ModelCheckpoint.model.save_weights", "callbacks.ModelCheckpoint.model.save", "print", "callbacks.ModelCheckpoint.model.save_weights", "callbacks.ModelCheckpoint.model.save", "print"], "methods", ["None"], ["", "def", "on_model_save", "(", "self", ",", "epoch", ",", "iter", ",", "logs", "=", "None", ")", ":", "\n", "        ", "\"\"\" save the model to hdf5. Code mostly from keras core \"\"\"", "\n", "\n", "with", "timer", ".", "Timer", "(", "'model save callback'", ",", "self", ".", "verbose", ")", ":", "\n", "            ", "logs", "=", "logs", "or", "{", "}", "\n", "self", ".", "steps_since_last_save", "+=", "1", "\n", "if", "self", ".", "steps_since_last_save", ">=", "self", ".", "period", ":", "\n", "                ", "self", ".", "steps_since_last_save", "=", "0", "\n", "filepath", "=", "self", ".", "filepath", ".", "format", "(", "epoch", "=", "epoch", ",", "iter", "=", "iter", ",", "**", "logs", ")", "\n", "if", "self", ".", "save_best_only", ":", "\n", "                    ", "current", "=", "logs", ".", "get", "(", "self", ".", "monitor", ")", "\n", "if", "current", "is", "None", ":", "\n", "                        ", "warnings", ".", "warn", "(", "'Can save best model only with %s available, '", "\n", "'skipping.'", "%", "(", "self", ".", "monitor", ")", ",", "RuntimeWarning", ")", "\n", "", "else", ":", "\n", "                        ", "if", "self", ".", "monitor_op", "(", "current", ",", "self", ".", "best", ")", ":", "\n", "                            ", "if", "self", ".", "verbose", ">", "0", ":", "\n", "                                ", "print", "(", "'Epoch %05d Iter%05d: %s improved from %0.5f to %0.5f,'", "\n", "' saving model to %s'", "\n", "%", "(", "epoch", ",", "iter", ",", "self", ".", "monitor", ",", "self", ".", "best", ",", "\n", "current", ",", "filepath", ")", ")", "\n", "", "self", ".", "best", "=", "current", "\n", "if", "self", ".", "save_weights_only", ":", "\n", "                                ", "self", ".", "model", ".", "save_weights", "(", "filepath", ",", "overwrite", "=", "True", ")", "\n", "", "else", ":", "\n", "                                ", "self", ".", "model", ".", "save", "(", "filepath", ",", "overwrite", "=", "True", ")", "\n", "", "", "else", ":", "\n", "                            ", "if", "self", ".", "verbose", ">", "0", ":", "\n", "                                ", "print", "(", "'Epoch %05d Iter%05d: %s did not improve'", "%", "\n", "(", "epoch", ",", "iter", ",", "self", ".", "monitor", ")", ")", "\n", "", "", "", "", "else", ":", "\n", "                    ", "if", "self", ".", "verbose", ">", "0", ":", "\n", "                        ", "print", "(", "'Epoch %05d: saving model to %s'", "%", "(", "epoch", ",", "filepath", ")", ")", "\n", "", "if", "self", ".", "save_weights_only", ":", "\n", "                        ", "self", ".", "model", ".", "save_weights", "(", "filepath", ",", "overwrite", "=", "True", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "model", ".", "save", "(", "filepath", ",", "overwrite", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpointParallel.__init__": [[502, 539], ["super().__init__", "warnings.warn", "callbacks.ModelCheckpointParallel.monitor.startswith"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__"], ["def", "__init__", "(", "self", ",", "filepath", ",", "monitor", "=", "'val_loss'", ",", "verbose", "=", "0", ",", "\n", "save_best_only", "=", "False", ",", "save_weights_only", "=", "False", ",", "\n", "at_batch_end", "=", "None", ",", "\n", "at_epoch_end", "=", "True", ",", "\n", "mode", "=", "'auto'", ",", "period", "=", "1", ")", ":", "\n", "        ", "super", "(", "ModelCheckpointParallel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "monitor", "=", "monitor", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "filepath", "=", "filepath", "\n", "self", ".", "save_best_only", "=", "save_best_only", "\n", "self", ".", "save_weights_only", "=", "save_weights_only", "\n", "self", ".", "period", "=", "period", "\n", "self", ".", "epochs_since_last_save", "=", "0", "\n", "\n", "if", "mode", "not", "in", "[", "'auto'", ",", "'min'", ",", "'max'", "]", ":", "\n", "            ", "warnings", ".", "warn", "(", "'ModelCheckpointParallel mode %s is unknown, '", "\n", "'fallback to auto mode.'", "%", "(", "mode", ")", ",", "\n", "RuntimeWarning", ")", "\n", "mode", "=", "'auto'", "\n", "\n", "", "if", "mode", "==", "'min'", ":", "\n", "            ", "self", ".", "monitor_op", "=", "np", ".", "less", "\n", "self", ".", "best", "=", "np", ".", "Inf", "\n", "", "elif", "mode", "==", "'max'", ":", "\n", "            ", "self", ".", "monitor_op", "=", "np", ".", "greater", "\n", "self", ".", "best", "=", "-", "np", ".", "Inf", "\n", "", "else", ":", "\n", "            ", "if", "'acc'", "in", "self", ".", "monitor", "or", "self", ".", "monitor", ".", "startswith", "(", "'fmeasure'", ")", ":", "\n", "                ", "self", ".", "monitor_op", "=", "np", ".", "greater", "\n", "self", ".", "best", "=", "-", "np", ".", "Inf", "\n", "", "else", ":", "\n", "                ", "self", ".", "monitor_op", "=", "np", ".", "less", "\n", "self", ".", "best", "=", "np", ".", "Inf", "\n", "\n", "", "", "self", ".", "at_batch_end", "=", "at_batch_end", "\n", "self", ".", "at_epoch_end", "=", "at_epoch_end", "\n", "self", ".", "current_epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpointParallel.on_epoch_begin": [[540, 542], ["None"], "methods", ["None"], ["", "def", "on_epoch_begin", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "self", ".", "current_epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpointParallel.on_batch_end": [[543, 547], ["print", "callbacks.ModelCheckpointParallel.on_model_save", "numpy.mod"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpointParallel.on_model_save"], ["", "def", "on_batch_end", "(", "self", ",", "batch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "at_batch_end", "is", "not", "None", "and", "np", ".", "mod", "(", "batch", "+", "1", ",", "self", ".", "at_batch_end", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"Saving model at batch end!\"", ")", "\n", "self", ".", "on_model_save", "(", "self", ".", "current_epoch", ",", "batch", "+", "1", ",", "logs", "=", "logs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpointParallel.on_epoch_end": [[548, 552], ["callbacks.ModelCheckpointParallel.on_model_save"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpointParallel.on_model_save"], ["", "", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "at_epoch_end", ":", "\n", "            ", "self", ".", "on_model_save", "(", "epoch", ",", "0", ",", "logs", "=", "logs", ")", "\n", "", "self", ".", "current_epoch", "=", "epoch", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks.ModelCheckpointParallel.on_model_save": [[553, 591], ["ext.pytools.timer.Timer", "len", "callbacks.ModelCheckpointParallel.filepath.format", "logs.get", "warnings.warn", "callbacks.ModelCheckpointParallel.monitor_op", "print", "callbacks.ModelCheckpointParallel.model.layers[].save_weights", "callbacks.ModelCheckpointParallel.model.layers[].save", "print", "callbacks.ModelCheckpointParallel.model.layers[].save_weights", "callbacks.ModelCheckpointParallel.model.layers[].save", "print"], "methods", ["None"], ["", "def", "on_model_save", "(", "self", ",", "epoch", ",", "iter", ",", "logs", "=", "None", ")", ":", "\n", "        ", "\"\"\" save the model to hdf5. Code mostly from keras core \"\"\"", "\n", "\n", "with", "timer", ".", "Timer", "(", "'model save callback'", ",", "self", ".", "verbose", ")", ":", "\n", "            ", "logs", "=", "logs", "or", "{", "}", "\n", "num_outputs", "=", "len", "(", "self", ".", "model", ".", "outputs", ")", "\n", "self", ".", "epochs_since_last_save", "+=", "1", "\n", "if", "self", ".", "epochs_since_last_save", ">=", "self", ".", "period", ":", "\n", "                ", "self", ".", "epochs_since_last_save", "=", "0", "\n", "filepath", "=", "self", ".", "filepath", ".", "format", "(", "epoch", "=", "epoch", ",", "iter", "=", "iter", ",", "**", "logs", ")", "\n", "if", "self", ".", "save_best_only", ":", "\n", "                    ", "current", "=", "logs", ".", "get", "(", "self", ".", "monitor", ")", "\n", "if", "current", "is", "None", ":", "\n", "                        ", "warnings", ".", "warn", "(", "'Can save best model only with %s available, '", "\n", "'skipping.'", "%", "(", "self", ".", "monitor", ")", ",", "RuntimeWarning", ")", "\n", "", "else", ":", "\n", "                        ", "if", "self", ".", "monitor_op", "(", "current", ",", "self", ".", "best", ")", ":", "\n", "                            ", "if", "self", ".", "verbose", ">", "0", ":", "\n", "                                ", "print", "(", "'Epoch %05d: Iter%05d: %s improved from %0.5f to %0.5f,'", "\n", "' saving model to %s'", "\n", "%", "(", "epoch", ",", "iter", ",", "self", ".", "monitor", ",", "self", ".", "best", ",", "\n", "current", ",", "filepath", ")", ")", "\n", "", "self", ".", "best", "=", "current", "\n", "if", "self", ".", "save_weights_only", ":", "\n", "                                ", "self", ".", "model", ".", "layers", "[", "-", "(", "num_outputs", "+", "1", ")", "]", ".", "save_weights", "(", "filepath", ",", "overwrite", "=", "True", ")", "\n", "", "else", ":", "\n", "                                ", "self", ".", "model", ".", "layers", "[", "-", "(", "num_outputs", "+", "1", ")", "]", ".", "save", "(", "filepath", ",", "overwrite", "=", "True", ")", "\n", "", "", "else", ":", "\n", "                            ", "if", "self", ".", "verbose", ">", "0", ":", "\n", "                                ", "print", "(", "'Epoch %05d Iter%05d: %s did not improve'", "%", "\n", "(", "epoch", ",", "iter", ",", "self", ".", "monitor", ")", ")", "\n", "", "", "", "", "else", ":", "\n", "                    ", "if", "self", ".", "verbose", ">", "0", ":", "\n", "                        ", "print", "(", "'Epoch %05d: saving model to %s'", "%", "(", "epoch", ",", "filepath", ")", ")", "\n", "", "if", "self", ".", "save_weights_only", ":", "\n", "                        ", "self", ".", "model", ".", "layers", "[", "-", "(", "num_outputs", "+", "1", ")", "]", ".", "save_weights", "(", "filepath", ",", "overwrite", "=", "True", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "model", ".", "layers", "[", "-", "(", "num_outputs", "+", "1", ")", "]", ".", "save", "(", "filepath", ",", "overwrite", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks._generate_predictions": [[598, 616], ["range", "range", "ext.neuron.utils.predict_volumes", "ext.neuron.utils.next_label"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.predict_volumes", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.next_label"], ["", "", "", "", "", "", "def", "_generate_predictions", "(", "model", ",", "data_generator", ",", "batch_size", ",", "nb_samples", ",", "vol_params", ")", ":", "\n", "# whole volumes", "\n", "    ", "if", "vol_params", "is", "not", "None", ":", "\n", "        ", "for", "_", "in", "range", "(", "nb_samples", ")", ":", "# assumes nr volume", "\n", "            ", "vols", "=", "nrn_utils", ".", "predict_volumes", "(", "model", ",", "\n", "data_generator", ",", "\n", "batch_size", ",", "\n", "vol_params", "[", "\"patch_size\"", "]", ",", "\n", "vol_params", "[", "\"patch_stride\"", "]", ",", "\n", "vol_params", "[", "\"grid_size\"", "]", ")", "\n", "vol_true", ",", "vol_pred", "=", "vols", "[", "0", "]", ",", "vols", "[", "1", "]", "\n", "yield", "(", "vol_true", ",", "vol_pred", ")", "\n", "\n", "# just one batch", "\n", "", "", "else", ":", "\n", "        ", "for", "_", "in", "range", "(", "nb_samples", ")", ":", "# assumes nr batches", "\n", "            ", "vol_pred", ",", "vol_true", "=", "nrn_utils", ".", "next_label", "(", "model", ",", "data_generator", ")", "\n", "yield", "(", "vol_true", ",", "vol_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks._flatten": [[618, 625], ["isinstance", "isinstance", "callbacks._flatten"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.callbacks._flatten"], ["", "", "", "def", "_flatten", "(", "l", ")", ":", "\n", "# https://stackoverflow.com/questions/2158395/flatten-an-irregular-list-of-lists", "\n", "    ", "for", "el", "in", "l", ":", "\n", "        ", "if", "isinstance", "(", "el", ",", "collections", ".", "Iterable", ")", "and", "not", "isinstance", "(", "el", ",", "(", "str", ",", "bytes", ")", ")", ":", "\n", "            ", "yield", "from", "_flatten", "(", "el", ")", "\n", "", "else", ":", "\n", "            ", "yield", "el", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.inits.output_init": [[8, 19], ["numpy.random.random", "numpy.ones", "numpy.expand_dims", "numpy.concatenate", "keras.variable", "numpy.expand_dims"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims"], ["def", "output_init", "(", "shape", ",", "name", "=", "None", ",", "dim_ordering", "=", "None", ")", ":", "\n", "    ", "''' initialization for output weights'''", "\n", "size", "=", "(", "shape", "[", "0", "]", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", "-", "shape", "[", "3", "]", ",", "shape", "[", "3", "]", ")", "\n", "\n", "# initialize output weights with random and identity", "\n", "rpart", "=", "np", ".", "random", ".", "random", "(", "size", ")", "\n", "#     idpart_ = np.eye(size[3])", "\n", "idpart_", "=", "np", ".", "ones", "(", "(", "size", "[", "3", "]", ",", "size", "[", "3", "]", ")", ")", "\n", "idpart", "=", "np", ".", "expand_dims", "(", "np", ".", "expand_dims", "(", "idpart_", ",", "0", ")", ",", "0", ")", "\n", "value", "=", "np", ".", "concatenate", "(", "(", "rpart", ",", "idpart", ")", ",", "axis", "=", "2", ")", "\n", "return", "K", ".", "variable", "(", "value", ",", "name", "=", "name", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.interpn": [[39, 153], ["isinstance", "tensorflow.cast", "isinstance", "tensorflow.stack", "len", "Exception", "len", "Exception", "len", "keras.expand_dims", "K.expand_dims.shape.as_list", "tensorflow.floor", "list", "tensorflow.cast", "utils.sub2ind", "tensorflow.gather", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "itertools.product", "utils.sub2ind", "tensorflow.gather", "utils.prod_n", "keras.expand_dims", "tensorflow.round", "tensorflow.cast", "tensorflow.clip_by_value", "tensorflow.reshape", "K.expand_dims.get_shape().as_list", "range", "range", "range", "tensorflow.cast", "tensorflow.cast", "range", "tensorflow.reshape", "range", "len", "len", "range", "range", "K.expand_dims.get_shape"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.sub2ind", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.sub2ind", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.prod_n", "home.repos.pwc.inspect_result.BBillot_SynthSR.lab2im.edit_tensors.expand_dims", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["\n", "\n", "\n", "import", "os", "\n", "import", "glob", "\n", "import", "math", "\n", "import", "time", "\n", "import", "pickle", "\n", "import", "numpy", "as", "np", "\n", "import", "nibabel", "as", "nib", "\n", "import", "tensorflow", "as", "tf", "\n", "import", "keras", ".", "layers", "as", "KL", "\n", "import", "keras", ".", "backend", "as", "K", "\n", "from", "datetime", "import", "timedelta", "\n", "from", "scipy", ".", "ndimage", ".", "morphology", "import", "distance_transform_edt", "\n", "\n", "\n", "# ---------------------------------------------- loading/saving functions ----------------------------------------------", "\n", "\n", "\n", "def", "load_volume", "(", "path_volume", ",", "im_only", "=", "True", ",", "squeeze", "=", "True", ",", "dtype", "=", "None", ",", "aff_ref", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Load volume file.\n    :param path_volume: path of the volume to load. Can either be a nii, nii.gz, mgz, or npz format.\n    If npz format, 1) the variable name is assumed to be 'vol_data',\n    2) the volume is associated with a identity affine matrix and blank header.\n    :param im_only: (optional) if False, the function also returns the affine matrix and header of the volume.\n    :param squeeze: (optional) whether to squeeze the volume when loading.\n    :param dtype: (optional) if not None, convert the loaded volume to this numpy dtype.\n    :param aff_ref: (optional) If not None, the loaded volume is aligned to this affine matrix.\n    The returned affine matrix is also given in this new space. Must be a numpy array of dimension 4x4.\n    :return: the volume, with corresponding affine matrix and header if im_only is False.\n    \"\"\"", "\n", "assert", "path_volume", ".", "endswith", "(", "(", "'.nii'", ",", "'.nii.gz'", ",", "'.mgz'", ",", "'.npz'", ")", ")", ",", "'Unknown data file: %s'", "%", "path_volume", "\n", "\n", "if", "path_volume", ".", "endswith", "(", "(", "'.nii'", ",", "'.nii.gz'", ",", "'.mgz'", ")", ")", ":", "\n", "        ", "x", "=", "nib", ".", "load", "(", "path_volume", ")", "\n", "if", "squeeze", ":", "\n", "            ", "volume", "=", "np", ".", "squeeze", "(", "x", ".", "get_data", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "volume", "=", "x", ".", "get_data", "(", ")", "\n", "", "aff", "=", "x", ".", "affine", "\n", "header", "=", "x", ".", "header", "\n", "", "else", ":", "# npz", "\n", "        ", "volume", "=", "np", ".", "load", "(", "path_volume", ")", "[", "'vol_data'", "]", "\n", "if", "squeeze", ":", "\n", "            ", "volume", "=", "np", ".", "squeeze", "(", "volume", ")", "\n", "", "aff", "=", "np", ".", "eye", "(", "4", ")", "\n", "header", "=", "nib", ".", "Nifti1Header", "(", ")", "\n", "", "if", "dtype", "is", "not", "None", ":", "\n", "        ", "volume", "=", "volume", ".", "astype", "(", "dtype", "=", "dtype", ")", "\n", "\n", "# align image to reference affine matrix", "\n", "", "if", "aff_ref", "is", "not", "None", ":", "\n", "        ", "from", ".", "import", "edit_volumes", "# the import is done here to avoid import loops", "\n", "n_dims", ",", "_", "=", "get_dims", "(", "list", "(", "volume", ".", "shape", ")", ",", "max_channels", "=", "10", ")", "\n", "volume", ",", "aff", "=", "edit_volumes", ".", "align_volume_to_ref", "(", "volume", ",", "aff", ",", "aff_ref", "=", "aff_ref", ",", "return_aff", "=", "True", ",", "n_dims", "=", "n_dims", ")", "\n", "\n", "", "if", "im_only", ":", "\n", "        ", "return", "volume", "\n", "", "else", ":", "\n", "        ", "return", "volume", ",", "aff", ",", "header", "\n", "\n", "\n", "", "", "def", "save_volume", "(", "volume", ",", "aff", ",", "header", ",", "path", ",", "res", "=", "None", ",", "dtype", "=", "None", ",", "n_dims", "=", "3", ")", ":", "\n", "    ", "\"\"\"\n    Save a volume.\n    :param volume: volume to save\n    :param aff: affine matrix of the volume to save. If aff is None, the volume is saved with an identity affine matrix.\n    aff can also be set to 'FS', in which case the volume is saved with the affine matrix of FreeSurfer outputs.\n    :param header: header of the volume to save. If None, the volume is saved with a blank header.\n    :param path: path where to save the volume.\n    :param res: (optional) update the resolution in the header before saving the volume.\n    :param dtype: (optional) numpy dtype for the saved volume.\n    :param n_dims: (optional) number of dimensions, to avoid confusion in multi-channel case. Default is None, where\n    n_dims is automatically inferred.\n    \"\"\"", "\n", "\n", "mkdir", "(", "os", ".", "path", ".", "dirname", "(", "path", ")", ")", "\n", "if", "'.npz'", "in", "path", ":", "\n", "        ", "np", ".", "savez_compressed", "(", "path", ",", "vol_data", "=", "volume", ")", "\n", "", "else", ":", "\n", "        ", "if", "header", "is", "None", ":", "\n", "            ", "header", "=", "nib", ".", "Nifti1Header", "(", ")", "\n", "", "if", "isinstance", "(", "aff", ",", "str", ")", ":", "\n", "            ", "if", "aff", "==", "'FS'", ":", "\n", "                ", "aff", "=", "np", ".", "array", "(", "[", "[", "-", "1", ",", "0", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "1", ",", "0", "]", ",", "[", "0", ",", "-", "1", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "", "", "elif", "aff", "is", "None", ":", "\n", "            ", "aff", "=", "np", ".", "eye", "(", "4", ")", "\n", "", "nifty", "=", "nib", ".", "Nifti1Image", "(", "volume", ",", "aff", ",", "header", ")", "\n", "if", "dtype", "is", "not", "None", ":", "\n", "            ", "nifty", ".", "set_data_dtype", "(", "dtype", ")", "\n", "", "if", "res", "is", "not", "None", ":", "\n", "            ", "if", "n_dims", "is", "None", ":", "\n", "                ", "n_dims", ",", "_", "=", "get_dims", "(", "volume", ".", "shape", ")", "\n", "", "res", "=", "reformat_to_list", "(", "res", ",", "length", "=", "n_dims", ",", "dtype", "=", "None", ")", "\n", "nifty", ".", "header", ".", "set_zooms", "(", "res", ")", "\n", "", "nib", ".", "save", "(", "nifty", ",", "path", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.resize": [[155, 183], ["isinstance", "utils.volshape_to_ndgrid", "tensorflow.stack", "utils.transform", "len", "len", "tensorflow.cast", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.volshape_to_ndgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.transform", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["\n", "", "", "def", "get_volume_info", "(", "path_volume", ",", "return_volume", "=", "False", ",", "aff_ref", "=", "None", ",", "max_channels", "=", "10", ")", ":", "\n", "    ", "\"\"\"\n    Gather information about a volume: shape, affine matrix, number of dimensions and channels, header, and resolution.\n    :param path_volume: path of the volume to get information form.\n    :param return_volume: (optional) whether to return the volume along with the information.\n    :param aff_ref: (optional) If not None, the loaded volume is aligned to this affine matrix.\n    All info relative to the volume is then given in this new space. Must be a numpy array of dimension 4x4.\n    :return: volume (if return_volume is true), and corresponding info. If aff_ref is not None, the returned aff is\n    the original one, i.e. the affine of the image before being aligned to aff_ref.\n    \"\"\"", "\n", "# read image", "\n", "im", ",", "aff", ",", "header", "=", "load_volume", "(", "path_volume", ",", "im_only", "=", "False", ")", "\n", "\n", "# understand if image is multichannel", "\n", "im_shape", "=", "list", "(", "im", ".", "shape", ")", "\n", "n_dims", ",", "n_channels", "=", "get_dims", "(", "im_shape", ",", "max_channels", "=", "max_channels", ")", "\n", "im_shape", "=", "im_shape", "[", ":", "n_dims", "]", "\n", "\n", "# get labels res", "\n", "if", "'.nii'", "in", "path_volume", ":", "\n", "        ", "data_res", "=", "np", ".", "array", "(", "header", "[", "'pixdim'", "]", "[", "1", ":", "n_dims", "+", "1", "]", ")", "\n", "", "elif", "'.mgz'", "in", "path_volume", ":", "\n", "        ", "data_res", "=", "np", ".", "array", "(", "header", "[", "'delta'", "]", ")", "# mgz image", "\n", "", "else", ":", "\n", "        ", "data_res", "=", "np", ".", "array", "(", "[", "1.0", "]", "*", "n_dims", ")", "\n", "\n", "# align to given affine matrix", "\n", "", "if", "aff_ref", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.affine_to_shift": [[188, 248], ["isinstance", "len", "utils.volshape_to_meshgrid", "flat_mesh.append", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.reshape", "volshape.as_list.as_list", "tensorflow.cast", "len", "tensorflow.reshape", "Exception", "tensorflow.cast", "utils.flatten", "tensorflow.ones", "tensorflow.stack", "tensorflow.stack", "len", "ValueError", "list", "str", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.volshape_to_meshgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.flatten", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["im_shape", "=", "np", ".", "array", "(", "im_shape", ")", "\n", "data_res", "=", "np", ".", "array", "(", "data_res", ")", "\n", "im_shape", "[", "ras_axes_ref", "]", "=", "im_shape", "[", "ras_axes", "]", "\n", "data_res", "[", "ras_axes_ref", "]", "=", "data_res", "[", "ras_axes", "]", "\n", "im_shape", "=", "im_shape", ".", "tolist", "(", ")", "\n", "\n", "# return info", "\n", "", "if", "return_volume", ":", "\n", "        ", "return", "im", ",", "im_shape", ",", "aff", ",", "n_dims", ",", "n_channels", ",", "header", ",", "data_res", "\n", "", "else", ":", "\n", "        ", "return", "im_shape", ",", "aff", ",", "n_dims", ",", "n_channels", ",", "header", ",", "data_res", "\n", "\n", "\n", "", "", "def", "get_list_labels", "(", "label_list", "=", "None", ",", "labels_dir", "=", "None", ",", "save_label_list", "=", "None", ",", "FS_sort", "=", "False", ")", ":", "\n", "    ", "\"\"\"This function reads or computes a list of all label values used in a set of label maps.\n    It can also sort all labels according to FreeSurfer lut.\n    :param label_list: (optional) already computed label_list. Can be a sequence, a 1d numpy array, or the path to\n    a numpy 1d array.\n    :param labels_dir: (optional) if path_label_list is None, the label list is computed by reading all the label maps\n    in the given folder. Can also be the path to a single label map.\n    :param save_label_list: (optional) path where to save the label list.\n    :param FS_sort: (optional) whether to sort label values according to the FreeSurfer classification.\n    If true, the label values will be ordered as follows: neutral labels first (i.e. non-sided), left-side labels,\n    and right-side labels. If FS_sort is True, this function also returns the number of neutral labels in label_list.\n    :return: the label list (numpy 1d array), and the number of neutral (i.e. non-sided) labels if FS_sort is True.\n    If one side of the brain is not represented at all in label_list, all labels are considered as neutral, and\n    n_neutral_labels = len(label_list).\n    \"\"\"", "\n", "\n", "# load label list if previously computed", "\n", "if", "label_list", "is", "not", "None", ":", "\n", "        ", "label_list", "=", "np", ".", "array", "(", "reformat_to_list", "(", "label_list", ",", "load_as_numpy", "=", "True", ",", "dtype", "=", "'int'", ")", ")", "\n", "\n", "# compute label list from all label files", "\n", "", "elif", "labels_dir", "is", "not", "None", ":", "\n", "        ", "print", "(", "'Compiling list of unique labels'", ")", "\n", "# go through all labels files and compute unique list of labels", "\n", "labels_paths", "=", "list_images_in_folder", "(", "labels_dir", ")", "\n", "label_list", "=", "np", ".", "empty", "(", "0", ")", "\n", "loop_info", "=", "LoopInfo", "(", "len", "(", "labels_paths", ")", ",", "10", ",", "'processing'", ",", "print_time", "=", "True", ")", "\n", "for", "lab_idx", ",", "path", "in", "enumerate", "(", "labels_paths", ")", ":", "\n", "            ", "loop_info", ".", "update", "(", "lab_idx", ")", "\n", "y", "=", "load_volume", "(", "path", ",", "dtype", "=", "'int32'", ")", "\n", "y_unique", "=", "np", ".", "unique", "(", "y", ")", "\n", "label_list", "=", "np", ".", "unique", "(", "np", ".", "concatenate", "(", "(", "label_list", ",", "y_unique", ")", ")", ")", ".", "astype", "(", "'int'", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'either label_list, path_label_list or labels_dir should be provided'", ")", "\n", "\n", "# sort labels in neutral/left/right according to FS labels", "\n", "", "n_neutral_labels", "=", "0", "\n", "if", "FS_sort", ":", "\n", "        ", "neutral_FS_labels", "=", "[", "0", ",", "14", ",", "15", ",", "16", ",", "21", ",", "22", ",", "23", ",", "24", ",", "72", ",", "77", ",", "80", ",", "85", ",", "100", ",", "101", ",", "102", ",", "103", ",", "104", ",", "105", ",", "106", ",", "107", ",", "108", ",", "\n", "109", ",", "165", ",", "200", ",", "201", ",", "202", ",", "203", ",", "204", ",", "205", ",", "206", ",", "207", ",", "208", ",", "209", ",", "210", ",", "\n", "251", ",", "252", ",", "253", ",", "254", ",", "255", ",", "258", ",", "259", ",", "260", ",", "331", ",", "332", ",", "333", ",", "334", ",", "335", ",", "336", ",", "337", ",", "338", ",", "339", ",", "340", ",", "\n", "502", ",", "506", ",", "507", ",", "508", ",", "509", ",", "511", ",", "512", ",", "514", ",", "515", ",", "516", ",", "517", ",", "530", ",", "\n", "531", ",", "532", ",", "533", ",", "534", ",", "535", ",", "536", ",", "537", "]", "\n", "neutral", "=", "list", "(", ")", "\n", "left", "=", "list", "(", ")", "\n", "right", "=", "list", "(", ")", "\n", "for", "la", "in", "label_list", ":", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.combine_non_linear_and_aff_to_shift": [[250, 314], ["isinstance", "range", "len", "utils.volshape_to_meshgrid", "tensorflow.unstack", "flat_mesh.append", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.reshape", "volshape.as_list.as_list", "len", "len", "tensorflow.reshape", "Exception", "tensorflow.cast", "utils.flatten", "tensorflow.ones", "tensorflow.stack", "tensorflow.stack", "tensorflow.cast", "len", "ValueError", "range", "list", "str", "range", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.volshape_to_meshgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.flatten", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["                ", "if", "la", "not", "in", "neutral", ":", "\n", "                    ", "neutral", ".", "append", "(", "la", ")", "\n", "", "", "elif", "(", "0", "<", "la", "<", "14", ")", "|", "(", "16", "<", "la", "<", "21", ")", "|", "(", "24", "<", "la", "<", "40", ")", "|", "(", "135", "<", "la", "<", "138", ")", "|", "(", "20100", "<", "la", "<", "20110", ")", ":", "\n", "                ", "if", "la", "not", "in", "left", ":", "\n", "                    ", "left", ".", "append", "(", "la", ")", "\n", "", "", "elif", "(", "39", "<", "la", "<", "72", ")", "|", "(", "162", "<", "la", "<", "165", ")", "|", "(", "20000", "<", "la", "<", "20010", ")", ":", "\n", "                ", "if", "la", "not", "in", "right", ":", "\n", "                    ", "right", ".", "append", "(", "la", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'label {} not in our current FS classification, '", "\n", "'please update get_list_labels in utils.py'", ".", "format", "(", "la", ")", ")", "\n", "", "", "label_list", "=", "np", ".", "concatenate", "(", "[", "sorted", "(", "neutral", ")", ",", "sorted", "(", "left", ")", ",", "sorted", "(", "right", ")", "]", ")", "\n", "if", "(", "(", "len", "(", "left", ")", ">", "0", ")", "&", "(", "len", "(", "right", ")", ">", "0", ")", ")", "|", "(", "(", "len", "(", "left", ")", "==", "0", ")", "&", "(", "len", "(", "right", ")", "==", "0", ")", ")", ":", "\n", "            ", "n_neutral_labels", "=", "len", "(", "neutral", ")", "\n", "", "else", ":", "\n", "            ", "n_neutral_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# save labels if specified", "\n", "", "", "if", "save_label_list", "is", "not", "None", ":", "\n", "        ", "np", ".", "save", "(", "save_label_list", ",", "np", ".", "int32", "(", "label_list", ")", ")", "\n", "\n", "", "if", "FS_sort", ":", "\n", "        ", "return", "np", ".", "int32", "(", "label_list", ")", ",", "n_neutral_labels", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "int32", "(", "label_list", ")", ",", "None", "\n", "\n", "\n", "", "", "def", "load_array_if_path", "(", "var", ",", "load_as_numpy", "=", "True", ")", ":", "\n", "    ", "\"\"\"If var is a string and load_as_numpy is True, this function loads the array writen at the path indicated by var.\n    Otherwise it simply returns var as it is.\"\"\"", "\n", "if", "(", "isinstance", "(", "var", ",", "str", ")", ")", "&", "load_as_numpy", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "var", ")", ",", "'No such path: %s'", "%", "var", "\n", "var", "=", "np", ".", "load", "(", "var", ")", "\n", "", "return", "var", "\n", "\n", "\n", "", "def", "write_pickle", "(", "filepath", ",", "obj", ")", ":", "\n", "    ", "\"\"\" write a python object with a pickle at a given path\"\"\"", "\n", "with", "open", "(", "filepath", ",", "'wb'", ")", "as", "file", ":", "\n", "        ", "pickler", "=", "pickle", ".", "Pickler", "(", "file", ")", "\n", "pickler", ".", "dump", "(", "obj", ")", "\n", "\n", "\n", "", "", "def", "read_pickle", "(", "filepath", ")", ":", "\n", "    ", "\"\"\" read a python object with a pickle\"\"\"", "\n", "with", "open", "(", "filepath", ",", "'rb'", ")", "as", "file", ":", "\n", "        ", "unpickler", "=", "pickle", ".", "Unpickler", "(", "file", ")", "\n", "return", "unpickler", ".", "load", "(", ")", "\n", "\n", "\n", "", "", "def", "write_model_summary", "(", "model", ",", "filepath", "=", "'./model_summary.txt'", ",", "line_length", "=", "150", ")", ":", "\n", "    ", "\"\"\"Write the summary of a keras model at a given path, with a given length for each line\"\"\"", "\n", "with", "open", "(", "filepath", ",", "'w'", ")", "as", "fh", ":", "\n", "        ", "model", ".", "summary", "(", "print_fn", "=", "lambda", "x", ":", "fh", ".", "write", "(", "x", "+", "'\\n'", ")", ",", "line_length", "=", "line_length", ")", "\n", "\n", "\n", "# ----------------------------------------------- reformatting functions -----------------------------------------------", "\n", "\n", "\n", "", "", "def", "reformat_to_list", "(", "var", ",", "length", "=", "None", ",", "load_as_numpy", "=", "False", ",", "dtype", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.transform": [[316, 351], ["isinstance", "len", "utils.volshape_to_meshgrid", "utils.interpn", "loc_shift.shape[].as_list", "tensorflow.cast", "range"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.volshape_to_meshgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.interpn", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["\n", "\n", "# convert to list", "\n", "if", "var", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "var", "=", "load_array_if_path", "(", "var", ",", "load_as_numpy", "=", "load_as_numpy", ")", "\n", "if", "isinstance", "(", "var", ",", "(", "int", ",", "float", ",", "np", ".", "int", ",", "np", ".", "int32", ",", "np", ".", "int64", ",", "np", ".", "float", ",", "np", ".", "float32", ",", "np", ".", "float64", ")", ")", ":", "\n", "        ", "var", "=", "[", "var", "]", "\n", "", "elif", "isinstance", "(", "var", ",", "tuple", ")", ":", "\n", "        ", "var", "=", "list", "(", "var", ")", "\n", "", "elif", "isinstance", "(", "var", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "var", ".", "shape", "==", "(", "1", ",", ")", ":", "\n", "            ", "var", "=", "[", "var", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "            ", "var", "=", "np", ".", "squeeze", "(", "var", ")", ".", "tolist", "(", ")", "\n", "", "", "elif", "isinstance", "(", "var", ",", "str", ")", ":", "\n", "        ", "var", "=", "[", "var", "]", "\n", "", "elif", "isinstance", "(", "var", ",", "bool", ")", ":", "\n", "        ", "var", "=", "[", "var", "]", "\n", "", "if", "isinstance", "(", "var", ",", "list", ")", ":", "\n", "        ", "if", "length", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "var", ")", "==", "1", ":", "\n", "                ", "var", "=", "var", "*", "length", "\n", "", "elif", "len", "(", "var", ")", "!=", "length", ":", "\n", "                ", "raise", "ValueError", "(", "'if var is a list/tuple/numpy array, it should be of length 1 or {0}, '", "\n", "'had {1}'", ".", "format", "(", "length", ",", "var", ")", ")", "\n", "", "", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'var should be an int, float, tuple, list, numpy array, or path to numpy array'", ")", "\n", "\n", "# convert items type", "\n", "", "if", "dtype", "is", "not", "None", ":", "\n", "        ", "if", "dtype", "==", "'int'", ":", "\n", "            ", "var", "=", "[", "int", "(", "v", ")", "for", "v", "in", "var", "]", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.integrate_vec": [[353, 464], ["ValueError", "keras.permute_dimensions", "range", "range", "tensorflow.cast", "keras.concatenate", "odeint_fn", "keras.permute_dimensions", "utils.transform", "range", "range", "utils.transform", "keras.flatten", "tf.cast.get_shape().as_list", "ValueError", "kwargs.keys", "tensorflow.map_fn", "utils.transform", "utils.transform", "kwargs.keys", "kwargs.keys", "kwargs.keys", "range", "tf.cast.get_shape", "range", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.transform", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.transform", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.flatten", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.transform", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.transform", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["            ", "var", "=", "[", "float", "(", "v", ")", "for", "v", "in", "var", "]", "\n", "", "elif", "dtype", "==", "'bool'", ":", "\n", "            ", "var", "=", "[", "bool", "(", "v", ")", "for", "v", "in", "var", "]", "\n", "", "elif", "dtype", "==", "'str'", ":", "\n", "            ", "var", "=", "[", "str", "(", "v", ")", "for", "v", "in", "var", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"dtype should be 'str', 'float', 'int', or 'bool'; had {}\"", ".", "format", "(", "dtype", ")", ")", "\n", "", "", "return", "var", "\n", "\n", "\n", "", "def", "reformat_to_n_channels_array", "(", "var", ",", "n_dims", "=", "3", ",", "n_channels", "=", "1", ")", ":", "\n", "    ", "\"\"\"This function takes an int, float, list or tuple and reformat it to an array of shape (n_channels, n_dims).\n    If resolution is a str, it will be assumed to be the path of a numpy array.\n    If resolution is a numpy array, it will be checked to have shape (n_channels, n_dims).\n    Finally if resolution is None, this function returns None as well.\"\"\"", "\n", "if", "var", "is", "None", ":", "\n", "        ", "return", "[", "None", "]", "*", "n_channels", "\n", "", "if", "isinstance", "(", "var", ",", "str", ")", ":", "\n", "        ", "var", "=", "np", ".", "load", "(", "var", ")", "\n", "# convert to numpy array", "\n", "", "if", "isinstance", "(", "var", ",", "(", "int", ",", "float", ",", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "var", "=", "reformat_to_list", "(", "var", ",", "n_dims", ")", "\n", "var", "=", "np", ".", "tile", "(", "np", ".", "array", "(", "var", ")", ",", "(", "n_channels", ",", "1", ")", ")", "\n", "# check shape if numpy array", "\n", "", "elif", "isinstance", "(", "var", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "n_channels", "==", "1", ":", "\n", "            ", "var", "=", "var", ".", "reshape", "(", "(", "1", ",", "n_dims", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "np", ".", "squeeze", "(", "var", ")", ".", "shape", "==", "(", "n_dims", ",", ")", ":", "\n", "                ", "var", "=", "np", ".", "tile", "(", "var", ".", "reshape", "(", "(", "1", ",", "n_dims", ")", ")", ",", "(", "n_channels", ",", "1", ")", ")", "\n", "", "elif", "var", ".", "shape", "!=", "(", "n_channels", ",", "n_dims", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'if array, var should be {0} or {1}'", ".", "format", "(", "(", "1", ",", "n_dims", ")", ",", "(", "n_channels", ",", "n_dims", ")", ")", ")", "\n", "", "", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'var should be int, float, list, tuple or ndarray'", ")", "\n", "", "return", "np", ".", "round", "(", "var", ",", "3", ")", "\n", "\n", "\n", "# ----------------------------------------------- path-related functions -----------------------------------------------", "\n", "\n", "\n", "", "def", "list_images_in_folder", "(", "path_dir", ",", "include_single_image", "=", "True", ")", ":", "\n", "    ", "\"\"\"List all files with extension nii, nii.gz, mgz, or npz whithin a folder.\"\"\"", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "path_dir", ")", "\n", "if", "include_single_image", "&", "(", "(", "'.nii.gz'", "in", "basename", ")", "|", "(", "'.nii'", "in", "basename", ")", "|", "(", "'.mgz'", "in", "basename", ")", "|", "(", "'.npz'", "in", "basename", ")", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "path_dir", ")", ",", "'file %s does not exist'", "%", "path_dir", "\n", "list_images", "=", "[", "path_dir", "]", "\n", "", "else", ":", "\n", "        ", "if", "os", ".", "path", ".", "isdir", "(", "path_dir", ")", ":", "\n", "            ", "list_images", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "'*nii.gz'", ")", ")", "+", "\n", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "'*nii'", ")", ")", "+", "\n", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "'*.mgz'", ")", ")", "+", "\n", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "'*.npz'", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'extension not supported for %s, only use: nii.gz, .nii, .mgz, or .npz'", "%", "path_dir", ")", "\n", "", "assert", "len", "(", "list_images", ")", ">", "0", ",", "'no .nii, .nii.gz, .mgz or .npz image could be found in %s'", "%", "path_dir", "\n", "", "return", "list_images", "\n", "\n", "\n", "", "def", "list_files", "(", "path_dir", ",", "whole_path", "=", "True", ",", "expr", "=", "None", ",", "cond_type", "=", "'or'", ")", ":", "\n", "    ", "\"\"\"This function returns a list of files contained in a folder, whith possible regexp.\n    :param path_dir: path of a folder\n    :param whole_path: (optional) whether to return whole path or just the filenames.\n    :param expr: (optional) regexp for files to list. Can be a str or a list of str.\n    :param cond_type: (optional) if exp is a list, specify the logical link between expressions in exp.\n    Can be 'or', or 'and'.\n    :return: a list of files\n    \"\"\"", "\n", "assert", "isinstance", "(", "whole_path", ",", "bool", ")", ",", "\"whole_path should be bool\"", "\n", "assert", "cond_type", "in", "[", "'or'", ",", "'and'", "]", ",", "\"cond_type should be either 'or', or 'and'\"", "\n", "if", "whole_path", ":", "\n", "        ", "files_list", "=", "sorted", "(", "[", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", "for", "f", "in", "os", ".", "listdir", "(", "path_dir", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "files_list", "=", "sorted", "(", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "path_dir", ")", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", ")", "]", ")", "\n", "", "if", "expr", "is", "not", "None", ":", "# assumed to be either str or list of str", "\n", "        ", "if", "isinstance", "(", "expr", ",", "str", ")", ":", "\n", "            ", "expr", "=", "[", "expr", "]", "\n", "", "elif", "not", "isinstance", "(", "expr", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "raise", "Exception", "(", "\"if specified, 'expr' should be a string or list of strings.\"", ")", "\n", "", "matched_list_files", "=", "list", "(", ")", "\n", "for", "match", "in", "expr", ":", "\n", "            ", "tmp_matched_files_list", "=", "sorted", "(", "[", "f", "for", "f", "in", "files_list", "if", "match", "in", "os", ".", "path", ".", "basename", "(", "f", ")", "]", ")", "\n", "if", "cond_type", "==", "'or'", ":", "\n", "                ", "files_list", "=", "[", "f", "for", "f", "in", "files_list", "if", "f", "not", "in", "tmp_matched_files_list", "]", "\n", "matched_list_files", "+=", "tmp_matched_files_list", "\n", "", "elif", "cond_type", "==", "'and'", ":", "\n", "                ", "files_list", "=", "tmp_matched_files_list", "\n", "matched_list_files", "=", "tmp_matched_files_list", "\n", "", "", "files_list", "=", "sorted", "(", "matched_list_files", ")", "\n", "", "return", "files_list", "\n", "\n", "\n", "", "def", "list_subfolders", "(", "path_dir", ",", "whole_path", "=", "True", ",", "expr", "=", "None", ",", "cond_type", "=", "'or'", ")", ":", "\n", "    ", "\"\"\"This function returns a list of subfolders contained in a folder, with possible regexp.\n    :param path_dir: path of a folder\n    :param whole_path: (optional) whether to return whole path or just the subfolder names.\n    :param expr: (optional) regexp for files to list. Can be a str or a list of str.\n    :param cond_type: (optional) if exp is a list, specify the logical link between expressions in exp.\n    Can be 'or', or 'and'.\n    :return: a list of subfolders\n    \"\"\"", "\n", "assert", "isinstance", "(", "whole_path", ",", "bool", ")", ",", "\"whole_path should be bool\"", "\n", "assert", "cond_type", "in", "[", "'or'", ",", "'and'", "]", ",", "\"cond_type should be either 'or', or 'and'\"", "\n", "if", "whole_path", ":", "\n", "        ", "subdirs_list", "=", "sorted", "(", "[", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", "for", "f", "in", "os", ".", "listdir", "(", "path_dir", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "subdirs_list", "=", "sorted", "(", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "path_dir", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "path_dir", ",", "f", ")", ")", "]", ")", "\n", "", "if", "expr", "is", "not", "None", ":", "# assumed to be either str or list of str", "\n", "        ", "if", "isinstance", "(", "expr", ",", "str", ")", ":", "\n", "            ", "expr", "=", "[", "expr", "]", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.volshape_to_ndgrid": [[466, 487], ["utils.ndgrid", "float().is_integer", "all", "ValueError", "tensorflow.range", "float"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.ndgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["            ", "raise", "Exception", "(", "\"if specified, 'expr' should be a string or list of strings.\"", ")", "\n", "", "matched_list_subdirs", "=", "list", "(", ")", "\n", "for", "match", "in", "expr", ":", "\n", "            ", "tmp_matched_list_subdirs", "=", "sorted", "(", "[", "f", "for", "f", "in", "subdirs_list", "if", "match", "in", "os", ".", "path", ".", "basename", "(", "f", ")", "]", ")", "\n", "if", "cond_type", "==", "'or'", ":", "\n", "                ", "subdirs_list", "=", "[", "f", "for", "f", "in", "subdirs_list", "if", "f", "not", "in", "tmp_matched_list_subdirs", "]", "\n", "matched_list_subdirs", "+=", "tmp_matched_list_subdirs", "\n", "", "elif", "cond_type", "==", "'and'", ":", "\n", "                ", "subdirs_list", "=", "tmp_matched_list_subdirs", "\n", "matched_list_subdirs", "=", "tmp_matched_list_subdirs", "\n", "", "", "subdirs_list", "=", "sorted", "(", "matched_list_subdirs", ")", "\n", "", "return", "subdirs_list", "\n", "\n", "\n", "", "def", "get_image_extension", "(", "path", ")", ":", "\n", "    ", "name", "=", "os", ".", "path", ".", "basename", "(", "path", ")", "\n", "if", "name", "[", "-", "7", ":", "]", "==", "'.nii.gz'", ":", "\n", "        ", "return", "'nii.gz'", "\n", "", "elif", "name", "[", "-", "4", ":", "]", "==", "'.mgz'", ":", "\n", "        ", "return", "'mgz'", "\n", "", "elif", "name", "[", "-", "4", ":", "]", "==", "'.nii'", ":", "\n", "        ", "return", "'nii'", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.volshape_to_meshgrid": [[489, 510], ["utils.meshgrid", "float().is_integer", "all", "ValueError", "tensorflow.range", "float"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.meshgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["        ", "return", "'npz'", "\n", "\n", "\n", "", "", "def", "strip_extension", "(", "path", ")", ":", "\n", "    ", "\"\"\"Strip classical image extensions (.nii.gz, .nii, .mgz, .npz) from a filename.\"\"\"", "\n", "path", "=", "path", ".", "replace", "(", "'.nii.gz'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.nii'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.mgz'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.npz'", ",", "''", ")", "\n", "return", "path", "\n", "\n", "\n", "", "def", "strip_suffix", "(", "path", ")", ":", "\n", "    ", "\"\"\"Strip classical image suffix from a filename.\"\"\"", "\n", "path", "=", "path", ".", "replace", "(", "'_aseg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'aseg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.aseg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_aseg_1'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_aseg_2'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'aseg_1_'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'aseg_2_'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_orig'", ",", "''", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.ndgrid": [[512, 526], ["utils.meshgrid"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.meshgrid"], ["path", "=", "path", ".", "replace", "(", "'.orig'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_norm'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'norm'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.norm'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_talairach'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'GSP_FS_4p5'", ",", "'GSP'", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.nii_crispSegmentation'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_crispSegmentation'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_seg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.seg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'seg'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_seg_1'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'_seg_2'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'seg_1_'", ",", "''", ")", "\n", "path", "=", "path", ".", "replace", "(", "'seg_2_'", ",", "''", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.meshgrid": [[528, 607], ["kwargs.pop", "kwargs.pop", "len", "enumerate", "range", "TypeError", "ValueError", "output.append", "tensorflow.size", "tensorflow.reshape", "tensorflow.reshape", "len", "tensorflow.tile", "list", "tensorflow.reshape", "x.get_shape().as_list", "tensorflow.stack", "kwargs.keys", "tensorflow.stack", "x.get_shape"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack"], ["\n", "\n", "", "def", "mkdir", "(", "path_dir", ")", ":", "\n", "    ", "\"\"\"Recursively creates the current dir as well as its parent folders if they do not already exist.\"\"\"", "\n", "if", "path_dir", "[", "-", "1", "]", "==", "'/'", ":", "\n", "        ", "path_dir", "=", "path_dir", "[", ":", "-", "1", "]", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "path_dir", ")", ":", "\n", "        ", "list_dir_to_create", "=", "[", "path_dir", "]", "\n", "while", "not", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "dirname", "(", "list_dir_to_create", "[", "-", "1", "]", ")", ")", ":", "\n", "            ", "list_dir_to_create", ".", "append", "(", "os", ".", "path", ".", "dirname", "(", "list_dir_to_create", "[", "-", "1", "]", ")", ")", "\n", "", "for", "dir_to_create", "in", "reversed", "(", "list_dir_to_create", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "dir_to_create", ")", "\n", "\n", "\n", "", "", "", "def", "mkcmd", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"Creates terminal command with provided inputs.\n    Example: mkcmd('mv', 'source', 'dest') will give 'mv source dest'.\"\"\"", "\n", "return", "' '", ".", "join", "(", "[", "str", "(", "arg", ")", "for", "arg", "in", "args", "]", ")", "\n", "\n", "\n", "# ---------------------------------------------- shape-related functions -----------------------------------------------", "\n", "\n", "\n", "", "def", "get_dims", "(", "shape", ",", "max_channels", "=", "10", ")", ":", "\n", "    ", "\"\"\"Get the number of dimensions and channels from the shape of an array.\n    The number of dimensions is assumed to be the length of the shape, as long as the shape of the last dimension is\n    inferior or equal to max_channels (default 3).\n    :param shape: shape of an array. Can be a sequence or a 1d numpy array.\n    :param max_channels: maximum possible number of channels.\n    :return: the number of dimensions and channels associated with the provided shape.\n    example 1: get_dims([150, 150, 150], max_channels=10) = (3, 1)\n    example 2: get_dims([150, 150, 150, 3], max_channels=10) = (3, 3)\n    example 3: get_dims([150, 150, 150, 15], max_channels=10) = (4, 1), because 5>3\"\"\"", "\n", "if", "shape", "[", "-", "1", "]", "<=", "max_channels", ":", "\n", "        ", "n_dims", "=", "len", "(", "shape", ")", "-", "1", "\n", "n_channels", "=", "shape", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "n_dims", "=", "len", "(", "shape", ")", "\n", "n_channels", "=", "1", "\n", "", "return", "n_dims", ",", "n_channels", "\n", "\n", "\n", "", "def", "get_resample_shape", "(", "patch_shape", ",", "factor", ",", "n_channels", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute the shape of a resampled array given a shape factor.\n    :param patch_shape: size of the initial array (without number of channels).\n    :param factor: resampling factor. Can be a number, sequence, or 1d numpy array.\n    :param n_channels: (optional) if not None, add a number of channel at the end of the computed shape.\n    :return: list containing the shape of the input array after being resampled by the given factor.\n    \"\"\"", "\n", "factor", "=", "reformat_to_list", "(", "factor", ",", "length", "=", "len", "(", "patch_shape", ")", ")", "\n", "shape", "=", "[", "math", ".", "ceil", "(", "patch_shape", "[", "i", "]", "*", "factor", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "patch_shape", ")", ")", "]", "\n", "if", "n_channels", "is", "not", "None", ":", "\n", "        ", "shape", "+=", "[", "n_channels", "]", "\n", "", "return", "shape", "\n", "\n", "\n", "", "def", "add_axis", "(", "x", ",", "axis", "=", "0", ")", ":", "\n", "    ", "\"\"\"Add axis to a numpy array.\n    :param axis: index of the new axis to add. Can also be a list of indices to add several axes at the same time.\"\"\"", "\n", "axis", "=", "reformat_to_list", "(", "axis", ")", "\n", "for", "ax", "in", "axis", ":", "\n", "        ", "x", "=", "np", ".", "expand_dims", "(", "x", ",", "axis", "=", "ax", ")", "\n", "", "return", "x", "\n", "\n", "\n", "", "def", "get_padding_margin", "(", "cropping", ",", "loss_cropping", ")", ":", "\n", "    ", "\"\"\"Compute padding margin\"\"\"", "\n", "if", "(", "cropping", "is", "not", "None", ")", "&", "(", "loss_cropping", "is", "not", "None", ")", ":", "\n", "        ", "cropping", "=", "reformat_to_list", "(", "cropping", ")", "\n", "loss_cropping", "=", "reformat_to_list", "(", "loss_cropping", ")", "\n", "n_dims", "=", "max", "(", "len", "(", "cropping", ")", ",", "len", "(", "loss_cropping", ")", ")", "\n", "cropping", "=", "reformat_to_list", "(", "cropping", ",", "length", "=", "n_dims", ")", "\n", "loss_cropping", "=", "reformat_to_list", "(", "loss_cropping", ",", "length", "=", "n_dims", ")", "\n", "padding_margin", "=", "[", "int", "(", "(", "cropping", "[", "i", "]", "-", "loss_cropping", "[", "i", "]", ")", "/", "2", ")", "for", "i", "in", "range", "(", "n_dims", ")", "]", "\n", "if", "len", "(", "padding_margin", ")", "==", "1", ":", "\n", "            ", "padding_margin", "=", "padding_margin", "[", "0", "]", "\n", "", "", "else", ":", "\n", "        ", "padding_margin", "=", "None", "\n", "", "return", "padding_margin", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.flatten": [[609, 621], ["tensorflow.reshape"], "function", ["None"], ["# -------------------------------------------- build affine matrices/tensors -------------------------------------------", "\n", "\n", "\n", "", "def", "create_affine_transformation_matrix", "(", "n_dims", ",", "scaling", "=", "None", ",", "rotation", "=", "None", ",", "shearing", "=", "None", ",", "translation", "=", "None", ")", ":", "\n", "    ", "\"\"\"Create a 4x4 affine transformation matrix from specified values\n    :param n_dims: integer\n    :param scaling: list of 3 scaling values\n    :param rotation: list of 3 angles (degrees) for rotations around 1st, 2nd, 3rd axis\n    :param shearing: list of 6 shearing values\n    :param translation: list of 3 values\n    :return: 4x4 numpy matrix\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.prod_n": [[623, 628], ["None"], "function", ["None"], ["T_shearing", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "T_translation", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "\n", "if", "scaling", "is", "not", "None", ":", "\n", "        ", "T_scaling", "[", "np", ".", "arange", "(", "n_dims", "+", "1", ")", ",", "np", ".", "arange", "(", "n_dims", "+", "1", ")", "]", "=", "np", ".", "append", "(", "scaling", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.sub2ind": [[630, 644], ["numpy.cumprod", "enumerate", "len", "len", "len", "len"], "function", ["None"], ["        ", "shearing_index", "=", "np", ".", "ones", "(", "(", "n_dims", "+", "1", ",", "n_dims", "+", "1", ")", ",", "dtype", "=", "'bool'", ")", "\n", "shearing_index", "[", "np", ".", "eye", "(", "n_dims", "+", "1", ",", "dtype", "=", "'bool'", ")", "]", "=", "False", "\n", "shearing_index", "[", "-", "1", ",", ":", "]", "=", "np", ".", "zeros", "(", "(", "n_dims", "+", "1", ")", ")", "\n", "shearing_index", "[", ":", ",", "-", "1", "]", "=", "np", ".", "zeros", "(", "(", "n_dims", "+", "1", ")", ")", "\n", "T_shearing", "[", "shearing_index", "]", "=", "shearing", "\n", "\n", "", "if", "translation", "is", "not", "None", ":", "\n", "        ", "T_translation", "[", "np", ".", "arange", "(", "n_dims", ")", ",", "n_dims", "*", "np", ".", "ones", "(", "n_dims", ",", "dtype", "=", "'int'", ")", "]", "=", "translation", "\n", "\n", "", "if", "n_dims", "==", "2", ":", "\n", "        ", "if", "rotation", "is", "None", ":", "\n", "            ", "rotation", "=", "np", ".", "zeros", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "rotation", "=", "np", ".", "asarray", "(", "rotation", ")", "*", "(", "math", ".", "pi", "/", "180", ")", "\n", "", "T_rot", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.gaussian_kernel": [[646, 697], ["len", "utils.volshape_to_meshgrid", "tensorflow.stack", "keras.sum", "tensorflow.exp", "tensorflow.reduce_sum", "isinstance", "numpy.maximum", "len", "len", "ValueError", "tensorflow.cast", "range", "range", "numpy.log", "range", "numpy.finfo", "str", "len", "keras.square", "numpy.round", "numpy.sqrt", "str"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.volshape_to_meshgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["np", ".", "sin", "(", "rotation", "[", "0", "]", ")", "*", "-", "1", ",", "np", ".", "cos", "(", "rotation", "[", "0", "]", ")", "]", "\n", "return", "T_translation", "@", "T_rot", "@", "T_shearing", "@", "T_scaling", "\n", "\n", "", "else", ":", "\n", "\n", "        ", "if", "rotation", "is", "None", ":", "\n", "            ", "rotation", "=", "np", ".", "zeros", "(", "n_dims", ")", "\n", "", "else", ":", "\n", "            ", "rotation", "=", "np", ".", "asarray", "(", "rotation", ")", "*", "(", "math", ".", "pi", "/", "180", ")", "\n", "", "T_rot1", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "T_rot1", "[", "np", ".", "array", "(", "[", "1", ",", "2", ",", "1", ",", "2", "]", ")", ",", "np", ".", "array", "(", "[", "1", ",", "1", ",", "2", ",", "2", "]", ")", "]", "=", "[", "np", ".", "cos", "(", "rotation", "[", "0", "]", ")", ",", "np", ".", "sin", "(", "rotation", "[", "0", "]", ")", ",", "\n", "np", ".", "sin", "(", "rotation", "[", "0", "]", ")", "*", "-", "1", ",", "np", ".", "cos", "(", "rotation", "[", "0", "]", ")", "]", "\n", "T_rot2", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "T_rot2", "[", "np", ".", "array", "(", "[", "0", ",", "2", ",", "0", ",", "2", "]", ")", ",", "np", ".", "array", "(", "[", "0", ",", "0", ",", "2", ",", "2", "]", ")", "]", "=", "[", "np", ".", "cos", "(", "rotation", "[", "1", "]", ")", ",", "np", ".", "sin", "(", "rotation", "[", "1", "]", ")", "*", "-", "1", ",", "\n", "np", ".", "sin", "(", "rotation", "[", "1", "]", ")", ",", "np", ".", "cos", "(", "rotation", "[", "1", "]", ")", "]", "\n", "T_rot3", "=", "np", ".", "eye", "(", "n_dims", "+", "1", ")", "\n", "T_rot3", "[", "np", ".", "array", "(", "[", "0", ",", "1", ",", "0", ",", "1", "]", ")", ",", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "1", "]", ")", "]", "=", "[", "np", ".", "cos", "(", "rotation", "[", "2", "]", ")", ",", "np", ".", "sin", "(", "rotation", "[", "2", "]", ")", ",", "\n", "np", ".", "sin", "(", "rotation", "[", "2", "]", ")", "*", "-", "1", ",", "np", ".", "cos", "(", "rotation", "[", "2", "]", ")", "]", "\n", "return", "T_translation", "@", "T_rot3", "@", "T_rot2", "@", "T_rot1", "@", "T_shearing", "@", "T_scaling", "\n", "\n", "\n", "", "", "def", "sample_affine_transform", "(", "batchsize", ",", "\n", "n_dims", ",", "\n", "rotation_bounds", "=", "False", ",", "\n", "scaling_bounds", "=", "False", ",", "\n", "shearing_bounds", "=", "False", ",", "\n", "translation_bounds", "=", "False", ",", "\n", "enable_90_rotations", "=", "False", ")", ":", "\n", "    ", "\"\"\"build batchsizex4x4 tensor representing an affine transormation in homogeneous coordinates.\n    If return_inv is True, also returns the inverse of the created affine matrix.\"\"\"", "\n", "\n", "if", "(", "rotation_bounds", "is", "not", "False", ")", "|", "(", "enable_90_rotations", "is", "not", "False", ")", ":", "\n", "        ", "if", "n_dims", "==", "2", ":", "\n", "            ", "if", "rotation_bounds", "is", "not", "False", ":", "\n", "                ", "rotation", "=", "draw_value_from_distribution", "(", "rotation_bounds", ",", "\n", "size", "=", "1", ",", "\n", "default_range", "=", "15.0", ",", "\n", "return_as_tensor", "=", "True", ",", "\n", "batchsize", "=", "batchsize", ")", "\n", "", "else", ":", "\n", "                ", "rotation", "=", "tf", ".", "zeros", "(", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "1", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "", "", "else", ":", "# n_dims = 3", "\n", "            ", "if", "rotation_bounds", "is", "not", "False", ":", "\n", "                ", "rotation", "=", "draw_value_from_distribution", "(", "rotation_bounds", ",", "\n", "size", "=", "n_dims", ",", "\n", "default_range", "=", "15.0", ",", "\n", "return_as_tensor", "=", "True", ",", "\n", "batchsize", "=", "batchsize", ")", "\n", "", "else", ":", "\n", "                ", "rotation", "=", "tf", ".", "zeros", "(", "tf", ".", "concat", "(", "[", "batchsize", ",", "3", "*", "tf", ".", "ones", "(", "1", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "", "", "if", "enable_90_rotations", ":", "\n", "            ", "rotation", "=", "tf", ".", "cast", "(", "tf", ".", "random", ".", "uniform", "(", "tf", ".", "shape", "(", "rotation", ")", ",", "maxval", "=", "4", ",", "dtype", "=", "'int32'", ")", "*", "90", ",", "'float32'", ")"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.stack_models": [[699, 746], ["range", "keras.models.Model", "keras.models.Model", "len", "list", "list", "enumerate", "utils.mod_submodel", "list", "stacked_inputs.append", "range", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.mod_submodel", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "T_rot", "=", "create_rotation_transform", "(", "rotation", ",", "n_dims", ")", "\n", "", "else", ":", "\n", "        ", "T_rot", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "eye", "(", "n_dims", ")", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "2", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "if", "shearing_bounds", "is", "not", "False", ":", "\n", "        ", "shearing", "=", "draw_value_from_distribution", "(", "shearing_bounds", ",", "\n", "size", "=", "n_dims", "**", "2", "-", "n_dims", ",", "\n", "default_range", "=", ".01", ",", "\n", "return_as_tensor", "=", "True", ",", "\n", "batchsize", "=", "batchsize", ")", "\n", "T_shearing", "=", "create_shearing_transform", "(", "shearing", ",", "n_dims", ")", "\n", "", "else", ":", "\n", "        ", "T_shearing", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "eye", "(", "n_dims", ")", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "2", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "if", "scaling_bounds", "is", "not", "False", ":", "\n", "        ", "scaling", "=", "draw_value_from_distribution", "(", "scaling_bounds", ",", "\n", "size", "=", "n_dims", ",", "\n", "centre", "=", "1", ",", "\n", "default_range", "=", ".15", ",", "\n", "return_as_tensor", "=", "True", ",", "\n", "batchsize", "=", "batchsize", ")", "\n", "T_scaling", "=", "tf", ".", "linalg", ".", "diag", "(", "scaling", ")", "\n", "", "else", ":", "\n", "        ", "T_scaling", "=", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "eye", "(", "n_dims", ")", ",", "axis", "=", "0", ")", ",", "\n", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "2", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "T", "=", "tf", ".", "matmul", "(", "T_scaling", ",", "tf", ".", "matmul", "(", "T_shearing", ",", "T_rot", ")", ")", "\n", "\n", "if", "translation_bounds", "is", "not", "False", ":", "\n", "        ", "translation", "=", "draw_value_from_distribution", "(", "translation_bounds", ",", "\n", "size", "=", "n_dims", ",", "\n", "default_range", "=", "5", ",", "\n", "return_as_tensor", "=", "True", ",", "\n", "batchsize", "=", "batchsize", ")", "\n", "T", "=", "tf", ".", "concat", "(", "[", "T", ",", "tf", ".", "expand_dims", "(", "translation", ",", "axis", "=", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "T", "=", "tf", ".", "concat", "(", "[", "T", ",", "tf", ".", "zeros", "(", "tf", ".", "concat", "(", "[", "tf", ".", "shape", "(", "T", ")", "[", ":", "2", "]", ",", "tf", ".", "ones", "(", "1", ",", "dtype", "=", "'int32'", ")", "]", ",", "0", ")", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# build rigid transform", "\n", "", "T_last_row", "=", "tf", ".", "expand_dims", "(", "tf", ".", "concat", "(", "[", "tf", ".", "zeros", "(", "(", "1", ",", "n_dims", ")", ")", ",", "tf", ".", "ones", "(", "(", "1", ",", "1", ")", ")", "]", ",", "axis", "=", "1", ")", ",", "0", ")", "\n", "T_last_row", "=", "tf", ".", "tile", "(", "T_last_row", ",", "tf", ".", "concat", "(", "[", "batchsize", ",", "tf", ".", "ones", "(", "2", ",", "dtype", "=", "'int32'", ")", "]", ",", "axis", "=", "0", ")", ")", "\n", "T", "=", "tf", ".", "concat", "(", "[", "T", ",", "T_last_row", "]", ",", "axis", "=", "1", ")", "\n", "\n", "return", "T", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.mod_submodel": [[748, 891], ["utils.mod_submodel._layer_dependency_dict"], "function", ["None"], ["    ", "\"\"\"build rotation transform from 3d or 2d rotation coefficients. Angles are given in degrees.\"\"\"", "\n", "rotation", "=", "rotation", "*", "np", ".", "pi", "/", "180", "\n", "if", "n_dims", "==", "3", ":", "\n", "        ", "shape", "=", "tf", ".", "shape", "(", "tf", ".", "expand_dims", "(", "rotation", "[", "...", ",", "0", "]", ",", "-", "1", ")", ")", "\n", "\n", "Rx_row0", "=", "tf", ".", "expand_dims", "(", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "convert_to_tensor", "(", "[", "1.", ",", "0.", ",", "0.", "]", ")", ",", "0", ")", ",", "shape", ")", ",", "axis", "=", "1", ")", "\n", "Rx_row1", "=", "tf", ".", "stack", "(", "[", "tf", ".", "zeros", "(", "shape", ")", ",", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "-", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Rx_row2", "=", "tf", ".", "stack", "(", "[", "tf", ".", "zeros", "(", "shape", ")", ",", "tf", ".", "expand_dims", "(", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Rx", "=", "tf", ".", "concat", "(", "[", "Rx_row0", ",", "Rx_row1", ",", "Rx_row2", "]", ",", "axis", "=", "1", ")", "\n", "\n", "Ry_row0", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "1", "]", ")", ",", "-", "1", ")", ",", "tf", ".", "zeros", "(", "shape", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "1", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Ry_row1", "=", "tf", ".", "expand_dims", "(", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "convert_to_tensor", "(", "[", "0.", ",", "1.", ",", "0.", "]", ")", ",", "0", ")", ",", "shape", ")", ",", "axis", "=", "1", ")", "\n", "Ry_row2", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "-", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "1", "]", ")", ",", "-", "1", ")", ",", "tf", ".", "zeros", "(", "shape", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "1", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Ry", "=", "tf", ".", "concat", "(", "[", "Ry_row0", ",", "Ry_row1", ",", "Ry_row2", "]", ",", "axis", "=", "1", ")", "\n", "\n", "Rz_row0", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "2", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "-", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "2", "]", ")", ",", "-", "1", ")", ",", "tf", ".", "zeros", "(", "shape", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Rz_row1", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "2", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "2", "]", ")", ",", "-", "1", ")", ",", "tf", ".", "zeros", "(", "shape", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "Rz_row2", "=", "tf", ".", "expand_dims", "(", "tf", ".", "tile", "(", "tf", ".", "expand_dims", "(", "tf", ".", "convert_to_tensor", "(", "[", "0.", ",", "0.", ",", "1.", "]", ")", ",", "0", ")", ",", "shape", ")", ",", "axis", "=", "1", ")", "\n", "Rz", "=", "tf", ".", "concat", "(", "[", "Rz_row0", ",", "Rz_row1", ",", "Rz_row2", "]", ",", "axis", "=", "1", ")", "\n", "\n", "T_rot", "=", "tf", ".", "matmul", "(", "tf", ".", "matmul", "(", "Rx", ",", "Ry", ")", ",", "Rz", ")", "\n", "\n", "", "elif", "n_dims", "==", "2", ":", "\n", "        ", "R_row0", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "R_row1", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "-", "tf", ".", "sin", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "tf", ".", "cos", "(", "rotation", "[", "...", ",", "0", "]", ")", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "T_rot", "=", "tf", ".", "concat", "(", "[", "R_row0", ",", "R_row1", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'only supports 2 or 3D.'", ")", "\n", "\n", "", "return", "T_rot", "\n", "\n", "\n", "", "def", "create_shearing_transform", "(", "shearing", ",", "n_dims", ")", ":", "\n", "    ", "\"\"\"build shearing transform from 2d/3d shearing coefficients\"\"\"", "\n", "shape", "=", "tf", ".", "shape", "(", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "0", "]", ",", "-", "1", ")", ")", "\n", "if", "n_dims", "==", "3", ":", "\n", "        ", "shearing_row0", "=", "tf", ".", "stack", "(", "[", "tf", ".", "ones", "(", "shape", ")", ",", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "0", "]", ",", "-", "1", ")", ",", "\n", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "1", "]", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "shearing_row1", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "2", "]", ",", "-", "1", ")", ",", "tf", ".", "ones", "(", "shape", ")", ",", "\n", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "3", "]", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "shearing_row2", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "4", "]", ",", "-", "1", ")", ",", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "5", "]", ",", "-", "1", ")", ",", "\n", "tf", ".", "ones", "(", "shape", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "T_shearing", "=", "tf", ".", "concat", "(", "[", "shearing_row0", ",", "shearing_row1", ",", "shearing_row2", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "elif", "n_dims", "==", "2", ":", "\n", "        ", "shearing_row0", "=", "tf", ".", "stack", "(", "[", "tf", ".", "ones", "(", "shape", ")", ",", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "0", "]", ",", "-", "1", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "shearing_row1", "=", "tf", ".", "stack", "(", "[", "tf", ".", "expand_dims", "(", "shearing", "[", "...", ",", "1", "]", ",", "-", "1", ")", ",", "tf", ".", "ones", "(", "shape", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "T_shearing", "=", "tf", ".", "concat", "(", "[", "shearing_row0", ",", "shearing_row1", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'only supports 2 or 3D.'", ")", "\n", "", "return", "T_shearing", "\n", "\n", "\n", "# --------------------------------------------------- miscellaneous ----------------------------------------------------", "\n", "\n", "\n", "", "def", "infer", "(", "x", ")", ":", "\n", "    ", "''' Try to parse input to float. If it fails, tries boolean, and otherwise keep it as string '''", "\n", "try", ":", "\n", "        ", "x", "=", "float", "(", "x", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "if", "x", "==", "'False'", ":", "\n", "            ", "x", "=", "False", "\n", "", "elif", "x", "==", "'True'", ":", "\n", "            ", "x", "=", "True", "\n", "", "elif", "not", "isinstance", "(", "x", ",", "str", ")", ":", "\n", "            ", "raise", "TypeError", "(", "'input should be an int/float/boolean/str, had {}'", ".", "format", "(", "type", "(", "x", ")", ")", ")", "\n", "", "", "return", "x", "\n", "\n", "\n", "", "class", "LoopInfo", ":", "\n", "    ", "\"\"\"\n    Class to print the current iteration in a for loop, and optionally the estimated remaining time.\n    Instantiate just before the loop, and call the update method at the start of the loop.\n    The printed text has the following format:\n    processing i/total    remaining time: hh:mm:ss\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "n_iterations", ",", "spacing", "=", "10", ",", "text", "=", "'processing'", ",", "print_time", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param n_iterations: total number of iterations of the for loop.\n        :param spacing: frequency at which the update info will be printed on screen.\n        :param text: text to print. Default is processing.\n        :param print_time: whether to print the estimated remaining time. Default is False.\n        \"\"\"", "\n", "\n", "# loop parameters", "\n", "self", ".", "n_iterations", "=", "n_iterations", "\n", "self", ".", "spacing", "=", "spacing", "\n", "\n", "# text parameters", "\n", "self", ".", "text", "=", "text", "\n", "self", ".", "print_time", "=", "print_time", "\n", "self", ".", "print_previous_time", "=", "False", "\n", "self", ".", "align", "=", "len", "(", "str", "(", "self", ".", "n_iterations", ")", ")", "*", "2", "+", "1", "+", "3", "\n", "\n", "# timing parameters", "\n", "self", ".", "iteration_durations", "=", "np", ".", "zeros", "(", "(", "n_iterations", ",", ")", ")", "\n", "self", ".", "start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "previous", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "def", "update", "(", "self", ",", "idx", ")", ":", "\n", "\n", "# time iteration", "\n", "        ", "now", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "iteration_durations", "[", "idx", "]", "=", "now", "-", "self", ".", "previous", "\n", "self", ".", "previous", "=", "now", "\n", "\n", "# print text", "\n", "if", "idx", "==", "0", ":", "\n", "            ", "print", "(", "self", ".", "text", "+", "' 1/{}'", ".", "format", "(", "self", ".", "n_iterations", ")", ")", "\n", "", "elif", "idx", "%", "self", ".", "spacing", "==", "self", ".", "spacing", "-", "1", ":", "\n", "            ", "iteration", "=", "str", "(", "idx", "+", "1", ")", "+", "'/'", "+", "str", "(", "self", ".", "n_iterations", ")", "\n", "if", "self", ".", "print_time", ":", "\n", "# estimate remaining time", "\n", "                ", "max_duration", "=", "np", ".", "max", "(", "self", ".", "iteration_durations", ")", "\n", "average_duration", "=", "np", ".", "mean", "(", "self", ".", "iteration_durations", "[", "self", ".", "iteration_durations", ">", ".01", "*", "max_duration", "]", ")", "\n", "remaining_time", "=", "int", "(", "average_duration", "*", "(", "self", ".", "n_iterations", "-", "idx", ")", ")", "\n", "# print total remaining time only if it is greater than 1s or if it was previously printed", "\n", "if", "(", "remaining_time", ">", "1", ")", "|", "self", ".", "print_previous_time", ":", "\n", "                    ", "eta", "=", "str", "(", "timedelta", "(", "seconds", "=", "remaining_time", ")", ")", "\n", "print", "(", "self", ".", "text", "+", "' {:<{x}} remaining time: {}'", ".", "format", "(", "iteration", ",", "eta", ",", "x", "=", "self", ".", "align", ")", ")", "\n", "self", ".", "print_previous_time", "=", "True", "\n", "", "else", ":", "\n", "                    ", "print", "(", "self", ".", "text", "+", "' {}'", ".", "format", "(", "iteration", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "print", "(", "self", ".", "text", "+", "' {}'", ".", "format", "(", "iteration", ")", ")", "\n", "\n", "\n", "", "", "", "", "def", "get_mapping_lut", "(", "source", ",", "dest", "=", "None", ")", ":", "\n", "    ", "\"\"\"This functions returns the look-up table to map a list of N values (source) to another list (dest).\n    If the second list is not given, we assume it is equal to [0, ..., N-1].\"\"\"", "\n", "\n", "# initialise", "\n", "source", "=", "np", ".", "array", "(", "reformat_to_list", "(", "source", ")", ",", "dtype", "=", "'int32'", ")", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.reset_weights": [[893, 922], ["keras.get_session", "hasattr", "hasattr", "layer.kernel.initializer.run", "layer.bias.initializer.run", "print"], "function", ["None"], ["\n", "# build new label list if neccessary", "\n", "if", "dest", "is", "None", ":", "\n", "        ", "dest", "=", "np", ".", "arange", "(", "n_labels", ",", "dtype", "=", "'int32'", ")", "\n", "", "else", ":", "\n", "        ", "assert", "len", "(", "source", ")", "==", "len", "(", "dest", ")", ",", "'label_list and new_label_list should have the same length'", "\n", "dest", "=", "np", ".", "array", "(", "reformat_to_list", "(", "dest", ",", "dtype", "=", "'int'", ")", ")", "\n", "\n", "# build look-up table", "\n", "", "lut", "=", "np", ".", "zeros", "(", "np", ".", "max", "(", "source", ")", "+", "1", ",", "dtype", "=", "'int32'", ")", "\n", "for", "source", ",", "dest", "in", "zip", "(", "source", ",", "dest", ")", ":", "\n", "        ", "lut", "[", "source", "]", "=", "dest", "\n", "\n", "", "return", "lut", "\n", "\n", "\n", "", "def", "build_training_generator", "(", "gen", ",", "batchsize", ")", ":", "\n", "    ", "\"\"\"Build generator for training a network.\"\"\"", "\n", "while", "True", ":", "\n", "        ", "inputs", "=", "next", "(", "gen", ")", "\n", "if", "batchsize", ">", "1", ":", "\n", "            ", "target", "=", "np", ".", "concatenate", "(", "[", "np", ".", "zeros", "(", "(", "1", ",", "1", ")", ")", "]", "*", "batchsize", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "target", "=", "np", ".", "zeros", "(", "(", "1", ",", "1", ")", ")", "\n", "", "yield", "inputs", ",", "target", "\n", "\n", "\n", "", "", "def", "find_closest_number_divisible_by_m", "(", "n", ",", "m", ",", "answer_type", "=", "'lower'", ")", ":", "\n", "    ", "\"\"\"Return the closest integer to n that is divisible by m. answer_type can either be 'closer', 'lower' (only returns\n    values lower than n), or 'higher (only returns values higher than m).\"\"\"", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.copy_model_weights": [[924, 940], ["tqdm.tqdm_notebook", "src_model.get_layer().get_weights", "layer.set_weights", "print", "src_model.get_layer"], "function", ["None"], ["        ", "return", "n", "\n", "", "else", ":", "\n", "        ", "q", "=", "int", "(", "n", "/", "m", ")", "\n", "lower", "=", "q", "*", "m", "\n", "higher", "=", "(", "q", "+", "1", ")", "*", "m", "\n", "if", "answer_type", "==", "'lower'", ":", "\n", "            ", "return", "lower", "\n", "", "elif", "answer_type", "==", "'higher'", ":", "\n", "            ", "return", "higher", "\n", "", "elif", "answer_type", "==", "'closer'", ":", "\n", "            ", "return", "lower", "if", "(", "n", "-", "lower", ")", "<", "(", "higher", "-", "n", ")", "else", "higher", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'answer_type should be lower, higher, or closer, had : %s'", "%", "answer_type", ")", "\n", "\n", "\n", "", "", "", "def", "build_binary_structure", "(", "connectivity", ",", "n_dims", ",", "shape", "=", "None", ")", ":", "\n", "    ", "\"\"\"Return a dilation/erosion element with provided connectivity\"\"\"", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.robust_multi_gpu_model": [[942, 966], ["isinstance", "print", "keras.utils.multi_gpu_model", "keras.utils.multi_gpu_model", "print", "len", "len"], "function", ["None"], ["        ", "shape", "=", "[", "connectivity", "*", "2", "+", "1", "]", "*", "n_dims", "\n", "", "else", ":", "\n", "        ", "shape", "=", "reformat_to_list", "(", "shape", ",", "length", "=", "n_dims", ")", "\n", "", "dist", "=", "np", ".", "ones", "(", "shape", ")", "\n", "center", "=", "tuple", "(", "[", "tuple", "(", "[", "int", "(", "s", "/", "2", ")", "]", ")", "for", "s", "in", "shape", "]", ")", "\n", "dist", "[", "center", "]", "=", "0", "\n", "dist", "=", "distance_transform_edt", "(", "dist", ")", "\n", "struct", "=", "(", "dist", "<=", "connectivity", ")", "*", "1", "\n", "return", "struct", "\n", "\n", "\n", "", "def", "draw_value_from_distribution", "(", "hyperparameter", ",", "\n", "size", "=", "1", ",", "\n", "distribution", "=", "'uniform'", ",", "\n", "centre", "=", "0.", ",", "\n", "default_range", "=", "10.0", ",", "\n", "positive_only", "=", "False", ",", "\n", "return_as_tensor", "=", "False", ",", "\n", "batchsize", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.logtanh": [[968, 975], ["keras.tanh", "keras.log", "abs"], "function", ["None"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.arcsinh": [[977, 984], ["tensorflow.asinh"], "function", ["None"], ["\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.predict_volumes": [[986, 1081], ["enumerate", "isinstance", "ext.pytools.timer.Timer", "utils.predict_volume_stack", "len", "utils.pred_to_label", "_quilt().astype", "_quilt().astype", "len", "len", "len", "utils._quilt", "utils.prob_of_label", "utils._quilt", "len", "utils._quilt", "utils._quilt", "utils.pred_to_label", "_quilt().astype", "utils.prob_of_label", "utils._quilt", "utils._quilt"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.predict_volume_stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.pred_to_label", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils._quilt", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.prob_of_label", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils._quilt", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils._quilt", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils._quilt", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.pred_to_label", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.prob_of_label", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils._quilt", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils._quilt"], ["if", "hyperparameter", "is", "False", ":", "\n", "        ", "return", "None", "\n", "\n", "# reformat parameter_range", "\n", "", "hyperparameter", "=", "load_array_if_path", "(", "hyperparameter", ",", "load_as_numpy", "=", "True", ")", "\n", "if", "not", "isinstance", "(", "hyperparameter", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "if", "hyperparameter", "is", "None", ":", "\n", "            ", "hyperparameter", "=", "np", ".", "array", "(", "[", "[", "centre", "-", "default_range", "]", "*", "size", ",", "[", "centre", "+", "default_range", "]", "*", "size", "]", ")", "\n", "", "elif", "isinstance", "(", "hyperparameter", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "            ", "hyperparameter", "=", "np", ".", "array", "(", "[", "[", "centre", "-", "hyperparameter", "]", "*", "size", ",", "[", "centre", "+", "hyperparameter", "]", "*", "size", "]", ")", "\n", "", "elif", "isinstance", "(", "hyperparameter", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "assert", "len", "(", "hyperparameter", ")", "==", "2", ",", "'if list, parameter_range should be of length 2.'", "\n", "hyperparameter", "=", "np", ".", "transpose", "(", "np", ".", "tile", "(", "np", ".", "array", "(", "hyperparameter", ")", ",", "(", "size", ",", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'parameter_range should either be None, a nummber, a sequence, or a numpy array.'", ")", "\n", "", "", "elif", "isinstance", "(", "hyperparameter", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "assert", "hyperparameter", ".", "shape", "[", "0", "]", "%", "2", "==", "0", ",", "'number of rows of parameter_range should be divisible by 2'", "\n", "n_modalities", "=", "int", "(", "hyperparameter", ".", "shape", "[", "0", "]", "/", "2", ")", "\n", "modality_idx", "=", "2", "*", "np", ".", "random", ".", "randint", "(", "n_modalities", ")", "\n", "hyperparameter", "=", "hyperparameter", "[", "modality_idx", ":", "modality_idx", "+", "2", ",", ":", "]", "\n", "\n", "# draw values as tensor", "\n", "", "if", "return_as_tensor", ":", "\n", "        ", "shape", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "convert_to_tensor", "(", "hyperparameter", ".", "shape", "[", "1", "]", ",", "'int32'", ")", ")", "(", "[", "]", ")", "\n", "if", "batchsize", "is", "not", "None", ":", "\n", "            ", "shape", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "concat", "(", "[", "x", "[", "0", "]", ",", "tf", ".", "expand_dims", "(", "x", "[", "1", "]", ",", "axis", "=", "0", ")", "]", ",", "axis", "=", "0", ")", ")", "(", "[", "batchsize", ",", "shape", "]", ")", "\n", "", "if", "distribution", "==", "'uniform'", ":", "\n", "            ", "parameter_value", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "x", ",", "\n", "minval", "=", "hyperparameter", "[", "0", ",", ":", "]", ",", "\n", "maxval", "=", "hyperparameter", "[", "1", ",", ":", "]", ")", ")", "(", "shape", ")", "\n", "", "elif", "distribution", "==", "'normal'", ":", "\n", "            ", "parameter_value", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "tf", ".", "random", ".", "normal", "(", "shape", "=", "x", ",", "\n", "mean", "=", "hyperparameter", "[", "0", ",", ":", "]", ",", "\n", "stddev", "=", "hyperparameter", "[", "1", ",", ":", "]", ")", ")", "(", "shape", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Distribution not supported, should be 'uniform' or 'normal'.\"", ")", "\n", "\n", "", "if", "positive_only", ":", "\n", "            ", "parameter_value", "=", "KL", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "clip", "(", "x", ",", "0", ",", "None", ")", ")", "(", "parameter_value", ")", "\n", "\n", "# draw values as numpy array", "\n", "", "", "else", ":", "\n", "        ", "if", "distribution", "==", "'uniform'", ":", "\n", "            ", "parameter_value", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "hyperparameter", "[", "0", ",", ":", "]", ",", "high", "=", "hyperparameter", "[", "1", ",", ":", "]", ")", "\n", "", "elif", "distribution", "==", "'normal'", ":", "\n", "            ", "parameter_value", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "hyperparameter", "[", "0", ",", ":", "]", ",", "scale", "=", "hyperparameter", "[", "1", ",", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Distribution not supported, should be 'uniform' or 'normal'.\"", ")", "\n", "\n", "", "if", "positive_only", ":", "\n", "            ", "parameter_value", "[", "parameter_value", "<", "0", "]", "=", "0", "\n", "\n", "", "", "return", "parameter_value", "\n", "\n", "\n", "", "def", "build_exp", "(", "x", ",", "first", ",", "last", ",", "fix_point", ")", ":", "\n", "# first = f(0), last = f(+inf), fix_point = [x0, f(x0))]", "\n", "    ", "a", "=", "last", "\n", "b", "=", "first", "-", "last", "\n", "c", "=", "-", "(", "1", "/", "fix_point", "[", "0", "]", ")", "*", "np", ".", "log", "(", "(", "fix_point", "[", "1", "]", "-", "last", ")", "/", "(", "first", "-", "last", ")", ")", "\n", "return", "a", "+", "b", "*", "np", ".", "exp", "(", "-", "c", "*", "x", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.predict_volume_stack": [[1083, 1172], ["numpy.prod", "enumerate", "enumerate", "isinstance", "tqdm.tqdm_notebook", "range", "next", "numpy.prod", "isinstance", "enumerate", "numpy.reshape", "numpy.reshape", "len", "range", "model.predict", "numpy.minimum", "numpy.arange", "numpy.reshape", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "keras.batch_flatten", "keras.batch_flatten", "keras._batch_flatten", "keras.batch_flatten"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.arange"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.prob_of_label": [[1174, 1204], ["numpy.ndim", "numpy.prod", "numpy.reshape", "np.reshape.sum", "list", "numpy.reshape", "numpy.ndim", "range", "numpy.ndim"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.next_pred_label": [[1206, 1217], ["next", "utils.pred_to_label", "ext.pytools.timer.Timer", "model.predict", "isinstance"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.pred_to_label"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.next_label": [[1219, 1226], ["utils.next_pred_label"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.next_pred_label"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.sample_to_label": [[1228, 1237], ["model.predict", "utils.pred_to_label"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.pred_to_label"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.pred_to_label": [[1239, 1245], ["tuple", "numpy.argmax().astype", "numpy.argmax"], "function", ["None"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.next_vol_pred": [[1247, 1263], ["next", "isinstance", "ext.pytools.timer.Timer", "model.predict"], "function", ["None"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.batch_gather": [[1269, 1301], ["tensorflow.stack", "tensorflow.gather_nd", "keras.shape", "tensorflow.range"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.model_diagram": [[1303, 1307], ["plot_model", "Image", "NamedTemporaryFile"], "function", ["None"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils._concat": [[1313, 1318], ["numpy.concatenate"], "function", ["None"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils._quilt": [[1320, 1332], ["numpy.reshape", "ext.pytools.patchlib.quilt", "len", "pprint.pformat", "len"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.quilt"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.softmax": [[1335, 1341], ["numpy.exp", "numpy.sum", "numpy.exp"], "function", ["None"], []], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__init__": [[21, 24], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", "=", "None", ",", "verbose", "=", "True", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__enter__": [[25, 27], ["time.time"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "tstart", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.timer.Timer.__exit__": [[28, 33], ["print", "print", "time.time"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "type", ",", "value", ",", "traceback", ")", ":", "\n", "        ", "if", "self", ".", "verbose", ":", "\n", "            ", "if", "self", ".", "name", ":", "\n", "                ", "print", "(", "'[%s]'", "%", "self", ".", "name", ",", "end", "=", "\"\"", ")", "\n", "", "print", "(", "'Elapsed: %6.4s'", "%", "(", "time", ".", "time", "(", ")", "-", "self", ".", "tstart", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.Struct.__str__": [[93, 95], ["iniparse.Struct.__dict__.__str__"], "methods", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.Struct.__str__"], ["def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", ".", "__str__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.ini_to_struct": [[18, 84], ["configparser.ConfigParser", "configparser.ConfigParser.read", "iniparse.Struct", "configparser.ConfigParser.sections", "len", "iniparse.Struct", "setattr", "iniparse.str_convert_single", "setattr", "iniparse.str_to_list", "len", "all", "iniparse.str_convert_single", "iniparse.str_convert_single"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_convert_single", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_to_list", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_convert_single", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_convert_single"], ["def", "ini_to_struct", "(", "file", ")", ":", "\n", "    ", "\"\"\"\n    very simple ini parser that expands on configparser\n    tries to cast values from string whereever possible\n    parsed data ini can be accessed with\n\n    data = ini_to_struct(file)\n    value = data.section.key\n\n    does not support hierarchical sections\n\n    Parameters:\n        file: string full filename of the ini file.\n\n    Returns:\n        stuct: a Struct that allows ini data to be access in the manner of data.section.key\n    \"\"\"", "\n", "\n", "# read the file via config.", "\n", "conf", "=", "configparser", ".", "ConfigParser", "(", ")", "\n", "confout", "=", "conf", ".", "read", "(", "file", ")", "\n", "assert", "len", "(", "confout", ")", ">", "0", ",", "'Cannot read file %s '", "%", "file", "\n", "\n", "# prepare the Struct", "\n", "strct", "=", "Struct", "(", ")", "\n", "\n", "# go through the sections in the ini file", "\n", "for", "sec", "in", "conf", ".", "sections", "(", ")", ":", "\n", "\n", "# each section is its own struct", "\n", "        ", "secstrct", "=", "Struct", "(", ")", "\n", "\n", "# go through the keys", "\n", "for", "key", "in", "conf", "[", "sec", "]", ":", "\n", "            ", "val", "=", "conf", "[", "sec", "]", "[", "key", "]", "\n", "\n", "# try to cast the data", "\n", "ret", ",", "done", "=", "str_convert_single", "(", "val", ")", "\n", "\n", "# if couldn't cast, try a comma/whitespace separated list", "\n", "if", "not", "done", ":", "\n", "                ", "lst", "=", "str_to_list", "(", "val", ")", "\n", "\n", "# if the size of the list is 1, we didn't achieve anything", "\n", "if", "len", "(", "lst", ")", "==", "1", ":", "\n", "                    ", "ret", "=", "lst", "[", "0", "]", "# still not done", "\n", "\n", "# if we actually get a list, only keep it if we can cast its elements to something", "\n", "# otherwise keep the entry as an entire string", "\n", "", "else", ":", "\n", "# make sure all elements in the list convert to something", "\n", "                    ", "done", "=", "all", "(", "[", "str_convert_single", "(", "v", ")", "[", "1", "]", "for", "v", "in", "lst", "]", ")", "\n", "if", "done", ":", "\n", "                        ", "ret", "=", "[", "str_convert_single", "(", "v", ")", "[", "0", "]", "for", "v", "in", "lst", "]", "\n", "\n", "# defeated, accept the entry as just a simple string...", "\n", "", "", "", "if", "not", "done", ":", "\n", "                ", "ret", "=", "val", "# accept string", "\n", "\n", "# assign secstrct.key = ret", "\n", "", "setattr", "(", "secstrct", ",", "key", ",", "ret", ")", "\n", "\n", "# assign strct.sec = secstrct", "\n", "", "setattr", "(", "strct", ",", "sec", ",", "secstrct", ")", "\n", "\n", "", "return", "strct", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_to_none": [[97, 113], ["None"], "function", ["None"], ["", "", "def", "str_to_none", "(", "val", ")", ":", "\n", "    ", "\"\"\"\n    cast a string to a None\n\n    Parameters:\n        val: the string to cast\n\n    Returns:\n        (casted_val, success)\n        casted val: the casted value if successful, or None\n        success: None if casting was successful\n    \"\"\"", "\n", "if", "val", "==", "'None'", ":", "\n", "        ", "return", "(", "None", ",", "True", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "None", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_to_type": [[115, 137], ["ctype"], "function", ["None"], ["", "", "def", "str_to_type", "(", "val", ",", "ctype", ")", ":", "\n", "    ", "\"\"\"\n    cast a string to a type (e.g. int('8')), with try/except\n    do *not* use for bool casting, instead see str_to_bull\n\n    Parameters:\n        val: the string to cast\n\n    Returns:\n        (casted_val, success)\n        casted val: the casted value if successful, or None\n        success: bool if casting was successful\n    \"\"\"", "\n", "assert", "ctype", "is", "not", "bool", ",", "'use str_to_bull() for casting to bool'", "\n", "\n", "ret", "=", "None", "\n", "success", "=", "True", "\n", "try", ":", "\n", "        ", "ret", "=", "ctype", "(", "val", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "success", "=", "False", "\n", "", "return", "(", "ret", ",", "success", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_to_bool": [[139, 157], ["None"], "function", ["None"], ["", "def", "str_to_bool", "(", "val", ")", ":", "\n", "    ", "\"\"\"\n    cast a string to a bool\n\n    Parameters:\n        val: the string to cast\n\n    Returns:\n        (casted_val, success)\n        casted val: the casted value if successful, or None\n        success: bool if casting was successful\n    \"\"\"", "\n", "if", "val", "==", "'True'", ":", "\n", "        ", "return", "(", "True", ",", "True", ")", "\n", "", "elif", "val", "==", "'False'", ":", "\n", "        ", "return", "(", "False", ",", "True", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "None", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_to_list": [[159, 181], ["val.replace.replace", "val.replace.replace", "val.replace.replace", "val.replace.replace", "val.replace.split", "val.replace.split"], "function", ["None"], ["", "", "def", "str_to_list", "(", "val", ")", ":", "\n", "    ", "\"\"\"\n    Split a string to a list of elements, where elements are separated by whitespace or commas\n    Leading/ending parantheses are stripped.\n\n    Returns:\n        val: the string to split\n\n    Returns:\n        casted_dst: the casted list\n    \"\"\"", "\n", "val", "=", "val", ".", "replace", "(", "'['", ",", "''", ")", "\n", "val", "=", "val", ".", "replace", "(", "'('", ",", "''", ")", "\n", "val", "=", "val", ".", "replace", "(", "']'", ",", "''", ")", "\n", "val", "=", "val", ".", "replace", "(", "')'", ",", "''", ")", "\n", "\n", "if", "','", "in", "val", ":", "\n", "        ", "lst", "=", "val", ".", "split", "(", "','", ")", "\n", "", "else", ":", "\n", "        ", "lst", "=", "val", ".", "split", "(", ")", "\n", "\n", "", "return", "lst", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_convert_single": [[183, 212], ["val.strip.strip", "iniparse.str_to_type", "iniparse.str_to_type", "iniparse.str_to_bool", "iniparse.str_to_none"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_to_type", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_to_type", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_to_bool", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.iniparse.str_to_none"], ["", "def", "str_convert_single", "(", "val", ")", ":", "\n", "    ", "\"\"\"\n    try to cast a string to an int, float or bool (in that order)\n\n    Parameters:\n        val: the string to cast\n\n    Returns:\n        (casted_val, success)\n        casted val: the casted value if successful, or None\n        success: bool if casting was successful\n    \"\"\"", "\n", "val", "=", "val", ".", "strip", "(", ")", "\n", "# try int", "\n", "ret", ",", "done", "=", "str_to_type", "(", "val", ",", "int", ")", "\n", "\n", "# try float", "\n", "if", "not", "done", ":", "\n", "        ", "ret", ",", "done", "=", "str_to_type", "(", "val", ",", "float", ")", "\n", "\n", "# try bool", "\n", "", "if", "not", "done", ":", "\n", "        ", "ret", ",", "done", "=", "str_to_bool", "(", "val", ")", "\n", "\n", "# try None", "\n", "", "if", "not", "done", ":", "\n", "        ", "ret", ",", "done", "=", "str_to_none", "(", "val", ")", "\n", "\n", "", "return", "(", "ret", ",", "done", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.quilt": [[24, 67], ["len", "patchlib.stack", "nan_func_layers", "nan_func_K", "numpy.prod", "len", "numpy.prod"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack"], ["def", "quilt", "(", "patches", ",", "\n", "patch_size", ",", "\n", "grid_size", ",", "\n", "patch_stride", "=", "1", ",", "\n", "nan_func_layers", "=", "np", ".", "nanmean", ",", "\n", "nan_func_K", "=", "np", ".", "nanmean", ")", ":", "\n", "    ", "\"\"\"\n    quilt (merge) or reconstruct volume from patch indexes in library\n\n    TODO: allow patches to be generator\n\n    Parameters:\n        patches: matrix [N x V x K], with patches(i, :, 1:K)\n            indicates K patch candidates at location i (e.g. the result of a 3-nearest\n            neightbours search). V = prod(patch_size); N = prod(grid_size)\n        patch_size: vector indicating the patch size\n        grid_size or target_size: vector indicating the grid size in each dimension\n            OR\n            specification of the target image size instead of the grid_size\n        patch_stride (optional, default:1): patch stride (spacing), default is 1 (sliding window)\n        nan_func_layers (optional): function to compute accross stack layers. default: np.nanmean\n        nan_func_K (optional): function to compute accross K (nd+1th dim). default: np.nanmean\n\n    Returns:\n        quilt_img: the quilted nd volume\n    \"\"\"", "\n", "\n", "# input checks", "\n", "assert", "patches", ".", "ndim", "==", "2", "or", "patches", ".", "ndim", "==", "3", ",", "'patches should be [NxV] or [NxVxK]'", "\n", "assert", "patches", ".", "shape", "[", "1", "]", "==", "np", ".", "prod", "(", "patch_size", ")", ",", "\"patches V (%d) does not match patch size V (%d)\"", "%", "(", "patches", ".", "shape", "[", "1", "]", ",", "np", ".", "prod", "(", "patch_size", ")", ")", "\n", "nb_dims", "=", "len", "(", "patch_size", ")", "\n", "\n", "# stack patches", "\n", "patch_stack", "=", "stack", "(", "patches", ",", "patch_size", ",", "grid_size", ",", "patch_stride", ")", "\n", "\n", "# quilt via nan_funs", "\n", "quilted_vol_k", "=", "nan_func_layers", "(", "patch_stack", ",", "0", ")", "\n", "quilted_vol", "=", "nan_func_K", "(", "quilted_vol_k", ",", "nb_dims", ")", "\n", "assert", "quilted_vol", ".", "ndim", "==", "len", "(", "patch_size", ")", ",", "\"patchlib: problem with dimensions after quilt\"", "\n", "\n", "# done, yey! time to celebrate - maybe visualize the quilted volume?", "\n", "return", "quilted_vol", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.stack": [[69, 198], ["patchlib.grid", "numpy.all", "ext.pynd.ndutils.ind2sub_entries", "list", "numpy.array().transpose", "ext.pynd.ndutils.sub2ind", "numpy.unique", "len", "numpy.empty", "range", "numpy.prod", "patchlib.grid2volsize", "range", "numpy.empty", "numpy.where", "numpy.empty", "numpy.reshape", "len", "numpy.array", "numpy.nan", "numpy.squeeze", "numpy.reshape", "ext.pynd.ndutils.slice", "np.empty.flatten", "print", "numpy.array", "numpy.array", "numpy.matlib.repmat", "print", "numpy.zeros", "list", "patchlib._mod_base", "numpy.ones", "list", "numpy.max", "range", "range", "nd.sub2ind.flatten", "len", "numpy.prod"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.grid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.ind2sub_entries", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.sub2ind", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.grid2volsize", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.flatten", "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib._mod_base", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.flatten"], ["", "def", "stack", "(", "patches", ",", "patch_size", ",", "grid_size", ",", "patch_stride", "=", "1", ",", "nargout", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    Stack (gridded) patches in layer structure.\n\n    Together, patch_size, grid_size and the patch overlap (see below), indicate\n    how the patches will be layed out and what the target layer size will be. For more\n    information about the interplay between patch_size, grid_size and patchOverlap, see\n    patchlib.grid.\n\n    TODO: allow patches to be generator\n\n    Parameters:\n        patches: matrix [N x V x K], with patches(i, :, 1:K)\n            indicates K patch candidates at location i (e.g. the result of a 3-nearest\n            neightbours search). V = prod(patch_size); N = prod(grid_size)\n        patch_size: vector indicating the patch size\n        grid_size or target_size: vector indicating the grid size in each dimension\n            OR\n            specification of the target image size instead of the grid_size\n        patch_stride (optional, default:1): patch stride (spacing), default is 1 (sliding window)\n        nargout (optional, default:1): the number of arguments to output\n\n    Returns:\n        layers: a [nb_layers x target_size x K] array, with nb_layers that are the size of\n            the desired target (i.e. once the patches are positioned to fit the grid). The\n            first layer, essentially stacks the first patch, then the next non-overlapping patch,\n            and so on. The second layer takes the first non-stacked patch, and then the next\n            non-overlapping patch, and so on until we run out of patches.\n        idxmat (if nargout >= 2): also returns a matrix the same size as\n            'layers' containing linear indexes into the inputted patches matrix. This is useful,\n            for example, to create a layer structure of patch weights to match the patches\n            layer structure. idxmat is [2 x N x targetSize x K], with idxmat[1, :] giving patch\n            ids, and idxmat[2, :] giving voxel ids\n        p_layer_idx (if nargout == 3): a [V x 1] vector indicating the layer index of each input\n            patch\n\n    See Also:\n        grid(), quilt()\n\n    See example in patchlib.quilt code.\n\n    Contact: {adalca,klbouman}@csail.mit.edu\n    \"\"\"", "\n", "\n", "#    assert np.all(np.mod(patch_size, 2) == 1), \"patch size is not odd\"", "\n", "K", "=", "patches", ".", "shape", "[", "2", "]", "if", "len", "(", "patches", ".", "shape", ")", ">", "2", "else", "1", "\n", "\n", "# compute the input target_size and target", "\n", "if", "np", ".", "prod", "(", "grid_size", ")", "==", "patches", ".", "shape", "[", "0", "]", ":", "# given the number of patches in the grid", "\n", "        ", "target_size", "=", "grid2volsize", "(", "grid_size", ",", "patch_size", ",", "patch_stride", "=", "patch_stride", ")", "\n", "", "else", ":", "\n", "        ", "target_size", "=", "grid_size", "\n", "\n", "# compute the grid indexes (and check that the target size matches)", "\n", "", "[", "grid_idx", ",", "target_size_chk", "]", "=", "grid", "(", "target_size", ",", "patch_size", ",", "patch_stride", ",", "nargout", "=", "2", ")", "\n", "assert", "np", ".", "all", "(", "target_size", "==", "target_size_chk", ")", ",", "'Target does not match the provided target size'", "\n", "\n", "# prepare subscript and index vectors", "\n", "grid_sub", "=", "nd", ".", "ind2sub_entries", "(", "grid_idx", ",", "target_size", ")", "\n", "all_idx", "=", "list", "(", "range", "(", "grid_idx", ".", "size", ")", ")", "\n", "\n", "# get index of layer location so that patches don't overlap", "\n", "# we do this by computing the modulo of the patch start location", "\n", "# with respect to the patch size. This won't be optimal yet, but we'll", "\n", "# eliminate any layers with no patches after", "\n", "mod_sub", "=", "np", ".", "array", "(", "[", "_mod_base", "(", "g", ",", "patch_size", ")", "for", "g", "in", "grid_sub", "]", ")", ".", "transpose", "(", ")", "\n", "patch_payer_idx", "=", "nd", ".", "sub2ind", "(", "mod_sub", ",", "patch_size", ")", "\n", "\n", "# initiate the votes layer structure", "\n", "layer_ids", "=", "np", ".", "unique", "(", "patch_payer_idx", ")", "\n", "nb_layers", "=", "len", "(", "layer_ids", ")", "\n", "layers", "=", "np", ".", "empty", "(", "[", "nb_layers", ",", "*", "target_size", ",", "K", "]", ")", "\n", "layers", "[", ":", "]", "=", "np", ".", "NAN", "\n", "\n", "# prepare input matching matrix", "\n", "if", "nargout", ">=", "2", ":", "\n", "        ", "idxmat", "=", "np", ".", "empty", "(", "[", "2", ",", "nb_layers", ",", "*", "target_size", ",", "K", "]", ")", "\n", "idxmat", "[", ":", "]", "=", "np", ".", "NAN", "\n", "\n", "#  go over each layer index", "\n", "", "for", "layer_idx", "in", "range", "(", "nb_layers", ")", ":", "\n", "# get patches attributed to this layer", "\n", "        ", "patch_id_in_layer", "=", "np", ".", "where", "(", "patch_payer_idx", "==", "layer_ids", "[", "layer_idx", "]", ")", "\n", "\n", "# prepare the layers", "\n", "layer_stack", "=", "np", ".", "empty", "(", "[", "*", "target_size", ",", "K", "]", ")", "\n", "layer_stack", "[", ":", "]", "=", "np", ".", "NAN", "\n", "if", "nargout", ">=", "2", ":", "\n", "            ", "layer_idxmat", "=", "np", ".", "nan", "(", "[", "2", ",", "*", "target_size", ",", "K", "]", ")", "\n", "\n", "# go thorugh each patch location for patches in this layer", "\n", "", "for", "pidx", "in", "patch_id_in_layer", "[", "0", "]", ":", "\n", "\n", "# extract the patches", "\n", "            ", "localpatches", "=", "np", ".", "squeeze", "(", "patches", "[", "pidx", ",", ":", "]", ")", "\n", "patch", "=", "np", ".", "reshape", "(", "localpatches", ",", "[", "*", "patch_size", ",", "K", "]", ")", "\n", "\n", "# put the patches in the layers", "\n", "sub", "=", "[", "*", "grid_sub", "[", "pidx", ",", ":", "]", ",", "0", "]", "\n", "endsub", "=", "np", ".", "array", "(", "sub", ")", "+", "np", ".", "array", "(", "[", "*", "patch_size", ",", "K", "]", ")", "\n", "rge", "=", "nd", ".", "slice", "(", "sub", ",", "endsub", ")", "\n", "layer_stack", "[", "rge", "]", "=", "patch", "\n", "\n", "# update input matching matrix", "\n", "if", "nargout", ">=", "2", ":", "\n", "# the linear index of the patch in the grid", "\n", "                ", "locidx", "=", "np", ".", "ones", "(", "[", "2", ",", "*", "patch_size", ",", "K", "]", ")", "*", "all_idx", "[", "pidx", "]", "\n", "locidx", "[", "1", ",", ":", "]", "=", "np", ".", "matlib", ".", "repmat", "(", "list", "(", "range", "(", "np", ".", "prod", "(", "patch_size", ")", ")", ")", ",", "1", ",", "K", ")", "\n", "layer_idxmat", "[", "rge", "]", "=", "locidx", "\n", "\n", "# update layer", "\n", "", "", "layers", "[", "layer_idx", ",", ":", "]", "=", "np", ".", "reshape", "(", "layer_stack", ".", "flatten", "(", ")", ",", "[", "*", "target_size", ",", "K", "]", ")", "\n", "\n", "# update the complete idxmat", "\n", "if", "nargout", ">=", "2", ":", "\n", "            ", "idxmat", "[", "0", ",", "layer_idx", ",", ":", "]", "=", "layer_idxmat", "[", "0", ",", ":", "]", "\n", "idxmat", "[", "1", ",", "layer_idx", ",", ":", "]", "=", "layer_idxmat", "[", "1", ",", ":", "]", "\n", "\n", "# setup outputs", "\n", "", "", "if", "nargout", "==", "1", ":", "\n", "        ", "return", "layers", "\n", "", "elif", "nargout", "==", "2", ":", "\n", "        ", "print", "(", "\"idxmat UNTESTED\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "(", "layers", ",", "idxmat", ")", "\n", "", "elif", "nargout", "==", "3", ":", "\n", "        ", "print", "(", "\"p_layer_idx UNTESTED\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "p", "=", "np", ".", "zeros", "(", "1", ",", "np", ".", "max", "(", "patch_payer_idx", ".", "flatten", "(", ")", ")", ")", "\n", "p", "[", "layer_ids", "]", "=", "list", "(", "range", "(", "len", "(", "layer_ids", ")", ")", ")", "\n", "return", "(", "layers", ",", "idxmat", ",", "p", "[", "patch_payer_idx", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.grid2volsize": [[200, 231], ["len", "isinstance", "isinstance", "numpy.array", "isinstance", "numpy.array", "numpy.repeat().astype", "numpy.repeat"], "function", ["None"], ["", "", "def", "grid2volsize", "(", "grid_size", ",", "patch_size", ",", "patch_stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    Compute the volume size from the grid size and patch information\n\n    Parameters:\n        grid_size (vector): the size of the grid in each dimension\n        patch_size (vector): the size of the patch_gen\n        patch_stride (vector/scalar, optional): the size of the stride\n\n    Returns:\n        Volume size filled up by the patches\n\n    See Also:\n        gridsize(), grid()\n\n    Contact:\n        {adalca,klbouman}@csail.mit.edu\n    \"\"\"", "\n", "\n", "# parameter checking", "\n", "if", "not", "isinstance", "(", "grid_size", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "grid_size", "=", "np", ".", "array", "(", "grid_size", ",", "'int'", ")", "\n", "", "if", "not", "isinstance", "(", "patch_size", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "patch_size", "=", "np", ".", "array", "(", "patch_size", ",", "'int'", ")", "\n", "", "nb_dims", "=", "len", "(", "patch_size", ")", "# number of dimensions", "\n", "if", "isinstance", "(", "patch_stride", ",", "int", ")", ":", "\n", "        ", "patch_stride", "=", "np", ".", "repeat", "(", "patch_stride", ",", "nb_dims", ")", ".", "astype", "(", "'int'", ")", "\n", "\n", "", "patch_overlap", "=", "patch_size", "-", "patch_stride", "\n", "vol_size", "=", "grid_size", "*", "patch_stride", "+", "patch_overlap", "\n", "return", "vol_size", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.gridsize": [[233, 294], ["len", "isinstance", "isinstance", "numpy.all", "numpy.floor().astype", "numpy.all", "isinstance", "numpy.array", "isinstance", "numpy.array", "numpy.repeat().astype", "numpy.repeat().astype", "patchlib.grid2volsize", "numpy.array", "numpy.floor", "numpy.array", "numpy.repeat", "numpy.repeat"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.grid2volsize"], ["", "def", "gridsize", "(", "vol_size", ",", "patch_size", ",", "patch_stride", "=", "1", ",", "start_sub", "=", "0", ",", "nargout", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    Number of patches that fit into volSize given a particular patch_size. patch_strideb\n    cropped to the maximum size that fits the patch grid. For example, a [6x6] volume with\n    patch_size opatch_stridee\n\n    Parameters:\n        vol_size (numpy vector): the size of the input volume\n        patch_size (numpy vector): the size of the patches\n        patch_stride (int or numpy vector, optional): stride (separation) in each dimension.\n            default: 1\n        start_sub (int or numpy vector, optional): the volume location where patches start\n            This essentially means that the volume will be cropped starting at that location.\n            e.g. if startSub is [2, 2], then only vol(2:end, 2:end) will be included.\n            default: 0\n        nargout (int, 1 or 2): optionally output new (cropped) volume size.\n            return the grid_size only if nargout is 1, or (grid_size, new_vol_size)\n            if narout is 2.\n    Returns:\n        grid_size only, if nargout is 1, or\n        (grid_size, new_vol_size) if narout is 2\n\n    See Also:\n        grid()\n\n    Contact:\n        {adalca,klbouman}@csail.mit.edu\n    \"\"\"", "\n", "\n", "# parameter checking", "\n", "if", "not", "isinstance", "(", "vol_size", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "vol_size", "=", "np", ".", "array", "(", "vol_size", ",", "'int'", ")", "\n", "", "if", "not", "isinstance", "(", "patch_size", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "patch_size", "=", "np", ".", "array", "(", "patch_size", ",", "'int'", ")", "\n", "", "nb_dims", "=", "len", "(", "patch_size", ")", "# number of dimensions", "\n", "if", "isinstance", "(", "patch_stride", ",", "int", ")", ":", "\n", "        ", "patch_stride", "=", "np", ".", "repeat", "(", "patch_stride", ",", "nb_dims", ")", ".", "astype", "(", "'int'", ")", "\n", "", "if", "isinstance", "(", "start_sub", ",", "int", ")", ":", "\n", "        ", "start_sub", "=", "np", ".", "repeat", "(", "start_sub", ",", "nb_dims", ")", ".", "astype", "(", "'int'", ")", "\n", "\n", "# adjacent patch overlap", "\n", "", "patch_overlap", "=", "patch_size", "-", "patch_stride", "\n", "\n", "# modified volume size if starting late", "\n", "mod_vol_size", "=", "vol_size", "-", "start_sub", "\n", "assert", "np", ".", "all", "(", "np", ".", "array", "(", "mod_vol_size", ")", ">", "0", ")", ",", "\"New volume size is non-positive\"", "\n", "\n", "# compute the number of patches", "\n", "# the final volume size will be", "\n", "# >> grid_size * patch_stride + patch_overlap", "\n", "# thus the part that is a multiplier of patch_stride is vol_size - patch_overlap", "\n", "patch_stride_multiples", "=", "mod_vol_size", "-", "patch_overlap", "# not sure?", "\n", "grid_size", "=", "np", ".", "floor", "(", "patch_stride_multiples", "/", "patch_stride", ")", ".", "astype", "(", "'int'", ")", "\n", "assert", "np", ".", "all", "(", "np", ".", "array", "(", "grid_size", ")", ">", "0", ")", ",", "\"Grid size is non-positive\"", "\n", "\n", "if", "nargout", "==", "1", ":", "\n", "        ", "return", "grid_size", "\n", "", "else", ":", "\n", "# new volume size based on how far the patches can reach", "\n", "        ", "new_vol_size", "=", "grid2volsize", "(", "grid_size", ",", "patch_size", ",", "patch_stride", "=", "patch_stride", ")", "\n", "return", "(", "grid_size", ",", "new_vol_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.grid": [[296, 376], ["len", "isinstance", "isinstance", "patchlib.gridsize", "range", "ext.pynd.ndutils.ndgrid", "isinstance", "numpy.array", "isinstance", "numpy.array", "numpy.repeat().astype", "numpy.repeat().astype", "list", "any", "numpy.array", "numpy.reshape", "range", "list", "numpy.repeat", "numpy.repeat", "range", "numpy.prod"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.gridsize", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.ndgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "", "def", "grid", "(", "vol_size", ",", "patch_size", ",", "patch_stride", "=", "1", ",", "start_sub", "=", "0", ",", "nargout", "=", "1", ",", "grid_type", "=", "'idx'", ")", ":", "\n", "    ", "\"\"\"\n    grid of patch starting points for nd volume that fit into given volume size\n\n    The index is in the given volume. If the volume gets cropped as part of the function and you\n    want a linear indexing into the new volume size, use\n    >> newidx = ind2ind(new_vol_size, vol_size, idx)\n    new_vol_size can be passed by the current function, see below.\n\n    Parameters:\n        vol_size (numpy vector): the size of the input volume\n        patch_size (numpy vector): the size of the patches\n        patch_stride (int or numpy vector, optional): stride (separation) in each dimension.\n            default: 1\n        start_sub (int or numpy vector, optional): the volume location where patches start\n            This essentially means that the volume will be cropped starting at that location.\n            e.g. if startSub is [2, 2], then only vol(2:end, 2:end) will be included.\n            default: 0\n        nargout (int, 1,2 or 3): optionally output new (cropped) volume size and the grid size\n            return the idx array only if nargout is 1, or (idx, new_vol_size) if nargout is 2,\n            or (idx, new_vol_size, grid_size) if nargout is 3\n        grid_type ('idx' or 'sub', optional): how to describe the grid, in linear index (idx)\n            or nd subscripts ('sub'). sub will be a nb_patches x nb_dims ndarray. This is\n            equivalent to sub = ind2sub(vol_size, idx), but is done faster inside this function.\n            [TODO: or it was faster in MATLAB, this might not be true in python anymore]\n\n    Returns:\n        idx nd array only if nargout is 1, or (idx, new_vol_size) if nargout is 2,\n            or (idx, new_vol_size, grid_size) if nargout is 3\n\n    See also:\n        gridsize()\n\n    Contact:\n        {adalca,klbouman}@csail.mit.edu\n    \"\"\"", "\n", "\n", "# parameter checking", "\n", "assert", "grid_type", "in", "(", "'idx'", ",", "'sub'", ")", "\n", "if", "not", "isinstance", "(", "vol_size", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "vol_size", "=", "np", ".", "array", "(", "vol_size", ",", "'int'", ")", "\n", "", "if", "not", "isinstance", "(", "patch_size", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "patch_size", "=", "np", ".", "array", "(", "patch_size", ",", "'int'", ")", "\n", "", "nb_dims", "=", "len", "(", "patch_size", ")", "# number of dimensions", "\n", "if", "isinstance", "(", "patch_stride", ",", "int", ")", ":", "\n", "        ", "patch_stride", "=", "np", ".", "repeat", "(", "patch_stride", ",", "nb_dims", ")", ".", "astype", "(", "'int'", ")", "\n", "", "if", "isinstance", "(", "start_sub", ",", "int", ")", ":", "\n", "        ", "start_sub", "=", "np", ".", "repeat", "(", "start_sub", ",", "nb_dims", ")", ".", "astype", "(", "'int'", ")", "\n", "\n", "# get the grid data", "\n", "", "[", "grid_size", ",", "new_vol_size", "]", "=", "gridsize", "(", "vol_size", ",", "patch_size", ",", "\n", "patch_stride", "=", "patch_stride", ",", "\n", "start_sub", "=", "start_sub", ",", "\n", "nargout", "=", "2", ")", "\n", "\n", "# compute grid linear index", "\n", "# prepare the sample grid in each dimension", "\n", "xvec", "=", "(", ")", "\n", "for", "idx", "in", "range", "(", "nb_dims", ")", ":", "\n", "        ", "volend", "=", "new_vol_size", "[", "idx", "]", "+", "start_sub", "[", "idx", "]", "-", "patch_size", "[", "idx", "]", "+", "1", "\n", "locs", "=", "list", "(", "range", "(", "start_sub", "[", "idx", "]", ",", "volend", ",", "patch_stride", "[", "idx", "]", ")", ")", "\n", "xvec", "+=", "(", "locs", ",", ")", "\n", "assert", "any", "(", "(", "locs", "[", "-", "1", "]", "+", "patch_size", "-", "1", ")", "==", "(", "new_vol_size", "+", "start_sub", "-", "1", ")", ")", "\n", "\n", "# get the nd grid", "\n", "# if want subs, this is the faster way to compute in MATLAB (rather than ind -> ind2sub)", "\n", "# TODO: need to investigate for python, maybe use np.ix_ ?", "\n", "", "idx", "=", "nd", ".", "ndgrid", "(", "*", "xvec", ")", "\n", "if", "grid_type", "==", "'idx'", ":", "\n", "# if want index, this is the faster way to compute (rather than sub -> sub2ind", "\n", "        ", "all_idx", "=", "np", ".", "array", "(", "list", "(", "range", "(", "0", ",", "np", ".", "prod", "(", "vol_size", ")", ")", ")", ")", "\n", "all_idx", "=", "np", ".", "reshape", "(", "all_idx", ",", "vol_size", ")", "\n", "idx", "=", "all_idx", "[", "idx", "]", "\n", "\n", "", "if", "nargout", "==", "1", ":", "\n", "        ", "return", "idx", "\n", "", "elif", "nargout", "==", "2", ":", "\n", "        ", "return", "(", "idx", ",", "new_vol_size", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "idx", ",", "new_vol_size", ",", "grid_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.patch_gen": [[378, 439], ["isinstance", "numpy.all", "enumerate", "patchlib.gridsize", "ext.pynd.ndutils.ndgrid", "list", "len", "len", "len", "len", "list", "range", "random.shuffle", "pprint.pformat", "pprint.pformat", "pprint.pformat", "pprint.pformat", "numpy.array", "numpy.array", "list", "len", "len", "random.seed", "slice", "slicer", "range", "zip"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib.gridsize", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.ndgrid", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.slice", "home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range"], ["", "", "def", "patch_gen", "(", "vol", ",", "patch_size", ",", "stride", "=", "1", ",", "nargout", "=", "1", ",", "rand", "=", "False", ",", "rand_seed", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    generator of patches from volume\n\n    Parameters:\n        vol (numpy array): the n-d volume to be patched\n        patch_size (numpy vector): the size of the patches\n        patch_stride (int or numpy vector, optional): stride (separation) in each dimension.\n            default: 1\n        nargout (int, optional): how much to yield\n            1 (default: the patch) or 2 (tuple with the patch and volume slices for that patch)\n        rand (logical, optional): whether to randomize patch order (default: False)\n        rand_seed (number, optional): random seed if randomizing patch order\n\n    TODO: test more...\n    TODO: use .grid() to get sub\n    \"\"\"", "\n", "\n", "# some parameter checking", "\n", "if", "isinstance", "(", "stride", ",", "int", ")", ":", "\n", "        ", "stride", "=", "[", "stride", "for", "f", "in", "patch_size", "]", "\n", "", "assert", "len", "(", "vol", ".", "shape", ")", "==", "len", "(", "patch_size", ")", ",", "\"vol shape %s and patch size %s do not match dimensions\"", "%", "(", "pformat", "(", "vol", ".", "shape", ")", ",", "pformat", "(", "patch_size", ")", ")", "\n", "assert", "len", "(", "vol", ".", "shape", ")", "==", "len", "(", "stride", ")", ",", "\"vol shape %s and patch stride %s do not match dimensions\"", "%", "(", "pformat", "(", "vol", ".", "shape", ")", ",", "pformat", "(", "stride", ")", ")", "\n", "\n", "cropped_vol_size", "=", "np", ".", "array", "(", "vol", ".", "shape", ")", "-", "np", ".", "array", "(", "patch_size", ")", "+", "1", "\n", "assert", "np", ".", "all", "(", "cropped_vol_size", ">=", "0", ")", ",", "\"patch size needs to be smaller than volume size\"", "\n", "\n", "# get range subs", "\n", "sub", "=", "(", ")", "\n", "for", "idx", ",", "cvs", "in", "enumerate", "(", "cropped_vol_size", ")", ":", "\n", "        ", "sub", "+=", "(", "list", "(", "range", "(", "0", ",", "cvs", ",", "stride", "[", "idx", "]", ")", ")", ",", ")", "\n", "\n", "# check the size", "\n", "", "gs", "=", "gridsize", "(", "vol", ".", "shape", ",", "patch_size", ",", "patch_stride", "=", "stride", ")", "\n", "assert", "[", "len", "(", "f", ")", "for", "f", "in", "sub", "]", "==", "list", "(", "gs", ")", ",", "'Patch gen side failure'", "\n", "\n", "# get ndgrid of subs", "\n", "ndg", "=", "nd", ".", "ndgrid", "(", "*", "sub", ")", "\n", "ndg", "=", "[", "f", ".", "flat", "for", "f", "in", "ndg", "]", "\n", "\n", "# generator", "\n", "rng", "=", "list", "(", "range", "(", "len", "(", "ndg", "[", "0", "]", ")", ")", ")", "\n", "if", "rand", ":", "\n", "        ", "if", "rand_seed", "is", "not", "None", ":", "\n", "            ", "random", ".", "seed", "(", "rand_seed", ")", "\n", "", "shuffle", "(", "rng", ")", "\n", "\n", "\n", "", "for", "idx", "in", "rng", ":", "\n", "        ", "slicer", "=", "lambda", "f", ",", "g", ":", "slice", "(", "f", "[", "idx", "]", ",", "f", "[", "idx", "]", "+", "g", ")", "\n", "patch_sub", "=", "[", "slicer", "(", "f", ",", "g", ")", "for", "f", ",", "g", "in", "zip", "(", "ndg", ",", "patch_size", ")", "]", "\n", "# print(patch_sub)", "\n", "if", "nargout", "==", "1", ":", "\n", "            ", "yield", "vol", "[", "patch_sub", "]", "\n", "", "else", ":", "\n", "            ", "yield", "(", "vol", "[", "patch_sub", "]", ",", "patch_sub", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.patchlib._mod_base": [[443, 459], ["numpy.mod"], "function", ["None"], ["", "", "", "def", "_mod_base", "(", "num", ",", "div", ",", "base", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    modulo with respect to a specific base numbering system\n    i.e. returns base + ((num - base) % div)\n    modBase(num, div) behaves like num % div\n\n    Parameters:\n        num (array_like): divident\n        div (array_like): divisor\n        base (optional, default 0): the base\n\n    Returns:\n        the modulo\n    \"\"\"", "\n", "\n", "return", "base", "+", "np", ".", "mod", "(", "num", "-", "base", ",", "div", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.BBillot_SynthSR.pytools.plot.jitter": [[11, 64], ["range", "numpy.maximum().astype", "numpy.pad", "numpy.array", "isinstance", "matplotlib.colors.ListedColormap", "matplotlib.colors.ListedColormap", "numpy.ceil", "numpy.reshape().transpose().flatten", "len", "matplotlib.get_cmap", "plt.get_cmap.", "numpy.maximum", "numpy.where", "numpy.round", "numpy.reshape().transpose", "numpy.reshape"], "function", ["home.repos.pwc.inspect_result.BBillot_SynthSR.pynd.ndutils.range", "home.repos.pwc.inspect_result.BBillot_SynthSR.neuron.utils.flatten"], ["\n", "\n", "# third party", "\n", "import", "numpy", "as", "np", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "import", "matplotlib", ".", "cm", "as", "cm", "\n", "from", "matplotlib", ".", "colors", "import", "Normalize", "\n", "from", "mpl_toolkits", ".", "axes_grid1", "import", "make_axes_locatable", "# plotting", "\n", "\n", "\n", "def", "slices", "(", "slices_in", ",", "# the 2D slices", "\n", "titles", "=", "None", ",", "# list of titles", "\n", "cmaps", "=", "None", ",", "# list of colormaps", "\n", "norms", "=", "None", ",", "# list of normalizations", "\n", "do_colorbars", "=", "False", ",", "# option to show colorbars on each slice", "\n", "grid", "=", "False", ",", "# option to plot the images in a grid or a single row", "\n", "width", "=", "15", ",", "# width in in", "\n", "show", "=", "True", ",", "# option to actually show the plot (plt.show())", "\n", "axes_off", "=", "True", ",", "\n", "imshow_args", "=", "None", ")", ":", "\n", "    ", "'''\n    plot a grid of slices (2d images)\n    '''", "\n", "\n", "# input processing", "\n", "if", "type", "(", "slices_in", ")", "==", "np", ".", "ndarray", ":", "\n", "        ", "slices_in", "=", "[", "slices_in", "]", "\n", "", "nb_plots", "=", "len", "(", "slices_in", ")", "\n", "for", "si", ",", "slice_in", "in", "enumerate", "(", "slices_in", ")", ":", "\n", "        ", "if", "len", "(", "slice_in", ".", "shape", ")", "!=", "2", ":", "\n", "            ", "assert", "len", "(", "slice_in", ".", "shape", ")", "==", "3", "and", "slice_in", ".", "shape", "[", "-", "1", "]", "==", "3", ",", "'each slice has to be 2d or RGB (3 channels)'", "\n", "", "slices_in", "[", "si", "]", "=", "slice_in", ".", "astype", "(", "'float'", ")", "\n", "\n", "\n", "", "def", "input_check", "(", "inputs", ",", "nb_plots", ",", "name", ")", ":", "\n", "        ", "''' change input from None/single-link '''", "\n", "assert", "(", "inputs", "is", "None", ")", "or", "(", "len", "(", "inputs", ")", "==", "nb_plots", ")", "or", "(", "len", "(", "inputs", ")", "==", "1", ")", ",", "'number of %s is incorrect'", "%", "name", "\n", "if", "inputs", "is", "None", ":", "\n", "            ", "inputs", "=", "[", "None", "]", "\n", "", "if", "len", "(", "inputs", ")", "==", "1", ":", "\n", "            ", "inputs", "=", "[", "inputs", "[", "0", "]", "for", "i", "in", "range", "(", "nb_plots", ")", "]", "\n", "", "return", "inputs", "\n", "\n", "", "titles", "=", "input_check", "(", "titles", ",", "nb_plots", ",", "'titles'", ")", "\n", "cmaps", "=", "input_check", "(", "cmaps", ",", "nb_plots", ",", "'cmaps'", ")", "\n", "norms", "=", "input_check", "(", "norms", ",", "nb_plots", ",", "'norms'", ")", "\n", "imshow_args", "=", "input_check", "(", "imshow_args", ",", "nb_plots", ",", "'imshow_args'", ")", "\n", "for", "idx", ",", "ia", "in", "enumerate", "(", "imshow_args", ")", ":", "\n", "        ", "imshow_args", "[", "idx", "]", "=", "{", "}", "if", "ia", "is", "None", "else", "ia", "\n", "\n", "# figure out the number of rows and columns", "\n", "", "if", "grid", ":", "\n", "        ", "if", "isinstance", "(", "grid", ",", "bool", ")", ":", "\n"]]}