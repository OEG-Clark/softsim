{"home.repos.pwc.inspect_result.shamilcm_pedra.scripts.postprocess_decode.postprocess": [[7, 49], ["detokenizer.detokenize", "open", "open", "open", "zip", "re.sub().split", "detokenize.strip", "code.strip().split", "int", "re.sub", "foape.write", "postprocess_decode.postprocess.detokenize"], "function", ["None"], ["def", "postprocess", "(", "ape_file", ",", "codes_file", ",", "detokenizer", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n        post-process the output file of the post-editing system\n        by making use of the codes file.\n\n        Args:\n            ape_file: post-edited output of the system\n            codes_file: created during pre-processing that keeps track of <br> and symbols\n    \"\"\"", "\n", "def", "detokenize", "(", "s", ",", "detokenizer", ")", ":", "\n", "        ", "\"\"\" helper function to detokenize \"\"\"", "\n", "return", "detokenizer", ".", "detokenize", "(", "re", ".", "sub", "(", "\" ##\"", ",", "\"\"", ",", "s", ")", ".", "split", "(", ")", ")", "\n", "\n", "", "ape_out_file", "=", "ape_file", "+", "'.post'", "\n", "with", "open", "(", "ape_out_file", ",", "'w'", ")", "as", "foape", ",", "open", "(", "ape_file", ")", "as", "fape", ",", "open", "(", "codes_file", ")", "as", "fcodes", ":", "\n", "        ", "idx", "=", "0", "\n", "for", "ape", ",", "code", "in", "zip", "(", "fape", ",", "fcodes", ")", ":", "\n", "            ", "ape", "=", "ape", ".", "strip", "(", ")", "\n", "if", "detokenizer", "is", "not", "None", ":", "\n", "                ", "ape", "=", "detokenize", "(", "ape", ",", "detokenizer", ")", "\n", "", "pieces", "=", "code", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "orig_idx", "=", "int", "(", "pieces", "[", "0", "]", ")", "\n", "tags", "=", "[", "]", "if", "len", "(", "pieces", ")", "==", "1", "else", "pieces", "[", "1", ":", "]", "\n", "if", "orig_idx", "!=", "idx", ":", "\n", "                ", "if", "idx", "!=", "0", ":", "foape", ".", "write", "(", "'\\n'", ")", "#except for first line, add a new line to any new lne", "\n", "idx", "+=", "1", "\n", "", "else", ":", "\n", "                ", "foape", ".", "write", "(", "' <br> '", ")", "\n", "\n", "", "if", "\"MUSIC\"", "in", "tags", ":", "\n", "                ", "ape", "=", "\"\u266b {} \u266b\"", ".", "format", "(", "ape", ")", "\n", "\n", "", "if", "\"ITALICTAGS\"", "in", "tags", ":", "\n", "                ", "ape", "=", "\"<i> {} </i>\"", ".", "format", "(", "ape", ")", "\n", "\n", "", "if", "\"HYPHENBEGIN\"", "in", "tags", ":", "\n", "                ", "ape", "=", "\"- {}\"", ".", "format", "(", "ape", ")", "\n", "\n", "# removing spaces around hyphens due to BERT tokenizer split", "\n", "", "ape", "=", "re", ".", "sub", "(", "r\"([^>.?]) - ([^<])\"", ",", "r\"\\1-\\2\"", ",", "ape", ")", "\n", "\n", "foape", ".", "write", "(", "ape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shamilcm_pedra.scripts.postprocess_decode.main": [[50, 67], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "postprocess_decode.postprocess", "sacremoses.tokenize.MosesDetokenizer"], "function", ["home.repos.pwc.inspect_result.shamilcm_pedra.scripts.postprocess_decode.postprocess"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"-i\"", ",", "\"--input-pe-file\"", ",", "required", "=", "True", ",", "help", "=", "\"output of the pe system to be post processed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-tlang\"", ",", "\"--target-language\"", ",", "dest", "=", "\"target_language\"", ",", "help", "=", "\"required for detokenization\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-detok\"", ",", "\"--detokenize\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"do detokenization (-tlang is necessary)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-c\"", ",", "\"--codes-file\"", ",", "required", "=", "True", ",", "help", "=", "\"codes file used to post process the output\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "detokenizer", "=", "None", "\n", "if", "args", ".", "detokenize", "==", "True", ":", "\n", "        ", "assert", "(", "\n", "args", ".", "target_language", "is", "not", "None", "\n", ")", ",", "\"--target-language is required for detokenization\"", "\n", "detokenizer", "=", "MosesDetokenizer", "(", "lang", "=", "args", ".", "target_language", ")", "\n", "\n", "\n", "", "postprocess", "(", "ape_file", "=", "args", ".", "input_pe_file", ",", "codes_file", "=", "args", ".", "codes_file", ",", "detokenizer", "=", "detokenizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shamilcm_pedra.scripts.preprocess_train.cleanup": [[34, 42], ["re.sub", "re.sub.strip", "re.sub", "re.sub.strip", "re.sub.startswith"], "function", ["None"], ["", "def", "cleanup", "(", "s", ",", "args", "=", "None", ")", ":", "\n", "    ", "s", "=", "re", ".", "sub", "(", "'<[^>]*>'", ",", "' '", ",", "s", ")", "\n", "s", "=", "s", ".", "strip", "(", ")", "\n", "if", "args", ":", "\n", "        ", "if", "args", ".", "remove_begin_hyphens", "==", "True", "and", "s", ".", "startswith", "(", "'-'", ")", ":", "\n", "            ", "s", "=", "s", "[", "1", ":", "]", "\n", "", "", "s", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "s", ".", "strip", "(", ")", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.shamilcm_pedra.scripts.preprocess_decode.cleanup": [[8, 16], ["re.sub", "re.sub.strip", "re.sub", "re.sub.strip"], "function", ["None"], ["def", "cleanup", "(", "s", ")", ":", "\n", "    ", "\"\"\"\n    remove all other html tags and extra spaces\n    \"\"\"", "\n", "s", "=", "re", ".", "sub", "(", "'<[^>]*>'", ",", "' '", ",", "s", ")", "\n", "s", "=", "s", ".", "strip", "(", ")", "\n", "s", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "s", ".", "strip", "(", ")", ")", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.shamilcm_pedra.scripts.preprocess_decode.preprocess": [[17, 118], ["sacremoses.normalize.MosesPunctNormalizer", "sacremoses.tokenize.MosesTokenizer", "os.path.basename", "open", "open", "open", "open", "open", "zip", "os.path.basename", "os.path.basename", "re.sub", "re.sub", "re.split", "re.split", "zip", "re.sub.strip", "re.sub.strip", "re.sub.startswith", "re.sub.startswith", "re.search", "re.search", "sacremoses.normalize.MosesPunctNormalizer.normalize", "sacremoses.normalize.MosesPunctNormalizer.normalize", "fosrc.write", "fomt.write", "fcodes.write", "len", "len", "src_part[].lstrip", "mt_part[].lstrip", "re.sub", "re.sub", "re.sub.startswith", "re.sub.endswith", "re.sub.startswith", "re.sub.endswith", "preprocess_decode.cleanup", "preprocess_decode.cleanup", "sacremoses.tokenize.MosesTokenizer.tokenize", "sacremoses.tokenize.MosesTokenizer.tokenize", "re.sub.strip", "re.sub.strip"], "function", ["home.repos.pwc.inspect_result.shamilcm_pedra.scripts.preprocess_decode.cleanup", "home.repos.pwc.inspect_result.shamilcm_pedra.scripts.preprocess_decode.cleanup"], ["", "def", "preprocess", "(", "src_file", ",", "mt_file", ",", "output_dir", ",", "tokenize_lang", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n        pre-process input file before post-editing\n        split at <br> and remove <i> tags and music symbols.\n        store everything in a codes file in output_dir\n\n        Args:\n            src_file: src_file of the translation to be preprocessed\n            mt_file: output of the mt system file to be preprocessed\n            output_dir: output directory to output the preprocessed files and codes file\n\n    \"\"\"", "\n", "\n", "punct_normalizer", "=", "MosesPunctNormalizer", "(", ")", "\n", "\n", "# set tokenizer", "\n", "tokenizer", "=", "None", "\n", "if", "tokenize_lang", ":", "\n", "        ", "tokenizer", "=", "MosesTokenizer", "(", "lang", "=", "tokenize_lang", ")", "\n", "\n", "", "code_file", "=", "output_dir", "+", "'/codes.'", "+", "os", ".", "path", ".", "basename", "(", "mt_file", ")", "\n", "src_out_file", "=", "output_dir", "+", "'/'", "+", "os", ".", "path", ".", "basename", "(", "src_file", ")", "+", "'.pre'", "\n", "mt_out_file", "=", "output_dir", "+", "'/'", "+", "os", ".", "path", ".", "basename", "(", "mt_file", ")", "+", "'.pre'", "\n", "with", "open", "(", "src_out_file", ",", "'w'", ")", "as", "fosrc", ",", "open", "(", "mt_out_file", ",", "'w'", ")", "as", "fomt", ",", "open", "(", "code_file", ",", "'w'", ")", "as", "fcodes", ",", "open", "(", "src_file", ")", "as", "fsrc", ",", "open", "(", "mt_file", ")", "as", "fmt", ":", "\n", "        ", "idx", "=", "0", "\n", "for", "src", ",", "mt", "in", "zip", "(", "fsrc", ",", "fmt", ")", ":", "\n", "            ", "src", ",", "mt", "=", "src", ".", "strip", "(", ")", ",", "mt", ".", "strip", "(", ")", "\n", "\n", "\n", "idx", "+=", "1", "\n", "\n", "# standardize br tags", "\n", "src", "=", "re", ".", "sub", "(", "'<\\s*br\\s*\\/*>'", ",", "'<br>'", ",", "src", ",", "flags", "=", "re", ".", "IGNORECASE", ")", "\n", "mt", "=", "re", ".", "sub", "(", "'<\\s*br\\s*\\/*>'", ",", "'<br>'", ",", "mt", ",", "flags", "=", "re", ".", "IGNORECASE", ")", "\n", "\n", "\n", "# if number of <br> is same, split and save it as multiple lines", "\n", "src_split", "=", "re", ".", "split", "(", "r'\\s*<br>\\s*'", ",", "src", ")", "\n", "mt_split", "=", "re", ".", "split", "(", "r'\\s*<br>\\s*'", ",", "mt", ")", "\n", "\n", "# if the src, mt, do not have the same number of <br>, then do not split it", "\n", "if", "not", "(", "len", "(", "src_split", ")", "==", "len", "(", "mt_split", ")", ")", ":", "\n", "                ", "src_split", "=", "[", "src", "]", "\n", "mt_split", "=", "[", "mt", "]", "\n", "\n", "\n", "\n", "", "for", "src_part", ",", "mt_part", "in", "zip", "(", "src_split", ",", "mt_split", ")", ":", "\n", "                ", "code", "=", "\"{}\\t\"", ".", "format", "(", "idx", ")", "\n", "\n", "# check if they start with the hyphen", "\n", "has_hyphen", "=", "False", "\n", "if", "src_part", ".", "startswith", "(", "'-'", ")", ":", "\n", "                    ", "has_hyphen", "=", "True", "\n", "src_part", "=", "src_part", "[", "1", ":", "]", ".", "lstrip", "(", ")", "\n", "\n", "", "if", "mt_part", ".", "startswith", "(", "'-'", ")", ":", "\n", "                    ", "has_hyphen", "=", "True", "\n", "mt_part", "=", "mt_part", "[", "1", ":", "]", ".", "lstrip", "(", ")", "\n", "\n", "# check if they start with the music symbol", "\n", "", "music_syms", "=", "(", "'\u266b'", ",", "'\u266c'", ",", "'\u266a'", ")", "\n", "has_music", "=", "False", "\n", "if", "re", ".", "search", "(", "r'\\s*[{}]\\s*'", ".", "format", "(", "''", ".", "join", "(", "music_syms", ")", ")", ",", "src_part", ")", ":", "\n", "                    ", "has_music", "=", "True", "\n", "src_part", "=", "re", ".", "sub", "(", "r'\\s*[{}]\\s*'", ".", "format", "(", "''", ".", "join", "(", "music_syms", ")", ")", ",", "''", ",", "src_part", ")", "\n", "\n", "#if mt_part.startswith(music_syms) or mt_part.endswith(music_syms):", "\n", "", "if", "re", ".", "search", "(", "r'\\s*[{}]\\s*'", ".", "format", "(", "''", ".", "join", "(", "music_syms", ")", ")", ",", "mt_part", ")", ":", "\n", "                    ", "has_music", "=", "True", "\n", "mt_part", "=", "re", ".", "sub", "(", "r'\\s*[{}]\\s*'", ".", "format", "(", "''", ".", "join", "(", "music_syms", ")", ")", ",", "''", ",", "mt_part", ")", "\n", "\n", "# check if it has enclosing italics tags. otherwise leave it as it is", "\n", "", "itag", "=", "'<i>'", "\n", "eitag", "=", "'</i>'", "\n", "has_itag", "=", "False", "\n", "if", "src_part", ".", "startswith", "(", "itag", ")", "or", "src_part", ".", "endswith", "(", "eitag", ")", ":", "\n", "                    ", "has_itag", "=", "True", "\n", "\n", "", "if", "mt_part", ".", "startswith", "(", "itag", ")", "or", "mt_part", ".", "endswith", "(", "eitag", ")", ":", "\n", "                    ", "has_itag", "=", "True", "\n", "\n", "\n", "#if re.match(r'^<i>[^<]*</i>$', src_part):", "\n", "", "if", "has_hyphen", "==", "True", ":", "\n", "                    ", "code", "+=", "'HYPHENBEGIN\\t'", "\n", "", "if", "has_music", "==", "True", ":", "\n", "                    ", "code", "+=", "'MUSIC\\t'", "\n", "", "if", "has_itag", "==", "True", ":", "\n", "                    ", "code", "+=", "'ITALICTAGS\\t'", "\n", "\n", "", "src_part", "=", "punct_normalizer", ".", "normalize", "(", "cleanup", "(", "src_part", ")", ")", "\n", "mt_part", "=", "punct_normalizer", ".", "normalize", "(", "cleanup", "(", "mt_part", ")", ")", "\n", "\n", "if", "tokenizer", ":", "\n", "                    ", "src_part", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "src_part", ",", "escape", "=", "False", ")", ")", "\n", "mt_part", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "mt_part", ",", "escape", "=", "False", ")", ")", "\n", "\n", "", "fosrc", ".", "write", "(", "src_part", ".", "strip", "(", ")", "+", "'\\n'", ")", "\n", "fomt", ".", "write", "(", "mt_part", ".", "strip", "(", ")", "+", "'\\n'", ")", "\n", "fcodes", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "code", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shamilcm_pedra.scripts.preprocess_decode.main": [[120, 132], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "preprocess_decode.preprocess"], "function", ["home.repos.pwc.inspect_result.shamilcm_pedra.scripts.preprocess_decode.preprocess"], ["", "", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"-i\"", ",", "\"--input-files\"", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "help", "=", "\"paths to src and mt files\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-slang\"", ",", "\"--source-language\"", ",", "help", "=", "\"source languge for pre-tokenization using Moses tokenization (e.g. 'en')\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-tok\"", ",", "\"--tokenize\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"pre-tokenization with moses tokenizer\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-odir\"", ",", "\"--output-dir\"", ",", "required", "=", "True", ",", "help", "=", "\"directory to output processed file along with history of operation codes to post process\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "tokenize", ":", "\n", "        ", "assert", "args", ".", "source_language", ",", "\"--source-language must be set if --tokenize flag is used\"", "\n", "\n", "", "preprocess", "(", "src_file", "=", "args", ".", "input_files", "[", "0", "]", ",", "mt_file", "=", "args", ".", "input_files", "[", "1", "]", ",", "output_dir", "=", "args", ".", "output_dir", ",", "tokenize_lang", "=", "args", ".", "source_language", ")", "\n", "\n"]]}