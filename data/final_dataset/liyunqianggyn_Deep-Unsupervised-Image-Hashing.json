{"home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.Sign.hash.forward": [[41, 47], ["torch.sign", "ctx.save_for_backward"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ")", ":", "\n", "        ", "B_code", "=", "torch", ".", "sign", "(", "input", ")", "\n", "ctx", ".", "save_for_backward", "(", "input", ",", "B_code", ")", "\n", "# ctx.save_for_backward(input)", "\n", "return", "B_code", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.Sign.hash.backward": [[48, 57], ["input.clone", "input.clone.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "input", ",", "B_code", "=", "ctx", ".", "saved_tensors", "\n", "uu", "=", "input", ".", "clone", "(", ")", "\n", "size", "=", "uu", ".", "size", "(", ")", "\n", "extrgrad", "=", "(", "uu", "-", "B_code", ")", "/", "(", "size", "[", "0", "]", "*", "size", "[", "1", "]", ")", "\n", "grad_output", "=", "grad_output", "+", "gamma", "*", "extrgrad", "\n", "\n", "return", "grad_output", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.Sign.autoencoder.__init__": [[70, 83], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.manual_seed", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encode_length", ")", ":", "\n", "        ", "super", "(", "autoencoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "28", "*", "28", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "encode_length", ")", "\n", ")", "\n", "torch", ".", "manual_seed", "(", "1", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "encode_length", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "28", "*", "28", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.Sign.autoencoder.forward": [[85, 90], ["Sign.autoencoder.encoder", "Sign.hash_layer", "Sign.autoencoder.decoder"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash_layer"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "encoder", "(", "x", ")", "\n", "b", "=", "hash_layer", "(", "h", ")", "\n", "x", "=", "self", ".", "decoder", "(", "b", ")", "\n", "return", "x", ",", "h", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.Sign.to_img": [[21, 24], ["x.view.view", "x.view.size"], "function", ["None"], ["def", "to_img", "(", "x", ")", ":", "\n", "    ", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "28", ",", "28", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.Sign.min_max_normalization": [[26, 33], ["tensor.min", "tensor.max"], "function", ["None"], ["", "def", "min_max_normalization", "(", "tensor", ",", "min_value", ",", "max_value", ")", ":", "\n", "    ", "min_tensor", "=", "tensor", ".", "min", "(", ")", "\n", "tensor", "=", "(", "tensor", "-", "min_tensor", ")", "\n", "max_tensor", "=", "tensor", ".", "max", "(", ")", "\n", "tensor", "=", "tensor", "/", "max_tensor", "\n", "tensor", "=", "tensor", "*", "(", "max_value", "-", "min_value", ")", "+", "min_value", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.Sign.tensor_round": [[35, 37], ["torch.round"], "function", ["None"], ["", "def", "tensor_round", "(", "tensor", ")", ":", "\n", "    ", "return", "torch", ".", "round", "(", "tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.Sign.hash_layer": [[59, 61], ["hash.apply"], "function", ["None"], ["", "", "def", "hash_layer", "(", "input", ")", ":", "\n", "    ", "return", "hash", ".", "apply", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.Sign.adjust_learning_rate": [[63, 68], ["None"], "function", ["None"], ["", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", ":", "\n", "\t", "update_list", "=", "[", "60", ",", "80", "]", "\n", "if", "epoch", "in", "update_list", ":", "\n", "\t\t", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "\t\t\t", "param_group", "[", "'lr'", "]", "=", "param_group", "[", "'lr'", "]", "*", "0.1", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.Sign.main": [[92, 197], ["torchvision.transforms.Compose", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader", "torchvision.datasets.MNIST", "numpy.array", "range", "torch.utils.data.DataLoader", "Sign.autoencoder", "torch.nn.BCELoss", "torch.optim.Adam", "range", "numpy.random.seed", "numpy.random.permutation", "autoencoder.parameters", "print", "Sign.adjust_learning_rate", "enumerate", "torchvision.transforms.ToTensor", "torchvision.transforms.Lambda", "torchvision.transforms.Lambda", "numpy.where", "numpy.concatenate", "torch.cat", "torch.autograd.Variable.view", "torch.autograd.Variable", "autoencoder.", "nn.BCELoss.", "torch.optim.Adam.zero_grad", "criterion.backward", "torch.optim.Adam.step", "cal_map.compress", "cal_map.calculate_map", "print", "torch.autograd.Variable.size", "list", "list", "enumerate", "numpy.vstack", "numpy.hstack", "utilscluster.plot_latent_variable3d", "Sign.min_max_normalization", "Sign.tensor_round", "torch.autograd.Variable.view", "torch.autograd.Variable", "autoencoder.", "list.extend", "list.append", "torch.autograd.Variable.size", "qz.cpu().data.numpy", "qz.cpu"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.adjust_learning_rate", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash.backward", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.compress", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_map", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.utilscluster.plot_latent_variable3d", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.min_max_normalization", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.tensor_round"], ["", "", "def", "main", "(", ")", ":", "\n", "\n", "    ", "img_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Lambda", "(", "lambda", "tensor", ":", "min_max_normalization", "(", "tensor", ",", "0", ",", "1", ")", ")", ",", "\n", "transforms", ".", "Lambda", "(", "lambda", "tensor", ":", "tensor_round", "(", "tensor", ")", ")", "\n", "]", ")", "\n", "\n", "\n", "dataset", "=", "MNIST", "(", "'./data'", ",", "train", "=", "True", ",", "transform", "=", "img_transform", ",", "download", "=", "True", ")", "\n", "train_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "testset", "=", "MNIST", "(", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "img_transform", ",", "download", "=", "True", ")", "\n", "testloader", "=", "DataLoader", "(", "testset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n", "# visualize the distributions of the continuous feature U over 5,000 images", "\n", "visuadata", "=", "MNIST", "(", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "img_transform", ",", "download", "=", "True", ")", "\n", "X", "=", "dataset", ".", "data", "\n", "L", "=", "np", ".", "array", "(", "dataset", ".", "targets", ")", "\n", "\n", "first", "=", "True", "\n", "\n", "for", "label", "in", "range", "(", "10", ")", ":", "\n", "        ", "index", "=", "np", ".", "where", "(", "L", "==", "label", ")", "[", "0", "]", "\n", "\n", "N", "=", "index", ".", "shape", "[", "0", "]", "\n", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "N", ")", "\n", "index", "=", "index", "[", "perm", "]", "\n", "\n", "data", "=", "X", "[", "index", "[", "0", ":", "500", "]", "]", "\n", "labels", "=", "L", "[", "index", "[", "0", ":", "500", "]", "]", "\n", "if", "first", ":", "\n", "            ", "visualization_L", "=", "labels", "\n", "visualization_data", "=", "data", "\n", "", "else", ":", "\n", "            ", "visualization_L", "=", "np", ".", "concatenate", "(", "(", "visualization_L", ",", "labels", ")", ")", "\n", "visualization_data", "=", "torch", ".", "cat", "(", "(", "visualization_data", ",", "data", ")", ")", "\n", "\n", "\n", "", "first", "=", "False", "\n", "\n", "visuadata", ".", "data", "=", "visualization_data", "\n", "visuadata", ".", "targets", "=", "visualization_L", "\n", "\n", "# Data Loader", "\n", "", "visualization_loader", "=", "DataLoader", "(", "dataset", "=", "visuadata", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ")", "\n", "\n", "\n", "model", "=", "autoencoder", "(", "encode_length", "=", "encode_length", ")", "\n", "criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ",", "weight_decay", "=", "1e-5", ")", "\n", "\n", "\n", "for", "epoch", "in", "range", "(", "num_epochs", ")", ":", "\n", "        ", "print", "(", "'--------training epoch {}--------'", ".", "format", "(", "epoch", ")", ")", "\n", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", "\n", "\n", "# train the model using SGD        ", "\n", "for", "i", ",", "(", "img", ",", "_", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "img", "=", "img", ".", "view", "(", "img", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "img", "=", "Variable", "(", "img", ")", "\n", "\n", "# ===================forward=====================", "\n", "output", ",", "_", ",", "_", "=", "model", "(", "img", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "img", ")", "#BCE reconstruction loss ", "\n", "# ===================backward====================", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Test the Model using testset            ", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "1", "==", "0", ":", "\n", "\n", "\n", "            ", "'''\n            Calculate the mAP over test set            \n            '''", "\n", "\n", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "=", "compress", "(", "train_loader", ",", "testloader", ",", "model", ")", "\n", "result_map", "=", "calculate_map", "(", "qB", "=", "queryB", ",", "rB", "=", "retrievalB", ",", "queryL", "=", "queryL", ",", "retrievalL", "=", "retrievalL", ")", "\n", "print", "(", "'---{}_mAP: {}---'", ".", "format", "(", "name", ",", "result_map", ")", ")", "\n", "\n", "\n", "\n", "'''\n            visulization of latent variable over 5,000 images\n            In this setting, we set encode_length = 3            \n            '''", "\n", "if", "encode_length", "==", "3", ":", "\n", "                ", "z_buf", "=", "list", "(", "[", "]", ")", "\n", "label_buf", "=", "list", "(", "[", "]", ")", "\n", "for", "ii", ",", "(", "img", ",", "labelb", ")", "in", "enumerate", "(", "visualization_loader", ")", ":", "\n", "                    ", "img", "=", "img", ".", "view", "(", "img", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "img", "=", "Variable", "(", "img", ")", "\n", "# ===================forward=====================", "\n", "_", ",", "qz", ",", "_", "=", "model", "(", "img", ")", "\n", "z_buf", ".", "extend", "(", "qz", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "label_buf", ".", "append", "(", "labelb", ")", "\n", "", "X", "=", "np", ".", "vstack", "(", "z_buf", ")", "\n", "Y", "=", "np", ".", "hstack", "(", "label_buf", ")", "\n", "plot_latent_variable3d", "(", "X", ",", "Y", ",", "epoch", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.cal_map.extractab": [[6, 22], ["list", "list", "enumerate", "numpy.array", "numpy.array", "data.view.view", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "np.array.extend", "data.view.size", "torch.sign.cpu().data.numpy", "H.cpu().data.numpy", "torch.sign.cpu", "H.cpu"], "function", ["None"], ["def", "extractab", "(", "test", ",", "model", ",", "classes", "=", "10", ")", ":", "\n", "\n", "    ", "queryB", "=", "list", "(", "[", "]", ")", "\n", "queryH", "=", "list", "(", "[", "]", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "test", ")", ":", "\n", "        ", "data", "=", "data", ".", "view", "(", "data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "var_data", "=", "Variable", "(", "data", ")", "\n", "_", ",", "H", ",", "_", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "queryB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "queryH", ".", "extend", "(", "H", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "\n", "\n", "", "queryB", "=", "np", ".", "array", "(", "queryB", ")", "\n", "queryH", "=", "np", ".", "array", "(", "queryH", ")", "\n", "return", "queryB", ",", "queryH", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.cal_map.extractab1": [[23, 39], ["list", "list", "enumerate", "numpy.array", "numpy.array", "data.view.view", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "np.array.extend", "data.view.size", "torch.sign.cpu().data.numpy", "H.cpu().data.numpy", "torch.sign.cpu", "H.cpu"], "function", ["None"], ["", "def", "extractab1", "(", "test", ",", "model", ",", "classes", "=", "10", ")", ":", "\n", "\n", "    ", "queryB", "=", "list", "(", "[", "]", ")", "\n", "queryH", "=", "list", "(", "[", "]", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "test", ")", ":", "\n", "        ", "data", "=", "data", ".", "view", "(", "data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "var_data", "=", "Variable", "(", "data", ")", "\n", "_", ",", "H", ",", "_", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "queryB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "queryH", ".", "extend", "(", "H", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "\n", "\n", "", "queryB", "=", "np", ".", "array", "(", "queryB", ")", "\n", "queryH", "=", "np", ".", "array", "(", "queryH", ")", "\n", "return", "queryB", ",", "queryH", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.cal_map.compress": [[40, 68], ["list", "list", "enumerate", "list", "list", "enumerate", "numpy.array", "numpy.array", "data.view.view", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "list.extend", "data.view.view", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "list.extend", "numpy.eye", "numpy.eye", "data.view.size", "torch.sign.cpu().data.numpy", "data.view.size", "torch.sign.cpu().data.numpy", "numpy.array", "numpy.array", "torch.sign.cpu", "torch.sign.cpu"], "function", ["None"], ["", "def", "compress", "(", "train", ",", "test", ",", "model", ",", "classes", "=", "10", ")", ":", "\n", "    ", "retrievalB", "=", "list", "(", "[", "]", ")", "\n", "retrievalL", "=", "list", "(", "[", "]", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "train", ")", ":", "\n", "        ", "data", "=", "data", ".", "view", "(", "data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "var_data", "=", "Variable", "(", "data", ")", "\n", "\n", "_", ",", "H", ",", "_", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "retrievalB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "retrievalL", ".", "extend", "(", "target", ")", "\n", "\n", "", "queryB", "=", "list", "(", "[", "]", ")", "\n", "queryL", "=", "list", "(", "[", "]", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "test", ")", ":", "\n", "        ", "data", "=", "data", ".", "view", "(", "data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "var_data", "=", "Variable", "(", "data", ")", "\n", "_", ",", "H", ",", "_", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "queryB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "queryL", ".", "extend", "(", "target", ")", "\n", "\n", "", "retrievalB", "=", "np", ".", "array", "(", "retrievalB", ")", "\n", "retrievalL", "=", "np", ".", "eye", "(", "classes", ")", "[", "np", ".", "array", "(", "retrievalL", ")", "]", "\n", "\n", "queryB", "=", "np", ".", "array", "(", "queryB", ")", "\n", "queryL", "=", "np", ".", "eye", "(", "classes", ")", "[", "np", ".", "array", "(", "queryL", ")", "]", "\n", "return", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.cal_map.calculate_hamming": [[70, 79], ["numpy.dot", "B2.transpose"], "function", ["None"], ["", "def", "calculate_hamming", "(", "B1", ",", "B2", ")", ":", "\n", "    ", "\"\"\"\n    :param B1:  vector [n]\n    :param B2:  vector [r*n]\n    :return: hamming distance [r]\n    \"\"\"", "\n", "q", "=", "B2", ".", "shape", "[", "1", "]", "# max inner product value", "\n", "distH", "=", "0.5", "*", "(", "q", "-", "np", ".", "dot", "(", "B1", ",", "B2", ".", "transpose", "(", ")", ")", ")", "\n", "return", "distH", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.cal_map.calculate_map": [[81, 110], ["range", "numpy.sum", "cal_map.calculate_hamming", "numpy.argsort", "numpy.linspace", "numpy.mean", "numpy.asarray", "numpy.where", "numpy.dot", "retrievalL.transpose"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_hamming"], ["", "def", "calculate_map", "(", "qB", ",", "rB", ",", "queryL", ",", "retrievalL", ")", ":", "\n", "    ", "\"\"\"\n       :param qB: {-1,+1}^{mxq} query bits\n       :param rB: {-1,+1}^{nxq} retrieval bits\n       :param queryL: {0,1}^{mxl} query label\n       :param retrievalL: {0,1}^{nxl} retrieval label\n       :return:\n    \"\"\"", "\n", "num_query", "=", "queryL", ".", "shape", "[", "0", "]", "\n", "map", "=", "0", "\n", "for", "iter", "in", "range", "(", "num_query", ")", ":", "\n", "# gnd : check if exists any retrieval items with same label", "\n", "        ", "gnd", "=", "(", "np", ".", "dot", "(", "queryL", "[", "iter", ",", ":", "]", ",", "retrievalL", ".", "transpose", "(", ")", ")", ">", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# tsum number of items with same label", "\n", "tsum", "=", "np", ".", "sum", "(", "gnd", ")", "\n", "if", "tsum", "==", "0", ":", "\n", "            ", "continue", "\n", "# sort gnd by hamming dist", "\n", "", "hamm", "=", "calculate_hamming", "(", "qB", "[", "iter", ",", ":", "]", ",", "rB", ")", "\n", "ind", "=", "np", ".", "argsort", "(", "hamm", ")", "\n", "gnd", "=", "gnd", "[", "ind", "]", "\n", "\n", "count", "=", "np", ".", "linspace", "(", "1", ",", "tsum", ",", "tsum", ")", "# [1,2, tsum]", "\n", "tindex", "=", "np", ".", "asarray", "(", "np", ".", "where", "(", "gnd", "==", "1", ")", ")", "+", "1.0", "\n", "map_", "=", "np", ".", "mean", "(", "count", "/", "(", "tindex", ")", ")", "\n", "# print(map_)", "\n", "map", "=", "map", "+", "map_", "\n", "", "map", "=", "map", "/", "num_query", "\n", "return", "map", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.cal_map.calculate_top_map": [[112, 141], ["range", "cal_map.calculate_hamming", "numpy.argsort", "numpy.sum", "numpy.linspace", "numpy.mean", "numpy.asarray", "numpy.where", "numpy.dot", "retrievalL.transpose"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_hamming"], ["", "def", "calculate_top_map", "(", "qB", ",", "rB", ",", "queryL", ",", "retrievalL", ",", "topk", ")", ":", "\n", "    ", "\"\"\"\n    :param qB: {-1,+1}^{mxq} query bits\n    :param rB: {-1,+1}^{nxq} retrieval bits\n    :param queryL: {0,1}^{mxl} query label\n    :param retrievalL: {0,1}^{nxl} retrieval label\n    :param topk:\n    :return:\n    \"\"\"", "\n", "num_query", "=", "queryL", ".", "shape", "[", "0", "]", "\n", "topkmap", "=", "0", "\n", "for", "iter", "in", "range", "(", "num_query", ")", ":", "\n", "        ", "gnd", "=", "(", "np", ".", "dot", "(", "queryL", "[", "iter", ",", ":", "]", ",", "retrievalL", ".", "transpose", "(", ")", ")", ">", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "hamm", "=", "calculate_hamming", "(", "qB", "[", "iter", ",", ":", "]", ",", "rB", ")", "\n", "ind", "=", "np", ".", "argsort", "(", "hamm", ")", "\n", "gnd", "=", "gnd", "[", "ind", "]", "\n", "\n", "tgnd", "=", "gnd", "[", "0", ":", "topk", "]", "\n", "tsum", "=", "np", ".", "sum", "(", "tgnd", ")", "\n", "if", "tsum", "==", "0", ":", "\n", "            ", "continue", "\n", "", "count", "=", "np", ".", "linspace", "(", "1", ",", "tsum", ",", "tsum", ")", "\n", "\n", "tindex", "=", "np", ".", "asarray", "(", "np", ".", "where", "(", "tgnd", "==", "1", ")", ")", "+", "1.0", "\n", "topkmap_", "=", "np", ".", "mean", "(", "count", "/", "(", "tindex", ")", ")", "\n", "# print(topkmap_)", "\n", "topkmap", "=", "topkmap", "+", "topkmap_", "\n", "", "topkmap", "=", "topkmap", "/", "num_query", "\n", "return", "topkmap", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.cal_map.mean_average_precision": [[143, 169], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.sign", "numpy.sign", "numpy.dot", "numpy.argsort", "range", "numpy.mean", "numpy.sum", "numpy.cumsum", "numpy.array", "numpy.sum", "np.cumsum.astype", "numpy.arange", "APx.append", "numpy.sum"], "function", ["None"], ["", "def", "mean_average_precision", "(", "params", ")", ":", "\n", "    ", "database_code", "=", "np", ".", "array", "(", "params", "[", "'database_code'", "]", ")", "\n", "validation_code", "=", "np", ".", "array", "(", "params", "[", "'validation_code'", "]", ")", "\n", "database_labels", "=", "np", ".", "array", "(", "params", "[", "'database_labels'", "]", ")", "\n", "validation_labels", "=", "np", ".", "array", "(", "params", "[", "'validation_labels'", "]", ")", "\n", "R", "=", "params", "[", "'R'", "]", "\n", "query_num", "=", "validation_code", ".", "shape", "[", "0", "]", "\n", "database_code", "=", "np", ".", "sign", "(", "database_code", ")", "\n", "validation_code", "=", "np", ".", "sign", "(", "validation_code", ")", "\n", "\n", "sim", "=", "np", ".", "dot", "(", "database_code", ",", "validation_code", ".", "T", ")", "\n", "ids", "=", "np", ".", "argsort", "(", "-", "sim", ",", "axis", "=", "0", ")", "\n", "APx", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "query_num", ")", ":", "\n", "        ", "label", "=", "validation_labels", "[", "i", ",", ":", "]", "\n", "label", "[", "label", "==", "0", "]", "=", "-", "1", "\n", "idx", "=", "ids", "[", ":", ",", "i", "]", "\n", "imatch", "=", "np", ".", "sum", "(", "database_labels", "[", "idx", "[", "0", ":", "R", "]", ",", ":", "]", "==", "label", ",", "axis", "=", "1", ")", ">", "0", "\n", "relevant_num", "=", "np", ".", "sum", "(", "imatch", ")", "\n", "Lx", "=", "np", ".", "cumsum", "(", "imatch", ")", "\n", "Px", "=", "Lx", ".", "astype", "(", "float", ")", "/", "np", ".", "arange", "(", "1", ",", "R", "+", "1", ",", "1", ")", "\n", "if", "relevant_num", "!=", "0", ":", "\n", "            ", "APx", ".", "append", "(", "np", ".", "sum", "(", "Px", "*", "imatch", ")", "/", "relevant_num", ")", "\n", "\n", "", "", "return", "np", ".", "mean", "(", "np", ".", "array", "(", "APx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.cal_map.precision": [[195, 236], ["np.asarray.cpu().numpy", "numpy.asarray", "trn_label.cpu().numpy.cpu().numpy", "np.asarray.cpu().numpy", "numpy.asarray", "tst_label.cpu().numpy.cpu().numpy", "range", "numpy.zeros", "numpy.zeros", "numpy.arange", "numpy.zeros", "range", "print", "numpy.save", "print", "numpy.mean", "print", "numpy.max", "print", "numpy.count_nonzero", "numpy.argsort", "numpy.equal().astype", "numpy.mean", "np.asarray.cpu", "trn_label.cpu().numpy.cpu", "np.asarray.cpu", "tst_label.cpu().numpy.cpu", "numpy.array().repeat", "numpy.concatenate", "numpy.concatenate", "numpy.cumsum", "numpy.sum", "sum", "numpy.cumsum", "numpy.equal", "numpy.array", "numpy.array().repeat", "numpy.random.RandomState().permutation", "numpy.array", "numpy.where", "numpy.random.RandomState", "numpy.where", "numpy.random.RandomState().permutation", "numpy.sort", "numpy.random.RandomState", "numpy.where"], "function", ["None"], ["", "def", "precision", "(", "trn_binary", ",", "trn_label", ",", "tst_binary", ",", "tst_label", ")", ":", "\n", "    ", "trn_binary", "=", "trn_binary", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "trn_binary", "=", "np", ".", "asarray", "(", "trn_binary", ",", "np", ".", "int32", ")", "\n", "trn_label", "=", "trn_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "tst_binary", "=", "tst_binary", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "tst_binary", "=", "np", ".", "asarray", "(", "tst_binary", ",", "np", ".", "int32", ")", "\n", "tst_label", "=", "tst_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "classes", "=", "np", ".", "max", "(", "tst_label", ")", "+", "1", "\n", "for", "i", "in", "range", "(", "classes", ")", ":", "\n", "        ", "if", "i", "==", "0", ":", "\n", "            ", "tst_sample_binary", "=", "tst_binary", "[", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "i", ")", ".", "permutation", "(", "np", ".", "where", "(", "tst_label", "==", "i", ")", "[", "0", "]", ")", "[", ":", "100", "]", "]", "\n", "tst_sample_label", "=", "np", ".", "array", "(", "[", "i", "]", ")", ".", "repeat", "(", "100", ")", "\n", "continue", "\n", "", "else", ":", "\n", "            ", "tst_sample_binary", "=", "np", ".", "concatenate", "(", "[", "tst_sample_binary", ",", "tst_binary", "[", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "i", ")", ".", "permutation", "(", "np", ".", "where", "(", "tst_label", "==", "i", ")", "[", "0", "]", ")", "[", ":", "100", "]", "]", "]", ")", "\n", "tst_sample_label", "=", "np", ".", "concatenate", "(", "[", "tst_sample_label", ",", "np", ".", "array", "(", "[", "i", "]", ")", ".", "repeat", "(", "100", ")", "]", ")", "\n", "", "", "query_times", "=", "tst_sample_binary", ".", "shape", "[", "0", "]", "\n", "trainset_len", "=", "trn_binary", ".", "shape", "[", "0", "]", "\n", "AP", "=", "np", ".", "zeros", "(", "query_times", ")", "\n", "precision_radius", "=", "np", ".", "zeros", "(", "query_times", ")", "\n", "Ns", "=", "np", ".", "arange", "(", "1", ",", "trainset_len", "+", "1", ")", "\n", "sum_tp", "=", "np", ".", "zeros", "(", "trainset_len", ")", "\n", "for", "i", "in", "range", "(", "query_times", ")", ":", "\n", "        ", "print", "(", "'Query '", ",", "i", "+", "1", ")", "\n", "query_label", "=", "tst_sample_label", "[", "i", "]", "\n", "query_binary", "=", "tst_sample_binary", "[", "i", ",", ":", "]", "\n", "query_result", "=", "np", ".", "count_nonzero", "(", "query_binary", "!=", "trn_binary", ",", "axis", "=", "1", ")", "#don't need to divide binary length", "\n", "sort_indices", "=", "np", ".", "argsort", "(", "query_result", ")", "\n", "buffer_yes", "=", "np", ".", "equal", "(", "query_label", ",", "trn_label", "[", "sort_indices", "]", ")", ".", "astype", "(", "int", ")", "\n", "P", "=", "np", ".", "cumsum", "(", "buffer_yes", ")", "/", "Ns", "\n", "precision_radius", "[", "i", "]", "=", "P", "[", "np", ".", "where", "(", "np", ".", "sort", "(", "query_result", ")", ">", "2", ")", "[", "0", "]", "[", "0", "]", "-", "1", "]", "\n", "AP", "[", "i", "]", "=", "np", ".", "sum", "(", "P", "*", "buffer_yes", ")", "/", "sum", "(", "buffer_yes", ")", "\n", "sum_tp", "=", "sum_tp", "+", "np", ".", "cumsum", "(", "buffer_yes", ")", "\n", "", "precision_at_k", "=", "sum_tp", "/", "Ns", "/", "query_times", "\n", "index", "=", "[", "100", ",", "200", ",", "400", ",", "600", ",", "800", ",", "1000", "]", "\n", "index", "=", "[", "i", "-", "1", "for", "i", "in", "index", "]", "\n", "print", "(", "'precision at k:'", ",", "precision_at_k", "[", "index", "]", ")", "\n", "np", ".", "save", "(", "'precision_at_k'", ",", "precision_at_k", ")", "\n", "print", "(", "'precision within Hamming radius 2:'", ",", "np", ".", "mean", "(", "precision_radius", ")", ")", "\n", "map", "=", "np", ".", "mean", "(", "AP", ")", "\n", "print", "(", "'mAP:'", ",", "map", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.cal_map.compute_precision_at_k": [[243, 263], ["query_labels.size", "relevances.sum().type", "true_positive.div_.div_", "torch.mean", "query_labels.unsqueeze().expand", "torch.cat", "torch.cat().type", "query_labels.unsqueeze().expand().type", "torch.index_select().unsqueeze_", "torch.index_select().unsqueeze_", "relevances.sum", "query_labels.unsqueeze", "range", "range", "torch.cat", "query_labels.unsqueeze().expand", "torch.index_select", "torch.index_select", "torch.cat().type.size", "query_labels.unsqueeze"], "function", ["None"], ["", "def", "compute_precision_at_k", "(", "retrieved_indices", ",", "query_labels", ",", "doc_labels", ",", "topK", ",", "is_single_label", ")", ":", "\n", "    ", "n_test", "=", "query_labels", ".", "size", "(", "0", ")", "\n", "\n", "Indices", "=", "retrieved_indices", "[", ":", ",", ":", "topK", "]", "\n", "if", "is_single_label", ":", "\n", "        ", "test_labels", "=", "query_labels", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "n_test", ",", "topK", ")", "\n", "topTrainLabels", "=", "[", "torch", ".", "index_select", "(", "doc_labels", ",", "0", ",", "Indices", "[", "idx", "]", ")", ".", "unsqueeze_", "(", "0", ")", "for", "idx", "in", "range", "(", "0", ",", "n_test", ")", "]", "\n", "topTrainLabels", "=", "torch", ".", "cat", "(", "topTrainLabels", ",", "dim", "=", "0", ")", "\n", "relevances", "=", "(", "test_labels", "==", "topTrainLabels", ")", ".", "type", "(", "torch", ".", "cuda", ".", "ShortTensor", ")", "\n", "", "else", ":", "\n", "        ", "topTrainLabels", "=", "[", "torch", ".", "index_select", "(", "doc_labels", ",", "0", ",", "Indices", "[", "idx", "]", ")", ".", "unsqueeze_", "(", "0", ")", "for", "idx", "in", "range", "(", "0", ",", "n_test", ")", "]", "\n", "topTrainLabels", "=", "torch", ".", "cat", "(", "topTrainLabels", ",", "dim", "=", "0", ")", ".", "type", "(", "torch", ".", "cuda", ".", "ShortTensor", ")", "\n", "test_labels", "=", "query_labels", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "n_test", ",", "topK", ",", "topTrainLabels", ".", "size", "(", "-", "1", ")", ")", ".", "type", "(", "torch", ".", "cuda", ".", "ShortTensor", ")", "\n", "relevances", "=", "(", "topTrainLabels", "&", "test_labels", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "relevances", "=", "(", "relevances", ">", "0", ")", ".", "type", "(", "torch", ".", "cuda", ".", "ShortTensor", ")", "\n", "\n", "", "true_positive", "=", "relevances", ".", "sum", "(", "dim", "=", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "true_positive", "=", "true_positive", ".", "div_", "(", "100", ")", "\n", "prec_at_k", "=", "torch", ".", "mean", "(", "true_positive", ")", "\n", "return", "prec_at_k", "\n", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.SignReg.hash.forward": [[41, 47], ["torch.sign", "ctx.save_for_backward"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ")", ":", "\n", "        ", "B_code", "=", "torch", ".", "sign", "(", "input", ")", "\n", "ctx", ".", "save_for_backward", "(", "input", ",", "B_code", ")", "\n", "# ctx.save_for_backward(input)", "\n", "return", "B_code", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.SignReg.hash.backward": [[48, 57], ["input.clone", "input.clone.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "input", ",", "B_code", "=", "ctx", ".", "saved_tensors", "\n", "uu", "=", "input", ".", "clone", "(", ")", "\n", "size", "=", "uu", ".", "size", "(", ")", "\n", "extrgrad", "=", "(", "uu", "-", "B_code", ")", "/", "(", "size", "[", "0", "]", "*", "size", "[", "1", "]", ")", "\n", "grad_output", "=", "grad_output", "+", "gamma", "*", "extrgrad", "\n", "\n", "return", "grad_output", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.SignReg.autoencoder.__init__": [[70, 83], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.manual_seed", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encode_length", ")", ":", "\n", "        ", "super", "(", "autoencoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "28", "*", "28", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "encode_length", ")", "\n", ")", "\n", "torch", ".", "manual_seed", "(", "1", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "encode_length", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "28", "*", "28", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.SignReg.autoencoder.forward": [[85, 90], ["SignReg.autoencoder.encoder", "SignReg.hash_layer", "SignReg.autoencoder.decoder"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash_layer"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "encoder", "(", "x", ")", "\n", "b", "=", "hash_layer", "(", "h", ")", "\n", "x", "=", "self", ".", "decoder", "(", "b", ")", "\n", "return", "x", ",", "h", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.SignReg.to_img": [[21, 24], ["x.view.view", "x.view.size"], "function", ["None"], ["def", "to_img", "(", "x", ")", ":", "\n", "    ", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "28", ",", "28", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.SignReg.min_max_normalization": [[26, 33], ["tensor.min", "tensor.max"], "function", ["None"], ["", "def", "min_max_normalization", "(", "tensor", ",", "min_value", ",", "max_value", ")", ":", "\n", "    ", "min_tensor", "=", "tensor", ".", "min", "(", ")", "\n", "tensor", "=", "(", "tensor", "-", "min_tensor", ")", "\n", "max_tensor", "=", "tensor", ".", "max", "(", ")", "\n", "tensor", "=", "tensor", "/", "max_tensor", "\n", "tensor", "=", "tensor", "*", "(", "max_value", "-", "min_value", ")", "+", "min_value", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.SignReg.tensor_round": [[35, 37], ["torch.round"], "function", ["None"], ["", "def", "tensor_round", "(", "tensor", ")", ":", "\n", "    ", "return", "torch", ".", "round", "(", "tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.SignReg.hash_layer": [[59, 61], ["hash.apply"], "function", ["None"], ["", "", "def", "hash_layer", "(", "input", ")", ":", "\n", "    ", "return", "hash", ".", "apply", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.SignReg.adjust_learning_rate": [[63, 68], ["None"], "function", ["None"], ["", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", ":", "\n", "\t", "update_list", "=", "[", "60", ",", "80", "]", "\n", "if", "epoch", "in", "update_list", ":", "\n", "\t\t", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "\t\t\t", "param_group", "[", "'lr'", "]", "=", "param_group", "[", "'lr'", "]", "*", "0.1", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.SignReg.main": [[92, 202], ["torchvision.transforms.Compose", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader", "torchvision.datasets.MNIST", "numpy.array", "range", "torch.utils.data.DataLoader", "SignReg.autoencoder", "torch.nn.BCELoss", "torch.optim.Adam", "range", "numpy.random.seed", "numpy.random.permutation", "autoencoder.parameters", "print", "SignReg.adjust_learning_rate", "enumerate", "torchvision.transforms.ToTensor", "torchvision.transforms.Lambda", "torchvision.transforms.Lambda", "numpy.where", "numpy.concatenate", "torch.cat", "torch.autograd.Variable.view", "torch.autograd.Variable", "autoencoder.", "nn.BCELoss.", "torch.autograd.Variable", "torch.transpose", "torch.optim.Adam.zero_grad", "loss.backward", "torch.optim.Adam.step", "cal_map.compress", "cal_map.calculate_map", "print", "torch.autograd.Variable.size", "torch.ones", "torch.mean", "list", "list", "enumerate", "numpy.vstack", "numpy.hstack", "utilscluster.plot_latent_variable3d", "SignReg.min_max_normalization", "SignReg.tensor_round", "h.size", "torch.pow", "torch.autograd.Variable.view", "torch.autograd.Variable", "autoencoder.", "list.extend", "list.append", "torch.autograd.Variable.size", "qz.cpu().data.numpy", "torch.transpose.mm", "h.size", "qz.cpu"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.adjust_learning_rate", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash.backward", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.compress", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_map", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.utilscluster.plot_latent_variable3d", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.min_max_normalization", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.tensor_round"], ["", "", "def", "main", "(", ")", ":", "\n", "\n", "    ", "img_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Lambda", "(", "lambda", "tensor", ":", "min_max_normalization", "(", "tensor", ",", "0", ",", "1", ")", ")", ",", "\n", "transforms", ".", "Lambda", "(", "lambda", "tensor", ":", "tensor_round", "(", "tensor", ")", ")", "\n", "]", ")", "\n", "\n", "\n", "dataset", "=", "MNIST", "(", "'./data'", ",", "train", "=", "True", ",", "transform", "=", "img_transform", ",", "download", "=", "True", ")", "\n", "train_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "testset", "=", "MNIST", "(", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "img_transform", ",", "download", "=", "True", ")", "\n", "testloader", "=", "DataLoader", "(", "testset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n", "# visualize the distributions of the continuous feature U over 5,000 images", "\n", "visuadata", "=", "MNIST", "(", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "img_transform", ",", "download", "=", "True", ")", "\n", "X", "=", "dataset", ".", "data", "\n", "L", "=", "np", ".", "array", "(", "dataset", ".", "targets", ")", "\n", "\n", "first", "=", "True", "\n", "\n", "for", "label", "in", "range", "(", "10", ")", ":", "\n", "        ", "index", "=", "np", ".", "where", "(", "L", "==", "label", ")", "[", "0", "]", "\n", "\n", "N", "=", "index", ".", "shape", "[", "0", "]", "\n", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "N", ")", "\n", "index", "=", "index", "[", "perm", "]", "\n", "\n", "data", "=", "X", "[", "index", "[", "0", ":", "500", "]", "]", "\n", "labels", "=", "L", "[", "index", "[", "0", ":", "500", "]", "]", "\n", "if", "first", ":", "\n", "            ", "visualization_L", "=", "labels", "\n", "visualization_data", "=", "data", "\n", "", "else", ":", "\n", "            ", "visualization_L", "=", "np", ".", "concatenate", "(", "(", "visualization_L", ",", "labels", ")", ")", "\n", "visualization_data", "=", "torch", ".", "cat", "(", "(", "visualization_data", ",", "data", ")", ")", "\n", "\n", "\n", "", "first", "=", "False", "\n", "\n", "visuadata", ".", "data", "=", "visualization_data", "\n", "visuadata", ".", "targets", "=", "visualization_L", "\n", "\n", "# Data Loader", "\n", "", "visualization_loader", "=", "DataLoader", "(", "dataset", "=", "visuadata", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ")", "\n", "\n", "\n", "\n", "model", "=", "autoencoder", "(", "encode_length", "=", "encode_length", ")", "\n", "criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ",", "weight_decay", "=", "1e-5", ")", "\n", "\n", "\n", "for", "epoch", "in", "range", "(", "num_epochs", ")", ":", "\n", "        ", "print", "(", "'--------training epoch {}--------'", ".", "format", "(", "epoch", ")", ")", "\n", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", "\n", "\n", "# train the model using SGD        ", "\n", "for", "i", ",", "(", "img", ",", "_", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "img", "=", "img", ".", "view", "(", "img", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "img", "=", "Variable", "(", "img", ")", "\n", "\n", "# ===================forward=====================", "\n", "output", ",", "h", ",", "b", "=", "model", "(", "img", ")", "\n", "loss_BCE", "=", "criterion", "(", "output", ",", "img", ")", "\n", "onesvec", "=", "Variable", "(", "torch", ".", "ones", "(", "h", ".", "size", "(", "0", ")", ",", "1", ")", ")", "\n", "Tcode", "=", "torch", ".", "transpose", "(", "b", ",", "1", ",", "0", ")", "\n", "loss_reg", "=", "torch", ".", "mean", "(", "torch", ".", "pow", "(", "Tcode", ".", "mm", "(", "onesvec", ")", "/", "h", ".", "size", "(", "0", ")", ",", "2", ")", ")", "/", "2", "\n", "loss", "=", "loss_BCE", "+", "Alpha", "*", "loss_reg", "\n", "# ===================backward====================", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Test the Model using testset            ", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "1", "==", "0", ":", "\n", "\n", "\n", "            ", "'''\n            Calculate the mAP over test set            \n            '''", "\n", "\n", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "=", "compress", "(", "train_loader", ",", "testloader", ",", "model", ")", "\n", "result_map", "=", "calculate_map", "(", "qB", "=", "queryB", ",", "rB", "=", "retrievalB", ",", "queryL", "=", "queryL", ",", "retrievalL", "=", "retrievalL", ")", "\n", "print", "(", "'---{}_mAP: {}---'", ".", "format", "(", "name", ",", "result_map", ")", ")", "\n", "\n", "\n", "\n", "'''\n            visulization of latent variable over 5,000 images\n            In this setting, we set encode_length = 3            \n            '''", "\n", "if", "encode_length", "==", "3", ":", "\n", "                ", "z_buf", "=", "list", "(", "[", "]", ")", "\n", "label_buf", "=", "list", "(", "[", "]", ")", "\n", "for", "ii", ",", "(", "img", ",", "labelb", ")", "in", "enumerate", "(", "visualization_loader", ")", ":", "\n", "                    ", "img", "=", "img", ".", "view", "(", "img", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "img", "=", "Variable", "(", "img", ")", "\n", "# ===================forward=====================", "\n", "_", ",", "qz", ",", "_", "=", "model", "(", "img", ")", "\n", "z_buf", ".", "extend", "(", "qz", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "label_buf", ".", "append", "(", "labelb", ")", "\n", "", "X", "=", "np", ".", "vstack", "(", "z_buf", ")", "\n", "Y", "=", "np", ".", "hstack", "(", "label_buf", ")", "\n", "plot_latent_variable3d", "(", "X", ",", "Y", ",", "epoch", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.utilscluster.plot_latent_variable3d": [[6, 29], ["matplotlib.figure", "matplotlib.axes", "plt.axes.view_init", "plt.axes.grid", "plt.axes.w_xaxis.set_pane_color", "plt.axes.w_yaxis.set_pane_color", "plt.axes.w_zaxis.set_pane_color", "enumerate", "matplotlib.xlim", "matplotlib.ylim", "plt.axes.set_zlim3d", "matplotlib.xticks", "matplotlib.yticks", "plt.axes.set_zticks", "matplotlib.savefig", "matplotlib.show", "numpy.where", "plt.axes.scatter3D", "X[].min", "X[].max", "X[].min", "X[].max", "X[].min", "X[].max"], "function", ["None"], ["def", "plot_latent_variable3d", "(", "X", ",", "Y", ",", "epoch", ",", "name", ")", ":", "\n", "    ", "plt", ".", "figure", "(", "figsize", "=", "(", "16", ",", "11.5", ")", ")", "\n", "ax", "=", "plt", ".", "axes", "(", "projection", "=", "'3d'", ")", "\n", "ax", ".", "view_init", "(", "25", ",", "25", ")", "\n", "\n", "ax", ".", "grid", "(", "False", ")", "\n", "ax", ".", "w_xaxis", ".", "set_pane_color", "(", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "ax", ".", "w_yaxis", ".", "set_pane_color", "(", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "ax", ".", "w_zaxis", ".", "set_pane_color", "(", "(", "1.0", ",", "1.0", ",", "1.0", ",", "1.0", ")", ")", "\n", "\n", "color", "=", "[", "'b'", ",", "'g'", ",", "'r'", ",", "'c'", ",", "'m'", ",", "'y'", ",", "'k'", ",", "'cyan'", ",", "'lime'", ",", "'yellow'", "]", "\n", "for", "l", ",", "c", "in", "enumerate", "(", "color", ")", ":", "\n", "        ", "inds", "=", "np", ".", "where", "(", "Y", "==", "l", ")", "\n", "ax", ".", "scatter3D", "(", "X", "[", "inds", ",", "0", "]", ",", "X", "[", "inds", ",", "1", "]", ",", "X", "[", "inds", ",", "2", "]", ",", "color", "=", "c", ",", "label", "=", "l", ",", "linewidth", "=", "0", ")", "\n", "", "plt", ".", "xlim", "(", "[", "X", "[", ":", ",", "0", "]", ".", "min", "(", ")", "-", "0.1", ",", "X", "[", ":", ",", "0", "]", ".", "max", "(", ")", "+", "0.1", "]", ")", "\n", "plt", ".", "ylim", "(", "[", "X", "[", ":", ",", "1", "]", ".", "min", "(", ")", "-", "0.1", ",", "X", "[", ":", ",", "1", "]", ".", "max", "(", ")", "+", "0.1", "]", ")", "\n", "ax", ".", "set_zlim3d", "(", "[", "X", "[", ":", ",", "2", "]", ".", "min", "(", ")", "-", "0.1", ",", "X", "[", ":", ",", "2", "]", ".", "max", "(", ")", "+", "0.1", "]", ")", "\n", "#    ax.legend()", "\n", "plt", ".", "xticks", "(", "[", "]", ")", "\n", "plt", ".", "yticks", "(", "[", "]", ")", "\n", "ax", ".", "set_zticks", "(", "[", "]", ")", "\n", "plt", ".", "savefig", "(", "'3d_visualization/{}_epoch_{}.pdf'", ".", "format", "(", "name", ",", "epoch", ")", ")", "\n", "plt", ".", "show", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.hash.forward": [[41, 53], ["U.sort", "torch.cat", "torch.zeros().scatter_", "ctx.save_for_backward", "torch.ones", "torch.zeros", "torch.ones", "int", "int"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "U", ")", ":", "\n", "\n", "# Yunqiang for half and half (optimal transport)", "\n", "        ", "_", ",", "index", "=", "U", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "N", ",", "D", "=", "U", ".", "shape", "\n", "B_creat", "=", "torch", ".", "cat", "(", "(", "torch", ".", "ones", "(", "[", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ",", "-", "torch", ".", "ones", "(", "[", "N", "-", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ")", ")", "\n", "B", "=", "torch", ".", "zeros", "(", "U", ".", "shape", ")", ".", "scatter_", "(", "0", ",", "index", ",", "B_creat", ")", "\n", "\n", "ctx", ".", "save_for_backward", "(", "U", ",", "B", ")", "\n", "\n", "return", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.hash.backward": [[54, 62], ["B.numel"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "g", ")", ":", "\n", "        ", "U", ",", "B", "=", "ctx", ".", "saved_tensors", "\n", "add_g", "=", "(", "U", "-", "B", ")", "/", "(", "B", ".", "numel", "(", ")", ")", "\n", "\n", "grad", "=", "g", "+", "gamma", "*", "add_g", "\n", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.autoencoder.__init__": [[75, 88], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.manual_seed", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encode_length", ")", ":", "\n", "        ", "super", "(", "autoencoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "28", "*", "28", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "encode_length", ")", "\n", ")", "\n", "torch", ".", "manual_seed", "(", "1", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "encode_length", ",", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "256", ",", "28", "*", "28", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.autoencoder.forward": [[90, 95], ["BiHalf.autoencoder.encoder", "BiHalf.hash_layer", "BiHalf.autoencoder.decoder"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash_layer"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "encoder", "(", "x", ")", "\n", "b", "=", "hash_layer", "(", "h", ")", "\n", "x", "=", "self", ".", "decoder", "(", "b", ")", "\n", "return", "x", ",", "h", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.to_img": [[21, 24], ["x.view.view", "x.view.size"], "function", ["None"], ["def", "to_img", "(", "x", ")", ":", "\n", "    ", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "1", ",", "28", ",", "28", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.min_max_normalization": [[26, 33], ["tensor.min", "tensor.max"], "function", ["None"], ["", "def", "min_max_normalization", "(", "tensor", ",", "min_value", ",", "max_value", ")", ":", "\n", "    ", "min_tensor", "=", "tensor", ".", "min", "(", ")", "\n", "tensor", "=", "(", "tensor", "-", "min_tensor", ")", "\n", "max_tensor", "=", "tensor", ".", "max", "(", ")", "\n", "tensor", "=", "tensor", "/", "max_tensor", "\n", "tensor", "=", "tensor", "*", "(", "max_value", "-", "min_value", ")", "+", "min_value", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.tensor_round": [[35, 37], ["torch.round"], "function", ["None"], ["", "def", "tensor_round", "(", "tensor", ")", ":", "\n", "    ", "return", "torch", ".", "round", "(", "tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.hash_layer": [[64, 66], ["hash.apply"], "function", ["None"], ["", "", "def", "hash_layer", "(", "input", ")", ":", "\n", "    ", "return", "hash", ".", "apply", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.adjust_learning_rate": [[68, 73], ["None"], "function", ["None"], ["", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", ":", "\n", "\t", "update_list", "=", "[", "60", ",", "80", "]", "\n", "if", "epoch", "in", "update_list", ":", "\n", "\t\t", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "\t\t\t", "param_group", "[", "'lr'", "]", "=", "param_group", "[", "'lr'", "]", "*", "0.1", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.main": [[97, 203], ["torchvision.transforms.Compose", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader", "torchvision.datasets.MNIST", "numpy.array", "range", "torch.utils.data.DataLoader", "BiHalf.autoencoder", "torch.nn.BCELoss", "torch.optim.Adam", "range", "numpy.random.seed", "numpy.random.permutation", "autoencoder.parameters", "print", "BiHalf.adjust_learning_rate", "enumerate", "torchvision.transforms.ToTensor", "torchvision.transforms.Lambda", "torchvision.transforms.Lambda", "numpy.where", "numpy.concatenate", "torch.cat", "torch.autograd.Variable.view", "torch.autograd.Variable", "autoencoder.", "nn.BCELoss.", "torch.optim.Adam.zero_grad", "criterion.backward", "torch.optim.Adam.step", "cal_map.compress", "cal_map.calculate_map", "print", "torch.autograd.Variable.size", "list", "list", "enumerate", "numpy.vstack", "numpy.hstack", "utilscluster.plot_latent_variable3d", "BiHalf.min_max_normalization", "BiHalf.tensor_round", "torch.autograd.Variable.view", "torch.autograd.Variable", "autoencoder.", "list.extend", "list.append", "torch.autograd.Variable.size", "qz.cpu().data.numpy", "qz.cpu"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.adjust_learning_rate", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash.backward", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.compress", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_map", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.utilscluster.plot_latent_variable3d", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.min_max_normalization", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.AutoEncoder.BiHalf.tensor_round"], ["", "", "def", "main", "(", ")", ":", "\n", "\n", "    ", "img_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Lambda", "(", "lambda", "tensor", ":", "min_max_normalization", "(", "tensor", ",", "0", ",", "1", ")", ")", ",", "\n", "transforms", ".", "Lambda", "(", "lambda", "tensor", ":", "tensor_round", "(", "tensor", ")", ")", "\n", "]", ")", "\n", "\n", "\n", "dataset", "=", "MNIST", "(", "'./data'", ",", "train", "=", "True", ",", "transform", "=", "img_transform", ",", "download", "=", "True", ")", "\n", "train_loader", "=", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "testset", "=", "MNIST", "(", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "img_transform", ",", "download", "=", "True", ")", "\n", "testloader", "=", "DataLoader", "(", "testset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n", "# visualize the distributions of the continuous feature U over 5,000 images", "\n", "visuadata", "=", "MNIST", "(", "'./data'", ",", "train", "=", "False", ",", "transform", "=", "img_transform", ",", "download", "=", "True", ")", "\n", "X", "=", "dataset", ".", "data", "\n", "L", "=", "np", ".", "array", "(", "dataset", ".", "targets", ")", "\n", "\n", "first", "=", "True", "\n", "\n", "for", "label", "in", "range", "(", "10", ")", ":", "\n", "        ", "index", "=", "np", ".", "where", "(", "L", "==", "label", ")", "[", "0", "]", "\n", "\n", "N", "=", "index", ".", "shape", "[", "0", "]", "\n", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "N", ")", "\n", "index", "=", "index", "[", "perm", "]", "\n", "\n", "data", "=", "X", "[", "index", "[", "0", ":", "500", "]", "]", "\n", "labels", "=", "L", "[", "index", "[", "0", ":", "500", "]", "]", "\n", "if", "first", ":", "\n", "            ", "visualization_L", "=", "labels", "\n", "visualization_data", "=", "data", "\n", "", "else", ":", "\n", "            ", "visualization_L", "=", "np", ".", "concatenate", "(", "(", "visualization_L", ",", "labels", ")", ")", "\n", "visualization_data", "=", "torch", ".", "cat", "(", "(", "visualization_data", ",", "data", ")", ")", "\n", "\n", "\n", "", "first", "=", "False", "\n", "\n", "visuadata", ".", "data", "=", "visualization_data", "\n", "visuadata", ".", "targets", "=", "visualization_L", "\n", "\n", "# Data Loader", "\n", "", "visualization_loader", "=", "DataLoader", "(", "dataset", "=", "visuadata", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "0", ")", "\n", "\n", "\n", "\n", "model", "=", "autoencoder", "(", "encode_length", "=", "encode_length", ")", "\n", "criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ",", "weight_decay", "=", "1e-5", ")", "\n", "\n", "\n", "for", "epoch", "in", "range", "(", "num_epochs", ")", ":", "\n", "        ", "print", "(", "'--------training epoch {}--------'", ".", "format", "(", "epoch", ")", ")", "\n", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", "\n", "\n", "# train the model using SGD        ", "\n", "for", "i", ",", "(", "img", ",", "_", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "img", "=", "img", ".", "view", "(", "img", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "img", "=", "Variable", "(", "img", ")", "\n", "\n", "# ===================forward=====================", "\n", "output", ",", "_", ",", "_", "=", "model", "(", "img", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "img", ")", "#BCE reconstruction loss ", "\n", "# ===================backward====================", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Test the Model using testset            ", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "1", "==", "0", ":", "\n", "\n", "\n", "            ", "'''\n            Calculate the mAP over test set            \n            '''", "\n", "\n", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "=", "compress", "(", "train_loader", ",", "testloader", ",", "model", ")", "\n", "result_map", "=", "calculate_map", "(", "qB", "=", "queryB", ",", "rB", "=", "retrievalB", ",", "queryL", "=", "queryL", ",", "retrievalL", "=", "retrievalL", ")", "\n", "print", "(", "'---{}_mAP: {}---'", ".", "format", "(", "name", ",", "result_map", ")", ")", "\n", "\n", "\n", "\n", "'''\n            visulization of latent variable over 5,000 images\n            In this setting, we set encode_length = 3            \n            '''", "\n", "if", "encode_length", "==", "3", ":", "\n", "                ", "z_buf", "=", "list", "(", "[", "]", ")", "\n", "label_buf", "=", "list", "(", "[", "]", ")", "\n", "for", "ii", ",", "(", "img", ",", "labelb", ")", "in", "enumerate", "(", "visualization_loader", ")", ":", "\n", "                    ", "img", "=", "img", ".", "view", "(", "img", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "img", "=", "Variable", "(", "img", ")", "\n", "# ===================forward=====================", "\n", "_", ",", "qz", ",", "_", "=", "model", "(", "img", ")", "\n", "z_buf", ".", "extend", "(", "qz", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "label_buf", ".", "append", "(", "labelb", ")", "\n", "", "X", "=", "np", ".", "vstack", "(", "z_buf", ")", "\n", "Y", "=", "np", ".", "hstack", "(", "label_buf", ")", "\n", "plot_latent_variable3d", "(", "X", ",", "Y", ",", "epoch", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.cal_map.extractab": [[6, 21], ["list", "list", "enumerate", "numpy.array", "numpy.array", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "np.array.extend", "data.cuda", "torch.sign.cpu().data.numpy", "H.cpu().data.numpy", "torch.sign.cpu", "H.cpu"], "function", ["None"], ["def", "extractab", "(", "test", ",", "model", ",", "classes", "=", "10", ")", ":", "\n", "\n", "    ", "queryB", "=", "list", "(", "[", "]", ")", "\n", "queryH", "=", "list", "(", "[", "]", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "test", ")", ":", "\n", "        ", "data", "=", "data", ".", "view", "(", "data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "var_data", "=", "Variable", "(", "data", ")", "\n", "_", ",", "H", ",", "_", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "queryB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "queryH", ".", "extend", "(", "H", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "\n", "\n", "", "queryB", "=", "np", ".", "array", "(", "queryB", ")", "\n", "queryH", "=", "np", ".", "array", "(", "queryH", ")", "\n", "return", "queryB", ",", "queryH", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.cal_map.extractab1": [[22, 37], ["list", "list", "enumerate", "numpy.array", "numpy.array", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "np.array.extend", "data.cuda", "torch.sign.cpu().data.numpy", "H.cpu().data.numpy", "torch.sign.cpu", "H.cpu"], "function", ["None"], ["\n", "", "def", "extractab1", "(", "test", ",", "model", ",", "classes", "=", "10", ")", ":", "\n", "\n", "    ", "queryB", "=", "list", "(", "[", "]", ")", "\n", "queryH", "=", "list", "(", "[", "]", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "test", ")", ":", "\n", "        ", "data", "=", "data", ".", "view", "(", "data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "var_data", "=", "Variable", "(", "data", ")", "\n", "_", ",", "H", ",", "_", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "queryB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "queryH", ".", "extend", "(", "H", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "\n", "\n", "", "queryB", "=", "np", ".", "array", "(", "queryB", ")", "\n", "queryH", "=", "np", ".", "array", "(", "queryH", ")", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.cal_map.compress": [[38, 63], ["list", "list", "enumerate", "list", "list", "enumerate", "numpy.array", "numpy.array", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "list.extend", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "list.extend", "numpy.eye", "numpy.eye", "data.cuda", "torch.sign.cpu().data.numpy", "data.cuda", "torch.sign.cpu().data.numpy", "numpy.array", "numpy.array", "torch.sign.cpu", "torch.sign.cpu"], "function", ["None"], ["return", "queryB", ",", "queryH", "\n", "\n", "", "def", "compress", "(", "train", ",", "test", ",", "model", ",", "classes", "=", "10", ")", ":", "\n", "    ", "retrievalB", "=", "list", "(", "[", "]", ")", "\n", "retrievalL", "=", "list", "(", "[", "]", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "train", ")", ":", "\n", "        ", "data", "=", "data", ".", "view", "(", "data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "var_data", "=", "Variable", "(", "data", ")", "\n", "\n", "_", ",", "H", ",", "_", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "retrievalB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "retrievalL", ".", "extend", "(", "target", ")", "\n", "\n", "", "queryB", "=", "list", "(", "[", "]", ")", "\n", "queryL", "=", "list", "(", "[", "]", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "test", ")", ":", "\n", "        ", "data", "=", "data", ".", "view", "(", "data", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "var_data", "=", "Variable", "(", "data", ")", "\n", "_", ",", "H", ",", "_", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "queryB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "queryL", ".", "extend", "(", "target", ")", "\n", "\n", "", "retrievalB", "=", "np", ".", "array", "(", "retrievalB", ")", "\n", "retrievalL", "=", "np", ".", "eye", "(", "classes", ")", "[", "np", ".", "array", "(", "retrievalL", ")", "]", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.cal_map.calculate_hamming": [[65, 74], ["numpy.dot", "B2.transpose"], "function", ["None"], ["queryB", "=", "np", ".", "array", "(", "queryB", ")", "\n", "queryL", "=", "np", ".", "eye", "(", "classes", ")", "[", "np", ".", "array", "(", "queryL", ")", "]", "\n", "return", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "\n", "\n", "\n", "", "def", "calculate_hamming", "(", "B1", ",", "B2", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.cal_map.calculate_map": [[76, 105], ["range", "numpy.sum", "cal_map.calculate_hamming", "numpy.argsort", "numpy.linspace", "numpy.mean", "numpy.asarray", "numpy.where", "numpy.dot", "retrievalL.transpose"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_hamming"], ["q", "=", "B2", ".", "shape", "[", "1", "]", "# max inner product value", "\n", "distH", "=", "0.5", "*", "(", "q", "-", "np", ".", "dot", "(", "B1", ",", "B2", ".", "transpose", "(", ")", ")", ")", "\n", "return", "distH", "\n", "\n", "\n", "", "def", "calculate_map", "(", "qB", ",", "rB", ",", "queryL", ",", "retrievalL", ")", ":", "\n", "    ", "\"\"\"\n       :param qB: {-1,+1}^{mxq} query bits\n       :param rB: {-1,+1}^{nxq} retrieval bits\n       :param queryL: {0,1}^{mxl} query label\n       :param retrievalL: {0,1}^{nxl} retrieval label\n       :return:\n    \"\"\"", "\n", "num_query", "=", "queryL", ".", "shape", "[", "0", "]", "\n", "map", "=", "0", "\n", "for", "iter", "in", "range", "(", "num_query", ")", ":", "\n", "# gnd : check if exists any retrieval items with same label", "\n", "        ", "gnd", "=", "(", "np", ".", "dot", "(", "queryL", "[", "iter", ",", ":", "]", ",", "retrievalL", ".", "transpose", "(", ")", ")", ">", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# tsum number of items with same label", "\n", "tsum", "=", "np", ".", "sum", "(", "gnd", ")", "\n", "if", "tsum", "==", "0", ":", "\n", "            ", "continue", "\n", "# sort gnd by hamming dist", "\n", "", "hamm", "=", "calculate_hamming", "(", "qB", "[", "iter", ",", ":", "]", ",", "rB", ")", "\n", "ind", "=", "np", ".", "argsort", "(", "hamm", ")", "\n", "gnd", "=", "gnd", "[", "ind", "]", "\n", "\n", "count", "=", "np", ".", "linspace", "(", "1", ",", "tsum", ",", "tsum", ")", "# [1,2, tsum]", "\n", "tindex", "=", "np", ".", "asarray", "(", "np", ".", "where", "(", "gnd", "==", "1", ")", ")", "+", "1.0", "\n", "map_", "=", "np", ".", "mean", "(", "count", "/", "(", "tindex", ")", ")", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.cal_map.calculate_top_map": [[107, 136], ["range", "cal_map.calculate_hamming", "numpy.argsort", "numpy.sum", "numpy.linspace", "numpy.mean", "numpy.asarray", "numpy.where", "numpy.dot", "retrievalL.transpose"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_hamming"], ["map", "=", "map", "+", "map_", "\n", "", "map", "=", "map", "/", "num_query", "\n", "return", "map", "\n", "\n", "\n", "", "def", "calculate_top_map", "(", "qB", ",", "rB", ",", "queryL", ",", "retrievalL", ",", "topk", ")", ":", "\n", "    ", "\"\"\"\n    :param qB: {-1,+1}^{mxq} query bits\n    :param rB: {-1,+1}^{nxq} retrieval bits\n    :param queryL: {0,1}^{mxl} query label\n    :param retrievalL: {0,1}^{nxl} retrieval label\n    :param topk:\n    :return:\n    \"\"\"", "\n", "num_query", "=", "queryL", ".", "shape", "[", "0", "]", "\n", "topkmap", "=", "0", "\n", "for", "iter", "in", "range", "(", "num_query", ")", ":", "\n", "        ", "gnd", "=", "(", "np", ".", "dot", "(", "queryL", "[", "iter", ",", ":", "]", ",", "retrievalL", ".", "transpose", "(", ")", ")", ">", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "hamm", "=", "calculate_hamming", "(", "qB", "[", "iter", ",", ":", "]", ",", "rB", ")", "\n", "ind", "=", "np", ".", "argsort", "(", "hamm", ")", "\n", "gnd", "=", "gnd", "[", "ind", "]", "\n", "\n", "tgnd", "=", "gnd", "[", "0", ":", "topk", "]", "\n", "tsum", "=", "np", ".", "sum", "(", "tgnd", ")", "\n", "if", "tsum", "==", "0", ":", "\n", "            ", "continue", "\n", "", "count", "=", "np", ".", "linspace", "(", "1", ",", "tsum", ",", "tsum", ")", "\n", "\n", "tindex", "=", "np", ".", "asarray", "(", "np", ".", "where", "(", "tgnd", "==", "1", ")", ")", "+", "1.0", "\n", "topkmap_", "=", "np", ".", "mean", "(", "count", "/", "(", "tindex", ")", ")", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.cal_map.mean_average_precision": [[138, 164], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.sign", "numpy.sign", "numpy.dot", "numpy.argsort", "range", "numpy.mean", "numpy.sum", "numpy.cumsum", "numpy.array", "numpy.sum", "np.cumsum.astype", "numpy.arange", "APx.append", "numpy.sum"], "function", ["None"], ["topkmap", "=", "topkmap", "+", "topkmap_", "\n", "", "topkmap", "=", "topkmap", "/", "num_query", "\n", "return", "topkmap", "\n", "\n", "\n", "", "def", "mean_average_precision", "(", "params", ")", ":", "\n", "    ", "database_code", "=", "np", ".", "array", "(", "params", "[", "'database_code'", "]", ")", "\n", "validation_code", "=", "np", ".", "array", "(", "params", "[", "'validation_code'", "]", ")", "\n", "database_labels", "=", "np", ".", "array", "(", "params", "[", "'database_labels'", "]", ")", "\n", "validation_labels", "=", "np", ".", "array", "(", "params", "[", "'validation_labels'", "]", ")", "\n", "R", "=", "params", "[", "'R'", "]", "\n", "query_num", "=", "validation_code", ".", "shape", "[", "0", "]", "\n", "database_code", "=", "np", ".", "sign", "(", "database_code", ")", "\n", "validation_code", "=", "np", ".", "sign", "(", "validation_code", ")", "\n", "\n", "sim", "=", "np", ".", "dot", "(", "database_code", ",", "validation_code", ".", "T", ")", "\n", "ids", "=", "np", ".", "argsort", "(", "-", "sim", ",", "axis", "=", "0", ")", "\n", "APx", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "query_num", ")", ":", "\n", "        ", "label", "=", "validation_labels", "[", "i", ",", ":", "]", "\n", "label", "[", "label", "==", "0", "]", "=", "-", "1", "\n", "idx", "=", "ids", "[", ":", ",", "i", "]", "\n", "imatch", "=", "np", ".", "sum", "(", "database_labels", "[", "idx", "[", "0", ":", "R", "]", ",", ":", "]", "==", "label", ",", "axis", "=", "1", ")", ">", "0", "\n", "relevant_num", "=", "np", ".", "sum", "(", "imatch", ")", "\n", "Lx", "=", "np", ".", "cumsum", "(", "imatch", ")", "\n", "Px", "=", "Lx", ".", "astype", "(", "float", ")", "/", "np", ".", "arange", "(", "1", ",", "R", "+", "1", ",", "1", ")", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.cal_map.precision": [[190, 231], ["np.asarray.cpu().numpy", "numpy.asarray", "trn_label.cpu().numpy.cpu().numpy", "np.asarray.cpu().numpy", "numpy.asarray", "tst_label.cpu().numpy.cpu().numpy", "range", "numpy.zeros", "numpy.zeros", "numpy.arange", "numpy.zeros", "range", "print", "numpy.save", "print", "numpy.mean", "print", "numpy.max", "print", "numpy.count_nonzero", "numpy.argsort", "numpy.equal().astype", "numpy.mean", "np.asarray.cpu", "trn_label.cpu().numpy.cpu", "np.asarray.cpu", "tst_label.cpu().numpy.cpu", "numpy.array().repeat", "numpy.concatenate", "numpy.concatenate", "numpy.cumsum", "numpy.sum", "sum", "numpy.cumsum", "numpy.equal", "numpy.array", "numpy.array().repeat", "numpy.random.RandomState().permutation", "numpy.array", "numpy.where", "numpy.random.RandomState", "numpy.where", "numpy.random.RandomState().permutation", "numpy.sort", "numpy.random.RandomState", "numpy.where"], "function", ["None"], ["APx", ".", "append", "(", "float", "(", "relevant_num", ")", "/", "R", ")", "\n", "\n", "", "return", "np", ".", "mean", "(", "np", ".", "array", "(", "APx", ")", ")", "\n", "\n", "\n", "", "def", "precision", "(", "trn_binary", ",", "trn_label", ",", "tst_binary", ",", "tst_label", ")", ":", "\n", "    ", "trn_binary", "=", "trn_binary", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "trn_binary", "=", "np", ".", "asarray", "(", "trn_binary", ",", "np", ".", "int32", ")", "\n", "trn_label", "=", "trn_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "tst_binary", "=", "tst_binary", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "tst_binary", "=", "np", ".", "asarray", "(", "tst_binary", ",", "np", ".", "int32", ")", "\n", "tst_label", "=", "tst_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "classes", "=", "np", ".", "max", "(", "tst_label", ")", "+", "1", "\n", "for", "i", "in", "range", "(", "classes", ")", ":", "\n", "        ", "if", "i", "==", "0", ":", "\n", "            ", "tst_sample_binary", "=", "tst_binary", "[", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "i", ")", ".", "permutation", "(", "np", ".", "where", "(", "tst_label", "==", "i", ")", "[", "0", "]", ")", "[", ":", "100", "]", "]", "\n", "tst_sample_label", "=", "np", ".", "array", "(", "[", "i", "]", ")", ".", "repeat", "(", "100", ")", "\n", "continue", "\n", "", "else", ":", "\n", "            ", "tst_sample_binary", "=", "np", ".", "concatenate", "(", "[", "tst_sample_binary", ",", "tst_binary", "[", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "i", ")", ".", "permutation", "(", "np", ".", "where", "(", "tst_label", "==", "i", ")", "[", "0", "]", ")", "[", ":", "100", "]", "]", "]", ")", "\n", "tst_sample_label", "=", "np", ".", "concatenate", "(", "[", "tst_sample_label", ",", "np", ".", "array", "(", "[", "i", "]", ")", ".", "repeat", "(", "100", ")", "]", ")", "\n", "", "", "query_times", "=", "tst_sample_binary", ".", "shape", "[", "0", "]", "\n", "trainset_len", "=", "trn_binary", ".", "shape", "[", "0", "]", "\n", "AP", "=", "np", ".", "zeros", "(", "query_times", ")", "\n", "precision_radius", "=", "np", ".", "zeros", "(", "query_times", ")", "\n", "Ns", "=", "np", ".", "arange", "(", "1", ",", "trainset_len", "+", "1", ")", "\n", "sum_tp", "=", "np", ".", "zeros", "(", "trainset_len", ")", "\n", "for", "i", "in", "range", "(", "query_times", ")", ":", "\n", "        ", "print", "(", "'Query '", ",", "i", "+", "1", ")", "\n", "query_label", "=", "tst_sample_label", "[", "i", "]", "\n", "query_binary", "=", "tst_sample_binary", "[", "i", ",", ":", "]", "\n", "query_result", "=", "np", ".", "count_nonzero", "(", "query_binary", "!=", "trn_binary", ",", "axis", "=", "1", ")", "#don't need to divide binary length", "\n", "sort_indices", "=", "np", ".", "argsort", "(", "query_result", ")", "\n", "buffer_yes", "=", "np", ".", "equal", "(", "query_label", ",", "trn_label", "[", "sort_indices", "]", ")", ".", "astype", "(", "int", ")", "\n", "P", "=", "np", ".", "cumsum", "(", "buffer_yes", ")", "/", "Ns", "\n", "precision_radius", "[", "i", "]", "=", "P", "[", "np", ".", "where", "(", "np", ".", "sort", "(", "query_result", ")", ">", "2", ")", "[", "0", "]", "[", "0", "]", "-", "1", "]", "\n", "AP", "[", "i", "]", "=", "np", ".", "sum", "(", "P", "*", "buffer_yes", ")", "/", "sum", "(", "buffer_yes", ")", "\n", "sum_tp", "=", "sum_tp", "+", "np", ".", "cumsum", "(", "buffer_yes", ")", "\n", "", "precision_at_k", "=", "sum_tp", "/", "Ns", "/", "query_times", "\n", "index", "=", "[", "100", ",", "200", ",", "400", ",", "600", ",", "800", ",", "1000", "]", "\n", "index", "=", "[", "i", "-", "1", "for", "i", "in", "index", "]", "\n", "print", "(", "'precision at k:'", ",", "precision_at_k", "[", "index", "]", ")", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.cal_map.compute_precision_at_k": [[238, 258], ["query_labels.size", "relevances.sum().type", "true_positive.div_.div_", "torch.mean", "query_labels.unsqueeze().expand", "torch.cat", "torch.cat().type", "query_labels.unsqueeze().expand().type", "torch.index_select().unsqueeze_", "torch.index_select().unsqueeze_", "relevances.sum", "query_labels.unsqueeze", "range", "range", "torch.cat", "query_labels.unsqueeze().expand", "torch.index_select", "torch.index_select", "torch.cat().type.size", "query_labels.unsqueeze"], "function", ["None"], ["\n", "\n", "\n", "\n", "\n", "", "def", "compute_precision_at_k", "(", "retrieved_indices", ",", "query_labels", ",", "doc_labels", ",", "topK", ",", "is_single_label", ")", ":", "\n", "    ", "n_test", "=", "query_labels", ".", "size", "(", "0", ")", "\n", "\n", "Indices", "=", "retrieved_indices", "[", ":", ",", ":", "topK", "]", "\n", "if", "is_single_label", ":", "\n", "        ", "test_labels", "=", "query_labels", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "n_test", ",", "topK", ")", "\n", "topTrainLabels", "=", "[", "torch", ".", "index_select", "(", "doc_labels", ",", "0", ",", "Indices", "[", "idx", "]", ")", ".", "unsqueeze_", "(", "0", ")", "for", "idx", "in", "range", "(", "0", ",", "n_test", ")", "]", "\n", "topTrainLabels", "=", "torch", ".", "cat", "(", "topTrainLabels", ",", "dim", "=", "0", ")", "\n", "relevances", "=", "(", "test_labels", "==", "topTrainLabels", ")", ".", "type", "(", "torch", ".", "cuda", ".", "ShortTensor", ")", "\n", "", "else", ":", "\n", "        ", "topTrainLabels", "=", "[", "torch", ".", "index_select", "(", "doc_labels", ",", "0", ",", "Indices", "[", "idx", "]", ")", ".", "unsqueeze_", "(", "0", ")", "for", "idx", "in", "range", "(", "0", ",", "n_test", ")", "]", "\n", "topTrainLabels", "=", "torch", ".", "cat", "(", "topTrainLabels", ",", "dim", "=", "0", ")", ".", "type", "(", "torch", ".", "cuda", ".", "ShortTensor", ")", "\n", "test_labels", "=", "query_labels", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "n_test", ",", "topK", ",", "topTrainLabels", ".", "size", "(", "-", "1", ")", ")", ".", "type", "(", "torch", ".", "cuda", ".", "ShortTensor", ")", "\n", "relevances", "=", "(", "topTrainLabels", "&", "test_labels", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "relevances", "=", "(", "relevances", ">", "0", ")", ".", "type", "(", "torch", ".", "cuda", ".", "ShortTensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.opts.parse_opts": [[4, 246], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_opts", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--root_path'", ",", "\n", "default", "=", "'datasets/HMBD51/'", ",", "\n", "#        default='datasets/UFC101/',    # for ucf101", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Root directory path of data'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--video_path'", ",", "\n", "default", "=", "'HMDBJPG/'", ",", "\n", "#        default='UCFJPG/',       # for ucf101", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Directory path of Videos'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--annotation_path'", ",", "\n", "default", "=", "'hmdb51_1.json'", ",", "\n", "#        default='ucf101_01.json',   # for ucf101       ", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Annotation file path'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--result_path'", ",", "\n", "default", "=", "'results'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Result directory path'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--dataset'", ",", "\n", "default", "=", "'hmdb51'", ",", "\n", "#        default='ucf101',     # for ucf101", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Used dataset (activitynet | kinetics | ucf101 | hmdb51)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--n_classes'", ",", "\n", "default", "=", "400", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\n", "'Number of classes (activitynet: 200, kinetics: 400, ucf101: 101, hmdb51: 51)'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--codelength'", ",", "\n", "default", "=", "32", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\n", "'Number of bits (16, 32, 64, 128)'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--n_finetune_classes'", ",", "\n", "default", "=", "51", ",", "\n", "#        default=101,      # for ucf101", "\n", "type", "=", "int", ",", "\n", "help", "=", "\n", "'Number of classes for fine-tuning. n_classes is set to the number when pretraining.'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_size'", ",", "\n", "default", "=", "112", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Height and width of inputs'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--sample_duration'", ",", "\n", "default", "=", "16", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Temporal duration of inputs'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--initial_scale'", ",", "\n", "default", "=", "1.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "'Initial scale for multiscale cropping'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--n_scales'", ",", "\n", "default", "=", "5", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Number of scales for multiscale cropping'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--scale_step'", ",", "\n", "default", "=", "0.84089641525", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "'Scale step for multiscale cropping'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--train_crop'", ",", "\n", "default", "=", "'corner'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\n", "'Spatial cropping method in training. random is uniform. corner is selection from 4 corners and 1 center.  (random | corner | center)'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--learning_rate'", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\n", "'Initial learning rate (divided by 10 while training by lr scheduler)'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "default", "=", "0.9", ",", "type", "=", "float", ",", "help", "=", "'Momentum'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--dampening'", ",", "default", "=", "0.9", ",", "type", "=", "float", ",", "help", "=", "'dampening of SGD'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--weight_decay'", ",", "default", "=", "1e-3", ",", "type", "=", "float", ",", "help", "=", "'Weight Decay'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--mean_dataset'", ",", "\n", "default", "=", "'activitynet'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\n", "'dataset for mean values of mean subtraction (activitynet | kinetics)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_mean_norm'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If true, inputs are not normalized by mean.'", ")", "\n", "parser", ".", "set_defaults", "(", "no_mean_norm", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--std_norm'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If true, inputs are normalized by standard deviation.'", ")", "\n", "parser", ".", "set_defaults", "(", "std_norm", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--nesterov'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Nesterov momentum'", ")", "\n", "parser", ".", "set_defaults", "(", "nesterov", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--optimizer'", ",", "\n", "default", "=", "'sgd'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Currently only support SGD'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--lr_patience'", ",", "\n", "default", "=", "10", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Patience of LR scheduler. See documentation of ReduceLROnPlateau.'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--batch_size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "help", "=", "'Batch Size'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--n_epochs'", ",", "\n", "default", "=", "200", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Number of total epochs to run'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--begin_epoch'", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\n", "'Training begins at this epoch. Previous trained model indicated by resume_path is loaded.'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--n_val_samples'", ",", "\n", "default", "=", "3", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Number of validation samples for each activity'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resume_path'", ",", "\n", "default", "=", "''", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Save data (.pth) of previous training'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--pretrain_path'", ",", "default", "=", "'resnet-34-kinetics.pth'", ",", "type", "=", "str", ",", "help", "=", "'Pretrained model (.pth)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--ft_begin_index'", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Begin block index of fine-tuning'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_train'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If true, training is not performed.'", ")", "\n", "parser", ".", "set_defaults", "(", "no_train", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_val'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If true, validation is not performed.'", ")", "\n", "parser", ".", "set_defaults", "(", "no_val", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--test'", ",", "action", "=", "'store_true'", ",", "help", "=", "'If true, test is performed.'", ")", "\n", "parser", ".", "set_defaults", "(", "test", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--test_subset'", ",", "\n", "default", "=", "'val'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Used subset in test (val | test)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--scale_in_test'", ",", "\n", "default", "=", "1.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "'Spatial scale in test'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--crop_position_in_test'", ",", "\n", "default", "=", "'c'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Cropping method (c | tl | tr | bl | br) in test'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_softmax_in_test'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If true, output for each clip is not normalized using softmax.'", ")", "\n", "parser", ".", "set_defaults", "(", "no_softmax_in_test", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_cuda'", ",", "action", "=", "'store_true'", ",", "help", "=", "'If true, cuda is not used.'", ")", "\n", "parser", ".", "set_defaults", "(", "no_cuda", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--n_threads'", ",", "\n", "default", "=", "4", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Number of threads for multi-thread loading'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--checkpoint'", ",", "\n", "default", "=", "50", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Trained model is saved at every this epochs.'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_hflip'", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'If true holizontal flipping is not performed.'", ")", "\n", "parser", ".", "set_defaults", "(", "no_hflip", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--norm_value'", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\n", "'If 1, range of inputs is [0-255]. If 255, range of inputs is [0-1].'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--model'", ",", "\n", "default", "=", "'resnet'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'(resnet | preresnet | wideresnet | resnext | densenet | '", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--model_depth'", ",", "\n", "default", "=", "34", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'Depth of resnet (10 | 18 | 34 | 50 | 101)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resnet_shortcut'", ",", "\n", "default", "=", "'A'", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "'Shortcut type of resnet (A | B)'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--wide_resnet_k'", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "'Wide resnet k'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--resnext_cardinality'", ",", "\n", "default", "=", "32", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "'ResNeXt cardinality'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--manual_seed'", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "'Manually set random seed'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.Compose.__init__": [[25, 27], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.Compose.__call__": [[28, 32], ["t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "img", "=", "t", "(", "img", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.Compose.randomize_parameters": [[33, 36], ["t.randomize_parameters"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.MultiScaleRandomCrop.randomize_parameters"], ["", "def", "randomize_parameters", "(", "self", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "t", ".", "randomize_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.ToTensor.__init__": [[44, 46], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "norm_value", "=", "255", ")", ":", "\n", "        ", "self", ".", "norm_value", "=", "norm_value", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.ToTensor.__call__": [[47, 88], ["isinstance", "torch.ByteTensor.view", "torch.ByteTensor.transpose().transpose().contiguous", "isinstance", "torch.from_numpy", "torch.ByteTensor.float().div", "isinstance", "numpy.zeros", "pic.copyto", "torch.from_numpy", "torch.from_numpy", "torch.ByteTensor.float().div", "pic.transpose", "numpy.array", "torch.from_numpy", "torch.ByteTensor", "len", "torch.ByteTensor.transpose().transpose", "torch.ByteTensor.float", "numpy.array", "torch.ByteStorage.from_buffer", "torch.ByteTensor.float", "pic.tobytes", "torch.ByteTensor.transpose"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "pic", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            pic (PIL.Image or numpy.ndarray): Image to be converted to tensor.\n        Returns:\n            Tensor: Converted image.\n        \"\"\"", "\n", "if", "isinstance", "(", "pic", ",", "np", ".", "ndarray", ")", ":", "\n", "# handle numpy array", "\n", "            ", "img", "=", "torch", ".", "from_numpy", "(", "pic", ".", "transpose", "(", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "# backward compatibility", "\n", "return", "img", ".", "float", "(", ")", ".", "div", "(", "self", ".", "norm_value", ")", "\n", "\n", "", "if", "accimage", "is", "not", "None", "and", "isinstance", "(", "pic", ",", "accimage", ".", "Image", ")", ":", "\n", "            ", "nppic", "=", "np", ".", "zeros", "(", "\n", "[", "pic", ".", "channels", ",", "pic", ".", "height", ",", "pic", ".", "width", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "pic", ".", "copyto", "(", "nppic", ")", "\n", "return", "torch", ".", "from_numpy", "(", "nppic", ")", "\n", "\n", "# handle PIL Image", "\n", "", "if", "pic", ".", "mode", "==", "'I'", ":", "\n", "            ", "img", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "pic", ",", "np", ".", "int32", ",", "copy", "=", "False", ")", ")", "\n", "", "elif", "pic", ".", "mode", "==", "'I;16'", ":", "\n", "            ", "img", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "pic", ",", "np", ".", "int16", ",", "copy", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "            ", "img", "=", "torch", ".", "ByteTensor", "(", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "pic", ".", "tobytes", "(", ")", ")", ")", "\n", "# PIL image mode: 1, L, P, I, F, RGB, YCbCr, RGBA, CMYK", "\n", "", "if", "pic", ".", "mode", "==", "'YCbCr'", ":", "\n", "            ", "nchannel", "=", "3", "\n", "", "elif", "pic", ".", "mode", "==", "'I;16'", ":", "\n", "            ", "nchannel", "=", "1", "\n", "", "else", ":", "\n", "            ", "nchannel", "=", "len", "(", "pic", ".", "mode", ")", "\n", "", "img", "=", "img", ".", "view", "(", "pic", ".", "size", "[", "1", "]", ",", "pic", ".", "size", "[", "0", "]", ",", "nchannel", ")", "\n", "# put it from HWC to CHW format", "\n", "# yikes, this transpose takes 80% of the loading time/CPU", "\n", "img", "=", "img", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "if", "isinstance", "(", "img", ",", "torch", ".", "ByteTensor", ")", ":", "\n", "            ", "return", "img", ".", "float", "(", ")", ".", "div", "(", "self", ".", "norm_value", ")", "\n", "", "else", ":", "\n", "            ", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.ToTensor.randomize_parameters": [[89, 91], ["None"], "methods", ["None"], ["", "", "def", "randomize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.Normalize.__init__": [[104, 107], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.Normalize.__call__": [[108, 119], ["zip", "t.sub_().div_", "t.sub_"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n        Returns:\n            Tensor: Normalized image.\n        \"\"\"", "\n", "# TODO: make efficient", "\n", "for", "t", ",", "m", ",", "s", "in", "zip", "(", "tensor", ",", "self", ".", "mean", ",", "self", ".", "std", ")", ":", "\n", "            ", "t", ".", "sub_", "(", "m", ")", ".", "div_", "(", "s", ")", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.Normalize.randomize_parameters": [[120, 122], ["None"], "methods", ["None"], ["", "def", "randomize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.Scale.__init__": [[136, 142], ["isinstance", "isinstance", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "assert", "isinstance", "(", "size", ",", "\n", "int", ")", "or", "(", "isinstance", "(", "size", ",", "collections", ".", "Iterable", ")", "and", "\n", "len", "(", "size", ")", "==", "2", ")", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.Scale.__call__": [[143, 164], ["isinstance", "img.resize", "int", "img.resize", "int", "img.resize"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL.Image): Image to be scaled.\n        Returns:\n            PIL.Image: Rescaled image.\n        \"\"\"", "\n", "if", "isinstance", "(", "self", ".", "size", ",", "int", ")", ":", "\n", "            ", "w", ",", "h", "=", "img", ".", "size", "\n", "if", "(", "w", "<=", "h", "and", "w", "==", "self", ".", "size", ")", "or", "(", "h", "<=", "w", "and", "h", "==", "self", ".", "size", ")", ":", "\n", "                ", "return", "img", "\n", "", "if", "w", "<", "h", ":", "\n", "                ", "ow", "=", "self", ".", "size", "\n", "oh", "=", "int", "(", "self", ".", "size", "*", "h", "/", "w", ")", "\n", "return", "img", ".", "resize", "(", "(", "ow", ",", "oh", ")", ",", "self", ".", "interpolation", ")", "\n", "", "else", ":", "\n", "                ", "oh", "=", "self", ".", "size", "\n", "ow", "=", "int", "(", "self", ".", "size", "*", "w", "/", "h", ")", "\n", "return", "img", ".", "resize", "(", "(", "ow", ",", "oh", ")", ",", "self", ".", "interpolation", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "img", ".", "resize", "(", "self", ".", "size", ",", "self", ".", "interpolation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.Scale.randomize_parameters": [[165, 167], ["None"], "methods", ["None"], ["", "", "def", "randomize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.CenterCrop.__init__": [[177, 182], ["isinstance", "int", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.CenterCrop.__call__": [[183, 195], ["int", "int", "img.crop", "round", "round"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL.Image): Image to be cropped.\n        Returns:\n            PIL.Image: Cropped image.\n        \"\"\"", "\n", "w", ",", "h", "=", "img", ".", "size", "\n", "th", ",", "tw", "=", "self", ".", "size", "\n", "x1", "=", "int", "(", "round", "(", "(", "w", "-", "tw", ")", "/", "2.", ")", ")", "\n", "y1", "=", "int", "(", "round", "(", "(", "h", "-", "th", ")", "/", "2.", ")", ")", "\n", "return", "img", ".", "crop", "(", "(", "x1", ",", "y1", ",", "x1", "+", "tw", ",", "y1", "+", "th", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.CenterCrop.randomize_parameters": [[196, 198], ["None"], "methods", ["None"], ["", "def", "randomize_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.CornerCrop.__init__": [[202, 210], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "crop_position", "=", "None", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "if", "crop_position", "is", "None", ":", "\n", "            ", "self", ".", "randomize", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "randomize", "=", "False", "\n", "", "self", ".", "crop_position", "=", "crop_position", "\n", "self", ".", "crop_positions", "=", "[", "'c'", ",", "'tl'", ",", "'tr'", ",", "'bl'", ",", "'br'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.CornerCrop.__call__": [[211, 245], ["img.crop.crop.crop", "int", "int", "round", "round"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "image_width", "=", "img", ".", "size", "[", "0", "]", "\n", "image_height", "=", "img", ".", "size", "[", "1", "]", "\n", "\n", "if", "self", ".", "crop_position", "==", "'c'", ":", "\n", "            ", "th", ",", "tw", "=", "(", "self", ".", "size", ",", "self", ".", "size", ")", "\n", "x1", "=", "int", "(", "round", "(", "(", "image_width", "-", "tw", ")", "/", "2.", ")", ")", "\n", "y1", "=", "int", "(", "round", "(", "(", "image_height", "-", "th", ")", "/", "2.", ")", ")", "\n", "x2", "=", "x1", "+", "tw", "\n", "y2", "=", "y1", "+", "th", "\n", "", "elif", "self", ".", "crop_position", "==", "'tl'", ":", "\n", "            ", "x1", "=", "0", "\n", "y1", "=", "0", "\n", "x2", "=", "self", ".", "size", "\n", "y2", "=", "self", ".", "size", "\n", "", "elif", "self", ".", "crop_position", "==", "'tr'", ":", "\n", "            ", "x1", "=", "image_width", "-", "self", ".", "size", "\n", "y1", "=", "0", "\n", "x2", "=", "image_width", "\n", "y2", "=", "self", ".", "size", "\n", "", "elif", "self", ".", "crop_position", "==", "'bl'", ":", "\n", "            ", "x1", "=", "0", "\n", "y1", "=", "image_height", "-", "self", ".", "size", "\n", "x2", "=", "self", ".", "size", "\n", "y2", "=", "image_height", "\n", "", "elif", "self", ".", "crop_position", "==", "'br'", ":", "\n", "            ", "x1", "=", "image_width", "-", "self", ".", "size", "\n", "y1", "=", "image_height", "-", "self", ".", "size", "\n", "x2", "=", "image_width", "\n", "y2", "=", "image_height", "\n", "\n", "", "img", "=", "img", ".", "crop", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ")", "\n", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.CornerCrop.randomize_parameters": [[246, 251], ["random.randint", "len"], "methods", ["None"], ["", "def", "randomize_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "randomize", ":", "\n", "            ", "self", ".", "crop_position", "=", "self", ".", "crop_positions", "[", "random", ".", "randint", "(", "\n", "0", ",", "\n", "len", "(", "self", ".", "crop_positions", ")", "-", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.RandomHorizontalFlip.__call__": [[256, 266], ["img.transpose"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (PIL.Image): Image to be flipped.\n        Returns:\n            PIL.Image: Randomly flipped image.\n        \"\"\"", "\n", "if", "self", ".", "p", "<", "0.5", ":", "\n", "            ", "return", "img", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.RandomHorizontalFlip.randomize_parameters": [[267, 269], ["random.random"], "methods", ["None"], ["", "def", "randomize_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "p", "=", "random", ".", "random", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.MultiScaleCornerCrop.__init__": [[282, 292], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "scales", ",", "\n", "size", ",", "\n", "interpolation", "=", "Image", ".", "BILINEAR", ",", "\n", "crop_positions", "=", "[", "'c'", ",", "'tl'", ",", "'tr'", ",", "'bl'", ",", "'br'", "]", ")", ":", "\n", "        ", "self", ".", "scales", "=", "scales", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n", "self", ".", "crop_positions", "=", "crop_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.MultiScaleCornerCrop.__call__": [[293, 332], ["min", "int", "img.crop.crop.crop", "img.crop.crop.resize"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "min_length", "=", "min", "(", "img", ".", "size", "[", "0", "]", ",", "img", ".", "size", "[", "1", "]", ")", "\n", "crop_size", "=", "int", "(", "min_length", "*", "self", ".", "scale", ")", "\n", "\n", "image_width", "=", "img", ".", "size", "[", "0", "]", "\n", "image_height", "=", "img", ".", "size", "[", "1", "]", "\n", "\n", "if", "self", ".", "crop_position", "==", "'c'", ":", "\n", "            ", "center_x", "=", "image_width", "//", "2", "\n", "center_y", "=", "image_height", "//", "2", "\n", "box_half", "=", "crop_size", "//", "2", "\n", "x1", "=", "center_x", "-", "box_half", "\n", "y1", "=", "center_y", "-", "box_half", "\n", "x2", "=", "center_x", "+", "box_half", "\n", "y2", "=", "center_y", "+", "box_half", "\n", "", "elif", "self", ".", "crop_position", "==", "'tl'", ":", "\n", "            ", "x1", "=", "0", "\n", "y1", "=", "0", "\n", "x2", "=", "crop_size", "\n", "y2", "=", "crop_size", "\n", "", "elif", "self", ".", "crop_position", "==", "'tr'", ":", "\n", "            ", "x1", "=", "image_width", "-", "crop_size", "\n", "y1", "=", "0", "\n", "x2", "=", "image_width", "\n", "y2", "=", "crop_size", "\n", "", "elif", "self", ".", "crop_position", "==", "'bl'", ":", "\n", "            ", "x1", "=", "0", "\n", "y1", "=", "image_height", "-", "crop_size", "\n", "x2", "=", "crop_size", "\n", "y2", "=", "image_height", "\n", "", "elif", "self", ".", "crop_position", "==", "'br'", ":", "\n", "            ", "x1", "=", "image_width", "-", "crop_size", "\n", "y1", "=", "image_height", "-", "crop_size", "\n", "x2", "=", "image_width", "\n", "y2", "=", "image_height", "\n", "\n", "", "img", "=", "img", ".", "crop", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ")", "\n", "\n", "return", "img", ".", "resize", "(", "(", "self", ".", "size", ",", "self", ".", "size", ")", ",", "self", ".", "interpolation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.MultiScaleCornerCrop.randomize_parameters": [[333, 338], ["random.randint", "random.randint", "len", "len"], "methods", ["None"], ["", "def", "randomize_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "scale", "=", "self", ".", "scales", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "scales", ")", "-", "1", ")", "]", "\n", "self", ".", "crop_position", "=", "self", ".", "crop_positions", "[", "random", ".", "randint", "(", "\n", "0", ",", "\n", "len", "(", "self", ".", "crop_positions", ")", "-", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.MultiScaleRandomCrop.__init__": [[342, 346], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "scales", ",", "size", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "self", ".", "scales", "=", "scales", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.MultiScaleRandomCrop.__call__": [[347, 362], ["min", "int", "img.crop.crop.crop", "img.crop.crop.resize"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img", ")", ":", "\n", "        ", "min_length", "=", "min", "(", "img", ".", "size", "[", "0", "]", ",", "img", ".", "size", "[", "1", "]", ")", "\n", "crop_size", "=", "int", "(", "min_length", "*", "self", ".", "scale", ")", "\n", "\n", "image_width", "=", "img", ".", "size", "[", "0", "]", "\n", "image_height", "=", "img", ".", "size", "[", "1", "]", "\n", "\n", "x1", "=", "self", ".", "tl_x", "*", "(", "image_width", "-", "crop_size", ")", "\n", "y1", "=", "self", ".", "tl_y", "*", "(", "image_height", "-", "crop_size", ")", "\n", "x2", "=", "x1", "+", "crop_size", "\n", "y2", "=", "y1", "+", "crop_size", "\n", "\n", "img", "=", "img", ".", "crop", "(", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ")", "\n", "\n", "return", "img", ".", "resize", "(", "(", "self", ".", "size", ",", "self", ".", "size", ")", ",", "self", ".", "interpolation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.MultiScaleRandomCrop.randomize_parameters": [[363, 367], ["random.random", "random.random", "random.randint", "len"], "methods", ["None"], ["", "def", "randomize_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "scale", "=", "self", ".", "scales", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "scales", ")", "-", "1", ")", "]", "\n", "self", ".", "tl_x", "=", "random", ".", "random", "(", ")", "\n", "self", ".", "tl_y", "=", "random", ".", "random", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.main.hash.forward": [[47, 59], ["U.sort", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "ctx.save_for_backward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "int", "int"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "U", ")", ":", "\n", "\n", "# Yunqiang for half and half (optimal transport)", "\n", "        ", "_", ",", "index", "=", "U", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "N", ",", "D", "=", "U", ".", "shape", "\n", "B_creat", "=", "torch", ".", "cat", "(", "(", "torch", ".", "ones", "(", "[", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ",", "-", "torch", ".", "ones", "(", "[", "N", "-", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "B", "=", "torch", ".", "zeros", "(", "U", ".", "shape", ")", ".", "cuda", "(", ")", ".", "scatter_", "(", "0", ",", "index", ",", "B_creat", ")", "\n", "\n", "ctx", ".", "save_for_backward", "(", "U", ",", "B", ")", "\n", "\n", "return", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.main.hash.backward": [[60, 68], ["B.numel"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "g", ")", ":", "\n", "        ", "U", ",", "B", "=", "ctx", ".", "saved_tensors", "\n", "add_g", "=", "(", "U", "-", "B", ")", "/", "(", "B", ".", "numel", "(", ")", ")", "\n", "\n", "grad", "=", "g", "+", "gamma", "*", "add_g", "\n", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.main.ReNet34.__init__": [[75, 81], ["torch.nn.Module.__init__", "main.ReNet34.resnet.parameters", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ",", "resnet_in", ",", "encode_length", ")", ":", "\n", "        ", "super", "(", "ReNet34", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "resnet", "=", "resnet_in", "\n", "for", "param", "in", "self", ".", "resnet", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "self", ".", "fc_encode", "=", "nn", ".", "Linear", "(", "512", ",", "encode_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.main.ReNet34.forward": [[82, 87], ["main.ReNet34.resnet", "main.ReNet34.fc_encode", "main.hash_layer"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash_layer"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "resnet", "(", "x", ")", "\n", "h", "=", "self", ".", "fc_encode", "(", "x", ")", "\n", "b", "=", "hash_layer", "(", "h", ")", "\n", "return", "x", ",", "h", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.main.Identity.__init__": [[89, 91], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Identity", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.main.Identity.forward": [[92, 94], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.main.hash_layer": [[70, 72], ["hash.apply"], "function", ["None"], ["", "", "def", "hash_layer", "(", "input", ")", ":", "\n", "    ", "return", "hash", ".", "apply", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.main.main": [[95, 226], ["model.generate_model", "main.Identity", "main.ReNet34", "print", "range", "spatial_transforms.Normalize", "spatial_transforms.Compose", "temporal_transforms.TemporalRandomCrop", "target_transforms.ClassLabel", "dataset.get_training_set", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "spatial_transforms.Compose", "temporal_transforms.LoopPadding", "target_transforms.ClassLabel", "dataset.get_test_set", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "spatial_transforms.Compose", "temporal_transforms.LoopPadding", "target_transforms.ClassLabel", "dataset.get_validation_set", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.optim.SGD", "torch.optim.lr_scheduler.ReduceLROnPlateau", "print", "torch.load", "torch.load", "ReNet34.load_state_dict", "ReNet34.cuda().train", "enumerate", "spatial_transforms.Normalize", "spatial_transforms.Normalize", "spatial_transforms.MultiScaleRandomCrop", "ReNet34.parameters", "optim.SGD.load_state_dict", "optim.SGD.state.values", "torch.autograd.Variable", "torch.autograd.Variable", "optim.SGD.zero_grad", "ReNet34.", "torch.cosine_similarity", "torch.cosine_similarity", "torch.mse_loss", "F.mse_loss.backward", "optim.SGD.step", "lr_scheduler.ReduceLROnPlateau.step", "ReNet34.eval", "cal_map.compress", "cal_map.calculate_top_map", "print", "spatial_transforms.MultiScaleCornerCrop", "spatial_transforms.RandomHorizontalFlip", "spatial_transforms.ToTensor", "spatial_transforms.Scale", "spatial_transforms.CornerCrop", "spatial_transforms.ToTensor", "spatial_transforms.Scale", "spatial_transforms.CornerCrop", "spatial_transforms.ToTensor", "state.items", "ReNet34.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda().long", "spatial_transforms.MultiScaleCornerCrop", "int", "int", "torch.is_tensor", "torch.is_tensor", "v.cuda", "torch.autograd.Variable.cuda", "int", "int", "int", "int", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.model.generate_model", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.dataset.get_training_set", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.dataset.get_test_set", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.dataset.get_validation_set", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash.backward", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.compress", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_top_map"], ["", "", "def", "main", "(", ")", ":", "\n", "\n", "    ", "resnet_in", "=", "generate_model", "(", "opt", ")", "\n", "resnet_in", ".", "module", ".", "fc", "=", "Identity", "(", ")", "\n", "model", "=", "ReNet34", "(", "resnet_in", ",", "encode_length", "=", "encode_length", ")", "\n", "\n", "if", "opt", ".", "no_mean_norm", "and", "not", "opt", ".", "std_norm", ":", "\n", "        ", "norm_method", "=", "Normalize", "(", "[", "0", ",", "0", ",", "0", "]", ",", "[", "1", ",", "1", ",", "1", "]", ")", "\n", "", "elif", "not", "opt", ".", "std_norm", ":", "\n", "        ", "norm_method", "=", "Normalize", "(", "opt", ".", "mean", ",", "[", "1", ",", "1", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "norm_method", "=", "Normalize", "(", "opt", ".", "mean", ",", "opt", ".", "std", ")", "\n", "\n", "", "if", "not", "opt", ".", "no_train", ":", "\n", "        ", "assert", "opt", ".", "train_crop", "in", "[", "'random'", ",", "'corner'", ",", "'center'", "]", "\n", "if", "opt", ".", "train_crop", "==", "'random'", ":", "\n", "            ", "crop_method", "=", "MultiScaleRandomCrop", "(", "opt", ".", "scales", ",", "opt", ".", "sample_size", ")", "\n", "", "elif", "opt", ".", "train_crop", "==", "'corner'", ":", "\n", "            ", "crop_method", "=", "MultiScaleCornerCrop", "(", "opt", ".", "scales", ",", "opt", ".", "sample_size", ")", "\n", "", "elif", "opt", ".", "train_crop", "==", "'center'", ":", "\n", "            ", "crop_method", "=", "MultiScaleCornerCrop", "(", "\n", "opt", ".", "scales", ",", "opt", ".", "sample_size", ",", "crop_positions", "=", "[", "'c'", "]", ")", "\n", "\n", "## train loader    ", "\n", "", "spatial_transform", "=", "Compose", "(", "[", "\n", "crop_method", ",", "\n", "RandomHorizontalFlip", "(", ")", ",", "\n", "ToTensor", "(", "opt", ".", "norm_value", ")", ",", "norm_method", "\n", "]", ")", "\n", "temporal_transform", "=", "TemporalRandomCrop", "(", "opt", ".", "sample_duration", ")", "\n", "target_transform", "=", "ClassLabel", "(", ")", "\n", "training_data", "=", "get_training_set", "(", "opt", ",", "spatial_transform", ",", "\n", "temporal_transform", ",", "target_transform", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "training_data", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "opt", ".", "n_threads", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n", "## test loader", "\n", "spatial_transform", "=", "Compose", "(", "[", "\n", "Scale", "(", "int", "(", "opt", ".", "sample_size", "/", "opt", ".", "scale_in_test", ")", ")", ",", "\n", "CornerCrop", "(", "opt", ".", "sample_size", ",", "opt", ".", "crop_position_in_test", ")", ",", "\n", "ToTensor", "(", "opt", ".", "norm_value", ")", ",", "norm_method", "\n", "]", ")", "\n", "temporal_transform", "=", "LoopPadding", "(", "opt", ".", "sample_duration", ")", "\n", "\n", "target_transform", "=", "ClassLabel", "(", ")", "\n", "test_data", "=", "get_test_set", "(", "opt", ",", "spatial_transform", ",", "temporal_transform", ",", "\n", "target_transform", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "test_data", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "opt", ".", "n_threads", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n", "## Database loader", "\n", "spatial_transform", "=", "Compose", "(", "[", "\n", "Scale", "(", "int", "(", "opt", ".", "sample_size", "/", "opt", ".", "scale_in_test", ")", ")", ",", "\n", "CornerCrop", "(", "opt", ".", "sample_size", ",", "opt", ".", "crop_position_in_test", ")", ",", "\n", "ToTensor", "(", "opt", ".", "norm_value", ")", ",", "norm_method", "\n", "]", ")", "\n", "temporal_transform", "=", "LoopPadding", "(", "opt", ".", "sample_duration", ")", "\n", "target_transform", "=", "ClassLabel", "(", ")", "\n", "validation_data", "=", "get_validation_set", "(", "opt", ",", "spatial_transform", ",", "temporal_transform", ",", "\n", "target_transform", ")", "\n", "database_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "validation_data", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "opt", ".", "n_threads", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n", "\n", "if", "opt", ".", "nesterov", ":", "\n", "            ", "dampening", "=", "0", "\n", "", "else", ":", "\n", "            ", "dampening", "=", "opt", ".", "dampening", "\n", "\n", "", "optimizer", "=", "optim", ".", "SGD", "(", "\n", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "opt", ".", "learning_rate", ",", "\n", "momentum", "=", "opt", ".", "momentum", ",", "\n", "dampening", "=", "dampening", ",", "\n", "weight_decay", "=", "opt", ".", "weight_decay", ",", "\n", "nesterov", "=", "opt", ".", "nesterov", ")", "\n", "scheduler", "=", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "\n", "optimizer", ",", "'min'", ",", "patience", "=", "opt", ".", "lr_patience", ")", "\n", "\n", "", "if", "opt", ".", "resume_path", ":", "\n", "        ", "print", "(", "'loading checkpoint {}'", ".", "format", "(", "opt", ".", "resume_path", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "resume_path", ")", "\n", "assert", "opt", ".", "arch", "==", "checkpoint", "[", "'arch'", "]", "\n", "\n", "opt", ".", "begin_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "if", "not", "opt", ".", "no_train", ":", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "for", "state", "in", "optimizer", ".", "state", ".", "values", "(", ")", ":", "\n", "                ", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "                    ", "if", "torch", ".", "is_tensor", "(", "v", ")", ":", "\n", "                        ", "state", "[", "k", "]", "=", "v", ".", "cuda", "(", ")", "\n", "\n", "", "", "", "", "", "print", "(", "'run'", ")", "\n", "for", "epoch", "in", "range", "(", "opt", ".", "begin_epoch", ",", "opt", ".", "n_epochs", "+", "1", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", ".", "train", "(", ")", "\n", "for", "i", ",", "(", "images", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "\n", "            ", "images", "=", "Variable", "(", "images", ".", "cuda", "(", ")", ")", "\n", "labels", "=", "Variable", "(", "labels", ".", "cuda", "(", ")", ".", "long", "(", ")", ")", "\n", "\n", "# Forward + Backward + Optimize", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "x", ",", "_", ",", "b", "=", "model", "(", "images", ")", "\n", "\n", "target_b", "=", "F", ".", "cosine_similarity", "(", "b", "[", ":", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", "]", ",", "b", "[", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", ":", "]", ")", "\n", "target_x", "=", "F", ".", "cosine_similarity", "(", "x", "[", ":", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", "]", ",", "x", "[", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", ":", "]", ")", "\n", "loss", "=", "F", ".", "mse_loss", "(", "target_b", ",", "target_x", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "\n", "# Test the Model", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "10", "==", "0", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "=", "compress", "(", "database_loader", ",", "test_loader", ",", "model", ")", "\n", "result_map", "=", "calculate_top_map", "(", "qB", "=", "queryB", ",", "rB", "=", "retrievalB", ",", "queryL", "=", "queryL", ",", "retrievalL", "=", "retrievalL", ",", "topk", "=", "100", ")", "\n", "print", "(", "'--------mAP@100: {}--------'", ".", "format", "(", "result_map", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.dataset.get_training_set": [[7, 46], ["datasets.kinetics.Kinetics", "datasets.activitynet.ActivityNet", "datasets.ucf101.UCF101", "datasets.hmdb51.HMDB51"], "function", ["None"], ["def", "get_training_set", "(", "opt", ",", "spatial_transform", ",", "temporal_transform", ",", "\n", "target_transform", ")", ":", "\n", "    ", "assert", "opt", ".", "dataset", "in", "[", "'kinetics'", ",", "'activitynet'", ",", "'ucf101'", ",", "'hmdb51'", "]", "\n", "\n", "if", "opt", ".", "dataset", "==", "'kinetics'", ":", "\n", "        ", "training_data", "=", "Kinetics", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "'training'", ",", "\n", "spatial_transform", "=", "spatial_transform", ",", "\n", "temporal_transform", "=", "temporal_transform", ",", "\n", "target_transform", "=", "target_transform", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'activitynet'", ":", "\n", "        ", "training_data", "=", "ActivityNet", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "'training'", ",", "\n", "False", ",", "\n", "spatial_transform", "=", "spatial_transform", ",", "\n", "temporal_transform", "=", "temporal_transform", ",", "\n", "target_transform", "=", "target_transform", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'ucf101'", ":", "\n", "        ", "training_data", "=", "UCF101", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "'training'", ",", "\n", "spatial_transform", "=", "spatial_transform", ",", "\n", "temporal_transform", "=", "temporal_transform", ",", "\n", "target_transform", "=", "target_transform", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'hmdb51'", ":", "\n", "        ", "training_data", "=", "HMDB51", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "'training'", ",", "\n", "spatial_transform", "=", "spatial_transform", ",", "\n", "temporal_transform", "=", "temporal_transform", ",", "\n", "target_transform", "=", "target_transform", ")", "\n", "\n", "", "return", "training_data", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.dataset.get_validation_set": [[48, 94], ["datasets.kinetics.Kinetics", "datasets.activitynet.ActivityNet", "datasets.ucf101.UCF101", "datasets.hmdb51.HMDB51"], "function", ["None"], ["", "def", "get_validation_set", "(", "opt", ",", "spatial_transform", ",", "temporal_transform", ",", "\n", "target_transform", ")", ":", "\n", "    ", "assert", "opt", ".", "dataset", "in", "[", "'kinetics'", ",", "'activitynet'", ",", "'ucf101'", ",", "'hmdb51'", "]", "\n", "\n", "if", "opt", ".", "dataset", "==", "'kinetics'", ":", "\n", "        ", "validation_data", "=", "Kinetics", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "'validation'", ",", "\n", "opt", ".", "n_val_samples", ",", "\n", "spatial_transform", ",", "\n", "temporal_transform", ",", "\n", "target_transform", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'activitynet'", ":", "\n", "        ", "validation_data", "=", "ActivityNet", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "'validation'", ",", "\n", "False", ",", "\n", "opt", ".", "n_val_samples", ",", "\n", "spatial_transform", ",", "\n", "temporal_transform", ",", "\n", "target_transform", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'ucf101'", ":", "\n", "        ", "validation_data", "=", "UCF101", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "'training'", ",", "\n", "0", ",", "\n", "spatial_transform", ",", "\n", "temporal_transform", ",", "\n", "target_transform", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'hmdb51'", ":", "\n", "        ", "validation_data", "=", "HMDB51", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "'training'", ",", "\n", "0", ",", "\n", "spatial_transform", ",", "\n", "temporal_transform", ",", "\n", "target_transform", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "return", "validation_data", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.dataset.get_test_set": [[96, 147], ["datasets.kinetics.Kinetics", "datasets.activitynet.ActivityNet", "datasets.ucf101.UCF101", "datasets.hmdb51.HMDB51"], "function", ["None"], ["", "def", "get_test_set", "(", "opt", ",", "spatial_transform", ",", "temporal_transform", ",", "target_transform", ")", ":", "\n", "    ", "assert", "opt", ".", "dataset", "in", "[", "'kinetics'", ",", "'activitynet'", ",", "'ucf101'", ",", "'hmdb51'", "]", "\n", "assert", "opt", ".", "test_subset", "in", "[", "'val'", ",", "'test'", "]", "\n", "\n", "if", "opt", ".", "test_subset", "==", "'val'", ":", "\n", "        ", "subset", "=", "'validation'", "\n", "", "elif", "opt", ".", "test_subset", "==", "'test'", ":", "\n", "        ", "subset", "=", "'testing'", "\n", "", "if", "opt", ".", "dataset", "==", "'kinetics'", ":", "\n", "        ", "test_data", "=", "Kinetics", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "subset", ",", "\n", "0", ",", "\n", "spatial_transform", ",", "\n", "temporal_transform", ",", "\n", "target_transform", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'activitynet'", ":", "\n", "        ", "test_data", "=", "ActivityNet", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "subset", ",", "\n", "True", ",", "\n", "0", ",", "\n", "spatial_transform", ",", "\n", "temporal_transform", ",", "\n", "target_transform", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'ucf101'", ":", "\n", "        ", "test_data", "=", "UCF101", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "subset", ",", "\n", "0", ",", "\n", "spatial_transform", ",", "\n", "temporal_transform", ",", "\n", "target_transform", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "'hmdb51'", ":", "\n", "        ", "test_data", "=", "HMDB51", "(", "\n", "opt", ".", "video_path", ",", "\n", "opt", ".", "annotation_path", ",", "\n", "subset", ",", "\n", "0", ",", "\n", "spatial_transform", ",", "\n", "temporal_transform", ",", "\n", "target_transform", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "\n", "", "return", "test_data", "\n", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.test.calculate_video_results": [[12, 25], ["torch.stack", "torch.stack", "torch.mean", "torch.mean", "torch.topk", "torch.topk", "range", "sorted_scores.size", "video_results.append"], "function", ["None"], ["def", "calculate_video_results", "(", "output_buffer", ",", "video_id", ",", "test_results", ",", "class_names", ")", ":", "\n", "    ", "video_outputs", "=", "torch", ".", "stack", "(", "output_buffer", ")", "\n", "average_scores", "=", "torch", ".", "mean", "(", "video_outputs", ",", "dim", "=", "0", ")", "\n", "sorted_scores", ",", "locs", "=", "torch", ".", "topk", "(", "average_scores", ",", "k", "=", "10", ")", "\n", "\n", "video_results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "sorted_scores", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "video_results", ".", "append", "(", "{", "\n", "'label'", ":", "class_names", "[", "locs", "[", "i", "]", "]", ",", "\n", "'score'", ":", "sorted_scores", "[", "i", "]", "\n", "}", ")", "\n", "\n", "", "test_results", "[", "'results'", "]", "[", "video_id", "]", "=", "video_results", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.test.test": [[27, 75], ["print", "model.eval", "utils.AverageMeter", "utils.AverageMeter", "time.time", "enumerate", "utils.AverageMeter.update", "torch.autograd.Variable", "model", "range", "utils.AverageMeter.update", "time.time", "print", "open", "json.dump", "torch.softmax", "F.softmax.size", "output_buffer.append", "os.path.join", "time.time", "test.calculate_video_results", "outputs[].data.cpu", "open", "json.dump", "time.time", "len", "os.path.join"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.update", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.update", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.test.calculate_video_results"], ["", "def", "test", "(", "data_loader", ",", "model", ",", "opt", ",", "class_names", ")", ":", "\n", "    ", "print", "(", "'test'", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "output_buffer", "=", "[", "]", "\n", "previous_video_id", "=", "''", "\n", "test_results", "=", "{", "'results'", ":", "{", "}", "}", "\n", "for", "i", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "\n", "\n", "inputs", "=", "Variable", "(", "inputs", ",", "volatile", "=", "True", ")", "\n", "outputs", "=", "model", "(", "inputs", ")", "\n", "if", "not", "opt", ".", "no_softmax_in_test", ":", "\n", "            ", "outputs", "=", "F", ".", "softmax", "(", "outputs", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "outputs", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "if", "not", "(", "i", "==", "0", "and", "j", "==", "0", ")", "and", "targets", "[", "j", "]", "!=", "previous_video_id", ":", "\n", "                ", "calculate_video_results", "(", "output_buffer", ",", "previous_video_id", ",", "\n", "test_results", ",", "class_names", ")", "\n", "output_buffer", "=", "[", "]", "\n", "", "output_buffer", ".", "append", "(", "outputs", "[", "j", "]", ".", "data", ".", "cpu", "(", ")", ")", "\n", "previous_video_id", "=", "targets", "[", "j", "]", "\n", "\n", "", "if", "(", "i", "%", "100", ")", "==", "0", ":", "\n", "            ", "with", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "opt", ".", "result_path", ",", "'{}.json'", ".", "format", "(", "\n", "opt", ".", "test_subset", ")", ")", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "test_results", ",", "f", ")", "\n", "\n", "", "", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end_time", ")", "\n", "end_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "print", "(", "'[{}/{}]\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'", ".", "format", "(", "\n", "i", "+", "1", ",", "\n", "len", "(", "data_loader", ")", ",", "\n", "batch_time", "=", "batch_time", ",", "\n", "data_time", "=", "data_time", ")", ")", "\n", "", "with", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "opt", ".", "result_path", ",", "'{}.json'", ".", "format", "(", "opt", ".", "test_subset", ")", ")", ",", "\n", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "test_results", ",", "f", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.temporal_transforms.LoopPadding.__init__": [[7, 9], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.temporal_transforms.LoopPadding.__call__": [[10, 19], ["out.append", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "frame_indices", ")", ":", "\n", "        ", "out", "=", "frame_indices", "\n", "\n", "for", "index", "in", "out", ":", "\n", "            ", "if", "len", "(", "out", ")", ">=", "self", ".", "size", ":", "\n", "                ", "break", "\n", "", "out", ".", "append", "(", "index", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.temporal_transforms.TemporalBeginCrop.__init__": [[31, 33], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.temporal_transforms.TemporalBeginCrop.__call__": [[34, 43], ["out.append", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "frame_indices", ")", ":", "\n", "        ", "out", "=", "frame_indices", "[", ":", "self", ".", "size", "]", "\n", "\n", "for", "index", "in", "out", ":", "\n", "            ", "if", "len", "(", "out", ")", ">=", "self", ".", "size", ":", "\n", "                ", "break", "\n", "", "out", ".", "append", "(", "index", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.temporal_transforms.TemporalCenterCrop.__init__": [[55, 57], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.temporal_transforms.TemporalCenterCrop.__call__": [[58, 78], ["max", "min", "len", "len", "out.append", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "frame_indices", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            frame_indices (list): frame indices to be cropped.\n        Returns:\n            list: Cropped frame indices.\n        \"\"\"", "\n", "\n", "center_index", "=", "len", "(", "frame_indices", ")", "//", "2", "\n", "begin_index", "=", "max", "(", "0", ",", "center_index", "-", "(", "self", ".", "size", "//", "2", ")", ")", "\n", "end_index", "=", "min", "(", "begin_index", "+", "self", ".", "size", ",", "len", "(", "frame_indices", ")", ")", "\n", "\n", "out", "=", "frame_indices", "[", "begin_index", ":", "end_index", "]", "\n", "\n", "for", "index", "in", "out", ":", "\n", "            ", "if", "len", "(", "out", ")", ">=", "self", ".", "size", ":", "\n", "                ", "break", "\n", "", "out", ".", "append", "(", "index", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.temporal_transforms.TemporalRandomCrop.__init__": [[90, 92], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.temporal_transforms.TemporalRandomCrop.__call__": [[93, 113], ["max", "random.randint", "min", "len", "out.append", "len", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "frame_indices", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            frame_indices (list): frame indices to be cropped.\n        Returns:\n            list: Cropped frame indices.\n        \"\"\"", "\n", "\n", "rand_end", "=", "max", "(", "0", ",", "len", "(", "frame_indices", ")", "-", "self", ".", "size", "-", "1", ")", "\n", "begin_index", "=", "random", ".", "randint", "(", "0", ",", "rand_end", ")", "\n", "end_index", "=", "min", "(", "begin_index", "+", "self", ".", "size", ",", "len", "(", "frame_indices", ")", ")", "\n", "\n", "out", "=", "frame_indices", "[", "begin_index", ":", "end_index", "]", "\n", "\n", "for", "index", "in", "out", ":", "\n", "            ", "if", "len", "(", "out", ")", ">=", "self", ".", "size", ":", "\n", "                ", "break", "\n", "", "out", ".", "append", "(", "index", ")", "\n", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.model.Identity.__init__": [[10, 12], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Identity", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.model.Identity.forward": [[13, 15], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.model.generate_model": [[18, 218], ["pre_act_resnet.resnet200.cuda", "torch.nn.DataParallel", "models.resnet.resnet10", "print", "torch.load", "pre_act_resnet.resnet200.load_state_dict", "get_fine_tuning_parameters", "print", "torch.load", "pre_act_resnet.resnet200.load_state_dict", "get_fine_tuning_parameters", "models.resnet.resnet18", "models.wide_resnet.resnet50", "torch.nn.Linear", "pre_act_resnet.resnet200.module.classifier.cuda", "torch.nn.Linear", "pre_act_resnet.resnet200.module.fc.cuda", "torch.nn.Linear", "torch.nn.Linear", "models.resnet.resnet34", "models.resnext.resnet50", "models.resnet.resnet50", "models.resnext.resnet101", "models.pre_act_resnet.resnet18", "models.resnet.resnet101", "models.resnext.resnet152", "models.pre_act_resnet.resnet34", "models.densenet.densenet121", "models.resnet.resnet152", "models.pre_act_resnet.resnet50", "models.densenet.densenet169", "models.resnet.resnet200", "models.pre_act_resnet.resnet101", "models.densenet.densenet201", "models.pre_act_resnet.resnet152", "models.densenet.densenet264", "models.pre_act_resnet.resnet200"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet10", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.get_fine_tuning_parameters", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.get_fine_tuning_parameters", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet18", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet50", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet34", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet50", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet50", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet101", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet18", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet101", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet152", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet34", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet.densenet121", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet152", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet50", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet.densenet169", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet200", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet101", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet.densenet201", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet152", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet.densenet264", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet200"], ["", "", "def", "generate_model", "(", "opt", ")", ":", "\n", "    ", "assert", "opt", ".", "model", "in", "[", "\n", "'resnet'", ",", "'preresnet'", ",", "'wideresnet'", ",", "'resnext'", ",", "'densenet'", "\n", "]", "\n", "\n", "if", "opt", ".", "model", "==", "'resnet'", ":", "\n", "        ", "assert", "opt", ".", "model_depth", "in", "[", "10", ",", "18", ",", "34", ",", "50", ",", "101", ",", "152", ",", "200", "]", "\n", "\n", "from", "models", ".", "resnet", "import", "get_fine_tuning_parameters", "\n", "\n", "if", "opt", ".", "model_depth", "==", "10", ":", "\n", "            ", "model", "=", "resnet", ".", "resnet10", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "18", ":", "\n", "            ", "model", "=", "resnet", ".", "resnet18", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "34", ":", "\n", "            ", "model", "=", "resnet", ".", "resnet34", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "50", ":", "\n", "            ", "model", "=", "resnet", ".", "resnet50", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "101", ":", "\n", "            ", "model", "=", "resnet", ".", "resnet101", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "152", ":", "\n", "            ", "model", "=", "resnet", ".", "resnet152", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "200", ":", "\n", "            ", "model", "=", "resnet", ".", "resnet200", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "", "elif", "opt", ".", "model", "==", "'wideresnet'", ":", "\n", "        ", "assert", "opt", ".", "model_depth", "in", "[", "50", "]", "\n", "\n", "from", "models", ".", "wide_resnet", "import", "get_fine_tuning_parameters", "\n", "\n", "if", "opt", ".", "model_depth", "==", "50", ":", "\n", "            ", "model", "=", "wide_resnet", ".", "resnet50", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "k", "=", "opt", ".", "wide_resnet_k", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "", "elif", "opt", ".", "model", "==", "'resnext'", ":", "\n", "        ", "assert", "opt", ".", "model_depth", "in", "[", "50", ",", "101", ",", "152", "]", "\n", "\n", "from", "models", ".", "resnext", "import", "get_fine_tuning_parameters", "\n", "\n", "if", "opt", ".", "model_depth", "==", "50", ":", "\n", "            ", "model", "=", "resnext", ".", "resnet50", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "cardinality", "=", "opt", ".", "resnext_cardinality", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "101", ":", "\n", "            ", "model", "=", "resnext", ".", "resnet101", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "cardinality", "=", "opt", ".", "resnext_cardinality", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "152", ":", "\n", "            ", "model", "=", "resnext", ".", "resnet152", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "cardinality", "=", "opt", ".", "resnext_cardinality", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "", "elif", "opt", ".", "model", "==", "'preresnet'", ":", "\n", "        ", "assert", "opt", ".", "model_depth", "in", "[", "18", ",", "34", ",", "50", ",", "101", ",", "152", ",", "200", "]", "\n", "\n", "from", "models", ".", "pre_act_resnet", "import", "get_fine_tuning_parameters", "\n", "\n", "if", "opt", ".", "model_depth", "==", "18", ":", "\n", "            ", "model", "=", "pre_act_resnet", ".", "resnet18", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "34", ":", "\n", "            ", "model", "=", "pre_act_resnet", ".", "resnet34", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "50", ":", "\n", "            ", "model", "=", "pre_act_resnet", ".", "resnet50", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "101", ":", "\n", "            ", "model", "=", "pre_act_resnet", ".", "resnet101", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "152", ":", "\n", "            ", "model", "=", "pre_act_resnet", ".", "resnet152", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "200", ":", "\n", "            ", "model", "=", "pre_act_resnet", ".", "resnet200", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "shortcut_type", "=", "opt", ".", "resnet_shortcut", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "", "elif", "opt", ".", "model", "==", "'densenet'", ":", "\n", "        ", "assert", "opt", ".", "model_depth", "in", "[", "121", ",", "169", ",", "201", ",", "264", "]", "\n", "\n", "from", "models", ".", "densenet", "import", "get_fine_tuning_parameters", "\n", "\n", "if", "opt", ".", "model_depth", "==", "121", ":", "\n", "            ", "model", "=", "densenet", ".", "densenet121", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "169", ":", "\n", "            ", "model", "=", "densenet", ".", "densenet169", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "201", ":", "\n", "            ", "model", "=", "densenet", ".", "densenet201", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "", "elif", "opt", ".", "model_depth", "==", "264", ":", "\n", "            ", "model", "=", "densenet", ".", "densenet264", "(", "\n", "num_classes", "=", "opt", ".", "n_classes", ",", "\n", "sample_size", "=", "opt", ".", "sample_size", ",", "\n", "sample_duration", "=", "opt", ".", "sample_duration", ")", "\n", "\n", "", "", "if", "not", "opt", ".", "no_cuda", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "model", "=", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "None", ")", "\n", "\n", "if", "opt", ".", "pretrain_path", ":", "\n", "            ", "print", "(", "'loading pretrained model {}'", ".", "format", "(", "opt", ".", "pretrain_path", ")", ")", "\n", "pretrain", "=", "torch", ".", "load", "(", "opt", ".", "pretrain_path", ")", "\n", "assert", "opt", ".", "arch", "==", "pretrain", "[", "'arch'", "]", "\n", "\n", "model", ".", "load_state_dict", "(", "pretrain", "[", "'state_dict'", "]", ")", "\n", "\n", "#            print(model)", "\n", "\n", "if", "opt", ".", "model", "==", "'densenet'", ":", "\n", "                ", "model", ".", "module", ".", "classifier", "=", "nn", ".", "Linear", "(", "\n", "model", ".", "module", ".", "classifier", ".", "in_features", ",", "opt", ".", "n_finetune_classes", ")", "\n", "model", ".", "module", ".", "classifier", "=", "model", ".", "module", ".", "classifier", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "module", ".", "fc", "=", "nn", ".", "Linear", "(", "model", ".", "module", ".", "fc", ".", "in_features", ",", "\n", "opt", ".", "n_finetune_classes", ")", "\n", "model", ".", "module", ".", "fc", "=", "model", ".", "module", ".", "fc", ".", "cuda", "(", ")", "\n", "\n", "", "parameters", "=", "get_fine_tuning_parameters", "(", "model", ",", "opt", ".", "ft_begin_index", ")", "\n", "return", "model", "\n", "", "", "else", ":", "\n", "        ", "if", "opt", ".", "pretrain_path", ":", "\n", "            ", "print", "(", "'loading pretrained model {}'", ".", "format", "(", "opt", ".", "pretrain_path", ")", ")", "\n", "pretrain", "=", "torch", ".", "load", "(", "opt", ".", "pretrain_path", ")", "\n", "assert", "opt", ".", "arch", "==", "pretrain", "[", "'arch'", "]", "\n", "\n", "model", ".", "load_state_dict", "(", "pretrain", "[", "'state_dict'", "]", ")", "\n", "\n", "if", "opt", ".", "model", "==", "'densenet'", ":", "\n", "                ", "model", ".", "classifier", "=", "nn", ".", "Linear", "(", "\n", "model", ".", "classifier", ".", "in_features", ",", "opt", ".", "n_finetune_classes", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "fc", "=", "nn", ".", "Linear", "(", "model", ".", "fc", ".", "in_features", ",", "\n", "opt", ".", "codelength", ")", "\n", "\n", "", "parameters", "=", "get_fine_tuning_parameters", "(", "model", ",", "opt", ".", "ft_begin_index", ")", "\n", "return", "model", "\n", "\n", "", "", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.mean.get_mean": [[1, 13], ["None"], "function", ["None"], ["def", "get_mean", "(", "norm_value", "=", "255", ",", "dataset", "=", "'activitynet'", ")", ":", "\n", "    ", "assert", "dataset", "in", "[", "'activitynet'", ",", "'kinetics'", "]", "\n", "\n", "if", "dataset", "==", "'activitynet'", ":", "\n", "        ", "return", "[", "\n", "114.7748", "/", "norm_value", ",", "107.7354", "/", "norm_value", ",", "99.4750", "/", "norm_value", "\n", "]", "\n", "", "elif", "dataset", "==", "'kinetics'", ":", "\n", "# Kinetics (10 videos for each class)", "\n", "        ", "return", "[", "\n", "110.63666788", "/", "norm_value", ",", "103.16065604", "/", "norm_value", ",", "\n", "96.29023126", "/", "norm_value", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.mean.get_std": [[16, 21], ["None"], "function", ["None"], ["", "", "def", "get_std", "(", "norm_value", "=", "255", ")", ":", "\n", "# Kinetics (10 videos for each class)", "\n", "    ", "return", "[", "\n", "38.7568578", "/", "norm_value", ",", "37.88248729", "/", "norm_value", ",", "\n", "40.02898126", "/", "norm_value", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.target_transforms.Compose.__init__": [[7, 9], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.target_transforms.Compose.__call__": [[10, 15], ["dst.append", "t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "target", ")", ":", "\n", "        ", "dst", "=", "[", "]", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "dst", ".", "append", "(", "t", "(", "target", ")", ")", "\n", "", "return", "dst", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.target_transforms.ClassLabel.__call__": [[19, 21], ["None"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "target", ")", ":", "\n", "        ", "return", "target", "[", "'label'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.target_transforms.VideoID.__call__": [[25, 27], ["None"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "target", ")", ":", "\n", "        ", "return", "target", "[", "'video_id'", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.__init__": [[7, 9], ["utils.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.reset": [[10, 15], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.update": [[16, 21], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.Logger.__init__": [[25, 31], ["open", "csv.writer", "utils.Logger.logger.writerow"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "header", ")", ":", "\n", "        ", "self", ".", "log_file", "=", "open", "(", "path", ",", "'w'", ")", "\n", "self", ".", "logger", "=", "csv", ".", "writer", "(", "self", ".", "log_file", ",", "delimiter", "=", "'\\t'", ")", "\n", "\n", "self", ".", "logger", ".", "writerow", "(", "header", ")", "\n", "self", ".", "header", "=", "header", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.Logger.__del": [[32, 34], ["utils.Logger.log_file.close"], "methods", ["None"], ["", "def", "__del", "(", "self", ")", ":", "\n", "        ", "self", ".", "log_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.Logger.log": [[35, 43], ["utils.Logger.logger.writerow", "utils.Logger.log_file.flush", "write_values.append"], "methods", ["None"], ["", "def", "log", "(", "self", ",", "values", ")", ":", "\n", "        ", "write_values", "=", "[", "]", "\n", "for", "col", "in", "self", ".", "header", ":", "\n", "            ", "assert", "col", "in", "values", "\n", "write_values", ".", "append", "(", "values", "[", "col", "]", ")", "\n", "\n", "", "self", ".", "logger", ".", "writerow", "(", "write_values", ")", "\n", "self", ".", "log_file", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.load_value_file": [[45, 50], ["open", "float", "input_file.read().rstrip", "input_file.read"], "function", ["None"], ["", "", "def", "load_value_file", "(", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "'r'", ")", "as", "input_file", ":", "\n", "        ", "value", "=", "float", "(", "input_file", ".", "read", "(", ")", ".", "rstrip", "(", "'\\n\\r'", ")", ")", "\n", "\n", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.calculate_accuracy": [[52, 61], ["targets.size", "outputs.topk", "pred.t.t", "pred.t.eq", "targets.view", "pred.eq.float().sum", "pred.eq.float"], "function", ["None"], ["", "def", "calculate_accuracy", "(", "outputs", ",", "targets", ")", ":", "\n", "    ", "batch_size", "=", "targets", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "outputs", ".", "topk", "(", "1", ",", "1", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "targets", ".", "view", "(", "1", ",", "-", "1", ")", ")", "\n", "n_correct_elems", "=", "correct", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "data", "[", "0", "]", "\n", "\n", "return", "n_correct_elems", "/", "batch_size", "\n", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.ucf101_json.convert_csv_to_dict": [[7, 29], ["pandas.read_csv", "range", "range", "pd.read_csv.ix[].split", "keys.append", "key_labels.append", "len", "slash_rows[].split"], "function", ["None"], ["def", "convert_csv_to_dict", "(", "csv_path", ",", "subset", ")", ":", "\n", "    ", "data", "=", "pd", ".", "read_csv", "(", "csv_path", ",", "delimiter", "=", "' '", ",", "header", "=", "None", ")", "\n", "keys", "=", "[", "]", "\n", "key_labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "data", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "row", "=", "data", ".", "ix", "[", "i", ",", ":", "]", "\n", "slash_rows", "=", "data", ".", "ix", "[", "i", ",", "0", "]", ".", "split", "(", "'/'", ")", "\n", "class_name", "=", "slash_rows", "[", "0", "]", "\n", "basename", "=", "slash_rows", "[", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "\n", "keys", ".", "append", "(", "basename", ")", "\n", "key_labels", ".", "append", "(", "class_name", ")", "\n", "\n", "", "database", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "keys", ")", ")", ":", "\n", "        ", "key", "=", "keys", "[", "i", "]", "\n", "database", "[", "key", "]", "=", "{", "}", "\n", "database", "[", "key", "]", "[", "'subset'", "]", "=", "subset", "\n", "label", "=", "key_labels", "[", "i", "]", "\n", "database", "[", "key", "]", "[", "'annotations'", "]", "=", "{", "'label'", ":", "label", "}", "\n", "\n", "", "return", "database", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.ucf101_json.load_labels": [[30, 36], ["pandas.read_csv", "range", "labels.append"], "function", ["None"], ["", "def", "load_labels", "(", "label_csv_path", ")", ":", "\n", "    ", "data", "=", "pd", ".", "read_csv", "(", "label_csv_path", ",", "delimiter", "=", "' '", ",", "header", "=", "None", ")", "\n", "labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "data", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "labels", ".", "append", "(", "data", ".", "ix", "[", "i", ",", "1", "]", ")", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.ucf101_json.convert_ucf101_csv_to_activitynet_json": [[37, 51], ["ucf101_json.load_labels", "ucf101_json.convert_csv_to_dict", "ucf101_json.convert_csv_to_dict", "dst_data[].update", "dst_data[].update", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.kinetics_json.load_labels", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.hmdb51_json.convert_csv_to_dict", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.hmdb51_json.convert_csv_to_dict", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.update", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.update"], ["", "def", "convert_ucf101_csv_to_activitynet_json", "(", "label_csv_path", ",", "train_csv_path", ",", "\n", "val_csv_path", ",", "dst_json_path", ")", ":", "\n", "    ", "labels", "=", "load_labels", "(", "label_csv_path", ")", "\n", "train_database", "=", "convert_csv_to_dict", "(", "train_csv_path", ",", "'training'", ")", "\n", "val_database", "=", "convert_csv_to_dict", "(", "val_csv_path", ",", "'validation'", ")", "\n", "\n", "dst_data", "=", "{", "}", "\n", "dst_data", "[", "'labels'", "]", "=", "labels", "\n", "dst_data", "[", "'database'", "]", "=", "{", "}", "\n", "dst_data", "[", "'database'", "]", ".", "update", "(", "train_database", ")", "\n", "dst_data", "[", "'database'", "]", ".", "update", "(", "val_database", ")", "\n", "\n", "with", "open", "(", "dst_json_path", ",", "'w'", ")", "as", "dst_file", ":", "\n", "        ", "json", ".", "dump", "(", "dst_data", ",", "dst_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.n_frames_kinetics.class_process": [[6, 28], ["os.path.join", "os.listdir", "os.path.isdir", "os.path.join", "os.listdir", "image_indices.append", "len", "print", "image_indices.sort", "print", "open", "dst_file.write", "int", "os.path.join", "str"], "function", ["None"], ["def", "class_process", "(", "dir_path", ",", "class_name", ")", ":", "\n", "  ", "class_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "class_name", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "class_path", ")", ":", "\n", "    ", "return", "\n", "\n", "", "for", "file_name", "in", "os", ".", "listdir", "(", "class_path", ")", ":", "\n", "    ", "video_dir_path", "=", "os", ".", "path", ".", "join", "(", "class_path", ",", "file_name", ")", "\n", "image_indices", "=", "[", "]", "\n", "for", "image_file_name", "in", "os", ".", "listdir", "(", "video_dir_path", ")", ":", "\n", "      ", "if", "'image'", "not", "in", "image_file_name", ":", "\n", "        ", "continue", "\n", "", "image_indices", ".", "append", "(", "int", "(", "image_file_name", "[", "6", ":", "11", "]", ")", ")", "\n", "\n", "", "if", "len", "(", "image_indices", ")", "==", "0", ":", "\n", "      ", "print", "(", "'no image files'", ",", "video_dir_path", ")", "\n", "n_frames", "=", "0", "\n", "", "else", ":", "\n", "      ", "image_indices", ".", "sort", "(", "reverse", "=", "True", ")", "\n", "n_frames", "=", "image_indices", "[", "0", "]", "\n", "print", "(", "video_dir_path", ",", "n_frames", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "video_dir_path", ",", "'n_frames'", ")", ",", "'w'", ")", "as", "dst_file", ":", "\n", "      ", "dst_file", ".", "write", "(", "str", "(", "n_frames", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.n_frames_ucf101_hmdb51.class_process": [[6, 28], ["os.path.join", "os.listdir", "os.path.isdir", "os.path.join", "os.listdir", "image_indices.append", "len", "print", "image_indices.sort", "print", "open", "dst_file.write", "int", "os.path.join", "str"], "function", ["None"], ["def", "class_process", "(", "dir_path", ",", "class_name", ")", ":", "\n", "  ", "class_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "class_name", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "class_path", ")", ":", "\n", "    ", "return", "\n", "\n", "", "for", "file_name", "in", "os", ".", "listdir", "(", "class_path", ")", ":", "\n", "    ", "video_dir_path", "=", "os", ".", "path", ".", "join", "(", "class_path", ",", "file_name", ")", "\n", "image_indices", "=", "[", "]", "\n", "for", "image_file_name", "in", "os", ".", "listdir", "(", "video_dir_path", ")", ":", "\n", "      ", "if", "'image'", "not", "in", "image_file_name", ":", "\n", "        ", "continue", "\n", "", "image_indices", ".", "append", "(", "int", "(", "image_file_name", "[", "6", ":", "11", "]", ")", ")", "\n", "\n", "", "if", "len", "(", "image_indices", ")", "==", "0", ":", "\n", "      ", "print", "(", "'no image files'", ",", "video_dir_path", ")", "\n", "n_frames", "=", "0", "\n", "", "else", ":", "\n", "      ", "image_indices", ".", "sort", "(", "reverse", "=", "True", ")", "\n", "n_frames", "=", "image_indices", "[", "0", "]", "\n", "print", "(", "video_dir_path", ",", "n_frames", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "video_dir_path", ",", "'n_frames'", ")", ",", "'w'", ")", "as", "dst_file", ":", "\n", "      ", "dst_file", ".", "write", "(", "str", "(", "n_frames", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.video_jpg_kinetics.class_process": [[6, 39], ["os.path.join", "os.path.join", "os.listdir", "os.path.isdir", "os.path.exists", "os.mkdir", "os.path.splitext", "os.path.join", "os.path.join", "print", "subprocess.call", "print", "os.path.exists", "os.mkdir", "print", "os.path.exists", "subprocess.call", "print", "os.mkdir", "os.path.join"], "function", ["None"], ["def", "class_process", "(", "dir_path", ",", "dst_dir_path", ",", "class_name", ")", ":", "\n", "  ", "class_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "class_name", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "class_path", ")", ":", "\n", "    ", "return", "\n", "\n", "", "dst_class_path", "=", "os", ".", "path", ".", "join", "(", "dst_dir_path", ",", "class_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dst_class_path", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "dst_class_path", ")", "\n", "\n", "", "for", "file_name", "in", "os", ".", "listdir", "(", "class_path", ")", ":", "\n", "    ", "if", "'.mp4'", "not", "in", "file_name", ":", "\n", "      ", "continue", "\n", "", "name", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "file_name", ")", "\n", "dst_directory_path", "=", "os", ".", "path", ".", "join", "(", "dst_class_path", ",", "name", ")", "\n", "\n", "video_file_path", "=", "os", ".", "path", ".", "join", "(", "class_path", ",", "file_name", ")", "\n", "try", ":", "\n", "      ", "if", "os", ".", "path", ".", "exists", "(", "dst_directory_path", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "dst_directory_path", ",", "'image_00001.jpg'", ")", ")", ":", "\n", "          ", "subprocess", ".", "call", "(", "'rm -r \\\"{}\\\"'", ".", "format", "(", "dst_directory_path", ")", ",", "shell", "=", "True", ")", "\n", "print", "(", "'remove {}'", ".", "format", "(", "dst_directory_path", ")", ")", "\n", "os", ".", "mkdir", "(", "dst_directory_path", ")", "\n", "", "else", ":", "\n", "          ", "continue", "\n", "", "", "else", ":", "\n", "        ", "os", ".", "mkdir", "(", "dst_directory_path", ")", "\n", "", "", "except", ":", "\n", "      ", "print", "(", "dst_directory_path", ")", "\n", "continue", "\n", "", "cmd", "=", "'ffmpeg -i \\\"{}\\\" -vf scale=-1:240 \\\"{}/image_%05d.jpg\\\"'", ".", "format", "(", "video_file_path", ",", "dst_directory_path", ")", "\n", "print", "(", "cmd", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ")", "\n", "print", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.kinetics_json.convert_csv_to_dict": [[7, 32], ["pandas.read_csv", "range", "range", "keys.append", "len", "key_labels.append"], "function", ["None"], ["def", "convert_csv_to_dict", "(", "csv_path", ",", "subset", ")", ":", "\n", "    ", "data", "=", "pd", ".", "read_csv", "(", "csv_path", ")", "\n", "keys", "=", "[", "]", "\n", "key_labels", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "data", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "row", "=", "data", ".", "ix", "[", "i", ",", ":", "]", "\n", "basename", "=", "'%s_%s_%s'", "%", "(", "row", "[", "'youtube_id'", "]", ",", "\n", "'%06d'", "%", "row", "[", "'time_start'", "]", ",", "\n", "'%06d'", "%", "row", "[", "'time_end'", "]", ")", "\n", "keys", ".", "append", "(", "basename", ")", "\n", "if", "subset", "!=", "'testing'", ":", "\n", "            ", "key_labels", ".", "append", "(", "row", "[", "'label'", "]", ")", "\n", "\n", "", "", "database", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "keys", ")", ")", ":", "\n", "        ", "key", "=", "keys", "[", "i", "]", "\n", "database", "[", "key", "]", "=", "{", "}", "\n", "database", "[", "key", "]", "[", "'subset'", "]", "=", "subset", "\n", "if", "subset", "!=", "'testing'", ":", "\n", "            ", "label", "=", "key_labels", "[", "i", "]", "\n", "database", "[", "key", "]", "[", "'annotations'", "]", "=", "{", "'label'", ":", "label", "}", "\n", "", "else", ":", "\n", "            ", "database", "[", "key", "]", "[", "'annotations'", "]", "=", "{", "}", "\n", "\n", "", "", "return", "database", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.kinetics_json.load_labels": [[33, 36], ["pandas.read_csv", "data[].unique().tolist", "data[].unique"], "function", ["None"], ["", "def", "load_labels", "(", "train_csv_path", ")", ":", "\n", "    ", "data", "=", "pd", ".", "read_csv", "(", "train_csv_path", ")", "\n", "return", "data", "[", "'label'", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.kinetics_json.convert_kinetics_csv_to_activitynet_json": [[37, 52], ["kinetics_json.load_labels", "kinetics_json.convert_csv_to_dict", "kinetics_json.convert_csv_to_dict", "kinetics_json.convert_csv_to_dict", "dst_data[].update", "dst_data[].update", "dst_data[].update", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.kinetics_json.load_labels", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.hmdb51_json.convert_csv_to_dict", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.hmdb51_json.convert_csv_to_dict", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.hmdb51_json.convert_csv_to_dict", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.update", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.update", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.update"], ["", "def", "convert_kinetics_csv_to_activitynet_json", "(", "train_csv_path", ",", "val_csv_path", ",", "test_csv_path", ",", "dst_json_path", ")", ":", "\n", "    ", "labels", "=", "load_labels", "(", "train_csv_path", ")", "\n", "train_database", "=", "convert_csv_to_dict", "(", "train_csv_path", ",", "'training'", ")", "\n", "val_database", "=", "convert_csv_to_dict", "(", "val_csv_path", ",", "'validation'", ")", "\n", "test_database", "=", "convert_csv_to_dict", "(", "test_csv_path", ",", "'testing'", ")", "\n", "\n", "dst_data", "=", "{", "}", "\n", "dst_data", "[", "'labels'", "]", "=", "labels", "\n", "dst_data", "[", "'database'", "]", "=", "{", "}", "\n", "dst_data", "[", "'database'", "]", ".", "update", "(", "train_database", ")", "\n", "dst_data", "[", "'database'", "]", ".", "update", "(", "val_database", ")", "\n", "dst_data", "[", "'database'", "]", ".", "update", "(", "test_database", ")", "\n", "\n", "with", "open", "(", "dst_json_path", ",", "'w'", ")", "as", "dst_file", ":", "\n", "        ", "json", ".", "dump", "(", "dst_data", ",", "dst_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.video_jpg_ucf101_hmdb51.class_process": [[6, 39], ["os.path.join", "os.path.join", "os.listdir", "os.path.isdir", "os.path.exists", "os.mkdir", "os.path.splitext", "os.path.join", "os.path.join", "print", "subprocess.call", "print", "os.path.exists", "os.mkdir", "print", "os.path.exists", "subprocess.call", "print", "os.mkdir", "os.path.join"], "function", ["None"], ["def", "class_process", "(", "dir_path", ",", "dst_dir_path", ",", "class_name", ")", ":", "\n", "  ", "class_path", "=", "os", ".", "path", ".", "join", "(", "dir_path", ",", "class_name", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "class_path", ")", ":", "\n", "    ", "return", "\n", "\n", "", "dst_class_path", "=", "os", ".", "path", ".", "join", "(", "dst_dir_path", ",", "class_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dst_class_path", ")", ":", "\n", "    ", "os", ".", "mkdir", "(", "dst_class_path", ")", "\n", "\n", "", "for", "file_name", "in", "os", ".", "listdir", "(", "class_path", ")", ":", "\n", "    ", "if", "'.avi'", "not", "in", "file_name", ":", "\n", "      ", "continue", "\n", "", "name", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "file_name", ")", "\n", "dst_directory_path", "=", "os", ".", "path", ".", "join", "(", "dst_class_path", ",", "name", ")", "\n", "\n", "video_file_path", "=", "os", ".", "path", ".", "join", "(", "class_path", ",", "file_name", ")", "\n", "try", ":", "\n", "      ", "if", "os", ".", "path", ".", "exists", "(", "dst_directory_path", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "dst_directory_path", ",", "'image_00001.jpg'", ")", ")", ":", "\n", "          ", "subprocess", ".", "call", "(", "'rm -r \\\"{}\\\"'", ".", "format", "(", "dst_directory_path", ")", ",", "shell", "=", "True", ")", "\n", "print", "(", "'remove {}'", ".", "format", "(", "dst_directory_path", ")", ")", "\n", "os", ".", "mkdir", "(", "dst_directory_path", ")", "\n", "", "else", ":", "\n", "          ", "continue", "\n", "", "", "else", ":", "\n", "        ", "os", ".", "mkdir", "(", "dst_directory_path", ")", "\n", "", "", "except", ":", "\n", "      ", "print", "(", "dst_directory_path", ")", "\n", "continue", "\n", "", "cmd", "=", "'ffmpeg -i \\\"{}\\\" -vf scale=-1:240 \\\"{}/image_%05d.jpg\\\"'", ".", "format", "(", "video_file_path", ",", "dst_directory_path", ")", "\n", "print", "(", "cmd", ")", "\n", "subprocess", ".", "call", "(", "cmd", ",", "shell", "=", "True", ")", "\n", "print", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.hmdb51_json.convert_csv_to_dict": [[7, 37], ["os.listdir", "pandas.read_csv", "range", "range", "os.path.join", "keys.append", "subsets.append", "len", "row[].split", "filename.split"], "function", ["None"], ["def", "convert_csv_to_dict", "(", "csv_dir_path", ",", "split_index", ")", ":", "\n", "    ", "database", "=", "{", "}", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "csv_dir_path", ")", ":", "\n", "        ", "if", "'split{}'", ".", "format", "(", "split_index", ")", "not", "in", "filename", ":", "\n", "            ", "continue", "\n", "\n", "", "data", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "csv_dir_path", ",", "filename", ")", ",", "\n", "delimiter", "=", "' '", ",", "header", "=", "None", ")", "\n", "keys", "=", "[", "]", "\n", "subsets", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "data", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "row", "=", "data", ".", "ix", "[", "i", ",", ":", "]", "\n", "if", "row", "[", "1", "]", "==", "0", ":", "\n", "                ", "continue", "\n", "", "elif", "row", "[", "1", "]", "==", "1", ":", "\n", "                ", "subset", "=", "'training'", "\n", "", "elif", "row", "[", "1", "]", "==", "2", ":", "\n", "                ", "subset", "=", "'validation'", "\n", "\n", "", "keys", ".", "append", "(", "row", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ")", "\n", "subsets", ".", "append", "(", "subset", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "keys", ")", ")", ":", "\n", "            ", "key", "=", "keys", "[", "i", "]", "\n", "database", "[", "key", "]", "=", "{", "}", "\n", "database", "[", "key", "]", "[", "'subset'", "]", "=", "subsets", "[", "i", "]", "\n", "label", "=", "'_'", ".", "join", "(", "filename", ".", "split", "(", "'_'", ")", "[", ":", "-", "2", "]", ")", "\n", "database", "[", "key", "]", "[", "'annotations'", "]", "=", "{", "'label'", ":", "label", "}", "\n", "\n", "", "", "return", "database", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.hmdb51_json.get_labels": [[38, 43], ["os.listdir", "sorted", "labels.append", "list", "set", "name.split"], "function", ["None"], ["", "def", "get_labels", "(", "csv_dir_path", ")", ":", "\n", "    ", "labels", "=", "[", "]", "\n", "for", "name", "in", "os", ".", "listdir", "(", "csv_dir_path", ")", ":", "\n", "        ", "labels", ".", "append", "(", "'_'", ".", "join", "(", "name", ".", "split", "(", "'_'", ")", "[", ":", "-", "2", "]", ")", ")", "\n", "", "return", "sorted", "(", "list", "(", "set", "(", "labels", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.hmdb51_json.convert_hmdb51_csv_to_activitynet_json": [[44, 55], ["hmdb51_json.get_labels", "hmdb51_json.convert_csv_to_dict", "dst_data[].update", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.hmdb51_json.get_labels", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.utils.hmdb51_json.convert_csv_to_dict", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.AverageMeter.update"], ["", "def", "convert_hmdb51_csv_to_activitynet_json", "(", "csv_dir_path", ",", "split_index", ",", "dst_json_path", ")", ":", "\n", "    ", "labels", "=", "get_labels", "(", "csv_dir_path", ")", "\n", "database", "=", "convert_csv_to_dict", "(", "csv_dir_path", ",", "split_index", ")", "\n", "\n", "dst_data", "=", "{", "}", "\n", "dst_data", "[", "'labels'", "]", "=", "labels", "\n", "dst_data", "[", "'database'", "]", "=", "{", "}", "\n", "dst_data", "[", "'database'", "]", ".", "update", "(", "database", ")", "\n", "\n", "with", "open", "(", "dst_json_path", ",", "'w'", ")", "as", "dst_file", ":", "\n", "        ", "json", ".", "dump", "(", "dst_data", ",", "dst_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.HMDB51.__init__": [[154, 172], ["hmdb51.make_dataset", "get_loader"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.make_dataset"], ["def", "__init__", "(", "self", ",", "\n", "root_path", ",", "\n", "annotation_path", ",", "\n", "subset", ",", "\n", "n_samples_for_each_video", "=", "1", ",", "\n", "spatial_transform", "=", "None", ",", "\n", "temporal_transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "\n", "sample_duration", "=", "16", ",", "\n", "get_loader", "=", "get_default_video_loader", ")", ":", "\n", "        ", "self", ".", "data", ",", "self", ".", "class_names", "=", "make_dataset", "(", "\n", "root_path", ",", "annotation_path", ",", "subset", ",", "n_samples_for_each_video", ",", "\n", "sample_duration", ")", "\n", "\n", "self", ".", "spatial_transform", "=", "spatial_transform", "\n", "self", ".", "temporal_transform", "=", "temporal_transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "get_loader", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.HMDB51.__getitem__": [[173, 196], ["hmdb51.HMDB51.loader", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "hmdb51.HMDB51.temporal_transform", "hmdb51.HMDB51.spatial_transform.randomize_parameters", "hmdb51.HMDB51.target_transform", "hmdb51.HMDB51.spatial_transform", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.MultiScaleRandomCrop.randomize_parameters"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", "=", "self", ".", "data", "[", "index", "]", "[", "'video'", "]", "\n", "\n", "frame_indices", "=", "self", ".", "data", "[", "index", "]", "[", "'frame_indices'", "]", "\n", "if", "self", ".", "temporal_transform", "is", "not", "None", ":", "\n", "            ", "frame_indices", "=", "self", ".", "temporal_transform", "(", "frame_indices", ")", "\n", "", "clip", "=", "self", ".", "loader", "(", "path", ",", "frame_indices", ")", "\n", "if", "self", ".", "spatial_transform", "is", "not", "None", ":", "\n", "            ", "self", ".", "spatial_transform", ".", "randomize_parameters", "(", ")", "\n", "clip", "=", "[", "self", ".", "spatial_transform", "(", "img", ")", "for", "img", "in", "clip", "]", "\n", "", "clip", "=", "torch", ".", "stack", "(", "clip", ",", "0", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n", "target", "=", "self", ".", "data", "[", "index", "]", "\n", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "clip", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.HMDB51.__len__": [[197, 199], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.pil_loader": [[13, 18], ["open", "PIL.Image.open", "img.convert"], "function", ["None"], ["def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "with", "Image", ".", "open", "(", "f", ")", "as", "img", ":", "\n", "            ", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.accimage_loader": [[20, 27], ["accimage.Image", "hmdb51.pil_loader"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.pil_loader"], ["", "", "", "def", "accimage_loader", "(", "path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "import", "accimage", "\n", "return", "accimage", ".", "Image", "(", "path", ")", "\n", "", "except", "IOError", ":", "\n", "# Potentially a decoding problem, fall back to PIL.Image", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.get_default_image_loader": [[29, 35], ["get_image_backend"], "function", ["None"], ["", "", "def", "get_default_image_loader", "(", ")", ":", "\n", "    ", "from", "torchvision", "import", "get_image_backend", "\n", "if", "get_image_backend", "(", ")", "==", "'accimage'", ":", "\n", "        ", "return", "accimage_loader", "\n", "", "else", ":", "\n", "        ", "return", "pil_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.video_loader": [[37, 47], ["os.path.join", "os.path.exists", "video.append", "image_loader"], "function", ["None"], ["", "", "def", "video_loader", "(", "video_dir_path", ",", "frame_indices", ",", "image_loader", ")", ":", "\n", "    ", "video", "=", "[", "]", "\n", "for", "i", "in", "frame_indices", ":", "\n", "        ", "image_path", "=", "os", ".", "path", ".", "join", "(", "video_dir_path", ",", "'image_{:05d}.jpg'", ".", "format", "(", "i", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "image_path", ")", ":", "\n", "            ", "video", ".", "append", "(", "image_loader", "(", "image_path", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "video", "\n", "\n", "", "", "return", "video", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.get_default_video_loader": [[49, 52], ["hmdb51.get_default_image_loader", "functools.partial"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_default_image_loader"], ["", "def", "get_default_video_loader", "(", ")", ":", "\n", "    ", "image_loader", "=", "get_default_image_loader", "(", ")", "\n", "return", "functools", ".", "partial", "(", "video_loader", ",", "image_loader", "=", "image_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.load_annotation_data": [[54, 57], ["open", "json.load"], "function", ["None"], ["", "def", "load_annotation_data", "(", "data_file_path", ")", ":", "\n", "    ", "with", "open", "(", "data_file_path", ",", "'r'", ")", "as", "data_file", ":", "\n", "        ", "return", "json", ".", "load", "(", "data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.get_class_labels": [[59, 66], ["torch.data"], "function", ["None"], ["", "", "def", "get_class_labels", "(", "data", ")", ":", "\n", "    ", "class_labels_map", "=", "{", "}", "\n", "index", "=", "0", "\n", "for", "class_label", "in", "data", "[", "'labels'", "]", ":", "\n", "        ", "class_labels_map", "[", "class_label", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "return", "class_labels_map", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.get_video_names_and_annotations": [[68, 80], ["data[].items", "video_names.append", "annotations.append", "torch.data"], "function", ["None"], ["", "def", "get_video_names_and_annotations", "(", "data", ",", "subset", ")", ":", "\n", "    ", "video_names", "=", "[", "]", "\n", "annotations", "=", "[", "]", "\n", "\n", "for", "key", ",", "value", "in", "data", "[", "'database'", "]", ".", "items", "(", ")", ":", "\n", "        ", "this_subset", "=", "value", "[", "'subset'", "]", "\n", "if", "this_subset", "==", "subset", ":", "\n", "            ", "label", "=", "value", "[", "'annotations'", "]", "[", "'label'", "]", "\n", "video_names", ".", "append", "(", "'{}/{}'", ".", "format", "(", "label", ",", "key", ")", ")", "\n", "annotations", ".", "append", "(", "value", "[", "'annotations'", "]", ")", "\n", "\n", "", "", "return", "video_names", ",", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.hmdb51.make_dataset": [[82, 135], ["hmdb51.load_annotation_data", "hmdb51.get_video_names_and_annotations", "hmdb51.get_class_labels", "get_class_labels.items", "range", "len", "os.path.join", "os.path.join", "int", "print", "os.path.exists", "utils.load_value_file", "len", "list", "dataset.append", "range", "video_names[].split", "range", "max", "copy.deepcopy", "list", "dataset.append", "len", "math.ceil", "range", "min"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.load_annotation_data", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_video_names_and_annotations", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_class_labels", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.load_value_file"], ["", "def", "make_dataset", "(", "root_path", ",", "annotation_path", ",", "subset", ",", "n_samples_for_each_video", ",", "\n", "sample_duration", ")", ":", "\n", "    ", "data", "=", "load_annotation_data", "(", "annotation_path", ")", "\n", "video_names", ",", "annotations", "=", "get_video_names_and_annotations", "(", "data", ",", "subset", ")", "\n", "class_to_idx", "=", "get_class_labels", "(", "data", ")", "\n", "idx_to_class", "=", "{", "}", "\n", "for", "name", ",", "label", "in", "class_to_idx", ".", "items", "(", ")", ":", "\n", "        ", "idx_to_class", "[", "label", "]", "=", "name", "\n", "\n", "", "dataset", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "video_names", ")", ")", ":", "\n", "        ", "if", "i", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "'dataset loading [{}/{}]'", ".", "format", "(", "i", ",", "len", "(", "video_names", ")", ")", ")", "\n", "\n", "", "video_path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "video_names", "[", "i", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "video_path", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "n_frames_file_path", "=", "os", ".", "path", ".", "join", "(", "video_path", ",", "'n_frames'", ")", "\n", "n_frames", "=", "int", "(", "load_value_file", "(", "n_frames_file_path", ")", ")", "\n", "if", "n_frames", "<=", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "begin_t", "=", "1", "\n", "end_t", "=", "n_frames", "\n", "sample", "=", "{", "\n", "'video'", ":", "video_path", ",", "\n", "'segment'", ":", "[", "begin_t", ",", "end_t", "]", ",", "\n", "'n_frames'", ":", "n_frames", ",", "\n", "'video_id'", ":", "video_names", "[", "i", "]", ".", "split", "(", "'/'", ")", "[", "1", "]", "\n", "}", "\n", "if", "len", "(", "annotations", ")", "!=", "0", ":", "\n", "            ", "sample", "[", "'label'", "]", "=", "class_to_idx", "[", "annotations", "[", "i", "]", "[", "'label'", "]", "]", "\n", "", "else", ":", "\n", "            ", "sample", "[", "'label'", "]", "=", "-", "1", "\n", "\n", "", "if", "n_samples_for_each_video", "==", "1", ":", "\n", "            ", "sample", "[", "'frame_indices'", "]", "=", "list", "(", "range", "(", "1", ",", "n_frames", "+", "1", ")", ")", "\n", "dataset", ".", "append", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "if", "n_samples_for_each_video", ">", "1", ":", "\n", "                ", "step", "=", "max", "(", "1", ",", "\n", "math", ".", "ceil", "(", "(", "n_frames", "-", "1", "-", "sample_duration", ")", "/", "\n", "(", "n_samples_for_each_video", "-", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "step", "=", "sample_duration", "\n", "", "for", "j", "in", "range", "(", "1", ",", "n_frames", ",", "step", ")", ":", "\n", "                ", "sample_j", "=", "copy", ".", "deepcopy", "(", "sample", ")", "\n", "sample_j", "[", "'frame_indices'", "]", "=", "list", "(", "\n", "range", "(", "j", ",", "min", "(", "n_frames", "+", "1", ",", "j", "+", "sample_duration", ")", ")", ")", "\n", "dataset", ".", "append", "(", "sample_j", ")", "\n", "\n", "", "", "", "return", "dataset", ",", "idx_to_class", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.UCF101.__init__": [[154, 172], ["ucf101.make_dataset", "get_loader"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.make_dataset"], ["def", "__init__", "(", "self", ",", "\n", "root_path", ",", "\n", "annotation_path", ",", "\n", "subset", ",", "\n", "n_samples_for_each_video", "=", "1", ",", "\n", "spatial_transform", "=", "None", ",", "\n", "temporal_transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "\n", "sample_duration", "=", "16", ",", "\n", "get_loader", "=", "get_default_video_loader", ")", ":", "\n", "        ", "self", ".", "data", ",", "self", ".", "class_names", "=", "make_dataset", "(", "\n", "root_path", ",", "annotation_path", ",", "subset", ",", "n_samples_for_each_video", ",", "\n", "sample_duration", ")", "\n", "\n", "self", ".", "spatial_transform", "=", "spatial_transform", "\n", "self", ".", "temporal_transform", "=", "temporal_transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "get_loader", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.UCF101.__getitem__": [[173, 196], ["ucf101.UCF101.loader", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "ucf101.UCF101.temporal_transform", "ucf101.UCF101.spatial_transform.randomize_parameters", "ucf101.UCF101.target_transform", "ucf101.UCF101.spatial_transform", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.MultiScaleRandomCrop.randomize_parameters"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", "=", "self", ".", "data", "[", "index", "]", "[", "'video'", "]", "\n", "\n", "frame_indices", "=", "self", ".", "data", "[", "index", "]", "[", "'frame_indices'", "]", "\n", "if", "self", ".", "temporal_transform", "is", "not", "None", ":", "\n", "            ", "frame_indices", "=", "self", ".", "temporal_transform", "(", "frame_indices", ")", "\n", "", "clip", "=", "self", ".", "loader", "(", "path", ",", "frame_indices", ")", "\n", "if", "self", ".", "spatial_transform", "is", "not", "None", ":", "\n", "            ", "self", ".", "spatial_transform", ".", "randomize_parameters", "(", ")", "\n", "clip", "=", "[", "self", ".", "spatial_transform", "(", "img", ")", "for", "img", "in", "clip", "]", "\n", "", "clip", "=", "torch", ".", "stack", "(", "clip", ",", "0", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n", "target", "=", "self", ".", "data", "[", "index", "]", "\n", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "clip", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.UCF101.__len__": [[197, 199], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.pil_loader": [[13, 18], ["open", "PIL.Image.open", "img.convert"], "function", ["None"], ["def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "with", "Image", ".", "open", "(", "f", ")", "as", "img", ":", "\n", "            ", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.accimage_loader": [[20, 27], ["accimage.Image", "ucf101.pil_loader"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.pil_loader"], ["", "", "", "def", "accimage_loader", "(", "path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "import", "accimage", "\n", "return", "accimage", ".", "Image", "(", "path", ")", "\n", "", "except", "IOError", ":", "\n", "# Potentially a decoding problem, fall back to PIL.Image", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.get_default_image_loader": [[29, 35], ["get_image_backend"], "function", ["None"], ["", "", "def", "get_default_image_loader", "(", ")", ":", "\n", "    ", "from", "torchvision", "import", "get_image_backend", "\n", "if", "get_image_backend", "(", ")", "==", "'accimage'", ":", "\n", "        ", "return", "accimage_loader", "\n", "", "else", ":", "\n", "        ", "return", "pil_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.video_loader": [[37, 47], ["os.path.join", "os.path.exists", "video.append", "image_loader"], "function", ["None"], ["", "", "def", "video_loader", "(", "video_dir_path", ",", "frame_indices", ",", "image_loader", ")", ":", "\n", "    ", "video", "=", "[", "]", "\n", "for", "i", "in", "frame_indices", ":", "\n", "        ", "image_path", "=", "os", ".", "path", ".", "join", "(", "video_dir_path", ",", "'image_{:05d}.jpg'", ".", "format", "(", "i", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "image_path", ")", ":", "\n", "            ", "video", ".", "append", "(", "image_loader", "(", "image_path", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "video", "\n", "\n", "", "", "return", "video", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.get_default_video_loader": [[49, 52], ["ucf101.get_default_image_loader", "functools.partial"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_default_image_loader"], ["", "def", "get_default_video_loader", "(", ")", ":", "\n", "    ", "image_loader", "=", "get_default_image_loader", "(", ")", "\n", "return", "functools", ".", "partial", "(", "video_loader", ",", "image_loader", "=", "image_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.load_annotation_data": [[54, 57], ["open", "json.load"], "function", ["None"], ["", "def", "load_annotation_data", "(", "data_file_path", ")", ":", "\n", "    ", "with", "open", "(", "data_file_path", ",", "'r'", ")", "as", "data_file", ":", "\n", "        ", "return", "json", ".", "load", "(", "data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.get_class_labels": [[59, 66], ["torch.data"], "function", ["None"], ["", "", "def", "get_class_labels", "(", "data", ")", ":", "\n", "    ", "class_labels_map", "=", "{", "}", "\n", "index", "=", "0", "\n", "for", "class_label", "in", "data", "[", "'labels'", "]", ":", "\n", "        ", "class_labels_map", "[", "class_label", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "return", "class_labels_map", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.get_video_names_and_annotations": [[68, 80], ["data[].items", "video_names.append", "annotations.append", "torch.data"], "function", ["None"], ["", "def", "get_video_names_and_annotations", "(", "data", ",", "subset", ")", ":", "\n", "    ", "video_names", "=", "[", "]", "\n", "annotations", "=", "[", "]", "\n", "\n", "for", "key", ",", "value", "in", "data", "[", "'database'", "]", ".", "items", "(", ")", ":", "\n", "        ", "this_subset", "=", "value", "[", "'subset'", "]", "\n", "if", "this_subset", "==", "subset", ":", "\n", "            ", "label", "=", "value", "[", "'annotations'", "]", "[", "'label'", "]", "\n", "video_names", ".", "append", "(", "'{}/{}'", ".", "format", "(", "label", ",", "key", ")", ")", "\n", "annotations", ".", "append", "(", "value", "[", "'annotations'", "]", ")", "\n", "\n", "", "", "return", "video_names", ",", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.ucf101.make_dataset": [[82, 135], ["ucf101.load_annotation_data", "ucf101.get_video_names_and_annotations", "ucf101.get_class_labels", "get_class_labels.items", "range", "len", "os.path.join", "os.path.join", "int", "print", "os.path.exists", "utils.load_value_file", "len", "list", "dataset.append", "range", "video_names[].split", "range", "max", "copy.deepcopy", "list", "dataset.append", "len", "math.ceil", "range", "min"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.load_annotation_data", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_video_names_and_annotations", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_class_labels", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.load_value_file"], ["", "def", "make_dataset", "(", "root_path", ",", "annotation_path", ",", "subset", ",", "n_samples_for_each_video", ",", "\n", "sample_duration", ")", ":", "\n", "    ", "data", "=", "load_annotation_data", "(", "annotation_path", ")", "\n", "video_names", ",", "annotations", "=", "get_video_names_and_annotations", "(", "data", ",", "subset", ")", "\n", "class_to_idx", "=", "get_class_labels", "(", "data", ")", "\n", "idx_to_class", "=", "{", "}", "\n", "for", "name", ",", "label", "in", "class_to_idx", ".", "items", "(", ")", ":", "\n", "        ", "idx_to_class", "[", "label", "]", "=", "name", "\n", "\n", "", "dataset", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "video_names", ")", ")", ":", "\n", "        ", "if", "i", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "'dataset loading [{}/{}]'", ".", "format", "(", "i", ",", "len", "(", "video_names", ")", ")", ")", "\n", "\n", "", "video_path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "video_names", "[", "i", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "video_path", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "n_frames_file_path", "=", "os", ".", "path", ".", "join", "(", "video_path", ",", "'n_frames'", ")", "\n", "n_frames", "=", "int", "(", "load_value_file", "(", "n_frames_file_path", ")", ")", "\n", "if", "n_frames", "<=", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "begin_t", "=", "1", "\n", "end_t", "=", "n_frames", "\n", "sample", "=", "{", "\n", "'video'", ":", "video_path", ",", "\n", "'segment'", ":", "[", "begin_t", ",", "end_t", "]", ",", "\n", "'n_frames'", ":", "n_frames", ",", "\n", "'video_id'", ":", "video_names", "[", "i", "]", ".", "split", "(", "'/'", ")", "[", "1", "]", "\n", "}", "\n", "if", "len", "(", "annotations", ")", "!=", "0", ":", "\n", "            ", "sample", "[", "'label'", "]", "=", "class_to_idx", "[", "annotations", "[", "i", "]", "[", "'label'", "]", "]", "\n", "", "else", ":", "\n", "            ", "sample", "[", "'label'", "]", "=", "-", "1", "\n", "\n", "", "if", "n_samples_for_each_video", "==", "1", ":", "\n", "            ", "sample", "[", "'frame_indices'", "]", "=", "list", "(", "range", "(", "1", ",", "n_frames", "+", "1", ")", ")", "\n", "dataset", ".", "append", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "if", "n_samples_for_each_video", ">", "1", ":", "\n", "                ", "step", "=", "max", "(", "1", ",", "\n", "math", ".", "ceil", "(", "(", "n_frames", "-", "1", "-", "sample_duration", ")", "/", "\n", "(", "n_samples_for_each_video", "-", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "step", "=", "sample_duration", "\n", "", "for", "j", "in", "range", "(", "1", ",", "n_frames", ",", "step", ")", ":", "\n", "                ", "sample_j", "=", "copy", ".", "deepcopy", "(", "sample", ")", "\n", "sample_j", "[", "'frame_indices'", "]", "=", "list", "(", "\n", "range", "(", "j", ",", "min", "(", "n_frames", "+", "1", ",", "j", "+", "sample_duration", ")", ")", ")", "\n", "dataset", ".", "append", "(", "sample_j", ")", "\n", "\n", "", "", "", "return", "dataset", ",", "idx_to_class", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.ActivityNet.__init__": [[247, 271], ["get_loader", "activitynet.make_untrimmed_dataset", "activitynet.make_dataset"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.make_untrimmed_dataset", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.make_dataset"], ["def", "__init__", "(", "self", ",", "\n", "root_path", ",", "\n", "annotation_path", ",", "\n", "subset", ",", "\n", "is_untrimmed_setting", "=", "False", ",", "\n", "n_samples_for_each_video", "=", "1", ",", "\n", "spatial_transform", "=", "None", ",", "\n", "temporal_transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "\n", "sample_duration", "=", "16", ",", "\n", "get_loader", "=", "get_default_video_loader", ")", ":", "\n", "        ", "if", "is_untrimmed_setting", ":", "\n", "            ", "self", ".", "data", ",", "self", ".", "class_names", "=", "make_untrimmed_dataset", "(", "\n", "root_path", ",", "annotation_path", ",", "subset", ",", "n_samples_for_each_video", ",", "\n", "sample_duration", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "data", ",", "self", ".", "class_names", "=", "make_dataset", "(", "\n", "root_path", ",", "annotation_path", ",", "subset", ",", "n_samples_for_each_video", ",", "\n", "sample_duration", ")", "\n", "\n", "", "self", ".", "spatial_transform", "=", "spatial_transform", "\n", "self", ".", "temporal_transform", "=", "temporal_transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "get_loader", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.ActivityNet.__getitem__": [[272, 295], ["activitynet.ActivityNet.loader", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "activitynet.ActivityNet.temporal_transform", "activitynet.ActivityNet.spatial_transform.randomize_parameters", "activitynet.ActivityNet.target_transform", "activitynet.ActivityNet.spatial_transform", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.MultiScaleRandomCrop.randomize_parameters"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", "=", "self", ".", "data", "[", "index", "]", "[", "'video'", "]", "\n", "\n", "frame_indices", "=", "self", ".", "data", "[", "index", "]", "[", "'frame_indices'", "]", "\n", "if", "self", ".", "temporal_transform", "is", "not", "None", ":", "\n", "            ", "frame_indices", "=", "self", ".", "temporal_transform", "(", "frame_indices", ")", "\n", "", "clip", "=", "self", ".", "loader", "(", "path", ",", "frame_indices", ")", "\n", "if", "self", ".", "spatial_transform", "is", "not", "None", ":", "\n", "            ", "self", ".", "spatial_transform", ".", "randomize_parameters", "(", ")", "\n", "clip", "=", "[", "self", ".", "spatial_transform", "(", "img", ")", "for", "img", "in", "clip", "]", "\n", "", "clip", "=", "torch", ".", "stack", "(", "clip", ",", "0", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n", "target", "=", "self", ".", "data", "[", "index", "]", "\n", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "clip", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.ActivityNet.__len__": [[296, 298], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.pil_loader": [[13, 18], ["open", "PIL.Image.open", "img.convert"], "function", ["None"], ["def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "with", "Image", ".", "open", "(", "f", ")", "as", "img", ":", "\n", "            ", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.accimage_loader": [[20, 27], ["accimage.Image", "activitynet.pil_loader"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.pil_loader"], ["", "", "", "def", "accimage_loader", "(", "path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "import", "accimage", "\n", "return", "accimage", ".", "Image", "(", "path", ")", "\n", "", "except", "IOError", ":", "\n", "# Potentially a decoding problem, fall back to PIL.Image", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.get_default_image_loader": [[29, 35], ["get_image_backend"], "function", ["None"], ["", "", "def", "get_default_image_loader", "(", ")", ":", "\n", "    ", "from", "torchvision", "import", "get_image_backend", "\n", "if", "get_image_backend", "(", ")", "==", "'accimage'", ":", "\n", "        ", "return", "accimage_loader", "\n", "", "else", ":", "\n", "        ", "return", "pil_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.video_loader": [[37, 47], ["os.path.join", "os.path.exists", "video.append", "image_loader"], "function", ["None"], ["", "", "def", "video_loader", "(", "video_dir_path", ",", "frame_indices", ",", "image_loader", ")", ":", "\n", "    ", "video", "=", "[", "]", "\n", "for", "i", "in", "frame_indices", ":", "\n", "        ", "image_path", "=", "os", ".", "path", ".", "join", "(", "video_dir_path", ",", "'image_{:05d}.jpg'", ".", "format", "(", "i", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "image_path", ")", ":", "\n", "            ", "video", ".", "append", "(", "image_loader", "(", "image_path", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "video", "\n", "\n", "", "", "return", "video", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.get_default_video_loader": [[49, 52], ["activitynet.get_default_image_loader", "functools.partial"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_default_image_loader"], ["", "def", "get_default_video_loader", "(", ")", ":", "\n", "    ", "image_loader", "=", "get_default_image_loader", "(", ")", "\n", "return", "functools", ".", "partial", "(", "video_loader", ",", "image_loader", "=", "image_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.load_annotation_data": [[54, 57], ["open", "json.load"], "function", ["None"], ["", "def", "load_annotation_data", "(", "data_file_path", ")", ":", "\n", "    ", "with", "open", "(", "data_file_path", ",", "'r'", ")", "as", "data_file", ":", "\n", "        ", "return", "json", ".", "load", "(", "data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.get_class_labels": [[59, 77], ["enumerate", "class_names.append", "torch.data", "torch.data"], "function", ["None"], ["", "", "def", "get_class_labels", "(", "data", ")", ":", "\n", "    ", "class_names", "=", "[", "]", "\n", "index", "=", "0", "\n", "for", "node1", "in", "data", "[", "'taxonomy'", "]", ":", "\n", "        ", "is_leaf", "=", "True", "\n", "for", "node2", "in", "data", "[", "'taxonomy'", "]", ":", "\n", "            ", "if", "node2", "[", "'parentId'", "]", "==", "node1", "[", "'nodeId'", "]", ":", "\n", "                ", "is_leaf", "=", "False", "\n", "break", "\n", "", "", "if", "is_leaf", ":", "\n", "            ", "class_names", ".", "append", "(", "node1", "[", "'nodeName'", "]", ")", "\n", "\n", "", "", "class_labels_map", "=", "{", "}", "\n", "\n", "for", "i", ",", "class_name", "in", "enumerate", "(", "class_names", ")", ":", "\n", "        ", "class_labels_map", "[", "class_name", "]", "=", "i", "\n", "\n", "", "return", "class_labels_map", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.get_video_names_and_annotations": [[79, 93], ["data[].items", "video_names.append", "video_names.append", "annotations.append", "torch.data", "torch.data"], "function", ["None"], ["", "def", "get_video_names_and_annotations", "(", "data", ",", "subset", ")", ":", "\n", "    ", "video_names", "=", "[", "]", "\n", "annotations", "=", "[", "]", "\n", "\n", "for", "key", ",", "value", "in", "data", "[", "'database'", "]", ".", "items", "(", ")", ":", "\n", "        ", "this_subset", "=", "value", "[", "'subset'", "]", "\n", "if", "this_subset", "==", "subset", ":", "\n", "            ", "if", "subset", "==", "'testing'", ":", "\n", "                ", "video_names", ".", "append", "(", "'v_{}'", ".", "format", "(", "key", ")", ")", "\n", "", "else", ":", "\n", "                ", "video_names", ".", "append", "(", "'v_{}'", ".", "format", "(", "key", ")", ")", "\n", "annotations", ".", "append", "(", "value", "[", "'annotations'", "]", ")", "\n", "\n", "", "", "", "return", "video_names", ",", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.modify_frame_indices": [[95, 103], ["os.path.join", "modified_indices.append", "os.path.exists"], "function", ["None"], ["", "def", "modify_frame_indices", "(", "video_dir_path", ",", "frame_indices", ")", ":", "\n", "    ", "modified_indices", "=", "[", "]", "\n", "for", "i", "in", "frame_indices", ":", "\n", "        ", "image_path", "=", "os", ".", "path", ".", "join", "(", "video_dir_path", ",", "'image_{:05d}.jpg'", ".", "format", "(", "i", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_path", ")", ":", "\n", "            ", "return", "modified_indices", "\n", "", "modified_indices", ".", "append", "(", "i", ")", "\n", "", "return", "modified_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.make_dataset": [[105, 170], ["activitynet.load_annotation_data", "activitynet.get_video_names_and_annotations", "activitynet.get_class_labels", "get_class_labels.items", "range", "len", "os.path.join", "os.path.join", "utils.load_value_file", "print", "os.path.exists", "math.ceil", "math.ceil", "len", "list", "activitynet.modify_frame_indices", "dataset.append", "range", "len", "range", "len", "max", "copy.deepcopy", "list", "activitynet.modify_frame_indices", "dataset.append", "math.ceil", "range", "len"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.load_annotation_data", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_video_names_and_annotations", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_class_labels", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.load_value_file", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.modify_frame_indices", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.modify_frame_indices"], ["", "def", "make_dataset", "(", "root_path", ",", "annotation_path", ",", "subset", ",", "n_samples_for_each_video", ",", "\n", "sample_duration", ")", ":", "\n", "    ", "data", "=", "load_annotation_data", "(", "annotation_path", ")", "\n", "video_names", ",", "annotations", "=", "get_video_names_and_annotations", "(", "data", ",", "subset", ")", "\n", "class_to_idx", "=", "get_class_labels", "(", "data", ")", "\n", "idx_to_class", "=", "{", "}", "\n", "for", "name", ",", "label", "in", "class_to_idx", ".", "items", "(", ")", ":", "\n", "        ", "idx_to_class", "[", "label", "]", "=", "name", "\n", "\n", "", "dataset", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "video_names", ")", ")", ":", "\n", "        ", "if", "i", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "'dataset loading [{}/{}]'", ".", "format", "(", "i", ",", "len", "(", "video_names", ")", ")", ")", "\n", "\n", "", "video_path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "video_names", "[", "i", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "video_path", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "fps_file_path", "=", "os", ".", "path", ".", "join", "(", "video_path", ",", "'fps'", ")", "\n", "fps", "=", "load_value_file", "(", "fps_file_path", ")", "\n", "\n", "for", "annotation", "in", "annotations", "[", "i", "]", ":", "\n", "            ", "begin_t", "=", "math", ".", "ceil", "(", "annotation", "[", "'segment'", "]", "[", "0", "]", "*", "fps", ")", "\n", "end_t", "=", "math", ".", "ceil", "(", "annotation", "[", "'segment'", "]", "[", "1", "]", "*", "fps", ")", "\n", "if", "begin_t", "==", "0", ":", "\n", "                ", "begin_t", "=", "1", "\n", "", "n_frames", "=", "end_t", "-", "begin_t", "\n", "\n", "sample", "=", "{", "\n", "'video'", ":", "video_path", ",", "\n", "'segment'", ":", "[", "begin_t", ",", "end_t", "]", ",", "\n", "'fps'", ":", "fps", ",", "\n", "'video_id'", ":", "video_names", "[", "i", "]", "[", "2", ":", "]", "\n", "}", "\n", "if", "len", "(", "annotations", ")", "!=", "0", ":", "\n", "                ", "sample", "[", "'label'", "]", "=", "class_to_idx", "[", "annotation", "[", "'label'", "]", "]", "\n", "", "else", ":", "\n", "                ", "sample", "[", "'label'", "]", "=", "-", "1", "\n", "\n", "", "if", "n_samples_for_each_video", "==", "1", ":", "\n", "                ", "frame_indices", "=", "list", "(", "range", "(", "begin_t", ",", "end_t", ")", ")", "\n", "frame_indices", "=", "modify_frame_indices", "(", "sample", "[", "'video'", "]", ",", "\n", "frame_indices", ")", "\n", "if", "len", "(", "frame_indices", ")", "<", "16", ":", "\n", "                    ", "continue", "\n", "", "sample", "[", "'frame_indices'", "]", "=", "frame_indices", "\n", "dataset", ".", "append", "(", "sample", ")", "\n", "", "else", ":", "\n", "                ", "if", "n_samples_for_each_video", ">", "1", ":", "\n", "                    ", "step", "=", "max", "(", "1", ",", "\n", "math", ".", "ceil", "(", "(", "n_frames", "-", "1", "-", "sample_duration", ")", "/", "\n", "(", "n_samples_for_each_video", "-", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "step", "=", "sample_duration", "\n", "", "for", "j", "in", "range", "(", "begin_t", ",", "end_t", ",", "step", ")", ":", "\n", "                    ", "sample_j", "=", "copy", ".", "deepcopy", "(", "sample", ")", "\n", "frame_indices", "=", "list", "(", "range", "(", "j", ",", "j", "+", "sample_duration", ")", ")", "\n", "frame_indices", "=", "modify_frame_indices", "(", "\n", "sample_j", "[", "'video'", "]", ",", "frame_indices", ")", "\n", "if", "len", "(", "frame_indices", ")", "<", "16", ":", "\n", "                        ", "continue", "\n", "", "sample_j", "[", "'frame_indices'", "]", "=", "frame_indices", "\n", "dataset", ".", "append", "(", "sample_j", ")", "\n", "\n", "", "", "", "", "return", "dataset", ",", "idx_to_class", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.get_end_t": [[172, 177], ["os.listdir", "image_file_names.sort", "int"], "function", ["None"], ["", "def", "get_end_t", "(", "video_path", ")", ":", "\n", "    ", "file_names", "=", "os", ".", "listdir", "(", "video_path", ")", "\n", "image_file_names", "=", "[", "x", "for", "x", "in", "file_names", "if", "'image'", "in", "x", "]", "\n", "image_file_names", ".", "sort", "(", "reverse", "=", "True", ")", "\n", "return", "int", "(", "image_file_names", "[", "0", "]", "[", "6", ":", "11", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.make_untrimmed_dataset": [[179, 228], ["activitynet.load_annotation_data", "activitynet.get_video_names_and_annotations", "activitynet.get_class_labels", "get_class_labels.items", "range", "len", "os.path.join", "os.path.join", "utils.load_value_file", "activitynet.get_end_t", "range", "print", "os.path.exists", "max", "copy.deepcopy", "list", "activitynet.modify_frame_indices", "dataset.append", "math.ceil", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.load_annotation_data", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_video_names_and_annotations", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_class_labels", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.load_value_file", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.get_end_t", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.activitynet.modify_frame_indices"], ["", "def", "make_untrimmed_dataset", "(", "root_path", ",", "annotation_path", ",", "subset", ",", "\n", "n_samples_for_each_video", ",", "sample_duration", ")", ":", "\n", "    ", "data", "=", "load_annotation_data", "(", "annotation_path", ")", "\n", "video_names", ",", "_", "=", "get_video_names_and_annotations", "(", "data", ",", "subset", ")", "\n", "class_to_idx", "=", "get_class_labels", "(", "data", ")", "\n", "idx_to_class", "=", "{", "}", "\n", "for", "name", ",", "label", "in", "class_to_idx", ".", "items", "(", ")", ":", "\n", "        ", "idx_to_class", "[", "label", "]", "=", "name", "\n", "\n", "", "dataset", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "video_names", ")", ")", ":", "\n", "        ", "if", "i", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "'dataset loading [{}/{}]'", ".", "format", "(", "i", ",", "len", "(", "video_names", ")", ")", ")", "\n", "\n", "", "video_path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "video_names", "[", "i", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "video_path", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "fps_file_path", "=", "os", ".", "path", ".", "join", "(", "video_path", ",", "'fps'", ")", "\n", "fps", "=", "load_value_file", "(", "fps_file_path", ")", "\n", "\n", "begin_t", "=", "1", "\n", "end_t", "=", "get_end_t", "(", "video_path", ")", "\n", "n_frames", "=", "end_t", "-", "begin_t", "\n", "\n", "sample", "=", "{", "\n", "'video'", ":", "video_path", ",", "\n", "'segment'", ":", "[", "begin_t", ",", "end_t", "]", ",", "\n", "'fps'", ":", "fps", ",", "\n", "'video_id'", ":", "video_names", "[", "i", "]", "[", "2", ":", "]", "\n", "}", "\n", "\n", "if", "n_samples_for_each_video", ">=", "1", ":", "\n", "            ", "step", "=", "max", "(", "1", ",", "\n", "math", ".", "ceil", "(", "(", "n_frames", "-", "1", "-", "sample_duration", ")", "/", "\n", "(", "n_samples_for_each_video", "-", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "step", "=", "sample_duration", "\n", "", "for", "j", "in", "range", "(", "begin_t", ",", "end_t", ",", "step", ")", ":", "\n", "            ", "sample_j", "=", "copy", ".", "deepcopy", "(", "sample", ")", "\n", "frame_indices", "=", "list", "(", "range", "(", "j", ",", "j", "+", "sample_duration", ")", ")", "\n", "frame_indices", "=", "modify_frame_indices", "(", "sample_j", "[", "'video'", "]", ",", "\n", "frame_indices", ")", "\n", "if", "len", "(", "frame_indices", ")", "<", "16", ":", "\n", "                ", "continue", "\n", "", "sample_j", "[", "'frame_indices'", "]", "=", "frame_indices", "\n", "dataset", ".", "append", "(", "sample_j", ")", "\n", "\n", "", "", "return", "dataset", ",", "idx_to_class", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.Kinetics.__init__": [[157, 175], ["kinetics.make_dataset", "get_loader"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.make_dataset"], ["def", "__init__", "(", "self", ",", "\n", "root_path", ",", "\n", "annotation_path", ",", "\n", "subset", ",", "\n", "n_samples_for_each_video", "=", "1", ",", "\n", "spatial_transform", "=", "None", ",", "\n", "temporal_transform", "=", "None", ",", "\n", "target_transform", "=", "None", ",", "\n", "sample_duration", "=", "16", ",", "\n", "get_loader", "=", "get_default_video_loader", ")", ":", "\n", "        ", "self", ".", "data", ",", "self", ".", "class_names", "=", "make_dataset", "(", "\n", "root_path", ",", "annotation_path", ",", "subset", ",", "n_samples_for_each_video", ",", "\n", "sample_duration", ")", "\n", "\n", "self", ".", "spatial_transform", "=", "spatial_transform", "\n", "self", ".", "temporal_transform", "=", "temporal_transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "loader", "=", "get_loader", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.Kinetics.__getitem__": [[176, 199], ["kinetics.Kinetics.loader", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "kinetics.Kinetics.temporal_transform", "kinetics.Kinetics.spatial_transform.randomize_parameters", "kinetics.Kinetics.target_transform", "kinetics.Kinetics.spatial_transform", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.spatial_transforms.MultiScaleRandomCrop.randomize_parameters"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is class_index of the target class.\n        \"\"\"", "\n", "path", "=", "self", ".", "data", "[", "index", "]", "[", "'video'", "]", "\n", "\n", "frame_indices", "=", "self", ".", "data", "[", "index", "]", "[", "'frame_indices'", "]", "\n", "if", "self", ".", "temporal_transform", "is", "not", "None", ":", "\n", "            ", "frame_indices", "=", "self", ".", "temporal_transform", "(", "frame_indices", ")", "\n", "", "clip", "=", "self", ".", "loader", "(", "path", ",", "frame_indices", ")", "\n", "if", "self", ".", "spatial_transform", "is", "not", "None", ":", "\n", "            ", "self", ".", "spatial_transform", ".", "randomize_parameters", "(", ")", "\n", "clip", "=", "[", "self", ".", "spatial_transform", "(", "img", ")", "for", "img", "in", "clip", "]", "\n", "", "clip", "=", "torch", ".", "stack", "(", "clip", ",", "0", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n", "target", "=", "self", ".", "data", "[", "index", "]", "\n", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "clip", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.Kinetics.__len__": [[200, 202], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.pil_loader": [[13, 18], ["open", "PIL.Image.open", "img.convert"], "function", ["None"], ["def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "with", "Image", ".", "open", "(", "f", ")", "as", "img", ":", "\n", "            ", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.accimage_loader": [[20, 27], ["accimage.Image", "kinetics.pil_loader"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.pil_loader"], ["", "", "", "def", "accimage_loader", "(", "path", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "import", "accimage", "\n", "return", "accimage", ".", "Image", "(", "path", ")", "\n", "", "except", "IOError", ":", "\n", "# Potentially a decoding problem, fall back to PIL.Image", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_default_image_loader": [[29, 35], ["get_image_backend"], "function", ["None"], ["", "", "def", "get_default_image_loader", "(", ")", ":", "\n", "    ", "from", "torchvision", "import", "get_image_backend", "\n", "if", "get_image_backend", "(", ")", "==", "'accimage'", ":", "\n", "        ", "return", "accimage_loader", "\n", "", "else", ":", "\n", "        ", "return", "pil_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.video_loader": [[37, 47], ["os.path.join", "os.path.exists", "video.append", "image_loader"], "function", ["None"], ["", "", "def", "video_loader", "(", "video_dir_path", ",", "frame_indices", ",", "image_loader", ")", ":", "\n", "    ", "video", "=", "[", "]", "\n", "for", "i", "in", "frame_indices", ":", "\n", "        ", "image_path", "=", "os", ".", "path", ".", "join", "(", "video_dir_path", ",", "'image_{:05d}.jpg'", ".", "format", "(", "i", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "image_path", ")", ":", "\n", "            ", "video", ".", "append", "(", "image_loader", "(", "image_path", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "video", "\n", "\n", "", "", "return", "video", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_default_video_loader": [[49, 52], ["kinetics.get_default_image_loader", "functools.partial"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_default_image_loader"], ["", "def", "get_default_video_loader", "(", ")", ":", "\n", "    ", "image_loader", "=", "get_default_image_loader", "(", ")", "\n", "return", "functools", ".", "partial", "(", "video_loader", ",", "image_loader", "=", "image_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.load_annotation_data": [[54, 57], ["open", "json.load"], "function", ["None"], ["", "def", "load_annotation_data", "(", "data_file_path", ")", ":", "\n", "    ", "with", "open", "(", "data_file_path", ",", "'r'", ")", "as", "data_file", ":", "\n", "        ", "return", "json", ".", "load", "(", "data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_class_labels": [[59, 66], ["torch.data"], "function", ["None"], ["", "", "def", "get_class_labels", "(", "data", ")", ":", "\n", "    ", "class_labels_map", "=", "{", "}", "\n", "index", "=", "0", "\n", "for", "class_label", "in", "data", "[", "'labels'", "]", ":", "\n", "        ", "class_labels_map", "[", "class_label", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "return", "class_labels_map", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_video_names_and_annotations": [[68, 83], ["data[].items", "video_names.append", "video_names.append", "annotations.append", "torch.data"], "function", ["None"], ["", "def", "get_video_names_and_annotations", "(", "data", ",", "subset", ")", ":", "\n", "    ", "video_names", "=", "[", "]", "\n", "annotations", "=", "[", "]", "\n", "\n", "for", "key", ",", "value", "in", "data", "[", "'database'", "]", ".", "items", "(", ")", ":", "\n", "        ", "this_subset", "=", "value", "[", "'subset'", "]", "\n", "if", "this_subset", "==", "subset", ":", "\n", "            ", "if", "subset", "==", "'testing'", ":", "\n", "                ", "video_names", ".", "append", "(", "'test/{}'", ".", "format", "(", "key", ")", ")", "\n", "", "else", ":", "\n", "                ", "label", "=", "value", "[", "'annotations'", "]", "[", "'label'", "]", "\n", "video_names", ".", "append", "(", "'{}/{}'", ".", "format", "(", "label", ",", "key", ")", ")", "\n", "annotations", ".", "append", "(", "value", "[", "'annotations'", "]", ")", "\n", "\n", "", "", "", "return", "video_names", ",", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.make_dataset": [[85, 138], ["kinetics.load_annotation_data", "kinetics.get_video_names_and_annotations", "kinetics.get_class_labels", "get_class_labels.items", "range", "len", "os.path.join", "os.path.join", "int", "print", "os.path.exists", "utils.load_value_file", "len", "list", "dataset.append", "range", "[].split", "range", "max", "copy.deepcopy", "list", "dataset.append", "len", "math.ceil", "range", "min"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.load_annotation_data", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_video_names_and_annotations", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.datasets.kinetics.get_class_labels", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.VideoHashing.utils.load_value_file"], ["", "def", "make_dataset", "(", "root_path", ",", "annotation_path", ",", "subset", ",", "n_samples_for_each_video", ",", "\n", "sample_duration", ")", ":", "\n", "    ", "data", "=", "load_annotation_data", "(", "annotation_path", ")", "\n", "video_names", ",", "annotations", "=", "get_video_names_and_annotations", "(", "data", ",", "subset", ")", "\n", "class_to_idx", "=", "get_class_labels", "(", "data", ")", "\n", "idx_to_class", "=", "{", "}", "\n", "for", "name", ",", "label", "in", "class_to_idx", ".", "items", "(", ")", ":", "\n", "        ", "idx_to_class", "[", "label", "]", "=", "name", "\n", "\n", "", "dataset", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "video_names", ")", ")", ":", "\n", "        ", "if", "i", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "'dataset loading [{}/{}]'", ".", "format", "(", "i", ",", "len", "(", "video_names", ")", ")", ")", "\n", "\n", "", "video_path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "video_names", "[", "i", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "video_path", ")", ":", "\n", "            ", "continue", "\n", "\n", "", "n_frames_file_path", "=", "os", ".", "path", ".", "join", "(", "video_path", ",", "'n_frames'", ")", "\n", "n_frames", "=", "int", "(", "load_value_file", "(", "n_frames_file_path", ")", ")", "\n", "if", "n_frames", "<=", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "begin_t", "=", "1", "\n", "end_t", "=", "n_frames", "\n", "sample", "=", "{", "\n", "'video'", ":", "video_path", ",", "\n", "'segment'", ":", "[", "begin_t", ",", "end_t", "]", ",", "\n", "'n_frames'", ":", "n_frames", ",", "\n", "'video_id'", ":", "video_names", "[", "i", "]", "[", ":", "-", "14", "]", ".", "split", "(", "'/'", ")", "[", "1", "]", "\n", "}", "\n", "if", "len", "(", "annotations", ")", "!=", "0", ":", "\n", "            ", "sample", "[", "'label'", "]", "=", "class_to_idx", "[", "annotations", "[", "i", "]", "[", "'label'", "]", "]", "\n", "", "else", ":", "\n", "            ", "sample", "[", "'label'", "]", "=", "-", "1", "\n", "\n", "", "if", "n_samples_for_each_video", "==", "1", ":", "\n", "            ", "sample", "[", "'frame_indices'", "]", "=", "list", "(", "range", "(", "1", ",", "n_frames", "+", "1", ")", ")", "\n", "dataset", ".", "append", "(", "sample", ")", "\n", "", "else", ":", "\n", "            ", "if", "n_samples_for_each_video", ">", "1", ":", "\n", "                ", "step", "=", "max", "(", "1", ",", "\n", "math", ".", "ceil", "(", "(", "n_frames", "-", "1", "-", "sample_duration", ")", "/", "\n", "(", "n_samples_for_each_video", "-", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "step", "=", "sample_duration", "\n", "", "for", "j", "in", "range", "(", "1", ",", "n_frames", ",", "step", ")", ":", "\n", "                ", "sample_j", "=", "copy", ".", "deepcopy", "(", "sample", ")", "\n", "sample_j", "[", "'frame_indices'", "]", "=", "list", "(", "\n", "range", "(", "j", ",", "min", "(", "n_frames", "+", "1", ",", "j", "+", "sample_duration", ")", ")", ")", "\n", "dataset", ".", "append", "(", "sample_j", ")", "\n", "\n", "", "", "", "return", "dataset", ",", "idx_to_class", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.PreActivationBasicBlock.__init__": [[41, 50], ["torch.Module.__init__", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "pre_act_resnet.conv3x3x3", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "pre_act_resnet.conv3x3x3", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.conv3x3x3", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.conv3x3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "PreActivationBasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "inplanes", ")", "\n", "self", ".", "conv1", "=", "conv3x3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "conv3x3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.PreActivationBasicBlock.forward": [[51, 68], ["pre_act_resnet.PreActivationBasicBlock.bn1", "pre_act_resnet.PreActivationBasicBlock.relu", "pre_act_resnet.PreActivationBasicBlock.conv1", "pre_act_resnet.PreActivationBasicBlock.bn2", "pre_act_resnet.PreActivationBasicBlock.relu", "pre_act_resnet.PreActivationBasicBlock.conv2", "pre_act_resnet.PreActivationBasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "bn1", "(", "x", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv1", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.PreActivationBottleneck.__init__": [[73, 85], ["torch.Module.__init__", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "PreActivationBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "inplanes", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv3d", "(", "\n", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv3d", "(", "planes", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.PreActivationBottleneck.forward": [[86, 107], ["pre_act_resnet.PreActivationBottleneck.bn1", "pre_act_resnet.PreActivationBottleneck.relu", "pre_act_resnet.PreActivationBottleneck.conv1", "pre_act_resnet.PreActivationBottleneck.bn2", "pre_act_resnet.PreActivationBottleneck.relu", "pre_act_resnet.PreActivationBottleneck.conv2", "pre_act_resnet.PreActivationBottleneck.bn3", "pre_act_resnet.PreActivationBottleneck.relu", "pre_act_resnet.PreActivationBottleneck.conv3", "pre_act_resnet.PreActivationBottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "bn1", "(", "x", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv1", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.PreActivationResNet.__init__": [[111, 149], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool3d", "torch.MaxPool3d", "torch.MaxPool3d", "pre_act_resnet.PreActivationResNet._make_layer", "pre_act_resnet.PreActivationResNet._make_layer", "pre_act_resnet.PreActivationResNet._make_layer", "pre_act_resnet.PreActivationResNet._make_layer", "int", "int", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.Linear", "torch.Linear", "torch.Linear", "pre_act_resnet.PreActivationResNet.modules", "math.ceil", "math.ceil", "isinstance", "torch.init.kaiming_normal", "torch.init.kaiming_normal", "torch.init.kaiming_normal", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "\n", "block", ",", "\n", "layers", ",", "\n", "sample_size", ",", "\n", "sample_duration", ",", "\n", "shortcut_type", "=", "'B'", ",", "\n", "num_classes", "=", "400", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "PreActivationResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "\n", "3", ",", "\n", "64", ",", "\n", "kernel_size", "=", "7", ",", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "(", "3", ",", "3", ",", "3", ")", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ",", "shortcut_type", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "shortcut_type", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "shortcut_type", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "shortcut_type", ",", "stride", "=", "2", ")", "\n", "last_duration", "=", "int", "(", "math", ".", "ceil", "(", "sample_duration", "/", "16", ")", ")", "\n", "last_size", "=", "int", "(", "math", ".", "ceil", "(", "sample_size", "/", "32", ")", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool3d", "(", "\n", "(", "last_duration", ",", "last_size", ",", "last_size", ")", ",", "stride", "=", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                ", "m", ".", "weight", "=", "nn", ".", "init", ".", "kaiming_normal", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm3d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.PreActivationResNet._make_layer": [[150, 174], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "functools.partial", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "shortcut_type", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "if", "shortcut_type", "==", "'A'", ":", "\n", "                ", "downsample", "=", "partial", "(", "\n", "downsample_basic_block", ",", "\n", "planes", "=", "planes", "*", "block", ".", "expansion", ",", "\n", "stride", "=", "stride", ")", "\n", "", "else", ":", "\n", "                ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv3d", "(", "\n", "self", ".", "inplanes", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ")", ",", "nn", ".", "BatchNorm3d", "(", "planes", "*", "block", ".", "expansion", ")", ")", "\n", "\n", "", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.PreActivationResNet.forward": [[175, 192], ["pre_act_resnet.PreActivationResNet.conv1", "pre_act_resnet.PreActivationResNet.bn1", "pre_act_resnet.PreActivationResNet.relu", "pre_act_resnet.PreActivationResNet.maxpool", "pre_act_resnet.PreActivationResNet.layer1", "pre_act_resnet.PreActivationResNet.layer2", "pre_act_resnet.PreActivationResNet.layer3", "pre_act_resnet.PreActivationResNet.layer4", "pre_act_resnet.PreActivationResNet.avgpool", "pre_act_resnet.PreActivationResNet.view", "pre_act_resnet.PreActivationResNet.fc", "pre_act_resnet.PreActivationResNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.conv3x3x3": [[14, 23], ["torch.Conv3d"], "function", ["None"], ["def", "conv3x3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "# 3x3x3 convolution with padding", "\n", "    ", "return", "nn", ".", "Conv3d", "(", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.downsample_basic_block": [[25, 36], ["torch.avg_pool3d", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "isinstance", "torch.autograd.Variable", "zero_pads.cuda.cuda", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "function", ["None"], ["", "def", "downsample_basic_block", "(", "x", ",", "planes", ",", "stride", ")", ":", "\n", "    ", "out", "=", "F", ".", "avg_pool3d", "(", "x", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ")", "\n", "zero_pads", "=", "torch", ".", "Tensor", "(", "\n", "out", ".", "size", "(", "0", ")", ",", "planes", "-", "out", ".", "size", "(", "1", ")", ",", "out", ".", "size", "(", "2", ")", ",", "out", ".", "size", "(", "3", ")", ",", "\n", "out", ".", "size", "(", "4", ")", ")", ".", "zero_", "(", ")", "\n", "if", "isinstance", "(", "out", ".", "data", ",", "torch", ".", "cuda", ".", "FloatTensor", ")", ":", "\n", "        ", "zero_pads", "=", "zero_pads", ".", "cuda", "(", ")", "\n", "\n", "", "out", "=", "Variable", "(", "torch", ".", "cat", "(", "[", "out", ".", "data", ",", "zero_pads", "]", ",", "dim", "=", "1", ")", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.get_fine_tuning_parameters": [[194, 213], ["range", "ft_module_names.append", "model.named_parameters", "model.parameters", "ft_module_names.append", "parameters.append", "parameters.append"], "function", ["None"], ["", "", "def", "get_fine_tuning_parameters", "(", "model", ",", "ft_begin_index", ")", ":", "\n", "    ", "if", "ft_begin_index", "==", "0", ":", "\n", "        ", "return", "model", ".", "parameters", "(", ")", "\n", "\n", "", "ft_module_names", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "ft_begin_index", ",", "5", ")", ":", "\n", "        ", "ft_module_names", ".", "append", "(", "'layer{}'", ".", "format", "(", "i", ")", ")", "\n", "", "ft_module_names", ".", "append", "(", "'fc'", ")", "\n", "\n", "parameters", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "for", "ft_module", "in", "ft_module_names", ":", "\n", "            ", "if", "ft_module", "in", "k", ":", "\n", "                ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", "}", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", ",", "'lr'", ":", "0.0", "}", ")", "\n", "\n", "", "", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.resnet18": [[215, 220], ["pre_act_resnet.PreActivationResNet"], "function", ["None"], ["", "def", "resnet18", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    \"\"\"", "\n", "model", "=", "PreActivationResNet", "(", "PreActivationBasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.resnet34": [[222, 227], ["pre_act_resnet.PreActivationResNet"], "function", ["None"], ["", "def", "resnet34", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n    \"\"\"", "\n", "model", "=", "PreActivationResNet", "(", "PreActivationBasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.resnet50": [[229, 234], ["pre_act_resnet.PreActivationResNet"], "function", ["None"], ["", "def", "resnet50", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "model", "=", "PreActivationResNet", "(", "PreActivationBottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.resnet101": [[236, 242], ["pre_act_resnet.PreActivationResNet"], "function", ["None"], ["", "def", "resnet101", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model", "=", "PreActivationResNet", "(", "PreActivationBottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.resnet152": [[244, 250], ["pre_act_resnet.PreActivationResNet"], "function", ["None"], ["", "def", "resnet152", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model", "=", "PreActivationResNet", "(", "PreActivationBottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.pre_act_resnet.resnet200": [[252, 258], ["pre_act_resnet.PreActivationResNet"], "function", ["None"], ["", "def", "resnet200", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model", "=", "PreActivationResNet", "(", "PreActivationBottleneck", ",", "[", "3", ",", "24", ",", "36", ",", "3", "]", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.wide_resnet.WideBottleneck.__init__": [[38, 51], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "WideBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv3d", "(", "\n", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv3d", "(", "\n", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm3d", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.wide_resnet.WideBottleneck.forward": [[52, 73], ["wide_resnet.WideBottleneck.conv1", "wide_resnet.WideBottleneck.bn1", "wide_resnet.WideBottleneck.relu", "wide_resnet.WideBottleneck.conv2", "wide_resnet.WideBottleneck.bn2", "wide_resnet.WideBottleneck.relu", "wide_resnet.WideBottleneck.conv3", "wide_resnet.WideBottleneck.bn3", "wide_resnet.WideBottleneck.relu", "wide_resnet.WideBottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.wide_resnet.WideResNet.__init__": [[77, 116], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool3d", "torch.MaxPool3d", "torch.MaxPool3d", "wide_resnet.WideResNet._make_layer", "wide_resnet.WideResNet._make_layer", "wide_resnet.WideResNet._make_layer", "wide_resnet.WideResNet._make_layer", "int", "int", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.Linear", "torch.Linear", "torch.Linear", "wide_resnet.WideResNet.modules", "math.ceil", "math.ceil", "isinstance", "torch.init.kaiming_normal", "torch.init.kaiming_normal", "torch.init.kaiming_normal", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "\n", "block", ",", "\n", "layers", ",", "\n", "sample_size", ",", "\n", "sample_duration", ",", "\n", "k", "=", "1", ",", "\n", "shortcut_type", "=", "'B'", ",", "\n", "num_classes", "=", "400", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "WideResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "\n", "3", ",", "\n", "64", ",", "\n", "kernel_size", "=", "7", ",", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "(", "3", ",", "3", ",", "3", ")", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", "*", "k", ",", "layers", "[", "0", "]", ",", "shortcut_type", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "128", "*", "k", ",", "layers", "[", "1", "]", ",", "shortcut_type", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "256", "*", "k", ",", "layers", "[", "2", "]", ",", "shortcut_type", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "512", "*", "k", ",", "layers", "[", "3", "]", ",", "shortcut_type", ",", "stride", "=", "2", ")", "\n", "last_duration", "=", "int", "(", "math", ".", "ceil", "(", "sample_duration", "/", "16", ")", ")", "\n", "last_size", "=", "int", "(", "math", ".", "ceil", "(", "sample_size", "/", "32", ")", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool3d", "(", "\n", "(", "last_duration", ",", "last_size", ",", "last_size", ")", ",", "stride", "=", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "k", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                ", "m", ".", "weight", "=", "nn", ".", "init", ".", "kaiming_normal", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm3d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.wide_resnet.WideResNet._make_layer": [[117, 141], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "functools.partial", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "shortcut_type", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "if", "shortcut_type", "==", "'A'", ":", "\n", "                ", "downsample", "=", "partial", "(", "\n", "downsample_basic_block", ",", "\n", "planes", "=", "planes", "*", "block", ".", "expansion", ",", "\n", "stride", "=", "stride", ")", "\n", "", "else", ":", "\n", "                ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv3d", "(", "\n", "self", ".", "inplanes", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ")", ",", "nn", ".", "BatchNorm3d", "(", "planes", "*", "block", ".", "expansion", ")", ")", "\n", "\n", "", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.wide_resnet.WideResNet.forward": [[142, 159], ["wide_resnet.WideResNet.conv1", "wide_resnet.WideResNet.bn1", "wide_resnet.WideResNet.relu", "wide_resnet.WideResNet.maxpool", "wide_resnet.WideResNet.layer1", "wide_resnet.WideResNet.layer2", "wide_resnet.WideResNet.layer3", "wide_resnet.WideResNet.layer4", "wide_resnet.WideResNet.avgpool", "wide_resnet.WideResNet.view", "wide_resnet.WideResNet.fc", "wide_resnet.WideResNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.wide_resnet.conv3x3x3": [[11, 20], ["torch.Conv3d"], "function", ["None"], ["def", "conv3x3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "# 3x3x3 convolution with padding", "\n", "    ", "return", "nn", ".", "Conv3d", "(", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.wide_resnet.downsample_basic_block": [[22, 33], ["torch.avg_pool3d", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "isinstance", "torch.autograd.Variable", "zero_pads.cuda.cuda", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "function", ["None"], ["", "def", "downsample_basic_block", "(", "x", ",", "planes", ",", "stride", ")", ":", "\n", "    ", "out", "=", "F", ".", "avg_pool3d", "(", "x", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ")", "\n", "zero_pads", "=", "torch", ".", "Tensor", "(", "\n", "out", ".", "size", "(", "0", ")", ",", "planes", "-", "out", ".", "size", "(", "1", ")", ",", "out", ".", "size", "(", "2", ")", ",", "out", ".", "size", "(", "3", ")", ",", "\n", "out", ".", "size", "(", "4", ")", ")", ".", "zero_", "(", ")", "\n", "if", "isinstance", "(", "out", ".", "data", ",", "torch", ".", "cuda", ".", "FloatTensor", ")", ":", "\n", "        ", "zero_pads", "=", "zero_pads", ".", "cuda", "(", ")", "\n", "\n", "", "out", "=", "Variable", "(", "torch", ".", "cat", "(", "[", "out", ".", "data", ",", "zero_pads", "]", ",", "dim", "=", "1", ")", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.wide_resnet.get_fine_tuning_parameters": [[161, 180], ["range", "ft_module_names.append", "model.named_parameters", "model.parameters", "ft_module_names.append", "parameters.append", "parameters.append"], "function", ["None"], ["", "", "def", "get_fine_tuning_parameters", "(", "model", ",", "ft_begin_index", ")", ":", "\n", "    ", "if", "ft_begin_index", "==", "0", ":", "\n", "        ", "return", "model", ".", "parameters", "(", ")", "\n", "\n", "", "ft_module_names", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "ft_begin_index", ",", "5", ")", ":", "\n", "        ", "ft_module_names", ".", "append", "(", "'layer{}'", ".", "format", "(", "i", ")", ")", "\n", "", "ft_module_names", ".", "append", "(", "'fc'", ")", "\n", "\n", "parameters", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "for", "ft_module", "in", "ft_module_names", ":", "\n", "            ", "if", "ft_module", "in", "k", ":", "\n", "                ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", "}", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", ",", "'lr'", ":", "0.0", "}", ")", "\n", "\n", "", "", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.wide_resnet.resnet50": [[182, 187], ["wide_resnet.WideResNet"], "function", ["None"], ["", "def", "resnet50", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "model", "=", "WideResNet", "(", "WideBottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.BasicBlock.__init__": [[41, 50], ["torch.Module.__init__", "resnet.conv3x3x3", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "resnet.conv3x3x3", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.conv3x3x3", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.conv3x3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.BasicBlock.forward": [[51, 68], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.Bottleneck.__init__": [[73, 85], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv3d", "(", "\n", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv3d", "(", "planes", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm3d", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.Bottleneck.forward": [[86, 107], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.ResNet.__init__": [[111, 149], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool3d", "torch.MaxPool3d", "torch.MaxPool3d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "int", "int", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.Linear", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "math.ceil", "math.ceil", "isinstance", "torch.init.kaiming_normal", "torch.init.kaiming_normal", "torch.init.kaiming_normal", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "\n", "block", ",", "\n", "layers", ",", "\n", "sample_size", ",", "\n", "sample_duration", ",", "\n", "shortcut_type", "=", "'B'", ",", "\n", "num_classes", "=", "400", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "\n", "3", ",", "\n", "64", ",", "\n", "kernel_size", "=", "7", ",", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "(", "3", ",", "3", ",", "3", ")", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ",", "shortcut_type", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "shortcut_type", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "shortcut_type", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "shortcut_type", ",", "stride", "=", "2", ")", "\n", "last_duration", "=", "int", "(", "math", ".", "ceil", "(", "sample_duration", "/", "16", ")", ")", "\n", "last_size", "=", "int", "(", "math", ".", "ceil", "(", "sample_size", "/", "32", ")", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool3d", "(", "\n", "(", "last_duration", ",", "last_size", ",", "last_size", ")", ",", "stride", "=", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                ", "m", ".", "weight", "=", "nn", ".", "init", ".", "kaiming_normal", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm3d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.ResNet._make_layer": [[150, 174], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "functools.partial", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "shortcut_type", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "if", "shortcut_type", "==", "'A'", ":", "\n", "                ", "downsample", "=", "partial", "(", "\n", "downsample_basic_block", ",", "\n", "planes", "=", "planes", "*", "block", ".", "expansion", ",", "\n", "stride", "=", "stride", ")", "\n", "", "else", ":", "\n", "                ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv3d", "(", "\n", "self", ".", "inplanes", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ")", ",", "nn", ".", "BatchNorm3d", "(", "planes", "*", "block", ".", "expansion", ")", ")", "\n", "\n", "", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.ResNet.forward": [[175, 192], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.fc", "resnet.ResNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.conv3x3x3": [[14, 23], ["torch.Conv3d"], "function", ["None"], ["def", "conv3x3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "# 3x3x3 convolution with padding", "\n", "    ", "return", "nn", ".", "Conv3d", "(", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.downsample_basic_block": [[25, 36], ["torch.avg_pool3d", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "isinstance", "torch.autograd.Variable", "zero_pads.cuda.cuda", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "function", ["None"], ["", "def", "downsample_basic_block", "(", "x", ",", "planes", ",", "stride", ")", ":", "\n", "    ", "out", "=", "F", ".", "avg_pool3d", "(", "x", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ")", "\n", "zero_pads", "=", "torch", ".", "Tensor", "(", "\n", "out", ".", "size", "(", "0", ")", ",", "planes", "-", "out", ".", "size", "(", "1", ")", ",", "out", ".", "size", "(", "2", ")", ",", "out", ".", "size", "(", "3", ")", ",", "\n", "out", ".", "size", "(", "4", ")", ")", ".", "zero_", "(", ")", "\n", "if", "isinstance", "(", "out", ".", "data", ",", "torch", ".", "cuda", ".", "FloatTensor", ")", ":", "\n", "        ", "zero_pads", "=", "zero_pads", ".", "cuda", "(", ")", "\n", "\n", "", "out", "=", "Variable", "(", "torch", ".", "cat", "(", "[", "out", ".", "data", ",", "zero_pads", "]", ",", "dim", "=", "1", ")", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.get_fine_tuning_parameters": [[194, 213], ["range", "ft_module_names.append", "model.named_parameters", "model.parameters", "ft_module_names.append", "parameters.append", "parameters.append"], "function", ["None"], ["", "", "def", "get_fine_tuning_parameters", "(", "model", ",", "ft_begin_index", ")", ":", "\n", "    ", "if", "ft_begin_index", "==", "0", ":", "\n", "        ", "return", "model", ".", "parameters", "(", ")", "\n", "\n", "", "ft_module_names", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "ft_begin_index", ",", "5", ")", ":", "\n", "        ", "ft_module_names", ".", "append", "(", "'layer{}'", ".", "format", "(", "i", ")", ")", "\n", "", "ft_module_names", ".", "append", "(", "'fc'", ")", "\n", "\n", "parameters", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "for", "ft_module", "in", "ft_module_names", ":", "\n", "            ", "if", "ft_module", "in", "k", ":", "\n", "                ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", "}", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", ",", "'lr'", ":", "0.0", "}", ")", "\n", "\n", "", "", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet10": [[215, 220], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet10", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet18": [[222, 227], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet18", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet34": [[229, 234], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet34", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet50": [[236, 241], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet50", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet101": [[243, 248], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet101", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet152": [[250, 255], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet152", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnet.resnet200": [[257, 262], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet200", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "24", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet._DenseLayer.__init__": [[73, 95], ["torch.Sequential.__init__", "densenet._DenseLayer.add_module", "densenet._DenseLayer.add_module", "densenet._DenseLayer.add_module", "densenet._DenseLayer.add_module", "densenet._DenseLayer.add_module", "densenet._DenseLayer.add_module", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_input_features", ",", "growth_rate", ",", "bn_size", ",", "drop_rate", ")", ":", "\n", "        ", "super", "(", "_DenseLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_module", "(", "'norm.1'", ",", "nn", ".", "BatchNorm3d", "(", "num_input_features", ")", ")", "\n", "self", ".", "add_module", "(", "'relu.1'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "add_module", "(", "'conv.1'", ",", "\n", "nn", ".", "Conv3d", "(", "\n", "num_input_features", ",", "\n", "bn_size", "*", "growth_rate", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "bias", "=", "False", ")", ")", "\n", "self", ".", "add_module", "(", "'norm.2'", ",", "nn", ".", "BatchNorm3d", "(", "bn_size", "*", "growth_rate", ")", ")", "\n", "self", ".", "add_module", "(", "'relu.2'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "add_module", "(", "'conv.2'", ",", "\n", "nn", ".", "Conv3d", "(", "\n", "bn_size", "*", "growth_rate", ",", "\n", "growth_rate", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", ")", "\n", "self", ".", "drop_rate", "=", "drop_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet._DenseLayer.forward": [[96, 102], ["super().forward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.dropout", "torch.dropout", "torch.dropout"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.CNN.forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_features", "=", "super", "(", "_DenseLayer", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "if", "self", ".", "drop_rate", ">", "0", ":", "\n", "            ", "new_features", "=", "F", ".", "dropout", "(", "\n", "new_features", ",", "p", "=", "self", ".", "drop_rate", ",", "training", "=", "self", ".", "training", ")", "\n", "", "return", "torch", ".", "cat", "(", "[", "x", ",", "new_features", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet._DenseBlock.__init__": [[106, 113], ["torch.Sequential.__init__", "range", "densenet._DenseLayer", "densenet._DenseBlock.add_module"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_layers", ",", "num_input_features", ",", "bn_size", ",", "growth_rate", ",", "\n", "drop_rate", ")", ":", "\n", "        ", "super", "(", "_DenseBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "for", "i", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "layer", "=", "_DenseLayer", "(", "num_input_features", "+", "i", "*", "growth_rate", ",", "\n", "growth_rate", ",", "bn_size", ",", "drop_rate", ")", "\n", "self", ".", "add_module", "(", "'denselayer%d'", "%", "(", "i", "+", "1", ")", ",", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet._Transition.__init__": [[117, 129], ["torch.Sequential.__init__", "densenet._Transition.add_module", "densenet._Transition.add_module", "densenet._Transition.add_module", "densenet._Transition.add_module", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_input_features", ",", "num_output_features", ")", ":", "\n", "        ", "super", "(", "_Transition", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "add_module", "(", "'norm'", ",", "nn", ".", "BatchNorm3d", "(", "num_input_features", ")", ")", "\n", "self", ".", "add_module", "(", "'relu'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "self", ".", "add_module", "(", "'conv'", ",", "\n", "nn", ".", "Conv3d", "(", "\n", "num_input_features", ",", "\n", "num_output_features", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "bias", "=", "False", ")", ")", "\n", "self", ".", "add_module", "(", "'pool'", ",", "nn", ".", "AvgPool3d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet.DenseNet.__init__": [[143, 204], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "enumerate", "densenet.DenseNet.features.add_module", "densenet.DenseNet.modules", "torch.Linear", "torch.Linear", "torch.Linear", "collections.OrderedDict", "densenet._DenseBlock", "densenet.DenseNet.features.add_module", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "isinstance", "densenet._Transition", "densenet.DenseNet.features.add_module", "torch.init.kaiming_normal", "torch.init.kaiming_normal", "torch.init.kaiming_normal", "len", "isinstance", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool3d", "torch.MaxPool3d", "torch.MaxPool3d"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["def", "__init__", "(", "self", ",", "\n", "sample_size", ",", "\n", "sample_duration", ",", "\n", "growth_rate", "=", "32", ",", "\n", "block_config", "=", "(", "6", ",", "12", ",", "24", ",", "16", ")", ",", "\n", "num_init_features", "=", "64", ",", "\n", "bn_size", "=", "4", ",", "\n", "drop_rate", "=", "0", ",", "\n", "num_classes", "=", "1000", ")", ":", "\n", "\n", "        ", "super", "(", "DenseNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "sample_size", "=", "sample_size", "\n", "self", ".", "sample_duration", "=", "sample_duration", "\n", "\n", "# First convolution", "\n", "self", ".", "features", "=", "nn", ".", "Sequential", "(", "\n", "OrderedDict", "(", "[", "\n", "(", "'conv0'", ",", "\n", "nn", ".", "Conv3d", "(", "\n", "3", ",", "\n", "num_init_features", ",", "\n", "kernel_size", "=", "7", ",", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "(", "3", ",", "3", ",", "3", ")", ",", "\n", "bias", "=", "False", ")", ")", ",", "\n", "(", "'norm0'", ",", "nn", ".", "BatchNorm3d", "(", "num_init_features", ")", ")", ",", "\n", "(", "'relu0'", ",", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", ",", "\n", "(", "'pool0'", ",", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", ",", "\n", "]", ")", ")", "\n", "\n", "# Each denseblock", "\n", "num_features", "=", "num_init_features", "\n", "for", "i", ",", "num_layers", "in", "enumerate", "(", "block_config", ")", ":", "\n", "            ", "block", "=", "_DenseBlock", "(", "\n", "num_layers", "=", "num_layers", ",", "\n", "num_input_features", "=", "num_features", ",", "\n", "bn_size", "=", "bn_size", ",", "\n", "growth_rate", "=", "growth_rate", ",", "\n", "drop_rate", "=", "drop_rate", ")", "\n", "self", ".", "features", ".", "add_module", "(", "'denseblock%d'", "%", "(", "i", "+", "1", ")", ",", "block", ")", "\n", "num_features", "=", "num_features", "+", "num_layers", "*", "growth_rate", "\n", "if", "i", "!=", "len", "(", "block_config", ")", "-", "1", ":", "\n", "                ", "trans", "=", "_Transition", "(", "\n", "num_input_features", "=", "num_features", ",", "\n", "num_output_features", "=", "num_features", "//", "2", ")", "\n", "self", ".", "features", ".", "add_module", "(", "'transition%d'", "%", "(", "i", "+", "1", ")", ",", "trans", ")", "\n", "num_features", "=", "num_features", "//", "2", "\n", "\n", "# Final batch norm", "\n", "", "", "self", ".", "features", ".", "add_module", "(", "'norm5'", ",", "nn", ".", "BatchNorm2d", "(", "num_features", ")", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                ", "m", ".", "weight", "=", "nn", ".", "init", ".", "kaiming_normal", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm3d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "# Linear layer", "\n", "", "", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "num_features", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet.DenseNet.forward": [[205, 215], ["densenet.DenseNet.features", "torch.relu", "torch.relu", "torch.relu", "int", "int", "torch.avg_pool3d().view", "torch.avg_pool3d().view", "torch.avg_pool3d().view", "densenet.DenseNet.classifier", "math.ceil", "math.floor", "densenet.DenseNet.size", "torch.avg_pool3d", "torch.avg_pool3d", "torch.avg_pool3d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "features", "=", "self", ".", "features", "(", "x", ")", "\n", "out", "=", "F", ".", "relu", "(", "features", ",", "inplace", "=", "True", ")", "\n", "last_duration", "=", "int", "(", "math", ".", "ceil", "(", "self", ".", "sample_duration", "/", "16", ")", ")", "\n", "last_size", "=", "int", "(", "math", ".", "floor", "(", "self", ".", "sample_size", "/", "32", ")", ")", "\n", "out", "=", "F", ".", "avg_pool3d", "(", "\n", "out", ",", "kernel_size", "=", "(", "last_duration", ",", "last_size", ",", "last_size", ")", ")", ".", "view", "(", "\n", "features", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "classifier", "(", "out", ")", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet.densenet121": [[12, 19], ["densenet.DenseNet"], "function", ["None"], ["def", "densenet121", "(", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "DenseNet", "(", "\n", "num_init_features", "=", "64", ",", "\n", "growth_rate", "=", "32", ",", "\n", "block_config", "=", "(", "6", ",", "12", ",", "24", ",", "16", ")", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet.densenet169": [[21, 28], ["densenet.DenseNet"], "function", ["None"], ["", "def", "densenet169", "(", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "DenseNet", "(", "\n", "num_init_features", "=", "64", ",", "\n", "growth_rate", "=", "32", ",", "\n", "block_config", "=", "(", "6", ",", "12", ",", "32", ",", "32", ")", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet.densenet201": [[30, 37], ["densenet.DenseNet"], "function", ["None"], ["", "def", "densenet201", "(", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "DenseNet", "(", "\n", "num_init_features", "=", "64", ",", "\n", "growth_rate", "=", "32", ",", "\n", "block_config", "=", "(", "6", ",", "12", ",", "48", ",", "32", ")", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet.densenet264": [[39, 46], ["densenet.DenseNet"], "function", ["None"], ["", "def", "densenet264", "(", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "DenseNet", "(", "\n", "num_init_features", "=", "64", ",", "\n", "growth_rate", "=", "32", ",", "\n", "block_config", "=", "(", "6", ",", "12", ",", "64", ",", "48", ")", ",", "\n", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.densenet.get_fine_tuning_parameters": [[48, 69], ["range", "ft_module_names.append", "ft_module_names.append", "model.named_parameters", "model.parameters", "ft_module_names.append", "ft_module_names.append", "parameters.append", "parameters.append"], "function", ["None"], ["", "def", "get_fine_tuning_parameters", "(", "model", ",", "ft_begin_index", ")", ":", "\n", "    ", "if", "ft_begin_index", "==", "0", ":", "\n", "        ", "return", "model", ".", "parameters", "(", ")", "\n", "\n", "", "ft_module_names", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "ft_begin_index", ",", "5", ")", ":", "\n", "        ", "ft_module_names", ".", "append", "(", "'denseblock{}'", ".", "format", "(", "i", ")", ")", "\n", "ft_module_names", ".", "append", "(", "'transition{}'", ".", "format", "(", "i", ")", ")", "\n", "", "ft_module_names", ".", "append", "(", "'norm5'", ")", "\n", "ft_module_names", ".", "append", "(", "'classifier'", ")", "\n", "\n", "parameters", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "for", "ft_module", "in", "ft_module_names", ":", "\n", "            ", "if", "ft_module", "in", "k", ":", "\n", "                ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", "}", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", ",", "'lr'", ":", "0.0", "}", ")", "\n", "\n", "", "", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXtBottleneck.__init__": [[38, 59], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "int"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "cardinality", ",", "stride", "=", "1", ",", "\n", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResNeXtBottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "mid_planes", "=", "cardinality", "*", "int", "(", "planes", "/", "32", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "inplanes", ",", "mid_planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "mid_planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv3d", "(", "\n", "mid_planes", ",", "\n", "mid_planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "groups", "=", "cardinality", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm3d", "(", "mid_planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv3d", "(", "\n", "mid_planes", ",", "planes", "*", "self", ".", "expansion", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm3d", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXtBottleneck.forward": [[60, 81], ["resnext.ResNeXtBottleneck.conv1", "resnext.ResNeXtBottleneck.bn1", "resnext.ResNeXtBottleneck.relu", "resnext.ResNeXtBottleneck.conv2", "resnext.ResNeXtBottleneck.bn2", "resnext.ResNeXtBottleneck.relu", "resnext.ResNeXtBottleneck.conv3", "resnext.ResNeXtBottleneck.bn3", "resnext.ResNeXtBottleneck.relu", "resnext.ResNeXtBottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt.__init__": [[85, 125], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool3d", "torch.MaxPool3d", "torch.MaxPool3d", "resnext.ResNeXt._make_layer", "resnext.ResNeXt._make_layer", "resnext.ResNeXt._make_layer", "resnext.ResNeXt._make_layer", "int", "int", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.Linear", "torch.Linear", "torch.Linear", "resnext.ResNeXt.modules", "math.ceil", "math.ceil", "isinstance", "torch.init.kaiming_normal", "torch.init.kaiming_normal", "torch.init.kaiming_normal", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "\n", "block", ",", "\n", "layers", ",", "\n", "sample_size", ",", "\n", "sample_duration", ",", "\n", "shortcut_type", "=", "'B'", ",", "\n", "cardinality", "=", "32", ",", "\n", "num_classes", "=", "400", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNeXt", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "\n", "3", ",", "\n", "64", ",", "\n", "kernel_size", "=", "7", ",", "\n", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "(", "3", ",", "3", ",", "3", ")", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool3d", "(", "kernel_size", "=", "(", "3", ",", "3", ",", "3", ")", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "0", "]", ",", "shortcut_type", ",", "\n", "cardinality", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "256", ",", "layers", "[", "1", "]", ",", "shortcut_type", ",", "cardinality", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "512", ",", "layers", "[", "2", "]", ",", "shortcut_type", ",", "cardinality", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "1024", ",", "layers", "[", "3", "]", ",", "shortcut_type", ",", "cardinality", ",", "stride", "=", "2", ")", "\n", "last_duration", "=", "int", "(", "math", ".", "ceil", "(", "sample_duration", "/", "16", ")", ")", "\n", "last_size", "=", "int", "(", "math", ".", "ceil", "(", "sample_size", "/", "32", ")", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool3d", "(", "\n", "(", "last_duration", ",", "last_size", ",", "last_size", ")", ",", "stride", "=", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "cardinality", "*", "32", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv3d", ")", ":", "\n", "                ", "m", ".", "weight", "=", "nn", ".", "init", ".", "kaiming_normal", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm3d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt._make_layer": [[126, 157], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "functools.partial", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "\n", "block", ",", "\n", "planes", ",", "\n", "blocks", ",", "\n", "shortcut_type", ",", "\n", "cardinality", ",", "\n", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "if", "shortcut_type", "==", "'A'", ":", "\n", "                ", "downsample", "=", "partial", "(", "\n", "downsample_basic_block", ",", "\n", "planes", "=", "planes", "*", "block", ".", "expansion", ",", "\n", "stride", "=", "stride", ")", "\n", "", "else", ":", "\n", "                ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv3d", "(", "\n", "self", ".", "inplanes", ",", "\n", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ")", ",", "nn", ".", "BatchNorm3d", "(", "planes", "*", "block", ".", "expansion", ")", ")", "\n", "\n", "", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "\n", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "cardinality", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "cardinality", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.ResNeXt.forward": [[158, 175], ["resnext.ResNeXt.conv1", "resnext.ResNeXt.bn1", "resnext.ResNeXt.relu", "resnext.ResNeXt.maxpool", "resnext.ResNeXt.layer1", "resnext.ResNeXt.layer2", "resnext.ResNeXt.layer3", "resnext.ResNeXt.layer4", "resnext.ResNeXt.avgpool", "resnext.ResNeXt.view", "resnext.ResNeXt.fc", "resnext.ResNeXt.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.conv3x3x3": [[11, 20], ["torch.Conv3d"], "function", ["None"], ["def", "conv3x3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "# 3x3x3 convolution with padding", "\n", "    ", "return", "nn", ".", "Conv3d", "(", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.downsample_basic_block": [[22, 33], ["torch.avg_pool3d", "torch.Tensor().zero_", "torch.Tensor().zero_", "torch.Tensor().zero_", "isinstance", "torch.autograd.Variable", "zero_pads.cuda.cuda", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "function", ["None"], ["", "def", "downsample_basic_block", "(", "x", ",", "planes", ",", "stride", ")", ":", "\n", "    ", "out", "=", "F", ".", "avg_pool3d", "(", "x", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ")", "\n", "zero_pads", "=", "torch", ".", "Tensor", "(", "\n", "out", ".", "size", "(", "0", ")", ",", "planes", "-", "out", ".", "size", "(", "1", ")", ",", "out", ".", "size", "(", "2", ")", ",", "out", ".", "size", "(", "3", ")", ",", "\n", "out", ".", "size", "(", "4", ")", ")", ".", "zero_", "(", ")", "\n", "if", "isinstance", "(", "out", ".", "data", ",", "torch", ".", "cuda", ".", "FloatTensor", ")", ":", "\n", "        ", "zero_pads", "=", "zero_pads", ".", "cuda", "(", ")", "\n", "\n", "", "out", "=", "Variable", "(", "torch", ".", "cat", "(", "[", "out", ".", "data", ",", "zero_pads", "]", ",", "dim", "=", "1", ")", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.get_fine_tuning_parameters": [[177, 196], ["range", "ft_module_names.append", "model.named_parameters", "model.parameters", "ft_module_names.append", "parameters.append", "parameters.append"], "function", ["None"], ["", "", "def", "get_fine_tuning_parameters", "(", "model", ",", "ft_begin_index", ")", ":", "\n", "    ", "if", "ft_begin_index", "==", "0", ":", "\n", "        ", "return", "model", ".", "parameters", "(", ")", "\n", "\n", "", "ft_module_names", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "ft_begin_index", ",", "5", ")", ":", "\n", "        ", "ft_module_names", ".", "append", "(", "'layer{}'", ".", "format", "(", "i", ")", ")", "\n", "", "ft_module_names", ".", "append", "(", "'fc'", ")", "\n", "\n", "parameters", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "for", "ft_module", "in", "ft_module_names", ":", "\n", "            ", "if", "ft_module", "in", "k", ":", "\n", "                ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", "}", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "parameters", ".", "append", "(", "{", "'params'", ":", "v", ",", "'lr'", ":", "0.0", "}", ")", "\n", "\n", "", "", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet50": [[198, 203], ["resnext.ResNeXt"], "function", ["None"], ["", "def", "resnet50", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "model", "=", "ResNeXt", "(", "ResNeXtBottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet101": [[205, 210], ["resnext.ResNeXt"], "function", ["None"], ["", "def", "resnet101", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model", "=", "ResNeXt", "(", "ResNeXtBottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.models.resnext.resnet152": [[212, 217], ["resnext.ResNeXt"], "function", ["None"], ["", "def", "resnet152", "(", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "model", "=", "ResNeXt", "(", "ResNeXtBottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_II.hash.forward": [[24, 36], ["U.sort", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "ctx.save_for_backward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "int", "int"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "U", ")", ":", "\n", "\n", "# Yunqiang for half and half (optimal transport)", "\n", "        ", "_", ",", "index", "=", "U", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "N", ",", "D", "=", "U", ".", "shape", "\n", "B_creat", "=", "torch", ".", "cat", "(", "(", "torch", ".", "ones", "(", "[", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ",", "-", "torch", ".", "ones", "(", "[", "N", "-", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "B", "=", "torch", ".", "zeros", "(", "U", ".", "shape", ")", ".", "cuda", "(", ")", ".", "scatter_", "(", "0", ",", "index", ",", "B_creat", ")", "\n", "\n", "ctx", ".", "save_for_backward", "(", "U", ",", "B", ")", "\n", "\n", "return", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_II.hash.backward": [[37, 45], ["B.numel"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "g", ")", ":", "\n", "        ", "U", ",", "B", "=", "ctx", ".", "saved_tensors", "\n", "add_g", "=", "(", "U", "-", "B", ")", "/", "(", "B", ".", "numel", "(", ")", ")", "\n", "\n", "grad", "=", "g", "+", "gamma", "*", "add_g", "\n", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_II.CNN.__init__": [[52, 60], ["torch.Module.__init__", "torchvision.models.vgg16", "torchvision.models.vgg16", "torchvision.models.vgg16", "torchvision.models.vgg16", "torch.Sequential", "torch.Sequential", "torch.Sequential", "Cifar10_II.CNN.vgg.parameters", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.Linear", "torch.Linear", "torch.Linear", "list", "Cifar10_II.CNN.vgg.classifier.children"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encode_length", ")", ":", "\n", "        ", "super", "(", "CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vgg", "=", "torchvision", ".", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", "\n", "self", ".", "vgg", ".", "classifier", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "self", ".", "vgg", ".", "classifier", ".", "children", "(", ")", ")", "[", ":", "6", "]", ")", "\n", "for", "param", "in", "self", ".", "vgg", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "torch", ".", "manual_seed", "(", "0", ")", "\n", "self", ".", "fc_encode", "=", "nn", ".", "Linear", "(", "4096", ",", "encode_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_II.CNN.forward": [[62, 70], ["Cifar10_II.CNN.vgg.features", "Cifar10_II.CNN.view", "Cifar10_II.CNN.vgg.classifier", "Cifar10_II.CNN.fc_encode", "Cifar10_II.hash_layer", "Cifar10_II.CNN.size"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash_layer"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "vgg", ".", "features", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "vgg", ".", "classifier", "(", "x", ")", "\n", "h", "=", "self", ".", "fc_encode", "(", "x", ")", "\n", "b", "=", "hash_layer", "(", "h", ")", "\n", "\n", "return", "x", ",", "h", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_II.hash_layer": [[47, 49], ["hash.apply"], "function", ["None"], ["", "", "def", "hash_layer", "(", "input", ")", ":", "\n", "    ", "return", "hash", ".", "apply", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_II.adjust_learning_rate": [[71, 75], ["None"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "lr", "=", "learning_rate", "*", "(", "0.1", "**", "(", "epoch", "//", "epoch_lr_decrease", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_II.main": [[76, 209], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.CIFAR10", "torchvision.CIFAR10", "torchvision.CIFAR10", "numpy.array", "numpy.concatenate", "numpy.concatenate", "range", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "Cifar10_II.CNN", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "range", "numpy.random.seed", "numpy.random.permutation", "np.concatenate.astype", "np.concatenate.astype", "np.concatenate.astype", "CNN.fc_encode.parameters", "CNN.cuda().train", "Cifar10_II.adjust_learning_rate", "enumerate", "torchvision.transforms.Scale", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Scale", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "numpy.array", "numpy.where", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.optim.SGD.zero_grad", "CNN.", "torch.cosine_similarity", "torch.cosine_similarity", "torch.mse_loss", "F.mse_loss.backward", "torch.optim.SGD.step", "CNN.eval", "cal_map_single.compress", "cal_map_single.calculate_map", "print", "CNN.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda().long", "torch.autograd.Variable.cuda", "int", "int", "int", "int", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.adjust_learning_rate", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash.backward", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.compress", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_map"], ["", "", "def", "main", "(", ")", ":", "\n", "\n", "\n", "\n", "    ", "train_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Scale", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "\n", "test_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Scale", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "\n", "# Dataset", "\n", "train_dataset", "=", "dsets", ".", "CIFAR10", "(", "root", "=", "'./data/Cifar/'", ",", "\n", "train", "=", "True", ",", "\n", "transform", "=", "train_transform", ",", "\n", "download", "=", "True", ")", "\n", "\n", "test_dataset", "=", "dsets", ".", "CIFAR10", "(", "root", "=", "'./data/Cifar/'", ",", "\n", "train", "=", "False", ",", "\n", "transform", "=", "test_transform", ")", "\n", "\n", "database_dataset", "=", "dsets", ".", "CIFAR10", "(", "root", "=", "'./data/Cifar/'", ",", "\n", "train", "=", "False", ",", "\n", "transform", "=", "test_transform", ")", "\n", "\n", "\n", "# Re-Construct training, query and database set", "\n", "X", "=", "train_dataset", ".", "data", "\n", "L", "=", "np", ".", "array", "(", "train_dataset", ".", "targets", ")", "\n", "\n", "X", "=", "np", ".", "concatenate", "(", "(", "X", ",", "test_dataset", ".", "data", ")", ")", "\n", "L", "=", "np", ".", "concatenate", "(", "(", "L", ",", "np", ".", "array", "(", "test_dataset", ".", "targets", ")", ")", ")", "\n", "\n", "first", "=", "True", "\n", "\n", "for", "label", "in", "range", "(", "10", ")", ":", "\n", "        ", "index", "=", "np", ".", "where", "(", "L", "==", "label", ")", "[", "0", "]", "\n", "\n", "N", "=", "index", ".", "shape", "[", "0", "]", "\n", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "N", ")", "\n", "index", "=", "index", "[", "perm", "]", "\n", "\n", "data", "=", "X", "[", "index", "[", "0", ":", "1000", "]", "]", "\n", "labels", "=", "L", "[", "index", "[", "0", ":", "1000", "]", "]", "\n", "if", "first", ":", "\n", "            ", "test_L", "=", "labels", "\n", "test_data", "=", "data", "\n", "", "else", ":", "\n", "            ", "test_L", "=", "np", ".", "concatenate", "(", "(", "test_L", ",", "labels", ")", ")", "\n", "test_data", "=", "np", ".", "concatenate", "(", "(", "test_data", ",", "data", ")", ")", "\n", "\n", "", "data", "=", "X", "[", "index", "[", "1000", ":", "6000", "]", "]", "\n", "labels", "=", "L", "[", "index", "[", "1000", ":", "6000", "]", "]", "\n", "if", "first", ":", "\n", "            ", "dataset_L", "=", "labels", "\n", "data_set", "=", "data", "\n", "", "else", ":", "\n", "            ", "dataset_L", "=", "np", ".", "concatenate", "(", "(", "dataset_L", ",", "labels", ")", ")", "\n", "data_set", "=", "np", ".", "concatenate", "(", "(", "data_set", ",", "data", ")", ")", "\n", "\n", "", "data", "=", "X", "[", "index", "[", "1000", ":", "1500", "]", "]", "\n", "labels", "=", "L", "[", "index", "[", "1000", ":", "1500", "]", "]", "\n", "if", "first", ":", "\n", "            ", "train_L", "=", "labels", "\n", "train_data", "=", "data", "\n", "", "else", ":", "\n", "            ", "train_L", "=", "np", ".", "concatenate", "(", "(", "train_L", ",", "labels", ")", ")", "\n", "train_data", "=", "np", ".", "concatenate", "(", "(", "train_data", ",", "data", ")", ")", "\n", "\n", "", "first", "=", "False", "\n", "\n", "train_dataset", ".", "data", "=", "train_data", "\n", "train_dataset", ".", "targets", "=", "train_L", ".", "astype", "(", "np", ".", "long", ")", "\n", "test_dataset", ".", "data", "=", "test_data", "\n", "test_dataset", ".", "targets", "=", "(", "test_L", ")", ".", "astype", "(", "np", ".", "long", ")", "\n", "database_dataset", ".", "data", "=", "data_set", "\n", "database_dataset", ".", "targets", "=", "(", "dataset_L", ")", ".", "astype", "(", "np", ".", "long", ")", "\n", "\n", "# Data Loader", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "train_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "4", ")", "\n", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "test_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "4", ")", "\n", "\n", "database_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "database_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "4", ")", "\n", "\n", "\n", "\n", "cnn", "=", "CNN", "(", "encode_length", "=", "encode_length", ")", "\n", "\n", "\n", "# Loss and Optimizer", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "cnn", ".", "fc_encode", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "5e-4", ")", "\n", "\n", "\n", "# Train the Model", "\n", "for", "epoch", "in", "range", "(", "num_epochs", ")", ":", "\n", "        ", "cnn", ".", "cuda", "(", ")", ".", "train", "(", ")", "\n", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", "\n", "for", "i", ",", "(", "images", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "images", "=", "Variable", "(", "images", ".", "cuda", "(", ")", ")", "\n", "labels", "=", "Variable", "(", "labels", ".", "cuda", "(", ")", ".", "long", "(", ")", ")", "\n", "\n", "# Forward + Backward + Optimize", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "x", ",", "_", ",", "b", "=", "cnn", "(", "images", ")", "\n", "\n", "target_b", "=", "F", ".", "cosine_similarity", "(", "b", "[", ":", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", "]", ",", "b", "[", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", ":", "]", ")", "\n", "target_x", "=", "F", ".", "cosine_similarity", "(", "x", "[", ":", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", "]", ",", "x", "[", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", ":", "]", ")", "\n", "loss", "=", "F", ".", "mse_loss", "(", "target_b", ",", "target_x", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Test the Model", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "10", "==", "0", ":", "\n", "            ", "cnn", ".", "eval", "(", ")", "\n", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "=", "compress", "(", "database_loader", ",", "test_loader", ",", "cnn", ")", "\n", "result_map", "=", "calculate_map", "(", "qB", "=", "queryB", ",", "rB", "=", "retrievalB", ",", "queryL", "=", "queryL", ",", "retrievalL", "=", "retrievalL", ")", "\n", "print", "(", "'--------mAP@All: {}--------'", ".", "format", "(", "result_map", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_single.compress": [[7, 32], ["list", "list", "enumerate", "list", "list", "enumerate", "numpy.array", "numpy.array", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "list.extend", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "list.extend", "numpy.eye", "numpy.eye", "data.cuda", "torch.sign.cpu().data.numpy", "data.cuda", "torch.sign.cpu().data.numpy", "numpy.array", "numpy.array", "torch.sign.cpu", "torch.sign.cpu"], "function", ["None"], ["def", "compress", "(", "train", ",", "test", ",", "model", ",", "classes", "=", "10", ")", ":", "\n", "    ", "retrievalB", "=", "list", "(", "[", "]", ")", "\n", "retrievalL", "=", "list", "(", "[", "]", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "train", ")", ":", "\n", "        ", "var_data", "=", "Variable", "(", "data", ".", "cuda", "(", ")", ")", "\n", "_", ",", "H", ",", "code", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "retrievalB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "retrievalL", ".", "extend", "(", "target", ")", "\n", "\n", "", "queryB", "=", "list", "(", "[", "]", ")", "\n", "queryL", "=", "list", "(", "[", "]", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "test", ")", ":", "\n", "        ", "var_data", "=", "Variable", "(", "data", ".", "cuda", "(", ")", ")", "\n", "_", ",", "H", ",", "code", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "queryB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "queryL", ".", "extend", "(", "target", ")", "\n", "\n", "", "retrievalB", "=", "np", ".", "array", "(", "retrievalB", ")", "\n", "retrievalL", "=", "np", ".", "eye", "(", "classes", ")", "[", "np", ".", "array", "(", "retrievalL", ")", "]", "\n", "\n", "queryB", "=", "np", ".", "array", "(", "queryB", ")", "\n", "queryL", "=", "np", ".", "eye", "(", "classes", ")", "[", "np", ".", "array", "(", "queryL", ")", "]", "\n", "return", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_single.calculate_hamming": [[34, 43], ["numpy.dot", "B2.transpose"], "function", ["None"], ["", "def", "calculate_hamming", "(", "B1", ",", "B2", ")", ":", "\n", "    ", "\"\"\"\n    :param B1:  vector [n]\n    :param B2:  vector [r*n]\n    :return: hamming distance [r]\n    \"\"\"", "\n", "q", "=", "B2", ".", "shape", "[", "1", "]", "# max inner product value", "\n", "distH", "=", "0.5", "*", "(", "q", "-", "np", ".", "dot", "(", "B1", ",", "B2", ".", "transpose", "(", ")", ")", ")", "\n", "return", "distH", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_single.calculate_map": [[45, 74], ["range", "numpy.sum", "cal_map_single.calculate_hamming", "numpy.argsort", "numpy.linspace", "numpy.mean", "numpy.asarray", "numpy.where", "numpy.dot", "retrievalL.transpose"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_hamming"], ["", "def", "calculate_map", "(", "qB", ",", "rB", ",", "queryL", ",", "retrievalL", ")", ":", "\n", "    ", "\"\"\"\n       :param qB: {-1,+1}^{mxq} query bits\n       :param rB: {-1,+1}^{nxq} retrieval bits\n       :param queryL: {0,1}^{mxl} query label\n       :param retrievalL: {0,1}^{nxl} retrieval label\n       :return:\n    \"\"\"", "\n", "num_query", "=", "queryL", ".", "shape", "[", "0", "]", "\n", "map", "=", "0", "\n", "for", "iter", "in", "range", "(", "num_query", ")", ":", "\n", "# gnd : check if exists any retrieval items with same label", "\n", "        ", "gnd", "=", "(", "np", ".", "dot", "(", "queryL", "[", "iter", ",", ":", "]", ",", "retrievalL", ".", "transpose", "(", ")", ")", ">", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# tsum number of items with same label", "\n", "tsum", "=", "np", ".", "sum", "(", "gnd", ")", "\n", "if", "tsum", "==", "0", ":", "\n", "            ", "continue", "\n", "# sort gnd by hamming dist", "\n", "", "hamm", "=", "calculate_hamming", "(", "qB", "[", "iter", ",", ":", "]", ",", "rB", ")", "\n", "ind", "=", "np", ".", "argsort", "(", "hamm", ")", "\n", "gnd", "=", "gnd", "[", "ind", "]", "\n", "\n", "count", "=", "np", ".", "linspace", "(", "1", ",", "tsum", ",", "tsum", ")", "# [1,2, tsum]", "\n", "tindex", "=", "np", ".", "asarray", "(", "np", ".", "where", "(", "gnd", "==", "1", ")", ")", "+", "1.0", "\n", "map_", "=", "np", ".", "mean", "(", "count", "/", "(", "tindex", ")", ")", "\n", "# print(map_)", "\n", "map", "=", "map", "+", "map_", "\n", "", "map", "=", "map", "/", "num_query", "\n", "return", "map", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_single.calculate_top_map": [[76, 105], ["range", "cal_map_single.calculate_hamming", "numpy.argsort", "numpy.sum", "numpy.linspace", "numpy.mean", "numpy.asarray", "numpy.where", "numpy.dot", "retrievalL.transpose"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_hamming"], ["", "def", "calculate_top_map", "(", "qB", ",", "rB", ",", "queryL", ",", "retrievalL", ",", "topk", ")", ":", "\n", "    ", "\"\"\"\n    :param qB: {-1,+1}^{mxq} query bits\n    :param rB: {-1,+1}^{nxq} retrieval bits\n    :param queryL: {0,1}^{mxl} query label\n    :param retrievalL: {0,1}^{nxl} retrieval label\n    :param topk:\n    :return:\n    \"\"\"", "\n", "num_query", "=", "queryL", ".", "shape", "[", "0", "]", "\n", "topkmap", "=", "0", "\n", "for", "iter", "in", "range", "(", "num_query", ")", ":", "\n", "        ", "gnd", "=", "(", "np", ".", "dot", "(", "queryL", "[", "iter", ",", ":", "]", ",", "retrievalL", ".", "transpose", "(", ")", ")", ">", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "hamm", "=", "calculate_hamming", "(", "qB", "[", "iter", ",", ":", "]", ",", "rB", ")", "\n", "ind", "=", "np", ".", "argsort", "(", "hamm", ")", "\n", "gnd", "=", "gnd", "[", "ind", "]", "\n", "\n", "tgnd", "=", "gnd", "[", "0", ":", "topk", "]", "\n", "tsum", "=", "np", ".", "sum", "(", "tgnd", ")", "\n", "if", "tsum", "==", "0", ":", "\n", "            ", "continue", "\n", "", "count", "=", "np", ".", "linspace", "(", "1", ",", "tsum", ",", "tsum", ")", "\n", "\n", "tindex", "=", "np", ".", "asarray", "(", "np", ".", "where", "(", "tgnd", "==", "1", ")", ")", "+", "1.0", "\n", "topkmap_", "=", "np", ".", "mean", "(", "count", "/", "(", "tindex", ")", ")", "\n", "# print(topkmap_)", "\n", "topkmap", "=", "topkmap", "+", "topkmap_", "\n", "", "topkmap", "=", "topkmap", "/", "num_query", "\n", "return", "topkmap", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.MScoco.__init__": [[50, 86], ["os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.expanduser", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.array", "numpy.array", "Mscoco.MScoco.train_labels.reshape", "open", "file_to_read.readline", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "Mscoco.MScoco.train_data.append", "Mscoco.MScoco.train_labels.append", "file_to_read.readline.split", "file_to_read.readline.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "train", "=", "True", ",", "database_bool", "=", "False", ")", ":", "\n", "        ", "self", ".", "loader", "=", "default_loader", "\n", "self", ".", "root", "=", "os", ".", "path", ".", "expanduser", "(", "root", ")", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "if", "train", ":", "\n", "            ", "self", ".", "base_folder", "=", "'train_coco.txt'", "\n", "", "elif", "database_bool", ":", "\n", "            ", "self", ".", "base_folder", "=", "'database_coco.txt'", "\n", "", "else", ":", "\n", "            ", "self", ".", "base_folder", "=", "'test_coco.txt'", "\n", "\n", "", "self", ".", "train_data", "=", "[", "]", "\n", "self", ".", "train_labels", "=", "[", "]", "\n", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ")", "\n", "# fo = open(file, 'rb')", "\n", "\n", "with", "open", "(", "filename", ",", "'r'", ")", "as", "file_to_read", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "lines", "=", "file_to_read", ".", "readline", "(", ")", "\n", "# print lines.split()", "\n", "if", "not", "lines", ":", "\n", "                    ", "break", "\n", "", "pos_tmp", "=", "lines", ".", "split", "(", ")", "[", "0", "]", "\n", "pos_tmp", "=", "pos_tmp", "[", "39", ":", "]", "\n", "# print pos_tmp", "\n", "pos_tmp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "pos_tmp", ")", "\n", "label_tmp", "=", "lines", ".", "split", "(", ")", "[", "1", ":", "]", "\n", "self", ".", "train_data", ".", "append", "(", "pos_tmp", ")", "\n", "self", ".", "train_labels", ".", "append", "(", "label_tmp", ")", "\n", "", "", "self", ".", "train_data", "=", "np", ".", "array", "(", "self", ".", "train_data", ")", "\n", "# self.train_labels.reshape()", "\n", "self", ".", "train_labels", "=", "np", ".", "array", "(", "self", ".", "train_labels", ",", "dtype", "=", "np", ".", "float", ")", "\n", "self", ".", "train_labels", ".", "reshape", "(", "(", "-", "1", ",", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.MScoco.__getitem__": [[87, 105], ["Mscoco.MScoco.loader", "Mscoco.MScoco.transform", "Mscoco.MScoco.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "\n", "img", ",", "target", "=", "self", ".", "train_data", "[", "index", "]", ",", "self", ".", "train_labels", "[", "index", "]", "\n", "img", "=", "self", ".", "loader", "(", "img", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.MScoco.__len__": [[106, 108], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "train_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.hash.forward": [[112, 124], ["U.sort", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "ctx.save_for_backward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "int", "int"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "U", ")", ":", "\n", "\n", "# Yunqiang for half and half (optimal transport)", "\n", "        ", "_", ",", "index", "=", "U", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "N", ",", "D", "=", "U", ".", "shape", "\n", "B_creat", "=", "torch", ".", "cat", "(", "(", "torch", ".", "ones", "(", "[", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ",", "-", "torch", ".", "ones", "(", "[", "N", "-", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "B", "=", "torch", ".", "zeros", "(", "U", ".", "shape", ")", ".", "cuda", "(", ")", ".", "scatter_", "(", "0", ",", "index", ",", "B_creat", ")", "\n", "\n", "ctx", ".", "save_for_backward", "(", "U", ",", "B", ")", "\n", "\n", "return", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.hash.backward": [[125, 133], ["B.numel"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "g", ")", ":", "\n", "        ", "U", ",", "B", "=", "ctx", ".", "saved_tensors", "\n", "add_g", "=", "(", "U", "-", "B", ")", "/", "(", "B", ".", "numel", "(", ")", ")", "\n", "\n", "grad", "=", "g", "+", "gamma", "*", "add_g", "\n", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.CNN.__init__": [[141, 149], ["torch.Module.__init__", "torchvision.models.vgg16", "torch.Sequential", "torch.Sequential", "torch.Sequential", "Mscoco.CNN.vgg.parameters", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.Linear", "torch.Linear", "torch.Linear", "list", "Mscoco.CNN.vgg.classifier.children"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encode_length", ")", ":", "\n", "        ", "super", "(", "CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vgg", "=", "torchvision", ".", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", "\n", "self", ".", "vgg", ".", "classifier", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "self", ".", "vgg", ".", "classifier", ".", "children", "(", ")", ")", "[", ":", "6", "]", ")", "\n", "for", "param", "in", "self", ".", "vgg", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "torch", ".", "manual_seed", "(", "0", ")", "\n", "self", ".", "fc_encode", "=", "nn", ".", "Linear", "(", "4096", ",", "encode_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.CNN.forward": [[150, 158], ["Mscoco.CNN.vgg.features", "Mscoco.CNN.view", "Mscoco.CNN.vgg.classifier", "Mscoco.CNN.fc_encode", "Mscoco.hash_layer", "Mscoco.CNN.size"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash_layer"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "vgg", ".", "features", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "vgg", ".", "classifier", "(", "x", ")", "\n", "h", "=", "self", ".", "fc_encode", "(", "x", ")", "\n", "b", "=", "hash_layer", "(", "h", ")", "\n", "\n", "return", "x", ",", "h", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.pil_loader": [[24, 29], ["open", "PIL.Image.open", "Image.open.convert"], "function", ["None"], ["def", "pil_loader", "(", "path", ")", ":", "\n", "# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)", "\n", "    ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "f", ")", "\n", "return", "img", ".", "convert", "(", "'RGB'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.accimage_loader": [[31, 38], ["accimage.Image", "Mscoco.pil_loader"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.pil_loader"], ["", "", "def", "accimage_loader", "(", "path", ")", ":", "\n", "    ", "import", "accimage", "\n", "try", ":", "\n", "        ", "return", "accimage", ".", "Image", "(", "path", ")", "\n", "", "except", "IOError", ":", "\n", "# Potentially a decoding problem, fall back to PIL.Image", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.default_loader": [[40, 46], ["get_image_backend", "Mscoco.accimage_loader", "Mscoco.pil_loader"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.accimage_loader", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.pil_loader"], ["", "", "def", "default_loader", "(", "path", ")", ":", "\n", "    ", "from", "torchvision", "import", "get_image_backend", "\n", "if", "get_image_backend", "(", ")", "==", "'accimage'", ":", "\n", "        ", "return", "accimage_loader", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "return", "pil_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.hash_layer": [[136, 138], ["hash.apply"], "function", ["None"], ["", "", "def", "hash_layer", "(", "input", ")", ":", "\n", "    ", "return", "hash", ".", "apply", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.adjust_learning_rate": [[160, 164], ["None"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "lr", "=", "learning_rate", "*", "(", "0.1", "**", "(", "epoch", "//", "epoch_lr_decrease", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Mscoco.main": [[166, 245], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "Mscoco.MScoco", "Mscoco.MScoco", "Mscoco.MScoco", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "Mscoco.CNN", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "range", "CNN.parameters", "CNN.cuda().train", "Mscoco.adjust_learning_rate", "enumerate", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.Scale", "torchvision.transforms.RandomCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Scale", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.autograd.Variable", "torch.autograd.Variable", "torch.optim.SGD.zero_grad", "CNN.", "torch.cosine_similarity", "torch.cosine_similarity", "torch.mse_loss", "F.mse_loss.backward", "torch.optim.SGD.step", "CNN.eval", "cal_map_mult.compress", "cal_map_mult.calculate_top_map", "print", "CNN.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda().long", "torch.autograd.Variable.cuda", "int", "int", "int", "int", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.adjust_learning_rate", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash.backward", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.compress", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_top_map"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "train_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "Scale", "(", "256", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "\n", "test_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Scale", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "\n", "# Dataset", "\n", "train_dataset", "=", "MScoco", "(", "root", "=", "'./data/Mscoco/'", ",", "\n", "train", "=", "True", ",", "\n", "transform", "=", "train_transform", ")", "\n", "\n", "test_dataset", "=", "MScoco", "(", "root", "=", "'./data/Mscoco/'", ",", "\n", "train", "=", "False", ",", "\n", "transform", "=", "test_transform", ")", "\n", "\n", "database_dataset", "=", "MScoco", "(", "root", "=", "'./data/Mscoco/'", ",", "\n", "train", "=", "False", ",", "\n", "transform", "=", "test_transform", ",", "\n", "database_bool", "=", "True", ")", "\n", "\n", "\n", "# Data Loader", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "train_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "4", ")", "\n", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "test_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "4", ")", "\n", "\n", "database_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "database_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "4", ")", "\n", "\n", "\n", "cnn", "=", "CNN", "(", "encode_length", "=", "encode_length", ")", "\n", "\n", "# Loss and Optimizer", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "cnn", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "5e-4", ")", "\n", "\n", "# Train the Model", "\n", "for", "epoch", "in", "range", "(", "num_epochs", ")", ":", "\n", "        ", "cnn", ".", "cuda", "(", ")", ".", "train", "(", ")", "\n", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", "\n", "for", "i", ",", "(", "images", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "images", "=", "Variable", "(", "images", ".", "cuda", "(", ")", ")", "\n", "labels", "=", "Variable", "(", "labels", ".", "cuda", "(", ")", ".", "long", "(", ")", ")", "\n", "\n", "# Forward + Backward + Optimize", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "x", ",", "_", ",", "b", "=", "cnn", "(", "images", ")", "\n", "\n", "target_b", "=", "F", ".", "cosine_similarity", "(", "b", "[", ":", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", "]", ",", "b", "[", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", ":", "]", ")", "\n", "target_x", "=", "F", ".", "cosine_similarity", "(", "x", "[", ":", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", "]", ",", "x", "[", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", ":", "]", ")", "\n", "loss", "=", "F", ".", "mse_loss", "(", "target_b", ",", "target_x", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "\n", "# Test the Model", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "10", "==", "0", ":", "\n", "            ", "cnn", ".", "eval", "(", ")", "\n", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "=", "compress", "(", "database_loader", ",", "test_loader", ",", "cnn", ",", "classes", "=", "num_classes", ")", "\n", "\n", "result_map", "=", "calculate_top_map", "(", "qB", "=", "queryB", ",", "rB", "=", "retrievalB", ",", "queryL", "=", "queryL", ",", "retrievalL", "=", "retrievalL", ",", "topk", "=", "5000", ")", "\n", "print", "(", "'--------mAP@5000: {}--------'", ".", "format", "(", "result_map", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Flickr25k.hash.forward": [[21, 33], ["U.sort", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "ctx.save_for_backward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "int", "int"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "U", ")", ":", "\n", "\n", "# Yunqiang for half and half (optimal transport)", "\n", "        ", "_", ",", "index", "=", "U", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "N", ",", "D", "=", "U", ".", "shape", "\n", "B_creat", "=", "torch", ".", "cat", "(", "(", "torch", ".", "ones", "(", "[", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ",", "-", "torch", ".", "ones", "(", "[", "N", "-", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "B", "=", "torch", ".", "zeros", "(", "U", ".", "shape", ")", ".", "cuda", "(", ")", ".", "scatter_", "(", "0", ",", "index", ",", "B_creat", ")", "\n", "\n", "ctx", ".", "save_for_backward", "(", "U", ",", "B", ")", "\n", "\n", "return", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Flickr25k.hash.backward": [[34, 42], ["B.numel"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "g", ")", ":", "\n", "        ", "U", ",", "B", "=", "ctx", ".", "saved_tensors", "\n", "add_g", "=", "(", "U", "-", "B", ")", "/", "(", "B", ".", "numel", "(", ")", ")", "\n", "\n", "grad", "=", "g", "+", "gamma", "*", "add_g", "\n", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Flickr25k.CNN.__init__": [[49, 57], ["torch.Module.__init__", "torchvision.models.vgg16", "torch.Sequential", "torch.Sequential", "torch.Sequential", "Flickr25k.CNN.vgg.parameters", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.Linear", "torch.Linear", "torch.Linear", "list", "Flickr25k.CNN.vgg.classifier.children"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encode_length", ")", ":", "\n", "        ", "super", "(", "CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vgg", "=", "torchvision", ".", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", "\n", "self", ".", "vgg", ".", "classifier", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "self", ".", "vgg", ".", "classifier", ".", "children", "(", ")", ")", "[", ":", "6", "]", ")", "\n", "for", "param", "in", "self", ".", "vgg", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "torch", ".", "manual_seed", "(", "0", ")", "\n", "self", ".", "fc_encode", "=", "nn", ".", "Linear", "(", "4096", ",", "encode_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Flickr25k.CNN.forward": [[58, 66], ["Flickr25k.CNN.vgg.features", "Flickr25k.CNN.view", "Flickr25k.CNN.vgg.classifier", "Flickr25k.CNN.fc_encode", "Flickr25k.hash_layer", "Flickr25k.CNN.size"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash_layer"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "vgg", ".", "features", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "vgg", ".", "classifier", "(", "x", ")", "\n", "h", "=", "self", ".", "fc_encode", "(", "x", ")", "\n", "b", "=", "hash_layer", "(", "h", ")", "\n", "\n", "return", "x", ",", "h", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Flickr25k.hash_layer": [[44, 46], ["hash.apply"], "function", ["None"], ["", "", "def", "hash_layer", "(", "input", ")", ":", "\n", "    ", "return", "hash", ".", "apply", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Flickr25k.adjust_learning_rate": [[68, 72], ["None"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "lr", "=", "learning_rate", "*", "(", "0.1", "**", "(", "epoch", "//", "epoch_lr_decrease", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Flickr25k.main": [[74, 113], ["data.load_data", "Flickr25k.CNN", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "range", "CNN.parameters", "CNN.cuda().train", "Flickr25k.adjust_learning_rate", "enumerate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.optim.SGD.zero_grad", "CNN.", "torch.cosine_similarity", "torch.cosine_similarity", "torch.mse_loss", "F.mse_loss.backward", "torch.optim.SGD.step", "CNN.eval", "cal_map_mult.compress", "cal_map_mult.calculate_map", "print", "CNN.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda().long", "torch.autograd.Variable.cuda", "int", "int", "int", "int", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.load_data", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.adjust_learning_rate", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash.backward", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.compress", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_map"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "test_loader", ",", "train_loader", ",", "database_loader", "=", "flickr25k", ".", "load_data", "(", "root", "=", "'/tudelft.net/staff-bulk/ewi/insy/VisionLab/yunqiangli/data/Flicker/flickr25k/'", ",", "\n", "num_query", "=", "2000", ",", "\n", "num_train", "=", "5000", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "4", ",", "\n", ")", "\n", "\n", "cnn", "=", "CNN", "(", "encode_length", "=", "encode_length", ")", "\n", "\n", "# Loss and Optimizer", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "cnn", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "5e-4", ")", "\n", "\n", "# Train the Model", "\n", "for", "epoch", "in", "range", "(", "num_epochs", ")", ":", "\n", "        ", "cnn", ".", "cuda", "(", ")", ".", "train", "(", ")", "\n", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", "\n", "for", "i", ",", "(", "images", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "images", "=", "Variable", "(", "images", ".", "cuda", "(", ")", ")", "\n", "labels", "=", "Variable", "(", "labels", ".", "cuda", "(", ")", ".", "long", "(", ")", ")", "\n", "\n", "# Forward + Backward + Optimize", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "x", ",", "_", ",", "b", "=", "cnn", "(", "images", ")", "\n", "\n", "target_b", "=", "F", ".", "cosine_similarity", "(", "b", "[", ":", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", "]", ",", "b", "[", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", ":", "]", ")", "\n", "target_x", "=", "F", ".", "cosine_similarity", "(", "x", "[", ":", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", "]", ",", "x", "[", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", ":", "]", ")", "\n", "loss", "=", "F", ".", "mse_loss", "(", "target_b", ",", "target_x", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "\n", "# Test the Model", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "10", "==", "0", ":", "\n", "            ", "cnn", ".", "eval", "(", ")", "\n", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "=", "compress", "(", "database_loader", ",", "test_loader", ",", "cnn", ",", "classes", "=", "num_classes", ")", "\n", "\n", "result_map", "=", "calculate_map", "(", "qB", "=", "queryB", ",", "rB", "=", "retrievalB", ",", "queryL", "=", "queryL", ",", "retrievalL", "=", "retrievalL", ")", "\n", "print", "(", "'--------mAP@All: {}--------'", ".", "format", "(", "result_map", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.compress": [[6, 35], ["list", "numpy.ones", "enumerate", "list", "numpy.ones", "enumerate", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "numpy.concatenate", "torch.autograd.Variable", "model", "torch.sign", "np.array.extend", "numpy.concatenate", "data.cuda", "torch.sign.cpu().data.numpy", "data.cuda", "torch.sign.cpu().data.numpy", "target.numpy", "target.numpy", "torch.sign.cpu", "torch.sign.cpu"], "function", ["None"], ["def", "compress", "(", "train", ",", "test", ",", "model", ",", "classes", "=", "80", ")", ":", "\n", "    ", "retrievalB", "=", "list", "(", "[", "]", ")", "\n", "retrievalL", "=", "np", ".", "ones", "(", "(", "1", ",", "classes", ")", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "train", ")", ":", "\n", "        ", "var_data", "=", "Variable", "(", "data", ".", "cuda", "(", ")", ")", "\n", "_", ",", "H", ",", "code", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "retrievalB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "retrievalL", "=", "np", ".", "concatenate", "(", "(", "retrievalL", ",", "target", ".", "numpy", "(", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "queryB", "=", "list", "(", "[", "]", ")", "\n", "queryL", "=", "np", ".", "ones", "(", "(", "1", ",", "classes", ")", ")", "\n", "for", "batch_step", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "test", ")", ":", "\n", "        ", "var_data", "=", "Variable", "(", "data", ".", "cuda", "(", ")", ")", "\n", "_", ",", "H", ",", "code", "=", "model", "(", "var_data", ")", "\n", "code", "=", "torch", ".", "sign", "(", "H", ")", "\n", "queryB", ".", "extend", "(", "code", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ")", "\n", "queryL", "=", "np", ".", "concatenate", "(", "(", "queryL", ",", "target", ".", "numpy", "(", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n", "\n", "", "retrievalB", "=", "np", ".", "array", "(", "retrievalB", ")", "\n", "retrievalL", "=", "retrievalL", "[", "1", ":", ",", ":", "]", "\n", "retrievalL", "=", "np", ".", "array", "(", "retrievalL", ")", "\n", "\n", "\n", "queryB", "=", "np", ".", "array", "(", "queryB", ")", "\n", "queryL", "=", "queryL", "[", "1", ":", ",", ":", "]", "\n", "queryL", "=", "np", ".", "array", "(", "queryL", ")", "\n", "return", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_hamming": [[37, 46], ["numpy.dot", "B2.transpose"], "function", ["None"], ["", "def", "calculate_hamming", "(", "B1", ",", "B2", ")", ":", "\n", "    ", "\"\"\"\n    :param B1:  vector [n]\n    :param B2:  vector [r*n]\n    :return: hamming distance [r]\n    \"\"\"", "\n", "q", "=", "B2", ".", "shape", "[", "1", "]", "# max inner product value", "\n", "distH", "=", "0.5", "*", "(", "q", "-", "np", ".", "dot", "(", "B1", ",", "B2", ".", "transpose", "(", ")", ")", ")", "\n", "return", "distH", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_map": [[48, 77], ["range", "numpy.sum", "cal_map_mult.calculate_hamming", "numpy.argsort", "numpy.linspace", "numpy.mean", "numpy.asarray", "numpy.where", "numpy.dot", "retrievalL.transpose"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_hamming"], ["", "def", "calculate_map", "(", "qB", ",", "rB", ",", "queryL", ",", "retrievalL", ")", ":", "\n", "    ", "\"\"\"\n       :param qB: {-1,+1}^{mxq} query bits\n       :param rB: {-1,+1}^{nxq} retrieval bits\n       :param queryL: {0,1}^{mxl} query label\n       :param retrievalL: {0,1}^{nxl} retrieval label\n       :return:\n    \"\"\"", "\n", "num_query", "=", "queryL", ".", "shape", "[", "0", "]", "\n", "map", "=", "0", "\n", "for", "iter", "in", "range", "(", "num_query", ")", ":", "\n", "# gnd : check if exists any retrieval items with same label", "\n", "        ", "gnd", "=", "(", "np", ".", "dot", "(", "queryL", "[", "iter", ",", ":", "]", ",", "retrievalL", ".", "transpose", "(", ")", ")", ">", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# tsum number of items with same label", "\n", "tsum", "=", "np", ".", "sum", "(", "gnd", ")", "\n", "if", "tsum", "==", "0", ":", "\n", "            ", "continue", "\n", "# sort gnd by hamming dist", "\n", "", "hamm", "=", "calculate_hamming", "(", "qB", "[", "iter", ",", ":", "]", ",", "rB", ")", "\n", "ind", "=", "np", ".", "argsort", "(", "hamm", ")", "\n", "gnd", "=", "gnd", "[", "ind", "]", "\n", "\n", "count", "=", "np", ".", "linspace", "(", "1", ",", "tsum", ",", "tsum", ")", "# [1,2, tsum]", "\n", "tindex", "=", "np", ".", "asarray", "(", "np", ".", "where", "(", "gnd", "==", "1", ")", ")", "+", "1.0", "\n", "map_", "=", "np", ".", "mean", "(", "count", "/", "(", "tindex", ")", ")", "\n", "# print(map_)", "\n", "map", "=", "map", "+", "map_", "\n", "", "map", "=", "map", "/", "num_query", "\n", "return", "map", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_top_map": [[79, 108], ["range", "cal_map_mult.calculate_hamming", "numpy.argsort", "numpy.sum", "numpy.linspace", "numpy.mean", "numpy.asarray", "numpy.where", "numpy.dot", "retrievalL.transpose"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_hamming"], ["", "def", "calculate_top_map", "(", "qB", ",", "rB", ",", "queryL", ",", "retrievalL", ",", "topk", ")", ":", "\n", "    ", "\"\"\"\n    :param qB: {-1,+1}^{mxq} query bits\n    :param rB: {-1,+1}^{nxq} retrieval bits\n    :param queryL: {0,1}^{mxl} query label\n    :param retrievalL: {0,1}^{nxl} retrieval label\n    :param topk:\n    :return:\n    \"\"\"", "\n", "num_query", "=", "queryL", ".", "shape", "[", "0", "]", "\n", "topkmap", "=", "0", "\n", "for", "iter", "in", "range", "(", "num_query", ")", ":", "\n", "        ", "gnd", "=", "(", "np", ".", "dot", "(", "queryL", "[", "iter", ",", ":", "]", ",", "retrievalL", ".", "transpose", "(", ")", ")", ">", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "hamm", "=", "calculate_hamming", "(", "qB", "[", "iter", ",", ":", "]", ",", "rB", ")", "\n", "ind", "=", "np", ".", "argsort", "(", "hamm", ")", "\n", "gnd", "=", "gnd", "[", "ind", "]", "\n", "\n", "tgnd", "=", "gnd", "[", "0", ":", "topk", "]", "\n", "tsum", "=", "np", ".", "sum", "(", "tgnd", ")", "\n", "if", "tsum", "==", "0", ":", "\n", "            ", "continue", "\n", "", "count", "=", "np", ".", "linspace", "(", "1", ",", "tsum", ",", "tsum", ")", "\n", "\n", "tindex", "=", "np", ".", "asarray", "(", "np", ".", "where", "(", "tgnd", "==", "1", ")", ")", "+", "1.0", "\n", "topkmap_", "=", "np", ".", "mean", "(", "count", "/", "(", "tindex", ")", ")", "\n", "# print(topkmap_)", "\n", "topkmap", "=", "topkmap", "+", "topkmap_", "\n", "", "topkmap", "=", "topkmap", "/", "num_query", "\n", "return", "topkmap", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_precision_recall_k": [[112, 161], ["numpy.arange", "numpy.zeros", "numpy.zeros", "range", "numpy.sum", "cal_map_mult.calculate_hamming", "numpy.argsort", "numpy.linspace", "numpy.mean", "numpy.cumsum", "numpy.sum", "sum", "numpy.cumsum", "gnd.sum", "numpy.asarray", "numpy.where", "numpy.dot", "retrievalL.transpose"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_hamming"], ["", "def", "calculate_precision_recall_k", "(", "qB", ",", "rB", ",", "queryL", ",", "retrievalL", ")", ":", "\n", "    ", "\"\"\"\n       :param qB: {-1,+1}^{mxq} query bits\n       :param rB: {-1,+1}^{nxq} retrieval bits\n       :param queryL: {0,1}^{mxl} query label\n       :param retrievalL: {0,1}^{nxl} retrieval label\n       :return:\n    \"\"\"", "\n", "num_query", "=", "queryL", ".", "shape", "[", "0", "]", "\n", "trainset_len", "=", "rB", ".", "shape", "[", "0", "]", "\n", "Ns", "=", "np", ".", "arange", "(", "1", ",", "trainset_len", "+", "1", ")", "\n", "sum_tp", "=", "np", ".", "zeros", "(", "trainset_len", ")", "\n", "AP", "=", "np", ".", "zeros", "(", "num_query", ")", "\n", "total_good_pairs", "=", "0", "\n", "\n", "map", "=", "0", "\n", "for", "iter", "in", "range", "(", "num_query", ")", ":", "\n", "# gnd : check if exists any retrieval items with same label", "\n", "        ", "gnd", "=", "(", "np", ".", "dot", "(", "queryL", "[", "iter", ",", ":", "]", ",", "retrievalL", ".", "transpose", "(", ")", ")", ">", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "# tsum number of items with same label", "\n", "tsum", "=", "np", ".", "sum", "(", "gnd", ")", "\n", "if", "tsum", "==", "0", ":", "\n", "            ", "continue", "\n", "# sort gnd by hamming dist", "\n", "", "hamm", "=", "calculate_hamming", "(", "qB", "[", "iter", ",", ":", "]", ",", "rB", ")", "\n", "ind", "=", "np", ".", "argsort", "(", "hamm", ")", "\n", "gnd", "=", "gnd", "[", "ind", "]", "\n", "\n", "# use another methods", "\n", "P", "=", "np", ".", "cumsum", "(", "gnd", ")", "/", "Ns", "\n", "AP", "[", "iter", "]", "=", "np", ".", "sum", "(", "P", "*", "gnd", ")", "/", "sum", "(", "gnd", ")", "\n", "sum_tp", "=", "sum_tp", "+", "np", ".", "cumsum", "(", "gnd", ")", "\n", "\n", "# recall total_good_pairs", "\n", "total_good_pairs", "=", "total_good_pairs", "+", "gnd", ".", "sum", "(", ")", "\n", "\n", "\n", "count", "=", "np", ".", "linspace", "(", "1", ",", "tsum", ",", "tsum", ")", "# [1,2, tsum]", "\n", "tindex", "=", "np", ".", "asarray", "(", "np", ".", "where", "(", "gnd", "==", "1", ")", ")", "+", "1.0", "\n", "map_", "=", "np", ".", "mean", "(", "count", "/", "(", "tindex", ")", ")", "\n", "# print(map_)", "\n", "map", "=", "map", "+", "map_", "\n", "", "map", "=", "map", "/", "num_query", "\n", "precision_at_k", "=", "sum_tp", "/", "Ns", "/", "num_query", "\n", "recall_at_k", "=", "sum_tp", "/", "total_good_pairs", "\n", "pre", "=", "precision_at_k", "[", ":", "10000", "]", "\n", "rec", "=", "recall_at_k", "[", ":", "10000", "]", "\n", "\n", "return", "pre", ",", "rec", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_p_r_curve": [[163, 182], ["cal_map_mult.calculate_hamming", "calculate_hamming.max", "Wtrue.sum", "numpy.zeros", "numpy.zeros", "range", "int", "Wtrue[].sum", "j.sum", "int", "int", "numpy.dot", "retrievalL.transpose"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_hamming"], ["", "def", "calculate_p_r_curve", "(", "qB", ",", "rB", ",", "queryL", ",", "retrievalL", ")", ":", "\n", "\n", "    ", "Wtrue", "=", "(", "np", ".", "dot", "(", "queryL", ",", "retrievalL", ".", "transpose", "(", ")", ")", ">", "0", ")", ".", "astype", "(", "np", ".", "float32", ")", "# 1000 *59000", "\n", "Dhat", "=", "calculate_hamming", "(", "qB", ",", "rB", ")", "\n", "max_hamm", "=", "Dhat", ".", "max", "(", ")", "\n", "total_good_pairs", "=", "Wtrue", ".", "sum", "(", ")", "\n", "\n", "precision", "=", "np", ".", "zeros", "(", "[", "int", "(", "max_hamm", ")", ",", "1", "]", ")", "\n", "recall", "=", "np", ".", "zeros", "(", "[", "int", "(", "max_hamm", ")", ",", "1", "]", ")", "\n", "for", "n", "in", "range", "(", "int", "(", "max_hamm", ")", ")", ":", "\n", "\n", "        ", "j", "=", "(", "Dhat", "<=", "(", "n", "+", "0.00001", ")", ")", "\n", "retrieved_good_pairs", "=", "Wtrue", "[", "j", "]", ".", "sum", "(", ")", "\n", "\n", "retrieved_pairs", "=", "j", ".", "sum", "(", ")", "\n", "precision", "[", "n", "]", "=", "retrieved_good_pairs", "/", "(", "retrieved_pairs", "+", "1e-24", ")", "\n", "recall", "[", "n", "]", "=", "retrieved_good_pairs", "/", "total_good_pairs", "\n", "\n", "", "return", "precision", ",", "recall", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.pr_curve": [[185, 223], ["torch.zeros", "torch.zeros", "range", "torch.sum", "tmp.sum", "t.sum", "torch.zeros.sum", "torch.zeros.sum", "retrieval_code.t", "torch.arange().reshape().float", "query_targets[].unsqueeze().mm", "torch.arange().reshape", "retrieval_targets.t", "query_targets[].unsqueeze", "torch.arange"], "function", ["None"], ["", "def", "pr_curve", "(", "query_code", ",", "retrieval_code", ",", "query_targets", ",", "retrieval_targets", ")", ":", "\n", "    ", "\"\"\"\n    P-R curve.\n    Args\n        query_code(torch.Tensor): Query hash code.\n        retrieval_code(torch.Tensor): Retrieval hash code.\n        query_targets(torch.Tensor): Query targets.\n        retrieval_targets(torch.Tensor): Retrieval targets.\n        device (torch.device): Using CPU or GPU.\n    Returns\n        P(torch.Tensor): Precision.\n        R(torch.Tensor): Recall.\n    \"\"\"", "\n", "num_query", "=", "query_code", ".", "shape", "[", "0", "]", "\n", "num_bit", "=", "query_code", ".", "shape", "[", "1", "]", "\n", "P", "=", "torch", ".", "zeros", "(", "num_query", ",", "num_bit", "+", "1", ")", "\n", "R", "=", "torch", ".", "zeros", "(", "num_query", ",", "num_bit", "+", "1", ")", "\n", "for", "i", "in", "range", "(", "num_query", ")", ":", "\n", "        ", "gnd", "=", "(", "query_targets", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ".", "mm", "(", "retrieval_targets", ".", "t", "(", ")", ")", ">", "0", ")", ".", "float", "(", ")", ".", "squeeze", "(", ")", "\n", "tsum", "=", "torch", ".", "sum", "(", "gnd", ")", "\n", "if", "tsum", "==", "0", ":", "\n", "            ", "continue", "\n", "", "hamm", "=", "0.5", "*", "(", "retrieval_code", ".", "shape", "[", "1", "]", "-", "query_code", "[", "i", ",", ":", "]", "@", "retrieval_code", ".", "t", "(", ")", ")", "\n", "tmp", "=", "(", "hamm", "<=", "torch", ".", "arange", "(", "0", ",", "num_bit", "+", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "float", "(", ")", ")", ".", "float", "(", ")", "\n", "total", "=", "tmp", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "total", "=", "total", "+", "(", "total", "==", "0", ")", ".", "float", "(", ")", "*", "0.1", "\n", "t", "=", "gnd", "*", "tmp", "\n", "count", "=", "t", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "p", "=", "count", "/", "total", "\n", "r", "=", "count", "/", "tsum", "\n", "P", "[", "i", "]", "=", "p", "\n", "R", "[", "i", "]", "=", "r", "\n", "", "mask", "=", "(", "P", ">", "0", ")", ".", "float", "(", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "mask", "=", "mask", "+", "(", "mask", "==", "0", ")", ".", "float", "(", ")", "*", "0.1", "\n", "P", "=", "P", ".", "sum", "(", "dim", "=", "0", ")", "/", "mask", "\n", "R", "=", "R", ".", "sum", "(", "dim", "=", "0", ")", "/", "mask", "\n", "\n", "return", "P", ",", "R", "\n", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash.forward": [[24, 36], ["U.sort", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.cat().cuda", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "torch.zeros().cuda().scatter_", "ctx.save_for_backward", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "int", "int"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "U", ")", ":", "\n", "\n", "# Yunqiang for half and half (optimal transport)", "\n", "        ", "_", ",", "index", "=", "U", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "N", ",", "D", "=", "U", ".", "shape", "\n", "B_creat", "=", "torch", ".", "cat", "(", "(", "torch", ".", "ones", "(", "[", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ",", "-", "torch", ".", "ones", "(", "[", "N", "-", "int", "(", "N", "/", "2", ")", ",", "D", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "B", "=", "torch", ".", "zeros", "(", "U", ".", "shape", ")", ".", "cuda", "(", ")", ".", "scatter_", "(", "0", ",", "index", ",", "B_creat", ")", "\n", "\n", "ctx", ".", "save_for_backward", "(", "U", ",", "B", ")", "\n", "\n", "return", "B", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash.backward": [[37, 45], ["B.numel"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "g", ")", ":", "\n", "        ", "U", ",", "B", "=", "ctx", ".", "saved_tensors", "\n", "add_g", "=", "(", "U", "-", "B", ")", "/", "(", "B", ".", "numel", "(", ")", ")", "\n", "\n", "grad", "=", "g", "+", "gamma", "*", "add_g", "\n", "\n", "return", "grad", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.CNN.__init__": [[52, 60], ["torch.Module.__init__", "torchvision.models.vgg16", "torchvision.models.vgg16", "torchvision.models.vgg16", "torchvision.models.vgg16", "torch.Sequential", "torch.Sequential", "torch.Sequential", "Cifar10_I.CNN.vgg.parameters", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.Linear", "torch.Linear", "torch.Linear", "list", "Cifar10_I.CNN.vgg.classifier.children"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encode_length", ")", ":", "\n", "        ", "super", "(", "CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vgg", "=", "torchvision", ".", "models", ".", "vgg16", "(", "pretrained", "=", "True", ")", "\n", "self", ".", "vgg", ".", "classifier", "=", "nn", ".", "Sequential", "(", "*", "list", "(", "self", ".", "vgg", ".", "classifier", ".", "children", "(", ")", ")", "[", ":", "6", "]", ")", "\n", "for", "param", "in", "self", ".", "vgg", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "torch", ".", "manual_seed", "(", "0", ")", "\n", "self", ".", "fc_encode", "=", "nn", ".", "Linear", "(", "4096", ",", "encode_length", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.CNN.forward": [[62, 70], ["Cifar10_I.CNN.vgg.features", "Cifar10_I.CNN.view", "Cifar10_I.CNN.vgg.classifier", "Cifar10_I.CNN.fc_encode", "Cifar10_I.hash_layer", "Cifar10_I.CNN.size"], "methods", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash_layer"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "vgg", ".", "features", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "vgg", ".", "classifier", "(", "x", ")", "\n", "h", "=", "self", ".", "fc_encode", "(", "x", ")", "\n", "b", "=", "hash_layer", "(", "h", ")", "\n", "\n", "return", "x", ",", "h", ",", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash_layer": [[47, 49], ["hash.apply"], "function", ["None"], ["", "", "def", "hash_layer", "(", "input", ")", ":", "\n", "    ", "return", "hash", ".", "apply", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.adjust_learning_rate": [[71, 75], ["None"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "lr", "=", "learning_rate", "*", "(", "0.1", "**", "(", "epoch", "//", "epoch_lr_decrease", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.main": [[76, 210], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.CIFAR10", "torchvision.CIFAR10", "torchvision.CIFAR10", "numpy.array", "numpy.concatenate", "numpy.concatenate", "range", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "Cifar10_I.CNN", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "range", "numpy.random.seed", "numpy.random.permutation", "np.concatenate.astype", "np.concatenate.astype", "np.concatenate.astype", "CNN.fc_encode.parameters", "CNN.cuda().train", "Cifar10_I.adjust_learning_rate", "enumerate", "torchvision.transforms.Scale", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Scale", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "numpy.array", "numpy.where", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.optim.SGD.zero_grad", "CNN.", "torch.cosine_similarity", "torch.cosine_similarity", "torch.mse_loss", "F.mse_loss.backward", "torch.optim.SGD.step", "CNN.eval", "cal_map_single.compress", "cal_map_single.calculate_top_map", "print", "CNN.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda().long", "torch.autograd.Variable.cuda", "int", "int", "int", "int", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "torch.autograd.Variable.size"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.adjust_learning_rate", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.Cifar10_I.hash.backward", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.compress", "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.ImageHashing.cal_map_mult.calculate_top_map"], ["", "", "def", "main", "(", ")", ":", "\n", "\n", "\n", "\n", "    ", "train_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Scale", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "\n", "test_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Scale", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "]", ")", "\n", "\n", "# Dataset", "\n", "train_dataset", "=", "dsets", ".", "CIFAR10", "(", "root", "=", "'./data/Cifar/'", ",", "\n", "train", "=", "True", ",", "\n", "transform", "=", "train_transform", ",", "\n", "download", "=", "True", ")", "\n", "\n", "test_dataset", "=", "dsets", ".", "CIFAR10", "(", "root", "=", "'./data/Cifar/'", ",", "\n", "train", "=", "False", ",", "\n", "transform", "=", "test_transform", ")", "\n", "\n", "database_dataset", "=", "dsets", ".", "CIFAR10", "(", "root", "=", "'./data/Cifar/'", ",", "\n", "train", "=", "False", ",", "\n", "transform", "=", "test_transform", ")", "\n", "\n", "\n", "# Re-Construct training, query and database set", "\n", "X", "=", "train_dataset", ".", "data", "\n", "L", "=", "np", ".", "array", "(", "train_dataset", ".", "targets", ")", "\n", "\n", "X", "=", "np", ".", "concatenate", "(", "(", "X", ",", "test_dataset", ".", "data", ")", ")", "\n", "L", "=", "np", ".", "concatenate", "(", "(", "L", ",", "np", ".", "array", "(", "test_dataset", ".", "targets", ")", ")", ")", "\n", "\n", "first", "=", "True", "\n", "\n", "\n", "for", "label", "in", "range", "(", "10", ")", ":", "\n", "        ", "index", "=", "np", ".", "where", "(", "L", "==", "label", ")", "[", "0", "]", "\n", "\n", "N", "=", "index", ".", "shape", "[", "0", "]", "\n", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "perm", "=", "np", ".", "random", ".", "permutation", "(", "N", ")", "\n", "index", "=", "index", "[", "perm", "]", "\n", "\n", "data", "=", "X", "[", "index", "[", "0", ":", "1000", "]", "]", "\n", "labels", "=", "L", "[", "index", "[", "0", ":", "1000", "]", "]", "\n", "if", "first", ":", "\n", "            ", "test_L", "=", "labels", "\n", "test_data", "=", "data", "\n", "", "else", ":", "\n", "            ", "test_L", "=", "np", ".", "concatenate", "(", "(", "test_L", ",", "labels", ")", ")", "\n", "test_data", "=", "np", ".", "concatenate", "(", "(", "test_data", ",", "data", ")", ")", "\n", "\n", "", "data", "=", "X", "[", "index", "[", "1000", ":", "6000", "]", "]", "\n", "labels", "=", "L", "[", "index", "[", "1000", ":", "6000", "]", "]", "\n", "if", "first", ":", "\n", "            ", "dataset_L", "=", "labels", "\n", "data_set", "=", "data", "\n", "", "else", ":", "\n", "            ", "dataset_L", "=", "np", ".", "concatenate", "(", "(", "dataset_L", ",", "labels", ")", ")", "\n", "data_set", "=", "np", ".", "concatenate", "(", "(", "data_set", ",", "data", ")", ")", "\n", "\n", "", "data", "=", "X", "[", "index", "[", "1000", ":", "6000", "]", "]", "\n", "labels", "=", "L", "[", "index", "[", "1000", ":", "6000", "]", "]", "\n", "if", "first", ":", "\n", "            ", "train_L", "=", "labels", "\n", "train_data", "=", "data", "\n", "", "else", ":", "\n", "            ", "train_L", "=", "np", ".", "concatenate", "(", "(", "train_L", ",", "labels", ")", ")", "\n", "train_data", "=", "np", ".", "concatenate", "(", "(", "train_data", ",", "data", ")", ")", "\n", "\n", "", "first", "=", "False", "\n", "\n", "train_dataset", ".", "data", "=", "train_data", "\n", "train_dataset", ".", "targets", "=", "train_L", ".", "astype", "(", "np", ".", "long", ")", "\n", "test_dataset", ".", "data", "=", "test_data", "\n", "test_dataset", ".", "targets", "=", "(", "test_L", ")", ".", "astype", "(", "np", ".", "long", ")", "\n", "database_dataset", ".", "data", "=", "data_set", "\n", "database_dataset", ".", "targets", "=", "(", "dataset_L", ")", ".", "astype", "(", "np", ".", "long", ")", "\n", "\n", "# Data Loader", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "train_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "4", ")", "\n", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "test_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "4", ")", "\n", "\n", "database_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "database_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "4", ")", "\n", "\n", "\n", "\n", "cnn", "=", "CNN", "(", "encode_length", "=", "encode_length", ")", "\n", "\n", "\n", "# Loss and Optimizer", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "cnn", ".", "fc_encode", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "5e-4", ")", "\n", "\n", "\n", "# Train the Model", "\n", "for", "epoch", "in", "range", "(", "num_epochs", ")", ":", "\n", "        ", "cnn", ".", "cuda", "(", ")", ".", "train", "(", ")", "\n", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ")", "\n", "for", "i", ",", "(", "images", ",", "labels", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "images", "=", "Variable", "(", "images", ".", "cuda", "(", ")", ")", "\n", "labels", "=", "Variable", "(", "labels", ".", "cuda", "(", ")", ".", "long", "(", ")", ")", "\n", "\n", "# Forward + Backward + Optimize", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "x", ",", "_", ",", "b", "=", "cnn", "(", "images", ")", "\n", "\n", "target_b", "=", "F", ".", "cosine_similarity", "(", "b", "[", ":", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", "]", ",", "b", "[", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", ":", "]", ")", "\n", "target_x", "=", "F", ".", "cosine_similarity", "(", "x", "[", ":", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", "]", ",", "x", "[", "int", "(", "labels", ".", "size", "(", "0", ")", "/", "2", ")", ":", "]", ")", "\n", "loss", "=", "F", ".", "mse_loss", "(", "target_b", ",", "target_x", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Test the Model", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "10", "==", "0", ":", "\n", "            ", "cnn", ".", "eval", "(", ")", "\n", "retrievalB", ",", "retrievalL", ",", "queryB", ",", "queryL", "=", "compress", "(", "database_loader", ",", "test_loader", ",", "cnn", ")", "\n", "result_map", "=", "calculate_top_map", "(", "qB", "=", "queryB", ",", "rB", "=", "retrievalB", ",", "queryL", "=", "queryL", ",", "retrievalL", "=", "retrievalL", ",", "topk", "=", "1000", ")", "\n", "print", "(", "'--------mAP@1000: {}--------'", ".", "format", "(", "result_map", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__init__": [[66, 81], ["ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "root", ",", "mode", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "if", "mode", "==", "'train'", ":", "\n", "            ", "self", ".", "data", "=", "Flickr25k", ".", "TRAIN_DATA", "\n", "self", ".", "targets", "=", "Flickr25k", ".", "TRAIN_TARGETS", "\n", "", "elif", "mode", "==", "'query'", ":", "\n", "            ", "self", ".", "data", "=", "Flickr25k", ".", "QUERY_DATA", "\n", "self", ".", "targets", "=", "Flickr25k", ".", "QUERY_TARGETS", "\n", "", "elif", "mode", "==", "'retrieval'", ":", "\n", "            ", "self", ".", "data", "=", "Flickr25k", ".", "RETRIEVAL_DATA", "\n", "self", ".", "targets", "=", "Flickr25k", ".", "RETRIEVAL_TARGETS", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "r'Invalid arguments: mode, can\\'t load dataset!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__getitem__": [[82, 87], ["PIL.Image.open().convert", "flickr25k.Flickr25k.transform", "PIL.Image.open", "os.path.join"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'images'", ",", "self", ".", "data", "[", "index", "]", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "return", "img", ",", "self", ".", "targets", "[", "index", "]", ",", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.__len__": [[88, 90], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "data", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.get_targets": [[91, 93], ["torch.FloatTensor"], "methods", ["None"], ["", "def", "get_targets", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "FloatTensor", "(", "self", ".", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.init": [[94, 127], ["os.path.join", "os.path.join", "numpy.loadtxt", "numpy.random.permutation", "open", "numpy.array", "i.strip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "init", "(", "root", ",", "num_query", ",", "num_train", ")", ":", "\n", "        ", "\"\"\"\n        Initialize dataset\n\n        Args\n            root(str): Path of image files.\n            num_query(int): Number of query data.\n            num_train(int): Number of training data.\n        \"\"\"", "\n", "# Load dataset", "\n", "img_txt_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'img.txt'", ")", "\n", "targets_txt_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'targets.txt'", ")", "\n", "\n", "# Read files", "\n", "with", "open", "(", "img_txt_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "data", "=", "np", ".", "array", "(", "[", "i", ".", "strip", "(", ")", "for", "i", "in", "f", "]", ")", "\n", "", "targets", "=", "np", ".", "loadtxt", "(", "targets_txt_path", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "\n", "# Split dataset", "\n", "perm_index", "=", "np", ".", "random", ".", "permutation", "(", "data", ".", "shape", "[", "0", "]", ")", "\n", "query_index", "=", "perm_index", "[", ":", "num_query", "]", "\n", "train_index", "=", "perm_index", "[", "num_query", ":", "num_query", "+", "num_train", "]", "\n", "retrieval_index", "=", "perm_index", "[", "num_query", ":", "]", "\n", "\n", "Flickr25k", ".", "QUERY_DATA", "=", "data", "[", "query_index", "]", "\n", "Flickr25k", ".", "QUERY_TARGETS", "=", "targets", "[", "query_index", ",", ":", "]", "\n", "\n", "Flickr25k", ".", "TRAIN_DATA", "=", "data", "[", "train_index", "]", "\n", "Flickr25k", ".", "TRAIN_TARGETS", "=", "targets", "[", "train_index", ",", ":", "]", "\n", "\n", "Flickr25k", ".", "RETRIEVAL_DATA", "=", "data", "[", "retrieval_index", "]", "\n", "Flickr25k", ".", "RETRIEVAL_TARGETS", "=", "targets", "[", "retrieval_index", ",", ":", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.load_data": [[14, 55], ["flickr25k.Flickr25k.init", "flickr25k.Flickr25k", "flickr25k.Flickr25k", "flickr25k.Flickr25k", "torch.utils.data.dataloader.DataLoader", "torch.utils.data.dataloader.DataLoader", "torch.utils.data.dataloader.DataLoader", "data.transform.query_transform", "data.transform.train_transform", "data.transform.query_transform"], "function", ["home.repos.pwc.inspect_result.liyunqianggyn_Deep-Unsupervised-Image-Hashing.data.flickr25k.Flickr25k.init"], ["def", "load_data", "(", "root", ",", "num_query", ",", "num_train", ",", "batch_size", ",", "num_workers", ")", ":", "\n", "    ", "\"\"\"\n    Loading nus-wide dataset.\n\n    Args:\n        root(str): Path of image files.\n        num_query(int): Number of query data.\n        num_train(int): Number of training data.\n        batch_size(int): Batch size.\n        num_workers(int): Number of loading data threads.\n\n    Returns\n        query_dataloader, train_dataloader, retrieval_dataloader (torch.evaluate.data.DataLoader): Data loader.\n    \"\"\"", "\n", "\n", "Flickr25k", ".", "init", "(", "root", ",", "num_query", ",", "num_train", ")", "\n", "query_dataset", "=", "Flickr25k", "(", "root", ",", "'query'", ",", "query_transform", "(", ")", ")", "\n", "train_dataset", "=", "Flickr25k", "(", "root", ",", "'train'", ",", "train_transform", "(", ")", ")", "\n", "retrieval_dataset", "=", "Flickr25k", "(", "root", ",", "'retrieval'", ",", "query_transform", "(", ")", ")", "\n", "\n", "query_dataloader", "=", "DataLoader", "(", "\n", "query_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "pin_memory", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "pin_memory", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", ")", "\n", "retrieval_dataloader", "=", "DataLoader", "(", "\n", "retrieval_dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "pin_memory", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", ")", "\n", "\n", "return", "query_dataloader", ",", "train_dataloader", ",", "retrieval_dataloader", "\n", "\n"]]}