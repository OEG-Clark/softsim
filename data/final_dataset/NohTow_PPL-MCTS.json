{"home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.classifier_emotion_training.TextDataset.__init__": [[16, 18], ["pandas.read_csv"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "set_name", ")", ":", "\n", "        ", "self", ".", "file", "=", "pd", ".", "read_csv", "(", "path", "+", "\"/\"", "+", "set_name", "+", "\".tsv\"", ",", "delimiter", "=", "'\\t'", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.classifier_emotion_training.TextDataset.__len__": [[18, 20], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "file", ")", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.classifier_emotion_training.TextDataset.__getitem__": [[20, 23], ["str"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "item", "=", "self", ".", "file", ".", "iloc", "[", "idx", "]", "\n", "return", "\"<|startoftext|> \"", "+", "str", "(", "item", "[", "\"text\"", "]", ")", "+", "\"<|endoftext|>\"", ",", "item", "[", "\"label\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.classifier_emotion_training.Net.__init__": [[28, 34], ["torch.Module.__init__", "transformers.BertModel.from_pretrained", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "'bert-base-cased'", ",", "output_hidden_states", "=", "True", ")", "\n", "self", ".", "fc_txt1", "=", "nn", ".", "Linear", "(", "768", ",", "512", ")", "\n", "self", ".", "fc_txt2", "=", "nn", ".", "Linear", "(", "512", ",", "256", ")", "\n", "self", ".", "fc_classif", "=", "nn", ".", "Linear", "(", "256", ",", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.classifier_emotion_training.Net.forward": [[37, 47], ["tokenizer.batch_encode_plus", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "classifier_emotion_training.Net.bert", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "classifier_emotion_training.Net.fc_classif", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "classifier_emotion_training.Net.fc_txt1", "classifier_emotion_training.Net.fc_txt2", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "texts", ")", ":", "\n", "        ", "tokenizer_res", "=", "tokenizer", ".", "batch_encode_plus", "(", "texts", ",", "truncation", "=", "True", ",", "max_length", "=", "512", ",", "padding", "=", "'longest'", ")", "\n", "tokens_tensor", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "tokenizer_res", "[", "'input_ids'", "]", ")", "\n", "attention_tensor", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "tokenizer_res", "[", "'attention_mask'", "]", ")", "\n", "output", "=", "self", ".", "bert", "(", "tokens_tensor", ",", "attention_mask", "=", "attention_tensor", ")", "\n", "text", "=", "F", ".", "normalize", "(", "torch", ".", "div", "(", "torch", ".", "sum", "(", "output", "[", "2", "]", "[", "-", "1", "]", ",", "axis", "=", "1", ")", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "sum", "(", "attention_tensor", ",", "axis", "=", "1", ")", ",", "1", ")", ")", ")", "\n", "text", "=", "F", ".", "relu", "(", "self", ".", "fc_txt1", "(", "text", ")", ")", "\n", "text", "=", "F", ".", "relu", "(", "self", ".", "fc_txt2", "(", "text", ")", ")", "\n", "text", "=", "self", ".", "fc_classif", "(", "text", ")", "\n", "return", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "text", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.Net.__init__": [[88, 94], ["torch.Module.__init__", "transformers.FlaubertModel.from_pretrained", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "flaubert", "=", "FlaubertModel", ".", "from_pretrained", "(", "'flaubert/flaubert_large_cased'", ",", "output_hidden_states", "=", "True", ")", "\n", "# self.fc_txt1 = nn.Linear(1024, 512)", "\n", "# self.fc_txt2 = nn.Linear(512, 256)", "\n", "self", ".", "fc_classif", "=", "nn", ".", "Linear", "(", "1024", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.Net.forward": [[97, 107], ["tokenizer.batch_encode_plus", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "mcts_rollout.Net.flaubert", "torch.normalize", "torch.normalize", "torch.normalize", "mcts_rollout.Net.fc_classif", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "texts", ")", ":", "\n", "        ", "tokenizer_res", "=", "tokenizer", ".", "batch_encode_plus", "(", "texts", ",", "truncation", "=", "True", ",", "max_length", "=", "512", ",", "padding", "=", "'longest'", ")", "\n", "tokens_tensor", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "tokenizer_res", "[", "'input_ids'", "]", ")", "\n", "attention_tensor", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "tokenizer_res", "[", "'attention_mask'", "]", ")", "\n", "output", "=", "self", ".", "flaubert", "(", "tokens_tensor", ",", "attention_mask", "=", "attention_tensor", ")", "\n", "text", "=", "F", ".", "normalize", "(", "torch", ".", "div", "(", "torch", ".", "sum", "(", "output", "[", "1", "]", "[", "-", "1", "]", ",", "axis", "=", "1", ")", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "sum", "(", "attention_tensor", ",", "axis", "=", "1", ")", ",", "1", ")", ")", ")", "\n", "# text = F.relu(self.fc_txt1(text))", "\n", "# text = F.relu(self.fc_txt2(text))", "\n", "text", "=", "self", ".", "fc_classif", "(", "text", ")", "\n", "return", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "text", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.__init__": [[273, 326], ["min", "numpy.zeros", "numpy.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.arange", "mcts_rollout.BatchedMCTS._reset_tree", "transformers.RepetitionPenaltyLogitsProcessor"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree"], ["    ", "def", "__init__", "(", "self", ",", "root_fun", ",", "rec_fun", ",", "batch_size", ",", "num_simulations", ",", "num_actions", ",", "num_sparse_actions", ",", "pb_c_init", ",", "temperature", ",", "alpha", ",", "penalty", ",", "rollout_size", ")", ":", "\n", "# Initialize parameters", "\n", "        ", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_num_simulations", "=", "num_simulations", "\n", "self", ".", "_num_actions", "=", "num_actions", "\n", "self", ".", "_num_sparse_actions", "=", "min", "(", "num_sparse_actions", ",", "num_actions", ")", "\n", "self", ".", "_pb_c_init", "=", "pb_c_init", "\n", "self", ".", "_temperature", "=", "temperature", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "rollout_size", "=", "rollout_size", "\n", "\n", "self", ".", "_root_fun", "=", "root_fun", "# a function called at the root", "\n", "self", ".", "_rec_fun", "=", "rec_fun", "# a function called in the tree", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_labels", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "args", ".", "device", ")", "\n", "\n", "# Allocate all necessary storage.", "\n", "# For a given search associated to a batch-index, node i is the i-th node", "\n", "# to be expanded. Node 0 corresponds to the root node.", "\n", "num_nodes", "=", "num_simulations", "+", "1", "\n", "batch_node", "=", "(", "batch_size", ",", "num_nodes", ")", "\n", "self", ".", "_num_nodes", "=", "num_nodes", "\n", "self", ".", "_visit_counts", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_likelihoods", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_raw_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# action_from_parents[b, i] is the action taken to reach node i.", "\n", "# Note that action_from_parents[b, 0] will remain -1, as we do not know,", "\n", "# when doing search from the root, what action led to the root.", "\n", "self", ".", "_action_from_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# The 0-indexed depth of the node. The root is the only 0-depth node.", "\n", "# The depth of node i, is the depth of its parent + 1.", "\n", "self", ".", "_depth", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_is_terminal", "=", "np", ".", "full", "(", "batch_node", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "\n", "# To avoid costly numpy ops, we store a sparse version of the actions.", "\n", "# We select the top k actions according to the policy, and keep a mapping", "\n", "# of indices from 0 to k-1 to the actual action indices in the", "\n", "# self._topk_mapping tensor.", "\n", "batch_node_action", "=", "(", "batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ")", "\n", "self", ".", "_topk_mapping", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_index", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_prior", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_values", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_visits", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_states", "=", "{", "}", "\n", "self", ".", "_token_ids", "=", "{", "}", "\n", "self", ".", "_attention_mask", "=", "{", "}", "\n", "self", ".", "_batch_range", "=", "np", ".", "arange", "(", "batch_size", ")", "\n", "self", ".", "_reset_tree", "(", ")", "\n", "self", ".", "_repetition_penalty", "=", "RepetitionPenaltyLogitsProcessor", "(", "penalty", "=", "penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS._reset_tree": [[327, 344], ["mcts_rollout.BatchedMCTS._visit_counts.fill", "mcts_rollout.BatchedMCTS._values.fill", "mcts_rollout.BatchedMCTS._likelihoods.fill", "mcts_rollout.BatchedMCTS._parents.fill", "mcts_rollout.BatchedMCTS._action_from_parents.fill", "mcts_rollout.BatchedMCTS._depth.fill", "mcts_rollout.BatchedMCTS._topk_mapping.fill", "mcts_rollout.BatchedMCTS._children_index.fill", "mcts_rollout.BatchedMCTS._children_prior.fill", "mcts_rollout.BatchedMCTS._children_values.fill", "mcts_rollout.BatchedMCTS._children_visits.fill"], "methods", ["None"], ["", "def", "_reset_tree", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the tree arrays.\"\"\"", "\n", "self", ".", "_visit_counts", ".", "fill", "(", "0", ")", "\n", "self", ".", "_values", ".", "fill", "(", "0", ")", "\n", "self", ".", "_likelihoods", ".", "fill", "(", "0", ")", "\n", "self", ".", "_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_action_from_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_depth", ".", "fill", "(", "0", ")", "\n", "\n", "self", ".", "_topk_mapping", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_index", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_prior", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_values", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_visits", ".", "fill", "(", "0", ")", "\n", "self", ".", "_states", "=", "{", "}", "\n", "self", ".", "_token_ids", "=", "{", "}", "# Indexed by tuples (batch index, node index)", "\n", "self", ".", "_attention_mask", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.set_labels": [[345, 347], ["None"], "methods", ["None"], ["", "def", "set_labels", "(", "self", ",", "labels", ")", ":", "\n", "        ", "self", ".", "_labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.search": [[348, 375], ["mcts_rollout.BatchedMCTS._reset_tree", "mcts_rollout.BatchedMCTS._root_fun", "mcts_rollout.BatchedMCTS.create_node", "numpy.zeros", "range", "mcts_rollout.BatchedMCTS.dense_visit_counts", "numpy.full", "mcts_rollout.BatchedMCTS.simulate", "mcts_rollout.BatchedMCTS.expand", "numpy.zeros.fill", "mcts_rollout.BatchedMCTS.backward"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.dense_visit_counts", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.simulate", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.backward"], ["", "def", "search", "(", "self", ",", "original_input", ")", ":", "\n", "        ", "self", ".", "_reset_tree", "(", ")", "\n", "\n", "# Evaluate the root.", "\n", "prior", ",", "values", ",", "states", "=", "self", ".", "_root_fun", "(", "original_input", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ")", "\n", "\n", "\n", "self", ".", "_adaptive_min_values", "=", "values", "\n", "self", ".", "_adaptive_max_values", "=", "values", "+", "1e-6", "\n", "\n", "root_index", "=", "0", "\n", "self", ".", "create_node", "(", "root_index", ",", "prior", ",", "1", ",", "values", ",", "states", ",", "original_input", ".", "input_ids", ",", "original_input", ".", "attention_mask", ",", "np", ".", "full", "(", "self", ".", "_batch_size", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", ")", "\n", "\n", "\n", "\n", "\n", "# Do simulations, expansions, and backwards.", "\n", "leaf_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "for", "sim", "in", "range", "(", "self", ".", "_num_simulations", ")", ":", "\n", "            ", "node_indices", ",", "actions", "=", "self", ".", "simulate", "(", ")", "\n", "next_node_index", "=", "sim", "+", "1", "# root is 0, therefore we offset by 1.", "\n", "self", ".", "expand", "(", "node_indices", ",", "actions", ",", "next_node_index", ")", "\n", "leaf_indices", ".", "fill", "(", "next_node_index", ")", "\n", "self", ".", "backward", "(", "leaf_indices", ")", "\n", "\n", "# Final choice: most visited, max score, max mean score", "\n", "", "return", "self", ".", "dense_visit_counts", "(", ")", "\n", "# return self.dense_scores()", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.dense_visit_counts": [[378, 384], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_visit_counts", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_visit_counts", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_visit_counts", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_visit_counts", "\n", "return", "dense_visit_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.dense_scores": [[385, 392], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_root_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_root_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_scores", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "return", "dense_root_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.dense_mean_scores": [[393, 401], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_mean_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_mean_scores", "=", "root_scores", "/", "root_visit_counts", "\n", "dense_mean_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_mean_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_mean_scores", "\n", "return", "dense_mean_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.simulate": [[402, 415], ["numpy.zeros", "mcts_rollout.BatchedMCTS.uct_select_action", "is_unexplored.all", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.uct_select_action"], ["", "def", "simulate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Goes down until all elements have reached unexplored actions.\"\"\"", "\n", "node_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "depth", "=", "0", "\n", "while", "True", ":", "\n", "            ", "depth", "+=", "1", "\n", "actions", "=", "self", ".", "uct_select_action", "(", "node_indices", ")", "\n", "next_node_indices", "=", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "is_unexplored", "=", "next_node_indices", "==", "-", "1", "\n", "if", "is_unexplored", ".", "all", "(", ")", ":", "\n", "                ", "return", "node_indices", ",", "actions", "\n", "", "else", ":", "\n", "                ", "node_indices", "=", "np", ".", "where", "(", "is_unexplored", ",", "node_indices", ",", "next_node_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.uct_select_action": [[416, 432], ["numpy.argmax", "numpy.sqrt"], "methods", ["None"], ["", "", "", "def", "uct_select_action", "(", "self", ",", "node_indices", ")", ":", "\n", "        ", "\"\"\"Returns the action selected for a batch of node indices of shape (B).\"\"\"", "\n", "node_children_prior", "=", "self", ".", "_children_prior", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_values", "=", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_visits", "=", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_visits", "=", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "# (B)", "\n", "node_policy_score", "=", "np", ".", "sqrt", "(", "node_visits", "[", ":", ",", "None", "]", ")", "*", "self", ".", "_pb_c_init", "*", "node_children_prior", "/", "(", "node_children_visits", "+", "1", ")", "# (B, A)", "\n", "\n", "# Remap values between 0 and 1.", "\n", "node_value_score", "=", "node_children_values", "\n", "# node_value_score = (node_value_score != 0.) * node_value_score + (node_value_score == 0.) * self._adaptive_min_values[:, None]", "\n", "# node_value_score = (node_value_score - self._adaptive_min_values[:, None]) / (self._adaptive_max_values[:, None] - self._adaptive_min_values[:, None])", "\n", "\n", "node_uct_score", "=", "node_value_score", "+", "node_policy_score", "# (B, A)", "\n", "actions", "=", "np", ".", "argmax", "(", "node_uct_score", ",", "axis", "=", "1", ")", "\n", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.get_states_from_node": [[433, 444], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "get_states_from_node", "(", "self", ",", "b", ",", "n", ",", "d", ")", ":", "\n", "        ", "\"\"\"Forge state tensor by going backward from the node to the root (because we only store on token's part on each node to avoid duplication)\"\"\"", "\n", "state_array", "=", "[", "None", "]", "*", "d", "\n", "state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_states", "[", "(", "b", ",", "n", ")", "]", "\n", "while", "n", "!=", "0", ":", "\n", "            ", "n", "=", "self", ".", "_parents", "[", "(", "b", ",", "n", ")", "]", "\n", "d", "-=", "1", "\n", "state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_states", "[", "(", "b", ",", "n", ")", "]", "\n", "\n", "", "result", "=", "torch", ".", "cat", "(", "state_array", ",", "3", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.expand": [[445, 485], ["mcts_rollout.pad_sequences_to_left", "mcts_rollout.pad_sequences_to_left", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.array", "numpy.array", "mcts_rollout.pad_sequences_to_left_states", "tuple", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mcts_rollout.BatchedMCTS._rec_fun", "mcts_rollout.BatchedMCTS.create_node", "numpy.minimum", "numpy.maximum", "mcts_rollout.BatchedMCTS.get_states_from_node", "len", "tuple", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "depths[].item", "enumerate", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left_states", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.get_states_from_node"], ["", "def", "expand", "(", "self", ",", "node_indices", ",", "actions", ",", "next_node_index", ")", ":", "\n", "        ", "\"\"\"Creates and evaluate child nodes from given nodes and unexplored actions.\"\"\"", "\n", "\n", "# Retrieve token ids for nodes to be evaluated.", "\n", "tokens_ids", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_token_ids", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "eos_token_id", ")", "\n", "attention_masks", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_attention_mask", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "0", ")", "\n", "depths", "=", "torch", ".", "tensor", "(", "[", "self", ".", "_depth", "[", "(", "b", ",", "n", ")", "]", "+", "1", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "device", "=", "args", ".", "device", ")", "\n", "children_priors", "=", "np", ".", "array", "(", "[", "self", ".", "_children_prior", "[", "(", "b", ",", "n", ")", "]", "[", "actions", "[", "b", "]", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "likelihoods", "=", "np", ".", "array", "(", "[", "self", ".", "_likelihoods", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "previous_node_is_terminal", "=", "self", ".", "_is_terminal", "[", "self", ".", "_batch_range", ",", "node_indices", "[", "self", ".", "_batch_range", "]", "]", "# (B)", "\n", "\n", "states_tensor", "=", "pad_sequences_to_left_states", "(", "[", "self", ".", "get_states_from_node", "(", "b", ",", "n", ",", "depths", "[", "b", "]", ".", "item", "(", ")", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "0", ",", "max_len", "=", "len", "(", "tokens_ids", "[", "0", "]", ")", ")", "\n", "states", "=", "tuple", "(", "tuple", "(", "type_of_value", "for", "type_of_value", "in", "layer", ")", "for", "layer", "in", "states_tensor", ")", "\n", "\n", "# Convert sparse actions to dense actions for network computation", "\n", "dense_actions", "=", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "# Add actions to list of tokens and extend attention mask by 1", "\n", "tokens_ids", "=", "torch", ".", "cat", "(", "(", "tokens_ids", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "cuda", ".", "LongTensor", "(", "dense_actions", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "attention_masks", "=", "torch", ".", "cat", "(", "(", "attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "dense_actions", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "args", ".", "device", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# Check if expanded nodes are terminal ", "\n", "expanded_node_is_terminal", "=", "dense_actions", "==", "eos_token_id", "\n", "\n", "# Evaluate nodes.", "\n", "(", "prior", ",", "values", ",", "next_states", ")", "=", "self", ".", "_rec_fun", "(", "states", ",", "tokens_ids", ",", "attention_masks", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ",", "self", ".", "rollout_size", ")", "\n", "\n", "# Create the new nodes.", "\n", "self", ".", "create_node", "(", "next_node_index", ",", "prior", ",", "likelihoods", "*", "children_priors", ",", "values", ",", "next_states", ",", "tokens_ids", ",", "attention_masks", ",", "expanded_node_is_terminal", ")", "\n", "\n", "# Update the min and max values arrays", "\n", "# self._adaptive_min_values = np.minimum(self._adaptive_min_values, values**(self.alpha) * (likelihoods*children_priors)**(1-self.alpha))", "\n", "# self._adaptive_max_values = np.maximum(self._adaptive_max_values, values**(self.alpha) * (likelihoods*children_priors)**(1-self.alpha))", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "minimum", "(", "self", ".", "_adaptive_min_values", ",", "values", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "maximum", "(", "self", ".", "_adaptive_max_values", ",", "values", ")", "\n", "\n", "# Update tree topology.", "\n", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "=", "next_node_index", "\n", "self", ".", "_parents", "[", ":", ",", "next_node_index", "]", "=", "node_indices", "\n", "self", ".", "_action_from_parents", "[", ":", ",", "next_node_index", "]", "=", "actions", "\n", "self", ".", "_depth", "[", ":", ",", "next_node_index", "]", "=", "self", ".", "_depth", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.create_node": [[486, 522], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "enumerate", "enumerate", "numpy.argpartition", "list", "range", "range", "len", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "len", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "list", "range", "len"], "methods", ["None"], ["", "def", "create_node", "(", "self", ",", "node_index", ",", "prior", ",", "likelihoods", ",", "values", ",", "next_states", ",", "tokens_ids", ",", "attention_masks", ",", "expanded_node_is_terminal", ")", ":", "\n", "        ", "\"\"\"Create nodes with computed values\"\"\"", "\n", "# Truncate the prior to only keep the top k logits", "\n", "prior_topk_indices", "=", "np", ".", "argpartition", "(", "prior", ",", "-", "self", ".", "_num_sparse_actions", ",", "axis", "=", "-", "1", ")", "[", ":", ",", "-", "self", ".", "_num_sparse_actions", ":", "]", "\n", "prior", "=", "prior", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "prior_topk_indices", "]", "# (B, A)", "\n", "\n", "# Store the indices of the top k logits", "\n", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_index", ",", ":", "]", "=", "prior_topk_indices", "\n", "\n", "# Update prior, values and visit counts.", "\n", "self", ".", "_children_prior", "[", ":", ",", "node_index", ",", ":", "]", "=", "prior", "\n", "self", ".", "_likelihoods", "[", ":", ",", "node_index", "]", "=", "likelihoods", "\n", "\n", "raw_values", "=", "values", "**", "(", "self", ".", "alpha", ")", "*", "likelihoods", "**", "(", "1", "-", "self", ".", "alpha", ")", "\n", "# raw_values = values", "\n", "self", ".", "_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_raw_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_visit_counts", "[", ":", ",", "node_index", "]", "=", "1", "\n", "self", ".", "_is_terminal", "[", ":", ",", "node_index", "]", "=", "expanded_node_is_terminal", "\n", "\n", "# Transform the returned states format into tensor for easier manipulation", "\n", "key_value_tensor", "=", "torch", ".", "stack", "(", "list", "(", "torch", ".", "stack", "(", "list", "(", "next_states", "[", "i", "]", ")", ",", "dim", "=", "0", ")", "for", "i", "in", "range", "(", "len", "(", "next_states", ")", ")", ")", ",", "dim", "=", "0", ")", "\n", "if", "(", "node_index", "==", "0", ")", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "tokens_ids", ")", ")", ":", "\n", "                ", "self", ".", "_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "key_value_tensor", "[", ":", ",", ":", ",", "b", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "tokens_ids", ")", ")", ":", "\n", "                ", "self", ".", "_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "key_value_tensor", "[", ":", ",", ":", ",", "b", ",", ":", ",", "-", "1", ":", "]", ")", "\n", "\n", "# Updates tokens ids", "\n", "", "", "for", "b", ",", "token_ids", "in", "enumerate", "(", "tokens_ids", ")", ":", "\n", "            ", "self", ".", "_token_ids", "[", "(", "b", ",", "node_index", ")", "]", "=", "token_ids", "\n", "\n", "# Updates attention masks", "\n", "", "for", "b", ",", "attention_mask", "in", "enumerate", "(", "attention_masks", ")", ":", "\n", "            ", "self", ".", "_attention_mask", "[", "(", "b", ",", "node_index", ")", "]", "=", "attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.BatchedMCTS.backward": [[524, 550], ["is_root.all", "numpy.where", "numpy.where"], "methods", ["None"], ["", "", "def", "backward", "(", "self", ",", "leaf_indices", ")", ":", "\n", "        ", "\"\"\"Goes up and updates the tree until all nodes reached the root.\"\"\"", "\n", "node_indices", "=", "leaf_indices", "# (B)", "\n", "leaf_values", "=", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "leaf_indices", "]", "\n", "while", "True", ":", "\n", "            ", "is_root", "=", "node_indices", "==", "0", "\n", "if", "is_root", ".", "all", "(", ")", ":", "\n", "                ", "return", "\n", "", "parents", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "root_mask", "=", "1.0", "*", "is_root", "\n", "not_root_mask_int", "=", "(", "1", "-", "is_root", ")", "\n", "not_root_mask", "=", "1.0", "-", "root_mask", "\n", "# Update the parent nodes iff their child is not the root.", "\n", "# We therefore mask the updates using not_root_mask and root_mask.", "\n", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "=", "not_root_mask", "*", "(", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "*", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+", "leaf_values", ")", "/", "(", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "\n", "parents", "]", "+", "1.0", ")", "+", "root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "\n", "\n", "# self._values[self._batch_range, parents] = not_root_mask * (np.maximum(self._values[self._batch_range, parents],leaf_values)) + root_mask * self._values[self._batch_range, parents]", "\n", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+=", "not_root_mask_int", "\n", "actions", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_action_from_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "=", "not_root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "root_mask", "*", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "\n", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "+=", "not_root_mask_int", "\n", "# Go up", "\n", "node_indices", "=", "parents", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.set_seed": [[137, 142], ["numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "", "", "set_seed", "(", "args", ")", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.get_values": [[145, 151], ["tokenizer_gpt.batch_decode", "torch.no_grad", "torch.no_grad", "torch.no_grad", "net"], "function", ["None"], ["def", "get_values", "(", "tokens_ids", ",", "labels", ")", ":", "\n", "    ", "\"\"\"Gets sequence scores from the discriminator\"\"\"", "\n", "propositions", "=", "tokenizer_gpt", ".", "batch_decode", "(", "tokens_ids", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "net", "(", "propositions", ")", "\n", "", "return", "outputs", "[", "labels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.pad_sequences_to_left": [[153, 175], ["sequences[].size", "max", "sequences[].new_full", "enumerate", "tensor.size", "s.size", "len", "len"], "function", ["None"], ["", "def", "pad_sequences_to_left", "(", "sequences", ",", "batch_first", "=", "False", ",", "padding_value", "=", "0", ")", ":", "\n", "    ", "\"\"\"Add left padding so sequences have same shape\"\"\"", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "max_len", "=", "max", "(", "[", "s", ".", "size", "(", "0", ")", "for", "s", "in", "sequences", "]", ")", "\n", "if", "batch_first", ":", "\n", "        ", "out_dims", "=", "(", "len", "(", "sequences", ")", ",", "max_len", ")", "+", "trailing_dims", "\n", "", "else", ":", "\n", "        ", "out_dims", "=", "(", "max_len", ",", "len", "(", "sequences", ")", ")", "+", "trailing_dims", "\n", "\n", "", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# use index notation to prevent duplicate references to the tensor", "\n", "if", "batch_first", ":", "\n", "            ", "out_tensor", "[", "i", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "else", ":", "\n", "            ", "out_tensor", "[", "max_len", "-", "length", ":", ",", "i", ",", "...", "]", "=", "tensor", "\n", "", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.pad_sequences_to_left_states": [[178, 192], ["sequences[].size", "sequences[].new_full", "enumerate", "len", "tensor.size"], "function", ["None"], ["", "def", "pad_sequences_to_left_states", "(", "sequences", ",", "padding_value", "=", "0", ",", "max_len", "=", "0", ")", ":", "\n", "    ", "\"\"\"Similar to pad_sequences_to_left function, but working on states tensor (in order to forge state for \"sequential generation\")\"\"\"", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "out_dims", "=", "(", "max_size", "[", "0", "]", ",", "max_size", "[", "1", "]", ",", "len", "(", "sequences", ")", ",", "max_size", "[", "2", "]", ",", "max_len", ",", "max_size", "[", "4", "]", ")", "\n", "# print(out_dims)", "\n", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ",", "device", "=", "args", ".", "device", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", ")", "[", "3", "]", "\n", "out_tensor", "[", ":", ",", ":", ",", "i", ",", ":", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.root_fun": [[194, 218], ["gpt.prepare_inputs_for_generation", "get_values().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gpt", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax().cpu().numpy", "get_values().cpu", "torch.softmax().cpu", "mcts_rollout.get_values", "torch.softmax"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.get_values"], ["", "def", "root_fun", "(", "original_input", ",", "labels", ",", "temperature", ",", "repetition_penalty", ")", ":", "\n", "    ", "\"\"\"Initialize roots scores\"\"\"", "\n", "# Forward pass of GPT-2 to get priors and states", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "original_input", ".", "input_ids", ",", "attention_mask", "=", "original_input", ".", "attention_mask", ",", "use_cache", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "gpt", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "states", "=", "outputs", ".", "past_key_values", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "model_inputs", "[", "\"input_ids\"", "]", ")", "\n", "inverted_attention_mask", "=", "model_inputs", "[", "\"attention_mask\"", "]", "==", "0", "\n", "prompt_masked_input_ids", "[", "inverted_attention_mask", "]", "=", "14827", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Use of our discriminator to get values", "\n", "", "values", "=", "get_values", "(", "original_input", ".", "input_ids", ",", "labels", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "return", "priors", ",", "values", ",", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.rec_fun": [[220, 269], ["gpt.prepare_inputs_for_generation", "get_values().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gpt", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax", "F.softmax.cpu().numpy", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gpt.prepare_inputs_for_generation", "range", "get_values().cpu", "torch.argmax", "torch.argmax", "torch.argmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gpt.prepare_inputs_for_generation", "F.softmax.cpu", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gpt", "mcts_rollout.get_values", "torch.ones", "torch.ones", "torch.ones", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "len", "torch.ones", "torch.ones", "torch.ones", "len"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.get_values"], ["", "def", "rec_fun", "(", "states", ",", "token_ids", ",", "attention_masks", ",", "labels", ",", "temperature", ",", "repetition_penalty", ",", "rollout_size", ")", ":", "\n", "    ", "\"\"\"Get score from current nodes\"\"\"", "\n", "# Forward pass of GPT-2 to get priors and states", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ",", "use_cache", "=", "True", ",", "past", "=", "states", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "gpt", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "\n", "next_states", "=", "outputs", ".", "past_key_values", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "token_ids", ")", "\n", "inverted_attention_mask", "=", "attention_masks", "==", "0", "\n", "#penalizing an unused token", "\n", "prompt_masked_input_ids", "[", "inverted_attention_mask", "]", "=", "14827", "\n", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", "\n", "if", "(", "rollout_size", ">", "0", ")", ":", "\n", "# next_tokens = torch.multinomial(priors, num_samples=1)", "\n", "            ", "next_tokens", "=", "torch", ".", "unsqueeze", "(", "torch", ".", "argmax", "(", "priors", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "1", ")", "\n", "token_ids", "=", "torch", ".", "cat", "(", "(", "token_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "attention_masks", "=", "torch", ".", "cat", "(", "(", "attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "attention_masks", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "args", ".", "device", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "prompt_masked_input_ids", "=", "torch", ".", "cat", "(", "(", "prompt_masked_input_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ",", "use_cache", "=", "True", ",", "past", "=", "outputs", ".", "past_key_values", ")", "\n", "for", "i", "in", "range", "(", "rollout_size", ")", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "outputs", "=", "gpt", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "# next_tokens = torch.unsqueeze(torch.argmax(F.softmax(repetition_penalty(prompt_masked_input_ids, outputs.logits[:, -1, :] / temperature), dim=-1), dim=-1), dim=1)", "\n", "", "next_tokens", "=", "torch", ".", "multinomial", "(", "priors", ",", "num_samples", "=", "1", ")", "\n", "token_ids", "=", "torch", ".", "cat", "(", "(", "token_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "attention_masks", "=", "torch", ".", "cat", "(", "(", "attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "attention_masks", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "args", ".", "device", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "cat", "(", "(", "prompt_masked_input_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ",", "use_cache", "=", "True", ",", "past", "=", "outputs", ".", "past_key_values", ")", "\n", "\n", "\n", "# Use of our discriminator to get values", "\n", "", "", "", "values", "=", "get_values", "(", "token_ids", ",", "labels", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "return", "priors", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "values", ",", "next_states", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout.main": [[551, 589], ["print", "pandas.read_csv", "print", "torch.zeros", "torch.zeros", "torch.zeros", "mcts_rollout.BatchedMCTS", "tqdm.tqdm", "torch.zeros.fill_", "enumerate", "mcts_rollout.BatchedMCTS.set_labels", "tokenizer_gpt().to", "tqdm.tqdm", "range", "tokenizer_gpt.batch_decode", "tqdm.tqdm.update", "lines.iterrows", "mcts_rollout.BatchedMCTS.search", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "tqdm.tqdm.update", "logging.warning", "str", "tokenizer_gpt", "tokenizer_gpt.decode", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "int", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.ones", "torch.ones", "torch.ones", "numpy.argmax", "[].split", "[].split", "text.split"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.set_labels", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.search"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"loading dataset\"", ")", "\n", "data_lines", "=", "pd", ".", "read_csv", "(", "\"../datasets/flue/CLS/test_2.tsv\"", ",", "sep", "=", "'\\t'", ",", "engine", "=", "'python'", ",", "encoding", "=", "\"utf8\"", ")", "\n", "print", "(", "\"dataset loaded\"", ")", "\n", "generated_counter", "=", "750", "\n", "samples_size", "=", "1040", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "labels", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "args", ".", "device", ")", "\n", "prompt_texts", "=", "[", "None", "]", "*", "batch_size", "\n", "MCTS", "=", "BatchedMCTS", "(", "root_fun", ",", "rec_fun", ",", "batch_size", "=", "batch_size", ",", "num_simulations", "=", "args", ".", "num_it", ",", "num_actions", "=", "vocab_size", "+", "1", ",", "num_sparse_actions", "=", "50", ",", "pb_c_init", "=", "args", ".", "c", ",", "temperature", "=", "args", ".", "temperature", ",", "alpha", "=", "args", ".", "alpha", ",", "penalty", "=", "args", ".", "penalty", ",", "rollout_size", "=", "args", ".", "rollout_size", ")", "\n", "samples_pbar", "=", "tqdm", "(", "total", "=", "samples_size", ",", "desc", "=", "\"Samples generated\"", ")", "\n", "while", "(", "generated_counter", "+", "batch_size", "<=", "samples_size", ")", ":", "\n", "        ", "labels", ".", "fill_", "(", "0", ")", "\n", "# Prepare search inputs", "\n", "lines", "=", "data_lines", "[", "generated_counter", ":", "generated_counter", "+", "batch_size", "]", "\n", "\n", "for", "i", ",", "(", "_", ",", "row", ")", "in", "enumerate", "(", "lines", ".", "iterrows", "(", ")", ")", ":", "\n", "            ", "labels", "[", "i", ",", "int", "(", "row", "[", "\"label\"", "]", ")", "]", "=", "1", "\n", "prompt_texts", "[", "i", "]", "=", "\"<|startoftext|> \"", "+", "str", "(", "row", "[", "\"text\"", "]", ")", "\n", "\n", "\n", "", "MCTS", ".", "set_labels", "(", "labels", ")", "\n", "original_input", "=", "tokenizer_gpt", "(", "prompt_texts", ",", "return_tensors", "=", "\"pt\"", ",", "padding", "=", "True", ",", "add_special_tokens", "=", "False", ",", "max_length", "=", "15", ",", "truncation", "=", "True", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "tokens_pbar", "=", "tqdm", "(", "total", "=", "137", ",", "desc", "=", "\"Tokens generated\"", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "137", ")", ":", "\n", "            ", "res_search", "=", "MCTS", ".", "search", "(", "original_input", ")", "\n", "original_input", ".", "input_ids", "=", "torch", ".", "cat", "(", "(", "original_input", ".", "input_ids", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "cuda", ".", "LongTensor", "(", "np", ".", "argmax", "(", "res_search", ",", "axis", "=", "1", ")", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "original_input", ".", "attention_mask", "=", "torch", ".", "cat", "(", "(", "original_input", ".", "attention_mask", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "args", ".", "device", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "prompt_texts", "=", "[", "tokenizer_gpt", ".", "decode", "(", "token_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", "for", "token_ids", "in", "original_input", ".", "input_ids", "]", "\n", "print", "(", "prompt_texts", ")", "\n", "\n", "tokens_pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "final_texts", "=", "tokenizer_gpt", ".", "batch_decode", "(", "original_input", ".", "input_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "for", "text", "in", "final_texts", ":", "\n", "            ", "logging", ".", "warning", "(", "\"<|startoftext|>\"", "+", "(", "(", "text", ".", "split", "(", "\"\\n\"", ")", "[", "0", "]", ")", ".", "split", "(", "\"<|startoftext|>\"", ")", "[", "1", "]", ")", ".", "split", "(", "\"<|endoftext|>\"", ")", "[", "0", "]", "+", "\"<|endoftext|>\"", ")", "\n", "", "generated_counter", "+=", "batch_size", "\n", "samples_pbar", ".", "update", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.language_model_training.DataTrainingArguments.__post_init__": [[141, 151], ["ValueError", "language_model_training.DataTrainingArguments.train_file.split", "language_model_training.DataTrainingArguments.validation_file.split"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_name", "is", "None", "and", "self", ".", "train_file", "is", "None", "and", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a dataset name or a training/validation file.\"", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "train_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`train_file` should be a csv, a json or a txt file.\"", "\n", "", "if", "self", ".", "validation_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`validation_file` should be a csv, a json or a txt file.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.language_model_training.main": [[153, 410], ["transformers.HfArgumentParser", "logging.basicConfig", "logger.setLevel", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "logger.info", "AutoModelForCausalLM.from_config.resize_token_embeddings", "datasets.load_dataset.map", "datasets.map.map", "transformers.Trainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "transformers.utils.logging.set_verbosity_info", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "datasets.load_dataset", "datasets.load_dataset", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForCausalLM.from_pretrained", "logger.info", "transformers.AutoModelForCausalLM.from_config", "len", "AutoTokenizer.from_pretrained.", "min", "len", "result[].copy", "transformers.Trainer.train", "transformers.Trainer.save_model", "os.path.join", "transformers.Trainer.is_world_process_zero", "logger.info", "transformers.Trainer.evaluate", "math.exp", "os.path.join", "transformers.Trainer.is_world_process_zero", "len", "ValueError", "transformers.trainer_utils.is_main_process", "datasets.load_dataset.keys", "datasets.load_dataset", "datasets.load_dataset", "data_args.train_file.split", "transformers.AutoConfig.from_pretrained", "logger.warning", "transformers.AutoTokenizer.from_pretrained", "ValueError", "sum", "logger.warn", "logger.warn", "sum", "transformers.Trainer.state.save_to_json", "os.path.abspath", "len", "logger.info", "logging.StreamHandler", "bool", "examples.keys", "concatenated_examples.items", "os.path.isdir", "open", "logger.info", "sorted", "os.path.join", "open", "logger.info", "sorted", "os.listdir", "bool", "p.numel", "range", "trainer.train.metrics.items", "logger.info", "writer.write", "results.items", "logger.info", "writer.write", "AutoModelForCausalLM.from_config.parameters", "list", "examples.keys"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.set_seed"], ["", "", "", "", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Setup logging", "\n", "", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", "else", "logging", ".", "WARN", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)", "\n", "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/", "\n", "# (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files, this script will use the column called 'text' or the first column if no column called", "\n", "# 'text' is found. You can easily tweak this behavior (see below).", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "if", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "datasets", "=", "load_dataset", "(", "data_args", ".", "dataset_name", ",", "data_args", ".", "dataset_config_name", ")", "\n", "if", "\"validation\"", "not", "in", "datasets", ".", "keys", "(", ")", ":", "\n", "            ", "datasets", "[", "\"validation\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[:{data_args.validation_split_percentage}%]\"", ",", "\n", ")", "\n", "datasets", "[", "\"train\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[{data_args.validation_split_percentage}%:]\"", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"train\"", "]", "=", "data_args", ".", "train_file", "\n", "", "if", "data_args", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"validation\"", "]", "=", "data_args", ".", "validation_file", "\n", "", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "if", "extension", "==", "\"txt\"", ":", "\n", "            ", "extension", "=", "\"text\"", "\n", "", "datasets", "=", "load_dataset", "(", "extension", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "'/nfs/nas4.irisa.fr/deepfakes/deepfakes/image_repurposing/IMATAG/.cache'", ")", "\n", "# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "\n", "", "config_kwargs", "=", "{", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "}", "\n", "if", "model_args", ".", "config_name", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "config_name", ",", "**", "config_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "config_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "CONFIG_MAPPING", "[", "model_args", ".", "model_type", "]", "(", ")", "\n", "logger", ".", "warning", "(", "\"You are instantiating a new config instance from scratch.\"", ")", "\n", "\n", "", "tokenizer_kwargs", "=", "{", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"use_fast\"", ":", "model_args", ".", "use_fast_tokenizer", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "# \"bos_token\": \"[startoftext]\",", "\n", "# \"eos_token\": \"<|endoftext|>\",", "\n", "# \"sep_token\": \"[SEP]\"", "\n", "}", "\n", "if", "model_args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "tokenizer_name", ",", "**", "tokenizer_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "tokenizer_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"", "\n", "\"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"", "\n", ")", "\n", "\n", "", "if", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "AutoModelForCausalLM", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "AutoModelForCausalLM", ".", "from_config", "(", "config", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"The size of the model is {}\"", ".", "format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", ")", ")", "\n", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "# Preprocessing the datasets.", "\n", "# First we tokenize all the texts.", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"train\"", "]", ".", "column_names", "\n", "", "else", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"validation\"", "]", ".", "column_names", "\n", "", "text_column_name", "=", "\"text\"", "if", "\"text\"", "in", "column_names", "else", "column_names", "[", "0", "]", "\n", "\n", "def", "tokenize_function", "(", "examples", ")", ":", "\n", "        ", "return", "tokenizer", "(", "examples", "[", "text_column_name", "]", ")", "\n", "\n", "", "tokenized_datasets", "=", "datasets", ".", "map", "(", "\n", "tokenize_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "if", "data_args", ".", "block_size", "is", "None", ":", "\n", "        ", "block_size", "=", "tokenizer", ".", "model_max_length", "\n", "if", "block_size", ">", "1024", ":", "\n", "            ", "logger", ".", "warn", "(", "\n", "f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}). \"", "\n", "\"Picking 1024 instead. You can change that default value by passing --block_size xxx.\"", "\n", ")", "\n", "", "block_size", "=", "1024", "\n", "", "else", ":", "\n", "        ", "if", "data_args", ".", "block_size", ">", "tokenizer", ".", "model_max_length", ":", "\n", "            ", "logger", ".", "warn", "(", "\n", "f\"The block_size passed ({data_args.block_size}) is larger than the maximum length for the model\"", "\n", "f\"({tokenizer.model_max_length}). Using block_size={tokenizer.model_max_length}.\"", "\n", ")", "\n", "", "block_size", "=", "min", "(", "data_args", ".", "block_size", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "# Main data processing function that will concatenate all texts from our dataset and generate chunks of block_size.", "\n", "", "def", "group_texts", "(", "examples", ")", ":", "\n", "# Concatenate all texts.", "\n", "        ", "concatenated_examples", "=", "{", "k", ":", "sum", "(", "examples", "[", "k", "]", ",", "[", "]", ")", "for", "k", "in", "examples", ".", "keys", "(", ")", "}", "\n", "total_length", "=", "len", "(", "concatenated_examples", "[", "list", "(", "examples", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ")", "\n", "# We drop the small remainder, we could add padding if the model supported it instead of this drop, you can", "\n", "# customize this part to your needs.", "\n", "total_length", "=", "(", "total_length", "//", "block_size", ")", "*", "block_size", "\n", "# Split by chunks of max_len.", "\n", "result", "=", "{", "\n", "k", ":", "[", "t", "[", "i", ":", "i", "+", "block_size", "]", "for", "i", "in", "range", "(", "0", ",", "total_length", ",", "block_size", ")", "]", "\n", "for", "k", ",", "t", "in", "concatenated_examples", ".", "items", "(", ")", "\n", "}", "\n", "result", "[", "\"labels\"", "]", "=", "result", "[", "\"input_ids\"", "]", ".", "copy", "(", ")", "\n", "return", "result", "\n", "\n", "# Note that with `batched=True`, this map processes 1,000 texts together, so group_texts throws away a remainder", "\n", "# for each of those groups of 1,000 texts. You can adjust that batch_size here but a higher value might be slower", "\n", "# to preprocess.", "\n", "#", "\n", "# To speed up this part, we use multiprocessing. See the documentation of the map method for more information:", "\n", "# https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map", "\n", "", "lm_datasets", "=", "tokenized_datasets", ".", "map", "(", "\n", "group_texts", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "# Initialize our Trainer", "\n", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "lm_datasets", "[", "\"train\"", "]", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "lm_datasets", "[", "\"validation\"", "]", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "# Data collator will default to DataCollatorWithPadding, so we change it.", "\n", "data_collator", "=", "default_data_collator", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "model_path", "=", "last_checkpoint", "\n", "", "elif", "model_args", ".", "model_name_or_path", "is", "not", "None", "and", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", ":", "\n", "            ", "model_path", "=", "model_args", ".", "model_name_or_path", "\n", "", "else", ":", "\n", "            ", "model_path", "=", "None", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "model_path", "=", "model_path", ")", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "output_train_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"train_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_train_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Train results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "train_result", ".", "metrics", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "# Need to save the state, since Trainer.save_model saves only the tokenizer with the model", "\n", "", "", "trainer", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "", "results", "=", "{", "}", "\n", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "eval_output", "=", "trainer", ".", "evaluate", "(", ")", "\n", "\n", "perplexity", "=", "math", ".", "exp", "(", "eval_output", "[", "\"eval_loss\"", "]", ")", "\n", "results", "[", "\"perplexity\"", "]", "=", "perplexity", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"eval_results_clm.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "results", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.language_model_training._mp_fn": [[412, 415], ["language_model_training.main"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.main"], ["", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.Net.__init__": [[81, 87], ["torch.Module.__init__", "transformers.BertModel.from_pretrained", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "'bert-base-cased'", ",", "output_hidden_states", "=", "True", ")", "\n", "self", ".", "fc_txt1", "=", "nn", ".", "Linear", "(", "768", ",", "512", ")", "\n", "self", ".", "fc_txt2", "=", "nn", ".", "Linear", "(", "512", ",", "256", ")", "\n", "self", ".", "fc_classif", "=", "nn", ".", "Linear", "(", "256", ",", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.Net.forward": [[89, 99], ["tokenizer.batch_encode_plus", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "mcts_rollout_emotion.Net.bert", "torch.normalize", "torch.normalize", "torch.normalize", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "mcts_rollout_emotion.Net.fc_classif", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "mcts_rollout_emotion.Net.fc_txt1", "mcts_rollout_emotion.Net.fc_txt2", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "texts", ")", ":", "\n", "        ", "tokenizer_res", "=", "tokenizer", ".", "batch_encode_plus", "(", "texts", ",", "truncation", "=", "True", ",", "max_length", "=", "512", ",", "padding", "=", "'longest'", ")", "\n", "tokens_tensor", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "tokenizer_res", "[", "'input_ids'", "]", ")", "\n", "attention_tensor", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "tokenizer_res", "[", "'attention_mask'", "]", ")", "\n", "output", "=", "self", ".", "bert", "(", "tokens_tensor", ",", "attention_mask", "=", "attention_tensor", ")", "\n", "text", "=", "F", ".", "normalize", "(", "torch", ".", "div", "(", "torch", ".", "sum", "(", "output", "[", "2", "]", "[", "-", "1", "]", ",", "axis", "=", "1", ")", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "sum", "(", "attention_tensor", ",", "axis", "=", "1", ")", ",", "1", ")", ")", ")", "\n", "text", "=", "F", ".", "relu", "(", "self", ".", "fc_txt1", "(", "text", ")", ")", "\n", "text", "=", "F", ".", "relu", "(", "self", ".", "fc_txt2", "(", "text", ")", ")", "\n", "text", "=", "self", ".", "fc_classif", "(", "text", ")", "\n", "return", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.__init__": [[268, 320], ["min", "numpy.zeros", "numpy.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.arange", "mcts_rollout_emotion.BatchedMCTS._reset_tree", "transformers.RepetitionPenaltyLogitsProcessor"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree"], ["    ", "def", "__init__", "(", "self", ",", "root_fun", ",", "rec_fun", ",", "batch_size", ",", "num_simulations", ",", "num_actions", ",", "num_sparse_actions", ",", "pb_c_init", ",", "temperature", ",", "alpha", ",", "penalty", ")", ":", "\n", "# Initialize parameters", "\n", "        ", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_num_simulations", "=", "num_simulations", "\n", "self", ".", "_num_actions", "=", "num_actions", "\n", "self", ".", "_num_sparse_actions", "=", "min", "(", "num_sparse_actions", ",", "num_actions", ")", "\n", "self", ".", "_pb_c_init", "=", "pb_c_init", "\n", "self", ".", "_temperature", "=", "temperature", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n", "self", ".", "_root_fun", "=", "root_fun", "# a function called at the root", "\n", "self", ".", "_rec_fun", "=", "rec_fun", "# a function called in the tree", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_labels", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "args", ".", "device", ")", "\n", "\n", "# Allocate all necessary storage.", "\n", "# For a given search associated to a batch-index, node i is the i-th node", "\n", "# to be expanded. Node 0 corresponds to the root node.", "\n", "num_nodes", "=", "num_simulations", "+", "1", "\n", "batch_node", "=", "(", "batch_size", ",", "num_nodes", ")", "\n", "self", ".", "_num_nodes", "=", "num_nodes", "\n", "self", ".", "_visit_counts", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_likelihoods", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_raw_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# action_from_parents[b, i] is the action taken to reach node i.", "\n", "# Note that action_from_parents[b, 0] will remain -1, as we do not know,", "\n", "# when doing search from the root, what action led to the root.", "\n", "self", ".", "_action_from_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# The 0-indexed depth of the node. The root is the only 0-depth node.", "\n", "# The depth of node i, is the depth of its parent + 1.", "\n", "self", ".", "_depth", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_is_terminal", "=", "np", ".", "full", "(", "batch_node", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "\n", "# To avoid costly numpy ops, we store a sparse version of the actions.", "\n", "# We select the top k actions according to the policy, and keep a mapping", "\n", "# of indices from 0 to k-1 to the actual action indices in the", "\n", "# self._topk_mapping tensor.", "\n", "batch_node_action", "=", "(", "batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ")", "\n", "self", ".", "_topk_mapping", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_index", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_prior", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_values", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_visits", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_states", "=", "{", "}", "\n", "self", ".", "_token_ids", "=", "{", "}", "\n", "self", ".", "_attention_mask", "=", "{", "}", "\n", "self", ".", "_batch_range", "=", "np", ".", "arange", "(", "batch_size", ")", "\n", "self", ".", "_reset_tree", "(", ")", "\n", "self", ".", "_repetition_penalty", "=", "RepetitionPenaltyLogitsProcessor", "(", "penalty", "=", "penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS._reset_tree": [[321, 338], ["mcts_rollout_emotion.BatchedMCTS._visit_counts.fill", "mcts_rollout_emotion.BatchedMCTS._values.fill", "mcts_rollout_emotion.BatchedMCTS._likelihoods.fill", "mcts_rollout_emotion.BatchedMCTS._parents.fill", "mcts_rollout_emotion.BatchedMCTS._action_from_parents.fill", "mcts_rollout_emotion.BatchedMCTS._depth.fill", "mcts_rollout_emotion.BatchedMCTS._topk_mapping.fill", "mcts_rollout_emotion.BatchedMCTS._children_index.fill", "mcts_rollout_emotion.BatchedMCTS._children_prior.fill", "mcts_rollout_emotion.BatchedMCTS._children_values.fill", "mcts_rollout_emotion.BatchedMCTS._children_visits.fill"], "methods", ["None"], ["", "def", "_reset_tree", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the tree arrays.\"\"\"", "\n", "self", ".", "_visit_counts", ".", "fill", "(", "0", ")", "\n", "self", ".", "_values", ".", "fill", "(", "0", ")", "\n", "self", ".", "_likelihoods", ".", "fill", "(", "0", ")", "\n", "self", ".", "_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_action_from_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_depth", ".", "fill", "(", "0", ")", "\n", "\n", "self", ".", "_topk_mapping", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_index", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_prior", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_values", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_visits", ".", "fill", "(", "0", ")", "\n", "self", ".", "_states", "=", "{", "}", "\n", "self", ".", "_token_ids", "=", "{", "}", "# Indexed by tuples (batch index, node index)", "\n", "self", ".", "_attention_mask", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.set_labels": [[339, 341], ["None"], "methods", ["None"], ["", "def", "set_labels", "(", "self", ",", "labels", ")", ":", "\n", "        ", "self", ".", "_labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.search": [[342, 369], ["mcts_rollout_emotion.BatchedMCTS._reset_tree", "mcts_rollout_emotion.BatchedMCTS._root_fun", "mcts_rollout_emotion.BatchedMCTS.create_node", "numpy.zeros", "range", "mcts_rollout_emotion.BatchedMCTS.dense_visit_counts", "numpy.full", "mcts_rollout_emotion.BatchedMCTS.simulate", "mcts_rollout_emotion.BatchedMCTS.expand", "numpy.zeros.fill", "mcts_rollout_emotion.BatchedMCTS.backward"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.dense_visit_counts", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.simulate", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.backward"], ["", "def", "search", "(", "self", ",", "original_input", ")", ":", "\n", "        ", "self", ".", "_reset_tree", "(", ")", "\n", "\n", "# Evaluate the root.", "\n", "prior", ",", "values", ",", "states", "=", "self", ".", "_root_fun", "(", "original_input", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ")", "\n", "\n", "\n", "self", ".", "_adaptive_min_values", "=", "values", "\n", "self", ".", "_adaptive_max_values", "=", "values", "+", "1e-6", "\n", "\n", "root_index", "=", "0", "\n", "self", ".", "create_node", "(", "root_index", ",", "prior", ",", "1", ",", "values", ",", "states", ",", "original_input", ".", "input_ids", ",", "original_input", ".", "attention_mask", ",", "np", ".", "full", "(", "self", ".", "_batch_size", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", ")", "\n", "\n", "\n", "\n", "\n", "# Do simulations, expansions, and backwards.", "\n", "leaf_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "for", "sim", "in", "range", "(", "self", ".", "_num_simulations", ")", ":", "\n", "            ", "node_indices", ",", "actions", "=", "self", ".", "simulate", "(", ")", "\n", "next_node_index", "=", "sim", "+", "1", "# root is 0, therefore we offset by 1.", "\n", "self", ".", "expand", "(", "node_indices", ",", "actions", ",", "next_node_index", ")", "\n", "leaf_indices", ".", "fill", "(", "next_node_index", ")", "\n", "self", ".", "backward", "(", "leaf_indices", ")", "\n", "\n", "# Final choice: most visited, max score, max mean score", "\n", "", "return", "self", ".", "dense_visit_counts", "(", ")", "\n", "# return self.dense_scores()", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.dense_visit_counts": [[372, 378], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_visit_counts", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_visit_counts", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_visit_counts", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_visit_counts", "\n", "return", "dense_visit_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.dense_scores": [[379, 386], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_root_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_root_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_scores", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "return", "dense_root_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.dense_mean_scores": [[387, 395], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_mean_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_mean_scores", "=", "root_scores", "/", "root_visit_counts", "\n", "dense_mean_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_mean_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_mean_scores", "\n", "return", "dense_mean_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.simulate": [[396, 409], ["numpy.zeros", "mcts_rollout_emotion.BatchedMCTS.uct_select_action", "is_unexplored.all", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.uct_select_action"], ["", "def", "simulate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Goes down until all elements have reached unexplored actions.\"\"\"", "\n", "node_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "depth", "=", "0", "\n", "while", "True", ":", "\n", "            ", "depth", "+=", "1", "\n", "actions", "=", "self", ".", "uct_select_action", "(", "node_indices", ")", "\n", "next_node_indices", "=", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "is_unexplored", "=", "next_node_indices", "==", "-", "1", "\n", "if", "is_unexplored", ".", "all", "(", ")", ":", "\n", "                ", "return", "node_indices", ",", "actions", "\n", "", "else", ":", "\n", "                ", "node_indices", "=", "np", ".", "where", "(", "is_unexplored", ",", "node_indices", ",", "next_node_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.uct_select_action": [[410, 426], ["numpy.argmax", "numpy.sqrt"], "methods", ["None"], ["", "", "", "def", "uct_select_action", "(", "self", ",", "node_indices", ")", ":", "\n", "        ", "\"\"\"Returns the action selected for a batch of node indices of shape (B).\"\"\"", "\n", "node_children_prior", "=", "self", ".", "_children_prior", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_values", "=", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_visits", "=", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_visits", "=", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "# (B)", "\n", "node_policy_score", "=", "np", ".", "sqrt", "(", "node_visits", "[", ":", ",", "None", "]", ")", "*", "self", ".", "_pb_c_init", "*", "node_children_prior", "/", "(", "node_children_visits", "+", "1", ")", "# (B, A)", "\n", "\n", "# Remap values between 0 and 1.", "\n", "node_value_score", "=", "node_children_values", "\n", "# node_value_score = (node_value_score != 0.) * node_value_score + (node_value_score == 0.) * self._adaptive_min_values[:, None]", "\n", "# node_value_score = (node_value_score - self._adaptive_min_values[:, None]) / (self._adaptive_max_values[:, None] - self._adaptive_min_values[:, None])", "\n", "\n", "node_uct_score", "=", "node_value_score", "+", "node_policy_score", "# (B, A)", "\n", "actions", "=", "np", ".", "argmax", "(", "node_uct_score", ",", "axis", "=", "1", ")", "\n", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.get_states_from_node": [[427, 438], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "get_states_from_node", "(", "self", ",", "b", ",", "n", ",", "d", ")", ":", "\n", "        ", "\"\"\"Forge state tensor by going backward from the node to the root (because we only store on token's part on each node to avoid duplication)\"\"\"", "\n", "state_array", "=", "[", "None", "]", "*", "d", "\n", "state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_states", "[", "(", "b", ",", "n", ")", "]", "\n", "while", "n", "!=", "0", ":", "\n", "            ", "n", "=", "self", ".", "_parents", "[", "(", "b", ",", "n", ")", "]", "\n", "d", "-=", "1", "\n", "state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_states", "[", "(", "b", ",", "n", ")", "]", "\n", "\n", "", "result", "=", "torch", ".", "cat", "(", "state_array", ",", "3", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.expand": [[439, 479], ["mcts_rollout_emotion.pad_sequences_to_left", "mcts_rollout_emotion.pad_sequences_to_left", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.array", "numpy.array", "mcts_rollout_emotion.pad_sequences_to_left_states", "tuple", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mcts_rollout_emotion.BatchedMCTS._rec_fun", "mcts_rollout_emotion.BatchedMCTS.create_node", "numpy.minimum", "numpy.maximum", "mcts_rollout_emotion.BatchedMCTS.get_states_from_node", "len", "tuple", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "depths[].item", "enumerate", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left_states", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.get_states_from_node"], ["", "def", "expand", "(", "self", ",", "node_indices", ",", "actions", ",", "next_node_index", ")", ":", "\n", "        ", "\"\"\"Creates and evaluate child nodes from given nodes and unexplored actions.\"\"\"", "\n", "\n", "# Retrieve token ids for nodes to be evaluated.", "\n", "tokens_ids", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_token_ids", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "eos_token_id", ")", "\n", "attention_masks", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_attention_mask", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "0", ")", "\n", "depths", "=", "torch", ".", "tensor", "(", "[", "self", ".", "_depth", "[", "(", "b", ",", "n", ")", "]", "+", "1", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "device", "=", "args", ".", "device", ")", "\n", "children_priors", "=", "np", ".", "array", "(", "[", "self", ".", "_children_prior", "[", "(", "b", ",", "n", ")", "]", "[", "actions", "[", "b", "]", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "likelihoods", "=", "np", ".", "array", "(", "[", "self", ".", "_likelihoods", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "previous_node_is_terminal", "=", "self", ".", "_is_terminal", "[", "self", ".", "_batch_range", ",", "node_indices", "[", "self", ".", "_batch_range", "]", "]", "# (B)", "\n", "\n", "states_tensor", "=", "pad_sequences_to_left_states", "(", "[", "self", ".", "get_states_from_node", "(", "b", ",", "n", ",", "depths", "[", "b", "]", ".", "item", "(", ")", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "0", ",", "max_len", "=", "len", "(", "tokens_ids", "[", "0", "]", ")", ")", "\n", "states", "=", "tuple", "(", "tuple", "(", "type_of_value", "for", "type_of_value", "in", "layer", ")", "for", "layer", "in", "states_tensor", ")", "\n", "\n", "# Convert sparse actions to dense actions for network computation", "\n", "dense_actions", "=", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "# Add actions to list of tokens and extend attention mask by 1", "\n", "tokens_ids", "=", "torch", ".", "cat", "(", "(", "tokens_ids", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "cuda", ".", "LongTensor", "(", "dense_actions", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "attention_masks", "=", "torch", ".", "cat", "(", "(", "attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "dense_actions", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "args", ".", "device", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# Check if expanded nodes are terminal ", "\n", "expanded_node_is_terminal", "=", "dense_actions", "==", "eos_token_id", "\n", "\n", "# Evaluate nodes.", "\n", "(", "prior", ",", "values", ",", "next_states", ")", "=", "self", ".", "_rec_fun", "(", "states", ",", "tokens_ids", ",", "attention_masks", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ")", "\n", "\n", "# Create the new nodes.", "\n", "self", ".", "create_node", "(", "next_node_index", ",", "prior", ",", "likelihoods", "*", "children_priors", ",", "values", ",", "next_states", ",", "tokens_ids", ",", "attention_masks", ",", "expanded_node_is_terminal", ")", "\n", "\n", "# Update the min and max values arrays", "\n", "# self._adaptive_min_values = np.minimum(self._adaptive_min_values, values**(self.alpha) * (likelihoods*children_priors)**(1-self.alpha))", "\n", "# self._adaptive_max_values = np.maximum(self._adaptive_max_values, values**(self.alpha) * (likelihoods*children_priors)**(1-self.alpha))", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "minimum", "(", "self", ".", "_adaptive_min_values", ",", "values", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "maximum", "(", "self", ".", "_adaptive_max_values", ",", "values", ")", "\n", "\n", "# Update tree topology.", "\n", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "=", "next_node_index", "\n", "self", ".", "_parents", "[", ":", ",", "next_node_index", "]", "=", "node_indices", "\n", "self", ".", "_action_from_parents", "[", ":", ",", "next_node_index", "]", "=", "actions", "\n", "self", ".", "_depth", "[", ":", ",", "next_node_index", "]", "=", "self", ".", "_depth", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.create_node": [[480, 516], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "enumerate", "enumerate", "numpy.argpartition", "list", "range", "range", "len", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "len", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "list", "range", "len"], "methods", ["None"], ["", "def", "create_node", "(", "self", ",", "node_index", ",", "prior", ",", "likelihoods", ",", "values", ",", "next_states", ",", "tokens_ids", ",", "attention_masks", ",", "expanded_node_is_terminal", ")", ":", "\n", "        ", "\"\"\"Create nodes with computed values\"\"\"", "\n", "# Truncate the prior to only keep the top k logits", "\n", "prior_topk_indices", "=", "np", ".", "argpartition", "(", "prior", ",", "-", "self", ".", "_num_sparse_actions", ",", "axis", "=", "-", "1", ")", "[", ":", ",", "-", "self", ".", "_num_sparse_actions", ":", "]", "\n", "prior", "=", "prior", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "prior_topk_indices", "]", "# (B, A)", "\n", "\n", "# Store the indices of the top k logits", "\n", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_index", ",", ":", "]", "=", "prior_topk_indices", "\n", "\n", "# Update prior, values and visit counts.", "\n", "self", ".", "_children_prior", "[", ":", ",", "node_index", ",", ":", "]", "=", "prior", "\n", "self", ".", "_likelihoods", "[", ":", ",", "node_index", "]", "=", "likelihoods", "\n", "\n", "raw_values", "=", "values", "**", "(", "self", ".", "alpha", ")", "*", "likelihoods", "**", "(", "1", "-", "self", ".", "alpha", ")", "\n", "# raw_values = values", "\n", "self", ".", "_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_raw_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_visit_counts", "[", ":", ",", "node_index", "]", "=", "1", "\n", "self", ".", "_is_terminal", "[", ":", ",", "node_index", "]", "=", "expanded_node_is_terminal", "\n", "\n", "# Transform the returned states format into tensor for easier manipulation", "\n", "key_value_tensor", "=", "torch", ".", "stack", "(", "list", "(", "torch", ".", "stack", "(", "list", "(", "next_states", "[", "i", "]", ")", ",", "dim", "=", "0", ")", "for", "i", "in", "range", "(", "len", "(", "next_states", ")", ")", ")", ",", "dim", "=", "0", ")", "\n", "if", "(", "node_index", "==", "0", ")", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "tokens_ids", ")", ")", ":", "\n", "                ", "self", ".", "_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "key_value_tensor", "[", ":", ",", ":", ",", "b", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "tokens_ids", ")", ")", ":", "\n", "                ", "self", ".", "_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "key_value_tensor", "[", ":", ",", ":", ",", "b", ",", ":", ",", "-", "1", ":", "]", ")", "\n", "\n", "# Updates tokens ids", "\n", "", "", "for", "b", ",", "token_ids", "in", "enumerate", "(", "tokens_ids", ")", ":", "\n", "            ", "self", ".", "_token_ids", "[", "(", "b", ",", "node_index", ")", "]", "=", "token_ids", "\n", "\n", "# Updates attention masks", "\n", "", "for", "b", ",", "attention_mask", "in", "enumerate", "(", "attention_masks", ")", ":", "\n", "            ", "self", ".", "_attention_mask", "[", "(", "b", ",", "node_index", ")", "]", "=", "attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.BatchedMCTS.backward": [[518, 544], ["is_root.all", "numpy.where", "numpy.where"], "methods", ["None"], ["", "", "def", "backward", "(", "self", ",", "leaf_indices", ")", ":", "\n", "        ", "\"\"\"Goes up and updates the tree until all nodes reached the root.\"\"\"", "\n", "node_indices", "=", "leaf_indices", "# (B)", "\n", "leaf_values", "=", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "leaf_indices", "]", "\n", "while", "True", ":", "\n", "            ", "is_root", "=", "node_indices", "==", "0", "\n", "if", "is_root", ".", "all", "(", ")", ":", "\n", "                ", "return", "\n", "", "parents", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "root_mask", "=", "1.0", "*", "is_root", "\n", "not_root_mask_int", "=", "(", "1", "-", "is_root", ")", "\n", "not_root_mask", "=", "1.0", "-", "root_mask", "\n", "# Update the parent nodes iff their child is not the root.", "\n", "# We therefore mask the updates using not_root_mask and root_mask.", "\n", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "=", "not_root_mask", "*", "(", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "*", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+", "leaf_values", ")", "/", "(", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "\n", "parents", "]", "+", "1.0", ")", "+", "root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "\n", "\n", "# self._values[self._batch_range, parents] = not_root_mask * (np.maximum(self._values[self._batch_range, parents],leaf_values)) + root_mask * self._values[self._batch_range, parents]", "\n", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+=", "not_root_mask_int", "\n", "actions", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_action_from_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "=", "not_root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "root_mask", "*", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "\n", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "+=", "not_root_mask_int", "\n", "# Go up", "\n", "node_indices", "=", "parents", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.set_seed": [[127, 132], ["numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "", "", "set_seed", "(", "args", ")", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.get_values": [[135, 141], ["tokenizer_gpt.batch_decode", "torch.no_grad", "torch.no_grad", "torch.no_grad", "net"], "function", ["None"], ["def", "get_values", "(", "tokens_ids", ",", "labels", ")", ":", "\n", "    ", "\"\"\"Gets sequence scores from the discriminator\"\"\"", "\n", "propositions", "=", "tokenizer_gpt", ".", "batch_decode", "(", "tokens_ids", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "net", "(", "propositions", ")", "\n", "", "return", "outputs", "[", "labels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.pad_sequences_to_left": [[143, 165], ["sequences[].size", "max", "sequences[].new_full", "enumerate", "tensor.size", "s.size", "len", "len"], "function", ["None"], ["", "def", "pad_sequences_to_left", "(", "sequences", ",", "batch_first", "=", "False", ",", "padding_value", "=", "0", ")", ":", "\n", "    ", "\"\"\"Add left padding so sequences have same shape\"\"\"", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "max_len", "=", "max", "(", "[", "s", ".", "size", "(", "0", ")", "for", "s", "in", "sequences", "]", ")", "\n", "if", "batch_first", ":", "\n", "        ", "out_dims", "=", "(", "len", "(", "sequences", ")", ",", "max_len", ")", "+", "trailing_dims", "\n", "", "else", ":", "\n", "        ", "out_dims", "=", "(", "max_len", ",", "len", "(", "sequences", ")", ")", "+", "trailing_dims", "\n", "\n", "", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# use index notation to prevent duplicate references to the tensor", "\n", "if", "batch_first", ":", "\n", "            ", "out_tensor", "[", "i", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "else", ":", "\n", "            ", "out_tensor", "[", "max_len", "-", "length", ":", ",", "i", ",", "...", "]", "=", "tensor", "\n", "", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.pad_sequences_to_left_states": [[168, 182], ["sequences[].size", "sequences[].new_full", "enumerate", "len", "tensor.size"], "function", ["None"], ["", "def", "pad_sequences_to_left_states", "(", "sequences", ",", "padding_value", "=", "0", ",", "max_len", "=", "0", ")", ":", "\n", "    ", "\"\"\"Similar to pad_sequences_to_left function, but working on states tensor (in order to forge state for \"sequential generation\")\"\"\"", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "out_dims", "=", "(", "max_size", "[", "0", "]", ",", "max_size", "[", "1", "]", ",", "len", "(", "sequences", ")", ",", "max_size", "[", "2", "]", ",", "max_len", ",", "max_size", "[", "4", "]", ")", "\n", "# print(out_dims)", "\n", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ",", "device", "=", "args", ".", "device", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", ")", "[", "3", "]", "\n", "out_tensor", "[", ":", ",", ":", ",", "i", ",", ":", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.root_fun": [[184, 208], ["gpt.prepare_inputs_for_generation", "get_values().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gpt", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax().cpu().numpy", "get_values().cpu", "torch.softmax().cpu", "mcts_rollout_emotion.get_values", "torch.softmax"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.get_values"], ["", "def", "root_fun", "(", "original_input", ",", "labels", ",", "temperature", ",", "repetition_penalty", ")", ":", "\n", "    ", "\"\"\"Initialize roots scores\"\"\"", "\n", "# Forward pass of GPT-2 to get priors and states", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "original_input", ".", "input_ids", ",", "attention_mask", "=", "original_input", ".", "attention_mask", ",", "use_cache", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "gpt", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "states", "=", "outputs", ".", "past_key_values", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "model_inputs", "[", "\"input_ids\"", "]", ")", "\n", "inverted_attention_mask", "=", "model_inputs", "[", "\"attention_mask\"", "]", "==", "0", "\n", "prompt_masked_input_ids", "[", "inverted_attention_mask", "]", "=", "14827", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Use of our discriminator to get values", "\n", "", "values", "=", "get_values", "(", "original_input", ".", "input_ids", ",", "labels", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "return", "priors", ",", "values", ",", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.rec_fun": [[210, 264], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "gpt.prepare_inputs_for_generation", "get_values().cpu().numpy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gpt", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gpt.prepare_inputs_for_generation", "F.softmax.cpu().numpy", "len", "torch.sum", "torch.sum", "torch.sum", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gpt.prepare_inputs_for_generation", "get_values().cpu", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "is_finished.all", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gpt", "torch.argmax", "torch.argmax", "torch.argmax", "torch.sum", "torch.sum", "torch.sum", "F.softmax.cpu", "torch.ones", "torch.ones", "torch.ones", "torch.softmax", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "mcts_rollout_emotion.get_values", "len", "repetition_penalty", "torch.ones", "torch.ones", "torch.ones", "len"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.get_values"], ["", "def", "rec_fun", "(", "states", ",", "token_ids", ",", "attention_masks", ",", "labels", ",", "temperature", ",", "repetition_penalty", ")", ":", "\n", "# Vector to store if the element in the batch is finished (eos or \".\")", "\n", "# is_finished = torch.unsqueeze(torch.zeros(len(token_ids), device=\"cuda\"), 1)", "\n", "    ", "index_ending", "=", "torch", ".", "unsqueeze", "(", "torch", ".", "zeros", "(", "len", "(", "token_ids", ")", ",", "device", "=", "\"cuda\"", ")", ",", "1", ")", "\n", "# Forward pass of GPT-2 to get priors and states", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ",", "use_cache", "=", "True", ",", "past", "=", "states", ")", "\n", "# model_inputs = gpt.prepare_inputs_for_generation(token_ids[:,[-1]], attention_mask=attention_masks[:,[-1]], use_cache=True, past=states)", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "gpt", "(", "\n", "**", "model_inputs", ",", "\n", "# past_key_values = states,", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "output_states", "=", "outputs", ".", "past_key_values", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "token_ids", ")", "\n", "#Masking padding to not penalize pad (==eos) token", "\n", "inverted_attention_mask", "=", "attention_masks", "==", "0", "\n", "#penalizing an unused token", "\n", "prompt_masked_input_ids", "[", "inverted_attention_mask", "]", "=", "14827", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", "\n", "next_tokens", "=", "torch", ".", "multinomial", "(", "priors", ",", "num_samples", "=", "1", ")", "\n", "# next_tokens =  torch.unsqueeze(torch.argmax(priors, dim=-1), dim=1)", "\n", "is_finished", "=", "torch", ".", "sum", "(", "prompt_masked_input_ids", "==", "eos_token_id", ",", "dim", "=", "1", ")", ">", "0", "\n", "\n", "token_ids", "=", "torch", ".", "cat", "(", "(", "token_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "attention_masks", "=", "torch", ".", "cat", "(", "(", "attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "attention_masks", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "prompt_masked_input_ids", "=", "torch", ".", "cat", "(", "(", "prompt_masked_input_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ",", "use_cache", "=", "True", ",", "past", "=", "outputs", ".", "past_key_values", ")", "\n", "#Until every rollouts are finished or we reached maximum gpt length", "\n", "while", "(", "not", "is_finished", ".", "all", "(", ")", "and", "len", "(", "token_ids", "[", "0", "]", ")", "<", "1024", ")", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "gpt", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "\n", "# next_tokens = torch.multinomial(F.softmax(repetition_penalty(prompt_masked_input_ids, outputs.logits[:, -1, :] / temperature), dim=-1), num_samples=1)", "\n", "", "next_tokens", "=", "torch", ".", "unsqueeze", "(", "torch", ".", "argmax", "(", "F", ".", "softmax", "(", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "1", ")", "\n", "token_ids", "=", "torch", ".", "cat", "(", "(", "token_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "attention_masks", "=", "torch", ".", "cat", "(", "(", "attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "attention_masks", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "cat", "(", "(", "prompt_masked_input_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "is_finished", "=", "torch", ".", "sum", "(", "prompt_masked_input_ids", "==", "eos_token_id", ",", "dim", "=", "1", ")", ">", "0", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ",", "use_cache", "=", "True", ",", "past", "=", "outputs", ".", "past_key_values", ")", "\n", "\n", "# Use of our discriminator to get values", "\n", "", "", "values", "=", "get_values", "(", "token_ids", ",", "labels", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "return", "priors", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "values", ",", "output_states", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_emotion.main": [[546, 584], ["print", "pandas.read_csv", "print", "torch.zeros", "torch.zeros", "torch.zeros", "mcts_rollout_emotion.BatchedMCTS", "tqdm.tqdm", "torch.zeros.fill_", "enumerate", "mcts_rollout_emotion.BatchedMCTS.set_labels", "tokenizer_gpt().to", "tqdm.tqdm", "range", "tokenizer_gpt.batch_decode", "tqdm.tqdm.update", "data_lines[].nunique", "lines.iterrows", "mcts_rollout_emotion.BatchedMCTS.search", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "tqdm.tqdm.update", "logging.warning", "str", "tokenizer_gpt", "tokenizer_gpt.decode", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "int", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.ones", "torch.ones", "torch.ones", "numpy.argmax", "[].split", "[].split", "text.split"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.set_labels", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.search"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"loading dataset\"", ")", "\n", "data_lines", "=", "pd", ".", "read_csv", "(", "\"../datasets/emotion/full/test_2.tsv\"", ",", "sep", "=", "'\\t'", ",", "engine", "=", "'python'", ",", "encoding", "=", "\"utf8\"", ")", "\n", "print", "(", "\"dataset loaded\"", ")", "\n", "generated_counter", "=", "0", "\n", "samples_size", "=", "1050", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "\n", "labels", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "data_lines", "[", "\"label\"", "]", ".", "nunique", "(", ")", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "\"cuda\"", ")", "\n", "prompt_texts", "=", "[", "None", "]", "*", "batch_size", "\n", "MCTS", "=", "BatchedMCTS", "(", "root_fun", ",", "rec_fun", ",", "batch_size", "=", "batch_size", ",", "num_simulations", "=", "args", ".", "num_it", ",", "num_actions", "=", "vocab_size", "+", "1", ",", "num_sparse_actions", "=", "50", ",", "pb_c_init", "=", "args", ".", "c", ",", "temperature", "=", "args", ".", "temperature", ",", "alpha", "=", "args", ".", "alpha", ",", "penalty", "=", "args", ".", "penalty", ")", "\n", "samples_pbar", "=", "tqdm", "(", "total", "=", "samples_size", ",", "desc", "=", "\"Samples generated\"", ")", "\n", "while", "(", "generated_counter", "+", "batch_size", "<=", "samples_size", ")", ":", "\n", "        ", "labels", ".", "fill_", "(", "0", ")", "\n", "# Prepare search inputs", "\n", "lines", "=", "data_lines", "[", "generated_counter", ":", "generated_counter", "+", "batch_size", "]", "\n", "\n", "for", "i", ",", "(", "_", ",", "row", ")", "in", "enumerate", "(", "lines", ".", "iterrows", "(", ")", ")", ":", "\n", "            ", "labels", "[", "i", ",", "int", "(", "row", "[", "\"label\"", "]", ")", "]", "=", "1", "\n", "prompt_texts", "[", "i", "]", "=", "\"<|startoftext|> \"", "+", "str", "(", "row", "[", "\"text\"", "]", ")", "\n", "\n", "", "MCTS", ".", "set_labels", "(", "labels", ")", "\n", "original_input", "=", "tokenizer_gpt", "(", "prompt_texts", ",", "return_tensors", "=", "\"pt\"", ",", "padding", "=", "True", ",", "add_special_tokens", "=", "False", ",", "max_length", "=", "11", ",", "truncation", "=", "True", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "# print(tokenizer_gpt.decode(original_input.input_ids[0], skip_special_tokens=False, clean_up_tokenization_spaces=True))", "\n", "tokens_pbar", "=", "tqdm", "(", "total", "=", "23", ",", "desc", "=", "\"Tokens generated\"", ")", "# 23", "\n", "for", "i", "in", "range", "(", "0", ",", "23", ")", ":", "\n", "            ", "res_search", "=", "MCTS", ".", "search", "(", "original_input", ")", "\n", "original_input", ".", "input_ids", "=", "torch", ".", "cat", "(", "(", "original_input", ".", "input_ids", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "cuda", ".", "LongTensor", "(", "np", ".", "argmax", "(", "res_search", ",", "axis", "=", "1", ")", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "original_input", ".", "attention_mask", "=", "torch", ".", "cat", "(", "(", "original_input", ".", "attention_mask", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "prompt_texts", "=", "[", "tokenizer_gpt", ".", "decode", "(", "token_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", "for", "token_ids", "in", "original_input", ".", "input_ids", "]", "\n", "print", "(", "prompt_texts", ")", "\n", "tokens_pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "final_texts", "=", "tokenizer_gpt", ".", "batch_decode", "(", "original_input", ".", "input_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "for", "text", "in", "final_texts", ":", "\n", "            ", "logging", ".", "warning", "(", "\"<|startoftext|> \"", "+", "(", "(", "text", ".", "split", "(", "\"\\n\"", ")", "[", "0", "]", ")", ".", "split", "(", "\"<|startoftext|> \"", ")", "[", "1", "]", ")", ".", "split", "(", "\"<|endoftext|>\"", ")", "[", "0", "]", "+", "\"<|endoftext|>\"", ")", "\n", "", "generated_counter", "+=", "batch_size", "\n", "samples_pbar", ".", "update", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.Net.__init__": [[87, 92], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc_txt1", "=", "nn", ".", "Linear", "(", "768", ",", "512", ")", "\n", "self", ".", "fc_txt2", "=", "nn", ".", "Linear", "(", "512", ",", "256", ")", "\n", "self", ".", "fc_classif", "=", "nn", ".", "Linear", "(", "256", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.Net.forward": [[95, 100], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "mcts_rollout_amazon.Net.fc_classif", "mcts_rollout_amazon.Net.fc_txt1", "mcts_rollout_amazon.Net.fc_txt2", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "text", ")", ":", "\n", "        ", "text", "=", "F", ".", "relu", "(", "self", ".", "fc_txt1", "(", "text", ")", ")", "\n", "text", "=", "F", ".", "relu", "(", "self", ".", "fc_txt2", "(", "text", ")", ")", "\n", "text", "=", "self", ".", "fc_classif", "(", "text", ")", "\n", "return", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.__init__": [[281, 335], ["min", "numpy.zeros", "numpy.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.arange", "mcts_rollout_amazon.BatchedMCTS._reset_tree", "transformers.RepetitionPenaltyLogitsProcessor"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree"], ["    ", "def", "__init__", "(", "self", ",", "root_fun", ",", "rec_fun", ",", "batch_size", ",", "num_simulations", ",", "num_actions", ",", "num_sparse_actions", ",", "pb_c_init", ",", "temperature", ",", "alpha", ",", "penalty", ",", "rollout_size", ")", ":", "\n", "# Initialize parameters", "\n", "        ", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_num_simulations", "=", "num_simulations", "\n", "self", ".", "_num_actions", "=", "num_actions", "\n", "self", ".", "_num_sparse_actions", "=", "min", "(", "num_sparse_actions", ",", "num_actions", ")", "\n", "self", ".", "_pb_c_init", "=", "pb_c_init", "\n", "self", ".", "_temperature", "=", "temperature", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "rollout_size", "=", "rollout_size", "\n", "\n", "self", ".", "_root_fun", "=", "root_fun", "# a function called at the root", "\n", "self", ".", "_rec_fun", "=", "rec_fun", "# a function called in the tree", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_labels", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "args", ".", "device", ")", "\n", "self", ".", "_prompt_lengths", "=", "torch", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "args", ".", "device", ")", "\n", "\n", "# Allocate all necessary storage.", "\n", "# For a given search associated to a batch-index, node i is the i-th node", "\n", "# to be expanded. Node 0 corresponds to the root node.", "\n", "num_nodes", "=", "num_simulations", "+", "1", "\n", "batch_node", "=", "(", "batch_size", ",", "num_nodes", ")", "\n", "self", ".", "_num_nodes", "=", "num_nodes", "\n", "self", ".", "_visit_counts", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_likelihoods", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_raw_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# action_from_parents[b, i] is the action taken to reach node i.", "\n", "# Note that action_from_parents[b, 0] will remain -1, as we do not know,", "\n", "# when doing search from the root, what action led to the root.", "\n", "self", ".", "_action_from_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# The 0-indexed depth of the node. The root is the only 0-depth node.", "\n", "# The depth of node i, is the depth of its parent + 1.", "\n", "self", ".", "_depth", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_is_terminal", "=", "np", ".", "full", "(", "batch_node", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "\n", "# To avoid costly numpy ops, we store a sparse version of the actions.", "\n", "# We select the top k actions according to the policy, and keep a mapping", "\n", "# of indices from 0 to k-1 to the actual action indices in the", "\n", "# self._topk_mapping tensor.", "\n", "batch_node_action", "=", "(", "batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ")", "\n", "self", ".", "_topk_mapping", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_index", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_prior", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_values", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_visits", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_states", "=", "{", "}", "\n", "self", ".", "_token_ids", "=", "{", "}", "\n", "self", ".", "_attention_mask", "=", "{", "}", "\n", "self", ".", "_batch_range", "=", "np", ".", "arange", "(", "batch_size", ")", "\n", "self", ".", "_reset_tree", "(", ")", "\n", "self", ".", "_repetition_penalty", "=", "RepetitionPenaltyLogitsProcessor", "(", "penalty", "=", "penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS._reset_tree": [[336, 353], ["mcts_rollout_amazon.BatchedMCTS._visit_counts.fill", "mcts_rollout_amazon.BatchedMCTS._values.fill", "mcts_rollout_amazon.BatchedMCTS._likelihoods.fill", "mcts_rollout_amazon.BatchedMCTS._parents.fill", "mcts_rollout_amazon.BatchedMCTS._action_from_parents.fill", "mcts_rollout_amazon.BatchedMCTS._depth.fill", "mcts_rollout_amazon.BatchedMCTS._topk_mapping.fill", "mcts_rollout_amazon.BatchedMCTS._children_index.fill", "mcts_rollout_amazon.BatchedMCTS._children_prior.fill", "mcts_rollout_amazon.BatchedMCTS._children_values.fill", "mcts_rollout_amazon.BatchedMCTS._children_visits.fill"], "methods", ["None"], ["", "def", "_reset_tree", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the tree arrays.\"\"\"", "\n", "self", ".", "_visit_counts", ".", "fill", "(", "0", ")", "\n", "self", ".", "_values", ".", "fill", "(", "0", ")", "\n", "self", ".", "_likelihoods", ".", "fill", "(", "0", ")", "\n", "self", ".", "_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_action_from_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_depth", ".", "fill", "(", "0", ")", "\n", "\n", "self", ".", "_topk_mapping", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_index", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_prior", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_values", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_visits", ".", "fill", "(", "0", ")", "\n", "self", ".", "_states", "=", "{", "}", "\n", "self", ".", "_token_ids", "=", "{", "}", "# Indexed by tuples (batch index, node index)", "\n", "self", ".", "_attention_mask", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.set_labels": [[354, 356], ["None"], "methods", ["None"], ["", "def", "set_labels", "(", "self", ",", "labels", ")", ":", "\n", "        ", "self", ".", "_labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.set_prompt_lengths": [[357, 359], ["None"], "methods", ["None"], ["", "def", "set_prompt_lengths", "(", "self", ",", "lengths", ")", ":", "\n", "        ", "self", ".", "_prompt_lengths", "=", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.search": [[360, 389], ["mcts_rollout_amazon.BatchedMCTS._reset_tree", "mcts_rollout_amazon.BatchedMCTS._root_fun", "mcts_rollout_amazon.BatchedMCTS.create_node", "numpy.zeros", "range", "mcts_rollout_amazon.BatchedMCTS.dense_visit_counts", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "numpy.full", "mcts_rollout_amazon.BatchedMCTS.simulate", "mcts_rollout_amazon.BatchedMCTS.expand", "numpy.zeros.fill", "mcts_rollout_amazon.BatchedMCTS.backward", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "len", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.dense_visit_counts", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.simulate", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.backward"], ["", "def", "search", "(", "self", ",", "original_input", ")", ":", "\n", "        ", "self", ".", "_reset_tree", "(", ")", "\n", "\n", "prompt_masks", "=", "torch", ".", "arange", "(", "len", "(", "original_input", ".", "input_ids", "[", "0", "]", ")", ",", "device", "=", "\"cuda\"", ")", "[", "None", ",", ":", "]", "<", "torch", ".", "unsqueeze", "(", "torch", ".", "sum", "(", "original_input", ".", "attention_mask", "==", "0", ",", "dim", "=", "1", ")", ".", "add", "(", "self", ".", "_prompt_lengths", ")", "-", "1", ",", "1", ")", "\n", "\n", "# Evaluate the root.", "\n", "prior", ",", "values", ",", "states", "=", "self", ".", "_root_fun", "(", "original_input", ",", "prompt_masks", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ")", "\n", "\n", "\n", "self", ".", "_adaptive_min_values", "=", "values", "\n", "self", ".", "_adaptive_max_values", "=", "values", "+", "1e-6", "\n", "\n", "root_index", "=", "0", "\n", "self", ".", "create_node", "(", "root_index", ",", "prior", ",", "1", ",", "values", ",", "states", ",", "original_input", ".", "input_ids", ",", "original_input", ".", "attention_mask", ",", "np", ".", "full", "(", "self", ".", "_batch_size", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", ")", "\n", "\n", "\n", "\n", "\n", "# Do simulations, expansions, and backwards.", "\n", "leaf_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "for", "sim", "in", "range", "(", "self", ".", "_num_simulations", ")", ":", "\n", "            ", "node_indices", ",", "actions", "=", "self", ".", "simulate", "(", ")", "\n", "next_node_index", "=", "sim", "+", "1", "# root is 0, therefore we offset by 1.", "\n", "self", ".", "expand", "(", "node_indices", ",", "actions", ",", "next_node_index", ")", "\n", "leaf_indices", ".", "fill", "(", "next_node_index", ")", "\n", "self", ".", "backward", "(", "leaf_indices", ")", "\n", "\n", "# Final choice: most visited, max score, max mean score", "\n", "", "return", "self", ".", "dense_visit_counts", "(", ")", "\n", "# return self.dense_scores()", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.dense_visit_counts": [[392, 398], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_visit_counts", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_visit_counts", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_visit_counts", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_visit_counts", "\n", "return", "dense_visit_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.dense_scores": [[399, 406], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_root_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_root_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_scores", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "return", "dense_root_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.dense_mean_scores": [[407, 415], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_mean_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_mean_scores", "=", "root_scores", "/", "root_visit_counts", "\n", "dense_mean_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_mean_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_mean_scores", "\n", "return", "dense_mean_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.simulate": [[416, 429], ["numpy.zeros", "mcts_rollout_amazon.BatchedMCTS.uct_select_action", "is_unexplored.all", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.uct_select_action"], ["", "def", "simulate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Goes down until all elements have reached unexplored actions.\"\"\"", "\n", "node_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "depth", "=", "0", "\n", "while", "True", ":", "\n", "            ", "depth", "+=", "1", "\n", "actions", "=", "self", ".", "uct_select_action", "(", "node_indices", ")", "\n", "next_node_indices", "=", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "is_unexplored", "=", "next_node_indices", "==", "-", "1", "\n", "if", "is_unexplored", ".", "all", "(", ")", ":", "\n", "                ", "return", "node_indices", ",", "actions", "\n", "", "else", ":", "\n", "                ", "node_indices", "=", "np", ".", "where", "(", "is_unexplored", ",", "node_indices", ",", "next_node_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.uct_select_action": [[430, 446], ["numpy.argmax", "numpy.sqrt"], "methods", ["None"], ["", "", "", "def", "uct_select_action", "(", "self", ",", "node_indices", ")", ":", "\n", "        ", "\"\"\"Returns the action selected for a batch of node indices of shape (B).\"\"\"", "\n", "node_children_prior", "=", "self", ".", "_children_prior", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_values", "=", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_visits", "=", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_visits", "=", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "# (B)", "\n", "node_policy_score", "=", "np", ".", "sqrt", "(", "node_visits", "[", ":", ",", "None", "]", ")", "*", "self", ".", "_pb_c_init", "*", "node_children_prior", "/", "(", "node_children_visits", "+", "1", ")", "# (B, A)", "\n", "\n", "# Remap values between 0 and 1.", "\n", "node_value_score", "=", "node_children_values", "\n", "# node_value_score = (node_value_score != 0.) * node_value_score + (node_value_score == 0.) * self._adaptive_min_values[:, None]", "\n", "# node_value_score = (node_value_score - self._adaptive_min_values[:, None]) / (self._adaptive_max_values[:, None] - self._adaptive_min_values[:, None])", "\n", "\n", "node_uct_score", "=", "node_value_score", "+", "node_policy_score", "# (B, A)", "\n", "actions", "=", "np", ".", "argmax", "(", "node_uct_score", ",", "axis", "=", "1", ")", "\n", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.get_states_from_node": [[447, 458], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "get_states_from_node", "(", "self", ",", "b", ",", "n", ",", "d", ")", ":", "\n", "        ", "\"\"\"Forge state tensor by going backward from the node to the root (because we only store on token's part on each node to avoid duplication)\"\"\"", "\n", "state_array", "=", "[", "None", "]", "*", "d", "\n", "state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_states", "[", "(", "b", ",", "n", ")", "]", "\n", "while", "n", "!=", "0", ":", "\n", "            ", "n", "=", "self", ".", "_parents", "[", "(", "b", ",", "n", ")", "]", "\n", "d", "-=", "1", "\n", "state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_states", "[", "(", "b", ",", "n", ")", "]", "\n", "\n", "", "result", "=", "torch", ".", "cat", "(", "state_array", ",", "3", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.expand": [[459, 500], ["mcts_rollout_amazon.pad_sequences_to_left", "mcts_rollout_amazon.pad_sequences_to_left", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.array", "numpy.array", "mcts_rollout_amazon.pad_sequences_to_left_states", "tuple", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mcts_rollout_amazon.BatchedMCTS._rec_fun", "mcts_rollout_amazon.BatchedMCTS.create_node", "numpy.minimum", "numpy.maximum", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "mcts_rollout_amazon.BatchedMCTS.get_states_from_node", "len", "tuple", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "depths[].item", "enumerate", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "torch.sum().add", "len", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left_states", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.get_states_from_node"], ["", "def", "expand", "(", "self", ",", "node_indices", ",", "actions", ",", "next_node_index", ")", ":", "\n", "        ", "\"\"\"Creates and evaluate child nodes from given nodes and unexplored actions.\"\"\"", "\n", "\n", "# Retrieve token ids for nodes to be evaluated.", "\n", "tokens_ids", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_token_ids", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "eos_token_id", ")", "\n", "attention_masks", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_attention_mask", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "0", ")", "\n", "depths", "=", "torch", ".", "tensor", "(", "[", "self", ".", "_depth", "[", "(", "b", ",", "n", ")", "]", "+", "1", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "device", "=", "args", ".", "device", ")", "\n", "children_priors", "=", "np", ".", "array", "(", "[", "self", ".", "_children_prior", "[", "(", "b", ",", "n", ")", "]", "[", "actions", "[", "b", "]", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "likelihoods", "=", "np", ".", "array", "(", "[", "self", ".", "_likelihoods", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "previous_node_is_terminal", "=", "self", ".", "_is_terminal", "[", "self", ".", "_batch_range", ",", "node_indices", "[", "self", ".", "_batch_range", "]", "]", "# (B)", "\n", "\n", "states_tensor", "=", "pad_sequences_to_left_states", "(", "[", "self", ".", "get_states_from_node", "(", "b", ",", "n", ",", "depths", "[", "b", "]", ".", "item", "(", ")", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "0", ",", "max_len", "=", "len", "(", "tokens_ids", "[", "0", "]", ")", ")", "\n", "states", "=", "tuple", "(", "tuple", "(", "type_of_value", "for", "type_of_value", "in", "layer", ")", "for", "layer", "in", "states_tensor", ")", "\n", "\n", "# Convert sparse actions to dense actions for network computation", "\n", "dense_actions", "=", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "# Add actions to list of tokens and extend attention mask by 1", "\n", "tokens_ids", "=", "torch", ".", "cat", "(", "(", "tokens_ids", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "cuda", ".", "LongTensor", "(", "dense_actions", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "attention_masks", "=", "torch", ".", "cat", "(", "(", "attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "dense_actions", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "args", ".", "device", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "prompt_masks", "=", "torch", ".", "arange", "(", "len", "(", "tokens_ids", "[", "0", "]", ")", ",", "device", "=", "\"cuda\"", ")", "[", "None", ",", ":", "]", "<", "torch", ".", "unsqueeze", "(", "torch", ".", "sum", "(", "attention_masks", "==", "0", ",", "dim", "=", "1", ")", ".", "add", "(", "self", ".", "_prompt_lengths", ")", "-", "1", ",", "1", ")", "\n", "\n", "# Check if expanded nodes are terminal ", "\n", "expanded_node_is_terminal", "=", "dense_actions", "==", "eos_token_id", "\n", "\n", "# Evaluate nodes.", "\n", "(", "prior", ",", "values", ",", "next_states", ")", "=", "self", ".", "_rec_fun", "(", "states", ",", "tokens_ids", ",", "attention_masks", ",", "prompt_masks", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ",", "self", ".", "rollout_size", ")", "\n", "\n", "# Create the new nodes.", "\n", "self", ".", "create_node", "(", "next_node_index", ",", "prior", ",", "likelihoods", "*", "children_priors", ",", "values", ",", "next_states", ",", "tokens_ids", ",", "attention_masks", ",", "expanded_node_is_terminal", ")", "\n", "\n", "# Update the min and max values arrays", "\n", "# self._adaptive_min_values = np.minimum(self._adaptive_min_values, values**(self.alpha) * (likelihoods*children_priors)**(1-self.alpha))", "\n", "# self._adaptive_max_values = np.maximum(self._adaptive_max_values, values**(self.alpha) * (likelihoods*children_priors)**(1-self.alpha))", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "minimum", "(", "self", ".", "_adaptive_min_values", ",", "values", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "maximum", "(", "self", ".", "_adaptive_max_values", ",", "values", ")", "\n", "\n", "# Update tree topology.", "\n", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "=", "next_node_index", "\n", "self", ".", "_parents", "[", ":", ",", "next_node_index", "]", "=", "node_indices", "\n", "self", ".", "_action_from_parents", "[", ":", ",", "next_node_index", "]", "=", "actions", "\n", "self", ".", "_depth", "[", ":", ",", "next_node_index", "]", "=", "self", ".", "_depth", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.create_node": [[501, 537], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "enumerate", "enumerate", "numpy.argpartition", "list", "range", "range", "len", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "len", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "list", "range", "len"], "methods", ["None"], ["", "def", "create_node", "(", "self", ",", "node_index", ",", "prior", ",", "likelihoods", ",", "values", ",", "next_states", ",", "tokens_ids", ",", "attention_masks", ",", "expanded_node_is_terminal", ")", ":", "\n", "        ", "\"\"\"Create nodes with computed values\"\"\"", "\n", "# Truncate the prior to only keep the top k logits", "\n", "prior_topk_indices", "=", "np", ".", "argpartition", "(", "prior", ",", "-", "self", ".", "_num_sparse_actions", ",", "axis", "=", "-", "1", ")", "[", ":", ",", "-", "self", ".", "_num_sparse_actions", ":", "]", "\n", "prior", "=", "prior", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "prior_topk_indices", "]", "# (B, A)", "\n", "\n", "# Store the indices of the top k logits", "\n", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_index", ",", ":", "]", "=", "prior_topk_indices", "\n", "\n", "# Update prior, values and visit counts.", "\n", "self", ".", "_children_prior", "[", ":", ",", "node_index", ",", ":", "]", "=", "prior", "\n", "self", ".", "_likelihoods", "[", ":", ",", "node_index", "]", "=", "likelihoods", "\n", "\n", "raw_values", "=", "values", "**", "(", "self", ".", "alpha", ")", "*", "likelihoods", "**", "(", "1", "-", "self", ".", "alpha", ")", "\n", "# raw_values = values", "\n", "self", ".", "_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_raw_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_visit_counts", "[", ":", ",", "node_index", "]", "=", "1", "\n", "self", ".", "_is_terminal", "[", ":", ",", "node_index", "]", "=", "expanded_node_is_terminal", "\n", "\n", "# Transform the returned states format into tensor for easier manipulation", "\n", "key_value_tensor", "=", "torch", ".", "stack", "(", "list", "(", "torch", ".", "stack", "(", "list", "(", "next_states", "[", "i", "]", ")", ",", "dim", "=", "0", ")", "for", "i", "in", "range", "(", "len", "(", "next_states", ")", ")", ")", ",", "dim", "=", "0", ")", "\n", "if", "(", "node_index", "==", "0", ")", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "tokens_ids", ")", ")", ":", "\n", "                ", "self", ".", "_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "key_value_tensor", "[", ":", ",", ":", ",", "b", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "tokens_ids", ")", ")", ":", "\n", "                ", "self", ".", "_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "key_value_tensor", "[", ":", ",", ":", ",", "b", ",", ":", ",", "-", "1", ":", "]", ")", "\n", "\n", "# Updates tokens ids", "\n", "", "", "for", "b", ",", "token_ids", "in", "enumerate", "(", "tokens_ids", ")", ":", "\n", "            ", "self", ".", "_token_ids", "[", "(", "b", ",", "node_index", ")", "]", "=", "token_ids", "\n", "\n", "# Updates attention masks", "\n", "", "for", "b", ",", "attention_mask", "in", "enumerate", "(", "attention_masks", ")", ":", "\n", "            ", "self", ".", "_attention_mask", "[", "(", "b", ",", "node_index", ")", "]", "=", "attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.backward": [[539, 565], ["is_root.all", "numpy.where", "numpy.where"], "methods", ["None"], ["", "", "def", "backward", "(", "self", ",", "leaf_indices", ")", ":", "\n", "        ", "\"\"\"Goes up and updates the tree until all nodes reached the root.\"\"\"", "\n", "node_indices", "=", "leaf_indices", "# (B)", "\n", "leaf_values", "=", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "leaf_indices", "]", "\n", "while", "True", ":", "\n", "            ", "is_root", "=", "node_indices", "==", "0", "\n", "if", "is_root", ".", "all", "(", ")", ":", "\n", "                ", "return", "\n", "", "parents", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "root_mask", "=", "1.0", "*", "is_root", "\n", "not_root_mask_int", "=", "(", "1", "-", "is_root", ")", "\n", "not_root_mask", "=", "1.0", "-", "root_mask", "\n", "# Update the parent nodes iff their child is not the root.", "\n", "# We therefore mask the updates using not_root_mask and root_mask.", "\n", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "=", "not_root_mask", "*", "(", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "*", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+", "leaf_values", ")", "/", "(", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "\n", "parents", "]", "+", "1.0", ")", "+", "root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "\n", "\n", "# self._values[self._batch_range, parents] = not_root_mask * (np.maximum(self._values[self._batch_range, parents],leaf_values)) + root_mask * self._values[self._batch_range, parents]", "\n", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+=", "not_root_mask_int", "\n", "actions", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_action_from_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "=", "not_root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "root_mask", "*", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "\n", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "+=", "not_root_mask_int", "\n", "# Go up", "\n", "node_indices", "=", "parents", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.set_seed": [[137, 142], ["numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "", "", "set_seed", "(", "args", ")", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.get_values": [[151, 162], ["tokenizer_gpt.batch_decode", "bert_tokenizer.batch_encode_plus", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.no_grad", "torch.no_grad", "torch.no_grad", "bert", "torch.normalize", "net", "torch.div", "torch.div", "torch.div", "torch.sum", "torch.sum", "torch.sum", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.sum", "torch.sum", "torch.sum"], "function", ["None"], ["", "def", "get_values", "(", "tokens_ids", ",", "labels", ")", ":", "\n", "    ", "\"\"\"Gets sequence scores from the discriminator\"\"\"", "\n", "propositions", "=", "tokenizer_gpt", ".", "batch_decode", "(", "tokens_ids", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "tokenizer_res", "=", "bert_tokenizer", ".", "batch_encode_plus", "(", "propositions", ",", "truncation", "=", "True", ",", "padding", "=", "True", ",", "max_length", "=", "512", ")", "\n", "tokens_tensor", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "tokenizer_res", "[", "'input_ids'", "]", ")", "\n", "attention_tensor", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "tokenizer_res", "[", "'attention_mask'", "]", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "output", "=", "bert", "(", "tokens_tensor", ",", "attention_mask", "=", "attention_tensor", ")", "\n", "embeddings_tensor", "=", "F", ".", "normalize", "(", "torch", ".", "div", "(", "torch", ".", "sum", "(", "output", "[", "2", "]", "[", "-", "1", "]", ",", "axis", "=", "1", ")", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "sum", "(", "attention_tensor", ",", "axis", "=", "1", ")", ",", "1", ")", ")", ")", "\n", "outputs", "=", "net", "(", "embeddings_tensor", ")", "\n", "", "return", "outputs", "[", "labels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.pad_sequences_to_left": [[163, 185], ["sequences[].size", "max", "sequences[].new_full", "enumerate", "tensor.size", "s.size", "len", "len"], "function", ["None"], ["", "def", "pad_sequences_to_left", "(", "sequences", ",", "batch_first", "=", "False", ",", "padding_value", "=", "0", ")", ":", "\n", "    ", "\"\"\"Add left padding so sequences have same shape\"\"\"", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "max_len", "=", "max", "(", "[", "s", ".", "size", "(", "0", ")", "for", "s", "in", "sequences", "]", ")", "\n", "if", "batch_first", ":", "\n", "        ", "out_dims", "=", "(", "len", "(", "sequences", ")", ",", "max_len", ")", "+", "trailing_dims", "\n", "", "else", ":", "\n", "        ", "out_dims", "=", "(", "max_len", ",", "len", "(", "sequences", ")", ")", "+", "trailing_dims", "\n", "\n", "", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# use index notation to prevent duplicate references to the tensor", "\n", "if", "batch_first", ":", "\n", "            ", "out_tensor", "[", "i", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "else", ":", "\n", "            ", "out_tensor", "[", "max_len", "-", "length", ":", ",", "i", ",", "...", "]", "=", "tensor", "\n", "", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.pad_sequences_to_left_states": [[188, 202], ["sequences[].size", "sequences[].new_full", "enumerate", "len", "tensor.size"], "function", ["None"], ["", "def", "pad_sequences_to_left_states", "(", "sequences", ",", "padding_value", "=", "0", ",", "max_len", "=", "0", ")", ":", "\n", "    ", "\"\"\"Similar to pad_sequences_to_left function, but working on states tensor (in order to forge state for \"sequential generation\")\"\"\"", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "out_dims", "=", "(", "max_size", "[", "0", "]", ",", "max_size", "[", "1", "]", ",", "len", "(", "sequences", ")", ",", "max_size", "[", "2", "]", ",", "max_len", ",", "max_size", "[", "4", "]", ")", "\n", "# print(out_dims)", "\n", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ",", "device", "=", "args", ".", "device", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", ")", "[", "3", "]", "\n", "out_tensor", "[", ":", ",", ":", ",", "i", ",", ":", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.root_fun": [[204, 227], ["gpt.prepare_inputs_for_generation", "get_values().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gpt", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax().cpu().numpy", "get_values().cpu", "torch.softmax().cpu", "mcts_rollout_amazon.get_values", "torch.softmax"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.get_values"], ["", "def", "root_fun", "(", "original_input", ",", "prompt_masks", ",", "labels", ",", "temperature", ",", "repetition_penalty", ")", ":", "\n", "    ", "\"\"\"Initialize roots scores\"\"\"", "\n", "# Forward pass of GPT-2 to get priors and states", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "original_input", ".", "input_ids", ",", "attention_mask", "=", "original_input", ".", "attention_mask", ",", "use_cache", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "gpt", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "states", "=", "outputs", ".", "past_key_values", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "model_inputs", "[", "\"input_ids\"", "]", ")", "\n", "prompt_masked_input_ids", "[", "prompt_masks", "]", "=", "14827", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Use of our discriminator to get values", "\n", "", "values", "=", "get_values", "(", "original_input", ".", "input_ids", ",", "labels", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "return", "priors", ",", "values", ",", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.rec_fun": [[229, 277], ["gpt.prepare_inputs_for_generation", "get_values().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gpt", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax", "F.softmax.cpu().numpy", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gpt.prepare_inputs_for_generation", "range", "get_values().cpu", "torch.argmax", "torch.argmax", "torch.argmax", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gpt.prepare_inputs_for_generation", "F.softmax.cpu", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gpt", "mcts_rollout_amazon.get_values", "torch.ones", "torch.ones", "torch.ones", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "len", "torch.ones", "torch.ones", "torch.ones", "len"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.get_values"], ["", "def", "rec_fun", "(", "states", ",", "token_ids", ",", "attention_masks", ",", "prompt_masks", ",", "labels", ",", "temperature", ",", "repetition_penalty", ",", "rollout_size", ")", ":", "\n", "    ", "\"\"\"Get score from current nodes\"\"\"", "\n", "# Forward pass of GPT-2 to get priors and states", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ",", "use_cache", "=", "True", ",", "past", "=", "states", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "gpt", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "\n", "next_states", "=", "outputs", ".", "past_key_values", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "token_ids", ")", "\n", "#penalizing an unused token", "\n", "prompt_masked_input_ids", "[", "prompt_masks", "]", "=", "14827", "\n", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", "\n", "if", "(", "rollout_size", ">", "0", ")", ":", "\n", "# next_tokens = torch.multinomial(priors, num_samples=1)", "\n", "            ", "next_tokens", "=", "torch", ".", "unsqueeze", "(", "torch", ".", "argmax", "(", "priors", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "1", ")", "\n", "token_ids", "=", "torch", ".", "cat", "(", "(", "token_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "attention_masks", "=", "torch", ".", "cat", "(", "(", "attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "attention_masks", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "args", ".", "device", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "prompt_masked_input_ids", "=", "torch", ".", "cat", "(", "(", "prompt_masked_input_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ",", "use_cache", "=", "True", ",", "past", "=", "outputs", ".", "past_key_values", ")", "\n", "for", "i", "in", "range", "(", "rollout_size", ")", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "outputs", "=", "gpt", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "# next_tokens = torch.unsqueeze(torch.argmax(F.softmax(repetition_penalty(prompt_masked_input_ids, outputs.logits[:, -1, :] / temperature), dim=-1), dim=-1), dim=1)", "\n", "", "next_tokens", "=", "torch", ".", "multinomial", "(", "priors", ",", "num_samples", "=", "1", ")", "\n", "token_ids", "=", "torch", ".", "cat", "(", "(", "token_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "attention_masks", "=", "torch", ".", "cat", "(", "(", "attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "attention_masks", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "args", ".", "device", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "cat", "(", "(", "prompt_masked_input_ids", ",", "next_tokens", ")", ",", "dim", "=", "1", ")", "\n", "model_inputs", "=", "gpt", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ",", "use_cache", "=", "True", ",", "past", "=", "outputs", ".", "past_key_values", ")", "\n", "\n", "\n", "# Use of our discriminator to get values", "\n", "", "", "", "values", "=", "get_values", "(", "token_ids", ",", "labels", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "return", "priors", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "values", ",", "next_states", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.main": [[566, 606], ["print", "pandas.read_csv", "print", "torch.zeros", "torch.zeros", "torch.zeros", "mcts_rollout_amazon.BatchedMCTS", "tqdm.tqdm", "torch.zeros.fill_", "enumerate", "tokenizer_gpt().to", "mcts_rollout_amazon.BatchedMCTS.set_labels", "mcts_rollout_amazon.BatchedMCTS.set_prompt_lengths", "tqdm.tqdm", "range", "tokenizer_gpt.batch_decode", "tqdm.tqdm.update", "lines.iterrows", "torch.sum", "torch.sum", "torch.sum", "mcts_rollout_amazon.BatchedMCTS.search", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "print", "tqdm.tqdm.update", "text.split", "logging.warning", "tokenizer_gpt", "tokenizer_gpt.decode", "str", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "int", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.ones", "torch.ones", "torch.ones", "numpy.argmax", "split[].replace", "split[].split"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.set_labels", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.BatchedMCTS.set_prompt_lengths", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.search"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"loading dataset\"", ")", "\n", "data_lines", "=", "pd", ".", "read_csv", "(", "\"../datasets/amazon_polarity/full/dataset_test_2.tsv\"", ",", "sep", "=", "'\\t'", ",", "engine", "=", "'python'", ",", "encoding", "=", "\"utf8\"", ")", "\n", "print", "(", "\"dataset loaded\"", ")", "\n", "generated_counter", "=", "750", "\n", "samples_size", "=", "1040", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "labels", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "args", ".", "device", ")", "\n", "prompt_texts", "=", "[", "None", "]", "*", "batch_size", "\n", "MCTS", "=", "BatchedMCTS", "(", "root_fun", ",", "rec_fun", ",", "batch_size", "=", "batch_size", ",", "num_simulations", "=", "args", ".", "num_it", ",", "num_actions", "=", "vocab_size", "+", "1", ",", "num_sparse_actions", "=", "50", ",", "pb_c_init", "=", "args", ".", "c", ",", "temperature", "=", "args", ".", "temperature", ",", "alpha", "=", "args", ".", "alpha", ",", "penalty", "=", "args", ".", "penalty", ",", "rollout_size", "=", "args", ".", "rollout_size", ")", "\n", "samples_pbar", "=", "tqdm", "(", "total", "=", "samples_size", ",", "desc", "=", "\"Samples generated\"", ")", "\n", "while", "(", "generated_counter", "+", "batch_size", "<=", "samples_size", ")", ":", "\n", "        ", "labels", ".", "fill_", "(", "0", ")", "\n", "# Prepare search inputs", "\n", "lines", "=", "data_lines", "[", "generated_counter", ":", "generated_counter", "+", "batch_size", "]", "\n", "\n", "for", "i", ",", "(", "_", ",", "row", ")", "in", "enumerate", "(", "lines", ".", "iterrows", "(", ")", ")", ":", "\n", "            ", "labels", "[", "i", ",", "int", "(", "row", "[", "\"label\"", "]", ")", "]", "=", "1", "\n", "prompt_texts", "[", "i", "]", "=", "\"<|startoftext|> \"", "+", "str", "(", "row", "[", "\"title\"", "]", ")", "+", "\" [SEP] \"", "\n", "\n", "", "original_input", "=", "tokenizer_gpt", "(", "prompt_texts", ",", "return_tensors", "=", "\"pt\"", ",", "padding", "=", "True", ",", "add_special_tokens", "=", "False", ",", "max_length", "=", "512", ",", "truncation", "=", "True", ")", ".", "to", "(", "args", ".", "device", ")", "\n", "MCTS", ".", "set_labels", "(", "labels", ")", "\n", "MCTS", ".", "set_prompt_lengths", "(", "torch", ".", "sum", "(", "original_input", ".", "attention_mask", ",", "dim", "=", "1", ")", ")", "\n", "\n", "tokens_pbar", "=", "tqdm", "(", "total", "=", "98", ",", "desc", "=", "\"Tokens generated\"", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "98", ")", ":", "\n", "            ", "res_search", "=", "MCTS", ".", "search", "(", "original_input", ")", "\n", "original_input", ".", "input_ids", "=", "torch", ".", "cat", "(", "(", "original_input", ".", "input_ids", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "cuda", ".", "LongTensor", "(", "np", ".", "argmax", "(", "res_search", ",", "axis", "=", "1", ")", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "original_input", ".", "attention_mask", "=", "torch", ".", "cat", "(", "(", "original_input", ".", "attention_mask", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "args", ".", "device", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "prompt_texts", "=", "[", "tokenizer_gpt", ".", "decode", "(", "token_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", "for", "token_ids", "in", "original_input", ".", "input_ids", "]", "\n", "print", "(", "prompt_texts", ")", "\n", "\n", "tokens_pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "final_texts", "=", "tokenizer_gpt", ".", "batch_decode", "(", "original_input", ".", "input_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "for", "text", "in", "final_texts", ":", "\n", "            ", "split", "=", "text", ".", "split", "(", "\"[SEP]\"", ")", "\n", "logging", ".", "warning", "(", "split", "[", "0", "]", ".", "replace", "(", "\"<|endoftext|>\"", ",", "\"\"", ")", "+", "\"[SEP]\"", "+", "split", "[", "1", "]", ".", "split", "(", "\"<|endoftext|>\"", ")", "[", "0", "]", "+", "\"<|endoftext|>\"", ")", "\n", "", "generated_counter", "+=", "batch_size", "\n", "samples_pbar", ".", "update", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_bidi_ag.DataTrainingArguments.__post_init__": [[107, 117], ["ValueError", "classifier_bidi_ag.DataTrainingArguments.train_file.split", "classifier_bidi_ag.DataTrainingArguments.validation_file.split"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_name", "is", "None", "and", "self", ".", "train_file", "is", "None", "and", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a dataset name or a training/validation file.\"", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "train_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`train_file` should be a csv, a json or a txt file.\"", "\n", "", "if", "self", ".", "validation_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`validation_file` should be a csv, a json or a txt file.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_bidi_ag.Net.__init__": [[121, 127], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "config", ".", "output_hidden_states", "=", "True", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", "=", "config", ")", "\n", "# Classification layer from (hidden_states, num_classes)", "\n", "self", ".", "fc_classif", "=", "nn", ".", "Linear", "(", "768", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_bidi_ag.Net.forward": [[128, 151], ["classifier_bidi_ag.Net.bert", "classifier_bidi_ag.Net.fc_classif", "loss_fct", "transformers.modeling_outputs.SequenceClassifierOutput", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "[].size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "# Get mean of hidden states", "\n", "# text = F.normalize(torch.div(torch.sum(outputs[2][-1], axis=1),torch.unsqueeze(torch.sum(attention_mask, axis=1),1)))", "\n", "#\u00a0Get last (non padding) token hidden_states ", "\n", "text", "=", "outputs", "[", "2", "]", "[", "-", "1", "]", "[", "torch", ".", "arange", "(", "outputs", "[", "2", "]", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ",", "torch", ".", "sum", "(", "attention_mask", ",", "axis", "=", "1", ")", "-", "1", "]", "\n", "logits", "=", "self", ".", "fc_classif", "(", "text", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "return", "SequenceClassifierOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "logits", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_bidi_ag.main": [[153, 381], ["transformers.HfArgumentParser", "logging.basicConfig", "logger.setLevel", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "Net.from_pretrained.cuda", "datasets.load_dataset.map", "ClassificationLossTrainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "transformers.utils.logging.set_verbosity_info", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "datasets.load_dataset", "datasets.load_dataset", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "Net.from_pretrained", "AutoTokenizer.from_pretrained.", "print", "ClassificationLossTrainer.train", "ClassificationLossTrainer.save_model", "os.path.join", "ClassificationLossTrainer.is_world_process_zero", "logger.info", "ClassificationLossTrainer.evaluate", "os.path.join", "ClassificationLossTrainer.is_world_process_zero", "len", "ValueError", "transformers.trainer_utils.is_main_process", "datasets.load_dataset.keys", "datasets.load_dataset", "datasets.load_dataset", "data_args.train_file.split", "transformers.AutoConfig.from_pretrained", "logger.warning", "transformers.AutoTokenizer.from_pretrained", "ValueError", "torch.max", "torch.max", "torch.max", "random.randint", "classifier_bidi_ag.._prepare_inputs", "ClassificationLossTrainer.state.save_to_json", "os.path.abspath", "len", "logger.info", "logging.StreamHandler", "bool", "torch.sum", "torch.sum", "torch.sum", "Net.from_pretrained.", "Net.from_pretrained.", "torch.no_grad", "torch.no_grad", "torch.no_grad", "classifier_bidi_ag..compute_loss", "os.path.isdir", "open", "logger.info", "sorted", "os.path.join", "open", "logger.info", "sorted", "os.listdir", "bool", "torch.sum", "torch.sum", "torch.sum", "len", "trainer.train.metrics.items", "logger.info", "writer.write", "results.items", "logger.info", "writer.write", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.softmax", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.set_seed"], ["", "", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Setup logging", "\n", "", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", "else", "logging", ".", "WARN", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)", "\n", "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/", "\n", "# (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files, this script will use the column called 'text' or the first column if no column called", "\n", "# 'text' is found. You can easily tweak this behavior (see below).", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "if", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "datasets", "=", "load_dataset", "(", "data_args", ".", "dataset_name", ",", "data_args", ".", "dataset_config_name", ")", "\n", "if", "\"validation\"", "not", "in", "datasets", ".", "keys", "(", ")", ":", "\n", "            ", "datasets", "[", "\"validation\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[:{data_args.validation_split_percentage}%]\"", ",", "\n", ")", "\n", "datasets", "[", "\"train\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[{data_args.validation_split_percentage}%:]\"", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"train\"", "]", "=", "data_args", ".", "train_file", "\n", "", "if", "data_args", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"validation\"", "]", "=", "data_args", ".", "validation_file", "\n", "", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "if", "extension", "==", "\"txt\"", ":", "\n", "            ", "extension", "=", "\"text\"", "\n", "", "datasets", "=", "load_dataset", "(", "extension", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "'./.cache'", ")", "\n", "# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "\n", "", "config_kwargs", "=", "{", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "}", "\n", "if", "model_args", ".", "config_name", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "config_name", ",", "**", "config_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "config_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "CONFIG_MAPPING", "[", "model_args", ".", "model_type", "]", "(", ")", "\n", "logger", ".", "warning", "(", "\"You are instantiating a new config instance from scratch.\"", ")", "\n", "\n", "", "tokenizer_kwargs", "=", "{", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"use_fast\"", ":", "model_args", ".", "use_fast_tokenizer", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "}", "\n", "if", "model_args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "tokenizer_name", ",", "**", "tokenizer_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "tokenizer_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"", "\n", "\"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"", "\n", ")", "\n", "\n", "\n", "", "if", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "Net", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "", "model", "=", "model", ".", "cuda", "(", ")", "\n", "# Preprocessing the datasets.", "\n", "# First we tokenize all the texts.", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"train\"", "]", ".", "column_names", "\n", "", "else", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"validation\"", "]", ".", "column_names", "\n", "", "text_column_name", "=", "\"text\"", "if", "\"text\"", "in", "column_names", "else", "column_names", "[", "-", "1", "]", "\n", "\n", "def", "tokenize_function", "(", "examples", ")", ":", "\n", "# res = {}", "\n", "        ", "inputs", "=", "[", "\"[CLS] \"", "+", "example", "+", "\"[PAD]\"", "for", "example", "in", "examples", "[", "\"text\"", "]", "]", "\n", "res", "=", "tokenizer", "(", "inputs", ",", "padding", "=", "\"max_length\"", ",", "max_length", "=", "512", ",", "truncation", "=", "True", ",", "add_special_tokens", "=", "False", ")", "\n", "res", "[", "\"labels\"", "]", "=", "examples", "[", "\"label\"", "]", "\n", "return", "res", "\n", "\n", "", "tokenized_datasets", "=", "datasets", ".", "map", "(", "\n", "tokenize_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "class", "ClassificationLossTrainer", "(", "Trainer", ")", ":", "\n", "        ", "def", "compute_loss", "(", "self", ",", "model", ",", "inputs", ",", "return_outputs", "=", "False", ",", "is_eval", "=", "False", ")", ":", "\n", "            ", "max_len", "=", "torch", ".", "max", "(", "torch", ".", "sum", "(", "inputs", "[", "\"attention_mask\"", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "# Sample how many token we keep to do training on variable length (at least one, up to full sequences)", "\n", "random_len", "=", "randint", "(", "1", ",", "max_len", ")", "\n", "if", "(", "is_eval", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "inputs", "[", "\"input_ids\"", "]", ",", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", ",", "labels", "=", "inputs", "[", "\"labels\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "model", "(", "inputs", "[", "\"input_ids\"", "]", "[", ":", ",", ":", "random_len", "]", ",", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", "[", ":", ",", ":", "random_len", "]", ",", "labels", "=", "inputs", "[", "\"labels\"", "]", ")", "\n", "\n", "", "return", "(", "outputs", "[", "\"loss\"", "]", ",", "outputs", ")", "if", "return_outputs", "else", "outputs", "[", "\"loss\"", "]", "\n", "", "def", "prediction_step", "(", "self", ",", "model", ",", "inputs", ",", "prediction_loss_only", ",", "ignore_keys", ")", ":", "\n", "            ", "inputs", "=", "self", ".", "_prepare_inputs", "(", "inputs", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "loss", ",", "outputs", "=", "self", ".", "compute_loss", "(", "model", ",", "inputs", ",", "return_outputs", "=", "True", ",", "is_eval", "=", "True", ")", "\n", "", "return", "(", "loss", ",", "outputs", "[", "\"logits\"", "]", ",", "inputs", "[", "\"labels\"", "]", ")", "\n", "\n", "\n", "", "", "def", "compute_metrics", "(", "eval_pred", ")", ":", "\n", "        ", "print", "(", "eval_pred", ")", "\n", "predictions", ",", "labels", "=", "eval_pred", "\n", "res", "=", "{", "}", "\n", "res", "[", "\"accuracy\"", "]", "=", "(", "torch", ".", "sum", "(", "torch", ".", "argmax", "(", "F", ".", "softmax", "(", "torch", ".", "tensor", "(", "predictions", ")", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "==", "torch", ".", "tensor", "(", "labels", ")", ")", "/", "len", "(", "labels", ")", ")", ".", "item", "(", ")", "\n", "return", "res", "\n", "\n", "", "trainer", "=", "ClassificationLossTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "tokenized_datasets", "[", "\"train\"", "]", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "tokenized_datasets", "[", "\"validation\"", "]", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "# tokenizer=tokenizer,", "\n", "# Data collator will default to DataCollatorWithPadding, so we change it.", "\n", "data_collator", "=", "default_data_collator", ",", "\n", "compute_metrics", "=", "compute_metrics", "\n", ")", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "model_path", "=", "last_checkpoint", "\n", "", "elif", "model_args", ".", "model_name_or_path", "is", "not", "None", "and", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", ":", "\n", "            ", "model_path", "=", "model_args", ".", "model_name_or_path", "\n", "", "else", ":", "\n", "            ", "model_path", "=", "None", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "model_path", "=", "model_path", ")", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "output_train_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"train_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_train_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Train results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "train_result", ".", "metrics", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "# Need to save the state, since Trainer.save_model saves only the tokenizer with the model", "\n", "", "", "trainer", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "", "results", "=", "{", "}", "\n", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "eval_output", "=", "trainer", ".", "evaluate", "(", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"eval_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "results", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.Net.__init__": [[90, 95], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", "=", "config", ")", "\n", "# Classification layer from (hidden_states, num_classes)", "\n", "self", ".", "fc_classif", "=", "nn", ".", "Linear", "(", "768", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.Net.forward": [[96, 105], ["lm.prepare_inputs_for_generation", "mcts_ag_bert_bidi.Net.fc_classif", "[].cpu", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "mcts_ag_bert_bidi.Net.bert", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "token_ids", ",", "attention_masks", ",", "labels", ")", ":", "\n", "\n", "        ", "model_inputs", "=", "lm", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output", "=", "self", ".", "bert", "(", "**", "model_inputs", ",", "return_dict", "=", "True", ")", "\n", "# text = output[2][-1][torch.arange(output[2][-1].size(0)), torch.sum(attention_masks, axis=1)-1]", "\n", "", "text", "=", "output", "[", "2", "]", "[", "-", "1", "]", "[", ":", ",", "-", "1", "]", "\n", "text", "=", "self", ".", "fc_classif", "(", "text", ")", "\n", "return", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "text", ")", "[", "labels", "]", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.__init__": [[217, 268], ["min", "numpy.zeros", "numpy.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.arange", "mcts_ag_bert_bidi.NumpyMCTS._reset_tree", "transformers.RepetitionPenaltyLogitsProcessor"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree"], ["    ", "def", "__init__", "(", "self", ",", "root_fun", ",", "rec_fun", ",", "batch_size", ",", "num_simulations", ",", "num_actions", ",", "num_sparse_actions", ",", "pb_c_init", ",", "temperature", ",", "alpha", ",", "penalty", ")", ":", "\n", "        ", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_num_simulations", "=", "num_simulations", "\n", "self", ".", "_num_actions", "=", "num_actions", "\n", "self", ".", "_num_sparse_actions", "=", "min", "(", "num_sparse_actions", ",", "num_actions", ")", "\n", "self", ".", "_pb_c_init", "=", "pb_c_init", "\n", "self", ".", "_temperature", "=", "temperature", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n", "self", ".", "_root_fun", "=", "root_fun", "# a function called at the root", "\n", "self", ".", "_rec_fun", "=", "rec_fun", "# a function called in the tree", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_labels", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "4", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "\"cuda\"", ")", "\n", "\n", "# Allocate all necessary storage.", "\n", "# For a given search associated to a batch-index, node i is the i-th node", "\n", "# to be expanded. Node 0 corresponds to the root node.", "\n", "num_nodes", "=", "num_simulations", "+", "1", "\n", "batch_node", "=", "(", "batch_size", ",", "num_nodes", ")", "\n", "self", ".", "_num_nodes", "=", "num_nodes", "\n", "self", ".", "_visit_counts", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_likelihoods", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_raw_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# action_from_parents[b, i] is the action taken to reach node i.", "\n", "# Note that action_from_parents[b, 0] will remain -1, as we do not know,", "\n", "# when doing search from the root, what action led to the root.", "\n", "self", ".", "_action_from_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# The 0-indexed depth of the node. The root is the only 0-depth node.", "\n", "# The depth of node i, is the depth of its parent + 1.", "\n", "self", ".", "_depth", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_is_terminal", "=", "np", ".", "full", "(", "batch_node", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "\n", "# To avoid costly numpy ops, we store a sparse version of the actions.", "\n", "# We select the top k actions according to the policy, and keep a mapping", "\n", "# of indices from 0 to k-1 to the actual action indices in the", "\n", "# self._topk_mapping tensor.", "\n", "batch_node_action", "=", "(", "batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ")", "# (B, )", "\n", "self", ".", "_topk_mapping", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_index", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_prior", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_values", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_visits", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_original_states", "=", "{", "}", "\n", "self", ".", "_original_token_ids", "=", "{", "}", "\n", "self", ".", "_original_attention_mask", "=", "{", "}", "\n", "self", ".", "_batch_range", "=", "np", ".", "arange", "(", "batch_size", ")", "\n", "self", ".", "_reset_tree", "(", ")", "\n", "self", ".", "_repetition_penalty", "=", "RepetitionPenaltyLogitsProcessor", "(", "penalty", "=", "penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS._reset_tree": [[269, 286], ["mcts_ag_bert_bidi.NumpyMCTS._visit_counts.fill", "mcts_ag_bert_bidi.NumpyMCTS._values.fill", "mcts_ag_bert_bidi.NumpyMCTS._likelihoods.fill", "mcts_ag_bert_bidi.NumpyMCTS._parents.fill", "mcts_ag_bert_bidi.NumpyMCTS._action_from_parents.fill", "mcts_ag_bert_bidi.NumpyMCTS._depth.fill", "mcts_ag_bert_bidi.NumpyMCTS._topk_mapping.fill", "mcts_ag_bert_bidi.NumpyMCTS._children_index.fill", "mcts_ag_bert_bidi.NumpyMCTS._children_prior.fill", "mcts_ag_bert_bidi.NumpyMCTS._children_values.fill", "mcts_ag_bert_bidi.NumpyMCTS._children_visits.fill"], "methods", ["None"], ["", "def", "_reset_tree", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the tree arrays.\"\"\"", "\n", "self", ".", "_visit_counts", ".", "fill", "(", "0", ")", "\n", "self", ".", "_values", ".", "fill", "(", "0", ")", "\n", "self", ".", "_likelihoods", ".", "fill", "(", "0", ")", "\n", "self", ".", "_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_action_from_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_depth", ".", "fill", "(", "0", ")", "\n", "\n", "self", ".", "_topk_mapping", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_index", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_prior", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_values", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_visits", ".", "fill", "(", "0", ")", "\n", "self", ".", "_original_states", "=", "{", "}", "\n", "self", ".", "_original_token_ids", "=", "{", "}", "# Indexed by tuples (batch index, node index)", "\n", "self", ".", "_original_attention_mask", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.set_labels": [[288, 290], ["None"], "methods", ["None"], ["", "def", "set_labels", "(", "self", ",", "labels", ")", ":", "\n", "        ", "self", ".", "_labels", "=", "labels", "\n", "", "def", "search", "(", "self", ",", "original_input", ")", ":", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.search": [[290, 409], ["mcts_ag_bert_bidi.NumpyMCTS._reset_tree", "mcts_ag_bert_bidi.NumpyMCTS._root_fun", "mcts_ag_bert_bidi.NumpyMCTS.create_node", "numpy.zeros", "tqdm.tqdm.tqdm", "range", "range", "numpy.full", "range", "mcts_ag_bert_bidi.NumpyMCTS.dense_visit_counts", "numpy.amax", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "numpy.full", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "tqdm.tqdm.tqdm.update", "mcts_ag_bert_bidi.NumpyMCTS._is_terminal[].all", "logging.warning", "mcts_ag_bert_bidi.NumpyMCTS.simulate", "mcts_ag_bert_bidi.NumpyMCTS.expand", "numpy.zeros.fill", "mcts_ag_bert_bidi.NumpyMCTS.backward", "numpy.argmax", "[].tolist", "old_to_new_id.items", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "[].tolist.pop", "[].tolist", "enumerate", "tokenizer.decode().replace().replace", "tokenizer.decode().replace", "tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.dense_visit_counts", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.simulate", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.backward"], ["", "def", "search", "(", "self", ",", "original_input", ")", ":", "\n", "        ", "self", ".", "_reset_tree", "(", ")", "\n", "\n", "# Evaluate the root.", "\n", "prior", ",", "values", ",", "states", "=", "self", ".", "_root_fun", "(", "original_input", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ")", "\n", "\n", "\n", "self", ".", "_adaptive_min_values", "=", "1", "\n", "self", ".", "_adaptive_max_values", "=", "1", "+", "1e-6", "\n", "\n", "root_index", "=", "0", "\n", "\n", "self", ".", "create_node", "(", "root_index", ",", "prior", ",", "1", ",", "values", ",", "states", ",", "original_input", ".", "input_ids", ",", "original_input", ".", "attention_mask", ",", "np", ".", "full", "(", "self", ".", "_batch_size", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", ")", "\n", "\n", "\n", "\n", "\n", "# Do simulations, expansions, and backwards.", "\n", "leaf_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "existing_nodes", "=", "0", "\n", "tokens_to_generate", "=", "98", "\n", "tokens_pbar", "=", "tqdm", "(", "total", "=", "tokens_to_generate", ",", "desc", "=", "\"Tokens generated\"", ")", "\n", "for", "i", "in", "range", "(", "tokens_to_generate", ")", ":", "\n", "            ", "for", "sim", "in", "range", "(", "self", ".", "_num_simulations", ")", ":", "\n", "                ", "node_indices", ",", "actions", "=", "self", ".", "simulate", "(", ")", "\n", "next_node_index", "=", "sim", "+", "1", "+", "existing_nodes", "# root is 0, therefore we offset by 1.", "\n", "self", ".", "expand", "(", "node_indices", ",", "actions", ",", "next_node_index", ")", "\n", "leaf_indices", ".", "fill", "(", "next_node_index", ")", "\n", "self", ".", "backward", "(", "leaf_indices", ")", "\n", "", "visit_counts", ",", "_", "=", "self", ".", "dense_visit_counts", "(", ")", "\n", "existing_nodes", "=", "np", ".", "amax", "(", "visit_counts", ")", "\n", "# Create new tree with selected node as root", "\n", "num_nodes", "=", "self", ".", "_num_simulations", "+", "existing_nodes", "+", "1", "\n", "batch_node", "=", "(", "self", ".", "_batch_size", ",", "num_nodes", ")", "\n", "temp_visit_counts", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_likelihoods", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_raw_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_parents", "=", "np", ".", "full", "(", "batch_node", ",", "-", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_action_from_parents", "=", "np", ".", "full", "(", "batch_node", ",", "-", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_depth", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_is_terminal", "=", "np", ".", "full", "(", "batch_node", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "batch_node_action", "=", "(", "self", ".", "_batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ")", "# (B, )", "\n", "temp_topk_mapping", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_children_index", "=", "np", ".", "full", "(", "batch_node_action", ",", "-", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_children_prior", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_children_probas", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_children_values", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_children_visits", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_original_states", "=", "{", "}", "\n", "temp_original_token_ids", "=", "{", "}", "# Indexed by tuples (batch index, node index)", "\n", "temp_original_attention_mask", "=", "{", "}", "\n", "\n", "for", "b", ",", "new_root_action", "in", "enumerate", "(", "np", ".", "argmax", "(", "visit_counts", ",", "axis", "=", "1", ")", ")", ":", "\n", "                ", "new_root_id", "=", "self", ".", "_children_index", "[", "b", ",", "0", ",", "new_root_action", "]", "\n", "new_node_id", "=", "1", "\n", "old_to_new_id", "=", "{", "new_root_id", ":", "0", "}", "\n", "children_to_explore", "=", "self", ".", "_children_index", "[", "b", ",", "new_root_id", "]", "[", "self", ".", "_children_index", "[", "b", ",", "new_root_id", "]", "!=", "-", "1", "]", ".", "tolist", "(", ")", "\n", "while", "(", "len", "(", "children_to_explore", ")", ">", "0", ")", ":", "\n", "                    ", "child_id", "=", "children_to_explore", ".", "pop", "(", "0", ")", "\n", "old_to_new_id", "[", "child_id", "]", "=", "new_node_id", "\n", "children_to_explore", "+=", "self", ".", "_children_index", "[", "b", ",", "child_id", "]", "[", "self", ".", "_children_index", "[", "b", ",", "child_id", "]", "!=", "-", "1", "]", ".", "tolist", "(", ")", "\n", "new_node_id", "+=", "1", "\n", "", "for", "old_id", ",", "new_id", "in", "old_to_new_id", ".", "items", "(", ")", ":", "\n", "                    ", "if", "(", "new_id", "!=", "0", ")", ":", "\n", "                        ", "temp_parents", "[", "b", ",", "new_id", "]", "=", "old_to_new_id", "[", "self", ".", "_parents", "[", "b", ",", "old_id", "]", "]", "\n", "temp_action_from_parents", "[", "b", ",", "new_id", "]", "=", "self", ".", "_action_from_parents", "[", "b", ",", "old_id", "]", "\n", "", "for", "i", ",", "children", "in", "enumerate", "(", "self", ".", "_children_index", "[", "b", ",", "old_id", "]", ")", ":", "\n", "                        ", "if", "(", "children", "!=", "-", "1", ")", ":", "\n", "                            ", "temp_children_index", "[", "b", ",", "new_id", ",", "i", "]", "=", "old_to_new_id", "[", "children", "]", "\n", "", "", "temp_visit_counts", "[", "b", ",", "new_id", "]", "=", "self", ".", "_visit_counts", "[", "b", ",", "old_id", "]", "\n", "temp_values", "[", "b", ",", "new_id", "]", "=", "self", ".", "_values", "[", "b", ",", "old_id", "]", "\n", "temp_likelihoods", "[", "b", ",", "new_id", "]", "=", "self", ".", "_likelihoods", "[", "b", ",", "old_id", "]", "\n", "temp_raw_values", "[", "b", ",", "new_id", "]", "=", "self", ".", "_raw_values", "[", "b", ",", "old_id", "]", "\n", "\n", "temp_action_from_parents", "[", "b", ",", "new_id", "]", "=", "self", ".", "_action_from_parents", "[", "b", ",", "old_id", "]", "\n", "temp_depth", "[", "b", ",", "new_id", "]", "=", "self", ".", "_depth", "[", "b", ",", "old_id", "]", "-", "1", "\n", "temp_is_terminal", "[", "b", ",", "new_id", "]", "=", "self", ".", "_is_terminal", "[", "b", ",", "old_id", "]", "\n", "\n", "temp_topk_mapping", "[", "b", ",", "new_id", "]", "=", "self", ".", "_topk_mapping", "[", "b", ",", "old_id", "]", "\n", "temp_children_prior", "[", "b", ",", "new_id", "]", "=", "self", ".", "_children_prior", "[", "b", ",", "old_id", "]", "\n", "temp_children_values", "[", "b", ",", "new_id", "]", "=", "self", ".", "_children_values", "[", "b", ",", "old_id", "]", "\n", "temp_children_visits", "[", "b", ",", "new_id", "]", "=", "self", ".", "_children_visits", "[", "b", ",", "old_id", "]", "\n", "\n", "temp_original_states", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_original_states", "[", "(", "b", ",", "old_id", ")", "]", "\n", "\n", "temp_original_token_ids", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_original_token_ids", "[", "(", "b", ",", "old_id", ")", "]", "\n", "temp_original_attention_mask", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_original_attention_mask", "[", "(", "b", ",", "old_id", ")", "]", "\n", "\n", "", "temp_original_states", "[", "(", "b", ",", "0", ")", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "_original_states", "[", "(", "b", ",", "0", ")", "]", ",", "self", ".", "_original_states", "[", "(", "b", ",", "new_root_id", ")", "]", ")", ",", "3", ")", "\n", "\n", "", "self", ".", "_num_nodes", "=", "num_nodes", "\n", "self", ".", "_visit_counts", "=", "temp_visit_counts", "\n", "self", ".", "_values", "=", "temp_values", "\n", "self", ".", "_likelihoods", "=", "temp_likelihoods", "\n", "self", ".", "_raw_values", "=", "temp_raw_values", "\n", "self", ".", "_parents", "=", "temp_parents", "\n", "self", ".", "_action_from_parents", "=", "temp_action_from_parents", "\n", "# The 0-indexed depth of the node. The root is the only 0-depth node.", "\n", "# The depth of node i, is the depth of its parent + 1.", "\n", "self", ".", "_depth", "=", "temp_depth", "\n", "self", ".", "_is_terminal", "=", "temp_is_terminal", "\n", "self", ".", "_topk_mapping", "=", "temp_topk_mapping", "\n", "self", ".", "_children_index", "=", "temp_children_index", "\n", "self", ".", "_children_prior", "=", "temp_children_prior", "\n", "self", ".", "_children_values", "=", "temp_children_values", "\n", "self", ".", "_children_visits", "=", "temp_children_visits", "\n", "self", ".", "_original_states", "=", "temp_original_states", "\n", "\n", "\n", "self", ".", "_original_token_ids", "=", "temp_original_token_ids", "\n", "self", ".", "_original_attention_mask", "=", "temp_original_attention_mask", "\n", "\n", "tokens_pbar", ".", "update", "(", "1", ")", "\n", "# If every sequences is finished, stop", "\n", "if", "(", "self", ".", "_is_terminal", "[", ":", ",", "0", "]", ".", "all", "(", ")", ")", ":", "\n", "                ", "break", "\n", "", "", "for", "b", "in", "range", "(", "self", ".", "_batch_size", ")", ":", "\n", "            ", "logging", ".", "warning", "(", "(", "tokenizer", ".", "decode", "(", "self", ".", "_original_token_ids", "[", "(", "b", ",", "0", ")", "]", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\" [PAD]\"", ",", "\"\"", ")", "+", "\"[PAD]\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.dense_visit_counts": [[410, 416], ["numpy.zeros"], "methods", ["None"], ["", "", "def", "dense_visit_counts", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_visit_counts", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_visit_counts", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_visit_counts", "\n", "return", "root_visit_counts", ",", "dense_visit_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.dense_scores": [[417, 424], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_root_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_root_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_child_prob_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_scores", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "return", "dense_root_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.dense_mean_scores": [[425, 433], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_mean_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_mean_scores", "=", "root_scores", "/", "root_visit_counts", "\n", "dense_mean_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_mean_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_child_prob_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_mean_scores", "\n", "return", "dense_mean_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.simulate": [[434, 447], ["numpy.zeros", "mcts_ag_bert_bidi.NumpyMCTS.uct_select_action", "is_unexplored.all", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.uct_select_action"], ["", "def", "simulate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Goes down until all elements have reached unexplored actions.\"\"\"", "\n", "node_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "depth", "=", "0", "\n", "while", "True", ":", "\n", "            ", "depth", "+=", "1", "\n", "actions", "=", "self", ".", "uct_select_action", "(", "node_indices", ")", "\n", "next_node_indices", "=", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "is_unexplored", "=", "next_node_indices", "==", "-", "1", "\n", "if", "is_unexplored", ".", "all", "(", ")", ":", "\n", "                ", "return", "node_indices", ",", "actions", "\n", "", "else", ":", "\n", "                ", "node_indices", "=", "np", ".", "where", "(", "is_unexplored", ",", "node_indices", ",", "next_node_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.uct_select_action": [[448, 463], ["numpy.argmax", "numpy.sqrt"], "methods", ["None"], ["", "", "", "def", "uct_select_action", "(", "self", ",", "node_indices", ")", ":", "\n", "        ", "\"\"\"Returns the action selected for a batch of node indices of shape (B).\"\"\"", "\n", "node_children_prior", "=", "self", ".", "_children_prior", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_values", "=", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_visits", "=", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_visits", "=", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "# (B)", "\n", "node_policy_score", "=", "np", ".", "sqrt", "(", "node_visits", "[", ":", ",", "None", "]", ")", "*", "self", ".", "_pb_c_init", "*", "node_children_prior", "/", "(", "node_children_visits", "+", "1", ")", "\n", "\n", "\n", "\n", "node_value_score", "=", "node_children_values", "\n", "\n", "node_uct_score", "=", "node_value_score", "+", "node_policy_score", "# (B, A)", "\n", "actions", "=", "np", ".", "argmax", "(", "node_uct_score", ",", "axis", "=", "1", ")", "\n", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.get_original_states_from_node": [[466, 476], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "get_original_states_from_node", "(", "self", ",", "b", ",", "n", ",", "d", ")", ":", "\n", "        ", "original_d", "=", "d", "\n", "original_n", "=", "n", "\n", "original_state_array", "=", "[", "None", "]", "*", "d", "\n", "original_state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_original_states", "[", "(", "b", ",", "n", ")", "]", "\n", "while", "n", "!=", "0", ":", "\n", "            ", "n", "=", "self", ".", "_parents", "[", "(", "b", ",", "n", ")", "]", "\n", "d", "-=", "1", "\n", "original_state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_original_states", "[", "(", "b", ",", "n", ")", "]", "\n", "", "return", "torch", ".", "cat", "(", "original_state_array", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.get_classi_states_from_node": [[477, 485], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "get_classi_states_from_node", "(", "self", ",", "b", ",", "n", ",", "d", ")", ":", "\n", "        ", "classi_state_array", "=", "[", "None", "]", "*", "d", "\n", "classi_state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_classi_states", "[", "(", "b", ",", "n", ")", "]", "\n", "while", "n", "!=", "0", ":", "\n", "            ", "n", "=", "self", ".", "_parents", "[", "(", "b", ",", "n", ")", "]", "\n", "d", "-=", "1", "\n", "classi_state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_classi_states", "[", "(", "b", ",", "n", ")", "]", "\n", "", "return", "torch", ".", "cat", "(", "classi_state_array", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.expand": [[486, 540], ["mcts_ag_bert_bidi.pad_sequences_to_left", "mcts_ag_bert_bidi.pad_sequences_to_left", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.array", "numpy.array", "numpy.array", "mcts_ag_bert_bidi.pad_sequences_to_left_states", "tuple", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.logical_or", "mcts_ag_bert_bidi.NumpyMCTS._rec_fun", "mcts_ag_bert_bidi.NumpyMCTS.create_node", "numpy.minimum", "numpy.maximum", "len", "values.numpy", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mcts_ag_bert_bidi.NumpyMCTS.get_original_states_from_node", "len", "tuple", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "n.item", "depths[].item", "enumerate", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "len", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left_states", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.get_original_states_from_node"], ["", "def", "expand", "(", "self", ",", "node_indices", ",", "actions", ",", "next_node_index", ")", ":", "\n", "        ", "\"\"\"Creates and evaluate child nodes from given nodes and unexplored actions.\"\"\"", "\n", "# Retrieve token ids and masks for nodes to be evaluated.", "\n", "original_tokens_ids", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_original_token_ids", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "pad_token_id", ")", "\n", "original_attention_masks", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_original_attention_mask", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "0", ")", "\n", "depths", "=", "torch", ".", "tensor", "(", "[", "self", ".", "_depth", "[", "(", "b", ",", "n", ")", "]", "+", "1", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "device", "=", "\"cuda\"", ")", "\n", "children_priors", "=", "np", ".", "array", "(", "[", "self", ".", "_children_prior", "[", "(", "b", ",", "n", ")", "]", "[", "actions", "[", "b", "]", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "likelihoods", "=", "np", ".", "array", "(", "[", "self", ".", "_likelihoods", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "previous_values", "=", "np", ".", "array", "(", "[", "self", ".", "_values", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "previous_node_is_terminal", "=", "self", ".", "_is_terminal", "[", "self", ".", "_batch_range", ",", "node_indices", "[", "self", ".", "_batch_range", "]", "]", "# (B)", "\n", "\n", "original_states_tensor", "=", "pad_sequences_to_left_states", "(", "[", "self", ".", "get_original_states_from_node", "(", "b", ",", "n", ".", "item", "(", ")", ",", "depths", "[", "b", "]", ".", "item", "(", ")", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "0", ",", "max_len", "=", "len", "(", "original_tokens_ids", "[", "0", "]", ")", ")", "\n", "if", "(", "len", "(", "original_tokens_ids", "[", "0", "]", ")", ">=", "MAX_SEQUENCE_LENGTH", ")", ":", "\n", "            ", "previous_node_is_terminal", "[", "torch", ".", "sum", "(", "original_attention_masks", ",", "axis", "=", "1", ")", ".", "cpu", "(", ")", ">=", "MAX_SEQUENCE_LENGTH", "]", "=", "True", "\n", "original_tokens_ids", "=", "original_tokens_ids", "[", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "1", ")", ":", "]", "\n", "original_attention_masks", "=", "original_attention_masks", "[", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "1", ")", ":", "]", "\n", "original_states_tensor", "=", "original_states_tensor", "[", ":", ",", ":", ",", ":", ",", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "1", ")", ":", "]", "\n", "\n", "\n", "", "original_states", "=", "tuple", "(", "tuple", "(", "type_of_value", "for", "type_of_value", "in", "layer", ")", "for", "layer", "in", "original_states_tensor", ")", "\n", "\n", "\n", "\n", "\n", "# Convert sparse actions to dense actions for network computation", "\n", "dense_actions", "=", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "dense_actions", "[", "previous_node_is_terminal", "]", "=", "pad_token_id", "\n", "# Add actions to list of tokens and extend attention mask by 1", "\n", "original_tokens_ids", "=", "torch", ".", "cat", "(", "(", "original_tokens_ids", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "cuda", ".", "LongTensor", "(", "dense_actions", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "original_attention_masks", "=", "torch", ".", "cat", "(", "(", "original_attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "dense_actions", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# Check if expanded nodes are terminal ", "\n", "expanded_node_is_terminal", "=", "np", ".", "logical_or", "(", "(", "dense_actions", "==", "pad_token_id", ")", ",", "previous_node_is_terminal", ")", "\n", "\n", "# Evaluate nodes.", "\n", "(", "prior", ",", "values", ",", "next_states", ")", "=", "self", ".", "_rec_fun", "(", "original_states", ",", "original_tokens_ids", ",", "original_attention_masks", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ")", "\n", "values", ".", "numpy", "(", ")", "[", "previous_node_is_terminal", "]", "=", "previous_values", "[", "previous_node_is_terminal", "]", "\n", "\n", "# Store unpaded version of inputs to save space", "\n", "original_attention_masks", "=", "[", "torch", ".", "cat", "(", "(", "self", ".", "_original_attention_mask", "[", "(", "b", ",", "n", ")", "]", ",", "torch", ".", "ones", "(", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", ")", ",", "dim", "=", "0", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", "\n", "original_tokens_ids", "=", "[", "torch", ".", "cat", "(", "(", "self", ".", "_original_token_ids", "[", "(", "b", ",", "n", ")", "]", ",", "torch", ".", "cuda", ".", "LongTensor", "(", "[", "dense_actions", "[", "b", "]", "]", ")", ")", ",", "dim", "=", "0", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", "\n", "\n", "# Create the new nodes.", "\n", "self", ".", "create_node", "(", "next_node_index", ",", "prior", ",", "likelihoods", "*", "children_priors", ",", "values", ",", "next_states", ",", "original_tokens_ids", ",", "original_attention_masks", ",", "expanded_node_is_terminal", ")", "\n", "\n", "# Update the min and max values arrays", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "minimum", "(", "self", ".", "_adaptive_min_values", ",", "values", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "maximum", "(", "self", ".", "_adaptive_max_values", ",", "values", ")", "\n", "\n", "# Update tree topology.", "\n", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "=", "next_node_index", "\n", "self", ".", "_parents", "[", ":", ",", "next_node_index", "]", "=", "node_indices", "\n", "self", ".", "_action_from_parents", "[", ":", ",", "next_node_index", "]", "=", "actions", "\n", "self", ".", "_depth", "[", ":", ",", "next_node_index", "]", "=", "self", ".", "_depth", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.create_node": [[541, 576], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "enumerate", "enumerate", "numpy.argpartition", "list", "range", "range", "len", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "len", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "list", "range", "len"], "methods", ["None"], ["", "def", "create_node", "(", "self", ",", "node_index", ",", "prior", ",", "likelihoods", ",", "values", ",", "original_states", ",", "original_tokens_ids", ",", "original_attention_masks", ",", "expanded_node_is_terminal", ")", ":", "\n", "# Truncate the prior to only keep the top k logits", "\n", "        ", "prior_topk_indices", "=", "np", ".", "argpartition", "(", "prior", ",", "-", "self", ".", "_num_sparse_actions", ",", "axis", "=", "-", "1", ")", "[", ":", ",", "-", "self", ".", "_num_sparse_actions", ":", "]", "\n", "prior", "=", "prior", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "prior_topk_indices", "]", "# (B, A)", "\n", "# Store the indices of the top k logits", "\n", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_index", ",", ":", "]", "=", "prior_topk_indices", "\n", "\n", "# Update prior, values and visit counts.", "\n", "self", ".", "_children_prior", "[", ":", ",", "node_index", ",", ":", "]", "=", "prior", "\n", "self", ".", "_likelihoods", "[", ":", ",", "node_index", "]", "=", "likelihoods", "\n", "# raw_values = values**(self.alpha) * likelihoods**(1-self.alpha)", "\n", "raw_values", "=", "values", "\n", "self", ".", "_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_raw_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_visit_counts", "[", ":", ",", "node_index", "]", "=", "1", "\n", "self", ".", "_is_terminal", "[", ":", ",", "node_index", "]", "=", "expanded_node_is_terminal", "\n", "# States has shape [12 (nhead), 2(key/value), batch_size, 12(nlayer), seq_len, 64]", "\n", "original_key_value_tensor", "=", "torch", ".", "stack", "(", "list", "(", "torch", ".", "stack", "(", "list", "(", "original_states", "[", "i", "]", ")", ",", "dim", "=", "0", ")", "for", "i", "in", "range", "(", "len", "(", "original_states", ")", ")", ")", ",", "dim", "=", "0", ")", "\n", "\n", "# If root, store the whole states", "\n", "if", "(", "node_index", "==", "0", ")", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "original_tokens_ids", ")", ")", ":", "\n", "                ", "self", ".", "_original_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "original_key_value_tensor", "[", ":", ",", ":", ",", "b", "]", ")", "\n", "# Else just store the additional token hidden states to save space", "\n", "", "", "else", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "original_tokens_ids", ")", ")", ":", "\n", "                ", "self", ".", "_original_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "original_key_value_tensor", "[", ":", ",", ":", ",", "b", ",", ":", ",", "-", "1", ":", "]", ")", "\n", "\n", "# Updates tokens ids", "\n", "", "", "for", "b", ",", "original_token_ids", "in", "enumerate", "(", "original_tokens_ids", ")", ":", "\n", "            ", "self", ".", "_original_token_ids", "[", "(", "b", ",", "node_index", ")", "]", "=", "original_token_ids", "\n", "\n", "# Updates attention masks", "\n", "", "for", "b", ",", "original_attention_mask", "in", "enumerate", "(", "original_attention_masks", ")", ":", "\n", "            ", "self", ".", "_original_attention_mask", "[", "(", "b", ",", "node_index", ")", "]", "=", "original_attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.NumpyMCTS.backward": [[577, 601], ["is_root.all", "numpy.where", "numpy.where"], "methods", ["None"], ["", "", "def", "backward", "(", "self", ",", "leaf_indices", ")", ":", "\n", "        ", "\"\"\"Goes up and updates the tree until all nodes reached the root.\"\"\"", "\n", "node_indices", "=", "leaf_indices", "# (B)", "\n", "leaf_values", "=", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "leaf_indices", "]", "\n", "while", "True", ":", "\n", "            ", "is_root", "=", "node_indices", "==", "0", "\n", "if", "is_root", ".", "all", "(", ")", ":", "\n", "                ", "return", "\n", "", "parents", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "root_mask", "=", "1.0", "*", "is_root", "\n", "not_root_mask_int", "=", "(", "1", "-", "is_root", ")", "\n", "not_root_mask", "=", "1.0", "-", "root_mask", "\n", "# Update the parent nodes iff their child is not the root.", "\n", "# We therefore mask the updates using not_root_mask and root_mask.", "\n", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "=", "not_root_mask", "*", "(", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "*", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+", "leaf_values", ")", "/", "(", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "\n", "parents", "]", "+", "1.0", ")", "+", "root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "\n", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+=", "not_root_mask_int", "\n", "actions", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_action_from_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "=", "not_root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "root_mask", "*", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "\n", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "+=", "not_root_mask_int", "\n", "# Go up", "\n", "node_indices", "=", "parents", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.pad_sequences_to_left": [[124, 145], ["sequences[].size", "max", "sequences[].new_full", "enumerate", "tensor.size", "s.size", "len", "len"], "function", ["None"], ["", "def", "pad_sequences_to_left", "(", "sequences", ",", "batch_first", "=", "False", ",", "padding_value", "=", "0", ")", ":", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "    ", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "max_len", "=", "max", "(", "[", "s", ".", "size", "(", "0", ")", "for", "s", "in", "sequences", "]", ")", "\n", "if", "batch_first", ":", "\n", "        ", "out_dims", "=", "(", "len", "(", "sequences", ")", ",", "max_len", ")", "+", "trailing_dims", "\n", "", "else", ":", "\n", "        ", "out_dims", "=", "(", "max_len", ",", "len", "(", "sequences", ")", ")", "+", "trailing_dims", "\n", "\n", "", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# use index notation to prevent duplicate references to the tensor", "\n", "if", "batch_first", ":", "\n", "            ", "out_tensor", "[", "i", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "else", ":", "\n", "            ", "out_tensor", "[", "max_len", "-", "length", ":", ",", "i", ",", "...", "]", "=", "tensor", "\n", "", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.pad_sequences_to_left_states": [[147, 159], ["sequences[].size", "sequences[].new_full", "enumerate", "len", "tensor.size"], "function", ["None"], ["", "def", "pad_sequences_to_left_states", "(", "sequences", ",", "padding_value", "=", "0", ",", "max_len", "=", "0", ")", ":", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "    ", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "out_dims", "=", "(", "max_size", "[", "0", "]", ",", "max_size", "[", "1", "]", ",", "len", "(", "sequences", ")", ",", "max_size", "[", "2", "]", ",", "max_len", ",", "max_size", "[", "4", "]", ")", "\n", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ",", "device", "=", "\"cuda\"", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", ")", "[", "3", "]", "\n", "out_tensor", "[", ":", ",", ":", ",", "i", ",", ":", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.root_fun": [[161, 186], ["lm.prepare_inputs_for_generation", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lm", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "classi", "torch.softmax().cpu", "torch.softmax"], "function", ["None"], ["", "def", "root_fun", "(", "original_input", ",", "labels", ",", "temperature", ",", "repetition_penalty", ")", ":", "\n", "# Forward pass of LM to get priors and states", "\n", "    ", "model_inputs", "=", "lm", ".", "prepare_inputs_for_generation", "(", "original_input", ".", "input_ids", ",", "attention_mask", "=", "original_input", ".", "attention_mask", ",", "use_cache", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "lm", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", "use_cache", "=", "True", ",", "\n", ")", "\n", "states", "=", "outputs", ".", "past_key_values", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "model_inputs", "[", "\"input_ids\"", "]", ")", "\n", "inverted_attention_mask", "=", "model_inputs", "[", "\"attention_mask\"", "]", "==", "0", "\n", "prompt_masked_input_ids", "[", "inverted_attention_mask", "]", "=", "14827", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "# Use of our discriminator to get values", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "values", "=", "classi", "(", "original_input", ".", "input_ids", ",", "original_input", ".", "attention_mask", ",", "labels", ")", "\n", "\n", "", "return", "priors", ",", "values", ",", "states", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.rec_fun": [[187, 213], ["lm.prepare_inputs_for_generation", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lm", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "classi", "torch.softmax().cpu", "torch.softmax"], "function", ["None"], ["", "def", "rec_fun", "(", "original_states", ",", "original_token_ids", ",", "original_attention_masks", ",", "labels", ",", "temperature", ",", "repetition_penalty", ")", ":", "\n", "# Forward pass of LM to get priors and states", "\n", "    ", "model_inputs", "=", "lm", ".", "prepare_inputs_for_generation", "(", "original_token_ids", ",", "attention_mask", "=", "original_attention_masks", ",", "past", "=", "original_states", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "lm", "(", "\n", "**", "model_inputs", ",", "\n", "use_cache", "=", "True", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "next_states", "=", "outputs", ".", "past_key_values", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "original_token_ids", ")", "\n", "inverted_attention_mask", "=", "original_attention_masks", "==", "0", "\n", "# penalizing an unused token", "\n", "prompt_masked_input_ids", "[", "inverted_attention_mask", "]", "=", "28988", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Use of our discriminator to get values", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "values", "=", "classi", "(", "original_token_ids", ",", "original_attention_masks", ",", "labels", ")", "\n", "\n", "", "return", "priors", ",", "values", ",", "next_states", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_bidi.main": [[602, 629], ["print", "pandas.read_csv", "print", "torch.zeros", "torch.zeros", "torch.zeros", "mcts_ag_bert_bidi.NumpyMCTS", "tqdm.tqdm", "torch.zeros.fill_", "enumerate", "mcts_ag_bert_bidi.NumpyMCTS.set_labels", "tokenizer().to", "mcts_ag_bert_bidi.NumpyMCTS.search", "tqdm.tqdm.update", "lines.iterrows", "str", "tokenizer", "int"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.set_labels", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.search"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"loading dataset\"", ")", "\n", "data_lines", "=", "pd", ".", "read_csv", "(", "\"datasets/ag_news/full/prompts.tsv\"", ",", "sep", "=", "'\\t'", ",", "engine", "=", "'python'", ",", "encoding", "=", "\"utf8\"", ")", "\n", "print", "(", "\"dataset loaded\"", ")", "\n", "generated_counter", "=", "0", "\n", "samples_size", "=", "501", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "labels", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "4", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "\"cuda\"", ")", "\n", "sot_texts", "=", "[", "None", "]", "*", "batch_size", "\n", "MCTS", "=", "NumpyMCTS", "(", "root_fun", ",", "rec_fun", ",", "batch_size", "=", "batch_size", ",", "num_simulations", "=", "args", ".", "num_it", ",", "num_actions", "=", "vocab_size", "+", "1", ",", "num_sparse_actions", "=", "50", ",", "pb_c_init", "=", "args", ".", "c", ",", "temperature", "=", "args", ".", "temperature", ",", "alpha", "=", "args", ".", "alpha", ",", "penalty", "=", "args", ".", "penalty", ")", "\n", "samples_pbar", "=", "tqdm", "(", "total", "=", "samples_size", ",", "desc", "=", "\"Samples generated\"", ")", "\n", "while", "(", "generated_counter", "+", "batch_size", "<=", "samples_size", ")", ":", "\n", "        ", "labels", ".", "fill_", "(", "0", ")", "\n", "# Prepare search inputs", "\n", "lines", "=", "data_lines", "[", "generated_counter", ":", "generated_counter", "+", "batch_size", "]", "\n", "\n", "\n", "for", "i", ",", "(", "_", ",", "row", ")", "in", "enumerate", "(", "lines", ".", "iterrows", "(", ")", ")", ":", "\n", "            ", "labels", "[", "i", ",", "int", "(", "row", "[", "\"label\"", "]", ")", "]", "=", "1", "\n", "sot_texts", "[", "i", "]", "=", "\"[CLS] \"", "+", "str", "(", "row", "[", "\"text\"", "]", ")", "\n", "\n", "", "MCTS", ".", "set_labels", "(", "labels", ")", "\n", "\n", "original_input", "=", "tokenizer", "(", "sot_texts", ",", "return_tensors", "=", "\"pt\"", ",", "padding", "=", "True", ",", "add_special_tokens", "=", "False", ",", "truncation", "=", "True", ",", "max_length", "=", "20", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "MCTS", ".", "search", "(", "original_input", ")", "\n", "generated_counter", "+=", "batch_size", "\n", "samples_pbar", ".", "update", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.__init__": [[211, 270], ["min", "numpy.zeros", "numpy.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.arange", "mcts_ag_bert_gedi.NumpyMCTS._reset_tree", "transformers.RepetitionPenaltyLogitsProcessor", "len", "len"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree"], ["    ", "def", "__init__", "(", "self", ",", "root_fun", ",", "rec_fun", ",", "batch_size", ",", "num_simulations", ",", "num_actions", ",", "num_sparse_actions", ",", "pb_c_init", ",", "temperature", ",", "alpha", ",", "penalty", ")", ":", "\n", "        ", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_num_simulations", "=", "num_simulations", "\n", "self", ".", "_num_actions", "=", "num_actions", "\n", "self", ".", "_num_sparse_actions", "=", "min", "(", "num_sparse_actions", ",", "num_actions", ")", "\n", "self", ".", "_pb_c_init", "=", "pb_c_init", "\n", "self", ".", "_temperature", "=", "temperature", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n", "self", ".", "_root_fun", "=", "root_fun", "# a function called at the root", "\n", "self", ".", "_rec_fun", "=", "rec_fun", "# a function called in the tree", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_labels", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "len", "(", "label_names", ")", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "\"cuda\"", ")", "\n", "\n", "# Allocate all necessary storage.", "\n", "# For a given search associated to a batch-index, node i is the i-th node", "\n", "# to be expanded. Node 0 corresponds to the root node.", "\n", "num_nodes", "=", "num_simulations", "+", "1", "\n", "batch_node", "=", "(", "batch_size", ",", "num_nodes", ")", "\n", "self", ".", "_num_nodes", "=", "num_nodes", "\n", "self", ".", "_visit_counts", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_likelihoods", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_raw_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# action_from_parents[b, i] is the action taken to reach node i.", "\n", "# Note that action_from_parents[b, 0] will remain -1, as we do not know,", "\n", "# when doing search from the root, what action led to the root.", "\n", "self", ".", "_action_from_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# The 0-indexed depth of the node. The root is the only 0-depth node.", "\n", "# The depth of node i, is the depth of its parent + 1.", "\n", "self", ".", "_depth", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_is_terminal", "=", "np", ".", "full", "(", "batch_node", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "\n", "# To avoid costly numpy ops, we store a sparse version of the actions.", "\n", "# We select the top k actions according to the policy, and keep a mapping", "\n", "# of indices from 0 to k-1 to the actual action indices in the", "\n", "# self._topk_mapping tensor.", "\n", "batch_node_action", "=", "(", "batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ")", "# (B, )", "\n", "self", ".", "_topk_mapping", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_index", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_prior", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_probas", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ",", "len", "(", "label_names", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_values", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_visits", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_states", "=", "{", "}", "\n", "self", ".", "_token_ids", "=", "{", "}", "\n", "self", ".", "_attention_mask", "=", "{", "}", "\n", "for", "label_name", "in", "label_names", ":", "\n", "            ", "self", ".", "_states", "[", "label_name", "]", "=", "{", "}", "\n", "self", ".", "_token_ids", "[", "label_name", "]", "=", "{", "}", "\n", "self", ".", "_attention_mask", "[", "label_name", "]", "=", "{", "}", "\n", "", "self", ".", "_states", "[", "\"original\"", "]", "=", "{", "}", "\n", "self", ".", "_token_ids", "[", "\"original\"", "]", "=", "{", "}", "\n", "self", ".", "_attention_mask", "[", "\"original\"", "]", "=", "{", "}", "\n", "self", ".", "_batch_range", "=", "np", ".", "arange", "(", "batch_size", ")", "\n", "self", ".", "_reset_tree", "(", ")", "\n", "self", ".", "_repetition_penalty", "=", "RepetitionPenaltyLogitsProcessor", "(", "penalty", "=", "penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS._reset_tree": [[271, 296], ["mcts_ag_bert_gedi.NumpyMCTS._visit_counts.fill", "mcts_ag_bert_gedi.NumpyMCTS._values.fill", "mcts_ag_bert_gedi.NumpyMCTS._likelihoods.fill", "mcts_ag_bert_gedi.NumpyMCTS._parents.fill", "mcts_ag_bert_gedi.NumpyMCTS._action_from_parents.fill", "mcts_ag_bert_gedi.NumpyMCTS._depth.fill", "mcts_ag_bert_gedi.NumpyMCTS._topk_mapping.fill", "mcts_ag_bert_gedi.NumpyMCTS._children_index.fill", "mcts_ag_bert_gedi.NumpyMCTS._children_prior.fill", "mcts_ag_bert_gedi.NumpyMCTS._children_values.fill", "mcts_ag_bert_gedi.NumpyMCTS._children_probas.fill", "mcts_ag_bert_gedi.NumpyMCTS._children_visits.fill"], "methods", ["None"], ["", "def", "_reset_tree", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the tree arrays.\"\"\"", "\n", "self", ".", "_visit_counts", ".", "fill", "(", "0", ")", "\n", "self", ".", "_values", ".", "fill", "(", "0", ")", "\n", "self", ".", "_likelihoods", ".", "fill", "(", "0", ")", "\n", "self", ".", "_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_action_from_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_depth", ".", "fill", "(", "0", ")", "\n", "\n", "self", ".", "_topk_mapping", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_index", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_prior", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_values", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_probas", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_visits", ".", "fill", "(", "0", ")", "\n", "self", ".", "_states", "=", "{", "}", "\n", "self", ".", "_token_ids", "=", "{", "}", "\n", "self", ".", "_attention_mask", "=", "{", "}", "\n", "for", "label_name", "in", "label_names", ":", "\n", "            ", "self", ".", "_states", "[", "label_name", "]", "=", "{", "}", "\n", "self", ".", "_token_ids", "[", "label_name", "]", "=", "{", "}", "\n", "self", ".", "_attention_mask", "[", "label_name", "]", "=", "{", "}", "\n", "", "self", ".", "_states", "[", "\"original\"", "]", "=", "{", "}", "\n", "self", ".", "_token_ids", "[", "\"original\"", "]", "=", "{", "}", "\n", "self", ".", "_attention_mask", "[", "\"original\"", "]", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.set_labels": [[297, 299], ["None"], "methods", ["None"], ["", "def", "set_labels", "(", "self", ",", "labels", ")", ":", "\n", "        ", "self", ".", "_labels", "=", "labels", "\n", "", "def", "search", "(", "self", ",", "original_input", ",", "cons_input_ids", ",", "cons_attention_masks", ")", ":", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.search": [[299, 424], ["mcts_ag_bert_gedi.NumpyMCTS._reset_tree", "mcts_ag_bert_gedi.NumpyMCTS._root_fun", "mcts_ag_bert_gedi.NumpyMCTS.create_node", "numpy.zeros", "tqdm.tqdm.tqdm", "range", "range", "numpy.full", "range", "mcts_ag_bert_gedi.NumpyMCTS.dense_visit_counts", "numpy.amax", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "numpy.full", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "tqdm.tqdm.tqdm.update", "mcts_ag_bert_gedi.NumpyMCTS._is_terminal[].all", "logging.warning", "mcts_ag_bert_gedi.NumpyMCTS.simulate", "mcts_ag_bert_gedi.NumpyMCTS.expand", "numpy.zeros.fill", "mcts_ag_bert_gedi.NumpyMCTS.backward", "numpy.argmax", "[].tolist", "old_to_new_id.items", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "len", "[].tolist.pop", "[].tolist", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tokenizer.decode().replace().replace", "tokenizer.decode().replace", "tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.dense_visit_counts", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.simulate", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.backward"], ["", "def", "search", "(", "self", ",", "original_input", ",", "cons_input_ids", ",", "cons_attention_masks", ")", ":", "\n", "        ", "self", ".", "_reset_tree", "(", ")", "\n", "\n", "# Evaluate the root.", "\n", "prior", ",", "child_prob", ",", "states", ",", "cons_states", "=", "self", ".", "_root_fun", "(", "original_input", ",", "cons_input_ids", ",", "cons_attention_masks", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ")", "\n", "\n", "\n", "self", ".", "_adaptive_min_values", "=", "1", "\n", "self", ".", "_adaptive_max_values", "=", "1", "+", "1e-6", "\n", "\n", "root_index", "=", "0", "\n", "self", ".", "create_node", "(", "root_index", ",", "prior", ",", "1", ",", "1", ",", "child_prob", ",", "states", ",", "original_input", ".", "input_ids", ",", "original_input", ".", "attention_mask", ",", "cons_states", ",", "cons_input_ids", ",", "cons_attention_masks", ",", "np", ".", "full", "(", "self", ".", "_batch_size", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", ")", "\n", "\n", "# Do simulations, expansions, and backwards.", "\n", "leaf_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "existing_nodes", "=", "0", "\n", "tokens_to_generate", "=", "98", "\n", "tokens_pbar", "=", "tqdm", "(", "total", "=", "tokens_to_generate", ",", "desc", "=", "\"Tokens generated\"", ")", "\n", "for", "i", "in", "range", "(", "tokens_to_generate", ")", ":", "\n", "            ", "for", "sim", "in", "range", "(", "self", ".", "_num_simulations", ")", ":", "\n", "                ", "node_indices", ",", "actions", "=", "self", ".", "simulate", "(", ")", "\n", "next_node_index", "=", "sim", "+", "1", "+", "existing_nodes", "# root is 0, therefore we offset by 1.", "\n", "self", ".", "expand", "(", "node_indices", ",", "actions", ",", "next_node_index", ")", "\n", "leaf_indices", ".", "fill", "(", "next_node_index", ")", "\n", "self", ".", "backward", "(", "leaf_indices", ")", "\n", "", "visit_counts", ",", "_", "=", "self", ".", "dense_visit_counts", "(", ")", "\n", "existing_nodes", "=", "np", ".", "amax", "(", "visit_counts", ")", "\n", "# Create new tree with selected node as root", "\n", "num_nodes", "=", "self", ".", "_num_simulations", "+", "existing_nodes", "+", "1", "\n", "batch_node", "=", "(", "self", ".", "_batch_size", ",", "num_nodes", ")", "\n", "temp_visit_counts", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_likelihoods", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_raw_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_parents", "=", "np", ".", "full", "(", "batch_node", ",", "-", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_action_from_parents", "=", "np", ".", "full", "(", "batch_node", ",", "-", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_depth", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_is_terminal", "=", "np", ".", "full", "(", "batch_node", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "batch_node_action", "=", "(", "self", ".", "_batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ")", "# (B, )", "\n", "temp_topk_mapping", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_children_index", "=", "np", ".", "full", "(", "batch_node_action", ",", "-", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_children_prior", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_children_probas", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ",", "len", "(", "label_names", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_children_values", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_children_visits", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_states", "=", "{", "}", "\n", "temp_token_ids", "=", "{", "}", "# Indexed by tuples (batch index, node index)", "\n", "temp_attention_mask", "=", "{", "}", "\n", "for", "label_name", "in", "label_names", ":", "\n", "                ", "temp_states", "[", "label_name", "]", "=", "{", "}", "\n", "temp_token_ids", "[", "label_name", "]", "=", "{", "}", "\n", "temp_attention_mask", "[", "label_name", "]", "=", "{", "}", "\n", "", "temp_states", "[", "\"original\"", "]", "=", "{", "}", "\n", "temp_token_ids", "[", "\"original\"", "]", "=", "{", "}", "\n", "temp_attention_mask", "[", "\"original\"", "]", "=", "{", "}", "\n", "\n", "for", "b", ",", "new_root_action", "in", "enumerate", "(", "np", ".", "argmax", "(", "visit_counts", ",", "axis", "=", "1", ")", ")", ":", "\n", "                ", "new_root_id", "=", "self", ".", "_children_index", "[", "b", ",", "0", ",", "new_root_action", "]", "\n", "new_node_id", "=", "1", "\n", "old_to_new_id", "=", "{", "new_root_id", ":", "0", "}", "\n", "children_to_explore", "=", "self", ".", "_children_index", "[", "b", ",", "new_root_id", "]", "[", "self", ".", "_children_index", "[", "b", ",", "new_root_id", "]", "!=", "-", "1", "]", ".", "tolist", "(", ")", "\n", "while", "(", "len", "(", "children_to_explore", ")", ">", "0", ")", ":", "\n", "                    ", "child_id", "=", "children_to_explore", ".", "pop", "(", "0", ")", "\n", "old_to_new_id", "[", "child_id", "]", "=", "new_node_id", "\n", "children_to_explore", "+=", "self", ".", "_children_index", "[", "b", ",", "child_id", "]", "[", "self", ".", "_children_index", "[", "b", ",", "child_id", "]", "!=", "-", "1", "]", ".", "tolist", "(", ")", "\n", "new_node_id", "+=", "1", "\n", "", "for", "old_id", ",", "new_id", "in", "old_to_new_id", ".", "items", "(", ")", ":", "\n", "                    ", "if", "(", "new_id", "!=", "0", ")", ":", "\n", "                        ", "temp_parents", "[", "b", ",", "new_id", "]", "=", "old_to_new_id", "[", "self", ".", "_parents", "[", "b", ",", "old_id", "]", "]", "\n", "temp_action_from_parents", "[", "b", ",", "new_id", "]", "=", "self", ".", "_action_from_parents", "[", "b", ",", "old_id", "]", "\n", "", "for", "i", ",", "children", "in", "enumerate", "(", "self", ".", "_children_index", "[", "b", ",", "old_id", "]", ")", ":", "\n", "                        ", "if", "(", "children", "!=", "-", "1", ")", ":", "\n", "                            ", "temp_children_index", "[", "b", ",", "new_id", ",", "i", "]", "=", "old_to_new_id", "[", "children", "]", "\n", "", "", "temp_visit_counts", "[", "b", ",", "new_id", "]", "=", "self", ".", "_visit_counts", "[", "b", ",", "old_id", "]", "\n", "temp_values", "[", "b", ",", "new_id", "]", "=", "self", ".", "_values", "[", "b", ",", "old_id", "]", "\n", "temp_likelihoods", "[", "b", ",", "new_id", "]", "=", "self", ".", "_likelihoods", "[", "b", ",", "old_id", "]", "\n", "temp_raw_values", "[", "b", ",", "new_id", "]", "=", "self", ".", "_raw_values", "[", "b", ",", "old_id", "]", "\n", "\n", "temp_action_from_parents", "[", "b", ",", "new_id", "]", "=", "self", ".", "_action_from_parents", "[", "b", ",", "old_id", "]", "\n", "temp_depth", "[", "b", ",", "new_id", "]", "=", "self", ".", "_depth", "[", "b", ",", "old_id", "]", "-", "1", "\n", "temp_is_terminal", "[", "b", ",", "new_id", "]", "=", "self", ".", "_is_terminal", "[", "b", ",", "old_id", "]", "\n", "\n", "temp_topk_mapping", "[", "b", ",", "new_id", "]", "=", "self", ".", "_topk_mapping", "[", "b", ",", "old_id", "]", "\n", "temp_children_prior", "[", "b", ",", "new_id", "]", "=", "self", ".", "_children_prior", "[", "b", ",", "old_id", "]", "\n", "temp_children_probas", "[", "b", ",", "new_id", "]", "=", "self", ".", "_children_probas", "[", "b", ",", "old_id", "]", "\n", "temp_children_values", "[", "b", ",", "new_id", "]", "=", "self", ".", "_children_values", "[", "b", ",", "old_id", "]", "\n", "temp_children_visits", "[", "b", ",", "new_id", "]", "=", "self", ".", "_children_visits", "[", "b", ",", "old_id", "]", "\n", "\n", "for", "label_name", "in", "label_names", ":", "\n", "                        ", "temp_states", "[", "label_name", "]", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_states", "[", "label_name", "]", "[", "(", "b", ",", "old_id", ")", "]", "\n", "temp_token_ids", "[", "label_name", "]", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_token_ids", "[", "label_name", "]", "[", "(", "b", ",", "old_id", ")", "]", "\n", "temp_attention_mask", "[", "label_name", "]", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_attention_mask", "[", "label_name", "]", "[", "(", "b", ",", "old_id", ")", "]", "\n", "", "temp_states", "[", "\"original\"", "]", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_states", "[", "\"original\"", "]", "[", "(", "b", ",", "old_id", ")", "]", "\n", "temp_token_ids", "[", "\"original\"", "]", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_token_ids", "[", "\"original\"", "]", "[", "(", "b", ",", "old_id", ")", "]", "\n", "temp_attention_mask", "[", "\"original\"", "]", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_attention_mask", "[", "\"original\"", "]", "[", "(", "b", ",", "old_id", ")", "]", "\n", "", "for", "label_name", "in", "label_names", ":", "\n", "                    ", "temp_states", "[", "label_name", "]", "[", "(", "b", ",", "0", ")", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "_states", "[", "label_name", "]", "[", "(", "b", ",", "0", ")", "]", ",", "self", ".", "_states", "[", "label_name", "]", "[", "(", "b", ",", "new_root_id", ")", "]", ")", ",", "3", ")", "\n", "", "temp_states", "[", "\"original\"", "]", "[", "(", "b", ",", "0", ")", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "_states", "[", "\"original\"", "]", "[", "(", "b", ",", "0", ")", "]", ",", "self", ".", "_states", "[", "\"original\"", "]", "[", "(", "b", ",", "new_root_id", ")", "]", ")", ",", "3", ")", "\n", "\n", "", "self", ".", "_num_nodes", "=", "num_nodes", "\n", "self", ".", "_visit_counts", "=", "temp_visit_counts", "\n", "self", ".", "_values", "=", "temp_values", "\n", "self", ".", "_likelihoods", "=", "temp_likelihoods", "\n", "self", ".", "_raw_values", "=", "temp_raw_values", "\n", "self", ".", "_parents", "=", "temp_parents", "\n", "self", ".", "_action_from_parents", "=", "temp_action_from_parents", "\n", "# The 0-indexed depth of the node. The root is the only 0-depth node.", "\n", "# The depth of node i, is the depth of its parent + 1.", "\n", "self", ".", "_depth", "=", "temp_depth", "\n", "self", ".", "_is_terminal", "=", "temp_is_terminal", "\n", "self", ".", "_topk_mapping", "=", "temp_topk_mapping", "\n", "self", ".", "_children_index", "=", "temp_children_index", "\n", "self", ".", "_children_prior", "=", "temp_children_prior", "\n", "self", ".", "_children_probas", "=", "temp_children_probas", "\n", "self", ".", "_children_values", "=", "temp_children_values", "\n", "self", ".", "_children_visits", "=", "temp_children_visits", "\n", "self", ".", "_states", "=", "temp_states", "\n", "self", ".", "_token_ids", "=", "temp_token_ids", "\n", "self", ".", "_attention_mask", "=", "temp_attention_mask", "\n", "tokens_pbar", ".", "update", "(", "1", ")", "\n", "# If every sequences is finished, stop", "\n", "if", "(", "self", ".", "_is_terminal", "[", ":", ",", "0", "]", ".", "all", "(", ")", ")", ":", "\n", "                ", "break", "\n", "", "", "for", "b", "in", "range", "(", "self", ".", "_batch_size", ")", ":", "\n", "            ", "logging", ".", "warning", "(", "(", "tokenizer", ".", "decode", "(", "self", ".", "_token_ids", "[", "\"original\"", "]", "[", "(", "b", ",", "0", ")", "]", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\" [PAD]\"", ",", "\"\"", ")", "+", "\"[PAD]\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.dense_visit_counts": [[425, 431], ["numpy.zeros"], "methods", ["None"], ["", "", "def", "dense_visit_counts", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_visit_counts", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_visit_counts", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_visit_counts", "\n", "return", "root_visit_counts", ",", "dense_visit_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.dense_scores": [[432, 439], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_root_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_root_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_child_prob_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_scores", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "return", "dense_root_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.dense_mean_scores": [[440, 448], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_mean_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_mean_scores", "=", "root_scores", "/", "root_visit_counts", "\n", "dense_mean_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_mean_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_child_prob_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_mean_scores", "\n", "return", "dense_mean_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.simulate": [[449, 462], ["numpy.zeros", "mcts_ag_bert_gedi.NumpyMCTS.uct_select_action", "is_unexplored.all", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.uct_select_action"], ["", "def", "simulate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Goes down until all elements have reached unexplored actions.\"\"\"", "\n", "node_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "depth", "=", "0", "\n", "while", "True", ":", "\n", "            ", "depth", "+=", "1", "\n", "actions", "=", "self", ".", "uct_select_action", "(", "node_indices", ")", "\n", "next_node_indices", "=", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "is_unexplored", "=", "next_node_indices", "==", "-", "1", "\n", "if", "is_unexplored", ".", "all", "(", ")", ":", "\n", "                ", "return", "node_indices", ",", "actions", "\n", "", "else", ":", "\n", "                ", "node_indices", "=", "np", ".", "where", "(", "is_unexplored", ",", "node_indices", ",", "next_node_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.uct_select_action": [[463, 477], ["numpy.argmax", "numpy.sqrt"], "methods", ["None"], ["", "", "", "def", "uct_select_action", "(", "self", ",", "node_indices", ")", ":", "\n", "        ", "\"\"\"Returns the action selected for a batch of node indices of shape (B).\"\"\"", "\n", "node_children_prior", "=", "self", ".", "_children_prior", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_values", "=", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_visits", "=", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_visits", "=", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "# (B)", "\n", "node_policy_score", "=", "np", ".", "sqrt", "(", "node_visits", "[", ":", ",", "None", "]", ")", "*", "self", ".", "_pb_c_init", "*", "node_children_prior", "/", "(", "node_children_visits", "+", "1", ")", "\n", "# (B, A)", "\n", "\n", "node_value_score", "=", "node_children_values", "\n", "\n", "node_uct_score", "=", "node_value_score", "+", "node_policy_score", "# (B, A)", "\n", "actions", "=", "np", ".", "argmax", "(", "node_uct_score", ",", "axis", "=", "1", ")", "\n", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.get_states_from_node": [[479, 487], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "get_states_from_node", "(", "self", ",", "b", ",", "n", ",", "d", ",", "label", ")", ":", "\n", "        ", "state_array", "=", "[", "None", "]", "*", "d", "\n", "state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_states", "[", "label", "]", "[", "(", "b", ",", "n", ")", "]", "\n", "while", "n", "!=", "0", ":", "\n", "            ", "n", "=", "self", ".", "_parents", "[", "(", "b", ",", "n", ")", "]", "\n", "d", "-=", "1", "\n", "state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_states", "[", "label", "]", "[", "(", "b", ",", "n", ")", "]", "\n", "", "return", "torch", ".", "cat", "(", "state_array", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.expand": [[491, 565], ["mcts_ag_bert_gedi.pad_sequences_to_left", "mcts_ag_bert_gedi.pad_sequences_to_left", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.array", "numpy.array", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mcts_ag_bert_gedi.pad_sequences_to_left_states", "tuple", "tuple", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.logical_or", "mcts_ag_bert_gedi.NumpyMCTS._rec_fun", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "mcts_ag_bert_gedi.NumpyMCTS.create_node", "numpy.minimum", "numpy.maximum", "mcts_ag_bert_gedi.pad_sequences_to_left", "mcts_ag_bert_gedi.pad_sequences_to_left", "mcts_ag_bert_gedi.pad_sequences_to_left_states", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mcts_ag_bert_gedi.NumpyMCTS.get_states_from_node", "len", "tuple", "tuple", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "enumerate", "enumerate", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "n.item", "depths[].item", "enumerate", "mcts_ag_bert_gedi.NumpyMCTS.get_states_from_node", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "enumerate", "enumerate", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "enumerate", "enumerate", "depths[].item", "enumerate", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "tuple", "len", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "cross_entropy", "len", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left_states", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left_states", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.get_states_from_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.get_states_from_node"], ["", "def", "expand", "(", "self", ",", "node_indices", ",", "actions", ",", "next_node_index", ")", ":", "\n", "        ", "\"\"\"Creates and evaluate child nodes from given nodes and unexplored actions.\"\"\"", "\n", "# Retrieve token ids and masks for nodes to be evaluated.", "\n", "original_tokens_ids", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_token_ids", "[", "\"original\"", "]", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "pad_token_id", ")", "\n", "original_attention_masks", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_attention_mask", "[", "\"original\"", "]", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "0", ")", "\n", "cons_tokens_ids", "=", "{", "}", "\n", "cons_attention_masks", "=", "{", "}", "\n", "for", "label_name", "in", "label_names", ":", "\n", "            ", "cons_tokens_ids", "[", "label_name", "]", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_token_ids", "[", "label_name", "]", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "pad_token_id", ")", "\n", "cons_attention_masks", "[", "label_name", "]", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_attention_mask", "[", "label_name", "]", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "0", ")", "\n", "", "depths", "=", "torch", ".", "tensor", "(", "[", "self", ".", "_depth", "[", "(", "b", ",", "n", ")", "]", "+", "1", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "device", "=", "\"cuda\"", ")", "\n", "children_priors", "=", "np", ".", "array", "(", "[", "self", ".", "_children_prior", "[", "(", "b", ",", "n", ")", "]", "[", "actions", "[", "b", "]", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "likelihoods", "=", "np", ".", "array", "(", "[", "self", ".", "_likelihoods", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "values", "=", "torch", ".", "tensor", "(", "[", "self", ".", "_children_probas", "[", "(", "b", ",", "n", ")", "]", "[", "actions", "[", "b", "]", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "device", "=", "\"cuda\"", ")", "\n", "previous_node_is_terminal", "=", "self", ".", "_is_terminal", "[", "self", ".", "_batch_range", ",", "node_indices", "[", "self", ".", "_batch_range", "]", "]", "# (B)", "\n", "\n", "\n", "original_states_tensor", "=", "pad_sequences_to_left_states", "(", "[", "self", ".", "get_states_from_node", "(", "b", ",", "n", ".", "item", "(", ")", ",", "depths", "[", "b", "]", ".", "item", "(", ")", ",", "\"original\"", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "0", ",", "max_len", "=", "len", "(", "original_tokens_ids", "[", "0", "]", ")", ")", "\n", "cons_states_tensor", "=", "{", "}", "\n", "for", "label_name", "in", "label_names", ":", "\n", "            ", "cons_states_tensor", "[", "label_name", "]", "=", "pad_sequences_to_left_states", "(", "[", "self", ".", "get_states_from_node", "(", "b", ",", "n", ",", "depths", "[", "b", "]", ".", "item", "(", ")", ",", "label_name", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "0", ",", "max_len", "=", "len", "(", "cons_tokens_ids", "[", "label_name", "]", "[", "0", "]", ")", ")", "\n", "\n", "", "if", "(", "len", "(", "cons_tokens_ids", "[", "label_names", "[", "0", "]", "]", "[", "0", "]", ")", ">=", "MAX_SEQUENCE_LENGTH", ")", ":", "\n", "            ", "previous_node_is_terminal", "[", "torch", ".", "sum", "(", "cons_attention_masks", "[", "label_names", "[", "0", "]", "]", ",", "axis", "=", "1", ")", ".", "cpu", "(", ")", ">=", "MAX_SEQUENCE_LENGTH", "]", "=", "True", "\n", "original_tokens_ids", "=", "original_tokens_ids", "[", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "LABEL_LENGTH", "-", "1", ")", ":", "]", "\n", "original_attention_masks", "=", "original_attention_masks", "[", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "LABEL_LENGTH", "-", "1", ")", ":", "]", "\n", "original_states_tensor", "=", "original_states_tensor", "[", ":", ",", ":", ",", ":", ",", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "LABEL_LENGTH", "-", "1", ")", ":", "]", "\n", "for", "label_name", "in", "label_names", ":", "\n", "                ", "cons_states_tensor", "[", "label_name", "]", "=", "cons_states_tensor", "[", "label_name", "]", "[", ":", ",", ":", ",", ":", ",", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "1", ")", ":", "]", "\n", "cons_tokens_ids", "[", "label_name", "]", "=", "cons_tokens_ids", "[", "label_name", "]", "[", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "1", ")", ":", "]", "\n", "cons_attention_masks", "[", "label_name", "]", "=", "cons_attention_masks", "[", "label_name", "]", "[", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "1", ")", ":", "]", "\n", "", "", "original_states", "=", "tuple", "(", "tuple", "(", "type_of_value", "for", "type_of_value", "in", "layer", ")", "for", "layer", "in", "original_states_tensor", ")", "\n", "cons_states", "=", "tuple", "(", "tuple", "(", "type_of_value", "for", "type_of_value", "in", "layer", ")", "for", "layer", "in", "torch", ".", "cat", "(", "tuple", "(", "cons_states_tensor", "[", "label_name", "]", "for", "label_name", "in", "label_names", ")", ",", "dim", "=", "2", ")", ")", "\n", "\n", "\n", "\n", "# Convert sparse actions to dense actions for network computation", "\n", "dense_actions", "=", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "dense_actions", "[", "previous_node_is_terminal", "]", "=", "pad_token_id", "\n", "# Add actions to list of tokens and extend attention mask by 1", "\n", "original_tokens_ids", "=", "torch", ".", "cat", "(", "(", "original_tokens_ids", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "cuda", ".", "LongTensor", "(", "dense_actions", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "original_attention_masks", "=", "torch", ".", "cat", "(", "(", "original_attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "dense_actions", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "for", "label_name", "in", "label_names", ":", "\n", "            ", "cons_tokens_ids", "[", "label_name", "]", "=", "torch", ".", "cat", "(", "(", "cons_tokens_ids", "[", "label_name", "]", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "cuda", ".", "LongTensor", "(", "dense_actions", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "cons_attention_masks", "[", "label_name", "]", "=", "torch", ".", "cat", "(", "(", "cons_attention_masks", "[", "label_name", "]", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "dense_actions", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# Check if expanded nodes are terminal ", "\n", "", "expanded_node_is_terminal", "=", "np", ".", "logical_or", "(", "(", "dense_actions", "==", "pad_token_id", ")", ",", "previous_node_is_terminal", ")", "\n", "# Evaluate nodes.", "\n", "(", "prior", ",", "child_prob", ",", "next_states", ",", "cons_states", ")", "=", "self", ".", "_rec_fun", "(", "original_states", ",", "cons_states", ",", "original_tokens_ids", ",", "original_attention_masks", ",", "cons_tokens_ids", ",", "cons_attention_masks", ",", "values", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ")", "\n", "\n", "child_prob", "[", "previous_node_is_terminal", "]", "=", "torch", ".", "unsqueeze", "(", "values", "[", "previous_node_is_terminal", "]", ",", "2", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "tokenizer", ".", "vocab_size", ")", "\n", "\n", "for", "label_name", "in", "label_names", ":", "\n", "            ", "cons_attention_masks", "[", "label_name", "]", "=", "[", "torch", ".", "cat", "(", "(", "self", ".", "_attention_mask", "[", "label_name", "]", "[", "(", "b", ",", "n", ")", "]", ",", "torch", ".", "ones", "(", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", ")", ",", "dim", "=", "0", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", "\n", "cons_tokens_ids", "[", "label_name", "]", "=", "[", "torch", ".", "cat", "(", "(", "self", ".", "_token_ids", "[", "label_name", "]", "[", "(", "b", ",", "n", ")", "]", ",", "torch", ".", "cuda", ".", "LongTensor", "(", "[", "dense_actions", "[", "b", "]", "]", ")", ")", ",", "dim", "=", "0", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", "\n", "", "original_attention_masks", "=", "[", "torch", ".", "cat", "(", "(", "self", ".", "_attention_mask", "[", "\"original\"", "]", "[", "(", "b", ",", "n", ")", "]", ",", "torch", ".", "ones", "(", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", ")", ",", "dim", "=", "0", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", "\n", "original_tokens_ids", "=", "[", "torch", ".", "cat", "(", "(", "self", ".", "_token_ids", "[", "\"original\"", "]", "[", "(", "b", ",", "n", ")", "]", ",", "torch", ".", "cuda", ".", "LongTensor", "(", "[", "dense_actions", "[", "b", "]", "]", ")", ")", ",", "dim", "=", "0", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", "\n", "\n", "\n", "\n", "# Create the new nodes.", "\n", "values", "=", "torch", ".", "exp", "(", "-", "cross_entropy", "(", "values", ",", "self", ".", "_labels", ")", ")", ".", "cpu", "(", ")", "\n", "self", ".", "create_node", "(", "next_node_index", ",", "prior", ",", "likelihoods", "*", "children_priors", ",", "values", ",", "child_prob", ",", "next_states", ",", "original_tokens_ids", ",", "original_attention_masks", ",", "cons_states", ",", "cons_tokens_ids", ",", "cons_attention_masks", ",", "expanded_node_is_terminal", ")", "\n", "\n", "# Update the min and max values arrays", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "minimum", "(", "self", ".", "_adaptive_min_values", ",", "values", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "maximum", "(", "self", ".", "_adaptive_max_values", ",", "values", ")", "\n", "\n", "# Update tree topology.", "\n", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "=", "next_node_index", "\n", "self", ".", "_parents", "[", ":", ",", "next_node_index", "]", "=", "node_indices", "\n", "self", ".", "_action_from_parents", "[", ":", ",", "next_node_index", "]", "=", "actions", "\n", "self", ".", "_depth", "[", ":", ",", "next_node_index", "]", "=", "self", ".", "_depth", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.create_node": [[566, 612], ["child_prob.cpu", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "enumerate", "enumerate", "numpy.argpartition", "list", "list", "range", "range", "enumerate", "enumerate", "len", "enumerate", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "len", "enumerate", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "list", "range", "list", "range", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "create_node", "(", "self", ",", "node_index", ",", "prior", ",", "likelihoods", ",", "values", ",", "child_prob", ",", "original_states", ",", "original_tokens_ids", ",", "original_attention_masks", ",", "cons_states", ",", "cons_input_ids", ",", "cons_attention_mask", ",", "expanded_node_is_terminal", ")", ":", "\n", "# Truncate the prior to only keep the top k logits", "\n", "        ", "prior_topk_indices", "=", "np", ".", "argpartition", "(", "prior", ",", "-", "self", ".", "_num_sparse_actions", ",", "axis", "=", "-", "1", ")", "[", ":", ",", "-", "self", ".", "_num_sparse_actions", ":", "]", "\n", "child_prob", "=", "child_prob", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", ":", ",", "prior_topk_indices", "]", "# (B, A)", "\n", "prior", "=", "prior", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "prior_topk_indices", "]", "# (B, A)", "\n", "# Store the indices of the top k logits", "\n", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_index", ",", ":", "]", "=", "prior_topk_indices", "\n", "\n", "# Update prior, values and visit counts.", "\n", "self", ".", "_children_prior", "[", ":", ",", "node_index", ",", ":", "]", "=", "prior", "\n", "self", ".", "_children_probas", "[", ":", ",", "node_index", ",", ":", "]", "=", "child_prob", ".", "cpu", "(", ")", "\n", "self", ".", "_likelihoods", "[", ":", ",", "node_index", "]", "=", "likelihoods", "\n", "# raw_values = values**(self.alpha) * likelihoods**(1-self.alpha)", "\n", "raw_values", "=", "values", "\n", "self", ".", "_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_raw_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_visit_counts", "[", ":", ",", "node_index", "]", "=", "1", "\n", "self", ".", "_is_terminal", "[", ":", ",", "node_index", "]", "=", "expanded_node_is_terminal", "\n", "# States has shape [12 (nhead), 2(key/value), batch_size, 12(nlayer), seq_len, 64]", "\n", "original_key_value_tensor", "=", "torch", ".", "stack", "(", "list", "(", "torch", ".", "stack", "(", "list", "(", "original_states", "[", "i", "]", ")", ",", "dim", "=", "0", ")", "for", "i", "in", "range", "(", "len", "(", "original_states", ")", ")", ")", ",", "dim", "=", "0", ")", "\n", "cons_key_value_tensor", "=", "torch", ".", "stack", "(", "list", "(", "torch", ".", "stack", "(", "list", "(", "cons_states", "[", "i", "]", ")", ",", "dim", "=", "0", ")", "for", "i", "in", "range", "(", "len", "(", "cons_states", ")", ")", ")", ",", "dim", "=", "0", ")", "\n", "# If root, store the whole states", "\n", "if", "(", "node_index", "==", "0", ")", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "original_tokens_ids", ")", ")", ":", "\n", "                ", "for", "i", ",", "label_name", "in", "enumerate", "(", "label_names", ")", ":", "\n", "                    ", "self", ".", "_states", "[", "label_name", "]", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "cons_key_value_tensor", "[", ":", ",", ":", ",", "i", "*", "len", "(", "original_tokens_ids", ")", "+", "b", "]", ")", "\n", "", "self", ".", "_states", "[", "\"original\"", "]", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "original_key_value_tensor", "[", ":", ",", ":", ",", "b", "]", ")", "\n", "# Else just store the additional token hidden states to save space", "\n", "", "", "else", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "original_tokens_ids", ")", ")", ":", "\n", "                ", "for", "i", ",", "label_name", "in", "enumerate", "(", "label_names", ")", ":", "\n", "                    ", "self", ".", "_states", "[", "label_name", "]", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "cons_key_value_tensor", "[", ":", ",", ":", ",", "i", "*", "len", "(", "original_tokens_ids", ")", "+", "b", ",", ":", ",", "-", "1", ":", "]", ")", "\n", "", "self", ".", "_states", "[", "\"original\"", "]", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "original_key_value_tensor", "[", ":", ",", ":", ",", "b", ",", ":", ",", "-", "1", ":", "]", ")", "\n", "\n", "\n", "# Updates tokens ids ", "\n", "", "", "for", "b", ",", "original_token_ids", "in", "enumerate", "(", "original_tokens_ids", ")", ":", "\n", "            ", "for", "i", ",", "label_name", "in", "enumerate", "(", "label_names", ")", ":", "\n", "                ", "self", ".", "_token_ids", "[", "label_name", "]", "[", "(", "b", ",", "node_index", ")", "]", "=", "cons_input_ids", "[", "label_name", "]", "[", "b", "]", "\n", "", "self", ".", "_token_ids", "[", "\"original\"", "]", "[", "(", "b", ",", "node_index", ")", "]", "=", "original_token_ids", "\n", "\n", "# Updates attention masks", "\n", "", "for", "b", ",", "original_attention_mask", "in", "enumerate", "(", "original_attention_masks", ")", ":", "\n", "            ", "for", "i", ",", "label_name", "in", "enumerate", "(", "label_names", ")", ":", "\n", "                ", "self", ".", "_attention_mask", "[", "label_name", "]", "[", "(", "b", ",", "node_index", ")", "]", "=", "cons_attention_mask", "[", "label_name", "]", "[", "b", "]", "\n", "", "self", ".", "_attention_mask", "[", "\"original\"", "]", "[", "(", "b", ",", "node_index", ")", "]", "=", "original_attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.NumpyMCTS.backward": [[613, 637], ["is_root.all", "numpy.where", "numpy.where"], "methods", ["None"], ["", "", "def", "backward", "(", "self", ",", "leaf_indices", ")", ":", "\n", "        ", "\"\"\"Goes up and updates the tree until all nodes reached the root.\"\"\"", "\n", "node_indices", "=", "leaf_indices", "# (B)", "\n", "leaf_values", "=", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "leaf_indices", "]", "\n", "while", "True", ":", "\n", "            ", "is_root", "=", "node_indices", "==", "0", "\n", "if", "is_root", ".", "all", "(", ")", ":", "\n", "                ", "return", "\n", "", "parents", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "root_mask", "=", "1.0", "*", "is_root", "\n", "not_root_mask_int", "=", "(", "1", "-", "is_root", ")", "\n", "not_root_mask", "=", "1.0", "-", "root_mask", "\n", "# Update the parent nodes iff their child is not the root.", "\n", "# We therefore mask the updates using not_root_mask and root_mask.", "\n", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "=", "not_root_mask", "*", "(", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "*", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+", "leaf_values", ")", "/", "(", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "\n", "parents", "]", "+", "1.0", ")", "+", "root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "\n", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+=", "not_root_mask_int", "\n", "actions", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_action_from_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "=", "not_root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "root_mask", "*", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "\n", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "+=", "not_root_mask_int", "\n", "# Go up", "\n", "node_indices", "=", "parents", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.pad_sequences_to_left": [[106, 127], ["sequences[].size", "max", "sequences[].new_full", "enumerate", "tensor.size", "s.size", "len", "len"], "function", ["None"], ["def", "pad_sequences_to_left", "(", "sequences", ",", "batch_first", "=", "False", ",", "padding_value", "=", "0", ")", ":", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "    ", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "max_len", "=", "max", "(", "[", "s", ".", "size", "(", "0", ")", "for", "s", "in", "sequences", "]", ")", "\n", "if", "batch_first", ":", "\n", "        ", "out_dims", "=", "(", "len", "(", "sequences", ")", ",", "max_len", ")", "+", "trailing_dims", "\n", "", "else", ":", "\n", "        ", "out_dims", "=", "(", "max_len", ",", "len", "(", "sequences", ")", ")", "+", "trailing_dims", "\n", "\n", "", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# use index notation to prevent duplicate references to the tensor", "\n", "if", "batch_first", ":", "\n", "            ", "out_tensor", "[", "i", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "else", ":", "\n", "            ", "out_tensor", "[", "max_len", "-", "length", ":", ",", "i", ",", "...", "]", "=", "tensor", "\n", "", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.pad_sequences_to_left_states": [[129, 141], ["sequences[].size", "sequences[].new_full", "enumerate", "len", "tensor.size"], "function", ["None"], ["", "def", "pad_sequences_to_left_states", "(", "sequences", ",", "padding_value", "=", "0", ",", "max_len", "=", "0", ")", ":", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "    ", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "out_dims", "=", "(", "max_size", "[", "0", "]", ",", "max_size", "[", "1", "]", ",", "len", "(", "sequences", ")", ",", "max_size", "[", "2", "]", ",", "max_len", ",", "max_size", "[", "4", "]", ")", "\n", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ",", "device", "=", "\"cuda\"", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", ")", "[", "3", "]", "\n", "out_tensor", "[", ":", ",", ":", ",", "i", ",", ":", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.root_fun": [[143, 175], ["lm.prepare_inputs_for_generation", "torch.cat", "torch.cat", "torch.cat", "torch.cat.clone", "torch.cat", "torch.cat", "torch.cat", "gedi.prepare_inputs_for_generation", "torch.sum().view().permute", "torch.sum().view().permute", "torch.sum().view().permute", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lm", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax().cpu().numpy", "tuple", "tuple", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gedi", "torch.log_softmax().view().permute", "torch.sum().view().permute.view().expand", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.softmax().cpu", "len", "torch.log_softmax().view", "torch.sum().view().permute.view", "torch.sum", "torch.sum", "torch.sum", "len", "len", "torch.softmax", "torch.log_softmax", "torch.sum", "torch.sum", "torch.sum", "gedi_output[].view", "len"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand"], ["", "def", "root_fun", "(", "original_input", ",", "cons_input_ids", ",", "cons_attention_masks", ",", "labels", ",", "temperature", ",", "repetition_penalty", ")", ":", "\n", "# Forward pass of LM to get priors and states", "\n", "    ", "model_inputs", "=", "lm", ".", "prepare_inputs_for_generation", "(", "original_input", ".", "input_ids", ",", "attention_mask", "=", "original_input", ".", "attention_mask", ",", "use_cache", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "lm", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", "use_cache", "=", "True", ",", "\n", ")", "\n", "states", "=", "outputs", ".", "past_key_values", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "model_inputs", "[", "\"input_ids\"", "]", ")", "\n", "inverted_attention_mask", "=", "model_inputs", "[", "\"attention_mask\"", "]", "==", "0", "\n", "prompt_masked_input_ids", "[", "inverted_attention_mask", "]", "=", "14827", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "", "seq_ids", "=", "torch", ".", "cat", "(", "tuple", "(", "cons_input_ids", "[", "label_name", "]", "for", "label_name", "in", "label_names", ")", ",", "dim", "=", "0", ")", "\n", "label_tokens", "=", "seq_ids", ".", "clone", "(", ")", "\n", "seq_masks", "=", "torch", ".", "cat", "(", "tuple", "(", "cons_attention_masks", "[", "label_name", "]", "for", "label_name", "in", "label_names", ")", ",", "dim", "=", "0", ")", "\n", "gedi_inputs", "=", "gedi", ".", "prepare_inputs_for_generation", "(", "seq_ids", ",", "attention_mask", "=", "seq_masks", ")", "\n", "gedi_inputs", "[", "\"labels\"", "]", "=", "label_tokens", "\n", "# Use of our discriminator to get values", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "gedi_output", "=", "gedi", "(", "**", "gedi_inputs", ",", "return_dict", "=", "True", ",", "output_attentions", "=", "False", ",", "output_hidden_states", "=", "False", ",", "use_cache", "=", "True", ")", "\n", "", "gen_losses", "=", "torch", ".", "sum", "(", "(", "gedi_output", "[", "\"loss\"", "]", ".", "view", "(", "len", "(", "label_names", ")", "*", "original_input", "[", "\"input_ids\"", "]", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "*", "seq_masks", "[", ":", ",", "1", ":", "]", ")", "/", "torch", ".", "sum", "(", "seq_masks", "[", ":", ",", "1", ":", "]", ",", "1", ",", "keepdim", "=", "True", ")", ",", "dim", "=", "1", ")", ".", "view", "(", "len", "(", "label_names", ")", ",", "-", "1", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "child_prob", "=", "F", ".", "log_softmax", "(", "gedi_output", "[", "\"logits\"", "]", "[", ":", ",", "-", "1", ",", ":", "]", ")", ".", "view", "(", "len", "(", "label_names", ")", ",", "original_input", "[", "\"input_ids\"", "]", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "-", "gen_losses", ".", "view", "(", "original_input", "[", "\"input_ids\"", "]", ".", "shape", "[", "0", "]", ",", "len", "(", "label_names", ")", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "tokenizer", ".", "vocab_size", ")", "\n", "cons_states", "=", "gedi_output", ".", "past_key_values", "\n", "return", "priors", ",", "child_prob", ",", "states", ",", "cons_states", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.rec_fun": [[176, 207], ["lm.prepare_inputs_for_generation", "torch.cat", "torch.cat", "torch.cat", "torch.cat.clone", "torch.cat", "torch.cat", "torch.cat", "gedi.prepare_inputs_for_generation", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lm", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax().cpu().numpy", "tuple", "tuple", "torch.no_grad", "torch.no_grad", "torch.no_grad", "gedi", "torch.log_softmax().view().permute", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.unsqueeze().expand", "torch.softmax().cpu", "torch.log_softmax().view", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "len", "torch.softmax", "torch.log_softmax"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand"], ["", "def", "rec_fun", "(", "original_states", ",", "cons_states", ",", "original_token_ids", ",", "original_attention_masks", ",", "cons_input_ids", ",", "cons_attention_masks", ",", "values", ",", "labels", ",", "temperature", ",", "repetition_penalty", ")", ":", "\n", "# Forward pass of LM to get priors and states", "\n", "    ", "model_inputs", "=", "lm", ".", "prepare_inputs_for_generation", "(", "original_token_ids", ",", "attention_mask", "=", "original_attention_masks", ",", "past", "=", "original_states", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "lm", "(", "\n", "**", "model_inputs", ",", "\n", "use_cache", "=", "True", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "next_states", "=", "outputs", ".", "past_key_values", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "original_token_ids", ")", "\n", "inverted_attention_mask", "=", "original_attention_masks", "==", "0", "\n", "#penalizing an unused token", "\n", "prompt_masked_input_ids", "[", "inverted_attention_mask", "]", "=", "28988", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "seq_ids", "=", "torch", ".", "cat", "(", "tuple", "(", "cons_input_ids", "[", "label_name", "]", "for", "label_name", "in", "label_names", ")", ",", "dim", "=", "0", ")", "\n", "label_tokens", "=", "seq_ids", ".", "clone", "(", ")", "\n", "seq_masks", "=", "torch", ".", "cat", "(", "tuple", "(", "cons_attention_masks", "[", "label_name", "]", "for", "label_name", "in", "label_names", ")", ",", "dim", "=", "0", ")", "\n", "gedi_inputs", "=", "gedi", ".", "prepare_inputs_for_generation", "(", "seq_ids", ",", "attention_mask", "=", "seq_masks", ",", "past", "=", "cons_states", ")", "\n", "# Use of our discriminator to get values", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "gedi_output", "=", "gedi", "(", "**", "gedi_inputs", ",", "return_dict", "=", "True", ",", "output_attentions", "=", "False", ",", "output_hidden_states", "=", "False", ",", "use_cache", "=", "True", ")", "\n", "", "child_prob", "=", "F", ".", "log_softmax", "(", "gedi_output", "[", "\"logits\"", "]", "[", ":", ",", "-", "1", ",", ":", "]", ")", ".", "view", "(", "len", "(", "label_names", ")", ",", "original_token_ids", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "+", "torch", ".", "unsqueeze", "(", "values", ",", "2", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "tokenizer", ".", "vocab_size", ")", "\n", "cons_states", "=", "gedi_output", ".", "past_key_values", "\n", "return", "priors", ",", "child_prob", ",", "next_states", ",", "cons_states", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_gedi.main": [[638, 676], ["print", "pandas.read_csv", "print", "torch.zeros", "torch.zeros", "torch.zeros", "mcts_ag_bert_gedi.NumpyMCTS", "tqdm.tqdm", "torch.zeros.fill_", "enumerate", "mcts_ag_bert_gedi.NumpyMCTS.set_labels", "tokenizer().to", "mcts_ag_bert_gedi.NumpyMCTS.search", "tqdm.tqdm.update", "lines.iterrows", "int", "tokenizer().to", "str", "tokenizer", "str", "tokenizer", "label_name.upper"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.set_labels", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.search"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"loading dataset\"", ")", "\n", "data_lines", "=", "pd", ".", "read_csv", "(", "\"datasets/ag_news/full/prompts.tsv\"", ",", "sep", "=", "'\\t'", ",", "engine", "=", "'python'", ",", "encoding", "=", "\"utf8\"", ")", "\n", "print", "(", "\"dataset loaded\"", ")", "\n", "generated_counter", "=", "0", "\n", "samples_size", "=", "501", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "labels", "=", "torch", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", "\n", "texts", "=", "{", "}", "\n", "for", "label_name", "in", "label_names", ":", "\n", "        ", "texts", "[", "label_name", "]", "=", "[", "None", "]", "*", "batch_size", "\n", "", "texts", "[", "\"original\"", "]", "=", "[", "None", "]", "*", "batch_size", "\n", "MCTS", "=", "NumpyMCTS", "(", "root_fun", ",", "rec_fun", ",", "batch_size", "=", "batch_size", ",", "num_simulations", "=", "args", ".", "num_it", ",", "num_actions", "=", "vocab_size", "+", "1", ",", "num_sparse_actions", "=", "50", ",", "pb_c_init", "=", "args", ".", "c", ",", "temperature", "=", "args", ".", "temperature", ",", "alpha", "=", "args", ".", "alpha", ",", "penalty", "=", "args", ".", "penalty", ")", "\n", "samples_pbar", "=", "tqdm", "(", "total", "=", "samples_size", ",", "desc", "=", "\"Samples generated\"", ")", "\n", "while", "(", "generated_counter", "+", "batch_size", "<=", "samples_size", ")", ":", "\n", "        ", "labels", ".", "fill_", "(", "0", ")", "\n", "# Prepare search inputs", "\n", "lines", "=", "data_lines", "[", "generated_counter", ":", "generated_counter", "+", "batch_size", "]", "\n", "\n", "\n", "for", "i", ",", "(", "_", ",", "row", ")", "in", "enumerate", "(", "lines", ".", "iterrows", "(", ")", ")", ":", "\n", "            ", "labels", "[", "i", "]", "=", "int", "(", "row", "[", "\"label\"", "]", ")", "\n", "for", "label_name", "in", "label_names", ":", "\n", "                ", "texts", "[", "label_name", "]", "[", "i", "]", "=", "\"[CLS] [\"", "+", "label_name", ".", "upper", "(", ")", "+", "\"] \"", "+", "str", "(", "row", "[", "\"text\"", "]", ")", "\n", "", "texts", "[", "\"original\"", "]", "[", "i", "]", "=", "\"[CLS] \"", "+", "str", "(", "row", "[", "\"text\"", "]", ")", "\n", "\n", "", "MCTS", ".", "set_labels", "(", "labels", ")", "\n", "original_input", "=", "tokenizer", "(", "texts", "[", "\"original\"", "]", ",", "return_tensors", "=", "\"pt\"", ",", "padding", "=", "True", ",", "add_special_tokens", "=", "False", ",", "truncation", "=", "True", ",", "max_length", "=", "20", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "cons_input_ids", "=", "{", "}", "\n", "cons_attention_masks", "=", "{", "}", "\n", "for", "label_name", "in", "label_names", ":", "\n", "            ", "tokenizer_res", "=", "tokenizer", "(", "texts", "[", "label_name", "]", ",", "return_tensors", "=", "\"pt\"", ",", "padding", "=", "True", ",", "add_special_tokens", "=", "False", ",", "truncation", "=", "True", ",", "max_length", "=", "24", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "cons_input_ids", "[", "label_name", "]", "=", "tokenizer_res", "[", "\"input_ids\"", "]", "\n", "cons_attention_masks", "[", "label_name", "]", "=", "tokenizer_res", "[", "\"attention_mask\"", "]", "\n", "\n", "", "MCTS", ".", "search", "(", "original_input", ",", "cons_input_ids", ",", "cons_attention_masks", ")", "\n", "generated_counter", "+=", "batch_size", "\n", "samples_pbar", ".", "update", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.run_clm_bert.DataTrainingArguments.__post_init__": [[141, 151], ["ValueError", "run_clm_bert.DataTrainingArguments.train_file.split", "run_clm_bert.DataTrainingArguments.validation_file.split"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_name", "is", "None", "and", "self", ".", "train_file", "is", "None", "and", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a dataset name or a training/validation file.\"", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "train_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`train_file` should be a csv, a json or a txt file.\"", "\n", "", "if", "self", ".", "validation_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`validation_file` should be a csv, a json or a txt file.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.run_clm_bert.main": [[153, 422], ["transformers.HfArgumentParser", "logging.basicConfig", "logger.setLevel", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "logger.info", "datasets.load_dataset.map", "datasets.map.map", "transformers.Trainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "transformers.utils.logging.set_verbosity_info", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "datasets.load_dataset", "datasets.load_dataset", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForCausalLM.from_pretrained", "logger.info", "transformers.AutoModelForCausalLM.from_config", "AutoTokenizer.from_pretrained.", "min", "len", "result[].copy", "transformers.Trainer.train", "transformers.Trainer.save_model", "os.path.join", "transformers.Trainer.is_world_process_zero", "logger.info", "transformers.Trainer.evaluate", "math.exp", "os.path.join", "transformers.Trainer.is_world_process_zero", "len", "ValueError", "transformers.trainer_utils.is_main_process", "datasets.load_dataset.keys", "datasets.load_dataset", "datasets.load_dataset", "data_args.train_file.split", "transformers.AutoConfig.from_pretrained", "logger.warning", "transformers.AutoTokenizer.from_pretrained", "ValueError", "sum", "logger.warn", "logger.warn", "sum", "transformers.Trainer.state.save_to_json", "os.path.abspath", "len", "logger.info", "logging.StreamHandler", "bool", "examples.keys", "concatenated_examples.items", "os.path.isdir", "open", "logger.info", "sorted", "os.path.join", "open", "logger.info", "sorted", "os.listdir", "bool", "p.numel", "range", "trainer.train.metrics.items", "logger.info", "writer.write", "results.items", "logger.info", "writer.write", "AutoModelForCausalLM.from_config.parameters", "list", "examples.keys"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.set_seed"], ["", "", "", "", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Setup logging", "\n", "", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", "else", "logging", ".", "WARN", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)", "\n", "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/", "\n", "# (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files, this script will use the column called 'text' or the first column if no column called", "\n", "# 'text' is found. You can easily tweak this behavior (see below).", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "if", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "datasets", "=", "load_dataset", "(", "data_args", ".", "dataset_name", ",", "data_args", ".", "dataset_config_name", ")", "\n", "if", "\"validation\"", "not", "in", "datasets", ".", "keys", "(", ")", ":", "\n", "            ", "datasets", "[", "\"validation\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[:{data_args.validation_split_percentage}%]\"", ",", "\n", ")", "\n", "datasets", "[", "\"train\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[{data_args.validation_split_percentage}%:]\"", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"train\"", "]", "=", "data_args", ".", "train_file", "\n", "", "if", "data_args", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"validation\"", "]", "=", "data_args", ".", "validation_file", "\n", "", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "if", "extension", "==", "\"txt\"", ":", "\n", "            ", "extension", "=", "\"text\"", "\n", "", "datasets", "=", "load_dataset", "(", "extension", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "'/srv/tempdd/achaffin/.cache'", ")", "\n", "# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "\n", "", "config_kwargs", "=", "{", "\n", "\"is_decoder\"", ":", "True", ",", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "\"position_embedding_type\"", ":", "\"relative_key_query\"", "\n", "}", "\n", "if", "model_args", ".", "config_name", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "config_name", ",", "**", "config_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "config_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "CONFIG_MAPPING", "[", "model_args", ".", "model_type", "]", "(", ")", "\n", "logger", ".", "warning", "(", "\"You are instantiating a new config instance from scratch.\"", ")", "\n", "\n", "", "tokenizer_kwargs", "=", "{", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"use_fast\"", ":", "model_args", ".", "use_fast_tokenizer", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "# \"bos_token\": \"[startoftext]\",", "\n", "# \"eos_token\": \"<|endoftext|>\",", "\n", "# \"sep_token\": \"[SEP]\"", "\n", "}", "\n", "if", "model_args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "tokenizer_name", ",", "**", "tokenizer_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "tokenizer_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"", "\n", "\"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"", "\n", ")", "\n", "# special_tokens_dict = {", "\n", "# \"bos_token\": \"<|startoftext|>\",", "\n", "# \"eos_token\": \"<|endoftext|>\",", "\n", "# # \"sep_token\": \"[SEP]\"", "\n", "# }", "\n", "# tokenizer.add_special_tokens(special_tokens_dict)", "\n", "# logger.info(\"Token bos = {}\".format(tokenizer.bos_token))", "\n", "# logger.info(\"Token eos = {}\".format(tokenizer.eos_token))", "\n", "# logger.info(\"Token sep = {}\".format(tokenizer.sep_token))", "\n", "\n", "", "if", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "AutoModelForCausalLM", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "AutoModelForCausalLM", ".", "from_config", "(", "config", ")", "\n", "\n", "#logger.info(\"The size of the model is {}\".format(len([x for x in model.parameters()])))", "\n", "", "logger", ".", "info", "(", "\"The size of the model is {}\"", ".", "format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", ")", ")", "\n", "# model.resize_token_embeddings(len(tokenizer))", "\n", "\n", "# Preprocessing the datasets.", "\n", "# First we tokenize all the texts.", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"train\"", "]", ".", "column_names", "\n", "", "else", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"validation\"", "]", ".", "column_names", "\n", "", "text_column_name", "=", "\"text\"", "if", "\"text\"", "in", "column_names", "else", "column_names", "[", "0", "]", "\n", "\n", "def", "tokenize_function", "(", "examples", ")", ":", "\n", "        ", "return", "tokenizer", "(", "examples", "[", "text_column_name", "]", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "", "tokenized_datasets", "=", "datasets", ".", "map", "(", "\n", "tokenize_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "if", "data_args", ".", "block_size", "is", "None", ":", "\n", "        ", "block_size", "=", "tokenizer", ".", "model_max_length", "\n", "if", "block_size", ">", "1024", ":", "\n", "            ", "logger", ".", "warn", "(", "\n", "f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}). \"", "\n", "\"Picking 1024 instead. You can change that default value by passing --block_size xxx.\"", "\n", ")", "\n", "block_size", "=", "1024", "\n", "", "", "else", ":", "\n", "        ", "if", "data_args", ".", "block_size", ">", "tokenizer", ".", "model_max_length", ":", "\n", "            ", "logger", ".", "warn", "(", "\n", "f\"The block_size passed ({data_args.block_size}) is larger than the maximum length for the model\"", "\n", "f\"({tokenizer.model_max_length}). Using block_size={tokenizer.model_max_length}.\"", "\n", ")", "\n", "", "block_size", "=", "min", "(", "data_args", ".", "block_size", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "# Main data processing function that will concatenate all texts from our dataset and generate chunks of block_size.", "\n", "", "def", "group_texts", "(", "examples", ")", ":", "\n", "# Concatenate all texts.", "\n", "        ", "concatenated_examples", "=", "{", "k", ":", "sum", "(", "examples", "[", "k", "]", ",", "[", "]", ")", "for", "k", "in", "examples", ".", "keys", "(", ")", "}", "\n", "total_length", "=", "len", "(", "concatenated_examples", "[", "list", "(", "examples", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ")", "\n", "# We drop the small remainder, we could add padding if the model supported it instead of this drop, you can", "\n", "# customize this part to your needs.", "\n", "total_length", "=", "(", "total_length", "//", "block_size", ")", "*", "block_size", "\n", "# Split by chunks of max_len.", "\n", "result", "=", "{", "\n", "k", ":", "[", "t", "[", "i", ":", "i", "+", "block_size", "]", "for", "i", "in", "range", "(", "0", ",", "total_length", ",", "block_size", ")", "]", "\n", "for", "k", ",", "t", "in", "concatenated_examples", ".", "items", "(", ")", "\n", "}", "\n", "result", "[", "\"labels\"", "]", "=", "result", "[", "\"input_ids\"", "]", ".", "copy", "(", ")", "\n", "return", "result", "\n", "\n", "# Note that with `batched=True`, this map processes 1,000 texts together, so group_texts throws away a remainder", "\n", "# for each of those groups of 1,000 texts. You can adjust that batch_size here but a higher value might be slower", "\n", "# to preprocess.", "\n", "#", "\n", "# To speed up this part, we use multiprocessing. See the documentation of the map method for more information:", "\n", "# https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map", "\n", "", "lm_datasets", "=", "tokenized_datasets", ".", "map", "(", "\n", "group_texts", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "# Initialize our Trainer", "\n", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "lm_datasets", "[", "\"train\"", "]", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "lm_datasets", "[", "\"validation\"", "]", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "# Data collator will default to DataCollatorWithPadding, so we change it.", "\n", "data_collator", "=", "default_data_collator", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "model_path", "=", "last_checkpoint", "\n", "", "elif", "model_args", ".", "model_name_or_path", "is", "not", "None", "and", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", ":", "\n", "            ", "model_path", "=", "model_args", ".", "model_name_or_path", "\n", "", "else", ":", "\n", "            ", "model_path", "=", "None", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "model_path", "=", "model_path", ")", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "output_train_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"train_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_train_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Train results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "train_result", ".", "metrics", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "# Need to save the state, since Trainer.save_model saves only the tokenizer with the model", "\n", "", "", "trainer", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "", "results", "=", "{", "}", "\n", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "eval_output", "=", "trainer", ".", "evaluate", "(", ")", "\n", "\n", "perplexity", "=", "math", ".", "exp", "(", "eval_output", "[", "\"eval_loss\"", "]", ")", "\n", "results", "[", "\"perplexity\"", "]", "=", "perplexity", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"eval_results_clm.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "results", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.run_clm_bert._mp_fn": [[424, 427], ["run_clm_bert.main"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.main"], ["", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_generative_ag.DataTrainingArguments.__post_init__": [[144, 154], ["ValueError", "classifier_generative_ag.DataTrainingArguments.train_file.split", "classifier_generative_ag.DataTrainingArguments.validation_file.split"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_name", "is", "None", "and", "self", ".", "train_file", "is", "None", "and", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a dataset name or a training/validation file.\"", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "train_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`train_file` should be a csv, a json or a txt file.\"", "\n", "", "if", "self", ".", "validation_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`validation_file` should be a csv, a json or a txt file.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_generative_ag.main": [[156, 449], ["transformers.HfArgumentParser", "logging.basicConfig", "logger.setLevel", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "logger.info", "datasets.load_dataset.map", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "datasets.load_metric", "print", "print", "ClassificationLossTrainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "transformers.utils.logging.set_verbosity_info", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "datasets.load_dataset", "datasets.load_dataset", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForCausalLM.from_pretrained", "logger.info", "transformers.AutoModelForCausalLM.from_config", "enumerate", "min", "print", "ClassificationLossTrainer.train", "ClassificationLossTrainer.save_model", "os.path.join", "ClassificationLossTrainer.is_world_process_zero", "logger.info", "ClassificationLossTrainer.evaluate", "math.exp", "os.path.join", "ClassificationLossTrainer.is_world_process_zero", "len", "ValueError", "transformers.trainer_utils.is_main_process", "datasets.load_dataset.keys", "datasets.load_dataset", "datasets.load_dataset", "data_args.train_file.split", "transformers.AutoConfig.from_pretrained", "logger.warning", "transformers.AutoTokenizer.from_pretrained", "ValueError", "sum", "AutoTokenizer.from_pretrained.", "logger.warn", "logger.warn", "torch.cat().view.clone", "AutoModelForCausalLM.from_config.", "torch.sum().view().permute", "torch.sum().view().permute", "torch.softmax", "classifier_generative_ag.._prepare_inputs", "ClassificationLossTrainer.state.save_to_json", "os.path.abspath", "len", "logger.info", "logging.StreamHandler", "bool", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max", "torch.max", "random.randint", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.no_grad", "torch.no_grad", "classifier_generative_ag..compute_loss", "os.path.isdir", "open", "logger.info", "sorted", "os.path.join", "open", "logger.info", "sorted", "os.listdir", "bool", "p.numel", "tuple", "tuple", "torch.sum", "torch.sum", "min", "torch.sum().view", "torch.sum().view", "torch.nn.CrossEntropyLoss.", "torch.sum", "torch.sum", "len", "trainer.train.metrics.items", "logger.info", "writer.write", "results.items", "logger.info", "writer.write", "AutoModelForCausalLM.from_config.parameters", "torch.cat", "torch.cat", "len", "torch.cat", "torch.cat", "len", "len", "gen_losses[].sum", "str", "torch.sum", "torch.sum", "tuple", "tuple", "torch.sum", "torch.sum", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "label.upper", "torch.sum", "torch.sum", "enumerate", "enumerate", "outputs[].view", "torch.arange", "torch.arange", "len", "torch.sum().view().permute.size"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.set_seed"], ["", "", "", "", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Setup logging", "\n", "", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", "else", "logging", ".", "WARN", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)", "\n", "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/", "\n", "# (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files, this script will use the column called 'text' or the first column if no column called", "\n", "# 'text' is found. You can easily tweak this behavior (see below).", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "if", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "datasets", "=", "load_dataset", "(", "data_args", ".", "dataset_name", ",", "data_args", ".", "dataset_config_name", ")", "\n", "if", "\"validation\"", "not", "in", "datasets", ".", "keys", "(", ")", ":", "\n", "            ", "datasets", "[", "\"validation\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[:{data_args.validation_split_percentage}%]\"", ",", "\n", ")", "\n", "datasets", "[", "\"train\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[{data_args.validation_split_percentage}%:]\"", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"train\"", "]", "=", "data_args", ".", "train_file", "\n", "", "if", "data_args", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"validation\"", "]", "=", "data_args", ".", "validation_file", "\n", "", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "if", "extension", "==", "\"txt\"", ":", "\n", "            ", "extension", "=", "\"text\"", "\n", "", "datasets", "=", "load_dataset", "(", "extension", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "'/srv/tempdd/achaffin/.cache'", ")", "\n", "# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "\n", "", "config_kwargs", "=", "{", "\n", "\"is_decoder\"", ":", "True", ",", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "\"position_embedding_type\"", ":", "\"relative_key\"", "\n", "}", "\n", "if", "model_args", ".", "config_name", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "config_name", ",", "**", "config_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "config_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "CONFIG_MAPPING", "[", "model_args", ".", "model_type", "]", "(", ")", "\n", "logger", ".", "warning", "(", "\"You are instantiating a new config instance from scratch.\"", ")", "\n", "\n", "", "tokenizer_kwargs", "=", "{", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"use_fast\"", ":", "model_args", ".", "use_fast_tokenizer", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "}", "\n", "if", "model_args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "tokenizer_name", ",", "**", "tokenizer_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "tokenizer_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"", "\n", "\"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"", "\n", ")", "\n", "", "tokenizer", ".", "padding_side", "=", "\"left\"", "\n", "\n", "if", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "AutoModelForCausalLM", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "AutoModelForCausalLM", ".", "from_config", "(", "config", ")", "\n", "", "logger", ".", "info", "(", "\"The size of the model is {}\"", ".", "format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", ")", ")", "\n", "\n", "\n", "# Preprocessing the datasets.", "\n", "# First we tokenize all the texts.", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"train\"", "]", ".", "column_names", "\n", "", "else", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"validation\"", "]", ".", "column_names", "\n", "", "text_column_name", "=", "\"text\"", "if", "\"text\"", "in", "column_names", "else", "column_names", "[", "-", "1", "]", "\n", "labels", "=", "[", "\"Wor\"", ",", "\"Spo\"", ",", "\"Bus\"", ",", "\"Sci\"", "]", "\n", "def", "tokenize_function", "(", "examples", ")", ":", "\n", "        ", "res", "=", "{", "}", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "            ", "tokenizer_result", "=", "tokenizer", "(", "[", "\"[CLS] [\"", "+", "label", ".", "upper", "(", ")", "+", "\"] \"", "+", "str", "(", "example", ")", "+", "\"[PAD]\"", "for", "example", "in", "examples", "[", "\"text\"", "]", "]", ",", "padding", "=", "\"max_length\"", ",", "max_length", "=", "512", ",", "truncation", "=", "True", ",", "add_special_tokens", "=", "False", ")", "\n", "res", "[", "\"input_ids_\"", "+", "label", "]", "=", "tokenizer_result", "[", "\"input_ids\"", "]", "\n", "res", "[", "\"attention_mask_\"", "+", "label", "]", "=", "tokenizer_result", "[", "\"attention_mask\"", "]", "\n", "\n", "", "res", "[", "\"labels\"", "]", "=", "examples", "[", "\"label\"", "]", "\n", "\n", "return", "res", "\n", "\n", "", "tokenized_datasets", "=", "datasets", ".", "map", "(", "\n", "tokenize_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "if", "data_args", ".", "block_size", "is", "None", ":", "\n", "        ", "block_size", "=", "tokenizer", ".", "model_max_length", "\n", "if", "block_size", ">", "1024", ":", "\n", "            ", "logger", ".", "warn", "(", "\n", "f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}). \"", "\n", "\"Picking 1024 instead. You can change that default value by passing --block_size xxx.\"", "\n", ")", "\n", "", "block_size", "=", "1024", "\n", "", "else", ":", "\n", "        ", "if", "data_args", ".", "block_size", ">", "tokenizer", ".", "model_max_length", ":", "\n", "            ", "logger", ".", "warn", "(", "\n", "f\"The block_size passed ({data_args.block_size}) is larger than the maximum length for the model\"", "\n", "f\"({tokenizer.model_max_length}). Using block_size={tokenizer.model_max_length}.\"", "\n", ")", "\n", "", "block_size", "=", "min", "(", "data_args", ".", "block_size", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "", "loss_fn", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "class", "ClassificationLossTrainer", "(", "Trainer", ")", ":", "\n", "        ", "def", "compute_loss", "(", "self", ",", "model", ",", "inputs", ",", "return_outputs", "=", "False", ",", "is_eval", "=", "False", ")", ":", "\n", "            ", "if", "(", "is_eval", ")", ":", "\n", "                ", "seq_batched", "=", "torch", ".", "cat", "(", "tuple", "(", "inputs", "[", "\"input_ids_\"", "+", "label", "]", "for", "label", "in", "labels", ")", ",", "dim", "=", "0", ")", "\n", "attention_masks", "=", "torch", ".", "cat", "(", "tuple", "(", "inputs", "[", "\"attention_mask_\"", "+", "label", "]", "for", "label", "in", "labels", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "max_len", "=", "torch", ".", "max", "(", "torch", ".", "sum", "(", "inputs", "[", "\"attention_mask_\"", "+", "labels", "[", "0", "]", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "# Sample how many token we keep to do training on variable length (at least one, up to full sequences)", "\n", "random_len", "=", "randint", "(", "2", ",", "max_len", ")", "\n", "total_len", "=", "inputs", "[", "\"input_ids_\"", "+", "labels", "[", "0", "]", "]", ".", "shape", "[", "-", "1", "]", "\n", "# Since left padding, need to compute the starting index in order to get the sequence with corresponding length. If len(seq) > random_len, take from start:start+random_len to get the beginning of the sequence, start from total_len-random_len:", "\n", "start_indexes", "=", "[", "min", "(", "total_len", "-", "random_len", ",", "total_len", "-", "torch", ".", "sum", "(", "attention_mask", ")", ")", "for", "attention_mask", "in", "inputs", "[", "\"attention_mask_\"", "+", "labels", "[", "0", "]", "]", "]", "\n", "\n", "seq_batched", "=", "torch", ".", "cat", "(", "tuple", "(", "inputs", "[", "\"input_ids_\"", "+", "label", "]", "[", "i", ",", "start_index", ":", "start_index", "+", "random_len", "]", "for", "label", "in", "labels", "for", "i", ",", "start_index", "in", "enumerate", "(", "start_indexes", ")", ")", ",", "dim", "=", "0", ")", ".", "view", "(", "len", "(", "labels", ")", "*", "inputs", "[", "\"input_ids_\"", "+", "labels", "[", "0", "]", "]", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "attention_masks", "=", "torch", ".", "cat", "(", "tuple", "(", "inputs", "[", "\"attention_mask_\"", "+", "label", "]", "[", "i", ",", "start_index", ":", "start_index", "+", "random_len", "]", "for", "label", "in", "labels", "for", "i", ",", "start_index", "in", "enumerate", "(", "start_indexes", ")", ")", ",", "dim", "=", "0", ")", ".", "view", "(", "len", "(", "labels", ")", "*", "inputs", "[", "\"input_ids_\"", "+", "labels", "[", "0", "]", "]", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "", "labels_token", "=", "seq_batched", ".", "clone", "(", ")", "\n", "\n", "outputs", "=", "model", "(", "seq_batched", ",", "attention_mask", "=", "attention_masks", ",", "labels", "=", "labels_token", ")", "\n", "# Inputs are flattened into the LM, so we first restore the original shape to mask padding token loss, normalize by the number of tokens and then group the different class-version of each prompt (because we inputed prompts grouped by class, not by prompt : (num_class, nb_prompts) -> (nb_prompts, num_class))", "\n", "gen_losses", "=", "torch", ".", "sum", "(", "(", "outputs", "[", "\"loss\"", "]", ".", "view", "(", "len", "(", "labels", ")", "*", "inputs", "[", "\"labels\"", "]", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "*", "attention_masks", "[", ":", ",", ":", "-", "1", "]", ")", "/", "torch", ".", "sum", "(", "attention_masks", "[", ":", ",", ":", "-", "1", "]", ",", "1", ",", "keepdim", "=", "True", ")", ",", "dim", "=", "1", ")", ".", "view", "(", "len", "(", "labels", ")", ",", "-", "1", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "# print(gen_losses)", "\n", "\n", "# Use cross entropy to get the log-softmax of the target label. Get gen_losses corresponding prompts with the correct control code", "\n", "loss", "=", "loss_fn", "(", "-", "gen_losses", ",", "inputs", "[", "\"labels\"", "]", ")", "*", "0.4", "+", "gen_losses", "[", "torch", ".", "arange", "(", "gen_losses", ".", "size", "(", "0", ")", ")", ",", "inputs", "[", "\"labels\"", "]", "]", ".", "sum", "(", "dim", "=", "0", ")", "/", "inputs", "[", "\"labels\"", "]", ".", "shape", "[", "0", "]", "*", "0.6", "# class_loss + LM loss", "\n", "outputs", "[", "\"logits\"", "]", "=", "F", ".", "softmax", "(", "-", "gen_losses", ",", "dim", "=", "-", "1", ")", "\n", "return", "(", "loss", ",", "outputs", ")", "if", "return_outputs", "else", "loss", "\n", "", "def", "prediction_step", "(", "self", ",", "model", ",", "inputs", ",", "prediction_loss_only", ",", "ignore_keys", ")", ":", "\n", "            ", "inputs", "=", "self", ".", "_prepare_inputs", "(", "inputs", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "loss", ",", "outputs", "=", "self", ".", "compute_loss", "(", "model", ",", "inputs", ",", "return_outputs", "=", "True", ",", "is_eval", "=", "True", ")", "\n", "", "return", "(", "loss", ",", "outputs", "[", "\"logits\"", "]", ",", "inputs", "[", "\"labels\"", "]", ")", "\n", "\n", "", "", "accuracy", "=", "load_metric", "(", "\"accuracy\"", ")", "\n", "def", "compute_metrics", "(", "eval_pred", ")", ":", "\n", "        ", "print", "(", "eval_pred", ")", "\n", "predictions", ",", "labels", "=", "eval_pred", "\n", "res", "=", "{", "}", "\n", "res", "[", "\"accuracy\"", "]", "=", "(", "torch", ".", "sum", "(", "torch", ".", "argmax", "(", "torch", ".", "tensor", "(", "predictions", ")", ",", "dim", "=", "-", "1", ")", "==", "torch", ".", "tensor", "(", "labels", ")", ")", "/", "len", "(", "labels", ")", ")", ".", "item", "(", ")", "\n", "return", "res", "\n", "# return accuracy.compute(predictions=predictions, references=labels)", "\n", "# Note that with `batched=True`, this map processes 1,000 texts together, so group_texts throws away a remainder", "\n", "# for each of those groups of 1,000 texts. You can adjust that batch_size here but a higher value might be slower", "\n", "# to preprocess.", "\n", "#", "\n", "# To speed up this part, we use multiprocessing. See the documentation of the map method for more information:", "\n", "# https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map", "\n", "# lm_datasets = tokenized_datasets.map(", "\n", "#     group_texts,", "\n", "#     batched=True,", "\n", "#     num_proc=data_args.preprocessing_num_workers,", "\n", "#     load_from_cache_file=not data_args.overwrite_cache,", "\n", "# )", "\n", "#optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)", "\n", "\n", "# Initialize our Trainer", "\n", "", "print", "(", "tokenized_datasets", "[", "\"train\"", "]", ")", "\n", "print", "(", "tokenized_datasets", "[", "\"validation\"", "]", ")", "\n", "trainer", "=", "ClassificationLossTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "tokenized_datasets", "[", "\"train\"", "]", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "tokenized_datasets", "[", "\"validation\"", "]", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "# tokenizer=tokenizer,", "\n", "# Data collator will default to DataCollatorWithPadding, so we change it.", "\n", "data_collator", "=", "default_data_collator", ",", "\n", "compute_metrics", "=", "compute_metrics", "\n", ")", "\n", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "model_path", "=", "last_checkpoint", "\n", "", "elif", "model_args", ".", "model_name_or_path", "is", "not", "None", "and", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", ":", "\n", "            ", "model_path", "=", "model_args", ".", "model_name_or_path", "\n", "", "else", ":", "\n", "            ", "model_path", "=", "None", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "model_path", "=", "model_path", ")", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "output_train_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"train_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_train_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Train results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "train_result", ".", "metrics", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "# Need to save the state, since Trainer.save_model saves only the tokenizer with the model", "\n", "", "", "trainer", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "", "results", "=", "{", "}", "\n", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "eval_output", "=", "trainer", ".", "evaluate", "(", ")", "\n", "\n", "perplexity", "=", "math", ".", "exp", "(", "eval_output", "[", "\"eval_loss\"", "]", ")", "\n", "results", "[", "\"perplexity\"", "]", "=", "perplexity", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"eval_results_clm.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "results", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_generative_ag._mp_fn": [[451, 454], ["classifier_generative_ag.main"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.main"], ["", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_generative_ag.pad_sequences_to_left": [[456, 477], ["sequences[].size", "sequences[].new_full", "enumerate", "tensor.size", "len", "len"], "function", ["None"], ["", "def", "pad_sequences_to_left", "(", "sequences", ",", "batch_first", "=", "False", ",", "padding_value", "=", "0", ",", "max_len", "=", "0", ")", ":", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "    ", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "# max_len = max([s.size(0) for s in sequences])", "\n", "if", "batch_first", ":", "\n", "        ", "out_dims", "=", "(", "len", "(", "sequences", ")", ",", "max_len", ")", "+", "trailing_dims", "\n", "", "else", ":", "\n", "        ", "out_dims", "=", "(", "max_len", ",", "len", "(", "sequences", ")", ")", "+", "trailing_dims", "\n", "\n", "", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# use index notation to prevent duplicate references to the tensor", "\n", "if", "batch_first", ":", "\n", "            ", "out_tensor", "[", "i", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "else", ":", "\n", "            ", "out_tensor", "[", "max_len", "-", "length", ":", ",", "i", ",", "...", "]", "=", "tensor", "\n", "", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_uni_ag.DataTrainingArguments.__post_init__": [[107, 117], ["ValueError", "classifier_uni_ag.DataTrainingArguments.train_file.split", "classifier_uni_ag.DataTrainingArguments.validation_file.split"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_name", "is", "None", "and", "self", ".", "train_file", "is", "None", "and", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a dataset name or a training/validation file.\"", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "train_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`train_file` should be a csv, a json or a txt file.\"", "\n", "", "if", "self", ".", "validation_file", "is", "not", "None", ":", "\n", "                ", "extension", "=", "self", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "assert", "extension", "in", "[", "\"csv\"", ",", "\"json\"", ",", "\"txt\"", "]", ",", "\"`validation_file` should be a csv, a json or a txt file.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_uni_ag.Net.__init__": [[121, 127], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "config", ".", "output_hidden_states", "=", "True", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", "=", "config", ")", "\n", "# Classification layer from (hidden_states, num_classes)", "\n", "self", ".", "fc_classif", "=", "nn", ".", "Linear", "(", "768", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_uni_ag.Net.forward": [[128, 151], ["classifier_uni_ag.Net.bert", "classifier_uni_ag.Net.fc_classif", "loss_fct", "transformers.modeling_outputs.SequenceClassifierOutput", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "[].size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "# Get mean of hidden states", "\n", "# text = F.normalize(torch.div(torch.sum(outputs[2][-1], axis=1),torch.unsqueeze(torch.sum(attention_mask, axis=1),1)))", "\n", "#\u00a0Get last (non padding) token hidden_states ", "\n", "text", "=", "outputs", "[", "2", "]", "[", "-", "1", "]", "[", "torch", ".", "arange", "(", "outputs", "[", "2", "]", "[", "-", "1", "]", ".", "size", "(", "0", ")", ")", ",", "torch", ".", "sum", "(", "attention_mask", ",", "axis", "=", "1", ")", "-", "1", "]", "\n", "logits", "=", "self", ".", "fc_classif", "(", "text", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ",", "labels", ")", "\n", "return", "SequenceClassifierOutput", "(", "\n", "loss", "=", "loss", ",", "\n", "logits", "=", "logits", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.classifier_uni_ag.main": [[153, 382], ["transformers.HfArgumentParser", "logging.basicConfig", "logger.setLevel", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "Net.from_pretrained.cuda", "datasets.load_dataset.map", "ClassificationLossTrainer", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "transformers.utils.logging.set_verbosity_info", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "datasets.load_dataset", "datasets.load_dataset", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "Net.from_pretrained", "AutoTokenizer.from_pretrained.", "print", "ClassificationLossTrainer.train", "ClassificationLossTrainer.save_model", "os.path.join", "ClassificationLossTrainer.is_world_process_zero", "logger.info", "ClassificationLossTrainer.evaluate", "os.path.join", "ClassificationLossTrainer.is_world_process_zero", "len", "ValueError", "transformers.trainer_utils.is_main_process", "datasets.load_dataset.keys", "datasets.load_dataset", "datasets.load_dataset", "data_args.train_file.split", "transformers.AutoConfig.from_pretrained", "logger.warning", "transformers.AutoTokenizer.from_pretrained", "ValueError", "torch.max", "torch.max", "torch.max", "random.randint", "classifier_uni_ag.._prepare_inputs", "ClassificationLossTrainer.state.save_to_json", "os.path.abspath", "len", "logger.info", "logging.StreamHandler", "bool", "torch.sum", "torch.sum", "torch.sum", "Net.from_pretrained.", "Net.from_pretrained.", "torch.no_grad", "torch.no_grad", "torch.no_grad", "classifier_uni_ag..compute_loss", "os.path.isdir", "open", "logger.info", "sorted", "os.path.join", "open", "logger.info", "sorted", "os.listdir", "bool", "torch.sum", "torch.sum", "torch.sum", "len", "trainer.train.metrics.items", "logger.info", "writer.write", "results.items", "logger.info", "writer.write", "torch.argmax", "torch.argmax", "torch.argmax", "torch.tensor", "torch.tensor", "torch.tensor", "torch.softmax", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.None.mcts_rollout_amazon.set_seed"], ["", "", "def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "TrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Setup logging", "\n", "", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", "else", "logging", ".", "WARN", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON/TXT training and evaluation files (see below)", "\n", "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/", "\n", "# (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files, this script will use the column called 'text' or the first column if no column called", "\n", "# 'text' is found. You can easily tweak this behavior (see below).", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "if", "data_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "# Downloading and loading a dataset from the hub.", "\n", "        ", "datasets", "=", "load_dataset", "(", "data_args", ".", "dataset_name", ",", "data_args", ".", "dataset_config_name", ")", "\n", "if", "\"validation\"", "not", "in", "datasets", ".", "keys", "(", ")", ":", "\n", "            ", "datasets", "[", "\"validation\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[:{data_args.validation_split_percentage}%]\"", ",", "\n", ")", "\n", "datasets", "[", "\"train\"", "]", "=", "load_dataset", "(", "\n", "data_args", ".", "dataset_name", ",", "\n", "data_args", ".", "dataset_config_name", ",", "\n", "split", "=", "f\"train[{data_args.validation_split_percentage}%:]\"", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"train\"", "]", "=", "data_args", ".", "train_file", "\n", "", "if", "data_args", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"validation\"", "]", "=", "data_args", ".", "validation_file", "\n", "", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "if", "extension", "==", "\"txt\"", ":", "\n", "            ", "extension", "=", "\"text\"", "\n", "", "datasets", "=", "load_dataset", "(", "extension", ",", "data_files", "=", "data_files", ",", "cache_dir", "=", "'./.cache'", ")", "\n", "# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at", "\n", "# https://huggingface.co/docs/datasets/loading_datasets.html.", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "\n", "", "config_kwargs", "=", "{", "\n", "\"is_decoder\"", ":", "True", ",", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "}", "\n", "if", "model_args", ".", "config_name", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "config_name", ",", "**", "config_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "config_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "CONFIG_MAPPING", "[", "model_args", ".", "model_type", "]", "(", ")", "\n", "logger", ".", "warning", "(", "\"You are instantiating a new config instance from scratch.\"", ")", "\n", "\n", "", "tokenizer_kwargs", "=", "{", "\n", "\"cache_dir\"", ":", "model_args", ".", "cache_dir", ",", "\n", "\"use_fast\"", ":", "model_args", ".", "use_fast_tokenizer", ",", "\n", "\"revision\"", ":", "model_args", ".", "model_revision", ",", "\n", "\"use_auth_token\"", ":", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", "}", "\n", "if", "model_args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "tokenizer_name", ",", "**", "tokenizer_kwargs", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ",", "**", "tokenizer_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"", "\n", "\"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"", "\n", ")", "\n", "\n", "\n", "", "if", "model_args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "Net", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "", "model", "=", "model", ".", "cuda", "(", ")", "\n", "# Preprocessing the datasets.", "\n", "# First we tokenize all the texts.", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"train\"", "]", ".", "column_names", "\n", "", "else", ":", "\n", "        ", "column_names", "=", "datasets", "[", "\"validation\"", "]", ".", "column_names", "\n", "", "text_column_name", "=", "\"text\"", "if", "\"text\"", "in", "column_names", "else", "column_names", "[", "-", "1", "]", "\n", "\n", "def", "tokenize_function", "(", "examples", ")", ":", "\n", "# res = {}", "\n", "        ", "inputs", "=", "[", "\"[CLS] \"", "+", "example", "+", "\"[PAD]\"", "for", "example", "in", "examples", "[", "\"text\"", "]", "]", "\n", "res", "=", "tokenizer", "(", "inputs", ",", "padding", "=", "\"max_length\"", ",", "max_length", "=", "512", ",", "truncation", "=", "True", ",", "add_special_tokens", "=", "False", ")", "\n", "res", "[", "\"labels\"", "]", "=", "examples", "[", "\"label\"", "]", "\n", "return", "res", "\n", "\n", "", "tokenized_datasets", "=", "datasets", ".", "map", "(", "\n", "tokenize_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "class", "ClassificationLossTrainer", "(", "Trainer", ")", ":", "\n", "        ", "def", "compute_loss", "(", "self", ",", "model", ",", "inputs", ",", "return_outputs", "=", "False", ",", "is_eval", "=", "False", ")", ":", "\n", "            ", "max_len", "=", "torch", ".", "max", "(", "torch", ".", "sum", "(", "inputs", "[", "\"attention_mask\"", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "# Sample how many token we substract from original prompts (max is the shortest prompt -1 to let a least 1 tokens)", "\n", "random_len", "=", "randint", "(", "1", ",", "max_len", ")", "\n", "if", "(", "is_eval", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "inputs", "[", "\"input_ids\"", "]", ",", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", ",", "labels", "=", "inputs", "[", "\"labels\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "model", "(", "inputs", "[", "\"input_ids\"", "]", "[", ":", ",", ":", "random_len", "]", ",", "attention_mask", "=", "inputs", "[", "\"attention_mask\"", "]", "[", ":", ",", ":", "random_len", "]", ",", "labels", "=", "inputs", "[", "\"labels\"", "]", ")", "\n", "\n", "", "return", "(", "outputs", "[", "\"loss\"", "]", ",", "outputs", ")", "if", "return_outputs", "else", "outputs", "[", "\"loss\"", "]", "\n", "", "def", "prediction_step", "(", "self", ",", "model", ",", "inputs", ",", "prediction_loss_only", ",", "ignore_keys", ")", ":", "\n", "            ", "inputs", "=", "self", ".", "_prepare_inputs", "(", "inputs", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "loss", ",", "outputs", "=", "self", ".", "compute_loss", "(", "model", ",", "inputs", ",", "return_outputs", "=", "True", ",", "is_eval", "=", "True", ")", "\n", "", "return", "(", "loss", ",", "outputs", "[", "\"logits\"", "]", ",", "inputs", "[", "\"labels\"", "]", ")", "\n", "\n", "\n", "", "", "def", "compute_metrics", "(", "eval_pred", ")", ":", "\n", "        ", "print", "(", "eval_pred", ")", "\n", "predictions", ",", "labels", "=", "eval_pred", "\n", "res", "=", "{", "}", "\n", "res", "[", "\"accuracy\"", "]", "=", "(", "torch", ".", "sum", "(", "torch", ".", "argmax", "(", "F", ".", "softmax", "(", "torch", ".", "tensor", "(", "predictions", ")", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "==", "torch", ".", "tensor", "(", "labels", ")", ")", "/", "len", "(", "labels", ")", ")", ".", "item", "(", ")", "\n", "return", "res", "\n", "\n", "", "trainer", "=", "ClassificationLossTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "tokenized_datasets", "[", "\"train\"", "]", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "tokenized_datasets", "[", "\"validation\"", "]", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "# tokenizer=tokenizer,", "\n", "# Data collator will default to DataCollatorWithPadding, so we change it.", "\n", "data_collator", "=", "default_data_collator", ",", "\n", "compute_metrics", "=", "compute_metrics", "\n", ")", "\n", "# Training", "\n", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "model_path", "=", "last_checkpoint", "\n", "", "elif", "model_args", ".", "model_name_or_path", "is", "not", "None", "and", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", ":", "\n", "            ", "model_path", "=", "model_args", ".", "model_name_or_path", "\n", "", "else", ":", "\n", "            ", "model_path", "=", "None", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "model_path", "=", "model_path", ")", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "output_train_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"train_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_train_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Train results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "train_result", ".", "metrics", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "# Need to save the state, since Trainer.save_model saves only the tokenizer with the model", "\n", "", "", "trainer", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "", "results", "=", "{", "}", "\n", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "eval_output", "=", "trainer", ".", "evaluate", "(", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"eval_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "results", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.Net.__init__": [[88, 93], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", "=", "config", ")", "\n", "# Classification layer from (hidden_states, num_classes)", "\n", "self", ".", "fc_classif", "=", "nn", ".", "Linear", "(", "768", ",", "4", ")", "\n", "", "def", "forward", "(", "self", ",", "token_ids", ",", "attention_masks", ",", "labels", ",", "classi_states", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.Net.forward": [[93, 106], ["mcts_ag_bert_uni.Net.fc_classif", "lm.prepare_inputs_for_generation", "lm.prepare_inputs_for_generation", "[].cpu", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "mcts_ag_bert_uni.Net.bert", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "mcts_ag_bert_uni.Net.bert", "torch.Softmax", "torch.Softmax", "torch.Softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "token_ids", ",", "attention_masks", ",", "labels", ",", "classi_states", "=", "None", ")", ":", "\n", "        ", "if", "(", "classi_states", "is", "None", ")", ":", "\n", "            ", "model_inputs", "=", "lm", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "output", "=", "self", ".", "bert", "(", "**", "model_inputs", ",", "return_dict", "=", "True", ",", "use_cache", "=", "True", ")", "\n", "", "text", "=", "output", "[", "2", "]", "[", "-", "1", "]", "[", ":", ",", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "model_inputs", "=", "lm", ".", "prepare_inputs_for_generation", "(", "token_ids", ",", "attention_mask", "=", "attention_masks", ",", "past", "=", "classi_states", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "output", "=", "self", ".", "bert", "(", "**", "model_inputs", ",", "return_dict", "=", "True", ",", "use_cache", "=", "True", ")", "\n", "", "text", "=", "output", "[", "2", "]", "[", "-", "1", "]", "[", ":", ",", "-", "1", "]", "\n", "", "text", "=", "self", ".", "fc_classif", "(", "text", ")", "\n", "return", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "text", ")", "[", "labels", "]", ".", "cpu", "(", ")", ",", "output", ".", "past_key_values", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.__init__": [[219, 271], ["min", "numpy.zeros", "numpy.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.arange", "mcts_ag_bert_uni.NumpyMCTS._reset_tree", "transformers.RepetitionPenaltyLogitsProcessor"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree"], ["    ", "def", "__init__", "(", "self", ",", "root_fun", ",", "rec_fun", ",", "batch_size", ",", "num_simulations", ",", "num_actions", ",", "num_sparse_actions", ",", "pb_c_init", ",", "temperature", ",", "alpha", ",", "penalty", ")", ":", "\n", "        ", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_num_simulations", "=", "num_simulations", "\n", "self", ".", "_num_actions", "=", "num_actions", "\n", "self", ".", "_num_sparse_actions", "=", "min", "(", "num_sparse_actions", ",", "num_actions", ")", "\n", "self", ".", "_pb_c_init", "=", "pb_c_init", "\n", "self", ".", "_temperature", "=", "temperature", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n", "self", ".", "_root_fun", "=", "root_fun", "# a function called at the root", "\n", "self", ".", "_rec_fun", "=", "rec_fun", "# a function called in the tree", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "zeros", "(", "batch_size", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_labels", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "4", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "\"cuda\"", ")", "\n", "\n", "# Allocate all necessary storage.", "\n", "# For a given search associated to a batch-index, node i is the i-th node", "\n", "# to be expanded. Node 0 corresponds to the root node.", "\n", "num_nodes", "=", "num_simulations", "+", "1", "\n", "batch_node", "=", "(", "batch_size", ",", "num_nodes", ")", "\n", "self", ".", "_num_nodes", "=", "num_nodes", "\n", "self", ".", "_visit_counts", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_likelihoods", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_raw_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# action_from_parents[b, i] is the action taken to reach node i.", "\n", "# Note that action_from_parents[b, 0] will remain -1, as we do not know,", "\n", "# when doing search from the root, what action led to the root.", "\n", "self", ".", "_action_from_parents", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# The 0-indexed depth of the node. The root is the only 0-depth node.", "\n", "# The depth of node i, is the depth of its parent + 1.", "\n", "self", ".", "_depth", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_is_terminal", "=", "np", ".", "full", "(", "batch_node", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "\n", "# To avoid costly numpy ops, we store a sparse version of the actions.", "\n", "# We select the top k actions according to the policy, and keep a mapping", "\n", "# of indices from 0 to k-1 to the actual action indices in the", "\n", "# self._topk_mapping tensor.", "\n", "batch_node_action", "=", "(", "batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ")", "# (B, )", "\n", "self", ".", "_topk_mapping", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_index", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_children_prior", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_values", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "_children_visits", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "_original_states", "=", "{", "}", "\n", "self", ".", "_classi_states", "=", "{", "}", "\n", "self", ".", "_original_token_ids", "=", "{", "}", "\n", "self", ".", "_original_attention_mask", "=", "{", "}", "\n", "self", ".", "_batch_range", "=", "np", ".", "arange", "(", "batch_size", ")", "\n", "self", ".", "_reset_tree", "(", ")", "\n", "self", ".", "_repetition_penalty", "=", "RepetitionPenaltyLogitsProcessor", "(", "penalty", "=", "penalty", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree": [[272, 290], ["mcts_ag_bert_uni.NumpyMCTS._visit_counts.fill", "mcts_ag_bert_uni.NumpyMCTS._values.fill", "mcts_ag_bert_uni.NumpyMCTS._likelihoods.fill", "mcts_ag_bert_uni.NumpyMCTS._parents.fill", "mcts_ag_bert_uni.NumpyMCTS._action_from_parents.fill", "mcts_ag_bert_uni.NumpyMCTS._depth.fill", "mcts_ag_bert_uni.NumpyMCTS._topk_mapping.fill", "mcts_ag_bert_uni.NumpyMCTS._children_index.fill", "mcts_ag_bert_uni.NumpyMCTS._children_prior.fill", "mcts_ag_bert_uni.NumpyMCTS._children_values.fill", "mcts_ag_bert_uni.NumpyMCTS._children_visits.fill"], "methods", ["None"], ["", "def", "_reset_tree", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the tree arrays.\"\"\"", "\n", "self", ".", "_visit_counts", ".", "fill", "(", "0", ")", "\n", "self", ".", "_values", ".", "fill", "(", "0", ")", "\n", "self", ".", "_likelihoods", ".", "fill", "(", "0", ")", "\n", "self", ".", "_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_action_from_parents", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_depth", ".", "fill", "(", "0", ")", "\n", "\n", "self", ".", "_topk_mapping", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_index", ".", "fill", "(", "-", "1", ")", "\n", "self", ".", "_children_prior", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_values", ".", "fill", "(", "0.0", ")", "\n", "self", ".", "_children_visits", ".", "fill", "(", "0", ")", "\n", "self", ".", "_original_states", "=", "{", "}", "\n", "self", ".", "_classi_states", "=", "{", "}", "\n", "self", ".", "_original_token_ids", "=", "{", "}", "# Indexed by tuples (batch index, node index)", "\n", "self", ".", "_original_attention_mask", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.set_labels": [[292, 294], ["None"], "methods", ["None"], ["", "def", "set_labels", "(", "self", ",", "labels", ")", ":", "\n", "        ", "self", ".", "_labels", "=", "labels", "\n", "", "def", "search", "(", "self", ",", "original_input", ")", ":", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.search": [[294, 410], ["mcts_ag_bert_uni.NumpyMCTS._reset_tree", "mcts_ag_bert_uni.NumpyMCTS._root_fun", "mcts_ag_bert_uni.NumpyMCTS.create_node", "numpy.zeros", "tqdm.tqdm.tqdm", "range", "range", "numpy.full", "range", "mcts_ag_bert_uni.NumpyMCTS.dense_visit_counts", "numpy.amax", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "numpy.full", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.full", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "tqdm.tqdm.tqdm.update", "mcts_ag_bert_uni.NumpyMCTS._is_terminal[].all", "logging.warning", "mcts_ag_bert_uni.NumpyMCTS.simulate", "mcts_ag_bert_uni.NumpyMCTS.expand", "numpy.zeros.fill", "mcts_ag_bert_uni.NumpyMCTS.backward", "numpy.argmax", "[].tolist", "old_to_new_id.items", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "[].tolist.pop", "[].tolist", "enumerate", "tokenizer.decode().replace().replace", "tokenizer.decode().replace", "tokenizer.decode"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS._reset_tree", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.dense_visit_counts", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.simulate", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.backward"], ["", "def", "search", "(", "self", ",", "original_input", ")", ":", "\n", "        ", "self", ".", "_reset_tree", "(", ")", "\n", "\n", "# Evaluate the root.", "\n", "prior", ",", "values", ",", "states", ",", "classi_states", "=", "self", ".", "_root_fun", "(", "original_input", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ")", "\n", "\n", "\n", "self", ".", "_adaptive_min_values", "=", "1", "\n", "self", ".", "_adaptive_max_values", "=", "1", "+", "1e-6", "\n", "\n", "root_index", "=", "0", "\n", "self", ".", "create_node", "(", "root_index", ",", "prior", ",", "1", ",", "values", ",", "states", ",", "original_input", ".", "input_ids", ",", "original_input", ".", "attention_mask", ",", "classi_states", ",", "np", ".", "full", "(", "self", ".", "_batch_size", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", ")", "\n", "\n", "\n", "# Do simulations, expansions, and backwards.", "\n", "leaf_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "existing_nodes", "=", "0", "\n", "tokens_to_generate", "=", "98", "\n", "tokens_pbar", "=", "tqdm", "(", "total", "=", "tokens_to_generate", ",", "desc", "=", "\"Tokens generated\"", ")", "\n", "for", "i", "in", "range", "(", "tokens_to_generate", ")", ":", "\n", "            ", "for", "sim", "in", "range", "(", "self", ".", "_num_simulations", ")", ":", "\n", "                ", "node_indices", ",", "actions", "=", "self", ".", "simulate", "(", ")", "\n", "next_node_index", "=", "sim", "+", "1", "+", "existing_nodes", "# root is 0, therefore we offset by 1.", "\n", "self", ".", "expand", "(", "node_indices", ",", "actions", ",", "next_node_index", ")", "\n", "leaf_indices", ".", "fill", "(", "next_node_index", ")", "\n", "self", ".", "backward", "(", "leaf_indices", ")", "\n", "", "visit_counts", ",", "_", "=", "self", ".", "dense_visit_counts", "(", ")", "\n", "existing_nodes", "=", "np", ".", "amax", "(", "visit_counts", ")", "\n", "# Create new tree with selected node as root", "\n", "num_nodes", "=", "self", ".", "_num_simulations", "+", "existing_nodes", "+", "1", "\n", "batch_node", "=", "(", "self", ".", "_batch_size", ",", "num_nodes", ")", "\n", "temp_visit_counts", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_likelihoods", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_raw_values", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_parents", "=", "np", ".", "full", "(", "batch_node", ",", "-", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_action_from_parents", "=", "np", ".", "full", "(", "batch_node", ",", "-", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_depth", "=", "np", ".", "zeros", "(", "batch_node", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_is_terminal", "=", "np", ".", "full", "(", "batch_node", ",", "False", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "batch_node_action", "=", "(", "self", ".", "_batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ")", "# (B, )", "\n", "temp_topk_mapping", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_children_index", "=", "np", ".", "full", "(", "batch_node_action", ",", "-", "1", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_children_prior", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_children_probas", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "num_nodes", ",", "self", ".", "_num_sparse_actions", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_children_values", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "temp_children_visits", "=", "np", ".", "zeros", "(", "batch_node_action", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "temp_original_states", "=", "{", "}", "\n", "temp_classi_states", "=", "{", "}", "\n", "temp_original_token_ids", "=", "{", "}", "# Indexed by tuples (batch index, node index)", "\n", "temp_original_attention_mask", "=", "{", "}", "\n", "\n", "for", "b", ",", "new_root_action", "in", "enumerate", "(", "np", ".", "argmax", "(", "visit_counts", ",", "axis", "=", "1", ")", ")", ":", "\n", "                ", "new_root_id", "=", "self", ".", "_children_index", "[", "b", ",", "0", ",", "new_root_action", "]", "\n", "new_node_id", "=", "1", "\n", "old_to_new_id", "=", "{", "new_root_id", ":", "0", "}", "\n", "children_to_explore", "=", "self", ".", "_children_index", "[", "b", ",", "new_root_id", "]", "[", "self", ".", "_children_index", "[", "b", ",", "new_root_id", "]", "!=", "-", "1", "]", ".", "tolist", "(", ")", "\n", "while", "(", "len", "(", "children_to_explore", ")", ">", "0", ")", ":", "\n", "                    ", "child_id", "=", "children_to_explore", ".", "pop", "(", "0", ")", "\n", "old_to_new_id", "[", "child_id", "]", "=", "new_node_id", "\n", "children_to_explore", "+=", "self", ".", "_children_index", "[", "b", ",", "child_id", "]", "[", "self", ".", "_children_index", "[", "b", ",", "child_id", "]", "!=", "-", "1", "]", ".", "tolist", "(", ")", "\n", "new_node_id", "+=", "1", "\n", "", "for", "old_id", ",", "new_id", "in", "old_to_new_id", ".", "items", "(", ")", ":", "\n", "                    ", "if", "(", "new_id", "!=", "0", ")", ":", "\n", "                        ", "temp_parents", "[", "b", ",", "new_id", "]", "=", "old_to_new_id", "[", "self", ".", "_parents", "[", "b", ",", "old_id", "]", "]", "\n", "temp_action_from_parents", "[", "b", ",", "new_id", "]", "=", "self", ".", "_action_from_parents", "[", "b", ",", "old_id", "]", "\n", "", "for", "i", ",", "children", "in", "enumerate", "(", "self", ".", "_children_index", "[", "b", ",", "old_id", "]", ")", ":", "\n", "                        ", "if", "(", "children", "!=", "-", "1", ")", ":", "\n", "                            ", "temp_children_index", "[", "b", ",", "new_id", ",", "i", "]", "=", "old_to_new_id", "[", "children", "]", "\n", "", "", "temp_visit_counts", "[", "b", ",", "new_id", "]", "=", "self", ".", "_visit_counts", "[", "b", ",", "old_id", "]", "\n", "temp_values", "[", "b", ",", "new_id", "]", "=", "self", ".", "_values", "[", "b", ",", "old_id", "]", "\n", "temp_likelihoods", "[", "b", ",", "new_id", "]", "=", "self", ".", "_likelihoods", "[", "b", ",", "old_id", "]", "\n", "temp_raw_values", "[", "b", ",", "new_id", "]", "=", "self", ".", "_raw_values", "[", "b", ",", "old_id", "]", "\n", "\n", "temp_action_from_parents", "[", "b", ",", "new_id", "]", "=", "self", ".", "_action_from_parents", "[", "b", ",", "old_id", "]", "\n", "temp_depth", "[", "b", ",", "new_id", "]", "=", "self", ".", "_depth", "[", "b", ",", "old_id", "]", "-", "1", "\n", "temp_is_terminal", "[", "b", ",", "new_id", "]", "=", "self", ".", "_is_terminal", "[", "b", ",", "old_id", "]", "\n", "\n", "temp_topk_mapping", "[", "b", ",", "new_id", "]", "=", "self", ".", "_topk_mapping", "[", "b", ",", "old_id", "]", "\n", "temp_children_prior", "[", "b", ",", "new_id", "]", "=", "self", ".", "_children_prior", "[", "b", ",", "old_id", "]", "\n", "temp_children_values", "[", "b", ",", "new_id", "]", "=", "self", ".", "_children_values", "[", "b", ",", "old_id", "]", "\n", "temp_children_visits", "[", "b", ",", "new_id", "]", "=", "self", ".", "_children_visits", "[", "b", ",", "old_id", "]", "\n", "\n", "temp_original_states", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_original_states", "[", "(", "b", ",", "old_id", ")", "]", "\n", "temp_classi_states", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_classi_states", "[", "(", "b", ",", "old_id", ")", "]", "\n", "temp_original_token_ids", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_original_token_ids", "[", "(", "b", ",", "old_id", ")", "]", "\n", "temp_original_attention_mask", "[", "(", "b", ",", "new_id", ")", "]", "=", "self", ".", "_original_attention_mask", "[", "(", "b", ",", "old_id", ")", "]", "\n", "\n", "", "temp_original_states", "[", "(", "b", ",", "0", ")", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "_original_states", "[", "(", "b", ",", "0", ")", "]", ",", "self", ".", "_original_states", "[", "(", "b", ",", "new_root_id", ")", "]", ")", ",", "3", ")", "\n", "temp_classi_states", "[", "(", "b", ",", "0", ")", "]", "=", "torch", ".", "cat", "(", "(", "self", ".", "_classi_states", "[", "(", "b", ",", "0", ")", "]", ",", "self", ".", "_classi_states", "[", "(", "b", ",", "new_root_id", ")", "]", ")", ",", "3", ")", "\n", "\n", "", "self", ".", "_num_nodes", "=", "num_nodes", "\n", "self", ".", "_visit_counts", "=", "temp_visit_counts", "\n", "self", ".", "_values", "=", "temp_values", "\n", "self", ".", "_likelihoods", "=", "temp_likelihoods", "\n", "self", ".", "_raw_values", "=", "temp_raw_values", "\n", "self", ".", "_parents", "=", "temp_parents", "\n", "self", ".", "_action_from_parents", "=", "temp_action_from_parents", "\n", "# The 0-indexed depth of the node. The root is the only 0-depth node.", "\n", "# The depth of node i, is the depth of its parent + 1.", "\n", "self", ".", "_depth", "=", "temp_depth", "\n", "self", ".", "_is_terminal", "=", "temp_is_terminal", "\n", "self", ".", "_topk_mapping", "=", "temp_topk_mapping", "\n", "self", ".", "_children_index", "=", "temp_children_index", "\n", "self", ".", "_children_prior", "=", "temp_children_prior", "\n", "self", ".", "_children_values", "=", "temp_children_values", "\n", "self", ".", "_children_visits", "=", "temp_children_visits", "\n", "self", ".", "_original_states", "=", "temp_original_states", "\n", "self", ".", "_original_token_ids", "=", "temp_original_token_ids", "\n", "self", ".", "_original_attention_mask", "=", "temp_original_attention_mask", "\n", "self", ".", "_classi_states", "=", "temp_classi_states", "\n", "tokens_pbar", ".", "update", "(", "1", ")", "\n", "# If every sequences is finished, stop", "\n", "if", "(", "self", ".", "_is_terminal", "[", ":", ",", "0", "]", ".", "all", "(", ")", ")", ":", "\n", "                ", "break", "\n", "", "", "for", "b", "in", "range", "(", "self", ".", "_batch_size", ")", ":", "\n", "            ", "logging", ".", "warning", "(", "(", "tokenizer", ".", "decode", "(", "self", ".", "_original_token_ids", "[", "(", "b", ",", "0", ")", "]", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\" [PAD]\"", ",", "\"\"", ")", "+", "\"[PAD]\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.dense_visit_counts": [[411, 417], ["numpy.zeros"], "methods", ["None"], ["", "", "def", "dense_visit_counts", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_visit_counts", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_visit_counts", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_topk_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_visit_counts", "\n", "return", "root_visit_counts", ",", "dense_visit_counts", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.dense_scores": [[418, 425], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "dense_root_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_root_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_child_prob_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_scores", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "return", "dense_root_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.dense_mean_scores": [[426, 434], ["numpy.zeros"], "methods", ["None"], ["", "def", "dense_mean_scores", "(", "self", ")", ":", "\n", "        ", "root_index", "=", "0", "\n", "root_visit_counts", "=", "self", ".", "_children_visits", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_scores", "=", "self", ".", "_children_values", "[", ":", ",", "root_index", ",", ":", "]", "\n", "root_mean_scores", "=", "root_scores", "/", "root_visit_counts", "\n", "dense_mean_scores", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ",", "self", ".", "_num_actions", ")", ")", "\n", "dense_mean_scores", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "self", ".", "_child_prob_mapping", "[", ":", ",", "root_index", ",", ":", "]", "]", "=", "root_mean_scores", "\n", "return", "dense_mean_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.simulate": [[435, 448], ["numpy.zeros", "mcts_ag_bert_uni.NumpyMCTS.uct_select_action", "is_unexplored.all", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.uct_select_action"], ["", "def", "simulate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Goes down until all elements have reached unexplored actions.\"\"\"", "\n", "node_indices", "=", "np", ".", "zeros", "(", "(", "self", ".", "_batch_size", ")", ",", "np", ".", "int32", ")", "\n", "depth", "=", "0", "\n", "while", "True", ":", "\n", "            ", "depth", "+=", "1", "\n", "actions", "=", "self", ".", "uct_select_action", "(", "node_indices", ")", "\n", "next_node_indices", "=", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "is_unexplored", "=", "next_node_indices", "==", "-", "1", "\n", "if", "is_unexplored", ".", "all", "(", ")", ":", "\n", "                ", "return", "node_indices", ",", "actions", "\n", "", "else", ":", "\n", "                ", "node_indices", "=", "np", ".", "where", "(", "is_unexplored", ",", "node_indices", ",", "next_node_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.uct_select_action": [[449, 463], ["numpy.argmax", "numpy.sqrt"], "methods", ["None"], ["", "", "", "def", "uct_select_action", "(", "self", ",", "node_indices", ")", ":", "\n", "        ", "\"\"\"Returns the action selected for a batch of node indices of shape (B).\"\"\"", "\n", "node_children_prior", "=", "self", ".", "_children_prior", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_values", "=", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_children_visits", "=", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "node_indices", ",", ":", "]", "# (B, A)", "\n", "node_visits", "=", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "# (B)", "\n", "node_policy_score", "=", "np", ".", "sqrt", "(", "node_visits", "[", ":", ",", "None", "]", ")", "*", "self", ".", "_pb_c_init", "*", "node_children_prior", "/", "(", "node_children_visits", "+", "1", ")", "\n", "# (B, A)", "\n", "\n", "node_value_score", "=", "node_children_values", "\n", "\n", "node_uct_score", "=", "node_value_score", "+", "node_policy_score", "# (B, A)", "\n", "actions", "=", "np", ".", "argmax", "(", "node_uct_score", ",", "axis", "=", "1", ")", "\n", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.get_original_states_from_node": [[465, 475], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "get_original_states_from_node", "(", "self", ",", "b", ",", "n", ",", "d", ")", ":", "\n", "        ", "original_d", "=", "d", "\n", "original_n", "=", "n", "\n", "original_state_array", "=", "[", "None", "]", "*", "d", "\n", "original_state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_original_states", "[", "(", "b", ",", "n", ")", "]", "\n", "while", "n", "!=", "0", ":", "\n", "            ", "n", "=", "self", ".", "_parents", "[", "(", "b", ",", "n", ")", "]", "\n", "d", "-=", "1", "\n", "original_state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_original_states", "[", "(", "b", ",", "n", ")", "]", "\n", "", "return", "torch", ".", "cat", "(", "original_state_array", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.get_classi_states_from_node": [[476, 484], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "get_classi_states_from_node", "(", "self", ",", "b", ",", "n", ",", "d", ")", ":", "\n", "        ", "classi_state_array", "=", "[", "None", "]", "*", "d", "\n", "classi_state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_classi_states", "[", "(", "b", ",", "n", ")", "]", "\n", "while", "n", "!=", "0", ":", "\n", "            ", "n", "=", "self", ".", "_parents", "[", "(", "b", ",", "n", ")", "]", "\n", "d", "-=", "1", "\n", "classi_state_array", "[", "d", "-", "1", "]", "=", "self", ".", "_classi_states", "[", "(", "b", ",", "n", ")", "]", "\n", "", "return", "torch", ".", "cat", "(", "classi_state_array", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.expand": [[485, 540], ["mcts_ag_bert_uni.pad_sequences_to_left", "mcts_ag_bert_uni.pad_sequences_to_left", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.array", "numpy.array", "numpy.array", "mcts_ag_bert_uni.pad_sequences_to_left_states", "mcts_ag_bert_uni.pad_sequences_to_left_states", "tuple", "tuple", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.logical_or", "mcts_ag_bert_uni.NumpyMCTS._rec_fun", "mcts_ag_bert_uni.NumpyMCTS.create_node", "numpy.minimum", "numpy.maximum", "len", "values.numpy", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mcts_ag_bert_uni.NumpyMCTS.get_original_states_from_node", "len", "mcts_ag_bert_uni.NumpyMCTS.get_classi_states_from_node", "len", "tuple", "tuple", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "n.item", "depths[].item", "enumerate", "depths[].item", "enumerate", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.cuda.LongTensor", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "torch.sum().cpu", "len", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left_states", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left_states", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.get_original_states_from_node", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.get_classi_states_from_node"], ["", "def", "expand", "(", "self", ",", "node_indices", ",", "actions", ",", "next_node_index", ")", ":", "\n", "        ", "\"\"\"Creates and evaluate child nodes from given nodes and unexplored actions.\"\"\"", "\n", "# Retrieve token ids and masks for nodes to be evaluated.", "\n", "original_tokens_ids", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_original_token_ids", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "pad_token_id", ")", "\n", "original_attention_masks", "=", "pad_sequences_to_left", "(", "[", "self", ".", "_original_attention_mask", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "True", ",", "0", ")", "\n", "depths", "=", "torch", ".", "tensor", "(", "[", "self", ".", "_depth", "[", "(", "b", ",", "n", ")", "]", "+", "1", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "device", "=", "\"cuda\"", ")", "\n", "children_priors", "=", "np", ".", "array", "(", "[", "self", ".", "_children_prior", "[", "(", "b", ",", "n", ")", "]", "[", "actions", "[", "b", "]", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "likelihoods", "=", "np", ".", "array", "(", "[", "self", ".", "_likelihoods", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "previous_values", "=", "np", ".", "array", "(", "[", "self", ".", "_values", "[", "(", "b", ",", "n", ")", "]", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ")", "\n", "previous_node_is_terminal", "=", "self", ".", "_is_terminal", "[", "self", ".", "_batch_range", ",", "node_indices", "[", "self", ".", "_batch_range", "]", "]", "# (B)", "\n", "\n", "original_states_tensor", "=", "pad_sequences_to_left_states", "(", "[", "self", ".", "get_original_states_from_node", "(", "b", ",", "n", ".", "item", "(", ")", ",", "depths", "[", "b", "]", ".", "item", "(", ")", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "0", ",", "max_len", "=", "len", "(", "original_tokens_ids", "[", "0", "]", ")", ")", "\n", "classi_states_tensor", "=", "pad_sequences_to_left_states", "(", "[", "self", ".", "get_classi_states_from_node", "(", "b", ",", "n", ",", "depths", "[", "b", "]", ".", "item", "(", ")", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", ",", "0", ",", "max_len", "=", "len", "(", "original_tokens_ids", "[", "0", "]", ")", ")", "\n", "if", "(", "len", "(", "original_tokens_ids", "[", "0", "]", ")", ">=", "MAX_SEQUENCE_LENGTH", ")", ":", "\n", "            ", "previous_node_is_terminal", "[", "torch", ".", "sum", "(", "original_attention_masks", ",", "axis", "=", "1", ")", ".", "cpu", "(", ")", ">=", "MAX_SEQUENCE_LENGTH", "]", "=", "True", "\n", "original_tokens_ids", "=", "original_tokens_ids", "[", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "1", ")", ":", "]", "\n", "original_attention_masks", "=", "original_attention_masks", "[", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "1", ")", ":", "]", "\n", "original_states_tensor", "=", "original_states_tensor", "[", ":", ",", ":", ",", ":", ",", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "1", ")", ":", "]", "\n", "classi_states_tensor", "=", "classi_states_tensor", "[", ":", ",", ":", ",", ":", ",", ":", ",", "-", "(", "MAX_SEQUENCE_LENGTH", "-", "1", ")", ":", "]", "\n", "\n", "\n", "", "original_states", "=", "tuple", "(", "tuple", "(", "type_of_value", "for", "type_of_value", "in", "layer", ")", "for", "layer", "in", "original_states_tensor", ")", "\n", "classi_states", "=", "tuple", "(", "tuple", "(", "type_of_value", "for", "type_of_value", "in", "layer", ")", "for", "layer", "in", "classi_states_tensor", ")", "\n", "\n", "\n", "\n", "# Convert sparse actions to dense actions for network computation", "\n", "dense_actions", "=", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "\n", "dense_actions", "[", "previous_node_is_terminal", "]", "=", "pad_token_id", "\n", "# Add actions to list of tokens and extend attention mask by 1", "\n", "original_tokens_ids", "=", "torch", ".", "cat", "(", "(", "original_tokens_ids", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "cuda", ".", "LongTensor", "(", "dense_actions", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "original_attention_masks", "=", "torch", ".", "cat", "(", "(", "original_attention_masks", ",", "torch", ".", "unsqueeze", "(", "torch", ".", "ones", "(", "len", "(", "dense_actions", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# Check if expanded nodes are terminal ", "\n", "expanded_node_is_terminal", "=", "np", ".", "logical_or", "(", "(", "dense_actions", "==", "pad_token_id", ")", ",", "previous_node_is_terminal", ")", "\n", "# Evaluate nodes.", "\n", "(", "prior", ",", "values", ",", "next_states", ",", "classi_states", ")", "=", "self", ".", "_rec_fun", "(", "original_states", ",", "classi_states", ",", "original_tokens_ids", ",", "original_attention_masks", ",", "self", ".", "_labels", ",", "self", ".", "_temperature", ",", "self", ".", "_repetition_penalty", ")", "\n", "values", ".", "numpy", "(", ")", "[", "previous_node_is_terminal", "]", "=", "previous_values", "[", "previous_node_is_terminal", "]", "\n", "\n", "# Store unpaded version of inputs to save space", "\n", "original_attention_masks", "=", "[", "torch", ".", "cat", "(", "(", "self", ".", "_original_attention_mask", "[", "(", "b", ",", "n", ")", "]", ",", "torch", ".", "ones", "(", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "\"cuda\"", ")", ")", ",", "dim", "=", "0", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", "\n", "original_tokens_ids", "=", "[", "torch", ".", "cat", "(", "(", "self", ".", "_original_token_ids", "[", "(", "b", ",", "n", ")", "]", ",", "torch", ".", "cuda", ".", "LongTensor", "(", "[", "dense_actions", "[", "b", "]", "]", ")", ")", ",", "dim", "=", "0", ")", "for", "b", ",", "n", "in", "enumerate", "(", "node_indices", ")", "]", "\n", "\n", "# Create the new nodes.", "\n", "self", ".", "create_node", "(", "next_node_index", ",", "prior", ",", "likelihoods", "*", "children_priors", ",", "values", ",", "next_states", ",", "original_tokens_ids", ",", "original_attention_masks", ",", "classi_states", ",", "expanded_node_is_terminal", ")", "\n", "\n", "# Update the min and max values arrays", "\n", "self", ".", "_adaptive_min_values", "=", "np", ".", "minimum", "(", "self", ".", "_adaptive_min_values", ",", "values", ")", "\n", "self", ".", "_adaptive_max_values", "=", "np", ".", "maximum", "(", "self", ".", "_adaptive_max_values", ",", "values", ")", "\n", "\n", "# Update tree topology.", "\n", "self", ".", "_children_index", "[", "self", ".", "_batch_range", ",", "node_indices", ",", "actions", "]", "=", "next_node_index", "\n", "self", ".", "_parents", "[", ":", ",", "next_node_index", "]", "=", "node_indices", "\n", "self", ".", "_action_from_parents", "[", ":", ",", "next_node_index", "]", "=", "actions", "\n", "self", ".", "_depth", "[", ":", ",", "next_node_index", "]", "=", "self", ".", "_depth", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.create_node": [[541, 578], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "enumerate", "enumerate", "numpy.argpartition", "list", "list", "range", "range", "len", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "len", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.clone", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "list", "range", "list", "range", "len", "len"], "methods", ["None"], ["", "def", "create_node", "(", "self", ",", "node_index", ",", "prior", ",", "likelihoods", ",", "values", ",", "original_states", ",", "original_tokens_ids", ",", "original_attention_masks", ",", "classi_states", ",", "expanded_node_is_terminal", ")", ":", "\n", "# Truncate the prior to only keep the top k logits", "\n", "        ", "prior_topk_indices", "=", "np", ".", "argpartition", "(", "prior", ",", "-", "self", ".", "_num_sparse_actions", ",", "axis", "=", "-", "1", ")", "[", ":", ",", "-", "self", ".", "_num_sparse_actions", ":", "]", "\n", "prior", "=", "prior", "[", "self", ".", "_batch_range", "[", ":", ",", "None", "]", ",", "prior_topk_indices", "]", "# (B, A)", "\n", "# Store the indices of the top k logits", "\n", "self", ".", "_topk_mapping", "[", "self", ".", "_batch_range", ",", "node_index", ",", ":", "]", "=", "prior_topk_indices", "\n", "\n", "# Update prior, values and visit counts.", "\n", "self", ".", "_children_prior", "[", ":", ",", "node_index", ",", ":", "]", "=", "prior", "\n", "self", ".", "_likelihoods", "[", ":", ",", "node_index", "]", "=", "likelihoods", "\n", "# raw_values = values**(self.alpha) * likelihoods**(1-self.alpha)", "\n", "raw_values", "=", "values", "\n", "self", ".", "_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_raw_values", "[", ":", ",", "node_index", "]", "=", "raw_values", "\n", "self", ".", "_visit_counts", "[", ":", ",", "node_index", "]", "=", "1", "\n", "self", ".", "_is_terminal", "[", ":", ",", "node_index", "]", "=", "expanded_node_is_terminal", "\n", "# States has shape [12 (nhead), 2(key/value), batch_size, 12(nlayer), seq_len, 64]", "\n", "original_key_value_tensor", "=", "torch", ".", "stack", "(", "list", "(", "torch", ".", "stack", "(", "list", "(", "original_states", "[", "i", "]", ")", ",", "dim", "=", "0", ")", "for", "i", "in", "range", "(", "len", "(", "original_states", ")", ")", ")", ",", "dim", "=", "0", ")", "\n", "classi_key_value_tensor", "=", "torch", ".", "stack", "(", "list", "(", "torch", ".", "stack", "(", "list", "(", "classi_states", "[", "i", "]", ")", ",", "dim", "=", "0", ")", "for", "i", "in", "range", "(", "len", "(", "classi_states", ")", ")", ")", ",", "dim", "=", "0", ")", "\n", "# If root, store the whole states", "\n", "if", "(", "node_index", "==", "0", ")", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "original_tokens_ids", ")", ")", ":", "\n", "                ", "self", ".", "_original_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "original_key_value_tensor", "[", ":", ",", ":", ",", "b", "]", ")", "\n", "self", ".", "_classi_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "classi_key_value_tensor", "[", ":", ",", ":", ",", "b", "]", ")", "\n", "# Else just store the additional token hidden states to save space", "\n", "", "", "else", ":", "\n", "            ", "for", "b", "in", "range", "(", "len", "(", "original_tokens_ids", ")", ")", ":", "\n", "                ", "self", ".", "_original_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "original_key_value_tensor", "[", ":", ",", ":", ",", "b", ",", ":", ",", "-", "1", ":", "]", ")", "\n", "self", ".", "_classi_states", "[", "(", "b", ",", "node_index", ")", "]", "=", "torch", ".", "clone", "(", "classi_key_value_tensor", "[", ":", ",", ":", ",", "b", ",", ":", ",", "-", "1", ":", "]", ")", "\n", "\n", "# Updates tokens ids", "\n", "", "", "for", "b", ",", "original_token_ids", "in", "enumerate", "(", "original_tokens_ids", ")", ":", "\n", "            ", "self", ".", "_original_token_ids", "[", "(", "b", ",", "node_index", ")", "]", "=", "original_token_ids", "\n", "\n", "# Updates attention masks", "\n", "", "for", "b", ",", "original_attention_mask", "in", "enumerate", "(", "original_attention_masks", ")", ":", "\n", "            ", "self", ".", "_original_attention_mask", "[", "(", "b", ",", "node_index", ")", "]", "=", "original_attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.backward": [[579, 603], ["is_root.all", "numpy.where", "numpy.where"], "methods", ["None"], ["", "", "def", "backward", "(", "self", ",", "leaf_indices", ")", ":", "\n", "        ", "\"\"\"Goes up and updates the tree until all nodes reached the root.\"\"\"", "\n", "node_indices", "=", "leaf_indices", "# (B)", "\n", "leaf_values", "=", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "leaf_indices", "]", "\n", "while", "True", ":", "\n", "            ", "is_root", "=", "node_indices", "==", "0", "\n", "if", "is_root", ".", "all", "(", ")", ":", "\n", "                ", "return", "\n", "", "parents", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "root_mask", "=", "1.0", "*", "is_root", "\n", "not_root_mask_int", "=", "(", "1", "-", "is_root", ")", "\n", "not_root_mask", "=", "1.0", "-", "root_mask", "\n", "# Update the parent nodes iff their child is not the root.", "\n", "# We therefore mask the updates using not_root_mask and root_mask.", "\n", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "=", "not_root_mask", "*", "(", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "*", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+", "leaf_values", ")", "/", "(", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "\n", "parents", "]", "+", "1.0", ")", "+", "root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "parents", "]", "\n", "\n", "self", ".", "_visit_counts", "[", "self", ".", "_batch_range", ",", "parents", "]", "+=", "not_root_mask_int", "\n", "actions", "=", "np", ".", "where", "(", "is_root", ",", "0", ",", "self", ".", "_action_from_parents", "[", "self", ".", "_batch_range", ",", "node_indices", "]", ")", "\n", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "=", "not_root_mask", "*", "self", ".", "_values", "[", "self", ".", "_batch_range", ",", "node_indices", "]", "+", "root_mask", "*", "self", ".", "_children_values", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "\n", "self", ".", "_children_visits", "[", "self", ".", "_batch_range", ",", "parents", ",", "actions", "]", "+=", "not_root_mask_int", "\n", "# Go up", "\n", "node_indices", "=", "parents", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left": [[127, 148], ["sequences[].size", "max", "sequences[].new_full", "enumerate", "tensor.size", "s.size", "len", "len"], "function", ["None"], ["", "def", "pad_sequences_to_left", "(", "sequences", ",", "batch_first", "=", "False", ",", "padding_value", "=", "0", ")", ":", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "    ", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "max_len", "=", "max", "(", "[", "s", ".", "size", "(", "0", ")", "for", "s", "in", "sequences", "]", ")", "\n", "if", "batch_first", ":", "\n", "        ", "out_dims", "=", "(", "len", "(", "sequences", ")", ",", "max_len", ")", "+", "trailing_dims", "\n", "", "else", ":", "\n", "        ", "out_dims", "=", "(", "max_len", ",", "len", "(", "sequences", ")", ")", "+", "trailing_dims", "\n", "\n", "", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", "0", ")", "\n", "# use index notation to prevent duplicate references to the tensor", "\n", "if", "batch_first", ":", "\n", "            ", "out_tensor", "[", "i", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "else", ":", "\n", "            ", "out_tensor", "[", "max_len", "-", "length", ":", ",", "i", ",", "...", "]", "=", "tensor", "\n", "", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.pad_sequences_to_left_states": [[150, 162], ["sequences[].size", "sequences[].new_full", "enumerate", "len", "tensor.size"], "function", ["None"], ["", "def", "pad_sequences_to_left_states", "(", "sequences", ",", "padding_value", "=", "0", ",", "max_len", "=", "0", ")", ":", "\n", "# Same function as in PyTorch, but add padding to left to be used with Auto Regressive models", "\n", "# assuming trailing dimensions and type of all the Tensors", "\n", "# in sequences are same and fetching those from sequences[0]", "\n", "    ", "max_size", "=", "sequences", "[", "0", "]", ".", "size", "(", ")", "\n", "trailing_dims", "=", "max_size", "[", "1", ":", "]", "\n", "out_dims", "=", "(", "max_size", "[", "0", "]", ",", "max_size", "[", "1", "]", ",", "len", "(", "sequences", ")", ",", "max_size", "[", "2", "]", ",", "max_len", ",", "max_size", "[", "4", "]", ")", "\n", "out_tensor", "=", "sequences", "[", "0", "]", ".", "new_full", "(", "out_dims", ",", "padding_value", ",", "device", "=", "\"cuda\"", ")", "\n", "for", "i", ",", "tensor", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "length", "=", "tensor", ".", "size", "(", ")", "[", "3", "]", "\n", "out_tensor", "[", ":", ",", ":", ",", "i", ",", ":", ",", "max_len", "-", "length", ":", ",", "...", "]", "=", "tensor", "\n", "", "return", "out_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.root_fun": [[164, 189], ["lm.prepare_inputs_for_generation", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lm", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "classi", "torch.softmax().cpu", "torch.softmax"], "function", ["None"], ["", "def", "root_fun", "(", "original_input", ",", "labels", ",", "temperature", ",", "repetition_penalty", ")", ":", "\n", "# Forward pass of LM to get priors and states", "\n", "    ", "model_inputs", "=", "lm", ".", "prepare_inputs_for_generation", "(", "original_input", ".", "input_ids", ",", "attention_mask", "=", "original_input", ".", "attention_mask", ",", "use_cache", "=", "True", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "lm", "(", "\n", "**", "model_inputs", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", "use_cache", "=", "True", ",", "\n", ")", "\n", "states", "=", "outputs", ".", "past_key_values", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "model_inputs", "[", "\"input_ids\"", "]", ")", "\n", "inverted_attention_mask", "=", "model_inputs", "[", "\"attention_mask\"", "]", "==", "0", "\n", "prompt_masked_input_ids", "[", "inverted_attention_mask", "]", "=", "14827", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "# Use of our discriminator to get values", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "values", ",", "classi_past_key_values", "=", "classi", "(", "original_input", ".", "input_ids", ",", "original_input", ".", "attention_mask", ",", "labels", ")", "\n", "\n", "", "return", "priors", ",", "values", ",", "states", ",", "classi_past_key_values", "\n", "", "def", "rec_fun", "(", "original_states", ",", "classi_states", ",", "original_token_ids", ",", "original_attention_masks", ",", "labels", ",", "temperature", ",", "repetition_penalty", ")", ":", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.rec_fun": [[189, 215], ["lm.prepare_inputs_for_generation", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lm", "torch.clone", "torch.clone", "torch.clone", "repetition_penalty", "torch.softmax().cpu().numpy", "torch.no_grad", "torch.no_grad", "torch.no_grad", "classi", "torch.softmax().cpu", "torch.softmax"], "function", ["None"], ["", "def", "rec_fun", "(", "original_states", ",", "classi_states", ",", "original_token_ids", ",", "original_attention_masks", ",", "labels", ",", "temperature", ",", "repetition_penalty", ")", ":", "\n", "# Forward pass of LM to get priors and states", "\n", "    ", "model_inputs", "=", "lm", ".", "prepare_inputs_for_generation", "(", "original_token_ids", ",", "attention_mask", "=", "original_attention_masks", ",", "past", "=", "original_states", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outputs", "=", "lm", "(", "\n", "**", "model_inputs", ",", "\n", "use_cache", "=", "True", ",", "\n", "return_dict", "=", "True", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", ")", "\n", "next_states", "=", "outputs", ".", "past_key_values", "\n", "\n", "prompt_masked_input_ids", "=", "torch", ".", "clone", "(", "original_token_ids", ")", "\n", "inverted_attention_mask", "=", "original_attention_masks", "==", "0", "\n", "# penalizing an unused token", "\n", "prompt_masked_input_ids", "[", "inverted_attention_mask", "]", "=", "28988", "\n", "priors", "=", "repetition_penalty", "(", "prompt_masked_input_ids", ",", "outputs", ".", "logits", "[", ":", ",", "-", "1", ",", ":", "]", "/", "temperature", ")", "\n", "\n", "priors", "=", "F", ".", "softmax", "(", "priors", ",", "dim", "=", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Use of our discriminator to get values", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "values", ",", "classi_past_key_values", "=", "classi", "(", "original_token_ids", ",", "original_attention_masks", ",", "labels", ",", "classi_states", ")", "\n", "\n", "", "return", "priors", ",", "values", ",", "next_states", ",", "classi_past_key_values", "\n", "\n"]], "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.main": [[604, 631], ["print", "pandas.read_csv", "print", "torch.zeros", "torch.zeros", "torch.zeros", "mcts_ag_bert_uni.NumpyMCTS", "tqdm.tqdm", "torch.zeros.fill_", "enumerate", "mcts_ag_bert_uni.NumpyMCTS.set_labels", "tokenizer().to", "mcts_ag_bert_uni.NumpyMCTS.search", "tqdm.tqdm.update", "lines.iterrows", "str", "tokenizer", "int"], "function", ["home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.set_labels", "home.repos.pwc.inspect_result.NohTow_PPL-MCTS.teammates.mcts_ag_bert_uni.NumpyMCTS.search"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "\"loading dataset\"", ")", "\n", "data_lines", "=", "pd", ".", "read_csv", "(", "\"datasets/ag_news/full/prompts.tsv\"", ",", "sep", "=", "'\\t'", ",", "engine", "=", "'python'", ",", "encoding", "=", "\"utf8\"", ")", "\n", "print", "(", "\"dataset loaded\"", ")", "\n", "generated_counter", "=", "0", "\n", "samples_size", "=", "501", "\n", "batch_size", "=", "args", ".", "batch_size", "\n", "labels", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "4", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "\"cuda\"", ")", "\n", "sot_texts", "=", "[", "None", "]", "*", "batch_size", "\n", "MCTS", "=", "NumpyMCTS", "(", "root_fun", ",", "rec_fun", ",", "batch_size", "=", "batch_size", ",", "num_simulations", "=", "args", ".", "num_it", ",", "num_actions", "=", "vocab_size", "+", "1", ",", "num_sparse_actions", "=", "50", ",", "pb_c_init", "=", "args", ".", "c", ",", "temperature", "=", "args", ".", "temperature", ",", "alpha", "=", "args", ".", "alpha", ",", "penalty", "=", "args", ".", "penalty", ")", "\n", "samples_pbar", "=", "tqdm", "(", "total", "=", "samples_size", ",", "desc", "=", "\"Samples generated\"", ")", "\n", "while", "(", "generated_counter", "+", "batch_size", "<=", "samples_size", ")", ":", "\n", "        ", "labels", ".", "fill_", "(", "0", ")", "\n", "# Prepare search inputs", "\n", "lines", "=", "data_lines", "[", "generated_counter", ":", "generated_counter", "+", "batch_size", "]", "\n", "\n", "\n", "for", "i", ",", "(", "_", ",", "row", ")", "in", "enumerate", "(", "lines", ".", "iterrows", "(", ")", ")", ":", "\n", "            ", "labels", "[", "i", ",", "int", "(", "row", "[", "\"label\"", "]", ")", "]", "=", "1", "\n", "sot_texts", "[", "i", "]", "=", "\"[CLS] \"", "+", "str", "(", "row", "[", "\"text\"", "]", ")", "\n", "\n", "", "MCTS", ".", "set_labels", "(", "labels", ")", "\n", "\n", "original_input", "=", "tokenizer", "(", "sot_texts", ",", "return_tensors", "=", "\"pt\"", ",", "padding", "=", "True", ",", "add_special_tokens", "=", "False", ",", "truncation", "=", "True", ",", "max_length", "=", "20", ")", ".", "to", "(", "\"cuda\"", ")", "\n", "MCTS", ".", "search", "(", "original_input", ")", "\n", "generated_counter", "+=", "batch_size", "\n", "samples_pbar", ".", "update", "(", "batch_size", ")", "\n", "\n"]]}