{"home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.CIFAR10Data.__init__": [[50, 77], ["numpy.zeros", "numpy.zeros", "enumerate", "resnet.CIFAR10Data._load_datafile", "range", "resnet.DataSubset", "resnet.DataSubset", "resnet.CIFAR10Data._load_datafile", "os.path.join", "open", "len", "resnet.CIFAR10Data.label_names[].decode", "range", "os.path.join", "os.path.join", "pickle.load", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.CIFAR10Data._load_datafile", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.CIFAR10Data._load_datafile"], ["def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "train_filenames", "=", "[", "'data_batch_{}'", ".", "format", "(", "ii", "+", "1", ")", "for", "ii", "in", "range", "(", "5", ")", "]", "\n", "eval_filename", "=", "'test_batch'", "\n", "metadata_filename", "=", "'batches.meta'", "\n", "\n", "train_images", "=", "np", ".", "zeros", "(", "(", "50000", ",", "32", ",", "32", ",", "3", ")", ",", "dtype", "=", "'uint8'", ")", "\n", "train_labels", "=", "np", ".", "zeros", "(", "50000", ",", "dtype", "=", "'int32'", ")", "\n", "for", "ii", ",", "fname", "in", "enumerate", "(", "train_filenames", ")", ":", "\n", "            ", "cur_images", ",", "cur_labels", "=", "self", ".", "_load_datafile", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "fname", ")", ")", "\n", "train_images", "[", "ii", "*", "10000", ":", "(", "ii", "+", "1", ")", "*", "10000", ",", "...", "]", "=", "cur_images", "\n", "train_labels", "[", "ii", "*", "10000", ":", "(", "ii", "+", "1", ")", "*", "10000", ",", "...", "]", "=", "cur_labels", "\n", "", "eval_images", ",", "eval_labels", "=", "self", ".", "_load_datafile", "(", "\n", "os", ".", "path", ".", "join", "(", "path", ",", "eval_filename", ")", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "metadata_filename", ")", ",", "'rb'", ")", "as", "fo", ":", "\n", "            ", "if", "version", ".", "major", "==", "3", ":", "\n", "                ", "data_dict", "=", "pickle", ".", "load", "(", "fo", ",", "encoding", "=", "'bytes'", ")", "\n", "", "else", ":", "\n", "                ", "data_dict", "=", "pickle", ".", "load", "(", "fo", ")", "\n", "\n", "", "self", ".", "label_names", "=", "data_dict", "[", "b'label_names'", "]", "\n", "", "for", "ii", "in", "range", "(", "len", "(", "self", ".", "label_names", ")", ")", ":", "\n", "            ", "self", ".", "label_names", "[", "ii", "]", "=", "self", ".", "label_names", "[", "ii", "]", ".", "decode", "(", "'utf-8'", ")", "\n", "\n", "", "self", ".", "train_data", "=", "DataSubset", "(", "train_images", ",", "train_labels", ")", "\n", "self", ".", "eval_data", "=", "DataSubset", "(", "eval_images", ",", "eval_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.CIFAR10Data._load_datafile": [[78, 91], ["open", "image_data.reshape().transpose.reshape().transpose.reshape().transpose", "pickle.load", "pickle.load", "numpy.array", "image_data.reshape().transpose.reshape().transpose.reshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_load_datafile", "(", "filename", ")", ":", "\n", "        ", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "fo", ":", "\n", "            ", "if", "version", ".", "major", "==", "3", ":", "\n", "                ", "data_dict", "=", "pickle", ".", "load", "(", "fo", ",", "encoding", "=", "'bytes'", ")", "\n", "", "else", ":", "\n", "                ", "data_dict", "=", "pickle", ".", "load", "(", "fo", ")", "\n", "\n", "", "assert", "data_dict", "[", "b'data'", "]", ".", "dtype", "==", "np", ".", "uint8", "\n", "image_data", "=", "data_dict", "[", "b'data'", "]", "\n", "image_data", "=", "image_data", ".", "reshape", "(", "\n", "(", "10000", ",", "3", ",", "32", ",", "32", ")", ")", ".", "transpose", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "return", "image_data", ",", "np", ".", "array", "(", "data_dict", "[", "b'labels'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.AugmentedCIFAR10Data.__init__": [[103, 127], ["isinstance", "tensorflow.placeholder", "tensorflow.map_fn", "tensorflow.map_fn", "tensorflow.map_fn", "resnet.AugmentedDataSubset", "resnet.AugmentedDataSubset", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.random_crop", "tensorflow.image.random_flip_left_right"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "raw_cifar10data", ",", "sess", ",", "model", ")", ":", "\n", "        ", "assert", "isinstance", "(", "raw_cifar10data", ",", "CIFAR10Data", ")", "\n", "self", ".", "image_size", "=", "32", "\n", "\n", "# create augmentation computational graph", "\n", "self", ".", "x_input_placeholder", "=", "tf", ".", "placeholder", "(", "\n", "tf", ".", "float32", ",", "shape", "=", "[", "None", ",", "32", ",", "32", ",", "3", "]", ")", "\n", "padded", "=", "tf", ".", "map_fn", "(", "lambda", "img", ":", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "\n", "img", ",", "self", ".", "image_size", "+", "4", ",", "self", ".", "image_size", "+", "4", ")", ",", "\n", "self", ".", "x_input_placeholder", ")", "\n", "cropped", "=", "tf", ".", "map_fn", "(", "lambda", "img", ":", "tf", ".", "random_crop", "(", "img", ",", "[", "self", ".", "image_size", ",", "\n", "self", ".", "image_size", ",", "\n", "3", "]", ")", ",", "padded", ")", "\n", "flipped", "=", "tf", ".", "map_fn", "(", "\n", "lambda", "img", ":", "tf", ".", "image", ".", "random_flip_left_right", "(", "img", ")", ",", "cropped", ")", "\n", "self", ".", "augmented", "=", "flipped", "\n", "\n", "self", ".", "train_data", "=", "AugmentedDataSubset", "(", "raw_cifar10data", ".", "train_data", ",", "sess", ",", "\n", "self", ".", "x_input_placeholder", ",", "\n", "self", ".", "augmented", ")", "\n", "self", ".", "eval_data", "=", "AugmentedDataSubset", "(", "raw_cifar10data", ".", "eval_data", ",", "sess", ",", "\n", "self", ".", "x_input_placeholder", ",", "\n", "self", ".", "augmented", ")", "\n", "self", ".", "label_names", "=", "raw_cifar10data", ".", "label_names", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.DataSubset.__init__": [[130, 136], ["numpy.random.permutation"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "xs", ",", "ys", ")", ":", "\n", "        ", "self", ".", "xs", "=", "xs", "\n", "self", ".", "n", "=", "xs", ".", "shape", "[", "0", "]", "\n", "self", ".", "ys", "=", "ys", "\n", "self", ".", "batch_start", "=", "0", "\n", "self", ".", "cur_order", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.DataSubset.get_next_batch": [[137, 159], ["min", "ValueError", "min", "ValueError", "numpy.random.permutation"], "methods", ["None"], ["", "def", "get_next_batch", "(", "self", ",", "batch_size", ",", "multiple_passes", "=", "False", ",", "reshuffle_after_pass", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "n", "<", "batch_size", ":", "\n", "            ", "raise", "ValueError", "(", "'Batch size can be at most the dataset size'", ")", "\n", "", "if", "not", "multiple_passes", ":", "\n", "            ", "actual_batch_size", "=", "min", "(", "batch_size", ",", "self", ".", "n", "-", "self", ".", "batch_start", ")", "\n", "if", "actual_batch_size", "<=", "0", ":", "\n", "                ", "raise", "ValueError", "(", "'Pass through the dataset is complete.'", ")", "\n", "", "batch_end", "=", "self", ".", "batch_start", "+", "actual_batch_size", "\n", "batch_xs", "=", "self", ".", "xs", "[", "self", ".", "cur_order", "[", "self", ".", "batch_start", ":", "batch_end", "]", ",", "...", "]", "\n", "batch_ys", "=", "self", ".", "ys", "[", "self", ".", "cur_order", "[", "self", ".", "batch_start", ":", "batch_end", "]", ",", "...", "]", "\n", "self", ".", "batch_start", "+=", "actual_batch_size", "\n", "return", "batch_xs", ",", "batch_ys", "\n", "", "actual_batch_size", "=", "min", "(", "batch_size", ",", "self", ".", "n", "-", "self", ".", "batch_start", ")", "\n", "if", "actual_batch_size", "<", "batch_size", ":", "\n", "            ", "if", "reshuffle_after_pass", ":", "\n", "                ", "self", ".", "cur_order", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "n", ")", "\n", "", "self", ".", "batch_start", "=", "0", "\n", "", "batch_end", "=", "self", ".", "batch_start", "+", "batch_size", "\n", "batch_xs", "=", "self", ".", "xs", "[", "self", ".", "cur_order", "[", "self", ".", "batch_start", ":", "batch_end", "]", ",", "...", "]", "\n", "batch_ys", "=", "self", ".", "ys", "[", "self", ".", "cur_order", "[", "self", ".", "batch_start", ":", "batch_end", "]", ",", "...", "]", "\n", "self", ".", "batch_start", "+=", "batch_size", "\n", "return", "batch_xs", ",", "batch_ys", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.AugmentedDataSubset.__init__": [[162, 168], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "raw_datasubset", ",", "sess", ",", "x_input_placeholder", ",", "\n", "augmented", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "self", ".", "raw_datasubset", "=", "raw_datasubset", "\n", "self", ".", "x_input_placeholder", "=", "x_input_placeholder", "\n", "self", ".", "augmented", "=", "augmented", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.AugmentedDataSubset.get_next_batch": [[169, 174], ["resnet.AugmentedDataSubset.raw_datasubset.get_next_batch", "raw_batch[].astype", "resnet.AugmentedDataSubset.sess.run"], "methods", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.AugmentedDataSubset.get_next_batch"], ["", "def", "get_next_batch", "(", "self", ",", "batch_size", ",", "multiple_passes", "=", "False", ",", "reshuffle_after_pass", "=", "True", ")", ":", "\n", "        ", "raw_batch", "=", "self", ".", "raw_datasubset", ".", "get_next_batch", "(", "batch_size", ",", "multiple_passes", ",", "\n", "reshuffle_after_pass", ")", "\n", "images", "=", "raw_batch", "[", "0", "]", ".", "astype", "(", "np", ".", "float32", ")", "\n", "return", "self", ".", "sess", ".", "run", "(", "self", ".", "augmented", ",", "feed_dict", "=", "{", "self", ".", "x_input_placeholder", ":", "raw_batch", "[", "0", "]", "}", ")", ",", "raw_batch", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.ResNet.__init__": [[359, 375], ["tensorflow.reshape", "resnet.ResNet.evaluate", "tensorflow.reduce_mean", "tensorflow.nn.softmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.ResNet.evaluate"], ["    ", "def", "__init__", "(", "self", ",", "x", ",", "y", ",", "conf", ")", ":", "\n", "        ", "self", ".", "x", "=", "tf", ".", "reshape", "(", "x", ",", "shape", "=", "[", "-", "1", ",", "32", ",", "32", ",", "3", "]", ")", "\n", "self", ".", "y", "=", "y", "\n", "self", ".", "keep_prob", "=", "1", "\n", "self", ".", "top_k", "=", "5", "\n", "self", ".", "NUM_CLASSES", "=", "10", "\n", "self", ".", "batch_size", "=", "conf", ".", "batch_size", "\n", "self", ".", "conf", "=", "conf", "\n", "self", ".", "conv_loss", "=", "self", ".", "evaluate", "(", "self", ".", "x", ")", "\n", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "labels", "=", "self", ".", "y", ",", "logits", "=", "self", ".", "conv_loss", ")", ")", "\n", "\n", "self", ".", "softmax", "=", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "conv_loss", ")", "\n", "self", ".", "pred", "=", "tf", ".", "argmax", "(", "self", ".", "conv_loss", ",", "1", ")", "\n", "\n", "self", ".", "correct_prediction", "=", "tf", ".", "equal", "(", "tf", ".", "argmax", "(", "self", ".", "conv_loss", ",", "1", ")", ",", "tf", ".", "argmax", "(", "self", ".", "y", ",", "1", ")", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "self", ".", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.ResNet.evaluate": [[376, 411], ["tensorflow.variable_scope", "range", "range", "range", "tensorflow.variable_scope", "resnet.conv_bn_relu_layer", "tensorflow.variable_scope", "tensorflow.nn.relu", "tensorflow.reduce_mean", "resnet.output_layer", "tensorflow.variable_scope", "tensorflow.variable_scope", "resnet.residual_block", "tensorflow.variable_scope", "resnet.residual_block", "resnet.residual_block", "resnet.residual_block", "residual_block.get_shape().as_list", "tensorflow.reduce_mean.get_shape().as_list", "residual_block.get_shape", "tensorflow.reduce_mean.get_shape"], "methods", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.conv_bn_relu_layer", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.output_layer", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.residual_block", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.residual_block", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.residual_block", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.residual_block"], ["", "def", "evaluate", "(", "self", ",", "x", ")", ":", "\n", "        ", "n", "=", "5", "\n", "with", "tf", ".", "variable_scope", "(", "'cnn'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "\n", "# layers = []", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'conv0'", ")", ":", "\n", "                ", "conv0", "=", "conv_bn_relu_layer", "(", "x", ",", "[", "3", ",", "3", ",", "3", ",", "16", "]", ",", "1", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'conv1_%d'", "%", "i", ")", ":", "\n", "                    ", "if", "i", "==", "0", ":", "\n", "                        ", "conv1", "=", "residual_block", "(", "conv0", ",", "16", ",", "first_block", "=", "True", ")", "\n", "", "else", ":", "\n", "                        ", "conv1", "=", "residual_block", "(", "conv1", ",", "16", ")", "\n", "", "", "", "conv2", "=", "conv1", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'conv2_%d'", "%", "i", ")", ":", "\n", "                    ", "conv2", "=", "residual_block", "(", "conv2", ",", "32", ")", "\n", "", "", "conv3", "=", "conv2", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'conv3_%d'", "%", "i", ")", ":", "\n", "                    ", "conv3", "=", "residual_block", "(", "conv3", ",", "64", ")", "\n", "", "assert", "conv3", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", "==", "[", "8", ",", "8", ",", "64", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'fc'", ")", ":", "\n", "# in_channel = conv3.get_shape().as_list()[-1]", "\n", "# bn_layer = batch_normalization_layer(layers[-1], in_channel)", "\n", "# conv3_drop = tf.nn.dropout(conv3, 0.5)", "\n", "\n", "                ", "relu_layer", "=", "tf", ".", "nn", ".", "relu", "(", "conv3", ")", "\n", "global_pool", "=", "tf", ".", "reduce_mean", "(", "relu_layer", ",", "[", "1", ",", "2", "]", ")", "\n", "\n", "assert", "global_pool", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", ":", "]", "==", "[", "64", "]", "\n", "output", "=", "output_layer", "(", "global_pool", ",", "10", ")", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.ResNet.loadWeights": [[412, 426], ["resnet.getSaveName", "numpy.load().item", "tensorflow.trainable_variables", "session.run", "numpy.load", "v.assign", "v.name.find", "v.name.find", "utility.frequencyHelper.generateSmoothKernel"], "methods", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.getSaveName"], ["", "def", "loadWeights", "(", "self", ",", "session", ",", "args", ")", ":", "\n", "        ", "saveName", "=", "getSaveName", "(", "args", ")", "\n", "weights_dict", "=", "np", ".", "load", "(", "'weights/'", "+", "saveName", "+", "'.npy'", ",", "encoding", "=", "'bytes'", ",", "\n", "allow_pickle", "=", "True", ")", ".", "item", "(", ")", "\n", "# Loop over all layer names stored in the weights dict", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "            ", "data", "=", "weights_dict", "[", "v", ".", "name", "]", "\n", "\n", "if", "args", ".", "rho", ">", "0", ":", "\n", "                ", "if", "v", ".", "name", ".", "find", "(", "'conv'", ")", "!=", "-", "1", ":", "\n", "                    ", "if", "v", ".", "name", ".", "find", "(", "'conv0'", ")", "!=", "-", "1", ":", "\n", "                        ", "data", "=", "generateSmoothKernel", "(", "data", ",", "args", ".", "rho", ")", "\n", "\n", "", "", "", "session", ".", "run", "(", "v", ".", "assign", "(", "data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.getSaveName": [[25, 31], ["None"], "function", ["None"], ["def", "getSaveName", "(", "args", ")", ":", "\n", "\n", "# todo: generate a name to save the model according to the args", "\n", "\n", "    ", "saveName", "=", "''", "\n", "return", "saveName", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.oneHotRepresentation": [[176, 183], ["range", "numpy.array", "numpy.zeros", "r.append"], "function", ["None"], ["", "", "def", "oneHotRepresentation", "(", "y", ",", "num", "=", "10", ")", ":", "\n", "    ", "r", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "y", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "l", "=", "np", ".", "zeros", "(", "num", ")", "\n", "l", "[", "y", "[", "i", "]", "]", "=", "1", "\n", "r", ".", "append", "(", "l", ")", "\n", "", "return", "np", ".", "array", "(", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.fft": [[185, 187], ["numpy.fft.fft2"], "function", ["None"], ["", "def", "fft", "(", "img", ")", ":", "\n", "    ", "return", "np", ".", "fft", ".", "fft2", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.fftshift": [[189, 191], ["numpy.fft.fftshift", "resnet.fft"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.fftshift", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.fft"], ["", "def", "fftshift", "(", "img", ")", ":", "\n", "    ", "return", "np", ".", "fft", ".", "fftshift", "(", "fft", "(", "img", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.weight_variable": [[193, 196], ["tensorflow.truncated_normal_initializer", "tensorflow.get_variable"], "function", ["None"], ["", "def", "weight_variable", "(", "shape", ")", ":", "\n", "    ", "initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "dtype", "=", "tf", ".", "float32", ",", "stddev", "=", "5e-2", ")", "\n", "return", "tf", ".", "get_variable", "(", "\"weights\"", ",", "shape", ",", "initializer", "=", "initializer", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.bias_variable": [[198, 201], ["tensorflow.constant_initializer", "tensorflow.get_variable"], "function", ["None"], ["", "def", "bias_variable", "(", "shape", ")", ":", "\n", "    ", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", "\n", "return", "tf", ".", "get_variable", "(", "\"biases\"", ",", "shape", ",", "initializer", "=", "initializer", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.conv2d": [[203, 205], ["tensorflow.nn.conv2d"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.conv2d"], ["", "def", "conv2d", "(", "x", ",", "W", ")", ":", "\n", "    ", "return", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "W", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.max_pool_2x2": [[207, 209], ["tensorflow.nn.max_pool"], "function", ["None"], ["", "def", "max_pool_2x2", "(", "x", ")", ":", "\n", "    ", "return", "tf", ".", "nn", ".", "max_pool", "(", "x", ",", "ksize", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.activation_summary": [[214, 222], ["tensorflow.summary.histogram", "tensorflow.summary.scalar", "tensorflow.nn.zero_fraction"], "function", ["None"], ["def", "activation_summary", "(", "x", ")", ":", "\n", "    ", "'''\n    :param x: A Tensor\n    :return: Add histogram summary and scalar summary of the sparsity of the tensor\n    '''", "\n", "tensor_name", "=", "x", ".", "op", ".", "name", "\n", "tf", ".", "summary", ".", "histogram", "(", "tensor_name", "+", "'/activations'", ",", "x", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "tensor_name", "+", "'/sparsity'", ",", "tf", ".", "nn", ".", "zero_fraction", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.create_variables": [[224, 238], ["tensorflow.contrib.layers.xavier_initializer", "tensorflow.contrib.layers.l2_regularizer", "tensorflow.get_variable"], "function", ["None"], ["", "def", "create_variables", "(", "name", ",", "shape", ",", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ",", "is_fc_layer", "=", "False", ")", ":", "\n", "    ", "'''\n    :param name: A string. The name of the new variable\n    :param shape: A list of dimensions\n    :param initializer: User Xavier as default.\n    :param is_fc_layer: Want to create fc layer variable? May use different weight_decay for fc\n    layers.\n    :return: The created variable\n    '''", "\n", "\n", "regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "scale", "=", "0.0002", ")", "\n", "\n", "new_variables", "=", "tf", ".", "get_variable", "(", "name", ",", "shape", "=", "shape", ",", "initializer", "=", "initializer", ")", "# , regularizer=regularizer)", "\n", "return", "new_variables", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.output_layer": [[240, 253], ["resnet.create_variables", "resnet.create_variables", "input_layer.get_shape().as_list", "tensorflow.matmul", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.zeros_initializer", "input_layer.get_shape"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.create_variables", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.create_variables"], ["", "def", "output_layer", "(", "input_layer", ",", "num_labels", ")", ":", "\n", "    ", "'''\n    :param input_layer: 2D tensor\n    :param num_labels: int. How many output labels in total? (10 for cifar10 and 100 for cifar100)\n    :return: output layer Y = WX + B\n    '''", "\n", "input_dim", "=", "input_layer", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "fc_w", "=", "create_variables", "(", "name", "=", "'fc_weights'", ",", "shape", "=", "[", "input_dim", ",", "num_labels", "]", ",", "is_fc_layer", "=", "True", ",", "\n", "initializer", "=", "tf", ".", "uniform_unit_scaling_initializer", "(", "factor", "=", "1.0", ")", ")", "\n", "fc_b", "=", "create_variables", "(", "name", "=", "'fc_bias'", ",", "shape", "=", "[", "num_labels", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "\n", "fc_h", "=", "tf", ".", "matmul", "(", "input_layer", ",", "fc_w", ")", "+", "fc_b", "\n", "return", "fc_h", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.batch_normalization_layer": [[255, 273], ["None"], "function", ["None"], ["", "def", "batch_normalization_layer", "(", "input_layer", ",", "dimension", ")", ":", "\n", "    ", "'''\n    Helper function to do batch normalziation\n    :param input_layer: 4D tensor\n    :param dimension: input_layer.get_shape().as_list()[-1]. The depth of the 4D tensor\n    :return: the 4D tensor after being normalized\n    '''", "\n", "\n", "# TODO: use the following seven lines to control the usage of batch normalization", "\n", "# mean, variance = tf.nn.moments(input_layer, axes=[0, 1, 2])", "\n", "# beta = tf.get_variable('beta', dimension, tf.float32,", "\n", "#                        initializer=tf.constant_initializer(0.0, tf.float32))", "\n", "# gamma = tf.get_variable('gamma', dimension, tf.float32,", "\n", "#                         initializer=tf.constant_initializer(1.0, tf.float32))", "\n", "# bn_layer = tf.nn.batch_normalization(input_layer, mean, variance, beta, gamma, BN_EPSILON)", "\n", "# return bn_layer", "\n", "\n", "return", "input_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.conv_bn_relu_layer": [[275, 292], ["resnet.create_variables", "tensorflow.nn.conv2d", "resnet.batch_normalization_layer", "tensorflow.nn.relu"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.create_variables", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.conv2d", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.batch_normalization_layer"], ["", "def", "conv_bn_relu_layer", "(", "input_layer", ",", "filter_shape", ",", "stride", ")", ":", "\n", "    ", "'''\n    A helper function to conv, batch normalize and relu the input tensor sequentially\n    :param input_layer: 4D tensor\n    :param filter_shape: list. [filter_height, filter_width, filter_depth, filter_number]\n    :param stride: stride size for conv\n    :return: 4D tensor. Y = Relu(batch_normalize(conv(X)))\n    '''", "\n", "\n", "out_channel", "=", "filter_shape", "[", "-", "1", "]", "\n", "filter", "=", "create_variables", "(", "name", "=", "'conv'", ",", "shape", "=", "filter_shape", ")", "\n", "\n", "conv_layer", "=", "tf", ".", "nn", ".", "conv2d", "(", "input_layer", ",", "filter", ",", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "bn_layer", "=", "batch_normalization_layer", "(", "conv_layer", ",", "out_channel", ")", "\n", "\n", "output", "=", "tf", ".", "nn", ".", "relu", "(", "bn_layer", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.bn_relu_conv_layer": [[294, 311], ["resnet.batch_normalization_layer", "tensorflow.nn.relu", "resnet.create_variables", "tensorflow.nn.conv2d", "input_layer.get_shape().as_list", "input_layer.get_shape"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.batch_normalization_layer", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.create_variables", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.conv2d"], ["", "def", "bn_relu_conv_layer", "(", "input_layer", ",", "filter_shape", ",", "stride", ")", ":", "\n", "    ", "'''\n    A helper function to batch normalize, relu and conv the input layer sequentially\n    :param input_layer: 4D tensor\n    :param filter_shape: list. [filter_height, filter_width, filter_depth, filter_number]\n    :param stride: stride size for conv\n    :return: 4D tensor. Y = conv(Relu(batch_normalize(X)))\n    '''", "\n", "\n", "in_channel", "=", "input_layer", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "bn_layer", "=", "batch_normalization_layer", "(", "input_layer", ",", "in_channel", ")", "\n", "relu_layer", "=", "tf", ".", "nn", ".", "relu", "(", "bn_layer", ")", "\n", "\n", "filter", "=", "create_variables", "(", "name", "=", "'conv'", ",", "shape", "=", "filter_shape", ")", "\n", "conv_layer", "=", "tf", ".", "nn", ".", "conv2d", "(", "relu_layer", ",", "filter", ",", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "return", "conv_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.residual_block": [[313, 356], ["input_layer.get_shape().as_list", "tensorflow.variable_scope", "tensorflow.variable_scope", "resnet.bn_relu_conv_layer", "tensorflow.nn.avg_pool", "tensorflow.pad", "ValueError", "resnet.create_variables", "tensorflow.nn.conv2d", "resnet.bn_relu_conv_layer", "input_layer.get_shape"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.bn_relu_conv_layer", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.create_variables", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.conv2d", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.bn_relu_conv_layer"], ["", "def", "residual_block", "(", "input_layer", ",", "output_channel", ",", "first_block", "=", "False", ")", ":", "\n", "    ", "'''\n    Defines a residual block in ResNet\n    :param input_layer: 4D tensor\n    :param output_channel: int. return_tensor.get_shape().as_list()[-1] = output_channel\n    :param first_block: if this is the first residual block of the whole network\n    :return: 4D tensor.\n    '''", "\n", "input_channel", "=", "input_layer", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", "\n", "\n", "# When it's time to \"shrink\" the image size, we use stride = 2", "\n", "if", "input_channel", "*", "2", "==", "output_channel", ":", "\n", "        ", "increase_dim", "=", "True", "\n", "stride", "=", "2", "\n", "", "elif", "input_channel", "==", "output_channel", ":", "\n", "        ", "increase_dim", "=", "False", "\n", "stride", "=", "1", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Output and input channel does not match in residual blocks!!!'", ")", "\n", "\n", "# The first conv layer of the first residual block does not need to be normalized and relu-ed.", "\n", "", "with", "tf", ".", "variable_scope", "(", "'conv1_in_block'", ")", ":", "\n", "        ", "if", "first_block", ":", "\n", "            ", "filter", "=", "create_variables", "(", "name", "=", "'conv'", ",", "shape", "=", "[", "3", ",", "3", ",", "input_channel", ",", "output_channel", "]", ")", "\n", "conv1", "=", "tf", ".", "nn", ".", "conv2d", "(", "input_layer", ",", "filter", "=", "filter", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "", "else", ":", "\n", "            ", "conv1", "=", "bn_relu_conv_layer", "(", "input_layer", ",", "[", "3", ",", "3", ",", "input_channel", ",", "output_channel", "]", ",", "stride", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "'conv2_in_block'", ")", ":", "\n", "        ", "conv2", "=", "bn_relu_conv_layer", "(", "conv1", ",", "[", "3", ",", "3", ",", "output_channel", ",", "output_channel", "]", ",", "1", ")", "\n", "\n", "# When the channels of input layer and conv2 does not match, we add zero pads to increase the", "\n", "#  depth of input layers", "\n", "", "if", "increase_dim", "is", "True", ":", "\n", "        ", "pooled_input", "=", "tf", ".", "nn", ".", "avg_pool", "(", "input_layer", ",", "ksize", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "padding", "=", "'VALID'", ")", "\n", "padded_input", "=", "tf", ".", "pad", "(", "pooled_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "input_channel", "//", "2", ",", "\n", "input_channel", "//", "2", "]", "]", ")", "\n", "", "else", ":", "\n", "        ", "padded_input", "=", "input_layer", "\n", "\n", "", "output", "=", "conv2", "+", "padded_input", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.train": [[428, 603], ["resnet.CIFAR10Data", "tensorflow.placeholder", "tensorflow.placeholder", "resnet.ResNet", "tensorflow.train.AdamOptimizer", "tensorflow.get_collection", "tf.train.AdamOptimizer.minimize", "numpy.load", "range", "numpy.load", "numpy.load", "trainDatas.append", "trainDatas.append", "range", "numpy.load", "testDatas.append", "testDatas.append", "range", "tensorflow.Session", "sess.run", "print", "range", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "tensorflow.global_variables_initializer", "time.time", "numpy.array", "numpy.random.shuffle", "range", "range", "numpy.mean", "numpy.mean", "numpy.mean", "sys.stdout.flush", "tensorflow.trainable_variables", "numpy.save", "numpy.max", "range", "len", "resnet.oneHotRepresentation", "sess.run", "train_accuracies.append", "train_losses.append", "adv_losses.append", "range", "numpy.mean", "val_acc.append", "print", "range", "range", "v.eval", "numpy.max", "numpy.max", "CIFAR10Data.eval_data.get_next_batch", "resnet.oneHotRepresentation", "sess.run", "val_accuracies.append", "len", "range", "len", "range", "resnet.getSaveName", "str", "str", "str", "str", "str", "str", "range", "numpy.mean", "train_acc.append", "range", "numpy.mean", "val_acc.append", "resnet.oneHotRepresentation", "sess.run", "train_accuracies.append", "print", "print", "resnet.oneHotRepresentation", "sess.run", "val_accuracies.append", "print", "print", "time.time"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.oneHotRepresentation", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.AugmentedDataSubset.get_next_batch", "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.oneHotRepresentation", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.getSaveName", "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.oneHotRepresentation", "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.oneHotRepresentation"], ["", "", "", "def", "train", "(", "args", ")", ":", "\n", "    ", "num_classes", "=", "10", "\n", "data_path", "=", "'../data/CIFAR10/'", "\n", "raw_cifar", "=", "CIFAR10Data", "(", "data_path", ")", "\n", "\n", "train_batches_per_epoch", "=", "50000", "//", "args", ".", "batch_size", "\n", "\n", "val_batches_per_epoch", "=", "10000", "//", "100", "\n", "\n", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "32", ",", "32", ",", "3", ")", ")", "\n", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "num_classes", ")", ")", "\n", "\n", "model", "=", "ResNet", "(", "x", ",", "y", ",", "args", ")", "\n", "\n", "optimizer1", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "1e-4", ")", "\n", "# optimizer1 = tf.train.GradientDescentOptimizer(1e-2)", "\n", "# optimizer1 = tf.train.AdadeltaOptimizer(1e-1)", "\n", "first_train_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "\"cnn\"", ")", "\n", "first_train_op", "=", "optimizer1", ".", "minimize", "(", "model", ".", "loss", ",", "var_list", "=", "first_train_vars", ")", "\n", "\n", "radius", "=", "[", "4", ",", "8", ",", "12", ",", "16", "]", "\n", "\n", "trainData", "=", "np", ".", "load", "(", "'../data/CIFAR10/train_images.npy'", ")", "\n", "if", "args", ".", "frequency", "!=", "0", ":", "\n", "        ", "if", "args", ".", "high", "==", "1", ":", "\n", "            ", "trainData", "=", "np", ".", "load", "(", "'../data/CIFAR10/train_data_high_'", "+", "str", "(", "args", ".", "frequency", ")", "+", "'.npy'", ")", "\n", "", "else", ":", "\n", "            ", "trainData", "=", "np", ".", "load", "(", "'../data/CIFAR10/train_data_low_'", "+", "str", "(", "args", ".", "frequency", ")", "+", "'.npy'", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "trainData", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "trainData", "[", "i", "]", "=", "trainData", "[", "i", "]", "/", "np", ".", "max", "(", "trainData", "[", "i", "]", ")", "*", "255", "\n", "\n", "", "trainDatas", "=", "[", "]", "\n", "for", "r", "in", "radius", ":", "\n", "        ", "trainDatas", ".", "append", "(", "np", ".", "load", "(", "'../data/CIFAR10/train_data_low_'", "+", "str", "(", "r", ")", "+", "'.npy'", ")", ")", "\n", "trainDatas", ".", "append", "(", "np", ".", "load", "(", "'../data/CIFAR10/train_data_high_'", "+", "str", "(", "r", ")", "+", "'.npy'", ")", ")", "\n", "\n", "", "for", "td", "in", "trainDatas", ":", "\n", "        ", "for", "i", "in", "range", "(", "td", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "td", "[", "i", "]", "=", "td", "[", "i", "]", "/", "np", ".", "max", "(", "td", "[", "i", "]", ")", "*", "255", "\n", "\n", "", "", "trainLabel", "=", "np", ".", "load", "(", "'../data/CIFAR10/train_label.npy'", ")", "\n", "\n", "if", "args", ".", "shuffle", ":", "\n", "# it's much better to shuffle data once then load it when needed than shuffling every time for replication purpose", "\n", "        ", "trainLabel", "=", "np", ".", "load", "(", "'../data/CIFAR10/train_label_shuffle.npy'", ")", "\n", "\n", "", "testDatas", "=", "[", "]", "\n", "for", "r", "in", "radius", ":", "\n", "        ", "testDatas", ".", "append", "(", "np", ".", "load", "(", "'../data/CIFAR10/test_data_low_'", "+", "str", "(", "r", ")", "+", "'.npy'", ")", ")", "\n", "testDatas", ".", "append", "(", "np", ".", "load", "(", "'../data/CIFAR10/test_data_high_'", "+", "str", "(", "r", ")", "+", "'.npy'", ")", ")", "\n", "", "testLabel", "=", "np", ".", "load", "(", "'../data/CIFAR10/test_label.npy'", ")", "\n", "\n", "for", "td", "in", "testDatas", ":", "\n", "        ", "for", "i", "in", "range", "(", "td", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "td", "[", "i", "]", "=", "td", "[", "i", "]", "/", "np", ".", "max", "(", "td", "[", "i", "]", ")", "*", "255", "\n", "\n", "", "", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "print", "(", "'Starting training'", ")", "\n", "best_validate_accuracy", "=", "0", "\n", "validation", "=", "True", "\n", "score", "=", "0", "\n", "train_acc", "=", "[", "]", "\n", "val_acc", "=", "[", "]", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "\n", "            ", "begin", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_accuracies", "=", "[", "]", "\n", "train_losses", "=", "[", "]", "\n", "adv_losses", "=", "[", "]", "\n", "adv_loss", "=", "0", "\n", "\n", "idx", "=", "np", ".", "array", "(", "range", "(", "50000", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "trainData", "=", "trainData", "[", "idx", ",", ":", "]", "\n", "trainLabel", "=", "trainLabel", "[", "idx", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "trainDatas", ")", ")", ":", "\n", "                ", "trainDatas", "[", "i", "]", "=", "trainDatas", "[", "i", "]", "[", "idx", ",", ":", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "train_batches_per_epoch", ")", ":", "\n", "# batch_x, batch_y = cifar.train_data.get_next_batch(args.batch_size, multiple_passes=True)", "\n", "                ", "batch_x", "=", "trainData", "[", "i", "*", "args", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", ",", ":", "]", "\n", "batch_y", "=", "trainLabel", "[", "i", "*", "args", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", "]", "\n", "batch_y", "=", "oneHotRepresentation", "(", "batch_y", ")", "\n", "batch_x", "=", "batch_x", "/", "255.0", "\n", "\n", "\n", "# todo: use the following code to control usage of mixup", "\n", "# idx = np.array(range(args.batch_size))", "\n", "# np.random.shuffle(idx)", "\n", "# b = np.random.beta(1, 1)", "\n", "# batch_x = batch_x*b + batch_x[idx,:]*(1-b)", "\n", "# batch_y = batch_y*b + batch_y[idx,:]*(1-b)", "\n", "\n", "_", ",", "acc", ",", "loss", "=", "sess", ".", "run", "(", "[", "first_train_op", ",", "model", ".", "accuracy", ",", "model", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "x", ":", "batch_x", ",", "y", ":", "batch_y", "}", ")", "\n", "\n", "train_accuracies", ".", "append", "(", "acc", ")", "\n", "train_losses", ".", "append", "(", "loss", ")", "\n", "adv_losses", ".", "append", "(", "adv_loss", ")", "\n", "\n", "", "train_acc_mean", "=", "np", ".", "mean", "(", "train_accuracies", ")", "\n", "train_loss_mean", "=", "np", ".", "mean", "(", "train_losses", ")", "\n", "adv_loss_mean", "=", "np", ".", "mean", "(", "adv_losses", ")", "\n", "\n", "\n", "if", "validation", ":", "\n", "\n", "                ", "val_accuracies", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "val_batches_per_epoch", ")", ":", "\n", "                    ", "batch_x", ",", "batch_y", "=", "raw_cifar", ".", "eval_data", ".", "get_next_batch", "(", "100", ",", "multiple_passes", "=", "True", ")", "\n", "batch_y", "=", "oneHotRepresentation", "(", "batch_y", ")", "\n", "batch_x", "=", "batch_x", "/", "255.0", "\n", "\n", "acc", "=", "sess", ".", "run", "(", "model", ".", "accuracy", ",", "feed_dict", "=", "{", "x", ":", "batch_x", ",", "y", ":", "batch_y", "}", ")", "\n", "val_accuracies", ".", "append", "(", "acc", ")", "\n", "", "val_acc_mean", "=", "np", ".", "mean", "(", "val_accuracies", ")", "\n", "val_acc", ".", "append", "(", "val_acc_mean", ")", "\n", "# log progress to console", "\n", "print", "(", "\n", "\"Epoch %d, time = %ds, train accuracy = %.4f, loss = %.4f, adv accuracy = %.4f,  validation accuracy = %.4f\"", "%", "(", "\n", "epoch", ",", "time", ".", "time", "(", ")", "-", "begin", ",", "train_acc_mean", ",", "train_loss_mean", ",", "adv_loss_mean", ",", "val_acc_mean", ")", ")", "\n", "\n", "for", "r", "in", "range", "(", "len", "(", "radius", ")", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "2", ")", ":", "\n", "                        ", "train_accuracies", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "500", ")", ":", "\n", "                            ", "batch_x", "=", "trainDatas", "[", "r", "*", "2", "+", "j", "]", "[", "i", "*", "100", ":", "(", "i", "+", "1", ")", "*", "100", ",", ":", "]", "\n", "batch_y", "=", "trainLabel", "[", "i", "*", "100", ":", "(", "i", "+", "1", ")", "*", "100", "]", "\n", "batch_y", "=", "oneHotRepresentation", "(", "batch_y", ")", "\n", "batch_x", "=", "batch_x", "/", "255.0", "\n", "\n", "acc", "=", "sess", ".", "run", "(", "model", ".", "accuracy", ",", "feed_dict", "=", "{", "x", ":", "batch_x", ",", "y", ":", "batch_y", "}", ")", "\n", "train_accuracies", ".", "append", "(", "acc", ")", "\n", "", "train_acc_mean", "=", "np", ".", "mean", "(", "train_accuracies", ")", "\n", "train_acc", ".", "append", "(", "train_acc_mean", ")", "\n", "# log progress to console", "\n", "if", "j", "==", "0", ":", "\n", "                            ", "print", "(", "\"Radius = %d, low end, train accuracy = %.4f\"", "%", "(", "radius", "[", "r", "]", ",", "\n", "train_acc_mean", ")", ")", "\n", "", "else", ":", "\n", "                            ", "print", "(", "\"Radius = %d, high end, train accuracy = %.4f\"", "%", "(", "radius", "[", "r", "]", ",", "\n", "train_acc_mean", ")", ")", "\n", "\n", "", "", "", "for", "r", "in", "range", "(", "len", "(", "radius", ")", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "2", ")", ":", "\n", "                        ", "val_accuracies", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "val_batches_per_epoch", ")", ":", "\n", "                            ", "batch_x", "=", "testDatas", "[", "r", "*", "2", "+", "j", "]", "[", "i", "*", "100", ":", "(", "i", "+", "1", ")", "*", "100", ",", ":", "]", "\n", "batch_y", "=", "testLabel", "[", "i", "*", "100", ":", "(", "i", "+", "1", ")", "*", "100", "]", "\n", "batch_y", "=", "oneHotRepresentation", "(", "batch_y", ")", "\n", "batch_x", "=", "batch_x", "/", "255.0", "\n", "\n", "acc", "=", "sess", ".", "run", "(", "model", ".", "accuracy", ",", "feed_dict", "=", "{", "x", ":", "batch_x", ",", "y", ":", "batch_y", "}", ")", "\n", "val_accuracies", ".", "append", "(", "acc", ")", "\n", "", "val_acc_mean", "=", "np", ".", "mean", "(", "val_accuracies", ")", "\n", "val_acc", ".", "append", "(", "val_acc_mean", ")", "\n", "# log progress to console", "\n", "if", "j", "==", "0", ":", "\n", "                            ", "print", "(", "\"Radius = %d, low end, validation accuracy = %.4f\"", "%", "(", "radius", "[", "r", "]", ",", "\n", "val_acc_mean", ")", ")", "\n", "", "else", ":", "\n", "                            ", "print", "(", "\"Radius = %d, high end, validation accuracy = %.4f\"", "%", "(", "radius", "[", "r", "]", ",", "\n", "val_acc_mean", ")", ")", "\n", "\n", "", "", "", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "if", "args", ".", "saveModel", "==", "1", ":", "\n", "            ", "weights", "=", "{", "}", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "                ", "weights", "[", "v", ".", "name", "]", "=", "v", ".", "eval", "(", ")", "\n", "\n", "", "np", ".", "save", "(", "'weights/resnet_'", "+", "getSaveName", "(", "args", ")", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.trainMadry": [[606, 722], ["resnet.CIFAR10Data", "tensorflow.placeholder", "tensorflow.placeholder", "resnet.ResNet", "tensorflow.train.AdamOptimizer", "tensorflow.get_collection", "tf.train.AdamOptimizer.minimize", "numpy.load", "utility.pgd_attack.LinfPGDAttack", "testDatas.append", "testDatas.append", "tensorflow.Session", "print", "sess.run", "resnet.AugmentedCIFAR10Data", "range", "numpy.load", "numpy.load", "tensorflow.initialize_all_variables", "time.time", "range", "numpy.mean", "train_acc.append", "numpy.mean", "numpy.mean", "sys.stdout.flush", "tensorflow.trainable_variables", "numpy.save", "AugmentedCIFAR10Data.train_data.get_next_batch", "resnet.oneHotRepresentation", "utility.pgd_attack.LinfPGDAttack.perturb", "sess.run", "train_accuracies.append", "train_losses.append", "adv_losses.append", "range", "numpy.mean", "val_acc.append", "print", "range", "v.eval", "CIFAR10Data.eval_data.get_next_batch", "resnet.oneHotRepresentation", "sess.run", "val_accuracies.append", "len", "range", "resnet.getSaveName", "str", "str", "range", "numpy.mean", "val_acc.append", "resnet.oneHotRepresentation", "sess.run", "val_accuracies.append", "print", "print", "time.time"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.AugmentedDataSubset.get_next_batch", "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.oneHotRepresentation", "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.pgd_attack.LinfPGDAttack.perturb", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.AugmentedDataSubset.get_next_batch", "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.oneHotRepresentation", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.getSaveName", "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.oneHotRepresentation"], ["", "", "", "def", "trainMadry", "(", "args", ")", ":", "\n", "# \"\"\" reuse \"\"\"", "\n", "# with tf.variable_scope('model',reuse=tf.AUTO_REUSE ) as scope:", "\n", "    ", "num_classes", "=", "10", "\n", "data_path", "=", "'../data/CIFAR10/'", "\n", "raw_cifar", "=", "CIFAR10Data", "(", "data_path", ")", "\n", "\n", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "32", ",", "32", ",", "3", ")", ")", "\n", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "num_classes", ")", ")", "\n", "\n", "model", "=", "ResNet", "(", "x", ",", "y", ",", "args", ")", "\n", "# For sanping's server", "\n", "train_batches_per_epoch", "=", "50000", "//", "args", ".", "batch_size", "\n", "\n", "val_batches_per_epoch", "=", "10000", "//", "100", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "1e-4", ")", "\n", "train_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "\"cnn\"", ")", "\n", "first_train_op", "=", "optimizer", ".", "minimize", "(", "model", ".", "loss", ",", "var_list", "=", "train_vars", ")", "\n", "\n", "radius", "=", "[", "4", ",", "8", ",", "12", ",", "16", ",", "20", ",", "24", ",", "28", "]", "\n", "testDatas", "=", "[", "]", "\n", "for", "r", "in", "radius", ":", "\n", "        ", "testDatas", ".", "append", "(", "np", ".", "load", "(", "'../data/CIFAR10/test_data_low_'", "+", "str", "(", "r", ")", "+", "'.npy'", ")", ")", "\n", "testDatas", ".", "append", "(", "np", ".", "load", "(", "'../data/CIFAR10/test_data_high_'", "+", "str", "(", "r", ")", "+", "'.npy'", ")", ")", "\n", "", "testLabel", "=", "np", ".", "load", "(", "'../data/CIFAR10/test_label.npy'", ")", "\n", "\n", "attack", "=", "LinfPGDAttack", "(", "model", ",", "args", ".", "epsilon", ",", "10", ",", "args", ".", "epsilon", "/", "10", ",", "False", ",", "'loss'", ")", "\n", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "\n", "        ", "print", "(", "'Starting training'", ")", "\n", "sess", ".", "run", "(", "tf", ".", "initialize_all_variables", "(", ")", ")", "\n", "cifar", "=", "AugmentedCIFAR10Data", "(", "raw_cifar", ",", "sess", ",", "model", ")", "\n", "\n", "validation", "=", "True", "\n", "\n", "train_acc", "=", "[", "]", "\n", "val_acc", "=", "[", "]", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "\n", "            ", "begin", "=", "time", ".", "time", "(", ")", "\n", "\n", "train_accuracies", "=", "[", "]", "\n", "train_losses", "=", "[", "]", "\n", "adv_losses", "=", "[", "]", "\n", "adv_loss", "=", "0", "\n", "acc", "=", "0", "\n", "adv_acc", "=", "0", "\n", "for", "i", "in", "range", "(", "train_batches_per_epoch", ")", ":", "\n", "                ", "batch_x", ",", "batch_y", "=", "cifar", ".", "train_data", ".", "get_next_batch", "(", "args", ".", "batch_size", ",", "multiple_passes", "=", "True", ")", "\n", "batch_y", "=", "oneHotRepresentation", "(", "batch_y", ")", "\n", "batch_x", "=", "batch_x", "/", "255.0", "\n", "\n", "batch_x_adv", "=", "attack", ".", "perturb", "(", "batch_x", ",", "batch_y", ",", "sess", ")", "\n", "\n", "_", ",", "adv_acc", ",", "loss", "=", "sess", ".", "run", "(", "[", "first_train_op", ",", "model", ".", "accuracy", ",", "model", ".", "loss", "]", ",", "\n", "feed_dict", "=", "{", "x", ":", "batch_x_adv", ",", "y", ":", "batch_y", "}", ")", "\n", "\n", "train_accuracies", ".", "append", "(", "acc", ")", "\n", "train_losses", ".", "append", "(", "loss", ")", "\n", "adv_losses", ".", "append", "(", "adv_acc", ")", "\n", "", "train_acc_mean", "=", "np", ".", "mean", "(", "train_accuracies", ")", "\n", "train_acc", ".", "append", "(", "train_acc_mean", ")", "\n", "\n", "train_loss_mean", "=", "np", ".", "mean", "(", "train_losses", ")", "\n", "adv_loss_mean", "=", "np", ".", "mean", "(", "adv_losses", ")", "\n", "\n", "# print ()", "\n", "# compute loss over validation data", "\n", "if", "validation", ":", "\n", "                ", "val_accuracies", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "val_batches_per_epoch", ")", ":", "\n", "                    ", "batch_x", ",", "batch_y", "=", "raw_cifar", ".", "eval_data", ".", "get_next_batch", "(", "100", ",", "multiple_passes", "=", "True", ")", "\n", "batch_y", "=", "oneHotRepresentation", "(", "batch_y", ")", "\n", "batch_x", "=", "batch_x", "/", "255.0", "\n", "\n", "acc", "=", "sess", ".", "run", "(", "model", ".", "accuracy", ",", "feed_dict", "=", "{", "x", ":", "batch_x", ",", "y", ":", "batch_y", "}", ")", "\n", "val_accuracies", ".", "append", "(", "acc", ")", "\n", "", "val_acc_mean", "=", "np", ".", "mean", "(", "val_accuracies", ")", "\n", "val_acc", ".", "append", "(", "val_acc_mean", ")", "\n", "# log progress to console", "\n", "print", "(", "\n", "\"Epoch %d, time = %ds, train accuracy = %.4f, loss = %.4f, adv accuracy = %.4f,  validation accuracy = %.4f\"", "%", "(", "\n", "epoch", ",", "time", ".", "time", "(", ")", "-", "begin", ",", "train_acc_mean", ",", "train_loss_mean", ",", "adv_loss_mean", ",", "val_acc_mean", ")", ")", "\n", "\n", "for", "r", "in", "range", "(", "len", "(", "radius", ")", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "2", ")", ":", "\n", "                        ", "val_accuracies", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "val_batches_per_epoch", ")", ":", "\n", "                            ", "batch_x", "=", "testDatas", "[", "r", "*", "2", "+", "j", "]", "[", "i", "*", "100", ":", "(", "i", "+", "1", ")", "*", "100", ",", ":", "]", "\n", "batch_y", "=", "testLabel", "[", "i", "*", "100", ":", "(", "i", "+", "1", ")", "*", "100", "]", "\n", "batch_y", "=", "oneHotRepresentation", "(", "batch_y", ")", "\n", "batch_x", "=", "batch_x", "/", "255.0", "\n", "\n", "acc", "=", "sess", ".", "run", "(", "model", ".", "accuracy", ",", "feed_dict", "=", "{", "x", ":", "batch_x", ",", "y", ":", "batch_y", "}", ")", "\n", "val_accuracies", ".", "append", "(", "acc", ")", "\n", "", "val_acc_mean", "=", "np", ".", "mean", "(", "val_accuracies", ")", "\n", "val_acc", ".", "append", "(", "val_acc_mean", ")", "\n", "# log progress to console", "\n", "if", "j", "==", "0", ":", "\n", "                            ", "print", "(", "\"Radius = %d, low end, validation accuracy = %.4f\"", "%", "(", "radius", "[", "r", "]", ",", "\n", "val_acc_mean", ")", ")", "\n", "", "else", ":", "\n", "                            ", "print", "(", "\"Radius = %d, high end, validation accuracy = %.4f\"", "%", "(", "radius", "[", "r", "]", ",", "\n", "val_acc_mean", ")", ")", "\n", "\n", "", "", "", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "if", "args", ".", "saveModel", "==", "1", ":", "\n", "            ", "weights", "=", "{", "}", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "                ", "weights", "[", "v", ".", "name", "]", "=", "v", ".", "eval", "(", ")", "\n", "\n", "", "np", ".", "save", "(", "'weights/resnet_'", "+", "getSaveName", "(", "args", ")", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.attackModel": [[724, 742], ["utility.dataLoader.loadDataCifar10", "tensorflow.placeholder", "tensorflow.placeholder", "resnet.ResNet", "tensorflow.Session", "sess.run", "resnet.ResNet.loadWeights", "utility.attackHelper.attackAModelCIFAR", "resnet.getSaveName", "numpy.save", "numpy.save", "tensorflow.global_variables_initializer"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.loadDataCifar10", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.ResNet.loadWeights", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.getSaveName"], ["", "", "", "def", "attackModel", "(", "args", ")", ":", "\n", "    ", "Xtest", ",", "Ytest", "=", "loadDataCifar10", "(", ")", "\n", "\n", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "32", ",", "32", ",", "3", ")", ")", "\n", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "10", ")", ")", "\n", "\n", "model", "=", "ResNet", "(", "x", ",", "y", ",", "args", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "model", ".", "loadWeights", "(", "sess", ",", "args", ")", "\n", "\n", "Xadv_fgsm", ",", "Xadv_pgd", "=", "attackAModelCIFAR", "(", "x", ",", "model", ".", "conv_loss", ",", "1.0", ",", "Xtest", ",", "Ytest", ")", "\n", "\n", "saveName", "=", "getSaveName", "(", "args", ")", "\n", "\n", "np", ".", "save", "(", "'advs/fgsm'", "+", "saveName", ",", "Xadv_fgsm", ")", "\n", "np", ".", "save", "(", "'advs/pgd'", "+", "saveName", ",", "Xadv_pgd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.predictAdvDataModelComparisions": [[744, 799], ["utility.dataLoader.loadDataCifar10", "print", "resnet.getSaveName", "utility.dataLoader.loadDataCifar10AdvFast", "numpy.zeros", "numpy.zeros", "tensorflow.placeholder", "tensorflow.placeholder", "resnet.ResNet", "numpy.save", "range", "numpy.save", "a.reshape.reshape", "b.reshape.reshape", "tensorflow.Session", "sess.run", "resnet.ResNet.loadWeights", "sys.stdout.flush", "range", "range", "range", "resnet.predictAdvDataModelComparisions.distance3"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.loadDataCifar10", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.getSaveName", "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.loadDataCifar10AdvFast", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.ResNet.loadWeights"], ["", "", "def", "predictAdvDataModelComparisions", "(", "args", ")", ":", "\n", "    ", "def", "distance3", "(", "a", ",", "b", ")", ":", "\n", "        ", "a", "=", "a", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "b", "=", "b", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "return", "np", ".", "sum", "(", "a", "!=", "b", ")", "/", "a", ".", "shape", "[", "0", "]", ",", "np", ".", "linalg", ".", "norm", "(", "a", "-", "b", ",", "ord", "=", "2", ")", ",", "np", ".", "linalg", ".", "norm", "(", "a", "-", "b", ",", "ord", "=", "np", ".", "inf", ")", "\n", "\n", "", "Xtest", ",", "Ytest", "=", "loadDataCifar10", "(", ")", "\n", "print", "(", "\"Xtest\"", ",", "Xtest", ".", "shape", "[", "0", "]", ")", "\n", "\n", "saveName", "=", "getSaveName", "(", "args", ")", "\n", "Xadv_fgsm", ",", "Xadv_pgd", "=", "loadDataCifar10AdvFast", "(", "saveName", ")", "\n", "distances", "=", "np", ".", "zeros", "(", "[", "Xtest", ".", "shape", "[", "0", "]", ",", "3", ",", "3", "]", ")", "# number_of_samples * (attack method + original test) * distances", "\n", "correct_predictions", "=", "np", ".", "zeros", "(", "[", "Xtest", ".", "shape", "[", "0", "]", ",", "3", "]", ")", "\n", "\n", "num_classes", "=", "10", "\n", "\n", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "32", ",", "32", ",", "3", ")", ")", "\n", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", "num_classes", ")", ")", "\n", "\n", "model", "=", "ResNet", "(", "x", ",", "y", ",", "args", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "\n", "        ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "model", ".", "loadWeights", "(", "sess", ",", "args", ")", "\n", "\n", "test_num_batches", "=", "Xtest", ".", "shape", "[", "0", "]", "//", "100", "\n", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "test_num_batches", ")", ":", "\n", "            ", "batch_x", "=", "Xtest", "[", "i", "*", "args", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", ",", ":", "]", "\n", "batch_y", "=", "Ytest", "[", "i", "*", "args", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", ",", ":", "]", "\n", "cp", "=", "sess", ".", "run", "(", "model", ".", "correct_prediction", ",", "feed_dict", "=", "{", "x", ":", "batch_x", ",", "y", ":", "batch_y", "}", ")", "\n", "correct_predictions", "[", "i", "*", "args", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", ",", "0", "]", "=", "cp", "\n", "\n", "", "for", "i", "in", "range", "(", "test_num_batches", ")", ":", "\n", "            ", "batch_x", "=", "Xadv_fgsm", "[", "i", "*", "args", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", ",", ":", "]", "\n", "batch_y", "=", "Ytest", "[", "i", "*", "args", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", ",", ":", "]", "\n", "cp", "=", "sess", ".", "run", "(", "model", ".", "correct_prediction", ",", "feed_dict", "=", "{", "x", ":", "batch_x", ",", "y", ":", "batch_y", "}", ")", "\n", "correct_predictions", "[", "i", "*", "args", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", ",", "1", "]", "=", "cp", "\n", "\n", "", "for", "i", "in", "range", "(", "test_num_batches", ")", ":", "\n", "            ", "batch_x", "=", "Xadv_pgd", "[", "i", "*", "args", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", ",", ":", "]", "\n", "batch_y", "=", "Ytest", "[", "i", "*", "args", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", ",", ":", "]", "\n", "cp", "=", "sess", ".", "run", "(", "model", ".", "correct_prediction", ",", "feed_dict", "=", "{", "x", ":", "batch_x", ",", "y", ":", "batch_y", "}", ")", "\n", "correct_predictions", "[", "i", "*", "args", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "args", ".", "batch_size", ",", "2", "]", "=", "cp", "\n", "\n", "", "", "np", ".", "save", "(", "'results/correct_predictions'", "+", "saveName", ",", "correct_predictions", ")", "\n", "\n", "for", "i", "in", "range", "(", "Xtest", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "distances", "[", "i", ",", "1", ",", ":", "]", "=", "distance3", "(", "Xadv_fgsm", "[", "i", "]", ",", "Xtest", "[", "i", "]", ")", "\n", "distances", "[", "i", ",", "2", ",", ":", "]", "=", "distance3", "(", "Xadv_pgd", "[", "i", "]", ",", "Xtest", "[", "i", "]", ")", "\n", "\n", "", "np", ".", "save", "(", "'results/distance'", "+", "saveName", ",", "distances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.main": [[801, 808], ["print", "json.dumps", "resnet.train", "resnet.trainMadry", "vars"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.train", "home.repos.pwc.inspect_result.HaohanWang_HFC.scripts.resnet.trainMadry"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "print", "(", "'input args:\\n'", ",", "json", ".", "dumps", "(", "vars", "(", "args", ")", ",", "indent", "=", "4", ",", "separators", "=", "(", "','", ",", "':'", ")", ")", ")", "\n", "\n", "if", "args", ".", "madry", "==", "0", ":", "\n", "        ", "train", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "trainMadry", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.pgd_attack.LinfPGDAttack.__init__": [[15, 41], ["tensorflow.gradients", "tensorflow.one_hot", "tensorflow.reduce_sum", "tensorflow.reduce_max", "print", "tensorflow.nn.relu"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "model", ",", "epsilon", ",", "k", ",", "a", ",", "random_start", ",", "loss_func", ")", ":", "\n", "    ", "\"\"\"Attack parameter initialization. The attack performs k steps of\n       size a, while always staying within epsilon from the initial\n       point.\"\"\"", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "a", "=", "a", "\n", "self", ".", "rand", "=", "random_start", "\n", "\n", "if", "loss_func", "==", "'loss'", ":", "\n", "      ", "loss", "=", "model", ".", "loss", "\n", "", "elif", "loss_func", "==", "'cw'", ":", "\n", "      ", "label_mask", "=", "tf", ".", "one_hot", "(", "model", ".", "y_input", ",", "\n", "10", ",", "\n", "on_value", "=", "1.0", ",", "\n", "off_value", "=", "0.0", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "correct_logit", "=", "tf", ".", "reduce_sum", "(", "label_mask", "*", "model", ".", "pre_softmax", ",", "axis", "=", "1", ")", "\n", "wrong_logit", "=", "tf", ".", "reduce_max", "(", "(", "1", "-", "label_mask", ")", "*", "model", ".", "pre_softmax", ",", "axis", "=", "1", ")", "\n", "loss", "=", "-", "tf", ".", "nn", ".", "relu", "(", "correct_logit", "-", "wrong_logit", "+", "50", ")", "\n", "", "else", ":", "\n", "      ", "print", "(", "'Unknown loss function. Defaulting to cross-entropy'", ")", "\n", "loss", "=", "model", ".", "xent", "\n", "\n", "", "self", ".", "grad", "=", "tf", ".", "gradients", "(", "loss", ",", "model", ".", "x", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.pgd_attack.LinfPGDAttack.perturb": [[42, 61], ["range", "numpy.clip", "numpy.copy", "sess.run", "numpy.clip", "numpy.clip", "numpy.random.uniform", "numpy.sign"], "methods", ["None"], ["", "def", "perturb", "(", "self", ",", "x_nat", ",", "y", ",", "sess", ")", ":", "\n", "    ", "\"\"\"Given a set of examples (x_nat, y), returns a set of adversarial\n       examples within epsilon of x_nat in l_infinity norm.\"\"\"", "\n", "if", "self", ".", "rand", ":", "\n", "      ", "x", "=", "x_nat", "+", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "epsilon", ",", "self", ".", "epsilon", ",", "x_nat", ".", "shape", ")", "\n", "x", "=", "np", ".", "clip", "(", "x", ",", "0", ",", "1", ")", "# ensure valid pixel range", "\n", "", "else", ":", "\n", "      ", "x", "=", "np", ".", "copy", "(", "x_nat", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "      ", "grad", "=", "sess", ".", "run", "(", "self", ".", "grad", ",", "feed_dict", "=", "{", "self", ".", "model", ".", "x", ":", "x", ",", "\n", "self", ".", "model", ".", "y", ":", "y", "}", ")", "\n", "\n", "x", "+=", "self", ".", "a", "*", "np", ".", "sign", "(", "grad", ")", "\n", "\n", "x", "=", "np", ".", "clip", "(", "x", ",", "x_nat", "-", "self", ".", "epsilon", ",", "x_nat", "+", "self", ".", "epsilon", ")", "\n", "x", "=", "np", ".", "clip", "(", "x", ",", "0", ",", "1", ")", "# ensure valid pixel range", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.oneHotRepresentation": [[5, 12], ["range", "numpy.array", "numpy.zeros", "r.append"], "function", ["None"], ["def", "oneHotRepresentation", "(", "y", ",", "num", "=", "10", ")", ":", "\n", "    ", "r", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "y", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "l", "=", "np", ".", "zeros", "(", "num", ")", "\n", "l", "[", "y", "[", "i", "]", "]", "=", "1", "\n", "r", ".", "append", "(", "l", ")", "\n", "", "return", "np", ".", "array", "(", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.loadDataCifar10": [[14, 19], ["numpy.load().astype", "numpy.load", "dataLoader.oneHotRepresentation", "numpy.load"], "function", ["home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.oneHotRepresentation"], ["", "def", "loadDataCifar10", "(", ")", ":", "\n", "    ", "Xtest", "=", "np", ".", "load", "(", "'../data/CIFAR10/testData100.npy'", ")", "/", "255.0", "\n", "Ytest", "=", "np", ".", "load", "(", "'../data/CIFAR10/testLabel100.npy'", ")", ".", "astype", "(", "int", ")", "\n", "\n", "return", "Xtest", ",", "oneHotRepresentation", "(", "Ytest", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HaohanWang_HFC.utility.dataLoader.loadDataCifar10AdvFast": [[20, 25], ["numpy.load", "numpy.load"], "function", ["None"], ["", "def", "loadDataCifar10AdvFast", "(", "saveName", ")", ":", "\n", "    ", "Xadv_fgsm", "=", "np", ".", "load", "(", "'../CIFAR10/advs/fgsm'", "+", "saveName", "+", "'.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "Xadv_pgd", "=", "np", ".", "load", "(", "'../CIFAR10/advs/pgd'", "+", "saveName", "+", "'.npy'", ",", "allow_pickle", "=", "True", ")", "\n", "\n", "return", "Xadv_fgsm", ",", "Xadv_pgd", "\n", "\n"]]}