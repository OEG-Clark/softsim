{"home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.AverageMeter.__init__": [[560, 564], ["main_lincls.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.reset"], ["def", "__init__", "(", "self", ",", "name", ",", "fmt", "=", "\":f\"", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "fmt", "=", "fmt", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.AverageMeter.reset": [[565, 570], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.AverageMeter.update": [[571, 576], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.AverageMeter.__str__": [[577, 580], ["fmtstr.format"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "fmtstr", "=", "\"{name} {val\"", "+", "self", ".", "fmt", "+", "\"} ({avg\"", "+", "self", ".", "fmt", "+", "\"})\"", "\n", "return", "fmtstr", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.ProgressMeter.__init__": [[583, 587], ["main_lincls.ProgressMeter._get_batch_fmtstr"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.ProgressMeter._get_batch_fmtstr"], ["    ", "def", "__init__", "(", "self", ",", "num_batches", ",", "meters", ",", "prefix", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "batch_fmtstr", "=", "self", ".", "_get_batch_fmtstr", "(", "num_batches", ")", "\n", "self", ".", "meters", "=", "meters", "\n", "self", ".", "prefix", "=", "prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.ProgressMeter.display": [[588, 592], ["print", "str", "main_lincls.ProgressMeter.batch_fmtstr.format"], "methods", ["None"], ["", "def", "display", "(", "self", ",", "batch", ")", ":", "\n", "        ", "entries", "=", "[", "self", ".", "prefix", "+", "self", ".", "batch_fmtstr", ".", "format", "(", "batch", ")", "]", "\n", "entries", "+=", "[", "str", "(", "meter", ")", "for", "meter", "in", "self", ".", "meters", "]", "\n", "print", "(", "\"\\t\"", ".", "join", "(", "entries", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.ProgressMeter._get_batch_fmtstr": [[593, 597], ["len", "str", "str", "fmt.format"], "methods", ["None"], ["", "def", "_get_batch_fmtstr", "(", "self", ",", "num_batches", ")", ":", "\n", "        ", "num_digits", "=", "len", "(", "str", "(", "num_batches", "//", "1", ")", ")", "\n", "fmt", "=", "\"{:\"", "+", "str", "(", "num_digits", ")", "+", "\"d}\"", "\n", "return", "\"[\"", "+", "fmt", "+", "\"/\"", "+", "fmt", ".", "format", "(", "num_batches", ")", "+", "\"]\"", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.main": [[155, 192], ["parser.parse_args", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "warnings.warn", "warnings.warn", "int", "torch.spawn", "main_lincls.main_worker"], "function", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.main_worker"], ["def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "        ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "cudnn", ".", "deterministic", "=", "True", "\n", "warnings", ".", "warn", "(", "\n", "\"You have chosen to seed training. \"", "\n", "\"This will turn on the CUDNN deterministic setting, \"", "\n", "\"which can slow down your training considerably! \"", "\n", "\"You may see unexpected behavior when restarting \"", "\n", "\"from checkpoints.\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"You have chosen a specific GPU. This will completely \"", "\n", "\"disable data parallelism.\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "dist_url", "==", "\"env://\"", "and", "args", ".", "world_size", "==", "-", "1", ":", "\n", "        ", "args", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "\n", "\n", "", "args", ".", "distributed", "=", "args", ".", "world_size", ">", "1", "or", "args", ".", "multiprocessing_distributed", "\n", "\n", "ngpus_per_node", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "if", "args", ".", "multiprocessing_distributed", ":", "\n", "# Since we have ngpus_per_node processes per node, the total world_size", "\n", "# needs to be adjusted accordingly", "\n", "        ", "args", ".", "world_size", "=", "ngpus_per_node", "*", "args", ".", "world_size", "\n", "# Use torch.multiprocessing.spawn to launch distributed processes: the", "\n", "# main_worker process function", "\n", "mp", ".", "spawn", "(", "main_worker", ",", "nprocs", "=", "ngpus_per_node", ",", "args", "=", "(", "ngpus_per_node", ",", "args", ")", ")", "\n", "", "else", ":", "\n", "# Simply call main_worker function", "\n", "        ", "main_worker", "(", "args", ".", "gpu", ",", "ngpus_per_node", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.main_worker": [[194, 424], ["print", "torch.nn.DataParallel().cuda.named_parameters", "torch.nn.DataParallel().cuda.fc.weight.data.normal_", "torch.nn.DataParallel().cuda.fc.bias.data.zero_", "torch.CrossEntropyLoss().cuda", "list", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "os.path.join", "os.path.join", "torchvision.Normalize", "torchvision.ImageFolder", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "print", "torch.init_process_group", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "os.path.isfile", "filter", "len", "print", "LARC", "os.path.isfile", "torchvision.Compose", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torchvision.ImageFolder", "main_lincls.validate", "main_lincls.adjust_learning_rate", "main_lincls.train", "main_lincls.validate", "max", "int", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "list", "torch.nn.DataParallel().cuda.load_state_dict", "print", "print", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.nn.DataParallel().cuda.cuda", "int", "int", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.DataParallel().cuda.cuda", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.nn.DataParallel().cuda.cuda", "torch.CrossEntropyLoss", "torch.nn.DataParallel().cuda.parameters", "print", "torch.nn.DataParallel().cuda.load_state_dict", "LARC.load_state_dict", "print", "print", "torchvision.Compose", "torch.utils.data.distributed.DistributedSampler.set_epoch", "main_lincls.save_checkpoint", "state_dict.keys", "set", "args.arch.startswith", "args.arch.startswith", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel().cuda.cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "best_acc1.to.to", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "main_lincls.sanity_check", "k.startswith", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.ToTensor", "torch.nn.DataParallel().cuda.state_dict", "LARC.state_dict", "torch.nn.DataParallel().cuda.state_dict", "k.startswith", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "len"], "function", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.validate", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.adjust_learning_rate", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.train", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.validate", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.save_checkpoint", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.sanity_check"], ["", "", "def", "main_worker", "(", "gpu", ",", "ngpus_per_node", ",", "args", ")", ":", "\n", "    ", "global", "best_acc1", "\n", "args", ".", "gpu", "=", "gpu", "\n", "\n", "# suppress printing if not master", "\n", "if", "args", ".", "multiprocessing_distributed", "and", "args", ".", "gpu", "!=", "0", ":", "\n", "\n", "        ", "def", "print_pass", "(", "*", "args", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "builtins", ".", "print", "=", "print_pass", "\n", "\n", "", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"Use GPU: {} for training\"", ".", "format", "(", "args", ".", "gpu", ")", ")", "\n", "\n", "", "if", "args", ".", "distributed", ":", "\n", "        ", "if", "args", ".", "dist_url", "==", "\"env://\"", "and", "args", ".", "rank", "==", "-", "1", ":", "\n", "            ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "\"RANK\"", "]", ")", "\n", "", "if", "args", ".", "multiprocessing_distributed", ":", "\n", "# For multiprocessing distributed training, rank needs to be the", "\n", "# global rank among all the processes", "\n", "            ", "args", ".", "rank", "=", "args", ".", "rank", "*", "ngpus_per_node", "+", "gpu", "\n", "", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "args", ".", "dist_backend", ",", "\n", "init_method", "=", "args", ".", "dist_url", ",", "\n", "world_size", "=", "args", ".", "world_size", ",", "\n", "rank", "=", "args", ".", "rank", ",", "\n", ")", "\n", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "# create model", "\n", "", "print", "(", "\"=> creating model '{}'\"", ".", "format", "(", "args", ".", "arch", ")", ")", "\n", "model", "=", "models", ".", "__dict__", "[", "args", ".", "arch", "]", "(", ")", "\n", "\n", "# freeze all layers but the last fc", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "name", "not", "in", "[", "\"fc.weight\"", ",", "\"fc.bias\"", "]", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "# init the fc layer", "\n", "", "", "model", ".", "fc", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.01", ")", "\n", "model", ".", "fc", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "# load from pre-trained, before DistributedDataParallel constructor", "\n", "if", "args", ".", "pretrained", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "args", ".", "pretrained", ")", ":", "\n", "            ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "args", ".", "pretrained", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "pretrained", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "# rename moco pre-trained keys", "\n", "state_dict", "=", "checkpoint", "[", "\"state_dict\"", "]", "\n", "for", "k", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "# retain only encoder_q up to before the embedding layer", "\n", "                ", "if", "k", ".", "startswith", "(", "\"module.encoder_q\"", ")", "and", "not", "k", ".", "startswith", "(", "\n", "\"module.encoder_q.fc\"", "\n", ")", ":", "\n", "# remove prefix", "\n", "                    ", "state_dict", "[", "k", "[", "len", "(", "\"module.encoder_q.\"", ")", ":", "]", "]", "=", "state_dict", "[", "k", "]", "\n", "# delete renamed or unused k", "\n", "", "del", "state_dict", "[", "k", "]", "\n", "\n", "", "args", ".", "start_epoch", "=", "0", "\n", "msg", "=", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "assert", "set", "(", "msg", ".", "missing_keys", ")", "==", "{", "\"fc.weight\"", ",", "\"fc.bias\"", "}", "\n", "\n", "print", "(", "\"=> loaded pre-trained model '{}'\"", ".", "format", "(", "args", ".", "pretrained", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "args", ".", "pretrained", ")", ")", "\n", "\n", "# infer learning rate before changing batch size", "\n", "", "", "init_lr", "=", "args", ".", "lr", "*", "args", ".", "batch_size", "/", "256", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "# For multiprocessing distributed, DistributedDataParallel constructor", "\n", "# should always set the single device scope, otherwise,", "\n", "# DistributedDataParallel will use all available devices.", "\n", "        ", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "model", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "# When using a single GPU per process and per", "\n", "# DistributedDataParallel, we need to divide the batch size", "\n", "# ourselves based on the total number of GPUs we have", "\n", "args", ".", "batch_size", "=", "int", "(", "args", ".", "batch_size", "/", "ngpus_per_node", ")", "\n", "args", ".", "workers", "=", "int", "(", "(", "args", ".", "workers", "+", "ngpus_per_node", "-", "1", ")", "/", "ngpus_per_node", ")", "\n", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "gpu", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model", ".", "cuda", "(", ")", "\n", "# DistributedDataParallel will divide and allocate batch_size to all", "\n", "# available GPUs if device_ids are not set", "\n", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ")", "\n", "", "", "elif", "args", ".", "gpu", "is", "not", "None", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "model", "=", "model", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "", "else", ":", "\n", "# DataParallel will divide and allocate batch_size to all available GPUs", "\n", "        ", "if", "args", ".", "arch", ".", "startswith", "(", "\"alexnet\"", ")", "or", "args", ".", "arch", ".", "startswith", "(", "\"vgg\"", ")", ":", "\n", "            ", "model", ".", "features", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ".", "features", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", ".", "cuda", "(", ")", "\n", "\n", "# define loss function (criterion) and optimizer", "\n", "", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "\n", "# optimize only the linear classifier", "\n", "parameters", "=", "list", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ")", "\n", "assert", "len", "(", "parameters", ")", "==", "2", "# fc.weight, fc.bias", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "parameters", ",", "init_lr", ",", "momentum", "=", "args", ".", "momentum", ",", "weight_decay", "=", "args", ".", "weight_decay", "\n", ")", "\n", "if", "args", ".", "lars", ":", "\n", "        ", "print", "(", "\"=> use LARS optimizer.\"", ")", "\n", "from", "apex", ".", "parallel", ".", "LARC", "import", "LARC", "\n", "\n", "optimizer", "=", "LARC", "(", "optimizer", "=", "optimizer", ",", "trust_coefficient", "=", "0.001", ",", "clip", "=", "False", ")", "\n", "\n", "# optionally resume from a checkpoint", "\n", "", "if", "args", ".", "resume", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "args", ".", "resume", ")", ":", "\n", "            ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "if", "args", ".", "gpu", "is", "None", ":", "\n", "                ", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume", ")", "\n", "", "else", ":", "\n", "# Map model to be loaded to specified single gpu.", "\n", "                ", "loc", "=", "\"cuda:{}\"", ".", "format", "(", "args", ".", "gpu", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume", ",", "map_location", "=", "loc", ")", "\n", "", "args", ".", "start_epoch", "=", "checkpoint", "[", "\"epoch\"", "]", "\n", "best_acc1", "=", "checkpoint", "[", "\"best_acc1\"", "]", "\n", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "# best_acc1 may be from a checkpoint from a different GPU", "\n", "                ", "best_acc1", "=", "best_acc1", ".", "to", "(", "args", ".", "gpu", ")", "\n", "", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"state_dict\"", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer\"", "]", ")", "\n", "print", "(", "\n", "\"=> loaded checkpoint '{}' (epoch {})\"", ".", "format", "(", "\n", "args", ".", "resume", ",", "checkpoint", "[", "\"epoch\"", "]", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "\n", "", "", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Data loading code", "\n", "traindir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "\"train\"", ")", "\n", "valdir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "\"val\"", ")", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", ")", "\n", "\n", "train_dataset", "=", "datasets", ".", "ImageFolder", "(", "\n", "traindir", ",", "\n", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "224", ",", "scale", "=", "(", "0.08", ",", "1.0", ")", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", "\n", ")", ",", "\n", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "train_sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "train_dataset", ")", "\n", "", "else", ":", "\n", "        ", "train_sampler", "=", "None", "\n", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "(", "train_sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "datasets", ".", "ImageFolder", "(", "\n", "valdir", ",", "\n", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Resize", "(", "256", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "224", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", "\n", ")", ",", "\n", ")", ",", "\n", "batch_size", "=", "256", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", ")", "\n", "\n", "if", "args", ".", "evaluate", ":", "\n", "        ", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "args", ")", "\n", "return", "\n", "\n", "", "for", "epoch", "in", "range", "(", "args", ".", "start_epoch", ",", "args", ".", "epochs", ")", ":", "\n", "        ", "if", "args", ".", "distributed", ":", "\n", "            ", "train_sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "adjust_learning_rate", "(", "optimizer", ",", "init_lr", ",", "epoch", ",", "args", ")", "\n", "\n", "# train for one epoch", "\n", "train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "args", ")", "\n", "\n", "# evaluate on validation set", "\n", "acc1", "=", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "args", ")", "\n", "\n", "# remember best acc@1 and save checkpoint", "\n", "is_best", "=", "acc1", ">", "best_acc1", "\n", "best_acc1", "=", "max", "(", "acc1", ",", "best_acc1", ")", "\n", "\n", "if", "not", "args", ".", "multiprocessing_distributed", "or", "(", "\n", "args", ".", "multiprocessing_distributed", "and", "args", ".", "rank", "%", "ngpus_per_node", "==", "0", "\n", ")", ":", "\n", "            ", "save_checkpoint", "(", "\n", "{", "\n", "\"epoch\"", ":", "epoch", "+", "1", ",", "\n", "\"arch\"", ":", "args", ".", "arch", ",", "\n", "\"state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"best_acc1\"", ":", "best_acc1", ",", "\n", "\"optimizer\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "\n", "is_best", ",", "\n", ")", "\n", "if", "epoch", "==", "args", ".", "start_epoch", ":", "\n", "                ", "sanity_check", "(", "model", ".", "state_dict", "(", ")", ",", "args", ".", "pretrained", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.train": [[426, 477], ["main_lincls.AverageMeter", "main_lincls.AverageMeter", "main_lincls.AverageMeter", "main_lincls.AverageMeter", "main_lincls.AverageMeter", "main_lincls.ProgressMeter", "model.eval", "time.time", "enumerate", "len", "main_lincls.AverageMeter.update", "target.cuda.cuda", "model", "criterion", "main_lincls.accuracy", "main_lincls.AverageMeter.update", "main_lincls.AverageMeter.update", "main_lincls.AverageMeter.update", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "main_lincls.AverageMeter.update", "time.time", "images.cuda.cuda", "criterion.item", "images.cuda.size", "images.cuda.size", "images.cuda.size", "main_lincls.ProgressMeter.display", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.accuracy", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.ProgressMeter.display"], ["", "", "", "", "def", "train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "args", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", "\"Time\"", ",", "\":6.3f\"", ")", "\n", "data_time", "=", "AverageMeter", "(", "\"Data\"", ",", "\":6.3f\"", ")", "\n", "losses", "=", "AverageMeter", "(", "\"Loss\"", ",", "\":.4e\"", ")", "\n", "top1", "=", "AverageMeter", "(", "\"Acc@1\"", ",", "\":6.2f\"", ")", "\n", "top5", "=", "AverageMeter", "(", "\"Acc@5\"", ",", "\":6.2f\"", ")", "\n", "progress", "=", "ProgressMeter", "(", "\n", "len", "(", "train_loader", ")", ",", "\n", "[", "batch_time", ",", "data_time", ",", "losses", ",", "top1", ",", "top5", "]", ",", "\n", "prefix", "=", "\"Epoch: [{}]\"", ".", "format", "(", "epoch", ")", ",", "\n", ")", "\n", "\n", "\"\"\"\n    Switch to eval mode:\n    Under the protocol of linear classification on frozen features/models,\n    it is not legitimate to change any part of the pre-trained model.\n    BatchNorm in train mode may revise running mean/std (even if it receives\n    no gradient), which are part of the model parameters too.\n    \"\"\"", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "images", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "# measure data loading time", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "\n", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "            ", "images", "=", "images", ".", "cuda", "(", "args", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "", "target", "=", "target", ".", "cuda", "(", "args", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "\n", "# compute output", "\n", "output", "=", "model", "(", "images", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "acc1", ",", "acc5", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "acc1", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "acc5", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "\n", "# compute gradient and do SGD step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", ":", "\n", "            ", "progress", ".", "display", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.validate": [[479, 521], ["main_lincls.AverageMeter", "main_lincls.AverageMeter", "main_lincls.AverageMeter", "main_lincls.AverageMeter", "main_lincls.ProgressMeter", "model.eval", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "time.time", "enumerate", "print", "target.cuda.cuda", "model", "criterion", "main_lincls.accuracy", "main_lincls.AverageMeter.update", "main_lincls.AverageMeter.update", "main_lincls.AverageMeter.update", "main_lincls.AverageMeter.update", "time.time", "images.cuda.cuda", "criterion.item", "images.cuda.size", "images.cuda.size", "images.cuda.size", "main_lincls.ProgressMeter.display", "time.time"], "function", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.accuracy", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.ProgressMeter.display"], ["", "", "", "def", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "args", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", "\"Time\"", ",", "\":6.3f\"", ")", "\n", "losses", "=", "AverageMeter", "(", "\"Loss\"", ",", "\":.4e\"", ")", "\n", "top1", "=", "AverageMeter", "(", "\"Acc@1\"", ",", "\":6.2f\"", ")", "\n", "top5", "=", "AverageMeter", "(", "\"Acc@5\"", ",", "\":6.2f\"", ")", "\n", "progress", "=", "ProgressMeter", "(", "\n", "len", "(", "val_loader", ")", ",", "[", "batch_time", ",", "losses", ",", "top1", ",", "top5", "]", ",", "prefix", "=", "\"Test: \"", "\n", ")", "\n", "\n", "# switch to evaluate mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "images", ",", "target", ")", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "            ", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "                ", "images", "=", "images", ".", "cuda", "(", "args", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "", "target", "=", "target", ".", "cuda", "(", "args", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "\n", "# compute output", "\n", "output", "=", "model", "(", "images", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "acc1", ",", "acc5", "=", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "acc1", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "acc5", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", ":", "\n", "                ", "progress", ".", "display", "(", "i", ")", "\n", "\n", "# TODO: this should also be done with the ProgressMeter", "\n", "", "", "print", "(", "\n", "\" * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}\"", ".", "format", "(", "top1", "=", "top1", ",", "top5", "=", "top5", ")", "\n", ")", "\n", "\n", "", "return", "top1", ".", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.save_checkpoint": [[523, 527], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "shutil.copyfile"], "function", ["None"], ["", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "filename", "=", "\"checkpoint.pth.tar\"", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "filename", ",", "\"model_best.pth.tar\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.sanity_check": [[529, 555], ["print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "list", "print", "state_dict.keys", "k.startswith", "state_dict[].cpu", "len"], "function", ["None"], ["", "", "def", "sanity_check", "(", "state_dict", ",", "pretrained_weights", ")", ":", "\n", "    ", "\"\"\"\n    Linear classifier should not change any weights other than the linear layer.\n    This sanity check asserts nothing wrong happens (e.g., BN stats updated).\n    \"\"\"", "\n", "print", "(", "\"=> loading '{}' for sanity check\"", ".", "format", "(", "pretrained_weights", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "pretrained_weights", ",", "map_location", "=", "\"cpu\"", ")", "\n", "state_dict_pre", "=", "checkpoint", "[", "\"state_dict\"", "]", "\n", "\n", "for", "k", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "# only ignore fc layer", "\n", "        ", "if", "\"fc.weight\"", "in", "k", "or", "\"fc.bias\"", "in", "k", ":", "\n", "            ", "continue", "\n", "\n", "# name in pretrained model", "\n", "", "k_pre", "=", "(", "\n", "\"module.encoder_q.\"", "+", "k", "[", "len", "(", "\"module.\"", ")", ":", "]", "\n", "if", "k", ".", "startswith", "(", "\"module.\"", ")", "\n", "else", "\"module.encoder_q.\"", "+", "k", "\n", ")", "\n", "\n", "assert", "(", "\n", "state_dict", "[", "k", "]", ".", "cpu", "(", ")", "==", "state_dict_pre", "[", "k_pre", "]", "\n", ")", ".", "all", "(", ")", ",", "\"{} is changed in linear classifier training.\"", ".", "format", "(", "k", ")", "\n", "\n", "", "print", "(", "\"=> sanity check passed.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.adjust_learning_rate": [[599, 604], ["math.cos"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "optimizer", ",", "init_lr", ",", "epoch", ",", "args", ")", ":", "\n", "    ", "\"\"\"Decay the learning rate based on schedule\"\"\"", "\n", "cur_lr", "=", "init_lr", "*", "0.5", "*", "(", "1.0", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "epoch", "/", "args", ".", "epochs", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "\"lr\"", "]", "=", "cur_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_lincls.accuracy": [[606, 621], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].reshape().float().sum", "res.append", "correct[].reshape().float().sum.mul_", "target.view", "correct[].reshape().float", "correct[].reshape"], "function", ["None"], ["", "", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "reshape", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.__init__": [[580, 584], ["main_moco.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.reset"], ["def", "__init__", "(", "self", ",", "name", ",", "fmt", "=", "\":f\"", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "fmt", "=", "fmt", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.reset": [[585, 590], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update": [[591, 596], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.__str__": [[597, 600], ["fmtstr.format"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "fmtstr", "=", "\"{name} {val\"", "+", "self", ".", "fmt", "+", "\"} ({avg\"", "+", "self", ".", "fmt", "+", "\"})\"", "\n", "return", "fmtstr", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.ProgressMeter.__init__": [[603, 607], ["main_moco.ProgressMeter._get_batch_fmtstr"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.ProgressMeter._get_batch_fmtstr"], ["    ", "def", "__init__", "(", "self", ",", "num_batches", ",", "meters", ",", "prefix", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "batch_fmtstr", "=", "self", ".", "_get_batch_fmtstr", "(", "num_batches", ")", "\n", "self", ".", "meters", "=", "meters", "\n", "self", ".", "prefix", "=", "prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.ProgressMeter.display": [[608, 612], ["print", "str", "main_moco.ProgressMeter.batch_fmtstr.format"], "methods", ["None"], ["", "def", "display", "(", "self", ",", "batch", ")", ":", "\n", "        ", "entries", "=", "[", "self", ".", "prefix", "+", "self", ".", "batch_fmtstr", ".", "format", "(", "batch", ")", "]", "\n", "entries", "+=", "[", "str", "(", "meter", ")", "for", "meter", "in", "self", ".", "meters", "]", "\n", "print", "(", "\"\\t\"", ".", "join", "(", "entries", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.ProgressMeter._get_batch_fmtstr": [[613, 617], ["len", "str", "str", "fmt.format"], "methods", ["None"], ["", "def", "_get_batch_fmtstr", "(", "self", ",", "num_batches", ")", ":", "\n", "        ", "num_digits", "=", "len", "(", "str", "(", "num_batches", "//", "1", ")", ")", "\n", "fmt", "=", "\"{:\"", "+", "str", "(", "num_digits", ")", "+", "\"d}\"", "\n", "return", "\"[\"", "+", "fmt", "+", "\"/\"", "+", "fmt", ".", "format", "(", "num_batches", ")", "+", "\"]\"", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.main": [[223, 262], ["parser.parse_args", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "warnings.warn", "warnings.warn", "int", "torch.spawn", "main_moco.main_worker"], "function", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.main_worker"], ["def", "main", "(", ")", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "seed", "is", "not", "None", ":", "\n", "        ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "cudnn", ".", "deterministic", "=", "True", "\n", "warnings", ".", "warn", "(", "\n", "\"You have chosen to seed training. \"", "\n", "\"This will turn on the CUDNN deterministic setting, \"", "\n", "\"which can slow down your training considerably! \"", "\n", "\"You may see unexpected behavior when restarting \"", "\n", "\"from checkpoints.\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"You have chosen a specific GPU. This will completely \"", "\n", "\"disable data parallelism.\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "dist_url", "==", "\"env://\"", "and", "args", ".", "world_size", "==", "-", "1", ":", "\n", "        ", "args", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "\n", "\n", "", "args", ".", "distributed", "=", "args", ".", "world_size", ">", "1", "or", "args", ".", "multiprocessing_distributed", "\n", "\n", "ngpus_per_node", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "if", "args", ".", "multiprocessing_distributed", ":", "\n", "# Since we have ngpus_per_node processes per node, the total world_size", "\n", "# needs to be adjusted accordingly", "\n", "        ", "args", ".", "world_size", "=", "ngpus_per_node", "*", "args", ".", "world_size", "\n", "# Use torch.multiprocessing.spawn to launch distributed processes: the", "\n", "# main_worker process function", "\n", "mp", ".", "spawn", "(", "\n", "main_worker", ",", "nprocs", "=", "ngpus_per_node", ",", "args", "=", "(", "ngpus_per_node", ",", "args", ")", "\n", ")", "\n", "", "else", ":", "\n", "# Simply call main_worker function", "\n", "        ", "main_worker", "(", "args", ".", "gpu", ",", "ngpus_per_node", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.main_worker": [[264, 503], ["print", "moco.builder.MoCo", "moco.builder.MoCo", "print", "torch.CrossEntropyLoss().cuda", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "os.path.join", "torchvision.Normalize", "torchvision.ImageFolder", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "print", "torch.init_process_group", "model.cuda.parameters", "os.path.isfile", "torchvision.RandomResizedCrop", "torchvision.RandomApply", "torchvision.RandomGrayscale", "torchvision.RandomApply", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "torchvision.RandomResizedCrop", "torchvision.RandomApply", "torchvision.RandomGrayscale", "torchvision.RandomApply", "torchvision.RandomHorizontalFlip", "timm.data.auto_augment.rand_augment_transform", "torchvision.ToTensor", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "torchvision.RandomResizedCrop", "torchvision.RandomApply", "torchvision.RandomGrayscale", "torchvision.RandomApply", "torchvision.RandomHorizontalFlip", "torchvision.ToTensor", "moco.loader.CropsTransform", "moco.loader.CropsTransform", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "main_moco.adjust_learning_rate", "main_moco.train", "int", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "model.cuda.cuda", "int", "int", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "model.cuda.cuda", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "model.cuda.cuda", "NotImplementedError", "NotImplementedError", "torch.CrossEntropyLoss", "print", "model.cuda.load_state_dict", "torch.optim.SGD.load_state_dict", "print", "print", "torch.utils.data.distributed.DistributedSampler.set_epoch", "main_moco.save_checkpoint", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torchvision.ColorJitter", "moco.loader.GaussianBlur", "moco.loader.GaussianBlur", "torchvision.ColorJitter", "moco.loader.GaussianBlur", "moco.loader.GaussianBlur", "torchvision.ColorJitter", "moco.loader.GaussianBlur", "moco.loader.GaussianBlur", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "torchvision.Compose", "model.cuda.state_dict", "torch.optim.SGD.state_dict"], "function", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.adjust_learning_rate", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.train", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.save_checkpoint"], ["", "", "def", "main_worker", "(", "gpu", ",", "ngpus_per_node", ",", "args", ")", ":", "\n", "    ", "args", ".", "gpu", "=", "gpu", "\n", "\n", "# suppress printing if not master", "\n", "if", "args", ".", "multiprocessing_distributed", "and", "args", ".", "gpu", "!=", "0", ":", "\n", "\n", "        ", "def", "print_pass", "(", "*", "args", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "builtins", ".", "print", "=", "print_pass", "\n", "\n", "", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"Use GPU: {} for training\"", ".", "format", "(", "args", ".", "gpu", ")", ")", "\n", "\n", "", "if", "args", ".", "distributed", ":", "\n", "        ", "if", "args", ".", "dist_url", "==", "\"env://\"", "and", "args", ".", "rank", "==", "-", "1", ":", "\n", "            ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "\"RANK\"", "]", ")", "\n", "", "if", "args", ".", "multiprocessing_distributed", ":", "\n", "# For multiprocessing distributed training, rank needs to be the", "\n", "# global rank among all the processes", "\n", "            ", "args", ".", "rank", "=", "args", ".", "rank", "*", "ngpus_per_node", "+", "gpu", "\n", "", "dist", ".", "init_process_group", "(", "\n", "backend", "=", "args", ".", "dist_backend", ",", "\n", "init_method", "=", "args", ".", "dist_url", ",", "\n", "world_size", "=", "args", ".", "world_size", ",", "\n", "rank", "=", "args", ".", "rank", ",", "\n", ")", "\n", "# create model", "\n", "", "print", "(", "\"=> creating model '{}'\"", ".", "format", "(", "args", ".", "arch", ")", ")", "\n", "model", "=", "moco", ".", "builder", ".", "MoCo", "(", "\n", "models", ".", "__dict__", "[", "args", ".", "arch", "]", ",", "\n", "args", ".", "moco_dim", ",", "\n", "args", ".", "moco_k", ",", "\n", "args", ".", "moco_m", ",", "\n", "args", ".", "moco_t", ",", "\n", "args", ".", "enable_asym_bn", ",", "\n", ")", "\n", "print", "(", "model", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "# For multiprocessing distributed, DistributedDataParallel constructor", "\n", "# should always set the single device scope, otherwise,", "\n", "# DistributedDataParallel will use all available devices.", "\n", "        ", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "            ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "model", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "# When using a single GPU per process and per", "\n", "# DistributedDataParallel, we need to divide the batch size", "\n", "# ourselves based on the total number of GPUs we have", "\n", "args", ".", "batch_size", "=", "int", "(", "args", ".", "batch_size", "/", "ngpus_per_node", ")", "\n", "args", ".", "workers", "=", "int", "(", "\n", "(", "args", ".", "workers", "+", "ngpus_per_node", "-", "1", ")", "/", "ngpus_per_node", "\n", ")", "\n", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "gpu", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model", ".", "cuda", "(", ")", "\n", "# DistributedDataParallel will divide and allocate batch_size to", "\n", "# all available GPUs if device_ids are not set", "\n", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ")", "\n", "", "", "elif", "args", ".", "gpu", "is", "not", "None", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "model", "=", "model", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "# comment out the following line for debugging", "\n", "raise", "NotImplementedError", "(", "\"Only DistributedDataParallel is supported.\"", ")", "\n", "", "else", ":", "\n", "# AllGather implementation (batch shuffle, queue update, etc.) in", "\n", "# this code only supports DistributedDataParallel.", "\n", "        ", "raise", "NotImplementedError", "(", "\"Only DistributedDataParallel is supported.\"", ")", "\n", "\n", "# define loss function (criterion) and optimizer", "\n", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "model", ".", "parameters", "(", ")", ",", "\n", "args", ".", "lr", ",", "\n", "momentum", "=", "args", ".", "momentum", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ",", "\n", ")", "\n", "\n", "# optionally resume from a checkpoint", "\n", "if", "args", ".", "resume", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "args", ".", "resume", ")", ":", "\n", "            ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "if", "args", ".", "gpu", "is", "None", ":", "\n", "                ", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume", ")", "\n", "", "else", ":", "\n", "# Map model to be loaded to specified single gpu.", "\n", "                ", "loc", "=", "\"cuda:{}\"", ".", "format", "(", "args", ".", "gpu", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume", ",", "map_location", "=", "loc", ")", "\n", "", "args", ".", "start_epoch", "=", "checkpoint", "[", "\"epoch\"", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"state_dict\"", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer\"", "]", ")", "\n", "print", "(", "\n", "\"=> loaded checkpoint '{}' (epoch {})\"", ".", "format", "(", "\n", "args", ".", "resume", ",", "checkpoint", "[", "\"epoch\"", "]", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", "\n", "\n", "", "", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Data loading code", "\n", "traindir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data", ",", "\"train\"", ")", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", ")", "\n", "# MoCo v2's aug: similar to SimCLR https://arxiv.org/abs/2002.05709", "\n", "if", "args", ".", "enable_multicrop", ":", "\n", "        ", "ratio_range", "=", "(", "0.14", ",", "1.0", ")", "\n", "", "else", ":", "\n", "        ", "ratio_range", "=", "(", "0.2", ",", "1.0", ")", "\n", "\n", "", "augmentation", "=", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "224", ",", "scale", "=", "ratio_range", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "0.4", ",", "0.4", ",", "0.4", ",", "0.1", ")", "]", ",", "# not strengthened", "\n", "p", "=", "0.8", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "moco", ".", "loader", ".", "GaussianBlur", "(", "[", "0.1", ",", "2.0", "]", ")", "]", ",", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", "\n", "\n", "\"\"\"\n# --------------------------------------------------------------------------- #\n#                           Asymmetric Augmentations                          #\n# --------------------------------------------------------------------------- #\nasymmetric augmentation recipes are formed by stronger and weaker augmentation\nin source and target. Stronger augmentation introduces a higher variance, that\nhurts target but helps source, and vice versa for weaker augmentation.\n# --------------------------------------------------------------------------- #\n    \"\"\"", "\n", "\n", "augmentation_stronger", "=", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "224", ",", "scale", "=", "ratio_range", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "0.4", ",", "0.4", ",", "0.4", ",", "0.1", ")", "]", ",", "# not strengthened", "\n", "p", "=", "0.8", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "moco", ".", "loader", ".", "GaussianBlur", "(", "[", "0.1", ",", "2.0", "]", ")", "]", ",", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "rand_augment_transform", "(", "\n", "\"rand-m10-n2-mstd0.5\"", ",", "{", "\"translate_const\"", ":", "100", "}", ",", "\n", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", "\n", "augmentation_weaker", "=", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "224", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", "\n", "\n", "\"\"\"\n# --------------------------------------------------------------------------- #\n#                                  MultiCrop                                  #\n# --------------------------------------------------------------------------- #\nBesides the two basic views needed for Siamese learning, MultiCrop takes\nadditional views from each image per iteration. To alleviate the added\ncomputation cost, a common strategy is to have low-resolution crops\n(e.g., 96\u00d796) instead of standard-resolution crops (224\u00d7224) as added views.\nAs a side effect, inputting small crops can potentially increase the variance\nfor an encoder due to the size and crop-distribution changes.\n# --------------------------------------------------------------------------- #\n    \"\"\"", "\n", "\n", "augmentation_mini", "=", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "96", ",", "scale", "=", "(", "0.05", ",", "0.14", ")", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "\n", "[", "transforms", ".", "ColorJitter", "(", "0.4", ",", "0.4", ",", "0.4", ",", "0.1", ")", "]", ",", "# not strengthened", "\n", "p", "=", "0.8", ",", "\n", ")", ",", "\n", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ",", "\n", "transforms", ".", "RandomApply", "(", "[", "moco", ".", "loader", ".", "GaussianBlur", "(", "[", "0.1", ",", "2.0", "]", ")", "]", ",", "p", "=", "0.5", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", "\n", "\n", "train_dataset", "=", "datasets", ".", "ImageFolder", "(", "\n", "traindir", ",", "\n", "moco", ".", "loader", ".", "CropsTransform", "(", "\n", "key_transform", "=", "transforms", ".", "Compose", "(", "augmentation_weaker", ")", "\n", "if", "args", ".", "enable_asymm_aug", "\n", "else", "transforms", ".", "Compose", "(", "augmentation", ")", ",", "\n", "query_mini_transform", "=", "transforms", ".", "Compose", "(", "augmentation_mini", ")", ",", "\n", "query_transform", "=", "transforms", ".", "Compose", "(", "augmentation_stronger", ")", "\n", "if", "args", ".", "enable_asymm_aug", "\n", "else", "transforms", ".", "Compose", "(", "augmentation", ")", ",", "\n", "enable_scalemix", "=", "args", ".", "enable_scalemix", ",", "\n", "enable_multicrop", "=", "args", ".", "enable_multicrop", ",", "\n", "enable_mean_encoding", "=", "args", ".", "enable_mean_encoding", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "if", "args", ".", "distributed", ":", "\n", "        ", "train_sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "\n", "train_dataset", "\n", ")", "\n", "", "else", ":", "\n", "        ", "train_sampler", "=", "None", "\n", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "(", "train_sampler", "is", "None", ")", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "args", ".", "start_epoch", ",", "args", ".", "epochs", ")", ":", "\n", "        ", "if", "args", ".", "distributed", ":", "\n", "            ", "train_sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ",", "args", ")", "\n", "\n", "# train for one epoch", "\n", "train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "args", ")", "\n", "\n", "if", "not", "args", ".", "multiprocessing_distributed", "or", "(", "\n", "args", ".", "multiprocessing_distributed", "and", "args", ".", "rank", "%", "ngpus_per_node", "==", "0", "\n", ")", ":", "\n", "            ", "save_checkpoint", "(", "\n", "{", "\n", "\"epoch\"", ":", "epoch", "+", "1", ",", "\n", "\"arch\"", ":", "args", ".", "arch", ",", "\n", "\"state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "\n", "is_best", "=", "False", ",", "\n", "filename", "=", "\"checkpoint_{}_{:04d}.pth.tar\"", ".", "format", "(", "args", ".", "tag", ",", "epoch", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.train": [[506, 569], ["main_moco.AverageMeter", "main_moco.AverageMeter", "main_moco.AverageMeter", "main_moco.AverageMeter", "main_moco.AverageMeter", "main_moco.ProgressMeter", "model.train", "time.time", "enumerate", "len", "main_moco.AverageMeter.update", "model", "criterion", "main_moco.accuracy", "main_moco.AverageMeter.update", "main_moco.AverageMeter.update", "main_moco.AverageMeter.update", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "main_moco.AverageMeter.update", "time.time", "range", "criterion.item", "images[].size", "images[].size", "images[].size", "main_moco.ProgressMeter.display", "time.time", "len", "images[].cuda", "sum", "len", "time.time", "map", "zip", "criterion"], "function", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.train", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.accuracy", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.AverageMeter.update", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.ProgressMeter.display"], ["", "", "", "def", "train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "args", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", "\"Time\"", ",", "\":6.3f\"", ")", "\n", "data_time", "=", "AverageMeter", "(", "\"Data\"", ",", "\":6.3f\"", ")", "\n", "losses", "=", "AverageMeter", "(", "\"Loss\"", ",", "\":.4e\"", ")", "\n", "top1", "=", "AverageMeter", "(", "\"Acc@1\"", ",", "\":6.2f\"", ")", "\n", "top5", "=", "AverageMeter", "(", "\"Acc@5\"", ",", "\":6.2f\"", ")", "\n", "progress", "=", "ProgressMeter", "(", "\n", "len", "(", "train_loader", ")", ",", "\n", "[", "batch_time", ",", "data_time", ",", "losses", ",", "top1", ",", "top5", "]", ",", "\n", "prefix", "=", "\"Epoch: [{}]\"", ".", "format", "(", "epoch", ")", ",", "\n", ")", "\n", "\n", "# switch to train mode", "\n", "model", ".", "train", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "images", ",", "_", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "# measure data loading time", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "\n", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "            ", "for", "j", "in", "range", "(", "len", "(", "images", ")", ")", ":", "\n", "                ", "images", "[", "j", "]", "=", "images", "[", "j", "]", ".", "cuda", "(", "args", ".", "gpu", ",", "non_blocking", "=", "True", ")", "\n", "\n", "", "", "if", "args", ".", "enable_mean_encoding", ":", "\n", "            ", "q_mini_ind", ",", "k_ind", "=", "1", ",", "-", "2", "\n", "", "else", ":", "\n", "            ", "q_mini_ind", ",", "k_ind", "=", "1", ",", "-", "1", "\n", "# compute outputs", "\n", "", "outputs", ",", "targets", "=", "model", "(", "\n", "im_q", "=", "images", "[", ":", "q_mini_ind", "]", ",", "\n", "im_q_mini", "=", "images", "[", "q_mini_ind", ":", "k_ind", "]", ",", "\n", "im_k", "=", "images", "[", "k_ind", ":", "]", ",", "\n", ")", "\n", "loss", "=", "criterion", "(", "outputs", "[", "0", "]", ",", "targets", "[", "0", "]", ")", "\n", "\n", "# Loss for mini multi-crops", "\n", "if", "args", ".", "enable_multicrop", ":", "\n", "            ", "loss", "+=", "sum", "(", "\n", "map", "(", "\n", "lambda", "crop", ":", "criterion", "(", "crop", "[", "0", "]", ",", "crop", "[", "1", "]", ")", ",", "\n", "zip", "(", "outputs", "[", "q_mini_ind", ":", "]", ",", "targets", "[", "q_mini_ind", ":", "]", ")", ",", "\n", ")", "\n", ")", "/", "len", "(", "outputs", "[", "q_mini_ind", ":", "]", ")", "\n", "\n", "# acc1/acc5 are (K+1)-way contrast classifier accuracy", "\n", "# measure accuracy and record loss", "\n", "", "acc1", ",", "acc5", "=", "accuracy", "(", "outputs", "[", "0", "]", ",", "targets", "[", "0", "]", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "images", "[", "0", "]", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "acc1", "[", "0", "]", ",", "images", "[", "0", "]", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "acc5", "[", "0", "]", ",", "images", "[", "0", "]", ".", "size", "(", "0", ")", ")", "\n", "\n", "# compute gradient and do SGD step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", ":", "\n", "            ", "progress", ".", "display", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.save_checkpoint": [[571, 575], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "shutil.copyfile"], "function", ["None"], ["", "", "", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "filename", "=", "\"checkpoint.pth.tar\"", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "filename", ",", "\"model_best.pth.tar\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.adjust_learning_rate": [[619, 626], ["math.cos"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ",", "args", ")", ":", "\n", "    ", "\"\"\"Decay the learning rate based on schedule\"\"\"", "\n", "lr", "=", "args", ".", "lr", "\n", "lr", "*=", "0.5", "*", "(", "1.0", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "epoch", "/", "args", ".", "epochs", ")", ")", "\n", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "\"lr\"", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.None.main_moco.accuracy": [[628, 648], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].reshape().float().sum", "res.append", "correct[].reshape().float().sum.mul_", "target.view", "correct[].reshape().float", "correct[].reshape"], "function", ["None"], ["", "", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"\n    Computes the accuracy over the k top predictions for the specified values\n    of k\n    \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "(", "\n", "correct", "[", ":", "k", "]", ".", "reshape", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.MoCo.__init__": [[12, 83], ["torch.Module.__init__", "base_encoder", "base_encoder", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "zip", "builder.MoCo.register_buffer", "torch.functional.normalize", "torch.functional.normalize", "builder.MoCo.register_buffer", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "builder.create_syncbn_process_group", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "builder.MoCo.encoder_q.parameters", "builder.MoCo.encoder_k.parameters", "param_k.data.copy_", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.loader.GaussianBlur.__init__", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.create_syncbn_process_group"], ["def", "__init__", "(", "\n", "self", ",", "\n", "base_encoder", ",", "\n", "dim", "=", "128", ",", "\n", "K", "=", "65536", ",", "\n", "m", "=", "0.999", ",", "\n", "T", "=", "0.07", ",", "\n", "enable_asym_bn", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        dim: feature dimension (default: 128)\n        K: queue size; number of negative keys (default: 65536)\n        m: moco momentum of updating key encoder (default: 0.999)\n        T: softmax temperature (default: 0.07)\n        \"\"\"", "\n", "super", "(", "MoCo", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "K", "=", "K", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "T", "=", "T", "\n", "\n", "# create the encoders", "\n", "# num_classes is the output fc dimension", "\n", "self", ".", "encoder_q", "=", "base_encoder", "(", "num_classes", "=", "dim", ")", "\n", "self", ".", "encoder_k", "=", "base_encoder", "(", "num_classes", "=", "dim", ")", "\n", "\n", "dim_mlp", "=", "self", ".", "encoder_q", ".", "fc", ".", "weight", ".", "shape", "[", "1", "]", "\n", "self", ".", "encoder_q", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "dim_mlp", ",", "dim_mlp", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "dim_mlp", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "dim_mlp", ",", "dim_mlp", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "self", ".", "encoder_q", ".", "fc", ",", "\n", ")", "\n", "self", ".", "encoder_k", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "dim_mlp", ",", "dim_mlp", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "dim_mlp", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "dim_mlp", ",", "dim_mlp", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "self", ".", "encoder_k", ".", "fc", ",", "\n", ")", "\n", "\n", "\"\"\"\n# --------------------------------------------------------------------------- #\n#                               Sync BatchNorm                                #\n# --------------------------------------------------------------------------- #\nIntermediate Sync BatchNorm layers is a way to reduce intra-image variance\nintarget encoder. Sync BatchNorm leads to a notable improvement when applied to\ntarget (as referred \u2018AsymBN\u2019 in our paper) and degeneration to source.\n# --------------------------------------------------------------------------- #\n        \"\"\"", "\n", "\n", "if", "enable_asym_bn", ":", "\n", "            ", "process_group", "=", "create_syncbn_process_group", "(", "8", ")", "\n", "self", ".", "encoder_k", ".", "fc", "=", "torch", ".", "nn", ".", "SyncBatchNorm", ".", "convert_sync_batchnorm", "(", "\n", "self", ".", "encoder_k", ".", "fc", ",", "process_group", "\n", ")", "\n", "\n", "", "for", "param_q", ",", "param_k", "in", "zip", "(", "\n", "self", ".", "encoder_q", ".", "parameters", "(", ")", ",", "self", ".", "encoder_k", ".", "parameters", "(", ")", "\n", ")", ":", "\n", "            ", "param_k", ".", "data", ".", "copy_", "(", "param_q", ".", "data", ")", "# initialize", "\n", "param_k", ".", "requires_grad", "=", "False", "# not update by gradient", "\n", "\n", "# create the queue", "\n", "", "self", ".", "register_buffer", "(", "\"queue\"", ",", "torch", ".", "randn", "(", "dim", ",", "K", ")", ")", "\n", "self", ".", "queue", "=", "nn", ".", "functional", ".", "normalize", "(", "self", ".", "queue", ",", "dim", "=", "0", ")", "\n", "\n", "self", ".", "register_buffer", "(", "\"queue_ptr\"", ",", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.MoCo._momentum_update_key_encoder": [[84, 93], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "zip", "builder.MoCo.encoder_q.parameters", "builder.MoCo.encoder_k.parameters"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_momentum_update_key_encoder", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Momentum update of the key encoder\n        \"\"\"", "\n", "for", "param_q", ",", "param_k", "in", "zip", "(", "\n", "self", ".", "encoder_q", ".", "parameters", "(", ")", ",", "self", ".", "encoder_k", ".", "parameters", "(", ")", "\n", ")", ":", "\n", "            ", "param_k", ".", "data", "=", "param_k", ".", "data", "*", "self", ".", "m", "+", "param_q", ".", "data", "*", "(", "1.0", "-", "self", ".", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.MoCo._dequeue_and_enqueue": [[94, 109], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "builder.concat_all_gather", "int"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.concat_all_gather"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_dequeue_and_enqueue", "(", "self", ",", "keys", ")", ":", "\n", "# gather keys before updating queue", "\n", "        ", "keys", "=", "concat_all_gather", "(", "keys", ")", "\n", "\n", "batch_size", "=", "keys", ".", "shape", "[", "0", "]", "\n", "\n", "ptr", "=", "int", "(", "self", ".", "queue_ptr", ")", "\n", "assert", "self", ".", "K", "%", "batch_size", "==", "0", "# for simplicity", "\n", "\n", "# replace the keys at ptr (dequeue and enqueue)", "\n", "self", ".", "queue", "[", ":", ",", "ptr", ":", "ptr", "+", "batch_size", "]", "=", "keys", ".", "T", "\n", "ptr", "=", "(", "ptr", "+", "batch_size", ")", "%", "self", ".", "K", "# move pointer", "\n", "\n", "self", ".", "queue_ptr", "[", "0", "]", "=", "ptr", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.MoCo._batch_shuffle_ddp": [[110, 137], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "builder.concat_all_gather", "torch.randperm().cuda", "torch.randperm().cuda", "torch.randperm().cuda", "torch.randperm().cuda", "torch.distributed.broadcast", "torch.distributed.broadcast", "torch.distributed.broadcast", "torch.distributed.broadcast", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.randperm().cuda.view", "torch.randperm().cuda.view", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.concat_all_gather"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_batch_shuffle_ddp", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Batch shuffle, for making use of BatchNorm.\n        *** Only support DistributedDataParallel (DDP) model. ***\n        \"\"\"", "\n", "# gather from all gpus", "\n", "batch_size_this", "=", "x", ".", "shape", "[", "0", "]", "\n", "x_gather", "=", "concat_all_gather", "(", "x", ")", "\n", "batch_size_all", "=", "x_gather", ".", "shape", "[", "0", "]", "\n", "\n", "num_gpus", "=", "batch_size_all", "//", "batch_size_this", "\n", "\n", "# random shuffle index", "\n", "idx_shuffle", "=", "torch", ".", "randperm", "(", "batch_size_all", ")", ".", "cuda", "(", ")", "\n", "\n", "# broadcast to all gpus", "\n", "torch", ".", "distributed", ".", "broadcast", "(", "idx_shuffle", ",", "src", "=", "0", ")", "\n", "\n", "# index for restoring", "\n", "idx_unshuffle", "=", "torch", ".", "argsort", "(", "idx_shuffle", ")", "\n", "\n", "# shuffled index for this gpu", "\n", "gpu_idx", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "idx_this", "=", "idx_shuffle", ".", "view", "(", "num_gpus", ",", "-", "1", ")", "[", "gpu_idx", "]", "\n", "\n", "return", "x_gather", "[", "idx_this", "]", ",", "idx_unshuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.MoCo._batch_unshuffle_ddp": [[138, 156], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "builder.concat_all_gather", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "torch.distributed.get_rank", "idx_unshuffle.view"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.concat_all_gather"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_batch_unshuffle_ddp", "(", "self", ",", "x", ",", "idx_unshuffle", ")", ":", "\n", "        ", "\"\"\"\n        Undo batch shuffle.\n        *** Only support DistributedDataParallel (DDP) model. ***\n        \"\"\"", "\n", "# gather from all gpus", "\n", "batch_size_this", "=", "x", ".", "shape", "[", "0", "]", "\n", "x_gather", "=", "concat_all_gather", "(", "x", ")", "\n", "batch_size_all", "=", "x_gather", ".", "shape", "[", "0", "]", "\n", "\n", "num_gpus", "=", "batch_size_all", "//", "batch_size_this", "\n", "\n", "# restored index for this gpu", "\n", "gpu_idx", "=", "torch", ".", "distributed", ".", "get_rank", "(", ")", "\n", "idx_this", "=", "idx_unshuffle", ".", "view", "(", "num_gpus", ",", "-", "1", ")", "[", "gpu_idx", "]", "\n", "\n", "return", "x_gather", "[", "idx_this", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.MoCo.forward": [[157, 233], ["len", "builder.MoCo._dequeue_and_enqueue", "builder.MoCo.encoder_q", "torch.functional.normalize", "torch.functional.normalize", "q_large.append", "builder.MoCo.encoder_q", "torch.functional.normalize", "torch.functional.normalize", "q_mini.append", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "builder.MoCo._momentum_update_key_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "builder.MoCo._batch_shuffle_ddp", "builder.MoCo.encoder_k", "builder.MoCo._batch_unshuffle_ddp", "torch.functional.normalize.view", "torch.functional.normalize", "torch.functional.normalize", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum().unsqueeze", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "logits_list.append", "labels_list.append", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "builder.MoCo.queue.clone().detach", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "builder.MoCo.queue.clone"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.MoCo._dequeue_and_enqueue", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.MoCo._momentum_update_key_encoder", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.MoCo._batch_shuffle_ddp", "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.MoCo._batch_unshuffle_ddp"], ["", "def", "forward", "(", "self", ",", "im_q", ",", "im_q_mini", ",", "im_k", ")", ":", "\n", "        ", "\"\"\"\n        Input:\n            im_q: a batch of query images\n            im_k: a batch of key images\n        Output:\n            logits, targets\n        \"\"\"", "\n", "\n", "# compute query features", "\n", "q_large", "=", "[", "]", "\n", "for", "im", "in", "im_q", ":", "\n", "            ", "_q", "=", "self", ".", "encoder_q", "(", "im", ")", "# queries: NxC", "\n", "_q", "=", "nn", ".", "functional", ".", "normalize", "(", "_q", ",", "dim", "=", "1", ")", "\n", "q_large", ".", "append", "(", "_q", ")", "\n", "\n", "", "q_mini", "=", "[", "]", "\n", "for", "im", "in", "im_q_mini", ":", "\n", "            ", "_q_mini", "=", "self", ".", "encoder_q", "(", "im", ")", "# queries: NxC", "\n", "_q_mini", "=", "nn", ".", "functional", ".", "normalize", "(", "_q_mini", ",", "dim", "=", "1", ")", "\n", "q_mini", ".", "append", "(", "_q_mini", ")", "\n", "\n", "", "\"\"\"\n# --------------------------------------------------------------------------- #\n#                                 Mean Encoding                               #\n# --------------------------------------------------------------------------- #\nMean Encoding is a direct approach to reduce the variance of a random variable\nby performing i.i.d. sampling multiple times and take the mean as the new\nvariable. Mean Encoding is simply generated by running the same encoder on\nmultiple augmented views of the same image.\n# --------------------------------------------------------------------------- #\n        \"\"\"", "\n", "\n", "crop_num", "=", "len", "(", "im_k", ")", "\n", "# compute key features", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "# no gradient to keys", "\n", "            ", "self", ".", "_momentum_update_key_encoder", "(", ")", "# update the key encoder", "\n", "\n", "im_k", "=", "torch", ".", "cat", "(", "im_k", ",", "dim", "=", "0", ")", "\n", "# shuffle for making use of BN", "\n", "im_k", ",", "idx_unshuffle", "=", "self", ".", "_batch_shuffle_ddp", "(", "im_k", ")", "\n", "\n", "k", "=", "self", ".", "encoder_k", "(", "im_k", ")", "# keys: NxC", "\n", "\n", "# undo shuffle", "\n", "k", "=", "self", ".", "_batch_unshuffle_ddp", "(", "k", ",", "idx_unshuffle", ")", "\n", "cur_size", ",", "embedding_length", "=", "k", ".", "shape", "\n", "k", "=", "k", ".", "view", "(", "crop_num", ",", "cur_size", "//", "crop_num", ",", "embedding_length", ")", "\n", "k", "=", "nn", ".", "functional", ".", "normalize", "(", "torch", ".", "mean", "(", "k", ",", "dim", "=", "0", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "logits_list", "=", "[", "]", "\n", "labels_list", "=", "[", "]", "\n", "for", "q", "in", "q_large", "+", "q_mini", ":", "\n", "# compute logits", "\n", "# Einstein sum is more intuitive", "\n", "# positive logits: Nx1", "\n", "            ", "l_pos", "=", "torch", ".", "einsum", "(", "\"nc,nc->n\"", ",", "[", "q", ",", "k", "]", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# negative logits: NxK", "\n", "l_neg", "=", "torch", ".", "einsum", "(", "\"nc,ck->nk\"", ",", "[", "q", ",", "self", ".", "queue", ".", "clone", "(", ")", ".", "detach", "(", ")", "]", ")", "\n", "\n", "# logits: Nx(1+K)", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "l_pos", ",", "l_neg", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# apply temperature", "\n", "logits", "/=", "self", ".", "T", "\n", "\n", "# labels: positive key indicators", "\n", "labels", "=", "torch", ".", "zeros", "(", "logits", ".", "shape", "[", "0", "]", ",", "dtype", "=", "torch", ".", "long", ")", ".", "cuda", "(", ")", "\n", "\n", "logits_list", ".", "append", "(", "logits", ")", "\n", "labels_list", ".", "append", "(", "labels", ")", "\n", "\n", "# dequeue and enqueue", "\n", "", "self", ".", "_dequeue_and_enqueue", "(", "k", ")", "\n", "\n", "return", "logits_list", ",", "labels_list", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.concat_all_gather": [[236, 250], ["torch.no_grad", "torch.no_grad", "torch.distributed.all_gather", "torch.distributed.all_gather", "torch.cat", "torch.cat", "torch.ones_like", "torch.ones_like", "range", "torch.distributed.get_world_size", "torch.distributed.get_world_size"], "function", ["None"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "concat_all_gather", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"\n    Performs all_gather operation on the provided tensors.\n    *** Warning ***: torch.distributed.all_gather has no gradient.\n    \"\"\"", "\n", "tensors_gather", "=", "[", "\n", "torch", ".", "ones_like", "(", "tensor", ")", "\n", "for", "_", "in", "range", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", ")", "\n", "]", "\n", "torch", ".", "distributed", ".", "all_gather", "(", "tensors_gather", ",", "tensor", ",", "async_op", "=", "False", ")", "\n", "\n", "output", "=", "torch", ".", "cat", "(", "tensors_gather", ",", "dim", "=", "0", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.builder.create_syncbn_process_group": [[252, 271], ["torch.distributed.get_world_size", "torch.distributed.get_world_size", "range", "range", "torch.distributed.new_group", "torch.distributed.new_group", "torch.distributed.get_rank", "torch.distributed.get_rank"], "function", ["None"], ["", "def", "create_syncbn_process_group", "(", "num_gpu_per_group", ")", ":", "\n", "    ", "if", "num_gpu_per_group", "==", "0", ":", "\n", "        ", "return", "None", "\n", "\n", "", "world_size", "=", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "\n", "assert", "world_size", ">=", "num_gpu_per_group", "\n", "assert", "world_size", "%", "num_gpu_per_group", "==", "0", "\n", "\n", "group", "=", "None", "\n", "for", "group_num", "in", "range", "(", "world_size", "//", "num_gpu_per_group", ")", ":", "\n", "        ", "group_ids", "=", "range", "(", "\n", "group_num", "*", "num_gpu_per_group", ",", "(", "group_num", "+", "1", ")", "*", "num_gpu_per_group", "\n", ")", "\n", "cur_group", "=", "torch", ".", "distributed", ".", "new_group", "(", "ranks", "=", "group_ids", ")", "\n", "if", "torch", ".", "distributed", ".", "get_rank", "(", ")", "//", "num_gpu_per_group", "==", "group_num", ":", "\n", "            ", "group", "=", "cur_group", "\n", "\n", "", "", "assert", "group", "is", "not", "None", "\n", "return", "group", "\n", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.loader.CropsTransform.__init__": [[46, 61], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "key_transform", ",", "\n", "query_mini_transform", ",", "\n", "query_transform", ",", "\n", "enable_scalemix", "=", "False", ",", "\n", "enable_multicrop", "=", "False", ",", "\n", "enable_mean_encoding", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "key_transform", "=", "key_transform", "\n", "self", ".", "query_mini_transform", "=", "query_mini_transform", "\n", "self", ".", "query_transform", "=", "query_transform", "\n", "self", ".", "enable_scalemix", "=", "enable_scalemix", "\n", "self", ".", "enable_multicrop", "=", "enable_multicrop", "\n", "self", ".", "enable_mean_encoding", "=", "enable_mean_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.loader.CropsTransform.__call__": [[62, 79], ["crops.append", "crops.append", "loader.scalemix", "loader.CropsTransform.query_transform", "range", "loader.CropsTransform.key_transform", "crops.append", "loader.CropsTransform.query_transform", "loader.CropsTransform.query_transform", "crops.append", "loader.CropsTransform.key_transform", "loader.CropsTransform.query_mini_transform"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.loader.scalemix"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "crops", "=", "[", "]", "\n", "# Query crop", "\n", "if", "self", ".", "enable_scalemix", ":", "\n", "            ", "q", "=", "scalemix", "(", "self", ".", "query_transform", "(", "x", ")", ",", "self", ".", "query_transform", "(", "x", ")", ",", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "query_transform", "(", "x", ")", "\n", "", "crops", ".", "append", "(", "q", ")", "\n", "# Query mini crops", "\n", "if", "self", ".", "enable_multicrop", ":", "\n", "            ", "for", "i", "in", "range", "(", "6", ")", ":", "\n", "                ", "crops", ".", "append", "(", "self", ".", "query_mini_transform", "(", "x", ")", ")", "\n", "# Key crop", "\n", "", "", "crops", ".", "append", "(", "self", ".", "key_transform", "(", "x", ")", ")", "\n", "if", "self", ".", "enable_mean_encoding", ":", "\n", "            ", "crops", ".", "append", "(", "self", ".", "key_transform", "(", "x", ")", ")", "\n", "", "return", "crops", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.loader.GaussianBlur.__init__": [[84, 86], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sigma", "=", "[", "0.1", ",", "2.0", "]", ")", ":", "\n", "        ", "self", ".", "sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.loader.GaussianBlur.__call__": [[87, 91], ["random.uniform", "x.filter.filter.filter", "PIL.ImageFilter.GaussianBlur"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "sigma", "=", "random", ".", "uniform", "(", "self", ".", "sigma", "[", "0", "]", ",", "self", ".", "sigma", "[", "1", "]", ")", "\n", "x", "=", "x", ".", "filter", "(", "ImageFilter", ".", "GaussianBlur", "(", "radius", "=", "sigma", ")", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_asym-siam.moco.loader.scalemix": [[21, 41], ["numpy.random.uniform", "loader.scalemix.random_bbox"], "function", ["None"], ["def", "scalemix", "(", "view1", ",", "view2", ")", ":", "\n", "    ", "def", "random_bbox", "(", "lam", ",", "H", ",", "W", ")", ":", "\n", "        ", "cut_rat", "=", "np", ".", "sqrt", "(", "1.0", "-", "lam", ")", "\n", "cut_w", "=", "np", ".", "int", "(", "W", "*", "cut_rat", ")", "\n", "cut_h", "=", "np", ".", "int", "(", "H", "*", "cut_rat", ")", "\n", "\n", "cx", "=", "np", ".", "random", ".", "randint", "(", "W", ")", "\n", "cy", "=", "np", ".", "random", ".", "randint", "(", "H", ")", "\n", "\n", "bbx1", "=", "np", ".", "clip", "(", "cx", "-", "cut_w", "//", "2", ",", "0", ",", "W", ")", "\n", "bby1", "=", "np", ".", "clip", "(", "cy", "-", "cut_h", "//", "2", ",", "0", ",", "H", ")", "\n", "bbx2", "=", "np", ".", "clip", "(", "cx", "+", "cut_w", "//", "2", ",", "0", ",", "W", ")", "\n", "bby2", "=", "np", ".", "clip", "(", "cy", "+", "cut_h", "//", "2", ",", "0", ",", "H", ")", "\n", "return", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", "\n", "\n", "", "_", ",", "h", ",", "w", "=", "view1", ".", "shape", "\n", "lam", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.0", ",", "high", "=", "1.0", ")", "\n", "bbx1", ",", "bby1", ",", "bbx2", ",", "bby2", "=", "random_bbox", "(", "lam", ",", "h", ",", "w", ")", "\n", "view1", "[", ":", ",", "bbx1", ":", "bbx2", ",", "bby1", ":", "bby2", "]", "=", "view2", "[", ":", ",", "bbx1", ":", "bbx2", ",", "bby1", ":", "bby2", "]", "\n", "return", "view1", "\n", "\n"]]}