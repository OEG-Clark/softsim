{"home.repos.pwc.inspect_result.feobi1999_tdd.None.train_net.setup": [[33, 42], ["detectron2.config.get_cfg", "ubteacher.add_ubteacher_config", "detectron2.config.get_cfg.merge_from_file", "detectron2.config.get_cfg.merge_from_list", "detectron2.config.get_cfg.freeze", "detectron2.engine.default_setup"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.ubteacher.config.add_ubteacher_config", "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.freeze"], ["def", "setup", "(", "args", ")", ":", "\n", "    ", "\"\"\"Create configs and perform basic setups.\"\"\"", "\n", "cfg", "=", "get_cfg", "(", ")", "\n", "add_ubteacher_config", "(", "cfg", ")", "\n", "cfg", ".", "merge_from_file", "(", "args", ".", "config_file", ")", "\n", "cfg", ".", "merge_from_list", "(", "args", ".", "opts", ")", "\n", "cfg", ".", "freeze", "(", ")", "\n", "default_setup", "(", "cfg", ",", "args", ")", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.None.train_net.main": [[44, 114], ["train_net.setup", "Trainer", "Trainer.resume_or_load", "Trainer.train", "ValueError", "Trainer.build_model", "Trainer.build_model", "ubteacher.modeling.meta_arch.ts_ensemble.EnsembleTSModel", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "Trainer.test", "Trainer.model.module.roi_heads.state_dict", "Trainer.model.module.roi_heads_2.load_state_dict", "Trainer.model.module.register_buffer", "Trainer.model.roi_heads.state_dict", "Trainer.model.roi_heads_2.load_state_dict", "Trainer.model.register_buffer", "Trainer.build_model", "Trainer.build_model", "ubteacher.modeling.meta_arch.ts_ensemble.EnsembleTSModel", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "Trainer.test_two_head", "Trainer.build_model", "detectron2.checkpoint.DetectionCheckpointer().resume_or_load", "Trainer.test", "Trainer.model.state_dict", "torch.zeros().cuda", "torch.zeros().cuda", "Trainer.model.state_dict", "torch.zeros().cuda", "torch.zeros().cuda", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.checkpoint.DetectionCheckpointer", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.None.train_net.setup", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.resume_or_load", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.train", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.resume_or_load", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.test", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.resume_or_load", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.test_two_head", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.resume_or_load", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.test"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "cfg", "=", "setup", "(", "args", ")", "\n", "if", "cfg", ".", "SEMISUPNET", ".", "Trainer", "==", "\"joint_pretrain\"", ":", "\n", "        ", "Trainer", "=", "UBTeacherTrainer", "\n", "\n", "\n", "#use", "\n", "", "elif", "cfg", ".", "SEMISUPNET", ".", "Trainer", "==", "\"TDD\"", ":", "\n", "        ", "Trainer", "=", "Two_head_fft_UBTeacherTrainer_V2_object_relation", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Trainer Name is not found.\"", ")", "\n", "\n", "\n", "", "if", "args", ".", "eval_only", ":", "\n", "\n", "        ", "if", "cfg", ".", "SEMISUPNET", ".", "Trainer", "==", "\"joint_pretrain\"", ":", "\n", "            ", "model", "=", "Trainer", ".", "build_model", "(", "cfg", ")", "\n", "model_teacher", "=", "Trainer", ".", "build_model", "(", "cfg", ")", "\n", "ensem_ts_model", "=", "EnsembleTSModel", "(", "model_teacher", ",", "model", ")", "\n", "\n", "\n", "DetectionCheckpointer", "(", "\n", "ensem_ts_model", ",", "save_dir", "=", "cfg", ".", "OUTPUT_DIR", "\n", ")", ".", "resume_or_load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "args", ".", "resume", ")", "\n", "\n", "res", "=", "Trainer", ".", "test", "(", "cfg", ",", "ensem_ts_model", ".", "modelStudent", ")", "\n", "\n", "\n", "", "elif", "\"TDD\"", "in", "cfg", ".", "SEMISUPNET", ".", "Trainer", ":", "\n", "            ", "model", "=", "Trainer", ".", "build_model", "(", "cfg", ")", "\n", "model_teacher", "=", "Trainer", ".", "build_model", "(", "cfg", ")", "\n", "ensem_ts_model", "=", "EnsembleTSModel", "(", "model_teacher", ",", "model", ")", "\n", "\n", "DetectionCheckpointer", "(", "\n", "ensem_ts_model", ",", "save_dir", "=", "cfg", ".", "OUTPUT_DIR", "\n", ")", ".", "resume_or_load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "args", ".", "resume", ")", "\n", "\n", "res1", "=", "Trainer", ".", "test_two_head", "(", "cfg", ",", "ensem_ts_model", ".", "modelTeacher", ",", "head", "=", "1", ")", "\n", "\n", "# res3 = Trainer.test_two_head(cfg, ensem_ts_model.modelTeacher,head=2)", "\n", "\n", "return", "res1", "\n", "\n", "\n", "", "else", ":", "\n", "            ", "model", "=", "Trainer", ".", "build_model", "(", "cfg", ")", "\n", "\n", "DetectionCheckpointer", "(", "model", ",", "save_dir", "=", "cfg", ".", "OUTPUT_DIR", ")", ".", "resume_or_load", "(", "\n", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "args", ".", "resume", "\n", ")", "\n", "res", "=", "Trainer", ".", "test", "(", "cfg", ",", "model", ")", "\n", "", "return", "res", "\n", "\n", "", "trainer", "=", "Trainer", "(", "cfg", ")", "\n", "trainer", ".", "resume_or_load", "(", "resume", "=", "args", ".", "resume", ")", "\n", "\n", "# init need_copy =1  ckpt contain need_copy then cover the 1 to 0", "\n", "if", "args", ".", "num_gpus", ">", "1", ":", "\n", "\n", "        ", "if", "\"TDD\"", "in", "cfg", ".", "SEMISUPNET", ".", "Trainer", "and", "trainer", ".", "model", ".", "state_dict", "(", ")", "[", "\"module.need_copy\"", "]", ":", "\n", "            ", "roi_head_dict", "=", "trainer", ".", "model", ".", "module", ".", "roi_heads", ".", "state_dict", "(", ")", "\n", "trainer", ".", "model", ".", "module", ".", "roi_heads_2", ".", "load_state_dict", "(", "roi_head_dict", ")", "\n", "trainer", ".", "model", ".", "module", ".", "register_buffer", "(", "\"need_copy\"", ",", "torch", ".", "zeros", "(", "1", ")", ".", "cuda", "(", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "\"TDD\"", "in", "cfg", ".", "SEMISUPNET", ".", "Trainer", "and", "trainer", ".", "model", ".", "state_dict", "(", ")", "[", "\"need_copy\"", "]", ":", "\n", "            ", "roi_head_dict", "=", "trainer", ".", "model", ".", "roi_heads", ".", "state_dict", "(", ")", "\n", "trainer", ".", "model", ".", "roi_heads_2", ".", "load_state_dict", "(", "roi_head_dict", ")", "\n", "trainer", ".", "model", ".", "register_buffer", "(", "\"need_copy\"", ",", "torch", ".", "zeros", "(", "1", ")", ".", "cuda", "(", ")", ")", "\n", "", "", "return", "trainer", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.ubteacher.config.add_ubteacher_config": [[5, 74], ["detectron2.config.CfgNode", "detectron2.config.CfgNode"], "function", ["None"], ["def", "add_ubteacher_config", "(", "cfg", ")", ":", "\n", "    ", "\"\"\"\n    Add config for semisupnet.\n    \"\"\"", "\n", "_C", "=", "cfg", "\n", "_C", ".", "TEST", ".", "VAL_LOSS", "=", "False", "\n", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "UNSUP_LOSS_WEIGHT", "=", "1.0", "\n", "_C", ".", "MODEL", ".", "RPN", ".", "LOSS", "=", "\"CrossEntropy\"", "\n", "_C", ".", "MODEL", ".", "ROI_HEADS", ".", "LOSS", "=", "\"CrossEntropy\"", "\n", "\n", "_C", ".", "SOLVER", ".", "IMG_PER_BATCH_LABEL", "=", "1", "\n", "_C", ".", "SOLVER", ".", "IMG_PER_BATCH_UNLABEL", "=", "1", "\n", "_C", ".", "SOLVER", ".", "FACTOR_LIST", "=", "(", "1", ",", ")", "\n", "_C", ".", "SOLVER", ".", "IMS_PER_BATCH", "=", "8", "\n", "_C", ".", "SOLVER", ".", "SUB_LR", "=", "None", "\n", "_C", ".", "DATASETS", ".", "TRAIN_LABEL", "=", "(", "\"coco_2017_train\"", ",", ")", "\n", "_C", ".", "DATASETS", ".", "TRAIN_UNLABEL", "=", "(", "\"coco_2017_train\"", ",", ")", "\n", "_C", ".", "DATASETS", ".", "CROSS_DATASET", "=", "False", "\n", "_C", ".", "TEST", ".", "EVALUATOR", "=", "\"COCOeval\"", "\n", "\n", "_C", ".", "SEMISUPNET", "=", "CN", "(", ")", "\n", "\n", "# Output dimension of the MLP projector after `res5` block", "\n", "_C", ".", "SEMISUPNET", ".", "MLP_DIM", "=", "128", "\n", "\n", "# Semi-supervised training", "\n", "_C", ".", "SEMISUPNET", ".", "Trainer", "=", "\"joint_pretrain\"", "\n", "_C", ".", "SEMISUPNET", ".", "BBOX_THRESHOLD", "=", "0.7", "\n", "_C", ".", "SEMISUPNET", ".", "PSEUDO_BBOX_SAMPLE", "=", "\"thresholding\"", "\n", "_C", ".", "SEMISUPNET", ".", "TEACHER_UPDATE_ITER", "=", "1", "\n", "_C", ".", "SEMISUPNET", ".", "BURN_UP_STEP", "=", "12000", "\n", "_C", ".", "SEMISUPNET", ".", "EMA_KEEP_RATE", "=", "0.0", "\n", "_C", ".", "SEMISUPNET", ".", "UNSUP_LOSS_WEIGHT", "=", "4.0", "\n", "_C", ".", "SEMISUPNET", ".", "SUP_LOSS_WEIGHT", "=", "0.5", "\n", "_C", ".", "SEMISUPNET", ".", "LOSS_WEIGHT_TYPE", "=", "\"standard\"", "\n", "_C", ".", "SEMISUPNET", ".", "TWO_STAGE_THRESHHOLD", "=", "False", "\n", "_C", ".", "SEMISUPNET", ".", "BBOX_THRESHOLD_1", "=", "0.9", "\n", "_C", ".", "SEMISUPNET", ".", "BBOX_THRESHOLD_2", "=", "0.7", "\n", "_C", ".", "SEMISUPNET", ".", "STEP", "=", "10000", "\n", "_C", ".", "SEMISUPNET", ".", "Teacher_Refine", "=", "False", "\n", "# dataloader", "\n", "# supervision level", "\n", "_C", ".", "DATALOADER", ".", "SUP_PERCENT", "=", "100.0", "# 5 = 5% dataset as labeled set", "\n", "_C", ".", "DATALOADER", ".", "RANDOM_DATA_SEED", "=", "0", "# random seed to read data", "\n", "_C", ".", "DATALOADER", ".", "RANDOM_DATA_SEED_PATH", "=", "\"dataseed/COCO_supervision.txt\"", "\n", "\n", "_C", ".", "EMAMODEL", "=", "CN", "(", ")", "\n", "_C", ".", "EMAMODEL", ".", "SUP_CONSIST", "=", "True", "\n", "_C", ".", "DA_CASE", "=", "None", "\n", "_C", ".", "DA_FPN_FEATURE", "=", "[", "\"p2\"", ",", "\"p3\"", ",", "\"p4\"", ",", "\"p5\"", "]", "\n", "_C", ".", "CONSIST_MODE", "=", "\"\"", "\n", "_C", ".", "ADDITIONAL_BRANCH", "=", "0", "\n", "_C", ".", "CONSIST_ON", "=", "False", "\n", "_C", ".", "CONTRAST_ON", "=", "False", "\n", "_C", ".", "FFT_ON", "=", "False", "\n", "_C", ".", "FFT_ON_1", "=", "False", "\n", "_C", ".", "FFT_ON_2", "=", "False", "\n", "_C", ".", "LABEL_REFINE_THRESH", "=", "0.7", "\n", "_C", ".", "LABEL_REFINE_RATIO", "=", "0.97", "\n", "_C", ".", "REFINE_ITER", "=", "2000", "\n", "_C", ".", "CROSS_THRESH", "=", "0.7", "\n", "_C", ".", "CROSS_ALPHA", "=", "0.97", "\n", "_C", ".", "OBJECT_RELATION", "=", "False", "\n", "_C", ".", "BOTH_ATTENTION", "=", "False", "\n", "_C", ".", "SHARE", "=", "True", "\n", "_C", ".", "GROUP", "=", "16", "\n", "_C", ".", "SOLVER", ".", "IMG_PER_BATCH_GAN", "=", "8", "\n", "_C", ".", "DATASETS", ".", "TRAIN_LABEL_GAN", "=", "\"voc_clip_0712\"", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.serialize.PicklableWrapper.__init__": [[15, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "obj", ")", ":", "\n", "        ", "self", ".", "_obj", "=", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.serialize.PicklableWrapper.__reduce__": [[18, 21], ["cloudpickle.dumps"], "methods", ["None"], ["", "def", "__reduce__", "(", "self", ")", ":", "\n", "        ", "s", "=", "cloudpickle", ".", "dumps", "(", "self", ".", "_obj", ")", "\n", "return", "cloudpickle", ".", "loads", ",", "(", "s", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.serialize.PicklableWrapper.__call__": [[22, 24], ["serialize.PicklableWrapper._obj"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "_obj", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.serialize.PicklableWrapper.__getattr__": [[25, 30], ["getattr", "getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "attr", ")", ":", "\n", "# Ensure that the wrapped object can be used seamlessly as the previous object.", "\n", "        ", "if", "attr", "not", "in", "[", "\"_obj\"", "]", ":", "\n", "            ", "return", "getattr", "(", "self", ".", "_obj", ",", "attr", ")", "\n", "", "return", "getattr", "(", "self", ",", "attr", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.colormap.colormap": [[95, 109], ["None"], "function", ["None"], ["def", "colormap", "(", "rgb", "=", "False", ",", "maximum", "=", "255", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        rgb (bool): whether to return RGB colors or BGR colors.\n        maximum (int): either 255 or 1\n\n    Returns:\n        ndarray: a float32 array of Nx3 colors, in range [0, 255] or [0, 1]\n    \"\"\"", "\n", "assert", "maximum", "in", "[", "255", ",", "1", "]", ",", "maximum", "\n", "c", "=", "_COLORS", "*", "maximum", "\n", "if", "not", "rgb", ":", "\n", "        ", "c", "=", "c", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "", "return", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.colormap.random_color": [[111, 125], ["numpy.random.randint", "len"], "function", ["None"], ["", "def", "random_color", "(", "rgb", "=", "False", ",", "maximum", "=", "255", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        rgb (bool): whether to return RGB colors or BGR colors.\n        maximum (int): either 255 or 1\n\n    Returns:\n        ndarray: a vector of 3 numbers\n    \"\"\"", "\n", "idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "_COLORS", ")", ")", "\n", "ret", "=", "_COLORS", "[", "idx", "]", "*", "maximum", "\n", "if", "not", "rgb", ":", "\n", "        ", "ret", "=", "ret", "[", ":", ":", "-", "1", "]", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventWriter.write": [[43, 45], ["None"], "methods", ["None"], ["def", "write", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventWriter.close": [[46, 48], ["None"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.JSONWriter.__init__": [[94, 104], ["detectron2.utils.file_io.PathManager.open"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "json_file", ",", "window_size", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            json_file (str): path to the json file. New data will be appended if the file exists.\n            window_size (int): the window size of median smoothing for the scalars whose\n                `smoothing_hint` are True.\n        \"\"\"", "\n", "self", ".", "_file_handle", "=", "PathManager", ".", "open", "(", "json_file", ",", "\"a\"", ")", "\n", "self", ".", "_window_size", "=", "window_size", "\n", "self", ".", "_last_write", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.JSONWriter.write": [[105, 126], ["events.get_event_storage", "collections.defaultdict", "get_event_storage.latest_with_smoothing_hint().items", "len", "collections.defaultdict.items", "events.JSONWriter._file_handle.flush", "sorted", "max", "events.JSONWriter._file_handle.write", "os.fsync", "get_event_storage.latest_with_smoothing_hint", "collections.defaultdict.keys", "events.JSONWriter._file_handle.fileno", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.get_event_storage", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.latest_with_smoothing_hint"], ["", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "to_save", "=", "defaultdict", "(", "dict", ")", "\n", "\n", "for", "k", ",", "(", "v", ",", "iter", ")", "in", "storage", ".", "latest_with_smoothing_hint", "(", "self", ".", "_window_size", ")", ".", "items", "(", ")", ":", "\n", "# keep scalars that have not been written", "\n", "            ", "if", "iter", "<=", "self", ".", "_last_write", ":", "\n", "                ", "continue", "\n", "", "to_save", "[", "iter", "]", "[", "k", "]", "=", "v", "\n", "", "if", "len", "(", "to_save", ")", ":", "\n", "            ", "all_iters", "=", "sorted", "(", "to_save", ".", "keys", "(", ")", ")", "\n", "self", ".", "_last_write", "=", "max", "(", "all_iters", ")", "\n", "\n", "", "for", "itr", ",", "scalars_per_iter", "in", "to_save", ".", "items", "(", ")", ":", "\n", "            ", "scalars_per_iter", "[", "\"iteration\"", "]", "=", "itr", "\n", "self", ".", "_file_handle", ".", "write", "(", "json", ".", "dumps", "(", "scalars_per_iter", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", ")", "\n", "", "self", ".", "_file_handle", ".", "flush", "(", ")", "\n", "try", ":", "\n", "            ", "os", ".", "fsync", "(", "self", ".", "_file_handle", ".", "fileno", "(", ")", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.JSONWriter.close": [[127, 129], ["events.JSONWriter._file_handle.close"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.TensorboardXWriter.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "_file_handle", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.TensorboardXWriter.__init__": [[136, 149], ["SummaryWriter"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "log_dir", ":", "str", ",", "window_size", ":", "int", "=", "20", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            log_dir (str): the directory to save the output events\n            window_size (int): the scalars will be median-smoothed by this window size\n\n            kwargs: other arguments passed to `torch.utils.tensorboard.SummaryWriter(...)`\n        \"\"\"", "\n", "self", ".", "_window_size", "=", "window_size", "\n", "from", "torch", ".", "utils", ".", "tensorboard", "import", "SummaryWriter", "\n", "\n", "self", ".", "_writer", "=", "SummaryWriter", "(", "log_dir", ",", "**", "kwargs", ")", "\n", "self", ".", "_last_write", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.TensorboardXWriter.write": [[150, 175], ["events.get_event_storage", "get_event_storage.latest_with_smoothing_hint().items", "len", "get_event_storage.clear_images", "len", "get_event_storage.clear_histograms", "get_event_storage.latest_with_smoothing_hint", "events.TensorboardXWriter._writer.add_scalar", "max", "events.TensorboardXWriter._writer.add_image", "events.TensorboardXWriter._writer.add_histogram_raw"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.get_event_storage", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.clear_images", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.clear_histograms", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.latest_with_smoothing_hint"], ["", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "new_last_write", "=", "self", ".", "_last_write", "\n", "for", "k", ",", "(", "v", ",", "iter", ")", "in", "storage", ".", "latest_with_smoothing_hint", "(", "self", ".", "_window_size", ")", ".", "items", "(", ")", ":", "\n", "            ", "if", "iter", ">", "self", ".", "_last_write", ":", "\n", "                ", "self", ".", "_writer", ".", "add_scalar", "(", "k", ",", "v", ",", "iter", ")", "\n", "new_last_write", "=", "max", "(", "new_last_write", ",", "iter", ")", "\n", "", "", "self", ".", "_last_write", "=", "new_last_write", "\n", "\n", "# storage.put_{image,histogram} is only meant to be used by", "\n", "# tensorboard writer. So we access its internal fields directly from here.", "\n", "if", "len", "(", "storage", ".", "_vis_data", ")", ">=", "1", ":", "\n", "            ", "for", "img_name", ",", "img", ",", "step_num", "in", "storage", ".", "_vis_data", ":", "\n", "                ", "self", ".", "_writer", ".", "add_image", "(", "img_name", ",", "img", ",", "step_num", ")", "\n", "# Storage stores all image data and rely on this writer to clear them.", "\n", "# As a result it assumes only one writer will use its image data.", "\n", "# An alternative design is to let storage store limited recent", "\n", "# data (e.g. only the most recent image) that all writers can access.", "\n", "# In that case a writer may not see all image data if its period is long.", "\n", "", "storage", ".", "clear_images", "(", ")", "\n", "\n", "", "if", "len", "(", "storage", ".", "_histograms", ")", ">=", "1", ":", "\n", "            ", "for", "params", "in", "storage", ".", "_histograms", ":", "\n", "                ", "self", ".", "_writer", ".", "add_histogram_raw", "(", "**", "params", ")", "\n", "", "storage", ".", "clear_histograms", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.TensorboardXWriter.close": [[176, 179], ["hasattr", "events.TensorboardXWriter._writer.close"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.TensorboardXWriter.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "\"_writer\"", ")", ":", "# doesn't exist when the code fails at import", "\n", "            ", "self", ".", "_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.CommonMetricPrinter.__init__": [[191, 202], ["logging.getLogger"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "max_iter", ":", "Optional", "[", "int", "]", "=", "None", ",", "window_size", ":", "int", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            max_iter: the maximum number of iterations to train.\n                Used to compute ETA. If not given, ETA will not be printed.\n            window_size (int): the losses will be median-smoothed by this window size\n        \"\"\"", "\n", "self", ".", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "self", ".", "_max_iter", "=", "max_iter", "\n", "self", ".", "_window_size", "=", "window_size", "\n", "self", ".", "_last_write", "=", "None", "# (step, time) of last call to write(). Used to compute ETA", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.CommonMetricPrinter._get_eta": [[203, 222], ["storage.put_scalar", "str", "storage.history().median", "datetime.timedelta", "str", "time.perf_counter", "storage.history", "int", "datetime.timedelta", "time.perf_counter", "int"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.history"], ["", "def", "_get_eta", "(", "self", ",", "storage", ")", "->", "Optional", "[", "str", "]", ":", "\n", "        ", "if", "self", ".", "_max_iter", "is", "None", ":", "\n", "            ", "return", "\"\"", "\n", "", "iteration", "=", "storage", ".", "iter", "\n", "try", ":", "\n", "            ", "eta_seconds", "=", "storage", ".", "history", "(", "\"time\"", ")", ".", "median", "(", "1000", ")", "*", "(", "self", ".", "_max_iter", "-", "iteration", "-", "1", ")", "\n", "storage", ".", "put_scalar", "(", "\"eta_seconds\"", ",", "eta_seconds", ",", "smoothing_hint", "=", "False", ")", "\n", "return", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "", "except", "KeyError", ":", "\n", "# estimate eta on our own - more noisy", "\n", "            ", "eta_string", "=", "None", "\n", "if", "self", ".", "_last_write", "is", "not", "None", ":", "\n", "                ", "estimate_iter_time", "=", "(", "time", ".", "perf_counter", "(", ")", "-", "self", ".", "_last_write", "[", "1", "]", ")", "/", "(", "\n", "iteration", "-", "self", ".", "_last_write", "[", "0", "]", "\n", ")", "\n", "eta_seconds", "=", "estimate_iter_time", "*", "(", "self", ".", "_max_iter", "-", "iteration", "-", "1", ")", "\n", "eta_string", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "eta_seconds", ")", ")", ")", "\n", "", "self", ".", "_last_write", "=", "(", "iteration", ",", "time", ".", "perf_counter", "(", ")", ")", "\n", "return", "eta_string", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.CommonMetricPrinter.write": [[223, 270], ["events.get_event_storage", "events.CommonMetricPrinter._get_eta", "torch.cuda.is_available", "events.CommonMetricPrinter.logger.info", "get_event_storage.history().avg", "get_event_storage.history().global_avg", "get_event_storage.history().latest", "get_event_storage.history", "get_event_storage.history", "torch.cuda.max_memory_allocated", "get_event_storage.history", "v.median", "get_event_storage.histories().items", "get_event_storage.histories"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.get_event_storage", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.CommonMetricPrinter._get_eta", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.latest", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.history", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.histories"], ["", "", "def", "write", "(", "self", ")", ":", "\n", "        ", "storage", "=", "get_event_storage", "(", ")", "\n", "iteration", "=", "storage", ".", "iter", "\n", "if", "iteration", "==", "self", ".", "_max_iter", ":", "\n", "# This hook only reports training progress (loss, ETA, etc) but not other data,", "\n", "# therefore do not write anything after training succeeds, even if this method", "\n", "# is called.", "\n", "            ", "return", "\n", "\n", "", "try", ":", "\n", "            ", "data_time", "=", "storage", ".", "history", "(", "\"data_time\"", ")", ".", "avg", "(", "20", ")", "\n", "", "except", "KeyError", ":", "\n", "# they may not exist in the first few iterations (due to warmup)", "\n", "# or when SimpleTrainer is not used", "\n", "            ", "data_time", "=", "None", "\n", "", "try", ":", "\n", "            ", "iter_time", "=", "storage", ".", "history", "(", "\"time\"", ")", ".", "global_avg", "(", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "iter_time", "=", "None", "\n", "", "try", ":", "\n", "            ", "lr", "=", "\"{:.5g}\"", ".", "format", "(", "storage", ".", "history", "(", "\"lr\"", ")", ".", "latest", "(", ")", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "lr", "=", "\"N/A\"", "\n", "\n", "", "eta_string", "=", "self", ".", "_get_eta", "(", "storage", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "max_mem_mb", "=", "torch", ".", "cuda", ".", "max_memory_allocated", "(", ")", "/", "1024.0", "/", "1024.0", "\n", "", "else", ":", "\n", "            ", "max_mem_mb", "=", "None", "\n", "\n", "# NOTE: max_mem is parsed by grep in \"dev/parse_results.sh\"", "\n", "", "self", ".", "logger", ".", "info", "(", "\n", "\" {eta}iter: {iter}  {losses}  {time}{data_time}lr: {lr}  {memory}\"", ".", "format", "(", "\n", "eta", "=", "f\"eta: {eta_string}  \"", "if", "eta_string", "else", "\"\"", ",", "\n", "iter", "=", "iteration", ",", "\n", "losses", "=", "\"  \"", ".", "join", "(", "\n", "[", "\n", "\"{}: {:.4g}\"", ".", "format", "(", "k", ",", "v", ".", "median", "(", "self", ".", "_window_size", ")", ")", "\n", "for", "k", ",", "v", "in", "storage", ".", "histories", "(", ")", ".", "items", "(", ")", "\n", "if", "\"loss\"", "in", "k", "\n", "]", "\n", ")", ",", "\n", "time", "=", "\"time: {:.4f}  \"", ".", "format", "(", "iter_time", ")", "if", "iter_time", "is", "not", "None", "else", "\"\"", ",", "\n", "data_time", "=", "\"data_time: {:.4f}  \"", ".", "format", "(", "data_time", ")", "if", "data_time", "is", "not", "None", "else", "\"\"", ",", "\n", "lr", "=", "lr", ",", "\n", "memory", "=", "\"max_mem: {:.0f}M\"", ".", "format", "(", "max_mem_mb", ")", "if", "max_mem_mb", "is", "not", "None", "else", "\"\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.__init__": [[281, 293], ["collections.defaultdict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "start_iter", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            start_iter (int): the iteration number to start with\n        \"\"\"", "\n", "self", ".", "_history", "=", "defaultdict", "(", "HistoryBuffer", ")", "\n", "self", ".", "_smoothing_hints", "=", "{", "}", "\n", "self", ".", "_latest_scalars", "=", "{", "}", "\n", "self", ".", "_iter", "=", "start_iter", "\n", "self", ".", "_current_prefix", "=", "\"\"", "\n", "self", ".", "_vis_data", "=", "[", "]", "\n", "self", ".", "_histograms", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_image": [[294, 308], ["events.EventStorage._vis_data.append"], "methods", ["None"], ["", "def", "put_image", "(", "self", ",", "img_name", ",", "img_tensor", ")", ":", "\n", "        ", "\"\"\"\n        Add an `img_tensor` associated with `img_name`, to be shown on\n        tensorboard.\n\n        Args:\n            img_name (str): The name of the image to put into tensorboard.\n            img_tensor (torch.Tensor or numpy.array): An `uint8` or `float`\n                Tensor of shape `[channel, height, width]` where `channel` is\n                3. The image format should be RGB. The elements in img_tensor\n                can either have values in [0, 1] (float32) or [0, 255] (uint8).\n                The `img_tensor` will be visualized in tensorboard.\n        \"\"\"", "\n", "self", ".", "_vis_data", ".", "append", "(", "(", "img_name", ",", "img_tensor", ",", "self", ".", "_iter", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar": [[309, 335], ["float", "history.update", "events.EventStorage._smoothing_hints.get"], "methods", ["None"], ["", "def", "put_scalar", "(", "self", ",", "name", ",", "value", ",", "smoothing_hint", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Add a scalar `value` to the `HistoryBuffer` associated with `name`.\n\n        Args:\n            smoothing_hint (bool): a 'hint' on whether this scalar is noisy and should be\n                smoothed when logged. The hint will be accessible through\n                :meth:`EventStorage.smoothing_hints`.  A writer may ignore the hint\n                and apply custom smoothing rule.\n\n                It defaults to True because most scalars we save need to be smoothed to\n                provide any useful signal.\n        \"\"\"", "\n", "name", "=", "self", ".", "_current_prefix", "+", "name", "\n", "history", "=", "self", ".", "_history", "[", "name", "]", "\n", "value", "=", "float", "(", "value", ")", "\n", "history", ".", "update", "(", "value", ",", "self", ".", "_iter", ")", "\n", "self", ".", "_latest_scalars", "[", "name", "]", "=", "(", "value", ",", "self", ".", "_iter", ")", "\n", "\n", "existing_hint", "=", "self", ".", "_smoothing_hints", ".", "get", "(", "name", ")", "\n", "if", "existing_hint", "is", "not", "None", ":", "\n", "            ", "assert", "(", "\n", "existing_hint", "==", "smoothing_hint", "\n", ")", ",", "\"Scalar {} was put with a different smoothing_hint!\"", ".", "format", "(", "name", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_smoothing_hints", "[", "name", "]", "=", "smoothing_hint", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalars": [[336, 346], ["kwargs.items", "events.EventStorage.put_scalar"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar"], ["", "", "def", "put_scalars", "(", "self", ",", "*", ",", "smoothing_hint", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Put multiple scalars from keyword arguments.\n\n        Examples:\n\n            storage.put_scalars(loss=my_loss, accuracy=my_accuracy, smoothing_hint=True)\n        \"\"\"", "\n", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "put_scalar", "(", "k", ",", "v", ",", "smoothing_hint", "=", "smoothing_hint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_histogram": [[347, 376], ["torch.histc", "torch.linspace", "dict", "events.EventStorage._histograms.append", "hist_tensor.min().item", "hist_tensor.max().item", "len", "float", "float", "hist_edges[].tolist", "torch.histc.tolist", "hist_tensor.min", "hist_tensor.max", "hist_tensor.sum", "torch.sum"], "methods", ["None"], ["", "", "def", "put_histogram", "(", "self", ",", "hist_name", ",", "hist_tensor", ",", "bins", "=", "1000", ")", ":", "\n", "        ", "\"\"\"\n        Create a histogram from a tensor.\n\n        Args:\n            hist_name (str): The name of the histogram to put into tensorboard.\n            hist_tensor (torch.Tensor): A Tensor of arbitrary shape to be converted\n                into a histogram.\n            bins (int): Number of histogram bins.\n        \"\"\"", "\n", "ht_min", ",", "ht_max", "=", "hist_tensor", ".", "min", "(", ")", ".", "item", "(", ")", ",", "hist_tensor", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "\n", "# Create a histogram with PyTorch", "\n", "hist_counts", "=", "torch", ".", "histc", "(", "hist_tensor", ",", "bins", "=", "bins", ")", "\n", "hist_edges", "=", "torch", ".", "linspace", "(", "start", "=", "ht_min", ",", "end", "=", "ht_max", ",", "steps", "=", "bins", "+", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Parameter for the add_histogram_raw function of SummaryWriter", "\n", "hist_params", "=", "dict", "(", "\n", "tag", "=", "hist_name", ",", "\n", "min", "=", "ht_min", ",", "\n", "max", "=", "ht_max", ",", "\n", "num", "=", "len", "(", "hist_tensor", ")", ",", "\n", "sum", "=", "float", "(", "hist_tensor", ".", "sum", "(", ")", ")", ",", "\n", "sum_squares", "=", "float", "(", "torch", ".", "sum", "(", "hist_tensor", "**", "2", ")", ")", ",", "\n", "bucket_limits", "=", "hist_edges", "[", "1", ":", "]", ".", "tolist", "(", ")", ",", "\n", "bucket_counts", "=", "hist_counts", ".", "tolist", "(", ")", ",", "\n", "global_step", "=", "self", ".", "_iter", ",", "\n", ")", "\n", "self", ".", "_histograms", ".", "append", "(", "hist_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.history": [[377, 386], ["events.EventStorage._history.get", "KeyError"], "methods", ["None"], ["", "def", "history", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            HistoryBuffer: the scalar history for name\n        \"\"\"", "\n", "ret", "=", "self", ".", "_history", ".", "get", "(", "name", ",", "None", ")", "\n", "if", "ret", "is", "None", ":", "\n", "            ", "raise", "KeyError", "(", "\"No history metric available for {}!\"", ".", "format", "(", "name", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.histories": [[387, 393], ["None"], "methods", ["None"], ["", "def", "histories", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[name -> HistoryBuffer]: the HistoryBuffer for all scalars\n        \"\"\"", "\n", "return", "self", ".", "_history", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.latest": [[394, 401], ["None"], "methods", ["None"], ["", "def", "latest", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[str -> (float, int)]: mapping from the name of each scalar to the most\n                recent value and the iteration number its added.\n        \"\"\"", "\n", "return", "self", ".", "_latest_scalars", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.latest_with_smoothing_hint": [[402, 418], ["events.EventStorage._latest_scalars.items", "events.EventStorage._history[].median"], "methods", ["None"], ["", "def", "latest_with_smoothing_hint", "(", "self", ",", "window_size", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        Similar to :meth:`latest`, but the returned values\n        are either the un-smoothed original latest value,\n        or a median of the given window_size,\n        depend on whether the smoothing_hint is True.\n\n        This provides a default behavior that other writers can use.\n        \"\"\"", "\n", "result", "=", "{", "}", "\n", "for", "k", ",", "(", "v", ",", "itr", ")", "in", "self", ".", "_latest_scalars", ".", "items", "(", ")", ":", "\n", "            ", "result", "[", "k", "]", "=", "(", "\n", "self", ".", "_history", "[", "k", "]", ".", "median", "(", "window_size", ")", "if", "self", ".", "_smoothing_hints", "[", "k", "]", "else", "v", ",", "\n", "itr", ",", "\n", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.smoothing_hints": [[419, 426], ["None"], "methods", ["None"], ["", "def", "smoothing_hints", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            dict[name -> bool]: the user-provided hint on whether the scalar\n                is noisy and needs smoothing.\n        \"\"\"", "\n", "return", "self", ".", "_smoothing_hints", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.step": [[427, 435], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        User should either: (1) Call this function to increment storage.iter when needed. Or\n        (2) Set `storage.iter` to the correct iteration number before each iteration.\n\n        The storage will then be able to associate the new data with an iteration number.\n        \"\"\"", "\n", "self", ".", "_iter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.iter": [[445, 448], ["int"], "methods", ["None"], ["", "@", "iter", ".", "setter", "\n", "def", "iter", "(", "self", ",", "val", ")", ":", "\n", "        ", "self", ".", "_iter", "=", "int", "(", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.iteration": [[449, 453], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "iteration", "(", "self", ")", ":", "\n", "# for backward compatibility", "\n", "        ", "return", "self", ".", "_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.__enter__": [[454, 457], ["_CURRENT_STORAGE_STACK.append"], "methods", ["None"], ["", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "_CURRENT_STORAGE_STACK", ".", "append", "(", "self", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.__exit__": [[458, 461], ["_CURRENT_STORAGE_STACK.pop"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_val", ",", "exc_tb", ")", ":", "\n", "        ", "assert", "_CURRENT_STORAGE_STACK", "[", "-", "1", "]", "==", "self", "\n", "_CURRENT_STORAGE_STACK", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.name_scope": [[462, 473], ["name.rstrip"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "name_scope", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Yields:\n            A context within which all the events added to this storage\n            will be prefixed by the name scope.\n        \"\"\"", "\n", "old_prefix", "=", "self", ".", "_current_prefix", "\n", "self", ".", "_current_prefix", "=", "name", ".", "rstrip", "(", "\"/\"", ")", "+", "\"/\"", "\n", "yield", "\n", "self", ".", "_current_prefix", "=", "old_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.clear_images": [[474, 480], ["None"], "methods", ["None"], ["", "def", "clear_images", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Delete all the stored images for visualization. This should be called\n        after images are written to tensorboard.\n        \"\"\"", "\n", "self", ".", "_vis_data", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.clear_histograms": [[481, 487], ["None"], "methods", ["None"], ["", "def", "clear_histograms", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Delete all the stored histograms for visualization.\n        This should be called after histograms are written to tensorboard.\n        \"\"\"", "\n", "self", ".", "_histograms", "=", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.get_event_storage": [[26, 36], ["len"], "function", ["None"], ["def", "get_event_storage", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The :class:`EventStorage` object that's currently being used.\n        Throws an error if no :class:`EventStorage` is currently enabled.\n    \"\"\"", "\n", "assert", "len", "(", "\n", "_CURRENT_STORAGE_STACK", "\n", ")", ",", "\"get_event_storage() has to be called inside a 'with EventStorage(...)' context!\"", "\n", "return", "_CURRENT_STORAGE_STACK", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size": [[21, 27], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size"], ["def", "get_world_size", "(", ")", "->", "int", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_rank": [[29, 35], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_rank"], ["", "def", "get_rank", "(", ")", "->", "int", ":", "\n", "    ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "return", "dist", ".", "get_rank", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_local_rank": [[37, 48], ["torch.get_rank", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_rank"], ["", "def", "get_local_rank", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The rank of the current process within the local (per-machine) process group.\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "0", "\n", "", "assert", "_LOCAL_PROCESS_GROUP", "is", "not", "None", "\n", "return", "dist", ".", "get_rank", "(", "group", "=", "_LOCAL_PROCESS_GROUP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_local_size": [[50, 61], ["torch.get_world_size", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size"], ["", "def", "get_local_size", "(", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The size of the per-machine process group,\n        i.e. the number of processes per machine.\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "1", "\n", "", "return", "dist", ".", "get_world_size", "(", "group", "=", "_LOCAL_PROCESS_GROUP", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process": [[63, 65], ["comm.get_rank"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_rank"], ["", "def", "is_main_process", "(", ")", "->", "bool", ":", "\n", "    ", "return", "get_rank", "(", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.synchronize": [[67, 80], ["torch.get_world_size", "torch.barrier", "torch.is_available", "torch.is_initialized"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size"], ["", "def", "synchronize", "(", ")", ":", "\n", "    ", "\"\"\"\n    Helper function to synchronize (barrier) among all processes when\n    using distributed training\n    \"\"\"", "\n", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "\n", "", "if", "not", "dist", ".", "is_initialized", "(", ")", ":", "\n", "        ", "return", "\n", "", "world_size", "=", "dist", ".", "get_world_size", "(", ")", "\n", "if", "world_size", "==", "1", ":", "\n", "        ", "return", "\n", "", "dist", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm._get_global_gloo_group": [[82, 92], ["functools.lru_cache", "torch.get_backend", "torch.new_group"], "function", ["None"], ["", "@", "functools", ".", "lru_cache", "(", ")", "\n", "def", "_get_global_gloo_group", "(", ")", ":", "\n", "    ", "\"\"\"\n    Return a process group based on gloo backend, containing all the ranks\n    The result is cached.\n    \"\"\"", "\n", "if", "dist", ".", "get_backend", "(", ")", "==", "\"nccl\"", ":", "\n", "        ", "return", "dist", ".", "new_group", "(", "backend", "=", "\"gloo\"", ")", "\n", "", "else", ":", "\n", "        ", "return", "dist", ".", "group", ".", "WORLD", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm._serialize_to_tensor": [[94, 110], ["torch.get_backend", "torch.device", "torch.device", "pickle.dumps", "torch.ByteStorage.from_buffer", "torch.ByteStorage.from_buffer", "torch.ByteTensor().to", "torch.ByteTensor().to", "len", "logging.getLogger", "logging.getLogger.warning", "torch.ByteTensor", "torch.ByteTensor", "comm.get_rank", "len"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_rank"], ["", "", "def", "_serialize_to_tensor", "(", "data", ",", "group", ")", ":", "\n", "    ", "backend", "=", "dist", ".", "get_backend", "(", "group", ")", "\n", "assert", "backend", "in", "[", "\"gloo\"", ",", "\"nccl\"", "]", "\n", "device", "=", "torch", ".", "device", "(", "\"cpu\"", "if", "backend", "==", "\"gloo\"", "else", "\"cuda\"", ")", "\n", "\n", "buffer", "=", "pickle", ".", "dumps", "(", "data", ")", "\n", "if", "len", "(", "buffer", ")", ">", "1024", "**", "3", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Rank {} trying to all-gather {:.2f} GB of data on device {}\"", ".", "format", "(", "\n", "get_rank", "(", ")", ",", "len", "(", "buffer", ")", "/", "(", "1024", "**", "3", ")", ",", "device", "\n", ")", "\n", ")", "\n", "", "storage", "=", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "buffer", ")", "\n", "tensor", "=", "torch", ".", "ByteTensor", "(", "storage", ")", ".", "to", "(", "device", "=", "device", ")", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm._pad_to_largest_tensor": [[112, 137], ["torch.get_world_size", "torch.tensor", "torch.tensor", "torch.all_gather", "max", "torch.zeros", "torch.zeros", "int", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat.numel", "range", "size.item"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.all_gather"], ["", "def", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        list[int]: size of the tensor, on each rank\n        Tensor: padded tensor that has the max size\n    \"\"\"", "\n", "world_size", "=", "dist", ".", "get_world_size", "(", "group", "=", "group", ")", "\n", "assert", "(", "\n", "world_size", ">=", "1", "\n", ")", ",", "\"comm.gather/all_gather must be called from ranks within the given group!\"", "\n", "local_size", "=", "torch", ".", "tensor", "(", "[", "tensor", ".", "numel", "(", ")", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "tensor", ".", "device", ")", "\n", "size_list", "=", "[", "\n", "torch", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "torch", ".", "int64", ",", "device", "=", "tensor", ".", "device", ")", "for", "_", "in", "range", "(", "world_size", ")", "\n", "]", "\n", "dist", ".", "all_gather", "(", "size_list", ",", "local_size", ",", "group", "=", "group", ")", "\n", "size_list", "=", "[", "int", "(", "size", ".", "item", "(", ")", ")", "for", "size", "in", "size_list", "]", "\n", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# we pad the tensor because torch all_gather does not support", "\n", "# gathering tensors of different shapes", "\n", "if", "local_size", "!=", "max_size", ":", "\n", "        ", "padding", "=", "torch", ".", "zeros", "(", "(", "max_size", "-", "local_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "\n", "tensor", "=", "torch", ".", "cat", "(", "(", "tensor", ",", "padding", ")", ",", "dim", "=", "0", ")", "\n", "", "return", "size_list", ",", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.all_gather": [[139, 175], ["comm._serialize_to_tensor", "comm._pad_to_largest_tensor", "max", "torch.all_gather", "zip", "comm.get_world_size", "comm._get_global_gloo_group", "torch.get_world_size", "torch.empty", "torch.empty", "data_list.append", "_serialize_to_tensor.cpu().numpy().tobytes", "pickle.loads", "_serialize_to_tensor.cpu().numpy", "_serialize_to_tensor.cpu"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm._serialize_to_tensor", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm._pad_to_largest_tensor", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.all_gather", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm._get_global_gloo_group", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size"], ["", "def", "all_gather", "(", "data", ",", "group", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Run all_gather on arbitrary picklable data (not necessarily tensors).\n\n    Args:\n        data: any picklable object\n        group: a torch process group. By default, will use a group which\n            contains all ranks on gloo backend.\n\n    Returns:\n        list[data]: list of data gathered from each rank\n    \"\"\"", "\n", "if", "get_world_size", "(", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "_get_global_gloo_group", "(", ")", "\n", "", "if", "dist", ".", "get_world_size", "(", "group", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "\n", "", "tensor", "=", "_serialize_to_tensor", "(", "data", ",", "group", ")", "\n", "\n", "size_list", ",", "tensor", "=", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", "\n", "max_size", "=", "max", "(", "size_list", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "tensor_list", "=", "[", "\n", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "for", "_", "in", "size_list", "\n", "]", "\n", "dist", ".", "all_gather", "(", "tensor_list", ",", "tensor", ",", "group", "=", "group", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "        ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "\n", "", "return", "data_list", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.gather": [[177, 218], ["torch.get_rank", "comm._serialize_to_tensor", "comm._pad_to_largest_tensor", "comm.get_world_size", "comm._get_global_gloo_group", "torch.get_world_size", "max", "torch.gather", "zip", "torch.gather", "torch.empty", "torch.empty", "data_list.append", "_serialize_to_tensor.cpu().numpy().tobytes", "pickle.loads", "_serialize_to_tensor.cpu().numpy", "_serialize_to_tensor.cpu"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_rank", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm._serialize_to_tensor", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm._pad_to_largest_tensor", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm._get_global_gloo_group", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.gather", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.gather"], ["", "def", "gather", "(", "data", ",", "dst", "=", "0", ",", "group", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Run gather on arbitrary picklable data (not necessarily tensors).\n\n    Args:\n        data: any picklable object\n        dst (int): destination rank\n        group: a torch process group. By default, will use a group which\n            contains all ranks on gloo backend.\n\n    Returns:\n        list[data]: on dst, a list of data gathered from each rank. Otherwise,\n            an empty list.\n    \"\"\"", "\n", "if", "get_world_size", "(", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "if", "group", "is", "None", ":", "\n", "        ", "group", "=", "_get_global_gloo_group", "(", ")", "\n", "", "if", "dist", ".", "get_world_size", "(", "group", "=", "group", ")", "==", "1", ":", "\n", "        ", "return", "[", "data", "]", "\n", "", "rank", "=", "dist", ".", "get_rank", "(", "group", "=", "group", ")", "\n", "\n", "tensor", "=", "_serialize_to_tensor", "(", "data", ",", "group", ")", "\n", "size_list", ",", "tensor", "=", "_pad_to_largest_tensor", "(", "tensor", ",", "group", ")", "\n", "\n", "# receiving Tensor from all ranks", "\n", "if", "rank", "==", "dst", ":", "\n", "        ", "max_size", "=", "max", "(", "size_list", ")", "\n", "tensor_list", "=", "[", "\n", "torch", ".", "empty", "(", "(", "max_size", ",", ")", ",", "dtype", "=", "torch", ".", "uint8", ",", "device", "=", "tensor", ".", "device", ")", "for", "_", "in", "size_list", "\n", "]", "\n", "dist", ".", "gather", "(", "tensor", ",", "tensor_list", ",", "dst", "=", "dst", ",", "group", "=", "group", ")", "\n", "\n", "data_list", "=", "[", "]", "\n", "for", "size", ",", "tensor", "in", "zip", "(", "size_list", ",", "tensor_list", ")", ":", "\n", "            ", "buffer", "=", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tobytes", "(", ")", "[", ":", "size", "]", "\n", "data_list", ".", "append", "(", "pickle", ".", "loads", "(", "buffer", ")", ")", "\n", "", "return", "data_list", "\n", "", "else", ":", "\n", "        ", "dist", ".", "gather", "(", "tensor", ",", "[", "]", ",", "dst", "=", "dst", ",", "group", "=", "group", ")", "\n", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.shared_random_seed": [[220, 232], ["numpy.random.randint", "comm.all_gather"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.all_gather"], ["", "", "def", "shared_random_seed", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        int: a random number that is the same across all workers.\n        If workers need a shared RNG, they can use this shared seed to\n        create one.\n\n    All workers must call this function, otherwise it will deadlock.\n    \"\"\"", "\n", "ints", "=", "np", ".", "random", ".", "randint", "(", "2", "**", "31", ")", "\n", "all_ints", "=", "all_gather", "(", "ints", ")", "\n", "return", "all_ints", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.reduce_dict": [[234, 264], ["comm.get_world_size", "torch.no_grad", "torch.no_grad", "sorted", "torch.stack", "torch.stack", "torch.reduce", "input_dict.keys", "names.append", "torch.stack.append", "torch.get_rank", "zip"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_rank"], ["", "def", "reduce_dict", "(", "input_dict", ",", "average", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Reduce the values in the dictionary from all processes so that process with rank\n    0 has the reduced results.\n\n    Args:\n        input_dict (dict): inputs to be reduced. All the values must be scalar CUDA Tensor.\n        average (bool): whether to do average or sum\n\n    Returns:\n        a dict with the same keys as input_dict, after reduction.\n    \"\"\"", "\n", "world_size", "=", "get_world_size", "(", ")", "\n", "if", "world_size", "<", "2", ":", "\n", "        ", "return", "input_dict", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "names", "=", "[", "]", "\n", "values", "=", "[", "]", "\n", "# sort the keys so that they are consistent across processes", "\n", "for", "k", "in", "sorted", "(", "input_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "names", ".", "append", "(", "k", ")", "\n", "values", ".", "append", "(", "input_dict", "[", "k", "]", ")", "\n", "", "values", "=", "torch", ".", "stack", "(", "values", ",", "dim", "=", "0", ")", "\n", "dist", ".", "reduce", "(", "values", ",", "dst", "=", "0", ")", "\n", "if", "dist", ".", "get_rank", "(", ")", "==", "0", "and", "average", ":", "\n", "# only main process gets accumulated, so only divide by", "\n", "# world_size in this case", "\n", "            ", "values", "/=", "world_size", "\n", "", "reduced_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "names", ",", "values", ")", "}", "\n", "", "return", "reduced_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.__init__": [[67, 94], ["isinstance", "isinstance", "isinstance", "ValueError", "isinstance", "pycocotools.frPyObjects.astype", "pycocotools.frPyObjects", "pycocotools.decode", "numpy.asarray().reshape", "type", "numpy.asarray"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mask_or_polygons", ",", "height", ",", "width", ")", ":", "\n", "        ", "self", ".", "_mask", "=", "self", ".", "_polygons", "=", "self", ".", "_has_holes", "=", "None", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "width", "=", "width", "\n", "\n", "m", "=", "mask_or_polygons", "\n", "if", "isinstance", "(", "m", ",", "dict", ")", ":", "\n", "# RLEs", "\n", "            ", "assert", "\"counts\"", "in", "m", "and", "\"size\"", "in", "m", "\n", "if", "isinstance", "(", "m", "[", "\"counts\"", "]", ",", "list", ")", ":", "# uncompressed RLEs", "\n", "                ", "h", ",", "w", "=", "m", "[", "\"size\"", "]", "\n", "assert", "h", "==", "height", "and", "w", "==", "width", "\n", "m", "=", "mask_util", ".", "frPyObjects", "(", "m", ",", "h", ",", "w", ")", "\n", "", "self", ".", "_mask", "=", "mask_util", ".", "decode", "(", "m", ")", "[", ":", ",", ":", "]", "\n", "return", "\n", "\n", "", "if", "isinstance", "(", "m", ",", "list", ")", ":", "# list[ndarray]", "\n", "            ", "self", ".", "_polygons", "=", "[", "np", ".", "asarray", "(", "x", ")", ".", "reshape", "(", "-", "1", ")", "for", "x", "in", "m", "]", "\n", "return", "\n", "\n", "", "if", "isinstance", "(", "m", ",", "np", ".", "ndarray", ")", ":", "# assumed to be a binary mask", "\n", "            ", "assert", "m", ".", "shape", "[", "1", "]", "!=", "2", ",", "m", ".", "shape", "\n", "assert", "m", ".", "shape", "==", "(", "height", ",", "width", ")", ",", "m", ".", "shape", "\n", "self", ".", "_mask", "=", "m", ".", "astype", "(", "\"uint8\"", ")", "\n", "return", "\n", "\n", "", "raise", "ValueError", "(", "\"GenericMask cannot handle object {} of type '{}'\"", ".", "format", "(", "m", ",", "type", "(", "m", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.mask": [[95, 100], ["visualizer.GenericMask.polygons_to_mask"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.polygons_to_mask"], ["", "@", "property", "\n", "def", "mask", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_mask", "is", "None", ":", "\n", "            ", "self", ".", "_mask", "=", "self", ".", "polygons_to_mask", "(", "self", ".", "_polygons", ")", "\n", "", "return", "self", ".", "_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.polygons": [[101, 106], ["visualizer.GenericMask.mask_to_polygons"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.mask_to_polygons"], ["", "@", "property", "\n", "def", "polygons", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_polygons", "is", "None", ":", "\n", "            ", "self", ".", "_polygons", ",", "self", ".", "_has_holes", "=", "self", ".", "mask_to_polygons", "(", "self", ".", "_mask", ")", "\n", "", "return", "self", ".", "_polygons", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.has_holes": [[107, 115], ["visualizer.GenericMask.mask_to_polygons"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.mask_to_polygons"], ["", "@", "property", "\n", "def", "has_holes", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_has_holes", "is", "None", ":", "\n", "            ", "if", "self", ".", "_mask", "is", "not", "None", ":", "\n", "                ", "self", ".", "_polygons", ",", "self", ".", "_has_holes", "=", "self", ".", "mask_to_polygons", "(", "self", ".", "_mask", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_has_holes", "=", "False", "# if original format is polygon, does not have holes", "\n", "", "", "return", "self", ".", "_has_holes", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.mask_to_polygons": [[116, 134], ["numpy.ascontiguousarray", "cv2.findContours", "numpy.ascontiguousarray.astype", "x.flatten", "len", "hierarchy.reshape"], "methods", ["None"], ["", "def", "mask_to_polygons", "(", "self", ",", "mask", ")", ":", "\n", "# cv2.RETR_CCOMP flag retrieves all the contours and arranges them to a 2-level", "\n", "# hierarchy. External contours (boundary) of the object are placed in hierarchy-1.", "\n", "# Internal contours (holes) are placed in hierarchy-2.", "\n", "# cv2.CHAIN_APPROX_NONE flag gets vertices of polygons from contours.", "\n", "        ", "mask", "=", "np", ".", "ascontiguousarray", "(", "mask", ")", "# some versions of cv2 does not support incontiguous arr", "\n", "res", "=", "cv2", ".", "findContours", "(", "mask", ".", "astype", "(", "\"uint8\"", ")", ",", "cv2", ".", "RETR_CCOMP", ",", "cv2", ".", "CHAIN_APPROX_NONE", ")", "\n", "hierarchy", "=", "res", "[", "-", "1", "]", "\n", "if", "hierarchy", "is", "None", ":", "# empty mask", "\n", "            ", "return", "[", "]", ",", "False", "\n", "", "has_holes", "=", "(", "hierarchy", ".", "reshape", "(", "-", "1", ",", "4", ")", "[", ":", ",", "3", "]", ">=", "0", ")", ".", "sum", "(", ")", ">", "0", "\n", "res", "=", "res", "[", "-", "2", "]", "\n", "res", "=", "[", "x", ".", "flatten", "(", ")", "for", "x", "in", "res", "]", "\n", "# These coordinates from OpenCV are integers in range [0, W-1 or H-1].", "\n", "# We add 0.5 to turn them into real-value coordinate space. A better solution", "\n", "# would be to first +0.5 and then dilate the returned polygon by 0.5.", "\n", "res", "=", "[", "x", "+", "0.5", "for", "x", "in", "res", "if", "len", "(", "x", ")", ">=", "6", "]", "\n", "return", "res", ",", "has_holes", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.polygons_to_mask": [[135, 139], ["pycocotools.frPyObjects", "pycocotools.merge", "pycocotools.decode"], "methods", ["None"], ["", "def", "polygons_to_mask", "(", "self", ",", "polygons", ")", ":", "\n", "        ", "rle", "=", "mask_util", ".", "frPyObjects", "(", "polygons", ",", "self", ".", "height", ",", "self", ".", "width", ")", "\n", "rle", "=", "mask_util", ".", "merge", "(", "rle", ")", "\n", "return", "mask_util", ".", "decode", "(", "rle", ")", "[", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.area": [[140, 142], ["visualizer.GenericMask.mask.sum"], "methods", ["None"], ["", "def", "area", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mask", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.bbox": [[143, 150], ["pycocotools.frPyObjects", "pycocotools.merge", "pycocotools.toBbox"], "methods", ["None"], ["", "def", "bbox", "(", "self", ")", ":", "\n", "        ", "p", "=", "mask_util", ".", "frPyObjects", "(", "self", ".", "polygons", ",", "self", ".", "height", ",", "self", ".", "width", ")", "\n", "p", "=", "mask_util", ".", "merge", "(", "p", ")", "\n", "bbox", "=", "mask_util", ".", "toBbox", "(", "p", ")", "\n", "bbox", "[", "2", "]", "+=", "bbox", "[", "0", "]", "\n", "bbox", "[", "3", "]", "+=", "bbox", "[", "1", "]", "\n", "return", "bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._PanopticPrediction.__init__": [[157, 192], ["torch.unique", "areas.numpy.numpy.numpy", "numpy.argsort", "visualizer._PanopticPrediction._seg_ids.tolist", "zip", "numpy.unique", "panoptic_seg.numpy", "segments_info.append", "float", "metadata.thing_dataset_id_to_contiguous_id.values", "int", "int", "bool"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "panoptic_seg", ",", "segments_info", ",", "metadata", "=", "None", ")", ":", "\n", "        ", "if", "segments_info", "is", "None", ":", "\n", "            ", "assert", "metadata", "is", "not", "None", "\n", "# If \"segments_info\" is None, we assume \"panoptic_img\" is a", "\n", "# H*W int32 image storing the panoptic_id in the format of", "\n", "# category_id * label_divisor + instance_id. We reserve -1 for", "\n", "# VOID label.", "\n", "label_divisor", "=", "metadata", ".", "label_divisor", "\n", "segments_info", "=", "[", "]", "\n", "for", "panoptic_label", "in", "np", ".", "unique", "(", "panoptic_seg", ".", "numpy", "(", ")", ")", ":", "\n", "                ", "if", "panoptic_label", "==", "-", "1", ":", "\n", "# VOID region.", "\n", "                    ", "continue", "\n", "", "pred_class", "=", "panoptic_label", "//", "label_divisor", "\n", "isthing", "=", "pred_class", "in", "metadata", ".", "thing_dataset_id_to_contiguous_id", ".", "values", "(", ")", "\n", "segments_info", ".", "append", "(", "\n", "{", "\n", "\"id\"", ":", "int", "(", "panoptic_label", ")", ",", "\n", "\"category_id\"", ":", "int", "(", "pred_class", ")", ",", "\n", "\"isthing\"", ":", "bool", "(", "isthing", ")", ",", "\n", "}", "\n", ")", "\n", "", "", "del", "metadata", "\n", "\n", "self", ".", "_seg", "=", "panoptic_seg", "\n", "\n", "self", ".", "_sinfo", "=", "{", "s", "[", "\"id\"", "]", ":", "s", "for", "s", "in", "segments_info", "}", "# seg id -> seg info", "\n", "segment_ids", ",", "areas", "=", "torch", ".", "unique", "(", "panoptic_seg", ",", "sorted", "=", "True", ",", "return_counts", "=", "True", ")", "\n", "areas", "=", "areas", ".", "numpy", "(", ")", "\n", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", "\n", "self", ".", "_seg_ids", ",", "self", ".", "_seg_areas", "=", "segment_ids", "[", "sorted_idxs", "]", ",", "areas", "[", "sorted_idxs", "]", "\n", "self", ".", "_seg_ids", "=", "self", ".", "_seg_ids", ".", "tolist", "(", ")", "\n", "for", "sid", ",", "area", "in", "zip", "(", "self", ".", "_seg_ids", ",", "self", ".", "_seg_areas", ")", ":", "\n", "            ", "if", "sid", "in", "self", ".", "_sinfo", ":", "\n", "                ", "self", ".", "_sinfo", "[", "sid", "]", "[", "\"area\"", "]", "=", "float", "(", "area", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._PanopticPrediction.non_empty_mask": [[193, 208], ["len", "numpy.zeros", "len", "empty_ids.append"], "methods", ["None"], ["", "", "", "def", "non_empty_mask", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            (H, W) array, a mask for all pixels that have a prediction\n        \"\"\"", "\n", "empty_ids", "=", "[", "]", "\n", "for", "id", "in", "self", ".", "_seg_ids", ":", "\n", "            ", "if", "id", "not", "in", "self", ".", "_sinfo", ":", "\n", "                ", "empty_ids", ".", "append", "(", "id", ")", "\n", "", "", "if", "len", "(", "empty_ids", ")", "==", "0", ":", "\n", "            ", "return", "np", ".", "zeros", "(", "self", ".", "_seg", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "", "assert", "(", "\n", "len", "(", "empty_ids", ")", "==", "1", "\n", ")", ",", "\">1 ids corresponds to no labels. This is currently not supported\"", "\n", "return", "(", "self", ".", "_seg", "!=", "empty_ids", "[", "0", "]", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._PanopticPrediction.semantic_masks": [[209, 216], ["visualizer._PanopticPrediction._sinfo.get"], "methods", ["None"], ["", "def", "semantic_masks", "(", "self", ")", ":", "\n", "        ", "for", "sid", "in", "self", ".", "_seg_ids", ":", "\n", "            ", "sinfo", "=", "self", ".", "_sinfo", ".", "get", "(", "sid", ")", "\n", "if", "sinfo", "is", "None", "or", "sinfo", "[", "\"isthing\"", "]", ":", "\n", "# Some pixels (e.g. id 0 in PanopticFPN) have no instance or semantic predictions.", "\n", "                ", "continue", "\n", "", "yield", "(", "self", ".", "_seg", "==", "sid", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "bool", ")", ",", "sinfo", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._PanopticPrediction.instance_masks": [[217, 225], ["visualizer._PanopticPrediction._sinfo.get", "mask.sum"], "methods", ["None"], ["", "", "def", "instance_masks", "(", "self", ")", ":", "\n", "        ", "for", "sid", "in", "self", ".", "_seg_ids", ":", "\n", "            ", "sinfo", "=", "self", ".", "_sinfo", ".", "get", "(", "sid", ")", "\n", "if", "sinfo", "is", "None", "or", "not", "sinfo", "[", "\"isthing\"", "]", ":", "\n", "                ", "continue", "\n", "", "mask", "=", "(", "self", ".", "_seg", "==", "sid", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "bool", ")", "\n", "if", "mask", ".", "sum", "(", ")", ">", "0", ":", "\n", "                ", "yield", "mask", ",", "sinfo", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.VisImage.__init__": [[255, 265], ["visualizer.VisImage._setup_figure"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.VisImage._setup_figure"], ["    ", "def", "__init__", "(", "self", ",", "img", ",", "scale", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img (ndarray): an RGB image of shape (H, W, 3).\n            scale (float): scale the input image\n        \"\"\"", "\n", "self", ".", "img", "=", "img", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "width", ",", "self", ".", "height", "=", "img", ".", "shape", "[", "1", "]", ",", "img", ".", "shape", "[", "0", "]", "\n", "self", ".", "_setup_figure", "(", "img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.VisImage._setup_figure": [[266, 292], ["matplotlib.Figure", "matplotlib.Figure", "matplotlib.Figure", "matplotlib.Figure.get_dpi", "matplotlib.Figure.set_size_inches", "matplotlib.backends.backend_agg.FigureCanvasAgg", "matplotlib.backends.backend_agg.FigureCanvasAgg", "matplotlib.backends.backend_agg.FigureCanvasAgg", "matplotlib.Figure.add_axes", "mplfigure.Figure.add_axes.axis", "mplfigure.Figure.add_axes.imshow"], "methods", ["None"], ["", "def", "_setup_figure", "(", "self", ",", "img", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            Same as in :meth:`__init__()`.\n\n        Returns:\n            fig (matplotlib.pyplot.figure): top level container for all the image plot elements.\n            ax (matplotlib.pyplot.Axes): contains figure elements and sets the coordinate system.\n        \"\"\"", "\n", "fig", "=", "mplfigure", ".", "Figure", "(", "frameon", "=", "False", ")", "\n", "self", ".", "dpi", "=", "fig", ".", "get_dpi", "(", ")", "\n", "# add a small 1e-2 to avoid precision lost due to matplotlib's truncation", "\n", "# (https://github.com/matplotlib/matplotlib/issues/15363)", "\n", "fig", ".", "set_size_inches", "(", "\n", "(", "self", ".", "width", "*", "self", ".", "scale", "+", "1e-2", ")", "/", "self", ".", "dpi", ",", "\n", "(", "self", ".", "height", "*", "self", ".", "scale", "+", "1e-2", ")", "/", "self", ".", "dpi", ",", "\n", ")", "\n", "self", ".", "canvas", "=", "FigureCanvasAgg", "(", "fig", ")", "\n", "# self.canvas = mpl.backends.backend_cairo.FigureCanvasCairo(fig)", "\n", "ax", "=", "fig", ".", "add_axes", "(", "[", "0.0", ",", "0.0", ",", "1.0", ",", "1.0", "]", ")", "\n", "ax", ".", "axis", "(", "\"off\"", ")", "\n", "# Need to imshow this first so that other patches can be drawn on top", "\n", "ax", ".", "imshow", "(", "img", ",", "extent", "=", "(", "0", ",", "self", ".", "width", ",", "self", ".", "height", ",", "0", ")", ",", "interpolation", "=", "\"nearest\"", ")", "\n", "\n", "self", ".", "fig", "=", "fig", "\n", "self", ".", "ax", "=", "ax", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.VisImage.save": [[293, 300], ["visualizer.VisImage.fig.savefig"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            filepath (str): a string that contains the absolute path, including the file name, where\n                the visualized image will be saved.\n        \"\"\"", "\n", "self", ".", "fig", ".", "savefig", "(", "filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.VisImage.get_image": [[301, 320], ["canvas.print_to_buffer", "numpy.frombuffer", "numpy.frombuffer.reshape", "numpy.split", "rgb.astype"], "methods", ["None"], ["", "def", "get_image", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            ndarray:\n                the visualized image of shape (H, W, 3) (RGB) in uint8 type.\n                The shape is scaled w.r.t the input image using the given `scale` argument.\n        \"\"\"", "\n", "canvas", "=", "self", ".", "canvas", "\n", "s", ",", "(", "width", ",", "height", ")", "=", "canvas", ".", "print_to_buffer", "(", ")", "\n", "# buf = io.BytesIO()  # works for cairo backend", "\n", "# canvas.print_rgba(buf)", "\n", "# width, height = self.width, self.height", "\n", "# s = buf.getvalue()", "\n", "\n", "buffer", "=", "np", ".", "frombuffer", "(", "s", ",", "dtype", "=", "\"uint8\"", ")", "\n", "\n", "img_rgba", "=", "buffer", ".", "reshape", "(", "height", ",", "width", ",", "4", ")", "\n", "rgb", ",", "alpha", "=", "np", ".", "split", "(", "img_rgba", ",", "[", "3", "]", ",", "axis", "=", "2", ")", "\n", "return", "rgb", ".", "astype", "(", "\"uint8\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.__init__": [[348, 372], ["numpy.asarray().clip().astype", "visualizer.VisImage", "torch.device", "max", "detectron2.data.MetadataCatalog.get", "numpy.asarray().clip", "numpy.sqrt", "numpy.asarray"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "img_rgb", ",", "metadata", "=", "None", ",", "scale", "=", "1.0", ",", "instance_mode", "=", "ColorMode", ".", "IMAGE", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img_rgb: a numpy array of shape (H, W, C), where H and W correspond to\n                the height and width of the image respectively. C is the number of\n                color channels. The image is required to be in RGB format since that\n                is a requirement of the Matplotlib library. The image is also expected\n                to be in the range [0, 255].\n            metadata (Metadata): dataset metadata (e.g. class names and colors)\n            instance_mode (ColorMode): defines one of the pre-defined style for drawing\n                instances on an image.\n        \"\"\"", "\n", "self", ".", "img", "=", "np", ".", "asarray", "(", "img_rgb", ")", ".", "clip", "(", "0", ",", "255", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "if", "metadata", "is", "None", ":", "\n", "            ", "metadata", "=", "MetadataCatalog", ".", "get", "(", "\"__nonexist__\"", ")", "\n", "", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "output", "=", "VisImage", "(", "self", ".", "img", ",", "scale", "=", "scale", ")", "\n", "self", ".", "cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "# too small texts are useless, therefore clamp to 9", "\n", "self", ".", "_default_font_size", "=", "max", "(", "\n", "np", ".", "sqrt", "(", "self", ".", "output", ".", "height", "*", "self", ".", "output", ".", "width", ")", "//", "90", ",", "10", "//", "scale", "\n", ")", "\n", "self", ".", "_instance_mode", "=", "instance_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_instance_predictions": [[373, 423], ["visualizer._create_text_labels", "predictions.has", "visualizer.Visualizer.overlay_instances", "predictions.has", "predictions.has", "predictions.has", "predictions.pred_classes.tolist", "visualizer.Visualizer.metadata.get", "predictions.has", "numpy.asarray", "visualizer.Visualizer.metadata.get", "visualizer.Visualizer._create_grayscale_image", "visualizer.GenericMask", "visualizer.Visualizer._jitter", "predictions.has", "predictions.pred_masks.any"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._create_grayscale_image", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._jitter"], ["", "def", "draw_instance_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Draw instance-level prediction results on an image.\n\n        Args:\n            predictions (Instances): the output of an instance detection/segmentation\n                model. Following fields will be used to draw:\n                \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\" (or \"pred_masks_rle\").\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "\n", "# colors_list = ['r',(0,1,0),'k','b','w','y','c','m']", "\n", "colors_list", "=", "[", "'r'", ",", "(", "0", ",", "1", ",", "0", ")", ",", "(", "0.07", ",", "0.5", ",", "1", ")", ",", "'b'", ",", "(", "1", ",", "0.41", ",", "0.71", ")", ",", "'y'", ",", "'c'", ",", "'m'", "]", "\n", "# colors_list = [(0,1,0),(0.07,0.5,1),'b','w','y','c','m']", "\n", "boxes", "=", "predictions", ".", "pred_boxes", "if", "predictions", ".", "has", "(", "\"pred_boxes\"", ")", "else", "None", "\n", "scores", "=", "predictions", ".", "scores", "if", "predictions", ".", "has", "(", "\"scores\"", ")", "else", "None", "\n", "classes", "=", "predictions", ".", "pred_classes", ".", "tolist", "(", ")", "if", "predictions", ".", "has", "(", "\"pred_classes\"", ")", "else", "None", "\n", "\n", "colors", "=", "[", "colors_list", "[", "i", "]", "for", "i", "in", "classes", "]", "\n", "\n", "labels", "=", "_create_text_labels", "(", "classes", ",", "scores", ",", "self", ".", "metadata", ".", "get", "(", "\"thing_classes\"", ",", "None", ")", ")", "\n", "keypoints", "=", "predictions", ".", "pred_keypoints", "if", "predictions", ".", "has", "(", "\"pred_keypoints\"", ")", "else", "None", "\n", "\n", "if", "predictions", ".", "has", "(", "\"pred_masks\"", ")", ":", "\n", "            ", "masks", "=", "np", ".", "asarray", "(", "predictions", ".", "pred_masks", ")", "\n", "masks", "=", "[", "GenericMask", "(", "x", ",", "self", ".", "output", ".", "height", ",", "self", ".", "output", ".", "width", ")", "for", "x", "in", "masks", "]", "\n", "", "else", ":", "\n", "            ", "masks", "=", "None", "\n", "\n", "", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "SEGMENTATION", "and", "self", ".", "metadata", ".", "get", "(", "\"thing_colors\"", ")", ":", "\n", "# colors = [", "\n", "#     self._jitter([x / 255 for x in self.metadata.thing_colors[c]]) for c in classes", "\n", "# ]", "\n", "            ", "alpha", "=", "0.8", "\n", "", "else", ":", "\n", "# colors = None", "\n", "            ", "alpha", "=", "0.5", "\n", "\n", "", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "            ", "self", ".", "output", ".", "img", "=", "self", ".", "_create_grayscale_image", "(", "\n", "(", "predictions", ".", "pred_masks", ".", "any", "(", "dim", "=", "0", ")", ">", "0", ")", ".", "numpy", "(", ")", "\n", "if", "predictions", ".", "has", "(", "\"pred_masks\"", ")", "\n", "else", "None", "\n", ")", "\n", "\n", "", "alpha", "=", "1", "\n", "self", ".", "overlay_instances", "(", "\n", "masks", "=", "masks", ",", "\n", "boxes", "=", "boxes", ",", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_proposal_predictions": [[423, 473], ["visualizer._create_text_labels", "predictions.has", "visualizer.Visualizer.overlay_instances", "predictions.has", "predictions.has", "predictions.has", "predictions.pred_classes.tolist", "visualizer.Visualizer.metadata.get", "predictions.has", "numpy.asarray", "visualizer.Visualizer.metadata.get", "visualizer.Visualizer._create_grayscale_image", "visualizer.GenericMask", "visualizer.Visualizer._jitter", "predictions.has", "predictions.pred_masks.any"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._create_grayscale_image", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._jitter"], ["boxes", "=", "boxes", ",", "\n", "labels", "=", "labels", ",", "\n", "keypoints", "=", "keypoints", ",", "\n", "assigned_colors", "=", "colors", ",", "\n", "alpha", "=", "alpha", "\n", ")", "\n", "return", "self", ".", "output", "\n", "", "def", "draw_proposal_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Draw instance-level prediction results on an image.\n\n        Args:\n            predictions (Instances): the output of an instance detection/segmentation\n                model. Following fields will be used to draw:\n                \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\" (or \"pred_masks_rle\").\n            objectness_logits,proposal_boxes\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "# predictions_s = predictions[0]", "\n", "# predictions_t = predictions[1:]", "\n", "\n", "\n", "boxes", "=", "predictions", ".", "proposal_boxes", "if", "predictions", ".", "has", "(", "\"proposal_boxes\"", ")", "else", "None", "\n", "scores", "=", "predictions", ".", "objectness_logits", "if", "predictions", ".", "has", "(", "\"objectness_logits\"", ")", "else", "None", "\n", "classes", "=", "predictions", ".", "pred_classes", ".", "tolist", "(", ")", "if", "predictions", ".", "has", "(", "\"pred_classes\"", ")", "else", "None", "\n", "# labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))", "\n", "keypoints", "=", "predictions", ".", "pred_keypoints", "if", "predictions", ".", "has", "(", "\"pred_keypoints\"", ")", "else", "None", "\n", "# labels = [\"1\",\"2\",\"3\",\"s\"]", "\n", "labels", "=", "[", "\"1\"", ",", "\"2\"", ",", "\"3\"", "]", "\n", "# labels = [\"s\"]", "\n", "\n", "#", "\n", "# boxes_s = predictions_s.proposal_boxes if predictions_s.has(\"proposal_boxes\") else None", "\n", "# scores_s = predictions_s.objectness_logits if predictions_s.has(\"objectness_logits\") else None", "\n", "# classes_s = predictions_s.pred_classes.tolist() if predictions_s.has(\"pred_classes\") else None", "\n", "# labels_s = _create_text_labels(classes_s, scores_s, self.metadata.get(\"thing_classes\", None))", "\n", "# keypoints_s = predictions_s.pred_keypoints if predictions_s.has(\"pred_keypoints\") else None", "\n", "#", "\n", "#", "\n", "# boxes_t = predictions_t.proposal_boxes if predictions_t.has(\"proposal_boxes\") else None", "\n", "# scores_t = predictions_t.objectness_logits if predictions_t.has(\"objectness_logits\") else None", "\n", "# classes_t = predictions_t.pred_classes.tolist() if predictions_t.has(\"pred_classes\") else None", "\n", "# labels_t = _create_text_labels(classes_t, scores_t, self.metadata.get(\"thing_classes\", None))", "\n", "# keypoints_t = predictions_t.pred_keypoints if predictions_t.has(\"pred_keypoints\") else None", "\n", "\n", "\n", "if", "predictions", ".", "has", "(", "\"pred_masks\"", ")", ":", "\n", "            ", "masks", "=", "np", ".", "asarray", "(", "predictions", ".", "pred_masks", ")", "\n", "masks", "=", "[", "GenericMask", "(", "x", ",", "self", ".", "output", ".", "height", ",", "self", ".", "output", ".", "width", ")", "for", "x", "in", "masks", "]", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_sem_seg": [[473, 508], ["isinstance", "numpy.unique", "numpy.argsort().tolist", "filter", "sem_seg.numpy.numpy.numpy", "visualizer.Visualizer.draw_binary_mask", "numpy.argsort", "len"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_binary_mask"], ["", "else", ":", "\n", "            ", "masks", "=", "None", "\n", "\n", "", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "SEGMENTATION", "and", "self", ".", "metadata", ".", "get", "(", "\"thing_colors\"", ")", ":", "\n", "            ", "colors", "=", "[", "\n", "self", ".", "_jitter", "(", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "thing_colors", "[", "c", "]", "]", ")", "for", "c", "in", "classes", "\n", "]", "\n", "alpha", "=", "0.8", "\n", "", "else", ":", "\n", "            ", "colors", "=", "None", "\n", "alpha", "=", "1", "\n", "\n", "colors", "=", "[", "'green'", ",", "'green'", ",", "'green'", ",", "'red'", "]", "\n", "# colors = ['red']", "\n", "\n", "\n", "", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "            ", "self", ".", "output", ".", "img", "=", "self", ".", "_create_grayscale_image", "(", "\n", "(", "predictions", ".", "pred_masks", ".", "any", "(", "dim", "=", "0", ")", ">", "0", ")", ".", "numpy", "(", ")", "\n", "if", "predictions", ".", "has", "(", "\"pred_masks\"", ")", "\n", "else", "None", "\n", ")", "\n", "", "alpha", "=", "1", "\n", "\n", "self", ".", "overlay_instances", "(", "\n", "masks", "=", "masks", ",", "\n", "boxes", "=", "boxes", ",", "\n", "labels", "=", "labels", ",", "\n", "keypoints", "=", "keypoints", ",", "\n", "assigned_colors", "=", "colors", ",", "\n", "alpha", "=", "alpha", ",", "\n", ")", "\n", "\n", "return", "self", ".", "output", "\n", "", "def", "draw_sem_seg", "(", "self", ",", "sem_seg", ",", "area_threshold", "=", "None", ",", "alpha", "=", "0.8", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_panoptic_seg": [[509, 572], ["visualizer._PanopticPrediction", "visualizer._PanopticPrediction.semantic_masks", "list", "list", "visualizer._create_text_labels", "visualizer.Visualizer.overlay_instances", "visualizer.Visualizer._create_grayscale_image", "visualizer.Visualizer.draw_binary_mask", "visualizer._PanopticPrediction.instance_masks", "len", "zip", "visualizer._PanopticPrediction.non_empty_mask", "x.get", "visualizer.Visualizer._jitter"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._PanopticPrediction.semantic_masks", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._create_grayscale_image", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_binary_mask", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._PanopticPrediction.instance_masks", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._PanopticPrediction.non_empty_mask", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._jitter"], ["\n", "if", "isinstance", "(", "sem_seg", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "sem_seg", "=", "sem_seg", ".", "numpy", "(", ")", "\n", "", "labels", ",", "areas", "=", "np", ".", "unique", "(", "sem_seg", ",", "return_counts", "=", "True", ")", "\n", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", ".", "tolist", "(", ")", "\n", "labels", "=", "labels", "[", "sorted_idxs", "]", "\n", "for", "label", "in", "filter", "(", "lambda", "l", ":", "l", "<", "len", "(", "self", ".", "metadata", ".", "stuff_classes", ")", ",", "labels", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "mask_color", "=", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "stuff_colors", "[", "label", "]", "]", "\n", "", "except", "(", "AttributeError", ",", "IndexError", ")", ":", "\n", "                ", "mask_color", "=", "None", "\n", "\n", "", "binary_mask", "=", "(", "sem_seg", "==", "label", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "text", "=", "self", ".", "metadata", ".", "stuff_classes", "[", "label", "]", "\n", "self", ".", "draw_binary_mask", "(", "\n", "binary_mask", ",", "\n", "color", "=", "mask_color", ",", "\n", "edge_color", "=", "_OFF_WHITE", ",", "\n", "text", "=", "text", ",", "\n", "alpha", "=", "alpha", ",", "\n", "area_threshold", "=", "area_threshold", ",", "\n", ")", "\n", "", "return", "self", ".", "output", "\n", "\n", "", "def", "draw_panoptic_seg", "(", "self", ",", "panoptic_seg", ",", "segments_info", ",", "area_threshold", "=", "None", ",", "alpha", "=", "0.7", ")", ":", "\n", "        ", "\"\"\"\n        Draw panoptic prediction annotations or results.\n\n        Args:\n            panoptic_seg (Tensor): of shape (height, width) where the values are ids for each\n                segment.\n            segments_info (list[dict] or None): Describe each segment in `panoptic_seg`.\n                If it is a ``list[dict]``, each dict contains keys \"id\", \"category_id\".\n                If None, category id of each pixel is computed by\n                ``pixel // metadata.label_divisor``.\n            area_threshold (int): stuff segments with less than `area_threshold` are not drawn.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "pred", "=", "_PanopticPrediction", "(", "panoptic_seg", ",", "segments_info", ",", "self", ".", "metadata", ")", "\n", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "            ", "self", ".", "output", ".", "img", "=", "self", ".", "_create_grayscale_image", "(", "pred", ".", "non_empty_mask", "(", ")", ")", "\n", "\n", "# draw mask for all semantic segments first i.e. \"stuff\"", "\n", "", "for", "mask", ",", "sinfo", "in", "pred", ".", "semantic_masks", "(", ")", ":", "\n", "            ", "category_idx", "=", "sinfo", "[", "\"category_id\"", "]", "\n", "try", ":", "\n", "                ", "mask_color", "=", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "stuff_colors", "[", "category_idx", "]", "]", "\n", "", "except", "AttributeError", ":", "\n", "                ", "mask_color", "=", "None", "\n", "\n", "", "text", "=", "self", ".", "metadata", ".", "stuff_classes", "[", "category_idx", "]", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_dataset_dict": [[575, 643], ["dic.get", "dic.get", "dic.get", "visualizer.Visualizer.metadata.get", "visualizer._create_text_labels", "visualizer.Visualizer.overlay_instances", "visualizer.Visualizer.draw_sem_seg", "torch.tensor", "visualizer.Visualizer.draw_panoptic_seg", "numpy.array().reshape", "visualizer.Visualizer.metadata.get", "detectron2.utils.file_io.PathManager.open", "PIL.Image.open", "numpy.asarray", "detectron2.utils.file_io.PathManager.open", "PIL.Image.open", "numpy.asarray", "rgb2id", "len", "detectron2.structures.BoxMode.convert", "visualizer.Visualizer._jitter", "numpy.array", "len", "x.get"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.video_visualizer.VideoVisualizer.draw_sem_seg", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_panoptic_seg", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._jitter"], ["color", "=", "mask_color", ",", "\n", "edge_color", "=", "_OFF_WHITE", ",", "\n", "text", "=", "text", ",", "\n", "alpha", "=", "alpha", ",", "\n", "area_threshold", "=", "area_threshold", ",", "\n", ")", "\n", "\n", "# draw mask for all instances second", "\n", "", "all_instances", "=", "list", "(", "pred", ".", "instance_masks", "(", ")", ")", "\n", "if", "len", "(", "all_instances", ")", "==", "0", ":", "\n", "            ", "return", "self", ".", "output", "\n", "", "masks", ",", "sinfo", "=", "list", "(", "zip", "(", "*", "all_instances", ")", ")", "\n", "category_ids", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "sinfo", "]", "\n", "\n", "try", ":", "\n", "            ", "scores", "=", "[", "x", "[", "\"score\"", "]", "for", "x", "in", "sinfo", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "scores", "=", "None", "\n", "", "labels", "=", "_create_text_labels", "(", "\n", "category_ids", ",", "scores", ",", "self", ".", "metadata", ".", "thing_classes", ",", "[", "x", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", "for", "x", "in", "sinfo", "]", "\n", ")", "\n", "\n", "try", ":", "\n", "            ", "colors", "=", "[", "\n", "self", ".", "_jitter", "(", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "thing_colors", "[", "c", "]", "]", ")", "for", "c", "in", "category_ids", "\n", "]", "\n", "", "except", "AttributeError", ":", "\n", "            ", "colors", "=", "None", "\n", "", "self", ".", "overlay_instances", "(", "masks", "=", "masks", ",", "labels", "=", "labels", ",", "assigned_colors", "=", "colors", ",", "alpha", "=", "alpha", ")", "\n", "\n", "return", "self", ".", "output", "\n", "\n", "", "draw_panoptic_seg_predictions", "=", "draw_panoptic_seg", "# backward compatibility", "\n", "\n", "def", "draw_dataset_dict", "(", "self", ",", "dic", ")", ":", "\n", "        ", "\"\"\"\n        Draw annotations/segmentaions in Detectron2 Dataset format.\n\n        Args:\n            dic (dict): annotation/segmentation data of one image, in Detectron2 Dataset format.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "annos", "=", "dic", ".", "get", "(", "\"annotations\"", ",", "None", ")", "\n", "if", "annos", ":", "\n", "            ", "if", "\"segmentation\"", "in", "annos", "[", "0", "]", ":", "\n", "                ", "masks", "=", "[", "x", "[", "\"segmentation\"", "]", "for", "x", "in", "annos", "]", "\n", "", "else", ":", "\n", "                ", "masks", "=", "None", "\n", "", "if", "\"keypoints\"", "in", "annos", "[", "0", "]", ":", "\n", "                ", "keypts", "=", "[", "x", "[", "\"keypoints\"", "]", "for", "x", "in", "annos", "]", "\n", "keypts", "=", "np", ".", "array", "(", "keypts", ")", ".", "reshape", "(", "len", "(", "annos", ")", ",", "-", "1", ",", "3", ")", "\n", "", "else", ":", "\n", "                ", "keypts", "=", "None", "\n", "\n", "", "boxes", "=", "[", "\n", "BoxMode", ".", "convert", "(", "x", "[", "\"bbox\"", "]", ",", "x", "[", "\"bbox_mode\"", "]", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "if", "len", "(", "x", "[", "\"bbox\"", "]", ")", "==", "4", "\n", "else", "x", "[", "\"bbox\"", "]", "\n", "for", "x", "in", "annos", "\n", "]", "\n", "\n", "colors", "=", "None", "\n", "category_ids", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "annos", "]", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "SEGMENTATION", "and", "self", ".", "metadata", ".", "get", "(", "\"thing_colors\"", ")", ":", "\n", "                ", "colors", "=", "[", "\n", "self", ".", "_jitter", "(", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "thing_colors", "[", "c", "]", "]", ")", "\n", "for", "c", "in", "category_ids", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.overlay_instances": [[644, 789], ["pdb.set_trace", "range", "visualizer.Visualizer._convert_boxes", "len", "visualizer.Visualizer._convert_masks", "visualizer.Visualizer._convert_keypoints", "visualizer.Visualizer.overlay_rotated_instances", "numpy.prod", "numpy.argsort().tolist", "len", "len", "len", "colormap.random_color", "numpy.asarray", "visualizer.Visualizer.draw_box", "visualizer.Visualizer._change_color_brightness", "visualizer.Visualizer.draw_text", "visualizer.Visualizer.draw_and_connect_keypoints", "len", "len", "range", "numpy.argsort", "visualizer.Visualizer.draw_polygon", "numpy.sqrt", "x.area", "segment.reshape", "masks[].bbox", "numpy.clip", "len", "numpy.median", "masks[].mask.nonzero"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._convert_boxes", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._convert_masks", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._convert_keypoints", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.overlay_rotated_instances", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.colormap.random_color", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_box", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._change_color_brightness", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_text", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_and_connect_keypoints", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_polygon", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.area", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.bbox"], ["]", "\n", "", "names", "=", "self", ".", "metadata", ".", "get", "(", "\"thing_classes\"", ",", "None", ")", "\n", "labels", "=", "_create_text_labels", "(", "\n", "category_ids", ",", "\n", "scores", "=", "None", ",", "\n", "class_names", "=", "names", ",", "\n", "is_crowd", "=", "[", "x", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", "for", "x", "in", "annos", "]", ",", "\n", ")", "\n", "self", ".", "overlay_instances", "(", "\n", "labels", "=", "labels", ",", "boxes", "=", "boxes", ",", "masks", "=", "masks", ",", "keypoints", "=", "keypts", ",", "assigned_colors", "=", "colors", "\n", ")", "\n", "\n", "", "sem_seg", "=", "dic", ".", "get", "(", "\"sem_seg\"", ",", "None", ")", "\n", "if", "sem_seg", "is", "None", "and", "\"sem_seg_file_name\"", "in", "dic", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "dic", "[", "\"sem_seg_file_name\"", "]", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "sem_seg", "=", "Image", ".", "open", "(", "f", ")", "\n", "sem_seg", "=", "np", ".", "asarray", "(", "sem_seg", ",", "dtype", "=", "\"uint8\"", ")", "\n", "", "", "if", "sem_seg", "is", "not", "None", ":", "\n", "            ", "self", ".", "draw_sem_seg", "(", "sem_seg", ",", "area_threshold", "=", "0", ",", "alpha", "=", "0.5", ")", "\n", "\n", "", "pan_seg", "=", "dic", ".", "get", "(", "\"pan_seg\"", ",", "None", ")", "\n", "if", "pan_seg", "is", "None", "and", "\"pan_seg_file_name\"", "in", "dic", ":", "\n", "            ", "with", "PathManager", ".", "open", "(", "dic", "[", "\"pan_seg_file_name\"", "]", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "pan_seg", "=", "Image", ".", "open", "(", "f", ")", "\n", "pan_seg", "=", "np", ".", "asarray", "(", "pan_seg", ")", "\n", "from", "panopticapi", ".", "utils", "import", "rgb2id", "\n", "\n", "pan_seg", "=", "rgb2id", "(", "pan_seg", ")", "\n", "", "", "if", "pan_seg", "is", "not", "None", ":", "\n", "            ", "segments_info", "=", "dic", "[", "\"segments_info\"", "]", "\n", "pan_seg", "=", "torch", ".", "tensor", "(", "pan_seg", ")", "\n", "self", ".", "draw_panoptic_seg", "(", "pan_seg", ",", "segments_info", ",", "area_threshold", "=", "0", ",", "alpha", "=", "0.5", ")", "\n", "", "return", "self", ".", "output", "\n", "\n", "", "def", "overlay_instances", "(", "\n", "self", ",", "\n", "*", ",", "\n", "boxes", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "masks", "=", "None", ",", "\n", "keypoints", "=", "None", ",", "\n", "assigned_colors", "=", "None", ",", "\n", "alpha", "=", "0.5", ",", "\n", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            boxes (Boxes, RotatedBoxes or ndarray): either a :class:`Boxes`,\n                or an Nx4 numpy array of XYXY_ABS format for the N objects in a single image,\n                or a :class:`RotatedBoxes`,\n                or an Nx5 numpy array of (x_center, y_center, width, height, angle_degrees) format\n                for the N objects in a single image,\n            labels (list[str]): the text to be displayed for each instance.\n            masks (masks-like object): Supported types are:\n\n                * :class:`detectron2.structures.PolygonMasks`,\n                  :class:`detectron2.structures.BitMasks`.\n                * list[list[ndarray]]: contains the segmentation masks for all objects in one image.\n                  The first level of the list corresponds to individual instances. The second\n                  level to all the polygon that compose the instance, and the third level\n                  to the polygon coordinates. The third level should have the format of\n                  [x0, y0, x1, y1, ..., xn, yn] (n >= 3).\n                * list[ndarray]: each ndarray is a binary mask of shape (H, W).\n                * list[dict]: each dict is a COCO-style RLE.\n            keypoints (Keypoint or array like): an array-like object of shape (N, K, 3),\n                where the N is the number of instances and K is the number of keypoints.\n                The last dimension corresponds to (x, y, visibility or score).\n            assigned_colors (list[matplotlib.colors]): a list of colors, where each color\n                corresponds to each mask or box in the image. Refer to 'matplotlib.colors'\n                for full list of formats that the colors are accepted in.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "num_instances", "=", "0", "\n", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "boxes", "=", "self", ".", "_convert_boxes", "(", "boxes", ")", "\n", "num_instances", "=", "len", "(", "boxes", ")", "\n", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "", "if", "masks", "is", "not", "None", ":", "\n", "            ", "masks", "=", "self", ".", "_convert_masks", "(", "masks", ")", "\n", "if", "num_instances", ":", "\n", "                ", "assert", "len", "(", "masks", ")", "==", "num_instances", "\n", "", "else", ":", "\n", "                ", "num_instances", "=", "len", "(", "masks", ")", "\n", "", "", "if", "keypoints", "is", "not", "None", ":", "\n", "            ", "if", "num_instances", ":", "\n", "                ", "assert", "len", "(", "keypoints", ")", "==", "num_instances", "\n", "", "else", ":", "\n", "                ", "num_instances", "=", "len", "(", "keypoints", ")", "\n", "", "keypoints", "=", "self", ".", "_convert_keypoints", "(", "keypoints", ")", "\n", "", "if", "labels", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "labels", ")", "==", "num_instances", "\n", "", "if", "assigned_colors", "is", "None", ":", "\n", "\n", "            ", "assigned_colors", "=", "[", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "for", "_", "in", "range", "(", "num_instances", ")", "]", "\n", "", "if", "num_instances", "==", "0", ":", "\n", "            ", "return", "self", ".", "output", "\n", "", "if", "boxes", "is", "not", "None", "and", "boxes", ".", "shape", "[", "1", "]", "==", "5", ":", "\n", "            ", "return", "self", ".", "overlay_rotated_instances", "(", "\n", "boxes", "=", "boxes", ",", "labels", "=", "labels", ",", "assigned_colors", "=", "assigned_colors", "\n", ")", "\n", "\n", "# Display in largest to smallest order to reduce occlusion.", "\n", "", "areas", "=", "None", "\n", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "areas", "=", "np", ".", "prod", "(", "boxes", "[", ":", ",", "2", ":", "]", "-", "boxes", "[", ":", ",", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "", "elif", "masks", "is", "not", "None", ":", "\n", "            ", "areas", "=", "np", ".", "asarray", "(", "[", "x", ".", "area", "(", ")", "for", "x", "in", "masks", "]", ")", "\n", "\n", "", "if", "areas", "is", "not", "None", ":", "\n", "            ", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", ".", "tolist", "(", ")", "\n", "# Re-order overlapped instances in descending order.", "\n", "boxes", "=", "boxes", "[", "sorted_idxs", "]", "if", "boxes", "is", "not", "None", "else", "None", "\n", "# labels = [labels[k] for k in sorted_idxs] if labels is not None else None", "\n", "labels", "=", "[", "labels", "[", "k", "]", ".", "split", "(", "\" \"", ")", "[", "0", "]", "for", "k", "in", "sorted_idxs", "]", "if", "labels", "is", "not", "None", "else", "None", "\n", "\n", "masks", "=", "[", "masks", "[", "idx", "]", "for", "idx", "in", "sorted_idxs", "]", "if", "masks", "is", "not", "None", "else", "None", "\n", "assigned_colors", "=", "[", "assigned_colors", "[", "idx", "]", "for", "idx", "in", "sorted_idxs", "]", "\n", "keypoints", "=", "keypoints", "[", "sorted_idxs", "]", "if", "keypoints", "is", "not", "None", "else", "None", "\n", "\n", "", "cls_name", "=", "[", "'pedestrian'", ",", "'car'", ",", "'train'", ",", "'rider'", ",", "'truck'", ",", "'motorcycle'", ",", "'bicycle'", ",", "'bus'", "]", "\n", "colors_list", "=", "[", "'r'", ",", "(", "0", ",", "1", ",", "0", ")", ",", "'k'", ",", "'b'", ",", "(", "1", ",", "0.41", ",", "0.71", ")", ",", "'y'", ",", "'c'", ",", "'m'", "]", "\n", "\n", "\n", "\n", "\n", "for", "i", "in", "range", "(", "num_instances", ")", ":", "\n", "            ", "color", "=", "assigned_colors", "[", "i", "]", "\n", "if", "boxes", "is", "not", "None", ":", "\n", "                ", "self", ".", "draw_box", "(", "boxes", "[", "i", "]", ",", "edge_color", "=", "color", ")", "\n", "", "if", "masks", "is", "not", "None", ":", "\n", "                ", "for", "segment", "in", "masks", "[", "i", "]", ".", "polygons", ":", "\n", "                    ", "self", ".", "draw_polygon", "(", "segment", ".", "reshape", "(", "-", "1", ",", "2", ")", ",", "color", ",", "alpha", "=", "alpha", ")", "\n", "\n", "", "", "if", "labels", "is", "not", "None", ":", "\n", "# first get a box", "\n", "                ", "if", "boxes", "is", "not", "None", ":", "\n", "                    ", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "boxes", "[", "i", "]", "\n", "text_pos", "=", "(", "x0", ",", "y0", ")", "# if drawing boxes, put text on the box corner.", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.overlay_rotated_instances": [[790, 827], ["len", "numpy.argsort().tolist", "range", "visualizer.Visualizer.draw_rotated_box_with_label", "colormap.random_color", "numpy.argsort", "range"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_rotated_box_with_label", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.colormap.random_color"], ["horiz_align", "=", "\"left\"", "\n", "", "elif", "masks", "is", "not", "None", ":", "\n", "# skip small mask without polygon", "\n", "                    ", "if", "len", "(", "masks", "[", "i", "]", ".", "polygons", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "masks", "[", "i", "]", ".", "bbox", "(", ")", "\n", "\n", "# draw text in the center (defined by median) when box is not drawn", "\n", "# median is less sensitive to outliers.", "\n", "text_pos", "=", "np", ".", "median", "(", "masks", "[", "i", "]", ".", "mask", ".", "nonzero", "(", ")", ",", "axis", "=", "1", ")", "[", ":", ":", "-", "1", "]", "\n", "horiz_align", "=", "\"center\"", "\n", "", "else", ":", "\n", "                    ", "continue", "# drawing the box confidence for keypoints isn't very useful.", "\n", "# for small objects, draw text at the side to avoid occlusion", "\n", "", "instance_area", "=", "(", "y1", "-", "y0", ")", "*", "(", "x1", "-", "x0", ")", "\n", "if", "(", "\n", "instance_area", "<", "_SMALL_OBJECT_AREA_THRESH", "*", "self", ".", "output", ".", "scale", "\n", "or", "y1", "-", "y0", "<", "40", "*", "self", ".", "output", ".", "scale", "\n", ")", ":", "\n", "                    ", "if", "y1", ">=", "self", ".", "output", ".", "height", "-", "5", ":", "\n", "                        ", "text_pos", "=", "(", "x1", ",", "y0", ")", "\n", "", "else", ":", "\n", "                        ", "text_pos", "=", "(", "x0", ",", "y1", ")", "\n", "\n", "", "", "height_ratio", "=", "(", "y1", "-", "y0", ")", "/", "np", ".", "sqrt", "(", "self", ".", "output", ".", "height", "*", "self", ".", "output", ".", "width", ")", "\n", "lighter_color", "=", "self", ".", "_change_color_brightness", "(", "color", ",", "brightness_factor", "=", "0.7", ")", "\n", "font_size", "=", "(", "\n", "np", ".", "clip", "(", "(", "height_ratio", "-", "0.02", ")", "/", "0.08", "+", "1", ",", "1.2", ",", "2", ")", "\n", "*", "0.7", "\n", "*", "self", ".", "_default_font_size", "\n", ")", "\n", "\n", "\n", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "self", ".", "draw_text", "(", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_and_connect_keypoints": [[828, 885], ["visualizer.Visualizer.metadata.get", "enumerate", "visualizer.Visualizer.metadata.get", "visible.get", "visualizer.Visualizer.draw_circle", "visualizer.Visualizer.draw_line", "visualizer.Visualizer.draw_line", "tuple", "visualizer.Visualizer.draw_line"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_circle", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_line", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_line", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_line"], ["labels", "[", "i", "]", ",", "\n", "text_pos", ",", "\n", "color", "=", "lighter_color", ",", "\n", "horizontal_alignment", "=", "horiz_align", ",", "\n", "font_size", "=", "font_size", ",", "\n", ")", "\n", "\n", "# draw keypoints", "\n", "", "", "if", "keypoints", "is", "not", "None", ":", "\n", "            ", "for", "keypoints_per_instance", "in", "keypoints", ":", "\n", "                ", "self", ".", "draw_and_connect_keypoints", "(", "keypoints_per_instance", ")", "\n", "\n", "", "", "return", "self", ".", "output", "\n", "\n", "", "def", "overlay_rotated_instances", "(", "self", ",", "boxes", "=", "None", ",", "labels", "=", "None", ",", "assigned_colors", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            boxes (ndarray): an Nx5 numpy array of\n                (x_center, y_center, width, height, angle_degrees) format\n                for the N objects in a single image.\n            labels (list[str]): the text to be displayed for each instance.\n            assigned_colors (list[matplotlib.colors]): a list of colors, where each color\n                corresponds to each mask or box in the image. Refer to 'matplotlib.colors'\n                for full list of formats that the colors are accepted in.\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "num_instances", "=", "len", "(", "boxes", ")", "\n", "\n", "if", "assigned_colors", "is", "None", ":", "\n", "            ", "assigned_colors", "=", "[", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "for", "_", "in", "range", "(", "num_instances", ")", "]", "\n", "", "if", "num_instances", "==", "0", ":", "\n", "            ", "return", "self", ".", "output", "\n", "\n", "# Display in largest to smallest order to reduce occlusion.", "\n", "", "if", "boxes", "is", "not", "None", ":", "\n", "            ", "areas", "=", "boxes", "[", ":", ",", "2", "]", "*", "boxes", "[", ":", ",", "3", "]", "\n", "\n", "", "sorted_idxs", "=", "np", ".", "argsort", "(", "-", "areas", ")", ".", "tolist", "(", ")", "\n", "# Re-order overlapped instances in descending order.", "\n", "boxes", "=", "boxes", "[", "sorted_idxs", "]", "\n", "labels", "=", "[", "labels", "[", "k", "]", "for", "k", "in", "sorted_idxs", "]", "if", "labels", "is", "not", "None", "else", "None", "\n", "colors", "=", "[", "assigned_colors", "[", "idx", "]", "for", "idx", "in", "sorted_idxs", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_instances", ")", ":", "\n", "            ", "self", ".", "draw_rotated_box_with_label", "(", "\n", "boxes", "[", "i", "]", ",", "edge_color", "=", "colors", "[", "i", "]", ",", "label", "=", "labels", "[", "i", "]", "if", "labels", "is", "not", "None", "else", "None", "\n", ")", "\n", "\n", "", "return", "self", ".", "output", "\n", "\n", "", "def", "draw_and_connect_keypoints", "(", "self", ",", "keypoints", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_text": [[890, 936], ["numpy.maximum", "max", "visualizer.Visualizer.output.ax.text", "list", "numpy.max", "matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "numpy.argmax"], "methods", ["None"], ["\n", "visible", "=", "{", "}", "\n", "keypoint_names", "=", "self", ".", "metadata", ".", "get", "(", "\"keypoint_names\"", ")", "\n", "for", "idx", ",", "keypoint", "in", "enumerate", "(", "keypoints", ")", ":", "\n", "# draw keypoint", "\n", "            ", "x", ",", "y", ",", "prob", "=", "keypoint", "\n", "if", "prob", ">", "_KEYPOINT_THRESHOLD", ":", "\n", "                ", "self", ".", "draw_circle", "(", "(", "x", ",", "y", ")", ",", "color", "=", "_RED", ")", "\n", "if", "keypoint_names", ":", "\n", "                    ", "keypoint_name", "=", "keypoint_names", "[", "idx", "]", "\n", "visible", "[", "keypoint_name", "]", "=", "(", "x", ",", "y", ")", "\n", "\n", "", "", "", "if", "self", ".", "metadata", ".", "get", "(", "\"keypoint_connection_rules\"", ")", ":", "\n", "            ", "for", "kp0", ",", "kp1", ",", "color", "in", "self", ".", "metadata", ".", "keypoint_connection_rules", ":", "\n", "                ", "if", "kp0", "in", "visible", "and", "kp1", "in", "visible", ":", "\n", "                    ", "x0", ",", "y0", "=", "visible", "[", "kp0", "]", "\n", "x1", ",", "y1", "=", "visible", "[", "kp1", "]", "\n", "color", "=", "tuple", "(", "x", "/", "255.0", "for", "x", "in", "color", ")", "\n", "self", ".", "draw_line", "(", "[", "x0", ",", "x1", "]", ",", "[", "y0", ",", "y1", "]", ",", "color", "=", "color", ")", "\n", "\n", "# draw lines from nose to mid-shoulder and mid-shoulder to mid-hip", "\n", "# Note that this strategy is specific to person keypoints.", "\n", "# For other keypoints, it should just do nothing", "\n", "", "", "", "try", ":", "\n", "            ", "ls_x", ",", "ls_y", "=", "visible", "[", "\"left_shoulder\"", "]", "\n", "rs_x", ",", "rs_y", "=", "visible", "[", "\"right_shoulder\"", "]", "\n", "mid_shoulder_x", ",", "mid_shoulder_y", "=", "(", "ls_x", "+", "rs_x", ")", "/", "2", ",", "(", "ls_y", "+", "rs_y", ")", "/", "2", "\n", "", "except", "KeyError", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "# draw line from nose to mid-shoulder", "\n", "            ", "nose_x", ",", "nose_y", "=", "visible", ".", "get", "(", "\"nose\"", ",", "(", "None", ",", "None", ")", ")", "\n", "if", "nose_x", "is", "not", "None", ":", "\n", "                ", "self", ".", "draw_line", "(", "[", "nose_x", ",", "mid_shoulder_x", "]", ",", "[", "nose_y", ",", "mid_shoulder_y", "]", ",", "color", "=", "_RED", ")", "\n", "\n", "", "try", ":", "\n", "# draw line from mid-shoulder to mid-hip", "\n", "                ", "lh_x", ",", "lh_y", "=", "visible", "[", "\"left_hip\"", "]", "\n", "rh_x", ",", "rh_y", "=", "visible", "[", "\"right_hip\"", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "mid_hip_x", ",", "mid_hip_y", "=", "(", "lh_x", "+", "rh_x", ")", "/", "2", ",", "(", "lh_y", "+", "rh_y", ")", "/", "2", "\n", "self", ".", "draw_line", "(", "[", "mid_hip_x", ",", "mid_shoulder_x", "]", ",", "[", "mid_hip_y", ",", "mid_shoulder_y", "]", ",", "color", "=", "_RED", ")", "\n", "", "", "return", "self", ".", "output", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_box": [[937, 970], ["max", "visualizer.Visualizer.output.ax.add_patch", "matplotlib.patches.Rectangle", "matplotlib.patches.Rectangle", "matplotlib.patches.Rectangle"], "methods", ["None"], ["\n", "", "\"\"\"\n    Primitive drawing functions:\n    \"\"\"", "\n", "\n", "def", "draw_text", "(", "\n", "self", ",", "\n", "text", ",", "\n", "position", ",", "\n", "*", ",", "\n", "font_size", "=", "None", ",", "\n", "color", "=", "\"g\"", ",", "\n", "horizontal_alignment", "=", "\"center\"", ",", "\n", "rotation", "=", "0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            text (str): class label\n            position (tuple): a tuple of the x and y coordinates to place text on image.\n            font_size (int, optional): font of the text. If not provided, a font size\n                proportional to the image width is calculated and used.\n            color: color of the text. Refer to `matplotlib.colors` for full list\n                of formats that are accepted.\n            horizontal_alignment (str): see `matplotlib.text.Text`\n            rotation: rotation angle in degrees CCW\n\n        Returns:\n            output (VisImage): image object with text drawn.\n        \"\"\"", "\n", "if", "not", "font_size", ":", "\n", "            ", "font_size", "=", "self", ".", "_default_font_size", "\n", "\n", "# since the text background is dark, we don't want the text to be dark", "\n", "", "color", "=", "np", ".", "maximum", "(", "list", "(", "mplc", ".", "to_rgb", "(", "color", ")", ")", ",", "0.2", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_rotated_box_with_label": [[971, 1025], ["math.cos", "math.sin", "range", "visualizer.Visualizer.draw_line", "visualizer.Visualizer._change_color_brightness", "visualizer.Visualizer.draw_text", "numpy.sqrt", "numpy.clip"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_line", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._change_color_brightness", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_text"], ["color", "[", "np", ".", "argmax", "(", "color", ")", "]", "=", "max", "(", "0.8", ",", "np", ".", "max", "(", "color", ")", ")", "\n", "\n", "x", ",", "y", "=", "position", "\n", "self", ".", "output", ".", "ax", ".", "text", "(", "\n", "x", ",", "\n", "y", ",", "\n", "text", ",", "\n", "size", "=", "font_size", "*", "self", ".", "output", ".", "scale", ",", "\n", "family", "=", "\"sans-serif\"", ",", "\n", "bbox", "=", "{", "\"facecolor\"", ":", "\"black\"", ",", "\"alpha\"", ":", "0.5", ",", "\"pad\"", ":", "0.7", ",", "\"edgecolor\"", ":", "\"none\"", "}", ",", "\n", "verticalalignment", "=", "\"top\"", ",", "\n", "horizontalalignment", "=", "horizontal_alignment", ",", "\n", "color", "=", "color", ",", "\n", "zorder", "=", "10", ",", "\n", "rotation", "=", "rotation", ",", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n", "", "def", "draw_box", "(", "self", ",", "box_coord", ",", "alpha", "=", "1", ",", "edge_color", "=", "\"g\"", ",", "line_style", "=", "\"-\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            box_coord (tuple): a tuple containing x0, y0, x1, y1 coordinates, where x0 and y0\n                are the coordinates of the image's top left corner. x1 and y1 are the\n                coordinates of the image's bottom right corner.\n            alpha (float): blending efficient. Smaller values lead to more transparent masks.\n            edge_color: color of the outline of the box. Refer to `matplotlib.colors`\n                for full list of formats that are accepted.\n            line_style (string): the string to use to create the outline of the boxes.\n\n        Returns:\n            output (VisImage): image object with box drawn.\n        \"\"\"", "\n", "x0", ",", "y0", ",", "x1", ",", "y1", "=", "box_coord", "\n", "width", "=", "x1", "-", "x0", "\n", "height", "=", "y1", "-", "y0", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "# linewidth = max(self._default_font_size / 4, 1)", "\n", "linewidth", "=", "3", "\n", "self", ".", "output", ".", "ax", ".", "add_patch", "(", "\n", "mpl", ".", "patches", ".", "Rectangle", "(", "\n", "(", "x0", ",", "y0", ")", ",", "\n", "width", ",", "\n", "height", ",", "\n", "fill", "=", "False", ",", "\n", "edgecolor", "=", "edge_color", ",", "\n", "linewidth", "=", "linewidth", "*", "self", ".", "output", ".", "scale", ",", "\n", "alpha", "=", "alpha", ",", "\n", "linestyle", "=", "line_style", ",", "\n", ")", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n", "", "def", "draw_rotated_box_with_label", "(", "\n", "self", ",", "rotated_box", ",", "alpha", "=", "0.5", ",", "edge_color", "=", "\"g\"", ",", "line_style", "=", "\"-\"", ",", "label", "=", "None", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_circle": [[1026, 1043], ["visualizer.Visualizer.output.ax.add_patch", "matplotlib.patches.Circle", "matplotlib.patches.Circle", "matplotlib.patches.Circle"], "methods", ["None"], [")", ":", "\n", "        ", "\"\"\"\n        Draw a rotated box with label on its top-left corner.\n\n        Args:\n            rotated_box (tuple): a tuple containing (cnt_x, cnt_y, w, h, angle),\n                where cnt_x and cnt_y are the center coordinates of the box.\n                w and h are the width and height of the box. angle represents how\n                many degrees the box is rotated CCW with regard to the 0-degree box.\n            alpha (float): blending efficient. Smaller values lead to more transparent masks.\n            edge_color: color of the outline of the box. Refer to `matplotlib.colors`\n                for full list of formats that are accepted.\n            line_style (string): the string to use to create the outline of the boxes.\n            label (string): label for rotated box. It will not be rendered when set to None.\n\n        Returns:\n            output (VisImage): image object with box drawn.\n        \"\"\"", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_line": [[1044, 1074], ["max", "visualizer.Visualizer.output.ax.add_line", "matplotlib.lines.Line2D", "matplotlib.lines.Line2D", "matplotlib.lines.Line2D"], "methods", ["None"], ["cnt_x", ",", "cnt_y", ",", "w", ",", "h", ",", "angle", "=", "rotated_box", "\n", "area", "=", "w", "*", "h", "\n", "# use thinner lines when the box is small", "\n", "linewidth", "=", "self", ".", "_default_font_size", "/", "(", "\n", "6", "if", "area", "<", "_SMALL_OBJECT_AREA_THRESH", "*", "self", ".", "output", ".", "scale", "else", "3", "\n", ")", "\n", "\n", "theta", "=", "angle", "*", "math", ".", "pi", "/", "180.0", "\n", "c", "=", "math", ".", "cos", "(", "theta", ")", "\n", "s", "=", "math", ".", "sin", "(", "theta", ")", "\n", "rect", "=", "[", "(", "-", "w", "/", "2", ",", "h", "/", "2", ")", ",", "(", "-", "w", "/", "2", ",", "-", "h", "/", "2", ")", ",", "(", "w", "/", "2", ",", "-", "h", "/", "2", ")", ",", "(", "w", "/", "2", ",", "h", "/", "2", ")", "]", "\n", "# x: left->right ; y: top->down", "\n", "rotated_rect", "=", "[", "(", "s", "*", "yy", "+", "c", "*", "xx", "+", "cnt_x", ",", "c", "*", "yy", "-", "s", "*", "xx", "+", "cnt_y", ")", "for", "(", "xx", ",", "yy", ")", "in", "rect", "]", "\n", "for", "k", "in", "range", "(", "4", ")", ":", "\n", "            ", "j", "=", "(", "k", "+", "1", ")", "%", "4", "\n", "self", ".", "draw_line", "(", "\n", "[", "rotated_rect", "[", "k", "]", "[", "0", "]", ",", "rotated_rect", "[", "j", "]", "[", "0", "]", "]", ",", "\n", "[", "rotated_rect", "[", "k", "]", "[", "1", "]", ",", "rotated_rect", "[", "j", "]", "[", "1", "]", "]", ",", "\n", "color", "=", "edge_color", ",", "\n", "linestyle", "=", "\"--\"", "if", "k", "==", "1", "else", "line_style", ",", "\n", "linewidth", "=", "linewidth", ",", "\n", ")", "\n", "\n", "", "if", "label", "is", "not", "None", ":", "\n", "            ", "text_pos", "=", "rotated_rect", "[", "1", "]", "# topleft corner", "\n", "\n", "height_ratio", "=", "h", "/", "np", ".", "sqrt", "(", "self", ".", "output", ".", "height", "*", "self", ".", "output", ".", "width", ")", "\n", "label_color", "=", "self", ".", "_change_color_brightness", "(", "edge_color", ",", "brightness_factor", "=", "0.7", ")", "\n", "font_size", "=", "(", "\n", "np", ".", "clip", "(", "(", "height_ratio", "-", "0.02", ")", "/", "0.08", "+", "1", ",", "1.2", ",", "2", ")", "*", "0.5", "*", "self", ".", "_default_font_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_binary_mask": [[1075, 1135], ["matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "binary_mask.astype.astype.astype", "visualizer.GenericMask", "colormap.random_color", "numpy.zeros", "visualizer.Visualizer.output.ax.imshow", "visualizer.Visualizer._change_color_brightness", "cv2.connectedComponentsWithStats", "range", "pycocotools.area", "segment.reshape.reshape.reshape", "visualizer.Visualizer.draw_polygon", "numpy.argmax", "pycocotools.frPyObjects", "visualizer.Visualizer.draw_text", "numpy.median"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.colormap.random_color", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._change_color_brightness", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.area", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_polygon", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_text"], ["self", ".", "draw_text", "(", "label", ",", "text_pos", ",", "color", "=", "label_color", ",", "font_size", "=", "font_size", ",", "rotation", "=", "angle", ")", "\n", "\n", "", "return", "self", ".", "output", "\n", "\n", "", "def", "draw_circle", "(", "self", ",", "circle_coord", ",", "color", ",", "radius", "=", "3", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            circle_coord (list(int) or tuple(int)): contains the x and y coordinates\n                of the center of the circle.\n            color: color of the polygon. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted.\n            radius (int): radius of the circle.\n\n        Returns:\n            output (VisImage): image object with box drawn.\n        \"\"\"", "\n", "x", ",", "y", "=", "circle_coord", "\n", "self", ".", "output", ".", "ax", ".", "add_patch", "(", "\n", "mpl", ".", "patches", ".", "Circle", "(", "circle_coord", ",", "radius", "=", "radius", ",", "fill", "=", "True", ",", "color", "=", "color", ")", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n", "", "def", "draw_line", "(", "self", ",", "x_data", ",", "y_data", ",", "color", ",", "linestyle", "=", "\"-\"", ",", "linewidth", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x_data (list[int]): a list containing x values of all the points being drawn.\n                Length of list should match the length of y_data.\n            y_data (list[int]): a list containing y values of all the points being drawn.\n                Length of list should match the length of x_data.\n            color: color of the line. Refer to `matplotlib.colors` for a full list of\n                formats that are accepted.\n            linestyle: style of the line. Refer to `matplotlib.lines.Line2D`\n                for a full list of formats that are accepted.\n            linewidth (float or None): width of the line. When it's None,\n                a default value will be computed and used.\n\n        Returns:\n            output (VisImage): image object with line drawn.\n        \"\"\"", "\n", "if", "linewidth", "is", "None", ":", "\n", "            ", "linewidth", "=", "self", ".", "_default_font_size", "/", "3", "\n", "", "linewidth", "=", "max", "(", "linewidth", ",", "1", ")", "\n", "self", ".", "output", ".", "ax", ".", "add_line", "(", "\n", "mpl", ".", "lines", ".", "Line2D", "(", "\n", "x_data", ",", "\n", "y_data", ",", "\n", "linewidth", "=", "linewidth", "*", "self", ".", "output", ".", "scale", ",", "\n", "color", "=", "color", ",", "\n", "linestyle", "=", "linestyle", ",", "\n", ")", "\n", ")", "\n", "return", "self", ".", "output", "\n", "\n", "", "def", "draw_binary_mask", "(", "\n", "self", ",", "binary_mask", ",", "color", "=", "None", ",", "*", ",", "edge_color", "=", "None", ",", "text", "=", "None", ",", "alpha", "=", "0.5", ",", "area_threshold", "=", "0", "\n", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_polygon": [[1136, 1167], ["matplotlib.patches.Polygon", "matplotlib.patches.Polygon", "matplotlib.patches.Polygon", "visualizer.Visualizer.output.ax.add_patch", "matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "visualizer.Visualizer._change_color_brightness", "max", "matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._change_color_brightness"], ["\n", "if", "color", "is", "None", ":", "\n", "            ", "color", "=", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "", "color", "=", "mplc", ".", "to_rgb", "(", "color", ")", "\n", "\n", "has_valid_segment", "=", "False", "\n", "binary_mask", "=", "binary_mask", ".", "astype", "(", "\"uint8\"", ")", "# opencv needs uint8", "\n", "mask", "=", "GenericMask", "(", "binary_mask", ",", "self", ".", "output", ".", "height", ",", "self", ".", "output", ".", "width", ")", "\n", "shape2d", "=", "(", "binary_mask", ".", "shape", "[", "0", "]", ",", "binary_mask", ".", "shape", "[", "1", "]", ")", "\n", "\n", "if", "not", "mask", ".", "has_holes", ":", "\n", "# draw polygons for regular masks", "\n", "            ", "for", "segment", "in", "mask", ".", "polygons", ":", "\n", "                ", "area", "=", "mask_util", ".", "area", "(", "mask_util", ".", "frPyObjects", "(", "[", "segment", "]", ",", "shape2d", "[", "0", "]", ",", "shape2d", "[", "1", "]", ")", ")", "\n", "if", "area", "<", "(", "area_threshold", "or", "0", ")", ":", "\n", "                    ", "continue", "\n", "", "has_valid_segment", "=", "True", "\n", "segment", "=", "segment", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "self", ".", "draw_polygon", "(", "segment", ",", "color", "=", "color", ",", "edge_color", "=", "edge_color", ",", "alpha", "=", "alpha", ")", "\n", "", "", "else", ":", "\n", "# TODO: Use Path/PathPatch to draw vector graphics:", "\n", "# https://stackoverflow.com/questions/8919719/how-to-plot-a-complex-polygon", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._jitter": [[1172, 1190], ["matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "numpy.random.rand", "numpy.clip", "tuple", "numpy.linalg.norm"], "methods", ["None"], ["self", ".", "output", ".", "ax", ".", "imshow", "(", "rgba", ",", "extent", "=", "(", "0", ",", "self", ".", "output", ".", "width", ",", "self", ".", "output", ".", "height", ",", "0", ")", ")", "\n", "\n", "", "if", "text", "is", "not", "None", "and", "has_valid_segment", ":", "\n", "# TODO sometimes drawn on wrong objects. the heuristics here can improve.", "\n", "            ", "lighter_color", "=", "self", ".", "_change_color_brightness", "(", "color", ",", "brightness_factor", "=", "0.7", ")", "\n", "_num_cc", ",", "cc_labels", ",", "stats", ",", "centroids", "=", "cv2", ".", "connectedComponentsWithStats", "(", "binary_mask", ",", "8", ")", "\n", "largest_component_id", "=", "np", ".", "argmax", "(", "stats", "[", "1", ":", ",", "-", "1", "]", ")", "+", "1", "\n", "\n", "# draw text on the largest component, as well as other very large components.", "\n", "for", "cid", "in", "range", "(", "1", ",", "_num_cc", ")", ":", "\n", "                ", "if", "cid", "==", "largest_component_id", "or", "stats", "[", "cid", ",", "-", "1", "]", ">", "_LARGE_MASK_AREA_THRESH", ":", "\n", "# median is more stable than centroid", "\n", "# center = centroids[largest_component_id]", "\n", "                    ", "center", "=", "np", ".", "median", "(", "(", "cc_labels", "==", "cid", ")", ".", "nonzero", "(", ")", ",", "axis", "=", "1", ")", "[", ":", ":", "-", "1", "]", "\n", "self", ".", "draw_text", "(", "text", ",", "center", ",", "color", "=", "lighter_color", ")", "\n", "", "", "", "return", "self", ".", "output", "\n", "\n", "", "def", "draw_polygon", "(", "self", ",", "segment", ",", "color", ",", "edge_color", "=", "None", ",", "alpha", "=", "0.5", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._create_grayscale_image": [[1191, 1201], ["visualizer.Visualizer.img.astype().mean", "numpy.stack", "visualizer.Visualizer.img.astype"], "methods", ["None"], []], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._change_color_brightness": [[1202, 1226], ["matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "colorsys.rgb_to_hls", "colorsys.hls_to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb", "matplotlib.to_rgb"], "methods", ["None"], ["\n", "if", "edge_color", "is", "None", ":", "\n", "# make edge color darker than the polygon color", "\n", "            ", "if", "alpha", ">", "0.8", ":", "\n", "                ", "edge_color", "=", "self", ".", "_change_color_brightness", "(", "color", ",", "brightness_factor", "=", "-", "0.7", ")", "\n", "", "else", ":", "\n", "                ", "edge_color", "=", "color", "\n", "", "", "edge_color", "=", "mplc", ".", "to_rgb", "(", "edge_color", ")", "+", "(", "1", ",", ")", "\n", "\n", "polygon", "=", "mpl", ".", "patches", ".", "Polygon", "(", "\n", "segment", ",", "\n", "fill", "=", "True", ",", "\n", "facecolor", "=", "mplc", ".", "to_rgb", "(", "color", ")", "+", "(", "alpha", ",", ")", ",", "\n", "edgecolor", "=", "edge_color", ",", "\n", "linewidth", "=", "max", "(", "self", ".", "_default_font_size", "//", "15", "*", "self", ".", "output", ".", "scale", ",", "1", ")", ",", "\n", ")", "\n", "self", ".", "output", ".", "ax", ".", "add_patch", "(", "polygon", ")", "\n", "return", "self", ".", "output", "\n", "\n", "", "\"\"\"\n    Internal methods:\n    \"\"\"", "\n", "\n", "def", "_jitter", "(", "self", ",", "color", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._convert_boxes": [[1227, 1235], ["isinstance", "isinstance", "boxes.tensor.numpy", "numpy.asarray"], "methods", ["None"], []], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._convert_masks": [[1236, 1258], ["isinstance", "isinstance", "isinstance", "m.numpy.numpy.tensor.numpy", "m.numpy.numpy.numpy", "isinstance", "ret.append", "ret.append", "visualizer.GenericMask"], "methods", ["None"], ["\n", "color", "=", "mplc", ".", "to_rgb", "(", "color", ")", "\n", "vec", "=", "np", ".", "random", ".", "rand", "(", "3", ")", "\n", "# better to do it in another color space", "\n", "vec", "=", "vec", "/", "np", ".", "linalg", ".", "norm", "(", "vec", ")", "*", "0.5", "\n", "res", "=", "np", ".", "clip", "(", "vec", "+", "color", ",", "0", ",", "1", ")", "\n", "return", "tuple", "(", "res", ")", "\n", "\n", "", "def", "_create_grayscale_image", "(", "self", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Create a grayscale version of the original image.\n        The colors in masked area, if given, will be kept.\n        \"\"\"", "\n", "img_bw", "=", "self", ".", "img", ".", "astype", "(", "\"f4\"", ")", ".", "mean", "(", "axis", "=", "2", ")", "\n", "img_bw", "=", "np", ".", "stack", "(", "[", "img_bw", "]", "*", "3", ",", "axis", "=", "2", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "img_bw", "[", "mask", "]", "=", "self", ".", "img", "[", "mask", "]", "\n", "", "return", "img_bw", "\n", "\n", "", "def", "_change_color_brightness", "(", "self", ",", "color", ",", "brightness_factor", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._convert_keypoints": [[1259, 1264], ["isinstance", "numpy.asarray"], "methods", ["None"], []], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.get_output": [[1265, 1272], ["None"], "methods", ["None"], ["\n", "assert", "brightness_factor", ">=", "-", "1.0", "and", "brightness_factor", "<=", "1.0", "\n", "color", "=", "mplc", ".", "to_rgb", "(", "color", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._create_text_labels": [[227, 252], ["len", "str", "zip", "zip"], "function", ["None"], ["", "", "", "", "def", "_create_text_labels", "(", "classes", ",", "scores", ",", "class_names", ",", "is_crowd", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        classes (list[int] or None):\n        scores (list[float] or None):\n        class_names (list[str] or None):\n        is_crowd (list[bool] or None):\n\n    Returns:\n        list[str] or None\n    \"\"\"", "\n", "labels", "=", "None", "\n", "if", "classes", "is", "not", "None", ":", "\n", "        ", "if", "class_names", "is", "not", "None", "and", "len", "(", "class_names", ")", ">", "0", ":", "\n", "            ", "labels", "=", "[", "class_names", "[", "i", "]", "for", "i", "in", "classes", "]", "\n", "", "else", ":", "\n", "            ", "labels", "=", "[", "str", "(", "i", ")", "for", "i", "in", "classes", "]", "\n", "", "", "if", "scores", "is", "not", "None", ":", "\n", "        ", "if", "labels", "is", "None", ":", "\n", "            ", "labels", "=", "[", "\"{:.0f}%\"", ".", "format", "(", "s", "*", "100", ")", "for", "s", "in", "scores", "]", "\n", "", "else", ":", "\n", "            ", "labels", "=", "[", "\"{} {:.0f}%\"", ".", "format", "(", "l", ",", "s", "*", "100", ")", "for", "l", ",", "s", "in", "zip", "(", "labels", ",", "scores", ")", "]", "\n", "", "", "if", "labels", "is", "not", "None", "and", "is_crowd", "is", "not", "None", ":", "\n", "        ", "labels", "=", "[", "l", "+", "(", "\"|crowd\"", "if", "crowd", "else", "\"\"", ")", "for", "l", ",", "crowd", "in", "zip", "(", "labels", ",", "is_crowd", ")", "]", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.video_visualizer._DetectedInstance.__init__": [[31, 37], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "label", ",", "bbox", ",", "mask_rle", ",", "color", ",", "ttl", ")", ":", "\n", "        ", "self", ".", "label", "=", "label", "\n", "self", ".", "bbox", "=", "bbox", "\n", "self", ".", "mask_rle", "=", "mask_rle", "\n", "self", ".", "color", "=", "color", "\n", "self", ".", "ttl", "=", "ttl", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.video_visualizer.VideoVisualizer.__init__": [[40, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "metadata", ",", "instance_mode", "=", "ColorMode", ".", "IMAGE", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            metadata (MetadataCatalog): image metadata.\n        \"\"\"", "\n", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "_old_instances", "=", "[", "]", "\n", "assert", "instance_mode", "in", "[", "\n", "ColorMode", ".", "IMAGE", ",", "\n", "ColorMode", ".", "IMAGE_BW", ",", "\n", "]", ",", "\"Other mode not supported yet.\"", "\n", "self", ".", "_instance_mode", "=", "instance_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.video_visualizer.VideoVisualizer.draw_instance_predictions": [[53, 111], ["detectron2.utils.visualizer.Visualizer", "len", "predictions.has", "video_visualizer.VideoVisualizer._assign_colors", "detectron2.utils.visualizer._create_text_labels", "detectron2.utils.visualizer.Visualizer.overlay_instances", "predictions.has", "predictions.pred_boxes.tensor.numpy", "predictions.has", "predictions.has", "predictions.pred_classes.numpy", "predictions.has", "video_visualizer._DetectedInstance", "video_visualizer.VideoVisualizer.metadata.get", "detectron2.utils.visualizer.Visualizer._create_grayscale_image", "range", "masks.any"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.video_visualizer.VideoVisualizer._assign_colors", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._create_text_labels", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._create_grayscale_image"], ["", "def", "draw_instance_predictions", "(", "self", ",", "frame", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Draw instance-level prediction results on an image.\n\n        Args:\n            frame (ndarray): an RGB image of shape (H, W, C), in the range [0, 255].\n            predictions (Instances): the output of an instance detection/segmentation\n                model. Following fields will be used to draw:\n                \"pred_boxes\", \"pred_classes\", \"scores\", \"pred_masks\" (or \"pred_masks_rle\").\n\n        Returns:\n            output (VisImage): image object with visualizations.\n        \"\"\"", "\n", "frame_visualizer", "=", "Visualizer", "(", "frame", ",", "self", ".", "metadata", ")", "\n", "num_instances", "=", "len", "(", "predictions", ")", "\n", "if", "num_instances", "==", "0", ":", "\n", "            ", "return", "frame_visualizer", ".", "output", "\n", "\n", "", "boxes", "=", "predictions", ".", "pred_boxes", ".", "tensor", ".", "numpy", "(", ")", "if", "predictions", ".", "has", "(", "\"pred_boxes\"", ")", "else", "None", "\n", "scores", "=", "predictions", ".", "scores", "if", "predictions", ".", "has", "(", "\"scores\"", ")", "else", "None", "\n", "classes", "=", "predictions", ".", "pred_classes", ".", "numpy", "(", ")", "if", "predictions", ".", "has", "(", "\"pred_classes\"", ")", "else", "None", "\n", "keypoints", "=", "predictions", ".", "pred_keypoints", "if", "predictions", ".", "has", "(", "\"pred_keypoints\"", ")", "else", "None", "\n", "\n", "if", "predictions", ".", "has", "(", "\"pred_masks\"", ")", ":", "\n", "            ", "masks", "=", "predictions", ".", "pred_masks", "\n", "# mask IOU is not yet enabled", "\n", "# masks_rles = mask_util.encode(np.asarray(masks.permute(1, 2, 0), order=\"F\"))", "\n", "# assert len(masks_rles) == num_instances", "\n", "", "else", ":", "\n", "            ", "masks", "=", "None", "\n", "\n", "", "detected", "=", "[", "\n", "_DetectedInstance", "(", "classes", "[", "i", "]", ",", "boxes", "[", "i", "]", ",", "mask_rle", "=", "None", ",", "color", "=", "None", ",", "ttl", "=", "8", ")", "\n", "for", "i", "in", "range", "(", "num_instances", ")", "\n", "]", "\n", "colors", "=", "self", ".", "_assign_colors", "(", "detected", ")", "\n", "\n", "labels", "=", "_create_text_labels", "(", "classes", ",", "scores", ",", "self", ".", "metadata", ".", "get", "(", "\"thing_classes\"", ",", "None", ")", ")", "\n", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "# any() returns uint8 tensor", "\n", "            ", "frame_visualizer", ".", "output", ".", "img", "=", "frame_visualizer", ".", "_create_grayscale_image", "(", "\n", "(", "masks", ".", "any", "(", "dim", "=", "0", ")", ">", "0", ")", ".", "numpy", "(", ")", "if", "masks", "is", "not", "None", "else", "None", "\n", ")", "\n", "alpha", "=", "0.3", "\n", "", "else", ":", "\n", "            ", "alpha", "=", "0.5", "\n", "\n", "", "frame_visualizer", ".", "overlay_instances", "(", "\n", "boxes", "=", "None", "if", "masks", "is", "not", "None", "else", "boxes", ",", "# boxes are a bit distracting", "\n", "masks", "=", "masks", ",", "\n", "labels", "=", "labels", ",", "\n", "keypoints", "=", "keypoints", ",", "\n", "assigned_colors", "=", "colors", ",", "\n", "alpha", "=", "alpha", ",", "\n", ")", "\n", "\n", "return", "frame_visualizer", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.video_visualizer.VideoVisualizer.draw_sem_seg": [[112, 123], ["detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer.Visualizer.draw_sem_seg"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.video_visualizer.VideoVisualizer.draw_sem_seg"], ["", "def", "draw_sem_seg", "(", "self", ",", "frame", ",", "sem_seg", ",", "area_threshold", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            sem_seg (ndarray or Tensor): semantic segmentation of shape (H, W),\n                each value is the integer label.\n            area_threshold (Optional[int]): only draw segmentations larger than the threshold\n        \"\"\"", "\n", "# don't need to do anything special", "\n", "frame_visualizer", "=", "Visualizer", "(", "frame", ",", "self", ".", "metadata", ")", "\n", "frame_visualizer", ".", "draw_sem_seg", "(", "sem_seg", ",", "area_threshold", "=", "None", ")", "\n", "return", "frame_visualizer", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.video_visualizer.VideoVisualizer.draw_panoptic_seg_predictions": [[124, 179], ["detectron2.utils.visualizer.Visualizer", "detectron2.utils.visualizer._PanopticPrediction", "detectron2.utils.visualizer._PanopticPrediction.semantic_masks", "list", "list", "len", "pycocotools.encode", "video_visualizer.VideoVisualizer._assign_colors", "detectron2.utils.visualizer.Visualizer.overlay_instances", "detectron2.utils.visualizer.Visualizer._create_grayscale_image", "detectron2.utils.visualizer.Visualizer.draw_binary_mask", "detectron2.utils.visualizer._PanopticPrediction.instance_masks", "len", "zip", "numpy.asarray", "len", "video_visualizer._DetectedInstance", "detectron2.utils.visualizer._PanopticPrediction.non_empty_mask", "numpy.asarray().transpose", "range", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._PanopticPrediction.semantic_masks", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.video_visualizer.VideoVisualizer._assign_colors", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.overlay_instances", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer._create_grayscale_image", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.Visualizer.draw_binary_mask", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._PanopticPrediction.instance_masks", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer._PanopticPrediction.non_empty_mask"], ["", "def", "draw_panoptic_seg_predictions", "(", "\n", "self", ",", "frame", ",", "panoptic_seg", ",", "segments_info", ",", "area_threshold", "=", "None", ",", "alpha", "=", "0.5", "\n", ")", ":", "\n", "        ", "frame_visualizer", "=", "Visualizer", "(", "frame", ",", "self", ".", "metadata", ")", "\n", "pred", "=", "_PanopticPrediction", "(", "panoptic_seg", ",", "segments_info", ",", "self", ".", "metadata", ")", "\n", "\n", "if", "self", ".", "_instance_mode", "==", "ColorMode", ".", "IMAGE_BW", ":", "\n", "            ", "frame_visualizer", ".", "output", ".", "img", "=", "frame_visualizer", ".", "_create_grayscale_image", "(", "\n", "pred", ".", "non_empty_mask", "(", ")", "\n", ")", "\n", "\n", "# draw mask for all semantic segments first i.e. \"stuff\"", "\n", "", "for", "mask", ",", "sinfo", "in", "pred", ".", "semantic_masks", "(", ")", ":", "\n", "            ", "category_idx", "=", "sinfo", "[", "\"category_id\"", "]", "\n", "try", ":", "\n", "                ", "mask_color", "=", "[", "x", "/", "255", "for", "x", "in", "self", ".", "metadata", ".", "stuff_colors", "[", "category_idx", "]", "]", "\n", "", "except", "AttributeError", ":", "\n", "                ", "mask_color", "=", "None", "\n", "\n", "", "frame_visualizer", ".", "draw_binary_mask", "(", "\n", "mask", ",", "\n", "color", "=", "mask_color", ",", "\n", "text", "=", "self", ".", "metadata", ".", "stuff_classes", "[", "category_idx", "]", ",", "\n", "alpha", "=", "alpha", ",", "\n", "area_threshold", "=", "area_threshold", ",", "\n", ")", "\n", "\n", "", "all_instances", "=", "list", "(", "pred", ".", "instance_masks", "(", ")", ")", "\n", "if", "len", "(", "all_instances", ")", "==", "0", ":", "\n", "            ", "return", "frame_visualizer", ".", "output", "\n", "# draw mask for all instances second", "\n", "", "masks", ",", "sinfo", "=", "list", "(", "zip", "(", "*", "all_instances", ")", ")", "\n", "num_instances", "=", "len", "(", "masks", ")", "\n", "masks_rles", "=", "mask_util", ".", "encode", "(", "\n", "np", ".", "asarray", "(", "np", ".", "asarray", "(", "masks", ")", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ",", "dtype", "=", "np", ".", "uint8", ",", "order", "=", "\"F\"", ")", "\n", ")", "\n", "assert", "len", "(", "masks_rles", ")", "==", "num_instances", "\n", "\n", "category_ids", "=", "[", "x", "[", "\"category_id\"", "]", "for", "x", "in", "sinfo", "]", "\n", "detected", "=", "[", "\n", "_DetectedInstance", "(", "category_ids", "[", "i", "]", ",", "bbox", "=", "None", ",", "mask_rle", "=", "masks_rles", "[", "i", "]", ",", "color", "=", "None", ",", "ttl", "=", "8", ")", "\n", "for", "i", "in", "range", "(", "num_instances", ")", "\n", "]", "\n", "colors", "=", "self", ".", "_assign_colors", "(", "detected", ")", "\n", "labels", "=", "[", "self", ".", "metadata", ".", "thing_classes", "[", "k", "]", "for", "k", "in", "category_ids", "]", "\n", "\n", "frame_visualizer", ".", "overlay_instances", "(", "\n", "boxes", "=", "None", ",", "\n", "masks", "=", "masks", ",", "\n", "labels", "=", "labels", ",", "\n", "keypoints", "=", "None", ",", "\n", "assigned_colors", "=", "colors", ",", "\n", "alpha", "=", "alpha", ",", "\n", ")", "\n", "return", "frame_visualizer", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.video_visualizer.VideoVisualizer._assign_colors": [[180, 236], ["numpy.zeros", "enumerate", "numpy.asarray().argmax", "numpy.asarray().max", "enumerate", "pycocotools.iou", "pycocotools.iou", "len", "numpy.zeros", "enumerate", "len", "numpy.asarray", "numpy.asarray", "extra_instances.append", "colormap.random_color", "len", "len"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.colormap.random_color"], ["", "def", "_assign_colors", "(", "self", ",", "instances", ")", ":", "\n", "        ", "\"\"\"\n        Naive tracking heuristics to assign same color to the same instance,\n        will update the internal state of tracked instances.\n\n        Returns:\n            list[tuple[float]]: list of colors.\n        \"\"\"", "\n", "\n", "# Compute iou with either boxes or masks:", "\n", "is_crowd", "=", "np", ".", "zeros", "(", "(", "len", "(", "instances", ")", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "if", "instances", "[", "0", "]", ".", "bbox", "is", "None", ":", "\n", "            ", "assert", "instances", "[", "0", "]", ".", "mask_rle", "is", "not", "None", "\n", "# use mask iou only when box iou is None", "\n", "# because box seems good enough", "\n", "rles_old", "=", "[", "x", ".", "mask_rle", "for", "x", "in", "self", ".", "_old_instances", "]", "\n", "rles_new", "=", "[", "x", ".", "mask_rle", "for", "x", "in", "instances", "]", "\n", "ious", "=", "mask_util", ".", "iou", "(", "rles_old", ",", "rles_new", ",", "is_crowd", ")", "\n", "threshold", "=", "0.5", "\n", "", "else", ":", "\n", "            ", "boxes_old", "=", "[", "x", ".", "bbox", "for", "x", "in", "self", ".", "_old_instances", "]", "\n", "boxes_new", "=", "[", "x", ".", "bbox", "for", "x", "in", "instances", "]", "\n", "ious", "=", "mask_util", ".", "iou", "(", "boxes_old", ",", "boxes_new", ",", "is_crowd", ")", "\n", "threshold", "=", "0.6", "\n", "", "if", "len", "(", "ious", ")", "==", "0", ":", "\n", "            ", "ious", "=", "np", ".", "zeros", "(", "(", "len", "(", "self", ".", "_old_instances", ")", ",", "len", "(", "instances", ")", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n", "# Only allow matching instances of the same label:", "\n", "", "for", "old_idx", ",", "old", "in", "enumerate", "(", "self", ".", "_old_instances", ")", ":", "\n", "            ", "for", "new_idx", ",", "new", "in", "enumerate", "(", "instances", ")", ":", "\n", "                ", "if", "old", ".", "label", "!=", "new", ".", "label", ":", "\n", "                    ", "ious", "[", "old_idx", ",", "new_idx", "]", "=", "0", "\n", "\n", "", "", "", "matched_new_per_old", "=", "np", ".", "asarray", "(", "ious", ")", ".", "argmax", "(", "axis", "=", "1", ")", "\n", "max_iou_per_old", "=", "np", ".", "asarray", "(", "ious", ")", ".", "max", "(", "axis", "=", "1", ")", "\n", "\n", "# Try to find match for each old instance:", "\n", "extra_instances", "=", "[", "]", "\n", "for", "idx", ",", "inst", "in", "enumerate", "(", "self", ".", "_old_instances", ")", ":", "\n", "            ", "if", "max_iou_per_old", "[", "idx", "]", ">", "threshold", ":", "\n", "                ", "newidx", "=", "matched_new_per_old", "[", "idx", "]", "\n", "if", "instances", "[", "newidx", "]", ".", "color", "is", "None", ":", "\n", "                    ", "instances", "[", "newidx", "]", ".", "color", "=", "inst", ".", "color", "\n", "continue", "\n", "# If an old instance does not match any new instances,", "\n", "# keep it for the next frame in case it is just missed by the detector", "\n", "", "", "inst", ".", "ttl", "-=", "1", "\n", "if", "inst", ".", "ttl", ">", "0", ":", "\n", "                ", "extra_instances", ".", "append", "(", "inst", ")", "\n", "\n", "# Assign random color to newly-detected instances:", "\n", "", "", "for", "inst", "in", "instances", ":", "\n", "            ", "if", "inst", ".", "color", "is", "None", ":", "\n", "                ", "inst", ".", "color", "=", "random_color", "(", "rgb", "=", "True", ",", "maximum", "=", "1", ")", "\n", "", "", "self", ".", "_old_instances", "=", "instances", "[", ":", "]", "+", "extra_instances", "\n", "return", "[", "d", ".", "color", "for", "d", "in", "instances", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.analysis.FlopCountAnalysis.__init__": [[57, 66], ["detectron2.export.TracingAdapter", "super().__init__", "analysis.FlopCountAnalysis.set_op_handle"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["def", "__init__", "(", "self", ",", "model", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            model (nn.Module):\n            inputs (Any): inputs of the given model. Does not have to be tuple of tensors.\n        \"\"\"", "\n", "wrapper", "=", "TracingAdapter", "(", "model", ",", "inputs", ",", "allow_non_tensor", "=", "True", ")", "\n", "super", "(", ")", ".", "__init__", "(", "wrapper", ",", "wrapper", ".", "flattened_inputs", ")", "\n", "self", ".", "set_op_handle", "(", "**", "{", "k", ":", "None", "for", "k", "in", "_IGNORED_OPS", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.analysis.flop_count_operators": [[68, 98], ["model.eval", "FlopCountAnalysis().by_operator", "model.train", "analysis.FlopCountAnalysis", "FlopCountAnalysis().by_operator.items"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.train"], ["", "", "def", "flop_count_operators", "(", "model", ":", "nn", ".", "Module", ",", "inputs", ":", "list", ")", "->", "typing", ".", "DefaultDict", "[", "str", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Implement operator-level flops counting using jit.\n    This is a wrapper of :func:`fvcore.nn.flop_count` and adds supports for standard\n    detection models in detectron2.\n    Please use :class:`FlopCountAnalysis` for more advanced functionalities.\n\n    Note:\n        The function runs the input through the model to compute flops.\n        The flops of a detection model is often input-dependent, for example,\n        the flops of box & mask head depends on the number of proposals &\n        the number of detected objects.\n        Therefore, the flops counting using a single input may not accurately\n        reflect the computation cost of a model. It's recommended to average\n        across a number of inputs.\n\n    Args:\n        model: a detectron2 model that takes `list[dict]` as input.\n        inputs (list[dict]): inputs to model, in detectron2's standard format.\n            Only \"image\" key will be used.\n        supported_ops (dict[str, Handle]): see documentation of :func:`fvcore.nn.flop_count`\n\n    Returns:\n        Counter: Gflop count per operator\n    \"\"\"", "\n", "old_train", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "ret", "=", "FlopCountAnalysis", "(", "model", ",", "inputs", ")", ".", "by_operator", "(", ")", "\n", "model", ".", "train", "(", "old_train", ")", "\n", "return", "{", "k", ":", "v", "/", "1e9", "for", "k", ",", "v", "in", "ret", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.analysis.activation_count_operators": [[100, 123], ["analysis._wrapper_count_operators"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.analysis._wrapper_count_operators"], ["", "def", "activation_count_operators", "(", "\n", "model", ":", "nn", ".", "Module", ",", "inputs", ":", "list", ",", "**", "kwargs", "\n", ")", "->", "typing", ".", "DefaultDict", "[", "str", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Implement operator-level activations counting using jit.\n    This is a wrapper of fvcore.nn.activation_count, that supports standard detection models\n    in detectron2.\n\n    Note:\n        The function runs the input through the model to compute activations.\n        The activations of a detection model is often input-dependent, for example,\n        the activations of box & mask head depends on the number of proposals &\n        the number of detected objects.\n\n    Args:\n        model: a detectron2 model that takes `list[dict]` as input.\n        inputs (list[dict]): inputs to model, in detectron2's standard format.\n            Only \"image\" key will be used.\n\n    Returns:\n        Counter: activation count per operator\n    \"\"\"", "\n", "return", "_wrapper_count_operators", "(", "model", "=", "model", ",", "inputs", "=", "inputs", ",", "mode", "=", "ACTIVATIONS_MODE", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.analysis._wrapper_count_operators": [[125, 153], ["supported_ops.update", "isinstance", "detectron2.export.TracingAdapter", "detectron2.export.TracingAdapter.eval", "isinstance", "model.train", "kwargs.pop", "len", "fvcore.nn.flop_count", "fvcore.nn.activation_count", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.train"], ["", "def", "_wrapper_count_operators", "(", "\n", "model", ":", "nn", ".", "Module", ",", "inputs", ":", "list", ",", "mode", ":", "str", ",", "**", "kwargs", "\n", ")", "->", "typing", ".", "DefaultDict", "[", "str", ",", "float", "]", ":", "\n", "# ignore some ops", "\n", "    ", "supported_ops", "=", "{", "k", ":", "lambda", "*", "args", ",", "**", "kwargs", ":", "{", "}", "for", "k", "in", "_IGNORED_OPS", "}", "\n", "supported_ops", ".", "update", "(", "kwargs", ".", "pop", "(", "\"supported_ops\"", ",", "{", "}", ")", ")", "\n", "kwargs", "[", "\"supported_ops\"", "]", "=", "supported_ops", "\n", "\n", "assert", "len", "(", "inputs", ")", "==", "1", ",", "\"Please use batch size=1\"", "\n", "tensor_input", "=", "inputs", "[", "0", "]", "[", "\"image\"", "]", "\n", "inputs", "=", "[", "{", "\"image\"", ":", "tensor_input", "}", "]", "# remove other keys, in case there are any", "\n", "\n", "old_train", "=", "model", ".", "training", "\n", "if", "isinstance", "(", "model", ",", "(", "nn", ".", "parallel", ".", "distributed", ".", "DistributedDataParallel", ",", "nn", ".", "DataParallel", ")", ")", ":", "\n", "        ", "model", "=", "model", ".", "module", "\n", "", "wrapper", "=", "TracingAdapter", "(", "model", ",", "inputs", ")", "\n", "wrapper", ".", "eval", "(", ")", "\n", "if", "mode", "==", "FLOPS_MODE", ":", "\n", "        ", "ret", "=", "flop_count", "(", "wrapper", ",", "(", "tensor_input", ",", ")", ",", "**", "kwargs", ")", "\n", "", "elif", "mode", "==", "ACTIVATIONS_MODE", ":", "\n", "        ", "ret", "=", "activation_count", "(", "wrapper", ",", "(", "tensor_input", ",", ")", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Count for mode {} is not supported yet.\"", ".", "format", "(", "mode", ")", ")", "\n", "# compatible with change in fvcore", "\n", "", "if", "isinstance", "(", "ret", ",", "tuple", ")", ":", "\n", "        ", "ret", "=", "ret", "[", "0", "]", "\n", "", "model", ".", "train", "(", "old_train", ")", "\n", "return", "ret", "\n", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger._ColorfulFormatter.__init__": [[19, 25], ["kwargs.pop", "len", "logging.Formatter.__init__", "kwargs.pop"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_root_name", "=", "kwargs", ".", "pop", "(", "\"root_name\"", ")", "+", "\".\"", "\n", "self", ".", "_abbrev_name", "=", "kwargs", ".", "pop", "(", "\"abbrev_name\"", ",", "\"\"", ")", "\n", "if", "len", "(", "self", ".", "_abbrev_name", ")", ":", "\n", "            ", "self", ".", "_abbrev_name", "=", "self", ".", "_abbrev_name", "+", "\".\"", "\n", "", "super", "(", "_ColorfulFormatter", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger._ColorfulFormatter.formatMessage": [[26, 36], ["record.name.replace", "super().formatMessage", "termcolor.colored", "termcolor.colored"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger._ColorfulFormatter.formatMessage"], ["", "def", "formatMessage", "(", "self", ",", "record", ")", ":", "\n", "        ", "record", ".", "name", "=", "record", ".", "name", ".", "replace", "(", "self", ".", "_root_name", ",", "self", ".", "_abbrev_name", ")", "\n", "log", "=", "super", "(", "_ColorfulFormatter", ",", "self", ")", ".", "formatMessage", "(", "record", ")", "\n", "if", "record", ".", "levelno", "==", "logging", ".", "WARNING", ":", "\n", "            ", "prefix", "=", "colored", "(", "\"WARNING\"", ",", "\"red\"", ",", "attrs", "=", "[", "\"blink\"", "]", ")", "\n", "", "elif", "record", ".", "levelno", "==", "logging", ".", "ERROR", "or", "record", ".", "levelno", "==", "logging", ".", "CRITICAL", ":", "\n", "            ", "prefix", "=", "colored", "(", "\"ERROR\"", ",", "\"red\"", ",", "attrs", "=", "[", "\"blink\"", ",", "\"underline\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "log", "\n", "", "return", "prefix", "+", "\" \"", "+", "log", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger.setup_logger": [[38, 100], ["functools.lru_cache", "logging.getLogger", "logging.getLogger.setLevel", "logging.Formatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "detectron2.utils.file_io.PathManager.mkdirs", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logger._ColorfulFormatter", "output.endswith", "output.endswith", "os.path.join", "os.path.dirname", "logger._cached_log_stream", "termcolor.colored", "str"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger._cached_log_stream"], ["", "", "@", "functools", ".", "lru_cache", "(", ")", "# so that calling setup_logger multiple times won't add many handlers", "\n", "def", "setup_logger", "(", "\n", "output", "=", "None", ",", "distributed_rank", "=", "0", ",", "*", ",", "color", "=", "True", ",", "name", "=", "\"detectron2\"", ",", "abbrev_name", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Initialize the detectron2 logger and set its verbosity level to \"DEBUG\".\n\n    Args:\n        output (str): a file name or a directory to save log. If None, will not save log file.\n            If ends with \".txt\" or \".log\", assumed to be a file name.\n            Otherwise, logs will be saved to `output/log.txt`.\n        name (str): the root module name of this logger\n        abbrev_name (str): an abbreviation of the module, to avoid long names in logs.\n            Set to \"\" to not log the root module in logs.\n            By default, will abbreviate \"detectron2\" to \"d2\" and leave other\n            modules unchanged.\n\n    Returns:\n        logging.Logger: a logger\n    \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "logger", ".", "propagate", "=", "False", "\n", "\n", "if", "abbrev_name", "is", "None", ":", "\n", "        ", "abbrev_name", "=", "\"d2\"", "if", "name", "==", "\"detectron2\"", "else", "name", "\n", "\n", "", "plain_formatter", "=", "logging", ".", "Formatter", "(", "\n", "\"[%(asctime)s] %(name)s %(levelname)s: %(message)s\"", ",", "datefmt", "=", "\"%m/%d %H:%M:%S\"", "\n", ")", "\n", "# stdout logging: master only", "\n", "if", "distributed_rank", "==", "0", ":", "\n", "        ", "ch", "=", "logging", ".", "StreamHandler", "(", "stream", "=", "sys", ".", "stdout", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "if", "color", ":", "\n", "            ", "formatter", "=", "_ColorfulFormatter", "(", "\n", "colored", "(", "\"[%(asctime)s %(name)s]: \"", ",", "\"green\"", ")", "+", "\"%(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d %H:%M:%S\"", ",", "\n", "root_name", "=", "name", ",", "\n", "abbrev_name", "=", "str", "(", "abbrev_name", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "formatter", "=", "plain_formatter", "\n", "", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "\n", "# file logging: all workers", "\n", "", "if", "output", "is", "not", "None", ":", "\n", "        ", "if", "output", ".", "endswith", "(", "\".txt\"", ")", "or", "output", ".", "endswith", "(", "\".log\"", ")", ":", "\n", "            ", "filename", "=", "output", "\n", "", "else", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "output", ",", "\"log.txt\"", ")", "\n", "", "if", "distributed_rank", ">", "0", ":", "\n", "            ", "filename", "=", "filename", "+", "\".rank{}\"", ".", "format", "(", "distributed_rank", ")", "\n", "", "PathManager", ".", "mkdirs", "(", "os", ".", "path", ".", "dirname", "(", "filename", ")", ")", "\n", "\n", "fh", "=", "logging", ".", "StreamHandler", "(", "_cached_log_stream", "(", "filename", ")", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "fh", ".", "setFormatter", "(", "plain_formatter", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "\n", "", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger._cached_log_stream": [[104, 110], ["functools.lru_cache", "detectron2.utils.file_io.PathManager.open", "atexit.register"], "function", ["None"], ["", "@", "functools", ".", "lru_cache", "(", "maxsize", "=", "None", ")", "\n", "def", "_cached_log_stream", "(", "filename", ")", ":", "\n", "# use 1K buffer if writing to cloud storage", "\n", "    ", "io", "=", "PathManager", ".", "open", "(", "filename", ",", "\"a\"", ",", "buffering", "=", "1024", "if", "\"://\"", "in", "filename", "else", "-", "1", ")", "\n", "atexit", ".", "register", "(", "io", ".", "close", ")", "\n", "return", "io", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger._find_caller": [[119, 134], ["sys._getframe", "os.path.join"], "function", ["None"], ["def", "_find_caller", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        str: module name of the caller\n        tuple: a hashable key to be used to identify different callers\n    \"\"\"", "\n", "frame", "=", "sys", ".", "_getframe", "(", "2", ")", "\n", "while", "frame", ":", "\n", "        ", "code", "=", "frame", ".", "f_code", "\n", "if", "os", ".", "path", ".", "join", "(", "\"utils\"", ",", "\"logger.\"", ")", "not", "in", "code", ".", "co_filename", ":", "\n", "            ", "mod_name", "=", "frame", ".", "f_globals", "[", "\"__name__\"", "]", "\n", "if", "mod_name", "==", "\"__main__\"", ":", "\n", "                ", "mod_name", "=", "\"detectron2\"", "\n", "", "return", "mod_name", ",", "(", "code", ".", "co_filename", ",", "frame", ".", "f_lineno", ",", "code", ".", "co_name", ")", "\n", "", "frame", "=", "frame", ".", "f_back", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger.log_first_n": [[140, 173], ["isinstance", "logger._find_caller", "len", "logging.getLogger().log", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger._find_caller"], ["def", "log_first_n", "(", "lvl", ",", "msg", ",", "n", "=", "1", ",", "*", ",", "name", "=", "None", ",", "key", "=", "\"caller\"", ")", ":", "\n", "    ", "\"\"\"\n    Log only for the first n times.\n\n    Args:\n        lvl (int): the logging level\n        msg (str):\n        n (int):\n        name (str): name of the logger to use. Will use the caller's module by default.\n        key (str or tuple[str]): the string(s) can be one of \"caller\" or\n            \"message\", which defines how to identify duplicated logs.\n            For example, if called with `n=1, key=\"caller\"`, this function\n            will only log the first call from the same caller, regardless of\n            the message content.\n            If called with `n=1, key=\"message\"`, this function will log the\n            same content only once, even if they are called from different places.\n            If called with `n=1, key=(\"caller\", \"message\")`, this function\n            will not log only if the same caller has logged the same message before.\n    \"\"\"", "\n", "if", "isinstance", "(", "key", ",", "str", ")", ":", "\n", "        ", "key", "=", "(", "key", ",", ")", "\n", "", "assert", "len", "(", "key", ")", ">", "0", "\n", "\n", "caller_module", ",", "caller_key", "=", "_find_caller", "(", ")", "\n", "hash_key", "=", "(", ")", "\n", "if", "\"caller\"", "in", "key", ":", "\n", "        ", "hash_key", "=", "hash_key", "+", "caller_key", "\n", "", "if", "\"message\"", "in", "key", ":", "\n", "        ", "hash_key", "=", "hash_key", "+", "(", "msg", ",", ")", "\n", "\n", "", "_LOG_COUNTER", "[", "hash_key", "]", "+=", "1", "\n", "if", "_LOG_COUNTER", "[", "hash_key", "]", "<=", "n", ":", "\n", "        ", "logging", ".", "getLogger", "(", "name", "or", "caller_module", ")", ".", "log", "(", "lvl", ",", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger.log_every_n": [[175, 189], ["logger._find_caller", "logging.getLogger().log", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger._find_caller"], ["", "", "def", "log_every_n", "(", "lvl", ",", "msg", ",", "n", "=", "1", ",", "*", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Log once per n times.\n\n    Args:\n        lvl (int): the logging level\n        msg (str):\n        n (int):\n        name (str): name of the logger to use. Will use the caller's module by default.\n    \"\"\"", "\n", "caller_module", ",", "key", "=", "_find_caller", "(", ")", "\n", "_LOG_COUNTER", "[", "key", "]", "+=", "1", "\n", "if", "n", "==", "1", "or", "_LOG_COUNTER", "[", "key", "]", "%", "n", "==", "1", ":", "\n", "        ", "logging", ".", "getLogger", "(", "name", "or", "caller_module", ")", ".", "log", "(", "lvl", ",", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger.log_every_n_seconds": [[191, 207], ["logger._find_caller", "_LOG_TIMER.get", "time.time", "logging.getLogger().log", "logging.getLogger"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger._find_caller"], ["", "", "def", "log_every_n_seconds", "(", "lvl", ",", "msg", ",", "n", "=", "1", ",", "*", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Log no more than once per n seconds.\n\n    Args:\n        lvl (int): the logging level\n        msg (str):\n        n (int):\n        name (str): name of the logger to use. Will use the caller's module by default.\n    \"\"\"", "\n", "caller_module", ",", "key", "=", "_find_caller", "(", ")", "\n", "last_logged", "=", "_LOG_TIMER", ".", "get", "(", "key", ",", "None", ")", "\n", "current_time", "=", "time", ".", "time", "(", ")", "\n", "if", "last_logged", "is", "None", "or", "current_time", "-", "last_logged", ">=", "n", ":", "\n", "        ", "logging", ".", "getLogger", "(", "name", "or", "caller_module", ")", ".", "log", "(", "lvl", ",", "msg", ")", "\n", "_LOG_TIMER", "[", "key", "]", "=", "current_time", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger.create_small_table": [[209, 230], ["tuple", "tabulate.tabulate", "zip", "small_dict.items"], "function", ["None"], ["", "", "def", "create_small_table", "(", "small_dict", ")", ":", "\n", "    ", "\"\"\"\n    Create a small table using the keys of small_dict as headers. This is only\n    suitable for small dictionaries.\n\n    Args:\n        small_dict (dict): a result dictionary of only a few items.\n\n    Returns:\n        str: the table as a string.\n    \"\"\"", "\n", "keys", ",", "values", "=", "tuple", "(", "zip", "(", "*", "small_dict", ".", "items", "(", ")", ")", ")", "\n", "table", "=", "tabulate", "(", "\n", "[", "values", "]", ",", "\n", "headers", "=", "keys", ",", "\n", "tablefmt", "=", "\"pipe\"", ",", "\n", "floatfmt", "=", "\".3f\"", ",", "\n", "stralign", "=", "\"center\"", ",", "\n", "numalign", "=", "\"center\"", ",", "\n", ")", "\n", "return", "table", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger._log_api_usage": [[232, 238], ["torch._C._log_api_usage_once"], "function", ["None"], ["", "def", "_log_api_usage", "(", "identifier", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Internal function used to log the usage of different detectron2 components\n    inside facebook's infra.\n    \"\"\"", "\n", "torch", ".", "_C", ".", "_log_api_usage_once", "(", "\"detectron2.\"", "+", "identifier", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.registry._convert_target_to_string": [[15, 38], ["module.split", "range", "len", "registry.locate"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.registry.locate"], ["def", "_convert_target_to_string", "(", "t", ":", "Any", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Inverse of ``locate()``.\n\n    Args:\n        t: any object with ``__module__`` and ``__qualname__``\n    \"\"\"", "\n", "module", ",", "qualname", "=", "t", ".", "__module__", ",", "t", ".", "__qualname__", "\n", "\n", "# Compress the path to this object, e.g. ``module.submodule._impl.class``", "\n", "# may become ``module.submodule.class``, if the later also resolves to the same", "\n", "# object. This simplifies the string, and also is less affected by moving the", "\n", "# class implementation.", "\n", "module_parts", "=", "module", ".", "split", "(", "\".\"", ")", "\n", "for", "k", "in", "range", "(", "1", ",", "len", "(", "module_parts", ")", ")", ":", "\n", "        ", "prefix", "=", "\".\"", ".", "join", "(", "module_parts", "[", ":", "k", "]", ")", "\n", "candidate", "=", "f\"{prefix}.{qualname}\"", "\n", "try", ":", "\n", "            ", "if", "locate", "(", "candidate", ")", "is", "t", ":", "\n", "                ", "return", "candidate", "\n", "", "", "except", "ImportError", ":", "\n", "            ", "pass", "\n", "", "", "return", "f\"{module}.{qualname}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.registry.locate": [[40, 61], ["pydoc.locate", "_locate", "ImportError"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.registry.locate"], ["", "def", "locate", "(", "name", ":", "str", ")", "->", "Any", ":", "\n", "    ", "\"\"\"\n    Locate and return an object ``x`` using an input string ``{x.__module__}.{x.__qualname__}``,\n    such as \"module.submodule.class_name\".\n\n    Raise Exception if it cannot be found.\n    \"\"\"", "\n", "obj", "=", "pydoc", ".", "locate", "(", "name", ")", "\n", "\n", "# Some cases (e.g. torch.optim.sgd.SGD) not handled correctly", "\n", "# by pydoc.locate. Try a private function from hydra.", "\n", "if", "obj", "is", "None", ":", "\n", "        ", "try", ":", "\n", "# from hydra.utils import get_method - will print many errors", "\n", "            ", "from", "hydra", ".", "utils", "import", "_locate", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "            ", "raise", "ImportError", "(", "f\"Cannot dynamically locate object {name}!\"", ")", "from", "e", "\n", "", "else", ":", "\n", "            ", "obj", "=", "_locate", "(", "name", ")", "# it raises if fails", "\n", "\n", "", "", "return", "obj", "\n", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.collect_env.collect_torch_env": [[17, 27], ["torch.__config__.show", "get_pretty_env_info"], "function", ["None"], ["def", "collect_torch_env", "(", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "import", "torch", ".", "__config__", "\n", "\n", "return", "torch", ".", "__config__", ".", "show", "(", ")", "\n", "", "except", "ImportError", ":", "\n", "# compatible with older versions of pytorch", "\n", "        ", "from", "torch", ".", "utils", ".", "collect_env", "import", "get_pretty_env_info", "\n", "\n", "return", "get_pretty_env_info", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.collect_env.get_env_module": [[29, 32], ["os.environ.get"], "function", ["None"], ["", "", "def", "get_env_module", "(", ")", ":", "\n", "    ", "var_name", "=", "\"DETECTRON2_ENV_MODULE\"", "\n", "return", "var_name", ",", "os", ".", "environ", ".", "get", "(", "var_name", ",", "\"<not set>\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.collect_env.detect_compute_compatibility": [[34, 53], ["os.path.join", "os.path.isfile", "subprocess.check_output", "output.decode().strip().split.decode().strip().split", "sorted", "sorted.append", "set", "output.decode().strip().split.decode().strip", "re.findall", "output.decode().strip().split.decode"], "function", ["None"], ["", "def", "detect_compute_compatibility", "(", "CUDA_HOME", ",", "so_file", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "cuobjdump", "=", "os", ".", "path", ".", "join", "(", "CUDA_HOME", ",", "\"bin\"", ",", "\"cuobjdump\"", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "cuobjdump", ")", ":", "\n", "            ", "output", "=", "subprocess", ".", "check_output", "(", "\n", "\"'{}' --list-elf '{}'\"", ".", "format", "(", "cuobjdump", ",", "so_file", ")", ",", "shell", "=", "True", "\n", ")", "\n", "output", "=", "output", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "arch", "=", "[", "]", "\n", "for", "line", "in", "output", ":", "\n", "                ", "line", "=", "re", ".", "findall", "(", "r\"\\.sm_([0-9]*)\\.\"", ",", "line", ")", "[", "0", "]", "\n", "arch", ".", "append", "(", "\".\"", ".", "join", "(", "line", ")", ")", "\n", "", "arch", "=", "sorted", "(", "set", "(", "arch", ")", ")", "\n", "return", "\", \"", ".", "join", "(", "arch", ")", "\n", "", "else", ":", "\n", "            ", "return", "so_file", "+", "\"; cannot find cuobjdump\"", "\n", "", "", "except", "Exception", ":", "\n", "# unhandled failure", "\n", "        ", "return", "so_file", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.collect_env.collect_env_info": [[55, 191], ["torch.cuda.is_available", "data.append", "data.append", "data.append", "data.append", "data.append", "data.append", "data.append", "data.append", "collect_env.collect_torch_env", "data.append", "data.append", "data.append", "collect_env.get_env_module", "collections.defaultdict", "range", "collections.defaultdict.items", "data.append", "data.append", "data.append", "data.append", "tabulate.tabulate", "getattr", "sys.version.replace", "data.append", "data.append", "data.append", "data.append", "torch.cuda.device_count", "devices[].append", "data.append", "data.append", "data.append", "os.environ.get", "data.append", "data.append", "data.append", "_C.get_compiler_version", "_C.get_cuda_version", "getattr", "os.path.dirname", "torch.cuda.get_device_name", "str", "data.append", "collect_env.detect_compute_compatibility", "data.append", "os.path.dirname", "os.environ.get", "subprocess.check_output", "data.append", "data.append", "collect_env.detect_compute_compatibility", "str", "os.path.dirname", "importlib.util.find_spec", "data.append", "subprocess.check_output.decode().strip().split", "os.path.join", "subprocess.check_output", "importlib.util.find_spec", "torch.cuda.get_device_capability", "os.path.isdir", "str", "os.path.isdir", "str", "str", "subprocess.check_output.decode().strip().split", "collect_env.detect_compute_compatibility", "subprocess.check_output.decode().strip", "subprocess.check_output.decode().strip", "subprocess.check_output.decode", "subprocess.check_output.decode"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.collect_env.collect_torch_env", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.collect_env.get_env_module", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.collect_env.detect_compute_compatibility", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.collect_env.detect_compute_compatibility", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.collect_env.detect_compute_compatibility"], ["", "", "def", "collect_env_info", "(", ")", ":", "\n", "    ", "has_gpu", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "# true for both CUDA & ROCM", "\n", "torch_version", "=", "torch", ".", "__version__", "\n", "\n", "# NOTE that CUDA_HOME/ROCM_HOME could be None even when CUDA runtime libs are functional", "\n", "from", "torch", ".", "utils", ".", "cpp_extension", "import", "CUDA_HOME", ",", "ROCM_HOME", "\n", "\n", "has_rocm", "=", "False", "\n", "if", "(", "getattr", "(", "torch", ".", "version", ",", "\"hip\"", ",", "None", ")", "is", "not", "None", ")", "and", "(", "ROCM_HOME", "is", "not", "None", ")", ":", "\n", "        ", "has_rocm", "=", "True", "\n", "", "has_cuda", "=", "has_gpu", "and", "(", "not", "has_rocm", ")", "\n", "\n", "data", "=", "[", "]", "\n", "data", ".", "append", "(", "(", "\"sys.platform\"", ",", "sys", ".", "platform", ")", ")", "# check-template.yml depends on it", "\n", "data", ".", "append", "(", "(", "\"Python\"", ",", "sys", ".", "version", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", ")", "\n", "data", ".", "append", "(", "(", "\"numpy\"", ",", "np", ".", "__version__", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "import", "detectron2", "# noqa", "\n", "\n", "data", ".", "append", "(", "\n", "(", "\"detectron2\"", ",", "detectron2", ".", "__version__", "+", "\" @\"", "+", "os", ".", "path", ".", "dirname", "(", "detectron2", ".", "__file__", ")", ")", "\n", ")", "\n", "", "except", "ImportError", ":", "\n", "        ", "data", ".", "append", "(", "(", "\"detectron2\"", ",", "\"failed to import\"", ")", ")", "\n", "", "except", "AttributeError", ":", "\n", "        ", "data", ".", "append", "(", "(", "\"detectron2\"", ",", "\"imported a wrong installation\"", ")", ")", "\n", "\n", "", "try", ":", "\n", "        ", "import", "detectron2", ".", "_C", "as", "_C", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "        ", "data", ".", "append", "(", "(", "\"detectron2._C\"", ",", "f\"not built correctly: {e}\"", ")", ")", "\n", "\n", "# print system compilers when extension fails to build", "\n", "if", "sys", ".", "platform", "!=", "\"win32\"", ":", "# don't know what to do for windows", "\n", "            ", "try", ":", "\n", "# this is how torch/utils/cpp_extensions.py choose compiler", "\n", "                ", "cxx", "=", "os", ".", "environ", ".", "get", "(", "\"CXX\"", ",", "\"c++\"", ")", "\n", "cxx", "=", "subprocess", ".", "check_output", "(", "\"'{}' --version\"", ".", "format", "(", "cxx", ")", ",", "shell", "=", "True", ")", "\n", "cxx", "=", "cxx", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", ".", "split", "(", "\"\\n\"", ")", "[", "0", "]", "\n", "", "except", "subprocess", ".", "SubprocessError", ":", "\n", "                ", "cxx", "=", "\"Not found\"", "\n", "", "data", ".", "append", "(", "(", "\"Compiler ($CXX)\"", ",", "cxx", ")", ")", "\n", "\n", "if", "has_cuda", "and", "CUDA_HOME", "is", "not", "None", ":", "\n", "                ", "try", ":", "\n", "                    ", "nvcc", "=", "os", ".", "path", ".", "join", "(", "CUDA_HOME", ",", "\"bin\"", ",", "\"nvcc\"", ")", "\n", "nvcc", "=", "subprocess", ".", "check_output", "(", "\"'{}' -V\"", ".", "format", "(", "nvcc", ")", ",", "shell", "=", "True", ")", "\n", "nvcc", "=", "nvcc", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", ".", "split", "(", "\"\\n\"", ")", "[", "-", "1", "]", "\n", "", "except", "subprocess", ".", "SubprocessError", ":", "\n", "                    ", "nvcc", "=", "\"Not found\"", "\n", "", "data", ".", "append", "(", "(", "\"CUDA compiler\"", ",", "nvcc", ")", ")", "\n", "", "", "if", "has_cuda", "and", "sys", ".", "platform", "!=", "\"win32\"", ":", "\n", "            ", "try", ":", "\n", "                ", "so_file", "=", "importlib", ".", "util", ".", "find_spec", "(", "\"detectron2._C\"", ")", ".", "origin", "\n", "", "except", "(", "ImportError", ",", "AttributeError", ")", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "data", ".", "append", "(", "\n", "(", "\"detectron2 arch flags\"", ",", "detect_compute_compatibility", "(", "CUDA_HOME", ",", "so_file", ")", ")", "\n", ")", "\n", "", "", "", "else", ":", "\n", "# print compilers that are used to build extension", "\n", "        ", "data", ".", "append", "(", "(", "\"Compiler\"", ",", "_C", ".", "get_compiler_version", "(", ")", ")", ")", "\n", "data", ".", "append", "(", "(", "\"CUDA compiler\"", ",", "_C", ".", "get_cuda_version", "(", ")", ")", ")", "# cuda or hip", "\n", "if", "has_cuda", "and", "getattr", "(", "_C", ",", "\"has_cuda\"", ",", "lambda", ":", "True", ")", "(", ")", ":", "\n", "            ", "data", ".", "append", "(", "\n", "(", "\"detectron2 arch flags\"", ",", "detect_compute_compatibility", "(", "CUDA_HOME", ",", "_C", ".", "__file__", ")", ")", "\n", ")", "\n", "\n", "", "", "data", ".", "append", "(", "get_env_module", "(", ")", ")", "\n", "data", ".", "append", "(", "(", "\"PyTorch\"", ",", "torch_version", "+", "\" @\"", "+", "os", ".", "path", ".", "dirname", "(", "torch", ".", "__file__", ")", ")", ")", "\n", "data", ".", "append", "(", "(", "\"PyTorch debug build\"", ",", "torch", ".", "version", ".", "debug", ")", ")", "\n", "\n", "data", ".", "append", "(", "(", "\"GPU available\"", ",", "has_gpu", ")", ")", "\n", "if", "has_gpu", ":", "\n", "        ", "devices", "=", "defaultdict", "(", "list", ")", "\n", "for", "k", "in", "range", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", ":", "\n", "            ", "cap", "=", "\".\"", ".", "join", "(", "(", "str", "(", "x", ")", "for", "x", "in", "torch", ".", "cuda", ".", "get_device_capability", "(", "k", ")", ")", ")", "\n", "name", "=", "torch", ".", "cuda", ".", "get_device_name", "(", "k", ")", "+", "f\" (arch={cap})\"", "\n", "devices", "[", "name", "]", ".", "append", "(", "str", "(", "k", ")", ")", "\n", "", "for", "name", ",", "devids", "in", "devices", ".", "items", "(", ")", ":", "\n", "            ", "data", ".", "append", "(", "(", "\"GPU \"", "+", "\",\"", ".", "join", "(", "devids", ")", ",", "name", ")", ")", "\n", "\n", "", "if", "has_rocm", ":", "\n", "            ", "msg", "=", "\" - invalid!\"", "if", "not", "(", "ROCM_HOME", "and", "os", ".", "path", ".", "isdir", "(", "ROCM_HOME", ")", ")", "else", "\"\"", "\n", "data", ".", "append", "(", "(", "\"ROCM_HOME\"", ",", "str", "(", "ROCM_HOME", ")", "+", "msg", ")", ")", "\n", "", "else", ":", "\n", "            ", "msg", "=", "\" - invalid!\"", "if", "not", "(", "CUDA_HOME", "and", "os", ".", "path", ".", "isdir", "(", "CUDA_HOME", ")", ")", "else", "\"\"", "\n", "data", ".", "append", "(", "(", "\"CUDA_HOME\"", ",", "str", "(", "CUDA_HOME", ")", "+", "msg", ")", ")", "\n", "\n", "cuda_arch_list", "=", "os", ".", "environ", ".", "get", "(", "\"TORCH_CUDA_ARCH_LIST\"", ",", "None", ")", "\n", "if", "cuda_arch_list", ":", "\n", "                ", "data", ".", "append", "(", "(", "\"TORCH_CUDA_ARCH_LIST\"", ",", "cuda_arch_list", ")", ")", "\n", "", "", "", "data", ".", "append", "(", "(", "\"Pillow\"", ",", "PIL", ".", "__version__", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "data", ".", "append", "(", "\n", "(", "\n", "\"torchvision\"", ",", "\n", "str", "(", "torchvision", ".", "__version__", ")", "+", "\" @\"", "+", "os", ".", "path", ".", "dirname", "(", "torchvision", ".", "__file__", ")", ",", "\n", ")", "\n", ")", "\n", "if", "has_cuda", ":", "\n", "            ", "try", ":", "\n", "                ", "torchvision_C", "=", "importlib", ".", "util", ".", "find_spec", "(", "\"torchvision._C\"", ")", ".", "origin", "\n", "msg", "=", "detect_compute_compatibility", "(", "CUDA_HOME", ",", "torchvision_C", ")", "\n", "data", ".", "append", "(", "(", "\"torchvision arch flags\"", ",", "msg", ")", ")", "\n", "", "except", "(", "ImportError", ",", "AttributeError", ")", ":", "\n", "                ", "data", ".", "append", "(", "(", "\"torchvision._C\"", ",", "\"Not found\"", ")", ")", "\n", "", "", "", "except", "AttributeError", ":", "\n", "        ", "data", ".", "append", "(", "(", "\"torchvision\"", ",", "\"unknown\"", ")", ")", "\n", "\n", "", "try", ":", "\n", "        ", "import", "fvcore", "\n", "\n", "data", ".", "append", "(", "(", "\"fvcore\"", ",", "fvcore", ".", "__version__", ")", ")", "\n", "", "except", "(", "ImportError", ",", "AttributeError", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "try", ":", "\n", "        ", "import", "iopath", "\n", "\n", "data", ".", "append", "(", "(", "\"iopath\"", ",", "iopath", ".", "__version__", ")", ")", "\n", "", "except", "(", "ImportError", ",", "AttributeError", ")", ":", "\n", "        ", "pass", "\n", "\n", "", "try", ":", "\n", "        ", "import", "cv2", "\n", "\n", "data", ".", "append", "(", "(", "\"cv2\"", ",", "cv2", ".", "__version__", ")", ")", "\n", "", "except", "(", "ImportError", ",", "AttributeError", ")", ":", "\n", "        ", "data", ".", "append", "(", "(", "\"cv2\"", ",", "\"Not found\"", ")", ")", "\n", "", "env_str", "=", "tabulate", "(", "data", ")", "+", "\"\\n\"", "\n", "env_str", "+=", "collect_torch_env", "(", ")", "\n", "return", "env_str", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.testing.get_model_no_weights": [[19, 27], ["detectron2.model_zoo.get_config", "detectron2.modeling.build_model", "torch.cuda.is_available"], "function", ["None"], ["def", "get_model_no_weights", "(", "config_path", ")", ":", "\n", "    ", "\"\"\"\n    Like model_zoo.get, but do not load any weights (even pretrained)\n    \"\"\"", "\n", "cfg", "=", "model_zoo", ".", "get_config", "(", "config_path", ")", "\n", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "cfg", ".", "MODEL", ".", "DEVICE", "=", "\"cpu\"", "\n", "", "return", "build_model", "(", "cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.testing.random_boxes": [[29, 41], ["boxes.clamp_", "torch.rand"], "function", ["None"], ["", "def", "random_boxes", "(", "num_boxes", ",", "max_coord", "=", "100", ",", "device", "=", "\"cpu\"", ")", ":", "\n", "    ", "\"\"\"\n    Create a random Nx4 boxes tensor, with coordinates < max_coord.\n    \"\"\"", "\n", "boxes", "=", "torch", ".", "rand", "(", "num_boxes", ",", "4", ",", "device", "=", "device", ")", "*", "(", "max_coord", "*", "0.5", ")", "\n", "boxes", ".", "clamp_", "(", "min", "=", "1.0", ")", "# tiny boxes cause numerical instability in box regression", "\n", "# Note: the implementation of this function in torchvision is:", "\n", "# boxes[:, 2:] += torch.rand(N, 2) * 100", "\n", "# but it does not guarantee non-negative widths/heights constraints:", "\n", "# boxes[:, 2] >= boxes[:, 0] and boxes[:, 3] >= boxes[:, 1]:", "\n", "boxes", "[", ":", ",", "2", ":", "]", "+=", "boxes", "[", ":", ",", ":", "2", "]", "\n", "return", "boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.testing.get_sample_coco_image": [[43, 63], ["detectron2.data.detection_utils.read_image", "torch.from_numpy", "detectron2.utils.file_io.PathManager.exists", "FileNotFoundError", "numpy.ascontiguousarray", "detectron2.data.DatasetCatalog.get", "torch.from_numpy.transpose"], "function", ["None"], ["", "def", "get_sample_coco_image", "(", "tensor", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        tensor (bool): if True, returns 3xHxW tensor.\n            else, returns a HxWx3 numpy array.\n\n    Returns:\n        an image, in BGR color.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "file_name", "=", "DatasetCatalog", ".", "get", "(", "\"coco_2017_val_100\"", ")", "[", "0", "]", "[", "\"file_name\"", "]", "\n", "if", "not", "PathManager", ".", "exists", "(", "file_name", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", ")", "\n", "", "", "except", "IOError", ":", "\n", "# for public CI to run", "\n", "        ", "file_name", "=", "\"http://images.cocodataset.org/train2017/000000000009.jpg\"", "\n", "", "ret", "=", "read_image", "(", "file_name", ",", "format", "=", "\"BGR\"", ")", "\n", "if", "tensor", ":", "\n", "        ", "ret", "=", "torch", ".", "from_numpy", "(", "np", ".", "ascontiguousarray", "(", "ret", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.testing.convert_scripted_instances": [[65, 75], ["detectron2.structures.Instances", "getattr", "detectron2.structures.Instances.set"], "function", ["None"], ["", "def", "convert_scripted_instances", "(", "instances", ")", ":", "\n", "    ", "\"\"\"\n    Convert a scripted Instances object to a regular :class:`Instances` object\n    \"\"\"", "\n", "ret", "=", "Instances", "(", "instances", ".", "image_size", ")", "\n", "for", "name", "in", "instances", ".", "_field_names", ":", "\n", "        ", "val", "=", "getattr", "(", "instances", ",", "\"_\"", "+", "name", ",", "None", ")", "\n", "if", "val", "is", "not", "None", ":", "\n", "            ", "ret", ".", "set", "(", "name", ",", "val", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.testing.assert_instances_allclose": [[77, 122], ["sorted", "sorted", "isinstance", "testing.convert_scripted_instances", "isinstance", "testing.convert_scripted_instances", "torch.equal", "convert_scripted_instances.get_fields().keys", "convert_scripted_instances.get_fields().keys", "isinstance", "msg.rstrip", "torch.tensor", "torch.tensor", "convert_scripted_instances.get", "convert_scripted_instances.get", "torch.allclose", "isinstance", "convert_scripted_instances.get_fields", "convert_scripted_instances.get_fields", "ValueError", "torch.abs().max().cpu().item", "torch.allclose", "torch.equal", "torch.abs().max().cpu", "type", "torch.abs().max", "torch.abs"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.testing.convert_scripted_instances", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.testing.convert_scripted_instances"], ["", "def", "assert_instances_allclose", "(", "input", ",", "other", ",", "*", ",", "rtol", "=", "1e-5", ",", "msg", "=", "\"\"", ",", "size_as_tensor", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        input, other (Instances):\n        size_as_tensor: compare image_size of the Instances as tensors (instead of tuples).\n             Useful for comparing outputs of tracing.\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "input", ",", "Instances", ")", ":", "\n", "        ", "input", "=", "convert_scripted_instances", "(", "input", ")", "\n", "", "if", "not", "isinstance", "(", "other", ",", "Instances", ")", ":", "\n", "        ", "other", "=", "convert_scripted_instances", "(", "other", ")", "\n", "\n", "", "if", "not", "msg", ":", "\n", "        ", "msg", "=", "\"Two Instances are different! \"", "\n", "", "else", ":", "\n", "        ", "msg", "=", "msg", ".", "rstrip", "(", ")", "+", "\" \"", "\n", "\n", "", "size_error_msg", "=", "msg", "+", "f\"image_size is {input.image_size} vs. {other.image_size}!\"", "\n", "if", "size_as_tensor", ":", "\n", "        ", "assert", "torch", ".", "equal", "(", "\n", "torch", ".", "tensor", "(", "input", ".", "image_size", ")", ",", "torch", ".", "tensor", "(", "other", ".", "image_size", ")", "\n", ")", ",", "size_error_msg", "\n", "", "else", ":", "\n", "        ", "assert", "input", ".", "image_size", "==", "other", ".", "image_size", ",", "size_error_msg", "\n", "", "fields", "=", "sorted", "(", "input", ".", "get_fields", "(", ")", ".", "keys", "(", ")", ")", "\n", "fields_other", "=", "sorted", "(", "other", ".", "get_fields", "(", ")", ".", "keys", "(", ")", ")", "\n", "assert", "fields", "==", "fields_other", ",", "msg", "+", "f\"Fields are {fields} vs {fields_other}!\"", "\n", "\n", "for", "f", "in", "fields", ":", "\n", "        ", "val1", ",", "val2", "=", "input", ".", "get", "(", "f", ")", ",", "other", ".", "get", "(", "f", ")", "\n", "if", "isinstance", "(", "val1", ",", "(", "Boxes", ",", "ROIMasks", ")", ")", ":", "\n", "# boxes in the range of O(100) and can have a larger tolerance", "\n", "            ", "assert", "torch", ".", "allclose", "(", "val1", ".", "tensor", ",", "val2", ".", "tensor", ",", "atol", "=", "100", "*", "rtol", ")", ",", "(", "\n", "msg", "+", "f\"Field {f} differs too much!\"", "\n", ")", "\n", "", "elif", "isinstance", "(", "val1", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "if", "val1", ".", "dtype", ".", "is_floating_point", ":", "\n", "                ", "mag", "=", "torch", ".", "abs", "(", "val1", ")", ".", "max", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "assert", "torch", ".", "allclose", "(", "val1", ",", "val2", ",", "atol", "=", "mag", "*", "rtol", ")", ",", "(", "\n", "msg", "+", "f\"Field {f} differs too much!\"", "\n", ")", "\n", "", "else", ":", "\n", "                ", "assert", "torch", ".", "equal", "(", "val1", ",", "val2", ")", ",", "msg", "+", "f\"Field {f} is different!\"", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Don't know how to compare type {type(val1)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.testing.reload_script_model": [[124, 133], ["io.BytesIO", "torch.jit.save", "io.BytesIO.seek", "torch.jit.load"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.VisImage.save"], ["", "", "", "def", "reload_script_model", "(", "module", ")", ":", "\n", "    ", "\"\"\"\n    Save a jit module and load it back.\n    Similar to the `getExportImportCopy` function in torch/testing/\n    \"\"\"", "\n", "buffer", "=", "io", ".", "BytesIO", "(", ")", "\n", "torch", ".", "jit", ".", "save", "(", "module", ",", "buffer", ")", "\n", "buffer", ".", "seek", "(", "0", ")", "\n", "return", "torch", ".", "jit", ".", "load", "(", "buffer", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.file_io.Detectron2Handler._get_supported_prefixes": [[24, 26], ["None"], "methods", ["None"], ["def", "_get_supported_prefixes", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "PREFIX", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.file_io.Detectron2Handler._get_local_path": [[27, 30], ["iopath.common.file_io.PathManager.get_local_path", "len"], "methods", ["None"], ["", "def", "_get_local_path", "(", "self", ",", "path", ",", "**", "kwargs", ")", ":", "\n", "        ", "name", "=", "path", "[", "len", "(", "self", ".", "PREFIX", ")", ":", "]", "\n", "return", "PathManager", ".", "get_local_path", "(", "self", ".", "S3_DETECTRON2_PREFIX", "+", "name", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.file_io.Detectron2Handler._open": [[31, 33], ["iopath.common.file_io.PathManager.open", "file_io.Detectron2Handler._get_local_path"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.file_io.Detectron2Handler._get_local_path"], ["", "def", "_open", "(", "self", ",", "path", ",", "mode", "=", "\"r\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "PathManager", ".", "open", "(", "self", ".", "_get_local_path", "(", "path", ")", ",", "mode", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.env.seed_all_rng": [[27, 46], ["numpy.random.seed", "torch.manual_seed", "random.seed", "str", "logging.getLogger", "logging.getLogger.info", "int.from_bytes", "os.getpid", "int", "os.urandom", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["def", "seed_all_rng", "(", "seed", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Set the random seed for the RNG in torch, numpy and python.\n\n    Args:\n        seed (int): if None, will use a strong random seed.\n    \"\"\"", "\n", "if", "seed", "is", "None", ":", "\n", "        ", "seed", "=", "(", "\n", "os", ".", "getpid", "(", ")", "\n", "+", "int", "(", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%S%f\"", ")", ")", "\n", "+", "int", ".", "from_bytes", "(", "os", ".", "urandom", "(", "2", ")", ",", "\"big\"", ")", "\n", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Using a generated random seed {}\"", ".", "format", "(", "seed", ")", ")", "\n", "", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "\"PYTHONHASHSEED\"", "]", "=", "str", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.env._import_file": [[49, 56], ["importlib.util.spec_from_file_location", "importlib.util.spec_from_file_location", "importlib.util.module_from_spec", "importlib.util.module_from_spec", "importlib.util.spec_from_file_location.loader.exec_module"], "function", ["None"], ["", "def", "_import_file", "(", "module_name", ",", "file_path", ",", "make_importable", "=", "False", ")", ":", "\n", "    ", "spec", "=", "importlib", ".", "util", ".", "spec_from_file_location", "(", "module_name", ",", "file_path", ")", "\n", "module", "=", "importlib", ".", "util", ".", "module_from_spec", "(", "spec", ")", "\n", "spec", ".", "loader", ".", "exec_module", "(", "module", ")", "\n", "if", "make_importable", ":", "\n", "        ", "sys", ".", "modules", "[", "module_name", "]", "=", "module", "\n", "", "return", "module", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.env._configure_libraries": [[58, 91], ["int", "os.environ.get", "tuple", "env._configure_libraries.get_version"], "function", ["None"], ["", "def", "_configure_libraries", "(", ")", ":", "\n", "    ", "\"\"\"\n    Configurations for some libraries.\n    \"\"\"", "\n", "# An environment option to disable `import cv2` globally,", "\n", "# in case it leads to negative performance impact", "\n", "disable_cv2", "=", "int", "(", "os", ".", "environ", ".", "get", "(", "\"DETECTRON2_DISABLE_CV2\"", ",", "False", ")", ")", "\n", "if", "disable_cv2", ":", "\n", "        ", "sys", ".", "modules", "[", "\"cv2\"", "]", "=", "None", "\n", "", "else", ":", "\n", "# Disable opencl in opencv since its interaction with cuda often has negative effects", "\n", "# This envvar is supported after OpenCV 3.4.0", "\n", "        ", "os", ".", "environ", "[", "\"OPENCV_OPENCL_RUNTIME\"", "]", "=", "\"disabled\"", "\n", "try", ":", "\n", "            ", "import", "cv2", "\n", "\n", "if", "int", "(", "cv2", ".", "__version__", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", ">=", "3", ":", "\n", "                ", "cv2", ".", "ocl", ".", "setUseOpenCL", "(", "False", ")", "\n", "", "", "except", "ModuleNotFoundError", ":", "\n", "# Other types of ImportError, if happened, should not be ignored.", "\n", "# Because a failed opencv import could mess up address space", "\n", "# https://github.com/skvark/opencv-python/issues/381", "\n", "            ", "pass", "\n", "\n", "", "", "def", "get_version", "(", "module", ",", "digit", "=", "2", ")", ":", "\n", "        ", "return", "tuple", "(", "map", "(", "int", ",", "module", ".", "__version__", ".", "split", "(", "\".\"", ")", "[", ":", "digit", "]", ")", ")", "\n", "\n", "# fmt: off", "\n", "", "assert", "get_version", "(", "torch", ")", ">=", "(", "1", ",", "4", ")", ",", "\"Requires torch>=1.4\"", "\n", "import", "fvcore", "\n", "assert", "get_version", "(", "fvcore", ",", "3", ")", ">=", "(", "0", ",", "1", ",", "2", ")", ",", "\"Requires fvcore>=0.1.2\"", "\n", "import", "yaml", "\n", "assert", "get_version", "(", "yaml", ")", ">=", "(", "5", ",", "1", ")", ",", "\"Requires pyyaml>=5.1\"", "\n", "# fmt: on", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.env.setup_environment": [[97, 117], ["env._configure_libraries", "os.environ.get", "env.setup_custom_environment"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.env._configure_libraries", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.env.setup_custom_environment"], ["def", "setup_environment", "(", ")", ":", "\n", "    ", "\"\"\"Perform environment setup work. The default setup is a no-op, but this\n    function allows the user to specify a Python source file or a module in\n    the $DETECTRON2_ENV_MODULE environment variable, that performs\n    custom setup work that may be necessary to their computing environment.\n    \"\"\"", "\n", "global", "_ENV_SETUP_DONE", "\n", "if", "_ENV_SETUP_DONE", ":", "\n", "        ", "return", "\n", "", "_ENV_SETUP_DONE", "=", "True", "\n", "\n", "_configure_libraries", "(", ")", "\n", "\n", "custom_module_path", "=", "os", ".", "environ", ".", "get", "(", "\"DETECTRON2_ENV_MODULE\"", ")", "\n", "\n", "if", "custom_module_path", ":", "\n", "        ", "setup_custom_environment", "(", "custom_module_path", ")", "\n", "", "else", ":", "\n", "# The default setup is a no-op", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.env.setup_custom_environment": [[119, 133], ["custom_module.endswith", "importlib.import_module.setup_environment", "env._import_file", "importlib.import_module", "importlib.import_module", "hasattr", "callable"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.env.setup_environment", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.env._import_file"], ["", "", "def", "setup_custom_environment", "(", "custom_module", ")", ":", "\n", "    ", "\"\"\"\n    Load custom environment setup by importing a Python source file or a\n    module, and run the setup function.\n    \"\"\"", "\n", "if", "custom_module", ".", "endswith", "(", "\".py\"", ")", ":", "\n", "        ", "module", "=", "_import_file", "(", "\"detectron2.utils.env.custom_module\"", ",", "custom_module", ")", "\n", "", "else", ":", "\n", "        ", "module", "=", "importlib", ".", "import_module", "(", "custom_module", ")", "\n", "", "assert", "hasattr", "(", "module", ",", "\"setup_environment\"", ")", "and", "callable", "(", "module", ".", "setup_environment", ")", ",", "(", "\n", "\"Custom environment module defined in {} does not have the \"", "\n", "\"required callable attribute 'setup_environment'.\"", "\n", ")", ".", "format", "(", "custom_module", ")", "\n", "module", ".", "setup_environment", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.env.fixup_module_metadata": [[135, 171], ["set", "set.add", "getattr", "namespace.keys", "id", "id", "isinstance", "objname.startswith", "env.fixup_module_metadata.fix_one"], "function", ["None"], ["", "def", "fixup_module_metadata", "(", "module_name", ",", "namespace", ",", "keys", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Fix the __qualname__ of module members to be their exported api name, so\n    when they are referenced in docs, sphinx can find them. Reference:\n    https://github.com/python-trio/trio/blob/6754c74eacfad9cc5c92d5c24727a2f3b620624e/trio/_util.py#L216-L241\n    \"\"\"", "\n", "if", "not", "DOC_BUILDING", ":", "\n", "        ", "return", "\n", "", "seen_ids", "=", "set", "(", ")", "\n", "\n", "def", "fix_one", "(", "qualname", ",", "name", ",", "obj", ")", ":", "\n", "# avoid infinite recursion (relevant when using", "\n", "# typing.Generic, for example)", "\n", "        ", "if", "id", "(", "obj", ")", "in", "seen_ids", ":", "\n", "            ", "return", "\n", "", "seen_ids", ".", "add", "(", "id", "(", "obj", ")", ")", "\n", "\n", "mod", "=", "getattr", "(", "obj", ",", "\"__module__\"", ",", "None", ")", "\n", "if", "mod", "is", "not", "None", "and", "(", "mod", ".", "startswith", "(", "module_name", ")", "or", "mod", ".", "startswith", "(", "\"fvcore.\"", ")", ")", ":", "\n", "            ", "obj", ".", "__module__", "=", "module_name", "\n", "# Modules, unlike everything else in Python, put fully-qualitied", "\n", "# names into their __name__ attribute. We check for \".\" to avoid", "\n", "# rewriting these.", "\n", "if", "hasattr", "(", "obj", ",", "\"__name__\"", ")", "and", "\".\"", "not", "in", "obj", ".", "__name__", ":", "\n", "                ", "obj", ".", "__name__", "=", "name", "\n", "obj", ".", "__qualname__", "=", "qualname", "\n", "", "if", "isinstance", "(", "obj", ",", "type", ")", ":", "\n", "                ", "for", "attr_name", ",", "attr_value", "in", "obj", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "                    ", "fix_one", "(", "objname", "+", "\".\"", "+", "attr_name", ",", "attr_name", ",", "attr_value", ")", "\n", "\n", "", "", "", "", "if", "keys", "is", "None", ":", "\n", "        ", "keys", "=", "namespace", ".", "keys", "(", ")", "\n", "", "for", "objname", "in", "keys", ":", "\n", "        ", "if", "not", "objname", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "            ", "obj", "=", "namespace", "[", "objname", "]", "\n", "fix_one", "(", "objname", ",", "objname", ",", "obj", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.memory._ignore_torch_cuda_oom": [[11, 24], ["str"], "function", ["None"], ["@", "contextmanager", "\n", "def", "_ignore_torch_cuda_oom", "(", ")", ":", "\n", "    ", "\"\"\"\n    A context which ignores CUDA OOM exception from pytorch.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "# NOTE: the string may change?", "\n", "        ", "if", "\"CUDA out of memory. \"", "in", "str", "(", "e", ")", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.memory.retry_if_cuda_oom": [[26, 85], ["functools.wraps", "torch.cuda.empty_cache", "logging.getLogger", "logging.getLogger.info", "func", "x.to", "memory._ignore_torch_cuda_oom", "func", "memory._ignore_torch_cuda_oom", "func", "memory.retry_if_cuda_oom.maybe_to_cpu"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.memory._ignore_torch_cuda_oom", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.memory._ignore_torch_cuda_oom"], ["", "", "", "def", "retry_if_cuda_oom", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Makes a function retry itself after encountering\n    pytorch's CUDA OOM error.\n    It will first retry after calling `torch.cuda.empty_cache()`.\n\n    If that still fails, it will then retry by trying to convert inputs to CPUs.\n    In this case, it expects the function to dispatch to CPU implementation.\n    The return values may become CPU tensors as well and it's user's\n    responsibility to convert it back to CUDA tensor if needed.\n\n    Args:\n        func: a stateless callable that takes tensor-like objects as arguments\n\n    Returns:\n        a callable which retries `func` if OOM is encountered.\n\n    Examples:\n    ::\n        output = retry_if_cuda_oom(some_torch_function)(input1, input2)\n        # output may be on CPU even if inputs are on GPU\n\n    Note:\n        1. When converting inputs to CPU, it will only look at each argument and check\n           if it has `.device` and `.to` for conversion. Nested structures of tensors\n           are not supported.\n\n        2. Since the function might be called more than once, it has to be\n           stateless.\n    \"\"\"", "\n", "\n", "def", "maybe_to_cpu", "(", "x", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "like_gpu_tensor", "=", "x", ".", "device", ".", "type", "==", "\"cuda\"", "and", "hasattr", "(", "x", ",", "\"to\"", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "like_gpu_tensor", "=", "False", "\n", "", "if", "like_gpu_tensor", ":", "\n", "            ", "return", "x", ".", "to", "(", "device", "=", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n", "", "", "@", "wraps", "(", "func", ")", "\n", "def", "wrapped", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "with", "_ignore_torch_cuda_oom", "(", ")", ":", "\n", "            ", "return", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Clear cache and retry", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "with", "_ignore_torch_cuda_oom", "(", ")", ":", "\n", "            ", "return", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Try on CPU. This slows down the code significantly, therefore print a notice.", "\n", "", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Attempting to copy inputs of {} to CPU due to CUDA OOM\"", ".", "format", "(", "str", "(", "func", ")", ")", ")", "\n", "new_args", "=", "(", "maybe_to_cpu", "(", "x", ")", "for", "x", "in", "args", ")", "\n", "new_kwargs", "=", "{", "k", ":", "maybe_to_cpu", "(", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "}", "\n", "return", "func", "(", "*", "new_args", ",", "**", "new_kwargs", ")", "\n", "\n", "", "return", "wrapped", "\n", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.timer.Timer.__init__": [[5, 11], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "total_time", "=", "0.", "\n", "self", ".", "calls", "=", "0", "\n", "self", ".", "start_time", "=", "0.", "\n", "self", ".", "diff", "=", "0.", "\n", "self", ".", "average_time", "=", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.timer.Timer.tic": [[12, 14], ["time.time"], "methods", ["None"], ["", "def", "tic", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.timer.Timer.toc": [[15, 24], ["time.time"], "methods", ["None"], ["", "def", "toc", "(", "self", ",", "average", "=", "True", ")", ":", "\n", "        ", "self", ".", "diff", "=", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", "\n", "self", ".", "total_time", "+=", "self", ".", "diff", "\n", "self", ".", "calls", "+=", "1", "\n", "self", ".", "average_time", "=", "self", ".", "total_time", "/", "self", ".", "calls", "\n", "if", "average", ":", "\n", "            ", "return", "self", ".", "average_time", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "diff", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.extract_ampl_phase": [[4, 11], ["torch.sqrt", "torch.atan2"], "function", ["None"], []], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.low_freq_mutate": [[12, 20], ["amp_src.size", "numpy.floor().astype", "numpy.floor", "numpy.amin"], "function", ["None"], []], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.low_freq_mutate_np": [[21, 38], ["numpy.fft.fftshift", "numpy.fft.fftshift", "numpy.floor().astype", "numpy.floor().astype", "numpy.floor().astype", "numpy.fft.ifftshift", "numpy.floor", "numpy.floor", "numpy.floor", "numpy.amin"], "function", ["None"], []], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.FDA_source_to_target_test": [[38, 40], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.FDA_source_to_target": [[43, 68], ["torch.rfft", "torch.rfft", "__init__.extract_ampl_phase", "__init__.extract_ampl_phase", "__init__.low_freq_mutate", "torch.zeros", "src_img.size", "torch.irfft", "src_img.clone", "trg_img.clone", "torch.rfft.clone", "torch.rfft.clone", "amp_src.clone", "amp_trg.clone", "torch.rfft.size", "torch.cos", "low_freq_mutate.clone", "torch.sin", "low_freq_mutate.clone", "pha_src.clone", "pha_src.clone"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.extract_ampl_phase", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.extract_ampl_phase", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.low_freq_mutate"], []], "home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.FDA_source_to_target_np": [[69, 95], ["numpy.fft.fft2", "numpy.fft.fft2", "__init__.low_freq_mutate_np", "numpy.fft.ifft2", "numpy.real", "numpy.abs", "numpy.angle", "numpy.abs", "numpy.angle", "numpy.exp"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.low_freq_mutate_np"], []], "home.repos.pwc.inspect_result.feobi1999_tdd.modeling.poolers.ROIPooler.__init__": [[105, 193], ["torch.nn.Module.__init__", "isinstance", "int", "int", "len", "isinstance", "isinstance", "torch.nn.ModuleList", "math.log2", "math.log2", "math.isclose", "math.isclose", "len", "torch.nn.ModuleList", "int", "int", "detectron2.layers.ROIAlign", "torch.nn.ModuleList", "detectron2.layers.ROIAlign", "torch.nn.ModuleList", "ValueError", "torchvision.ops.RoIPool", "detectron2.layers.ROIAlignRotated"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "output_size", ",", "\n", "scales", ",", "\n", "sampling_ratio", ",", "\n", "pooler_type", ",", "\n", "canonical_box_size", "=", "224", ",", "\n", "canonical_level", "=", "4", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            output_size (int, tuple[int] or list[int]): output size of the pooled region,\n                e.g., 14 x 14. If tuple or list is given, the length must be 2.\n            scales (list[float]): The scale for each low-level pooling op relative to\n                the input image. For a feature map with stride s relative to the input\n                image, scale is defined as 1/s. The stride must be power of 2.\n                When there are multiple scales, they must form a pyramid, i.e. they must be\n                a monotically decreasing geometric sequence with a factor of 1/2.\n            sampling_ratio (int): The `sampling_ratio` parameter for the ROIAlign op.\n            pooler_type (string): Name of the type of pooling operation that should be applied.\n                For instance, \"ROIPool\" or \"ROIAlignV2\".\n            canonical_box_size (int): A canonical box size in pixels (sqrt(box area)). The default\n                is heuristically defined as 224 pixels in the FPN paper (based on ImageNet\n                pre-training).\n            canonical_level (int): The feature map level index from which a canonically-sized box\n                should be placed. The default is defined as level 4 (stride=16) in the FPN paper,\n                i.e., a box of size 224x224 will be placed on the feature with stride=16.\n                The box placement for all boxes will be determined from their sizes w.r.t\n                canonical_box_size. For example, a box whose area is 4x that of a canonical box\n                should be used to pool features from feature level ``canonical_level+1``.\n\n                Note that the actual input feature maps given to this module may not have\n                sufficiently many levels for the input boxes. If the boxes are too large or too\n                small for the input feature maps, the closest level will be used.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "isinstance", "(", "output_size", ",", "int", ")", ":", "\n", "            ", "output_size", "=", "(", "output_size", ",", "output_size", ")", "\n", "", "assert", "len", "(", "output_size", ")", "==", "2", "\n", "assert", "isinstance", "(", "output_size", "[", "0", "]", ",", "int", ")", "and", "isinstance", "(", "output_size", "[", "1", "]", ",", "int", ")", "\n", "self", ".", "output_size", "=", "output_size", "\n", "\n", "# self.conv_cross_1 = nn.Conv2d(256, 256, kernel_size=2, stride=1)", "\n", "# self.conv_cross_2 = nn.Conv2d(256, 256, kernel_size=2, stride=1)", "\n", "\n", "if", "pooler_type", "==", "\"ROIAlign\"", ":", "\n", "            ", "self", ".", "level_poolers", "=", "nn", ".", "ModuleList", "(", "\n", "ROIAlign", "(", "\n", "output_size", ",", "spatial_scale", "=", "scale", ",", "sampling_ratio", "=", "sampling_ratio", ",", "aligned", "=", "False", "\n", ")", "\n", "for", "scale", "in", "scales", "\n", ")", "\n", "", "elif", "pooler_type", "==", "\"ROIAlignV2\"", ":", "\n", "            ", "self", ".", "level_poolers", "=", "nn", ".", "ModuleList", "(", "\n", "ROIAlign", "(", "\n", "output_size", ",", "spatial_scale", "=", "scale", ",", "sampling_ratio", "=", "sampling_ratio", ",", "aligned", "=", "True", "\n", ")", "\n", "for", "scale", "in", "scales", "\n", ")", "\n", "", "elif", "pooler_type", "==", "\"ROIPool\"", ":", "\n", "            ", "self", ".", "level_poolers", "=", "nn", ".", "ModuleList", "(", "\n", "RoIPool", "(", "output_size", ",", "spatial_scale", "=", "scale", ")", "for", "scale", "in", "scales", "\n", ")", "\n", "", "elif", "pooler_type", "==", "\"ROIAlignRotated\"", ":", "\n", "            ", "self", ".", "level_poolers", "=", "nn", ".", "ModuleList", "(", "\n", "ROIAlignRotated", "(", "output_size", ",", "spatial_scale", "=", "scale", ",", "sampling_ratio", "=", "sampling_ratio", ")", "\n", "for", "scale", "in", "scales", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown pooler type: {}\"", ".", "format", "(", "pooler_type", ")", ")", "\n", "\n", "# Map scale (defined as 1 / stride) to its feature map level under the", "\n", "# assumption that stride is a power of 2.", "\n", "", "min_level", "=", "-", "(", "math", ".", "log2", "(", "scales", "[", "0", "]", ")", ")", "\n", "max_level", "=", "-", "(", "math", ".", "log2", "(", "scales", "[", "-", "1", "]", ")", ")", "\n", "assert", "math", ".", "isclose", "(", "min_level", ",", "int", "(", "min_level", ")", ")", "and", "math", ".", "isclose", "(", "\n", "max_level", ",", "int", "(", "max_level", ")", "\n", ")", ",", "\"Featuremap stride is not power of 2!\"", "\n", "self", ".", "min_level", "=", "int", "(", "min_level", ")", "\n", "self", ".", "max_level", "=", "int", "(", "max_level", ")", "\n", "assert", "(", "\n", "len", "(", "scales", ")", "==", "self", ".", "max_level", "-", "self", ".", "min_level", "+", "1", "\n", ")", ",", "\"[ROIPooler] Sizes of input featuremaps do not form a pyramid!\"", "\n", "assert", "0", "<=", "self", ".", "min_level", "and", "self", ".", "min_level", "<=", "self", ".", "max_level", "\n", "self", ".", "canonical_level", "=", "canonical_level", "\n", "assert", "canonical_box_size", ">", "0", "\n", "self", ".", "canonical_box_size", "=", "canonical_box_size", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.modeling.poolers.ROIPooler.forward": [[205, 296], ["len", "poolers.convert_boxes_to_pooler_format", "poolers.assign_boxes_to_levels", "convert_boxes_to_pooler_format.size", "torch.zeros", "enumerate", "torch.zeros_like", "int", "isinstance", "isinstance", "len", "len", "len", "x[].size", "x[].size", "len", "len", "torch.zeros", "torch.zeros.index_put_", "detectron2.layers.nonzero_tuple", "pooler"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.modeling.poolers.convert_boxes_to_pooler_format", "home.repos.pwc.inspect_result.feobi1999_tdd.modeling.poolers.assign_boxes_to_levels"], ["", "def", "forward", "(", "self", ",", "x", ":", "List", "[", "torch", ".", "Tensor", "]", ",", "box_lists", ":", "List", "[", "Boxes", "]", ",", "branch", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x (list[Tensor]): A list of feature maps of NCHW shape, with scales matching those\n                used to construct this module.\n            box_lists (list[Boxes] | list[RotatedBoxes]):\n                A list of N Boxes or N RotatedBoxes, where N is the number of images in the batch.\n                The box coordinates are defined on the original image and\n                will be scaled by the `scales` argument of :class:`ROIPooler`.\n\n        Returns:\n            Tensor:\n                A tensor of shape (M, C, output_size, output_size) where M is the total number of\n                boxes aggregated over all N batch images and C is the number of channels in `x`.\n        \"\"\"", "\n", "\n", "if", "branch", "==", "\"supervised_cross\"", ":", "\n", "#", "\n", "#merge first layer", "\n", "# feature = copy.deepcopy(x)", "\n", "# x  feature list [] x[0]  [2,C,h,w]", "\n", "# first_feature = x[0]", "\n", "# print(x[0].shape)", "\n", "            ", "feature", "=", "x", "[", "0", "]", "\n", "feature2", "=", "torch", ".", "zeros_like", "(", "feature", ")", "\n", "im_per_gpu", "=", "int", "(", "feature", ".", "shape", "[", "0", "]", "/", "2", ")", "\n", "# source_feature, fft_feature = torch.split(feature,[im_per_gpu, im_per_gpu], dim=0)", "\n", "# conv_feature = nn.Conv2d(256, 256, kernel_size=3, stride=1,padding=1).cuda()(feature[0])", "\n", "# for name, param in self.conv_cross1.named_parameters():", "\n", "#     param.requires_grad = True", "\n", "#     # logger.info('after requires_grad is : %s' % param.requires_grad)", "\n", "#", "\n", "# for name, param in self.conv_cross2.named_parameters():", "\n", "#     param.requires_grad = True", "\n", "\n", "# source_conv=self.conv_cross1(source_feature)", "\n", "# fft_conv = self.conv_cross2(fft_feature)", "\n", "# # print(\"source_feature:\",source_feature.shape)", "\n", "# # print(\"source_conv:\",source_conv.shape)", "\n", "# feature2[0] =  ((source_feature+fft_conv)/2).squeeze(0)", "\n", "# # # print(\"source_feature2\",source_feature2.shape)", "\n", "# feature2[1] = ((fft_feature + source_conv)/2).squeeze(0)", "\n", "\n", "x", "[", "0", "]", "=", "feature2", "\n", "\n", "", "num_level_assignments", "=", "len", "(", "self", ".", "level_poolers", ")", "\n", "\n", "assert", "isinstance", "(", "x", ",", "list", ")", "and", "isinstance", "(", "\n", "box_lists", ",", "list", "\n", ")", ",", "\"Arguments to pooler must be lists\"", "\n", "assert", "(", "\n", "len", "(", "x", ")", "==", "num_level_assignments", "\n", ")", ",", "\"unequal value, num_level_assignments={}, but x is list of {} Tensors\"", ".", "format", "(", "\n", "num_level_assignments", ",", "len", "(", "x", ")", "\n", ")", "\n", "\n", "assert", "len", "(", "box_lists", ")", "==", "x", "[", "0", "]", ".", "size", "(", "\n", "0", "\n", ")", ",", "\"unequal value, x[0] batch dim 0 is {}, but box_list has length {}\"", ".", "format", "(", "\n", "x", "[", "0", "]", ".", "size", "(", "0", ")", ",", "len", "(", "box_lists", ")", "\n", ")", "\n", "if", "len", "(", "box_lists", ")", "==", "0", ":", "\n", "            ", "return", "torch", ".", "zeros", "(", "\n", "(", "0", ",", "x", "[", "0", "]", ".", "shape", "[", "1", "]", ")", "+", "self", ".", "output_size", ",", "device", "=", "x", "[", "0", "]", ".", "device", ",", "dtype", "=", "x", "[", "0", "]", ".", "dtype", "\n", ")", "\n", "\n", "", "pooler_fmt_boxes", "=", "convert_boxes_to_pooler_format", "(", "box_lists", ")", "\n", "\n", "if", "num_level_assignments", "==", "1", ":", "\n", "            ", "return", "self", ".", "level_poolers", "[", "0", "]", "(", "x", "[", "0", "]", ",", "pooler_fmt_boxes", ")", "\n", "\n", "", "level_assignments", "=", "assign_boxes_to_levels", "(", "\n", "box_lists", ",", "self", ".", "min_level", ",", "self", ".", "max_level", ",", "self", ".", "canonical_box_size", ",", "self", ".", "canonical_level", "\n", ")", "\n", "\n", "num_boxes", "=", "pooler_fmt_boxes", ".", "size", "(", "0", ")", "\n", "num_channels", "=", "x", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "output_size", "=", "self", ".", "output_size", "[", "0", "]", "\n", "\n", "dtype", ",", "device", "=", "x", "[", "0", "]", ".", "dtype", ",", "x", "[", "0", "]", ".", "device", "\n", "output", "=", "torch", ".", "zeros", "(", "\n", "(", "num_boxes", ",", "num_channels", ",", "output_size", ",", "output_size", ")", ",", "dtype", "=", "dtype", ",", "device", "=", "device", "\n", ")", "\n", "\n", "for", "level", ",", "pooler", "in", "enumerate", "(", "self", ".", "level_poolers", ")", ":", "\n", "            ", "inds", "=", "nonzero_tuple", "(", "level_assignments", "==", "level", ")", "[", "0", "]", "\n", "pooler_fmt_boxes_level", "=", "pooler_fmt_boxes", "[", "inds", "]", "\n", "# Use index_put_ instead of advance indexing, to avoid pytorch/issues/49852", "\n", "output", ".", "index_put_", "(", "(", "inds", ",", ")", ",", "pooler", "(", "x", "[", "level", "]", ",", "pooler_fmt_boxes_level", ")", ")", "\n", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.modeling.poolers.assign_boxes_to_levels": [[22, 59], ["torch.sqrt", "torch.floor", "torch.clamp", "detectron2.layers.cat", "torch.clamp.to", "torch.log2", "boxes.area"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.GenericMask.area"], ["def", "assign_boxes_to_levels", "(", "\n", "box_lists", ":", "List", "[", "Boxes", "]", ",", "\n", "min_level", ":", "int", ",", "\n", "max_level", ":", "int", ",", "\n", "canonical_box_size", ":", "int", ",", "\n", "canonical_level", ":", "int", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Map each box in `box_lists` to a feature map level index and return the assignment\n    vector.\n\n    Args:\n        box_lists (list[Boxes] | list[RotatedBoxes]): A list of N Boxes or N RotatedBoxes,\n            where N is the number of images in the batch.\n        min_level (int): Smallest feature map level index. The input is considered index 0,\n            the output of stage 1 is index 1, and so.\n        max_level (int): Largest feature map level index.\n        canonical_box_size (int): A canonical box size in pixels (sqrt(box area)).\n        canonical_level (int): The feature map level index on which a canonically-sized box\n            should be placed.\n\n    Returns:\n        A tensor of length M, where M is the total number of boxes aggregated over all\n            N batch images. The memory layout corresponds to the concatenation of boxes\n            from all images. Each element is the feature map index, as an offset from\n            `self.min_level`, for the corresponding box (so value i means the box is at\n            `self.min_level + i`).\n    \"\"\"", "\n", "box_sizes", "=", "torch", ".", "sqrt", "(", "cat", "(", "[", "boxes", ".", "area", "(", ")", "for", "boxes", "in", "box_lists", "]", ")", ")", "\n", "# Eqn.(1) in FPN paper", "\n", "level_assignments", "=", "torch", ".", "floor", "(", "\n", "canonical_level", "+", "torch", ".", "log2", "(", "box_sizes", "/", "canonical_box_size", "+", "1e-8", ")", "\n", ")", "\n", "# clamp level to (min, max), in case the box size is too large or too small", "\n", "# for the available feature maps", "\n", "level_assignments", "=", "torch", ".", "clamp", "(", "level_assignments", ",", "min", "=", "min_level", ",", "max", "=", "max_level", ")", "\n", "return", "level_assignments", ".", "to", "(", "torch", ".", "int64", ")", "-", "min_level", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.modeling.poolers._fmt_box_list": [[61, 66], ["torch.full_like", "detectron2.layers.cat"], "function", ["None"], ["", "def", "_fmt_box_list", "(", "box_tensor", ",", "batch_index", ":", "int", ")", ":", "\n", "    ", "repeated_index", "=", "torch", ".", "full_like", "(", "\n", "box_tensor", "[", ":", ",", ":", "1", "]", ",", "batch_index", ",", "dtype", "=", "box_tensor", ".", "dtype", ",", "device", "=", "box_tensor", ".", "device", "\n", ")", "\n", "return", "cat", "(", "(", "repeated_index", ",", "box_tensor", ")", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.modeling.poolers.convert_boxes_to_pooler_format": [[68, 97], ["detectron2.layers.cat", "poolers._fmt_box_list", "enumerate"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.modeling.poolers._fmt_box_list"], ["", "def", "convert_boxes_to_pooler_format", "(", "box_lists", ":", "List", "[", "Boxes", "]", ")", ":", "\n", "    ", "\"\"\"\n    Convert all boxes in `box_lists` to the low-level format used by ROI pooling ops\n    (see description under Returns).\n\n    Args:\n        box_lists (list[Boxes] | list[RotatedBoxes]):\n            A list of N Boxes or N RotatedBoxes, where N is the number of images in the batch.\n\n    Returns:\n        When input is list[Boxes]:\n            A tensor of shape (M, 5), where M is the total number of boxes aggregated over all\n            N batch images.\n            The 5 columns are (batch index, x0, y0, x1, y1), where batch index\n            is the index in [0, N) identifying which batch image the box with corners at\n            (x0, y0, x1, y1) comes from.\n        When input is list[RotatedBoxes]:\n            A tensor of shape (M, 6), where M is the total number of boxes aggregated over all\n            N batch images.\n            The 6 columns are (batch index, x_ctr, y_ctr, width, height, angle_degrees),\n            where batch index is the index in [0, N) identifying which batch image the\n            rotated box (x_ctr, y_ctr, width, height, angle_degrees) comes from.\n    \"\"\"", "\n", "pooler_fmt_boxes", "=", "cat", "(", "\n", "[", "_fmt_box_list", "(", "box_list", ".", "tensor", ",", "i", ")", "for", "i", ",", "box_list", "in", "enumerate", "(", "box_lists", ")", "]", ",", "dim", "=", "0", "\n", "# [_fmt_box_list(box_list, i) for i, box_list in enumerate(box_lists)], dim=0", "\n", ")", "\n", "\n", "return", "pooler_fmt_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.rcnn.TwoStagePseudoLabGeneralizedRCNN.forward": [[14, 104], ["rcnn.TwoStagePseudoLabGeneralizedRCNN.preprocess_image", "rcnn.TwoStagePseudoLabGeneralizedRCNN.backbone", "rcnn.TwoStagePseudoLabGeneralizedRCNN.inference", "rcnn.TwoStagePseudoLabGeneralizedRCNN.proposal_generator", "rcnn.TwoStagePseudoLabGeneralizedRCNN.roi_heads", "losses.update", "losses.update", "x[].to", "rcnn.TwoStagePseudoLabGeneralizedRCNN.proposal_generator", "rcnn.TwoStagePseudoLabGeneralizedRCNN.roi_heads", "rcnn.TwoStagePseudoLabGeneralizedRCNN.proposal_generator", "rcnn.TwoStagePseudoLabGeneralizedRCNN.roi_heads", "losses.update", "losses.update"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.inference"], ["    ", "def", "forward", "(", "\n", "self", ",", "batched_inputs", ",", "branch", "=", "\"supervised\"", ",", "given_proposals", "=", "None", ",", "val_mode", "=", "False", "\n", ")", ":", "\n", "\n", "\n", "        ", "'''\n        batched_inputs: list of inputs\n        len(batched_inputs) = image_per_batch\n        batched_inputs[0] dict keys() ['file_name', 'height', 'width', 'image_id', 'image'])\n        '''", "\n", "\n", "#for fft try", "\n", "\n", "\n", "if", "(", "not", "self", ".", "training", ")", "and", "(", "not", "val_mode", ")", ":", "\n", "\n", "            ", "import", "pdb", "\n", "# pdb.set_trace()", "\n", "return", "self", ".", "inference", "(", "batched_inputs", ")", "\n", "\n", "\n", "\n", "\n", "", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "import", "pdb", "\n", "# pdb.set_trace()", "\n", "if", "\"instances\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n", "\n", "", "else", ":", "\n", "            ", "gt_instances", "=", "None", "\n", "\n", "", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "branch", "==", "\"supervised\"", ":", "\n", "# Region proposal network", "\n", "            ", "proposals_rpn", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "gt_instances", "\n", ")", "\n", "\n", "# # roi_head lower branch", "\n", "_", ",", "detector_losses", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "features", ",", "proposals_rpn", ",", "gt_instances", ",", "branch", "=", "branch", "\n", ")", "\n", "\n", "losses", "=", "{", "}", "\n", "losses", ".", "update", "(", "detector_losses", ")", "\n", "losses", ".", "update", "(", "proposal_losses", ")", "\n", "return", "losses", ",", "[", "]", ",", "[", "]", ",", "None", "\n", "\n", "", "elif", "branch", "==", "\"unsup_data_weak\"", ":", "\n", "# Region proposal network", "\n", "            ", "proposals_rpn", ",", "_", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "None", ",", "compute_loss", "=", "False", "\n", ")", "\n", "\n", "# roi_head lower branch (keep this for further production)  # notice that we do not use any target in ROI head to do inference !", "\n", "proposals_roih", ",", "ROI_predictions", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "\n", "features", ",", "\n", "proposals_rpn", ",", "\n", "targets", "=", "None", ",", "\n", "compute_loss", "=", "False", ",", "\n", "branch", "=", "branch", ",", "\n", ")", "\n", "\n", "return", "{", "}", ",", "proposals_rpn", ",", "proposals_roih", ",", "ROI_predictions", "\n", "\n", "", "elif", "branch", "==", "\"val_loss\"", ":", "\n", "\n", "# Region proposal network", "\n", "            ", "proposals_rpn", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "gt_instances", ",", "compute_val_loss", "=", "True", "\n", ")", "\n", "\n", "# roi_head lower branch", "\n", "_", ",", "detector_losses", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "\n", "features", ",", "\n", "proposals_rpn", ",", "\n", "gt_instances", ",", "\n", "branch", "=", "branch", ",", "\n", "compute_val_loss", "=", "True", ",", "\n", ")", "\n", "\n", "losses", "=", "{", "}", "\n", "losses", ".", "update", "(", "detector_losses", ")", "\n", "losses", ".", "update", "(", "proposal_losses", ")", "\n", "return", "losses", ",", "[", "]", ",", "[", "]", ",", "None", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.forward": [[14, 94], ["pdb.set_trace", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.preprocess_image", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.backbone", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.inference", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.proposal_generator", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.roi_heads", "losses.update", "losses.update", "x[].to", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.proposal_generator", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.roi_heads", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.proposal_generator", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.roi_heads", "losses.update", "losses.update"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.inference"], ["    ", "def", "forward", "(", "\n", "self", ",", "batched_inputs", ",", "branch", "=", "\"supervised\"", ",", "given_proposals", "=", "None", ",", "val_mode", "=", "False", "\n", ")", ":", "\n", "\n", "        ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "if", "(", "not", "self", ".", "training", ")", "and", "(", "not", "val_mode", ")", ":", "\n", "\n", "\n", "\n", "            ", "return", "self", ".", "inference", "(", "batched_inputs", ")", "\n", "\n", "", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "\n", "if", "\"instances\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "", "else", ":", "\n", "            ", "gt_instances", "=", "None", "\n", "\n", "", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "\n", "\n", "\n", "\n", "if", "branch", "==", "\"supervised\"", ":", "\n", "# Region proposal network", "\n", "            ", "proposals_rpn", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "gt_instances", "\n", ")", "\n", "\n", "# # roi_head lower branch", "\n", "_", ",", "detector_losses", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "features", ",", "proposals_rpn", ",", "gt_instances", ",", "branch", "=", "branch", "\n", ")", "\n", "\n", "losses", "=", "{", "}", "\n", "losses", ".", "update", "(", "detector_losses", ")", "\n", "losses", ".", "update", "(", "proposal_losses", ")", "\n", "return", "losses", ",", "[", "]", ",", "[", "]", ",", "None", "\n", "\n", "", "elif", "branch", "==", "\"unsup_data_weak\"", ":", "\n", "# Region proposal network", "\n", "            ", "proposals_rpn", ",", "_", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "None", ",", "compute_loss", "=", "False", "\n", ")", "\n", "\n", "# roi_head lower branch (keep this for further production)  # notice that we do not use any target in ROI head to do inference !", "\n", "proposals_roih", ",", "ROI_predictions", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "\n", "features", ",", "\n", "proposals_rpn", ",", "\n", "targets", "=", "None", ",", "\n", "compute_loss", "=", "False", ",", "\n", "branch", "=", "branch", ",", "\n", ")", "\n", "\n", "return", "{", "}", ",", "proposals_rpn", ",", "proposals_roih", ",", "ROI_predictions", "\n", "\n", "", "elif", "branch", "==", "\"val_loss\"", ":", "\n", "\n", "# Region proposal network", "\n", "            ", "proposals_rpn", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "gt_instances", ",", "compute_val_loss", "=", "True", "\n", ")", "\n", "\n", "# roi_head lower branch", "\n", "_", ",", "detector_losses", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "\n", "features", ",", "\n", "proposals_rpn", ",", "\n", "gt_instances", ",", "\n", "branch", "=", "branch", ",", "\n", "compute_val_loss", "=", "True", ",", "\n", ")", "\n", "\n", "losses", "=", "{", "}", "\n", "losses", ".", "update", "(", "detector_losses", ")", "\n", "losses", ".", "update", "(", "proposal_losses", ")", "\n", "return", "losses", ",", "[", "]", ",", "[", "]", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.inference": [[97, 166], ["cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.preprocess_image", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.backbone", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.roi_heads", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.roi_heads.forward_with_given_boxes", "x[].to", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN.proposal_generator", "x.to", "torch.jit.is_scripting", "cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN._postprocess", "x[].to"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN._postprocess"], ["", "", "def", "inference", "(", "\n", "self", ",", "\n", "batched_inputs", ",", "\n", "detected_instances", "=", "None", ",", "\n", "do_postprocess", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Run inference on the given inputs.\n\n        Args:\n            batched_inputs (list[dict]): same as in :meth:`forward`\n            detected_instances (None or list[Instances]): if not None, it\n                contains an `Instances` object per image. The `Instances`\n                object contains \"pred_boxes\" and \"pred_classes\" which are\n                known boxes in the image.\n                The inference will then skip the detection of bounding boxes,\n                and only predict other per-ROI outputs.\n            do_postprocess (bool): whether to apply post-processing on the outputs.\n\n        Returns:\n            When do_postprocess=True, same as in :meth:`forward`.\n            Otherwise, a list[Instances] containing raw network outputs.\n        \"\"\"", "\n", "if", "\"instances\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n", "", "else", ":", "\n", "            ", "gt_instances", "=", "None", "\n", "\n", "", "assert", "not", "self", ".", "training", "\n", "import", "pdb", "\n", "# pdb.set_trace()", "\n", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "features_save", "=", "[", "]", "\n", "\n", "img_id", "=", "[", "x", "[", "\"image_id\"", "]", "for", "x", "in", "batched_inputs", "]", "\n", "\n", "if", "detected_instances", "is", "None", ":", "\n", "            ", "if", "self", ".", "proposal_generator", "is", "not", "None", ":", "\n", "                ", "proposals", ",", "_", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "None", ")", "\n", "", "else", ":", "\n", "                ", "assert", "\"proposals\"", "in", "batched_inputs", "[", "0", "]", "\n", "proposals", "=", "[", "x", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "# proposals = [x[\"instances\"].to(self.device) for x in batched_inputs]", "\n", "\n", "", "import", "pdb", "\n", "\n", "results", ",", "box_features_save", "=", "self", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ",", "None", ")", "\n", "#     results,box_features_save = self.roi_heads(images, features, proposals, None, branch='proposal_pooling')", "\n", "# else:", "\n", "#     results,box_features_save = self.roi_heads(images, features, gt_instances, None,branch=\"gt_pooling\")", "\n", "# pred_cls = results[0]._fields['pred_classes']", "\n", "pred_cls", "=", "results", "[", "0", "]", ".", "_fields", "[", "'pred_classes'", "]", "\n", "pred_scores", "=", "results", "[", "0", "]", ".", "_fields", "[", "'scores'", "]", "\n", "", "else", ":", "\n", "            ", "detected_instances", "=", "[", "x", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "detected_instances", "]", "\n", "results", "=", "self", ".", "roi_heads", ".", "forward_with_given_boxes", "(", "features", ",", "detected_instances", ")", "\n", "\n", "", "if", "do_postprocess", ":", "\n", "            ", "assert", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ",", "\"Scripting is not supported for postprocess.\"", "\n", "# return self._postprocess(results, batched_inputs, images.image_sizes)", "\n", "# return self._postprocess(results, batched_inputs, images.image_sizes), box_features_save, pred_cls ,pred_scores", "\n", "return", "self", ".", "_postprocess", "(", "results", ",", "batched_inputs", ",", "images", ".", "image_sizes", ")", ",", "features_save", "\n", "\n", "# return self._postprocess(results, batched_inputs, images.image_sizes), box_features_save, pred_cls, img_id, proposals", "\n", "", "else", ":", "\n", "            ", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN._postprocess": [[167, 185], ["zip", "input_per_image.get", "input_per_image.get", "detectron2.modeling.postprocessing.detector_postprocess", "processed_results.append"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_postprocess", "(", "instances", ",", "batched_inputs", ",", "image_sizes", ")", ":", "\n", "        ", "\"\"\"\n        Rescale the output instances to the target size.\n        \"\"\"", "\n", "# note: private function; subject to changes", "\n", "processed_results", "=", "[", "]", "\n", "for", "results_per_image", ",", "input_per_image", ",", "image_size", "in", "zip", "(", "\n", "instances", ",", "batched_inputs", ",", "image_sizes", "\n", ")", ":", "\n", "            ", "height", "=", "input_per_image", ".", "get", "(", "\"height\"", ",", "image_size", "[", "0", "]", ")", "\n", "width", "=", "input_per_image", ".", "get", "(", "\"width\"", ",", "image_size", "[", "1", "]", ")", "\n", "r", "=", "detector_postprocess", "(", "results_per_image", ",", "height", ",", "width", ")", "\n", "import", "pdb", "\n", "# pdb.set_trace()", "\n", "processed_results", ".", "append", "(", "{", "\"instances\"", ":", "r", "}", ")", "\n", "\n", "", "return", "processed_results", "", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.ts_ensemble.EnsembleTSModel.__init__": [[7, 17], ["torch.Module.__init__", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["    ", "def", "__init__", "(", "self", ",", "modelTeacher", ",", "modelStudent", ")", ":", "\n", "        ", "super", "(", "EnsembleTSModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "isinstance", "(", "modelTeacher", ",", "(", "DistributedDataParallel", ",", "DataParallel", ")", ")", ":", "\n", "            ", "modelTeacher", "=", "modelTeacher", ".", "module", "\n", "", "if", "isinstance", "(", "modelStudent", ",", "(", "DistributedDataParallel", ",", "DataParallel", ")", ")", ":", "\n", "            ", "modelStudent", "=", "modelStudent", ".", "module", "\n", "\n", "", "self", ".", "modelTeacher", "=", "modelTeacher", "\n", "self", ".", "modelStudent", "=", "modelStudent", "", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.__init__": [[36, 143], ["detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN.__init__", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.register_buffer", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.kaiming_normal_", "torch.kaiming_normal_", "torch.kaiming_normal_", "torch.kaiming_normal_", "torch.kaiming_normal_", "torch.kaiming_normal_", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.theta.bias.data.fill_", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.phi.bias.data.fill_", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.g.bias.data.fill_", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.Wz.data.fill_", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.Wz2.data.fill_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "int", "range", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "int", "range", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "Wgs.append", "Wqs.append", "Wks.append", "Wvs.append", "Wgs.append", "Wqs.append", "Wks.append", "Wvs.append", "Wgs_2.append", "Wqs_2.append", "Wks_2.append", "Wvs_2.append", "two_head_rcnn_refine.Conv2d", "two_head_rcnn_refine.make_fc", "two_head_rcnn_refine.make_fc", "two_head_rcnn_refine.Conv2d", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "two_head_rcnn_refine.Conv2d", "two_head_rcnn_refine.make_fc", "two_head_rcnn_refine.make_fc", "two_head_rcnn_refine.Conv2d", "two_head_rcnn_refine.Conv2d", "two_head_rcnn_refine.make_fc", "two_head_rcnn_refine.make_fc", "two_head_rcnn_refine.Conv2d", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.make_fc", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.make_fc", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.make_fc", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.make_fc", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.make_fc", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.make_fc"], ["    ", "@", "configurable", "\n", "def", "__init__", "(", "self", ",", "roi_heads_2", ",", "cross_alpha", ",", "cross_thresh", ",", "object_relation", ",", "both_attention", ",", "share_object_relation", ",", "group", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "# super().__init__()", "\n", "self", ".", "roi_heads_2", "=", "roi_heads_2", "\n", "self", ".", "init_head2", "=", "False", "\n", "self", ".", "cross_alpha", "=", "cross_alpha", "\n", "self", ".", "cross_thresh", "=", "cross_thresh", "\n", "self", ".", "register_buffer", "(", "\"need_copy\"", ",", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "object_relation", "=", "object_relation", "\n", "self", ".", "both_attention", "=", "both_attention", "\n", "self", ".", "share", "=", "share_object_relation", "\n", "self", ".", "group", "=", "group", "\n", "if", "self", ".", "both_attention", ":", "\n", "            ", "self", ".", "theta", "=", "nn", ".", "Linear", "(", "9", ",", "9", ")", "\n", "self", ".", "phi", "=", "nn", ".", "Linear", "(", "9", ",", "9", ")", "\n", "self", ".", "g", "=", "nn", ".", "Linear", "(", "9", ",", "9", ")", "\n", "self", ".", "h", "=", "nn", ".", "Linear", "(", "9", ",", "9", ")", "\n", "self", ".", "Wz", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "9", ")", ")", "\n", "self", ".", "Wz2", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "9", ")", ")", "\n", "\n", "self", ".", "scale", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "[", "5", "]", ")", ",", "requires_grad", "=", "False", ")", "\n", "init", ".", "kaiming_normal_", "(", "self", ".", "theta", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "init", ".", "kaiming_normal_", "(", "self", ".", "phi", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "init", ".", "kaiming_normal_", "(", "self", ".", "g", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "self", ".", "theta", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "phi", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "g", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "Wz", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "Wz2", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "if", "self", ".", "object_relation", ":", "\n", "            ", "if", "self", ".", "share", ":", "\n", "                ", "representation_size", "=", "1024", "\n", "self", ".", "embed_dim", "=", "64", "\n", "self", ".", "groups", "=", "self", ".", "group", "\n", "self", ".", "feat_dim", "=", "representation_size", "\n", "input_size", "=", "12544", "\n", "self", ".", "base_stage", "=", "2", "\n", "self", ".", "advanced_stage", "=", "0", "\n", "\n", "self", ".", "base_num", "=", "512", "\n", "self", ".", "advanced_num", "=", "int", "(", "self", ".", "base_num", "*", "0.2", ")", "\n", "\n", "Wgs", ",", "Wqs", ",", "Wks", ",", "Wvs", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "base_stage", "+", "self", ".", "advanced_stage", "+", "1", ")", ":", "\n", "                    ", "r_size", "=", "input_size", "if", "i", "==", "0", "else", "representation_size", "\n", "\n", "if", "i", "==", "self", ".", "base_stage", "and", "self", ".", "advanced_stage", "==", "0", ":", "\n", "                        ", "break", "\n", "\n", "\n", "", "Wgs", ".", "append", "(", "Conv2d", "(", "self", ".", "embed_dim", ",", "self", ".", "groups", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ")", "\n", "Wqs", ".", "append", "(", "make_fc", "(", "self", ".", "feat_dim", ",", "self", ".", "feat_dim", ")", ")", "\n", "Wks", ".", "append", "(", "make_fc", "(", "self", ".", "feat_dim", ",", "self", ".", "feat_dim", ")", ")", "\n", "Wvs", ".", "append", "(", "Conv2d", "(", "self", ".", "feat_dim", "*", "self", ".", "groups", ",", "self", ".", "feat_dim", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "self", ".", "groups", ")", ")", "\n", "\n", "for", "l", "in", "[", "Wgs", "[", "i", "]", ",", "Wvs", "[", "i", "]", "]", ":", "\n", "                        ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "", "", "self", ".", "Wgs", "=", "nn", ".", "ModuleList", "(", "Wgs", ")", "\n", "self", ".", "Wqs", "=", "nn", ".", "ModuleList", "(", "Wqs", ")", "\n", "self", ".", "Wks", "=", "nn", ".", "ModuleList", "(", "Wks", ")", "\n", "self", ".", "Wvs", "=", "nn", ".", "ModuleList", "(", "Wvs", ")", "\n", "", "else", ":", "\n", "                ", "representation_size", "=", "1024", "\n", "self", ".", "embed_dim", "=", "64", "\n", "self", ".", "groups", "=", "16", "\n", "self", ".", "feat_dim", "=", "representation_size", "\n", "input_size", "=", "12544", "\n", "self", ".", "base_stage", "=", "2", "\n", "self", ".", "advanced_stage", "=", "0", "\n", "\n", "self", ".", "base_num", "=", "512", "\n", "self", ".", "advanced_num", "=", "int", "(", "self", ".", "base_num", "*", "0.2", ")", "\n", "\n", "Wgs", ",", "Wgs_2", ",", "Wqs", ",", "Wks", ",", "Wvs", ",", "Wqs_2", ",", "Wks_2", ",", "Wvs_2", ",", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "base_stage", "+", "self", ".", "advanced_stage", "+", "1", ")", ":", "\n", "                    ", "r_size", "=", "input_size", "if", "i", "==", "0", "else", "representation_size", "\n", "\n", "if", "i", "==", "self", ".", "base_stage", "and", "self", ".", "advanced_stage", "==", "0", ":", "\n", "                        ", "break", "\n", "\n", "\n", "", "Wgs", ".", "append", "(", "Conv2d", "(", "self", ".", "embed_dim", ",", "self", ".", "groups", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ")", "\n", "Wqs", ".", "append", "(", "make_fc", "(", "self", ".", "feat_dim", ",", "self", ".", "feat_dim", ")", ")", "\n", "Wks", ".", "append", "(", "make_fc", "(", "self", ".", "feat_dim", ",", "self", ".", "feat_dim", ")", ")", "\n", "Wvs", ".", "append", "(", "Conv2d", "(", "self", ".", "feat_dim", "*", "self", ".", "groups", ",", "self", ".", "feat_dim", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "self", ".", "groups", ")", ")", "\n", "Wgs_2", ".", "append", "(", "Conv2d", "(", "self", ".", "embed_dim", ",", "self", ".", "groups", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ")", "\n", "Wqs_2", ".", "append", "(", "make_fc", "(", "self", ".", "feat_dim", ",", "self", ".", "feat_dim", ")", ")", "\n", "Wks_2", ".", "append", "(", "make_fc", "(", "self", ".", "feat_dim", ",", "self", ".", "feat_dim", ")", ")", "\n", "Wvs_2", ".", "append", "(", "Conv2d", "(", "self", ".", "feat_dim", "*", "self", ".", "groups", ",", "self", ".", "feat_dim", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "groups", "=", "self", ".", "groups", ")", ")", "\n", "\n", "\n", "for", "l", "in", "[", "Wgs", "[", "i", "]", ",", "Wvs", "[", "i", "]", ",", "Wgs_2", "[", "i", "]", ",", "Wvs_2", "[", "i", "]", "]", ":", "\n", "                            ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "l", ".", "weight", ",", "std", "=", "0.01", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "l", ".", "bias", ",", "0", ")", "\n", "", "", "self", ".", "Wgs", "=", "nn", ".", "ModuleList", "(", "Wgs", ")", "\n", "self", ".", "Wqs", "=", "nn", ".", "ModuleList", "(", "Wqs", ")", "\n", "self", ".", "Wks", "=", "nn", ".", "ModuleList", "(", "Wks", ")", "\n", "self", ".", "Wvs", "=", "nn", ".", "ModuleList", "(", "Wvs", ")", "\n", "self", ".", "Wgs_2", "=", "nn", ".", "ModuleList", "(", "Wgs_2", ")", "\n", "self", ".", "Wqs_2", "=", "nn", ".", "ModuleList", "(", "Wqs_2", ")", "\n", "self", ".", "Wks_2", "=", "nn", ".", "ModuleList", "(", "Wks_2", ")", "\n", "self", ".", "Wvs_2", "=", "nn", ".", "ModuleList", "(", "Wvs_2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.from_config": [[145, 165], ["detectron2.modeling.backbone.build_backbone", "detectron2.modeling.proposal_generator.build_proposal_generator", "detectron2.modeling.roi_heads.build_roi_heads", "detectron2.modeling.roi_heads.build_roi_heads", "detectron2.modeling.backbone.build_backbone.output_shape", "detectron2.modeling.backbone.build_backbone.output_shape", "detectron2.modeling.backbone.build_backbone.output_shape"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.output_shape", "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.output_shape", "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.output_shape"], ["", "", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ")", ":", "\n", "\n", "\n", "        ", "backbone", "=", "build_backbone", "(", "cfg", ")", "\n", "return", "{", "\n", "\"backbone\"", ":", "backbone", ",", "\n", "\"proposal_generator\"", ":", "build_proposal_generator", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", ",", "\n", "\"roi_heads\"", ":", "build_roi_heads", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", ",", "\n", "\"roi_heads_2\"", ":", "build_roi_heads", "(", "cfg", ",", "backbone", ".", "output_shape", "(", ")", ")", ",", "\n", "\"input_format\"", ":", "cfg", ".", "INPUT", ".", "FORMAT", ",", "\n", "\"vis_period\"", ":", "cfg", ".", "VIS_PERIOD", ",", "\n", "\"pixel_mean\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_MEAN", ",", "\n", "\"pixel_std\"", ":", "cfg", ".", "MODEL", ".", "PIXEL_STD", ",", "\n", "\"cross_thresh\"", ":", "cfg", ".", "CROSS_THRESH", ",", "\n", "\"cross_alpha\"", ":", "cfg", ".", "CROSS_ALPHA", ",", "\n", "\"object_relation\"", ":", "cfg", ".", "OBJECT_RELATION", ",", "\n", "\"both_attention\"", ":", "cfg", ".", "BOTH_ATTENTION", ",", "\n", "\"share_object_relation\"", ":", "cfg", ".", "SHARE", ",", "\n", "\"group\"", ":", "cfg", ".", "GROUP", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.extract_position_embedding": [[168, 187], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.full().pow", "torch.full().pow", "torch.full().pow", "torch.full().pow", "dim_mat.view().expand.view().expand.view().expand", "position_mat.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "embedding.reshape.reshape.reshape", "div_mat.sin", "div_mat.cos", "torch.full", "torch.full", "torch.full", "torch.full", "dim_mat.view().expand.view().expand.view", "position_mat.unsqueeze().expand.unsqueeze().expand.unsqueeze", "len"], "methods", ["None"], ["", "def", "extract_position_embedding", "(", "self", ",", "position_mat", ",", "feat_dim", ",", "wave_length", "=", "1000.0", ")", ":", "\n", "        ", "device", "=", "position_mat", ".", "device", "\n", "# position_mat, [num_rois, num_nongt_rois, 4]", "\n", "feat_range", "=", "torch", ".", "arange", "(", "0", ",", "feat_dim", "/", "8", ",", "device", "=", "device", ")", "\n", "dim_mat", "=", "torch", ".", "full", "(", "(", "len", "(", "feat_range", ")", ",", ")", ",", "wave_length", ",", "device", "=", "device", ")", ".", "pow", "(", "8.0", "/", "feat_dim", "*", "feat_range", ")", "\n", "dim_mat", "=", "dim_mat", ".", "view", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", ".", "expand", "(", "*", "position_mat", ".", "shape", ",", "-", "1", ")", "\n", "\n", "position_mat", "=", "position_mat", ".", "unsqueeze", "(", "3", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "-", "1", ",", "dim_mat", ".", "shape", "[", "3", "]", ")", "\n", "position_mat", "=", "position_mat", "*", "100.0", "\n", "\n", "div_mat", "=", "position_mat", "/", "dim_mat", "\n", "sin_mat", ",", "cos_mat", "=", "div_mat", ".", "sin", "(", ")", ",", "div_mat", ".", "cos", "(", ")", "\n", "\n", "# [num_rois, num_nongt_rois, 4, feat_dim / 4]", "\n", "embedding", "=", "torch", ".", "cat", "(", "[", "sin_mat", ",", "cos_mat", "]", ",", "dim", "=", "3", ")", "\n", "# [num_rois, num_nongt_rois, feat_dim]", "\n", "embedding", "=", "embedding", ".", "reshape", "(", "embedding", ".", "shape", "[", "0", "]", ",", "embedding", ".", "shape", "[", "1", "]", ",", "embedding", ".", "shape", "[", "2", "]", "*", "embedding", ".", "shape", "[", "3", "]", ")", "\n", "\n", "return", "embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.extract_position_matrix": [[188, 220], ["torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "delta_width.log.log.log", "delta_height.log.log.log", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "center_x_ref.transpose", "center_y_ref.transpose", "bbox_width_ref.transpose", "bbox_height_ref.transpose", "delta_x.abs", "delta_y.abs"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "extract_position_matrix", "(", "bbox", ",", "ref_bbox", ")", ":", "\n", "        ", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "torch", ".", "chunk", "(", "ref_bbox", ",", "4", ",", "dim", "=", "1", ")", "\n", "bbox_width_ref", "=", "xmax", "-", "xmin", "+", "1", "\n", "bbox_height_ref", "=", "ymax", "-", "ymin", "+", "1", "\n", "center_x_ref", "=", "0.5", "*", "(", "xmin", "+", "xmax", ")", "\n", "center_y_ref", "=", "0.5", "*", "(", "ymin", "+", "ymax", ")", "\n", "\n", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "=", "torch", ".", "chunk", "(", "bbox", ",", "4", ",", "dim", "=", "1", ")", "\n", "bbox_width", "=", "xmax", "-", "xmin", "+", "1", "\n", "bbox_height", "=", "ymax", "-", "ymin", "+", "1", "\n", "center_x", "=", "0.5", "*", "(", "xmin", "+", "xmax", ")", "\n", "center_y", "=", "0.5", "*", "(", "ymin", "+", "ymax", ")", "\n", "\n", "delta_x", "=", "center_x", "-", "center_x_ref", ".", "transpose", "(", "0", ",", "1", ")", "\n", "delta_x", "=", "delta_x", "/", "bbox_width", "\n", "delta_x", "=", "(", "delta_x", ".", "abs", "(", ")", "+", "1e-3", ")", ".", "log", "(", ")", "\n", "\n", "delta_y", "=", "center_y", "-", "center_y_ref", ".", "transpose", "(", "0", ",", "1", ")", "\n", "delta_y", "=", "delta_y", "/", "bbox_height", "\n", "delta_y", "=", "(", "delta_y", ".", "abs", "(", ")", "+", "1e-3", ")", ".", "log", "(", ")", "\n", "\n", "delta_width", "=", "bbox_width", "/", "bbox_width_ref", ".", "transpose", "(", "0", ",", "1", ")", "\n", "delta_width", "=", "delta_width", ".", "log", "(", ")", "\n", "\n", "delta_height", "=", "bbox_height", "/", "bbox_height_ref", ".", "transpose", "(", "0", ",", "1", ")", "\n", "delta_height", "=", "delta_height", ".", "log", "(", ")", "\n", "\n", "position_matrix", "=", "torch", ".", "stack", "(", "[", "delta_x", ",", "delta_y", ",", "delta_width", ",", "delta_height", "]", ",", "dim", "=", "2", ")", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "return", "position_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.attention_module_multi_head": [[221, 282], ["torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu.permute", "aff_weight.squeeze.squeeze.squeeze", "q_data.reshape", "q_data_batch.permute.permute.permute", "k_data.reshape", "k_data_batch.permute.permute.permute", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "aff_scale.permute.permute.permute", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax.reshape", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "output_t.reshape.reshape.reshape", "linear_out.squeeze().squeeze", "int", "int", "k_data_batch.permute.permute.transpose", "math.sqrt", "linear_out.squeeze", "float"], "methods", ["None"], ["", "def", "attention_module_multi_head", "(", "self", ",", "roi_feat", ",", "ref_feat", ",", "position_embedding", ",", "\n", "feat_dim", "=", "1024", ",", "dim", "=", "(", "1024", ",", "1024", ",", "1024", ")", ",", "group", "=", "16", ",", "\n", "index", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n\n        :param roi_feat: [num_rois, feat_dim]\n        :param ref_feat: [num_nongt_rois, feat_dim]\n        :param position_embedding: [1, emb_dim, num_rois, num_nongt_rois]\n        :param feat_dim: should be same as dim[2]\n        :param dim: a 3-tuple of (query, key, output)\n        :param group:\n        :return:\n        \"\"\"", "\n", "dim_group", "=", "(", "dim", "[", "0", "]", "/", "group", ",", "dim", "[", "1", "]", "/", "group", ",", "dim", "[", "2", "]", "/", "group", ")", "\n", "\n", "# position_embedding, [1, emb_dim, num_rois, num_nongt_rois]", "\n", "# -> position_feat_1, [1, group, num_rois, num_nongt_rois]", "\n", "position_feat_1", "=", "F", ".", "relu", "(", "self", ".", "Wgs", "[", "index", "]", "(", "position_embedding", ")", ")", "\n", "# aff_weight, [num_rois, group, num_nongt_rois, 1]", "\n", "aff_weight", "=", "position_feat_1", ".", "permute", "(", "2", ",", "1", ",", "3", ",", "0", ")", "\n", "# aff_weight, [num_rois, group, num_nongt_rois]", "\n", "aff_weight", "=", "aff_weight", ".", "squeeze", "(", "3", ")", "\n", "\n", "# multi head", "\n", "assert", "dim", "[", "0", "]", "==", "dim", "[", "1", "]", "\n", "\n", "q_data", "=", "self", ".", "Wqs", "[", "index", "]", "(", "roi_feat", ")", "\n", "q_data_batch", "=", "q_data", ".", "reshape", "(", "-", "1", ",", "group", ",", "int", "(", "dim_group", "[", "0", "]", ")", ")", "\n", "# q_data_batch, [group, num_rois, dim_group[0]]", "\n", "q_data_batch", "=", "q_data_batch", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "k_data", "=", "self", ".", "Wks", "[", "index", "]", "(", "ref_feat", ")", "\n", "k_data_batch", "=", "k_data", ".", "reshape", "(", "-", "1", ",", "group", ",", "int", "(", "dim_group", "[", "1", "]", ")", ")", "\n", "# k_data_batch, [group, num_nongt_rois, dim_group[1]]", "\n", "k_data_batch", "=", "k_data_batch", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "# v_data, [num_nongt_rois, feat_dim]", "\n", "v_data", "=", "ref_feat", "\n", "\n", "# aff, [group, num_rois, num_nongt_rois]", "\n", "aff", "=", "torch", ".", "bmm", "(", "q_data_batch", ",", "k_data_batch", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "aff_scale", "=", "(", "1.0", "/", "math", ".", "sqrt", "(", "float", "(", "dim_group", "[", "1", "]", ")", ")", ")", "*", "aff", "\n", "# aff_scale, [num_rois, group, num_nongt_rois]", "\n", "aff_scale", "=", "aff_scale", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "# weighted_aff, [num_rois, group, num_nongt_rois]", "\n", "weighted_aff", "=", "(", "aff_weight", "+", "1e-6", ")", ".", "log", "(", ")", "+", "aff_scale", "\n", "aff_softmax", "=", "F", ".", "softmax", "(", "weighted_aff", ",", "dim", "=", "2", ")", "\n", "\n", "aff_softmax_reshape", "=", "aff_softmax", ".", "reshape", "(", "aff_softmax", ".", "shape", "[", "0", "]", "*", "aff_softmax", ".", "shape", "[", "1", "]", ",", "aff_softmax", ".", "shape", "[", "2", "]", ")", "\n", "\n", "# output_t, [num_rois * group, feat_dim]", "\n", "output_t", "=", "torch", ".", "matmul", "(", "aff_softmax_reshape", ",", "v_data", ")", "\n", "# output_t, [num_rois, group * feat_dim, 1, 1]", "\n", "output_t", "=", "output_t", ".", "reshape", "(", "-", "1", ",", "group", "*", "feat_dim", ",", "1", ",", "1", ")", "\n", "# linear_out, [num_rois, dim[2], 1, 1]", "\n", "linear_out", "=", "self", ".", "Wvs", "[", "index", "]", "(", "output_t", ")", "\n", "\n", "output", "=", "linear_out", ".", "squeeze", "(", "3", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.attentionG_module_multi_head_2": [[283, 344], ["torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu.permute", "aff_weight.squeeze.squeeze.squeeze", "q_data.reshape", "q_data_batch.permute.permute.permute", "k_data.reshape", "k_data_batch.permute.permute.permute", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "aff_scale.permute.permute.permute", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax.reshape", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "output_t.reshape.reshape.reshape", "linear_out.squeeze().squeeze", "int", "int", "k_data_batch.permute.permute.transpose", "math.sqrt", "linear_out.squeeze", "float"], "methods", ["None"], ["", "def", "attentionG_module_multi_head_2", "(", "self", ",", "roi_feat", ",", "ref_feat", ",", "position_embedding", ",", "\n", "feat_dim", "=", "1024", ",", "dim", "=", "(", "1024", ",", "1024", ",", "1024", ")", ",", "group", "=", "16", ",", "\n", "index", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n\n        :param roi_feat: [num_rois, feat_dim]\n        :param ref_feat: [num_nongt_rois, feat_dim]\n        :param position_embedding: [1, emb_dim, num_rois, num_nongt_rois]\n        :param feat_dim: should be same as dim[2]\n        :param dim: a 3-tuple of (query, key, output)\n        :param group:\n        :return:\n        \"\"\"", "\n", "dim_group", "=", "(", "dim", "[", "0", "]", "/", "group", ",", "dim", "[", "1", "]", "/", "group", ",", "dim", "[", "2", "]", "/", "group", ")", "\n", "\n", "# position_embedding, [1, emb_dim, num_rois, num_nongt_rois]", "\n", "# -> position_feat_1, [1, group, num_rois, num_nongt_rois]", "\n", "position_feat_1", "=", "F", ".", "relu", "(", "self", ".", "Wgs_2", "[", "index", "]", "(", "position_embedding", ")", ")", "\n", "# aff_weight, [num_rois, group, num_nongt_rois, 1]", "\n", "aff_weight", "=", "position_feat_1", ".", "permute", "(", "2", ",", "1", ",", "3", ",", "0", ")", "\n", "# aff_weight, [num_rois, group, num_nongt_rois]", "\n", "aff_weight", "=", "aff_weight", ".", "squeeze", "(", "3", ")", "\n", "\n", "# multi head", "\n", "assert", "dim", "[", "0", "]", "==", "dim", "[", "1", "]", "\n", "\n", "q_data", "=", "self", ".", "Wqs_2", "[", "index", "]", "(", "roi_feat", ")", "\n", "q_data_batch", "=", "q_data", ".", "reshape", "(", "-", "1", ",", "group", ",", "int", "(", "dim_group", "[", "0", "]", ")", ")", "\n", "# q_data_batch, [group, num_rois, dim_group[0]]", "\n", "q_data_batch", "=", "q_data_batch", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "k_data", "=", "self", ".", "Wks_2", "[", "index", "]", "(", "ref_feat", ")", "\n", "k_data_batch", "=", "k_data", ".", "reshape", "(", "-", "1", ",", "group", ",", "int", "(", "dim_group", "[", "1", "]", ")", ")", "\n", "# k_data_batch, [group, num_nongt_rois, dim_group[1]]", "\n", "k_data_batch", "=", "k_data_batch", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "# v_data, [num_nongt_rois, feat_dim]", "\n", "v_data", "=", "ref_feat", "\n", "\n", "# aff, [group, num_rois, num_nongt_rois]", "\n", "aff", "=", "torch", ".", "bmm", "(", "q_data_batch", ",", "k_data_batch", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "aff_scale", "=", "(", "1.0", "/", "math", ".", "sqrt", "(", "float", "(", "dim_group", "[", "1", "]", ")", ")", ")", "*", "aff", "\n", "# aff_scale, [num_rois, group, num_nongt_rois]", "\n", "aff_scale", "=", "aff_scale", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "\n", "# weighted_aff, [num_rois, group, num_nongt_rois]", "\n", "weighted_aff", "=", "(", "aff_weight", "+", "1e-6", ")", ".", "log", "(", ")", "+", "aff_scale", "\n", "aff_softmax", "=", "F", ".", "softmax", "(", "weighted_aff", ",", "dim", "=", "2", ")", "\n", "\n", "aff_softmax_reshape", "=", "aff_softmax", ".", "reshape", "(", "aff_softmax", ".", "shape", "[", "0", "]", "*", "aff_softmax", ".", "shape", "[", "1", "]", ",", "aff_softmax", ".", "shape", "[", "2", "]", ")", "\n", "\n", "# output_t, [num_rois * group, feat_dim]", "\n", "output_t", "=", "torch", ".", "matmul", "(", "aff_softmax_reshape", ",", "v_data", ")", "\n", "# output_t, [num_rois, group * feat_dim, 1, 1]", "\n", "output_t", "=", "output_t", ".", "reshape", "(", "-", "1", ",", "group", "*", "feat_dim", ",", "1", ",", "1", ")", "\n", "# linear_out, [num_rois, dim[2], 1, 1]", "\n", "linear_out", "=", "self", ".", "Wvs_2", "[", "index", "]", "(", "output_t", ")", "\n", "\n", "output", "=", "linear_out", ".", "squeeze", "(", "3", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.cal_position_embedding": [[345, 356], ["two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.extract_position_matrix", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.extract_position_embedding", "position_embedding.unsqueeze.unsqueeze.permute", "position_embedding.unsqueeze.unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.extract_position_matrix", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.extract_position_embedding"], ["", "def", "cal_position_embedding", "(", "self", ",", "rois1", ",", "rois2", ")", ":", "\n", "# [num_rois, num_nongt_rois, 4]", "\n", "        ", "position_matrix", "=", "self", ".", "extract_position_matrix", "(", "rois1", ",", "rois2", ")", "\n", "# [num_rois, num_nongt_rois, 64]", "\n", "position_embedding", "=", "self", ".", "extract_position_embedding", "(", "position_matrix", ",", "feat_dim", "=", "64", ")", "\n", "# [64, num_rois, num_nongt_rois]", "\n", "position_embedding", "=", "position_embedding", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "# [1, 64, num_rois, num_nongt_rois]", "\n", "position_embedding", "=", "position_embedding", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "return", "position_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.forward": [[360, 600], ["two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.preprocess_image", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.backbone", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.inference", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.proposal_generator", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads", "losses.update", "losses.update", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.proposal_generator", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads_2", "detector_losses.keys", "proposal_losses.keys", "losses.update", "losses.update", "x[].to", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.proposal_generator", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads_2", "x[].to", "x[].to", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.proposal_generator", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.proposal_generator", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads_2", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.cal_position_embedding", "range", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.attention_module_multi_head", "range", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.attention_module_multi_head", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads.box_predictor", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads_2.box_predictor", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads.box_predictor.losses", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads_2.box_predictor.losses", "proposal_losses_2.keys", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.keys", "losses.update", "losses.update", "losses_2.update", "losses_2.update", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.proposal_generator", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads_2", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.cal_position_embedding", "range", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.attention_module_multi_head", "range", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.attention_module_multi_head", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads.box_predictor", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads_2.box_predictor", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads.box_predictor.inference", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads_2.box_predictor.inference"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.inference", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.cal_position_embedding", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.attention_module_multi_head", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.attention_module_multi_head", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocalLoss.losses", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocalLoss.losses", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.cal_position_embedding", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.attention_module_multi_head", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.attention_module_multi_head", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.inference", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.inference"], ["", "def", "forward", "(", "\n", "self", ",", "batched_inputs", ",", "branch", "=", "\"supervised\"", ",", "domain_stats", "=", "None", ",", "given_proposals", "=", "None", ",", "val_mode", "=", "False", "\n", ")", ":", "\n", "\n", "\n", "        ", "'''\n        batched_inputs: list of inputs\n        len(batched_inputs) = image_per_batch\n        batched_inputs[0] dict keys() ['file_name', 'height', 'width', 'image_id', 'image'])\n        '''", "\n", "\n", "#for fft try", "\n", "#", "\n", "\n", "\n", "if", "(", "not", "self", ".", "training", ")", "and", "(", "not", "val_mode", ")", ":", "\n", "\n", "            ", "return", "self", ".", "inference", "(", "batched_inputs", ",", "branch", ")", "\n", "\n", "\n", "", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "\n", "if", "\"instances\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "gt_instances", "=", "[", "x", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n", "", "elif", "\"instances_head_1\"", "in", "batched_inputs", "[", "0", "]", ":", "\n", "            ", "gt_instances_1", "=", "[", "x", "[", "\"instances_head_1\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "gt_instances_2", "=", "[", "x", "[", "\"instances_head_2\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "\n", "", "else", ":", "\n", "            ", "gt_instances", "=", "None", "\n", "\n", "", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "branch", "==", "\"supervised\"", ":", "\n", "\n", "            ", "proposals_rpn", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "gt_instances", "\n", ")", "\n", "\n", "\n", "_", ",", "detector_losses", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "features", ",", "proposals_rpn", ",", "gt_instances", ",", "branch", "=", "branch", "\n", ")", "\n", "\n", "\n", "\n", "\n", "losses", "=", "{", "}", "\n", "losses", ".", "update", "(", "detector_losses", ")", "\n", "# losses.update(new_detector_loss_2)", "\n", "losses", ".", "update", "(", "proposal_losses", ")", "\n", "return", "losses", ",", "[", "]", ",", "[", "]", ",", "None", "\n", "", "if", "branch", "==", "\"target_supervised\"", ":", "\n", "            ", "new_detector_loss_2", "=", "{", "}", "\n", "new_proposal_loss_2", "=", "{", "}", "\n", "\n", "# Region proposal network", "\n", "proposals_rpn", ",", "proposal_losses", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "gt_instances", "\n", ")", "\n", "\n", "# # roi_head lower branch", "\n", "_", ",", "detector_losses", "=", "self", ".", "roi_heads_2", "(", "\n", "images", ",", "features", ",", "proposals_rpn", ",", "gt_instances", ",", "branch", "=", "branch", "\n", ")", "\n", "\n", "for", "key", "in", "detector_losses", ".", "keys", "(", ")", ":", "\n", "                ", "new_detector_loss_2", "[", "key", "+", "\"_tgt\"", "]", "=", "detector_losses", "[", "key", "]", "\n", "", "for", "key", "in", "proposal_losses", ".", "keys", "(", ")", ":", "\n", "                ", "new_proposal_loss_2", "[", "key", "+", "\"_tgt\"", "]", "=", "proposal_losses", "[", "key", "]", "\n", "\n", "\n", "", "losses", "=", "{", "}", "\n", "losses", ".", "update", "(", "new_detector_loss_2", ")", "\n", "losses", ".", "update", "(", "new_proposal_loss_2", ")", "\n", "return", "losses", ",", "[", "]", ",", "[", "]", ",", "None", "\n", "", "elif", "branch", "==", "\"unsup_data_weak_two_head\"", ":", "\n", "# Region proposal network", "\n", "            ", "proposals_rpn", ",", "_", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "None", ",", "compute_loss", "=", "False", "\n", ")", "\n", "\n", "# roi_head lower branch (keep this for further production)  # notice that we do not use any target in ROI head to do inference !", "\n", "proposals_roih_1", ",", "ROI_predictions_1", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "\n", "features", ",", "\n", "proposals_rpn", ",", "\n", "targets", "=", "None", ",", "\n", "compute_loss", "=", "False", ",", "\n", "branch", "=", "branch", ",", "\n", ")", "\n", "\n", "proposals_roih_2", ",", "ROI_predictions_2", "=", "self", ".", "roi_heads_2", "(", "\n", "images", ",", "\n", "features", ",", "\n", "proposals_rpn", ",", "\n", "targets", "=", "None", ",", "\n", "compute_loss", "=", "False", ",", "\n", "branch", "=", "branch", ",", "\n", ")", "\n", "\n", "\n", "return", "proposals_rpn", ",", "proposals_roih_1", ",", "proposals_roih_2", "\n", "", "elif", "branch", "==", "\"student_object_relation\"", ":", "\n", "# Region proposal network  for two head result refine", "\n", "            ", "proposals_rpn_1", ",", "proposal_losses_1", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "gt_instances_1", ")", "\n", "\n", "proposals_rpn_2", ",", "proposal_losses_2", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "gt_instances_2", ")", "\n", "\n", "\n", "proposals_1", ",", "box_features_1", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "\n", "features", ",", "\n", "proposals_rpn_1", ",", "\n", "gt_instances_1", ",", "\n", "compute_loss", "=", "True", ",", "\n", "branch", "=", "branch", ",", "\n", ")", "\n", "\n", "proposals_2", ",", "box_features_2", "=", "self", ".", "roi_heads_2", "(", "\n", "images", ",", "\n", "features", ",", "\n", "proposals_rpn_2", ",", "\n", "targets", "=", "gt_instances_2", ",", "\n", "compute_loss", "=", "True", ",", "\n", "branch", "=", "branch", ",", "\n", ")", "\n", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "rois_cur", "=", "proposals_1", "[", "0", "]", ".", "proposal_boxes", ".", "tensor", "\n", "rois_ref", "=", "proposals_2", "[", "0", "]", ".", "proposal_boxes", ".", "tensor", "\n", "position_embedding", "=", "self", ".", "cal_position_embedding", "(", "rois_cur", ",", "rois_ref", ")", "\n", "\n", "\n", "# the first fc layer and attention layer", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "\n", "                ", "box_features_1", "=", "self", ".", "roi_heads", ".", "box_head", "[", "i", "]", "(", "box_features_1", ")", "\n", "box_features_2", "=", "self", ".", "roi_heads_2", ".", "box_head", "[", "i", "]", "(", "box_features_2", ")", "\n", "", "attention", "=", "self", ".", "attention_module_multi_head", "(", "box_features_1", ",", "box_features_2", ",", "position_embedding", ",", "\n", "feat_dim", "=", "1024", ",", "group", "=", "self", ".", "group", ",", "dim", "=", "(", "1024", ",", "1024", ",", "1024", ")", ",", "\n", "index", "=", "0", ")", "\n", "# print(\"hhhhh1\",self.group)", "\n", "box_features_1", "=", "box_features_1", "+", "attention", "\n", "\n", "#the second fc layer and attention layer", "\n", "for", "i", "in", "range", "(", "3", ",", "5", ")", ":", "\n", "                ", "box_features_1", "=", "self", ".", "roi_heads", ".", "box_head", "[", "i", "]", "(", "box_features_1", ")", "\n", "box_features_2", "=", "self", ".", "roi_heads_2", ".", "box_head", "[", "i", "]", "(", "box_features_2", ")", "\n", "\n", "", "attention_2", "=", "self", ".", "attention_module_multi_head", "(", "box_features_1", ",", "box_features_2", ",", "position_embedding", ",", "\n", "feat_dim", "=", "1024", ",", "group", "=", "self", ".", "group", ",", "dim", "=", "(", "1024", ",", "1024", ",", "1024", ")", ",", "\n", "index", "=", "1", ")", "\n", "\n", "\n", "box_features_1", "=", "box_features_1", "+", "attention_2", "\n", "\n", "predictions_1", "=", "self", ".", "roi_heads", ".", "box_predictor", "(", "box_features_1", ")", "\n", "predictions_2", "=", "self", ".", "roi_heads_2", ".", "box_predictor", "(", "box_features_2", ")", "\n", "detector_losses_1", "=", "self", ".", "roi_heads", ".", "box_predictor", ".", "losses", "(", "predictions_1", ",", "proposals_1", ")", "\n", "detector_losses_2", "=", "self", ".", "roi_heads_2", ".", "box_predictor", ".", "losses", "(", "predictions_2", ",", "proposals_2", ")", "\n", "\n", "new_proposal_loss_2", "=", "{", "}", "\n", "for", "key", "in", "proposal_losses_2", ".", "keys", "(", ")", ":", "\n", "                ", "new_proposal_loss_2", "[", "key", "+", "\"_head_2\"", "]", "=", "proposal_losses_2", "[", "key", "]", "\n", "\n", "", "new_detector_loss_2", "=", "{", "}", "\n", "for", "key", "in", "detector_losses_2", ".", "keys", "(", ")", ":", "\n", "                ", "new_detector_loss_2", "[", "key", "+", "\"_head_2\"", "]", "=", "detector_losses_2", "[", "key", "]", "\n", "\n", "", "losses", "=", "{", "}", "\n", "losses_2", "=", "{", "}", "\n", "losses", ".", "update", "(", "detector_losses_1", ")", "\n", "losses", ".", "update", "(", "proposal_losses_1", ")", "\n", "\n", "# losses.update(new_detector_loss_2)", "\n", "losses_2", ".", "update", "(", "new_detector_loss_2", ")", "\n", "losses_2", ".", "update", "(", "new_proposal_loss_2", ")", "\n", "return", "losses", ",", "losses_2", ",", "[", "]", ",", "None", "\n", "", "elif", "branch", "==", "\"teacher_object_relation\"", ":", "\n", "# Region proposal network  for two head result refine", "\n", "            ", "proposals_rpn", ",", "_", "=", "self", ".", "proposal_generator", "(", "\n", "images", ",", "features", ",", "None", ",", "compute_loss", "=", "False", "\n", ")", "\n", "\n", "\n", "proposals_1", ",", "box_features_1", "=", "self", ".", "roi_heads", "(", "\n", "images", ",", "\n", "features", ",", "\n", "proposals_rpn", ",", "\n", "targets", "=", "None", ",", "\n", "compute_loss", "=", "False", ",", "\n", "branch", "=", "branch", ",", "\n", ")", "\n", "proposals_2", ",", "box_features_2", "=", "self", ".", "roi_heads_2", "(", "\n", "images", ",", "\n", "features", ",", "\n", "proposals_rpn", ",", "\n", "targets", "=", "None", ",", "\n", "compute_loss", "=", "False", ",", "\n", "branch", "=", "branch", ",", "\n", ")", "\n", "\n", "\n", "\n", "rois_cur", "=", "proposals_1", "[", "0", "]", ".", "proposal_boxes", ".", "tensor", "\n", "rois_ref", "=", "proposals_2", "[", "0", "]", ".", "proposal_boxes", ".", "tensor", "\n", "position_embedding", "=", "self", ".", "cal_position_embedding", "(", "rois_cur", ",", "rois_ref", ")", "\n", "\n", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "\n", "                ", "box_features_1", "=", "self", ".", "roi_heads", ".", "box_head", "[", "i", "]", "(", "box_features_1", ")", "\n", "box_features_2", "=", "self", ".", "roi_heads_2", ".", "box_head", "[", "i", "]", "(", "box_features_2", ")", "\n", "\n", "", "attention", "=", "self", ".", "attention_module_multi_head", "(", "box_features_1", ",", "box_features_2", ",", "position_embedding", ",", "\n", "feat_dim", "=", "1024", ",", "group", "=", "self", ".", "group", ",", "dim", "=", "(", "1024", ",", "1024", ",", "1024", ")", ",", "\n", "index", "=", "0", ")", "\n", "box_features_1", "=", "box_features_1", "+", "attention", "\n", "\n", "for", "i", "in", "range", "(", "3", ",", "5", ")", ":", "\n", "                ", "box_features_1", "=", "self", ".", "roi_heads", ".", "box_head", "[", "i", "]", "(", "box_features_1", ")", "\n", "box_features_2", "=", "self", ".", "roi_heads_2", ".", "box_head", "[", "i", "]", "(", "box_features_2", ")", "\n", "\n", "", "attention_2", "=", "self", ".", "attention_module_multi_head", "(", "box_features_1", ",", "box_features_2", ",", "position_embedding", ",", "\n", "feat_dim", "=", "1024", ",", "group", "=", "self", ".", "group", ",", "dim", "=", "(", "1024", ",", "1024", ",", "1024", ")", ",", "\n", "index", "=", "1", ")", "\n", "\n", "\n", "\n", "box_features_1", "=", "box_features_1", "+", "attention_2", "\n", "\n", "predictions_1", "=", "self", ".", "roi_heads", ".", "box_predictor", "(", "box_features_1", ")", "\n", "predictions_2", "=", "self", ".", "roi_heads_2", ".", "box_predictor", "(", "box_features_2", ")", "\n", "\n", "proposals_roih_1", ",", "_", "=", "self", ".", "roi_heads", ".", "box_predictor", ".", "inference", "(", "predictions", "=", "predictions_1", ",", "proposals", "=", "proposals_1", ",", "branch", "=", "branch", ")", "\n", "proposals_roih_2", ",", "_", "=", "self", ".", "roi_heads_2", ".", "box_predictor", ".", "inference", "(", "predictions", "=", "predictions_2", ",", "proposals", "=", "proposals_2", ",", "branch", "=", "branch", ")", "\n", "\n", "return", "proposals_rpn", ",", "proposals_roih_1", ",", "proposals_roih_2", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.inference": [[606, 663], ["two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.preprocess_image", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.backbone", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads_2", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.roi_heads.forward_with_given_boxes", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE.proposal_generator", "x.to", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "torch.jit.is_scripting", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE._postprocess", "two_head_rcnn_refine.Two_head_TwoStagePseudoLabGeneralizedRCNN_REFINE._postprocess", "x[].to"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN._postprocess", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.cp_rcnn.Ori_TwoStagePseudoLabGeneralizedRCNN._postprocess"], ["", "", "def", "inference", "(", "\n", "self", ",", "\n", "batched_inputs", ",", "\n", "branch", ",", "\n", "detected_instances", "=", "None", ",", "\n", "do_postprocess", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Run inference on the given inputs.\n\n        Args:\n            batched_inputs (list[dict]): same as in :meth:`forward`\n            detected_instances (None or list[Instances]): if not None, it\n                contains an `Instances` object per image. The `Instances`\n                object contains \"pred_boxes\" and \"pred_classes\" which are\n                known boxes in the image.\n                The inference will then skip the detection of bounding boxes,\n                and only predict other per-ROI outputs.\n            do_postprocess (bool): whether to apply post-processing on the outputs.\n\n        Returns:\n            When do_postprocess=True, same as in :meth:`forward`.\n            Otherwise, a list[Instances] containing raw network outputs.\n        \"\"\"", "\n", "assert", "not", "self", ".", "training", "\n", "# in_features = cfg.MODEL.ROI_HEADS.IN_FEATURES", "\n", "\n", "images", "=", "self", ".", "preprocess_image", "(", "batched_inputs", ")", "\n", "features", "=", "self", ".", "backbone", "(", "images", ".", "tensor", ")", "\n", "\n", "if", "detected_instances", "is", "None", ":", "\n", "            ", "if", "self", ".", "proposal_generator", "is", "not", "None", ":", "\n", "                ", "proposals", ",", "_", "=", "self", ".", "proposal_generator", "(", "images", ",", "features", ",", "None", ")", "\n", "", "else", ":", "\n", "                ", "assert", "\"proposals\"", "in", "batched_inputs", "[", "0", "]", "\n", "proposals", "=", "[", "x", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "batched_inputs", "]", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "\n", "", "results_1", ",", "box_feature_1", "=", "self", ".", "roi_heads", "(", "images", ",", "features", ",", "proposals", ",", "None", ")", "\n", "results_2", ",", "box_feature_2", "=", "self", ".", "roi_heads_2", "(", "images", ",", "features", ",", "proposals", ",", "None", ")", "\n", "\n", "\n", "\n", "", "else", ":", "\n", "            ", "detected_instances", "=", "[", "x", ".", "to", "(", "self", ".", "device", ")", "for", "x", "in", "detected_instances", "]", "\n", "# if 'tgt' in branch:", "\n", "results", "=", "self", ".", "roi_heads", ".", "forward_with_given_boxes", "(", "features", ",", "detected_instances", ")", "\n", "\n", "\n", "\n", "", "if", "do_postprocess", ":", "\n", "            ", "assert", "not", "torch", ".", "jit", ".", "is_scripting", "(", ")", ",", "\"Scripting is not supported for postprocess.\"", "\n", "# return self._postprocess(results, batched_inputs, images.image_sizes)", "\n", "return", "self", ".", "_postprocess", "(", "results_1", ",", "batched_inputs", ",", "images", ".", "image_sizes", ")", ",", "self", ".", "_postprocess", "(", "results_2", ",", "batched_inputs", ",", "images", ".", "image_sizes", ")", ",", "box_feature_1", ",", "box_feature_2", "\n", "", "else", ":", "\n", "            ", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine._NewEmptyTensorOp.forward": [[704, 708], ["x.new_empty"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ",", "new_shape", ")", ":", "\n", "        ", "ctx", ".", "shape", "=", "x", ".", "shape", "\n", "return", "x", ".", "new_empty", "(", "new_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine._NewEmptyTensorOp.backward": [[709, 713], ["_NewEmptyTensorOp.apply"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "shape", "=", "ctx", ".", "shape", "\n", "return", "_NewEmptyTensorOp", ".", "apply", "(", "grad", ",", "shape", ")", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.Conv2d.forward": [[715, 727], ["x.numel", "super().forward", "zip"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.forward"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "x", ".", "numel", "(", ")", ">", "0", ":", "\n", "            ", "return", "super", "(", "Conv2d", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "# get output shape", "\n", "\n", "", "output_shape", "=", "[", "\n", "(", "i", "+", "2", "*", "p", "-", "(", "di", "*", "(", "k", "-", "1", ")", "+", "1", ")", ")", "//", "d", "+", "1", "\n", "for", "i", ",", "p", ",", "di", ",", "k", ",", "d", "in", "zip", "(", "\n", "x", ".", "shape", "[", "-", "2", ":", "]", ",", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "kernel_size", ",", "self", ".", "stride", "\n", ")", "\n", "]", "\n", "output_shape", "=", "[", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "weight", ".", "shape", "[", "0", "]", "]", "+", "output_shape", "\n", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.cosinematrix": [[664, 669], ["torch.mm", "torch.mm", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.mm.div", "A.t", "torch.mm", "torch.mm", "torch.norm", "torch.norm", "torch.norm().unsqueeze.t"], "function", ["None"], ["", "", "", "def", "cosinematrix", "(", "A", ")", ":", "\n", "    ", "prod", "=", "torch", ".", "mm", "(", "A", ",", "A", ".", "t", "(", ")", ")", "#\u5206\u5b50", "\n", "norm", "=", "torch", ".", "norm", "(", "A", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "0", ")", "#\u5206\u6bcd", "\n", "cos", "=", "prod", ".", "div", "(", "torch", ".", "mm", "(", "norm", ".", "t", "(", ")", ",", "norm", ")", ")", "\n", "return", "cos", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.cosine_distance": [[670, 676], ["torch.mm", "torch.mm", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.norm().unsqueeze", "torch.mm.div", "matrix2.t", "torch.mm", "torch.mm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm().unsqueeze.t"], "function", ["None"], ["", "def", "cosine_distance", "(", "matrix1", ",", "matrix2", ")", ":", "\n", "    ", "matrix1_matrix2", "=", "torch", ".", "mm", "(", "matrix1", ",", "matrix2", ".", "t", "(", ")", ")", "\n", "norm_1", "=", "torch", ".", "norm", "(", "matrix1", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "0", ")", "#\u5206\u6bcd", "\n", "norm_2", "=", "torch", ".", "norm", "(", "matrix2", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "0", ")", "#\u5206\u6bcd", "\n", "cos", "=", "matrix1_matrix2", ".", "div", "(", "torch", ".", "mm", "(", "norm_1", ".", "t", "(", ")", ",", "norm_2", ")", ")", "\n", "return", "cos", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine.make_fc": [[677, 690], ["torch.nn.Linear", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_"], "function", ["None"], ["", "def", "make_fc", "(", "dim_in", ",", "hidden_dim", ",", "use_gn", "=", "False", ")", ":", "\n", "    ", "'''\n        Caffe2 implementation uses XavierFill, which in fact\n        corresponds to kaiming_uniform_ in PyTorch\n    '''", "\n", "# if use_gn:", "\n", "#     fc = nn.Linear(dim_in, hidden_dim, bias=False)", "\n", "#     nn.init.kaiming_uniform_(fc.weight, a=1)", "\n", "#     return nn.Sequential(fc, group_norm(hidden_dim))", "\n", "fc", "=", "nn", ".", "Linear", "(", "dim_in", ",", "hidden_dim", ")", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "fc", ".", "weight", ",", "a", "=", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "fc", ".", "bias", ",", "0", ")", "\n", "return", "fc", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.proposal_generator.rpn.PseudoLabRPN.forward": [[16, 61], ["rpn.PseudoLabRPN.anchor_generator", "rpn.PseudoLabRPN.rpn_head", "rpn.PseudoLabRPN.predict_proposals", "score.permute().flatten", "x.view().permute().flatten", "rpn.PseudoLabRPN.label_and_sample_anchors", "rpn.PseudoLabRPN.losses", "score.permute", "x.view().permute", "rpn.PseudoLabRPN.loss_weight.get", "rpn.PseudoLabRPN.items", "x.view"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocalLoss.losses"], ["def", "forward", "(", "\n", "self", ",", "\n", "images", ":", "ImageList", ",", "\n", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "gt_instances", ":", "Optional", "[", "Instances", "]", "=", "None", ",", "\n", "compute_loss", ":", "bool", "=", "True", ",", "\n", "compute_val_loss", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "in_features", "]", "\n", "anchors", "=", "self", ".", "anchor_generator", "(", "features", ")", "\n", "\n", "\n", "pred_objectness_logits", ",", "pred_anchor_deltas", "=", "self", ".", "rpn_head", "(", "features", ")", "\n", "pred_objectness_logits", "=", "[", "\n", "# (N, A, Hi, Wi) -> (N, Hi, Wi, A) -> (N, Hi*Wi*A)", "\n", "score", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "flatten", "(", "1", ")", "\n", "for", "score", "in", "pred_objectness_logits", "\n", "]", "\n", "pred_anchor_deltas", "=", "[", "\n", "# (N, A*B, Hi, Wi) -> (N, A, B, Hi, Wi) -> (N, Hi, Wi, A, B) -> (N, Hi*Wi*A, B)", "\n", "x", ".", "view", "(", "\n", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "self", ".", "anchor_generator", ".", "box_dim", ",", "x", ".", "shape", "[", "-", "2", "]", ",", "x", ".", "shape", "[", "-", "1", "]", "\n", ")", "\n", ".", "permute", "(", "0", ",", "3", ",", "4", ",", "1", ",", "2", ")", "\n", ".", "flatten", "(", "1", ",", "-", "2", ")", "\n", "for", "x", "in", "pred_anchor_deltas", "\n", "]", "\n", "\n", "if", "(", "self", ".", "training", "and", "compute_loss", ")", "or", "compute_val_loss", ":", "\n", "            ", "gt_labels", ",", "gt_boxes", "=", "self", ".", "label_and_sample_anchors", "(", "anchors", ",", "gt_instances", ")", "\n", "#", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "losses", "=", "self", ".", "losses", "(", "\n", "anchors", ",", "pred_objectness_logits", ",", "gt_labels", ",", "pred_anchor_deltas", ",", "gt_boxes", "\n", ")", "\n", "losses", "=", "{", "k", ":", "v", "*", "self", ".", "loss_weight", ".", "get", "(", "k", ",", "1.0", ")", "for", "k", ",", "v", "in", "losses", ".", "items", "(", ")", "}", "\n", "", "else", ":", "# inference", "\n", "            ", "losses", "=", "{", "}", "\n", "\n", "", "proposals", "=", "self", ".", "predict_proposals", "(", "\n", "anchors", ",", "pred_objectness_logits", ",", "pred_anchor_deltas", ",", "images", ".", "image_sizes", "\n", ")", "\n", "\n", "return", "proposals", ",", "losses", "", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNOutputs.__init__": [[222, 287], ["len", "len", "type", "type.cat", "proposals[].has", "detectron2.structures.Boxes", "len", "detectron2.layers.cat", "type.cat", "torch.zeros", "p.has"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "box2box_transform", ",", "\n", "pred_class_logits", ",", "\n", "pred_proposal_deltas", ",", "\n", "proposals", ",", "\n", "smooth_l1_beta", "=", "0.0", ",", "\n", "box_reg_loss_type", "=", "\"smooth_l1\"", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            box2box_transform (Box2BoxTransform/Box2BoxTransformRotated):\n                box2box transform instance for proposal-to-detection transformations.\n            pred_class_logits (Tensor): A tensor of shape (R, K + 1) storing the predicted class\n                logits for all R predicted object instances.\n                Each row corresponds to a predicted object instance.\n            pred_proposal_deltas (Tensor): A tensor of shape (R, K * B) or (R, B) for\n                class-specific or class-agnostic regression. It stores the predicted deltas that\n                transform proposals into final box detections.\n                B is the box dimension (4 or 5).\n                When B is 4, each row is [dx, dy, dw, dh (, ....)].\n                When B is 5, each row is [dx, dy, dw, dh, da (, ....)].\n            proposals (list[Instances]): A list of N Instances, where Instances i stores the\n                proposals for image i, in the field \"proposal_boxes\".\n                When training, each Instances must have ground-truth labels\n                stored in the field \"gt_classes\" and \"gt_boxes\".\n                The total number of all instances must be equal to R.\n            smooth_l1_beta (float): The transition point between L1 and L2 loss in\n                the smooth L1 loss function. When set to 0, the loss becomes L1. When\n                set to +inf, the loss becomes constant 0.\n            box_reg_loss_type (str): Box regression loss type. One of: \"smooth_l1\", \"giou\"\n        \"\"\"", "\n", "self", ".", "box2box_transform", "=", "box2box_transform", "\n", "self", ".", "num_preds_per_image", "=", "[", "len", "(", "p", ")", "for", "p", "in", "proposals", "]", "\n", "self", ".", "pred_class_logits", "=", "pred_class_logits", "\n", "self", ".", "pred_proposal_deltas", "=", "pred_proposal_deltas", "\n", "self", ".", "smooth_l1_beta", "=", "smooth_l1_beta", "\n", "self", ".", "box_reg_loss_type", "=", "box_reg_loss_type", "\n", "\n", "self", ".", "image_shapes", "=", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "\n", "\n", "if", "len", "(", "proposals", ")", ":", "\n", "            ", "box_type", "=", "type", "(", "proposals", "[", "0", "]", ".", "proposal_boxes", ")", "\n", "# cat(..., dim=0) concatenates over all images in the batch", "\n", "self", ".", "proposals", "=", "box_type", ".", "cat", "(", "[", "p", ".", "proposal_boxes", "for", "p", "in", "proposals", "]", ")", "\n", "assert", "(", "\n", "not", "self", ".", "proposals", ".", "tensor", ".", "requires_grad", "\n", ")", ",", "\"Proposals should not require gradients!\"", "\n", "\n", "# \"gt_classes\" exists if and only if training. But other gt fields may", "\n", "# not necessarily exist in training for images that have no groundtruth.", "\n", "if", "proposals", "[", "0", "]", ".", "has", "(", "\"gt_classes\"", ")", ":", "\n", "                ", "self", ".", "gt_classes", "=", "cat", "(", "[", "p", ".", "gt_classes", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# If \"gt_boxes\" does not exist, the proposals must be all negative and", "\n", "# should not be included in regression loss computation.", "\n", "# Here we just use proposal_boxes as an arbitrary placeholder because its", "\n", "# value won't be used in self.box_reg_loss().", "\n", "gt_boxes", "=", "[", "\n", "p", ".", "gt_boxes", "if", "p", ".", "has", "(", "\"gt_boxes\"", ")", "else", "p", ".", "proposal_boxes", "for", "p", "in", "proposals", "\n", "]", "\n", "self", ".", "gt_boxes", "=", "box_type", ".", "cat", "(", "gt_boxes", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "proposals", "=", "Boxes", "(", "torch", ".", "zeros", "(", "0", ",", "4", ",", "device", "=", "self", ".", "pred_proposal_deltas", ".", "device", ")", ")", "\n", "", "self", ".", "_no_instances", "=", "len", "(", "self", ".", "proposals", ")", "==", "0", "# no instances found", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNOutputs.softmax_cross_entropy_loss": [[288, 294], ["_log_classification_stats", "detectron2.layers.cross_entropy"], "methods", ["None"], ["", "def", "softmax_cross_entropy_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "_log_classification_stats", "(", "self", ".", "pred_class_logits", ",", "self", ".", "gt_classes", ")", "\n", "return", "cross_entropy", "(", "self", ".", "pred_class_logits", ",", "self", ".", "gt_classes", ",", "reduction", "=", "\"mean\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNOutputs.box_reg_loss": [[295, 350], ["fast_rcnn.FastRCNNOutputs.proposals.tensor.size", "fast_rcnn.FastRCNNOutputs.pred_proposal_deltas.size", "detectron2.layers.nonzero_tuple", "torch.arange", "fast_rcnn.FastRCNNOutputs.box2box_transform.get_deltas", "fvcore.nn.smooth_l1_loss", "fast_rcnn.FastRCNNOutputs.gt_classes.numel", "fast_rcnn.FastRCNNOutputs.pred_proposal_deltas.sum", "torch.arange", "fast_rcnn.FastRCNNOutputs.box2box_transform.apply_deltas", "fvcore.nn.giou_loss", "ValueError"], "methods", ["None"], ["", "def", "box_reg_loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "if", "self", ".", "_no_instances", ":", "\n", "            ", "return", "0.0", "*", "self", ".", "pred_proposal_deltas", ".", "sum", "(", ")", "\n", "\n", "", "box_dim", "=", "self", ".", "proposals", ".", "tensor", ".", "size", "(", "1", ")", "# 4 or 5", "\n", "cls_agnostic_bbox_reg", "=", "self", ".", "pred_proposal_deltas", ".", "size", "(", "1", ")", "==", "box_dim", "\n", "device", "=", "self", ".", "pred_proposal_deltas", ".", "device", "\n", "\n", "bg_class_ind", "=", "self", ".", "pred_class_logits", ".", "shape", "[", "1", "]", "-", "1", "\n", "# Box delta loss is only computed between the prediction for the gt class k", "\n", "# (if 0 <= k < bg_class_ind) and the target; there is no loss defined on predictions", "\n", "# for non-gt classes and background.", "\n", "# Empty fg_inds should produce a valid loss of zero because reduction=sum.", "\n", "fg_inds", "=", "nonzero_tuple", "(", "(", "self", ".", "gt_classes", ">=", "0", ")", "&", "(", "self", ".", "gt_classes", "<", "bg_class_ind", ")", ")", "[", "0", "]", "\n", "\n", "if", "cls_agnostic_bbox_reg", ":", "\n", "# pred_proposal_deltas only corresponds to foreground class for agnostic", "\n", "            ", "gt_class_cols", "=", "torch", ".", "arange", "(", "box_dim", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "# pred_proposal_deltas for class k are located in columns [b * k : b * k + b],", "\n", "# where b is the dimension of box representation (4 or 5)", "\n", "# Note that compared to Detectron1,", "\n", "# we do not perform bounding box regression for background classes.", "\n", "            ", "gt_class_cols", "=", "box_dim", "*", "self", ".", "gt_classes", "[", "fg_inds", ",", "None", "]", "+", "torch", ".", "arange", "(", "\n", "box_dim", ",", "device", "=", "device", "\n", ")", "\n", "\n", "", "if", "self", ".", "box_reg_loss_type", "==", "\"smooth_l1\"", ":", "\n", "            ", "gt_proposal_deltas", "=", "self", ".", "box2box_transform", ".", "get_deltas", "(", "\n", "self", ".", "proposals", ".", "tensor", ",", "self", ".", "gt_boxes", ".", "tensor", "\n", ")", "\n", "loss_box_reg", "=", "smooth_l1_loss", "(", "\n", "self", ".", "pred_proposal_deltas", "[", "fg_inds", "[", ":", ",", "None", "]", ",", "gt_class_cols", "]", ",", "\n", "gt_proposal_deltas", "[", "fg_inds", "]", ",", "\n", "self", ".", "smooth_l1_beta", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "", "elif", "self", ".", "box_reg_loss_type", "==", "\"giou\"", ":", "\n", "            ", "fg_pred_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "\n", "self", ".", "pred_proposal_deltas", "[", "fg_inds", "[", ":", ",", "None", "]", ",", "gt_class_cols", "]", ",", "\n", "self", ".", "proposals", ".", "tensor", "[", "fg_inds", "]", ",", "\n", ")", "\n", "loss_box_reg", "=", "giou_loss", "(", "\n", "fg_pred_boxes", ",", "\n", "self", ".", "gt_boxes", ".", "tensor", "[", "fg_inds", "]", ",", "\n", "reduction", "=", "\"sum\"", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid bbox reg loss type '{self.box_reg_loss_type}'\"", ")", "\n", "\n", "", "loss_box_reg", "=", "loss_box_reg", "/", "self", ".", "gt_classes", ".", "numel", "(", ")", "\n", "return", "loss_box_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNOutputs.losses": [[351, 356], ["fast_rcnn.FastRCNNOutputs.softmax_cross_entropy_loss", "fast_rcnn.FastRCNNOutputs.box_reg_loss"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNOutputs.softmax_cross_entropy_loss", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNOutputs.box_reg_loss"], ["", "def", "losses", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "return", "{", "\"loss_cls\"", ":", "self", ".", "softmax_cross_entropy_loss", "(", ")", ",", "\"loss_box_reg\"", ":", "self", ".", "box_reg_loss", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNOutputs.predict_boxes": [[357, 363], ["fast_rcnn.FastRCNNOutputs.box2box_transform.apply_deltas", "fast_rcnn.FastRCNNOutputs.split"], "methods", ["None"], ["", "def", "predict_boxes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "pred", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "self", ".", "pred_proposal_deltas", ",", "self", ".", "proposals", ".", "tensor", ")", "\n", "return", "pred", ".", "split", "(", "self", ".", "num_preds_per_image", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNOutputs.predict_probs": [[364, 370], ["torch.nn.functional.softmax", "torch.nn.functional.softmax.split"], "methods", ["None"], ["", "def", "predict_probs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Deprecated\n        \"\"\"", "\n", "probs", "=", "F", ".", "softmax", "(", "self", ".", "pred_class_logits", ",", "dim", "=", "-", "1", ")", "\n", "return", "probs", ".", "split", "(", "self", ".", "num_preds_per_image", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.__init__": [[373, 376], ["detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers.__init__"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "super", "(", "FastRCNNFocaltLossOutputLayers", ",", "self", ")", ".", "__init__", "(", "cfg", ",", "input_shape", ")", "\n", "self", ".", "num_classes", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "NUM_CLASSES", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.losses": [[377, 396], ["fast_rcnn.FastRCNNFocalLoss.losses", "fast_rcnn.FastRCNNFocalLoss"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocalLoss.losses"], ["", "def", "losses", "(", "self", ",", "predictions", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features\n                that were used to compute predictions.\n        \"\"\"", "\n", "scores", ",", "proposal_deltas", "=", "predictions", "\n", "losses", "=", "FastRCNNFocalLoss", "(", "\n", "self", ".", "box2box_transform", ",", "\n", "scores", ",", "\n", "proposal_deltas", ",", "\n", "proposals", ",", "\n", "self", ".", "smooth_l1_beta", ",", "\n", "self", ".", "box_reg_loss_type", ",", "\n", "num_classes", "=", "self", ".", "num_classes", ",", "\n", ")", ".", "losses", "(", ")", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.predict_boxes_gt_pooling": [[397, 422], ["detectron2.layers.cat", "fast_rcnn.FastRCNNFocaltLossOutputLayers.box2box_transform.apply_deltas", "fast_rcnn.FastRCNNFocaltLossOutputLayers.split", "len", "len"], "methods", ["None"], ["", "def", "predict_boxes_gt_pooling", "(", "\n", "self", ",", "predictions", ",", "proposals", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were\n                used to compute predictions. The ``proposal_boxes`` field is expected.\n\n        Returns:\n            list[Tensor]:\n                A list of Tensors of predicted class-specific or class-agnostic boxes\n                for each image. Element i has shape (Ri, K * B) or (Ri, B), where Ri is\n                the number of proposals for image i and B is the box dimension (4 or 5)\n        \"\"\"", "\n", "if", "not", "len", "(", "proposals", ")", ":", "\n", "            ", "return", "[", "]", "\n", "", "_", ",", "proposal_deltas", "=", "predictions", "\n", "num_prop_per_image", "=", "[", "len", "(", "p", ")", "for", "p", "in", "proposals", "]", "\n", "proposal_boxes", "=", "cat", "(", "[", "p", ".", "gt_boxes", ".", "tensor", "for", "p", "in", "proposals", "]", ",", "dim", "=", "0", ")", "\n", "predict_boxes", "=", "self", ".", "box2box_transform", ".", "apply_deltas", "(", "\n", "proposal_deltas", ",", "\n", "proposal_boxes", ",", "\n", ")", "# Nx(KxB)", "\n", "return", "predict_boxes", ".", "split", "(", "num_prop_per_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.inference": [[423, 450], ["fast_rcnn.FastRCNNFocaltLossOutputLayers.predict_probs", "fast_rcnn.fast_rcnn_inference", "fast_rcnn.FastRCNNFocaltLossOutputLayers.predict_boxes_gt_pooling", "fast_rcnn.FastRCNNFocaltLossOutputLayers.predict_boxes"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNOutputs.predict_probs", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.fast_rcnn_inference", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.predict_boxes_gt_pooling", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNOutputs.predict_boxes"], ["", "def", "inference", "(", "self", ",", "predictions", ",", "proposals", ",", "branch", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            predictions: return values of :meth:`forward()`.\n            proposals (list[Instances]): proposals that match the features that were\n                used to compute predictions. The ``proposal_boxes`` field is expected.\n\n        Returns:\n            list[Instances]: same as `fast_rcnn_inference`.\n            list[Tensor]: same as `fast_rcnn_inference`.\n        \"\"\"", "\n", "if", "\"gt\"", "in", "branch", ":", "\n", "\n", "            ", "boxes", "=", "self", ".", "predict_boxes_gt_pooling", "(", "predictions", ",", "proposals", ")", "\n", "", "else", ":", "\n", "\n", "            ", "boxes", "=", "self", ".", "predict_boxes", "(", "predictions", ",", "proposals", ")", "\n", "", "scores", "=", "self", ".", "predict_probs", "(", "predictions", ",", "proposals", ")", "\n", "image_shapes", "=", "[", "x", ".", "image_size", "for", "x", "in", "proposals", "]", "\n", "\n", "return", "fast_rcnn_inference", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_shapes", ",", "\n", "self", ".", "test_score_thresh", ",", "\n", "self", ".", "test_nms_thresh", ",", "\n", "self", ".", "test_topk_per_image", ",", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocalLoss.__init__": [[460, 479], ["fast_rcnn.FastRCNNOutputs.__init__"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "box2box_transform", ",", "\n", "pred_class_logits", ",", "\n", "pred_proposal_deltas", ",", "\n", "proposals", ",", "\n", "smooth_l1_beta", "=", "0.0", ",", "\n", "box_reg_loss_type", "=", "\"smooth_l1\"", ",", "\n", "num_classes", "=", "80", ",", "\n", ")", ":", "\n", "        ", "super", "(", "FastRCNNFocalLoss", ",", "self", ")", ".", "__init__", "(", "\n", "box2box_transform", ",", "\n", "pred_class_logits", ",", "\n", "pred_proposal_deltas", ",", "\n", "proposals", ",", "\n", "smooth_l1_beta", ",", "\n", "box_reg_loss_type", ",", "\n", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocalLoss.losses": [[480, 484], ["fast_rcnn.FastRCNNFocalLoss.comput_focal_loss", "fast_rcnn.FastRCNNFocalLoss.box_reg_loss"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocalLoss.comput_focal_loss", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNOutputs.box_reg_loss"], ["", "def", "losses", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"loss_cls\"", ":", "self", ".", "comput_focal_loss", "(", ")", ",", "\n", "\"loss_box_reg\"", ":", "self", ".", "box_reg_loss", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocalLoss.comput_focal_loss": [[486, 498], ["fast_rcnn.FocalLoss", "FocalLoss.", "fast_rcnn.FastRCNNFocalLoss.pred_class_logits.sum"], "methods", ["None"], ["", "def", "comput_focal_loss", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_no_instances", ":", "\n", "            ", "return", "0.0", "*", "self", ".", "pred_class_logits", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "FC_loss", "=", "FocalLoss", "(", "\n", "gamma", "=", "1.5", ",", "\n", "num_classes", "=", "self", ".", "num_classes", ",", "\n", ")", "\n", "total_loss", "=", "FC_loss", "(", "input", "=", "self", ".", "pred_class_logits", ",", "target", "=", "self", ".", "gt_classes", ")", "\n", "total_loss", "=", "total_loss", "/", "self", ".", "gt_classes", ".", "shape", "[", "0", "]", "\n", "\n", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FocalLoss.__init__": [[501, 513], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "weight", "=", "None", ",", "\n", "gamma", "=", "1.0", ",", "\n", "num_classes", "=", "80", ",", "\n", ")", ":", "\n", "        ", "super", "(", "FocalLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "gamma", ">=", "0", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "weight", "=", "weight", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FocalLoss.forward": [[514, 520], ["torch.nn.functional.cross_entropy", "torch.exp", "loss.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "# focal loss", "\n", "        ", "CE", "=", "F", ".", "cross_entropy", "(", "input", ",", "target", ",", "reduction", "=", "\"none\"", ")", "\n", "p", "=", "torch", ".", "exp", "(", "-", "CE", ")", "\n", "loss", "=", "(", "1", "-", "p", ")", "**", "self", ".", "gamma", "*", "CE", "\n", "return", "loss", ".", "sum", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.fast_rcnn_inference": [[14, 54], ["fast_rcnn.fast_rcnn_inference_single_image", "zip"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.fast_rcnn_inference_single_image"], ["def", "fast_rcnn_inference", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_shapes", ",", "\n", "score_thresh", ",", "\n", "nms_thresh", ",", "\n", "topk_per_image", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Call `fast_rcnn_inference_single_image` for all images.\n\n    Args:\n        boxes (list[Tensor]): A list of Tensors of predicted class-specific or class-agnostic\n            boxes for each image. Element i has shape (Ri, K * 4) if doing\n            class-specific regression, or (Ri, 4) if doing class-agnostic\n            regression, where Ri is the number of predicted objects for image i.\n            This is compatible with the output of :meth:`FastRCNNOutputLayers.predict_boxes`.\n        scores (list[Tensor]): A list of Tensors of predicted class scores for each image.\n            Element i has shape (Ri, K + 1), where Ri is the number of predicted objects\n            for image i. Compatible with the output of :meth:`FastRCNNOutputLayers.predict_probs`.\n        image_shapes (list[tuple]): A list of (width, height) tuples for each image in the batch.\n        score_thresh (float): Only return detections with a confidence score exceeding this\n            threshold.\n        nms_thresh (float):  The threshold to use for box non-maximum suppression. Value in [0, 1].\n        topk_per_image (int): The number of top scoring detections to return. Set < 0 to return\n            all detections.\n\n    Returns:\n        instances: (list[Instances]): A list of N instances, one for each image in the batch,\n            that stores the topk most confidence detections.\n        kept_indices: (list[Tensor]): A list of 1D tensor of length of N, each element indicates\n            the corresponding boxes/scores index in [0, Ri) from the input, for image i.\n    \"\"\"", "\n", "result_per_image", "=", "[", "\n", "fast_rcnn_inference_single_image", "(", "\n", "boxes_per_image", ",", "scores_per_image", ",", "image_shape", ",", "score_thresh", ",", "nms_thresh", ",", "topk_per_image", "\n", ")", "\n", "for", "scores_per_image", ",", "boxes_per_image", ",", "image_shape", "in", "zip", "(", "scores", ",", "boxes", ",", "image_shapes", ")", "\n", "]", "\n", "return", "[", "x", "[", "0", "]", "for", "x", "in", "result_per_image", "]", ",", "[", "x", "[", "1", "]", "for", "x", "in", "result_per_image", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.fast_rcnn_inference_2": [[55, 96], ["fast_rcnn.fast_rcnn_inference_single_image_2", "zip"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.fast_rcnn_inference_single_image_2"], ["", "def", "fast_rcnn_inference_2", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_shapes", ",", "\n", "score_thresh", ",", "\n", "nms_thresh", ",", "\n", "topk_per_image", ",", "\n", "box_features", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Call `fast_rcnn_inference_single_image` for all images.\n\n    Args:\n        boxes (list[Tensor]): A list of Tensors of predicted class-specific or class-agnostic\n            boxes for each image. Element i has shape (Ri, K * 4) if doing\n            class-specific regression, or (Ri, 4) if doing class-agnostic\n            regression, where Ri is the number of predicted objects for image i.\n            This is compatible with the output of :meth:`FastRCNNOutputLayers.predict_boxes`.\n        scores (list[Tensor]): A list of Tensors of predicted class scores for each image.\n            Element i has shape (Ri, K + 1), where Ri is the number of predicted objects\n            for image i. Compatible with the output of :meth:`FastRCNNOutputLayers.predict_probs`.\n        image_shapes (list[tuple]): A list of (width, height) tuples for each image in the batch.\n        score_thresh (float): Only return detections with a confidence score exceeding this\n            threshold.\n        nms_thresh (float):  The threshold to use for box non-maximum suppression. Value in [0, 1].\n        topk_per_image (int): The number of top scoring detections to return. Set < 0 to return\n            all detections.\n\n    Returns:\n        instances: (list[Instances]): A list of N instances, one for each image in the batch,\n            that stores the topk most confidence detections.\n        kept_indices: (list[Tensor]): A list of 1D tensor of length of N, each element indicates\n            the corresponding boxes/scores index in [0, Ri) from the input, for image i.\n    \"\"\"", "\n", "result_per_image", "=", "[", "\n", "fast_rcnn_inference_single_image_2", "(", "\n", "boxes_per_image", ",", "scores_per_image", ",", "image_shape", ",", "score_thresh", ",", "nms_thresh", ",", "topk_per_image", ",", "box_features", "\n", ")", "\n", "for", "scores_per_image", ",", "boxes_per_image", ",", "image_shape", "in", "zip", "(", "scores", ",", "boxes", ",", "image_shapes", ")", "\n", "]", "\n", "return", "[", "x", "[", "0", "]", "for", "x", "in", "result_per_image", "]", ",", "[", "x", "[", "1", "]", "for", "x", "in", "result_per_image", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.fast_rcnn_inference_single_image": [[98, 155], ["detectron2.structures.Boxes", "boxes.tensor.view.clip", "boxes.tensor.view.tensor.view", "filter_mask.nonzero", "detectron2.layers.batched_nms", "detectron2.structures.Instances", "detectron2.structures.Boxes", "torch.isfinite().all", "torch.isfinite().all", "valid_mask.all", "boxes.tensor.view.reshape", "torch.isfinite", "torch.isfinite"], "function", ["None"], ["", "def", "fast_rcnn_inference_single_image", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_shape", ",", "\n", "score_thresh", ",", "\n", "nms_thresh", ",", "\n", "topk_per_image", ",", "\n", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Single-image inference. Return bounding-box detection results by thresholding\n    on scores and applying non-maximum suppression (NMS).\n\n    Args:\n        Same as `fast_rcnn_inference`, but with boxes, scores, and image shapes\n        per image.\n\n    Returns:\n        Same as `fast_rcnn_inference`, but for only one image.\n    \"\"\"", "\n", "valid_mask", "=", "torch", ".", "isfinite", "(", "boxes", ")", ".", "all", "(", "dim", "=", "1", ")", "&", "torch", ".", "isfinite", "(", "scores", ")", ".", "all", "(", "dim", "=", "1", ")", "\n", "import", "pdb", "\n", "# pdb.set_trace()", "\n", "if", "not", "valid_mask", ".", "all", "(", ")", ":", "\n", "        ", "boxes", "=", "boxes", "[", "valid_mask", "]", "\n", "scores", "=", "scores", "[", "valid_mask", "]", "\n", "\n", "", "scores", "=", "scores", "[", ":", ",", ":", "-", "1", "]", "\n", "num_bbox_reg_classes", "=", "boxes", ".", "shape", "[", "1", "]", "//", "4", "\n", "# Convert to Boxes to use the `clip` function ...", "\n", "boxes", "=", "Boxes", "(", "boxes", ".", "reshape", "(", "-", "1", ",", "4", ")", ")", "\n", "boxes", ".", "clip", "(", "image_shape", ")", "\n", "boxes", "=", "boxes", ".", "tensor", ".", "view", "(", "-", "1", ",", "num_bbox_reg_classes", ",", "4", ")", "# R x C x 4", "\n", "\n", "# 1. Filter results based on detection scores. It can make NMS more efficient", "\n", "#    by filtering out low-confidence detections.", "\n", "filter_mask", "=", "scores", ">", "score_thresh", "# R x K", "\n", "# R' x 2. First column contains indices of the R predictions;", "\n", "# Second column contains indices of classes.", "\n", "filter_inds", "=", "filter_mask", ".", "nonzero", "(", ")", "#469,2", "\n", "if", "num_bbox_reg_classes", "==", "1", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_inds", "[", ":", ",", "0", "]", ",", "0", "]", "\n", "", "else", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_mask", "]", "\n", "", "scores", "=", "scores", "[", "filter_mask", "]", "\n", "\n", "# 2. Apply NMS for each class independently.", "\n", "keep", "=", "batched_nms", "(", "boxes", ",", "scores", ",", "filter_inds", "[", ":", ",", "1", "]", ",", "nms_thresh", ")", "\n", "if", "topk_per_image", ">=", "0", ":", "\n", "        ", "keep", "=", "keep", "[", ":", "topk_per_image", "]", "\n", "", "boxes", ",", "scores", ",", "filter_inds", "=", "boxes", "[", "keep", "]", ",", "scores", "[", "keep", "]", ",", "filter_inds", "[", "keep", "]", "#38,4", "\n", "\n", "result", "=", "Instances", "(", "image_shape", ")", "\n", "result", ".", "pred_boxes", "=", "Boxes", "(", "boxes", ")", "\n", "result", ".", "scores", "=", "scores", "\n", "result", ".", "pred_classes", "=", "filter_inds", "[", ":", ",", "1", "]", "\n", "return", "result", ",", "filter_inds", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.fast_rcnn_inference_single_image_2": [[156, 214], ["pdb.set_trace", "detectron2.structures.Boxes", "boxes.tensor.view.clip", "boxes.tensor.view.tensor.view", "filter_mask.nonzero", "detectron2.layers.batched_nms", "detectron2.structures.Instances", "detectron2.structures.Boxes", "torch.isfinite().all", "torch.isfinite().all", "valid_mask.all", "boxes.tensor.view.reshape", "torch.isfinite", "torch.isfinite"], "function", ["None"], ["", "def", "fast_rcnn_inference_single_image_2", "(", "\n", "boxes", ",", "\n", "scores", ",", "\n", "image_shape", ",", "\n", "score_thresh", ",", "\n", "nms_thresh", ",", "\n", "topk_per_image", ",", "\n", "box_features", ",", "\n", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Single-image inference. Return bounding-box detection results by thresholding\n    on scores and applying non-maximum suppression (NMS).\n\n    Args:\n        Same as `fast_rcnn_inference`, but with boxes, scores, and image shapes\n        per image.\n\n    Returns:\n        Same as `fast_rcnn_inference`, but for only one image.\n    \"\"\"", "\n", "valid_mask", "=", "torch", ".", "isfinite", "(", "boxes", ")", ".", "all", "(", "dim", "=", "1", ")", "&", "torch", ".", "isfinite", "(", "scores", ")", ".", "all", "(", "dim", "=", "1", ")", "\n", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "if", "not", "valid_mask", ".", "all", "(", ")", ":", "\n", "        ", "boxes", "=", "boxes", "[", "valid_mask", "]", "\n", "scores", "=", "scores", "[", "valid_mask", "]", "\n", "\n", "", "scores", "=", "scores", "[", ":", ",", ":", "-", "1", "]", "\n", "num_bbox_reg_classes", "=", "boxes", ".", "shape", "[", "1", "]", "//", "4", "\n", "# Convert to Boxes to use the `clip` function ...", "\n", "boxes", "=", "Boxes", "(", "boxes", ".", "reshape", "(", "-", "1", ",", "4", ")", ")", "\n", "boxes", ".", "clip", "(", "image_shape", ")", "\n", "boxes", "=", "boxes", ".", "tensor", ".", "view", "(", "-", "1", ",", "num_bbox_reg_classes", ",", "4", ")", "# R x C x 4", "\n", "\n", "# 1. Filter results based on detection scores. It can make NMS more efficient", "\n", "#    by filtering out low-confidence detections.", "\n", "filter_mask", "=", "scores", ">", "score_thresh", "# R x K", "\n", "# R' x 2. First column contains indices of the R predictions;", "\n", "# Second column contains indices of classes.", "\n", "filter_inds", "=", "filter_mask", ".", "nonzero", "(", ")", "#469,2", "\n", "if", "num_bbox_reg_classes", "==", "1", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_inds", "[", ":", ",", "0", "]", ",", "0", "]", "\n", "", "else", ":", "\n", "        ", "boxes", "=", "boxes", "[", "filter_mask", "]", "\n", "", "scores", "=", "scores", "[", "filter_mask", "]", "\n", "box_features", "=", "box_features", "[", "filter_mask", "]", "\n", "# 2. Apply NMS for each class independently.", "\n", "keep", "=", "batched_nms", "(", "boxes", ",", "scores", ",", "filter_inds", "[", ":", ",", "1", "]", ",", "nms_thresh", ")", "\n", "if", "topk_per_image", ">=", "0", ":", "\n", "        ", "keep", "=", "keep", "[", ":", "topk_per_image", "]", "\n", "", "boxes", ",", "scores", ",", "filter_inds", "=", "boxes", "[", "keep", "]", ",", "scores", "[", "keep", "]", ",", "filter_inds", "[", "keep", "]", "#38,4", "\n", "\n", "result", "=", "Instances", "(", "image_shape", ")", "\n", "result", ".", "pred_boxes", "=", "Boxes", "(", "boxes", ")", "\n", "result", ".", "scores", "=", "scores", "\n", "result", ".", "pred_classes", "=", "filter_inds", "[", ":", ",", "1", "]", "\n", "return", "result", ",", "filter_inds", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads.StandardROIHeadsPseudoLab._init_box_head": [[26, 65], ["tuple", "detectron2.modeling.poolers.ROIPooler", "detectron2.modeling.roi_heads.box_head.build_box_head", "len", "detectron2.layers.ShapeSpec", "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers", "set", "ubteacher.modeling.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers", "ValueError"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.box_head.build_box_head"], ["    ", "@", "classmethod", "\n", "def", "_init_box_head", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "# fmt: off", "\n", "        ", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "in_features", ")", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_TYPE", "\n", "# fmt: on", "\n", "\n", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "\n", "# Check all channel counts are equal", "\n", "assert", "len", "(", "set", "(", "in_channels", ")", ")", "==", "1", ",", "in_channels", "\n", "in_channels", "=", "in_channels", "[", "0", "]", "\n", "\n", "box_pooler", "=", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "box_head", "=", "build_box_head", "(", "\n", "cfg", ",", "\n", "ShapeSpec", "(", "\n", "channels", "=", "in_channels", ",", "height", "=", "pooler_resolution", ",", "width", "=", "pooler_resolution", "\n", ")", ",", "\n", ")", "\n", "if", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "LOSS", "==", "\"CrossEntropy\"", ":", "\n", "            ", "box_predictor", "=", "FastRCNNOutputLayers", "(", "cfg", ",", "box_head", ".", "output_shape", ")", "\n", "", "elif", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "LOSS", "==", "\"FocalLoss\"", ":", "\n", "            ", "box_predictor", "=", "FastRCNNFocaltLossOutputLayers", "(", "cfg", ",", "box_head", ".", "output_shape", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown ROI head loss.\"", ")", "\n", "\n", "", "return", "{", "\n", "\"box_in_features\"", ":", "in_features", ",", "\n", "\"box_pooler\"", ":", "box_pooler", ",", "\n", "\"box_head\"", ":", "box_head", ",", "\n", "\"box_predictor\"", ":", "box_predictor", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads.StandardROIHeadsPseudoLab.forward": [[67, 109], ["roi_heads.StandardROIHeadsPseudoLab.label_and_sample_proposals", "roi_heads.StandardROIHeadsPseudoLab._forward_box", "roi_heads.StandardROIHeadsPseudoLab._forward_box", "roi_heads.StandardROIHeadsPseudoLab.label_and_sample_proposals"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_teacher_refine.StandardROIHeadsPseudoLab_TeacherRefine.label_and_sample_proposals", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation._forward_box", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation._forward_box", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_teacher_refine.StandardROIHeadsPseudoLab_TeacherRefine.label_and_sample_proposals"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "images", ":", "ImageList", ",", "\n", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "proposals", ":", "List", "[", "Instances", "]", ",", "\n", "targets", ":", "Optional", "[", "List", "[", "Instances", "]", "]", "=", "None", ",", "\n", "compute_loss", "=", "True", ",", "\n", "branch", "=", "\"\"", ",", "\n", "compute_val_loss", "=", "False", ",", "\n", ")", "->", "Tuple", "[", "List", "[", "Instances", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "\n", "        ", "del", "images", "\n", "if", "self", ".", "training", "and", "compute_loss", ":", "# apply if training loss", "\n", "            ", "assert", "targets", "\n", "# 1000 --> 512", "\n", "proposals", "=", "self", ".", "label_and_sample_proposals", "(", "\n", "proposals", ",", "targets", ",", "branch", "=", "branch", "\n", ")", "\n", "", "elif", "compute_val_loss", ":", "# apply if val loss", "\n", "            ", "assert", "targets", "\n", "# 1000 --> 512", "\n", "temp_proposal_append_gt", "=", "self", ".", "proposal_append_gt", "\n", "self", ".", "proposal_append_gt", "=", "False", "\n", "proposals", "=", "self", ".", "label_and_sample_proposals", "(", "\n", "proposals", ",", "targets", ",", "branch", "=", "branch", "\n", ")", "# do not apply target on proposals", "\n", "self", ".", "proposal_append_gt", "=", "temp_proposal_append_gt", "\n", "# del targets", "\n", "\n", "", "if", "(", "self", ".", "training", "and", "compute_loss", ")", "or", "compute_val_loss", ":", "\n", "            ", "losses", ",", "_", "=", "self", ".", "_forward_box", "(", "\n", "features", ",", "proposals", ",", "compute_loss", ",", "compute_val_loss", ",", "targets", ",", "branch", "\n", ")", "\n", "import", "pdb", "\n", "# pdb.set_trace()", "\n", "return", "proposals", ",", "losses", "\n", "", "else", ":", "\n", "            ", "pred_instances", ",", "predictions", "=", "self", ".", "_forward_box", "(", "\n", "features", ",", "proposals", ",", "compute_loss", ",", "compute_val_loss", ",", "targets", ",", "branch", "\n", ")", "\n", "\n", "return", "pred_instances", ",", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads.StandardROIHeadsPseudoLab._forward_box": [[110, 158], ["roi_heads.StandardROIHeadsPseudoLab.box_pooler", "roi_heads.StandardROIHeadsPseudoLab.box_head", "roi_heads.StandardROIHeadsPseudoLab.box_predictor", "roi_heads.StandardROIHeadsPseudoLab.box_predictor.losses", "roi_heads.StandardROIHeadsPseudoLab.box_predictor.inference", "torch.no_grad", "roi_heads.StandardROIHeadsPseudoLab.box_predictor.predict_boxes_for_gt_classes", "zip", "detectron2.structures.Boxes"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocalLoss.losses", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.inference"], ["", "", "def", "_forward_box", "(", "\n", "self", ",", "\n", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "proposals", ":", "List", "[", "Instances", "]", ",", "\n", "compute_loss", ":", "bool", "=", "True", ",", "\n", "compute_val_loss", ":", "bool", "=", "False", ",", "\n", "targets", ":", "list", "=", "None", ",", "\n", "branch", ":", "str", "=", "\"\"", ",", "\n", ")", "->", "Union", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "List", "[", "Instances", "]", "]", ":", "\n", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "#features: a list", "\n", "#[8,256,h,w],[8, 256, h, w],[8, 256, h, w],[8, 256, h, w])", "\n", "\n", "\n", "        ", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "box_in_features", "]", "\n", "batch_size", "=", "features", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "box_features", "=", "self", ".", "box_pooler", "(", "features", ",", "[", "x", ".", "proposal_boxes", "for", "x", "in", "proposals", "]", ")", "#torch.Size([8000, 256, 7, 7])", "\n", "box_features", "=", "self", ".", "box_head", "(", "box_features", ")", "#8000,1024", "\n", "\n", "predictions", "=", "self", ".", "box_predictor", "(", "box_features", ")", "#[8000,2],[8000,4]", "\n", "\n", "\n", "if", "(", "\n", "self", ".", "training", "and", "compute_loss", "\n", ")", "or", "compute_val_loss", ":", "# apply if training loss or val loss", "\n", "\n", "            ", "losses", "=", "self", ".", "box_predictor", ".", "losses", "(", "predictions", ",", "proposals", ")", "\n", "\n", "\n", "if", "self", ".", "train_on_pred_boxes", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "pred_boxes", "=", "self", ".", "box_predictor", ".", "predict_boxes_for_gt_classes", "(", "\n", "predictions", ",", "proposals", "\n", ")", "\n", "for", "proposals_per_image", ",", "pred_boxes_per_image", "in", "zip", "(", "\n", "proposals", ",", "pred_boxes", "\n", ")", ":", "\n", "                        ", "proposals_per_image", ".", "proposal_boxes", "=", "Boxes", "(", "pred_boxes_per_image", ")", "\n", "", "", "", "return", "losses", ",", "predictions", "\n", "\n", "\n", "", "else", ":", "\n", "            ", "pred_instances", ",", "_", "=", "self", ".", "box_predictor", ".", "inference", "(", "predictions", ",", "proposals", ",", "branch", ")", "\n", "# del box_features", "\n", "# return pred_instances, predictions", "\n", "return", "pred_instances", ",", "box_features", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads.StandardROIHeadsPseudoLab.label_and_sample_proposals": [[159, 210], ["torch.no_grad", "zip", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.modeling.proposal_generator.proposal_utils.add_ground_truth_to_proposals", "detectron2.structures.pairwise_iou", "roi_heads.StandardROIHeadsPseudoLab.proposal_matcher", "roi_heads.StandardROIHeadsPseudoLab._sample_proposals", "num_bg_samples.append", "num_fg_samples.append", "proposals_with_gt.append", "numpy.mean", "numpy.mean", "len", "targets_per_image.get_fields().items", "detectron2.structures.Boxes", "targets_per_image.gt_boxes.tensor.new_zeros", "gt_classes.numel", "targets_per_image.get_fields", "trg_name.startswith", "proposals_per_image.set", "proposals_per_image.has", "len"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.get_event_storage", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "label_and_sample_proposals", "(", "\n", "self", ",", "proposals", ":", "List", "[", "Instances", "]", ",", "targets", ":", "List", "[", "Instances", "]", ",", "branch", ":", "str", "=", "\"\"", "\n", ")", "->", "List", "[", "Instances", "]", ":", "\n", "        ", "gt_boxes", "=", "[", "x", ".", "gt_boxes", "for", "x", "in", "targets", "]", "\n", "if", "self", ".", "proposal_append_gt", ":", "\n", "            ", "proposals", "=", "add_ground_truth_to_proposals", "(", "gt_boxes", ",", "proposals", ")", "\n", "\n", "", "proposals_with_gt", "=", "[", "]", "\n", "\n", "num_fg_samples", "=", "[", "]", "\n", "num_bg_samples", "=", "[", "]", "\n", "for", "proposals_per_image", ",", "targets_per_image", "in", "zip", "(", "proposals", ",", "targets", ")", ":", "\n", "            ", "has_gt", "=", "len", "(", "targets_per_image", ")", ">", "0", "\n", "match_quality_matrix", "=", "pairwise_iou", "(", "\n", "targets_per_image", ".", "gt_boxes", ",", "proposals_per_image", ".", "proposal_boxes", "\n", ")", "\n", "matched_idxs", ",", "matched_labels", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "sampled_idxs", ",", "gt_classes", "=", "self", ".", "_sample_proposals", "(", "\n", "matched_idxs", ",", "matched_labels", ",", "targets_per_image", ".", "gt_classes", "\n", ")", "\n", "\n", "proposals_per_image", "=", "proposals_per_image", "[", "sampled_idxs", "]", "\n", "proposals_per_image", ".", "gt_classes", "=", "gt_classes", "\n", "\n", "if", "has_gt", ":", "\n", "                ", "sampled_targets", "=", "matched_idxs", "[", "sampled_idxs", "]", "\n", "for", "(", "trg_name", ",", "trg_value", ")", "in", "targets_per_image", ".", "get_fields", "(", ")", ".", "items", "(", ")", ":", "\n", "                    ", "if", "trg_name", ".", "startswith", "(", "\"gt_\"", ")", "and", "not", "proposals_per_image", ".", "has", "(", "\n", "trg_name", "\n", ")", ":", "\n", "                        ", "proposals_per_image", ".", "set", "(", "trg_name", ",", "trg_value", "[", "sampled_targets", "]", ")", "\n", "", "", "", "else", ":", "\n", "                ", "gt_boxes", "=", "Boxes", "(", "\n", "targets_per_image", ".", "gt_boxes", ".", "tensor", ".", "new_zeros", "(", "(", "len", "(", "sampled_idxs", ")", ",", "4", ")", ")", "\n", ")", "\n", "proposals_per_image", ".", "gt_boxes", "=", "gt_boxes", "\n", "\n", "", "num_bg_samples", ".", "append", "(", "(", "gt_classes", "==", "self", ".", "num_classes", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "num_fg_samples", ".", "append", "(", "gt_classes", ".", "numel", "(", ")", "-", "num_bg_samples", "[", "-", "1", "]", ")", "\n", "proposals_with_gt", ".", "append", "(", "proposals_per_image", ")", "\n", "\n", "", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\n", "\"roi_head/num_target_fg_samples_\"", "+", "branch", ",", "np", ".", "mean", "(", "num_fg_samples", ")", "\n", ")", "\n", "storage", ".", "put_scalar", "(", "\n", "\"roi_head/num_target_bg_samples_\"", "+", "branch", ",", "np", ".", "mean", "(", "num_bg_samples", ")", "\n", ")", "\n", "\n", "return", "proposals_with_gt", "\n", "", "", "def", "cosinematrix", "(", "A", ")", ":", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads.cosinematrix": [[210, 215], ["torch.mm", "torch.norm().unsqueeze", "torch.mm.div", "A.t", "torch.mm", "torch.norm", "torch.norm().unsqueeze.t"], "function", ["None"], ["", "", "def", "cosinematrix", "(", "A", ")", ":", "\n", "    ", "prod", "=", "torch", ".", "mm", "(", "A", ",", "A", ".", "t", "(", ")", ")", "#", "\n", "norm", "=", "torch", ".", "norm", "(", "A", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "0", ")", "#", "\n", "cos", "=", "prod", ".", "div", "(", "torch", ".", "mm", "(", "norm", ".", "t", "(", ")", ",", "norm", ")", ")", "\n", "return", "cos", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_teacher_refine.StandardROIHeadsPseudoLab_TeacherRefine.__init__": [[29, 36], ["detectron2.modeling.roi_heads.StandardROIHeads.__init__"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["    ", "@", "configurable", "\n", "def", "__init__", "(", "self", ",", "label_refine_score_thresh", ",", "label_refine_ratio", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "# super().__init__()", "\n", "self", ".", "label_refine_score_thresh", "=", "label_refine_score_thresh", "\n", "self", ".", "label_refine_ratio", "=", "label_refine_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_teacher_refine.StandardROIHeadsPseudoLab_TeacherRefine._init_box_head": [[39, 82], ["tuple", "detectron2.modeling.poolers.ROIPooler", "detectron2.modeling.roi_heads.box_head.build_box_head", "len", "detectron2.layers.ShapeSpec", "detectron2.modeling.roi_heads.fast_rcnn.FastRCNNOutputLayers", "set", "ubteacher.modeling.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers", "ValueError"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.box_head.build_box_head"], ["", "@", "classmethod", "\n", "def", "_init_box_head", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "# fmt: off", "\n", "        ", "in_features", "=", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "IN_FEATURES", "\n", "pooler_resolution", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_RESOLUTION", "\n", "pooler_scales", "=", "tuple", "(", "1.0", "/", "input_shape", "[", "k", "]", ".", "stride", "for", "k", "in", "in_features", ")", "\n", "sampling_ratio", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_SAMPLING_RATIO", "\n", "pooler_type", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "POOLER_TYPE", "\n", "label_refine_score_thresh", "=", "cfg", ".", "LABEL_REFINE_THRESH", "\n", "label_refine_ratio", "=", "cfg", ".", "LABEL_REFINE_RATIO", "\n", "# fmt: on", "\n", "\n", "in_channels", "=", "[", "input_shape", "[", "f", "]", ".", "channels", "for", "f", "in", "in_features", "]", "\n", "# Check all channel counts are equal", "\n", "assert", "len", "(", "set", "(", "in_channels", ")", ")", "==", "1", ",", "in_channels", "\n", "in_channels", "=", "in_channels", "[", "0", "]", "\n", "\n", "box_pooler", "=", "ROIPooler", "(", "\n", "output_size", "=", "pooler_resolution", ",", "\n", "scales", "=", "pooler_scales", ",", "\n", "sampling_ratio", "=", "sampling_ratio", ",", "\n", "pooler_type", "=", "pooler_type", ",", "\n", ")", "\n", "box_head", "=", "build_box_head", "(", "\n", "cfg", ",", "\n", "ShapeSpec", "(", "\n", "channels", "=", "in_channels", ",", "height", "=", "pooler_resolution", ",", "width", "=", "pooler_resolution", "\n", ")", ",", "\n", ")", "\n", "if", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "LOSS", "==", "\"CrossEntropy\"", ":", "\n", "            ", "box_predictor", "=", "FastRCNNOutputLayers", "(", "cfg", ",", "box_head", ".", "output_shape", ")", "\n", "", "elif", "cfg", ".", "MODEL", ".", "ROI_HEADS", ".", "LOSS", "==", "\"FocalLoss\"", ":", "\n", "            ", "box_predictor", "=", "FastRCNNFocaltLossOutputLayers", "(", "cfg", ",", "box_head", ".", "output_shape", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown ROI head loss.\"", ")", "\n", "\n", "", "return", "{", "\n", "\"box_in_features\"", ":", "in_features", ",", "\n", "\"box_pooler\"", ":", "box_pooler", ",", "\n", "\"box_head\"", ":", "box_head", ",", "\n", "\"box_predictor\"", ":", "box_predictor", ",", "\n", "\"label_refine_score_thresh\"", ":", "label_refine_score_thresh", ",", "\n", "\"label_refine_ratio\"", ":", "label_refine_ratio", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_teacher_refine.StandardROIHeadsPseudoLab_TeacherRefine.label_and_sample_proposals": [[85, 136], ["torch.no_grad", "zip", "detectron2.utils.events.get_event_storage", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.utils.events.get_event_storage.put_scalar", "detectron2.modeling.proposal_generator.proposal_utils.add_ground_truth_to_proposals", "detectron2.structures.pairwise_iou", "roi_heads_teacher_refine.StandardROIHeadsPseudoLab_TeacherRefine.proposal_matcher", "roi_heads_teacher_refine.StandardROIHeadsPseudoLab_TeacherRefine._sample_proposals", "num_bg_samples.append", "num_fg_samples.append", "proposals_with_gt.append", "numpy.mean", "numpy.mean", "len", "targets_per_image.get_fields().items", "detectron2.structures.Boxes", "targets_per_image.gt_boxes.tensor.new_zeros", "gt_classes.numel", "targets_per_image.get_fields", "trg_name.startswith", "proposals_per_image.set", "proposals_per_image.has", "len"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.get_event_storage", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "label_and_sample_proposals", "(", "\n", "self", ",", "proposals", ":", "List", "[", "Instances", "]", ",", "targets", ":", "List", "[", "Instances", "]", ",", "branch", ":", "str", "=", "\"\"", "\n", ")", "->", "List", "[", "Instances", "]", ":", "\n", "        ", "gt_boxes", "=", "[", "x", ".", "gt_boxes", "for", "x", "in", "targets", "]", "\n", "if", "self", ".", "proposal_append_gt", ":", "\n", "            ", "proposals", "=", "add_ground_truth_to_proposals", "(", "gt_boxes", ",", "proposals", ")", "\n", "\n", "", "proposals_with_gt", "=", "[", "]", "\n", "\n", "num_fg_samples", "=", "[", "]", "\n", "num_bg_samples", "=", "[", "]", "\n", "for", "proposals_per_image", ",", "targets_per_image", "in", "zip", "(", "proposals", ",", "targets", ")", ":", "\n", "            ", "has_gt", "=", "len", "(", "targets_per_image", ")", ">", "0", "\n", "match_quality_matrix", "=", "pairwise_iou", "(", "\n", "targets_per_image", ".", "gt_boxes", ",", "proposals_per_image", ".", "proposal_boxes", "\n", ")", "\n", "matched_idxs", ",", "matched_labels", "=", "self", ".", "proposal_matcher", "(", "match_quality_matrix", ")", "\n", "sampled_idxs", ",", "gt_classes", "=", "self", ".", "_sample_proposals", "(", "\n", "matched_idxs", ",", "matched_labels", ",", "targets_per_image", ".", "gt_classes", "\n", ")", "\n", "\n", "proposals_per_image", "=", "proposals_per_image", "[", "sampled_idxs", "]", "\n", "proposals_per_image", ".", "gt_classes", "=", "gt_classes", "\n", "\n", "if", "has_gt", ":", "\n", "                ", "sampled_targets", "=", "matched_idxs", "[", "sampled_idxs", "]", "\n", "for", "(", "trg_name", ",", "trg_value", ")", "in", "targets_per_image", ".", "get_fields", "(", ")", ".", "items", "(", ")", ":", "\n", "                    ", "if", "trg_name", ".", "startswith", "(", "\"gt_\"", ")", "and", "not", "proposals_per_image", ".", "has", "(", "\n", "trg_name", "\n", ")", ":", "\n", "                        ", "proposals_per_image", ".", "set", "(", "trg_name", ",", "trg_value", "[", "sampled_targets", "]", ")", "\n", "", "", "", "else", ":", "\n", "                ", "gt_boxes", "=", "Boxes", "(", "\n", "targets_per_image", ".", "gt_boxes", ".", "tensor", ".", "new_zeros", "(", "(", "len", "(", "sampled_idxs", ")", ",", "4", ")", ")", "\n", ")", "\n", "proposals_per_image", ".", "gt_boxes", "=", "gt_boxes", "\n", "\n", "", "num_bg_samples", ".", "append", "(", "(", "gt_classes", "==", "self", ".", "num_classes", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "num_fg_samples", ".", "append", "(", "gt_classes", ".", "numel", "(", ")", "-", "num_bg_samples", "[", "-", "1", "]", ")", "\n", "proposals_with_gt", ".", "append", "(", "proposals_per_image", ")", "\n", "\n", "", "storage", "=", "get_event_storage", "(", ")", "\n", "storage", ".", "put_scalar", "(", "\n", "\"roi_head/num_target_fg_samples_\"", "+", "branch", ",", "np", ".", "mean", "(", "num_fg_samples", ")", "\n", ")", "\n", "storage", ".", "put_scalar", "(", "\n", "\"roi_head/num_target_bg_samples_\"", "+", "branch", ",", "np", ".", "mean", "(", "num_bg_samples", ")", "\n", ")", "\n", "\n", "return", "proposals_with_gt", "\n", "", "@", "torch", ".", "no_grad", "(", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_teacher_refine.StandardROIHeadsPseudoLab_TeacherRefine.cosinematrix": [[136, 142], ["torch.no_grad", "torch.mm", "torch.norm().unsqueeze", "torch.mm.div", "A.t", "torch.mm", "torch.norm", "torch.norm().unsqueeze.t"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "cosinematrix", "(", "self", ",", "A", ")", ":", "\n", "        ", "prod", "=", "torch", ".", "mm", "(", "A", ",", "A", ".", "t", "(", ")", ")", "#\u5206\u5b50", "\n", "norm", "=", "torch", ".", "norm", "(", "A", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "0", ")", "#\u5206\u6bcd", "\n", "cos", "=", "prod", ".", "div", "(", "torch", ".", "mm", "(", "norm", ".", "t", "(", ")", ",", "norm", ")", ")", "\n", "return", "cos", "", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.box_head.FastRCNNConvFCHead.__init__": [[32, 86], ["torch.nn.Sequential.__init__", "enumerate", "enumerate", "detectron2.layers.Conv2d", "box_head.FastRCNNConvFCHead.add_module", "box_head.FastRCNNConvFCHead.conv_norm_relus.append", "torch.nn.Linear", "box_head.FastRCNNConvFCHead.add_module", "box_head.FastRCNNConvFCHead.add_module", "box_head.FastRCNNConvFCHead.fcs.append", "fvcore.c2_msra_fill", "fvcore.c2_xavier_fill", "len", "len", "box_head.FastRCNNConvFCHead.add_module", "int", "torch.nn.ReLU", "detectron2.layers.get_norm", "torch.nn.ReLU", "torch.nn.Flatten", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["@", "configurable", "\n", "def", "__init__", "(", "\n", "self", ",", "input_shape", ":", "ShapeSpec", ",", "*", ",", "conv_dims", ":", "List", "[", "int", "]", ",", "fc_dims", ":", "List", "[", "int", "]", ",", "conv_norm", "=", "\"\"", "\n", ")", ":", "\n", "        ", "\"\"\"\n        NOTE: this interface is experimental.\n\n        Args:\n            input_shape (ShapeSpec): shape of the input feature.\n            conv_dims (list[int]): the output dimensions of the conv layers\n            fc_dims (list[int]): the output dimensions of the fc layers\n            conv_norm (str or callable): normalization for the conv layers.\n                See :func:`detectron2.layers.get_norm` for supported types.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "len", "(", "conv_dims", ")", "+", "len", "(", "fc_dims", ")", ">", "0", "\n", "\n", "self", ".", "_output_size", "=", "(", "input_shape", ".", "channels", ",", "input_shape", ".", "height", ",", "input_shape", ".", "width", ")", "\n", "\n", "self", ".", "conv_norm_relus", "=", "[", "]", "\n", "for", "k", ",", "conv_dim", "in", "enumerate", "(", "conv_dims", ")", ":", "\n", "            ", "conv", "=", "Conv2d", "(", "\n", "self", ".", "_output_size", "[", "0", "]", ",", "\n", "conv_dim", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "not", "conv_norm", ",", "\n", "norm", "=", "get_norm", "(", "conv_norm", ",", "conv_dim", ")", ",", "\n", "activation", "=", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n", "self", ".", "add_module", "(", "\"conv{}\"", ".", "format", "(", "k", "+", "1", ")", ",", "conv", ")", "\n", "self", ".", "conv_norm_relus", ".", "append", "(", "conv", ")", "\n", "self", ".", "_output_size", "=", "(", "conv_dim", ",", "self", ".", "_output_size", "[", "1", "]", ",", "self", ".", "_output_size", "[", "2", "]", ")", "\n", "\n", "", "self", ".", "fcs", "=", "[", "]", "\n", "for", "k", ",", "fc_dim", "in", "enumerate", "(", "fc_dims", ")", ":", "\n", "            ", "if", "k", "==", "0", ":", "\n", "                ", "self", ".", "add_module", "(", "\"flatten\"", ",", "nn", ".", "Flatten", "(", ")", ")", "\n", "", "fc", "=", "nn", ".", "Linear", "(", "int", "(", "np", ".", "prod", "(", "self", ".", "_output_size", ")", ")", ",", "fc_dim", ")", "\n", "self", ".", "add_module", "(", "\"fc{}\"", ".", "format", "(", "k", "+", "1", ")", ",", "fc", ")", "\n", "self", ".", "add_module", "(", "\"fc_relu{}\"", ".", "format", "(", "k", "+", "1", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "fcs", ".", "append", "(", "fc", ")", "\n", "self", ".", "_output_size", "=", "fc_dim", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "", "for", "layer", "in", "self", ".", "conv_norm_relus", ":", "\n", "            ", "weight_init", ".", "c2_msra_fill", "(", "layer", ")", "\n", "", "for", "layer", "in", "self", ".", "fcs", ":", "\n", "            ", "weight_init", ".", "c2_xavier_fill", "(", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.box_head.FastRCNNConvFCHead.from_config": [[87, 98], ["None"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "cfg", ",", "input_shape", ")", ":", "\n", "        ", "num_conv", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_CONV", "\n", "conv_dim", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "CONV_DIM", "\n", "num_fc", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NUM_FC", "\n", "fc_dim", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "FC_DIM", "\n", "return", "{", "\n", "\"input_shape\"", ":", "input_shape", ",", "\n", "\"conv_dims\"", ":", "[", "conv_dim", "]", "*", "num_conv", ",", "\n", "\"fc_dims\"", ":", "[", "fc_dim", "]", "*", "num_fc", ",", "\n", "\"conv_norm\"", ":", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NORM", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.box_head.FastRCNNConvFCHead.forward": [[100, 117], ["layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# x [batch*1000, 256,7,7]", "\n", "#1000 post nms", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "\n", "# total_layer=len(self)", "\n", "# num_box_head_layer=6", "\n", "# cross_layer=total_layer-num_box_head_layer", "\n", "\n", "        ", "for", "layer", "in", "self", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "\n", "# for j in (6,num_box_head_layer):", "\n", "#     x=self[j](x)", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.box_head.FastRCNNConvFCHead.output_shape": [[118, 130], ["isinstance", "detectron2.layers.ShapeSpec", "detectron2.layers.ShapeSpec"], "methods", ["None"], ["", "@", "property", "\n", "@", "torch", ".", "jit", ".", "unused", "\n", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            ShapeSpec: the output feature shape\n        \"\"\"", "\n", "o", "=", "self", ".", "_output_size", "\n", "if", "isinstance", "(", "o", ",", "int", ")", ":", "\n", "            ", "return", "ShapeSpec", "(", "channels", "=", "o", ")", "\n", "", "else", ":", "\n", "            ", "return", "ShapeSpec", "(", "channels", "=", "o", "[", "0", "]", ",", "height", "=", "o", "[", "1", "]", ",", "width", "=", "o", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.box_head.build_box_head": [[132, 138], ["ROI_BOX_HEAD_REGISTRY.get"], "function", ["None"], ["", "", "", "def", "build_box_head", "(", "cfg", ",", "input_shape", ")", ":", "\n", "    ", "\"\"\"\n    Build a box head defined by `cfg.MODEL.ROI_BOX_HEAD.NAME`.\n    \"\"\"", "\n", "name", "=", "cfg", ".", "MODEL", ".", "ROI_BOX_HEAD", ".", "NAME", "\n", "return", "ROI_BOX_HEAD_REGISTRY", ".", "get", "(", "name", ")", "(", "cfg", ",", "input_shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation.forward": [[30, 93], ["roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation.label_and_sample_proposals", "roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation._forward_box", "roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation.label_and_sample_proposals", "roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation._forward_box", "roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation._forward_box", "roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation._forward_box"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_teacher_refine.StandardROIHeadsPseudoLab_TeacherRefine.label_and_sample_proposals", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation._forward_box", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_teacher_refine.StandardROIHeadsPseudoLab_TeacherRefine.label_and_sample_proposals", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation._forward_box", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation._forward_box", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation._forward_box"], ["    ", "def", "forward", "(", "\n", "self", ",", "\n", "images", ":", "ImageList", ",", "\n", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "proposals", ":", "List", "[", "Instances", "]", ",", "\n", "targets", ":", "Optional", "[", "List", "[", "Instances", "]", "]", "=", "None", ",", "\n", "compute_loss", "=", "True", ",", "\n", "branch", "=", "\"\"", ",", "\n", "compute_val_loss", "=", "False", ",", "\n", ")", "->", "Tuple", "[", "List", "[", "Instances", "]", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "\n", "            ", "del", "images", "\n", "if", "self", ".", "training", "and", "compute_loss", ":", "# apply if training loss", "\n", "                ", "assert", "targets", "\n", "# 1000 --> 512", "\n", "\n", "proposals", "=", "self", ".", "label_and_sample_proposals", "(", "\n", "proposals", ",", "targets", ",", "branch", "=", "branch", "\n", ")", "\n", "", "elif", "compute_val_loss", ":", "# apply if val loss", "\n", "                ", "assert", "targets", "\n", "# 1000 --> 512", "\n", "temp_proposal_append_gt", "=", "self", ".", "proposal_append_gt", "\n", "self", ".", "proposal_append_gt", "=", "False", "\n", "proposals", "=", "self", ".", "label_and_sample_proposals", "(", "\n", "proposals", ",", "targets", ",", "branch", "=", "branch", "\n", ")", "# do not apply target on proposals", "\n", "self", ".", "proposal_append_gt", "=", "temp_proposal_append_gt", "\n", "# del targets", "\n", "\n", "", "if", "(", "self", ".", "training", "and", "compute_loss", ")", "or", "compute_val_loss", ":", "\n", "\n", "                ", "if", "\"object_relation\"", "in", "branch", ":", "\n", "                    ", "proposals_new", ",", "box_features", "=", "self", ".", "_forward_box", "(", "\n", "features", ",", "proposals", ",", "compute_loss", ",", "compute_val_loss", ",", "targets", ",", "branch", "\n", ")", "\n", "return", "proposals_new", ",", "box_features", "\n", "", "else", ":", "\n", "                    ", "losses", ",", "_", "=", "self", ".", "_forward_box", "(", "\n", "features", ",", "proposals", ",", "compute_loss", ",", "compute_val_loss", ",", "targets", ",", "branch", "\n", ")", "\n", "\n", "\n", "if", "branch", "==", "\"target_img_two_head_refine\"", "or", "branch", "==", "\"target_img_two_head_attention\"", ":", "\n", "                        ", "return", "losses", ",", "_", "\n", "# pdb.set_trace()", "\n", "", "return", "proposals", ",", "losses", "\n", "\n", "\n", "# del targets", "\n", "\n", "\n", "", "", "else", ":", "\n", "                ", "if", "\"object_relation\"", "in", "branch", ":", "\n", "                    ", "proposals_new", ",", "box_features", "=", "self", ".", "_forward_box", "(", "\n", "features", ",", "proposals", ",", "compute_loss", ",", "compute_val_loss", ",", "targets", ",", "branch", "\n", ")", "\n", "return", "proposals_new", ",", "box_features", "\n", "\n", "", "pred_instances", ",", "predictions", "=", "self", ".", "_forward_box", "(", "\n", "features", ",", "proposals", ",", "compute_loss", ",", "compute_val_loss", ",", "targets", ",", "branch", "\n", ")", "\n", "return", "pred_instances", ",", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation._forward_box": [[94, 143], ["roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation.box_pooler", "roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation.box_head", "roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation.box_predictor", "roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation.box_predictor.losses", "roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation.box_predictor.inference", "torch.no_grad", "roi_heads_two_head_refine_relation.StandardROIHeadsPseudoLab_object_relation.box_predictor.predict_boxes_for_gt_classes", "zip", "detectron2.structures.Boxes"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocalLoss.losses", "home.repos.pwc.inspect_result.feobi1999_tdd.roi_heads.fast_rcnn.FastRCNNFocaltLossOutputLayers.inference"], ["", "", "def", "_forward_box", "(", "\n", "self", ",", "\n", "features", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "\n", "proposals", ":", "List", "[", "Instances", "]", ",", "\n", "compute_loss", ":", "bool", "=", "True", ",", "\n", "compute_val_loss", ":", "bool", "=", "False", ",", "\n", "targets", ":", "list", "=", "None", ",", "\n", "branch", ":", "str", "=", "\"\"", ",", "\n", ")", "->", "Union", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ",", "List", "[", "Instances", "]", "]", ":", "\n", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "#features: a list", "\n", "#[8,256,h,w],[8, 256, h, w],[8, 256, h, w],[8, 256, h, w])", "\n", "\n", "\n", "        ", "features", "=", "[", "features", "[", "f", "]", "for", "f", "in", "self", ".", "box_in_features", "]", "\n", "batch_size", "=", "features", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "box_features", "=", "self", ".", "box_pooler", "(", "features", ",", "[", "x", ".", "proposal_boxes", "for", "x", "in", "proposals", "]", ")", "#torch.Size([8000, 256, 7, 7])", "\n", "if", "\"object_relation\"", "in", "branch", ":", "\n", "            ", "return", "proposals", ",", "box_features", "\n", "\n", "\n", "", "box_features", "=", "self", ".", "box_head", "(", "box_features", ")", "#8000,1024", "\n", "predictions", "=", "self", ".", "box_predictor", "(", "box_features", ")", "#[8000,2],[8000,4]", "\n", "\n", "\n", "if", "(", "\n", "self", ".", "training", "and", "compute_loss", "\n", ")", "or", "compute_val_loss", ":", "# apply if training loss or val loss", "\n", "            ", "losses", "=", "self", ".", "box_predictor", ".", "losses", "(", "predictions", ",", "proposals", ")", "\n", "\n", "\n", "if", "self", ".", "train_on_pred_boxes", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "pred_boxes", "=", "self", ".", "box_predictor", ".", "predict_boxes_for_gt_classes", "(", "\n", "predictions", ",", "proposals", "\n", ")", "\n", "for", "proposals_per_image", ",", "pred_boxes_per_image", "in", "zip", "(", "\n", "proposals", ",", "pred_boxes", "\n", ")", ":", "\n", "                        ", "proposals_per_image", ".", "proposal_boxes", "=", "Boxes", "(", "pred_boxes_per_image", ")", "\n", "\n", "\n", "", "", "", "return", "losses", ",", "predictions", "\n", "", "else", ":", "\n", "            ", "pred_instances", ",", "_", "=", "self", ".", "box_predictor", ".", "inference", "(", "predictions", ",", "proposals", ",", "branch", ")", "\n", "del", "box_features", "\n", "return", "pred_instances", ",", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGGBlock.__init__": [[42, 69], ["detectron2.layers.CNNBlockBase.__init__", "enumerate", "detectron2.layers.Conv2d", "setattr", "vgg.VGGBlock.convs.append", "torch.nn.MaxPool2d", "str", "fvcore.c2_msra_fill", "detectron2.layers.get_norm"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "channel_cfg", ",", "norm", "=", "\"BN\"", ",", "pool", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "in_channels", ",", "channel_cfg", "[", "-", "1", "]", ",", "2", ")", "\n", "\n", "self", ".", "convs", "=", "[", "]", "\n", "self", ".", "pool", "=", "pool", "\n", "\n", "for", "i", ",", "out_channels", "in", "enumerate", "(", "channel_cfg", ")", ":", "\n", "            ", "name", "=", "\"conv\"", "+", "str", "(", "i", "+", "1", ")", "\n", "conv", "=", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "norm", "=", "get_norm", "(", "norm", ",", "out_channels", ")", ",", "\n", ")", "\n", "in_channels", "=", "out_channels", "\n", "setattr", "(", "self", ",", "name", ",", "conv", ")", "\n", "self", ".", "convs", ".", "append", "(", "conv", ")", "\n", "\n", "", "if", "self", ".", "pool", ":", "\n", "            ", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "\n", "\n", "", "for", "layer", "in", "self", ".", "convs", ":", "\n", "            ", "if", "layer", "is", "not", "None", ":", "\n", "                ", "weight_init", ".", "c2_msra_fill", "(", "layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGGBlock.forward": [[70, 78], ["conv", "torch.relu_", "vgg.VGGBlock.maxpool"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "conv", "in", "self", ".", "convs", ":", "\n", "            ", "out", "=", "conv", "(", "x", ")", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "x", "=", "out", "\n", "", "if", "self", ".", "pool", ":", "\n", "            ", "out", "=", "self", ".", "maxpool", "(", "out", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.__init__": [[81, 130], ["backbone.Backbone.__init__", "enumerate", "len", "torch.nn.Sequential", "vgg.VGG.add_module", "vgg.VGG.stages_and_names.append", "int", "torch.nn.AdaptiveAvgPool2d", "torch.nn.Sequential", "vgg.VGG.classifier.modules", "str", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Dropout", "torch.nn.Linear", "isinstance", "vgg.VGG.named_children", "numpy.prod", "torch.nn.init.normal_"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["    ", "def", "__init__", "(", "self", ",", "stages", ",", "num_classes", "=", "None", ",", "out_features", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "\n", "current_stride", "=", "1", "\n", "self", ".", "_out_feature_strides", "=", "{", "}", "\n", "self", ".", "_out_feature_channels", "=", "{", "}", "\n", "\n", "self", ".", "stages_and_names", "=", "[", "]", "\n", "for", "i", ",", "block", "in", "enumerate", "(", "stages", ")", ":", "\n", "\n", "            ", "name", "=", "\"vgg_block\"", "+", "str", "(", "i", "+", "1", ")", "\n", "stage", "=", "nn", ".", "Sequential", "(", "block", ")", "\n", "\n", "self", ".", "add_module", "(", "name", ",", "stage", ")", "\n", "self", ".", "stages_and_names", ".", "append", "(", "(", "stage", ",", "name", ")", ")", "\n", "\n", "self", ".", "_out_feature_strides", "[", "name", "]", "=", "current_stride", "=", "int", "(", "\n", "current_stride", "*", "np", ".", "prod", "(", "[", "block", ".", "stride", "]", ")", "\n", ")", "\n", "self", ".", "_out_feature_channels", "[", "name", "]", "=", "block", ".", "convs", "[", "-", "1", "]", ".", "out_channels", "\n", "\n", "", "if", "num_classes", "is", "not", "None", ":", "\n", "            ", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "7", ",", "7", ")", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", "*", "7", "*", "7", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "num_classes", ")", ",", "\n", ")", "\n", "\n", "for", "m", "in", "self", ".", "classifier", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "0.01", ")", "\n", "# nn.init.constant_(m.bias, 0)", "\n", "name", "=", "\"classifier\"", "\n", "\n", "", "", "", "if", "out_features", "is", "None", ":", "\n", "            ", "out_features", "=", "[", "name", "]", "\n", "", "self", ".", "_out_features", "=", "out_features", "\n", "assert", "len", "(", "self", ".", "_out_features", ")", "\n", "children", "=", "[", "x", "[", "0", "]", "for", "x", "in", "self", ".", "named_children", "(", ")", "]", "\n", "for", "out_feature", "in", "self", ".", "_out_features", ":", "\n", "            ", "assert", "out_feature", "in", "children", ",", "\"Available children: {}\"", ".", "format", "(", "\", \"", ".", "join", "(", "children", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.forward": [[131, 143], ["stage", "vgg.VGG.avgpool", "vgg.VGG.classifier"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "outputs", "=", "{", "}", "\n", "for", "stage", ",", "name", "in", "self", ".", "stages_and_names", ":", "\n", "            ", "x", "=", "stage", "(", "x", ")", "\n", "if", "name", "in", "self", ".", "_out_features", ":", "\n", "                ", "outputs", "[", "name", "]", "=", "x", "\n", "", "", "if", "self", ".", "num_classes", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "if", "\"classifer\"", "in", "self", ".", "_out_features", ":", "\n", "                ", "outputs", "[", "\"classifer\"", "]", "=", "x", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.output_shape": [[144, 150], ["detectron2.layers.ShapeSpec"], "methods", ["None"], ["", "def", "output_shape", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "name", ":", "ShapeSpec", "(", "\n", "channels", "=", "self", ".", "_out_feature_channels", "[", "name", "]", ",", "stride", "=", "self", ".", "_out_feature_strides", "[", "name", "]", "\n", ")", "\n", "for", "name", "in", "self", ".", "_out_features", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.freeze": [[152, 158], ["enumerate", "stage.children", "block.freeze"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.freeze"], ["", "def", "freeze", "(", "self", ",", "freeze_at", "=", "0", ")", ":", "\n", "        ", "for", "idx", ",", "(", "stage", ",", "_", ")", "in", "enumerate", "(", "self", ".", "stages_and_names", ",", "start", "=", "1", ")", ":", "\n", "            ", "if", "freeze_at", ">=", "idx", ":", "\n", "                ", "for", "block", "in", "stage", ".", "children", "(", ")", ":", "\n", "                    ", "block", ".", "freeze", "(", ")", "\n", "", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.make_stage": [[159, 164], ["block_class"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "make_stage", "(", "block_class", ",", "in_channels", ",", "channel_cfg", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "\"stride\"", "not", "in", "kwargs", ",", "\"Stride of blocks in make_stage cannot be changed.\"", "\n", "blocks", "=", "block_class", "(", "in_channels", "=", "in_channels", ",", "channel_cfg", "=", "channel_cfg", ",", "**", "kwargs", ")", "\n", "return", "blocks", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.build_vgg_backbone": [[166, 207], ["build.BACKBONE_REGISTRY.register", "max", "enumerate", "vgg.VGG.freeze", "range", "vgg.VGG.make_stage", "stages.append", "enumerate", "vgg.VGG"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.freeze", "home.repos.pwc.inspect_result.feobi1999_tdd.backbone.vgg.VGG.make_stage"], ["", "", "@", "BACKBONE_REGISTRY", ".", "register", "(", ")", "\n", "def", "build_vgg_backbone", "(", "cfg", ",", "input_shape", ")", ":", "\n", "# fmt: off", "\n", "    ", "depth", "=", "cfg", ".", "MODEL", ".", "VGG", ".", "DEPTH", "\n", "freeze_at", "=", "cfg", ".", "MODEL", ".", "BACKBONE", ".", "FREEZE_AT", "\n", "norm", "=", "cfg", ".", "MODEL", ".", "VGG", ".", "NORM", "\n", "out_features", "=", "cfg", ".", "MODEL", ".", "VGG", ".", "OUT_FEATURES", "\n", "in_channels", "=", "input_shape", ".", "channels", "\n", "# fmt: on", "\n", "\n", "stages", "=", "[", "]", "\n", "out_stage_idx", "=", "[", "\n", "{", "\"vgg_block1\"", ":", "1", ",", "\"vgg_block2\"", ":", "2", ",", "\"vgg_block3\"", ":", "3", ",", "\"vgg_block4\"", ":", "4", ",", "\"vgg_block5\"", ":", "5", "}", "[", "f", "]", "\n", "for", "f", "in", "out_features", "\n", "]", "\n", "max_stage_idx", "=", "max", "(", "out_stage_idx", ")", "\n", "stage_inds", "=", "[", "i", "for", "i", ",", "x", "in", "enumerate", "(", "cfgs", "[", "depth", "]", ")", "if", "x", "==", "\"M\"", "]", "\n", "ind", "=", "0", "\n", "\n", "for", "idx", ",", "stage_idx", "in", "enumerate", "(", "range", "(", "1", ",", "max_stage_idx", "+", "1", ")", ")", ":", "\n", "\n", "# No maxpooling in the last block", "\n", "        ", "if", "stage_idx", "==", "5", ":", "\n", "            ", "pool", "=", "False", "\n", "", "else", ":", "\n", "            ", "pool", "=", "True", "\n", "\n", "", "stage_kargs", "=", "{", "\n", "\"block_class\"", ":", "VGGBlock", ",", "\n", "\"in_channels\"", ":", "in_channels", ",", "\n", "\"channel_cfg\"", ":", "cfgs", "[", "depth", "]", "[", "ind", ":", "stage_inds", "[", "idx", "]", "]", ",", "\n", "\"norm\"", ":", "norm", ",", "\n", "\"pool\"", ":", "pool", ",", "\n", "}", "\n", "\n", "blocks", "=", "VGG", ".", "make_stage", "(", "**", "stage_kargs", ")", "\n", "out_channels", "=", "cfgs", "[", "depth", "]", "[", "ind", ":", "stage_inds", "[", "idx", "]", "]", "[", "-", "1", "]", "\n", "in_channels", "=", "out_channels", "\n", "ind", "=", "stage_inds", "[", "idx", "]", "+", "1", "\n", "stages", ".", "append", "(", "blocks", ")", "\n", "", "return", "VGG", "(", "stages", ",", "out_features", "=", "out_features", ")", ".", "freeze", "(", "freeze_at", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.checkpoint.detection_checkpoint.DetectionTSCheckpointer._load_model": [[11, 61], ["checkpoint.get", "checkpoint.get", "detection_checkpoint.DetectionTSCheckpointer._load_student_model", "dict", "checkpoint.get", "super()._load_model", "dict", "detection_checkpoint.DetectionTSCheckpointer._convert_ndarray_to_tensor", "detectron2.checkpoint.c2_model_loading.align_and_update_state_dicts", "detection_checkpoint.DetectionTSCheckpointer.model.modelStudent.named_buffers", "detection_checkpoint.DetectionTSCheckpointer._convert_ndarray_to_tensor", "detectron2.checkpoint.c2_model_loading.align_and_update_state_dicts", "detection_checkpoint.DetectionTSCheckpointer.model.named_buffers", "detection_checkpoint.DetectionTSCheckpointer.model.modelStudent.state_dict", "detection_checkpoint.DetectionTSCheckpointer.model.state_dict", "super()._load_model.missing_keys.remove", "super()._load_model.missing_keys.remove", "checkpoint.get", "checkpoint.get"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.checkpoint.detection_checkpoint.DetectionTSCheckpointer._load_student_model", "home.repos.pwc.inspect_result.feobi1999_tdd.checkpoint.detection_checkpoint.DetectionTSCheckpointer._load_model"], ["    ", "def", "_load_model", "(", "self", ",", "checkpoint", ")", ":", "\n", "        ", "if", "checkpoint", ".", "get", "(", "\"__author__\"", ",", "None", ")", "==", "\"Caffe2\"", ":", "\n", "# pretrained model weight: only update student model", "\n", "            ", "if", "checkpoint", ".", "get", "(", "\"matching_heuristics\"", ",", "False", ")", ":", "\n", "                ", "self", ".", "_convert_ndarray_to_tensor", "(", "checkpoint", "[", "\"model\"", "]", ")", "\n", "# convert weights by name-matching heuristics", "\n", "checkpoint", "[", "\"model\"", "]", "=", "align_and_update_state_dicts", "(", "\n", "self", ".", "model", ".", "modelStudent", ".", "state_dict", "(", ")", ",", "\n", "checkpoint", "[", "\"model\"", "]", ",", "\n", "c2_conversion", "=", "checkpoint", ".", "get", "(", "\"__author__\"", ",", "None", ")", "==", "\"Caffe2\"", ",", "\n", ")", "\n", "\n", "# for non-caffe2 models, use standard ways to load it", "\n", "", "incompatible", "=", "self", ".", "_load_student_model", "(", "checkpoint", ")", "\n", "\n", "model_buffers", "=", "dict", "(", "self", ".", "model", ".", "modelStudent", ".", "named_buffers", "(", "recurse", "=", "False", ")", ")", "\n", "for", "k", "in", "[", "\"pixel_mean\"", ",", "\"pixel_std\"", "]", ":", "\n", "# Ignore missing key message about pixel_mean/std.", "\n", "# Though they may be missing in old checkpoints, they will be correctly", "\n", "# initialized from config anyway.", "\n", "                ", "if", "k", "in", "model_buffers", ":", "\n", "                    ", "try", ":", "\n", "                        ", "incompatible", ".", "missing_keys", ".", "remove", "(", "k", ")", "\n", "", "except", "ValueError", ":", "\n", "                        ", "pass", "\n", "", "", "", "return", "incompatible", "\n", "\n", "", "else", ":", "# whole model", "\n", "            ", "if", "checkpoint", ".", "get", "(", "\"matching_heuristics\"", ",", "False", ")", ":", "\n", "                ", "self", ".", "_convert_ndarray_to_tensor", "(", "checkpoint", "[", "\"model\"", "]", ")", "\n", "# convert weights by name-matching heuristics", "\n", "checkpoint", "[", "\"model\"", "]", "=", "align_and_update_state_dicts", "(", "\n", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "checkpoint", "[", "\"model\"", "]", ",", "\n", "c2_conversion", "=", "checkpoint", ".", "get", "(", "\"__author__\"", ",", "None", ")", "==", "\"Caffe2\"", ",", "\n", ")", "\n", "# for non-caffe2 models, use standard ways to load it", "\n", "", "incompatible", "=", "super", "(", ")", ".", "_load_model", "(", "checkpoint", ")", "\n", "\n", "model_buffers", "=", "dict", "(", "self", ".", "model", ".", "named_buffers", "(", "recurse", "=", "False", ")", ")", "\n", "for", "k", "in", "[", "\"pixel_mean\"", ",", "\"pixel_std\"", "]", ":", "\n", "# Ignore missing key message about pixel_mean/std.", "\n", "# Though they may be missing in old checkpoints, they will be correctly", "\n", "# initialized from config anyway.", "\n", "                ", "if", "k", "in", "model_buffers", ":", "\n", "                    ", "try", ":", "\n", "                        ", "incompatible", ".", "missing_keys", ".", "remove", "(", "k", ")", "\n", "", "except", "ValueError", ":", "\n", "                        ", "pass", "\n", "", "", "", "return", "incompatible", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.checkpoint.detection_checkpoint.DetectionTSCheckpointer._load_student_model": [[62, 89], ["checkpoint.pop", "detection_checkpoint.DetectionTSCheckpointer._convert_ndarray_to_tensor", "fvcore.common.checkpoint._strip_prefix_if_present", "detection_checkpoint.DetectionTSCheckpointer.model.modelStudent.state_dict", "list", "detection_checkpoint.DetectionTSCheckpointer.model.modelStudent.load_state_dict", "fvcore.common.checkpoint._IncompatibleKeys", "checkpoint.pop.keys", "tuple", "tuple", "incorrect_shapes.append", "checkpoint.pop.pop"], "methods", ["None"], ["", "", "def", "_load_student_model", "(", "self", ",", "checkpoint", ":", "Any", ")", "->", "_IncompatibleKeys", ":", "# pyre-ignore", "\n", "        ", "checkpoint_state_dict", "=", "checkpoint", ".", "pop", "(", "\"model\"", ")", "\n", "self", ".", "_convert_ndarray_to_tensor", "(", "checkpoint_state_dict", ")", "\n", "\n", "# if the state_dict comes from a model that was wrapped in a", "\n", "# DataParallel or DistributedDataParallel during serialization,", "\n", "# remove the \"module\" prefix before performing the matching.", "\n", "_strip_prefix_if_present", "(", "checkpoint_state_dict", ",", "\"module.\"", ")", "\n", "\n", "# work around https://github.com/pytorch/pytorch/issues/24139", "\n", "model_state_dict", "=", "self", ".", "model", ".", "modelStudent", ".", "state_dict", "(", ")", "\n", "incorrect_shapes", "=", "[", "]", "\n", "for", "k", "in", "list", "(", "checkpoint_state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "k", "in", "model_state_dict", ":", "\n", "                ", "shape_model", "=", "tuple", "(", "model_state_dict", "[", "k", "]", ".", "shape", ")", "\n", "shape_checkpoint", "=", "tuple", "(", "checkpoint_state_dict", "[", "k", "]", ".", "shape", ")", "\n", "if", "shape_model", "!=", "shape_checkpoint", ":", "\n", "                    ", "incorrect_shapes", ".", "append", "(", "(", "k", ",", "shape_checkpoint", ",", "shape_model", ")", ")", "\n", "checkpoint_state_dict", ".", "pop", "(", "k", ")", "\n", "# pyre-ignore", "\n", "", "", "", "incompatible", "=", "self", ".", "model", ".", "modelStudent", ".", "load_state_dict", "(", "\n", "checkpoint_state_dict", ",", "strict", "=", "False", "\n", ")", "\n", "return", "_IncompatibleKeys", "(", "\n", "missing_keys", "=", "incompatible", ".", "missing_keys", ",", "\n", "unexpected_keys", "=", "incompatible", ".", "unexpected_keys", ",", "\n", "incorrect_shapes", "=", "incorrect_shapes", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.add_label_for_two_head": [[51, 56], ["zip"], "methods", ["None"], ["    ", "def", "add_label_for_two_head", "(", "self", ",", "unlabled_data", ",", "label_1", ",", "label_2", ")", ":", "\n", "        ", "for", "unlabel_datum", ",", "lab_inst_1", ",", "lab_inst_2", "in", "zip", "(", "unlabled_data", ",", "label_1", ",", "label_2", ")", ":", "\n", "            ", "unlabel_datum", "[", "\"instances_head_1\"", "]", "=", "lab_inst_1", "\n", "unlabel_datum", "[", "\"instances_head_2\"", "]", "=", "lab_inst_2", "\n", "", "return", "unlabled_data", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.run_step_full_semisup": [[57, 233], ["time.perf_counter", "next", "label_data_k.copy", "[].cpu().numpy", "[].cpu().numpy", "utils.FDA_source_to_target_np", "torch.Tensor().cuda", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation._write_metrics", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.optimizer.zero_grad", "sum.backward", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.optimizer.step", "time.perf_counter", "label_data_q.extend", "record_dict.keys", "sum", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.process_pseudo_label", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.process_pseudo_label", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.process_pseudo_label", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.remove_label", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.remove_label", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.add_label_for_two_head", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.model", "record_dict.update", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.model", "record_dict.update", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.model", "record_unlabeld_data_head_1.keys", "record_dict.update", "record_dict.update", "record_dict.keys", "sum", "[].cpu", "[].cpu", "torch.Tensor", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.model", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.model", "loss_dict.values", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation._update_teacher_model", "torch.no_grad", "loss_dict.values", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation._update_teacher_model", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.model_teacher", "source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.model_teacher"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.FDA_source_to_target_np", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._write_metrics", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine._NewEmptyTensorOp.backward", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.process_pseudo_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.process_pseudo_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.process_pseudo_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.remove_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.remove_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer_two_head_version2_object_relation.Two_head_fft_UBTeacherTrainer_V2_object_relation.add_label_for_two_head", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._update_teacher_model", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._update_teacher_model"], ["", "def", "run_step_full_semisup", "(", "self", ")", ":", "\n", "        ", "self", ".", "_trainer", ".", "iter", "=", "self", ".", "iter", "\n", "assert", "self", ".", "model", ".", "training", ",", "\"[UBTeacherTrainer] model was changed to eval mode!\"", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "data", "=", "next", "(", "self", ".", "_trainer", ".", "_data_loader_iter", ")", "\n", "\n", "label_data_q", ",", "label_data_k", ",", "unlabel_data_q", ",", "unlabel_data_k", "=", "data", "\n", "import", "pdb", "\n", "src_label_data_k", "=", "label_data_k", ".", "copy", "(", ")", "\n", "\n", "src_image", "=", "label_data_k", "[", "0", "]", "[", "'image'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "#[3,600,1200]", "\n", "tgt_image", "=", "unlabel_data_k", "[", "0", "]", "[", "'image'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "src_in_trg", "=", "FDA_source_to_target_np", "(", "src_image", ",", "tgt_image", ",", "L", "=", "0.1", ")", "# src_lbl", "\n", "\n", "label_data_k", "[", "0", "]", "[", "'image'", "]", "=", "torch", ".", "Tensor", "(", "src_in_trg", ")", ".", "cuda", "(", ")", "\n", "\n", "data_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "\n", "# burn-in stage (supervised training with labeled data)", "\n", "if", "self", ".", "iter", "<", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BURN_UP_STEP", ":", "\n", "\n", "\n", "# input both strong and weak supervised data into model", "\n", "            ", "label_data_q", ".", "extend", "(", "label_data_k", ")", "\n", "if", "self", ".", "cfg", ".", "CONSIST_ON", ":", "\n", "                ", "record_dict", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "label_data_q", ",", "branch", "=", "\"consist_supervised\"", ")", "\n", "\n", "", "else", ":", "\n", "                ", "record_dict", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "label_data_q", ",", "branch", "=", "\"supervised\"", ")", "\n", "\n", "\n", "\n", "# weight losses", "\n", "", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "record_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", ":", "\n", "                    ", "loss_dict", "[", "key", "]", "=", "record_dict", "[", "key", "]", "*", "1", "\n", "", "", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "iter", "==", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BURN_UP_STEP", ":", "\n", "# update copy the the whole model", "\n", "                ", "self", ".", "_update_teacher_model", "(", "keep_rate", "=", "0.00", ")", "\n", "\n", "", "elif", "(", "\n", "self", ".", "iter", "-", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BURN_UP_STEP", "\n", ")", "%", "self", ".", "cfg", ".", "SEMISUPNET", ".", "TEACHER_UPDATE_ITER", "==", "0", ":", "\n", "                ", "self", ".", "_update_teacher_model", "(", "keep_rate", "=", "self", ".", "cfg", ".", "SEMISUPNET", ".", "EMA_KEEP_RATE", ")", "\n", "\n", "", "record_dict", "=", "{", "}", "\n", "#  generate the pseudo-label using teacher model", "\n", "# note that we do not convert to eval mode, as 1) there is no gradient computed in", "\n", "# teacher model and 2) batch norm layers are not updated as well", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "if", "self", ".", "cfg", ".", "SEMISUPNET", ".", "Teacher_Refine", ":", "\n", "                    ", "(", "\n", "proposals_rpn_unsup_k", ",", "\n", "proposals_roih1_unsup_k", ",", "\n", "proposals_roih2_unsup_k", "\n", ")", "=", "self", ".", "model_teacher", "(", "unlabel_data_k", ",", "branch", "=", "\"teacher_object_relation\"", ")", "\n", "", "else", ":", "\n", "                    ", "(", "\n", "proposals_rpn_unsup_k", ",", "\n", "proposals_roih1_unsup_k", ",", "\n", "proposals_roih2_unsup_k", "\n", ")", "=", "self", ".", "model_teacher", "(", "unlabel_data_k", ",", "branch", "=", "\"unsup_data_weak_two_head\"", ")", "\n", "", "", "cache", "=", "get_local", ".", "cache", "\n", "\n", "#  Pseudo-labeling", "\n", "cur_threshold", "=", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BBOX_THRESHOLD", "\n", "\n", "\n", "joint_proposal_dict", "=", "{", "}", "\n", "joint_proposal_dict", "[", "\"proposals_rpn\"", "]", "=", "proposals_rpn_unsup_k", "\n", "\n", "(", "\n", "pesudo_proposals_rpn_unsup_k", ",", "\n", "nun_pseudo_bbox_rpn", ",", "\n", ")", "=", "self", ".", "process_pseudo_label", "(", "\n", "proposals_rpn_unsup_k", ",", "cur_threshold", ",", "\"rpn\"", ",", "\"thresholding\"", "\n", ")", "\n", "joint_proposal_dict", "[", "\"proposals_pseudo_rpn\"", "]", "=", "pesudo_proposals_rpn_unsup_k", "\n", "\n", "\n", "\n", "# Pseudo_labeling for ROI head (bbox location/objectness)", "\n", "pesudo_proposals_roih1_unsup_k", ",", "_", "=", "self", ".", "process_pseudo_label", "(", "\n", "proposals_roih1_unsup_k", ",", "cur_threshold", ",", "\"roih\"", ",", "\"thresholding\"", "\n", ")", "\n", "joint_proposal_dict", "[", "\"proposals_pseudo_roih_1\"", "]", "=", "pesudo_proposals_roih1_unsup_k", "\n", "\n", "\n", "pesudo_proposals_roih2_unsup_k", ",", "_", "=", "self", ".", "process_pseudo_label", "(", "\n", "proposals_roih2_unsup_k", ",", "cur_threshold", ",", "\"roih\"", ",", "\"thresholding\"", "\n", ")", "\n", "joint_proposal_dict", "[", "\"proposals_pseudo_roih_2\"", "]", "=", "pesudo_proposals_roih2_unsup_k", "\n", "\n", "\n", "\n", "\n", "\n", "#  add pseudo-label to unlabeled data", "\n", "unlabel_data_q", "=", "self", ".", "remove_label", "(", "unlabel_data_q", ")", "\n", "unlabel_data_k", "=", "self", ".", "remove_label", "(", "unlabel_data_k", ")", "\n", "\n", "\n", "unlabel_data_q_two_label", "=", "self", ".", "add_label_for_two_head", "(", "\n", "unlabel_data_q", ",", "joint_proposal_dict", "[", "\"proposals_pseudo_roih_1\"", "]", ",", "joint_proposal_dict", "[", "\"proposals_pseudo_roih_1\"", "]", "\n", ")", "\n", "\n", "\n", "\n", "\n", "# for src domain images", "\n", "all_label_data", "=", "label_data_q", "+", "src_label_data_k", "\n", "record_all_label_data", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "\n", "all_label_data", ",", "branch", "=", "\"supervised\"", "\n", ")", "\n", "\n", "record_dict", ".", "update", "(", "record_all_label_data", ")", "\n", "\n", "# for fft image", "\n", "record_unlabeld_data_fft_head2", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "\n", "label_data_k", ",", "branch", "=", "\"target_supervised\"", "\n", ")", "\n", "record_dict", ".", "update", "(", "record_unlabeld_data_fft_head2", ")", "\n", "\n", "\n", "new_record_all_unlabel_data", "=", "{", "}", "\n", "\n", "\n", "record_unlabeld_data_head_1", ",", "record_unlabeld_data_head_2", ",", "_", ",", "_", "=", "self", ".", "model", "(", "\n", "unlabel_data_q_two_label", ",", "branch", "=", "\"student_object_relation\"", "\n", ")", "\n", "\n", "\n", "for", "key", "in", "record_unlabeld_data_head_1", ".", "keys", "(", ")", ":", "\n", "                ", "new_record_all_unlabel_data", "[", "key", "+", "\"_pseudo\"", "]", "=", "record_unlabeld_data_head_1", "[", "\n", "key", "\n", "]", "\n", "\n", "\n", "", "record_dict", ".", "update", "(", "new_record_all_unlabel_data", ")", "\n", "record_dict", ".", "update", "(", "record_unlabeld_data_head_2", ")", "\n", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "# weight losses", "\n", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "record_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", ":", "\n", "\n", "                    ", "if", "key", "==", "\"loss_rpn_loc_pseudo\"", "or", "key", "==", "\"loss_box_reg_pseudo\"", ":", "\n", "# pseudo bbox regression <- 0", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "record_dict", "[", "key", "]", "*", "0", "\n", "", "elif", "key", "[", "-", "6", ":", "]", "==", "\"pseudo\"", ":", "# unsupervised loss", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "(", "\n", "record_dict", "[", "key", "]", "*", "self", ".", "cfg", ".", "SEMISUPNET", ".", "UNSUP_LOSS_WEIGHT", "\n", ")", "\n", "", "elif", "'consist'", "in", "key", ":", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "(", "\n", "record_dict", "[", "key", "]", "*", "0.1", "\n", ")", "\n", "", "else", ":", "# supervised loss", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "record_dict", "[", "key", "]", "*", "1", "\n", "\n", "", "", "", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "", "metrics_dict", "=", "record_dict", "\n", "metrics_dict", "[", "\"data_time\"", "]", "=", "data_time", "\n", "self", ".", "_write_metrics", "(", "metrics_dict", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "losses", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.__init__": [[48, 82], ["detectron2.engine.DefaultTrainer.auto_scale_workers", "original_trainer_two_head.BaselineTrainer.build_model", "original_trainer_two_head.BaselineTrainer.build_optimizer", "original_trainer_two_head.BaselineTrainer.build_train_loader", "detectron2.engine.TrainerBase.__init__", "original_trainer_two_head.BaselineTrainer.build_lr_scheduler", "detectron2.checkpoint.DetectionCheckpointer", "original_trainer_two_head.BaselineTrainer.register_hooks", "detectron2.get_world_size", "detectron2.get_world_size", "torch.nn.parallel.DistributedDataParallel", "original_trainer_two_head.BaselineTrainer.build_hooks", "detectron2.get_local_rank"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_optimizer", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_train_loader", "home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__", "home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_lr_scheduler", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_hooks", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_local_rank"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n        Use the custom checkpointer, which loads other backbone models\n        with matching heuristics.\n        \"\"\"", "\n", "cfg", "=", "DefaultTrainer", ".", "auto_scale_workers", "(", "cfg", ",", "comm", ".", "get_world_size", "(", ")", ")", "\n", "model", "=", "self", ".", "build_model", "(", "cfg", ")", "\n", "optimizer", "=", "self", ".", "build_optimizer", "(", "cfg", ",", "model", ")", "\n", "data_loader", "=", "self", ".", "build_train_loader", "(", "cfg", ")", "\n", "\n", "if", "comm", ".", "get_world_size", "(", ")", ">", "1", ":", "\n", "            ", "model", "=", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "comm", ".", "get_local_rank", "(", ")", "]", ",", "broadcast_buffers", "=", "False", "\n", ")", "\n", "\n", "", "TrainerBase", ".", "__init__", "(", "self", ")", "\n", "self", ".", "_trainer", "=", "(", "AMPTrainer", "if", "cfg", ".", "SOLVER", ".", "AMP", ".", "ENABLED", "else", "SimpleTrainer", ")", "(", "\n", "model", ",", "data_loader", ",", "optimizer", "\n", ")", "\n", "\n", "self", ".", "scheduler", "=", "self", ".", "build_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "self", ".", "checkpointer", "=", "DetectionCheckpointer", "(", "\n", "model", ",", "\n", "cfg", ".", "OUTPUT_DIR", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "scheduler", "=", "self", ".", "scheduler", ",", "\n", ")", "\n", "self", ".", "start_iter", "=", "0", "\n", "self", ".", "max_iter", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "self", ".", "register_hooks", "(", "self", ".", "build_hooks", "(", ")", ")", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.test": [[82, 139], ["logging.getLogger", "isinstance", "collections.OrderedDict", "enumerate", "cls.build_test_loader", "ubteacher.evaluation.evaluator.inference_on_dataset", "detectron2.is_main_process", "len", "len", "len", "len", "len", "isinstance", "logging.getLogger.info", "detectron2.evaluation.print_csv_format", "list", "cls.build_evaluator", "collections.OrderedDict.values", "logging.getLogger.warn"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_test_loader", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.inference_on_dataset", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_evaluator"], ["", "@", "classmethod", "\n", "def", "test", "(", "cls", ",", "cfg", ",", "model", ",", "evaluators", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n            model (nn.Module):\n            evaluators (list[DatasetEvaluator] or None): if None, will call\n                :meth:`build_evaluator`. Otherwise, must have the same length as\n                ``cfg.DATASETS.TEST``.\n\n        Returns:\n            dict: a dict of result metrics\n        \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "if", "isinstance", "(", "evaluators", ",", "DatasetEvaluator", ")", ":", "\n", "            ", "evaluators", "=", "[", "evaluators", "]", "\n", "", "if", "evaluators", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", "==", "len", "(", "evaluators", ")", ",", "\"{} != {}\"", ".", "format", "(", "\n", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", ",", "len", "(", "evaluators", ")", "\n", ")", "\n", "\n", "", "results", "=", "OrderedDict", "(", ")", "\n", "for", "idx", ",", "dataset_name", "in", "enumerate", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", ":", "\n", "            ", "data_loader", "=", "cls", ".", "build_test_loader", "(", "cfg", ",", "dataset_name", ")", "\n", "# When evaluators are passed in as arguments,", "\n", "# implicitly assume that evaluators can be created before data_loader.", "\n", "if", "evaluators", "is", "not", "None", ":", "\n", "                ", "evaluator", "=", "evaluators", "[", "idx", "]", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "evaluator", "=", "cls", ".", "build_evaluator", "(", "cfg", ",", "dataset_name", ")", "\n", "", "except", "NotImplementedError", ":", "\n", "                    ", "logger", ".", "warn", "(", "\n", "\"No evaluator found. Use `DefaultTrainer.test(evaluators=)`, \"", "\n", "\"or implement its `build_evaluator` method.\"", "\n", ")", "\n", "results", "[", "dataset_name", "]", "=", "{", "}", "\n", "continue", "\n", "# results_i,feature_to_save, pred_cls,pred_score = inference_on_dataset(model, data_loader, evaluator)", "\n", "", "", "results_i", ",", "feature_to_save", ",", "pred_cls", ",", "pred_score", ",", "img_feature", "=", "inference_on_dataset", "(", "model", ",", "data_loader", ",", "evaluator", ")", "\n", "import", "pdb", "\n", "# pdb.set_trace()", "\n", "results", "[", "dataset_name", "]", "=", "results_i", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "                ", "assert", "isinstance", "(", "\n", "results_i", ",", "dict", "\n", ")", ",", "\"Evaluator must return a dict on the main process. Got {} instead.\"", ".", "format", "(", "\n", "results_i", "\n", ")", "\n", "logger", ".", "info", "(", "\"Evaluation results for {} in csv format:\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "print_csv_format", "(", "results_i", ")", "\n", "\n", "", "", "if", "len", "(", "results", ")", "==", "1", ":", "\n", "            ", "results", "=", "list", "(", "results", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "\n", "\n", "", "return", "results", "\n", "", "def", "train_loop", "(", "self", ",", "start_iter", ":", "int", ",", "max_iter", ":", "int", ")", ":", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.train_loop": [[139, 162], ["logging.getLogger", "logging.getLogger.info", "detectron2.utils.events.EventStorage", "original_trainer_two_head.BaselineTrainer.before_train", "range", "original_trainer_two_head.BaselineTrainer.after_train", "original_trainer_two_head.BaselineTrainer.before_step", "original_trainer_two_head.BaselineTrainer.run_step", "original_trainer_two_head.BaselineTrainer.after_step", "logging.getLogger.exception"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.BaselineTrainer.run_step", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook.after_step"], ["", "def", "train_loop", "(", "self", ",", "start_iter", ":", "int", ",", "max_iter", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            start_iter, max_iter (int): See docs above\n        \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Starting training from iteration {}\"", ".", "format", "(", "start_iter", ")", ")", "\n", "\n", "self", ".", "iter", "=", "self", ".", "start_iter", "=", "start_iter", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "\n", "with", "EventStorage", "(", "start_iter", ")", "as", "self", ".", "storage", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "before_train", "(", ")", "\n", "for", "self", ".", "iter", "in", "range", "(", "start_iter", ",", "max_iter", ")", ":", "\n", "                    ", "self", ".", "before_step", "(", ")", "\n", "self", ".", "run_step", "(", ")", "\n", "self", ".", "after_step", "(", ")", "\n", "", "", "except", "Exception", ":", "\n", "                ", "logger", ".", "exception", "(", "\"Exception during training:\"", ")", "\n", "raise", "\n", "", "finally", ":", "\n", "                ", "self", ".", "after_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.run_step": [[163, 194], ["time.perf_counter", "next", "original_trainer_two_head.BaselineTrainer.model", "record_dict.keys", "sum", "original_trainer_two_head.BaselineTrainer._write_metrics", "original_trainer_two_head.BaselineTrainer.optimizer.zero_grad", "sum.backward", "original_trainer_two_head.BaselineTrainer.optimizer.step", "time.perf_counter", "len", "len", "loss_dict.values"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._write_metrics", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine._NewEmptyTensorOp.backward", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.step"], ["", "", "", "def", "run_step", "(", "self", ")", ":", "\n", "        ", "self", ".", "_trainer", ".", "iter", "=", "self", ".", "iter", "\n", "\n", "assert", "self", ".", "model", ".", "training", ",", "\"[SimpleTrainer] model was changed to eval mode!\"", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "data", "=", "next", "(", "self", ".", "_trainer", ".", "_data_loader_iter", ")", "\n", "data_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "\n", "record_dict", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "data", ",", "branch", "=", "\"supervised\"", ")", "\n", "\n", "num_gt_bbox", "=", "0.0", "\n", "for", "element", "in", "data", ":", "\n", "            ", "num_gt_bbox", "+=", "len", "(", "element", "[", "\"instances\"", "]", ")", "\n", "", "num_gt_bbox", "=", "num_gt_bbox", "/", "len", "(", "data", ")", "\n", "record_dict", "[", "\"bbox_num/gt_bboxes\"", "]", "=", "num_gt_bbox", "\n", "\n", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "record_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", "and", "key", "[", "-", "3", ":", "]", "!=", "\"val\"", ":", "\n", "                ", "loss_dict", "[", "key", "]", "=", "record_dict", "[", "key", "]", "\n", "\n", "", "", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "metrics_dict", "=", "record_dict", "\n", "metrics_dict", "[", "\"data_time\"", "]", "=", "data_time", "\n", "self", ".", "_write_metrics", "(", "metrics_dict", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "losses", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.build_evaluator": [[195, 200], ["ubteacher.evaluation.coco_evaluation.COCOEvaluator", "os.path.join"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_evaluator", "(", "cls", ",", "cfg", ",", "dataset_name", ",", "output_folder", "=", "None", ")", ":", "\n", "        ", "if", "output_folder", "is", "None", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ")", "\n", "", "return", "COCOEvaluator", "(", "dataset_name", ",", "cfg", ",", "True", ",", "output_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.build_train_loader": [[201, 204], ["ubteacher.data.build.build_detection_semisup_train_loader"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_semisup_train_loader"], ["", "@", "classmethod", "\n", "def", "build_train_loader", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "return", "build_detection_semisup_train_loader", "(", "cfg", ",", "mapper", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.build_test_loader": [[206, 210], ["ubteacher.data.build.build_detection_test_loader"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_test_loader"], ["", "@", "classmethod", "\n", "def", "build_test_loader", "(", "cls", ",", "cfg", ",", "dataset_name", ")", ":", "\n", "# mapper = DatasetMapper_gt_test(cfg, False)", "\n", "        ", "return", "build_detection_test_loader", "(", "cfg", ",", "dataset_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.build_hooks": [[211, 252], ["original_trainer_two_head.BaselineTrainer.cfg.clone", "original_trainer_two_head.BaselineTrainer.defrost", "detectron2.is_main_process", "ret.append", "detectron2.is_main_process", "detectron2.engine.hooks.IterationTimer", "detectron2.engine.hooks.LRScheduler", "ret.append", "original_trainer_two_head.BaselineTrainer.test", "detectron2.engine.hooks.EvalHook", "ret.append", "detectron2.engine.hooks.PreciseBN", "detectron2.engine.hooks.PeriodicCheckpointer", "detectron2.engine.hooks.PeriodicWriter", "fvcore.nn.precise_bn.get_bn_modules", "original_trainer_two_head.BaselineTrainer.build_train_loader", "original_trainer_two_head.BaselineTrainer.build_writers"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.test", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_train_loader"], ["", "def", "build_hooks", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Build a list of default hooks, including timing, evaluation,\n        checkpointing, lr scheduling, precise BN, writing events.\n\n        Returns:\n            list[HookBase]:\n        \"\"\"", "\n", "cfg", "=", "self", ".", "cfg", ".", "clone", "(", ")", "\n", "cfg", ".", "defrost", "(", ")", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "\n", "\n", "ret", "=", "[", "\n", "hooks", ".", "IterationTimer", "(", ")", ",", "\n", "hooks", ".", "LRScheduler", "(", "self", ".", "optimizer", ",", "self", ".", "scheduler", ")", ",", "\n", "hooks", ".", "PreciseBN", "(", "\n", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "\n", "self", ".", "model", ",", "\n", "self", ".", "build_train_loader", "(", "cfg", ")", ",", "\n", "cfg", ".", "TEST", ".", "PRECISE_BN", ".", "NUM_ITER", ",", "\n", ")", "\n", "if", "cfg", ".", "TEST", ".", "PRECISE_BN", ".", "ENABLED", "and", "get_bn_modules", "(", "self", ".", "model", ")", "\n", "else", "None", ",", "\n", "]", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "ret", ".", "append", "(", "\n", "hooks", ".", "PeriodicCheckpointer", "(", "\n", "self", ".", "checkpointer", ",", "cfg", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", "\n", ")", "\n", ")", "\n", "\n", "", "def", "test_and_save_results", "(", ")", ":", "\n", "            ", "self", ".", "_last_eval_results", "=", "self", ".", "test", "(", "self", ".", "cfg", ",", "self", ".", "model", ")", "\n", "return", "self", ".", "_last_eval_results", "\n", "\n", "", "ret", ".", "append", "(", "hooks", ".", "EvalHook", "(", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "test_and_save_results", ")", ")", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "ret", ".", "append", "(", "hooks", ".", "PeriodicWriter", "(", "self", ".", "build_writers", "(", ")", ",", "period", "=", "20", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer._write_metrics": [[253, 287], ["detectron2.gather", "detectron2.is_main_process", "metrics_dict.keys", "sum", "original_trainer_two_head.BaselineTrainer.storage.put_scalar", "isinstance", "v.detach().cpu().item", "float", "metrics_dict.items", "numpy.max", "original_trainer_two_head.BaselineTrainer.storage.put_scalar", "numpy.mean", "len", "original_trainer_two_head.BaselineTrainer.storage.put_scalars", "all_metrics_dict[].keys", "v.detach().cpu", "x.pop", "loss_dict.values", "v.detach"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.gather", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalars"], ["", "def", "_write_metrics", "(", "self", ",", "metrics_dict", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            metrics_dict (dict): dict of scalar metrics\n        \"\"\"", "\n", "metrics_dict", "=", "{", "\n", "k", ":", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "else", "float", "(", "v", ")", "\n", "for", "k", ",", "v", "in", "metrics_dict", ".", "items", "(", ")", "\n", "}", "\n", "# gather metrics among all workers for logging", "\n", "# This assumes we do DDP-style training, which is currently the only", "\n", "# supported method in detectron2.", "\n", "all_metrics_dict", "=", "comm", ".", "gather", "(", "metrics_dict", ")", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "if", "\"data_time\"", "in", "all_metrics_dict", "[", "0", "]", ":", "\n", "                ", "data_time", "=", "np", ".", "max", "(", "[", "x", ".", "pop", "(", "\"data_time\"", ")", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "self", ".", "storage", ".", "put_scalar", "(", "\"data_time\"", ",", "data_time", ")", "\n", "\n", "", "metrics_dict", "=", "{", "\n", "k", ":", "np", ".", "mean", "(", "[", "x", "[", "k", "]", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "for", "k", "in", "all_metrics_dict", "[", "0", "]", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "metrics_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", ":", "\n", "                    ", "loss_dict", "[", "key", "]", "=", "metrics_dict", "[", "key", "]", "\n", "\n", "", "", "total_losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "self", ".", "storage", ".", "put_scalar", "(", "\"total_loss\"", ",", "total_losses_reduced", ")", "\n", "if", "len", "(", "metrics_dict", ")", ">", "1", ":", "\n", "                ", "self", ".", "storage", ".", "put_scalars", "(", "**", "metrics_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.__init__": [[291, 339], ["detectron2.engine.DefaultTrainer.auto_scale_workers", "original_trainer_two_head.Two_Head_UBTeacherTrainer.build_train_loader", "original_trainer_two_head.Two_Head_UBTeacherTrainer.build_model", "original_trainer_two_head.Two_Head_UBTeacherTrainer.build_optimizer", "original_trainer_two_head.Two_Head_UBTeacherTrainer.build_model", "detectron2.engine.TrainerBase.__init__", "original_trainer_two_head.Two_Head_UBTeacherTrainer.build_lr_scheduler", "ubteacher.modeling.meta_arch.ts_ensemble.EnsembleTSModel", "ubteacher.checkpoint.detection_checkpoint.DetectionTSCheckpointer", "original_trainer_two_head.Two_Head_UBTeacherTrainer.register_hooks", "detectron2.get_world_size", "detectron2.get_world_size", "torch.nn.parallel.DistributedDataParallel", "original_trainer_two_head.Two_Head_UBTeacherTrainer.build_hooks", "detectron2.get_local_rank"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_train_loader", "home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_optimizer", "home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__", "home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_lr_scheduler", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_hooks", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_local_rank"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n        Use the custom checkpointer, which loads other backbone models\n        with matching heuristics.\n        \"\"\"", "\n", "cfg", "=", "DefaultTrainer", ".", "auto_scale_workers", "(", "cfg", ",", "comm", ".", "get_world_size", "(", ")", ")", "\n", "data_loader", "=", "self", ".", "build_train_loader", "(", "cfg", ")", "\n", "\n", "# create an student model", "\n", "model", "=", "self", ".", "build_model", "(", "cfg", ")", "\n", "optimizer", "=", "self", ".", "build_optimizer", "(", "cfg", ",", "model", ")", "\n", "\n", "# create an teacher model", "\n", "model_teacher", "=", "self", ".", "build_model", "(", "cfg", ")", "\n", "self", ".", "model_teacher", "=", "model_teacher", "\n", "\n", "#load", "\n", "\n", "#copyOrNot", "\n", "\n", "# For training, wrap with DDP. But don't need this for inference.", "\n", "if", "comm", ".", "get_world_size", "(", ")", ">", "1", ":", "\n", "            ", "model", "=", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "comm", ".", "get_local_rank", "(", ")", "]", ",", "broadcast_buffers", "=", "False", "\n", ")", "\n", "\n", "", "TrainerBase", ".", "__init__", "(", "self", ")", "\n", "self", ".", "_trainer", "=", "(", "AMPTrainer", "if", "cfg", ".", "SOLVER", ".", "AMP", ".", "ENABLED", "else", "SimpleTrainer", ")", "(", "\n", "model", ",", "data_loader", ",", "optimizer", "\n", ")", "\n", "self", ".", "scheduler", "=", "self", ".", "build_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "# Ensemble teacher and student model is for model saving and loading", "\n", "ensem_ts_model", "=", "EnsembleTSModel", "(", "model_teacher", ",", "model", ")", "\n", "\n", "self", ".", "checkpointer", "=", "DetectionTSCheckpointer", "(", "\n", "ensem_ts_model", ",", "\n", "cfg", ".", "OUTPUT_DIR", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "scheduler", "=", "self", ".", "scheduler", ",", "\n", ")", "\n", "self", ".", "start_iter", "=", "0", "\n", "self", ".", "max_iter", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", "\n", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "head", "=", "0", "\n", "self", ".", "register_hooks", "(", "self", ".", "build_hooks", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.build_evaluator": [[340, 356], ["os.path.join", "os.path.join", "os.path.join", "ubteacher.evaluation.coco_evaluation.COCOEvaluator", "ValueError"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_evaluator", "(", "cls", ",", "cfg", ",", "dataset_name", ",", "output_folder", "=", "None", ")", ":", "\n", "\n", "\n", "        ", "if", "output_folder", "is", "not", "None", ":", "\n", "# else:", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "output_folder", ")", "\n", "output_folder", "=", "os", ".", "path", ".", "join", "(", "output_folder", ",", "\"inference\"", ")", "\n", "", "else", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ")", "\n", "\n", "\n", "", "if", "cfg", ".", "TEST", ".", "EVALUATOR", "==", "\"COCOeval\"", ":", "\n", "            ", "return", "COCOEvaluator", "(", "dataset_name", ",", "cfg", ",", "True", ",", "output_folder", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown test evaluator.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.build_train_loader": [[357, 361], ["ubteacher.data.dataset_mapper.DatasetMapperTwoCropSeparate", "ubteacher.data.build.build_detection_semisup_train_loader_two_crops"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_semisup_train_loader_two_crops"], ["", "", "@", "classmethod", "\n", "def", "build_train_loader", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "mapper", "=", "DatasetMapperTwoCropSeparate", "(", "cfg", ",", "True", ")", "\n", "return", "build_detection_semisup_train_loader_two_crops", "(", "cfg", ",", "mapper", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.build_lr_scheduler": [[362, 365], ["ubteacher.solver.build.build_lr_scheduler"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_lr_scheduler"], ["", "@", "classmethod", "\n", "def", "build_lr_scheduler", "(", "cls", ",", "cfg", ",", "optimizer", ")", ":", "\n", "        ", "return", "build_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.train": [[366, 371], ["original_trainer_two_head.Two_Head_UBTeacherTrainer.train_loop", "hasattr", "detectron2.is_main_process", "detectron2.evaluation.verify_results"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.train_loop", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "train_loop", "(", "self", ".", "start_iter", ",", "self", ".", "max_iter", ")", "\n", "if", "hasattr", "(", "self", ",", "\"_last_eval_results\"", ")", "and", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "verify_results", "(", "self", ".", "cfg", ",", "self", ".", "_last_eval_results", ")", "\n", "return", "self", ".", "_last_eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.train_loop": [[372, 392], ["logging.getLogger", "logging.getLogger.info", "detectron2.utils.events.EventStorage", "original_trainer_two_head.Two_Head_UBTeacherTrainer.before_train", "range", "original_trainer_two_head.Two_Head_UBTeacherTrainer.after_train", "original_trainer_two_head.Two_Head_UBTeacherTrainer.before_step", "original_trainer_two_head.Two_Head_UBTeacherTrainer.run_step_full_semisup", "original_trainer_two_head.Two_Head_UBTeacherTrainer.after_step", "logging.getLogger.exception"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.run_step_full_semisup", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook.after_step"], ["", "", "def", "train_loop", "(", "self", ",", "start_iter", ":", "int", ",", "max_iter", ":", "int", ")", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Starting training from iteration {}\"", ".", "format", "(", "start_iter", ")", ")", "\n", "\n", "self", ".", "iter", "=", "self", ".", "start_iter", "=", "start_iter", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "\n", "with", "EventStorage", "(", "start_iter", ")", "as", "self", ".", "storage", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "before_train", "(", ")", "\n", "\n", "for", "self", ".", "iter", "in", "range", "(", "start_iter", ",", "max_iter", ")", ":", "\n", "                    ", "self", ".", "before_step", "(", ")", "\n", "self", ".", "run_step_full_semisup", "(", ")", "\n", "self", ".", "after_step", "(", ")", "\n", "", "", "except", "Exception", ":", "\n", "                ", "logger", ".", "exception", "(", "\"Exception during training:\"", ")", "\n", "raise", "\n", "", "finally", ":", "\n", "                ", "self", ".", "after_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.threshold_bbox": [[396, 430], ["detectron2.structures.instances.Instances", "detectron2.structures.boxes.Boxes", "detectron2.structures.instances.Instances", "detectron2.structures.boxes.Boxes"], "methods", ["None"], ["", "", "", "def", "threshold_bbox", "(", "self", ",", "proposal_bbox_inst", ",", "thres", "=", "0.7", ",", "proposal_type", "=", "\"roih\"", ")", ":", "\n", "        ", "if", "proposal_type", "==", "\"rpn\"", ":", "\n", "            ", "valid_map", "=", "proposal_bbox_inst", ".", "objectness_logits", ">", "thres", "\n", "\n", "# create instances containing boxes and gt_classes", "\n", "image_shape", "=", "proposal_bbox_inst", ".", "image_size", "\n", "new_proposal_inst", "=", "Instances", "(", "image_shape", ")", "\n", "\n", "# create box", "\n", "new_bbox_loc", "=", "proposal_bbox_inst", ".", "proposal_boxes", ".", "tensor", "[", "valid_map", ",", ":", "]", "\n", "new_boxes", "=", "Boxes", "(", "new_bbox_loc", ")", "\n", "\n", "# add boxes to instances", "\n", "new_proposal_inst", ".", "gt_boxes", "=", "new_boxes", "\n", "new_proposal_inst", ".", "objectness_logits", "=", "proposal_bbox_inst", ".", "objectness_logits", "[", "\n", "valid_map", "\n", "]", "\n", "", "elif", "proposal_type", "==", "\"roih\"", ":", "\n", "            ", "valid_map", "=", "proposal_bbox_inst", ".", "scores", ">", "thres", "\n", "\n", "# create instances containing boxes and gt_classes", "\n", "image_shape", "=", "proposal_bbox_inst", ".", "image_size", "\n", "new_proposal_inst", "=", "Instances", "(", "image_shape", ")", "\n", "\n", "# create box", "\n", "new_bbox_loc", "=", "proposal_bbox_inst", ".", "pred_boxes", ".", "tensor", "[", "valid_map", ",", ":", "]", "\n", "new_boxes", "=", "Boxes", "(", "new_bbox_loc", ")", "\n", "\n", "# add boxes to instances", "\n", "new_proposal_inst", ".", "gt_boxes", "=", "new_boxes", "\n", "new_proposal_inst", ".", "gt_classes", "=", "proposal_bbox_inst", ".", "pred_classes", "[", "valid_map", "]", "\n", "new_proposal_inst", ".", "scores", "=", "proposal_bbox_inst", ".", "scores", "[", "valid_map", "]", "\n", "\n", "", "return", "new_proposal_inst", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.process_pseudo_label": [[431, 448], ["len", "list_instances.append", "len", "original_trainer_two_head.Two_Head_UBTeacherTrainer.threshold_bbox", "ValueError"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.threshold_bbox"], ["", "def", "process_pseudo_label", "(", "\n", "self", ",", "proposals_rpn_unsup_k", ",", "cur_threshold", ",", "proposal_type", ",", "psedo_label_method", "=", "\"\"", "\n", ")", ":", "\n", "        ", "list_instances", "=", "[", "]", "\n", "num_proposal_output", "=", "0.0", "\n", "for", "proposal_bbox_inst", "in", "proposals_rpn_unsup_k", ":", "\n", "# thresholding", "\n", "            ", "if", "psedo_label_method", "==", "\"thresholding\"", ":", "\n", "                ", "proposal_bbox_inst", "=", "self", ".", "threshold_bbox", "(", "\n", "proposal_bbox_inst", ",", "thres", "=", "cur_threshold", ",", "proposal_type", "=", "proposal_type", "\n", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unkown pseudo label boxes methods\"", ")", "\n", "", "num_proposal_output", "+=", "len", "(", "proposal_bbox_inst", ")", "\n", "list_instances", ".", "append", "(", "proposal_bbox_inst", ")", "\n", "", "num_proposal_output", "=", "num_proposal_output", "/", "len", "(", "proposals_rpn_unsup_k", ")", "\n", "return", "list_instances", ",", "num_proposal_output", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.remove_label": [[449, 454], ["label_datum.keys"], "methods", ["None"], ["", "def", "remove_label", "(", "self", ",", "label_data", ")", ":", "\n", "        ", "for", "label_datum", "in", "label_data", ":", "\n", "            ", "if", "\"instances\"", "in", "label_datum", ".", "keys", "(", ")", ":", "\n", "                ", "del", "label_datum", "[", "\"instances\"", "]", "\n", "", "", "return", "label_data", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.add_label": [[455, 459], ["zip"], "methods", ["None"], ["", "def", "add_label", "(", "self", ",", "unlabled_data", ",", "label", ")", ":", "\n", "        ", "for", "unlabel_datum", ",", "lab_inst", "in", "zip", "(", "unlabled_data", ",", "label", ")", ":", "\n", "            ", "unlabel_datum", "[", "\"instances\"", "]", "=", "lab_inst", "\n", "", "return", "unlabled_data", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.run_step_full_semisup": [[464, 622], ["time.perf_counter", "next", "original_trainer_two_head.Two_Head_UBTeacherTrainer._write_metrics", "original_trainer_two_head.Two_Head_UBTeacherTrainer.optimizer.zero_grad", "sum.backward", "original_trainer_two_head.Two_Head_UBTeacherTrainer.optimizer.step", "time.perf_counter", "label_data_q.extend", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model", "record_dict.keys", "sum", "original_trainer_two_head.Two_Head_UBTeacherTrainer.process_pseudo_label", "original_trainer_two_head.Two_Head_UBTeacherTrainer.process_pseudo_label", "original_trainer_two_head.Two_Head_UBTeacherTrainer.process_pseudo_label", "original_trainer_two_head.Two_Head_UBTeacherTrainer.remove_label", "original_trainer_two_head.Two_Head_UBTeacherTrainer.remove_label", "original_trainer_two_head.Two_Head_UBTeacherTrainer.add_label", "original_trainer_two_head.Two_Head_UBTeacherTrainer.add_label", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model", "record_dict.update", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model", "record_unlabeld_data_head_1.keys", "record_unlabeld_data_head_2.keys", "record_dict.update", "record_dict.keys", "sum", "loss_dict.values", "original_trainer_two_head.Two_Head_UBTeacherTrainer._update_teacher_model", "torch.no_grad", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model_teacher", "loss_dict.values", "original_trainer_two_head.Two_Head_UBTeacherTrainer._update_teacher_model"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._write_metrics", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine._NewEmptyTensorOp.backward", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.process_pseudo_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.process_pseudo_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.process_pseudo_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.remove_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.remove_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.add_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.add_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._update_teacher_model", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._update_teacher_model"], ["", "def", "run_step_full_semisup", "(", "self", ")", ":", "\n", "        ", "self", ".", "_trainer", ".", "iter", "=", "self", ".", "iter", "\n", "assert", "self", ".", "model", ".", "training", ",", "\"[UBTeacherTrainer] model was changed to eval mode!\"", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "data", "=", "next", "(", "self", ".", "_trainer", ".", "_data_loader_iter", ")", "\n", "# data_q and data_k from different augmentations (q:strong, k:weak)", "\n", "# label_strong, label_weak, unlabed_strong, unlabled_weak", "\n", "label_data_q", ",", "label_data_k", ",", "unlabel_data_q", ",", "unlabel_data_k", "=", "data", "\n", "\n", "\n", "data_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "\n", "# burn-in stage (supervised training with labeled data)", "\n", "if", "self", ".", "iter", "<", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BURN_UP_STEP", ":", "\n", "\n", "# input both strong and weak supervised data into model", "\n", "            ", "label_data_q", ".", "extend", "(", "label_data_k", ")", "\n", "record_dict", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "label_data_q", ",", "branch", "=", "\"supervised\"", ")", "\n", "\n", "\n", "# weight losses", "\n", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "record_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", ":", "\n", "                    ", "loss_dict", "[", "key", "]", "=", "record_dict", "[", "key", "]", "*", "1", "\n", "", "", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "iter", "==", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BURN_UP_STEP", ":", "\n", "# update copy the the whole model", "\n", "                ", "self", ".", "_update_teacher_model", "(", "keep_rate", "=", "0.00", ")", "\n", "\n", "", "elif", "(", "\n", "self", ".", "iter", "-", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BURN_UP_STEP", "\n", ")", "%", "self", ".", "cfg", ".", "SEMISUPNET", ".", "TEACHER_UPDATE_ITER", "==", "0", ":", "\n", "                ", "self", ".", "_update_teacher_model", "(", "keep_rate", "=", "self", ".", "cfg", ".", "SEMISUPNET", ".", "EMA_KEEP_RATE", ")", "\n", "\n", "", "record_dict", "=", "{", "}", "\n", "#  generate the pseudo-label using teacher model", "\n", "# note that we do not convert to eval mode, as 1) there is no gradient computed in", "\n", "# teacher model and 2) batch norm layers are not updated as well", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "(", "\n", "proposals_rpn_unsup_k", ",", "\n", "proposals_roih1_unsup_k", ",", "\n", "proposals_roih2_unsup_k", "\n", ")", "=", "self", ".", "model_teacher", "(", "unlabel_data_k", ",", "branch", "=", "\"unsup_data_weak_two_head\"", ")", "\n", "\n", "#  Pseudo-labeling", "\n", "", "cur_threshold", "=", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BBOX_THRESHOLD", "\n", "\n", "joint_proposal_dict", "=", "{", "}", "\n", "joint_proposal_dict", "[", "\"proposals_rpn\"", "]", "=", "proposals_rpn_unsup_k", "\n", "\n", "(", "\n", "pesudo_proposals_rpn_unsup_k", ",", "\n", "nun_pseudo_bbox_rpn", ",", "\n", ")", "=", "self", ".", "process_pseudo_label", "(", "\n", "proposals_rpn_unsup_k", ",", "cur_threshold", ",", "\"rpn\"", ",", "\"thresholding\"", "\n", ")", "\n", "joint_proposal_dict", "[", "\"proposals_pseudo_rpn\"", "]", "=", "pesudo_proposals_rpn_unsup_k", "\n", "\n", "\n", "# Pseudo_labeling for ROI head (bbox location/objectness)", "\n", "pesudo_proposals_roih1_unsup_k", ",", "_", "=", "self", ".", "process_pseudo_label", "(", "\n", "proposals_roih1_unsup_k", ",", "cur_threshold", ",", "\"roih\"", ",", "\"thresholding\"", "\n", ")", "\n", "joint_proposal_dict", "[", "\"proposals_pseudo_roih_1\"", "]", "=", "pesudo_proposals_roih1_unsup_k", "\n", "\n", "\n", "pesudo_proposals_roih2_unsup_k", ",", "_", "=", "self", ".", "process_pseudo_label", "(", "\n", "proposals_roih2_unsup_k", ",", "cur_threshold", ",", "\"roih\"", ",", "\"thresholding\"", "\n", ")", "\n", "joint_proposal_dict", "[", "\"proposals_pseudo_roih_2\"", "]", "=", "pesudo_proposals_roih2_unsup_k", "\n", "\n", "\n", "\n", "\n", "\n", "#  add pseudo-label to unlabeled data", "\n", "unlabel_data_q", "=", "self", ".", "remove_label", "(", "unlabel_data_q", ")", "\n", "unlabel_data_k", "=", "self", ".", "remove_label", "(", "unlabel_data_k", ")", "\n", "\n", "unlabel_data_q_1", "=", "self", ".", "add_label", "(", "\n", "unlabel_data_q", ",", "joint_proposal_dict", "[", "\"proposals_pseudo_roih_1\"", "]", "\n", ")", "\n", "\n", "unlabel_data_q_2", "=", "self", ".", "add_label", "(", "\n", "unlabel_data_q", ",", "joint_proposal_dict", "[", "\"proposals_pseudo_roih_2\"", "]", "\n", ")", "\n", "\n", "\n", "#", "\n", "# unlabel_data_k = self.add_label(", "\n", "#     unlabel_data_k, joint_proposal_dict[\"proposals_pseudo_roih\"]", "\n", "# )", "\n", "\n", "all_label_data", "=", "label_data_q", "+", "label_data_k", "\n", "# all_unlabel_data_1 = unlabel_data_q_1", "\n", "\n", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "record_all_label_data", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "\n", "all_label_data", ",", "branch", "=", "\"supervised\"", "\n", ")", "\n", "\n", "\n", "record_dict", ".", "update", "(", "record_all_label_data", ")", "\n", "\n", "\n", "record_unlabeld_data_head_1", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "\n", "unlabel_data_q_1", ",", "branch", "=", "\"supervised\"", "\n", ")", "\n", "\n", "record_unlabeld_data_head_2", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "\n", "unlabel_data_q_2", ",", "branch", "=", "\"target_supervised\"", "\n", ")", "\n", "\n", "\n", "new_record_all_unlabel_data", "=", "{", "}", "\n", "for", "key", "in", "record_unlabeld_data_head_1", ".", "keys", "(", ")", ":", "\n", "                ", "new_record_all_unlabel_data", "[", "key", "+", "\"_pseudo\"", "]", "=", "record_unlabeld_data_head_1", "[", "\n", "key", "\n", "]", "\n", "\n", "", "for", "key", "in", "record_unlabeld_data_head_2", ".", "keys", "(", ")", ":", "\n", "                ", "new_record_all_unlabel_data", "[", "key", "+", "\"_pseudo_2\"", "]", "=", "record_unlabeld_data_head_2", "[", "\n", "key", "\n", "]", "\n", "\n", "", "record_dict", ".", "update", "(", "new_record_all_unlabel_data", ")", "\n", "\n", "import", "pdb", "\n", "# pdb.set_trace()", "\n", "# weight losses", "\n", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "record_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", ":", "\n", "                    ", "if", "key", "==", "\"loss_rpn_loc_pseudo\"", "or", "key", "==", "\"loss_box_reg_pseudo\"", ":", "\n", "# pseudo bbox regression <- 0", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "record_dict", "[", "key", "]", "*", "0", "\n", "", "elif", "key", "[", "-", "6", ":", "]", "==", "\"pseudo\"", ":", "# unsupervised loss", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "(", "\n", "record_dict", "[", "key", "]", "*", "self", ".", "cfg", ".", "SEMISUPNET", ".", "UNSUP_LOSS_WEIGHT", "\n", ")", "\n", "", "else", ":", "# supervised loss", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "record_dict", "[", "key", "]", "*", "1", "\n", "\n", "", "", "", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "", "metrics_dict", "=", "record_dict", "\n", "metrics_dict", "[", "\"data_time\"", "]", "=", "data_time", "\n", "self", ".", "_write_metrics", "(", "metrics_dict", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "losses", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer._write_metrics": [[623, 659], ["detectron2.gather", "detectron2.is_main_process", "metrics_dict.keys", "sum", "original_trainer_two_head.Two_Head_UBTeacherTrainer.storage.put_scalar", "isinstance", "v.detach().cpu().item", "float", "metrics_dict.items", "numpy.max", "original_trainer_two_head.Two_Head_UBTeacherTrainer.storage.put_scalar", "numpy.mean", "len", "original_trainer_two_head.Two_Head_UBTeacherTrainer.storage.put_scalars", "all_metrics_dict[].keys", "v.detach().cpu", "x.pop", "loss_dict.values", "v.detach"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.gather", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalars"], ["", "def", "_write_metrics", "(", "self", ",", "metrics_dict", ":", "dict", ")", ":", "\n", "        ", "metrics_dict", "=", "{", "\n", "k", ":", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "else", "float", "(", "v", ")", "\n", "for", "k", ",", "v", "in", "metrics_dict", ".", "items", "(", ")", "\n", "}", "\n", "\n", "# gather metrics among all workers for logging", "\n", "# This assumes we do DDP-style training, which is currently the only", "\n", "# supported method in detectron2.", "\n", "all_metrics_dict", "=", "comm", ".", "gather", "(", "metrics_dict", ")", "\n", "# all_hg_dict = comm.gather(hg_dict)", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "if", "\"data_time\"", "in", "all_metrics_dict", "[", "0", "]", ":", "\n", "# data_time among workers can have high variance. The actual latency", "\n", "# caused by data_time is the maximum among workers.", "\n", "                ", "data_time", "=", "np", ".", "max", "(", "[", "x", ".", "pop", "(", "\"data_time\"", ")", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "self", ".", "storage", ".", "put_scalar", "(", "\"data_time\"", ",", "data_time", ")", "\n", "\n", "# average the rest metrics", "\n", "", "metrics_dict", "=", "{", "\n", "k", ":", "np", ".", "mean", "(", "[", "x", "[", "k", "]", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "for", "k", "in", "all_metrics_dict", "[", "0", "]", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "# append the list", "\n", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "metrics_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", ":", "\n", "                    ", "loss_dict", "[", "key", "]", "=", "metrics_dict", "[", "key", "]", "\n", "\n", "", "", "total_losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "self", ".", "storage", ".", "put_scalar", "(", "\"total_loss\"", ",", "total_losses_reduced", ")", "\n", "if", "len", "(", "metrics_dict", ")", ">", "1", ":", "\n", "                ", "self", ".", "storage", ".", "put_scalars", "(", "**", "metrics_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer._update_teacher_model": [[660, 681], ["torch.no_grad", "collections.OrderedDict", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model_teacher.state_dict().items", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model_teacher.load_state_dict", "detectron2.get_world_size", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model.state_dict", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model_teacher.state_dict", "original_trainer_two_head.Two_Head_UBTeacherTrainer.keys", "Exception", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model.state_dict().items", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_update_teacher_model", "(", "self", ",", "keep_rate", "=", "0.996", ")", ":", "\n", "        ", "if", "comm", ".", "get_world_size", "(", ")", ">", "1", ":", "\n", "            ", "student_model_dict", "=", "{", "\n", "key", "[", "7", ":", "]", ":", "value", "for", "key", ",", "value", "in", "self", ".", "model", ".", "state_dict", "(", ")", ".", "items", "(", ")", "\n", "}", "\n", "", "else", ":", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "            ", "student_model_dict", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "\n", "", "new_teacher_dict", "=", "OrderedDict", "(", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "model_teacher", ".", "state_dict", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "student_model_dict", ".", "keys", "(", ")", ":", "\n", "                ", "new_teacher_dict", "[", "key", "]", "=", "(", "\n", "student_model_dict", "[", "key", "]", "*", "(", "1", "-", "keep_rate", ")", "+", "value", "*", "keep_rate", "\n", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"{} is not found in student model\"", ".", "format", "(", "key", ")", ")", "\n", "\n", "", "", "self", ".", "model_teacher", ".", "load_state_dict", "(", "new_teacher_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer._copy_main_model": [[682, 692], ["torch.no_grad", "detectron2.get_world_size", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model_teacher.load_state_dict", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model_teacher.load_state_dict", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model.state_dict", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model.state_dict().items", "original_trainer_two_head.Two_Head_UBTeacherTrainer.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_copy_main_model", "(", "self", ")", ":", "\n", "# initialize all parameters", "\n", "        ", "if", "comm", ".", "get_world_size", "(", ")", ">", "1", ":", "\n", "            ", "rename_model_dict", "=", "{", "\n", "key", "[", "7", ":", "]", ":", "value", "for", "key", ",", "value", "in", "self", ".", "model", ".", "state_dict", "(", ")", ".", "items", "(", ")", "\n", "}", "\n", "self", ".", "model_teacher", ".", "load_state_dict", "(", "rename_model_dict", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model_teacher", ".", "load_state_dict", "(", "self", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.build_test_loader": [[693, 697], ["ubteacher.data.build.build_detection_test_loader"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_test_loader"], ["", "", "@", "classmethod", "\n", "def", "build_test_loader", "(", "cls", ",", "cfg", ",", "dataset_name", ")", ":", "\n", "# mapper = DatasetMapper_gt_test(cfg, False)", "\n", "        ", "return", "build_detection_test_loader", "(", "cfg", ",", "dataset_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.build_hooks": [[698, 856], ["original_trainer_two_head.Two_Head_UBTeacherTrainer.cfg.clone", "original_trainer_two_head.Two_Head_UBTeacherTrainer.defrost", "detectron2.is_main_process", "ret.append", "ret.append", "ret.append", "ret.append", "detectron2.is_main_process", "detectron2.engine.hooks.IterationTimer", "detectron2.engine.hooks.LRScheduler", "ret.append", "logging.getLogger", "logging.getLogger.info", "print", "original_trainer_two_head.Two_Head_UBTeacherTrainer.test_two_head", "logging.getLogger", "logging.getLogger.info", "print", "original_trainer_two_head.Two_Head_UBTeacherTrainer.test_two_head", "logging.getLogger", "print", "logging.getLogger.info", "original_trainer_two_head.Two_Head_UBTeacherTrainer.test_two_head", "logging.getLogger", "print", "logging.getLogger.info", "original_trainer_two_head.Two_Head_UBTeacherTrainer.test_two_head", "detectron2.engine.hooks.EvalHook", "detectron2.engine.hooks.EvalHook", "detectron2.engine.hooks.EvalHook", "detectron2.engine.hooks.EvalHook", "ret.append", "ret.append", "ret.append", "detectron2.engine.hooks.PreciseBN", "detectron2.engine.hooks.PeriodicCheckpointer", "original_trainer_two_head.Two_Head_UBTeacherTrainer.build_hooks.build_student_result"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.test_two_head", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.test_two_head", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.test_two_head", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.test_two_head"], ["", "def", "build_hooks", "(", "self", ")", ":", "\n", "        ", "import", "pdb", "\n", "\n", "cfg", "=", "self", ".", "cfg", ".", "clone", "(", ")", "\n", "cfg", ".", "defrost", "(", ")", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "# save some memory and time for PreciseBN", "\n", "\n", "ret", "=", "[", "\n", "hooks", ".", "IterationTimer", "(", ")", ",", "\n", "hooks", ".", "LRScheduler", "(", "self", ".", "optimizer", ",", "self", ".", "scheduler", ")", ",", "\n", "hooks", ".", "PreciseBN", "(", "\n", "# Run at the same freq as (but before) evaluation.", "\n", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "\n", "self", ".", "model", ",", "\n", "# Build a new data loader to not affect training", "\n", "self", ".", "build_train_loader", "(", "cfg", ")", ",", "\n", "cfg", ".", "TEST", ".", "PRECISE_BN", ".", "NUM_ITER", ",", "\n", ")", "\n", "if", "cfg", ".", "TEST", ".", "PRECISE_BN", ".", "ENABLED", "and", "get_bn_modules", "(", "self", ".", "model", ")", "\n", "else", "None", ",", "\n", "]", "\n", "\n", "# Do PreciseBN before checkpointer, because it updates the model and need to", "\n", "# be saved by checkpointer.", "\n", "# This is not always the best: if checkpointing has a different frequency,", "\n", "# some checkpoints may have more precise statistics than others.", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "ret", ".", "append", "(", "\n", "hooks", ".", "PeriodicCheckpointer", "(", "\n", "self", ".", "checkpointer", ",", "cfg", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", "\n", ")", "\n", ")", "\n", "\n", "\n", "", "def", "build_student_result", "(", "head", ")", ":", "\n", "            ", "if", "head", "==", "1", ":", "\n", "                ", "return", "test_and_save_results_student_head_1", "\n", "", "elif", "head", "==", "2", ":", "\n", "                ", "return", "test_and_save_results_student_head_2", "\n", "\n", "", "", "def", "build_teacher_result", "(", "head", ")", ":", "\n", "            ", "if", "head", "==", "1", ":", "\n", "                ", "return", "test_and_save_results_teacher_head_1", "\n", "", "elif", "head", "==", "2", ":", "\n", "                ", "return", "test_and_save_results_teacher_head_2", "\n", "\n", "\n", "\n", "", "", "def", "test_and_save_results_student_head_1", "(", ")", ":", "\n", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "logger", ".", "info", "(", "\"evaluate_on_student\"", ")", "\n", "\n", "print", "(", "\"test_on_student_head_1\"", ")", "\n", "self", ".", "_last_eval_results_student", "=", "self", ".", "test_two_head", "(", "self", ".", "cfg", ",", "self", ".", "model", ",", "head", "=", "1", ")", "\n", "\n", "_last_eval_results_student", "=", "{", "\n", "k", "+", "\"_student_1\"", ":", "self", ".", "_last_eval_results_student", "[", "k", "]", "\n", "for", "k", "in", "self", ".", "_last_eval_results_student", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "return", "_last_eval_results_student", "\n", "\n", "", "def", "test_and_save_results_student_head_2", "(", ")", ":", "\n", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "logger", ".", "info", "(", "\"evaluate_on_student\"", ")", "\n", "\n", "print", "(", "\"test_on_student_2:\"", ")", "\n", "self", ".", "_last_eval_results_student", "=", "self", ".", "test_two_head", "(", "self", ".", "cfg", ",", "self", ".", "model", ",", "head", "=", "2", ")", "\n", "\n", "_last_eval_results_student", "=", "{", "\n", "k", "+", "\"_student_2\"", ":", "self", ".", "_last_eval_results_student", "[", "k", "]", "\n", "for", "k", "in", "self", ".", "_last_eval_results_student", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "return", "_last_eval_results_student", "\n", "\n", "\n", "", "def", "test_and_save_results_teacher_head_1", "(", ")", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "print", "(", "\"test_on_teacher_head_1\"", ")", "\n", "logger", ".", "info", "(", "\"evaluate_on_teacher\"", ")", "\n", "self", ".", "_last_eval_results_teacher", "=", "self", ".", "test_two_head", "(", "self", ".", "cfg", ",", "self", ".", "model_teacher", ",", "head", "=", "1", ")", "\n", "\n", "_last_eval_results_teacher", "=", "{", "\n", "k", "+", "\"_teacher_1\"", ":", "self", ".", "_last_eval_results_teacher", "[", "k", "]", "\n", "for", "k", "in", "self", ".", "_last_eval_results_student", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "\n", "return", "_last_eval_results_teacher", "\n", "\n", "", "def", "test_and_save_results_teacher_head_2", "(", ")", ":", "\n", "            ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "print", "(", "\"test_on_teacher_head_2\"", ")", "\n", "logger", ".", "info", "(", "\"evaluate_on_teacher\"", ")", "\n", "self", ".", "_last_eval_results_teacher", "=", "self", ".", "test_two_head", "(", "self", ".", "cfg", ",", "self", ".", "model_teacher", ",", "head", "=", "2", ")", "\n", "\n", "_last_eval_results_teacher", "=", "{", "\n", "k", "+", "\"_teacher_2\"", ":", "self", ".", "_last_eval_results_teacher", "[", "k", "]", "\n", "for", "k", "in", "self", ".", "_last_eval_results_student", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "\n", "return", "_last_eval_results_teacher", "\n", "\n", "", "\"\"\" two head evaluation \"\"\"", "\n", "\n", "''' head=1  src branch teacher && student  '''", "\n", "\n", "ret", ".", "append", "(", "hooks", ".", "EvalHook", "(", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "build_student_result", "(", "head", "=", "1", ")", ")", ")", "\n", "ret", ".", "append", "(", "hooks", ".", "EvalHook", "(", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "build_teacher_result", "(", "head", "=", "1", ")", ")", ")", "\n", "\n", "''' head=2  src branch teacher && student  '''", "\n", "\n", "ret", ".", "append", "(", "hooks", ".", "EvalHook", "(", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "build_student_result", "(", "head", "=", "2", ")", ")", ")", "\n", "ret", ".", "append", "(", "hooks", ".", "EvalHook", "(", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "build_teacher_result", "(", "head", "=", "2", ")", ")", ")", "\n", "\n", "\n", "if", "cfg", ".", "TEST", ".", "VAL_LOSS", ":", "# default is True # save training time if not applied", "\n", "            ", "ret", ".", "append", "(", "\n", "LossEvalHook", "(", "\n", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "\n", "self", ".", "model", ",", "\n", "build_detection_test_loader", "(", "\n", "self", ".", "cfg", ",", "\n", "self", ".", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", ",", "\n", "DatasetMapper", "(", "self", ".", "cfg", ",", "True", ")", ",", "\n", ")", ",", "\n", "model_output", "=", "\"loss_proposal\"", ",", "\n", "model_name", "=", "\"student\"", ",", "\n", ")", "\n", ")", "\n", "\n", "ret", ".", "append", "(", "\n", "LossEvalHook", "(", "\n", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "\n", "self", ".", "model_teacher", ",", "\n", "build_detection_test_loader", "(", "\n", "self", ".", "cfg", ",", "\n", "self", ".", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", ",", "\n", "DatasetMapper", "(", "self", ".", "cfg", ",", "True", ")", ",", "\n", ")", ",", "\n", "model_output", "=", "\"loss_proposal\"", ",", "\n", "model_name", "=", "\"\"", ",", "\n", ")", "\n", ")", "\n", "\n", "", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "# run writers in the end, so that evaluation metrics are written", "\n", "            ", "ret", ".", "append", "(", "hooks", ".", "PeriodicWriter", "(", "self", ".", "build_writers", "(", ")", ",", "period", "=", "20", ")", ")", "\n", "", "import", "pdb", "\n", "# pdb.set_trace()", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.resume_or_load": [[859, 880], ["original_trainer_two_head.Two_Head_UBTeacherTrainer.checkpointer.resume_or_load", "original_trainer_two_head.Two_Head_UBTeacherTrainer.checkpointer.has_checkpoint"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.resume_or_load"], ["", "def", "resume_or_load", "(", "self", ",", "resume", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        If `resume==True` and `cfg.OUTPUT_DIR` contains the last checkpoint (defined by\n        a `last_checkpoint` file), resume from the file. Resuming means loading all\n        available states (eg. optimizer and scheduler) and update iteration counter\n        from the checkpoint. ``cfg.MODEL.WEIGHTS`` will not be used.\n\n        Otherwise, this is considered as an independent training. The method will load model\n        weights from the file `cfg.MODEL.WEIGHTS` (but will not load other states) and start\n        from iteration 0.\n\n        Args:\n            resume (bool): whether to do resume or not\n        \"\"\"", "\n", "ckpt", "=", "self", ".", "checkpointer", ".", "resume_or_load", "(", "self", ".", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "resume", ")", "\n", "# self.checkpointer.resume_or_load(self.cfg.MODEL.WEIGHTS, resume=resume)", "\n", "if", "resume", "and", "self", ".", "checkpointer", ".", "has_checkpoint", "(", ")", ":", "\n", "# The checkpoint stores the training iteration that just finished, thus we start", "\n", "# at the next iteration", "\n", "            ", "self", ".", "iter", "=", "ckpt", "[", "'iteration'", "]", "\n", "self", ".", "start_iter", "=", "self", ".", "iter", "+", "1", "\n", "", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.Two_Head_UBTeacherTrainer.test_two_head": [[880, 945], ["logging.getLogger", "isinstance", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "cls.build_test_loader", "ubteacher.evaluation.evaluator.two_head_inference_on_dataset", "detectron2.is_main_process", "len", "len", "len", "len", "len", "isinstance", "logging.getLogger.info", "detectron2.evaluation.print_csv_format", "list", "cls.build_evaluator", "cls.build_evaluator", "collections.OrderedDict.values", "logging.getLogger.warn"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_test_loader", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.two_head_inference_on_dataset", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_evaluator", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_evaluator"], ["", "", "@", "classmethod", "\n", "def", "test_two_head", "(", "cls", ",", "cfg", ",", "model", ",", "head", ",", "evaluators", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n            model (nn.Module):\n            evaluators (list[DatasetEvaluator] or None): if None, will call\n                :meth:`build_evaluator`. Otherwise, must have the same length as\n                ``cfg.DATASETS.TEST``.\n\n        Returns:\n            dict: a dict of result metrics\n        \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "if", "isinstance", "(", "evaluators", ",", "DatasetEvaluator", ")", ":", "\n", "            ", "evaluators", "=", "[", "evaluators", "]", "\n", "", "if", "evaluators", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", "==", "len", "(", "evaluators", ")", ",", "\"{} != {}\"", ".", "format", "(", "\n", "len", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", ",", "len", "(", "evaluators", ")", "\n", ")", "\n", "\n", "", "results_1", "=", "OrderedDict", "(", ")", "\n", "results_2", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "idx", ",", "dataset_name", "in", "enumerate", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", ":", "\n", "            ", "data_loader", "=", "cls", ".", "build_test_loader", "(", "cfg", ",", "dataset_name", ")", "\n", "# When evaluators are passed in as arguments,", "\n", "# implicitly assume that evaluators can be created before data_loader.", "\n", "if", "evaluators", "is", "not", "None", ":", "\n", "                ", "evaluator_1", "=", "evaluators", "[", "idx", "]", "\n", "evaluator_2", "=", "evaluators", "[", "idx", "]", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "evaluator_1", "=", "cls", ".", "build_evaluator", "(", "cfg", ",", "dataset_name", ",", "output_folder", "=", "'head1'", ")", "\n", "evaluator_2", "=", "cls", ".", "build_evaluator", "(", "cfg", ",", "dataset_name", ",", "output_folder", "=", "'head2'", ")", "\n", "", "except", "NotImplementedError", ":", "\n", "                    ", "logger", ".", "warn", "(", "\n", "\"No evaluator found. Use `DefaultTrainer.test(evaluators=)`, \"", "\n", "\"or implement its `build_evaluator` method.\"", "\n", ")", "\n", "results_1", "[", "dataset_name", "]", "=", "{", "}", "\n", "results_2", "[", "dataset_name", "]", "=", "{", "}", "\n", "continue", "\n", "", "", "results_i", ",", "save_feature", "=", "two_head_inference_on_dataset", "(", "model", ",", "data_loader", ",", "head", ",", "evaluator_1", ",", "evaluator_2", ")", "\n", "results_1", "[", "dataset_name", "]", "=", "results_i", "\n", "\n", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "                ", "assert", "isinstance", "(", "\n", "results_i", ",", "dict", "\n", ")", ",", "\"Evaluator must return a dict on the main process. Got {} instead.\"", ".", "format", "(", "\n", "results_i", "\n", ")", "\n", "logger", ".", "info", "(", "\"Evaluation results for {} in csv format:\"", ".", "format", "(", "dataset_name", ")", ")", "\n", "print_csv_format", "(", "results_i", ")", "\n", "\n", "\n", "\n", "", "", "if", "len", "(", "results_1", ")", "==", "1", ":", "\n", "            ", "results_1", "=", "list", "(", "results_1", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "# if len(results_2) == 1:", "\n", "#     results_2 = list(results_2.values())[0]", "\n", "\n", "", "return", "results_1", "", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook.__init__": [[11, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "eval_period", ",", "model", ",", "data_loader", ",", "model_output", ",", "model_name", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "_model", "=", "model", "\n", "self", ".", "_period", "=", "eval_period", "\n", "self", ".", "_data_loader", "=", "data_loader", "\n", "self", ".", "_model_output", "=", "model_output", "\n", "self", ".", "_model_name", "=", "model_name", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook._do_loss_eval": [[18, 55], ["hooks.inference_context", "torch.no_grad", "enumerate", "record_acc_dict.keys", "record_acc_dict.keys", "detectron2.is_main_process", "hooks.LossEvalHook._get_loss", "hooks.LossEvalHook.keys", "sum", "hooks.LossEvalHook.trainer.storage.put_scalar", "len", "len", "hooks.LossEvalHook.trainer.storage.put_scalars", "record_acc_dict.keys", "record_acc_dict.keys", "loss_acc_dict.values"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.inference_context", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook._get_loss", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalars"], ["", "def", "_do_loss_eval", "(", "self", ")", ":", "\n", "        ", "record_acc_dict", "=", "{", "}", "\n", "with", "inference_context", "(", "self", ".", "_model", ")", ",", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "_", ",", "inputs", "in", "enumerate", "(", "self", ".", "_data_loader", ")", ":", "\n", "                ", "record_dict", "=", "self", ".", "_get_loss", "(", "inputs", ",", "self", ".", "_model", ")", "\n", "# accumulate the losses", "\n", "for", "loss_type", "in", "record_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "loss_type", "not", "in", "record_acc_dict", ".", "keys", "(", ")", ":", "\n", "                        ", "record_acc_dict", "[", "loss_type", "]", "=", "record_dict", "[", "loss_type", "]", "\n", "", "else", ":", "\n", "                        ", "record_acc_dict", "[", "loss_type", "]", "+=", "record_dict", "[", "loss_type", "]", "\n", "# average", "\n", "", "", "", "for", "loss_type", "in", "record_acc_dict", ".", "keys", "(", ")", ":", "\n", "                ", "record_acc_dict", "[", "loss_type", "]", "=", "record_acc_dict", "[", "loss_type", "]", "/", "len", "(", "\n", "self", ".", "_data_loader", "\n", ")", "\n", "\n", "# divide loss and other metrics", "\n", "", "loss_acc_dict", "=", "{", "}", "\n", "for", "key", "in", "record_acc_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", ":", "\n", "                    ", "loss_acc_dict", "[", "key", "]", "=", "record_acc_dict", "[", "key", "]", "\n", "\n", "# only output the results of major node", "\n", "", "", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "                ", "total_losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "loss_acc_dict", ".", "values", "(", ")", ")", "\n", "self", ".", "trainer", ".", "storage", ".", "put_scalar", "(", "\n", "\"val_total_loss_val\"", "+", "self", ".", "_model_name", ",", "total_losses_reduced", "\n", ")", "\n", "\n", "record_acc_dict", "=", "{", "\n", "\"val_\"", "+", "k", "+", "self", ".", "_model_name", ":", "record_acc_dict", "[", "k", "]", "\n", "for", "k", "in", "record_acc_dict", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "if", "len", "(", "record_acc_dict", ")", ">", "1", ":", "\n", "                    ", "self", ".", "trainer", ".", "storage", ".", "put_scalars", "(", "**", "record_acc_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook._get_loss": [[56, 72], ["model", "model", "isinstance", "v.detach().cpu().item", "float", "model.items", "model", "v.detach().cpu", "v.detach"], "methods", ["None"], ["", "", "", "", "def", "_get_loss", "(", "self", ",", "data", ",", "model", ")", ":", "\n", "        ", "if", "self", ".", "_model_output", "==", "\"loss_only\"", ":", "\n", "            ", "record_dict", "=", "model", "(", "data", ")", "\n", "\n", "", "elif", "self", ".", "_model_output", "==", "\"loss_proposal\"", ":", "\n", "            ", "record_dict", ",", "_", ",", "_", ",", "_", "=", "model", "(", "data", ",", "branch", "=", "\"val_loss\"", ",", "val_mode", "=", "True", ")", "\n", "\n", "", "elif", "self", ".", "_model_output", "==", "\"meanteacher\"", ":", "\n", "            ", "record_dict", ",", "_", ",", "_", ",", "_", ",", "_", "=", "model", "(", "data", ")", "\n", "\n", "", "metrics_dict", "=", "{", "\n", "k", ":", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "else", "float", "(", "v", ")", "\n", "for", "k", ",", "v", "in", "record_dict", ".", "items", "(", ")", "\n", "}", "\n", "\n", "return", "metrics_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook._write_losses": [[73, 91], ["detectron2.synchronize", "detectron2.gather", "detectron2.is_main_process", "sum", "hooks.LossEvalHook.trainer.storage.put_scalar", "numpy.mean", "len", "hooks.LossEvalHook.trainer.storage.put_scalars", "all_metrics_dict[].keys", "metrics_dict.values"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.synchronize", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.gather", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalars"], ["", "def", "_write_losses", "(", "self", ",", "metrics_dict", ")", ":", "\n", "# gather metrics among all workers for logging", "\n", "# This assumes we do DDP-style training, which is currently the only", "\n", "# supported method in detectron2.", "\n", "        ", "comm", ".", "synchronize", "(", ")", "\n", "all_metrics_dict", "=", "comm", ".", "gather", "(", "metrics_dict", ",", "dst", "=", "0", ")", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "# average the rest metrics", "\n", "            ", "metrics_dict", "=", "{", "\n", "\"val_\"", "+", "k", ":", "np", ".", "mean", "(", "[", "x", "[", "k", "]", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "for", "k", "in", "all_metrics_dict", "[", "0", "]", ".", "keys", "(", ")", "\n", "}", "\n", "total_losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "metrics_dict", ".", "values", "(", ")", ")", "\n", "\n", "self", ".", "trainer", ".", "storage", ".", "put_scalar", "(", "\"val_total_loss_val\"", ",", "total_losses_reduced", ")", "\n", "if", "len", "(", "metrics_dict", ")", ">", "1", ":", "\n", "                ", "self", ".", "trainer", ".", "storage", ".", "put_scalars", "(", "**", "metrics_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook._detect_anomaly": [[92, 97], ["torch.isfinite().all", "FloatingPointError", "torch.isfinite"], "methods", ["None"], ["", "", "", "def", "_detect_anomaly", "(", "self", ",", "losses", ",", "loss_dict", ")", ":", "\n", "        ", "if", "not", "torch", ".", "isfinite", "(", "losses", ")", ".", "all", "(", ")", ":", "\n", "            ", "raise", "FloatingPointError", "(", "\n", "\"Loss became infinite or NaN at iteration={}!\\nloss_dict = {}\"", ".", "format", "(", "\n", "self", ".", "trainer", ".", "iter", ",", "loss_dict", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook.after_step": [[100, 105], ["hooks.LossEvalHook._do_loss_eval"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook._do_loss_eval"], ["", "", "def", "after_step", "(", "self", ")", ":", "\n", "        ", "next_iter", "=", "self", ".", "trainer", ".", "iter", "+", "1", "\n", "is_final", "=", "next_iter", "==", "self", ".", "trainer", ".", "max_iter", "\n", "if", "is_final", "or", "(", "self", ".", "_period", ">", "0", "and", "next_iter", "%", "self", ".", "_period", "==", "0", ")", ":", "\n", "            ", "self", ".", "_do_loss_eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.inference_context": [[107, 120], ["model.eval", "model.train"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.train"], ["", "", "", "@", "contextmanager", "\n", "def", "inference_context", "(", "model", ")", ":", "\n", "    ", "\"\"\"\n    A context where the model is temporarily changed to eval mode,\n    and restored to previous mode afterwards.\n\n    Args:\n        model: a torch Module\n    \"\"\"", "\n", "training_mode", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "yield", "\n", "model", ".", "train", "(", "training_mode", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.BaselineTrainer.__init__": [[47, 81], ["detectron2.engine.DefaultTrainer.auto_scale_workers", "source_fft_np_trainer.BaselineTrainer.build_model", "source_fft_np_trainer.BaselineTrainer.build_optimizer", "source_fft_np_trainer.BaselineTrainer.build_train_loader", "detectron2.engine.TrainerBase.__init__", "source_fft_np_trainer.BaselineTrainer.build_lr_scheduler", "detectron2.checkpoint.DetectionCheckpointer", "source_fft_np_trainer.BaselineTrainer.register_hooks", "detectron2.get_world_size", "detectron2.get_world_size", "torch.nn.parallel.DistributedDataParallel", "source_fft_np_trainer.BaselineTrainer.build_hooks", "detectron2.get_local_rank"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_optimizer", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_train_loader", "home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__", "home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_lr_scheduler", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_hooks", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_local_rank"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n        Use the custom checkpointer, which loads other backbone models\n        with matching heuristics.\n        \"\"\"", "\n", "cfg", "=", "DefaultTrainer", ".", "auto_scale_workers", "(", "cfg", ",", "comm", ".", "get_world_size", "(", ")", ")", "\n", "model", "=", "self", ".", "build_model", "(", "cfg", ")", "\n", "optimizer", "=", "self", ".", "build_optimizer", "(", "cfg", ",", "model", ")", "\n", "data_loader", "=", "self", ".", "build_train_loader", "(", "cfg", ")", "\n", "\n", "if", "comm", ".", "get_world_size", "(", ")", ">", "1", ":", "\n", "            ", "model", "=", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "comm", ".", "get_local_rank", "(", ")", "]", ",", "broadcast_buffers", "=", "False", "\n", ")", "\n", "\n", "", "TrainerBase", ".", "__init__", "(", "self", ")", "\n", "self", ".", "_trainer", "=", "(", "AMPTrainer", "if", "cfg", ".", "SOLVER", ".", "AMP", ".", "ENABLED", "else", "SimpleTrainer", ")", "(", "\n", "model", ",", "data_loader", ",", "optimizer", "\n", ")", "\n", "\n", "self", ".", "scheduler", "=", "self", ".", "build_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "self", ".", "checkpointer", "=", "DetectionCheckpointer", "(", "\n", "model", ",", "\n", "cfg", ".", "OUTPUT_DIR", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "scheduler", "=", "self", ".", "scheduler", ",", "\n", ")", "\n", "self", ".", "start_iter", "=", "0", "\n", "self", ".", "max_iter", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "self", ".", "register_hooks", "(", "self", ".", "build_hooks", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.BaselineTrainer.train_loop": [[82, 105], ["logging.getLogger", "logging.getLogger.info", "detectron2.utils.events.EventStorage", "source_fft_np_trainer.BaselineTrainer.before_train", "range", "source_fft_np_trainer.BaselineTrainer.after_train", "source_fft_np_trainer.BaselineTrainer.before_step", "source_fft_np_trainer.BaselineTrainer.run_step", "source_fft_np_trainer.BaselineTrainer.after_step", "logging.getLogger.exception"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.BaselineTrainer.run_step", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook.after_step"], ["", "def", "train_loop", "(", "self", ",", "start_iter", ":", "int", ",", "max_iter", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            start_iter, max_iter (int): See docs above\n        \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Starting training from iteration {}\"", ".", "format", "(", "start_iter", ")", ")", "\n", "\n", "self", ".", "iter", "=", "self", ".", "start_iter", "=", "start_iter", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "\n", "with", "EventStorage", "(", "start_iter", ")", "as", "self", ".", "storage", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "before_train", "(", ")", "\n", "for", "self", ".", "iter", "in", "range", "(", "start_iter", ",", "max_iter", ")", ":", "\n", "                    ", "self", ".", "before_step", "(", ")", "\n", "self", ".", "run_step", "(", ")", "\n", "self", ".", "after_step", "(", ")", "\n", "", "", "except", "Exception", ":", "\n", "                ", "logger", ".", "exception", "(", "\"Exception during training:\"", ")", "\n", "raise", "\n", "", "finally", ":", "\n", "                ", "self", ".", "after_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.BaselineTrainer.run_step": [[106, 138], ["time.perf_counter", "next", "source_fft_np_trainer.BaselineTrainer.model", "record_dict.keys", "sum", "source_fft_np_trainer.BaselineTrainer._write_metrics", "source_fft_np_trainer.BaselineTrainer.optimizer.zero_grad", "sum.backward", "source_fft_np_trainer.BaselineTrainer.optimizer.step", "time.perf_counter", "len", "len", "loss_dict.values"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._write_metrics", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine._NewEmptyTensorOp.backward", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.step"], ["", "", "", "def", "run_step", "(", "self", ")", ":", "\n", "        ", "self", ".", "_trainer", ".", "iter", "=", "self", ".", "iter", "\n", "\n", "assert", "self", ".", "model", ".", "training", ",", "\"[SimpleTrainer] model was changed to eval mode!\"", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "data", "=", "next", "(", "self", ".", "_trainer", ".", "_data_loader_iter", ")", "\n", "\n", "data_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "\n", "record_dict", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "data", ",", "branch", "=", "\"supervised\"", ")", "\n", "\n", "num_gt_bbox", "=", "0.0", "\n", "for", "element", "in", "data", ":", "\n", "            ", "num_gt_bbox", "+=", "len", "(", "element", "[", "\"instances\"", "]", ")", "\n", "", "num_gt_bbox", "=", "num_gt_bbox", "/", "len", "(", "data", ")", "\n", "record_dict", "[", "\"bbox_num/gt_bboxes\"", "]", "=", "num_gt_bbox", "\n", "\n", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "record_dict", ".", "keys", "(", ")", ":", "\n", "            ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", "and", "key", "[", "-", "3", ":", "]", "!=", "\"val\"", ":", "\n", "                ", "loss_dict", "[", "key", "]", "=", "record_dict", "[", "key", "]", "\n", "\n", "", "", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "metrics_dict", "=", "record_dict", "\n", "metrics_dict", "[", "\"data_time\"", "]", "=", "data_time", "\n", "self", ".", "_write_metrics", "(", "metrics_dict", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "losses", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.BaselineTrainer.build_evaluator": [[139, 144], ["ubteacher.evaluation.coco_evaluation.COCOEvaluator", "os.path.join"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_evaluator", "(", "cls", ",", "cfg", ",", "dataset_name", ",", "output_folder", "=", "None", ")", ":", "\n", "        ", "if", "output_folder", "is", "None", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ")", "\n", "", "return", "COCOEvaluator", "(", "dataset_name", ",", "cfg", ",", "True", ",", "output_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.BaselineTrainer.build_train_loader": [[145, 148], ["ubteacher.data.build.build_detection_semisup_train_loader"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_semisup_train_loader"], ["", "@", "classmethod", "\n", "def", "build_train_loader", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "return", "build_detection_semisup_train_loader", "(", "cfg", ",", "mapper", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.BaselineTrainer.build_test_loader": [[149, 156], ["ubteacher.data.build.build_detection_test_loader"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_test_loader"], ["", "@", "classmethod", "\n", "def", "build_test_loader", "(", "cls", ",", "cfg", ",", "dataset_name", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            iterable\n        \"\"\"", "\n", "return", "build_detection_test_loader", "(", "cfg", ",", "dataset_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.BaselineTrainer.build_hooks": [[157, 198], ["source_fft_np_trainer.BaselineTrainer.cfg.clone", "source_fft_np_trainer.BaselineTrainer.defrost", "detectron2.is_main_process", "ret.append", "detectron2.is_main_process", "detectron2.engine.hooks.IterationTimer", "detectron2.engine.hooks.LRScheduler", "ret.append", "source_fft_np_trainer.BaselineTrainer.test", "detectron2.engine.hooks.EvalHook", "ret.append", "detectron2.engine.hooks.PreciseBN", "detectron2.engine.hooks.PeriodicCheckpointer", "detectron2.engine.hooks.PeriodicWriter", "fvcore.nn.precise_bn.get_bn_modules", "source_fft_np_trainer.BaselineTrainer.build_train_loader", "source_fft_np_trainer.BaselineTrainer.build_writers"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.test", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_train_loader"], ["", "def", "build_hooks", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Build a list of default hooks, including timing, evaluation,\n        checkpointing, lr scheduling, precise BN, writing events.\n\n        Returns:\n            list[HookBase]:\n        \"\"\"", "\n", "cfg", "=", "self", ".", "cfg", ".", "clone", "(", ")", "\n", "cfg", ".", "defrost", "(", ")", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "\n", "\n", "ret", "=", "[", "\n", "hooks", ".", "IterationTimer", "(", ")", ",", "\n", "hooks", ".", "LRScheduler", "(", "self", ".", "optimizer", ",", "self", ".", "scheduler", ")", ",", "\n", "hooks", ".", "PreciseBN", "(", "\n", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "\n", "self", ".", "model", ",", "\n", "self", ".", "build_train_loader", "(", "cfg", ")", ",", "\n", "cfg", ".", "TEST", ".", "PRECISE_BN", ".", "NUM_ITER", ",", "\n", ")", "\n", "if", "cfg", ".", "TEST", ".", "PRECISE_BN", ".", "ENABLED", "and", "get_bn_modules", "(", "self", ".", "model", ")", "\n", "else", "None", ",", "\n", "]", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "ret", ".", "append", "(", "\n", "hooks", ".", "PeriodicCheckpointer", "(", "\n", "self", ".", "checkpointer", ",", "cfg", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", "\n", ")", "\n", ")", "\n", "\n", "", "def", "test_and_save_results", "(", ")", ":", "\n", "            ", "self", ".", "_last_eval_results", "=", "self", ".", "test", "(", "self", ".", "cfg", ",", "self", ".", "model", ")", "\n", "return", "self", ".", "_last_eval_results", "\n", "\n", "", "ret", ".", "append", "(", "hooks", ".", "EvalHook", "(", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "test_and_save_results", ")", ")", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "ret", ".", "append", "(", "hooks", ".", "PeriodicWriter", "(", "self", ".", "build_writers", "(", ")", ",", "period", "=", "20", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.BaselineTrainer._write_metrics": [[199, 233], ["detectron2.gather", "detectron2.is_main_process", "metrics_dict.keys", "sum", "source_fft_np_trainer.BaselineTrainer.storage.put_scalar", "isinstance", "v.detach().cpu().item", "float", "metrics_dict.items", "numpy.max", "source_fft_np_trainer.BaselineTrainer.storage.put_scalar", "numpy.mean", "len", "source_fft_np_trainer.BaselineTrainer.storage.put_scalars", "all_metrics_dict[].keys", "v.detach().cpu", "x.pop", "loss_dict.values", "v.detach"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.gather", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalars"], ["", "def", "_write_metrics", "(", "self", ",", "metrics_dict", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            metrics_dict (dict): dict of scalar metrics\n        \"\"\"", "\n", "metrics_dict", "=", "{", "\n", "k", ":", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "else", "float", "(", "v", ")", "\n", "for", "k", ",", "v", "in", "metrics_dict", ".", "items", "(", ")", "\n", "}", "\n", "# gather metrics among all workers for logging", "\n", "# This assumes we do DDP-style training, which is currently the only", "\n", "# supported method in detectron2.", "\n", "all_metrics_dict", "=", "comm", ".", "gather", "(", "metrics_dict", ")", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "if", "\"data_time\"", "in", "all_metrics_dict", "[", "0", "]", ":", "\n", "                ", "data_time", "=", "np", ".", "max", "(", "[", "x", ".", "pop", "(", "\"data_time\"", ")", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "self", ".", "storage", ".", "put_scalar", "(", "\"data_time\"", ",", "data_time", ")", "\n", "\n", "", "metrics_dict", "=", "{", "\n", "k", ":", "np", ".", "mean", "(", "[", "x", "[", "k", "]", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "for", "k", "in", "all_metrics_dict", "[", "0", "]", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "metrics_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", ":", "\n", "                    ", "loss_dict", "[", "key", "]", "=", "metrics_dict", "[", "key", "]", "\n", "\n", "", "", "total_losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "self", ".", "storage", ".", "put_scalar", "(", "\"total_loss\"", ",", "total_losses_reduced", ")", "\n", "if", "len", "(", "metrics_dict", ")", ">", "1", ":", "\n", "                ", "self", ".", "storage", ".", "put_scalars", "(", "**", "metrics_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.__init__": [[237, 281], ["detectron2.engine.DefaultTrainer.auto_scale_workers", "source_fft_np_trainer.UBTeacherTrainer.build_train_loader", "source_fft_np_trainer.UBTeacherTrainer.build_model", "source_fft_np_trainer.UBTeacherTrainer.build_optimizer", "source_fft_np_trainer.UBTeacherTrainer.build_model", "detectron2.engine.TrainerBase.__init__", "source_fft_np_trainer.UBTeacherTrainer.build_lr_scheduler", "ubteacher.modeling.meta_arch.ts_ensemble.EnsembleTSModel", "ubteacher.checkpoint.detection_checkpoint.DetectionTSCheckpointer", "source_fft_np_trainer.UBTeacherTrainer.register_hooks", "detectron2.get_world_size", "detectron2.get_world_size", "torch.nn.parallel.DistributedDataParallel", "source_fft_np_trainer.UBTeacherTrainer.build_hooks", "detectron2.get_local_rank"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_train_loader", "home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_optimizer", "home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__", "home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_lr_scheduler", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_hooks", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_local_rank"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            cfg (CfgNode):\n        Use the custom checkpointer, which loads other backbone models\n        with matching heuristics.\n        \"\"\"", "\n", "cfg", "=", "DefaultTrainer", ".", "auto_scale_workers", "(", "cfg", ",", "comm", ".", "get_world_size", "(", ")", ")", "\n", "data_loader", "=", "self", ".", "build_train_loader", "(", "cfg", ")", "\n", "\n", "# create an student model", "\n", "model", "=", "self", ".", "build_model", "(", "cfg", ")", "\n", "optimizer", "=", "self", ".", "build_optimizer", "(", "cfg", ",", "model", ")", "\n", "\n", "# create an teacher model", "\n", "model_teacher", "=", "self", ".", "build_model", "(", "cfg", ")", "\n", "self", ".", "model_teacher", "=", "model_teacher", "\n", "\n", "# For training, wrap with DDP. But don't need this for inference.", "\n", "if", "comm", ".", "get_world_size", "(", ")", ">", "1", ":", "\n", "            ", "model", "=", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "comm", ".", "get_local_rank", "(", ")", "]", ",", "broadcast_buffers", "=", "False", "\n", ")", "\n", "\n", "", "TrainerBase", ".", "__init__", "(", "self", ")", "\n", "self", ".", "_trainer", "=", "(", "AMPTrainer", "if", "cfg", ".", "SOLVER", ".", "AMP", ".", "ENABLED", "else", "SimpleTrainer", ")", "(", "\n", "model", ",", "data_loader", ",", "optimizer", "\n", ")", "\n", "self", ".", "scheduler", "=", "self", ".", "build_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n", "# Ensemble teacher and student model is for model saving and loading", "\n", "ensem_ts_model", "=", "EnsembleTSModel", "(", "model_teacher", ",", "model", ")", "\n", "\n", "self", ".", "checkpointer", "=", "DetectionTSCheckpointer", "(", "\n", "ensem_ts_model", ",", "\n", "cfg", ".", "OUTPUT_DIR", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "scheduler", "=", "self", ".", "scheduler", ",", "\n", ")", "\n", "self", ".", "start_iter", "=", "0", "\n", "self", ".", "max_iter", "=", "cfg", ".", "SOLVER", ".", "MAX_ITER", "\n", "self", ".", "cfg", "=", "cfg", "\n", "\n", "self", ".", "register_hooks", "(", "self", ".", "build_hooks", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_evaluator": [[282, 292], ["os.path.join", "ubteacher.evaluation.coco_evaluation.COCOEvaluator", "ValueError"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "build_evaluator", "(", "cls", ",", "cfg", ",", "dataset_name", ",", "output_folder", "=", "None", ")", ":", "\n", "        ", "if", "output_folder", "is", "None", ":", "\n", "            ", "output_folder", "=", "os", ".", "path", ".", "join", "(", "cfg", ".", "OUTPUT_DIR", ",", "\"inference\"", ")", "\n", "\n", "\n", "", "if", "cfg", ".", "TEST", ".", "EVALUATOR", "==", "\"COCOeval\"", ":", "\n", "            ", "return", "COCOEvaluator", "(", "dataset_name", ",", "cfg", ",", "True", ",", "output_folder", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown test evaluator.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_train_loader": [[293, 297], ["ubteacher.data.dataset_mapper.DatasetMapperTwoCropSeparate", "ubteacher.data.build.build_detection_semisup_train_loader_two_crops"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_semisup_train_loader_two_crops"], ["", "", "@", "classmethod", "\n", "def", "build_train_loader", "(", "cls", ",", "cfg", ")", ":", "\n", "        ", "mapper", "=", "DatasetMapperTwoCropSeparate", "(", "cfg", ",", "True", ")", "\n", "return", "build_detection_semisup_train_loader_two_crops", "(", "cfg", ",", "mapper", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_lr_scheduler": [[298, 301], ["ubteacher.solver.build.build_lr_scheduler"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_lr_scheduler"], ["", "@", "classmethod", "\n", "def", "build_lr_scheduler", "(", "cls", ",", "cfg", ",", "optimizer", ")", ":", "\n", "        ", "return", "build_lr_scheduler", "(", "cfg", ",", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.train": [[302, 307], ["source_fft_np_trainer.UBTeacherTrainer.train_loop", "hasattr", "detectron2.is_main_process", "detectron2.evaluation.verify_results"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.train_loop", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "self", ".", "train_loop", "(", "self", ".", "start_iter", ",", "self", ".", "max_iter", ")", "\n", "if", "hasattr", "(", "self", ",", "\"_last_eval_results\"", ")", "and", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "verify_results", "(", "self", ".", "cfg", ",", "self", ".", "_last_eval_results", ")", "\n", "return", "self", ".", "_last_eval_results", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.train_loop": [[311, 331], ["logging.getLogger", "logging.getLogger.info", "detectron2.utils.events.EventStorage", "source_fft_np_trainer.UBTeacherTrainer.before_train", "range", "source_fft_np_trainer.UBTeacherTrainer.after_train", "source_fft_np_trainer.UBTeacherTrainer.before_step", "source_fft_np_trainer.UBTeacherTrainer.run_step_full_semisup", "source_fft_np_trainer.UBTeacherTrainer.after_step", "logging.getLogger.exception"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.run_step_full_semisup", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.hooks.LossEvalHook.after_step"], ["", "", "def", "train_loop", "(", "self", ",", "start_iter", ":", "int", ",", "max_iter", ":", "int", ")", ":", "\n", "        ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Starting training from iteration {}\"", ".", "format", "(", "start_iter", ")", ")", "\n", "\n", "self", ".", "iter", "=", "self", ".", "start_iter", "=", "start_iter", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "\n", "with", "EventStorage", "(", "start_iter", ")", "as", "self", ".", "storage", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "before_train", "(", ")", "\n", "\n", "for", "self", ".", "iter", "in", "range", "(", "start_iter", ",", "max_iter", ")", ":", "\n", "                    ", "self", ".", "before_step", "(", ")", "\n", "self", ".", "run_step_full_semisup", "(", ")", "\n", "self", ".", "after_step", "(", ")", "\n", "", "", "except", "Exception", ":", "\n", "                ", "logger", ".", "exception", "(", "\"Exception during training:\"", ")", "\n", "raise", "\n", "", "finally", ":", "\n", "                ", "self", ".", "after_train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.threshold_bbox": [[335, 369], ["detectron2.structures.instances.Instances", "detectron2.structures.boxes.Boxes", "detectron2.structures.instances.Instances", "detectron2.structures.boxes.Boxes"], "methods", ["None"], ["", "", "", "def", "threshold_bbox", "(", "self", ",", "proposal_bbox_inst", ",", "thres", "=", "0.7", ",", "proposal_type", "=", "\"roih\"", ")", ":", "\n", "        ", "if", "proposal_type", "==", "\"rpn\"", ":", "\n", "            ", "valid_map", "=", "proposal_bbox_inst", ".", "objectness_logits", ">", "thres", "\n", "\n", "# create instances containing boxes and gt_classes", "\n", "image_shape", "=", "proposal_bbox_inst", ".", "image_size", "\n", "new_proposal_inst", "=", "Instances", "(", "image_shape", ")", "\n", "\n", "# create box", "\n", "new_bbox_loc", "=", "proposal_bbox_inst", ".", "proposal_boxes", ".", "tensor", "[", "valid_map", ",", ":", "]", "\n", "new_boxes", "=", "Boxes", "(", "new_bbox_loc", ")", "\n", "\n", "# add boxes to instances", "\n", "new_proposal_inst", ".", "gt_boxes", "=", "new_boxes", "\n", "new_proposal_inst", ".", "objectness_logits", "=", "proposal_bbox_inst", ".", "objectness_logits", "[", "\n", "valid_map", "\n", "]", "\n", "", "elif", "proposal_type", "==", "\"roih\"", ":", "\n", "            ", "valid_map", "=", "proposal_bbox_inst", ".", "scores", ">", "thres", "\n", "\n", "# create instances containing boxes and gt_classes", "\n", "image_shape", "=", "proposal_bbox_inst", ".", "image_size", "\n", "new_proposal_inst", "=", "Instances", "(", "image_shape", ")", "\n", "\n", "# create box", "\n", "new_bbox_loc", "=", "proposal_bbox_inst", ".", "pred_boxes", ".", "tensor", "[", "valid_map", ",", ":", "]", "\n", "new_boxes", "=", "Boxes", "(", "new_bbox_loc", ")", "\n", "\n", "# add boxes to instances", "\n", "new_proposal_inst", ".", "gt_boxes", "=", "new_boxes", "\n", "new_proposal_inst", ".", "gt_classes", "=", "proposal_bbox_inst", ".", "pred_classes", "[", "valid_map", "]", "\n", "new_proposal_inst", ".", "scores", "=", "proposal_bbox_inst", ".", "scores", "[", "valid_map", "]", "\n", "\n", "", "return", "new_proposal_inst", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.process_pseudo_label": [[370, 387], ["len", "list_instances.append", "len", "source_fft_np_trainer.UBTeacherTrainer.threshold_bbox", "ValueError"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.threshold_bbox"], ["", "def", "process_pseudo_label", "(", "\n", "self", ",", "proposals_rpn_unsup_k", ",", "cur_threshold", ",", "proposal_type", ",", "psedo_label_method", "=", "\"\"", "\n", ")", ":", "\n", "        ", "list_instances", "=", "[", "]", "\n", "num_proposal_output", "=", "0.0", "\n", "for", "proposal_bbox_inst", "in", "proposals_rpn_unsup_k", ":", "\n", "# thresholding", "\n", "            ", "if", "psedo_label_method", "==", "\"thresholding\"", ":", "\n", "                ", "proposal_bbox_inst", "=", "self", ".", "threshold_bbox", "(", "\n", "proposal_bbox_inst", ",", "thres", "=", "cur_threshold", ",", "proposal_type", "=", "proposal_type", "\n", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unkown pseudo label boxes methods\"", ")", "\n", "", "num_proposal_output", "+=", "len", "(", "proposal_bbox_inst", ")", "\n", "list_instances", ".", "append", "(", "proposal_bbox_inst", ")", "\n", "", "num_proposal_output", "=", "num_proposal_output", "/", "len", "(", "proposals_rpn_unsup_k", ")", "\n", "return", "list_instances", ",", "num_proposal_output", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.remove_label": [[388, 393], ["label_datum.keys"], "methods", ["None"], ["", "def", "remove_label", "(", "self", ",", "label_data", ")", ":", "\n", "        ", "for", "label_datum", "in", "label_data", ":", "\n", "            ", "if", "\"instances\"", "in", "label_datum", ".", "keys", "(", ")", ":", "\n", "                ", "del", "label_datum", "[", "\"instances\"", "]", "\n", "", "", "return", "label_data", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.add_label": [[394, 398], ["zip"], "methods", ["None"], ["", "def", "add_label", "(", "self", ",", "unlabled_data", ",", "label", ")", ":", "\n", "        ", "for", "unlabel_datum", ",", "lab_inst", "in", "zip", "(", "unlabled_data", ",", "label", ")", ":", "\n", "            ", "unlabel_datum", "[", "\"instances\"", "]", "=", "lab_inst", "\n", "", "return", "unlabled_data", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.run_step_full_semisup": [[403, 568], ["time.perf_counter", "next", "[].cpu().numpy", "[].cpu().numpy", "utils.FDA_source_to_target_np", "torch.Tensor().cuda", "source_fft_np_trainer.UBTeacherTrainer._write_metrics", "source_fft_np_trainer.UBTeacherTrainer.optimizer.zero_grad", "sum.backward", "source_fft_np_trainer.UBTeacherTrainer.optimizer.step", "time.perf_counter", "label_data_q.extend", "record_dict.keys", "sum", "source_fft_np_trainer.UBTeacherTrainer.process_pseudo_label", "source_fft_np_trainer.UBTeacherTrainer.process_pseudo_label", "source_fft_np_trainer.UBTeacherTrainer.remove_label", "source_fft_np_trainer.UBTeacherTrainer.remove_label", "source_fft_np_trainer.UBTeacherTrainer.add_label", "source_fft_np_trainer.UBTeacherTrainer.add_label", "record_dict.update", "source_fft_np_trainer.UBTeacherTrainer.model", "record_all_unlabel_data.keys", "record_dict.update", "record_dict.keys", "sum", "[].cpu", "[].cpu", "torch.Tensor", "source_fft_np_trainer.UBTeacherTrainer.model", "source_fft_np_trainer.UBTeacherTrainer.model", "loss_dict.values", "source_fft_np_trainer.UBTeacherTrainer._update_teacher_model", "torch.no_grad", "source_fft_np_trainer.UBTeacherTrainer.model_teacher", "source_fft_np_trainer.UBTeacherTrainer.model", "loss_dict.values", "source_fft_np_trainer.UBTeacherTrainer._update_teacher_model", "source_fft_np_trainer.UBTeacherTrainer.model", "source_fft_np_trainer.UBTeacherTrainer.model"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.__init__.FDA_source_to_target_np", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._write_metrics", "home.repos.pwc.inspect_result.feobi1999_tdd.meta_arch.two_head_rcnn_refine._NewEmptyTensorOp.backward", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.step", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.process_pseudo_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.process_pseudo_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.remove_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.remove_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.add_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.add_label", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._update_teacher_model", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._update_teacher_model"], ["", "def", "run_step_full_semisup", "(", "self", ")", ":", "\n", "        ", "self", ".", "_trainer", ".", "iter", "=", "self", ".", "iter", "\n", "assert", "self", ".", "model", ".", "training", ",", "\"[UBTeacherTrainer] model was changed to eval mode!\"", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "data", "=", "next", "(", "self", ".", "_trainer", ".", "_data_loader_iter", ")", "\n", "#import pdb", "\n", "#pdb.set_trace()", "\n", "label_data_q", ",", "label_data_k", ",", "unlabel_data_q", ",", "unlabel_data_k", "=", "data", "\n", "\n", "src_image", "=", "label_data_k", "[", "0", "]", "[", "'image'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "#[3,600,1200]", "\n", "tgt_image", "=", "unlabel_data_k", "[", "0", "]", "[", "'image'", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "#", "\n", "src_in_trg", "=", "FDA_source_to_target_np", "(", "src_image", ",", "tgt_image", ",", "L", "=", "0.1", ")", "# src_lbl", "\n", "\n", "label_data_k", "[", "0", "]", "[", "'image'", "]", "=", "torch", ".", "Tensor", "(", "src_in_trg", ")", ".", "cuda", "(", ")", "\n", "\n", "data_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start", "\n", "\n", "# burn-in stage (supervised training with labeled data)", "\n", "if", "self", ".", "iter", "<", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BURN_UP_STEP", ":", "\n", "\n", "\n", "# input both strong and weak supervised data into model", "\n", "            ", "label_data_q", ".", "extend", "(", "label_data_k", ")", "\n", "if", "self", ".", "cfg", ".", "CONSIST_ON", ":", "\n", "                ", "record_dict", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "label_data_q", ",", "branch", "=", "\"consist_supervised\"", ")", "\n", "# elif self.cfg.CONTRAST_ON:", "\n", "#     record_dict, _, _, _ = self.model(label_data_q, branch='contrast_supervised')", "\n", "", "else", ":", "\n", "                ", "record_dict", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "label_data_q", ",", "branch", "=", "\"supervised\"", ")", "\n", "\n", "\n", "# weight losses", "\n", "", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "record_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", ":", "\n", "                    ", "loss_dict", "[", "key", "]", "=", "record_dict", "[", "key", "]", "*", "1", "\n", "", "", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "iter", "==", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BURN_UP_STEP", ":", "\n", "# update copy the the whole model", "\n", "                ", "self", ".", "_update_teacher_model", "(", "keep_rate", "=", "0.00", ")", "\n", "\n", "", "elif", "(", "\n", "self", ".", "iter", "-", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BURN_UP_STEP", "\n", ")", "%", "self", ".", "cfg", ".", "SEMISUPNET", ".", "TEACHER_UPDATE_ITER", "==", "0", ":", "\n", "                ", "self", ".", "_update_teacher_model", "(", "keep_rate", "=", "self", ".", "cfg", ".", "SEMISUPNET", ".", "EMA_KEEP_RATE", ")", "\n", "\n", "", "record_dict", "=", "{", "}", "\n", "#  generate the pseudo-label using teacher model", "\n", "# note that we do not convert to eval mode, as 1) there is no gradient computed in", "\n", "# teacher model and 2) batch norm layers are not updated as well", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "(", "\n", "_", ",", "\n", "proposals_rpn_unsup_k", ",", "\n", "proposals_roih_unsup_k", ",", "\n", "_", ",", "\n", ")", "=", "self", ".", "model_teacher", "(", "unlabel_data_k", ",", "branch", "=", "\"unsup_data_weak\"", ")", "\n", "\n", "#  Pseudo-labeling", "\n", "", "if", "self", ".", "cfg", ".", "SEMISUPNET", ".", "TWO_STAGE_THRESHHOLD", ":", "\n", "                ", "if", "self", ".", "iter", ">", "self", ".", "cfg", ".", "SEMISUPNET", ".", "STEP", ":", "\n", "                    ", "cur_threshold", "=", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BBOX_THRESHOLD_2", "\n", "", "else", ":", "\n", "                    ", "cur_threshold", "=", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BBOX_THRESHOLD_1", "\n", "", "", "else", ":", "\n", "                ", "cur_threshold", "=", "self", ".", "cfg", ".", "SEMISUPNET", ".", "BBOX_THRESHOLD", "\n", "\n", "", "joint_proposal_dict", "=", "{", "}", "\n", "joint_proposal_dict", "[", "\"proposals_rpn\"", "]", "=", "proposals_rpn_unsup_k", "\n", "(", "\n", "pesudo_proposals_rpn_unsup_k", ",", "\n", "nun_pseudo_bbox_rpn", ",", "\n", ")", "=", "self", ".", "process_pseudo_label", "(", "\n", "proposals_rpn_unsup_k", ",", "cur_threshold", ",", "\"rpn\"", ",", "\"thresholding\"", "\n", ")", "\n", "joint_proposal_dict", "[", "\"proposals_pseudo_rpn\"", "]", "=", "pesudo_proposals_rpn_unsup_k", "\n", "# Pseudo_labeling for ROI head (bbox location/objectness)", "\n", "pesudo_proposals_roih_unsup_k", ",", "_", "=", "self", ".", "process_pseudo_label", "(", "\n", "proposals_roih_unsup_k", ",", "cur_threshold", ",", "\"roih\"", ",", "\"thresholding\"", "\n", ")", "\n", "joint_proposal_dict", "[", "\"proposals_pseudo_roih\"", "]", "=", "pesudo_proposals_roih_unsup_k", "\n", "\n", "#  add pseudo-label to unlabeled data", "\n", "unlabel_data_q", "=", "self", ".", "remove_label", "(", "unlabel_data_q", ")", "\n", "unlabel_data_k", "=", "self", ".", "remove_label", "(", "unlabel_data_k", ")", "\n", "\n", "unlabel_data_q", "=", "self", ".", "add_label", "(", "\n", "unlabel_data_q", ",", "joint_proposal_dict", "[", "\"proposals_pseudo_roih\"", "]", "\n", ")", "\n", "unlabel_data_k", "=", "self", ".", "add_label", "(", "\n", "unlabel_data_k", ",", "joint_proposal_dict", "[", "\"proposals_pseudo_roih\"", "]", "\n", ")", "\n", "\n", "\n", "\n", "all_label_data", "=", "label_data_q", "+", "label_data_k", "\n", "all_unlabel_data", "=", "unlabel_data_q", "\n", "\n", "\n", "if", "self", ".", "cfg", ".", "CONSIST_ON", ":", "\n", "\n", "                ", "record_all_label_data", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "\n", "all_label_data", ",", "branch", "=", "\"consist_supervised\"", "\n", ")", "\n", "", "elif", "self", ".", "cfg", ".", "CONTRAST_ON", ":", "\n", "                ", "record_all_label_data", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "\n", "all_label_data", ",", "branch", "=", "\"contrast_supervised\"", "\n", ")", "\n", "\n", "", "else", ":", "\n", "                ", "record_all_label_data", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "\n", "all_label_data", ",", "branch", "=", "\"supervised\"", "\n", ")", "\n", "\n", "\n", "", "record_dict", ".", "update", "(", "record_all_label_data", ")", "\n", "\n", "\n", "\n", "\n", "record_all_unlabel_data", ",", "_", ",", "_", ",", "_", "=", "self", ".", "model", "(", "\n", "all_unlabel_data", ",", "branch", "=", "\"supervised\"", "\n", ")", "\n", "\n", "new_record_all_unlabel_data", "=", "{", "}", "\n", "for", "key", "in", "record_all_unlabel_data", ".", "keys", "(", ")", ":", "\n", "                ", "new_record_all_unlabel_data", "[", "key", "+", "\"_pseudo\"", "]", "=", "record_all_unlabel_data", "[", "\n", "key", "]", "\n", "\n", "\n", "\n", "\n", "", "record_dict", ".", "update", "(", "new_record_all_unlabel_data", ")", "\n", "\n", "# weight losses", "\n", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "record_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", ":", "\n", "\n", "                    ", "if", "key", "==", "\"loss_rpn_loc_pseudo\"", "or", "key", "==", "\"loss_box_reg_pseudo\"", ":", "\n", "# pseudo bbox regression <- 0", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "record_dict", "[", "key", "]", "*", "0", "\n", "", "elif", "key", "[", "-", "6", ":", "]", "==", "\"pseudo\"", ":", "# unsupervised loss", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "(", "\n", "record_dict", "[", "key", "]", "*", "self", ".", "cfg", ".", "SEMISUPNET", ".", "UNSUP_LOSS_WEIGHT", "\n", ")", "\n", "", "elif", "'consist'", "in", "key", ":", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "(", "\n", "record_dict", "[", "key", "]", "*", "0.1", "\n", ")", "\n", "", "else", ":", "# supervised loss", "\n", "                        ", "loss_dict", "[", "key", "]", "=", "record_dict", "[", "key", "]", "*", "1", "\n", "\n", "", "", "", "losses", "=", "sum", "(", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "", "metrics_dict", "=", "record_dict", "\n", "metrics_dict", "[", "\"data_time\"", "]", "=", "data_time", "\n", "self", ".", "_write_metrics", "(", "metrics_dict", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "losses", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._write_metrics": [[570, 606], ["detectron2.gather", "detectron2.is_main_process", "metrics_dict.keys", "sum", "source_fft_np_trainer.UBTeacherTrainer.storage.put_scalar", "isinstance", "v.detach().cpu().item", "float", "metrics_dict.items", "numpy.max", "source_fft_np_trainer.UBTeacherTrainer.storage.put_scalar", "numpy.mean", "len", "source_fft_np_trainer.UBTeacherTrainer.storage.put_scalars", "all_metrics_dict[].keys", "v.detach().cpu", "x.pop", "loss_dict.values", "v.detach"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.gather", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalar", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.put_scalars"], ["", "def", "_write_metrics", "(", "self", ",", "metrics_dict", ":", "dict", ")", ":", "\n", "        ", "metrics_dict", "=", "{", "\n", "k", ":", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", "else", "float", "(", "v", ")", "\n", "for", "k", ",", "v", "in", "metrics_dict", ".", "items", "(", ")", "\n", "}", "\n", "\n", "# gather metrics among all workers for logging", "\n", "# This assumes we do DDP-style training, which is currently the only", "\n", "# supported method in detectron2.", "\n", "all_metrics_dict", "=", "comm", ".", "gather", "(", "metrics_dict", ")", "\n", "# all_hg_dict = comm.gather(hg_dict)", "\n", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "if", "\"data_time\"", "in", "all_metrics_dict", "[", "0", "]", ":", "\n", "# data_time among workers can have high variance. The actual latency", "\n", "# caused by data_time is the maximum among workers.", "\n", "                ", "data_time", "=", "np", ".", "max", "(", "[", "x", ".", "pop", "(", "\"data_time\"", ")", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "self", ".", "storage", ".", "put_scalar", "(", "\"data_time\"", ",", "data_time", ")", "\n", "\n", "# average the rest metrics", "\n", "", "metrics_dict", "=", "{", "\n", "k", ":", "np", ".", "mean", "(", "[", "x", "[", "k", "]", "for", "x", "in", "all_metrics_dict", "]", ")", "\n", "for", "k", "in", "all_metrics_dict", "[", "0", "]", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "# append the list", "\n", "loss_dict", "=", "{", "}", "\n", "for", "key", "in", "metrics_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "[", ":", "4", "]", "==", "\"loss\"", ":", "\n", "                    ", "loss_dict", "[", "key", "]", "=", "metrics_dict", "[", "key", "]", "\n", "\n", "", "", "total_losses_reduced", "=", "sum", "(", "loss", "for", "loss", "in", "loss_dict", ".", "values", "(", ")", ")", "\n", "\n", "self", ".", "storage", ".", "put_scalar", "(", "\"total_loss\"", ",", "total_losses_reduced", ")", "\n", "if", "len", "(", "metrics_dict", ")", ">", "1", ":", "\n", "                ", "self", ".", "storage", ".", "put_scalars", "(", "**", "metrics_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._update_teacher_model": [[607, 626], ["torch.no_grad", "collections.OrderedDict", "source_fft_np_trainer.UBTeacherTrainer.model_teacher.state_dict().items", "source_fft_np_trainer.UBTeacherTrainer.model_teacher.load_state_dict", "detectron2.get_world_size", "source_fft_np_trainer.UBTeacherTrainer.model.state_dict", "source_fft_np_trainer.UBTeacherTrainer.model_teacher.state_dict", "source_fft_np_trainer.UBTeacherTrainer.keys", "Exception", "source_fft_np_trainer.UBTeacherTrainer.model.state_dict().items", "source_fft_np_trainer.UBTeacherTrainer.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_update_teacher_model", "(", "self", ",", "keep_rate", "=", "0.996", ")", ":", "\n", "        ", "if", "comm", ".", "get_world_size", "(", ")", ">", "1", ":", "\n", "            ", "student_model_dict", "=", "{", "\n", "key", "[", "7", ":", "]", ":", "value", "for", "key", ",", "value", "in", "self", ".", "model", ".", "state_dict", "(", ")", ".", "items", "(", ")", "\n", "}", "\n", "", "else", ":", "\n", "            ", "student_model_dict", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "\n", "", "new_teacher_dict", "=", "OrderedDict", "(", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "model_teacher", ".", "state_dict", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "student_model_dict", ".", "keys", "(", ")", ":", "\n", "                ", "new_teacher_dict", "[", "key", "]", "=", "(", "\n", "student_model_dict", "[", "key", "]", "*", "(", "1", "-", "keep_rate", ")", "+", "value", "*", "keep_rate", "\n", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"{} is not found in student model\"", ".", "format", "(", "key", ")", ")", "\n", "\n", "", "", "self", ".", "model_teacher", ".", "load_state_dict", "(", "new_teacher_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer._copy_main_model": [[627, 637], ["torch.no_grad", "detectron2.get_world_size", "source_fft_np_trainer.UBTeacherTrainer.model_teacher.load_state_dict", "source_fft_np_trainer.UBTeacherTrainer.model_teacher.load_state_dict", "source_fft_np_trainer.UBTeacherTrainer.model.state_dict", "source_fft_np_trainer.UBTeacherTrainer.model.state_dict().items", "source_fft_np_trainer.UBTeacherTrainer.model.state_dict"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "_copy_main_model", "(", "self", ")", ":", "\n", "# initialize all parameters", "\n", "        ", "if", "comm", ".", "get_world_size", "(", ")", ">", "1", ":", "\n", "            ", "rename_model_dict", "=", "{", "\n", "key", "[", "7", ":", "]", ":", "value", "for", "key", ",", "value", "in", "self", ".", "model", ".", "state_dict", "(", ")", ".", "items", "(", ")", "\n", "}", "\n", "self", ".", "model_teacher", ".", "load_state_dict", "(", "rename_model_dict", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model_teacher", ".", "load_state_dict", "(", "self", ".", "model", ".", "state_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_test_loader": [[638, 641], ["ubteacher.data.build.build_detection_test_loader"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_test_loader"], ["", "", "@", "classmethod", "\n", "def", "build_test_loader", "(", "cls", ",", "cfg", ",", "dataset_name", ")", ":", "\n", "        ", "return", "build_detection_test_loader", "(", "cfg", ",", "dataset_name", ")", "\n", "# def build_test_loader(cls, cfg, dataset_name):", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_hooks": [[644, 723], ["source_fft_np_trainer.UBTeacherTrainer.cfg.clone", "source_fft_np_trainer.UBTeacherTrainer.defrost", "detectron2.is_main_process", "ret.append", "ret.append", "detectron2.is_main_process", "detectron2.engine.hooks.IterationTimer", "detectron2.engine.hooks.LRScheduler", "ret.append", "source_fft_np_trainer.UBTeacherTrainer.test", "source_fft_np_trainer.UBTeacherTrainer.test", "detectron2.engine.hooks.EvalHook", "detectron2.engine.hooks.EvalHook", "ret.append", "ret.append", "ret.append", "detectron2.engine.hooks.PreciseBN", "detectron2.engine.hooks.PeriodicCheckpointer", "ubteacher.engine.hooks.LossEvalHook", "ubteacher.engine.hooks.LossEvalHook", "detectron2.engine.hooks.PeriodicWriter", "fvcore.nn.precise_bn.get_bn_modules", "source_fft_np_trainer.UBTeacherTrainer.build_train_loader", "source_fft_np_trainer.UBTeacherTrainer._last_eval_results_student.keys", "ubteacher.data.build.build_detection_test_loader", "ubteacher.data.build.build_detection_test_loader", "source_fft_np_trainer.UBTeacherTrainer.build_writers", "detectron2.data.dataset_mapper.DatasetMapper", "detectron2.data.dataset_mapper.DatasetMapper"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.test", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.original_trainer_two_head.BaselineTrainer.test", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.build_train_loader", "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_test_loader", "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_test_loader"], ["", "def", "build_hooks", "(", "self", ")", ":", "\n", "        ", "cfg", "=", "self", ".", "cfg", ".", "clone", "(", ")", "\n", "cfg", ".", "defrost", "(", ")", "\n", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", "=", "0", "# save some memory and time for PreciseBN", "\n", "\n", "ret", "=", "[", "\n", "hooks", ".", "IterationTimer", "(", ")", ",", "\n", "hooks", ".", "LRScheduler", "(", "self", ".", "optimizer", ",", "self", ".", "scheduler", ")", ",", "\n", "hooks", ".", "PreciseBN", "(", "\n", "# Run at the same freq as (but before) evaluation.", "\n", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "\n", "self", ".", "model", ",", "\n", "# Build a new data loader to not affect training", "\n", "self", ".", "build_train_loader", "(", "cfg", ")", ",", "\n", "cfg", ".", "TEST", ".", "PRECISE_BN", ".", "NUM_ITER", ",", "\n", ")", "\n", "if", "cfg", ".", "TEST", ".", "PRECISE_BN", ".", "ENABLED", "and", "get_bn_modules", "(", "self", ".", "model", ")", "\n", "else", "None", ",", "\n", "]", "\n", "\n", "# Do PreciseBN before checkpointer, because it updates the model and need to", "\n", "# be saved by checkpointer.", "\n", "# This is not always the best: if checkpointing has a different frequency,", "\n", "# some checkpoints may have more precise statistics than others.", "\n", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "            ", "ret", ".", "append", "(", "\n", "hooks", ".", "PeriodicCheckpointer", "(", "\n", "self", ".", "checkpointer", ",", "cfg", ".", "SOLVER", ".", "CHECKPOINT_PERIOD", "\n", ")", "\n", ")", "\n", "\n", "", "def", "test_and_save_results_student", "(", ")", ":", "\n", "            ", "self", ".", "_last_eval_results_student", "=", "self", ".", "test", "(", "self", ".", "cfg", ",", "self", ".", "model", ")", "\n", "_last_eval_results_student", "=", "{", "\n", "k", "+", "\"_student\"", ":", "self", ".", "_last_eval_results_student", "[", "k", "]", "\n", "for", "k", "in", "self", ".", "_last_eval_results_student", ".", "keys", "(", ")", "\n", "}", "\n", "return", "_last_eval_results_student", "\n", "\n", "", "def", "test_and_save_results_teacher", "(", ")", ":", "\n", "            ", "self", ".", "_last_eval_results_teacher", "=", "self", ".", "test", "(", "self", ".", "cfg", ",", "self", ".", "model_teacher", ")", "\n", "return", "self", ".", "_last_eval_results_teacher", "\n", "\n", "", "ret", ".", "append", "(", "hooks", ".", "EvalHook", "(", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "test_and_save_results_student", ")", ")", "\n", "ret", ".", "append", "(", "hooks", ".", "EvalHook", "(", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "test_and_save_results_teacher", ")", ")", "\n", "\n", "if", "cfg", ".", "TEST", ".", "VAL_LOSS", ":", "# default is True # save training time if not applied", "\n", "            ", "ret", ".", "append", "(", "\n", "LossEvalHook", "(", "\n", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "\n", "self", ".", "model", ",", "\n", "build_detection_test_loader", "(", "\n", "self", ".", "cfg", ",", "\n", "self", ".", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", ",", "\n", "DatasetMapper", "(", "self", ".", "cfg", ",", "True", ")", ",", "\n", ")", ",", "\n", "model_output", "=", "\"loss_proposal\"", ",", "\n", "model_name", "=", "\"student\"", ",", "\n", ")", "\n", ")", "\n", "\n", "ret", ".", "append", "(", "\n", "LossEvalHook", "(", "\n", "cfg", ".", "TEST", ".", "EVAL_PERIOD", ",", "\n", "self", ".", "model_teacher", ",", "\n", "build_detection_test_loader", "(", "\n", "self", ".", "cfg", ",", "\n", "self", ".", "cfg", ".", "DATASETS", ".", "TEST", "[", "0", "]", ",", "\n", "DatasetMapper", "(", "self", ".", "cfg", ",", "True", ")", ",", "\n", ")", ",", "\n", "model_output", "=", "\"loss_proposal\"", ",", "\n", "model_name", "=", "\"\"", ",", "\n", ")", "\n", ")", "\n", "\n", "", "if", "comm", ".", "is_main_process", "(", ")", ":", "\n", "# run writers in the end, so that evaluation metrics are written", "\n", "            ", "ret", ".", "append", "(", "hooks", ".", "PeriodicWriter", "(", "self", ".", "build_writers", "(", ")", ",", "period", "=", "20", ")", ")", "\n", "", "return", "ret", "\n", "", "def", "resume_or_load", "(", "self", ",", "resume", "=", "True", ")", ":", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.resume_or_load": [[723, 744], ["source_fft_np_trainer.UBTeacherTrainer.checkpointer.resume_or_load", "source_fft_np_trainer.UBTeacherTrainer.checkpointer.has_checkpoint"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.resume_or_load"], ["", "def", "resume_or_load", "(", "self", ",", "resume", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        If `resume==True` and `cfg.OUTPUT_DIR` contains the last checkpoint (defined by\n        a `last_checkpoint` file), resume from the file. Resuming means loading all\n        available states (eg. optimizer and scheduler) and update iteration counter\n        from the checkpoint. ``cfg.MODEL.WEIGHTS`` will not be used.\n\n        Otherwise, this is considered as an independent training. The method will load model\n        weights from the file `cfg.MODEL.WEIGHTS` (but will not load other states) and start\n        from iteration 0.\n\n        Args:\n            resume (bool): whether to do resume or not\n        \"\"\"", "\n", "ckpt", "=", "self", ".", "checkpointer", ".", "resume_or_load", "(", "self", ".", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "resume", ")", "\n", "# self.checkpointer.resume_or_load(self.cfg.MODEL.WEIGHTS, resume=resume)", "\n", "if", "resume", "and", "self", ".", "checkpointer", ".", "has_checkpoint", "(", ")", ":", "\n", "# The checkpoint stores the training iteration that just finished, thus we start", "\n", "# at the next iteration", "\n", "            ", "self", ".", "iter", "=", "ckpt", "[", "'iteration'", "]", "\n", "self", ".", "start_iter", "=", "self", ".", "iter", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherPredictor.__init__": [[747, 765], ["detectron2.engine.DefaultPredictor.__init__", "cfg.clone", "detectron2.modeling.build_model", "detectron2.modeling.build_model", "ubteacher.modeling.meta_arch.ts_ensemble.EnsembleTSModel", "detectron2.checkpoint.DetectionCheckpointer", "detectron2.checkpoint.DetectionCheckpointer.resume_or_load", "source_fft_np_trainer.UBTeacherPredictor.model.eval"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__", "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.resume_or_load"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "super", "(", "UBTeacherPredictor", ",", "self", ")", ".", "__init__", "(", "cfg", ")", "\n", "self", ".", "cfg", "=", "cfg", ".", "clone", "(", ")", "# cfg can be modified by model", "\n", "# self.model = build_model(self.cfg)", "\n", "\n", "import", "pdb", "\n", "model", "=", "build_model", "(", "cfg", ")", "\n", "model_teacher", "=", "build_model", "(", "cfg", ")", "\n", "ensem_ts_model", "=", "EnsembleTSModel", "(", "model_teacher", ",", "model", ")", "\n", "# self.model = ensem_ts_model(cfg)", "\n", "\n", "checkpointer", "=", "DetectionCheckpointer", "(", "ensem_ts_model", ",", "save_dir", "=", "cfg", ".", "OUTPUT_DIR", ")", "\n", "checkpointer", ".", "resume_or_load", "(", "cfg", ".", "MODEL", ".", "WEIGHTS", ",", "resume", "=", "False", ")", "\n", "# checkpointer.load(cfg.MODEL.WEIGHTS)", "\n", "\n", "\n", "self", ".", "model", "=", "ensem_ts_model", ".", "modelTeacher", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherPredictor.__call__": [[766, 790], ["torch.no_grad", "source_fft_np_trainer.UBTeacherPredictor.aug.get_transform().apply_image", "torch.as_tensor", "torch.as_tensor.astype().transpose", "source_fft_np_trainer.UBTeacherPredictor.model", "source_fft_np_trainer.UBTeacherPredictor.aug.get_transform", "torch.as_tensor.astype"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "original_image", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            original_image (np.ndarray): an image of shape (H, W, C) (in BGR order).\n\n        Returns:\n            predictions (dict):\n                the output of the model for one image only.\n                See :doc:`/tutorials/models` for details about the format.\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "# https://github.com/sphinx-doc/sphinx/issues/4258", "\n", "# Apply pre-processing to image.", "\n", "            ", "if", "self", ".", "input_format", "==", "\"RGB\"", ":", "\n", "# whether the model expects BGR inputs or RGB", "\n", "                ", "original_image", "=", "original_image", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "", "height", ",", "width", "=", "original_image", ".", "shape", "[", ":", "2", "]", "\n", "image", "=", "self", ".", "aug", ".", "get_transform", "(", "original_image", ")", ".", "apply_image", "(", "original_image", ")", "\n", "image", "=", "torch", ".", "as_tensor", "(", "image", ".", "astype", "(", "\"float32\"", ")", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "inputs", "=", "{", "\"image\"", ":", "image", ",", "\"height\"", ":", "height", ",", "\"width\"", ":", "width", "}", "\n", "\n", "predictions", "=", "self", ".", "model", "(", "[", "inputs", "]", ")", "[", "0", "]", "\n", "\n", "return", "predictions", ",", "[", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.common.MapDatasetTwoCrop.__getitem__": [[21, 41], ["int", "common.MapDatasetTwoCrop._map_func", "common.MapDatasetTwoCrop._fallback_candidates.discard", "common.MapDatasetTwoCrop._fallback_candidates.add", "common.MapDatasetTwoCrop._rng.sample", "logging.getLogger", "logging.getLogger.warning"], "methods", ["None"], ["def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "retry_count", "=", "0", "\n", "cur_idx", "=", "int", "(", "idx", ")", "\n", "\n", "while", "True", ":", "\n", "            ", "data", "=", "self", ".", "_map_func", "(", "self", ".", "_dataset", "[", "cur_idx", "]", ")", "\n", "if", "data", "is", "not", "None", ":", "\n", "                ", "self", ".", "_fallback_candidates", ".", "add", "(", "cur_idx", ")", "\n", "return", "data", "\n", "\n", "# _map_func fails for this idx, use a random new index from the pool", "\n", "", "retry_count", "+=", "1", "\n", "self", ".", "_fallback_candidates", ".", "discard", "(", "cur_idx", ")", "\n", "cur_idx", "=", "self", ".", "_rng", ".", "sample", "(", "self", ".", "_fallback_candidates", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "\n", "if", "retry_count", ">=", "3", ":", "\n", "                ", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Failed to apply `_map_func` for idx: {}, retry count: {}\"", ".", "format", "(", "\n", "idx", ",", "retry_count", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.common.AspectRatioGroupedDatasetTwoCrop.__init__": [[58, 69], ["range", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset: an iterable. Each element must be a dict with keys\n                \"width\" and \"height\", which will be used to batch data.\n            batch_size (int):\n        \"\"\"", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "_buckets", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "self", ".", "_buckets_key", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "# Hard-coded two aspect ratio groups: w > h and w < h.", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.common.AspectRatioGroupedDatasetTwoCrop.__iter__": [[72, 90], ["bucket.append", "buckets_key.append", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "d", "in", "self", ".", "dataset", ":", "\n", "# d is a tuple with len = 2", "\n", "# It's two images (same size) from the same image instance", "\n", "            ", "w", ",", "h", "=", "d", "[", "0", "]", "[", "\"width\"", "]", ",", "d", "[", "0", "]", "[", "\"height\"", "]", "\n", "bucket_id", "=", "0", "if", "w", ">", "h", "else", "1", "\n", "\n", "# bucket = bucket for normal images", "\n", "bucket", "=", "self", ".", "_buckets", "[", "bucket_id", "]", "\n", "bucket", ".", "append", "(", "d", "[", "0", "]", ")", "\n", "\n", "# buckets_key = bucket for augmented images", "\n", "buckets_key", "=", "self", ".", "_buckets_key", "[", "bucket_id", "]", "\n", "buckets_key", ".", "append", "(", "d", "[", "1", "]", ")", "\n", "if", "len", "(", "bucket", ")", "==", "self", ".", "batch_size", ":", "\n", "                ", "yield", "(", "bucket", "[", ":", "]", ",", "buckets_key", "[", ":", "]", ")", "\n", "del", "bucket", "[", ":", "]", "\n", "del", "buckets_key", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.common.AspectRatioGroupedSemiSupDatasetTwoCrop.__init__": [[105, 122], ["range", "range", "range", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset: a tuple containing two iterable generators. \uff08labeled and unlabeled data)\n               Each element must be a dict with keys \"width\" and \"height\", which will be used\n               to batch data.\n            batch_size (int):\n        \"\"\"", "\n", "\n", "self", ".", "label_dataset", ",", "self", ".", "unlabel_dataset", "=", "dataset", "\n", "self", ".", "batch_size_label", "=", "batch_size", "[", "0", "]", "\n", "self", ".", "batch_size_unlabel", "=", "batch_size", "[", "1", "]", "\n", "\n", "self", ".", "_label_buckets", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "self", ".", "_label_buckets_key", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "self", ".", "_unlabel_buckets", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "self", ".", "_unlabel_buckets_key", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "# Hard-coded two aspect ratio groups: w > h and w < h.", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.common.AspectRatioGroupedSemiSupDatasetTwoCrop.__iter__": [[125, 167], ["zip", "len", "label_bucket.append", "label_buckets_key.append", "len", "unlabel_bucket.append", "unlabel_buckets_key.append", "len", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "label_bucket", ",", "unlabel_bucket", "=", "[", "]", ",", "[", "]", "\n", "for", "d_label", ",", "d_unlabel", "in", "zip", "(", "self", ".", "label_dataset", ",", "self", ".", "unlabel_dataset", ")", ":", "\n", "# d is a tuple with len = 2", "\n", "# It's two images (same size) from the same image instance", "\n", "# d[0] is with strong augmentation, d[1] is with weak augmentation", "\n", "\n", "# because we are grouping images with their aspect ratio", "\n", "# label and unlabel buckets might not have the same number of data", "\n", "# i.e., one could reach batch_size, while the other is still not", "\n", "            ", "if", "len", "(", "label_bucket", ")", "!=", "self", ".", "batch_size_label", ":", "\n", "                ", "w", ",", "h", "=", "d_label", "[", "0", "]", "[", "\"width\"", "]", ",", "d_label", "[", "0", "]", "[", "\"height\"", "]", "\n", "label_bucket_id", "=", "0", "if", "w", ">", "h", "else", "1", "\n", "label_bucket", "=", "self", ".", "_label_buckets", "[", "label_bucket_id", "]", "\n", "label_bucket", ".", "append", "(", "d_label", "[", "0", "]", ")", "\n", "label_buckets_key", "=", "self", ".", "_label_buckets_key", "[", "label_bucket_id", "]", "\n", "label_buckets_key", ".", "append", "(", "d_label", "[", "1", "]", ")", "\n", "\n", "", "if", "len", "(", "unlabel_bucket", ")", "!=", "self", ".", "batch_size_unlabel", ":", "\n", "                ", "w", ",", "h", "=", "d_unlabel", "[", "0", "]", "[", "\"width\"", "]", ",", "d_unlabel", "[", "0", "]", "[", "\"height\"", "]", "\n", "unlabel_bucket_id", "=", "0", "if", "w", ">", "h", "else", "1", "\n", "unlabel_bucket", "=", "self", ".", "_unlabel_buckets", "[", "unlabel_bucket_id", "]", "\n", "unlabel_bucket", ".", "append", "(", "d_unlabel", "[", "0", "]", ")", "\n", "unlabel_buckets_key", "=", "self", ".", "_unlabel_buckets_key", "[", "unlabel_bucket_id", "]", "\n", "unlabel_buckets_key", ".", "append", "(", "d_unlabel", "[", "1", "]", ")", "\n", "\n", "# yield the batch of data until all buckets are full", "\n", "", "if", "(", "\n", "len", "(", "label_bucket", ")", "==", "self", ".", "batch_size_label", "\n", "and", "len", "(", "unlabel_bucket", ")", "==", "self", ".", "batch_size_unlabel", "\n", ")", ":", "\n", "# label_strong, label_weak, unlabed_strong, unlabled_weak", "\n", "                ", "yield", "(", "\n", "label_bucket", "[", ":", "]", ",", "\n", "label_buckets_key", "[", ":", "]", ",", "\n", "unlabel_bucket", "[", ":", "]", ",", "\n", "unlabel_buckets_key", "[", ":", "]", ",", "\n", ")", "\n", "del", "label_bucket", "[", ":", "]", "\n", "del", "label_buckets_key", "[", ":", "]", "\n", "del", "unlabel_bucket", "[", ":", "]", "\n", "del", "unlabel_buckets_key", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.common.AspectRatioGroupedSemiSupDatasetThreeCrop.__init__": [[182, 203], ["range", "range", "range", "range", "range", "range"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset: a tuple containing two iterable generators. \uff08labeled and unlabeled data)\n               Each element must be a dict with keys \"width\" and \"height\", which will be used\n               to batch data.\n            batch_size (int):\n        \"\"\"", "\n", "\n", "self", ".", "label_dataset", ",", "self", ".", "unlabel_dataset", ",", "self", ".", "label_dataset_gan", "=", "dataset", "\n", "self", ".", "batch_size_label", "=", "batch_size", "[", "0", "]", "\n", "self", ".", "batch_size_unlabel", "=", "batch_size", "[", "1", "]", "\n", "self", ".", "batch_size_gan", "=", "batch_size", "[", "2", "]", "\n", "\n", "self", ".", "_label_buckets", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "self", ".", "_label_buckets_key", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "self", ".", "_unlabel_buckets", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "self", ".", "_unlabel_buckets_key", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "\n", "self", ".", "_unlabel_buckets_gan", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "self", ".", "_unlabel_buckets_key_gan", "=", "[", "[", "]", "for", "_", "in", "range", "(", "2", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.common.AspectRatioGroupedSemiSupDatasetThreeCrop.__iter__": [[209, 275], ["zip", "len", "label_bucket.append", "label_buckets_key.append", "len", "unlabel_bucket.append", "unlabel_buckets_key.append", "len", "label_bucket_gan.append", "label_bucket_gan_key.append", "len", "len", "len"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "label_bucket", ",", "unlabel_bucket", ",", "label_bucket_gan", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "d_label", ",", "d_unlabel", ",", "d_gan", "in", "zip", "(", "self", ".", "label_dataset", ",", "self", ".", "unlabel_dataset", ",", "self", ".", "label_dataset_gan", ")", ":", "\n", "# d is a tuple with len = 2", "\n", "# It's two images (same size) from the same image instance", "\n", "# d[0] is with strong augmentation, d[1] is with weak augmentation", "\n", "\n", "# because we are grouping images with their aspect ratio", "\n", "# label and unlabel buckets might not have the same number of data", "\n", "# i.e., one could reach batch_size, while the other is still not", "\n", "            ", "if", "len", "(", "label_bucket", ")", "!=", "self", ".", "batch_size_label", ":", "\n", "                ", "w", ",", "h", "=", "d_label", "[", "0", "]", "[", "\"width\"", "]", ",", "d_label", "[", "0", "]", "[", "\"height\"", "]", "\n", "label_bucket_id", "=", "0", "if", "w", ">", "h", "else", "1", "\n", "label_bucket", "=", "self", ".", "_label_buckets", "[", "label_bucket_id", "]", "\n", "label_bucket", ".", "append", "(", "d_label", "[", "0", "]", ")", "\n", "label_buckets_key", "=", "self", ".", "_label_buckets_key", "[", "label_bucket_id", "]", "\n", "label_buckets_key", ".", "append", "(", "d_label", "[", "1", "]", ")", "\n", "\n", "", "if", "len", "(", "unlabel_bucket", ")", "!=", "self", ".", "batch_size_unlabel", ":", "\n", "                ", "w", ",", "h", "=", "d_unlabel", "[", "0", "]", "[", "\"width\"", "]", ",", "d_unlabel", "[", "0", "]", "[", "\"height\"", "]", "\n", "unlabel_bucket_id", "=", "0", "if", "w", ">", "h", "else", "1", "\n", "unlabel_bucket", "=", "self", ".", "_unlabel_buckets", "[", "unlabel_bucket_id", "]", "\n", "unlabel_bucket", ".", "append", "(", "d_unlabel", "[", "0", "]", ")", "\n", "unlabel_buckets_key", "=", "self", ".", "_unlabel_buckets_key", "[", "unlabel_bucket_id", "]", "\n", "unlabel_buckets_key", ".", "append", "(", "d_unlabel", "[", "1", "]", ")", "\n", "\n", "", "if", "len", "(", "label_bucket_gan", ")", "!=", "self", ".", "batch_size_gan", ":", "\n", "                ", "w", ",", "h", "=", "d_gan", "[", "0", "]", "[", "\"width\"", "]", ",", "d_gan", "[", "0", "]", "[", "\"height\"", "]", "\n", "label_bucket_gan_id", "=", "0", "if", "w", ">", "h", "else", "1", "\n", "label_bucket_gan", "=", "self", ".", "_unlabel_buckets", "[", "unlabel_bucket_id", "]", "\n", "label_bucket_gan", ".", "append", "(", "d_unlabel", "[", "0", "]", ")", "\n", "label_bucket_gan_key", "=", "self", ".", "_unlabel_buckets_key", "[", "unlabel_bucket_id", "]", "\n", "label_bucket_gan_key", ".", "append", "(", "d_unlabel", "[", "1", "]", ")", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "# yield the batch of data until all buckets are full", "\n", "", "if", "(", "\n", "len", "(", "label_bucket", ")", "==", "self", ".", "batch_size_label", "\n", "and", "len", "(", "unlabel_bucket", ")", "==", "self", ".", "batch_size_unlabel", "and", "len", "(", "label_bucket_gan", ")", "==", "self", ".", "batch_size_gan", "\n", ")", ":", "\n", "# label_strong, label_weak, unlabed_strong, unlabled_weak", "\n", "                ", "yield", "(", "\n", "label_bucket", "[", ":", "]", ",", "\n", "label_buckets_key", "[", ":", "]", ",", "\n", "unlabel_bucket", "[", ":", "]", ",", "\n", "unlabel_buckets_key", "[", ":", "]", ",", "\n", "\n", "label_bucket_gan", "[", ":", "]", ",", "\n", "label_bucket_gan_key", "[", ":", "]", ",", "\n", "\n", "\n", ")", "\n", "del", "label_bucket", "[", ":", "]", "\n", "del", "label_buckets_key", "[", ":", "]", "\n", "del", "unlabel_bucket", "[", ":", "]", "\n", "del", "unlabel_buckets_key", "[", ":", "]", "\n", "del", "label_bucket_gan", "[", ":", "]", "\n", "del", "label_bucket_gan_key", "[", ":", "]", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.detection_utils.build_strong_augmentation": [[9, 47], ["logging.getLogger", "torchvision.Compose", "augmentation.append", "augmentation.append", "augmentation.append", "torchvision.Compose", "augmentation.append", "logging.getLogger.info", "torchvision.RandomApply", "torchvision.RandomGrayscale", "torchvision.RandomApply", "torchvision.ToTensor", "torchvision.RandomErasing", "torchvision.RandomErasing", "torchvision.RandomErasing", "torchvision.ToPILImage", "str", "torchvision.ColorJitter", "ubteacher.data.transforms.augmentation_impl.GaussianBlur"], "function", ["None"], ["def", "build_strong_augmentation", "(", "cfg", ",", "is_train", ")", ":", "\n", "    ", "\"\"\"\n    Create a list of :class:`Augmentation` from config.\n    Now it includes resizing and flipping.\n\n    Returns:\n        list[Augmentation]\n    \"\"\"", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "augmentation", "=", "[", "]", "\n", "if", "is_train", ":", "\n", "# This is simialr to SimCLR https://arxiv.org/abs/2002.05709", "\n", "        ", "augmentation", ".", "append", "(", "\n", "transforms", ".", "RandomApply", "(", "[", "transforms", ".", "ColorJitter", "(", "0.4", ",", "0.4", ",", "0.4", ",", "0.1", ")", "]", ",", "p", "=", "0.8", ")", "\n", ")", "\n", "augmentation", ".", "append", "(", "transforms", ".", "RandomGrayscale", "(", "p", "=", "0.2", ")", ")", "\n", "augmentation", ".", "append", "(", "transforms", ".", "RandomApply", "(", "[", "GaussianBlur", "(", "[", "0.1", ",", "2.0", "]", ")", "]", ",", "p", "=", "0.5", ")", ")", "\n", "\n", "randcrop_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "RandomErasing", "(", "\n", "p", "=", "0.7", ",", "scale", "=", "(", "0.05", ",", "0.2", ")", ",", "ratio", "=", "(", "0.3", ",", "3.3", ")", ",", "value", "=", "\"random\"", "\n", ")", ",", "\n", "transforms", ".", "RandomErasing", "(", "\n", "p", "=", "0.5", ",", "scale", "=", "(", "0.02", ",", "0.2", ")", ",", "ratio", "=", "(", "0.1", ",", "6", ")", ",", "value", "=", "\"random\"", "\n", ")", ",", "\n", "transforms", ".", "RandomErasing", "(", "\n", "p", "=", "0.3", ",", "scale", "=", "(", "0.02", ",", "0.2", ")", ",", "ratio", "=", "(", "0.05", ",", "8", ")", ",", "value", "=", "\"random\"", "\n", ")", ",", "\n", "transforms", ".", "ToPILImage", "(", ")", ",", "\n", "]", "\n", ")", "\n", "augmentation", ".", "append", "(", "randcrop_transform", ")", "\n", "\n", "logger", ".", "info", "(", "\"Augmentations used in training: \"", "+", "str", "(", "augmentation", ")", ")", "\n", "", "return", "transforms", ".", "Compose", "(", "augmentation", ")", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.divide_label_unlabel": [[48, 72], ["len", "int", "numpy.random.choice", "set", "range", "range", "len", "label_dicts.append", "unlabel_dicts.append"], "function", ["None"], ["def", "divide_label_unlabel", "(", "\n", "dataset_dicts", ",", "SupPercent", ",", "random_data_seed", ",", "random_data_seed_path", "\n", ")", ":", "\n", "    ", "num_all", "=", "len", "(", "dataset_dicts", ")", "\n", "num_label", "=", "int", "(", "SupPercent", "/", "100.0", "*", "num_all", ")", "\n", "\n", "# read from pre-generated data seed", "\n", "# with open(random_data_seed_path) as COCO_sup_file:", "\n", "#     coco_random_idx = json.load(COCO_sup_file)", "\n", "labeled_idx", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "num_all", ")", ",", "size", "=", "num_label", ",", "replace", "=", "False", ")", "\n", "# labeled_idx = np.array(coco_random_idx[str(SupPercent)][str(random_data_seed)])", "\n", "assert", "labeled_idx", ".", "shape", "[", "0", "]", "==", "num_label", ",", "\"Number of READ_DATA is mismatched.\"", "\n", "\n", "label_dicts", "=", "[", "]", "\n", "unlabel_dicts", "=", "[", "]", "\n", "labeled_idx", "=", "set", "(", "labeled_idx", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset_dicts", ")", ")", ":", "\n", "        ", "if", "i", "in", "labeled_idx", ":", "\n", "            ", "label_dicts", ".", "append", "(", "dataset_dicts", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "            ", "unlabel_dicts", ".", "append", "(", "dataset_dicts", "[", "i", "]", ")", "\n", "\n", "", "", "return", "label_dicts", ",", "unlabel_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_semisup_train_loader": [[75, 128], ["detectron2.data.build.get_detection_dataset_dicts", "build.divide_label_unlabel", "detectron2.data.common.DatasetFromList", "detectron2.data.common.MapDataset", "logging.getLogger", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "detectron2.data.build.build_batch_data_loader", "detectron2.data.dataset_mapper.DatasetMapper", "detectron2.data.samplers.TrainingSampler", "len", "detectron2.data.samplers.RepeatFactorTrainingSampler.repeat_factors_from_category_frequency", "detectron2.data.samplers.RepeatFactorTrainingSampler", "ValueError", "str", "str", "len"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.divide_label_unlabel"], ["", "def", "build_detection_semisup_train_loader", "(", "cfg", ",", "mapper", "=", "None", ")", ":", "\n", "\n", "    ", "dataset_dicts", "=", "get_detection_dataset_dicts", "(", "\n", "cfg", ".", "DATASETS", ".", "TRAIN", ",", "\n", "filter_empty", "=", "cfg", ".", "DATALOADER", ".", "FILTER_EMPTY_ANNOTATIONS", ",", "\n", "min_keypoints", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "MIN_KEYPOINTS_PER_IMAGE", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "\n", "else", "0", ",", "\n", "proposal_files", "=", "cfg", ".", "DATASETS", ".", "PROPOSAL_FILES_TRAIN", "\n", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "else", "None", ",", "\n", ")", "\n", "\n", "# Divide into labeled and unlabeled sets according to supervision percentage", "\n", "label_dicts", ",", "unlabel_dicts", "=", "divide_label_unlabel", "(", "\n", "dataset_dicts", ",", "\n", "cfg", ".", "DATALOADER", ".", "SUP_PERCENT", ",", "\n", "cfg", ".", "DATALOADER", ".", "RANDOM_DATA_SEED", ",", "\n", "cfg", ".", "DATALOADER", ".", "RANDOM_DATA_SEED_PATH", ",", "\n", ")", "\n", "\n", "dataset", "=", "DatasetFromList", "(", "label_dicts", ",", "copy", "=", "False", ")", "\n", "\n", "if", "mapper", "is", "None", ":", "\n", "        ", "mapper", "=", "DatasetMapper", "(", "cfg", ",", "True", ")", "\n", "", "dataset", "=", "MapDataset", "(", "dataset", ",", "mapper", ")", "\n", "\n", "sampler_name", "=", "cfg", ".", "DATALOADER", ".", "SAMPLER_TRAIN", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Using training sampler {}\"", ".", "format", "(", "sampler_name", ")", ")", "\n", "\n", "if", "sampler_name", "==", "\"TrainingSampler\"", ":", "\n", "        ", "sampler", "=", "TrainingSampler", "(", "len", "(", "dataset", ")", ")", "\n", "", "elif", "sampler_name", "==", "\"RepeatFactorTrainingSampler\"", ":", "\n", "        ", "repeat_factors", "=", "(", "\n", "RepeatFactorTrainingSampler", ".", "repeat_factors_from_category_frequency", "(", "\n", "label_dicts", ",", "cfg", ".", "DATALOADER", ".", "REPEAT_THRESHOLD", "\n", ")", "\n", ")", "\n", "sampler", "=", "RepeatFactorTrainingSampler", "(", "repeat_factors", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown training sampler: {}\"", ".", "format", "(", "sampler_name", ")", ")", "\n", "\n", "# list num of labeled and unlabeled", "\n", "", "logger", ".", "info", "(", "\"\bNumber of training samples \"", "+", "str", "(", "len", "(", "dataset", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Supervision percentage \"", "+", "str", "(", "cfg", ".", "DATALOADER", ".", "SUP_PERCENT", ")", ")", "\n", "\n", "return", "build_batch_data_loader", "(", "\n", "dataset", ",", "\n", "sampler", ",", "\n", "cfg", ".", "SOLVER", ".", "IMS_PER_BATCH", ",", "\n", "aspect_ratio_grouping", "=", "cfg", ".", "DATALOADER", ".", "ASPECT_RATIO_GROUPING", ",", "\n", "num_workers", "=", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_test_loader": [[132, 161], ["build.get_detection_dataset_dicts_test", "detectron2.data.common.DatasetFromList", "detectron2.data.common.MapDataset", "detectron2.data.samplers.InferenceSampler", "torch.utils.data.sampler.BatchSampler", "torch.utils.data.DataLoader", "detectron2.data.dataset_mapper.DatasetMapper", "len", "list().index", "list"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.get_detection_dataset_dicts_test"], ["", "def", "build_detection_test_loader", "(", "cfg", ",", "dataset_name", ",", "mapper", "=", "None", ")", ":", "\n", "    ", "dataset_dicts", "=", "get_detection_dataset_dicts_test", "(", "\n", "[", "dataset_name", "]", ",", "\n", "filter_empty", "=", "False", ",", "\n", "proposal_files", "=", "[", "\n", "cfg", ".", "DATASETS", ".", "PROPOSAL_FILES_TEST", "[", "\n", "list", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", ".", "index", "(", "dataset_name", ")", "\n", "]", "\n", "]", "\n", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "else", "None", ",", "\n", ")", "\n", "import", "pdb", "\n", "\n", "dataset", "=", "DatasetFromList", "(", "dataset_dicts", ")", "\n", "if", "mapper", "is", "None", ":", "\n", "        ", "mapper", "=", "DatasetMapper", "(", "cfg", ",", "False", ")", "\n", "", "dataset", "=", "MapDataset", "(", "dataset", ",", "mapper", ")", "\n", "# pdb.set_trace()", "\n", "sampler", "=", "InferenceSampler", "(", "len", "(", "dataset", ")", ")", "\n", "batch_sampler", "=", "torch", ".", "utils", ".", "data", ".", "sampler", ".", "BatchSampler", "(", "sampler", ",", "1", ",", "drop_last", "=", "False", ")", "\n", "\n", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "\n", "num_workers", "=", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "collate_fn", "=", "trivial_batch_collator", ",", "\n", ")", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_semisup_train_loader_two_crops": [[164, 245], ["detectron2.data.common.DatasetFromList", "detectron2.data.common.DatasetFromList", "detectron2.data.common.MapDataset", "detectron2.data.common.MapDataset", "logging.getLogger", "logging.getLogger.info", "build.build_semisup_batch_data_loader_two_crop", "detectron2.data.build.get_detection_dataset_dicts", "detectron2.data.build.get_detection_dataset_dicts", "detectron2.data.build.get_detection_dataset_dicts", "build.divide_label_unlabel", "detectron2.data.dataset_mapper.DatasetMapper", "detectron2.data.samplers.TrainingSampler", "detectron2.data.samplers.TrainingSampler", "len", "len", "NotImplementedError", "ValueError"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_semisup_batch_data_loader_two_crop", "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.divide_label_unlabel"], ["", "def", "build_detection_semisup_train_loader_two_crops", "(", "cfg", ",", "mapper", "=", "None", ")", ":", "\n", "    ", "if", "cfg", ".", "DATASETS", ".", "CROSS_DATASET", ":", "# cross-dataset (e.g., coco-additional)", "\n", "        ", "label_dicts", "=", "get_detection_dataset_dicts", "(", "\n", "cfg", ".", "DATASETS", ".", "TRAIN_LABEL", ",", "\n", "filter_empty", "=", "cfg", ".", "DATALOADER", ".", "FILTER_EMPTY_ANNOTATIONS", ",", "\n", "min_keypoints", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "MIN_KEYPOINTS_PER_IMAGE", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "\n", "else", "0", ",", "\n", "proposal_files", "=", "cfg", ".", "DATASETS", ".", "PROPOSAL_FILES_TRAIN", "\n", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "else", "None", ",", "\n", ")", "\n", "\n", "\n", "\n", "unlabel_dicts", "=", "get_detection_dataset_dicts", "(", "\n", "cfg", ".", "DATASETS", ".", "TRAIN_UNLABEL", ",", "\n", "filter_empty", "=", "False", ",", "\n", "min_keypoints", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "MIN_KEYPOINTS_PER_IMAGE", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "\n", "else", "0", ",", "\n", "proposal_files", "=", "cfg", ".", "DATASETS", ".", "PROPOSAL_FILES_TRAIN", "\n", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "else", "None", ",", "\n", ")", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "", "else", ":", "# different degree of supervision (e.g., COCO-supervision)", "\n", "        ", "dataset_dicts", "=", "get_detection_dataset_dicts", "(", "\n", "cfg", ".", "DATASETS", ".", "TRAIN", ",", "\n", "filter_empty", "=", "cfg", ".", "DATALOADER", ".", "FILTER_EMPTY_ANNOTATIONS", ",", "\n", "min_keypoints", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "MIN_KEYPOINTS_PER_IMAGE", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "\n", "else", "0", ",", "\n", "proposal_files", "=", "cfg", ".", "DATASETS", ".", "PROPOSAL_FILES_TRAIN", "\n", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "else", "None", ",", "\n", ")", "\n", "\n", "# Divide into labeled and unlabeled sets according to supervision percentage", "\n", "label_dicts", ",", "unlabel_dicts", "=", "divide_label_unlabel", "(", "\n", "dataset_dicts", ",", "\n", "cfg", ".", "DATALOADER", ".", "SUP_PERCENT", ",", "\n", "cfg", ".", "DATALOADER", ".", "RANDOM_DATA_SEED", ",", "\n", "cfg", ".", "DATALOADER", ".", "RANDOM_DATA_SEED_PATH", ",", "\n", ")", "\n", "\n", "", "label_dataset", "=", "DatasetFromList", "(", "label_dicts", ",", "copy", "=", "False", ")", "\n", "# exclude the labeled set from unlabeled dataset", "\n", "unlabel_dataset", "=", "DatasetFromList", "(", "unlabel_dicts", ",", "copy", "=", "False", ")", "\n", "# include the labeled set in unlabel dataset", "\n", "# unlabel_dataset = DatasetFromList(dataset_dicts, copy=False)", "\n", "\n", "if", "mapper", "is", "None", ":", "\n", "        ", "mapper", "=", "DatasetMapper", "(", "cfg", ",", "True", ")", "\n", "", "label_dataset", "=", "MapDataset", "(", "label_dataset", ",", "mapper", ")", "\n", "unlabel_dataset", "=", "MapDataset", "(", "unlabel_dataset", ",", "mapper", ")", "\n", "\n", "sampler_name", "=", "cfg", ".", "DATALOADER", ".", "SAMPLER_TRAIN", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Using training sampler {}\"", ".", "format", "(", "sampler_name", ")", ")", "\n", "if", "sampler_name", "==", "\"TrainingSampler\"", ":", "\n", "        ", "label_sampler", "=", "TrainingSampler", "(", "len", "(", "label_dataset", ")", ")", "\n", "unlabel_sampler", "=", "TrainingSampler", "(", "len", "(", "unlabel_dataset", ")", ")", "\n", "", "elif", "sampler_name", "==", "\"RepeatFactorTrainingSampler\"", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"{} not yet supported.\"", ".", "format", "(", "sampler_name", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown training sampler: {}\"", ".", "format", "(", "sampler_name", ")", ")", "\n", "", "return", "build_semisup_batch_data_loader_two_crop", "(", "\n", "(", "label_dataset", ",", "unlabel_dataset", ")", ",", "\n", "(", "label_sampler", ",", "unlabel_sampler", ")", ",", "\n", "cfg", ".", "SOLVER", ".", "IMG_PER_BATCH_LABEL", ",", "\n", "cfg", ".", "SOLVER", ".", "IMG_PER_BATCH_UNLABEL", ",", "\n", "aspect_ratio_grouping", "=", "cfg", ".", "DATALOADER", ".", "ASPECT_RATIO_GROUPING", ",", "\n", "num_workers", "=", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_detection_semisup_train_loader_three_crops": [[248, 337], ["detectron2.data.common.DatasetFromList", "detectron2.data.common.DatasetFromList", "detectron2.data.common.DatasetFromList", "detectron2.data.common.MapDataset", "detectron2.data.common.MapDataset", "detectron2.data.common.MapDataset", "logging.getLogger", "logging.getLogger.info", "build.build_semisup_batch_data_loader_three_crop", "detectron2.data.build.get_detection_dataset_dicts", "detectron2.data.build.get_detection_dataset_dicts", "detectron2.data.build.get_detection_dataset_dicts", "detectron2.data.build.get_detection_dataset_dicts", "build.divide_label_unlabel", "detectron2.data.dataset_mapper.DatasetMapper", "detectron2.data.samplers.TrainingSampler", "detectron2.data.samplers.TrainingSampler", "detectron2.data.samplers.TrainingSampler", "len", "len", "len", "NotImplementedError", "ValueError"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_semisup_batch_data_loader_three_crop", "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.divide_label_unlabel"], ["", "def", "build_detection_semisup_train_loader_three_crops", "(", "cfg", ",", "mapper", "=", "None", ")", ":", "\n", "    ", "if", "cfg", ".", "DATASETS", ".", "CROSS_DATASET", ":", "# cross-dataset (e.g., coco-additional)", "\n", "        ", "label_dicts", "=", "get_detection_dataset_dicts", "(", "\n", "cfg", ".", "DATASETS", ".", "TRAIN_LABEL", ",", "\n", "filter_empty", "=", "cfg", ".", "DATALOADER", ".", "FILTER_EMPTY_ANNOTATIONS", ",", "\n", "min_keypoints", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "MIN_KEYPOINTS_PER_IMAGE", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "\n", "else", "0", ",", "\n", "proposal_files", "=", "cfg", ".", "DATASETS", ".", "PROPOSAL_FILES_TRAIN", "\n", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "else", "None", ",", "\n", ")", "\n", "\n", "gan_label_dicts", "=", "get_detection_dataset_dicts", "(", "\n", "cfg", ".", "DATASETS", ".", "TRAIN_LABEL_GAN", ",", "\n", "filter_empty", "=", "cfg", ".", "DATALOADER", ".", "FILTER_EMPTY_ANNOTATIONS", ",", "\n", "min_keypoints", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "MIN_KEYPOINTS_PER_IMAGE", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "\n", "else", "0", ",", "\n", "proposal_files", "=", "cfg", ".", "DATASETS", ".", "PROPOSAL_FILES_TRAIN", "\n", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "else", "None", ",", "\n", ")", "\n", "\n", "unlabel_dicts", "=", "get_detection_dataset_dicts", "(", "\n", "cfg", ".", "DATASETS", ".", "TRAIN_UNLABEL", ",", "\n", "filter_empty", "=", "False", ",", "\n", "min_keypoints", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "MIN_KEYPOINTS_PER_IMAGE", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "\n", "else", "0", ",", "\n", "proposal_files", "=", "cfg", ".", "DATASETS", ".", "PROPOSAL_FILES_TRAIN", "\n", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "else", "None", ",", "\n", ")", "\n", "\n", "", "else", ":", "# different degree of supervision (e.g., COCO-supervision)", "\n", "        ", "dataset_dicts", "=", "get_detection_dataset_dicts", "(", "\n", "cfg", ".", "DATASETS", ".", "TRAIN", ",", "\n", "filter_empty", "=", "cfg", ".", "DATALOADER", ".", "FILTER_EMPTY_ANNOTATIONS", ",", "\n", "min_keypoints", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "MIN_KEYPOINTS_PER_IMAGE", "\n", "if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "\n", "else", "0", ",", "\n", "proposal_files", "=", "cfg", ".", "DATASETS", ".", "PROPOSAL_FILES_TRAIN", "\n", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "else", "None", ",", "\n", ")", "\n", "\n", "# Divide into labeled and unlabeled sets according to supervision percentage", "\n", "label_dicts", ",", "unlabel_dicts", "=", "divide_label_unlabel", "(", "\n", "dataset_dicts", ",", "\n", "cfg", ".", "DATALOADER", ".", "SUP_PERCENT", ",", "\n", "cfg", ".", "DATALOADER", ".", "RANDOM_DATA_SEED", ",", "\n", "cfg", ".", "DATALOADER", ".", "RANDOM_DATA_SEED_PATH", ",", "\n", ")", "\n", "\n", "", "label_dataset", "=", "DatasetFromList", "(", "label_dicts", ",", "copy", "=", "False", ")", "\n", "gan_label_dataset", "=", "DatasetFromList", "(", "gan_label_dicts", ",", "copy", "=", "False", ")", "\n", "# exclude the labeled set from unlabeled dataset", "\n", "unlabel_dataset", "=", "DatasetFromList", "(", "unlabel_dicts", ",", "copy", "=", "False", ")", "\n", "# include the labeled set in unlabel dataset", "\n", "# unlabel_dataset = DatasetFromList(dataset_dicts, copy=False)", "\n", "\n", "if", "mapper", "is", "None", ":", "\n", "        ", "mapper", "=", "DatasetMapper", "(", "cfg", ",", "True", ")", "\n", "", "label_dataset", "=", "MapDataset", "(", "label_dataset", ",", "mapper", ")", "\n", "gan_label_dataset", "=", "MapDataset", "(", "gan_label_dataset", ",", "mapper", ")", "\n", "unlabel_dataset", "=", "MapDataset", "(", "unlabel_dataset", ",", "mapper", ")", "\n", "\n", "sampler_name", "=", "cfg", ".", "DATALOADER", ".", "SAMPLER_TRAIN", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Using training sampler {}\"", ".", "format", "(", "sampler_name", ")", ")", "\n", "if", "sampler_name", "==", "\"TrainingSampler\"", ":", "\n", "        ", "label_sampler", "=", "TrainingSampler", "(", "len", "(", "label_dataset", ")", ")", "\n", "unlabel_sampler", "=", "TrainingSampler", "(", "len", "(", "unlabel_dataset", ")", ")", "\n", "gan_sampler", "=", "TrainingSampler", "(", "len", "(", "gan_label_dataset", ")", ")", "\n", "\n", "", "elif", "sampler_name", "==", "\"RepeatFactorTrainingSampler\"", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"{} not yet supported.\"", ".", "format", "(", "sampler_name", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown training sampler: {}\"", ".", "format", "(", "sampler_name", ")", ")", "\n", "", "return", "build_semisup_batch_data_loader_three_crop", "(", "\n", "(", "label_dataset", ",", "unlabel_dataset", ",", "gan_label_dataset", ")", ",", "\n", "(", "label_sampler", ",", "unlabel_sampler", ",", "gan_sampler", ")", ",", "\n", "\n", "cfg", ".", "SOLVER", ".", "IMG_PER_BATCH_LABEL", ",", "\n", "cfg", ".", "SOLVER", ".", "IMG_PER_BATCH_UNLABEL", ",", "\n", "cfg", ".", "SOLVER", ".", "IMG_PER_BATCH_GAN", ",", "\n", "aspect_ratio_grouping", "=", "cfg", ".", "DATALOADER", ".", "ASPECT_RATIO_GROUPING", ",", "\n", "num_workers", "=", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_semisup_batch_data_loader_two_crop": [[340, 402], ["detectron2.utils.comm.get_world_size", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "ubteacher.data.common.AspectRatioGroupedSemiSupDatasetTwoCrop", "NotImplementedError", "operator.itemgetter", "operator.itemgetter"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size"], ["", "def", "build_semisup_batch_data_loader_two_crop", "(", "\n", "dataset", ",", "\n", "sampler", ",", "\n", "total_batch_size_label", ",", "\n", "total_batch_size_unlabel", ",", "\n", "*", ",", "\n", "aspect_ratio_grouping", "=", "False", ",", "\n", "num_workers", "=", "0", "\n", ")", ":", "\n", "    ", "world_size", "=", "get_world_size", "(", ")", "\n", "assert", "(", "\n", "total_batch_size_label", ">", "0", "and", "total_batch_size_label", "%", "world_size", "==", "0", "\n", ")", ",", "\"Total label batch size ({}) must be divisible by the number of gpus ({}).\"", ".", "format", "(", "\n", "total_batch_size_label", ",", "world_size", "\n", ")", "\n", "\n", "assert", "(", "\n", "total_batch_size_unlabel", ">", "0", "and", "total_batch_size_unlabel", "%", "world_size", "==", "0", "\n", ")", ",", "\"Total unlabel batch size ({}) must be divisible by the number of gpus ({}).\"", ".", "format", "(", "\n", "total_batch_size_label", ",", "world_size", "\n", ")", "\n", "\n", "batch_size_label", "=", "total_batch_size_label", "//", "world_size", "\n", "batch_size_unlabel", "=", "total_batch_size_unlabel", "//", "world_size", "\n", "\n", "label_dataset", ",", "unlabel_dataset", "=", "dataset", "\n", "\n", "\n", "\n", "\n", "label_sampler", ",", "unlabel_sampler", "=", "sampler", "\n", "\n", "if", "aspect_ratio_grouping", ":", "\n", "        ", "label_data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "label_dataset", ",", "\n", "sampler", "=", "label_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_sampler", "=", "None", ",", "\n", "collate_fn", "=", "operator", ".", "itemgetter", "(", "\n", "0", "\n", ")", ",", "# don't batch, but yield individual elements", "\n", "worker_init_fn", "=", "worker_init_reset_seed", ",", "\n", ")", "# yield individual mapped dict", "\n", "unlabel_data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "unlabel_dataset", ",", "\n", "sampler", "=", "unlabel_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_sampler", "=", "None", ",", "\n", "collate_fn", "=", "operator", ".", "itemgetter", "(", "\n", "0", "\n", ")", ",", "# don't batch, but yield individual elements", "\n", "worker_init_fn", "=", "worker_init_reset_seed", ",", "\n", ")", "# yield individual mapped dict", "\n", "return", "AspectRatioGroupedSemiSupDatasetTwoCrop", "(", "\n", "(", "label_data_loader", ",", "unlabel_data_loader", ")", ",", "\n", "(", "batch_size_label", ",", "batch_size_unlabel", ")", ",", "\n", ")", "\n", "\n", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"ASPECT_RATIO_GROUPING = False is not supported yet\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.build_semisup_batch_data_loader_three_crop": [[405, 492], ["detectron2.utils.comm.get_world_size", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "ubteacher.data.common.AspectRatioGroupedSemiSupDatasetThreeCrop", "NotImplementedError", "operator.itemgetter", "operator.itemgetter", "operator.itemgetter"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size"], ["", "", "def", "build_semisup_batch_data_loader_three_crop", "(", "\n", "dataset", ",", "\n", "sampler", ",", "\n", "total_batch_size_label", ",", "\n", "total_batch_size_unlabel", ",", "\n", "total_batch_size_gan", ",", "\n", "*", ",", "\n", "aspect_ratio_grouping", "=", "False", ",", "\n", "num_workers", "=", "0", "\n", ")", ":", "\n", "    ", "world_size", "=", "get_world_size", "(", ")", "\n", "assert", "(", "\n", "total_batch_size_label", ">", "0", "and", "total_batch_size_label", "%", "world_size", "==", "0", "\n", ")", ",", "\"Total label batch size ({}) must be divisible by the number of gpus ({}).\"", ".", "format", "(", "\n", "total_batch_size_label", ",", "world_size", "\n", ")", "\n", "\n", "assert", "(", "\n", "total_batch_size_unlabel", ">", "0", "and", "total_batch_size_unlabel", "%", "world_size", "==", "0", "\n", ")", ",", "\"Total unlabel batch size ({}) must be divisible by the number of gpus ({}).\"", ".", "format", "(", "\n", "total_batch_size_label", ",", "world_size", "\n", ")", "\n", "\n", "assert", "(", "\n", "total_batch_size_gan", ">", "0", "and", "total_batch_size_gan", "%", "world_size", "==", "0", "\n", ")", ",", "\"Total unlabel batch size ({}) must be divisible by the number of gpus ({}).\"", ".", "format", "(", "\n", "total_batch_size_gan", ",", "world_size", "\n", ")", "\n", "\n", "\n", "\n", "\n", "batch_size_label", "=", "total_batch_size_label", "//", "world_size", "\n", "batch_size_unlabel", "=", "total_batch_size_unlabel", "//", "world_size", "\n", "batch_size_gan", "=", "total_batch_size_gan", "//", "world_size", "\n", "\n", "label_dataset", ",", "unlabel_dataset", ",", "gan_dataset", "=", "dataset", "\n", "\n", "\n", "\n", "\n", "label_sampler", ",", "unlabel_sampler", ",", "gan_sampler", "=", "sampler", "\n", "\n", "if", "aspect_ratio_grouping", ":", "\n", "        ", "label_data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "label_dataset", ",", "\n", "sampler", "=", "label_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_sampler", "=", "None", ",", "\n", "collate_fn", "=", "operator", ".", "itemgetter", "(", "\n", "0", "\n", ")", ",", "# don't batch, but yield individual elements", "\n", "worker_init_fn", "=", "worker_init_reset_seed", ",", "\n", ")", "# yield individual mapped dict", "\n", "unlabel_data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "unlabel_dataset", ",", "\n", "sampler", "=", "unlabel_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_sampler", "=", "None", ",", "\n", "collate_fn", "=", "operator", ".", "itemgetter", "(", "\n", "0", "\n", ")", ",", "# don't batch, but yield individual elements", "\n", "worker_init_fn", "=", "worker_init_reset_seed", ",", "\n", ")", "# yield individual mapped dict", "\n", "\n", "gan_data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "gan_dataset", ",", "\n", "sampler", "=", "gan_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "batch_sampler", "=", "None", ",", "\n", "collate_fn", "=", "operator", ".", "itemgetter", "(", "\n", "0", "\n", ")", ",", "# don't batch, but yield individual elements", "\n", "worker_init_fn", "=", "worker_init_reset_seed", ",", "\n", ")", "# yield individual mapped dict", "\n", "\n", "\n", "return", "AspectRatioGroupedSemiSupDatasetThreeCrop", "(", "\n", "(", "label_data_loader", ",", "unlabel_data_loader", ",", "gan_data_loader", ")", ",", "\n", "(", "batch_size_label", ",", "batch_size_unlabel", ",", "batch_size_gan", ")", ",", "\n", "\n", ")", "\n", "\n", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"ASPECT_RATIO_GROUPING = False is not supported yet\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.get_detection_dataset_dicts_test": [[498, 546], ["isinstance", "len", "zip", "list", "len", "detectron2.data.catalog.DatasetCatalog.get", "len", "itertools.chain.from_iterable", "detectron2.data.build.filter_images_with_only_crowd_annotations", "detectron2.data.build.filter_images_with_few_keypoints", "len", "len", "build.load_proposals_into_dataset", "detectron2.data.detection_utils.check_metadata_consistency", "detectron2.data.build.print_instances_class_histogram", "zip", "detectron2.data.catalog.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.build.load_proposals_into_dataset"], ["", "", "def", "get_detection_dataset_dicts_test", "(", "names", ",", "filter_empty", "=", "True", ",", "min_keypoints", "=", "0", ",", "proposal_files", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Load and prepare dataset dicts for instance detection/segmentation and semantic segmentation.\n\n    Args:\n        names (str or list[str]): a dataset name or a list of dataset names\n        filter_empty (bool): whether to filter out images without instance annotations\n        min_keypoints (int): filter out images with fewer keypoints than\n            `min_keypoints`. Set to 0 to do nothing.\n        proposal_files (list[str]): if given, a list of object proposal files\n            that match each dataset in `names`.\n\n    Returns:\n        list[dict]: a list of dicts following the standard dataset dict format.\n    \"\"\"", "\n", "if", "isinstance", "(", "names", ",", "str", ")", ":", "\n", "        ", "names", "=", "[", "names", "]", "\n", "", "assert", "len", "(", "names", ")", ",", "names", "\n", "dataset_dicts", "=", "[", "DatasetCatalog", ".", "get", "(", "dataset_name", ")", "for", "dataset_name", "in", "names", "]", "\n", "for", "dataset_name", ",", "dicts", "in", "zip", "(", "names", ",", "dataset_dicts", ")", ":", "\n", "        ", "assert", "len", "(", "dicts", ")", ",", "\"Dataset '{}' is empty!\"", ".", "format", "(", "dataset_name", ")", "\n", "\n", "", "if", "proposal_files", "is", "not", "None", ":", "\n", "        ", "assert", "len", "(", "names", ")", "==", "len", "(", "proposal_files", ")", "\n", "# load precomputed proposals from proposal files", "\n", "dataset_dicts", "=", "[", "\n", "load_proposals_into_dataset", "(", "dataset_i_dicts", ",", "proposal_file", ")", "\n", "for", "dataset_i_dicts", ",", "proposal_file", "in", "zip", "(", "dataset_dicts", ",", "proposal_files", ")", "\n", "]", "\n", "\n", "", "dataset_dicts", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "dataset_dicts", ")", ")", "\n", "\n", "has_instances", "=", "\"annotations\"", "in", "dataset_dicts", "[", "0", "]", "\n", "if", "filter_empty", "and", "has_instances", ":", "\n", "        ", "dataset_dicts", "=", "filter_images_with_only_crowd_annotations", "(", "dataset_dicts", ")", "\n", "", "if", "min_keypoints", ">", "0", "and", "has_instances", ":", "\n", "        ", "dataset_dicts", "=", "filter_images_with_few_keypoints", "(", "dataset_dicts", ",", "min_keypoints", ")", "\n", "\n", "", "if", "has_instances", ":", "\n", "        ", "try", ":", "\n", "            ", "class_names", "=", "MetadataCatalog", ".", "get", "(", "names", "[", "0", "]", ")", ".", "thing_classes", "\n", "check_metadata_consistency", "(", "\"thing_classes\"", ",", "names", ")", "\n", "print_instances_class_histogram", "(", "dataset_dicts", ",", "class_names", ")", "\n", "", "except", "AttributeError", ":", "# class names are not available for this dataset", "\n", "            ", "pass", "\n", "\n", "", "", "assert", "len", "(", "dataset_dicts", ")", ",", "\"No valid data found in {}.\"", ".", "format", "(", "\",\"", ".", "join", "(", "names", ")", ")", "\n", "return", "dataset_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.build.load_proposals_into_dataset": [[547, 600], ["logging.getLogger", "logging.getLogger.info", "set", "detectron2.utils.file_io.PathManager.open", "pickle.load", "str", "detectron2.structures.BoxMode", "pickle.load.pop", "str", "enumerate", "str", "str"], "function", ["None"], ["", "def", "load_proposals_into_dataset", "(", "dataset_dicts", ",", "proposal_file", ")", ":", "\n", "    ", "\"\"\"\n    Load precomputed object proposals into the dataset.\n\n    The proposal file should be a pickled dict with the following keys:\n\n    - \"ids\": list[int] or list[str], the image ids\n    - \"boxes\": list[np.ndarray], each is an Nx4 array of boxes corresponding to the image id\n    - \"objectness_logits\": list[np.ndarray], each is an N sized array of objectness scores\n      corresponding to the boxes.\n    - \"bbox_mode\": the BoxMode of the boxes array. Defaults to ``BoxMode.XYXY_ABS``.\n\n    Args:\n        dataset_dicts (list[dict]): annotations in Detectron2 Dataset format.\n        proposal_file (str): file path of pre-computed proposals, in pkl format.\n\n    Returns:\n        list[dict]: the same format as dataset_dicts, but added proposal field.\n    \"\"\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Loading proposals from: {}\"", ".", "format", "(", "proposal_file", ")", ")", "\n", "\n", "with", "PathManager", ".", "open", "(", "proposal_file", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "proposals", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "\"latin1\"", ")", "\n", "\n", "# Rename the key names in D1 proposal files", "\n", "", "rename_keys", "=", "{", "\"indexes\"", ":", "\"ids\"", ",", "\"scores\"", ":", "\"objectness_logits\"", "}", "\n", "for", "key", "in", "rename_keys", ":", "\n", "        ", "if", "key", "in", "proposals", ":", "\n", "            ", "proposals", "[", "rename_keys", "[", "key", "]", "]", "=", "proposals", ".", "pop", "(", "key", ")", "\n", "", "", "import", "pdb", "\n", "# pdb.set_trace()", "\n", "# Fetch the indexes of all proposals that are in the dataset", "\n", "# Convert image_id to str since they could be int.", "\n", "img_ids", "=", "set", "(", "{", "str", "(", "record", "[", "\"image_id\"", "]", ")", "for", "record", "in", "dataset_dicts", "}", ")", "\n", "id_to_index", "=", "{", "str", "(", "id", ")", ":", "i", "for", "i", ",", "id", "in", "enumerate", "(", "proposals", "[", "\"ids\"", "]", ")", "if", "str", "(", "id", ")", "in", "img_ids", "}", "\n", "# pdb.set_trace()", "\n", "# Assuming default bbox_mode of precomputed proposals are 'XYXY_ABS'", "\n", "bbox_mode", "=", "BoxMode", "(", "proposals", "[", "\"bbox_mode\"", "]", ")", "if", "\"bbox_mode\"", "in", "proposals", "else", "BoxMode", ".", "XYXY_ABS", "\n", "\n", "for", "record", "in", "dataset_dicts", ":", "\n", "# Get the index of the proposal", "\n", "        ", "i", "=", "id_to_index", "[", "str", "(", "record", "[", "\"image_id\"", "]", ")", "]", "\n", "\n", "boxes", "=", "proposals", "[", "\"boxes\"", "]", "[", "i", "]", "\n", "objectness_logits", "=", "proposals", "[", "\"objectness_logits\"", "]", "[", "i", "]", "\n", "# Sort the proposals in descending order of the scores", "\n", "# inds = objectness_logits.argsort()[::-1]", "\n", "record", "[", "\"proposal_boxes\"", "]", "=", "boxes", "\n", "record", "[", "\"proposal_objectness_logits\"", "]", "=", "objectness_logits", "\n", "record", "[", "\"proposal_bbox_mode\"", "]", "=", "bbox_mode", "\n", "# pdb.set_trace()", "\n", "", "return", "dataset_dicts", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.dataset_mapper.DatasetMapperTwoCropSeparate.__init__": [[35, 72], ["detectron2.build_augmentation", "detectron2.build_augmentation", "ubteacher.data.detection_utils.build_strong_augmentation", "dataset_mapper.DatasetMapperTwoCropSeparate.augmentation.insert", "logging.getLogger().info", "detectron2.create_keypoint_hflip_indices", "detectron2.create_keypoint_hflip_indices", "detectron2.RandomCrop", "detectron2.RandomCrop", "logging.getLogger", "str"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.data.detection_utils.build_strong_augmentation"], ["def", "__init__", "(", "self", ",", "cfg", ",", "is_train", "=", "True", ")", ":", "\n", "        ", "self", ".", "augmentation", "=", "utils", ".", "build_augmentation", "(", "cfg", ",", "is_train", ")", "\n", "# include crop into self.augmentation", "\n", "if", "cfg", ".", "INPUT", ".", "CROP", ".", "ENABLED", "and", "is_train", ":", "\n", "            ", "self", ".", "augmentation", ".", "insert", "(", "\n", "0", ",", "T", ".", "RandomCrop", "(", "cfg", ".", "INPUT", ".", "CROP", ".", "TYPE", ",", "cfg", ".", "INPUT", ".", "CROP", ".", "SIZE", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "__name__", ")", ".", "info", "(", "\n", "\"Cropping used in training: \"", "+", "str", "(", "self", ".", "augmentation", "[", "0", "]", ")", "\n", ")", "\n", "self", ".", "compute_tight_boxes", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "compute_tight_boxes", "=", "False", "\n", "", "self", ".", "strong_augmentation", "=", "build_strong_augmentation", "(", "cfg", ",", "is_train", ")", "\n", "\n", "# fmt: off", "\n", "self", ".", "img_format", "=", "cfg", ".", "INPUT", ".", "FORMAT", "\n", "self", ".", "mask_on", "=", "cfg", ".", "MODEL", ".", "MASK_ON", "\n", "self", ".", "mask_format", "=", "cfg", ".", "INPUT", ".", "MASK_FORMAT", "\n", "self", ".", "keypoint_on", "=", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "\n", "self", ".", "load_proposals", "=", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "# fmt: on", "\n", "if", "self", ".", "keypoint_on", "and", "is_train", ":", "\n", "            ", "self", ".", "keypoint_hflip_indices", "=", "utils", ".", "create_keypoint_hflip_indices", "(", "\n", "cfg", ".", "DATASETS", ".", "TRAIN", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "keypoint_hflip_indices", "=", "None", "\n", "\n", "", "if", "self", ".", "load_proposals", ":", "\n", "            ", "self", ".", "proposal_min_box_size", "=", "cfg", ".", "MODEL", ".", "PROPOSAL_GENERATOR", ".", "MIN_SIZE", "\n", "self", ".", "proposal_topk", "=", "(", "\n", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TRAIN", "\n", "if", "is_train", "\n", "else", "cfg", ".", "DATASETS", ".", "PRECOMPUTED_PROPOSAL_TOPK_TEST", "\n", ")", "\n", "", "self", ".", "is_train", "=", "is_train", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.data.dataset_mapper.DatasetMapperTwoCropSeparate.__call__": [[73, 158], ["copy.deepcopy", "detectron2.read_image", "detectron2.read_image", "detectron2.check_image_size", "detectron2.check_image_size", "detectron2.StandardAugInput", "detectron2.StandardAugInput", "detectron2.StandardAugInput.apply_augmentations", "PIL.Image.fromarray", "numpy.array", "torch.as_tensor", "copy.deepcopy", "torch.as_tensor", "detectron2.read_image().squeeze", "detectron2.read_image().squeeze", "torch.as_tensor", "detectron2.transform_proposals", "detectron2.transform_proposals", "copy.deepcopy.pop", "copy.deepcopy.pop", "detectron2.annotations_to_instances", "detectron2.annotations_to_instances", "detectron2.filter_empty_instances", "detectron2.filter_empty_instances", "image_weak_aug.astype", "dataset_mapper.DatasetMapperTwoCropSeparate.strong_augmentation", "numpy.ascontiguousarray", "numpy.ascontiguousarray", "dataset_dict[].size", "dataset_dict_key[].size", "dataset_dict[].size", "dataset_dict_key[].size", "detectron2.read_image().squeeze.astype", "detectron2.transform_instance_annotations", "detectron2.transform_instance_annotations", "detectron2.annotations_to_instances.has", "detectron2.annotations_to_instances.gt_masks.get_bounding_boxes", "numpy.array.transpose", "image_weak_aug.transpose", "detectron2.read_image", "detectron2.read_image", "anno.pop", "anno.pop", "copy.deepcopy.pop", "copy.deepcopy.pop", "obj.get"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "dataset_dict", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_dict (dict): Metadata of one image, in Detectron2 Dataset format.\n\n        Returns:\n            dict: a format that builtin models in detectron2 accept\n        \"\"\"", "\n", "dataset_dict", "=", "copy", ".", "deepcopy", "(", "dataset_dict", ")", "# it will be modified by code below", "\n", "image", "=", "utils", ".", "read_image", "(", "dataset_dict", "[", "\"file_name\"", "]", ",", "format", "=", "self", ".", "img_format", ")", "\n", "utils", ".", "check_image_size", "(", "dataset_dict", ",", "image", ")", "\n", "\n", "if", "\"sem_seg_file_name\"", "in", "dataset_dict", ":", "\n", "            ", "sem_seg_gt", "=", "utils", ".", "read_image", "(", "\n", "dataset_dict", ".", "pop", "(", "\"sem_seg_file_name\"", ")", ",", "\"L\"", "\n", ")", ".", "squeeze", "(", "2", ")", "\n", "", "else", ":", "\n", "            ", "sem_seg_gt", "=", "None", "\n", "\n", "", "aug_input", "=", "T", ".", "StandardAugInput", "(", "image", ",", "sem_seg", "=", "sem_seg_gt", ")", "\n", "transforms", "=", "aug_input", ".", "apply_augmentations", "(", "self", ".", "augmentation", ")", "\n", "image_weak_aug", ",", "sem_seg_gt", "=", "aug_input", ".", "image", ",", "aug_input", ".", "sem_seg", "\n", "image_shape", "=", "image_weak_aug", ".", "shape", "[", ":", "2", "]", "# h, w", "\n", "\n", "if", "sem_seg_gt", "is", "not", "None", ":", "\n", "            ", "dataset_dict", "[", "\"sem_seg\"", "]", "=", "torch", ".", "as_tensor", "(", "sem_seg_gt", ".", "astype", "(", "\"long\"", ")", ")", "\n", "\n", "", "if", "self", ".", "load_proposals", ":", "\n", "            ", "utils", ".", "transform_proposals", "(", "\n", "dataset_dict", ",", "\n", "image_shape", ",", "\n", "transforms", ",", "\n", "proposal_topk", "=", "self", ".", "proposal_topk", ",", "\n", "min_box_size", "=", "self", ".", "proposal_min_box_size", ",", "\n", ")", "\n", "\n", "", "if", "not", "self", ".", "is_train", ":", "\n", "            ", "dataset_dict", ".", "pop", "(", "\"annotations\"", ",", "None", ")", "\n", "dataset_dict", ".", "pop", "(", "\"sem_seg_file_name\"", ",", "None", ")", "\n", "return", "dataset_dict", "\n", "\n", "", "if", "\"annotations\"", "in", "dataset_dict", ":", "\n", "            ", "for", "anno", "in", "dataset_dict", "[", "\"annotations\"", "]", ":", "\n", "                ", "if", "not", "self", ".", "mask_on", ":", "\n", "                    ", "anno", ".", "pop", "(", "\"segmentation\"", ",", "None", ")", "\n", "", "if", "not", "self", ".", "keypoint_on", ":", "\n", "                    ", "anno", ".", "pop", "(", "\"keypoints\"", ",", "None", ")", "\n", "\n", "", "", "annos", "=", "[", "\n", "utils", ".", "transform_instance_annotations", "(", "\n", "obj", ",", "\n", "transforms", ",", "\n", "image_shape", ",", "\n", "keypoint_hflip_indices", "=", "self", ".", "keypoint_hflip_indices", ",", "\n", ")", "\n", "for", "obj", "in", "dataset_dict", ".", "pop", "(", "\"annotations\"", ")", "\n", "if", "obj", ".", "get", "(", "\"iscrowd\"", ",", "0", ")", "==", "0", "\n", "]", "\n", "instances", "=", "utils", ".", "annotations_to_instances", "(", "\n", "annos", ",", "image_shape", ",", "mask_format", "=", "self", ".", "mask_format", "\n", ")", "\n", "\n", "if", "self", ".", "compute_tight_boxes", "and", "instances", ".", "has", "(", "\"gt_masks\"", ")", ":", "\n", "                ", "instances", ".", "gt_boxes", "=", "instances", ".", "gt_masks", ".", "get_bounding_boxes", "(", ")", "\n", "\n", "", "bboxes_d2_format", "=", "utils", ".", "filter_empty_instances", "(", "instances", ")", "\n", "dataset_dict", "[", "\"instances\"", "]", "=", "bboxes_d2_format", "\n", "\n", "# apply strong augmentation", "\n", "# We use torchvision augmentation, which is not compatiable with", "\n", "# detectron2, which use numpy format for images. Thus, we need to", "\n", "# convert to PIL format first.", "\n", "", "image_pil", "=", "Image", ".", "fromarray", "(", "image_weak_aug", ".", "astype", "(", "\"uint8\"", ")", ",", "\"RGB\"", ")", "\n", "image_strong_aug", "=", "np", ".", "array", "(", "self", ".", "strong_augmentation", "(", "image_pil", ")", ")", "\n", "dataset_dict", "[", "\"image\"", "]", "=", "torch", ".", "as_tensor", "(", "\n", "np", ".", "ascontiguousarray", "(", "image_strong_aug", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", ")", "\n", "\n", "dataset_dict_key", "=", "copy", ".", "deepcopy", "(", "dataset_dict", ")", "\n", "dataset_dict_key", "[", "\"image\"", "]", "=", "torch", ".", "as_tensor", "(", "\n", "np", ".", "ascontiguousarray", "(", "image_weak_aug", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", "\n", ")", "\n", "assert", "dataset_dict", "[", "\"image\"", "]", ".", "size", "(", "1", ")", "==", "dataset_dict_key", "[", "\"image\"", "]", ".", "size", "(", "1", ")", "\n", "assert", "dataset_dict", "[", "\"image\"", "]", ".", "size", "(", "2", ")", "==", "dataset_dict_key", "[", "\"image\"", "]", ".", "size", "(", "2", ")", "\n", "return", "(", "dataset_dict", ",", "dataset_dict_key", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.datasets.builtin_69.register_coco_unlabel": [[49, 55], ["_SPLITS_COCO_FORMAT.items", "splits_per_dataset.items", "builtin_69.register_coco_unlabel_instances", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.datasets.builtin.register_coco_unlabel_instances"], ["def", "register_coco_unlabel", "(", "root", ")", ":", "\n", "    ", "for", "_", ",", "splits_per_dataset", "in", "_SPLITS_COCO_FORMAT", ".", "items", "(", ")", ":", "\n", "        ", "for", "key", ",", "(", "image_root", ",", "json_file", ")", "in", "splits_per_dataset", ".", "items", "(", ")", ":", "\n", "            ", "meta", "=", "{", "}", "\n", "register_coco_unlabel_instances", "(", "\n", "key", ",", "meta", ",", "os", ".", "path", ".", "join", "(", "root", ",", "json_file", ")", ",", "os", ".", "path", ".", "join", "(", "root", ",", "image_root", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.datasets.builtin_69.register_coco_unlabel_instances": [[58, 88], ["isinstance", "isinstance", "isinstance", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "builtin_69.load_coco_unlabel_json", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.datasets.builtin.load_coco_unlabel_json"], ["", "", "", "def", "register_coco_unlabel_instances", "(", "name", ",", "metadata", ",", "json_file", ",", "image_root", ")", ":", "\n", "    ", "\"\"\"\n    Register a dataset in COCO's json annotation format for\n    instance detection, instance segmentation and keypoint detection.\n    (i.e., Type 1 and 2 in http://cocodataset.org/#format-data.\n    `instances*.json` and `person_keypoints*.json` in the dataset).\n\n    This is an example of how to register a new dataset.\n    You can do something similar to this function, to register new datasets.\n\n    Args:\n        name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\n        metadata (dict): extra metadata associated with this dataset.  You can\n            leave it as an empty dict.\n        json_file (str): path to the json instance annotation file.\n        image_root (str or path-like): directory which contains all the images.\n    \"\"\"", "\n", "assert", "isinstance", "(", "name", ",", "str", ")", ",", "name", "\n", "assert", "isinstance", "(", "json_file", ",", "(", "str", ",", "os", ".", "PathLike", ")", ")", ",", "json_file", "\n", "assert", "isinstance", "(", "image_root", ",", "(", "str", ",", "os", ".", "PathLike", ")", ")", ",", "image_root", "\n", "\n", "# 1. register a function which returns dicts", "\n", "DatasetCatalog", ".", "register", "(", "\n", "name", ",", "lambda", ":", "load_coco_unlabel_json", "(", "json_file", ",", "image_root", ",", "name", ")", "\n", ")", "\n", "\n", "# 2. Optionally, add metadata about this dataset,", "\n", "# since they might be useful in evaluation, visualization or logging", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "\n", "json_file", "=", "json_file", ",", "image_root", "=", "image_root", ",", "evaluator_type", "=", "\"coco\"", ",", "**", "metadata", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.datasets.builtin_69.load_coco_unlabel_json": [[92, 126], ["fvcore.common.timer.Timer", "fvcore.common.file_io.PathManager.get_local_path", "sorted", "COCO.loadImgs", "logger.info", "contextlib.redirect_stdout", "COCO", "fvcore.common.timer.Timer.seconds", "logger.info", "COCO.imgs.keys", "os.path.join", "dataset_dicts.append", "io.StringIO", "len", "fvcore.common.timer.Timer.seconds"], "function", ["None"], ["", "def", "load_coco_unlabel_json", "(", "\n", "json_file", ",", "image_root", ",", "dataset_name", "=", "None", ",", "extra_annotation_keys", "=", "None", "\n", ")", ":", "\n", "    ", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "json_file", "=", "PathManager", ".", "get_local_path", "(", "json_file", ")", "\n", "with", "contextlib", ".", "redirect_stdout", "(", "io", ".", "StringIO", "(", ")", ")", ":", "\n", "        ", "coco_api", "=", "COCO", "(", "json_file", ")", "\n", "", "if", "timer", ".", "seconds", "(", ")", ">", "1", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Loading {} takes {:.2f} seconds.\"", ".", "format", "(", "json_file", ",", "timer", ".", "seconds", "(", ")", ")", "\n", ")", "\n", "\n", "", "id_map", "=", "None", "\n", "# sort indices for reproducible results", "\n", "img_ids", "=", "sorted", "(", "coco_api", ".", "imgs", ".", "keys", "(", ")", ")", "\n", "\n", "imgs", "=", "coco_api", ".", "loadImgs", "(", "img_ids", ")", "\n", "\n", "logger", ".", "info", "(", "\"Loaded {} images in COCO format from {}\"", ".", "format", "(", "len", "(", "imgs", ")", ",", "json_file", ")", ")", "\n", "\n", "dataset_dicts", "=", "[", "]", "\n", "\n", "for", "img_dict", "in", "imgs", ":", "\n", "        ", "record", "=", "{", "}", "\n", "record", "[", "\"file_name\"", "]", "=", "os", ".", "path", ".", "join", "(", "image_root", ",", "img_dict", "[", "\"file_name\"", "]", ")", "\n", "record", "[", "\"height\"", "]", "=", "img_dict", "[", "\"height\"", "]", "\n", "record", "[", "\"width\"", "]", "=", "img_dict", "[", "\"width\"", "]", "\n", "image_id", "=", "record", "[", "\"image_id\"", "]", "=", "img_dict", "[", "\"id\"", "]", "\n", "\n", "dataset_dicts", ".", "append", "(", "record", ")", "\n", "\n", "", "return", "dataset_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.datasets.builtin.register_coco_unlabel": [[42, 48], ["_SPLITS_COCO_FORMAT.items", "splits_per_dataset.items", "builtin.register_coco_unlabel_instances", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.datasets.builtin.register_coco_unlabel_instances"], ["def", "register_coco_unlabel", "(", "root", ")", ":", "\n", "    ", "for", "_", ",", "splits_per_dataset", "in", "_SPLITS_COCO_FORMAT", ".", "items", "(", ")", ":", "\n", "        ", "for", "key", ",", "(", "image_root", ",", "json_file", ")", "in", "splits_per_dataset", ".", "items", "(", ")", ":", "\n", "            ", "meta", "=", "{", "}", "\n", "register_coco_unlabel_instances", "(", "\n", "key", ",", "meta", ",", "os", ".", "path", ".", "join", "(", "root", ",", "json_file", ")", ",", "os", ".", "path", ".", "join", "(", "root", ",", "image_root", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.datasets.builtin.register_coco_unlabel_instances": [[51, 81], ["isinstance", "isinstance", "isinstance", "detectron2.data.DatasetCatalog.register", "detectron2.data.MetadataCatalog.get().set", "builtin.load_coco_unlabel_json", "detectron2.data.MetadataCatalog.get"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.datasets.builtin.load_coco_unlabel_json"], ["", "", "", "def", "register_coco_unlabel_instances", "(", "name", ",", "metadata", ",", "json_file", ",", "image_root", ")", ":", "\n", "    ", "\"\"\"\n    Register a dataset in COCO's json annotation format for\n    instance detection, instance segmentation and keypoint detection.\n    (i.e., Type 1 and 2 in http://cocodataset.org/#format-data.\n    `instances*.json` and `person_keypoints*.json` in the dataset).\n\n    This is an example of how to register a new dataset.\n    You can do something similar to this function, to register new datasets.\n\n    Args:\n        name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\n        metadata (dict): extra metadata associated with this dataset.  You can\n            leave it as an empty dict.\n        json_file (str): path to the json instance annotation file.\n        image_root (str or path-like): directory which contains all the images.\n    \"\"\"", "\n", "assert", "isinstance", "(", "name", ",", "str", ")", ",", "name", "\n", "assert", "isinstance", "(", "json_file", ",", "(", "str", ",", "os", ".", "PathLike", ")", ")", ",", "json_file", "\n", "assert", "isinstance", "(", "image_root", ",", "(", "str", ",", "os", ".", "PathLike", ")", ")", ",", "image_root", "\n", "\n", "# 1. register a function which returns dicts", "\n", "DatasetCatalog", ".", "register", "(", "\n", "name", ",", "lambda", ":", "load_coco_unlabel_json", "(", "json_file", ",", "image_root", ",", "name", ")", "\n", ")", "\n", "\n", "# 2. Optionally, add metadata about this dataset,", "\n", "# since they might be useful in evaluation, visualization or logging", "\n", "MetadataCatalog", ".", "get", "(", "name", ")", ".", "set", "(", "\n", "json_file", "=", "json_file", ",", "image_root", "=", "image_root", ",", "evaluator_type", "=", "\"coco\"", ",", "**", "metadata", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.datasets.builtin.load_coco_unlabel_json": [[85, 119], ["fvcore.common.timer.Timer", "fvcore.common.file_io.PathManager.get_local_path", "sorted", "COCO.loadImgs", "logger.info", "contextlib.redirect_stdout", "COCO", "fvcore.common.timer.Timer.seconds", "logger.info", "COCO.imgs.keys", "os.path.join", "dataset_dicts.append", "io.StringIO", "len", "fvcore.common.timer.Timer.seconds"], "function", ["None"], ["", "def", "load_coco_unlabel_json", "(", "\n", "json_file", ",", "image_root", ",", "dataset_name", "=", "None", ",", "extra_annotation_keys", "=", "None", "\n", ")", ":", "\n", "    ", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "json_file", "=", "PathManager", ".", "get_local_path", "(", "json_file", ")", "\n", "with", "contextlib", ".", "redirect_stdout", "(", "io", ".", "StringIO", "(", ")", ")", ":", "\n", "        ", "coco_api", "=", "COCO", "(", "json_file", ")", "\n", "", "if", "timer", ".", "seconds", "(", ")", ">", "1", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Loading {} takes {:.2f} seconds.\"", ".", "format", "(", "json_file", ",", "timer", ".", "seconds", "(", ")", ")", "\n", ")", "\n", "\n", "", "id_map", "=", "None", "\n", "# sort indices for reproducible results", "\n", "img_ids", "=", "sorted", "(", "coco_api", ".", "imgs", ".", "keys", "(", ")", ")", "\n", "\n", "imgs", "=", "coco_api", ".", "loadImgs", "(", "img_ids", ")", "\n", "\n", "logger", ".", "info", "(", "\"Loaded {} images in COCO format from {}\"", ".", "format", "(", "len", "(", "imgs", ")", ",", "json_file", ")", ")", "\n", "\n", "dataset_dicts", "=", "[", "]", "\n", "\n", "for", "img_dict", "in", "imgs", ":", "\n", "        ", "record", "=", "{", "}", "\n", "record", "[", "\"file_name\"", "]", "=", "os", ".", "path", ".", "join", "(", "image_root", ",", "img_dict", "[", "\"file_name\"", "]", ")", "\n", "record", "[", "\"height\"", "]", "=", "img_dict", "[", "\"height\"", "]", "\n", "record", "[", "\"width\"", "]", "=", "img_dict", "[", "\"width\"", "]", "\n", "image_id", "=", "record", "[", "\"image_id\"", "]", "=", "img_dict", "[", "\"id\"", "]", "\n", "\n", "dataset_dicts", ".", "append", "(", "record", ")", "\n", "\n", "", "return", "dataset_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.datasets.merge.load_coco_json": [[21, 214], ["fvcore.common.timer.Timer", "detectron2.utils.file_io.PathManager.get_local_path", "sorted", "COCO.loadImgs", "sum", "len", "list", "logger.info", "contextlib.redirect_stdout", "COCO", "fvcore.common.timer.Timer.seconds", "logger.info", "detectron2.data.MetadataCatalog.get", "sorted", "COCO.loadCats", "COCO.imgs.keys", "logger.warning", "zip", "os.path.join", "dataset_dicts.append", "logger.warning", "io.StringIO", "COCO.getCatIds", "len", "len", "len", "len", "anno.get", "anno.get", "objs.append", "fvcore.common.timer.Timer.seconds", "sorted", "logger.warning", "enumerate", "set", "anno.get", "isinstance", "enumerate", "min", "max", "len", "isinstance", "pycocotools.frPyObjects", "len", "KeyError", "len", "len"], "function", ["None"], ["def", "load_coco_json", "(", "json_file", ",", "image_root", ",", "dataset_name", "=", "None", ",", "extra_annotation_keys", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Load a json file with COCO's instances annotation format.\n    Currently supports instance detection, instance segmentation,\n    and person keypoints annotations.\n\n    Args:\n        json_file (str): full path to the json file in COCO instances annotation format.\n        image_root (str or path-like): the directory where the images in this json file exists.\n        dataset_name (str or None): the name of the dataset (e.g., coco_2017_train).\n            When provided, this function will also do the following:\n\n            * Put \"thing_classes\" into the metadata associated with this dataset.\n            * Map the category ids into a contiguous range (needed by standard dataset format),\n              and add \"thing_dataset_id_to_contiguous_id\" to the metadata associated\n              with this dataset.\n\n            This option should usually be provided, unless users need to load\n            the original json content and apply more processing manually.\n        extra_annotation_keys (list[str]): list of per-annotation keys that should also be\n            loaded into the dataset dict (besides \"iscrowd\", \"bbox\", \"keypoints\",\n            \"category_id\", \"segmentation\"). The values for these keys will be returned as-is.\n            For example, the densepose annotations are loaded in this way.\n\n    Returns:\n        list[dict]: a list of dicts in Detectron2 standard dataset dicts format (See\n        `Using Custom Datasets </tutorials/datasets.html>`_ ) when `dataset_name` is not None.\n        If `dataset_name` is None, the returned `category_ids` may be\n        incontiguous and may not conform to the Detectron2 standard format.\n\n    Notes:\n        1. This function does not read the image files.\n           The results do not have the \"image\" field.\n    \"\"\"", "\n", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "\n", "timer", "=", "Timer", "(", ")", "\n", "json_file", "=", "PathManager", ".", "get_local_path", "(", "json_file", ")", "\n", "with", "contextlib", ".", "redirect_stdout", "(", "io", ".", "StringIO", "(", ")", ")", ":", "\n", "        ", "coco_api", "=", "COCO", "(", "json_file", ")", "\n", "", "if", "timer", ".", "seconds", "(", ")", ">", "1", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading {} takes {:.2f} seconds.\"", ".", "format", "(", "json_file", ",", "timer", ".", "seconds", "(", ")", ")", ")", "\n", "\n", "", "id_map", "=", "None", "\n", "if", "dataset_name", "is", "not", "None", ":", "\n", "        ", "meta", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "cat_ids", "=", "sorted", "(", "coco_api", ".", "getCatIds", "(", ")", ")", "\n", "cats", "=", "coco_api", ".", "loadCats", "(", "cat_ids", ")", "\n", "# The categories in a custom json file may not be sorted.", "\n", "thing_classes", "=", "[", "c", "[", "\"name\"", "]", "for", "c", "in", "sorted", "(", "cats", ",", "key", "=", "lambda", "x", ":", "x", "[", "\"id\"", "]", ")", "]", "\n", "meta", ".", "thing_classes", "=", "thing_classes", "\n", "\n", "# In COCO, certain category ids are artificially removed,", "\n", "# and by convention they are always ignored.", "\n", "# We deal with COCO's id issue and translate", "\n", "# the category ids to contiguous ids in [0, 80).", "\n", "\n", "# It works by looking at the \"categories\" field in the json, therefore", "\n", "# if users' own json also have incontiguous ids, we'll", "\n", "# apply this mapping as well but print a warning.", "\n", "if", "not", "(", "min", "(", "cat_ids", ")", "==", "1", "and", "max", "(", "cat_ids", ")", "==", "len", "(", "cat_ids", ")", ")", ":", "\n", "            ", "if", "\"coco\"", "not", "in", "dataset_name", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"\"\"\nCategory ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n\"\"\"", "\n", ")", "\n", "", "", "id_map", "=", "{", "v", ":", "i", "for", "i", ",", "v", "in", "enumerate", "(", "cat_ids", ")", "}", "\n", "meta", ".", "thing_dataset_id_to_contiguous_id", "=", "id_map", "\n", "\n", "# sort indices for reproducible results", "\n", "", "img_ids", "=", "sorted", "(", "coco_api", ".", "imgs", ".", "keys", "(", ")", ")", "\n", "# imgs is a list of dicts, each looks something like:", "\n", "# {'license': 4,", "\n", "#  'url': 'http://farm6.staticflickr.com/5454/9413846304_881d5e5c3b_z.jpg',", "\n", "#  'file_name': 'COCO_val2014_000000001268.jpg',", "\n", "#  'height': 427,", "\n", "#  'width': 640,", "\n", "#  'date_captured': '2013-11-17 05:57:24',", "\n", "#  'id': 1268}", "\n", "imgs", "=", "coco_api", ".", "loadImgs", "(", "img_ids", ")", "\n", "# anns is a list[list[dict]], where each dict is an annotation", "\n", "# record for an object. The inner list enumerates the objects in an image", "\n", "# and the outer list enumerates over images. Example of anns[0]:", "\n", "# [{'segmentation': [[192.81,", "\n", "#     247.09,", "\n", "#     ...", "\n", "#     219.03,", "\n", "#     249.06]],", "\n", "#   'area': 1035.749,", "\n", "#   'iscrowd': 0,", "\n", "#   'image_id': 1268,", "\n", "#   'bbox': [192.81, 224.8, 74.73, 33.43],", "\n", "#   'category_id': 16,", "\n", "#   'id': 42986},", "\n", "#  ...]", "\n", "anns", "=", "[", "coco_api", ".", "imgToAnns", "[", "img_id", "]", "for", "img_id", "in", "img_ids", "]", "\n", "total_num_valid_anns", "=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "anns", "]", ")", "\n", "total_num_anns", "=", "len", "(", "coco_api", ".", "anns", ")", "\n", "if", "total_num_valid_anns", "<", "total_num_anns", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"{json_file} contains {total_num_anns} annotations, but only \"", "\n", "f\"{total_num_valid_anns} of them match to images in the file.\"", "\n", ")", "\n", "\n", "", "if", "\"minival\"", "not", "in", "json_file", ":", "\n", "# The popular valminusminival & minival annotations for COCO2014 contain this bug.", "\n", "# However the ratio of buggy annotations there is tiny and does not affect accuracy.", "\n", "# Therefore we explicitly white-list them.", "\n", "        ", "ann_ids", "=", "[", "ann", "[", "\"id\"", "]", "for", "anns_per_image", "in", "anns", "for", "ann", "in", "anns_per_image", "]", "\n", "assert", "len", "(", "set", "(", "ann_ids", ")", ")", "==", "len", "(", "ann_ids", ")", ",", "\"Annotation ids in '{}' are not unique!\"", ".", "format", "(", "\n", "json_file", "\n", ")", "\n", "\n", "", "imgs_anns", "=", "list", "(", "zip", "(", "imgs", ",", "anns", ")", ")", "\n", "logger", ".", "info", "(", "\"Loaded {} images in COCO format from {}\"", ".", "format", "(", "len", "(", "imgs_anns", ")", ",", "json_file", ")", ")", "\n", "\n", "dataset_dicts", "=", "[", "]", "\n", "\n", "ann_keys", "=", "[", "\"iscrowd\"", ",", "\"bbox\"", ",", "\"keypoints\"", ",", "\"category_id\"", "]", "+", "(", "extra_annotation_keys", "or", "[", "]", ")", "\n", "\n", "num_instances_without_valid_segmentation", "=", "0", "\n", "\n", "for", "(", "img_dict", ",", "anno_dict_list", ")", "in", "imgs_anns", ":", "\n", "        ", "record", "=", "{", "}", "\n", "record", "[", "\"file_name\"", "]", "=", "os", ".", "path", ".", "join", "(", "image_root", ",", "img_dict", "[", "\"file_name\"", "]", ")", "\n", "record", "[", "\"height\"", "]", "=", "img_dict", "[", "\"height\"", "]", "\n", "record", "[", "\"width\"", "]", "=", "img_dict", "[", "\"width\"", "]", "\n", "image_id", "=", "record", "[", "\"image_id\"", "]", "=", "img_dict", "[", "\"id\"", "]", "\n", "\n", "objs", "=", "[", "]", "\n", "for", "anno", "in", "anno_dict_list", ":", "\n", "# Check that the image_id in this annotation is the same as", "\n", "# the image_id we're looking at.", "\n", "# This fails only when the data parsing logic or the annotation file is buggy.", "\n", "\n", "# The original COCO valminusminival2014 & minival2014 annotation files", "\n", "# actually contains bugs that, together with certain ways of using COCO API,", "\n", "# can trigger this assertion.", "\n", "            ", "assert", "anno", "[", "\"image_id\"", "]", "==", "image_id", "\n", "\n", "assert", "anno", ".", "get", "(", "\"ignore\"", ",", "0", ")", "==", "0", ",", "'\"ignore\" in COCO json file is not supported.'", "\n", "\n", "obj", "=", "{", "key", ":", "anno", "[", "key", "]", "for", "key", "in", "ann_keys", "if", "key", "in", "anno", "}", "\n", "\n", "segm", "=", "anno", ".", "get", "(", "\"segmentation\"", ",", "None", ")", "\n", "if", "segm", ":", "# either list[list[float]] or dict(RLE)", "\n", "                ", "if", "isinstance", "(", "segm", ",", "dict", ")", ":", "\n", "                    ", "if", "isinstance", "(", "segm", "[", "\"counts\"", "]", ",", "list", ")", ":", "\n", "# convert to compressed RLE", "\n", "                        ", "segm", "=", "mask_util", ".", "frPyObjects", "(", "segm", ",", "*", "segm", "[", "\"size\"", "]", ")", "\n", "", "", "else", ":", "\n", "# filter out invalid polygons (< 3 points)", "\n", "                    ", "segm", "=", "[", "poly", "for", "poly", "in", "segm", "if", "len", "(", "poly", ")", "%", "2", "==", "0", "and", "len", "(", "poly", ")", ">=", "6", "]", "\n", "if", "len", "(", "segm", ")", "==", "0", ":", "\n", "                        ", "num_instances_without_valid_segmentation", "+=", "1", "\n", "continue", "# ignore this instance", "\n", "", "", "obj", "[", "\"segmentation\"", "]", "=", "segm", "\n", "\n", "", "keypts", "=", "anno", ".", "get", "(", "\"keypoints\"", ",", "None", ")", "\n", "if", "keypts", ":", "# list[int]", "\n", "                ", "for", "idx", ",", "v", "in", "enumerate", "(", "keypts", ")", ":", "\n", "                    ", "if", "idx", "%", "3", "!=", "2", ":", "\n", "# COCO's segmentation coordinates are floating points in [0, H or W],", "\n", "# but keypoint coordinates are integers in [0, H-1 or W-1]", "\n", "# Therefore we assume the coordinates are \"pixel indices\" and", "\n", "# add 0.5 to convert to floating point coordinates.", "\n", "                        ", "keypts", "[", "idx", "]", "=", "v", "+", "0.5", "\n", "", "", "obj", "[", "\"keypoints\"", "]", "=", "keypts", "\n", "\n", "", "obj", "[", "\"bbox_mode\"", "]", "=", "BoxMode", ".", "XYWH_ABS", "\n", "if", "id_map", ":", "\n", "                ", "annotation_category_id", "=", "obj", "[", "\"category_id\"", "]", "\n", "try", ":", "\n", "                    ", "obj", "[", "\"category_id\"", "]", "=", "id_map", "[", "annotation_category_id", "]", "\n", "", "except", "KeyError", "as", "e", ":", "\n", "                    ", "raise", "KeyError", "(", "\n", "f\"Encountered category_id={annotation_category_id} \"", "\n", "\"but this id does not exist in 'categories' of the json file.\"", "\n", ")", "from", "e", "\n", "", "", "objs", ".", "append", "(", "obj", ")", "\n", "", "record", "[", "\"annotations\"", "]", "=", "objs", "\n", "dataset_dicts", ".", "append", "(", "record", ")", "\n", "\n", "", "if", "num_instances_without_valid_segmentation", ">", "0", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"Filtered out {} instances without valid segmentation. \"", ".", "format", "(", "\n", "num_instances_without_valid_segmentation", "\n", ")", "\n", "+", "\"There might be issues in your dataset generation process.  Please \"", "\n", "\"check https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html carefully\"", "\n", ")", "\n", "", "return", "dataset_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.transforms.augmentation_impl.GaussianBlur.__init__": [[15, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sigma", "=", "[", "0.1", ",", "2.0", "]", ")", ":", "\n", "        ", "self", ".", "sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.transforms.augmentation_impl.GaussianBlur.__call__": [[18, 22], ["random.uniform", "x.filter.filter.filter", "PIL.ImageFilter.GaussianBlur"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "x", ")", ":", "\n", "        ", "sigma", "=", "random", ".", "uniform", "(", "self", ".", "sigma", "[", "0", "]", ",", "self", ".", "sigma", "[", "1", "]", ")", "\n", "x", "=", "x", ".", "filter", "(", "ImageFilter", ".", "GaussianBlur", "(", "radius", "=", "sigma", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator.__init__": [[43, 122], ["logging.getLogger", "torch.device", "detectron2.data.MetadataCatalog.get", "detectron2.utils.file_io.PathManager.get_local_path", "isinstance", "coco_evaluation.COCOEvaluator._logger.warn", "hasattr", "coco_evaluation.COCOEvaluator._logger.info", "os.path.join", "detectron2.data.datasets.coco.convert_to_coco_json", "contextlib.redirect_stdout", "pycocotools.coco.COCO", "io.StringIO"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "dataset_name", ",", "\n", "tasks", "=", "None", ",", "\n", "distributed", "=", "True", ",", "\n", "output_dir", "=", "None", ",", "\n", "*", ",", "\n", "use_fast_impl", "=", "True", ",", "\n", "kpt_oks_sigmas", "=", "(", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            dataset_name (str): name of the dataset to be evaluated.\n                It must have either the following corresponding metadata:\n\n                    \"json_file\": the path to the COCO format annotation\n\n                Or it must be in detectron2's standard dataset format\n                so it can be converted to COCO format automatically.\n            tasks (tuple[str]): tasks that can be evaluated under the given\n                configuration. A task is one of \"bbox\", \"segm\", \"keypoints\".\n                By default, will infer this automatically from predictions.\n            distributed (True): if True, will collect results from all ranks and run evaluation\n                in the main process.\n                Otherwise, will only evaluate the results in the current process.\n            output_dir (str): optional, an output directory to dump all\n                results predicted on the dataset. The dump contains two files:\n\n                1. \"instances_predictions.pth\" a file that can be loaded with `torch.load` and\n                   contains all the results in the format they are produced by the model.\n                2. \"coco_instances_results.json\" a json file in COCO's result format.\n            use_fast_impl (bool): use a fast but **unofficial** implementation to compute AP.\n                Although the results should be very close to the official implementation in COCO\n                API, it is still recommended to compute results with the official API for use in\n                papers. The faster implementation also uses more RAM.\n            kpt_oks_sigmas (list[float]): The sigmas used to calculate keypoint OKS.\n                See http://cocodataset.org/#keypoints-eval\n                When empty, it will use the defaults in COCO.\n                Otherwise it should be the same length as ROI_KEYPOINT_HEAD.NUM_KEYPOINTS.\n        \"\"\"", "\n", "self", ".", "_logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "self", ".", "_distributed", "=", "distributed", "\n", "self", ".", "_output_dir", "=", "output_dir", "\n", "self", ".", "_use_fast_impl", "=", "use_fast_impl", "\n", "\n", "if", "tasks", "is", "not", "None", "and", "isinstance", "(", "tasks", ",", "CfgNode", ")", ":", "\n", "            ", "kpt_oks_sigmas", "=", "(", "\n", "tasks", ".", "TEST", ".", "KEYPOINT_OKS_SIGMAS", "if", "not", "kpt_oks_sigmas", "else", "kpt_oks_sigmas", "\n", ")", "\n", "self", ".", "_logger", ".", "warn", "(", "\n", "\"COCO Evaluator instantiated using config, this is deprecated behavior.\"", "\n", "\" Please pass in explicit arguments instead.\"", "\n", ")", "\n", "self", ".", "_tasks", "=", "None", "# Infering it from predictions should be better", "\n", "", "else", ":", "\n", "            ", "self", ".", "_tasks", "=", "tasks", "\n", "\n", "", "self", ".", "_cpu_device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "self", ".", "_metadata", "=", "MetadataCatalog", ".", "get", "(", "dataset_name", ")", "\n", "if", "not", "hasattr", "(", "self", ".", "_metadata", ",", "\"json_file\"", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\n", "f\"'{dataset_name}' is not registered by `register_coco_instances`.\"", "\n", "\" Therefore trying to convert it to COCO format ...\"", "\n", ")", "\n", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "f\"{dataset_name}_coco_format.json\"", ")", "\n", "self", ".", "_metadata", ".", "json_file", "=", "cache_path", "\n", "convert_to_coco_json", "(", "dataset_name", ",", "cache_path", ")", "\n", "\n", "", "json_file", "=", "PathManager", ".", "get_local_path", "(", "self", ".", "_metadata", ".", "json_file", ")", "\n", "with", "contextlib", ".", "redirect_stdout", "(", "io", ".", "StringIO", "(", ")", ")", ":", "\n", "            ", "self", ".", "_coco_api", "=", "COCO", "(", "json_file", ")", "\n", "\n", "# Test set json files do not contain annotations (evaluation must be", "\n", "# performed using the COCO evaluation server).", "\n", "", "self", ".", "_do_evaluation", "=", "\"annotations\"", "in", "self", ".", "_coco_api", ".", "dataset", "\n", "if", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_kpt_oks_sigmas", "=", "kpt_oks_sigmas", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator.reset": [[123, 125], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_predictions", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator.process": [[126, 145], ["zip", "output[].to", "coco_evaluation.instances_to_coco_json", "output[].to", "len", "coco_evaluation.COCOEvaluator._predictions.append"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.instances_to_coco_json"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs: the inputs to a COCO model (e.g., GeneralizedRCNN).\n                It is a list of dict. Each dict corresponds to an image and\n                contains keys like \"height\", \"width\", \"file_name\", \"image_id\".\n            outputs: the outputs of a COCO model. It is a list of dicts with key\n                \"instances\" that contains :class:`Instances`.\n        \"\"\"", "\n", "for", "input", ",", "output", "in", "zip", "(", "inputs", ",", "outputs", ")", ":", "\n", "            ", "prediction", "=", "{", "\"image_id\"", ":", "input", "[", "\"image_id\"", "]", "}", "\n", "\n", "if", "\"instances\"", "in", "output", ":", "\n", "                ", "instances", "=", "output", "[", "\"instances\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "prediction", "[", "\"instances\"", "]", "=", "instances_to_coco_json", "(", "instances", ",", "input", "[", "\"image_id\"", "]", ")", "\n", "", "if", "\"proposals\"", "in", "output", ":", "\n", "                ", "prediction", "[", "\"proposals\"", "]", "=", "output", "[", "\"proposals\"", "]", ".", "to", "(", "self", ".", "_cpu_device", ")", "\n", "", "if", "len", "(", "prediction", ")", ">", "1", ":", "\n", "                ", "self", ".", "_predictions", ".", "append", "(", "prediction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator.evaluate": [[146, 179], ["collections.OrderedDict", "copy.deepcopy", "detectron2.synchronize", "detectron2.gather", "list", "len", "coco_evaluation.COCOEvaluator._logger.warning", "detectron2.utils.file_io.PathManager.mkdirs", "os.path.join", "coco_evaluation.COCOEvaluator._eval_box_proposals", "coco_evaluation.COCOEvaluator._eval_predictions", "itertools.chain", "detectron2.is_main_process", "detectron2.utils.file_io.PathManager.open", "torch.save"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.synchronize", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.gather", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator._eval_box_proposals", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator._eval_predictions", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.visualizer.VisImage.save"], ["", "", "", "def", "evaluate", "(", "self", ",", "img_ids", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            img_ids: a list of image IDs to evaluate on. Default to None for the whole dataset\n        \"\"\"", "\n", "\n", "if", "self", ".", "_distributed", ":", "\n", "            ", "comm", ".", "synchronize", "(", ")", "\n", "predictions", "=", "comm", ".", "gather", "(", "self", ".", "_predictions", ",", "dst", "=", "0", ")", "\n", "predictions", "=", "list", "(", "itertools", ".", "chain", "(", "*", "predictions", ")", ")", "\n", "\n", "if", "not", "comm", ".", "is_main_process", "(", ")", ":", "\n", "                ", "return", "{", "}", "\n", "", "", "else", ":", "\n", "            ", "predictions", "=", "self", ".", "_predictions", "\n", "\n", "", "if", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "self", ".", "_logger", ".", "warning", "(", "\"[COCOEvaluator] Did not receive valid predictions.\"", ")", "\n", "return", "{", "}", "\n", "\n", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "PathManager", ".", "mkdirs", "(", "self", ".", "_output_dir", ")", "\n", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"instances_predictions.pth\"", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "predictions", ",", "f", ")", "\n", "\n", "", "", "self", ".", "_results", "=", "OrderedDict", "(", ")", "\n", "if", "\"proposals\"", "in", "predictions", "[", "0", "]", ":", "\n", "            ", "self", ".", "_eval_box_proposals", "(", "predictions", ")", "\n", "", "if", "\"instances\"", "in", "predictions", "[", "0", "]", ":", "\n", "            ", "self", ".", "_eval_predictions", "(", "predictions", ",", "img_ids", "=", "img_ids", ")", "\n", "# Copy so the caller can do whatever with results", "\n", "", "return", "copy", ".", "deepcopy", "(", "self", ".", "_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator._tasks_from_predictions": [[180, 191], ["sorted", "tasks.add", "tasks.add"], "methods", ["None"], ["", "def", "_tasks_from_predictions", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Get COCO API \"tasks\" (i.e. iou_type) from COCO-format predictions.\n        \"\"\"", "\n", "tasks", "=", "{", "\"bbox\"", "}", "\n", "for", "pred", "in", "predictions", ":", "\n", "            ", "if", "\"segmentation\"", "in", "pred", ":", "\n", "                ", "tasks", ".", "add", "(", "\"segm\"", ")", "\n", "", "if", "\"keypoints\"", "in", "pred", ":", "\n", "                ", "tasks", ".", "add", "(", "\"keypoints\"", ")", "\n", "", "", "return", "sorted", "(", "tasks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator._eval_predictions": [[192, 254], ["coco_evaluation.COCOEvaluator._logger.info", "list", "hasattr", "coco_evaluation.COCOEvaluator._logger.info", "sorted", "itertools.chain", "coco_evaluation.COCOEvaluator._tasks_from_predictions", "list", "len", "os.path.join", "coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._derive_coco_results", "dataset_id_to_contiguous_id.values", "detectron2.utils.file_io.PathManager.open", "f.write", "f.flush", "coco_evaluation._evaluate_predictions_on_coco", "min", "max", "dataset_id_to_contiguous_id.items", "json.dumps", "len", "coco_evaluation.COCOEvaluator._metadata.get"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator._tasks_from_predictions", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator._derive_coco_results", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation._evaluate_predictions_on_coco"], ["", "def", "_eval_predictions", "(", "self", ",", "predictions", ",", "img_ids", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate predictions. Fill self._results with the metrics of the tasks.\n        \"\"\"", "\n", "self", ".", "_logger", ".", "info", "(", "\"Preparing results for COCO format ...\"", ")", "\n", "coco_results", "=", "list", "(", "itertools", ".", "chain", "(", "*", "[", "x", "[", "\"instances\"", "]", "for", "x", "in", "predictions", "]", ")", ")", "\n", "tasks", "=", "self", ".", "_tasks", "or", "self", ".", "_tasks_from_predictions", "(", "coco_results", ")", "\n", "\n", "# unmap the category ids for COCO", "\n", "if", "hasattr", "(", "self", ".", "_metadata", ",", "\"thing_dataset_id_to_contiguous_id\"", ")", ":", "\n", "            ", "dataset_id_to_contiguous_id", "=", "self", ".", "_metadata", ".", "thing_dataset_id_to_contiguous_id", "\n", "all_contiguous_ids", "=", "list", "(", "dataset_id_to_contiguous_id", ".", "values", "(", ")", ")", "\n", "num_classes", "=", "len", "(", "all_contiguous_ids", ")", "\n", "assert", "min", "(", "all_contiguous_ids", ")", "==", "0", "and", "max", "(", "all_contiguous_ids", ")", "==", "num_classes", "-", "1", "\n", "\n", "reverse_id_mapping", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "dataset_id_to_contiguous_id", ".", "items", "(", ")", "}", "\n", "for", "result", "in", "coco_results", ":", "\n", "                ", "category_id", "=", "result", "[", "\"category_id\"", "]", "\n", "assert", "category_id", "<", "num_classes", ",", "(", "\n", "f\"A prediction has class={category_id}, \"", "\n", "f\"but the dataset only has {num_classes} classes and \"", "\n", "f\"predicted class id should be in [0, {num_classes - 1}].\"", "\n", ")", "\n", "result", "[", "\"category_id\"", "]", "=", "reverse_id_mapping", "[", "category_id", "]", "\n", "\n", "", "", "if", "self", ".", "_output_dir", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"coco_instances_results.json\"", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Saving results to {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "with", "PathManager", ".", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "json", ".", "dumps", "(", "coco_results", ")", ")", "\n", "f", ".", "flush", "(", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\n", "\"Evaluating predictions with {} COCO API...\"", ".", "format", "(", "\n", "\"unofficial\"", "if", "self", ".", "_use_fast_impl", "else", "\"official\"", "\n", ")", "\n", ")", "\n", "for", "task", "in", "sorted", "(", "tasks", ")", ":", "\n", "            ", "assert", "task", "in", "{", "\"bbox\"", ",", "\"segm\"", ",", "\"keypoints\"", "}", ",", "f\"Got unknown task: {task}!\"", "\n", "coco_eval", "=", "(", "\n", "_evaluate_predictions_on_coco", "(", "\n", "self", ".", "_coco_api", ",", "\n", "coco_results", ",", "\n", "task", ",", "\n", "kpt_oks_sigmas", "=", "self", ".", "_kpt_oks_sigmas", ",", "\n", "use_fast_impl", "=", "self", ".", "_use_fast_impl", ",", "\n", "img_ids", "=", "img_ids", ",", "\n", ")", "\n", "if", "len", "(", "coco_results", ")", ">", "0", "\n", "else", "None", "# cocoapi does not handle empty results very well", "\n", ")", "\n", "\n", "import", "pdb", "\n", "# pdb.set_trace()", "\n", "res", "=", "self", ".", "_derive_coco_results", "(", "\n", "coco_eval", ",", "task", ",", "class_names", "=", "self", ".", "_metadata", ".", "get", "(", "\"thing_classes\"", ")", "\n", ")", "\n", "self", ".", "_results", "[", "task", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator._eval_box_proposals": [[255, 293], ["coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._logger.info", "coco_evaluation.COCOEvaluator._logger.info", "areas.items", "ids.append", "boxes.append", "objectness_logits.append", "detectron2.utils.file_io.PathManager.open", "pickle.dump", "coco_evaluation._evaluate_box_proposals", "float", "detectron2.utils.logger.create_small_table", "prediction[].proposal_boxes.tensor.numpy", "prediction[].objectness_logits.numpy", "os.path.join", "stats[].item"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation._evaluate_box_proposals", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger.create_small_table"], ["", "", "def", "_eval_box_proposals", "(", "self", ",", "predictions", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate the box proposals in predictions.\n        Fill self._results with the metrics for \"box_proposals\" task.\n        \"\"\"", "\n", "if", "self", ".", "_output_dir", ":", "\n", "# Saving generated box proposals to file.", "\n", "# Predicted box_proposals are in XYXY_ABS mode.", "\n", "            ", "bbox_mode", "=", "BoxMode", ".", "XYXY_ABS", ".", "value", "\n", "ids", ",", "boxes", ",", "objectness_logits", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "prediction", "in", "predictions", ":", "\n", "                ", "ids", ".", "append", "(", "prediction", "[", "\"image_id\"", "]", ")", "\n", "boxes", ".", "append", "(", "prediction", "[", "\"proposals\"", "]", ".", "proposal_boxes", ".", "tensor", ".", "numpy", "(", ")", ")", "\n", "objectness_logits", ".", "append", "(", "prediction", "[", "\"proposals\"", "]", ".", "objectness_logits", ".", "numpy", "(", ")", ")", "\n", "\n", "", "proposal_data", "=", "{", "\n", "\"boxes\"", ":", "boxes", ",", "\n", "\"objectness_logits\"", ":", "objectness_logits", ",", "\n", "\"ids\"", ":", "ids", ",", "\n", "\"bbox_mode\"", ":", "bbox_mode", ",", "\n", "}", "\n", "with", "PathManager", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_output_dir", ",", "\"box_proposals.pkl\"", ")", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "proposal_data", ",", "f", ")", "\n", "\n", "", "", "if", "not", "self", ".", "_do_evaluation", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Annotations are not available for evaluation.\"", ")", "\n", "return", "\n", "\n", "", "self", ".", "_logger", ".", "info", "(", "\"Evaluating bbox proposals ...\"", ")", "\n", "res", "=", "{", "}", "\n", "areas", "=", "{", "\"all\"", ":", "\"\"", ",", "\"small\"", ":", "\"s\"", ",", "\"medium\"", ":", "\"m\"", ",", "\"large\"", ":", "\"l\"", "}", "\n", "for", "limit", "in", "[", "100", ",", "1000", "]", ":", "\n", "            ", "for", "area", ",", "suffix", "in", "areas", ".", "items", "(", ")", ":", "\n", "                ", "stats", "=", "_evaluate_box_proposals", "(", "predictions", ",", "self", ".", "_coco_api", ",", "area", "=", "area", ",", "limit", "=", "limit", ")", "\n", "key", "=", "\"AR{}@{:d}\"", ".", "format", "(", "suffix", ",", "limit", ")", "\n", "res", "[", "key", "]", "=", "float", "(", "stats", "[", "\"ar\"", "]", ".", "item", "(", ")", "*", "100", ")", "\n", "", "", "self", ".", "_logger", ".", "info", "(", "\"Proposal metrics: \\n\"", "+", "create_small_table", "(", "res", ")", ")", "\n", "self", ".", "_results", "[", "\"box_proposals\"", "]", "=", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.COCOEvaluator._derive_coco_results": [[294, 391], ["coco_evaluation.COCOEvaluator._logger.info", "enumerate", "min", "list", "itertools.zip_longest", "tabulate.tabulate.tabulate", "coco_evaluation.COCOEvaluator._logger.info", "enumerate", "min", "list", "itertools.zip_longest", "tabulate.tabulate.tabulate", "coco_evaluation.COCOEvaluator._logger.info", "print", "sys.stdout.write", "results.update", "coco_evaluation.COCOEvaluator._logger.warn", "float", "numpy.isfinite", "coco_evaluation.COCOEvaluator._logger.info", "len", "results_per_category.append", "itertools.chain", "results_per_category_50.append", "itertools.chain", "float", "enumerate", "detectron2.utils.logger.create_small_table", "sum", "len", "numpy.mean", "float", "len", "numpy.mean", "float", "len", "results.values", "float", "float", "range", "range"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.CommonMetricPrinter.write", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger.create_small_table"], ["", "def", "_derive_coco_results", "(", "self", ",", "coco_eval", ",", "iou_type", ",", "class_names", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Derive the desired score numbers from summarized COCOeval.\n\n        Args:\n            coco_eval (None or COCOEval): None represents no predictions from model.\n            iou_type (str):\n            class_names (None or list[str]): if provided, will use it to predict\n                per-category AP.\n\n        Returns:\n            a dict of {metric name: score}\n        \"\"\"", "\n", "\n", "metrics", "=", "{", "\n", "\"bbox\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APs\"", ",", "\"APm\"", ",", "\"APl\"", "]", ",", "\n", "\"segm\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APs\"", ",", "\"APm\"", ",", "\"APl\"", "]", ",", "\n", "\"keypoints\"", ":", "[", "\"AP\"", ",", "\"AP50\"", ",", "\"AP75\"", ",", "\"APm\"", ",", "\"APl\"", "]", ",", "\n", "}", "[", "iou_type", "]", "\n", "\n", "if", "coco_eval", "is", "None", ":", "\n", "            ", "self", ".", "_logger", ".", "warn", "(", "\"No predictions from the model!\"", ")", "\n", "return", "{", "metric", ":", "float", "(", "\"nan\"", ")", "for", "metric", "in", "metrics", "}", "\n", "\n", "# the standard metrics", "\n", "", "results", "=", "{", "\n", "metric", ":", "float", "(", "coco_eval", ".", "stats", "[", "idx", "]", "*", "100", "if", "coco_eval", ".", "stats", "[", "idx", "]", ">=", "0", "else", "\"nan\"", ")", "\n", "for", "idx", ",", "metric", "in", "enumerate", "(", "metrics", ")", "\n", "}", "\n", "self", ".", "_logger", ".", "info", "(", "\n", "\"Evaluation results for {}: \\n\"", ".", "format", "(", "iou_type", ")", "+", "create_small_table", "(", "results", ")", "\n", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "sum", "(", "results", ".", "values", "(", ")", ")", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "info", "(", "\"Some metrics cannot be computed and is shown as NaN.\"", ")", "\n", "\n", "", "if", "class_names", "is", "None", "or", "len", "(", "class_names", ")", "<=", "1", ":", "\n", "            ", "return", "results", "\n", "# Compute per-category AP", "\n", "# from https://github.com/facebookresearch/Detectron/blob/a6a835f5b8208c45d0dce217ce9bbda915f44df7/detectron/datasets/json_dataset_evaluator.py#L222-L252 # noqa", "\n", "", "precisions", "=", "coco_eval", ".", "eval", "[", "\"precision\"", "]", "\n", "# precision has dims (iou, recall, cls, area range, max dets)", "\n", "assert", "len", "(", "class_names", ")", "==", "precisions", ".", "shape", "[", "2", "]", "\n", "\n", "results_per_category", "=", "[", "]", "\n", "for", "idx", ",", "name", "in", "enumerate", "(", "class_names", ")", ":", "\n", "# area range index 0: all area ranges", "\n", "# max dets index -1: typically 100 per image", "\n", "            ", "precision", "=", "precisions", "[", ":", ",", ":", ",", "idx", ",", "0", ",", "-", "1", "]", "\n", "precision", "=", "precision", "[", "precision", ">", "-", "1", "]", "\n", "ap", "=", "np", ".", "mean", "(", "precision", ")", "if", "precision", ".", "size", "else", "float", "(", "\"nan\"", ")", "\n", "results_per_category", ".", "append", "(", "(", "\"{}\"", ".", "format", "(", "name", ")", ",", "float", "(", "ap", "*", "100", ")", ")", ")", "\n", "\n", "# tabulate it", "\n", "", "N_COLS", "=", "min", "(", "6", ",", "len", "(", "results_per_category", ")", "*", "2", ")", "\n", "results_flatten", "=", "list", "(", "itertools", ".", "chain", "(", "*", "results_per_category", ")", ")", "\n", "results_2d", "=", "itertools", ".", "zip_longest", "(", "*", "[", "results_flatten", "[", "i", ":", ":", "N_COLS", "]", "for", "i", "in", "range", "(", "N_COLS", ")", "]", ")", "\n", "table", "=", "tabulate", "(", "\n", "results_2d", ",", "\n", "tablefmt", "=", "\"pipe\"", ",", "\n", "floatfmt", "=", "\".3f\"", ",", "\n", "headers", "=", "[", "\"category\"", ",", "\"AP\"", "]", "*", "(", "N_COLS", "//", "2", ")", ",", "\n", "numalign", "=", "\"left\"", ",", "\n", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Per-category {} AP: \\n\"", ".", "format", "(", "iou_type", ")", "+", "table", ")", "\n", "\n", "results_per_category_50", "=", "[", "]", "\n", "\n", "\n", "for", "idx", ",", "name", "in", "enumerate", "(", "class_names", ")", ":", "\n", "# area range index 0: all area ranges", "\n", "# max dets index -1: typically 100 per image", "\n", "            ", "precision", "=", "precisions", "[", "0", ",", ":", ",", "idx", ",", "0", ",", "-", "1", "]", "\n", "precision", "=", "precision", "[", "precision", ">", "-", "1", "]", "\n", "ap", "=", "np", ".", "mean", "(", "precision", ")", "if", "precision", ".", "size", "else", "float", "(", "\"nan\"", ")", "\n", "results_per_category_50", ".", "append", "(", "(", "\"{}\"", ".", "format", "(", "name", ")", ",", "float", "(", "ap", "*", "100", ")", ")", ")", "\n", "\n", "# tabulate it", "\n", "", "N_COLS", "=", "min", "(", "6", ",", "len", "(", "results_per_category_50", ")", "*", "2", ")", "\n", "results_flatten", "=", "list", "(", "itertools", ".", "chain", "(", "*", "results_per_category_50", ")", ")", "\n", "results_2d", "=", "itertools", ".", "zip_longest", "(", "*", "[", "results_flatten", "[", "i", ":", ":", "N_COLS", "]", "for", "i", "in", "range", "(", "N_COLS", ")", "]", ")", "\n", "table", "=", "tabulate", "(", "\n", "results_2d", ",", "\n", "tablefmt", "=", "\"pipe\"", ",", "\n", "floatfmt", "=", "\".3f\"", ",", "\n", "headers", "=", "[", "\"category\"", ",", "\"AP50\"", "]", "*", "(", "N_COLS", "//", "2", ")", ",", "\n", "numalign", "=", "\"left\"", ",", "\n", ")", "\n", "self", ".", "_logger", ".", "info", "(", "\"Per-category {} AP50: \\n\"", ".", "format", "(", "iou_type", ")", "+", "table", ")", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "print", "(", "table", ")", "\n", "#", "\n", "import", "sys", "\n", "sys", ".", "stdout", ".", "write", "(", "table", ")", "\n", "\n", "results", ".", "update", "(", "{", "\"AP-\"", "+", "name", ":", "ap", "for", "name", ",", "ap", "in", "results_per_category", "}", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation.instances_to_coco_json": [[393, 453], ["len", "instances.pred_boxes.tensor.numpy", "detectron2.structures.BoxMode.convert", "boxes.tolist.tolist", "instances.scores.tolist", "instances.pred_classes.tolist", "instances.has", "instances.has", "range", "results.append", "rle[].decode", "keypoints[].flatten().tolist", "pycocotools.encode", "numpy.array", "keypoints[].flatten"], "function", ["None"], ["", "", "def", "instances_to_coco_json", "(", "instances", ",", "img_id", ")", ":", "\n", "    ", "\"\"\"\n    Dump an \"Instances\" object to a COCO-format json that's used for evaluation.\n\n    Args:\n        instances (Instances):\n        img_id (int): the image id\n\n    Returns:\n        list[dict]: list of json annotations in COCO format.\n    \"\"\"", "\n", "num_instance", "=", "len", "(", "instances", ")", "\n", "if", "num_instance", "==", "0", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "boxes", "=", "instances", ".", "pred_boxes", ".", "tensor", ".", "numpy", "(", ")", "\n", "boxes", "=", "BoxMode", ".", "convert", "(", "boxes", ",", "BoxMode", ".", "XYXY_ABS", ",", "BoxMode", ".", "XYWH_ABS", ")", "\n", "boxes", "=", "boxes", ".", "tolist", "(", ")", "\n", "scores", "=", "instances", ".", "scores", ".", "tolist", "(", ")", "\n", "classes", "=", "instances", ".", "pred_classes", ".", "tolist", "(", ")", "\n", "\n", "has_mask", "=", "instances", ".", "has", "(", "\"pred_masks\"", ")", "\n", "if", "has_mask", ":", "\n", "# use RLE to encode the masks, because they are too large and takes memory", "\n", "# since this evaluator stores outputs of the entire dataset", "\n", "        ", "rles", "=", "[", "\n", "mask_util", ".", "encode", "(", "np", ".", "array", "(", "mask", "[", ":", ",", ":", ",", "None", "]", ",", "order", "=", "\"F\"", ",", "dtype", "=", "\"uint8\"", ")", ")", "[", "0", "]", "\n", "for", "mask", "in", "instances", ".", "pred_masks", "\n", "]", "\n", "for", "rle", "in", "rles", ":", "\n", "# \"counts\" is an array encoded by mask_util as a byte-stream. Python3's", "\n", "# json writer which always produces strings cannot serialize a bytestream", "\n", "# unless you decode it. Thankfully, utf-8 works out (which is also what", "\n", "# the pycocotools/_mask.pyx does).", "\n", "            ", "rle", "[", "\"counts\"", "]", "=", "rle", "[", "\"counts\"", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "", "", "has_keypoints", "=", "instances", ".", "has", "(", "\"pred_keypoints\"", ")", "\n", "if", "has_keypoints", ":", "\n", "        ", "keypoints", "=", "instances", ".", "pred_keypoints", "\n", "\n", "", "results", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "num_instance", ")", ":", "\n", "        ", "result", "=", "{", "\n", "\"image_id\"", ":", "img_id", ",", "\n", "\"category_id\"", ":", "classes", "[", "k", "]", ",", "\n", "\"bbox\"", ":", "boxes", "[", "k", "]", ",", "\n", "\"score\"", ":", "scores", "[", "k", "]", ",", "\n", "}", "\n", "if", "has_mask", ":", "\n", "            ", "result", "[", "\"segmentation\"", "]", "=", "rles", "[", "k", "]", "\n", "", "if", "has_keypoints", ":", "\n", "# In COCO annotations,", "\n", "# keypoints coordinates are pixel indices.", "\n", "# However our predictions are floating point coordinates.", "\n", "# Therefore we subtract 0.5 to be consistent with the annotation format.", "\n", "# This is the inverse of data loading logic in `datasets/coco.py`.", "\n", "            ", "keypoints", "[", "k", "]", "[", ":", ",", ":", "2", "]", "-=", "0.5", "\n", "result", "[", "\"keypoints\"", "]", "=", "keypoints", "[", "k", "]", ".", "flatten", "(", ")", ".", "tolist", "(", ")", "\n", "", "results", ".", "append", "(", "result", ")", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation._evaluate_box_proposals": [[457, 565], ["torch.sort", "torch.zeros_like", "enumerate", "torch.zeros_like.mean", "coco_api.getAnnIds", "coco_api.loadAnns", "torch.as_tensor().reshape", "detectron2.structures.Boxes", "torch.as_tensor", "len", "detectron2.structures.pairwise_iou", "torch.zeros", "range", "gt_overlaps.append", "len", "torch.cat", "torch.zeros", "torch.arange", "predictions.objectness_logits.sort", "detectron2.structures.BoxMode.convert", "len", "len", "min", "detectron2.structures.pairwise_iou.max", "max_overlaps.max", "float", "torch.as_tensor", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "_evaluate_box_proposals", "(", "dataset_predictions", ",", "coco_api", ",", "thresholds", "=", "None", ",", "area", "=", "\"all\"", ",", "limit", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate detection proposal recall metrics. This function is a much\n    faster alternative to the official COCO API recall evaluation code. However,\n    it produces slightly different results.\n    \"\"\"", "\n", "# Record max overlap value for each gt box", "\n", "# Return vector of overlap values", "\n", "areas", "=", "{", "\n", "\"all\"", ":", "0", ",", "\n", "\"small\"", ":", "1", ",", "\n", "\"medium\"", ":", "2", ",", "\n", "\"large\"", ":", "3", ",", "\n", "\"96-128\"", ":", "4", ",", "\n", "\"128-256\"", ":", "5", ",", "\n", "\"256-512\"", ":", "6", ",", "\n", "\"512-inf\"", ":", "7", ",", "\n", "}", "\n", "area_ranges", "=", "[", "\n", "[", "0", "**", "2", ",", "1e5", "**", "2", "]", ",", "# all", "\n", "[", "0", "**", "2", ",", "32", "**", "2", "]", ",", "# small", "\n", "[", "32", "**", "2", ",", "96", "**", "2", "]", ",", "# medium", "\n", "[", "96", "**", "2", ",", "1e5", "**", "2", "]", ",", "# large", "\n", "[", "96", "**", "2", ",", "128", "**", "2", "]", ",", "# 96-128", "\n", "[", "128", "**", "2", ",", "256", "**", "2", "]", ",", "# 128-256", "\n", "[", "256", "**", "2", ",", "512", "**", "2", "]", ",", "# 256-512", "\n", "[", "512", "**", "2", ",", "1e5", "**", "2", "]", ",", "\n", "]", "# 512-inf", "\n", "assert", "area", "in", "areas", ",", "\"Unknown area range: {}\"", ".", "format", "(", "area", ")", "\n", "area_range", "=", "area_ranges", "[", "areas", "[", "area", "]", "]", "\n", "gt_overlaps", "=", "[", "]", "\n", "num_pos", "=", "0", "\n", "\n", "for", "prediction_dict", "in", "dataset_predictions", ":", "\n", "        ", "predictions", "=", "prediction_dict", "[", "\"proposals\"", "]", "\n", "\n", "# sort predictions in descending order", "\n", "# TODO maybe remove this and make it explicit in the documentation", "\n", "inds", "=", "predictions", ".", "objectness_logits", ".", "sort", "(", "descending", "=", "True", ")", "[", "1", "]", "\n", "predictions", "=", "predictions", "[", "inds", "]", "\n", "\n", "ann_ids", "=", "coco_api", ".", "getAnnIds", "(", "imgIds", "=", "prediction_dict", "[", "\"image_id\"", "]", ")", "\n", "anno", "=", "coco_api", ".", "loadAnns", "(", "ann_ids", ")", "\n", "gt_boxes", "=", "[", "\n", "BoxMode", ".", "convert", "(", "obj", "[", "\"bbox\"", "]", ",", "BoxMode", ".", "XYWH_ABS", ",", "BoxMode", ".", "XYXY_ABS", ")", "\n", "for", "obj", "in", "anno", "\n", "if", "obj", "[", "\"iscrowd\"", "]", "==", "0", "\n", "]", "\n", "gt_boxes", "=", "torch", ".", "as_tensor", "(", "gt_boxes", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "# guard against no boxes", "\n", "gt_boxes", "=", "Boxes", "(", "gt_boxes", ")", "\n", "gt_areas", "=", "torch", ".", "as_tensor", "(", "[", "obj", "[", "\"area\"", "]", "for", "obj", "in", "anno", "if", "obj", "[", "\"iscrowd\"", "]", "==", "0", "]", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", "or", "len", "(", "predictions", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "valid_gt_inds", "=", "(", "gt_areas", ">=", "area_range", "[", "0", "]", ")", "&", "(", "gt_areas", "<=", "area_range", "[", "1", "]", ")", "\n", "gt_boxes", "=", "gt_boxes", "[", "valid_gt_inds", "]", "\n", "\n", "num_pos", "+=", "len", "(", "gt_boxes", ")", "\n", "\n", "if", "len", "(", "gt_boxes", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "limit", "is", "not", "None", "and", "len", "(", "predictions", ")", ">", "limit", ":", "\n", "            ", "predictions", "=", "predictions", "[", ":", "limit", "]", "\n", "\n", "", "overlaps", "=", "pairwise_iou", "(", "predictions", ".", "proposal_boxes", ",", "gt_boxes", ")", "\n", "\n", "_gt_overlaps", "=", "torch", ".", "zeros", "(", "len", "(", "gt_boxes", ")", ")", "\n", "for", "j", "in", "range", "(", "min", "(", "len", "(", "predictions", ")", ",", "len", "(", "gt_boxes", ")", ")", ")", ":", "\n", "# find which proposal box maximally covers each gt box", "\n", "# and get the iou amount of coverage for each gt box", "\n", "            ", "max_overlaps", ",", "argmax_overlaps", "=", "overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "\n", "# find which gt box is 'best' covered (i.e. 'best' = most iou)", "\n", "gt_ovr", ",", "gt_ind", "=", "max_overlaps", ".", "max", "(", "dim", "=", "0", ")", "\n", "assert", "gt_ovr", ">=", "0", "\n", "# find the proposal box that covers the best covered gt box", "\n", "box_ind", "=", "argmax_overlaps", "[", "gt_ind", "]", "\n", "# record the iou coverage of this gt box", "\n", "_gt_overlaps", "[", "j", "]", "=", "overlaps", "[", "box_ind", ",", "gt_ind", "]", "\n", "assert", "_gt_overlaps", "[", "j", "]", "==", "gt_ovr", "\n", "# mark the proposal box and the gt box as used", "\n", "overlaps", "[", "box_ind", ",", ":", "]", "=", "-", "1", "\n", "overlaps", "[", ":", ",", "gt_ind", "]", "=", "-", "1", "\n", "\n", "# append recorded iou coverage level", "\n", "", "gt_overlaps", ".", "append", "(", "_gt_overlaps", ")", "\n", "", "gt_overlaps", "=", "(", "\n", "torch", ".", "cat", "(", "gt_overlaps", ",", "dim", "=", "0", ")", "if", "len", "(", "gt_overlaps", ")", "else", "torch", ".", "zeros", "(", "0", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", ")", "\n", "gt_overlaps", ",", "_", "=", "torch", ".", "sort", "(", "gt_overlaps", ")", "\n", "\n", "if", "thresholds", "is", "None", ":", "\n", "        ", "step", "=", "0.05", "\n", "thresholds", "=", "torch", ".", "arange", "(", "0.5", ",", "0.95", "+", "1e-5", ",", "step", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "recalls", "=", "torch", ".", "zeros_like", "(", "thresholds", ")", "\n", "# compute recall for each iou threshold", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "        ", "recalls", "[", "i", "]", "=", "(", "gt_overlaps", ">=", "t", ")", ".", "float", "(", ")", ".", "sum", "(", ")", "/", "float", "(", "num_pos", ")", "\n", "# ar = 2 * np.trapz(recalls, thresholds)", "\n", "", "ar", "=", "recalls", ".", "mean", "(", ")", "\n", "return", "{", "\n", "\"ar\"", ":", "ar", ",", "\n", "\"recalls\"", ":", "recalls", ",", "\n", "\"thresholds\"", ":", "thresholds", ",", "\n", "\"gt_overlaps\"", ":", "gt_overlaps", ",", "\n", "\"num_pos\"", ":", "num_pos", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.coco_evaluation._evaluate_predictions_on_coco": [[568, 613], ["coco_gt.loadRes", "coco_eval.evaluate", "coco_eval.accumulate", "coco_eval.summarize", "len", "copy.deepcopy", "len", "c.pop", "hasattr", "numpy.array", "len", "len", "next", "iter", "coco_gt.anns.values"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.evaluate", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.iter"], ["", "def", "_evaluate_predictions_on_coco", "(", "\n", "coco_gt", ",", "coco_results", ",", "iou_type", ",", "kpt_oks_sigmas", "=", "None", ",", "use_fast_impl", "=", "True", ",", "img_ids", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate the coco results using COCOEval API.\n    \"\"\"", "\n", "assert", "len", "(", "coco_results", ")", ">", "0", "\n", "\n", "if", "iou_type", "==", "\"segm\"", ":", "\n", "        ", "coco_results", "=", "copy", ".", "deepcopy", "(", "coco_results", ")", "\n", "# When evaluating mask AP, if the results contain bbox, cocoapi will", "\n", "# use the box area as the area of the instance, instead of the mask area.", "\n", "# This leads to a different definition of small/medium/large.", "\n", "# We remove the bbox field to let mask AP use mask area.", "\n", "for", "c", "in", "coco_results", ":", "\n", "            ", "c", ".", "pop", "(", "\"bbox\"", ",", "None", ")", "\n", "\n", "", "", "coco_dt", "=", "coco_gt", ".", "loadRes", "(", "coco_results", ")", "\n", "coco_eval", "=", "(", "COCOeval_opt", "if", "use_fast_impl", "else", "COCOeval", ")", "(", "coco_gt", ",", "coco_dt", ",", "iou_type", ")", "\n", "if", "img_ids", "is", "not", "None", ":", "\n", "        ", "coco_eval", ".", "params", ".", "imgIds", "=", "img_ids", "\n", "\n", "", "if", "iou_type", "==", "\"keypoints\"", ":", "\n", "# Use the COCO default keypoint OKS sigmas unless overrides are specified", "\n", "        ", "if", "kpt_oks_sigmas", ":", "\n", "            ", "assert", "hasattr", "(", "coco_eval", ".", "params", ",", "\"kpt_oks_sigmas\"", ")", ",", "\"pycocotools is too old!\"", "\n", "coco_eval", ".", "params", ".", "kpt_oks_sigmas", "=", "np", ".", "array", "(", "kpt_oks_sigmas", ")", "\n", "# COCOAPI requires every detection and every gt to have keypoints, so", "\n", "# we just take the first entry from both", "\n", "", "num_keypoints_dt", "=", "len", "(", "coco_results", "[", "0", "]", "[", "\"keypoints\"", "]", ")", "//", "3", "\n", "num_keypoints_gt", "=", "len", "(", "next", "(", "iter", "(", "coco_gt", ".", "anns", ".", "values", "(", ")", ")", ")", "[", "\"keypoints\"", "]", ")", "//", "3", "\n", "num_keypoints_oks", "=", "len", "(", "coco_eval", ".", "params", ".", "kpt_oks_sigmas", ")", "\n", "assert", "num_keypoints_oks", "==", "num_keypoints_dt", "==", "num_keypoints_gt", ",", "(", "\n", "f\"[COCOEvaluator] Prediction contain {num_keypoints_dt} keypoints. \"", "\n", "f\"Ground truth contains {num_keypoints_gt} keypoints. \"", "\n", "f\"The length of cfg.TEST.KEYPOINT_OKS_SIGMAS is {num_keypoints_oks}. \"", "\n", "\"They have to agree with each other. For meaning of OKS, please refer to \"", "\n", "\"http://cocodataset.org/#keypoints-eval.\"", "\n", ")", "\n", "\n", "", "coco_eval", ".", "evaluate", "(", ")", "\n", "coco_eval", ".", "accumulate", "(", ")", "\n", "coco_eval", ".", "summarize", "(", ")", "\n", "\n", "return", "coco_eval", "\n", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluator.reset": [[27, 33], ["None"], "methods", ["None"], ["def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Preparation for a new round of evaluation.\n        Should be called before starting a round of evaluation.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluator.process": [[34, 50], ["None"], "methods", ["None"], ["", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"\n        Process the pair of inputs and outputs.\n        If they contain batches, the pairs can be consumed one-by-one using `zip`:\n\n        .. code-block:: python\n\n            for input_, output in zip(inputs, outputs):\n                # do evaluation on single input/output pair\n                ...\n\n        Args:\n            inputs (list): the inputs that's used to call the model.\n            outputs (list): the return value of `model(inputs)`\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluator.evaluate": [[51, 65], ["None"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Evaluate/summarize the performance, after processing all input/output pairs.\n\n        Returns:\n            dict:\n                A new evaluator class can return a dict of arbitrary format\n                as long as the user can process the results.\n                In our train_net.py, we expect the following format:\n\n                * key: the name of the task (e.g., bbox)\n                * value: a dict of {metric name: score}, e.g.: {\"AP50\": 80}\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.__init__": [[75, 82], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["def", "__init__", "(", "self", ",", "evaluators", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            evaluators (list): the evaluators to combine.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_evaluators", "=", "evaluators", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.reset": [[83, 86], ["evaluator.reset"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "evaluator", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.process": [[87, 90], ["evaluator.process"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.process"], ["", "", "def", "process", "(", "self", ",", "inputs", ",", "outputs", ")", ":", "\n", "        ", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "evaluator", ".", "process", "(", "inputs", ",", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.evaluate": [[91, 102], ["collections.OrderedDict", "evaluator.evaluate", "detectron2.utils.comm.is_main_process", "evaluator.evaluate.items"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.evaluate", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.is_main_process"], ["", "", "def", "evaluate", "(", "self", ")", ":", "\n", "        ", "results", "=", "OrderedDict", "(", ")", "\n", "for", "evaluator", "in", "self", ".", "_evaluators", ":", "\n", "            ", "result", "=", "evaluator", ".", "evaluate", "(", ")", "\n", "if", "is_main_process", "(", ")", "and", "result", "is", "not", "None", ":", "\n", "                ", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ":", "\n", "                    ", "assert", "(", "\n", "k", "not", "in", "results", "\n", ")", ",", "\"Different evaluators produce results with the same key {}\"", ".", "format", "(", "k", ")", "\n", "results", "[", "k", "]", "=", "v", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.inference_on_dataset": [[104, 209], ["detectron2.utils.comm.get_world_size", "logging.getLogger", "logging.getLogger.info", "len", "isinstance", "evaluator.DatasetEvaluators.reset", "min", "time.perf_counter", "str", "logging.getLogger.info", "str", "logging.getLogger.info", "evaluator.DatasetEvaluators.evaluate", "evaluator.DatasetEvaluators", "evaluator.DatasetEvaluators", "contextlib.ExitStack", "isinstance", "stack.enter_context", "enumerate", "time.perf_counter", "datetime.timedelta", "datetime.timedelta", "len", "stack.enter_context", "torch.no_grad", "time.perf_counter", "model", "torch.cuda.is_available", "evaluator.DatasetEvaluators.process", "evaluator.inference_context", "time.perf_counter", "torch.cuda.synchronize", "time.perf_counter", "datetime.timedelta", "detectron2.utils.logger.log_every_n_seconds", "int", "int", "time.perf_counter", "int", "str"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.reset", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.evaluate", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.process", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.inference_context", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.synchronize", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger.log_every_n_seconds"], ["", "", "def", "inference_on_dataset", "(", "\n", "model", ",", "data_loader", ",", "evaluator", ":", "Union", "[", "DatasetEvaluator", ",", "List", "[", "DatasetEvaluator", "]", ",", "None", "]", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Run model on the data_loader and evaluate the metrics with evaluator.\n    Also benchmark the inference speed of `model.__call__` accurately.\n    The model will be used in eval mode.\n\n    Args:\n        model (callable): a callable which takes an object from\n            `data_loader` and returns some outputs.\n\n            If it's an nn.Module, it will be temporarily set to `eval` mode.\n            If you wish to evaluate a model in `training` mode instead, you can\n            wrap the given model and override its behavior of `.eval()` and `.train()`.\n        data_loader: an iterable object with a length.\n            The elements it generates will be the inputs to the model.\n        evaluator: the evaluator(s) to run. Use `None` if you only want to benchmark,\n            but don't want to do any evaluation.\n\n    Returns:\n        The return value of `evaluator.evaluate()`\n    \"\"\"", "\n", "num_devices", "=", "get_world_size", "(", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Start inference on {} images\"", ".", "format", "(", "len", "(", "data_loader", ")", ")", ")", "\n", "\n", "total", "=", "len", "(", "data_loader", ")", "# inference data loader must have a fixed length", "\n", "if", "evaluator", "is", "None", ":", "\n", "# create a no-op evaluator", "\n", "        ", "evaluator", "=", "DatasetEvaluators", "(", "[", "]", ")", "\n", "", "if", "isinstance", "(", "evaluator", ",", "abc", ".", "MutableSequence", ")", ":", "\n", "        ", "evaluator", "=", "DatasetEvaluators", "(", "evaluator", ")", "\n", "", "evaluator", ".", "reset", "(", ")", "\n", "box_feature_to_save", "=", "[", "]", "\n", "box_predictions_to_save", "=", "[", "]", "\n", "box_score_to_save", "=", "[", "]", "\n", "img_feature_to_save", "=", "[", "]", "\n", "proposal_dict", "=", "{", "\"ids\"", ":", "[", "]", ",", "\n", "\"boxes\"", ":", "[", "]", ",", "\n", "\"objectness_logits\"", ":", "[", "]", "\n", "}", "\n", "# feature_to_save", "\n", "num_warmup", "=", "min", "(", "5", ",", "total", "-", "1", ")", "\n", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "total_compute_time", "=", "0", "\n", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "        ", "if", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", ":", "\n", "            ", "stack", ".", "enter_context", "(", "inference_context", "(", "model", ")", ")", "\n", "", "stack", ".", "enter_context", "(", "torch", ".", "no_grad", "(", ")", ")", "\n", "\n", "for", "idx", ",", "inputs", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "if", "idx", "==", "num_warmup", ":", "\n", "                ", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "total_compute_time", "=", "0", "\n", "\n", "", "start_compute_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "#for save proposal", "\n", "outputs", ",", "box_feature_save", "=", "model", "(", "inputs", ")", "\n", "\n", "\n", "# outputs= model(inputs)", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "", "total_compute_time", "+=", "time", ".", "perf_counter", "(", ")", "-", "start_compute_time", "\n", "evaluator", ".", "process", "(", "inputs", ",", "outputs", ")", "\n", "\n", "iters_after_start", "=", "idx", "+", "1", "-", "num_warmup", "*", "int", "(", "idx", ">=", "num_warmup", ")", "\n", "seconds_per_img", "=", "total_compute_time", "/", "iters_after_start", "\n", "if", "idx", ">=", "num_warmup", "*", "2", "or", "seconds_per_img", ">", "5", ":", "\n", "                ", "total_seconds_per_img", "=", "(", "time", ".", "perf_counter", "(", ")", "-", "start_time", ")", "/", "iters_after_start", "\n", "eta", "=", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_seconds_per_img", "*", "(", "total", "-", "idx", "-", "1", ")", ")", ")", "\n", "log_every_n_seconds", "(", "\n", "logging", ".", "INFO", ",", "\n", "\"Inference done {}/{}. {:.4f} s / img. ETA={}\"", ".", "format", "(", "\n", "idx", "+", "1", ",", "total", ",", "seconds_per_img", ",", "str", "(", "eta", ")", "\n", ")", ",", "\n", "n", "=", "5", ",", "\n", ")", "\n", "\n", "# Measure the time only for this worker (before the synchronization barrier)", "\n", "", "", "", "total_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "total_time", ")", ")", "\n", "# NOTE this format is parsed by grep", "\n", "logger", ".", "info", "(", "\n", "\"Total inference time: {} ({:.6f} s / img per device, on {} devices)\"", ".", "format", "(", "\n", "total_time_str", ",", "total_time", "/", "(", "total", "-", "num_warmup", ")", ",", "num_devices", "\n", ")", "\n", ")", "\n", "total_compute_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_compute_time", ")", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total inference pure compute time: {} ({:.6f} s / img per device, on {} devices)\"", ".", "format", "(", "\n", "total_compute_time_str", ",", "total_compute_time", "/", "(", "total", "-", "num_warmup", ")", ",", "num_devices", "\n", ")", "\n", ")", "\n", "\n", "\n", "\n", "results", "=", "evaluator", ".", "evaluate", "(", ")", "\n", "\n", "if", "results", "is", "None", ":", "\n", "        ", "results", "=", "{", "}", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.two_head_inference_on_dataset": [[212, 334], ["detectron2.utils.comm.get_world_size", "logging.getLogger", "logging.getLogger.info", "len", "isinstance", "evaluator.DatasetEvaluators.reset", "evaluator.DatasetEvaluators.reset", "min", "time.perf_counter", "str", "logging.getLogger.info", "str", "logging.getLogger.info", "evaluator.DatasetEvaluators", "evaluator.DatasetEvaluators", "evaluator.DatasetEvaluators", "evaluator.DatasetEvaluators", "contextlib.ExitStack", "isinstance", "stack.enter_context", "enumerate", "time.perf_counter", "datetime.timedelta", "datetime.timedelta", "evaluator.DatasetEvaluators.evaluate", "logging.getLogger.info", "len", "stack.enter_context", "torch.no_grad", "time.perf_counter", "model", "torch.cuda.is_available", "evaluator.DatasetEvaluators.evaluate", "logging.getLogger.info", "evaluator.inference_context", "time.perf_counter", "torch.cuda.synchronize", "time.perf_counter", "evaluator.DatasetEvaluators.process", "datetime.timedelta", "detectron2.utils.logger.log_every_n_seconds", "int", "evaluator.DatasetEvaluators.process", "int", "time.perf_counter", "int", "str"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.get_world_size", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.reset", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.reset", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.evaluate", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.evaluate", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.inference_context", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.comm.synchronize", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.process", "home.repos.pwc.inspect_result.feobi1999_tdd.utils.logger.log_every_n_seconds", "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.DatasetEvaluators.process"], ["", "def", "two_head_inference_on_dataset", "(", "\n", "model", ",", "data_loader", ",", "head", ",", "evaluator_1", ",", "evaluator_2", ":", "Union", "[", "DatasetEvaluator", ",", "List", "[", "DatasetEvaluator", "]", ",", "None", "]", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Run model on the data_loader and evaluate the metrics with evaluator.\n    Also benchmark the inference speed of `model.__call__` accurately.\n    The model will be used in eval mode.\n\n    Args:\n        model (callable): a callable which takes an object from\n            `data_loader` and returns some outputs.\n\n            If it's an nn.Module, it will be temporarily set to `eval` mode.\n            If you wish to evaluate a model in `training` mode instead, you can\n            wrap the given model and override its behavior of `.eval()` and `.train()`.\n        data_loader: an iterable object with a length.\n            The elements it generates will be the inputs to the model.\n        evaluator: the evaluator(s) to run. Use `None` if you only want to benchmark,\n            but don't want to do any evaluation.\n\n    Returns:\n        The return value of `evaluator.evaluate()`\n    \"\"\"", "\n", "num_devices", "=", "get_world_size", "(", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Start inference on {} images\"", ".", "format", "(", "len", "(", "data_loader", ")", ")", ")", "\n", "\n", "total", "=", "len", "(", "data_loader", ")", "# inference data loader must have a fixed length", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "if", "evaluator_1", "is", "None", ":", "\n", "# create a no-op evaluator", "\n", "        ", "evaluator_1", "=", "DatasetEvaluators", "(", "[", "]", ")", "\n", "evaluator_2", "=", "DatasetEvaluators", "(", "[", "]", ")", "\n", "\n", "", "if", "isinstance", "(", "evaluator_1", ",", "abc", ".", "MutableSequence", ")", ":", "\n", "        ", "evaluator_1", "=", "DatasetEvaluators", "(", "evaluator_1", ")", "\n", "evaluator_2", "=", "DatasetEvaluators", "(", "evaluator_2", ")", "\n", "\n", "", "evaluator_1", ".", "reset", "(", ")", "\n", "evaluator_2", ".", "reset", "(", ")", "\n", "\n", "num_warmup", "=", "min", "(", "5", ",", "total", "-", "1", ")", "\n", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "total_compute_time", "=", "0", "\n", "with", "ExitStack", "(", ")", "as", "stack", ":", "\n", "        ", "if", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", ":", "\n", "            ", "stack", ".", "enter_context", "(", "inference_context", "(", "model", ")", ")", "\n", "", "stack", ".", "enter_context", "(", "torch", ".", "no_grad", "(", ")", ")", "\n", "\n", "save_feature", "=", "[", "]", "\n", "for", "idx", ",", "inputs", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "if", "idx", "==", "num_warmup", ":", "\n", "                ", "start_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "total_compute_time", "=", "0", "\n", "\n", "", "start_compute_time", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "''' two head inference '''", "\n", "\n", "# outputs1, outputs2 = model(inputs)", "\n", "outputs1", ",", "outputs2", ",", "feature_1", ",", "feature_2", "=", "model", "(", "inputs", ")", "\n", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "", "total_compute_time", "+=", "time", ".", "perf_counter", "(", ")", "-", "start_compute_time", "\n", "if", "head", "==", "1", ":", "\n", "                ", "evaluator_1", ".", "process", "(", "inputs", ",", "outputs1", ")", "\n", "\n", "", "elif", "head", "==", "2", ":", "\n", "                ", "evaluator_2", ".", "process", "(", "inputs", ",", "outputs2", ")", "\n", "\n", "\n", "", "iters_after_start", "=", "idx", "+", "1", "-", "num_warmup", "*", "int", "(", "idx", ">=", "num_warmup", ")", "\n", "seconds_per_img", "=", "total_compute_time", "/", "iters_after_start", "\n", "if", "idx", ">=", "num_warmup", "*", "2", "or", "seconds_per_img", ">", "5", ":", "\n", "                ", "total_seconds_per_img", "=", "(", "time", ".", "perf_counter", "(", ")", "-", "start_time", ")", "/", "iters_after_start", "\n", "eta", "=", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_seconds_per_img", "*", "(", "total", "-", "idx", "-", "1", ")", ")", ")", "\n", "log_every_n_seconds", "(", "\n", "logging", ".", "INFO", ",", "\n", "\"Inference done {}/{}. {:.4f} s / img. ETA={}\"", ".", "format", "(", "\n", "idx", "+", "1", ",", "total", ",", "seconds_per_img", ",", "str", "(", "eta", ")", "\n", ")", ",", "\n", "n", "=", "5", ",", "\n", ")", "\n", "\n", "\n", "# Measure the time only for this worker (before the synchronization barrier)", "\n", "", "", "", "total_time", "=", "time", ".", "perf_counter", "(", ")", "-", "start_time", "\n", "total_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "total_time", ")", ")", "\n", "# NOTE this format is parsed by grep", "\n", "logger", ".", "info", "(", "\n", "\"Total inference time: {} ({:.6f} s / img per device, on {} devices)\"", ".", "format", "(", "\n", "total_time_str", ",", "total_time", "/", "(", "total", "-", "num_warmup", ")", ",", "num_devices", "\n", ")", "\n", ")", "\n", "total_compute_time_str", "=", "str", "(", "datetime", ".", "timedelta", "(", "seconds", "=", "int", "(", "total_compute_time", ")", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Total inference pure compute time: {} ({:.6f} s / img per device, on {} devices)\"", ".", "format", "(", "\n", "total_compute_time_str", ",", "total_compute_time", "/", "(", "total", "-", "num_warmup", ")", ",", "num_devices", "\n", ")", "\n", ")", "\n", "\n", "\n", "\n", "if", "head", "==", "1", ":", "\n", "\n", "        ", "results", "=", "evaluator_1", ".", "evaluate", "(", ")", "\n", "logger", ".", "info", "(", "\"evaluate_head1\"", ")", "\n", "\n", "", "elif", "head", "==", "2", ":", "\n", "        ", "results", "=", "evaluator_2", ".", "evaluate", "(", ")", "\n", "logger", ".", "info", "(", "\"evaluate_head2\"", ")", "\n", "\n", "\n", "# An evaluator may return None when not in main process.", "\n", "# Replace it by an empty dict instead to make it easier for downstream code to handle", "\n", "", "if", "results", "is", "None", ":", "\n", "        ", "results", "=", "{", "}", "\n", "\n", "", "return", "results", ",", "save_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.evaluation.evaluator.inference_context": [[335, 348], ["model.eval", "model.train"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.engine.source_fft_np_trainer.UBTeacherTrainer.train"], ["", "@", "contextmanager", "\n", "def", "inference_context", "(", "model", ")", ":", "\n", "    ", "\"\"\"\n    A context where the model is temporarily changed to eval mode,\n    and restored to previous mode afterwards.\n\n    Args:\n        model: a torch Module\n    \"\"\"", "\n", "training_mode", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "yield", "\n", "model", ".", "train", "(", "training_mode", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.feobi1999_tdd.solver.build._create_gradient_clipper": [[28, 46], ["copy.deepcopy", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.clip_grad_value_", "build.GradientClipType"], "function", ["None"], ["build_batch_data_loader", ",", "\n", "filter_images_with_only_crowd_annotations", ",", "\n", "filter_images_with_few_keypoints", ",", "\n", "print_instances_class_histogram", "\n", ")", "\n", "from", "ubteacher", ".", "data", ".", "common", "import", "(", "\n", "AspectRatioGroupedSemiSupDatasetTwoCrop", ",", "\n", ")", "\n", "\n", "from", "ubteacher", ".", "data", ".", "common", "import", "(", "\n", "AspectRatioGroupedSemiSupDatasetThreeCrop", ",", "\n", ")", "\n", "\n", "from", "detectron2", ".", "data", ".", "detection_utils", "import", "check_metadata_consistency", "\n", "\n", "\"\"\"\nThis file contains the default logic to build a dataloader for training or testing.\n\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.solver.build._generate_optimizer_class_with_gradient_clipping": [[48, 80], ["type", "super().step", "itertools.chain", "global_clipper", "per_param_clipper", "type"], "function", ["home.repos.pwc.inspect_result.feobi1999_tdd.utils.events.EventStorage.step"], ["def", "divide_label_unlabel", "(", "\n", "dataset_dicts", ",", "SupPercent", ",", "random_data_seed", ",", "random_data_seed_path", "\n", ")", ":", "\n", "    ", "num_all", "=", "len", "(", "dataset_dicts", ")", "\n", "num_label", "=", "int", "(", "SupPercent", "/", "100.0", "*", "num_all", ")", "\n", "\n", "# read from pre-generated data seed", "\n", "# with open(random_data_seed_path) as COCO_sup_file:", "\n", "#     coco_random_idx = json.load(COCO_sup_file)", "\n", "labeled_idx", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "num_all", ")", ",", "size", "=", "num_label", ",", "replace", "=", "False", ")", "\n", "# labeled_idx = np.array(coco_random_idx[str(SupPercent)][str(random_data_seed)])", "\n", "assert", "labeled_idx", ".", "shape", "[", "0", "]", "==", "num_label", ",", "\"Number of READ_DATA is mismatched.\"", "\n", "\n", "label_dicts", "=", "[", "]", "\n", "unlabel_dicts", "=", "[", "]", "\n", "labeled_idx", "=", "set", "(", "labeled_idx", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset_dicts", ")", ")", ":", "\n", "        ", "if", "i", "in", "labeled_idx", ":", "\n", "            ", "label_dicts", ".", "append", "(", "dataset_dicts", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "            ", "unlabel_dicts", ".", "append", "(", "dataset_dicts", "[", "i", "]", ")", "\n", "\n", "", "", "return", "label_dicts", ",", "unlabel_dicts", "\n", "\n", "\n", "# uesed by supervised-only baseline trainer", "\n", "", "def", "build_detection_semisup_train_loader", "(", "cfg", ",", "mapper", "=", "None", ")", ":", "\n", "\n", "    ", "dataset_dicts", "=", "get_detection_dataset_dicts", "(", "\n", "cfg", ".", "DATASETS", ".", "TRAIN", ",", "\n", "filter_empty", "=", "cfg", ".", "DATALOADER", ".", "FILTER_EMPTY_ANNOTATIONS", ",", "\n", "min_keypoints", "=", "cfg", ".", "MODEL", ".", "ROI_KEYPOINT_HEAD", ".", "MIN_KEYPOINTS_PER_IMAGE", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_lr_scheduler": [[81, 117], ["detectron2.solver.lr_scheduler.WarmupMultiStepLR", "detectron2.solver.lr_scheduler.WarmupCosineLR", "lr_scheduler.WarmupTwoStageMultiStepLR", "ValueError"], "function", ["None"], ["if", "cfg", ".", "MODEL", ".", "KEYPOINT_ON", "\n", "else", "0", ",", "\n", "proposal_files", "=", "cfg", ".", "DATASETS", ".", "PROPOSAL_FILES_TRAIN", "\n", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "else", "None", ",", "\n", ")", "\n", "\n", "# Divide into labeled and unlabeled sets according to supervision percentage", "\n", "label_dicts", ",", "unlabel_dicts", "=", "divide_label_unlabel", "(", "\n", "dataset_dicts", ",", "\n", "cfg", ".", "DATALOADER", ".", "SUP_PERCENT", ",", "\n", "cfg", ".", "DATALOADER", ".", "RANDOM_DATA_SEED", ",", "\n", "cfg", ".", "DATALOADER", ".", "RANDOM_DATA_SEED_PATH", ",", "\n", ")", "\n", "\n", "dataset", "=", "DatasetFromList", "(", "label_dicts", ",", "copy", "=", "False", ")", "\n", "\n", "if", "mapper", "is", "None", ":", "\n", "        ", "mapper", "=", "DatasetMapper", "(", "cfg", ",", "True", ")", "\n", "", "dataset", "=", "MapDataset", "(", "dataset", ",", "mapper", ")", "\n", "\n", "sampler_name", "=", "cfg", ".", "DATALOADER", ".", "SAMPLER_TRAIN", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "logger", ".", "info", "(", "\"Using training sampler {}\"", ".", "format", "(", "sampler_name", ")", ")", "\n", "\n", "if", "sampler_name", "==", "\"TrainingSampler\"", ":", "\n", "        ", "sampler", "=", "TrainingSampler", "(", "len", "(", "dataset", ")", ")", "\n", "", "elif", "sampler_name", "==", "\"RepeatFactorTrainingSampler\"", ":", "\n", "        ", "repeat_factors", "=", "(", "\n", "RepeatFactorTrainingSampler", ".", "repeat_factors_from_category_frequency", "(", "\n", "label_dicts", ",", "cfg", ".", "DATALOADER", ".", "REPEAT_THRESHOLD", "\n", ")", "\n", ")", "\n", "sampler", "=", "RepeatFactorTrainingSampler", "(", "repeat_factors", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown training sampler: {}\"", ".", "format", "(", "sampler_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.solver.build.build_optimizer": [[119, 149], ["model.named_parameters", "model.named_parameters", "torch.optim.SGD", "torch.optim.SGD", "print", "key.endswith", "key.endswith", "logging.getLogger", "logging.getLogger.info"], "function", ["None"], ["", "logger", ".", "info", "(", "\"\bNumber of training samples \"", "+", "str", "(", "len", "(", "dataset", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"Supervision percentage \"", "+", "str", "(", "cfg", ".", "DATALOADER", ".", "SUP_PERCENT", ")", ")", "\n", "\n", "return", "build_batch_data_loader", "(", "\n", "dataset", ",", "\n", "sampler", ",", "\n", "cfg", ".", "SOLVER", ".", "IMS_PER_BATCH", ",", "\n", "aspect_ratio_grouping", "=", "cfg", ".", "DATALOADER", ".", "ASPECT_RATIO_GROUPING", ",", "\n", "num_workers", "=", "cfg", ".", "DATALOADER", ".", "NUM_WORKERS", ",", "\n", ")", "\n", "\n", "\n", "# uesed by evaluation", "\n", "", "def", "build_detection_test_loader", "(", "cfg", ",", "dataset_name", ",", "mapper", "=", "None", ")", ":", "\n", "    ", "dataset_dicts", "=", "get_detection_dataset_dicts_test", "(", "\n", "[", "dataset_name", "]", ",", "\n", "filter_empty", "=", "False", ",", "\n", "proposal_files", "=", "[", "\n", "cfg", ".", "DATASETS", ".", "PROPOSAL_FILES_TEST", "[", "\n", "list", "(", "cfg", ".", "DATASETS", ".", "TEST", ")", ".", "index", "(", "dataset_name", ")", "\n", "]", "\n", "]", "\n", "if", "cfg", ".", "MODEL", ".", "LOAD_PROPOSALS", "\n", "else", "None", ",", "\n", ")", "\n", "import", "pdb", "\n", "\n", "dataset", "=", "DatasetFromList", "(", "dataset_dicts", ")", "\n", "if", "mapper", "is", "None", ":", "\n", "        ", "mapper", "=", "DatasetMapper", "(", "cfg", ",", "False", ")", "\n", "", "dataset", "=", "MapDataset", "(", "dataset", ",", "mapper", ")", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__": [[9, 36], ["super().__init__", "ValueError", "len", "ValueError", "list", "sorted", "len"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "milestones", ":", "List", "[", "int", "]", ",", "\n", "factor_list", ":", "List", "[", "int", "]", ",", "\n", "gamma", ":", "float", "=", "0.1", ",", "\n", "warmup_factor", ":", "float", "=", "0.001", ",", "\n", "warmup_iters", ":", "int", "=", "1000", ",", "\n", "warmup_method", ":", "str", "=", "\"linear\"", ",", "\n", "last_epoch", ":", "int", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "if", "not", "list", "(", "milestones", ")", "==", "sorted", "(", "milestones", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Milestones should be a list of\"", "\" increasing integers. Got {}\"", ",", "\n", "milestones", ",", "\n", ")", "\n", "", "if", "len", "(", "milestones", ")", "+", "1", "!=", "len", "(", "factor_list", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Length of milestones should match length of factor_list.\"", ")", "\n", "\n", "", "self", ".", "milestones", "=", "milestones", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "warmup_factor", "=", "warmup_factor", "\n", "self", ".", "warmup_iters", "=", "warmup_iters", "\n", "self", ".", "warmup_method", "=", "warmup_method", "\n", "self", ".", "factor_list", "=", "factor_list", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.get_lr": [[37, 50], ["detectron2.solver.lr_scheduler._get_warmup_factor_at_iter", "bisect.bisect_right"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", "->", "List", "[", "float", "]", ":", "\n", "\n", "        ", "warmup_factor", "=", "_get_warmup_factor_at_iter", "(", "\n", "self", ".", "warmup_method", ",", "self", ".", "last_epoch", ",", "self", ".", "warmup_iters", ",", "self", ".", "warmup_factor", "\n", ")", "\n", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "return", "[", "\n", "base_lr", "\n", "*", "warmup_factor", "\n", "*", "self", ".", "factor_list", "[", "bisect_right", "(", "self", ".", "milestones", ",", "self", ".", "last_epoch", ")", "]", "\n", "for", "base_lr", "in", "self", ".", "base_lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR._compute_values": [[53, 56], ["lr_scheduler.WarmupTwoStageMultiStepLR.get_lr"], "methods", ["home.repos.pwc.inspect_result.feobi1999_tdd.solver.lr_scheduler.WarmupTwoStageMultiStepLR.get_lr"], ["", "def", "_compute_values", "(", "self", ")", "->", "List", "[", "float", "]", ":", "\n", "# The new interface", "\n", "        ", "return", "self", ".", "get_lr", "(", ")", "\n", "", "", ""]]}