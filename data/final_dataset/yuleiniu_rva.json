{"home.repos.pwc.inspect_result.yuleiniu_rva.None.train.lr_lambda_fun": [[199, 212], ["float", "bisect.bisect", "pow", "float"], "function", ["None"], ["", "def", "lr_lambda_fun", "(", "current_iteration", ":", "int", ")", "->", "float", ":", "\n", "    ", "\"\"\"Returns a learning rate multiplier.\n\n    Till `warmup_epochs`, learning rate linearly increases to `initial_lr`,\n    and then gets multiplied by `lr_gamma` every time a milestone is crossed.\n    \"\"\"", "\n", "current_epoch", "=", "float", "(", "current_iteration", ")", "/", "iterations", "\n", "if", "current_epoch", "<=", "config", "[", "\"solver\"", "]", "[", "\"warmup_epochs\"", "]", ":", "\n", "        ", "alpha", "=", "current_epoch", "/", "float", "(", "config", "[", "\"solver\"", "]", "[", "\"warmup_epochs\"", "]", ")", "\n", "return", "config", "[", "\"solver\"", "]", "[", "\"warmup_factor\"", "]", "*", "(", "1.0", "-", "alpha", ")", "+", "alpha", "\n", "", "else", ":", "\n", "        ", "idx", "=", "bisect", "(", "config", "[", "\"solver\"", "]", "[", "\"lr_milestones\"", "]", ",", "current_epoch", ")", "\n", "return", "pow", "(", "config", "[", "\"solver\"", "]", "[", "\"lr_gamma\"", "]", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.init_glove.loadGloveModel": [[39, 50], ["print", "print", "open", "len", "line.split", "numpy.array", "float"], "function", ["home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset.split"], ["def", "loadGloveModel", "(", "gloveFile", ")", ":", "\n", "    ", "print", "(", "\"Loading pretrained word vectors...\"", ")", "\n", "with", "open", "(", "gloveFile", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "model", "=", "{", "}", "\n", "for", "line", "in", "f", ":", "\n", "            ", "splitLine", "=", "line", ".", "split", "(", ")", "\n", "word", "=", "splitLine", "[", "0", "]", "\n", "embedding", "=", "np", ".", "array", "(", "[", "float", "(", "val", ")", "for", "val", "in", "splitLine", "[", "1", ":", "]", "]", ")", "\n", "model", "[", "word", "]", "=", "embedding", "\n", "", "", "print", "(", "\"Done.\"", ",", "len", "(", "model", ")", ",", "\" words loaded!\"", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.extract_features_detectron.detect_image": [[80, 136], ["detectron.im_detect_bbox", "caffe2.python.workspace.FetchBlob", "caffe2.python.workspace.FetchBlob", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "numpy.hstack().astype", "numpy.array", "numpy.where", "detectron.utils.boxes.nms", "numpy.argsort", "numpy.hstack"], "function", ["None"], ["def", "detect_image", "(", "detectron_model", ",", "image", ",", "args", ")", ":", "\n", "    ", "\"\"\"Given an image and a detectron model, extract object boxes,\n    classes, confidences and features from the image using the model.\n\n    Parameters\n    ----------\n    detectron_model\n        Detectron model.\n    image : np.ndarray\n        Image in BGR format.\n    args : argparse.Namespace\n        Parsed command-line arguments.\n\n    Returns\n    -------\n    np.ndarray, np.ndarray, np.ndarray, np.ndarray\n        Object bounding boxes, classes, confidence and features.\n    \"\"\"", "\n", "\n", "scores", ",", "cls_boxes", ",", "im_scale", "=", "detectron_test", ".", "im_detect_bbox", "(", "\n", "detectron_model", ",", "\n", "image", ",", "\n", "detectron_config", ".", "TEST", ".", "SCALE", ",", "\n", "detectron_config", ".", "TEST", ".", "MAX_SIZE", ",", "\n", "boxes", "=", "None", ",", "\n", ")", "\n", "num_proposals", "=", "scores", ".", "shape", "[", "0", "]", "\n", "\n", "rois", "=", "workspace", ".", "FetchBlob", "(", "f\"gpu_{args.gpu_id}/rois\"", ")", "\n", "features", "=", "workspace", ".", "FetchBlob", "(", "\n", "f\"gpu_{args.gpu_id}/{args.feat_name}\"", "\n", ")", "\n", "\n", "cls_boxes", "=", "rois", "[", ":", ",", "1", ":", "5", "]", "/", "im_scale", "\n", "max_conf", "=", "np", ".", "zeros", "(", "(", "num_proposals", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "max_cls", "=", "np", ".", "zeros", "(", "(", "num_proposals", ",", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "max_box", "=", "np", ".", "zeros", "(", "(", "num_proposals", ",", "4", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "cls_ind", "in", "range", "(", "1", ",", "detectron_config", ".", "MODEL", ".", "NUM_CLASSES", ")", ":", "\n", "        ", "cls_scores", "=", "scores", "[", ":", ",", "cls_ind", "]", "\n", "dets", "=", "np", ".", "hstack", "(", "(", "cls_boxes", ",", "cls_scores", "[", ":", ",", "np", ".", "newaxis", "]", ")", ")", ".", "astype", "(", "\n", "np", ".", "float32", "\n", ")", "\n", "keep", "=", "np", ".", "array", "(", "detectron_nms", "(", "dets", ",", "detectron_config", ".", "TEST", ".", "NMS", ")", ")", "\n", "idxs_update", "=", "np", ".", "where", "(", "cls_scores", "[", "keep", "]", ">", "max_conf", "[", "keep", "]", ")", "\n", "keep_idxs", "=", "keep", "[", "idxs_update", "]", "\n", "max_conf", "[", "keep_idxs", "]", "=", "cls_scores", "[", "keep_idxs", "]", "\n", "max_cls", "[", "keep_idxs", "]", "=", "cls_ind", "\n", "max_box", "[", "keep_idxs", "]", "=", "dets", "[", "keep_idxs", "]", "[", ":", ",", ":", "4", "]", "\n", "\n", "", "keep_boxes", "=", "np", ".", "argsort", "(", "max_conf", ")", "[", ":", ":", "-", "1", "]", "[", ":", "args", ".", "max_boxes", "]", "\n", "boxes", "=", "max_box", "[", "keep_boxes", ",", ":", "]", "\n", "classes", "=", "max_cls", "[", "keep_boxes", "]", "\n", "confidence", "=", "max_conf", "[", "keep_boxes", "]", "\n", "features", "=", "features", "[", "keep_boxes", ",", ":", "]", "\n", "return", "boxes", ",", "features", ",", "classes", ",", "confidence", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.extract_features_detectron.image_id_from_path": [[138, 153], ["int", "image_path.split"], "function", ["home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset.split"], ["", "def", "image_id_from_path", "(", "image_path", ")", ":", "\n", "    ", "\"\"\"Given a path to an image, return its id.\n\n    Parameters\n    ----------\n    image_path : str\n        Path to image, e.g.: coco_train2014/COCO_train2014/000000123456.jpg\n\n    Returns\n    -------\n    int\n        Corresponding image id (123456)\n    \"\"\"", "\n", "\n", "return", "int", "(", "image_path", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "[", "-", "16", ":", "-", "4", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.extract_features_detectron.main": [[155, 226], ["detectron.core.config.merge_cfg_from_file", "detectron.core.config.assert_and_infer_cfg", "detectron.initialize_model_from_cfg", "h5py.File", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.close", "image_paths.extend", "detectron.NamedCudaScope", "enumerate", "len", "len", "len", "len", "len", "tqdm.tqdm", "extract_features_detectron.image_id_from_path", "cv2.imread", "extract_features_detectron.detect_image", "glob.glob", "print", "os.path.join"], "function", ["home.repos.pwc.inspect_result.yuleiniu_rva.data.extract_features_detectron.image_id_from_path", "home.repos.pwc.inspect_result.yuleiniu_rva.data.extract_features_detectron.detect_image"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "\"\"\"Extract bottom-up features from all images in a directory using\n    a pre-trained Detectron model, and save them in HDF format.\n\n    Parameters\n    ----------\n    args : argparse.Namespace\n        Parsed command-line arguments.\n    \"\"\"", "\n", "\n", "# specifically for visual genome", "\n", "detectron_config", ".", "MODEL", ".", "NUM_ATTRIBUTES", "=", "-", "1", "\n", "merge_cfg_from_file", "(", "args", ".", "config", ")", "\n", "\n", "# override some config options and validate the config", "\n", "detectron_config", ".", "NUM_GPUS", "=", "1", "\n", "detectron_config", ".", "TRAIN", ".", "CPP_RPN", "=", "\"none\"", "\n", "assert_and_infer_cfg", "(", "cache_urls", "=", "False", ")", "\n", "\n", "# initialize model", "\n", "detectron_model", "=", "infer_engine", ".", "initialize_model_from_cfg", "(", "\n", "args", ".", "weights", ",", "args", ".", "gpu_id", "\n", ")", "\n", "\n", "# list of paths (example: \"coco_train2014/COCO_train2014_000000123456.jpg\")", "\n", "image_paths", "=", "[", "]", "\n", "for", "image_root", "in", "args", ".", "image_root", ":", "\n", "        ", "image_paths", ".", "extend", "(", "\n", "[", "\n", "name", "\n", "for", "name", "in", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "image_root", ",", "\"*.jpg\"", ")", ")", "\n", "if", "name", "not", "in", "{", "\".\"", ",", "\"..\"", "}", "\n", "]", "\n", ")", "\n", "\n", "# create an output HDF to save extracted features", "\n", "", "save_h5", "=", "h5py", ".", "File", "(", "args", ".", "save_path", ",", "\"w\"", ")", "\n", "image_ids_h5d", "=", "save_h5", ".", "create_dataset", "(", "\n", "\"image_id\"", ",", "(", "len", "(", "image_paths", ")", ",", ")", ",", "dtype", "=", "int", "\n", ")", "\n", "boxes_h5d", "=", "save_h5", ".", "create_dataset", "(", "\n", "\"boxes\"", ",", "(", "len", "(", "image_paths", ")", ",", "args", ".", "max_boxes", ",", "4", ")", ",", "\n", ")", "\n", "features_h5d", "=", "save_h5", ".", "create_dataset", "(", "\n", "\"features\"", ",", "(", "len", "(", "image_paths", ")", ",", "args", ".", "max_boxes", ",", "args", ".", "feat_dims", ")", ",", "\n", ")", "\n", "classes_h5d", "=", "save_h5", ".", "create_dataset", "(", "\n", "\"classes\"", ",", "(", "len", "(", "image_paths", ")", ",", "args", ".", "max_boxes", ",", ")", ",", "\n", ")", "\n", "scores_h5d", "=", "save_h5", ".", "create_dataset", "(", "\n", "\"scores\"", ",", "(", "len", "(", "image_paths", ")", ",", "args", ".", "max_boxes", ",", ")", ",", "\n", ")", "\n", "\n", "with", "c2_utils", ".", "NamedCudaScope", "(", "args", ".", "gpu_id", ")", ":", "\n", "        ", "for", "idx", ",", "image_path", "in", "enumerate", "(", "tqdm", "(", "image_paths", ")", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "image_ids_h5d", "[", "idx", "]", "=", "image_id_from_path", "(", "image_path", ")", "\n", "\n", "image", "=", "cv2", ".", "imread", "(", "image_path", ")", "\n", "boxes", ",", "features", ",", "classes", ",", "scores", "=", "detect_image", "(", "detectron_model", ",", "image", ",", "args", ")", "\n", "\n", "boxes_h5d", "[", "idx", "]", "=", "boxes", "\n", "features_h5d", "[", "idx", "]", "=", "features", "\n", "classes_h5d", "[", "idx", "]", "=", "classes", "\n", "scores_h5d", "[", "idx", "]", "=", "scores", "\n", "", "except", ":", "\n", "                ", "print", "(", "f\"\\nWarning: Failed to extract features from {idx}, {image_path}.\\n\"", ")", "\n", "\n", "# set current split name in attributrs of file, for tractability", "\n", "", "", "", "save_h5", ".", "attrs", "[", "\"split\"", "]", "=", "args", ".", "split", "\n", "save_h5", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.DialogsReader.__init__": [[35, 83], ["open", "json.load", "readers.DialogsReader.questions.append", "readers.DialogsReader.answers.append", "print", "tqdm.tqdm.tqdm", "print", "tqdm.tqdm.tqdm", "print", "tqdm.tqdm.tqdm", "len", "range", "range", "nltk.tokenize.word_tokenize", "range", "nltk.tokenize.word_tokenize", "readers.DialogsReader.captions.items", "nltk.tokenize.word_tokenize", "len", "dialog_for_image[].append", "len", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dialogs_jsonpath", ":", "str", ")", ":", "\n", "        ", "with", "open", "(", "dialogs_jsonpath", ",", "\"r\"", ")", "as", "visdial_file", ":", "\n", "            ", "visdial_data", "=", "json", ".", "load", "(", "visdial_file", ")", "\n", "self", ".", "_split", "=", "visdial_data", "[", "\"split\"", "]", "\n", "\n", "self", ".", "questions", "=", "visdial_data", "[", "\"data\"", "]", "[", "\"questions\"", "]", "\n", "self", ".", "answers", "=", "visdial_data", "[", "\"data\"", "]", "[", "\"answers\"", "]", "\n", "\n", "# Add empty question, answer at the end, useful for padding dialog rounds for test.", "\n", "self", ".", "questions", ".", "append", "(", "\"\"", ")", "\n", "self", ".", "answers", ".", "append", "(", "\"\"", ")", "\n", "\n", "# Image_id serves as key for all three dicts here.", "\n", "self", ".", "captions", "=", "{", "}", "\n", "self", ".", "dialogs", "=", "{", "}", "\n", "self", ".", "num_rounds", "=", "{", "}", "\n", "\n", "for", "dialog_for_image", "in", "visdial_data", "[", "\"data\"", "]", "[", "\"dialogs\"", "]", ":", "\n", "                ", "self", ".", "captions", "[", "dialog_for_image", "[", "\"image_id\"", "]", "]", "=", "dialog_for_image", "[", "\"caption\"", "]", "\n", "\n", "# Record original length of dialog, before padding.", "\n", "# 10 for train and val splits, 10 or less for test split.", "\n", "self", ".", "num_rounds", "[", "dialog_for_image", "[", "\"image_id\"", "]", "]", "=", "len", "(", "dialog_for_image", "[", "\"dialog\"", "]", ")", "\n", "\n", "# Pad dialog at the end with empty question and answer pairs (for test split).", "\n", "while", "len", "(", "dialog_for_image", "[", "\"dialog\"", "]", ")", "<", "10", ":", "\n", "                    ", "dialog_for_image", "[", "\"dialog\"", "]", ".", "append", "(", "{", "\"question\"", ":", "-", "1", ",", "\"answer\"", ":", "-", "1", "}", ")", "\n", "\n", "# Add empty answer /answer options if not provided (for test split).", "\n", "", "for", "i", "in", "range", "(", "len", "(", "dialog_for_image", "[", "\"dialog\"", "]", ")", ")", ":", "\n", "                    ", "if", "\"answer\"", "not", "in", "dialog_for_image", "[", "\"dialog\"", "]", "[", "i", "]", ":", "\n", "                        ", "dialog_for_image", "[", "\"dialog\"", "]", "[", "i", "]", "[", "\"answer\"", "]", "=", "-", "1", "\n", "", "if", "\"answer_options\"", "not", "in", "dialog_for_image", "[", "\"dialog\"", "]", "[", "i", "]", ":", "\n", "                        ", "dialog_for_image", "[", "\"dialog\"", "]", "[", "i", "]", "[", "\"answer_options\"", "]", "=", "[", "-", "1", "]", "*", "100", "\n", "\n", "", "", "self", ".", "dialogs", "[", "dialog_for_image", "[", "\"image_id\"", "]", "]", "=", "dialog_for_image", "[", "\"dialog\"", "]", "\n", "\n", "", "print", "(", "f\"[{self._split}] Tokenizing questions...\"", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "self", ".", "questions", ")", ")", ")", ":", "\n", "                ", "self", ".", "questions", "[", "i", "]", "=", "word_tokenize", "(", "self", ".", "questions", "[", "i", "]", "+", "\"?\"", ")", "\n", "\n", "", "print", "(", "f\"[{self._split}] Tokenizing answers...\"", ")", "\n", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "self", ".", "answers", ")", ")", ")", ":", "\n", "                ", "self", ".", "answers", "[", "i", "]", "=", "word_tokenize", "(", "self", ".", "answers", "[", "i", "]", ")", "\n", "\n", "", "print", "(", "f\"[{self._split}] Tokenizing captions...\"", ")", "\n", "for", "image_id", ",", "caption", "in", "tqdm", "(", "self", ".", "captions", ".", "items", "(", ")", ")", ":", "\n", "                ", "self", ".", "captions", "[", "image_id", "]", "=", "word_tokenize", "(", "caption", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.DialogsReader.__len__": [[84, 86], ["len"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dialogs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.DialogsReader.__getitem__": [[87, 104], ["copy.deepcopy", "range", "len", "enumerate"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "image_id", ":", "int", ")", "->", "Dict", "[", "str", ",", "Union", "[", "int", ",", "str", ",", "List", "]", "]", ":", "\n", "        ", "caption_for_image", "=", "self", ".", "captions", "[", "image_id", "]", "\n", "dialog_for_image", "=", "copy", ".", "deepcopy", "(", "self", ".", "dialogs", "[", "image_id", "]", ")", "\n", "num_rounds", "=", "self", ".", "num_rounds", "[", "image_id", "]", "\n", "\n", "# Replace question and answer indices with actual word tokens.", "\n", "for", "i", "in", "range", "(", "len", "(", "dialog_for_image", ")", ")", ":", "\n", "            ", "dialog_for_image", "[", "i", "]", "[", "\"question\"", "]", "=", "self", ".", "questions", "[", "dialog_for_image", "[", "i", "]", "[", "\"question\"", "]", "]", "\n", "dialog_for_image", "[", "i", "]", "[", "\"answer\"", "]", "=", "self", ".", "answers", "[", "dialog_for_image", "[", "i", "]", "[", "\"answer\"", "]", "]", "\n", "for", "j", ",", "answer_option", "in", "enumerate", "(", "dialog_for_image", "[", "i", "]", "[", "\"answer_options\"", "]", ")", ":", "\n", "                ", "dialog_for_image", "[", "i", "]", "[", "\"answer_options\"", "]", "[", "j", "]", "=", "self", ".", "answers", "[", "answer_option", "]", "\n", "\n", "", "", "return", "{", "\n", "\"image_id\"", ":", "image_id", ",", "\n", "\"caption\"", ":", "caption_for_image", ",", "\n", "\"dialog\"", ":", "dialog_for_image", ",", "\n", "\"num_rounds\"", ":", "num_rounds", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.DialogsReader.keys": [[106, 108], ["list", "readers.DialogsReader.dialogs.keys"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.ImageFeaturesHdfReader.keys"], ["", "def", "keys", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "list", "(", "self", ".", "dialogs", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.DialogsReader.split": [[109, 112], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "split", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_split", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.DenseAnnotationsReader.__init__": [[125, 129], ["open", "json.load"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dense_annotations_jsonpath", ":", "str", ")", ":", "\n", "        ", "with", "open", "(", "dense_annotations_jsonpath", ",", "\"r\"", ")", "as", "visdial_file", ":", "\n", "            ", "self", ".", "_visdial_data", "=", "json", ".", "load", "(", "visdial_file", ")", "\n", "self", ".", "_image_ids", "=", "[", "entry", "[", "\"image_id\"", "]", "for", "entry", "in", "self", ".", "_visdial_data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.DenseAnnotationsReader.__len__": [[130, 132], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_image_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.DenseAnnotationsReader.__getitem__": [[133, 137], ["readers.DenseAnnotationsReader._image_ids.index"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "image_id", ":", "int", ")", "->", "Dict", "[", "str", ",", "Union", "[", "int", ",", "List", "]", "]", ":", "\n", "        ", "index", "=", "self", ".", "_image_ids", ".", "index", "(", "image_id", ")", "\n", "# keys: {\"image_id\", \"round_id\", \"gt_relevance\"}", "\n", "return", "self", ".", "_visdial_data", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.DenseAnnotationsReader.split": [[138, 142], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "split", "(", "self", ")", ":", "\n", "# always", "\n", "        ", "return", "\"val\"", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.ImageFeaturesHdfReader.__init__": [[167, 177], ["h5py.File", "list", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "features_hdfpath", ":", "str", ",", "in_memory", ":", "bool", "=", "False", ")", ":", "\n", "        ", "self", ".", "features_hdfpath", "=", "features_hdfpath", "\n", "self", ".", "_in_memory", "=", "in_memory", "\n", "\n", "with", "h5py", ".", "File", "(", "self", ".", "features_hdfpath", ",", "\"r\"", ")", "as", "features_hdf", ":", "\n", "            ", "self", ".", "_split", "=", "features_hdf", ".", "attrs", "[", "\"split\"", "]", "\n", "self", ".", "image_id_list", "=", "list", "(", "features_hdf", "[", "\"image_id\"", "]", ")", "\n", "# \"features\" is List[np.ndarray] if the dataset is loaded in-memory", "\n", "# If not loaded in memory, then list of None.", "\n", "self", ".", "features", "=", "[", "None", "]", "*", "len", "(", "self", ".", "image_id_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.ImageFeaturesHdfReader.__len__": [[179, 181], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_id_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.ImageFeaturesHdfReader.__getitem__": [[182, 198], ["readers.ImageFeaturesHdfReader.image_id_list.index", "h5py.File", "h5py.File"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "image_id", ":", "int", ")", ":", "\n", "        ", "index", "=", "self", ".", "image_id_list", ".", "index", "(", "image_id", ")", "\n", "if", "self", ".", "_in_memory", ":", "\n", "# Load features during first epoch, all not loaded together as it has a slow start.", "\n", "            ", "if", "self", ".", "features", "[", "index", "]", "is", "not", "None", ":", "\n", "                ", "image_id_features", "=", "self", ".", "features", "[", "index", "]", "\n", "", "else", ":", "\n", "                ", "with", "h5py", ".", "File", "(", "self", ".", "features_hdfpath", ",", "\"r\"", ")", "as", "features_hdf", ":", "\n", "                    ", "image_id_features", "=", "features_hdf", "[", "\"features\"", "]", "[", "index", "]", "\n", "self", ".", "features", "[", "index", "]", "=", "image_id_features", "\n", "", "", "", "else", ":", "\n", "# Read chunk from file everytime if not loaded in memory.", "\n", "            ", "with", "h5py", ".", "File", "(", "self", ".", "features_hdfpath", ",", "\"r\"", ")", "as", "features_hdf", ":", "\n", "                ", "image_id_features", "=", "features_hdf", "[", "\"features\"", "]", "[", "index", "]", "\n", "\n", "", "", "return", "image_id_features", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.ImageFeaturesHdfReader.keys": [[199, 201], ["None"], "methods", ["None"], ["", "def", "keys", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "self", ".", "image_id_list", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.ImageFeaturesHdfReader.split": [[202, 205], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "split", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_split", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.__init__": [[37, 61], ["enumerate", "os.path.exists", "FileNotFoundError", "open", "json.load", "sorted", "vocabulary.Vocabulary.word2index.items", "sorted.items"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "word_counts_path", ":", "str", ",", "min_count", ":", "int", "=", "5", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "word_counts_path", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Word counts do not exist at {word_counts_path}\"", ")", "\n", "\n", "", "with", "open", "(", "word_counts_path", ",", "\"r\"", ")", "as", "word_counts_file", ":", "\n", "            ", "word_counts", "=", "json", ".", "load", "(", "word_counts_file", ")", "\n", "\n", "# form a list of (word, count) tuples and apply min_count threshold", "\n", "word_counts", "=", "[", "\n", "(", "word", ",", "count", ")", "for", "word", ",", "count", "in", "word_counts", ".", "items", "(", ")", "if", "count", ">=", "min_count", "\n", "]", "\n", "# sort in descending order of word counts", "\n", "word_counts", "=", "sorted", "(", "word_counts", ",", "key", "=", "lambda", "wc", ":", "-", "wc", "[", "1", "]", ")", "\n", "words", "=", "[", "w", "[", "0", "]", "for", "w", "in", "word_counts", "]", "\n", "\n", "", "self", ".", "word2index", "=", "{", "}", "\n", "self", ".", "word2index", "[", "self", ".", "PAD_TOKEN", "]", "=", "self", ".", "PAD_INDEX", "\n", "self", ".", "word2index", "[", "self", ".", "SOS_TOKEN", "]", "=", "self", ".", "SOS_INDEX", "\n", "self", ".", "word2index", "[", "self", ".", "EOS_TOKEN", "]", "=", "self", ".", "EOS_INDEX", "\n", "self", ".", "word2index", "[", "self", ".", "UNK_TOKEN", "]", "=", "self", ".", "UNK_INDEX", "\n", "for", "index", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "self", ".", "word2index", "[", "word", "]", "=", "index", "+", "4", "\n", "\n", "", "self", ".", "index2word", "=", "{", "index", ":", "word", "for", "word", ",", "index", "in", "self", ".", "word2index", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.from_saved": [[62, 74], ["open", "json.load", "cls.word2index.items"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_saved", "(", "cls", ",", "saved_vocabulary_path", ":", "str", ")", "->", "\"Vocabulary\"", ":", "\n", "        ", "\"\"\"Build the vocabulary from a json file saved by ``save`` method.\n\n        Parameters\n        ----------\n        saved_vocabulary_path : str\n            Path to a json file containing word to integer mappings (saved vocabulary).\n        \"\"\"", "\n", "with", "open", "(", "saved_vocabulary_path", ",", "\"r\"", ")", "as", "saved_vocabulary_file", ":", "\n", "            ", "cls", ".", "word2index", "=", "json", ".", "load", "(", "saved_vocabulary_file", ")", "\n", "", "cls", ".", "index2word", "=", "{", "index", ":", "word", "for", "word", ",", "index", "in", "cls", ".", "word2index", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.to_indices": [[75, 77], ["vocabulary.Vocabulary.word2index.get"], "methods", ["None"], ["", "def", "to_indices", "(", "self", ",", "words", ":", "List", "[", "str", "]", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "return", "[", "self", ".", "word2index", ".", "get", "(", "word", ",", "self", ".", "UNK_INDEX", ")", "for", "word", "in", "words", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.to_words": [[78, 80], ["vocabulary.Vocabulary.index2word.get"], "methods", ["None"], ["", "def", "to_words", "(", "self", ",", "indices", ":", "List", "[", "int", "]", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "[", "self", ".", "index2word", ".", "get", "(", "index", ",", "self", ".", "UNK_TOKEN", ")", "for", "index", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.save": [[81, 84], ["open", "json.dump"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "save_vocabulary_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "with", "open", "(", "save_vocabulary_path", ",", "\"w\"", ")", "as", "save_vocabulary_file", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "word2index", ",", "saved_vocabulary_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.__len__": [[85, 87], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "index2word", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset.__init__": [[23, 65], ["torch.utils.data.Dataset.__init__", "visdialch.data.readers.DialogsReader", "visdialch.data.vocabulary.Vocabulary", "visdialch.data.readers.ImageFeaturesHdfReader", "list", "visdialch.data.readers.DenseAnnotationsReader", "dataset.VisDialDataset.dialogs_reader.dialogs.keys"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__", "home.repos.pwc.inspect_result.yuleiniu_rva.data.readers.ImageFeaturesHdfReader.keys"], ["def", "__init__", "(", "\n", "self", ",", "\n", "config", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", "dialogs_jsonpath", ":", "str", ",", "\n", "dense_annotations_jsonpath", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "overfit", ":", "bool", "=", "False", ",", "\n", "in_memory", ":", "bool", "=", "False", ",", "\n", "return_options", ":", "bool", "=", "True", ",", "\n", "add_boundary_toks", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "return_options", "=", "return_options", "\n", "self", ".", "add_boundary_toks", "=", "add_boundary_toks", "\n", "self", ".", "dialogs_reader", "=", "DialogsReader", "(", "dialogs_jsonpath", ")", "\n", "\n", "if", "\"val\"", "in", "self", ".", "split", "and", "dense_annotations_jsonpath", "is", "not", "None", ":", "\n", "            ", "self", ".", "annotations_reader", "=", "DenseAnnotationsReader", "(", "\n", "dense_annotations_jsonpath", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "annotations_reader", "=", "None", "\n", "\n", "", "self", ".", "vocabulary", "=", "Vocabulary", "(", "\n", "config", "[", "\"word_counts_json\"", "]", ",", "min_count", "=", "config", "[", "\"vocab_min_count\"", "]", "\n", ")", "\n", "\n", "# Initialize image features reader according to split.", "\n", "image_features_hdfpath", "=", "config", "[", "\"image_features_train_h5\"", "]", "\n", "if", "\"val\"", "in", "self", ".", "dialogs_reader", ".", "split", ":", "\n", "            ", "image_features_hdfpath", "=", "config", "[", "\"image_features_val_h5\"", "]", "\n", "", "elif", "\"test\"", "in", "self", ".", "dialogs_reader", ".", "split", ":", "\n", "            ", "image_features_hdfpath", "=", "config", "[", "\"image_features_test_h5\"", "]", "\n", "\n", "", "self", ".", "hdf_reader", "=", "ImageFeaturesHdfReader", "(", "\n", "image_features_hdfpath", ",", "in_memory", "\n", ")", "\n", "\n", "# Keep a list of image_ids as primary keys to access data.", "\n", "self", ".", "image_ids", "=", "list", "(", "self", ".", "dialogs_reader", ".", "dialogs", ".", "keys", "(", ")", ")", "\n", "if", "overfit", ":", "\n", "            ", "self", ".", "image_ids", "=", "self", ".", "image_ids", "[", ":", "5", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset.split": [[66, 69], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "split", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dialogs_reader", ".", "split", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset.__len__": [[70, 72], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "image_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset.__getitem__": [[73, 216], ["torch.tensor", "dataset.VisDialDataset.vocabulary.to_indices", "range", "dataset.VisDialDataset._pad_sequences", "dataset.VisDialDataset._get_history", "dataset.VisDialDataset._pad_sequences", "dataset.VisDialDataset._pad_sequences", "torch.tensor().long", "questions.long", "history.long", "answers_in.long", "answers_out.long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.nn.functional.normalize", "len", "dataset.VisDialDataset.vocabulary.to_indices", "torch.tensor().float", "torch.tensor().long", "dataset.VisDialDataset.vocabulary.to_indices", "dataset.VisDialDataset.vocabulary.to_indices", "range", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "torch.stack.long", "torch.stack.long", "torch.tensor().long", "torch.stack", "torch.stack.long", "torch.tensor().long", "torch.tensor().long", "len", "dataset.VisDialDataset._pad_sequences", "torch.stack.append", "dataset.VisDialDataset._pad_sequences", "torch.stack.append", "answer_option_lengths.append", "dataset.VisDialDataset._pad_sequences", "torch.stack.append", "answer_option_lengths.append", "torch.tensor", "torch.tensor", "dataset.VisDialDataset.vocabulary.to_indices", "dataset.VisDialDataset.vocabulary.to_indices", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.to_indices", "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset._get_history", "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.to_indices", "home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.to_indices", "home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.to_indices", "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset._pad_sequences", "home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.to_indices", "home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.to_indices"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# Get image_id, which serves as a primary key for current instance.", "\n", "        ", "image_id", "=", "self", ".", "image_ids", "[", "index", "]", "\n", "\n", "# Get image features for this image_id using hdf reader.", "\n", "image_features", "=", "self", ".", "hdf_reader", "[", "image_id", "]", "\n", "image_features", "=", "torch", ".", "tensor", "(", "image_features", ")", "\n", "# Normalize image features at zero-th dimension (since there's no batch", "\n", "# dimension).", "\n", "if", "self", ".", "config", "[", "\"img_norm\"", "]", ":", "\n", "            ", "image_features", "=", "normalize", "(", "image_features", ",", "dim", "=", "0", ",", "p", "=", "2", ")", "\n", "\n", "# Retrieve instance for this image_id using json reader.", "\n", "", "visdial_instance", "=", "self", ".", "dialogs_reader", "[", "image_id", "]", "\n", "caption", "=", "visdial_instance", "[", "\"caption\"", "]", "\n", "dialog", "=", "visdial_instance", "[", "\"dialog\"", "]", "\n", "\n", "# Convert word tokens of caption, question, answer and answer options", "\n", "# to integers.", "\n", "caption", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "caption", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "dialog", ")", ")", ":", "\n", "            ", "dialog", "[", "i", "]", "[", "\"question\"", "]", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "\n", "dialog", "[", "i", "]", "[", "\"question\"", "]", "\n", ")", "\n", "if", "self", ".", "add_boundary_toks", ":", "\n", "                ", "dialog", "[", "i", "]", "[", "\"answer\"", "]", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "\n", "[", "self", ".", "vocabulary", ".", "SOS_TOKEN", "]", "\n", "+", "dialog", "[", "i", "]", "[", "\"answer\"", "]", "\n", "+", "[", "self", ".", "vocabulary", ".", "EOS_TOKEN", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "dialog", "[", "i", "]", "[", "\"answer\"", "]", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "\n", "dialog", "[", "i", "]", "[", "\"answer\"", "]", "\n", ")", "\n", "\n", "", "if", "self", ".", "return_options", ":", "\n", "                ", "for", "j", "in", "range", "(", "len", "(", "dialog", "[", "i", "]", "[", "\"answer_options\"", "]", ")", ")", ":", "\n", "                    ", "if", "self", ".", "add_boundary_toks", ":", "\n", "                        ", "dialog", "[", "i", "]", "[", "\"answer_options\"", "]", "[", "\n", "j", "\n", "]", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "\n", "[", "self", ".", "vocabulary", ".", "SOS_TOKEN", "]", "\n", "+", "dialog", "[", "i", "]", "[", "\"answer_options\"", "]", "[", "j", "]", "\n", "+", "[", "self", ".", "vocabulary", ".", "EOS_TOKEN", "]", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "dialog", "[", "i", "]", "[", "\"answer_options\"", "]", "[", "\n", "j", "\n", "]", "=", "self", ".", "vocabulary", ".", "to_indices", "(", "\n", "dialog", "[", "i", "]", "[", "\"answer_options\"", "]", "[", "j", "]", "\n", ")", "\n", "\n", "", "", "", "", "questions", ",", "question_lengths", "=", "self", ".", "_pad_sequences", "(", "\n", "[", "dialog_round", "[", "\"question\"", "]", "for", "dialog_round", "in", "dialog", "]", "\n", ")", "\n", "history", ",", "history_lengths", "=", "self", ".", "_get_history", "(", "\n", "caption", ",", "\n", "[", "dialog_round", "[", "\"question\"", "]", "for", "dialog_round", "in", "dialog", "]", ",", "\n", "[", "dialog_round", "[", "\"answer\"", "]", "for", "dialog_round", "in", "dialog", "]", ",", "\n", ")", "\n", "answers_in", ",", "answer_lengths", "=", "self", ".", "_pad_sequences", "(", "\n", "[", "dialog_round", "[", "\"answer\"", "]", "[", ":", "-", "1", "]", "for", "dialog_round", "in", "dialog", "]", "\n", ")", "\n", "answers_out", ",", "_", "=", "self", ".", "_pad_sequences", "(", "\n", "[", "dialog_round", "[", "\"answer\"", "]", "[", "1", ":", "]", "for", "dialog_round", "in", "dialog", "]", "\n", ")", "\n", "\n", "# Collect everything as tensors for ``collate_fn`` of dataloader to", "\n", "# work seamlessly questions, history, etc. are converted to", "\n", "# LongTensors, for nn.Embedding input.", "\n", "item", "=", "{", "}", "\n", "item", "[", "\"img_ids\"", "]", "=", "torch", ".", "tensor", "(", "image_id", ")", ".", "long", "(", ")", "\n", "item", "[", "\"img_feat\"", "]", "=", "image_features", "\n", "item", "[", "\"ques\"", "]", "=", "questions", ".", "long", "(", ")", "\n", "item", "[", "\"hist\"", "]", "=", "history", ".", "long", "(", ")", "\n", "item", "[", "\"ans_in\"", "]", "=", "answers_in", ".", "long", "(", ")", "\n", "item", "[", "\"ans_out\"", "]", "=", "answers_out", ".", "long", "(", ")", "\n", "item", "[", "\"ques_len\"", "]", "=", "torch", ".", "tensor", "(", "question_lengths", ")", ".", "long", "(", ")", "\n", "item", "[", "\"hist_len\"", "]", "=", "torch", ".", "tensor", "(", "history_lengths", ")", ".", "long", "(", ")", "\n", "item", "[", "\"ans_len\"", "]", "=", "torch", ".", "tensor", "(", "answer_lengths", ")", ".", "long", "(", ")", "\n", "item", "[", "\"num_rounds\"", "]", "=", "torch", ".", "tensor", "(", "\n", "visdial_instance", "[", "\"num_rounds\"", "]", "\n", ")", ".", "long", "(", ")", "\n", "\n", "if", "self", ".", "return_options", ":", "\n", "            ", "if", "self", ".", "add_boundary_toks", ":", "\n", "                ", "answer_options_in", ",", "answer_options_out", "=", "[", "]", ",", "[", "]", "\n", "answer_option_lengths", "=", "[", "]", "\n", "for", "dialog_round", "in", "dialog", ":", "\n", "                    ", "options", ",", "option_lengths", "=", "self", ".", "_pad_sequences", "(", "\n", "[", "\n", "option", "[", ":", "-", "1", "]", "\n", "for", "option", "in", "dialog_round", "[", "\"answer_options\"", "]", "\n", "]", "\n", ")", "\n", "answer_options_in", ".", "append", "(", "options", ")", "\n", "\n", "options", ",", "_", "=", "self", ".", "_pad_sequences", "(", "\n", "[", "\n", "option", "[", "1", ":", "]", "\n", "for", "option", "in", "dialog_round", "[", "\"answer_options\"", "]", "\n", "]", "\n", ")", "\n", "answer_options_out", ".", "append", "(", "options", ")", "\n", "\n", "answer_option_lengths", ".", "append", "(", "option_lengths", ")", "\n", "", "answer_options_in", "=", "torch", ".", "stack", "(", "answer_options_in", ",", "0", ")", "\n", "answer_options_out", "=", "torch", ".", "stack", "(", "answer_options_out", ",", "0", ")", "\n", "\n", "item", "[", "\"opt_in\"", "]", "=", "answer_options_in", ".", "long", "(", ")", "\n", "item", "[", "\"opt_out\"", "]", "=", "answer_options_out", ".", "long", "(", ")", "\n", "item", "[", "\"opt_len\"", "]", "=", "torch", ".", "tensor", "(", "answer_option_lengths", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "answer_options", "=", "[", "]", "\n", "answer_option_lengths", "=", "[", "]", "\n", "for", "dialog_round", "in", "dialog", ":", "\n", "                    ", "options", ",", "option_lengths", "=", "self", ".", "_pad_sequences", "(", "\n", "dialog_round", "[", "\"answer_options\"", "]", "\n", ")", "\n", "answer_options", ".", "append", "(", "options", ")", "\n", "answer_option_lengths", ".", "append", "(", "option_lengths", ")", "\n", "", "answer_options", "=", "torch", ".", "stack", "(", "answer_options", ",", "0", ")", "\n", "\n", "item", "[", "\"opt\"", "]", "=", "answer_options", ".", "long", "(", ")", "\n", "item", "[", "\"opt_len\"", "]", "=", "torch", ".", "tensor", "(", "answer_option_lengths", ")", ".", "long", "(", ")", "\n", "\n", "", "if", "\"test\"", "not", "in", "self", ".", "split", ":", "\n", "                ", "answer_indices", "=", "[", "\n", "dialog_round", "[", "\"gt_index\"", "]", "for", "dialog_round", "in", "dialog", "\n", "]", "\n", "item", "[", "\"ans_ind\"", "]", "=", "torch", ".", "tensor", "(", "answer_indices", ")", ".", "long", "(", ")", "\n", "\n", "# Gather dense annotations.", "\n", "", "", "if", "\"val\"", "in", "self", ".", "split", ":", "\n", "            ", "dense_annotations", "=", "self", ".", "annotations_reader", "[", "image_id", "]", "\n", "item", "[", "\"gt_relevance\"", "]", "=", "torch", ".", "tensor", "(", "\n", "dense_annotations", "[", "\"gt_relevance\"", "]", "\n", ")", ".", "float", "(", ")", "\n", "item", "[", "\"round_id\"", "]", "=", "torch", ".", "tensor", "(", "\n", "dense_annotations", "[", "\"round_id\"", "]", "\n", ")", ".", "long", "(", ")", "\n", "\n", "", "return", "item", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset._pad_sequences": [[217, 257], ["range", "torch.full", "torch.nn.utils.rnn.pad_sequence", "len", "len", "len", "torch.tensor", "torch.nn.utils.rnn.pad_sequence.size"], "methods", ["None"], ["", "def", "_pad_sequences", "(", "self", ",", "sequences", ":", "List", "[", "List", "[", "int", "]", "]", ")", ":", "\n", "        ", "\"\"\"Given tokenized sequences (either questions, answers or answer\n        options, tokenized in ``__getitem__``), padding them to maximum\n        specified sequence length. Return as a tensor of size\n        ``(*, max_sequence_length)``.\n\n        This method is only called in ``__getitem__``, chunked out separately\n        for readability.\n\n        Parameters\n        ----------\n        sequences : List[List[int]]\n            List of tokenized sequences, each sequence is typically a\n            List[int].\n\n        Returns\n        -------\n        torch.Tensor, torch.Tensor\n            Tensor of sequences padded to max length, and length of sequences\n            before padding.\n        \"\"\"", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "sequences", ")", ")", ":", "\n", "            ", "sequences", "[", "i", "]", "=", "sequences", "[", "i", "]", "[", "\n", ":", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "-", "1", "\n", "]", "\n", "", "sequence_lengths", "=", "[", "len", "(", "sequence", ")", "for", "sequence", "in", "sequences", "]", "\n", "\n", "# Pad all sequences to max_sequence_length.", "\n", "maxpadded_sequences", "=", "torch", ".", "full", "(", "\n", "(", "len", "(", "sequences", ")", ",", "self", ".", "config", "[", "\"max_sequence_length\"", "]", ")", ",", "\n", "fill_value", "=", "self", ".", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "padded_sequences", "=", "pad_sequence", "(", "\n", "[", "torch", ".", "tensor", "(", "sequence", ")", "for", "sequence", "in", "sequences", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "self", ".", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "maxpadded_sequences", "[", ":", ",", ":", "padded_sequences", ".", "size", "(", "1", ")", "]", "=", "padded_sequences", "\n", "return", "maxpadded_sequences", ",", "sequence_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.data.dataset.VisDialDataset._get_history": [[258, 312], ["range", "range", "history.append", "zip", "dataset.VisDialDataset.config.get", "torch.full", "torch.nn.utils.rnn.pad_sequence", "len", "len", "history.append", "concatenated_history.append", "range", "len", "len", "concatenated_history.append", "range", "len", "len", "torch.tensor", "concatenated_history[].extend", "torch.nn.utils.rnn.pad_sequence.size"], "methods", ["None"], ["", "def", "_get_history", "(", "\n", "self", ",", "\n", "caption", ":", "List", "[", "int", "]", ",", "\n", "questions", ":", "List", "[", "List", "[", "int", "]", "]", ",", "\n", "answers", ":", "List", "[", "List", "[", "int", "]", "]", ",", "\n", ")", ":", "\n", "# Allow double length of caption, equivalent to a concatenated QA pair.", "\n", "        ", "caption", "=", "caption", "[", ":", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "*", "2", "-", "1", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "questions", ")", ")", ":", "\n", "            ", "questions", "[", "i", "]", "=", "questions", "[", "i", "]", "[", "\n", ":", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "-", "1", "\n", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "answers", ")", ")", ":", "\n", "            ", "answers", "[", "i", "]", "=", "answers", "[", "i", "]", "[", ":", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "-", "1", "]", "\n", "\n", "# History for first round is caption, else concatenated QA pair of", "\n", "# previous round.", "\n", "", "history", "=", "[", "]", "\n", "history", ".", "append", "(", "caption", ")", "\n", "for", "question", ",", "answer", "in", "zip", "(", "questions", ",", "answers", ")", ":", "\n", "            ", "history", ".", "append", "(", "question", "+", "answer", "+", "[", "self", ".", "vocabulary", ".", "EOS_INDEX", "]", ")", "\n", "# Drop last entry from history (there's no eleventh question).", "\n", "", "history", "=", "history", "[", ":", "-", "1", "]", "\n", "max_history_length", "=", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "*", "2", "\n", "\n", "if", "self", ".", "config", ".", "get", "(", "\"concat_history\"", ",", "False", ")", ":", "\n", "# Concatenated_history has similar structure as history, except it", "\n", "# contains concatenated QA pairs from previous rounds.", "\n", "            ", "concatenated_history", "=", "[", "]", "\n", "concatenated_history", ".", "append", "(", "caption", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "history", ")", ")", ":", "\n", "                ", "concatenated_history", ".", "append", "(", "[", "]", ")", "\n", "for", "j", "in", "range", "(", "i", "+", "1", ")", ":", "\n", "                    ", "concatenated_history", "[", "i", "]", ".", "extend", "(", "history", "[", "j", "]", ")", "\n", "\n", "", "", "max_history_length", "=", "(", "\n", "self", ".", "config", "[", "\"max_sequence_length\"", "]", "*", "2", "*", "len", "(", "history", ")", "\n", ")", "\n", "history", "=", "concatenated_history", "\n", "\n", "", "history_lengths", "=", "[", "len", "(", "round_history", ")", "for", "round_history", "in", "history", "]", "\n", "maxpadded_history", "=", "torch", ".", "full", "(", "\n", "(", "len", "(", "history", ")", ",", "max_history_length", ")", ",", "\n", "fill_value", "=", "self", ".", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "padded_history", "=", "pad_sequence", "(", "\n", "[", "torch", ".", "tensor", "(", "round_history", ")", "for", "round_history", "in", "history", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", "padding_value", "=", "self", ".", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "maxpadded_history", "[", ":", ",", ":", "padded_history", ".", "size", "(", "1", ")", "]", "=", "padded_history", "\n", "return", "maxpadded_history", ",", "history_lengths", "", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.SparseGTMetrics.__init__": [[48, 50], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_rank_list", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.SparseGTMetrics.observe": [[51, 73], ["predicted_scores.detach.detach.detach", "metrics.scores_to_ranks", "predicted_ranks.view.view.size", "predicted_ranks.view.view.view", "target_ranks.view().long.view().long.view().long", "metrics.SparseGTMetrics._rank_list.extend", "list", "target_ranks.view().long.view().long.view", "predicted_gt_ranks.cpu().numpy", "torch.arange", "predicted_gt_ranks.cpu"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.scores_to_ranks"], ["", "def", "observe", "(", "\n", "self", ",", "predicted_scores", ":", "torch", ".", "Tensor", ",", "target_ranks", ":", "torch", ".", "Tensor", "\n", ")", ":", "\n", "        ", "predicted_scores", "=", "predicted_scores", ".", "detach", "(", ")", "\n", "\n", "# shape: (batch_size, num_rounds, num_options)", "\n", "predicted_ranks", "=", "scores_to_ranks", "(", "predicted_scores", ")", "\n", "batch_size", ",", "num_rounds", ",", "num_options", "=", "predicted_ranks", ".", "size", "(", ")", "\n", "\n", "# collapse batch dimension", "\n", "predicted_ranks", "=", "predicted_ranks", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", ",", "num_options", "\n", ")", "\n", "\n", "# shape: (batch_size * num_rounds, )", "\n", "target_ranks", "=", "target_ranks", ".", "view", "(", "batch_size", "*", "num_rounds", ")", ".", "long", "(", ")", "\n", "\n", "# shape: (batch_size * num_rounds, )", "\n", "predicted_gt_ranks", "=", "predicted_ranks", "[", "\n", "torch", ".", "arange", "(", "batch_size", "*", "num_rounds", ")", ",", "target_ranks", "\n", "]", "\n", "self", ".", "_rank_list", ".", "extend", "(", "list", "(", "predicted_gt_ranks", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.SparseGTMetrics.retrieve": [[74, 92], ["len", "torch.tensor().float", "metrics.SparseGTMetrics.reset", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.tensor", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.tensor().float.reciprocal"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.NDCG.reset"], ["", "def", "retrieve", "(", "self", ",", "reset", ":", "bool", "=", "True", ")", ":", "\n", "        ", "num_examples", "=", "len", "(", "self", ".", "_rank_list", ")", "\n", "if", "num_examples", ">", "0", ":", "\n", "# convert to numpy array for easy calculation.", "\n", "            ", "__rank_list", "=", "torch", ".", "tensor", "(", "self", ".", "_rank_list", ")", ".", "float", "(", ")", "\n", "metrics", "=", "{", "\n", "\"r@1\"", ":", "torch", ".", "mean", "(", "(", "__rank_list", "<=", "1", ")", ".", "float", "(", ")", ")", ".", "item", "(", ")", ",", "\n", "\"r@5\"", ":", "torch", ".", "mean", "(", "(", "__rank_list", "<=", "5", ")", ".", "float", "(", ")", ")", ".", "item", "(", ")", ",", "\n", "\"r@10\"", ":", "torch", ".", "mean", "(", "(", "__rank_list", "<=", "10", ")", ".", "float", "(", ")", ")", ".", "item", "(", ")", ",", "\n", "\"mean\"", ":", "torch", ".", "mean", "(", "__rank_list", ")", ".", "item", "(", ")", ",", "\n", "\"mrr\"", ":", "torch", ".", "mean", "(", "__rank_list", ".", "reciprocal", "(", ")", ")", ".", "item", "(", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "            ", "metrics", "=", "{", "}", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.SparseGTMetrics.reset": [[93, 95], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_rank_list", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.NDCG.__init__": [[98, 101], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_ndcg_numerator", "=", "0.0", "\n", "self", ".", "_ndcg_denominator", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.NDCG.observe": [[102, 153], ["predicted_scores.unsqueeze.unsqueeze.detach", "predicted_scores.unsqueeze.unsqueeze.unsqueeze", "metrics.scores_to_ranks", "predicted_ranks.squeeze.squeeze.squeeze", "predicted_ranks.squeeze.squeeze.size", "torch.sum", "torch.sort", "torch.sort", "range", "sum", "metrics.NDCG._dcg", "metrics.NDCG._dcg", "batch_ndcg.append"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.scores_to_ranks", "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.NDCG._dcg", "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.NDCG._dcg"], ["", "def", "observe", "(", "\n", "self", ",", "predicted_scores", ":", "torch", ".", "Tensor", ",", "target_relevance", ":", "torch", ".", "Tensor", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Observe model output scores and target ground truth relevance and\n        accumulate NDCG metric.\n\n        Parameters\n        ----------\n        predicted_scores: torch.Tensor\n            A tensor of shape (batch_size, num_options), because dense\n            annotations are available for 1 randomly picked round out of 10.\n        target_relevance: torch.Tensor\n            A tensor of shape same as predicted scores, indicating ground truth\n            relevance of each answer option for a particular round.\n        \"\"\"", "\n", "predicted_scores", "=", "predicted_scores", ".", "detach", "(", ")", "\n", "\n", "# shape: (batch_size, 1, num_options)", "\n", "predicted_scores", "=", "predicted_scores", ".", "unsqueeze", "(", "1", ")", "\n", "predicted_ranks", "=", "scores_to_ranks", "(", "predicted_scores", ")", "\n", "\n", "# shape: (batch_size, num_options)", "\n", "predicted_ranks", "=", "predicted_ranks", ".", "squeeze", "(", ")", "\n", "batch_size", ",", "num_options", "=", "predicted_ranks", ".", "size", "(", ")", "\n", "\n", "k", "=", "torch", ".", "sum", "(", "target_relevance", "!=", "0", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# shape: (batch_size, num_options)", "\n", "_", ",", "rankings", "=", "torch", ".", "sort", "(", "predicted_ranks", ",", "dim", "=", "-", "1", ")", "\n", "# Sort relevance in descending order so highest relevance gets top rnk.", "\n", "_", ",", "best_rankings", "=", "torch", ".", "sort", "(", "\n", "target_relevance", ",", "dim", "=", "-", "1", ",", "descending", "=", "True", "\n", ")", "\n", "\n", "# shape: (batch_size, )", "\n", "batch_ndcg", "=", "[", "]", "\n", "for", "batch_index", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "num_relevant", "=", "k", "[", "batch_index", "]", "\n", "dcg", "=", "self", ".", "_dcg", "(", "\n", "rankings", "[", "batch_index", "]", "[", ":", "num_relevant", "]", ",", "\n", "target_relevance", "[", "batch_index", "]", ",", "\n", ")", "\n", "best_dcg", "=", "self", ".", "_dcg", "(", "\n", "best_rankings", "[", "batch_index", "]", "[", ":", "num_relevant", "]", ",", "\n", "target_relevance", "[", "batch_index", "]", ",", "\n", ")", "\n", "batch_ndcg", ".", "append", "(", "dcg", "/", "best_dcg", ")", "\n", "\n", "", "self", ".", "_ndcg_denominator", "+=", "batch_size", "\n", "self", ".", "_ndcg_numerator", "+=", "sum", "(", "batch_ndcg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.NDCG._dcg": [[154, 158], ["relevance[].cpu().float", "torch.log2", "torch.sum", "relevance[].cpu", "torch.arange().float", "torch.arange", "len"], "methods", ["None"], ["", "def", "_dcg", "(", "self", ",", "rankings", ":", "torch", ".", "Tensor", ",", "relevance", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "sorted_relevance", "=", "relevance", "[", "rankings", "]", ".", "cpu", "(", ")", ".", "float", "(", ")", "\n", "discounts", "=", "torch", ".", "log2", "(", "torch", ".", "arange", "(", "len", "(", "rankings", ")", ")", ".", "float", "(", ")", "+", "2", ")", "\n", "return", "torch", ".", "sum", "(", "sorted_relevance", "/", "discounts", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.NDCG.retrieve": [[159, 170], ["metrics.NDCG.reset", "float"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.NDCG.reset"], ["", "def", "retrieve", "(", "self", ",", "reset", ":", "bool", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "_ndcg_denominator", ">", "0", ":", "\n", "            ", "metrics", "=", "{", "\n", "\"ndcg\"", ":", "float", "(", "self", ".", "_ndcg_numerator", "/", "self", ".", "_ndcg_denominator", ")", "\n", "}", "\n", "", "else", ":", "\n", "            ", "metrics", "=", "{", "}", "\n", "\n", "", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.NDCG.reset": [[171, 174], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_ndcg_numerator", "=", "0.0", "\n", "self", ".", "_ndcg_denominator", "=", "0.0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.metrics.scores_to_ranks": [[21, 40], ["scores.view.size", "scores.view.view", "scores.view.sort", "ranked_idx.clone().fill_", "range", "ranks.view.view", "ranked_idx.size", "range", "ranked_idx.clone"], "function", ["None"], ["def", "scores_to_ranks", "(", "scores", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Convert model output scores into ranks.\"\"\"", "\n", "batch_size", ",", "num_rounds", ",", "num_options", "=", "scores", ".", "size", "(", ")", "\n", "scores", "=", "scores", ".", "view", "(", "-", "1", ",", "num_options", ")", "\n", "\n", "# sort in descending order - largest score gets highest rank", "\n", "sorted_ranks", ",", "ranked_idx", "=", "scores", ".", "sort", "(", "1", ",", "descending", "=", "True", ")", "\n", "\n", "# i-th position in ranked_idx specifies which score shall take this", "\n", "# position but we want i-th position to have rank of score at that", "\n", "# position, do this conversion", "\n", "ranks", "=", "ranked_idx", ".", "clone", "(", ")", ".", "fill_", "(", "0", ")", "\n", "for", "i", "in", "range", "(", "ranked_idx", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "num_options", ")", ":", "\n", "            ", "ranks", "[", "i", "]", "[", "ranked_idx", "[", "i", "]", "[", "j", "]", "]", "=", "j", "\n", "# convert from 0-99 ranks to 1-100 ranks", "\n", "", "", "ranks", "+=", "1", "\n", "ranks", "=", "ranks", ".", "view", "(", "batch_size", ",", "num_rounds", ",", "num_options", ")", "\n", "return", "ranks", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.model.EncoderDecoderModel.__init__": [[13, 17], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.visdialch.model.EncoderDecoderModel.forward": [[18, 22], ["model.EncoderDecoderModel.encoder", "model.EncoderDecoderModel.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "encoder_output", "=", "self", ".", "encoder", "(", "batch", ")", "\n", "decoder_output", "=", "self", ".", "decoder", "(", "encoder_output", ",", "batch", ")", "\n", "return", "decoder_output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.checkpointing.CheckpointManager.__init__": [[57, 81], ["pathlib.Path", "checkpointing.CheckpointManager.init_directory", "isinstance", "TypeError", "isinstance", "TypeError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.utils.checkpointing.CheckpointManager.init_directory"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "optimizer", ",", "\n", "checkpoint_dirpath", ",", "\n", "step_size", "=", "1", ",", "\n", "last_epoch", "=", "-", "1", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "model", ",", "nn", ".", "Module", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"{} is not a Module\"", ".", "format", "(", "type", "(", "model", ")", ".", "__name__", ")", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "optimizer", ",", "optim", ".", "Optimizer", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "\"{} is not an Optimizer\"", ".", "format", "(", "type", "(", "optimizer", ")", ".", "__name__", ")", "\n", ")", "\n", "\n", "", "self", ".", "model", "=", "model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "ckpt_dirpath", "=", "Path", "(", "checkpoint_dirpath", ")", "\n", "self", ".", "step_size", "=", "step_size", "\n", "self", ".", "last_epoch", "=", "last_epoch", "\n", "self", ".", "init_directory", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.checkpointing.CheckpointManager.init_directory": [[82, 101], ["checkpointing.CheckpointManager.ckpt_dirpath.mkdir", "subprocess.Popen", "subprocess.Popen.communicate", "commit_sha.decode().strip().replace.decode().strip().replace.decode().strip().replace", "commit_sha_filepath.touch", "yaml.dump", "open", "commit_sha.decode().strip().replace.decode().strip().replace.decode().strip", "str", "commit_sha.decode().strip().replace.decode().strip().replace.decode"], "methods", ["None"], ["", "def", "init_directory", "(", "self", ",", "config", "=", "{", "}", ")", ":", "\n", "        ", "\"\"\"Initialize empty checkpoint directory and record commit SHA\n        in it. Also save hyper-parameters config in this directory to\n        associate checkpoints with their hyper-parameters.\n        \"\"\"", "\n", "\n", "self", ".", "ckpt_dirpath", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "# save current git commit hash in this checkpoint directory", "\n", "commit_sha_subprocess", "=", "Popen", "(", "\n", "[", "\"git\"", ",", "\"rev-parse\"", ",", "\"--short\"", ",", "\"HEAD\"", "]", ",", "stdout", "=", "PIPE", ",", "stderr", "=", "PIPE", "\n", ")", "\n", "commit_sha", ",", "_", "=", "commit_sha_subprocess", ".", "communicate", "(", ")", "\n", "commit_sha", "=", "commit_sha", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "commit_sha_filepath", "=", "self", ".", "ckpt_dirpath", "/", "f\".commit-{commit_sha}\"", "\n", "commit_sha_filepath", ".", "touch", "(", ")", "\n", "yaml", ".", "dump", "(", "\n", "config", ",", "\n", "open", "(", "str", "(", "self", ".", "ckpt_dirpath", "/", "\"config.yml\"", ")", ",", "\"w\"", ")", ",", "\n", "default_flow_style", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.checkpointing.CheckpointManager.step": [[103, 117], ["torch.save", "checkpointing.CheckpointManager._model_state_dict", "checkpointing.CheckpointManager.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.data.vocabulary.Vocabulary.save", "home.repos.pwc.inspect_result.yuleiniu_rva.utils.checkpointing.CheckpointManager._model_state_dict"], ["", "def", "step", "(", "self", ",", "epoch", "=", "None", ")", ":", "\n", "        ", "\"\"\"Save checkpoint if step size conditions meet. \"\"\"", "\n", "\n", "if", "not", "epoch", ":", "\n", "            ", "epoch", "=", "self", ".", "last_epoch", "+", "1", "\n", "", "self", ".", "last_epoch", "=", "epoch", "\n", "\n", "if", "not", "self", ".", "last_epoch", "%", "self", ".", "step_size", ":", "\n", "            ", "torch", ".", "save", "(", "\n", "{", "\n", "\"model\"", ":", "self", ".", "_model_state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "\n", "self", ".", "ckpt_dirpath", "/", "f\"checkpoint_{self.last_epoch}.pth\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.checkpointing.CheckpointManager._model_state_dict": [[119, 125], ["isinstance", "checkpointing.CheckpointManager.model.module.state_dict", "checkpointing.CheckpointManager.model.state_dict"], "methods", ["None"], ["", "", "def", "_model_state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns state dict of model, taking care of DataParallel case.\"\"\"", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "nn", ".", "DataParallel", ")", ":", "\n", "            ", "return", "self", ".", "model", ".", "module", ".", "state_dict", "(", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.checkpointing.load_checkpoint": [[127, 180], ["isinstance", "list", "torch.load", "pathlib.Path", "pathlib.Path.resolve", "checkpoint_dirpath.glob", "len", "warnings.warn", "subprocess.Popen", "subprocess.Popen.communicate", "commit_sha.decode().strip().replace.decode().strip().replace", "warnings.warn", "commit_sha.decode().strip().replace.decode().strip", "commit_sha.decode().strip().replace.decode"], "function", ["None"], ["", "", "", "def", "load_checkpoint", "(", "checkpoint_pthpath", ")", ":", "\n", "    ", "\"\"\"Given a path to saved checkpoint, load corresponding state dicts\n    of model and optimizer from it. This method checks if the current\n    commit SHA of codebase matches the commit SHA recorded when this\n    checkpoint was saved by checkpoint manager.\n\n    Parameters\n    ----------\n    checkpoint_pthpath: str or pathlib.Path\n        Path to saved checkpoint (as created by ``CheckpointManager``).\n\n    Returns\n    -------\n    nn.Module, optim.Optimizer\n        Model and optimizer state dicts loaded from checkpoint.\n\n    Raises\n    ------\n    UserWarning\n        If commit SHA do not match, or if the directory doesn't have\n        the recorded commit SHA.\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "checkpoint_pthpath", ",", "str", ")", ":", "\n", "        ", "checkpoint_pthpath", "=", "Path", "(", "checkpoint_pthpath", ")", "\n", "", "checkpoint_dirpath", "=", "checkpoint_pthpath", ".", "resolve", "(", ")", ".", "parent", "\n", "checkpoint_commit_sha", "=", "list", "(", "checkpoint_dirpath", ".", "glob", "(", "\".commit-*\"", ")", ")", "\n", "\n", "if", "len", "(", "checkpoint_commit_sha", ")", "==", "0", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"Commit SHA was not recorded while saving checkpoints.\"", "\n", ")", "\n", "", "else", ":", "\n", "# verify commit sha, raise warning if it doesn't match", "\n", "        ", "commit_sha_subprocess", "=", "Popen", "(", "\n", "[", "\"git\"", ",", "\"rev-parse\"", ",", "\"--short\"", ",", "\"HEAD\"", "]", ",", "stdout", "=", "PIPE", ",", "stderr", "=", "PIPE", "\n", ")", "\n", "commit_sha", ",", "_", "=", "commit_sha_subprocess", ".", "communicate", "(", ")", "\n", "commit_sha", "=", "commit_sha", ".", "decode", "(", "\"utf-8\"", ")", ".", "strip", "(", ")", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "\n", "\n", "# remove \".commit-\"", "\n", "checkpoint_commit_sha", "=", "checkpoint_commit_sha", "[", "0", "]", ".", "name", "[", "8", ":", "]", "\n", "\n", "if", "commit_sha", "!=", "checkpoint_commit_sha", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "f\"Current commit ({commit_sha}) and the commit \"", "\n", "f\"({checkpoint_commit_sha}) at which checkpoint was saved,\"", "\n", "\" are different. This might affect reproducibility.\"", "\n", ")", "\n", "\n", "# load encoder, decoder, optimizer state_dicts", "\n", "", "", "components", "=", "torch", ".", "load", "(", "checkpoint_pthpath", ")", "\n", "return", "components", "[", "\"model\"", "]", ",", "components", "[", "\"optimizer\"", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.layers.GatedTrans.__init__": [[7, 23], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Linear", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["def", "__init__", "(", "self", ",", "in_dim", ",", "out_dim", ")", ":", "\n", "        ", "super", "(", "GatedTrans", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embed_y", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "\n", "in_dim", ",", "\n", "out_dim", "\n", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", ")", "\n", "self", ".", "embed_g", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "\n", "in_dim", ",", "\n", "out_dim", "\n", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.layers.GatedTrans.forward": [[25, 31], ["layers.GatedTrans.embed_y", "layers.GatedTrans.embed_g"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_in", ")", ":", "\n", "        ", "x_y", "=", "self", ".", "embed_y", "(", "x_in", ")", "\n", "x_g", "=", "self", ".", "embed_g", "(", "x_in", ")", "\n", "x_out", "=", "x_y", "*", "x_g", "\n", "\n", "return", "x_out", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.layers.Q_ATT.__init__": [[34, 58], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Softmax", "layers.Q_ATT.modules", "torch.nn.Dropout", "layers.GatedTrans", "torch.nn.Dropout", "torch.nn.Linear", "isinstance", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Q_ATT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embed", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "GatedTrans", "(", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "*", "2", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "\n", ")", ",", "\n", ")", "\n", "self", ".", "att", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "1", "\n", ")", "\n", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "m", ".", "weight", ".", "data", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.layers.Q_ATT.forward": [[59, 79], ["ques_word.size", "ques_word.size", "ques_word.size", "layers.Q_ATT.embed", "torch.nn.functional.normalize", "layers.Q_ATT.att().squeeze", "layers.Q_ATT.softmax", "torch.sum", "torch.sum", "layers.Q_ATT.att", "layers.Q_ATT.unsqueeze"], "methods", ["None"], ["", "", "", "", "def", "forward", "(", "self", ",", "ques_word", ",", "ques_word_encoded", ",", "ques_not_pad", ")", ":", "\n", "# ques_word shape: (batch_size, num_rounds, quen_len_max, word_embed_dim)", "\n", "# ques_embed shape: (batch_size, num_rounds, quen_len_max, lstm_hidden_size * 2)", "\n", "# ques_not_pad shape: (batch_size, num_rounds, quen_len_max)", "\n", "# output: img_att (batch_size, num_rounds, embed_dim)", "\n", "        ", "batch_size", "=", "ques_word", ".", "size", "(", "0", ")", "\n", "num_rounds", "=", "ques_word", ".", "size", "(", "1", ")", "\n", "quen_len_max", "=", "ques_word", ".", "size", "(", "2", ")", "\n", "\n", "ques_embed", "=", "self", ".", "embed", "(", "ques_word_encoded", ")", "# shape: (batch_size, num_rounds, quen_len_max, embed_dim)", "\n", "ques_norm", "=", "F", ".", "normalize", "(", "ques_embed", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "# shape: (batch_size, num_rounds, quen_len_max, embed_dim) ", "\n", "\n", "att", "=", "self", ".", "att", "(", "ques_norm", ")", ".", "squeeze", "(", "-", "1", ")", "# shape: (batch_size, num_rounds, quen_len_max)", "\n", "# ignore <pad> word", "\n", "att", "=", "self", ".", "softmax", "(", "att", ")", "\n", "att", "=", "att", "*", "ques_not_pad", "# shape: (batch_size, num_rounds, quen_len_max)", "\n", "att", "=", "att", "/", "torch", ".", "sum", "(", "att", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "# shape: (batch_size, num_rounds, quen_len_max)", "\n", "feat", "=", "torch", ".", "sum", "(", "att", ".", "unsqueeze", "(", "-", "1", ")", "*", "ques_word", ",", "dim", "=", "-", "2", ")", "# shape: (batch_size, num_rounds, rnn_dim)", "\n", "\n", "return", "feat", ",", "att", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.layers.H_ATT.__init__": [[82, 113], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Softmax", "layers.H_ATT.modules", "torch.nn.Dropout", "layers.GatedTrans", "torch.nn.Dropout", "layers.GatedTrans", "torch.nn.Dropout", "torch.nn.Linear", "isinstance", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "H_ATT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "H_embed", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "GatedTrans", "(", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "*", "2", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "\n", ")", ",", "\n", ")", "\n", "self", ".", "Q_embed", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "GatedTrans", "(", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "*", "2", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "\n", ")", ",", "\n", ")", "\n", "self", ".", "att", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "1", "\n", ")", "\n", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "m", ".", "weight", ".", "data", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.layers.H_ATT.forward": [[114, 137], ["ques.size", "ques.size", "layers.H_ATT.H_embed", "hist_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "layers.H_ATT.Q_embed", "ques_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "torch.nn.functional.normalize", "layers.H_ATT.att().squeeze", "layers.H_ATT.softmax", "torch.tril", "att_not_pad.cuda.cuda.cuda", "torch.sum", "torch.ones", "torch.sum", "hist_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "ques_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "layers.H_ATT.att", "att_masked.unsqueeze", "hist.unsqueeze"], "methods", ["None"], ["", "", "", "", "def", "forward", "(", "self", ",", "hist", ",", "ques", ")", ":", "\n", "# hist shape: (batch_size, num_rounds, rnn_dim)", "\n", "# ques shape: (batch_size, num_rounds, rnn_dim)", "\n", "# output: hist_att (batch_size, num_rounds, embed_dim)", "\n", "        ", "batch_size", "=", "ques", ".", "size", "(", "0", ")", "\n", "num_rounds", "=", "ques", ".", "size", "(", "1", ")", "\n", "\n", "hist_embed", "=", "self", ".", "H_embed", "(", "hist", ")", "# shape: (batch_size, num_rounds, embed_dim)", "\n", "hist_embed", "=", "hist_embed", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "num_rounds", ",", "1", ",", "1", ")", "# shape: (batch_size, num_rounds, num_rounds, embed_dim)", "\n", "\n", "ques_embed", "=", "self", ".", "Q_embed", "(", "ques", ")", "# shape: (batch_size, num_rounds, embed_dim)", "\n", "ques_embed", "=", "ques_embed", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "num_rounds", ",", "1", ")", "# shape: (batch_size, num_rounds, num_rounds, embed_dim)", "\n", "\n", "att_embed", "=", "F", ".", "normalize", "(", "hist_embed", "*", "ques_embed", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "# (batch_size, num_rounds, num_rounds, embed_dim)", "\n", "att_embed", "=", "self", ".", "att", "(", "att_embed", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "att", "=", "self", ".", "softmax", "(", "att_embed", ")", "# shape: (batch_size, num_rounds, num_rounds)", "\n", "att_not_pad", "=", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "size", "=", "[", "num_rounds", ",", "num_rounds", "]", ",", "requires_grad", "=", "False", ")", ")", "# shape: (num_rounds, num_rounds)", "\n", "att_not_pad", "=", "att_not_pad", ".", "cuda", "(", ")", "\n", "att_masked", "=", "att", "*", "att_not_pad", "# shape: (batch_size, num_rounds, num_rounds) ", "\n", "att_masked", "=", "att_masked", "/", "torch", ".", "sum", "(", "att_masked", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "# shape: (batch_size, num_rounds, num_rounds)", "\n", "feat", "=", "torch", ".", "sum", "(", "att_masked", ".", "unsqueeze", "(", "-", "1", ")", "*", "hist", ".", "unsqueeze", "(", "1", ")", ",", "dim", "=", "-", "2", ")", "# shape: (batch_size, num_rounds, rnn_dim)", "\n", "\n", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.layers.V_Filter.__init__": [[140, 157], ["torch.nn.Module.__init__", "torch.nn.Sequential", "layers.V_Filter.modules", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Sigmoid", "isinstance", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "V_Filter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "filter", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "config", "[", "\"img_feature_size\"", "]", "\n", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "\n", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "m", ".", "weight", ".", "data", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.layers.V_Filter.forward": [[158, 172], ["ques.size", "ques.size", "layers.V_Filter.filter"], "methods", ["None"], ["", "", "", "", "def", "forward", "(", "self", ",", "img", ",", "ques", ")", ":", "\n", "# img shape: (batch_size, num_rounds, i_dim)", "\n", "# ques shape: (batch_size, num_rounds, q_dim)", "\n", "# output: img_att (batch_size, num_rounds, embed_dim)", "\n", "\n", "        ", "batch_size", "=", "ques", ".", "size", "(", "0", ")", "\n", "num_rounds", "=", "ques", ".", "size", "(", "1", ")", "\n", "\n", "ques_embed", "=", "self", ".", "filter", "(", "ques", ")", "# shape: (batch_size, num_rounds, embed_dim)", "\n", "\n", "# gated", "\n", "img_fused", "=", "img", "*", "ques_embed", "\n", "\n", "return", "img_fused", "", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.dynamic_rnn.DynamicRNN.__init__": [[7, 10], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "rnn_model", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn_model", "=", "rnn_model", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.dynamic_rnn.DynamicRNN.forward": [[11, 56], ["seq_input.size", "dynamic_rnn.DynamicRNN._get_sorted_order", "seq_input.index_select", "torch.nn.utils.rnn.pack_padded_sequence", "dynamic_rnn.DynamicRNN.rnn_model.flatten_parameters", "dynamic_rnn.DynamicRNN.rnn_model", "h_n[].index_select", "c_n[].index_select", "[].index_select", "hx[].size", "torch.nn.utils.rnn.pad_packed_sequence"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.utils.dynamic_rnn.DynamicRNN._get_sorted_order"], ["", "def", "forward", "(", "self", ",", "seq_input", ",", "seq_lens", ",", "initial_state", "=", "None", ")", ":", "\n", "        ", "\"\"\"A wrapper over pytorch's rnn to handle sequences of variable length.\n\n        Arguments\n        ---------\n        seq_input : torch.Tensor\n            Input sequence tensor (padded) for RNN model.\n            Shape: (batch_size, max_sequence_length, embed_size)\n        seq_lens : torch.LongTensor\n            Length of sequences (b, )\n        initial_state : torch.Tensor\n            Initial (hidden, cell) states of RNN model.\n\n        Returns\n        -------\n            Single tensor of shape (batch_size, rnn_hidden_size) corresponding\n            to the outputs of the RNN model at the last time step of each input\n            sequence.\n        \"\"\"", "\n", "max_sequence_length", "=", "seq_input", ".", "size", "(", "1", ")", "\n", "sorted_len", ",", "fwd_order", ",", "bwd_order", "=", "self", ".", "_get_sorted_order", "(", "seq_lens", ")", "\n", "sorted_seq_input", "=", "seq_input", ".", "index_select", "(", "0", ",", "fwd_order", ")", "\n", "packed_seq_input", "=", "pack_padded_sequence", "(", "\n", "sorted_seq_input", ",", "lengths", "=", "sorted_len", ",", "batch_first", "=", "True", "\n", ")", "\n", "\n", "if", "initial_state", "is", "not", "None", ":", "\n", "            ", "hx", "=", "initial_state", "\n", "assert", "hx", "[", "0", "]", ".", "size", "(", "0", ")", "==", "self", ".", "rnn_model", ".", "num_layers", "\n", "", "else", ":", "\n", "            ", "sorted_hx", "=", "None", "\n", "\n", "", "self", ".", "rnn_model", ".", "flatten_parameters", "(", ")", "\n", "\n", "outputs", ",", "(", "h_n", ",", "c_n", ")", "=", "self", ".", "rnn_model", "(", "packed_seq_input", ",", "sorted_hx", ")", "\n", "\n", "# pick hidden and cell states of last layer", "\n", "h_n", "=", "h_n", "[", "-", "1", "]", ".", "index_select", "(", "dim", "=", "0", ",", "index", "=", "bwd_order", ")", "\n", "c_n", "=", "c_n", "[", "-", "1", "]", ".", "index_select", "(", "dim", "=", "0", ",", "index", "=", "bwd_order", ")", "\n", "\n", "outputs", "=", "pad_packed_sequence", "(", "\n", "outputs", ",", "batch_first", "=", "True", ",", "total_length", "=", "max_sequence_length", "\n", ")", "[", "0", "]", ".", "index_select", "(", "dim", "=", "0", ",", "index", "=", "bwd_order", ")", "\n", "\n", "return", "outputs", ",", "(", "h_n", ",", "c_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.utils.dynamic_rnn.DynamicRNN._get_sorted_order": [[57, 65], ["torch.sort", "torch.sort", "list", "lens.contiguous().view", "lens.contiguous"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_sorted_order", "(", "lens", ")", ":", "\n", "        ", "sorted_len", ",", "fwd_order", "=", "torch", ".", "sort", "(", "\n", "lens", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "0", ",", "descending", "=", "True", "\n", ")", "\n", "_", ",", "bwd_order", "=", "torch", ".", "sort", "(", "fwd_order", ")", "\n", "sorted_len", "=", "list", "(", "sorted_len", ")", "\n", "return", "sorted_len", ",", "fwd_order", ",", "bwd_order", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.decoders.disc.DiscriminativeDecoder.__init__": [[8, 27], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.LSTM", "visdialch.utils.DynamicRNN", "len"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocabulary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "word_embed", "=", "nn", ".", "Embedding", "(", "\n", "len", "(", "vocabulary", ")", ",", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "padding_idx", "=", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "self", ".", "option_rnn", "=", "nn", ".", "LSTM", "(", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "config", "[", "\"lstm_num_layers\"", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", "dropout", "=", "config", "[", "\"dropout\"", "]", ",", "\n", ")", "\n", "\n", "# Options are variable length padded sequences, use DynamicRNN.", "\n", "self", ".", "option_rnn", "=", "DynamicRNN", "(", "self", ".", "option_rnn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.decoders.disc.DiscriminativeDecoder.forward": [[28, 95], ["options.view.view.size", "options.view.view.view", "options_length.view.view.view", "options_length.view.view.nonzero().squeeze", "disc.DiscriminativeDecoder.word_embed", "disc.DiscriminativeDecoder.option_rnn", "torch.zeros", "encoder_output.view.view.unsqueeze().repeat", "encoder_output.view.view.view", "torch.sum", "scores.view.view.view", "disc.DiscriminativeDecoder.size", "options_length.view.view.nonzero", "encoder_output.view.view.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoder_output", ",", "batch", ")", ":", "\n", "        ", "\"\"\"Given `encoder_output` + candidate option sequences, predict a score\n        for each option sequence.\n\n        Parameters\n        ----------\n        encoder_output: torch.Tensor\n            Output from the encoder through its forward pass.\n            (batch_size, num_rounds, lstm_hidden_size)\n        \"\"\"", "\n", "\n", "options", "=", "batch", "[", "\"opt\"", "]", "\n", "batch_size", ",", "num_rounds", ",", "num_options", ",", "max_sequence_length", "=", "(", "\n", "options", ".", "size", "(", ")", "\n", ")", "\n", "options", "=", "options", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", ",", "max_sequence_length", "\n", ")", "\n", "\n", "options_length", "=", "batch", "[", "\"opt_len\"", "]", "\n", "options_length", "=", "options_length", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", "\n", ")", "\n", "\n", "# Pick options with non-zero length (relevant for test split).", "\n", "nonzero_options_length_indices", "=", "options_length", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "nonzero_options_length", "=", "options_length", "[", "nonzero_options_length_indices", "]", "\n", "nonzero_options", "=", "options", "[", "nonzero_options_length_indices", "]", "\n", "\n", "# shape: (batch_size * num_rounds * num_options, max_sequence_length,", "\n", "#         word_embedding_size)", "\n", "# FOR TEST SPLIT, shape: (batch_size * 1, num_options,", "\n", "#                         max_sequence_length, word_embedding_size)", "\n", "nonzero_options_embed", "=", "self", ".", "word_embed", "(", "nonzero_options", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options, lstm_hidden_size)", "\n", "# FOR TEST SPLIT, shape: (batch_size * 1, num_options,", "\n", "#                         lstm_hidden_size)", "\n", "_", ",", "(", "nonzero_options_embed", ",", "_", ")", "=", "self", ".", "option_rnn", "(", "\n", "nonzero_options_embed", ",", "nonzero_options_length", "\n", ")", "\n", "\n", "options_embed", "=", "torch", ".", "zeros", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", ",", "\n", "nonzero_options_embed", ".", "size", "(", "-", "1", ")", ",", "\n", "device", "=", "nonzero_options_embed", ".", "device", ",", "\n", ")", "\n", "options_embed", "[", "nonzero_options_length_indices", "]", "=", "nonzero_options_embed", "\n", "\n", "# Repeat encoder output for every option.", "\n", "# shape: (batch_size, num_rounds, num_options, max_sequence_length)", "\n", "encoder_output", "=", "encoder_output", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "\n", "1", ",", "1", ",", "num_options", ",", "1", "\n", ")", "\n", "\n", "# Shape now same as `options`, can calculate dot product similarity.", "\n", "# shape: (batch_size * num_rounds * num_options, lstm_hidden_state)", "\n", "encoder_output", "=", "encoder_output", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", ",", "\n", "self", ".", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options)", "\n", "scores", "=", "torch", ".", "sum", "(", "options_embed", "*", "encoder_output", ",", "1", ")", "\n", "# shape: (batch_size, num_rounds, num_options)", "\n", "scores", "=", "scores", ".", "view", "(", "batch_size", ",", "num_rounds", ",", "num_options", ")", "\n", "return", "scores", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.decoders.gen.GenerativeDecoder.__init__": [[6, 29], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.LogSoftmax", "len", "len"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocabulary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "word_embed", "=", "nn", ".", "Embedding", "(", "\n", "len", "(", "vocabulary", ")", ",", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "padding_idx", "=", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "self", ".", "answer_rnn", "=", "nn", ".", "LSTM", "(", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "config", "[", "\"lstm_num_layers\"", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", "dropout", "=", "config", "[", "\"dropout\"", "]", ",", "\n", ")", "\n", "\n", "self", ".", "lstm_to_words", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "config", "[", "\"lstm_hidden_size\"", "]", ",", "len", "(", "vocabulary", ")", "\n", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout\"", "]", ")", "\n", "self", ".", "logsoftmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.decoders.gen.GenerativeDecoder.forward": [[30, 132], ["ans_in.view.view.size", "ans_in.view.view.view", "gen.GenerativeDecoder.word_embed", "encoder_output.view", "init_hidden.repeat.repeat.repeat", "torch.zeros_like", "gen.GenerativeDecoder.answer_rnn", "gen.GenerativeDecoder.dropout", "gen.GenerativeDecoder.lstm_to_words", "ans_in.view.view.size", "ans_in.view.view.view", "gen.GenerativeDecoder.word_embed", "encoder_output.view", "init_hidden.repeat.repeat.repeat", "init_hidden.repeat.repeat.view", "init_hidden.repeat.repeat.repeat", "torch.zeros_like", "gen.GenerativeDecoder.answer_rnn", "gen.GenerativeDecoder.logsoftmax", "batch[].view", "torch.gather().squeeze", "torch.sum", "ans_scores.view.view.view", "gen.GenerativeDecoder.lstm_to_words", "torch.gather", "batch[].view.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoder_output", ",", "batch", ")", ":", "\n", "        ", "\"\"\"Given `encoder_output`, learn to autoregressively predict\n        ground-truth answer word-by-word during training.\n\n        During evaluation, assign log-likelihood scores to all answer options.\n\n        Parameters\n        ----------\n        encoder_output: torch.Tensor\n            Output from the encoder through its forward pass.\n            (batch_size, num_rounds, lstm_hidden_size)\n        \"\"\"", "\n", "\n", "if", "self", ".", "training", ":", "\n", "\n", "            ", "ans_in", "=", "batch", "[", "\"ans_in\"", "]", "\n", "batch_size", ",", "num_rounds", ",", "max_sequence_length", "=", "ans_in", ".", "size", "(", ")", "\n", "\n", "ans_in", "=", "ans_in", ".", "view", "(", "batch_size", "*", "num_rounds", ",", "max_sequence_length", ")", "\n", "\n", "# shape: (batch_size * num_rounds, max_sequence_length,", "\n", "#         word_embedding_size)", "\n", "ans_in_embed", "=", "self", ".", "word_embed", "(", "ans_in", ")", "\n", "\n", "# reshape encoder output to be set as initial hidden state of LSTM.", "\n", "# shape: (lstm_num_layers, batch_size * num_rounds,", "\n", "#         lstm_hidden_size)", "\n", "init_hidden", "=", "encoder_output", ".", "view", "(", "1", ",", "batch_size", "*", "num_rounds", ",", "-", "1", ")", "\n", "init_hidden", "=", "init_hidden", ".", "repeat", "(", "\n", "self", ".", "config", "[", "\"lstm_num_layers\"", "]", ",", "1", ",", "1", "\n", ")", "\n", "init_cell", "=", "torch", ".", "zeros_like", "(", "init_hidden", ")", "\n", "\n", "# shape: (batch_size * num_rounds, max_sequence_length,", "\n", "#         lstm_hidden_size)", "\n", "ans_out", ",", "(", "hidden", ",", "cell", ")", "=", "self", ".", "answer_rnn", "(", "\n", "ans_in_embed", ",", "(", "init_hidden", ",", "init_cell", ")", "\n", ")", "\n", "ans_out", "=", "self", ".", "dropout", "(", "ans_out", ")", "\n", "\n", "# shape: (batch_size * num_rounds, max_sequence_length,", "\n", "#         vocabulary_size)", "\n", "ans_word_scores", "=", "self", ".", "lstm_to_words", "(", "ans_out", ")", "\n", "return", "ans_word_scores", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "ans_in", "=", "batch", "[", "\"opt_in\"", "]", "\n", "batch_size", ",", "num_rounds", ",", "num_options", ",", "max_sequence_length", "=", "(", "\n", "ans_in", ".", "size", "(", ")", "\n", ")", "\n", "\n", "ans_in", "=", "ans_in", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", ",", "max_sequence_length", "\n", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options, max_sequence_length", "\n", "#         word_embedding_size)", "\n", "ans_in_embed", "=", "self", ".", "word_embed", "(", "ans_in", ")", "\n", "\n", "# reshape encoder output to be set as initial hidden state of LSTM.", "\n", "# shape: (lstm_num_layers, batch_size * num_rounds * num_options,", "\n", "#         lstm_hidden_size)", "\n", "init_hidden", "=", "encoder_output", ".", "view", "(", "batch_size", ",", "num_rounds", ",", "1", ",", "-", "1", ")", "\n", "init_hidden", "=", "init_hidden", ".", "repeat", "(", "1", ",", "1", ",", "num_options", ",", "1", ")", "\n", "init_hidden", "=", "init_hidden", ".", "view", "(", "\n", "1", ",", "batch_size", "*", "num_rounds", "*", "num_options", ",", "-", "1", "\n", ")", "\n", "init_hidden", "=", "init_hidden", ".", "repeat", "(", "\n", "self", ".", "config", "[", "\"lstm_num_layers\"", "]", ",", "1", ",", "1", "\n", ")", "\n", "init_cell", "=", "torch", ".", "zeros_like", "(", "init_hidden", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options,", "\n", "#         max_sequence_length, lstm_hidden_size)", "\n", "ans_out", ",", "(", "hidden", ",", "cell", ")", "=", "self", ".", "answer_rnn", "(", "\n", "ans_in_embed", ",", "(", "init_hidden", ",", "init_cell", ")", "\n", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options,", "\n", "#         max_sequence_length, vocabulary_size)", "\n", "ans_word_scores", "=", "self", ".", "logsoftmax", "(", "self", ".", "lstm_to_words", "(", "ans_out", ")", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options,", "\n", "#         max_sequence_length)", "\n", "target_ans_out", "=", "batch", "[", "\"opt_out\"", "]", ".", "view", "(", "\n", "batch_size", "*", "num_rounds", "*", "num_options", ",", "-", "1", "\n", ")", "\n", "\n", "# shape: (batch_size * num_rounds * num_options,", "\n", "#         max_sequence_length)", "\n", "ans_word_scores", "=", "torch", ".", "gather", "(", "\n", "ans_word_scores", ",", "-", "1", ",", "target_ans_out", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", ".", "squeeze", "(", ")", "\n", "ans_word_scores", "=", "(", "\n", "ans_word_scores", "*", "(", "target_ans_out", ">", "0", ")", ".", "float", "(", ")", ".", "cuda", "(", ")", "\n", ")", "# ugly", "\n", "\n", "ans_scores", "=", "torch", ".", "sum", "(", "ans_word_scores", ",", "-", "1", ")", "\n", "ans_scores", "=", "ans_scores", ".", "view", "(", "batch_size", ",", "num_rounds", ",", "num_options", ")", "\n", "\n", "return", "ans_scores", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.decoders.__init__.Decoder": [[5, 8], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.lf.LateFusionEncoder.__init__": [[9, 57], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.Dropout", "visdialch.utils.DynamicRNN", "visdialch.utils.DynamicRNN", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_", "len"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocabulary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "word_embed", "=", "nn", ".", "Embedding", "(", "\n", "len", "(", "vocabulary", ")", ",", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "padding_idx", "=", "vocabulary", ".", "PAD_INDEX", ",", "\n", ")", "\n", "self", ".", "hist_rnn", "=", "nn", ".", "LSTM", "(", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "config", "[", "\"lstm_num_layers\"", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", "dropout", "=", "config", "[", "\"dropout\"", "]", ",", "\n", ")", "\n", "self", ".", "ques_rnn", "=", "nn", ".", "LSTM", "(", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "config", "[", "\"lstm_num_layers\"", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", "dropout", "=", "config", "[", "\"dropout\"", "]", ",", "\n", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout\"", "]", ")", "\n", "\n", "# questions and history are right padded sequences of variable length", "\n", "# use the DynamicRNN utility module to handle them properly", "\n", "self", ".", "hist_rnn", "=", "DynamicRNN", "(", "self", ".", "hist_rnn", ")", "\n", "self", ".", "ques_rnn", "=", "DynamicRNN", "(", "self", ".", "ques_rnn", ")", "\n", "\n", "# project image features to lstm_hidden_size for computing attention", "\n", "self", ".", "image_features_projection", "=", "nn", ".", "Linear", "(", "\n", "config", "[", "\"img_feature_size\"", "]", ",", "config", "[", "\"lstm_hidden_size\"", "]", "\n", ")", "\n", "\n", "# fc layer for image * question to attention weights", "\n", "self", ".", "attention_proj", "=", "nn", ".", "Linear", "(", "config", "[", "\"lstm_hidden_size\"", "]", ",", "1", ")", "\n", "\n", "# fusion layer (attended_image_features + question + history)", "\n", "fusion_size", "=", "(", "\n", "config", "[", "\"img_feature_size\"", "]", "+", "config", "[", "\"lstm_hidden_size\"", "]", "*", "2", "\n", ")", "\n", "self", ".", "fusion", "=", "nn", ".", "Linear", "(", "fusion_size", ",", "config", "[", "\"lstm_hidden_size\"", "]", ")", "\n", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "image_features_projection", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "image_features_projection", ".", "bias", ",", "0", ")", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "fusion", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fusion", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.lf.LateFusionEncoder.forward": [[58, 136], ["ques.view.view.size", "ques.view.view.view", "lf.LateFusionEncoder.word_embed", "lf.LateFusionEncoder.ques_rnn", "lf.LateFusionEncoder.image_features_projection", "projected_image_features.view().repeat().view.view().repeat().view.view().repeat().view", "lf.LateFusionEncoder.unsqueeze().repeat", "lf.LateFusionEncoder.dropout", "lf.LateFusionEncoder.attention_proj().squeeze", "torch.nn.functional.softmax", "img.view().repeat().view.view().repeat().view.view().repeat().view", "image_attention_weights.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "hist.view.view.view", "lf.LateFusionEncoder.word_embed", "lf.LateFusionEncoder.hist_rnn", "torch.cat", "lf.LateFusionEncoder.dropout", "torch.tanh", "fused_embedding.view.view.view", "lf.LateFusionEncoder.fusion", "projected_image_features.view().repeat().view.view().repeat().view.view().repeat", "lf.LateFusionEncoder.unsqueeze", "lf.LateFusionEncoder.attention_proj", "img.view().repeat().view.view().repeat().view.view().repeat", "image_attention_weights.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "projected_image_features.view().repeat().view.view().repeat().view.view", "img.view().repeat().view.view().repeat().view.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "# shape: (batch_size, img_feature_size) - CNN fc7 features", "\n", "# shape: (batch_size, num_proposals, img_feature_size) - RCNN features", "\n", "        ", "img", "=", "batch", "[", "\"img_feat\"", "]", "\n", "# shape: (batch_size, 10, max_sequence_length)", "\n", "ques", "=", "batch", "[", "\"ques\"", "]", "\n", "# shape: (batch_size, 10, max_sequence_length * 2 * 10)", "\n", "# concatenated qa * 10 rounds", "\n", "hist", "=", "batch", "[", "\"hist\"", "]", "\n", "# num_rounds = 10, even for test (padded dialog rounds at the end)", "\n", "batch_size", ",", "num_rounds", ",", "max_sequence_length", "=", "ques", ".", "size", "(", ")", "\n", "\n", "# embed questions", "\n", "ques", "=", "ques", ".", "view", "(", "batch_size", "*", "num_rounds", ",", "max_sequence_length", ")", "\n", "ques_embed", "=", "self", ".", "word_embed", "(", "ques", ")", "\n", "\n", "# shape: (batch_size * num_rounds, max_sequence_length,", "\n", "#         lstm_hidden_size)", "\n", "_", ",", "(", "ques_embed", ",", "_", ")", "=", "self", ".", "ques_rnn", "(", "ques_embed", ",", "batch", "[", "\"ques_len\"", "]", ")", "\n", "\n", "# project down image features and ready for attention", "\n", "# shape: (batch_size, num_proposals, lstm_hidden_size)", "\n", "projected_image_features", "=", "self", ".", "image_features_projection", "(", "img", ")", "\n", "\n", "# repeat image feature vectors to be provided for every round", "\n", "# shape: (batch_size * num_rounds, num_proposals, lstm_hidden_size)", "\n", "projected_image_features", "=", "(", "\n", "projected_image_features", ".", "view", "(", "\n", "batch_size", ",", "1", ",", "-", "1", ",", "self", ".", "config", "[", "\"lstm_hidden_size\"", "]", "\n", ")", "\n", ".", "repeat", "(", "1", ",", "num_rounds", ",", "1", ",", "1", ")", "\n", ".", "view", "(", "batch_size", "*", "num_rounds", ",", "-", "1", ",", "self", ".", "config", "[", "\"lstm_hidden_size\"", "]", ")", "\n", ")", "\n", "\n", "# computing attention weights", "\n", "# shape: (batch_size * num_rounds, num_proposals)", "\n", "projected_ques_features", "=", "ques_embed", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "\n", "1", ",", "img", ".", "shape", "[", "1", "]", ",", "1", "\n", ")", "\n", "projected_ques_image", "=", "(", "\n", "projected_ques_features", "*", "projected_image_features", "\n", ")", "\n", "projected_ques_image", "=", "self", ".", "dropout", "(", "projected_ques_image", ")", "\n", "image_attention_weights", "=", "self", ".", "attention_proj", "(", "\n", "projected_ques_image", "\n", ")", ".", "squeeze", "(", ")", "\n", "image_attention_weights", "=", "F", ".", "softmax", "(", "image_attention_weights", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# shape: (batch_size * num_rounds, num_proposals, img_features_size)", "\n", "img", "=", "(", "\n", "img", ".", "view", "(", "batch_size", ",", "1", ",", "-", "1", ",", "self", ".", "config", "[", "\"img_feature_size\"", "]", ")", "\n", ".", "repeat", "(", "1", ",", "num_rounds", ",", "1", ",", "1", ")", "\n", ".", "view", "(", "batch_size", "*", "num_rounds", ",", "-", "1", ",", "self", ".", "config", "[", "\"img_feature_size\"", "]", ")", "\n", ")", "\n", "\n", "# multiply image features with their attention weights", "\n", "# shape: (batch_size * num_rounds, num_proposals, img_feature_size)", "\n", "image_attention_weights", "=", "image_attention_weights", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "\n", "1", ",", "1", ",", "self", ".", "config", "[", "\"img_feature_size\"", "]", "\n", ")", "\n", "# shape: (batch_size * num_rounds, img_feature_size)", "\n", "attended_image_features", "=", "(", "image_attention_weights", "*", "img", ")", ".", "sum", "(", "1", ")", "\n", "img", "=", "attended_image_features", "\n", "\n", "# embed history", "\n", "hist", "=", "hist", ".", "view", "(", "batch_size", "*", "num_rounds", ",", "max_sequence_length", "*", "20", ")", "\n", "hist_embed", "=", "self", ".", "word_embed", "(", "hist", ")", "\n", "\n", "# shape: (batch_size * num_rounds, lstm_hidden_size)", "\n", "_", ",", "(", "hist_embed", ",", "_", ")", "=", "self", ".", "hist_rnn", "(", "hist_embed", ",", "batch", "[", "\"hist_len\"", "]", ")", "\n", "\n", "fused_vector", "=", "torch", ".", "cat", "(", "(", "img", ",", "ques_embed", ",", "hist_embed", ")", ",", "1", ")", "\n", "fused_vector", "=", "self", ".", "dropout", "(", "fused_vector", ")", "\n", "\n", "fused_embedding", "=", "torch", ".", "tanh", "(", "self", ".", "fusion", "(", "fused_vector", ")", ")", "\n", "# shape: (batch_size, num_rounds, lstm_hidden_size)", "\n", "fused_embedding", "=", "fused_embedding", ".", "view", "(", "batch_size", ",", "num_rounds", ",", "-", "1", ")", "\n", "return", "fused_embedding", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.modules.ATT_MODULE.__init__": [[8, 40], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Softmax", "modules.ATT_MODULE.modules", "torch.nn.Dropout", "visdialch.utils.GatedTrans", "torch.nn.Dropout", "visdialch.utils.GatedTrans", "torch.nn.Dropout", "torch.nn.Linear", "isinstance", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "ATT_MODULE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "V_embed", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "GatedTrans", "(", "\n", "config", "[", "\"img_feature_size\"", "]", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "\n", ")", ",", "\n", ")", "\n", "self", ".", "Q_embed", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "GatedTrans", "(", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "\n", ")", ",", "\n", ")", "\n", "self", ".", "att", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "1", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "m", ".", "weight", ".", "data", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.modules.ATT_MODULE.forward": [[41, 67], ["ques.size", "ques.size", "img.size", "img.view", "modules.ATT_MODULE.V_embed", "img_embed.unsqueeze().repeat.unsqueeze().repeat.view", "img_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "ques.view", "modules.ATT_MODULE.Q_embed", "ques_embed.unsqueeze().repeat.unsqueeze().repeat.view", "ques_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "torch.nn.functional.normalize", "modules.ATT_MODULE.att().squeeze", "modules.ATT_MODULE.softmax", "img.size", "img_embed.unsqueeze().repeat.unsqueeze().repeat.size", "ques.size", "ques_embed.unsqueeze().repeat.unsqueeze().repeat.size", "img_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "ques_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "modules.ATT_MODULE.att"], "methods", ["None"], ["", "", "", "", "def", "forward", "(", "self", ",", "img", ",", "ques", ")", ":", "\n", "# input", "\n", "# img - shape: (batch_size, num_proposals, img_feature_size)", "\n", "# ques - shape: (batch_size, num_rounds, word_embedding_size)", "\n", "# output", "\n", "# att - shape: (batch_size, num_rounds, num_proposals)", "\n", "\n", "        ", "batch_size", "=", "ques", ".", "size", "(", "0", ")", "\n", "num_rounds", "=", "ques", ".", "size", "(", "1", ")", "\n", "num_proposals", "=", "img", ".", "size", "(", "1", ")", "\n", "\n", "img_embed", "=", "img", ".", "view", "(", "-", "1", ",", "img", ".", "size", "(", "-", "1", ")", ")", "# shape: (batch_size * num_proposals, img_feature_size)", "\n", "img_embed", "=", "self", ".", "V_embed", "(", "img_embed", ")", "# shape: (batch_size, num_proposals, lstm_hidden_size)", "\n", "img_embed", "=", "img_embed", ".", "view", "(", "batch_size", ",", "num_proposals", ",", "img_embed", ".", "size", "(", "-", "1", ")", ")", "# shape: (batch_size, num_proposals, lstm_hidden_size)", "\n", "img_embed", "=", "img_embed", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "num_rounds", ",", "1", ",", "1", ")", "# shape: (batch_size, num_rounds, num_proposals, lstm_hidden_size)", "\n", "\n", "ques_embed", "=", "ques", ".", "view", "(", "-", "1", ",", "ques", ".", "size", "(", "-", "1", ")", ")", "# shape: (batch_size * num_rounds, word_embedding_size)", "\n", "ques_embed", "=", "self", ".", "Q_embed", "(", "ques_embed", ")", "# shape: (batch_size, num_rounds, lstm_hidden_size)", "\n", "ques_embed", "=", "ques_embed", ".", "view", "(", "batch_size", ",", "num_rounds", ",", "ques_embed", ".", "size", "(", "-", "1", ")", ")", "# shape: (batch_size, num_rounds, lstm_hidden_size)", "\n", "ques_embed", "=", "ques_embed", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "num_proposals", ",", "1", ")", "# shape: (batch_size, num_rounds, num_proposals, lstm_hidden_size)", "\n", "\n", "att_embed", "=", "F", ".", "normalize", "(", "img_embed", "*", "ques_embed", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "# (batch_size, num_rounds, num_proposals, lstm_hidden_size)", "\n", "att_embed", "=", "self", ".", "att", "(", "att_embed", ")", ".", "squeeze", "(", "-", "1", ")", "# (batch_size, num_rounds, num_proposals)", "\n", "att", "=", "self", ".", "softmax", "(", "att_embed", ")", "# shape: (batch_size, num_rounds, num_proposals)", "\n", "\n", "return", "att", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.modules.PAIR_MODULE.__init__": [[70, 103], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "modules.PAIR_MODULE.modules", "torch.nn.Dropout", "visdialch.utils.GatedTrans", "torch.nn.Dropout", "visdialch.utils.GatedTrans", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Linear", "isinstance", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PAIR_MODULE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "H_embed", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "GatedTrans", "(", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "*", "2", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ")", ",", "\n", ")", "\n", "self", ".", "Q_embed", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "GatedTrans", "(", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "*", "2", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ")", ",", "\n", ")", "\n", "self", ".", "MLP", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "*", "2", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ")", ",", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "1", "\n", ")", "\n", ")", "\n", "self", ".", "att", "=", "nn", ".", "Linear", "(", "2", ",", "1", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "m", ".", "weight", ".", "data", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.modules.PAIR_MODULE.forward": [[104, 143], ["ques.size", "ques.size", "modules.PAIR_MODULE.H_embed", "hist_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "modules.PAIR_MODULE.Q_embed", "ques_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "torch.cat", "modules.PAIR_MODULE.MLP", "torch.tril().cumsum", "delta_t.cuda.cuda.view().repeat", "delta_t.cuda.cuda.cuda", "torch.cat", "modules.PAIR_MODULE.att().squeeze", "torch.zeros_like", "range", "hist_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "ques_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "torch.tril", "delta_t.cuda.cuda.view", "modules.PAIR_MODULE.att", "torch.nn.functional.gumbel_softmax", "logits.detach().max", "logits.detach().clone().zero_().scatter_", "torch.ones", "logits.detach", "logits.detach().clone().zero_", "logits.detach().clone", "logits.detach"], "methods", ["None"], ["", "", "", "", "def", "forward", "(", "self", ",", "hist", ",", "ques", ")", ":", "\n", "# input", "\n", "# ques shape: (batch_size, num_rounds, lstm_hidden_size*2)", "\n", "# hist shape: (batch_size, num_rounds, lstm_hidden_size*2)", "\n", "# output", "\n", "# hist_gs_set - shape: (batch_size, num_rounds, num_rounds)", "\n", "\n", "        ", "batch_size", "=", "ques", ".", "size", "(", "0", ")", "\n", "num_rounds", "=", "ques", ".", "size", "(", "1", ")", "\n", "\n", "hist_embed", "=", "self", ".", "H_embed", "(", "hist", ")", "# shape: (batch_size, num_rounds, lstm_hidden_size)", "\n", "hist_embed", "=", "hist_embed", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "num_rounds", ",", "1", ",", "1", ")", "# shape: (batch_size, num_rounds, num_rounds, lstm_hidden_size)", "\n", "\n", "ques_embed", "=", "self", ".", "Q_embed", "(", "ques", ")", "# shape: (batch_size, num_rounds, lstm_hidden_size)", "\n", "ques_embed", "=", "ques_embed", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "num_rounds", ",", "1", ")", "# shape: (batch_size, num_rounds, num_rounds, lstm_hidden_size)", "\n", "\n", "att_embed", "=", "torch", ".", "cat", "(", "(", "hist_embed", ",", "ques_embed", ")", ",", "dim", "=", "-", "1", ")", "\n", "score", "=", "self", ".", "MLP", "(", "att_embed", ")", "\n", "\n", "delta_t", "=", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "size", "=", "[", "num_rounds", ",", "num_rounds", "]", ",", "requires_grad", "=", "False", ")", ")", ".", "cumsum", "(", "dim", "=", "0", ")", "# (num_rounds, num_rounds)", "\n", "delta_t", "=", "delta_t", ".", "view", "(", "1", ",", "num_rounds", ",", "num_rounds", ",", "1", ")", ".", "repeat", "(", "batch_size", ",", "1", ",", "1", ",", "1", ")", "# (batch_size, num_rounds, num_rounds, 1)", "\n", "delta_t", "=", "delta_t", ".", "cuda", "(", ")", "\n", "att_embed", "=", "torch", ".", "cat", "(", "(", "score", ",", "delta_t", ")", ",", "dim", "=", "-", "1", ")", "# (batch_size, num_rounds, num_rounds, lstm_hidden_size*2)", "\n", "\n", "hist_logits", "=", "self", ".", "att", "(", "att_embed", ")", ".", "squeeze", "(", "-", "1", ")", "# (batch_size, num_rounds, num_rounds)", "\n", "\n", "# PAIR", "\n", "hist_gs_set", "=", "torch", ".", "zeros_like", "(", "hist_logits", ")", "\n", "for", "i", "in", "range", "(", "num_rounds", ")", ":", "\n", "# one-hot", "\n", "            ", "logits", "=", "hist_logits", "[", ":", ",", "i", ",", ":", "(", "i", "+", "1", ")", "]", "\n", "if", "self", ".", "training", ":", "\n", "                ", "hist_gs", "=", "F", ".", "gumbel_softmax", "(", "logits", ",", "hard", "=", "True", ")", "# shape: (batch_size, i+1)", "\n", "", "else", ":", "\n", "                ", "_", ",", "max_value_indexes", "=", "logits", ".", "detach", "(", ")", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "hist_gs", "=", "logits", ".", "detach", "(", ")", ".", "clone", "(", ")", ".", "zero_", "(", ")", ".", "scatter_", "(", "1", ",", "max_value_indexes", ",", "1", ")", "\n", "", "hist_gs_set", "[", ":", ",", "i", ",", ":", "(", "i", "+", "1", ")", "]", "=", "hist_gs", "\n", "\n", "", "return", "hist_gs_set", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.modules.INFER_MODULE.__init__": [[146, 170], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Softmax", "modules.INFER_MODULE.modules", "torch.nn.Dropout", "visdialch.utils.GatedTrans", "torch.nn.Dropout", "torch.nn.Linear", "isinstance", "torch.nn.init.kaiming_uniform_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "INFER_MODULE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "embed", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "GatedTrans", "(", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ")", ",", "\n", ")", "\n", "self", ".", "att", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "2", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "m", ".", "weight", ".", "data", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.modules.INFER_MODULE.forward": [[171, 196], ["ques.size", "ques.size", "modules.INFER_MODULE.embed", "torch.nn.functional.normalize", "modules.INFER_MODULE.att", "modules.INFER_MODULE.view", "ques_logits.view.detach().clone().zero_().scatter_.view", "modules.INFER_MODULE.softmax", "torch.nn.functional.gumbel_softmax", "modules.INFER_MODULE.view.detach().max", "modules.INFER_MODULE.view.detach().clone().zero_().scatter_", "modules.INFER_MODULE.view.detach", "modules.INFER_MODULE.view.detach().clone().zero_", "modules.INFER_MODULE.view.detach().clone", "modules.INFER_MODULE.view.detach"], "methods", ["None"], ["", "", "", "", "def", "forward", "(", "self", ",", "ques", ")", ":", "\n", "# input", "\n", "# ques - shape: (batch_size, num_rounds, word_embedding_size)", "\n", "# output", "\n", "# ques_gs - shape: (batch_size, num_rounds, 2)", "\n", "# Lambda - shape: (batch_size, num_rounds, 2)", "\n", "\n", "        ", "batch_size", "=", "ques", ".", "size", "(", "0", ")", "\n", "num_rounds", "=", "ques", ".", "size", "(", "1", ")", "\n", "\n", "ques_embed", "=", "self", ".", "embed", "(", "ques", ")", "# shape: (batch_size, num_rounds, quen_len_max, lstm_hidden_size)", "\n", "ques_embed", "=", "F", ".", "normalize", "(", "ques_embed", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "# shape: (batch_size, num_rounds, quen_len_max, lstm_hidden_size) ", "\n", "ques_logits", "=", "self", ".", "att", "(", "ques_embed", ")", "# shape: (batch_size, num_rounds, 2)", "\n", "\n", "logits", "=", "ques_logits", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "ques_gs", "=", "F", ".", "gumbel_softmax", "(", "logits", ",", "hard", "=", "True", ")", "# shape: (batch_size, i+1)", "\n", "", "else", ":", "\n", "            ", "_", ",", "max_value_indexes", "=", "logits", ".", "detach", "(", ")", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "ques_gs", "=", "logits", ".", "detach", "(", ")", ".", "clone", "(", ")", ".", "zero_", "(", ")", ".", "scatter_", "(", "1", ",", "max_value_indexes", ",", "1", ")", "\n", "", "ques_gs", "=", "ques_gs", ".", "view", "(", "-", "1", ",", "num_rounds", ",", "2", ")", "\n", "\n", "Lambda", "=", "self", ".", "softmax", "(", "ques_logits", ")", "\n", "\n", "return", "ques_gs", ",", "Lambda", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.modules.RvA_MODULE.__init__": [[199, 205], ["torch.nn.Module.__init__", "modules.INFER_MODULE", "modules.PAIR_MODULE", "modules.ATT_MODULE"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RvA_MODULE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "INFER_MODULE", "=", "INFER_MODULE", "(", "config", ")", "\n", "self", ".", "PAIR_MODULE", "=", "PAIR_MODULE", "(", "config", ")", "\n", "self", ".", "ATT_MODULE", "=", "ATT_MODULE", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.modules.RvA_MODULE.forward": [[206, 248], ["ques_feat.size", "ques_feat.size", "img.size", "modules.RvA_MODULE.INFER_MODULE", "modules.RvA_MODULE.PAIR_MODULE", "modules.RvA_MODULE.ATT_MODULE", "modules.RvA_MODULE.ATT_MODULE", "torch.Tensor().view().repeat", "ques_prob_single.cuda.cuda.cuda", "modules.RvA_MODULE.data.clone().zero_", "range", "torch.cat", "torch.cat", "ques_prob.view.view.view", "torch.bmm().view", "torch.bmm().view", "torch.Tensor().view", "modules.RvA_MODULE.data.clone", "modules.RvA_MODULE.view", "torch.cat", "torch.sum", "modules.RvA_MODULE.size", "img_att_ques[].unsqueeze", "torch.sum.unsqueeze", "torch.bmm", "torch.bmm", "torch.Tensor", "hist_gs.unsqueeze", "ques_gs[].view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "img", ",", "ques", ",", "hist", ")", ":", "\n", "# img shape: [batch_size, num_proposals, i_dim]", "\n", "# img_att_ques shape: [batch_size, num_rounds, num_proposals]", "\n", "# img_att_cap shape: [batch_size, 1, num_proposals]", "\n", "# ques_gs shape: [batch_size, num_rounds, 2]", "\n", "# hist_logits shape: [batch_size, num_rounds, num_rounds]", "\n", "# ques_gs_prob shape: [batch_size, num_rounds, 2]", "\n", "\n", "        ", "cap_feat", ",", "ques_feat", ",", "ques_encoded", "=", "ques", "\n", "\n", "batch_size", "=", "ques_feat", ".", "size", "(", "0", ")", "\n", "num_rounds", "=", "ques_feat", ".", "size", "(", "1", ")", "\n", "num_proposals", "=", "img", ".", "size", "(", "1", ")", "\n", "\n", "ques_gs", ",", "ques_gs_prob", "=", "self", ".", "INFER_MODULE", "(", "ques_feat", ")", "# (batch_size, num_rounds, 2)", "\n", "hist_gs_set", "=", "self", ".", "PAIR_MODULE", "(", "hist", ",", "ques_encoded", ")", "\n", "img_att_ques", "=", "self", ".", "ATT_MODULE", "(", "img", ",", "ques_feat", ")", "\n", "img_att_cap", "=", "self", ".", "ATT_MODULE", "(", "img", ",", "cap_feat", ")", "\n", "\n", "# soft", "\n", "ques_prob_single", "=", "torch", ".", "Tensor", "(", "data", "=", "[", "1", ",", "0", "]", ")", ".", "view", "(", "1", ",", "-", "1", ")", ".", "repeat", "(", "batch_size", ",", "1", ")", "# shape: [batch_size, 2]", "\n", "ques_prob_single", "=", "ques_prob_single", ".", "cuda", "(", ")", "\n", "ques_prob_single", ".", "requires_grad", "=", "False", "\n", "\n", "img_att_refined", "=", "img_att_ques", ".", "data", ".", "clone", "(", ")", ".", "zero_", "(", ")", "# shape: [batch_size, num_rounds, num_proposals]", "\n", "for", "i", "in", "range", "(", "num_rounds", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "img_att_temp", "=", "img_att_cap", ".", "view", "(", "-", "1", ",", "img_att_cap", ".", "size", "(", "-", "1", ")", ")", "# shape: [batch_size, num_proposals]", "\n", "", "else", ":", "\n", "                ", "hist_gs", "=", "hist_gs_set", "[", ":", ",", "i", ",", ":", "(", "i", "+", "1", ")", "]", "# shape: [batch_size, i+1]            ", "\n", "img_att_temp", "=", "torch", ".", "cat", "(", "(", "img_att_cap", ",", "img_att_refined", "[", ":", ",", ":", "i", ",", ":", "]", ")", ",", "dim", "=", "1", ")", "# shape: [batch_size, i+1, num_proposals]", "\n", "img_att_temp", "=", "torch", ".", "sum", "(", "hist_gs", ".", "unsqueeze", "(", "-", "1", ")", "*", "img_att_temp", ",", "dim", "=", "-", "2", ")", "# shape: [batch_size, num_proposals]", "\n", "", "img_att_cat", "=", "torch", ".", "cat", "(", "(", "img_att_ques", "[", ":", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ",", "img_att_temp", ".", "unsqueeze", "(", "1", ")", ")", ",", "dim", "=", "1", ")", "# shape: [batch_size ,2, num_proposals]", "\n", "# soft", "\n", "ques_prob_pair", "=", "ques_gs_prob", "[", ":", ",", "i", ",", ":", "]", "\n", "ques_prob", "=", "torch", ".", "cat", "(", "(", "ques_prob_single", ",", "ques_prob_pair", ")", ",", "dim", "=", "-", "1", ")", "# shape: [batch_size, 2]", "\n", "ques_prob", "=", "ques_prob", ".", "view", "(", "-", "1", ",", "2", ",", "2", ")", "# shape: [batch_size, 2, 2]", "\n", "ques_prob_refine", "=", "torch", ".", "bmm", "(", "ques_gs", "[", ":", ",", "i", ",", ":", "]", ".", "view", "(", "-", "1", ",", "1", ",", "2", ")", ",", "ques_prob", ")", ".", "view", "(", "-", "1", ",", "1", ",", "2", ")", "# shape: [batch_size, num_rounds, 2]", "\n", "\n", "img_att_refined", "[", ":", ",", "i", ",", ":", "]", "=", "torch", ".", "bmm", "(", "ques_prob_refine", ",", "img_att_cat", ")", ".", "view", "(", "-", "1", ",", "num_proposals", ")", "# shape: [batch_size, num_proposals]", "\n", "\n", "", "return", "img_att_refined", ",", "(", "ques_gs", ",", "hist_gs_set", ",", "img_att_ques", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__": [[10, 68], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.LSTM", "torch.nn.LSTM", "visdialch.utils.DynamicRNN", "visdialch.utils.DynamicRNN", "visdialch.utils.Q_ATT", "visdialch.utils.Q_ATT", "visdialch.utils.H_ATT", "modules.RvA_MODULE", "visdialch.utils.V_Filter", "torch.nn.Sequential", "torch.nn.Softmax", "rva.RvAEncoder.modules", "len", "torch.nn.Dropout", "torch.nn.Linear", "isinstance", "torch.nn.init.kaiming_uniform", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "vocabulary", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "word_embed", "=", "nn", ".", "Embedding", "(", "\n", "len", "(", "vocabulary", ")", ",", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "padding_idx", "=", "vocabulary", ".", "PAD_INDEX", "\n", ")", "\n", "\n", "self", ".", "hist_rnn", "=", "nn", ".", "LSTM", "(", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "config", "[", "\"lstm_num_layers\"", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", "dropout", "=", "config", "[", "\"dropout\"", "]", ",", "\n", "bidirectional", "=", "True", "\n", ")", "\n", "self", ".", "ques_rnn", "=", "nn", ".", "LSTM", "(", "\n", "config", "[", "\"word_embedding_size\"", "]", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", ",", "\n", "config", "[", "\"lstm_num_layers\"", "]", ",", "\n", "batch_first", "=", "True", ",", "\n", "dropout", "=", "config", "[", "\"dropout\"", "]", ",", "\n", "bidirectional", "=", "True", "\n", ")", "\n", "# questions and history are right padded sequences of variable length", "\n", "# use the DynamicRNN utility module to handle them properly", "\n", "self", ".", "hist_rnn", "=", "DynamicRNN", "(", "self", ".", "hist_rnn", ")", "\n", "self", ".", "ques_rnn", "=", "DynamicRNN", "(", "self", ".", "ques_rnn", ")", "\n", "\n", "# self attention for question", "\n", "self", ".", "Q_ATT_ans", "=", "Q_ATT", "(", "config", ")", "\n", "self", ".", "Q_ATT_ref", "=", "Q_ATT", "(", "config", ")", "\n", "# question-based history attention", "\n", "self", ".", "H_ATT_ans", "=", "H_ATT", "(", "config", ")", "\n", "\n", "# modules", "\n", "self", ".", "RvA_MODULE", "=", "RvA_MODULE", "(", "config", ")", "\n", "self", ".", "V_Filter", "=", "V_Filter", "(", "config", ")", "\n", "\n", "# fusion layer", "\n", "self", ".", "fusion", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "config", "[", "\"dropout_fc\"", "]", ")", ",", "\n", "nn", ".", "Linear", "(", "\n", "config", "[", "\"img_feature_size\"", "]", "+", "config", "[", "\"word_embedding_size\"", "]", "+", "config", "[", "\"lstm_hidden_size\"", "]", "*", "2", ",", "\n", "config", "[", "\"lstm_hidden_size\"", "]", "\n", ")", "\n", ")", "\n", "# other useful functions", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "# initialization", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_uniform", "(", "m", ".", "weight", ".", "data", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ".", "data", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.forward": [[69, 121], ["batch[].size", "batch[].size", "rva.RvAEncoder.init_q_embed", "rva.RvAEncoder.init_h_embed", "rva.RvAEncoder.init_cap_embed", "rva.RvAEncoder.Q_ATT_ref", "rva.RvAEncoder.Q_ATT_ref", "rva.RvAEncoder.RvA_MODULE", "torch.bmm", "rva.RvAEncoder.H_ATT_ans", "rva.RvAEncoder.Q_ATT_ans", "rva.RvAEncoder.V_Filter", "torch.cat", "torch.tanh", "rva.RvAEncoder.fusion"], "methods", ["home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.init_q_embed", "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.init_h_embed", "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.init_cap_embed"], ["", "", "", "", "def", "forward", "(", "self", ",", "batch", ",", "return_att", "=", "False", ")", ":", "\n", "# img - shape: (batch_size, num_proposals, img_feature_size) - RCNN bottom-up features", "\n", "        ", "img", "=", "batch", "[", "\"img_feat\"", "]", "\n", "batch_size", "=", "batch", "[", "\"ques\"", "]", ".", "size", "(", "0", ")", "\n", "num_rounds", "=", "batch", "[", "\"ques\"", "]", ".", "size", "(", "1", ")", "\n", "\n", "# init language embedding", "\n", "# ques_word_embed - shape: (batch_size, num_rounds, quen_len_max, word_embedding_size)", "\n", "# ques_word_encoded - shape: (batch_size, num_rounds, quen_len_max, lstm_hidden_size)", "\n", "# ques_not_pad - shape: (batch_size, num_rounds, quen_len_max)", "\n", "# ques_encoded - shape: (batch_size, num_rounds, lstm_hidden_size)", "\n", "ques_word_embed", ",", "ques_word_encoded", ",", "ques_not_pad", ",", "ques_encoded", "=", "self", ".", "init_q_embed", "(", "batch", ")", "\n", "# hist_word_embed - shape: (batch_size, num_rounds, quen_len_max, word_embedding_size)", "\n", "# hist_encoded - shape: (batch_size, num_rounds, lstm_hidden_size)", "\n", "hist_word_embed", ",", "hist_encoded", "=", "self", ".", "init_h_embed", "(", "batch", ")", "\n", "# cap_word_embed - shape: (batch_size, num_rounds, quen_len_max, word_embedding_size)", "\n", "# cap_word_encoded - shape: (batch_size, num_rounds, quen_len_max, lstm_hidden_size)", "\n", "# cap_not_pad - shape: (batch_size, num_rounds, quen_len_max)", "\n", "cap_word_embed", ",", "cap_word_encoded", ",", "cap_not_pad", "=", "self", ".", "init_cap_embed", "(", "batch", ")", "\n", "\n", "# question feature for RvA", "\n", "# ques_ref_feat - shape: (batch_size, num_rounds, lstm_hidden_size)", "\n", "# ques_ref_att - shape: (batch_size, num_rounds, quen_len_max)", "\n", "ques_ref_feat", ",", "ques_ref_att", "=", "self", ".", "Q_ATT_ref", "(", "ques_word_embed", ",", "ques_word_encoded", ",", "ques_not_pad", ")", "\n", "# cap_ref_feat - shape: (batch_size, num_rounds, lstm_hidden_size)", "\n", "cap_ref_feat", ",", "_", "=", "self", ".", "Q_ATT_ref", "(", "cap_word_embed", ",", "cap_word_encoded", ",", "cap_not_pad", ")", "\n", "\n", "# RvA module", "\n", "ques_feat", "=", "(", "cap_ref_feat", ",", "ques_ref_feat", ",", "ques_encoded", ")", "\n", "# img_att - shape: (batch_size, num_rounds, num_proposals)", "\n", "img_att", ",", "att_set", "=", "self", ".", "RvA_MODULE", "(", "img", ",", "ques_feat", ",", "hist_encoded", ")", "\n", "# img_feat - shape: (batch_size, num_rounds, img_feature_size)", "\n", "img_feat", "=", "torch", ".", "bmm", "(", "img_att", ",", "img", ")", "\n", "\n", "# ans_feat for joint embedding", "\n", "# hist_ans_feat - shape: (batch_size, num_rounds, lstm_hidden_size*2)", "\n", "hist_ans_feat", "=", "self", ".", "H_ATT_ans", "(", "hist_encoded", ",", "ques_encoded", ")", "\n", "# ques_ans_feat - shape: (batch_size, num_rounds, word_embedding_size)", "\n", "# ques_ans_att - shape: (batch_size, num_rounds, quen_len_max)", "\n", "ques_ans_feat", ",", "ques_ans_att", "=", "self", ".", "Q_ATT_ans", "(", "ques_word_embed", ",", "ques_word_encoded", ",", "ques_not_pad", ")", "\n", "# img_ans_feat - shape: (batch_size, num_rounds, img_feature_size)", "\n", "img_ans_feat", "=", "self", ".", "V_Filter", "(", "img_feat", ",", "ques_ans_feat", ")", "\n", "\n", "# joint embedding", "\n", "fused_vector", "=", "torch", ".", "cat", "(", "(", "img_ans_feat", ",", "ques_ans_feat", ",", "hist_ans_feat", ")", ",", "-", "1", ")", "\n", "# img_ans_feat - shape: (batch_size, num_rounds, lstm_hidden_size)", "\n", "fused_embedding", "=", "torch", ".", "tanh", "(", "self", ".", "fusion", "(", "fused_vector", ")", ")", "\n", "\n", "if", "return_att", ":", "\n", "            ", "return", "fused_embedding", ",", "att_set", "+", "(", "ques_ref_att", ",", "ques_ans_att", ")", "\n", "", "else", ":", "\n", "            ", "return", "fused_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.init_q_embed": [[122, 142], ["ques.view.view.size", "ques.view.view.view", "rva.RvAEncoder.word_embed", "rva.RvAEncoder.ques_rnn", "ques_word_encoded.view.view.size", "torch.cat", "ques_encoded.view.view.view", "ques_word_encoded.view.view.view", "ques_word_embed.view.view.view", "ques.view.view.size", "batch[].view().cpu().numpy", "ques_encoded.view.view.size", "ques_word_encoded.view.view.size", "ques_word_embed.view.view.size", "batch[].view().cpu", "range", "batch[].view"], "methods", ["None"], ["", "", "def", "init_q_embed", "(", "self", ",", "batch", ")", ":", "\n", "        ", "ques", "=", "batch", "[", "\"ques\"", "]", "# shape: (batch_size, num_rounds, quen_len_max)", "\n", "batch_size", ",", "num_rounds", ",", "_", "=", "ques", ".", "size", "(", ")", "\n", "lstm_hidden_size", "=", "self", ".", "config", "[", "\"lstm_hidden_size\"", "]", "\n", "\n", "# question feature", "\n", "ques_not_pad", "=", "(", "ques", "!=", "0", ")", ".", "float", "(", ")", "# shape: (batch_size, num_rounds, quen_len_max)", "\n", "ques", "=", "ques", ".", "view", "(", "-", "1", ",", "ques", ".", "size", "(", "-", "1", ")", ")", "# shape: (batch_size*num_rounds, quen_len_max)", "\n", "ques_word_embed", "=", "self", ".", "word_embed", "(", "ques", ")", "# shape: (batch_size*num_rounds, quen_len_max, lstm_hidden_size)", "\n", "ques_word_encoded", ",", "_", "=", "self", ".", "ques_rnn", "(", "ques_word_embed", ",", "batch", "[", "'ques_len'", "]", ")", "# shape: (batch_size*num_rounds, quen_len_max, lstm_hidden_size*2)", "\n", "quen_len_max", "=", "ques_word_encoded", ".", "size", "(", "1", ")", "\n", "loc", "=", "batch", "[", "'ques_len'", "]", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "-", "1", "\n", "ques_encoded_forawrd", "=", "ques_word_encoded", "[", "range", "(", "num_rounds", "*", "batch_size", ")", ",", "loc", ",", ":", "lstm_hidden_size", "]", "# shape: (batch_size*num_rounds, lstm_hidden_size) ", "\n", "ques_encoded_backward", "=", "ques_word_encoded", "[", ":", ",", "0", ",", "lstm_hidden_size", ":", "]", "# shape: (batch_size*num_rounds, lstm_hidden_size) ", "\n", "ques_encoded", "=", "torch", ".", "cat", "(", "(", "ques_encoded_forawrd", ",", "ques_encoded_backward", ")", ",", "dim", "=", "-", "1", ")", "\n", "ques_encoded", "=", "ques_encoded", ".", "view", "(", "-", "1", ",", "num_rounds", ",", "ques_encoded", ".", "size", "(", "-", "1", ")", ")", "# shape: (batch_size, num_rounds, lstm_hidden_size*2)", "\n", "ques_word_encoded", "=", "ques_word_encoded", ".", "view", "(", "-", "1", ",", "num_rounds", ",", "quen_len_max", ",", "ques_word_encoded", ".", "size", "(", "-", "1", ")", ")", "# shape: (batch_size, num_rounds, quen_len_max, lstm_hidden_size)", "\n", "ques_word_embed", "=", "ques_word_embed", ".", "view", "(", "-", "1", ",", "num_rounds", ",", "quen_len_max", ",", "ques_word_embed", ".", "size", "(", "-", "1", ")", ")", "# shape: (batch_size, num_rounds, quen_len_max, word_embedding_size)", "\n", "\n", "return", "ques_word_embed", ",", "ques_word_encoded", ",", "ques_not_pad", ",", "ques_encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.init_h_embed": [[143, 158], ["hist.view.view.size", "hist.view.view.view", "rva.RvAEncoder.word_embed", "rva.RvAEncoder.hist_rnn", "torch.cat", "hist_encoded.view.view.view", "hist.view.view.size", "batch[].view().cpu().numpy", "hist_encoded.view.view.size", "batch[].view().cpu", "range", "batch[].view"], "methods", ["None"], ["", "def", "init_h_embed", "(", "self", ",", "batch", ")", ":", "\n", "        ", "hist", "=", "batch", "[", "\"hist\"", "]", "# shape: (batch_size, num_rounds, hist_len_max)", "\n", "batch_size", ",", "num_rounds", ",", "_", "=", "hist", ".", "size", "(", ")", "\n", "lstm_hidden_size", "=", "self", ".", "config", "[", "\"lstm_hidden_size\"", "]", "\n", "\n", "hist", "=", "hist", ".", "view", "(", "-", "1", ",", "hist", ".", "size", "(", "-", "1", ")", ")", "# shape: (batch_size*num_rounds, hist_len_max)", "\n", "hist_word_embed", "=", "self", ".", "word_embed", "(", "hist", ")", "# shape: (batch_size*num_rounds, hist_len_max, word_embedding_size)", "\n", "hist_word_encoded", ",", "_", "=", "self", ".", "hist_rnn", "(", "hist_word_embed", ",", "batch", "[", "'hist_len'", "]", ")", "# shape: (batch_size*num_rounds, hist_len_max, lstm_hidden_size*2)", "\n", "loc", "=", "batch", "[", "'hist_len'", "]", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "-", "1", "\n", "hist_encoded_forward", "=", "hist_word_encoded", "[", "range", "(", "num_rounds", "*", "batch_size", ")", ",", "loc", ",", ":", "lstm_hidden_size", "]", "# shape: (batch_size*num_rounds, hist_len_max, lstm_hidden_size*2) ", "\n", "hist_encoded_backward", "=", "hist_word_encoded", "[", ":", ",", "0", ",", "lstm_hidden_size", ":", "]", "# shape: (batch_size*num_rounds, lstm_hidden_size) ", "\n", "hist_encoded", "=", "torch", ".", "cat", "(", "(", "hist_encoded_forward", ",", "hist_encoded_backward", ")", ",", "dim", "=", "-", "1", ")", "\n", "hist_encoded", "=", "hist_encoded", ".", "view", "(", "-", "1", ",", "num_rounds", ",", "hist_encoded", ".", "size", "(", "-", "1", ")", ")", "# shape: (batch_size, num_rounds, lstm_hidden_size)", "\n", "\n", "return", "hist_word_embed", ",", "hist_encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.rva.RvAEncoder.init_cap_embed": [[159, 171], ["rva.RvAEncoder.word_embed", "rva.RvAEncoder.ques_rnn", "cap_word_encoded.unsqueeze.unsqueeze.unsqueeze", "cap_word_embed.unsqueeze.unsqueeze.unsqueeze", "cap.squeeze"], "methods", ["None"], ["", "def", "init_cap_embed", "(", "self", ",", "batch", ")", ":", "\n", "        ", "cap", "=", "batch", "[", "\"hist\"", "]", "[", ":", ",", ":", "1", ",", ":", "]", "# shape: (batch_size, 1, hist_len_max)", "\n", "\n", "# caption feature like question", "\n", "cap_not_pad", "=", "(", "cap", "!=", "0", ")", ".", "float", "(", ")", "# shape: (batch_size, 1, hist_len_max)", "\n", "cap_word_embed", "=", "self", ".", "word_embed", "(", "cap", ".", "squeeze", "(", "1", ")", ")", "# shape: (batch_size*1, hist_len_max, lstm_hidden_size)", "\n", "cap_len", "=", "batch", "[", "'hist_len'", "]", "[", ":", ",", ":", "1", "]", "\n", "cap_word_encoded", ",", "_", "=", "self", ".", "ques_rnn", "(", "cap_word_embed", ",", "cap_len", ")", "# shape: (batch_size*1, hist_len_max, lstm_hidden_size)", "\n", "cap_word_encoded", "=", "cap_word_encoded", ".", "unsqueeze", "(", "1", ")", "# shape: (batch_size, 1, hist_len_max, lstm_hidden_size)", "\n", "cap_word_embed", "=", "cap_word_embed", ".", "unsqueeze", "(", "1", ")", "# shape: (batch_size, 1, hist_len_max, lstm_hidden_size)", "\n", "\n", "return", "cap_word_embed", ",", "cap_word_encoded", ",", "cap_not_pad", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yuleiniu_rva.encoders.__init__.Encoder": [[5, 11], ["None"], "function", ["None"], []]}