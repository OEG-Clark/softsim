{"home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.None.train.create_optimizer": [[12, 23], ["torch.optim.SGD", "net_rgbdepth.parameters", "net_audiodepth.parameters", "net_attention.parameters", "net_material.parameters", "torch.optim.Adam"], "function", ["None"], ["def", "create_optimizer", "(", "nets", ",", "opt", ")", ":", "\n", "\t", "(", "net_visualdepth", ",", "net_audiodepth", ",", "net_attention", ",", "net_material", ")", "=", "nets", "\n", "param_groups", "=", "[", "{", "'params'", ":", "net_rgbdepth", ".", "parameters", "(", ")", ",", "'lr'", ":", "opt", ".", "lr_visual", "}", ",", "\n", "{", "'params'", ":", "net_audiodepth", ".", "parameters", "(", ")", ",", "'lr'", ":", "opt", ".", "lr_audio", "}", ",", "\n", "{", "'params'", ":", "net_attention", ".", "parameters", "(", ")", ",", "'lr'", ":", "opt", ".", "lr_attention", "}", ",", "\n", "{", "'params'", ":", "net_material", ".", "parameters", "(", ")", ",", "'lr'", ":", "opt", ".", "lr_material", "}", "\n", "]", "\n", "if", "opt", ".", "optimizer", "==", "'sgd'", ":", "\n", "\t\t", "return", "torch", ".", "optim", ".", "SGD", "(", "param_groups", ",", "momentum", "=", "opt", ".", "beta1", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "", "elif", "opt", ".", "optimizer", "==", "'adam'", ":", "\n", "\t\t", "return", "torch", ".", "optim", ".", "Adam", "(", "param_groups", ",", "betas", "=", "(", "opt", ".", "beta1", ",", "0.999", ")", ",", "weight_decay", "=", "opt", ".", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.None.train.decrease_learning_rate": [[24, 27], ["None"], "function", ["None"], ["", "", "def", "decrease_learning_rate", "(", "optimizer", ",", "decay_factor", "=", "0.94", ")", ":", "\n", "    ", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "*=", "decay_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.None.train.evaluate": [[28, 51], ["numpy.array().mean", "print", "torch.no_grad", "enumerate", "sum", "len", "model.forward", "loss_criterion", "losses.append", "range", "numpy.array", "loss_criterion.item", "errors.append", "util.util.compute_errors", "depth_gt[].cpu().numpy", "depth_predicted[].cpu().numpy", "depth_gt[].cpu", "depth_predicted[].cpu"], "function", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.BaseLoss.forward", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.util.util.compute_errors"], ["", "", "def", "evaluate", "(", "model", ",", "loss_criterion", ",", "dataset_val", ",", "opt", ")", ":", "\n", "\t", "losses", "=", "[", "]", "\n", "errors", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t", "for", "i", ",", "val_data", "in", "enumerate", "(", "dataset_val", ")", ":", "\n", "\t\t\t", "output", "=", "model", ".", "forward", "(", "val_data", ")", "\n", "depth_predicted", "=", "output", "[", "'depth_predicted'", "]", "\n", "depth_gt", "=", "output", "[", "'depth_gt'", "]", "\n", "loss", "=", "loss_criterion", "(", "depth_predicted", "[", "depth_gt", "!=", "0", "]", ",", "depth_gt", "[", "depth_gt", "!=", "0", "]", ")", "\n", "losses", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "for", "idx", "in", "range", "(", "depth_predicted", ".", "shape", "[", "0", "]", ")", ":", "\n", "\t\t\t\t", "errors", ".", "append", "(", "compute_errors", "(", "depth_gt", "[", "idx", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "depth_predicted", "[", "idx", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "", "", "", "mean_loss", "=", "sum", "(", "losses", ")", "/", "len", "(", "losses", ")", "\n", "mean_errors", "=", "np", ".", "array", "(", "errors", ")", ".", "mean", "(", "0", ")", "\n", "print", "(", "'Loss: {:.3f}, RMSE: {:.3f}'", ".", "format", "(", "mean_loss", ",", "mean_errors", "[", "1", "]", ")", ")", "\n", "val_errors", "=", "{", "}", "\n", "val_errors", "[", "'ABS_REL'", "]", ",", "val_errors", "[", "'RMSE'", "]", "=", "mean_errors", "[", "0", "]", ",", "mean_errors", "[", "1", "]", "\n", "val_errors", "[", "'DELTA1'", "]", "=", "mean_errors", "[", "2", "]", "\n", "val_errors", "[", "'DELTA2'", "]", "=", "mean_errors", "[", "3", "]", "\n", "val_errors", "[", "'DELTA3'", "]", "=", "mean_errors", "[", "4", "]", "\n", "return", "mean_loss", ",", "val_errors", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.util.util.TextWrite.__init__": [[44, 49], ["open", "util.TextWrite.file.close"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "filename", ")", ":", "\n", "        ", "self", ".", "filename", "=", "filename", "\n", "self", ".", "file", "=", "open", "(", "self", ".", "filename", ",", "\"w+\"", ")", "\n", "self", ".", "file", ".", "close", "(", ")", "\n", "self", ".", "str_write", "=", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.util.util.TextWrite.add_line_csv": [[50, 61], ["isinstance", "isinstance", "isinstance", "str_tmp.append", "str_tmp.append", "str_tmp.append"], "methods", ["None"], ["", "def", "add_line_csv", "(", "self", ",", "data_list", ")", ":", "\n", "        ", "str_tmp", "=", "[", "]", "\n", "for", "item", "in", "data_list", ":", "\n", "            ", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "                ", "str_tmp", ".", "append", "(", "\"{:03d}\"", ".", "format", "(", "item", ")", ")", "\n", "", "if", "isinstance", "(", "item", ",", "str", ")", ":", "\n", "                ", "str_tmp", ".", "append", "(", "item", ")", "\n", "", "if", "isinstance", "(", "item", ",", "float", ")", ":", "\n", "                ", "str_tmp", ".", "append", "(", "\"{:.6f}\"", ".", "format", "(", "item", ")", ")", "\n", "\n", "", "", "self", ".", "str_write", "=", "\",\"", ".", "join", "(", "str_tmp", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.util.util.TextWrite.add_line_txt": [[62, 70], ["list", "list", "range", "map", "map", "len", "x.center", "x.rjust"], "methods", ["None"], ["", "def", "add_line_txt", "(", "self", ",", "content", ",", "size", "=", "None", ",", "maxLength", "=", "10", ",", "heading", "=", "False", ")", ":", "\n", "        ", "if", "size", "==", "None", ":", "\n", "            ", "size", "=", "[", "1", "for", "i", "in", "range", "(", "len", "(", "content", ")", ")", "]", "\n", "", "if", "heading", ":", "\n", "            ", "str_tmp", "=", "'|'", ".", "join", "(", "list", "(", "map", "(", "lambda", "x", ",", "s", ":", "x", ".", "center", "(", "(", "s", "*", "maxLength", ")", "+", "(", "s", "-", "1", ")", ")", ",", "content", ",", "size", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "str_tmp", "=", "'|'", ".", "join", "(", "list", "(", "map", "(", "lambda", "x", ",", "s", ":", "x", ".", "rjust", "(", "(", "s", "*", "maxLength", ")", "+", "(", "s", "-", "1", ")", ")", ",", "content", ",", "size", ")", ")", ")", "\n", "", "self", ".", "str_write", "+=", "str_tmp", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.util.util.TextWrite.write_line": [[71, 76], ["open", "util.TextWrite.file.write", "util.TextWrite.file.close"], "methods", ["None"], ["", "def", "write_line", "(", "self", ")", ":", "\n", "        ", "self", ".", "file", "=", "open", "(", "self", ".", "filename", ",", "\"a\"", ")", "\n", "self", ".", "file", ".", "write", "(", "self", ".", "str_write", ")", "\n", "self", ".", "file", ".", "close", "(", ")", "\n", "self", ".", "str_write", "=", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.util.util.compute_errors": [[5, 40], ["numpy.maximum", "numpy.sqrt", "numpy.mean", "numpy.abs().mean", "numpy.abs().mean", "np.sqrt.mean", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.log10", "numpy.log10"], "function", ["None"], ["def", "compute_errors", "(", "gt", ",", "pred", ")", ":", "\n", "    ", "\"\"\"Computation of error metrics between predicted and ground truth depths\n    \"\"\"", "\n", "# select only the values that are greater than zero", "\n", "mask", "=", "gt", ">", "0", "\n", "pred", "=", "pred", "[", "mask", "]", "\n", "gt", "=", "gt", "[", "mask", "]", "\n", "\n", "thresh", "=", "np", ".", "maximum", "(", "(", "gt", "/", "pred", ")", ",", "(", "pred", "/", "gt", ")", ")", "\n", "a1", "=", "(", "thresh", "<", "1.25", ")", ".", "mean", "(", ")", "\n", "a2", "=", "(", "thresh", "<", "1.25", "**", "2", ")", ".", "mean", "(", ")", "\n", "a3", "=", "(", "thresh", "<", "1.25", "**", "3", ")", ".", "mean", "(", ")", "\n", "\n", "rmse", "=", "(", "gt", "-", "pred", ")", "**", "2", "\n", "rmse", "=", "np", ".", "sqrt", "(", "rmse", ".", "mean", "(", ")", ")", "\n", "if", "rmse", "!=", "rmse", ":", "\n", "        ", "rmse", "=", "0.0", "\n", "", "if", "a1", "!=", "a1", ":", "\n", "        ", "a1", "=", "0.0", "\n", "", "if", "a2", "!=", "a2", ":", "\n", "        ", "a2", "=", "0.0", "\n", "", "if", "a3", "!=", "a3", ":", "\n", "        ", "a3", "=", "0.0", "\n", "\n", "", "abs_rel", "=", "np", ".", "mean", "(", "np", ".", "abs", "(", "gt", "-", "pred", ")", "/", "gt", ")", "\n", "log_10", "=", "(", "np", ".", "abs", "(", "np", ".", "log10", "(", "gt", ")", "-", "np", ".", "log10", "(", "pred", ")", ")", ")", ".", "mean", "(", ")", "\n", "mae", "=", "(", "np", ".", "abs", "(", "gt", "-", "pred", ")", ")", ".", "mean", "(", ")", "\n", "if", "abs_rel", "!=", "abs_rel", ":", "\n", "        ", "abs_rel", "=", "0.0", "\n", "", "if", "log_10", "!=", "log_10", ":", "\n", "        ", "log_10", "=", "0.0", "\n", "", "if", "mae", "!=", "mae", ":", "\n", "        ", "mae", "=", "0.0", "\n", "\n", "", "return", "abs_rel", ",", "rmse", ",", "a1", ",", "a2", ",", "a3", ",", "log_10", ",", "mae", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.util.util.mkdirs": [[77, 83], ["isinstance", "util.mkdir", "isinstance", "util.mkdir"], "function", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.util.util.mkdir", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.util.util.mkdir"], ["", "", "def", "mkdirs", "(", "paths", ")", ":", "\n", "    ", "if", "isinstance", "(", "paths", ",", "list", ")", "and", "not", "isinstance", "(", "paths", ",", "str", ")", ":", "\n", "        ", "for", "path", "in", "paths", ":", "\n", "            ", "mkdir", "(", "path", ")", "\n", "", "", "else", ":", "\n", "        ", "mkdir", "(", "paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.util.util.mkdir": [[84, 87], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "", "def", "mkdir", "(", "path", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "path", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.models.ModelBuilder.build_audiodepth": [[10, 17], ["networks.SimpleAudioDepthNet", "networks.SimpleAudioDepthNet.apply", "len", "print", "networks.SimpleAudioDepthNet.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["None"], ["    ", "def", "build_audiodepth", "(", "self", ",", "audio_shape", "=", "[", "2", ",", "257", ",", "121", "]", ",", "weights", "=", "''", ")", ":", "\n", "        ", "net", "=", "SimpleAudioDepthNet", "(", "8", ",", "audio_shape", "=", "audio_shape", ",", "audio_feature_length", "=", "512", ")", "\n", "net", ".", "apply", "(", "weights_init", ")", "\n", "if", "len", "(", "weights", ")", ">", "0", ":", "\n", "            ", "print", "(", "'Loading weights for audio stream'", ")", "\n", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "weights", ")", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.models.ModelBuilder.build_rgbdepth": [[19, 28], ["networks.RGBDepthNet", "networks.RGBDepthNet.apply", "len", "print", "networks.RGBDepthNet.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["None"], ["", "def", "build_rgbdepth", "(", "self", ",", "ngf", "=", "64", ",", "input_nc", "=", "3", ",", "output_nc", "=", "1", ",", "weights", "=", "''", ")", ":", "\n", "\n", "        ", "net", "=", "RGBDepthNet", "(", "ngf", ",", "input_nc", ",", "output_nc", ")", "\n", "\n", "net", ".", "apply", "(", "weights_init", ")", "\n", "if", "len", "(", "weights", ")", ">", "0", ":", "\n", "            ", "print", "(", "'Loading weights for visual stream'", ")", "\n", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "weights", ")", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.models.ModelBuilder.build_attention": [[29, 38], ["networks.attentionNet", "networks.attentionNet.apply", "len", "print", "networks.attentionNet.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["None"], ["", "def", "build_attention", "(", "self", ",", "weights", "=", "''", ")", ":", "\n", "\n", "        ", "net", "=", "attentionNet", "(", "att_out_nc", "=", "512", ",", "input_nc", "=", "2", "*", "512", ")", "\n", "\n", "net", ".", "apply", "(", "weights_init", ")", "\n", "if", "len", "(", "weights", ")", ">", "0", ":", "\n", "            ", "print", "(", "'Loading weights for attention stream'", ")", "\n", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "weights", ")", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.models.ModelBuilder.build_material_property": [[39, 63], ["len", "torchvision.models.resnet18", "networks.MaterialPropertyNet", "collections.OrderedDict", "pre_trained_dict.items", "networks.MaterialPropertyNet.load_state_dict", "print", "torch.Linear", "torch.Linear", "torchvision.models.resnet18", "networks.MaterialPropertyNet", "networks.MaterialPropertyNet.apply", "print", "len", "print", "networks.MaterialPropertyNet.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "collections.OrderedDict.items", "k.split", "networks.MaterialPropertyNet.state_dict"], "methods", ["None"], ["", "def", "build_material_property", "(", "self", ",", "nclass", "=", "10", ",", "weights", "=", "''", ",", "init_weights", "=", "''", ")", ":", "\n", "        ", "if", "len", "(", "init_weights", ")", ">", "0", ":", "\n", "            ", "original_resnet", "=", "torchvision", ".", "models", ".", "resnet18", "(", "pretrained", "=", "True", ")", "\n", "net", "=", "MaterialPropertyNet", "(", "23", ",", "original_resnet", ")", "\n", "pre_trained_dict", "=", "torch", ".", "load", "(", "init_weights", ")", "[", "'state_dict'", "]", "\n", "pre_trained_mod_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "pre_trained_dict", ".", "items", "(", ")", ":", "\n", "                ", "new_key", "=", "'.'", ".", "join", "(", "k", ".", "split", "(", "'.'", ")", "[", "1", ":", "]", ")", "\n", "pre_trained_mod_dict", "[", "new_key", "]", "=", "v", "\n", "", "pre_trained_mod_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "pre_trained_mod_dict", ".", "items", "(", ")", "if", "k", "in", "net", ".", "state_dict", "(", ")", "}", "\n", "net", ".", "load_state_dict", "(", "pre_trained_mod_dict", ",", "strict", "=", "False", ")", "\n", "\n", "print", "(", "'Initial Material Property Net Loaded'", ")", "\n", "net", ".", "fc", "=", "nn", ".", "Linear", "(", "512", ",", "nclass", ")", "\n", "", "else", ":", "\n", "            ", "original_resnet", "=", "torchvision", ".", "models", ".", "resnet18", "(", "pretrained", "=", "False", ")", "\n", "net", "=", "MaterialPropertyNet", "(", "nclass", ",", "original_resnet", ")", "\n", "net", ".", "apply", "(", "weights_init", ")", "\n", "print", "(", "'Moaterial Propert Net loaded'", ")", "\n", "\n", "", "if", "len", "(", "weights", ")", ">", "0", ":", "\n", "            ", "print", "(", "'Loading weights for material property stream'", ")", "\n", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "weights", ")", ")", "\n", "", "return", "net", "\n", "", "", ""]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.SimpleAudioDepthNet.__init__": [[46, 80], ["torch.Module.__init__", "numpy.array", "zip", "networks.create_conv", "networks.create_conv", "networks.create_conv", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.create_conv", "networks.unet_upconv", "networks.unet_upconv", "networks.unet_upconv", "networks.unet_upconv", "networks.unet_upconv", "networks.unet_upconv", "networks.unet_upconv", "networks.SimpleAudioDepthNet._conv_output_dim", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.create_conv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.create_conv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.create_conv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.create_conv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.SimpleAudioDepthNet._conv_output_dim"], ["def", "__init__", "(", "self", ",", "conv1x1_dim", ",", "audio_shape", ",", "audio_feature_length", ",", "output_nc", "=", "1", ")", ":", "\n", "        ", "super", "(", "SimpleAudioDepthNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_n_input_audio", "=", "audio_shape", "[", "0", "]", "\n", "# kernel size for different CNN layers", "\n", "self", ".", "_cnn_layers_kernel_size", "=", "[", "(", "8", ",", "8", ")", ",", "(", "4", ",", "4", ")", ",", "(", "3", ",", "3", ")", "]", "\n", "# strides for different CNN layers", "\n", "self", ".", "_cnn_layers_stride", "=", "[", "(", "4", ",", "4", ")", ",", "(", "2", ",", "2", ")", ",", "(", "1", ",", "1", ")", "]", "\n", "cnn_dims", "=", "np", ".", "array", "(", "audio_shape", "[", "1", ":", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "kernel_size", ",", "stride", "in", "zip", "(", "\n", "self", ".", "_cnn_layers_kernel_size", ",", "self", ".", "_cnn_layers_stride", "\n", ")", ":", "\n", "            ", "cnn_dims", "=", "self", ".", "_conv_output_dim", "(", "\n", "dimension", "=", "cnn_dims", ",", "\n", "padding", "=", "np", ".", "array", "(", "[", "0", ",", "0", "]", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "dilation", "=", "np", ".", "array", "(", "[", "1", ",", "1", "]", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "kernel_size", "=", "np", ".", "array", "(", "kernel_size", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", "stride", "=", "np", ".", "array", "(", "stride", ",", "dtype", "=", "np", ".", "float32", ")", ",", "\n", ")", "\n", "\n", "", "self", ".", "conv1", "=", "create_conv", "(", "self", ".", "_n_input_audio", ",", "32", ",", "kernel", "=", "self", ".", "_cnn_layers_kernel_size", "[", "0", "]", ",", "paddings", "=", "0", ",", "stride", "=", "self", ".", "_cnn_layers_stride", "[", "0", "]", ")", "\n", "self", ".", "conv2", "=", "create_conv", "(", "32", ",", "64", ",", "kernel", "=", "self", ".", "_cnn_layers_kernel_size", "[", "1", "]", ",", "paddings", "=", "0", ",", "stride", "=", "self", ".", "_cnn_layers_stride", "[", "1", "]", ")", "\n", "self", ".", "conv3", "=", "create_conv", "(", "64", ",", "conv1x1_dim", ",", "kernel", "=", "self", ".", "_cnn_layers_kernel_size", "[", "2", "]", ",", "paddings", "=", "0", ",", "stride", "=", "self", ".", "_cnn_layers_stride", "[", "2", "]", ")", "\n", "layers", "=", "[", "self", ".", "conv1", ",", "self", ".", "conv2", ",", "self", ".", "conv3", "]", "\n", "self", ".", "feature_extraction", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "conv1x1", "=", "create_conv", "(", "conv1x1_dim", "*", "cnn_dims", "[", "0", "]", "*", "cnn_dims", "[", "1", "]", ",", "audio_feature_length", ",", "1", ",", "0", ")", "\n", "\n", "self", ".", "rgbdepth_upconvlayer1", "=", "unet_upconv", "(", "512", ",", "512", ")", "#1016 (audio-visual feature) = 512 (visual feature) + 504 (audio feature)", "\n", "self", ".", "rgbdepth_upconvlayer2", "=", "unet_upconv", "(", "512", ",", "256", ")", "\n", "self", ".", "rgbdepth_upconvlayer3", "=", "unet_upconv", "(", "256", ",", "128", ")", "\n", "self", ".", "rgbdepth_upconvlayer4", "=", "unet_upconv", "(", "128", ",", "64", ")", "\n", "self", ".", "rgbdepth_upconvlayer5", "=", "unet_upconv", "(", "64", ",", "32", ")", "\n", "self", ".", "rgbdepth_upconvlayer6", "=", "unet_upconv", "(", "32", ",", "16", ")", "\n", "self", ".", "rgbdepth_upconvlayer7", "=", "unet_upconv", "(", "16", ",", "output_nc", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.SimpleAudioDepthNet._conv_output_dim": [[81, 108], ["range", "tuple", "len", "len", "out_dimension.append", "int", "numpy.floor"], "methods", ["None"], ["", "def", "_conv_output_dim", "(", "\n", "self", ",", "dimension", ",", "padding", ",", "dilation", ",", "kernel_size", ",", "stride", "\n", ")", ":", "\n", "        ", "r\"\"\"Calculates the output height and width based on the input\n        height and width to the convolution layer.\n        ref: https://pytorch.org/docs/master/nn.html#torch.nn.Conv2d\n        \"\"\"", "\n", "assert", "len", "(", "dimension", ")", "==", "2", "\n", "out_dimension", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "dimension", ")", ")", ":", "\n", "            ", "out_dimension", ".", "append", "(", "\n", "int", "(", "\n", "np", ".", "floor", "(", "\n", "(", "\n", "(", "\n", "dimension", "[", "i", "]", "\n", "+", "2", "*", "padding", "[", "i", "]", "\n", "-", "dilation", "[", "i", "]", "*", "(", "kernel_size", "[", "i", "]", "-", "1", ")", "\n", "-", "1", "\n", ")", "\n", "/", "stride", "[", "i", "]", "\n", ")", "\n", "+", "1", "\n", ")", "\n", ")", "\n", ")", "\n", "", "return", "tuple", "(", "out_dimension", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.SimpleAudioDepthNet.forward": [[109, 124], ["networks.SimpleAudioDepthNet.feature_extraction", "networks.SimpleAudioDepthNet.view", "networks.SimpleAudioDepthNet.conv1x1", "networks.SimpleAudioDepthNet.rgbdepth_upconvlayer1", "networks.SimpleAudioDepthNet.rgbdepth_upconvlayer2", "networks.SimpleAudioDepthNet.rgbdepth_upconvlayer3", "networks.SimpleAudioDepthNet.rgbdepth_upconvlayer4", "networks.SimpleAudioDepthNet.rgbdepth_upconvlayer5", "networks.SimpleAudioDepthNet.rgbdepth_upconvlayer6", "networks.SimpleAudioDepthNet.rgbdepth_upconvlayer7"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "feature_extraction", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "x", "=", "self", ".", "conv1x1", "(", "x", ")", "\n", "\n", "audio_feat", "=", "x", "\n", "\n", "rgbdepth_upconv1feature", "=", "self", ".", "rgbdepth_upconvlayer1", "(", "audio_feat", ")", "\n", "rgbdepth_upconv2feature", "=", "self", ".", "rgbdepth_upconvlayer2", "(", "rgbdepth_upconv1feature", ")", "\n", "rgbdepth_upconv3feature", "=", "self", ".", "rgbdepth_upconvlayer3", "(", "rgbdepth_upconv2feature", ")", "\n", "rgbdepth_upconv4feature", "=", "self", ".", "rgbdepth_upconvlayer4", "(", "rgbdepth_upconv3feature", ")", "\n", "rgbdepth_upconv5feature", "=", "self", ".", "rgbdepth_upconvlayer5", "(", "rgbdepth_upconv4feature", ")", "\n", "rgbdepth_upconv6feature", "=", "self", ".", "rgbdepth_upconvlayer6", "(", "rgbdepth_upconv5feature", ")", "\n", "depth_prediction", "=", "self", ".", "rgbdepth_upconvlayer7", "(", "rgbdepth_upconv6feature", ")", "\n", "return", "depth_prediction", ",", "audio_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.attentionNet.__init__": [[126, 137], ["torch.Module.__init__", "torch.Bilinear", "torch.Bilinear", "torch.Bilinear", "torch.Bilinear", "torch.Bilinear", "torch.Bilinear", "networks.unet_upconv", "networks.unet_upconv", "networks.unet_upconv", "networks.unet_upconv", "networks.unet_upconv"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv"], ["    ", "def", "__init__", "(", "self", ",", "att_out_nc", ",", "input_nc", ")", ":", "\n", "        ", "super", "(", "attentionNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "#initialize layers", "\n", "\n", "self", ".", "attention_img", "=", "nn", ".", "Bilinear", "(", "512", ",", "512", ",", "att_out_nc", ")", "\n", "self", ".", "attention_material", "=", "nn", ".", "Bilinear", "(", "512", ",", "512", ",", "att_out_nc", ")", "\n", "self", ".", "upconvlayer1", "=", "unet_upconv", "(", "input_nc", ",", "512", ")", "\n", "self", ".", "upconvlayer2", "=", "unet_upconv", "(", "512", ",", "256", ")", "\n", "self", ".", "upconvlayer3", "=", "unet_upconv", "(", "256", ",", "128", ")", "\n", "self", ".", "upconvlayer4", "=", "unet_upconv", "(", "128", ",", "64", ")", "\n", "self", ".", "upconvlayer5", "=", "unet_upconv", "(", "64", ",", "1", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.attentionNet.forward": [[138, 157], ["rgb_feat.permute().contiguous.permute().contiguous.permute().contiguous", "echo_feat.permute().contiguous.permute().contiguous.permute().contiguous", "mat_feat.permute().contiguous.permute().contiguous.permute().contiguous", "networks.attentionNet.attention_img", "networks.attentionNet.attention_material", "attentionImg.permute().contiguous.permute().contiguous.permute().contiguous", "attentionMat.permute().contiguous.permute().contiguous.permute().contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.attentionNet.upconvlayer1", "networks.attentionNet.upconvlayer2", "networks.attentionNet.upconvlayer3", "networks.attentionNet.upconvlayer4", "networks.attentionNet.upconvlayer5", "rgb_feat.permute().contiguous.permute().contiguous.permute", "echo_feat.permute().contiguous.permute().contiguous.permute", "mat_feat.permute().contiguous.permute().contiguous.permute", "attentionImg.permute().contiguous.permute().contiguous.permute", "attentionMat.permute().contiguous.permute().contiguous.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "rgb_feat", ",", "echo_feat", ",", "mat_feat", ")", ":", "\n", "        ", "rgb_feat", "=", "rgb_feat", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "echo_feat", "=", "echo_feat", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "mat_feat", "=", "mat_feat", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "attentionImg", "=", "self", ".", "attention_img", "(", "rgb_feat", ",", "echo_feat", ")", "\n", "attentionMat", "=", "self", ".", "attention_material", "(", "mat_feat", ",", "echo_feat", ")", "\n", "\n", "attentionImg", "=", "attentionImg", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "attentionMat", "=", "attentionMat", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "audioVisual_feature", "=", "torch", ".", "cat", "(", "(", "attentionImg", ",", "attentionMat", ")", ",", "dim", "=", "1", ")", "\n", "\n", "upconv1feature", "=", "self", ".", "upconvlayer1", "(", "audioVisual_feature", ")", "\n", "upconv2feature", "=", "self", ".", "upconvlayer2", "(", "upconv1feature", ")", "\n", "upconv3feature", "=", "self", ".", "upconvlayer3", "(", "upconv2feature", ")", "\n", "upconv4feature", "=", "self", ".", "upconvlayer4", "(", "upconv3feature", ")", "\n", "attention", "=", "self", ".", "upconvlayer5", "(", "upconv4feature", ")", "\n", "return", "attention", ",", "audioVisual_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.RGBDepthNet.__init__": [[159, 172], ["torch.Module.__init__", "networks.unet_conv", "networks.unet_conv", "networks.unet_conv", "networks.unet_conv", "networks.unet_conv", "networks.unet_upconv", "networks.unet_upconv", "networks.unet_upconv", "networks.unet_upconv", "networks.unet_upconv"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_conv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_conv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_conv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_conv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_conv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv"], ["    ", "def", "__init__", "(", "self", ",", "ngf", "=", "64", ",", "input_nc", "=", "3", ",", "output_nc", "=", "1", ")", ":", "\n", "        ", "super", "(", "RGBDepthNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "#initialize layers", "\n", "self", ".", "rgbdepth_convlayer1", "=", "unet_conv", "(", "input_nc", ",", "ngf", ")", "\n", "self", ".", "rgbdepth_convlayer2", "=", "unet_conv", "(", "ngf", ",", "ngf", "*", "2", ")", "\n", "self", ".", "rgbdepth_convlayer3", "=", "unet_conv", "(", "ngf", "*", "2", ",", "ngf", "*", "4", ")", "\n", "self", ".", "rgbdepth_convlayer4", "=", "unet_conv", "(", "ngf", "*", "4", ",", "ngf", "*", "8", ")", "\n", "self", ".", "rgbdepth_convlayer5", "=", "unet_conv", "(", "ngf", "*", "8", ",", "ngf", "*", "8", ")", "\n", "self", ".", "rgbdepth_upconvlayer1", "=", "unet_upconv", "(", "512", ",", "ngf", "*", "8", ")", "\n", "self", ".", "rgbdepth_upconvlayer2", "=", "unet_upconv", "(", "ngf", "*", "16", ",", "ngf", "*", "4", ")", "\n", "self", ".", "rgbdepth_upconvlayer3", "=", "unet_upconv", "(", "ngf", "*", "8", ",", "ngf", "*", "2", ")", "\n", "self", ".", "rgbdepth_upconvlayer4", "=", "unet_upconv", "(", "ngf", "*", "4", ",", "ngf", ")", "\n", "self", ".", "rgbdepth_upconvlayer5", "=", "unet_upconv", "(", "ngf", "*", "2", ",", "output_nc", ",", "True", ")", "\n", "#self.conv1x1 = create_conv(512, 8, 1, 0) #reduce dimension of extracted visual features", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.RGBDepthNet.forward": [[174, 187], ["networks.RGBDepthNet.rgbdepth_convlayer1", "networks.RGBDepthNet.rgbdepth_convlayer2", "networks.RGBDepthNet.rgbdepth_convlayer3", "networks.RGBDepthNet.rgbdepth_convlayer4", "networks.RGBDepthNet.rgbdepth_convlayer5", "networks.RGBDepthNet.rgbdepth_upconvlayer1", "networks.RGBDepthNet.rgbdepth_upconvlayer2", "networks.RGBDepthNet.rgbdepth_upconvlayer3", "networks.RGBDepthNet.rgbdepth_upconvlayer4", "networks.RGBDepthNet.rgbdepth_upconvlayer5", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "rgbdepth_conv1feature", "=", "self", ".", "rgbdepth_convlayer1", "(", "x", ")", "\n", "rgbdepth_conv2feature", "=", "self", ".", "rgbdepth_convlayer2", "(", "rgbdepth_conv1feature", ")", "\n", "rgbdepth_conv3feature", "=", "self", ".", "rgbdepth_convlayer3", "(", "rgbdepth_conv2feature", ")", "\n", "rgbdepth_conv4feature", "=", "self", ".", "rgbdepth_convlayer4", "(", "rgbdepth_conv3feature", ")", "\n", "rgbdepth_conv5feature", "=", "self", ".", "rgbdepth_convlayer5", "(", "rgbdepth_conv4feature", ")", "\n", "\n", "rgbdepth_upconv1feature", "=", "self", ".", "rgbdepth_upconvlayer1", "(", "rgbdepth_conv5feature", ")", "\n", "rgbdepth_upconv2feature", "=", "self", ".", "rgbdepth_upconvlayer2", "(", "torch", ".", "cat", "(", "(", "rgbdepth_upconv1feature", ",", "rgbdepth_conv4feature", ")", ",", "dim", "=", "1", ")", ")", "\n", "rgbdepth_upconv3feature", "=", "self", ".", "rgbdepth_upconvlayer3", "(", "torch", ".", "cat", "(", "(", "rgbdepth_upconv2feature", ",", "rgbdepth_conv3feature", ")", ",", "dim", "=", "1", ")", ")", "\n", "rgbdepth_upconv4feature", "=", "self", ".", "rgbdepth_upconvlayer4", "(", "torch", ".", "cat", "(", "(", "rgbdepth_upconv3feature", ",", "rgbdepth_conv2feature", ")", ",", "dim", "=", "1", ")", ")", "\n", "depth_prediction", "=", "self", ".", "rgbdepth_upconvlayer5", "(", "torch", ".", "cat", "(", "(", "rgbdepth_upconv4feature", ",", "rgbdepth_conv1feature", ")", ",", "dim", "=", "1", ")", ")", "\n", "return", "depth_prediction", ",", "rgbdepth_conv5feature", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.MaterialPropertyNet.__init__": [[189, 195], ["torch.Module.__init__", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nclass", ",", "backbone", ")", ":", "\n", "        ", "super", "(", "MaterialPropertyNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "pretrained", "=", "backbone", "\n", "self", ".", "pool", "=", "nn", ".", "AvgPool2d", "(", "4", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", ",", "nclass", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.MaterialPropertyNet.forward": [[196, 210], ["networks.MaterialPropertyNet.pretrained.conv1", "networks.MaterialPropertyNet.pretrained.bn1", "networks.MaterialPropertyNet.pretrained.relu", "networks.MaterialPropertyNet.pretrained.maxpool", "networks.MaterialPropertyNet.pretrained.layer1", "networks.MaterialPropertyNet.pretrained.layer2", "networks.MaterialPropertyNet.pretrained.layer3", "networks.MaterialPropertyNet.pretrained.layer4", "networks.MaterialPropertyNet.pool", "networks.MaterialPropertyNet.view", "networks.MaterialPropertyNet.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# pre-trained ResNet feature", "\n", "        ", "x", "=", "self", ".", "pretrained", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "pretrained", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "pretrained", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "pretrained", ".", "maxpool", "(", "x", ")", "\n", "x", "=", "self", ".", "pretrained", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "pretrained", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "pretrained", ".", "layer3", "(", "x", ")", "\n", "feat", "=", "self", ".", "pretrained", ".", "layer4", "(", "x", ")", "\n", "x", "=", "self", ".", "pool", "(", "feat", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "512", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", ",", "feat", "\n", "", "", ""]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_conv": [[7, 12], ["torch.Conv2d", "torch.LeakyReLU", "norm_layer", "torch.Sequential"], "function", ["None"], ["def", "unet_conv", "(", "input_nc", ",", "output_nc", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "    ", "downconv", "=", "nn", ".", "Conv2d", "(", "input_nc", ",", "output_nc", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "downrelu", "=", "nn", ".", "LeakyReLU", "(", "0.2", ",", "True", ")", "\n", "downnorm", "=", "norm_layer", "(", "output_nc", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "[", "downconv", ",", "downnorm", ",", "downrelu", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.unet_upconv": [[13, 21], ["torch.ConvTranspose2d", "torch.ReLU", "norm_layer", "torch.Sequential", "torch.Sequential", "torch.Sigmoid"], "function", ["None"], ["", "def", "unet_upconv", "(", "input_nc", ",", "output_nc", ",", "outermost", "=", "False", ",", "norm_layer", "=", "nn", ".", "BatchNorm2d", ")", ":", "\n", "    ", "upconv", "=", "nn", ".", "ConvTranspose2d", "(", "input_nc", ",", "output_nc", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "uprelu", "=", "nn", ".", "ReLU", "(", "True", ")", "\n", "upnorm", "=", "norm_layer", "(", "output_nc", ")", "\n", "if", "not", "outermost", ":", "\n", "        ", "return", "nn", ".", "Sequential", "(", "*", "[", "upconv", ",", "upnorm", ",", "uprelu", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "nn", ".", "Sequential", "(", "*", "[", "upconv", ",", "nn", ".", "Sigmoid", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.create_conv": [[23, 30], ["torch.Sequential", "torch.Conv2d", "model.append", "model.append", "torch.BatchNorm2d", "torch.ReLU"], "function", ["None"], ["", "", "def", "create_conv", "(", "input_channels", ",", "output_channels", ",", "kernel", ",", "paddings", ",", "batch_norm", "=", "True", ",", "Relu", "=", "True", ",", "stride", "=", "1", ")", ":", "\n", "    ", "model", "=", "[", "nn", ".", "Conv2d", "(", "input_channels", ",", "output_channels", ",", "kernel", ",", "stride", "=", "stride", ",", "padding", "=", "paddings", ")", "]", "\n", "if", "(", "batch_norm", ")", ":", "\n", "        ", "model", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "output_channels", ")", ")", "\n", "", "if", "(", "Relu", ")", ":", "\n", "        ", "model", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.networks.weights_init": [[31, 40], ["classname.find", "m.weight.data.normal_", "classname.find", "m.weight.data.normal_", "m.bias.data.fill_", "classname.find", "m.weight.data.normal_"], "function", ["None"], ["", "def", "weights_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm2d'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "1.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.audioVisual_model.AudioVisualModel.name": [[10, 12], ["None"], "methods", ["None"], ["    ", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'AudioVisualModel'", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.audioVisual_model.AudioVisualModel.__init__": [[13, 18], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__"], ["", "def", "__init__", "(", "self", ",", "nets", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AudioVisualModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "#initialize model", "\n", "self", ".", "net_rgbdepth", ",", "self", ".", "net_audio", ",", "self", ".", "net_attention", ",", "self", ".", "net_material", "=", "nets", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.audioVisual_model.AudioVisualModel.forward": [[20, 41], ["audioVisual_model.AudioVisualModel.net_audio", "audioVisual_model.AudioVisualModel.net_rgbdepth", "audioVisual_model.AudioVisualModel.net_material", "audio_feat.repeat.repeat.repeat", "audioVisual_model.AudioVisualModel.net_attention"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "volatile", "=", "False", ")", ":", "\n", "        ", "rgb_input", "=", "input", "[", "'img'", "]", "\n", "audio_input", "=", "input", "[", "'audio'", "]", "\n", "depth_gt", "=", "input", "[", "'depth'", "]", "\n", "\n", "audio_depth", ",", "audio_feat", "=", "self", ".", "net_audio", "(", "audio_input", ")", "\n", "img_depth", ",", "img_feat", "=", "self", ".", "net_rgbdepth", "(", "rgb_input", ")", "\n", "material_class", ",", "material_feat", "=", "self", ".", "net_material", "(", "rgb_input", ")", "\n", "audio_feat", "=", "audio_feat", ".", "repeat", "(", "1", ",", "1", ",", "img_feat", ".", "shape", "[", "-", "2", "]", ",", "img_feat", ".", "shape", "[", "-", "1", "]", ")", "#tile audio feature", "\n", "alpha", ",", "_", "=", "self", ".", "net_attention", "(", "img_feat", ",", "audio_feat", ",", "material_feat", ")", "\n", "depth_prediction", "=", "(", "(", "alpha", "*", "audio_depth", ")", "+", "(", "(", "1", "-", "alpha", ")", "*", "img_depth", ")", ")", "\n", "\n", "\n", "output", "=", "{", "'img_depth'", ":", "img_depth", "*", "self", ".", "opt", ".", "max_depth", ",", "\n", "'audio_depth'", ":", "audio_depth", "*", "self", ".", "opt", ".", "max_depth", ",", "\n", "'depth_predicted'", ":", "depth_prediction", "*", "self", ".", "opt", ".", "max_depth", ",", "\n", "'attention'", ":", "alpha", ",", "\n", "'img'", ":", "rgb_input", ",", "\n", "'audio'", ":", "audio_input", ",", "\n", "'depth_gt'", ":", "depth_gt", "}", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.BaseLoss.__init__": [[7, 9], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BaseLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.BaseLoss.forward": [[10, 26], ["isinstance", "len", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "isinstance", "preds[].new_ones", "criterion.BaseLoss._forward", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "criterion.BaseLoss._forward", "range", "preds.new_ones"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.BCEWithLogitsLoss._forward", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.BCEWithLogitsLoss._forward"], ["", "def", "forward", "(", "self", ",", "preds", ",", "targets", ",", "weight", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "preds", ",", "list", ")", ":", "\n", "            ", "N", "=", "len", "(", "preds", ")", "\n", "if", "weight", "is", "None", ":", "\n", "                ", "weight", "=", "preds", "[", "0", "]", ".", "new_ones", "(", "1", ")", "\n", "\n", "", "errs", "=", "[", "self", ".", "_forward", "(", "preds", "[", "n", "]", ",", "targets", "[", "n", "]", ",", "weight", "[", "n", "]", ")", "\n", "for", "n", "in", "range", "(", "N", ")", "]", "\n", "err", "=", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "errs", ")", ")", "\n", "\n", "", "elif", "isinstance", "(", "preds", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "if", "weight", "is", "None", ":", "\n", "                ", "weight", "=", "preds", ".", "new_ones", "(", "1", ")", "\n", "", "err", "=", "self", ".", "_forward", "(", "preds", ",", "targets", ",", "weight", ")", "\n", "\n", "", "return", "err", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.L1Loss.__init__": [[29, 31], ["criterion.BaseLoss.__init__"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "L1Loss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.L1Loss._forward": [[32, 34], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "pred", ",", "target", ",", "weight", ")", ":", "\n", "        ", "return", "torch", ".", "mean", "(", "weight", "*", "torch", ".", "abs", "(", "pred", "-", "target", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.L2Loss.__init__": [[37, 39], ["criterion.BaseLoss.__init__"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "L2Loss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.L2Loss._forward": [[40, 42], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "pred", ",", "target", ",", "weight", ")", ":", "\n", "        ", "return", "torch", ".", "mean", "(", "weight", "*", "torch", ".", "pow", "(", "pred", "-", "target", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.LogDepthLoss.__init__": [[45, 47], ["criterion.BaseLoss.__init__"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "LogDepthLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.LogDepthLoss._forward": [[48, 50], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "pred", ",", "target", ",", "weight", ")", ":", "\n", "        ", "return", "torch", ".", "mean", "(", "torch", ".", "log", "(", "torch", ".", "abs", "(", "pred", "-", "target", ")", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.MSELoss.__init__": [[52, 54], ["criterion.BaseLoss.__init__"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "MSELoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.MSELoss._forward": [[55, 57], ["torch.mse_loss", "torch.mse_loss", "torch.mse_loss"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "pred", ",", "target", ")", ":", "\n", "        ", "return", "F", ".", "mse_loss", "(", "pred", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.BCELoss.__init__": [[59, 61], ["criterion.BaseLoss.__init__"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BCELoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.BCELoss._forward": [[62, 64], ["torch.binary_cross_entropy", "torch.binary_cross_entropy", "torch.binary_cross_entropy"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "pred", ",", "target", ",", "weight", ")", ":", "\n", "        ", "return", "F", ".", "binary_cross_entropy", "(", "pred", ",", "target", ",", "weight", "=", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.BCEWithLogitsLoss.__init__": [[66, 68], ["criterion.BaseLoss.__init__"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BCEWithLogitsLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.models.criterion.BCEWithLogitsLoss._forward": [[69, 71], ["torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits", "torch.binary_cross_entropy_with_logits"], "methods", ["None"], ["", "def", "_forward", "(", "self", ",", "pred", ",", "target", ",", "weight", ")", ":", "\n", "        ", "return", "F", ".", "binary_cross_entropy_with_logits", "(", "pred", ",", "target", ",", "weight", "=", "weight", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.AudioVisualDataset.initialize": [[54, 76], ["torchvision.Normalize", "torchvision.Compose", "audio_visual_dataset.parse_all_data", "audio_visual_dataset.parse_all_data", "torchvision.ToTensor", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.parse_all_data", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.parse_all_data"], ["    ", "def", "initialize", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "if", "self", ".", "opt", ".", "dataset", "==", "'mp3d'", ":", "\n", "            ", "self", ".", "data_idx", ",", "self", ".", "data", "=", "parse_all_data", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "opt", ".", "img_path", ",", "opt", ".", "mode", "+", "'.pkl'", ")", ",", "\n", "self", ".", "opt", ".", "scenes", "[", "opt", ".", "mode", "]", ")", "\n", "self", ".", "win_length", "=", "32", "\n", "", "if", "self", ".", "opt", ".", "dataset", "==", "'replica'", ":", "\n", "            ", "self", ".", "data_idx", ",", "self", ".", "data", "=", "parse_all_data", "(", "self", ".", "opt", ".", "img_path", ",", "\n", "self", ".", "opt", ".", "scenes", "[", "opt", ".", "mode", "]", ")", "\n", "self", ".", "win_length", "=", "64", "\n", "", "normalize", "=", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", ")", "\n", "vision_transform_list", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", "\n", "self", ".", "vision_transform", "=", "transforms", ".", "Compose", "(", "vision_transform_list", ")", "\n", "self", ".", "base_audio_path", "=", "self", ".", "opt", ".", "audio_path", "\n", "if", "self", ".", "opt", ".", "dataset", "==", "'mp3d'", ":", "\n", "            ", "self", ".", "audio_type", "=", "'3ms_sweep_16khz'", "\n", "", "if", "self", ".", "opt", ".", "dataset", "==", "'replica'", ":", "\n", "            ", "self", ".", "audio_type", "=", "'3ms_sweep'", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.AudioVisualDataset.__getitem__": [[77, 111], ["audio_visual_dataset.AudioVisualDataset.data_idx[].split", "os.path.join", "librosa.load", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "PIL.Image.fromarray().convert", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "depth.unsqueeze.unsqueeze.unsqueeze", "audio_visual_dataset.normalize", "audio_visual_dataset.generate_spectrogram", "audio_visual_dataset.process_image", "audio_visual_dataset.AudioVisualDataset.vision_transform", "PIL.Image.fromarray", "random.randrange", "random.randrange", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.normalize", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.generate_spectrogram", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.process_image"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "#load audio", "\n", "        ", "scene", ",", "loc", ",", "orn", "=", "self", ".", "data_idx", "[", "index", "]", ".", "split", "(", "'/'", ")", "\n", "audio_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "base_audio_path", ",", "scene", ",", "self", ".", "audio_type", ",", "orn", ",", "loc", "+", "'.wav'", ")", "\n", "audio", ",", "audio_rate", "=", "librosa", ".", "load", "(", "audio_path", ",", "sr", "=", "self", ".", "opt", ".", "audio_sampling_rate", ",", "mono", "=", "False", ",", "duration", "=", "self", ".", "opt", ".", "audio_length", ")", "\n", "if", "self", ".", "opt", ".", "audio_normalize", ":", "\n", "            ", "audio", "=", "normalize", "(", "audio", ")", "\n", "\n", "#get the spectrogram of both channel", "\n", "", "audio_spec_both", "=", "torch", ".", "FloatTensor", "(", "generate_spectrogram", "(", "audio", "[", "0", ",", ":", "]", ",", "audio", "[", "1", ",", ":", "]", ",", "self", ".", "win_length", ")", ")", "\n", "#get the rgb image and depth image", "\n", "img", "=", "Image", ".", "fromarray", "(", "self", ".", "data", "[", "scene", "]", "[", "(", "int", "(", "loc", ")", ",", "int", "(", "orn", ")", ")", "]", "[", "(", "'rgb'", ")", "]", ")", ".", "convert", "(", "'RGB'", ")", "\n", "\n", "if", "self", ".", "opt", ".", "mode", "==", "\"train\"", ":", "\n", "           ", "img", "=", "process_image", "(", "img", ",", "self", ".", "opt", ".", "enable_img_augmentation", ")", "\n", "\n", "", "if", "self", ".", "opt", ".", "image_transform", ":", "\n", "            ", "img", "=", "self", ".", "vision_transform", "(", "img", ")", "\n", "\n", "", "depth", "=", "torch", ".", "FloatTensor", "(", "self", ".", "data", "[", "scene", "]", "[", "(", "int", "(", "loc", ")", ",", "int", "(", "orn", ")", ")", "]", "[", "(", "'depth'", ")", "]", ")", "\n", "depth", "=", "depth", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "if", "self", ".", "opt", ".", "mode", "==", "\"train\"", ":", "\n", "            ", "if", "self", ".", "opt", ".", "enable_cropping", ":", "\n", "                ", "RESOLUTION", "=", "self", ".", "opt", ".", "image_resolution", "\n", "w_offset", "=", "RESOLUTION", "-", "128", "\n", "h_offset", "=", "RESOLUTION", "-", "128", "\n", "left", "=", "random", ".", "randrange", "(", "0", ",", "w_offset", "+", "1", ")", "\n", "upper", "=", "random", ".", "randrange", "(", "0", ",", "h_offset", "+", "1", ")", "\n", "img", "=", "img", "[", ":", ",", "left", ":", "left", "+", "128", ",", "upper", ":", "upper", "+", "128", "]", "\n", "depth", "=", "depth", "[", ":", ",", "left", ":", "left", "+", "128", ",", "upper", ":", "upper", "+", "128", "]", "\n", "\n", "\n", "", "", "return", "{", "'img'", ":", "img", ",", "'depth'", ":", "depth", ",", "'audio'", ":", "audio_spec_both", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.AudioVisualDataset.__len__": [[112, 114], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.AudioVisualDataset.name": [[115, 117], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'AudioVisualDataset'", "", "", "", ""]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.normalize": [[16, 20], ["numpy.maximum", "numpy.sqrt", "numpy.mean"], "function", ["None"], ["def", "normalize", "(", "samples", ",", "desired_rms", "=", "0.1", ",", "eps", "=", "1e-4", ")", ":", "\n", "  ", "rms", "=", "np", ".", "maximum", "(", "eps", ",", "np", ".", "sqrt", "(", "np", ".", "mean", "(", "samples", "**", "2", ")", ")", ")", "\n", "samples", "=", "samples", "*", "(", "desired_rms", "/", "rms", ")", "\n", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.generate_spectrogram": [[21, 27], ["librosa.stft", "librosa.stft", "numpy.concatenate", "numpy.expand_dims", "numpy.expand_dims", "numpy.abs", "numpy.abs"], "function", ["None"], ["", "def", "generate_spectrogram", "(", "audioL", ",", "audioR", ",", "winl", "=", "32", ")", ":", "\n", "    ", "channel_1_spec", "=", "librosa", ".", "stft", "(", "audioL", ",", "n_fft", "=", "512", ",", "win_length", "=", "winl", ")", "\n", "channel_2_spec", "=", "librosa", ".", "stft", "(", "audioR", ",", "n_fft", "=", "512", ",", "win_length", "=", "winl", ")", "\n", "spectro_two_channel", "=", "np", ".", "concatenate", "(", "(", "np", ".", "expand_dims", "(", "np", ".", "abs", "(", "channel_1_spec", ")", ",", "axis", "=", "0", ")", ",", "np", ".", "expand_dims", "(", "np", ".", "abs", "(", "channel_2_spec", ")", ",", "axis", "=", "0", ")", ")", ",", "axis", "=", "0", ")", "\n", "#print(spectro_two_channel.shape)", "\n", "return", "spectro_two_channel", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.process_image": [[28, 38], ["PIL.ImageEnhance.Brightness", "ImageEnhance.Contrast.enhance", "PIL.ImageEnhance.Color", "ImageEnhance.Contrast.enhance", "PIL.ImageEnhance.Contrast", "ImageEnhance.Contrast.enhance", "random.random", "random.random", "random.random"], "function", ["None"], ["", "def", "process_image", "(", "rgb", ",", "augment", ")", ":", "\n", "    ", "if", "augment", ":", "\n", "# print('Doing Augmentation')", "\n", "        ", "enhancer", "=", "ImageEnhance", ".", "Brightness", "(", "rgb", ")", "\n", "rgb", "=", "enhancer", ".", "enhance", "(", "random", ".", "random", "(", ")", "*", "0.6", "+", "0.7", ")", "\n", "enhancer", "=", "ImageEnhance", ".", "Color", "(", "rgb", ")", "\n", "rgb", "=", "enhancer", ".", "enhance", "(", "random", ".", "random", "(", ")", "*", "0.6", "+", "0.7", ")", "\n", "enhancer", "=", "ImageEnhance", ".", "Contrast", "(", "rgb", ")", "\n", "rgb", "=", "enhancer", ".", "enhance", "(", "random", ".", "random", "(", ")", "*", "0.6", "+", "0.7", ")", "\n", "", "return", "rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.audio_visual_dataset.parse_all_data": [[40, 52], ["print", "open", "pickle.load", "print", "print", "len", "list", "str", "str", "data_dict[].keys"], "function", ["None"], ["", "def", "parse_all_data", "(", "root_path", ",", "scenes", ")", ":", "\n", "    ", "data_idx_all", "=", "[", "]", "\n", "print", "(", "root_path", ")", "\n", "with", "open", "(", "root_path", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "data_dict", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "for", "scene", "in", "scenes", ":", "\n", "        ", "print", "(", "scene", ")", "\n", "data_idx_all", "+=", "[", "'/'", ".", "join", "(", "[", "scene", ",", "str", "(", "loc", ")", ",", "str", "(", "ori", ")", "]", ")", "for", "(", "loc", ",", "ori", ")", "in", "list", "(", "data_dict", "[", "scene", "]", ".", "keys", "(", ")", ")", "]", "\n", "print", "(", "len", "(", "data_idx_all", ")", ")", "\n", "\n", "", "return", "data_idx_all", ",", "data_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.custom_dataset_data_loader.CustomDatasetDataLoader.name": [[13, 15], ["None"], "methods", ["None"], ["    ", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'CustomDatasetDataLoader'", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.custom_dataset_data_loader.CustomDatasetDataLoader.initialize": [[16, 27], ["custom_dataset_data_loader.CreateDataset", "torch.utils.data.DataLoader", "print", "int"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.custom_dataset_data_loader.CreateDataset"], ["", "def", "initialize", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "CreateDataset", "(", "opt", ")", "\n", "shuff", "=", "False", "\n", "if", "opt", ".", "mode", "==", "\"train\"", ":", "\n", "            ", "print", "(", "'Shuffling the dataset....'", ")", "\n", "shuff", "=", "True", "\n", "", "self", ".", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "dataset", ",", "\n", "batch_size", "=", "opt", ".", "batchSize", ",", "\n", "shuffle", "=", "shuff", ",", "\n", "num_workers", "=", "int", "(", "opt", ".", "nThreads", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.custom_dataset_data_loader.CustomDatasetDataLoader.load_data": [[28, 30], ["None"], "methods", ["None"], ["", "def", "load_data", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.custom_dataset_data_loader.CustomDatasetDataLoader.__len__": [[31, 33], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.custom_dataset_data_loader.CustomDatasetDataLoader.__iter__": [[34, 37], ["enumerate"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "i", ",", "data", "in", "enumerate", "(", "self", ".", "dataloader", ")", ":", "\n", "            ", "yield", "data", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.data_loader.custom_dataset_data_loader.CreateDataset": [[5, 11], ["AudioVisualDataset", "AudioVisualDataset.initialize"], "function", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.initialize"], ["def", "CreateDataset", "(", "opt", ")", ":", "\n", "    ", "dataset", "=", "None", "\n", "from", "data_loader", ".", "audio_visual_dataset", "import", "AudioVisualDataset", "\n", "dataset", "=", "AudioVisualDataset", "(", ")", "\n", "dataset", ".", "initialize", "(", "opt", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.test_options.TestOptions.initialize": [[12, 20], ["base_options.BaseOptions.initialize"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.initialize"], ["\t", "def", "initialize", "(", "self", ")", ":", "\n", "\t\t", "BaseOptions", ".", "initialize", "(", "self", ")", "\n", "\n", "#model arguments", "\n", "self", ".", "mode", "=", "\"test\"", "\n", "self", ".", "isTrain", "=", "False", "\n", "self", ".", "enable_data_augmentation", "=", "False", "\n", "self", ".", "enable_cropping", "=", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.train_options.TrainOptions.initialize": [[4, 33], ["base_options.BaseOptions.initialize", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument", "train_options.TrainOptions.parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.initialize"], ["\t", "def", "initialize", "(", "self", ")", ":", "\n", "\t\t", "BaseOptions", ".", "initialize", "(", "self", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--display_freq'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "help", "=", "'frequency of displaying average loss'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--niter'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "help", "=", "'# of epochs to train'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--learning_rate_decrease_itr'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'how often is the learning rate decreased by six percent'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--decay_factor'", ",", "type", "=", "float", ",", "default", "=", "0.94", ",", "help", "=", "'learning rate decay factor'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--validation_on'", ",", "action", "=", "'store_true'", ",", "help", "=", "'whether to test on validation set during training'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--validation_freq'", ",", "type", "=", "int", ",", "default", "=", "400", ",", "help", "=", "'frequency of testing on validation set'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--epoch_save_freq'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'frequency of saving intermediate models'", ")", "\n", "\n", "#model arguments", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--init_material_weight'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'path to the pre-trained material net'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--unet_ngf'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "\"unet base channel dimension\"", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--unet_input_nc'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "\"input spectrogram number of channels\"", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--unet_output_nc'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"output spectrogram number of channels\"", ")", "\n", "\n", "#optimizer arguments", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--lr_visual'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "help", "=", "'learning rate for visual stream'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--lr_audio'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "help", "=", "'learning rate for audio'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--lr_attention'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "help", "=", "'learning rate for attention network'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--lr_material'", ",", "type", "=", "float", ",", "default", "=", "0.0001", ",", "help", "=", "'learning rate for material network'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "default", "=", "'adam'", ",", "type", "=", "str", ",", "help", "=", "'adam or sgd for optimization'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--beta1'", ",", "default", "=", "0.9", ",", "type", "=", "float", ",", "help", "=", "'momentum for sgd, beta1 for adam'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "default", "=", "0.0005", ",", "type", "=", "float", ",", "help", "=", "'weights regularizer'", ")", "\n", "\n", "self", ".", "mode", "=", "\"train\"", "\n", "self", ".", "isTrain", "=", "True", "\n", "self", ".", "enable_data_augmentation", "=", "True", "\n", "self", ".", "enable_cropping", "=", "False", "", "", "", ""]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.__init__": [[9, 12], ["argparse.ArgumentParser"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "self", ".", "initialized", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.initialize": [[13, 28], ["base_options.BaseOptions.parser.add_argument", "base_options.BaseOptions.parser.add_argument", "base_options.BaseOptions.parser.add_argument", "base_options.BaseOptions.parser.add_argument", "base_options.BaseOptions.parser.add_argument", "base_options.BaseOptions.parser.add_argument", "base_options.BaseOptions.parser.add_argument", "base_options.BaseOptions.parser.add_argument", "base_options.BaseOptions.parser.add_argument", "base_options.BaseOptions.parser.add_argument", "base_options.BaseOptions.parser.add_argument", "base_options.BaseOptions.parser.add_argument"], "methods", ["None"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "parser", ".", "add_argument", "(", "'--img_path'", ",", "type", "=", "str", ",", "default", "=", "'/data1/kranti/audio-visual-depth/dataset/visual_echoes/images/mp3d_split_wise'", ",", "help", "=", "'root path to the file that contains the .pkl file'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--metadatapath'", ",", "type", "=", "str", ",", "default", "=", "'/data1/kranti/audio-visual-depth/dataset/visual_echoes/metadata/mp3d'", ",", "help", "=", "'path to metadata file for different split'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--audio_path'", ",", "type", "=", "str", ",", "default", "=", "'/data1/kranti/audio-visual-depth/dataset/visual_echoes/echoes/mp3d/echoes_navigable'", ",", "help", "=", "'path to the folder that contains echo responses'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--checkpoints_dir'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "'path to save checkpoints'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--gpu_ids'", ",", "type", "=", "str", ",", "default", "=", "'0'", ",", "help", "=", "'gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--batchSize'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'input batch size'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--nThreads'", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "'# threads for loading data'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--audio_length'", ",", "default", "=", "0.06", ",", "type", "=", "float", ",", "help", "=", "'audio length, default 0.06s'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--audio_normalize'", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "help", "=", "'whether to normalize the audio'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--image_transform'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'whether to transform the image data'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--image_resolution'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "help", "=", "'the resolution of image for cropping'", ")", "\n", "self", ".", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'mp3d'", ",", "type", "=", "str", ",", "help", "=", "'replica/mp3d'", ")", "\n", "## scratch was added after one step of training done with material property initialization", "\n", "self", ".", "initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.parse": [[29, 98], ["base_options.BaseOptions.parser.parse_args", "base_options.BaseOptions.opt.gpu_ids.split", "vars", "print", "sorted", "print", "os.path.join", "util.util.util.mkdirs", "os.path.join", "base_options.BaseOptions.initialize", "os.path.join", "os.path.join", "os.path.join", "int", "vars.items", "print", "open", "opt_file.write", "sorted", "opt_file.write", "open", "f.readlines", "x.strip", "open", "f.readlines", "x.strip", "open", "f.readlines", "x.strip", "base_options.BaseOptions.opt.gpu_ids.append", "vars.items", "opt_file.write", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.util.util.mkdirs", "home.repos.pwc.inspect_result.krantiparida_beyond-image-to-depth.options.base_options.BaseOptions.initialize"], ["", "def", "parse", "(", "self", ")", ":", "\n", "\t\t", "if", "not", "self", ".", "initialized", ":", "\n", "\t\t\t", "self", ".", "initialize", "(", ")", "\n", "", "self", ".", "opt", "=", "self", ".", "parser", ".", "parse_args", "(", ")", "\n", "\n", "self", ".", "opt", ".", "mode", "=", "self", ".", "mode", "\n", "self", ".", "opt", ".", "isTrain", "=", "self", ".", "isTrain", "\n", "self", ".", "opt", ".", "enable_img_augmentation", "=", "self", ".", "enable_data_augmentation", "\n", "self", ".", "opt", ".", "enable_cropping", "=", "self", ".", "enable_cropping", "\n", "\n", "\n", "# dataset specific paramters", "\n", "self", ".", "opt", ".", "scenes", "=", "{", "}", "\n", "if", "self", ".", "opt", ".", "dataset", "==", "'mp3d'", ":", "\n", "\t\t\t", "self", ".", "opt", ".", "audio_shape", "=", "[", "2", ",", "257", ",", "121", "]", "\n", "self", ".", "opt", ".", "audio_sampling_rate", "=", "16000", "\n", "self", ".", "opt", ".", "max_depth", "=", "10.0", "\n", "train_scenes_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "opt", ".", "metadatapath", ",", "'mp3d_scenes_train.txt'", ")", "\n", "val_scenes_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "opt", ".", "metadatapath", ",", "'mp3d_scenes_val.txt'", ")", "\n", "test_scenes_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "opt", ".", "metadatapath", ",", "'mp3d_scenes_test.txt'", ")", "\n", "with", "open", "(", "train_scenes_file", ")", "as", "f", ":", "\n", "\t\t\t\t", "content", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "opt", ".", "scenes", "[", "'train'", "]", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "content", "]", "\n", "\n", "with", "open", "(", "val_scenes_file", ")", "as", "f", ":", "\n", "\t\t\t\t", "content", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "opt", ".", "scenes", "[", "'val'", "]", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "content", "]", "\n", "\n", "with", "open", "(", "test_scenes_file", ")", "as", "f", ":", "\n", "\t\t\t\t", "content", "=", "f", ".", "readlines", "(", ")", "\n", "", "self", ".", "opt", ".", "scenes", "[", "'test'", "]", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "content", "]", "\n", "\n", "", "if", "self", ".", "opt", ".", "dataset", "==", "'replica'", ":", "\n", "\t\t\t", "self", ".", "opt", ".", "audio_shape", "=", "[", "2", ",", "257", ",", "166", "]", "\n", "self", ".", "opt", ".", "audio_sampling_rate", "=", "44100", "\n", "self", ".", "opt", ".", "max_depth", "=", "14.104", "\n", "self", ".", "opt", ".", "scenes", "[", "'train'", "]", "=", "[", "'apartment_0'", ",", "'apartment_1'", ",", "\n", "'frl_apartment_0'", ",", "'frl_apartment_1'", ",", "'frl_apartment_2'", ",", "'frl_apartment_3'", ",", "\n", "'frl_apartment_4'", ",", "'office_0'", ",", "'office_1'", ",", "'office_2'", ",", "'office_3'", ",", "\n", "'hotel_0'", ",", "'room_0'", ",", "'room_1'", ",", "'room_2'", "]", "\n", "self", ".", "opt", ".", "scenes", "[", "'test'", "]", "=", "[", "'apartment_2'", ",", "'frl_apartment_5'", ",", "'office_4'", "]", "\n", "\n", "\n", "", "str_ids", "=", "self", ".", "opt", ".", "gpu_ids", ".", "split", "(", "','", ")", "\n", "self", ".", "opt", ".", "gpu_ids", "=", "[", "]", "\n", "for", "str_id", "in", "str_ids", ":", "\n", "\t\t\t", "id", "=", "int", "(", "str_id", ")", "\n", "if", "id", ">=", "0", ":", "\n", "\t\t\t\t", "self", ".", "opt", ".", "gpu_ids", ".", "append", "(", "id", ")", "\n", "\n", "", "", "args", "=", "vars", "(", "self", ".", "opt", ")", "\n", "print", "(", "'------------ Options -------------'", ")", "\n", "for", "k", ",", "v", "in", "sorted", "(", "args", ".", "items", "(", ")", ")", ":", "\n", "\t\t\t", "print", "(", "'%s: %s'", "%", "(", "str", "(", "k", ")", ",", "str", "(", "v", ")", ")", ")", "\n", "", "print", "(", "'-------------- End ----------------'", ")", "\n", "\n", "\n", "# save to the disk", "\n", "expr_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "opt", ".", "checkpoints_dir", ",", "self", ".", "opt", ".", "dataset", ")", "\n", "self", ".", "opt", ".", "expr_dir", "=", "expr_dir", "\n", "util", ".", "mkdirs", "(", "expr_dir", ")", "\n", "file_name", "=", "os", ".", "path", ".", "join", "(", "expr_dir", ",", "'opt.txt'", ")", "\n", "with", "open", "(", "file_name", ",", "'wt'", ")", "as", "opt_file", ":", "\n", "\t\t\t", "opt_file", ".", "write", "(", "'------------ Options -------------\\n'", ")", "\n", "for", "k", ",", "v", "in", "sorted", "(", "args", ".", "items", "(", ")", ")", ":", "\n", "\t\t\t\t", "opt_file", ".", "write", "(", "'%s: %s\\n'", "%", "(", "str", "(", "k", ")", ",", "str", "(", "v", ")", ")", ")", "\n", "", "opt_file", ".", "write", "(", "'-------------- End ----------------\\n'", ")", "\n", "\n", "", "return", "self", ".", "opt", "\n", "", "", ""]]}